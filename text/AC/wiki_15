<doc id="27934" url="http://en.wikipedia.org/wiki?curid=27934" title="September 27">
September 27

September 27 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27935" url="http://en.wikipedia.org/wiki?curid=27935" title="September 11">
September 11

September 11 is the day of the year in the Gregorian calendar. It is usually the first day of the year in the Coptic calendar and Ethiopian calendar (in the period AD 1900 to AD 2099).

</doc>
<doc id="27936" url="http://en.wikipedia.org/wiki?curid=27936" title="Spider-Man">
Spider-Man

Spider-Man is a fictional superhero appearing in American comic books published by Marvel Comics. Created by writer-editor Stan Lee and writer-artist Steve Ditko, Spider-Man first appeared in "Amazing Fantasy" #15 (Aug. 1962). Lee and Ditko conceived the character as an orphan being raised by his Aunt May and Uncle Ben, and as a teenager, having to deal with the normal struggles of adolescence in addition to those of a costumed crime-fighter. Spider-Man's creators gave him super strength and agility, the ability to cling to most surfaces, shoot spider-webs using wrist-mounted devices of his own invention, which he calls "web-shooters", and react to danger quickly with his "spider-sense", enabling him to combat his foes.
When Spider-Man first appeared in the early 1960s, teenagers in superhero comic books were usually relegated to the role of sidekick to the protagonist. The Spider-Man series broke ground by featuring Peter Parker, the high school student behind Spider-Man's secret identity and with whose "self-obsessions with rejection, inadequacy, and loneliness" young readers could relate. Unlike previous teen heroes such as Bucky and Robin, Spider-Man had no superhero mentor like Captain America and Batman; he thus had to learn for himself that "with great power there must also come great responsibility"—a line included in a text box in the final panel of the first Spider-Man story but later retroactively attributed to his guardian, the late Uncle Ben.
Marvel has featured Spider-Man in several comic book series, the first and longest-lasting of which is titled "The Amazing Spider-Man". Over the years, the Peter Parker character has developed from shy, nerdy high school student to troubled but outgoing college student, to married high school teacher to, in the late 2000s, a single freelance photographer, his most typical adult role. In the 2010s, he joins the Avengers and the Fantastic Four, Marvel's flagship superhero teams. In a 2012–2014 storyline, Peter Parker dies while his mind is in the body of his enemy Doctor Octopus; Doctor Octopus then lives on inside of Parker's body, taking the role of Spider-Man in "The Superior Spider-Man". However, Parker returned to his body in April 2014. Separately, Marvel has also published books featuring alternate versions of Spider-Man, including "Spider-Man 2099", which features the adventures of Miguel O'Hara, the Spider-Man of the future; "Ultimate Spider-Man", which features the adventures of a teenaged Peter Parker in an alternate universe; and "Ultimate Comics Spider-Man", which depicts the teenager Miles Morales, who takes up the mantle of Spider-Man after Ultimate Peter Parker's supposed death.
Spider-Man is one of the most popular and commercially successful superheroes. As Marvel's flagship character and company mascot, he has appeared in many forms of media, including several animated and live-action television shows, syndicated newspaper comic strips, and a series of films starring Tobey Maguire as the hero in the first three movies. Andrew Garfield took over the role of Spider-Man in a reboot of the films. Reeve Carney starred as Spider-Man in the 2010 Broadway musical "". Spider-Man placed 3rd on IGN's Top 100 Comic Book Heroes of All Time in 2011, behind DC Comics characters Superman and Batman.
Publication history.
Creation and development.
In 1962, with the success of the Fantastic Four, Marvel Comics editor and head writer Stan Lee was casting about for a new superhero idea. He said the idea for Spider-Man arose from a surge in teenage demand for comic books, and the desire to create a character with whom teens could identify.:1 In his autobiography, Lee cites the non-superhuman pulp magazine crime fighter the Spider (see also The Spider's Web and The Spider Returns) as a great influence,:130 and in a multitude of print and video interviews, Lee stated he was further inspired by seeing a spider climb up a wall—adding in his autobiography that he has told that story so often he has become unsure of whether or not this is true. At that time Lee had to get only the consent of Marvel publisher Martin Goodman for the character's approval. In a 1986 interview, Lee described in detail his arguments to overcome Goodman's objections. Goodman eventually agreed to a Spider-Man tryout in what Lee in numerous interviews recalled as what would be the final issue of the science-fiction and supernatural anthology series "Amazing Adult Fantasy," which was renamed "Amazing Fantasy" for that single issue, #15 (cover-dated August 1962, on sale June 5, 1962). While this was indeed the final issue, its editorial page anticipated the comic continuing and that "The Spiderman [sic] ... will appear every month in "Amazing"."
Regardless, Lee received Goodman's approval for the name Spider-Man and the "ordinary teen" concept, and approached artist Jack Kirby. As comics historian Greg Theakston recounts, Kirby told Lee about an unpublished character on which he had collaborated with Joe Simon in the 1950s, in which an orphaned boy living with an old couple finds a magic ring that granted him superhuman powers. Lee and Kirby "immediately sat down for a story conference", Theakston writes, and Lee afterward directed Kirby to flesh out the character and draw some pages. Steve Ditko would be the inker. When Kirby showed Lee the first six pages, Lee recalled, "I "hated" the way he was doing it! Not that he did it badly—it just wasn't the character I wanted; it was too heroic".:12 Lee turned to Ditko, who developed a visual style Lee found satisfactory. Ditko recalled:
One of the first things I did was to work up a costume. A vital, visual part of the character. I had to know how he looked ... before I did any breakdowns. For example: A clinging power so he wouldn't have hard shoes or boots, a hidden wrist-shooter versus a web gun and holster, etc. ... I wasn't sure Stan would like the idea of covering the character's face but I did it because it hid an obviously boyish face. It would also add mystery to the character...
Although the interior artwork was by Ditko alone, Lee rejected Ditko's cover art and commissioned Kirby to pencil a cover that Ditko inked. As Lee explained in 2010, "I think I had Jack sketch out a cover for it because I always had a lot of confidence in Jack's covers."
In an early recollection of the character's creation, Ditko described his and Lee's contributions in a mail interview with Gary Martin published in "Comic Fan" #2 (Summer 1965): "Stan Lee thought the name up. I did costume, web gimmick on wrist & spider signal." At the time, Ditko shared a Manhattan studio with noted fetish artist Eric Stanton, an art-school classmate who, in a 1988 interview with Theakston, recalled that although his contribution to Spider-Man was "almost nil", he and Ditko had "worked on storyboards together and I added a few ideas. But the whole thing was created by Steve on his own... I think I added the business about the webs coming out of his hands".:14
Kirby disputed Lee's version of the story, and claimed Lee had minimal involvement in the character's creation. According to Kirby, the idea for Spider-Man had originated with Kirby and Joe Simon, who in the 1950s had developed a character called the Silver Spider for the Crestwood Publications comic "Black Magic," who was subsequently not used. Simon, in his 1990 autobiography, disputed Kirby's account, asserting that "Black Magic" was not a factor, and that he (Simon) devised the name "Spider-Man" (later changed to "The Silver Spider"), while Kirby outlined the character's story and powers. Simon later elaborated that his and Kirby's character conception became the basis for Simon's Archie Comics superhero the Fly. Artist Steve Ditko stated that Lee liked the name Hawkman from DC Comics, and that "Spider-Man" was an outgrowth of that interest.
Simon concurred that Kirby had shown the original Spider-Man version to Lee, who liked the idea and assigned Kirby to draw sample pages of the new character but disliked the results—in Simon's description, "Captain America with cobwebs". Writer Mark Evanier notes that Lee's reasoning that Kirby's character was too heroic seems unlikely—Kirby still drew the covers for "Amazing Fantasy" #15 and the first issue of "The Amazing Spider-Man". Evanier also disputes Kirby's given reason that he was "too busy" to also draw Spider-Man in addition to his other duties since Kirby was, said Evanier, "always busy".:127 Neither Lee's nor Kirby's explanation explains why key story elements like the magic ring were dropped; Evanier states that the most plausible explanation for the sudden change was that Goodman, or one of his assistants, decided that Spider-Man as drawn and envisioned by Kirby was too similar to the Fly.:127
Author and Ditko scholar Blake Bell writes that it was Ditko who noted the similarities to the Fly. Ditko recalled that, "Stan called Jack about the Fly", adding that "[d]ays later, Stan told me I would be penciling the story panel breakdowns from Stan's synopsis". It was at this point that the nature of the strip changed. "Out went the magic ring, adult Spider-Man and whatever legend ideas that Spider-Man story would have contained". Lee gave Ditko the premise of a teenager bitten by a spider and developing powers, a premise Ditko would expand upon to the point he became what Bell describes as "the first work for hire artist of his generation to create and control the narrative arc of his series". On the issue of the initial creation, Ditko states, "I still don't know whose idea was Spider-Man". Kirby noted in a 1971 interview that it was Ditko who "got "Spider-Man" to roll, and the thing caught on because of what he did". Lee, while claiming credit for the initial idea, has acknowledged Ditko's role, stating, "If Steve wants to be called co-creator, I think he deserves [it]". Writer Al Nickerson believes "that Stan Lee and Steve Ditko created the Spider-Man that we are familiar with today [but that] ultimately, Spider-Man came into existence, and prospered, through the efforts of not just one or two, but many, comic book creators".
Commercial success.
A few months after Spider-Man's introduction, publisher Goodman reviewed the sales figures for that issue and was shocked to find it to have been one of the nascent Marvel's highest-selling comics.:97 A solo ongoing series followed, beginning with "The Amazing Spider-Man" #1 (cover-dated March 1963). The title eventually became Marvel's top-selling series:211 with the character swiftly becoming a cultural icon; a 1965 "Esquire" poll of college campuses found that college students ranked Spider-Man and fellow Marvel hero the Hulk alongside Bob Dylan and Che Guevara as their favorite revolutionary icons. One interviewee selected Spider-Man because he was "beset by woes, money problems, and the question of existence. In short, he is one of us.":223 Following Ditko's departure after issue #38 (July 1966), John Romita, Sr. replaced him as penciler and would draw the series for the next several years. In 1968, Romita would also draw the character's extra-length stories in the comics magazine "The Spectacular Spider-Man", a proto-graphic novel designed to appeal to older readers. It only lasted for two issues, but it represented the first Spider-Man spin-off publication, aside from the original series' summer annuals that began in 1964.
An early 1970s Spider-Man story led to the revision of the Comics Code. Previously, the Code forbade the depiction of the use of illegal drugs, even negatively. However, in 1970, the Nixon administration's Department of Health, Education, and Welfare asked Stan Lee to publish an anti-drug message in one of Marvel's top-selling titles.:239 Lee chose the top-selling "The Amazing Spider-Man;" issues #96–98 (May–July 1971) feature a story arc depicting the negative effects of drug use. In the story, Peter Parker's friend Harry Osborn becomes addicted to pills. When Spider-Man fights the Green Goblin (Norman Osborn, Harry's father), Spider-Man defeats the Green Goblin, by revealing Harry's drug addiction. While the story had a clear anti-drug message, the Comics Code Authority refused to issue its seal of approval. Marvel nevertheless published the three issues without the Comics Code Authority's approval or seal. The issues sold so well that the industry's self-censorship was undercut and the Code was subsequently revised.:239
In 1972, a second monthly ongoing series starring Spider-Man began: "Marvel Team-Up," in which Spider-Man was paired with other superheroes and villains. From that point on there have generally been at least two ongoing Spider-Man series at any time. In 1976, his second solo series, "Peter Parker, the Spectacular Spider-Man" began running parallel to the main series. A third series featuring Spider-Man, "Web of Spider-Man", launched in 1985 to replace "Marvel Team-Up". The launch of a fourth monthly title in 1990, the "adjectiveless" "" (with the storyline "Torment"), written and drawn by popular artist Todd McFarlane, debuted with several different covers, all with the same interior content. The various versions combined sold over 3 million copies, an industry record at the time. Several limited series, one-shots, and loosely related comics have also been published, and Spider-Man makes frequent cameos and guest appearances in other comic series.:279 In 1996 "The Sensational Spider-Man" was created to replace "Web of Spider-Man".
In 1998 writer-artist John Byrne revamped the origin of Spider-Man in the 13-issue limited series "" (Dec. 1998 - Oct. 1999), similar to Byrne's adding details and some revisions to Superman's origin in DC Comics' "The Man of Steel". At the same time the original "The Amazing Spider-Man" was ended with issue #441 (Nov. 1998), and "The Amazing Spider-Man" was restarted with vol. 2, #1 (Jan. 1999). In 2003 Marvel reintroduced the original numbering for "The Amazing Spider-Man" and what would have been vol. 2, #59 became issue #500 (Dec. 2003).
When primary series "The Amazing Spider-Man" reached issue #545 (Dec. 2007), Marvel dropped its spin-off ongoing series and instead began publishing "The Amazing Spider-Man" three times monthly, beginning with #546-548 (all Jan. 2008). The three times monthly scheduling of "The Amazing Spider-Man" lasted until November 2010 when the comic book was increased from 22 pages to 30 pages each issue and published only twice a month, beginning with #648-649 (both Nov. 2010). The following year, Marvel launched "Avenging Spider-Man" as the first spinoff ongoing series in addition to the still twice monthly "The Amazing Spider-Man" since the previous ones were cancelled at the end of 2007. The "Amazing" series temporarily ended with issue #700 in December 2012, and was replaced by "The Superior Spider-Man", which had Doctor Octopus serve as the new Spider-Man, having taken over Peter Parker's body. "Superior" was an enormous commercial success for Marvel, and ran for 31-issue before the real Peter Parker returned in a newly relaunched "The Amazing Spider-Man" #1 in April 2014.
Fictional character biography.
In Forest Hills, Queens, New York, high school student Peter Parker is a science-whiz orphan living with his Uncle Ben and Aunt May. As depicted in "Amazing Fantasy" #15 (Aug. 1962), he is bitten by a radioactive spider (erroneously classified as an insect in the panel) at a science exhibit and "acquires the agility and proportionate strength of an arachnid." Along with super strength, Parker gains the ability to adhere to walls and ceilings. Through his native knack for science, he develops a gadget that lets him fire adhesive webbing of his own design through small, wrist-mounted barrels. Initially seeking to capitalize on his new abilities, Parker dons a costume and, as "Spider-Man", becomes a novelty television star. However, "He blithely ignores the chance to stop a fleeing thief, [and] his indifference ironically catches up with him when the same criminal later robs and kills his Uncle Ben." Spider-Man tracks and subdues the killer and learns, in the story's next-to-last caption, "With great power there must also come—great responsibility!"
Despite his superpowers, Parker struggles to help his widowed aunt pay rent, is taunted by his peers—particularly football star Flash Thompson—and, as Spider-Man, engenders the editorial wrath of newspaper publisher J. Jonah Jameson. As he battles his enemies for the first time, Parker finds juggling his personal life and costumed adventures difficult. In time, Peter graduates from high school, and enrolls at Empire State University (a fictional institution evoking the real-life Columbia University and New York University), where he meets roommate and best friend Harry Osborn, and girlfriend Gwen Stacy, and Aunt May introduces him to Mary Jane Watson. As Peter deals with Harry's drug problems, and Harry's father is revealed to be Spider-Man's nemesis the Green Goblin, Peter even attempts to give up his costumed identity for a while. Gwen Stacy's father, New York City Police detective captain George Stacy is accidentally killed during a battle between Spider-Man and Doctor Octopus (#90, Nov. 1970). In the course of his adventures Spider-Man has made a wide variety of friends and contacts within the superhero community, who often come to his aid when he faces problems that he cannot solve on his own.
In issue #121 (June 1973), the Green Goblin throws Gwen Stacy from a tower of either the Brooklyn Bridge (as depicted in the art) or the George Washington Bridge (as given in the text). She dies during Spider-Man's rescue attempt; a note on the letters page of issue #125 states: "It saddens us to say that the whiplash effect she underwent when Spidey's webbing stopped her so suddenly was, in fact, what killed her." The following issue, the Goblin appears to kill himself accidentally in the ensuing battle with Spider-Man.
Working through his grief, Parker eventually develops tentative feelings toward Watson, and the two "become confidants rather than lovers". A romantic relationship eventually develops, with Parker proposing to her in issue #182 (July 1978), and being turned down an issue later. Parker went on to graduate from college in issue #185, and becomes involved with the shy Debra Whitman and the extroverted, flirtatious costumed thief Felicia Hardy, the Black Cat, whom he meets in issue #194 (July 1979).
From 1984 to 1988, Spider-Man wore a black costume with a white spider design on his chest. The new costume originated in the "Secret Wars" limited series, on an alien planet where Spider-Man participates in a battle between Earth's major superheroes and villains. He continues wearing the costume when he returns from the Secret Wars, starting in "The Amazing Spider-Man" #252. Not unexpectedly, the change to a longstanding character's iconic design met with controversy, "with many hardcore comics fans decrying it as tantamount to sacrilege. Spider-Man's traditional red and blue costume was iconic, they argued, on par with those of his D.C. rivals Superman and Batman." The creators then revealed the costume was an alien symbiote which Spider-Man is able to reject after a difficult struggle, though the symbiote returns several times as Venom for revenge.
Parker proposes to Watson a second time in "The Amazing Spider-Man" #290 (July 1987), and she accepts two issues later, with the wedding taking place in "The Amazing Spider-Man Annual" #21 (1987)—promoted with a real-life mock wedding using actors (with model Tara Shannon as Watson) at Shea Stadium, with Stan Lee officiating, on June 5, 1987. However, David Michelinie, who scripted based on a plot by editor-in-chief Jim Shooter, said in 2007, "I didn't think they actually should [have gotten] married. ... I had actually planned another version, one that wasn't used."
In a controversial storyline, Peter becomes convinced that Ben Reilly, the Scarlet Spider (a clone of Peter created by his college professor Miles Warren) is the real Peter Parker, and that he, Peter, is the clone. Peter gives up the Spider-Man identity to Reilly for a time, until Reilly is killed by the returning Green Goblin and revealed to be the clone after all. In stories published in 2005 and 2006 (such as ""), he develops additional spider-like abilities including biological web-shooters, toxic stingers that extend from his forearms, the ability to stick individuals to his back, enhanced Spider-sense and night vision, and increased strength and speed. Peter later becomes a member of the New Avengers, and reveals his civilian identity to the world, furthering his already numerous problems. His marriage to Mary Jane and public unmasking are later erased in another controversial storyline "", in a Faustian bargain with the demon Mephisto, resulting in several adjustments to the timeline, such as the resurrection of Harry Osborn, the erasure of Parker's marriage, and the return of his traditional tools and powers.
That storyline came at the behest of editor-in-chief Joe Quesada, who said, "Peter being single is an intrinsic part of the very foundation of the world of Spider-Man". It caused unusual public friction between Quesada and writer J. Michael Straczynski, who "told Joe that I was going to take my name off the last two issues of the [story] arc" but was talked out of doing so. At issue with Straczynski's climax to the arc, Quesada said, was
...that we didn't receive the story and methodology to the resolution that we were all expecting. What made that very problematic is that we had four writers and artists well underway on [the sequel arc] "Brand New Day" that were expecting and needed "One More Day" to end in the way that we had all agreed it would. ... The fact that we had to ask for the story to move back to its original intent understandably made Joe upset and caused some major delays and page increases in the series. Also, the science that Joe was going to apply to the retcon of the marriage would have made over 30 years of Spider-Man books worthless, because they never would have had happened. ...[I]t would have reset way too many things outside of the Spider-Man titles. We just couldn't go there...
Following the "reboot", Parker's identity was no longer known to the general public; however, he revealed it to his teammates in the New Avengers and his friends in the Fantastic Four, and others have deduced it. Parker's Aunt May married J. Jonah Jameson's father, Jay Jameson. Jonah himself has been elected Mayor of New York City, and Parker became an employee of the think-tank Horizon Labs.
In issue #700, after the dying supervillain Doctor Octopus has swapped bodies with him, Parker dies. However, the ending of "The Superior Spider-Man" #1 it shows that Parker still exists within Doctor Octopus's mind. It is later revealed that the Peter Parker persona within Doctor Octopus's mind were just memories that he absorbed from Peter Parker, which he later purges to be completely free to control Parker's former body. However, Peter's consciousness is revealed to still exist, having somehow escaped the mind-purge from Doctor Octopus, but Peter decided to keep a low profile to prevent Doctor Octopus from attempting to erase him again. Doctor Octopus found himself overwhelmed while battling the Green Goblin with few resources or allies. Realizing he had failed as the "superior" Spider-Man he claimed to be, Doctor Octopus let the consciousness of Parker reclaim his body.
Following Peter Parker's return, "The Amazing Spider-Man" was re-launched in April 2014. Parker's consciousness has returned to its body but he has no memories of what Doctor Octopus did while in his body. Parker begins to deal with the fallout of Doctor Octopus' possession.
Personality.
"People often say glibly that Marvel succeeded by blending super hero adventure stories with soap opera. What Lee and Ditko actually did in "The Amazing Spider-Man" was to make the series an ongoing novelistic chronicle of the lead character's life. Most super heroes had problems no more complex or relevant to their readers' lives than thwarting this month's bad guys... Parker had far more serious concern in his life: coming to terms with the death of a loved one, falling in love for the first time, struggling to make a living, and undergoing crises of conscience."
Comics historian Peter Sanderson
As one contemporaneous journalist observed, "Spider-Man has a terrible identity problem, a marked inferiority complex, and a fear of women. He is anti-social, ["sic"] castration-ridden, racked with Oedipal guilt, and accident-prone ... [a] functioning neurotic". Agonizing over his choices, always attempting to do right, he is nonetheless viewed with suspicion by the authorities, who seem unsure as to whether he is a helpful vigilante or a clever criminal.
Notes cultural historian Bradford W. Wright,
Spider-Man's plight was to be misunderstood and persecuted by the very public that he swore to protect. In the first issue of "The Amazing Spider-Man", J. Jonah Jameson, publisher of the "Daily Bugle", launches an editorial campaign against the "Spider-Man menace." The resulting negative publicity exacerbates popular suspicions about the mysterious Spider-Man and makes it impossible for him to earn any more money by performing. Eventually, the bad press leads the authorities to brand him an outlaw. Ironically, Peter finally lands a job as a photographer for Jameson's "Daily Bugle".:212
The mid-1960s stories reflected the political tensions of the time, as early 1960s Marvel stories had often dealt with the Cold War and Communism.:220–223 As Wright observes,
From his high-school beginnings to his entry into college life, Spider-Man remained the superhero most relevant to the world of young people. Fittingly, then, his comic book also contained some of the earliest references to the politics of young people. In 1968, in the wake of actual militant student demonstrations at Columbia University, Peter Parker finds himself in the midst of similar unrest at his Empire State University... Peter has to reconcile his natural sympathy for the students with his assumed obligation to combat lawlessness as Spider-Man. As a law-upholding liberal, he finds himself caught between militant leftism and angry conservatives.:234–235
Powers, skills, and equipment.
A bite from a radioactive spider on a school field trip causes a variety of changes in the body of Peter Parker and gives him superpowers. In the original Lee-Ditko stories, Spider-Man has the ability to cling to walls, superhuman strength, a sixth sense ("spider-sense") that alerts him to danger, perfect balance and equilibrium, as well as superhuman speed and agility. Some of his comic series have him shooting webs from his wrists. Academically brilliant, Parker has expertise in the fields of applied science, chemistry, physics, biology, engineering, mathematics, and mechanics. The character was originally conceived by Stan Lee and Steve Ditko as intellectually gifted, but not a genius; however, later writers have depicted the character as a genius. With his talents, he sews his own costume to conceal his identity, and constructs many devices that complement his powers, most notably mechanical web-shooters. This mechanism ejects an advanced adhesive, releasing web-fluid in a variety of configurations, including a single rope-like strand to swing from, a net to bind enemies, and a simple glob to foul machinery or blind an opponent. He can also weave the web material into simple forms like a shield, a spherical protection or hemispherical barrier, a club, or a hang-glider wing. Other equipment include spider-tracers (spider-shaped adhesive homing beacons keyed to his own spider-sense), a light beacon which can either be used as a flashlight or project a "Spider-Signal" design, and a specially modified camera that can take pictures automatically.
Other versions.
Due to Spider-Man's popularity in the mainstream Marvel Universe, publishers have been able to introduce different variations of Spider-Man outside of mainstream comics as well as reimagined stories in many other multiversed spinoffs such as "Ultimate Spider-Man", "Spider-Man 2099", and "". Marvel has also made its own parodies of Spider-Man in comics such as "Not Brand Echh", which was published in the late 1960s and featured such characters as Peter Pooper alias Spidey-Man, and Peter Porker, the Spectacular Spider-Ham, who appeared in the 1980s. The fictional character has also inspired a number of deratives such as a drawn by
Japanese artist Ryoichi Ikegami as well as Hideshi Hino's "The Bug Boy", which has been cited as inspired by Spider-Man. Also the French comic "Télé-Junior" published strips based on popular TV series. In the late 1970s, the publisher also produced original Spider-Man adventures. Artists included Gérald Forton, who later moved to America and worked for Marvel.
Supporting characters.
Spider-Man has had a large range of supporting characters introduced in the comics that are essential in the issues and storylines that star him. After his parents died, Peter Parker was raised by his loving aunt, May Parker, and his uncle and father figure, Ben Parker. After Uncle Ben is murdered by a burglar, Aunt May is virtually Peter's only family, and she and Peter are very close.
J. Jonah Jameson is depicted as the publisher of the "Daily Bugle" and is Peter Parker's boss and as a harsh critic of Spider-Man, always saying negative things about the superhero in the newspaper. Despite his role as Jameson's publishing editor and confidant Robbie Robertson is always depicted as a supporter of both Peter Parker and Spider-Man.
Eugene "Flash" Thompson is commonly depicted as Parker's high school tormentor and bully, but in later comic issues he becomes a friend to Peter. Meanwhile Harry Osborn, son of Norman Osborn, is most commonly recognized as Peter's best friend but has also been depicted sometimes as his rival in the comics.
Peter Parker's romantic interests range between his first crush, the fellow high-school student Liz Allan, to having his first date with Betty Brant, the secretary to the "Daily Bugle" newspaper publisher J. Jonah Jameson. After his breakup with Betty Brant, Parker eventually falls in love with his college girlfriend Gwen Stacy, daughter of New York City Police Department detective captain George Stacy, both of whom are later killed by supervillain enemies of Spider-Man. Mary Jane Watson eventually became Peter's best friend and then his wife. Felicia Hardy, the Black Cat, is a reformed cat burglar who had been Spider-Man's girlfriend and partner at one point.
Enemies.
Writers and artists over the years have established a rogues gallery of supervillains to face Spider-Man. As with him, the majority of these villains' powers originate with scientific accidents or the misuse of scientific technology, and many have animal-themed costumes or powers. Early on Spider-Man faced such foes as the Chameleon (introduced in "The Amazing Spider-Man" #1, March 1963), the Vulture (#2, May 1963), Doctor Octopus (#3, July 1963), the Sandman (#4, Sept. 1963), the Lizard (#6, Nov. 1963), Electro (#9, Feb. 1964), Mysterio (#13, June 1964), Norman Osborn as the Green Goblin (#14, July 1964), Kraven the Hunter (#15, Aug. 1964), the Scorpion (#20, Jan. 1965), the Rhino (#41, Oct. 1966)—the first original Lee/Romita Spider-Man villain—, the Shocker (#46, March 1967), and the physically powerful and well-connected criminal capo Wilson Fisk, also known as the Kingpin. The Clone Saga introduces college professor Miles Warren, who becomes the Jackal, the antagonist of the storyline. Harry Osborn then replaces Norman as the Green Goblin and also a derivative villain called the Hobgoblin was developed to replace Norman as archenemy in #238 until Norman was revived later. After Spider-Man rejected his symbiotic black costume, Eddie Brock, a bitter ex-journalist with a grudge against Spider-Man, bonded with the symbiote (which also hated Spider-Man for rejecting it), gaining Spider-Man's powers and abilities, and became the villain Venom in issue #298 (May 1988). Brock briefly became an ally to Spider-Man when Carnage, another symbiote-based villain, went on a murderous spree in issue #344. At times these enemies of Spider-Man have formed groups such as the Sinister Six to oppose Spider-Man. Doctor Octopus, Green Goblin (Norman Osborn) and Venom (Eddie Brock) are generally described or written as his archenemies.
Cultural influence.
Comic book writer-editor and historian Paul Kupperberg, in "The Creation of Spider-Man", calls the character's superpowers "nothing too original"; what was original was that outside his secret identity, he was a "nerdy high school student".:5 Going against typical superhero fare, Spider-Man included "heavy doses of soap-opera and elements of melodrama." Kupperberg feels that Lee and Ditko had created something new in the world of comics: "the flawed superhero with everyday problems." This idea spawned a "comics revolution.":6 The insecurity and anxieties in Marvel's early 1960s comic books such as "The Amazing Spider-Man", "The Incredible Hulk", and "X-Men" ushered in a new type of superhero, very different from the certain and all-powerful superheroes before them, and changed the public's perception of them. Spider-Man has become one of the most recognizable fictional characters in the world, and has been used to sell toys, games, cereal, candy, soap, and many other products.
Spider-Man has become Marvel's flagship character, and has often been used as the company mascot. When Marvel became the first comic book company to be listed on the New York Stock Exchange in 1991, the "Wall Street Journal" announced "Spider-Man is coming to Wall Street"; the event was in turn promoted with an actor in a Spider-Man costume accompanying Stan Lee to the Stock Exchange.:254 Since 1962, hundreds of millions of comics featuring the character have been sold around the world.
Spider-Man joined the Macy's Thanksgiving Day Parade from 1987 to 1998 as one of the balloon floats, designed by John Romita Sr., one of the character's signature artists. A new, different Spider-Man balloon float is scheduled to appear from at least 2009 to 2011.
In 1981, skyscraper-safety activist Dan Goodwin, wearing a Spider-Man suit, scaled the Sears Tower in Chicago, Illinois, the Renaissance Tower in Dallas, Texas, and the John Hancock Center in Chicago, Illinois.
When Marvel wanted to issue a story dealing with the immediate aftermath of the September 11 attacks, the company chose the December 2001 issue of "The Amazing Spider-Man".
In 2006, Spider-Man garnered major media coverage with the revelation of the character's secret identity, an event detailed in a full page story in the "New York Post" before the issue containing the story was even released.
In 2008, Marvel announced plans to release a series of educational comics the following year in partnership with the United Nations, depicting Spider-Man alongside UN Peacekeeping Forces to highlight UN peacekeeping missions. A "BusinessWeek" article listed Spider-Man as one of the top ten most intelligent fictional characters in American comics.
Rapper Eminem has cited Spider-Man as one of his favorite comic book superheroes.
In other media.
Spider-Man has appeared in comics, cartoons, films, video games, coloring books, novels, records, and children's books. On television, he first starred in the ABC animated series "Spider-Man" (1967-1970) and the CBS live-action series "The Amazing Spider-Man" (1978–1979), starring Nicholas Hammond. Other animated series featuring the superhero include the syndicated "Spider-Man" (1981–1982), "Spider-Man and His Amazing Friends" (1981–1983), Fox Kids' "Spider-Man" (1994–1998), "Spider-Man Unlimited" (1999–2000), "" (2003), and "The Spectacular Spider-Man" (2008–2009). A new animated series titled "Ultimate Spider-Man", starring Drake Bell, premiered on Disney XD on April 1, 2012.
A tokusatsu show featuring Spider-Man was produced by Toei and aired in Japan. It is commonly referred to by its Japanese pronunciation "Supaidā-Man". Spider-Man also appeared in other print forms besides the comics, including novels, children's books, and the daily newspaper comic strip "The Amazing Spider-Man", which debuted in January 1977, with the earliest installments written by Stan Lee and drawn by John Romita, Sr. Spider-Man has been adapted to other media including games, toys, collectibles, and miscellaneous memorabilia, and has appeared as the main character in numerous computer and video games on over 15 gaming platforms.
Spider-Man was also featured in a trilogy of live-action films directed by Sam Raimi and starring Tobey Maguire as the titular superhero. The first "Spider-Man" film of the trilogy was released on May 3, 2002; its sequel, "Spider-Man 2", was released on June 30, 2004 and the next sequel, "Spider-Man 3", was released on May 4, 2007. A third sequel was originally scheduled to be released in 2011, however Sony later decided to reboot the franchise with a new director and cast. The reboot, titled "The Amazing Spider-Man", was released on July 3, 2012; directed by Marc Webb and starring Andrew Garfield as the new Spider-Man. A sequel titled "The Amazing Spider-Man 2" was released on May 2, 2014. Most recently, Sony and Disney have made a deal for Spider-Man to appear in the Marvel Cinematic Universe. 
A Broadway musical, "", began previews on November 14, 2010 at the Foxwoods Theatre on Broadway, with the official opening night on June 14, 2011. The music and lyrics were written by Bono and The Edge of the rock group U2, with a book by Julie Taymor, Glen Berger, Roberto Aguirre-Sacasa. "Turn Off the Dark" is currently the most expensive musical in Broadway history, costing an estimated $70 million. In addition, the show's unusually high running costs are reported to be about $1.2 million per week.
Awards and recognition.
From the character's inception, Spider-Man stories have won numerous awards, including:

</doc>
<doc id="27939" url="http://en.wikipedia.org/wiki?curid=27939" title="History of Stockholm">
History of Stockholm

The history of Stockholm, capital of Sweden, for many centuries coincided with the development of what is today known as Gamla stan, the Stockholm Old Town. Parts of this article, as a consequence, therefore overlap with the History of Gamla stan.
Furthermore, Stockholm's "raison d'être", always was to be the Swedish capital and by far the largest city in the country, and, consequently, retelling the story of the city without including some of the history of Sweden is virtually impossible.
For a timeline and a list of the historical population see: Timeline of Stockholm history
Origins.
The name 'Stockholm' easily splits into two distinct parts – Stock-holm, "Log-islet", but as no serious explanation to the name has been produced, various myths and legends have attempted to fill in the gap. According to a 17th-century myth the population at the viking settlement Birka decided to found a new settlement, and to determine its location had a log bound with gold drifting in Lake Mälaren. It landed on present day Riddarholmen where today the Tower of Birger Jarl stands, a building, as a consequence, still often erroneously mentioned as the oldest building in Stockholm. The most established explanation for the name are logs driven into the strait passing north of today's old town which dendrochronological examinations in the late 1970s dated to around 1000. While no solid proofs exists, it is often assumed the Three Crown Castle, which preceded the present Stockholm Palace, originated from these wooden structures, and that the medieval city quickly expanded around it in the mid 13th century. In a wider historical context, Stockholm can be thought of as the capital of the Lake Mälaren Region, and as such can trace its origin back to at least two much older cities: Birka (c. 790–975) and Sigtuna, which still exists but dominated the region c. 1000–1240 — a capital which has simply been relocated at a number of occasions.
Middle Ages.
The name Stockholm first appears in historical records in letters written by Birger Jarl and King Valdemar dated 1252. However, the two letters give no information about the appearance of the city and events during the following decades remain diffuse. While the absence of a perpendicular city plan in medieval Stockholm seem do indicate a spontaneous growth, it is known German merchants invited by Birger jarl played an important role in the foundation of the city. Under any circumstance, during the end of the 13th century, Stockholm quickly grew to become not only the largest city in Sweden, but also the "de facto" Swedish political centre and royal residence. So, from its foundation, Stockholm has been the largest and most important Swedish city, inseparable from and dependent of the Swedish government.
During the Kalmar Union (1397–1523), controlling Stockholm was crucial to anyone aspiring to control the kingdom, and the city was consequently repeatedly besieged by various Swedish-Danish fractions. In 1471, Sten Sture the Elder defeated Christian I of Denmark at the Battle of Brunkeberg only to lose the city to Hans of Denmark in 1497. Sten Sture managed to seize power again in 1501 which resulted in a Danish blockade lasting 1502–1509 and eventually a short peace. Hans' son Christian II of Denmark finally conquered it in 1520 and had many leading nobles and burghers of Stockholm beheaded in the so-called Stockholm Bloodbath. When King Gustav Vasa finally besieged and conquered the city three years later, an event which ended the Kalmar Union and the Swedish Middle Ages, he noted every second building in the city was abandoned.
By the end of the 15th century, the population in Stockholm can be estimated to 5,000–7,000 people, which made it a relatively small town compared to several other contemporary European cities. On the other hand, it was far larger than any other city in Sweden. Many of its inhabitants were Germans and Finns, with the former forming a political and economic elite in the city.
During the Middle Ages, export was administered mostly by German merchants living by the squares Kornhamnstorg ("Grain Harbour Square") and Järntorget ("Iron Square") on the southern corner of the city. Regional peasantry supplied the city with food and raw materials, while the craftsmen in the city produced handicrafts, most of whom lived by the central square Stortorget or by the oldest two streets in Stockholm, the names of which still reflects their trade: Köpmangatan ("Merchant Street") and Skomakargatan ("Shoemaker Street") in the central part of the city. Other groups lived by the eastern or western thoroughfares, Västerlånggatan and Österlånggatan.
Early Vasa era.
After Gustav Vasa's siege of Stockholm, he restored the privileges of the city which was beneficiary to the burghers of the city. The king maintained his control over the city by controlling the elections of aldermen and magistrates. By the mid-century, the numbers of officials increased in order to make the management of the city more professional and to ensure the state-controlled trade. Stockholm thus lost much of the independence it had had during the Middle Ages and became politically and financially bound to the state. During the reign of his sons (1561–1611), the city council remained escorted by a royal representative and both magistrates and aldermen were appointed by the king.
Gustav Vasa invited the clergyman Olaus Petri (1493–1552) to become the city secretary of Stockholm. With the two side-by-side, the new ideas of the Protestant Reformation could be quickly implemented, and sermons in the church where held in Swedish starting in 1525 and Latin abolished in 1530. A consequence of this development was a need for separate churches for the numerous German and Finnish-speaking citizens and during the 1530 the still-existent German and Finnish parishes were created. The king was, however, not favourably disposed to older chapels and churches in the city, and he ordered churches and monasteries on the ridges surrounding the city to be demolished, together with the numerous charitable institutions.
Because Stockholm had a city wall, it was exempted from the tax paid by other Swedish cities. During the reign of Gustav Vasa the city's fortifications were reinforced and in the Stockholm Archipelago, Vaxholm was created to guard the inlet from the Baltic. While the medieval structure of Stockholm remained mostly unaltered during the 16th century, the city's social and economic importance grew to the extent that no king could permit the city to determine its own faith – the most important export item being bar iron and the most important destination Lübeck. During the reign of Vasa's sons, trade led many Swedes to settle in the city, but the trade and the capital needed to control it was largely in the hands of the king and German merchants from Lübeck and Danzig. Throughout the era, Sweden could hardly claim the level of government and bureaucracy requisite to a capital in the modern sense, but Stockholm was the kingdom's strongest bastion and the king's main residence. As Eric XIV's pretensions were on par with those of Renaissance princes on the continent, he afforded himself the largest court his finances could possibly support, and the royal castle was thus the biggest employer in the city.
Around 1560–80, most of the citizens, some 8.000 people, still lived on Stadsholmen. This central island was at this time densely settled and the city was now expanding on the ridges surrounding the city. Stockholm had no private palaces at this time and the only larger buildings were the castle, the church, and the former Greyfriars monastery on Riddarholmen. The surrounding ridges, unable to boast a single timber framed building, were mostly used for activities that either required a lot of space, produced odours, or could cause fire. Even though some burghers had secondary residences outside the city, the population living on the ridges, perhaps a quarter of the city's population, were mostly poor, including the royal personnel occupying the ridges north of the city.
Great Power era.
Following the Thirty Years' War (1618–1648), Sweden was determined never to repeat the embarrassment experienced following the death of Gustavus II Adolphus (1594–1632) when Stockholm, still medieval in character, caused hesitation on whether to invite foreign statesmen for fear the lamentable appearance might undermine the nation's authority. Therefore, Stockholm saw many ambitious city plans during the era, of which those for the ridges surrounding today's old town still stands. In accordance to the mercantilism of the era, trade and industry was concentrated to cities where it was easier to control, and Stockholm was of central importance. In a letter in 1636, Chancellor Axel Oxenstierna (1583–1654) wrote that evolving the Swedish capital was a prerequisite for the nation's power and strength and that this would bring all the other cities on their feet. Increased state intervention on city level was not unique to Sweden at this time, but it was probably more prominent in the case of Stockholm than anywhere else in Europe. To this end, the government of the city was reformed and the former volunteered magistrates gradually replaced by professionals with a theoretical education.
Population and city plans.
The process of reshaping Stockholm was initiated by a major fire in 1625 which destroyed the south-western part of today's old town. As a result, two new boulevard-like streets were created — Stora Nygatan and Lilla Nygatan — and along the eastern waterfront the medieval wall was replaced by a row of prestigious palaces — Skeppsbron.
For the ridges surrounding the city – Norrmalm, Östermalm, Kungsholmen, and Södermalm – new city plans were worked out to create wide and straight artery streets. The project was implemented so thoroughly, in several parts of the city no traces exist of the previous medieval structures. Many of the streets from this era are still extant, and some of those proposed have been realised with some minor modifications.
The population grew from less than 10,000 in the early 17th century to more than 50,000 in the mid-1670s.
The city's income rose from 18,595 daler in 1635–36 to 81,480 daler in 1644. In 1642, approximately 60 per cent of that sum was spent on construction works.
Trade.
Other Swedish cities were deprived of their export privileges by the so-called "Bothnian Trade Coercion" ("Bottniska handelstvånget"). Most Swedish cities were granted a trade monopoly over a limited surrounding area, but for Stockholm most of the lands surrounding the Gulf of Bothnia formed part of the city's trade territory. However, the state-granted monopoly was not the only thing that favoured Stockholm at that time. It was one of the best natural harbours of the era and throughout the 17th century, countless foreign visitors marvelled at the sight of large ships "with 60 or 70 cannons" moored along the eastern quay next to the royal castle.
In contrast with other Swedish cities, all of which were self-supporting, Stockholm was completely dependent of the transit passing through the city—it had, for example, about the same number of domestic animals as Uppsala, which only had ten per cent the population of the capital. All goods brought into Stockholm had to pass through one of six customs stations, and approximately three-fourths of them were exported from the city. Half of the remaining items, mostly fishery products, were delivered from the Baltic, and corn came from the Lake Mälaren region. However, during the latter half of the century, the rapidly growing capital could not be supported by the Lake Mälaren region alone and therefore became dependent of corn imported from the provinces.
Sweden had played a passive role in international trade during the 16th century; German merchants and ships managed the export of Swedish primary products such as osmond iron, raw copper, and butter. This export was largely regarded as a means of securing the import of items not available in Sweden, such as salt, wine, and luxury goods demanded at the court. With the introduction of a mercantile doctrine around 1620, trade became a keystone to governmental income and the Swedish economy subsequently focused on export, not of raw materials, but of refined products. Over the entire period (c. 1590–1685), Stockholm's share of the national economy remained stable at around two-thirds, but during the first half of the 17th century, export grew fourfold and import fivefold. Most goods were delivered to the Netherlands in the mid-17th century and to the UK in the early 18th century.
Age of Liberty (1718–1772).
Following the Greater Wrath and the Treaty of Nystad in 1722, Sweden's role as a major European power was over, and the decades that followed brought even more disasters. Black death and the sufferings caused by the Great Northern Wars made Stockholm the capital of a shrinking nation, despair which would deepen even further when Sweden lost Finland in 1809. Notwithstanding Sweden's partial recover of spirit with the union with Norway in 1814, during the period 1750–1850, Stockholm was a stagnating city, with a dwindling population and widespread unemployment, marked by ill-health, poverty, alcoholism, and rampant mortality. The Mälaren region lost in influence to the benefit of south-western Sweden, and as population and welfare dwindled in the capital, there was a leveling of social classes. Wars and alcohol abuse resulted in a surplus of women during the period, with widows outnumbering widowers six to one in 1850. Stockholm was marked by an absence of children, caused by the number of unmarried people and high infant mortality. Average length of life was limited to 44, but those who survived infancy were likely to get about as old as people do today, except those born to a life of hard labour.
A stratification into three social groups can be made for this era :
Women were associated with their husband's status. However, as craftsmen saw their status sink with the introduction of industrialism, the proletarian class grew during the period. There also was an economic segregation in the city, with the present old town and the lower parts of Norrmalm being the wealthiest (more than 150% above average); the suburbs (today part of central Stockholm) were poor (50% below average).
During the 18th century the Mercantile model introduced the previous century was further developed, with domestic production promoted by loans and bounties and import limited to raw materials not available in Sweden by tolls. The era saw the rise of the so-called "Skeppsbro Nobility" ("Skeppsbroadeln"), the wealthy wholesalers at Skeppsbron who made a fortune by delivering bar iron to the international market and by controlling the chartered companies. The most successful of them was the Swedish East India Company (1731–1813) which had its headquarters in Gothenburg, but was of significant importance to Stockholm because of the shipbuilding yards, the trade houses, and the exotic products imported by the company. Furthermore, before these ships left Stockholm some 100–150 men per ship were recruited, most of them in the city, and as a single trip to China would take 1–2 years the company had a huge impact on Stockholm during this era.
During the 18th century, several devastating fires destroyed entire neighbourhoods which resulted in building codes being introduced. They improved fire safety by prohibiting wooden buildings and further embellished the city by implementing the 17th century city plans. In the old town, the new royal palace was gradually completed and the exterior of the Storkyrkan church was adopted to it. The skilled artists and craftsmen working for the royal court formed an elite which considerably raised the artistic standards in the capital.
Gustavian era (1772–1809).
During the enlightened absolute monarchy of Gustav III Stockholm managed to maintain its role as the political centre of Sweden and developed culturally.
The king had a great interest for the city's development. He created the Gustav Adolf square and had the Royal Opera inaugurated there in 1782 — in accordance to the original intentions of Tessin the Younger for a monumental square north of the palace. The façade of Arvfurstens palats on the opposite side is identical to the now replaced façade of the opera.
The neoclassical bridge Norrbro, designed by Erik Palmstedt and constructed 1741–1807, was an ambitious project that caused the centre of the city to gradually move out of the medieval city.
The colourful and often burlesque descriptions of Stockholm by troubadour and composer Carl Michael Bellman are still popular.
The period ended as King Gustav IV Adolf was deposed in 1809 in a coup d'état. The loss of Finland that same year meant Stockholm ceased to be the geographical centre of the Swedish kingdom.
Early industrial era (1809–1850).
For Stockholm, the early 19th century meant the only larger-scale projects to be realised were those initiated by the military which favoured a more stiff classicism, the local Swedish version of the Empire style (in Sweden named "Karl Johansstil" after King Charles XIV John). The architects dominating the era, Fredrik Blom and Carl Christoffer Gjörwell, both were commissioned by the military. Due to the general stagnation, few other constructions were realised — in average ten smaller residential buildings per year — additions which the ambitious city plans of the 17th century could easily handle.
During the later half of the 18th century real income dwindled to reach an all-time low in 1810 when it corresponded to roughly half that of the 1730s; public officials being those worst affected. Norrköping became the greatest manufacturing city of Sweden and Gothenburg developed into the key trading port because of its location on the North Sea.
Most people still lived within the present Old Town, with a growth along the eastern shore. Population also grew on the surrounding ridges, more so in the wealthy district Norrmalm and less so in the poor district Södermalm. However, many of the ridges surrounding the city were slums mostly rural in character without water and sewage and frequently ravaged by cholera.
Late industrial era (1850–1910).
In the second half of the century, Stockholm regained its leading economic role. New industries emerged, and Stockholm transformed into an important trade and service centre, as well as a key gateway point within Sweden.
While steam engines were introduced in Stockholm in 1806 with the Eldkvarn mill, it took until the mid-19th century for industrialization to take off. Two factories, Ludvigsberg and Bolinder, constructed in the 1840s were followed by many others, and the economic development that succeeded resulted in some 800 new buildings being constructed 1850–70 — many of which were located in the Klara district and subsequently demolished in the Redevelopment of Norrmalm 1950–70.
During the 1850s and 1860s, gas works, sewage, and running water was introduced. Many street were paved, including Skeppsbron and Strandvägen, and the railway brought Stockholm closer to continental Europe — an event which additionally lead to the creation of the first suburb Liljeholmen where railway workshops were located. As the railway was extended further north, Stockholm Central Station was inaugurated in 1871. The first horse-pulled trams were introduced in 1877. Long before the railway, steam engines became common on boats which resulted in many summertime residences being built around Stockholm. But the booming urban development was also notable in central Stockholm where several prominent Neo-Renaissance buildings were built, including the Academy of Music and Södra Teatern.
In 1866, a commission led by Albert Lindhagen produced a city plan for the ridges ("malmarna") designed to offer citizens light, fresh air and access to Swedish nature by mean of parks and plantations. To this goal, he proposed a system of esplanades culminating in Sveavägen, a 2 km long and 70 m wide boulevard inspired by Champs Elysées. 1877–80 new city plans were finally passed for central Stockholm, which made the city well-prepared for the major expansion that followed. During the 1880s more than 2.000 buildings were added on the ridges and the population grew from 168.000 to 245.000. At the end of the century, less than 40 per cent of the residents were born in Stockholm.
While this demand for housing was mostly dealt with by private entrepreneurs who built on pure speculation, street width and building heights were strictly regulated by the new city plans which ensured the city that evolved was given a uniform design. A trend initiated by the Bünsow House at Strandvägen, the 1880s saw many monumental brick buildings evolve, including Gamla Riksarkivet and the Norstedt Building on Riddarholmen. Before the end of the decade most new buildings were equipped with electricity and telephones were increasingly common. During the 1890, the Neo-Renaissance plaster architecture was replaced by structures in brick and natural stone, largely inspired by French Renaissance architecture. Around what still was factories outside the customs of Stockholm, shacks whose sanitary conditions defied all description evolved. Before the end of the century, however, these were transformed into municipal societies, which facilitated regulation of health and construction, and by the turn of the century the expansion had continued far beyond the city limits, with villa suburbs initiated by individuals adding a mix of purely speculative structures and more qualitative ambitions. The new century saw the introduction of Art Nouveau with the Central Post Office Building by Boberg (1898–1904) and Neo-Baroque with the Riksdag (1894–1906). Throughout the 1910s, trams were electrified and cars were rolling on the streets of Stockholm.
During this period, Stockholm further developed as a cultural and educational centre. In the 19th century, a number of scientific institutes opened in Stockholm, for example the Karolinska Institute. The General Art and Industrial Exposition, an international exhibition of World's Fair status, was held on the island of Djurgården in 1897.
20th century.
In the late 20th century, Stockholm became a modern, technologically advanced and ethnically diverse city. Throughout the century, many industries shifted away from work-intensive activities into more high-technology and service-industry knowledge-based areas.
The city continued to expand and new districts were created, some with high proportions of immigrants. Meanwhile, the inner city (Norrmalm) went through a criticised as well as admired wave of modernisation in the post-war period, the Redevelopment of Norrmalm, securing the city's geographical center as the political and business center for the future.
In 1923 the Stockholm municipal government moved to a new building, the Stockholm City Hall. The Stockholm International Exhibition was held in 1930. In 1967 the city of Stockholm was integrated into Stockholm County.

</doc>
<doc id="27940" url="http://en.wikipedia.org/wiki?curid=27940" title="Culture in Stockholm">
Culture in Stockholm

Apart from being a large city with an active cultural life, Stockholm, the capital of Sweden, houses many national cultural institutions. There are two UNESCO World Heritage sites in the Stockholm County area: the Royal Palace Drottningholm (within Ekerö Municipality) and the Skogskyrkogården (The Woodland Cemetery). 
Stockholm was the 1998 European City of Culture.
Literature.
Authors connected to Stockholm include the poet and songwriter Carl Michael Bellman (1740–1795), novelist and dramatist August Strindberg (1849–1912), and novelist Hjalmar Söderberg (1869–1941), all of whom made Stockholm part of their works. Other authors with notable heritage in Stockholm were the Nobel Prize laureate Eyvind Johnson (1900–1976) and the popular poet and composer Evert Taube (1890–1976). The novelist Per Anders Fogelström (1917–1998) wrote a popular series of historical novels depicting life in Stockholm from the 19th to the mid-20th century.
Architecture.
The city's oldest section is “Gamla Stan” (Old Town), located on the original small islands of the city's earliest settlements and still featuring the medieval street layout. Some notable buildings of Gamla Stan are the large German Church ("Tyska kyrkan") and several mansions and palaces: the "Riddarhuset" (the House of Nobles), the Bonde Palace, the Tessin Palace and the Oxenstierna Palace. The oldest building in Stockholm is the Riddarholmskyrkan from the late 13th century. After a fire in 1697 when the original medieval castle was destroyed, Stockholm Palace was erected in a baroque style. Storkyrkan Cathedral, the episcopal seat of the Bishop of Stockholm, stands next to the castle. It was founded in the 13th century but is clad in a baroque exterior dating to the 18th century.
As early as the 15th century, the city had expanded outside of its original borders. Some pre-industrial, small-scale buildings from this era can still be found in Södermalm. During the 19th century and the age of industrialization Stockholm grew rapidly, with plans and architecture inspired by the large cities of the continent such as Berlin and Vienna. Notable works of this time period include public buildings such as the Royal Swedish Opera and private developments such as the luxury housing developments on Strandvägen.
In the 20th century, a nationalistic push spurred a new architectural style inspired by medieval and renaissance ancestry as well as influences of the Jugend / Art Nouveau style. A key landmark of Stockholm, the Stockholm City Hall, was erected 1911–1923 by architect Ragnar Östberg. Other notable works of these times are the Stockholm Public Library and the Forest Cemetery, Skogskyrkogården
Modernism characterized the style of the Stockholm International Exhibition (1930) and the development of the city as it grew in that decade. New residential areas sprang up such as the development on Gärdet while industrial development added to the growth, such as the KF manufacturing industries on Kvarnholmen located in the Nacka Municipality. In the 1950s, suburban development entered a new phase with the introduction of the Stockholm metro. The modernist developments of Vällingby and Farsta where internationally praised. In the 1960s this suburban development continued but with the aesthetic of the times, the industrialised and mass-produced blocks of flats received a large amount of criticism.
At the same time that this suburban development was happening the most central areas of the inner city were being redesigned. Sergels Torg, with its five high-rise office towers was created in the 1960s, followed by the total clearance of large areas to make room for new development projects. The most notable buildings from this period is the ensemble of the House of Culture, City Theatre and National Bank at Sergels Torg, designed by architect Peter Celsing.
Museums.
Stockholm is one of the most crowded museum-towns in the world with some 70 museums, visited by over 9 million people per year.
One of the most renowned museums is the Nationalmuseum, with the largest national collection of art: 16,000 paintings and 30,000 objects of art handicraft. The collection dates back to the days of Gustav Vasa in the 16th century, and has since been expanded with works by artists such as Rembrandt, and Antoine Watteau, as well as constituting a main part of Sweden's art heritage, manifested in the works of Alexander Roslin, Anders Zorn, Johan Tobias Sergel, Carl Larsson, Carl Fredrik Hill and Ernst Josephson.
The Museum of Modern Art, or Moderna Museet, is Sweden's national museum of modern art. It has works by famous modern artists such as Picasso and Salvador Dalí. 
Other notable museums in Stockholm include:
Theatres.
Distinguished among Stockholm's many theatres are the Royal Dramatic Theatre ("Dramaten"), one of Europe's most renowned theatres, and the Royal Swedish Opera, inaugurated in 1773. 
Other notable theatres are the Stockholm City Theatre, the Peoples Opera ("Folkoperan"), the Modern Theatre of Dance ("Moderna dansteatern"), the China Theatre, the Göta Lejon Theatre, the Mosebacke Theatre, and the Oscar Theatre.
The stages of Stockholm number in their fifties at the least, and a wide variety of plays are constantly on, from classical to newly written.
Media.
Stockholm is basically the media center of Sweden. It has four nation-wide daily newspapers, is also the central location of the publicly funded radio (SR) and television (SVT); in addition, all other major television channels have their base in Stockholm (TV4 TV3, TV6 and Kanal 5). All major magazines are also located to Stockholm, as are the largest literature publisher, the Bonnier group.
Sports.
The most popular spectator sports are football and ice hockey. The three most popular football teams are AIK, Hammarby IF and Djurgårdens IF.
Historically, the city was the host of the 1912 Summer Olympics. From those days stem the Stockholms Olympiastadion which has since hosted numerous sports events, notably football and athletics. Stadion is the previous home arena of AIK and is the current home arena of Djurgårdens IF. For Sweden men's national ice hockey team, the home arena is Ericsson Globe, one of the largest spherical building in the world, but it is also hosting concerts and other events. 
Stockholm also hosted all but one of the Nordic Games, a winter multi-sport event that predated the Winter Olympics.

</doc>
<doc id="27946" url="http://en.wikipedia.org/wiki?curid=27946" title="Stephen R. Lawhead">
Stephen R. Lawhead

Stephen R. Lawhead, born (1950--) 2 1950 (age 64), is a UK–based American writer known for his works of fantasy, science fiction, and historical fiction, particularly Celtic historical fiction. He has written over 24 novels and numerous children's and non-fiction books.
Biography.
He was born to Robert Eugene Lawhead and Lois Rowena Bissell Lawhead at Good Samaritan Hospital, Kearney, Nebraska. In 1968, Lawhead graduated from Kearney High and entered Kearney State College as an Art major. In 1969, while at Kearney State College, he wrote a weekly humour column for the college newspaper and was a frequent contributor of poetry and short stories to "The Shore Anthology" and "The Antler". He paid his way through college largely through playing lead guitar in a college rock band named Mother Rush. Lawhead met Alice Slaikeu in 1971 and married her in 1972. He graduated from Kearney State College in 1973 with BA in Art and then went on to enroll in Northern Baptist Theological Seminary. During this time Lawhead also enrolled in a number of writing courses at nearby Wheaton College. In 1980, Lawhead became the manager of the successful Christian rock act DeGarmo and Key and formed his own record company, Ariel Records. The demise of Ariel Records in 1981 prompted the beginning of Lawhead's fiction-writing career. 
In 1981, Lawhead began to author novels, initially fantasy and science fiction, completing his first trilogy, the "Dragon King trilogy". In 1986, he moved to Oxford, England to do research for The Pendragon Cycle, a reinterpretation of the legend of King Arthur in a Celtic setting combined with elements of Atlantis. Heavily rooted in the original Celtic source material which gave rise to the later and more familiar versions of the Arthurian legend, the series has received critical acclaim for its creative retelling of the Arthur legend and historical credibility. 
The first book in the series, "Taliesin", won the Evangelical Christian Publishers Association's Gold Medallion Award for Fiction in 1988. Lawhead's research for The Pendragon Cycle sparked an interest in Celtic history and culture, especially Celtic Christianity, topics which have featured prominently in his work ever since. 
"The Song of Albion" trilogy prompted a return to England (Lawhead having left in 1987). This was a series of books set between the Celtic Otherworld and present-day Britain. In the 1990s, he published "Byzantium", a work of pure historical fiction, followed by "The Celtic Crusades" trilogy, set at the time of the Crusades, and then "Avalon: The Return of King Arthur", a stand-alone related to the "Pendragon Cycle". 
In 2003, Lawhead published the novel "Patrick: Son of Ireland", a fictionalized account of the early years of Saint Patrick. In 2006, he published "Hood", the first book in the King Raven Trilogy – a retelling of the Robin Hood legend, transferred to Wales. In 2008, the second book in the trilogy, "Scarlet," won a Christy Award in the category of Visionary Fiction.

</doc>
<doc id="27947" url="http://en.wikipedia.org/wiki?curid=27947" title="September 14">
September 14

September 14 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27948" url="http://en.wikipedia.org/wiki?curid=27948" title="September 6">
September 6

September 6 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27949" url="http://en.wikipedia.org/wiki?curid=27949" title="September 7">
September 7

September 7 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27951" url="http://en.wikipedia.org/wiki?curid=27951" title="Servius Tullius">
Servius Tullius

Servius Tullius was the legendary sixth king of Rome, and the second of its Etruscan dynasty. He reigned 578–535 BC. Roman and Greek sources describe his servile origins and later marriage to a daughter of Lucius Tarquinius Priscus, Rome's first Etruscan king, who was assassinated in 579 BC. Servius was variously said to have been the first Roman king to accede without election by the Senate, having gained the throne by popular support, at the contrivance of his mother-in-law; and the first to be elected by the Senate without reference to the people.
Several traditions describe Servius' father as divine. Livy depicts Servius' mother as a captured Latin princess enslaved by the Romans; her child is chosen as Rome's future king after a ring of fire is seen around his head. The Emperor Claudius discounted such origins and described him as an originally Etruscan mercenary, named Mastarna, who fought for Caelius Vibenna
Servius was a popular king, and one of Rome's most significant benefactors. He had military successes against Veii and the Etruscans, and expanded the city to include the Quirinal, Viminal and Esquiline hills. He is credited with the institution of the Compitalia festivals, the building of temples to Fortuna and Diana, and the invention of Rome's first true coinage. Despite the opposition of Rome's patricians, he expanded the Roman franchise and improved the lot and fortune of Rome's lowest classes of citizens and non-citizens. According to Livy, he reigned for 44 years, until murdered by his daughter Tullia and son-in-law Tarquinius Superbus. In consequence of this "tragic crime" and his hubristic arrogance as king, Tarquinius was eventually removed. This cleared the way for the abolition of Rome's monarchy and the founding of the Roman Republic, whose groundwork had already been laid by Servius' reforms.
Background.
Before its establishment as a Republic, Rome was ruled by kings (Latin "reges", singular "rex"). In Roman tradition, Rome's founder Romulus was the first. Servius Tullius was the sixth, and his successor Tarquinius Superbus (Tarquin the Proud) was the last. The nature of Roman kingship is unclear; most Roman kings were elected by the senate, as to a lifetime magistracy, but some claimed succession through dynastic or divine right. Some were native Romans, others were foreign. Later Romans had a complex ideological relationship with this distant past. In Republican mores and institutions kingship was abhorrent; and remained so, in name at least, during the Empire. On the one hand, Romulus was held to have brought Rome into being more-or-less at a stroke, so complete and purely Roman in its essentials that any acceptable change or reform thereafter must be clothed as restoration. On the other, Romans of the Republic and Empire saw each king as contributing in some distinctive and novel way to the city's fabric and territories, or its social, military, religious, legal or political institutions. Servius Tullius has been described as Rome's "second founder", "the most complex and enigmatic" of all its kings, and a kind of "proto-Republican magistrate".
Ancient sources.
The oldest surviving source for the overall political developments of the Roman kingdom and Republic is Cicero's "De republica" ("On the State"), written in 44 BC. The main literary sources for Servius' life and achievements are the Roman historian Livy (59 BC – AD 17), whose Ab urbe condita was generally accepted by the Romans as the standard, most authoritative account; Livy's near contemporary Dionysius of Halicarnassus, and Plutarch (c. 46 – 120 AD); their own sources included works by Quintus Fabius Pictor, Diocles of Peparethus, Quintus Ennius and Cato the Elder. Livy's sources probably included at least some official state records, he excluded what seemed implausible or contradictory traditions, and arranged his material within an overarching chronology. Dionysus and Plutarch offer various alternatives not found in Livy, Livy's own pupil, the etruscologist, historian and emperor Claudius offered yet another, based on Etruscan tradition.
Servius' origins.
Parentage and birth.
Most Roman sources name Servius' mother as Ocrisia, a young noblewoman taken at the Roman siege of Corniculum and brought to Rome, either pregnant by her husband, who was killed at the siege: or as a virgin. She was given to Tanaquil, wife of king Tarquinius, and though slave, was treated with the respect due her former status. In one variant, she became wife to a noble client of Tarquinius. In others, she served the domestic rites of the royal hearth as a Vestal Virgin, and on one such occasion, having damped the hearth flames with a sacrificial offering, she was penetrated by a disembodied phallus that rose from the hearth. According to Tanaquil, this was a divine manifestation, either of the household Lar or Vulcan himself. Thus Servius was divinely fathered and already destined for greatness, despite his mother's servile status; for the time being, Tanaquil and Ocrisia kept this a secret.
Early life.
Servius' birth to a slave of the royal household made him part of Tarquin's extended "familia". Ancient sources infer him as protégé, rather than adopted son, as he married Tarquinius' and Tanaquil's daughter, named by some sources as Gegania. All sources agree that before his accession, either in his early childhood or later, members of the royal household witnessed a nimbus of fire about his head while he slept, a sign of divine favour, and a great portent. He proved a loyal, responsible son-in-law. When given governmental and military responsibilities, he excelled in both.
Reign.
In Livy's account, Tarquinius Priscus had been elected king on the death of the previous king, Ancus Marcius, whose two sons were too young to inherit or offer themselves for election. When Servius' popularity and marriage to Tarquinius made him a likely successor to the kingship, these sons attempted to seize the throne for themselves. They hired two assassins, who attacked and severely wounded Tarquinius. Tanaquil immediately ordered the palace to be shut, and publicly announced from a palace window that Tarquinius had appointed Servius as regent; meanwhile, Tarquinius died of his wounds. When his death became public knowledge, the senate elected Servius as king, and the sons of Ancus fled to exile in Suessa Pometia. Livy describes this as the first occasion that the people of Rome were not involved in the election of the king. In Plutarch, Servius reluctantly consented to the kingship at the death-bed insistence of Tanaquil.
Early in his reign, Servius warred against Veii and the Etruscans. He is said to have shown valour in the campaign, and to have routed a great army of the enemy. His success helped him to cement his position at Rome. According to the "Fasti Triumphales", Servius celebrated three triumphs over the Etruscans, including on 25 November 571 BC and 25 May 567 BC (the date of the third triumph is not legible on the "Fasti").
In Livy's history, Servius Tullius had two daughters, Tullia the younger and Tullia the elder. He arranged their marriage to the two sons of his predecessor, Lucius Tarquinius Priscus. The younger Tullia married Arruns Tarquinius. The elder Tullia married Lucius Tarquinius. But Tullia the younger and Lucius Tarquinius shared a fierce and ambitious temperament, and were drawn together in conspiracy. They procured the murders of their respective siblings, married, and conspired to remove Servius Tullius. Tullia encouraged Lucius Tarquinius to secretly persuade or bribe senators, and Tarquinius went to the senate-house with a group of armed men. Then he summoned the senators and gave a speech criticising Servius: for being a slave born of a slave; for failing to be elected by the Senate and the people during an interregnum, as had been the tradition for the election of kings of Rome; for being gifted the throne by a woman; for favouring the lower classes of Rome over the wealthy and for taking the land of the upper classes for distribution to the poor; and for instituting the census so that the wealth of the upper classes might be exposed to popular envy.
When Servius Tullius arrived at the senate-house to defend his position, Tarquinius threw him down the steps and Servius was murdered in the street by Tarquin's men. Soon after, Tullia drove her chariot over her father's body. For Livy, Tarquinius' impious refusal to permit his father-in-law's burial earned him the sobriquet "Superbus" (arrogant or proud), and Servius' death is a "tragic crime" (tragicum scelus), a dark episode in Rome's history and just cause for the abolition of the monarchy. Servius thus becomes the last of Rome's benevolent kings; the place of this outrage – which Livy seems to suggest as a crossroads – is known thereafter as "Vicus Sceleratus" (street of shame, infamy or crime). His murder is parricide, the worst of all crimes. This morally justifies Tarquin's eventual expulsion and the abolition of Rome's aberrant, "un-Roman" monarchy. Livy's Republic is partly founded on the achievements and death of Rome's last benevolent king.
Servian reforms.
Most of the reforms credited to Servius extended voting rights to certain groups — in particular to Rome's citizen-commoners (known in the Republican era as plebs), minor landholders hitherto disqualified from voting by ancestry, status or ethnicity. The same reforms simultaneously defined the fiscal and military obligations of all Roman citizens. As a whole, the so-called Servian reforms probably represent a long-drawn, complex and piecemeal process of populist policy and reform, extending from Servius' predecessors, Ancus Marcius and Tarquinius Priscus, to his successor Tarquinius Superbus, and into the Middle and Late Republic. Rome's military and territorial expansion and consequent changes in its population would have made franchise regulation and reform an ongoing necessity, and their wholesale attribution to Servius "cannot be taken at face value".
Curiate reform and census.
Until the Servian reforms, the passing of laws and judgment was the prerogative of the "comitia curiata" (curiate assembly), made up from thirty curiae; Roman sources describe ten curiae for each of three aristocratic tribes or clans, each supposedly based on one of Rome's central hills, and claiming patrician status by virtue of their descent from Rome's founding families. These tribes comprised approximately 200 "gentes" (clans), each of which contributed one senator ("elder") to the Senate. The senate advised the king, devised laws in his name, and was held to represent the entire "populus Romanus" (Roman people); but it could only debate and discuss. Its decisions had no force unless approved by the "comitia curiata". By the time of Servius, if not long before, the tribes of the "comitia" were a minority of the population, ruling a multitude with no effective voice in their own government. Rome's far more populous citizen-commoners could participate in this assembly in limited fashion, and perhaps offer their opinions on decisions but only the "comitia curiata" could vote. A minority thus exercised power and control over the majority. Roman tradition held that Servius formed a comitia centuriata of commoners to displace the "comitia curiata" as Rome's central legislative body. This required his development of the first Roman census, making Servius the first Roman censor. For the purposes of the census, citizens assembled by tribe in the Campus Martius to register their social rank, household, property and income. This established an individual's tax obligations, his ability to muster arms for military service when required to do so, and his assignment to a particular voting bloc.
The institution of the census and the "comitia centuriata" are speculated as Servius' attempt to erode the civil and military power of the Roman aristocracy, and seek the direct support of his newly enfranchised citizenry in civil matters; if necessary, under arms. The "comitia curiata" continued to function through the Regal and Republican eras, but the Servian reform had reduced its powers to those of a largely symbolic "upper house" whose noble members were expected to do no more than ratify decisions of the "comitia centuriata".
Classes.
The census grouped Rome's male citizen population in classes, according to status, wealth and age. Each class was subdivided into groups called "centuriae" (centuries), nominally of 100 men (Latin "centum" = 100) but in practice of variable number, further divided as "seniores" (men aged 46 – 60, of a suitable age to serve as "home guards" or city police) and "iuniores" (men aged 17 – 45, to serve as front-line troops when required). Adult male citizens were obliged, when called upon, to fulfill military service according to their means, which was supposedly assessed in archaic "asses". A citizen's wealth and class would therefore have defined their position in the civil hierarchies, and up to a point, within the military; but despite its apparent military character, and its possible origins as the mustering of the citizenry-at-arms, the system would have primarily served to determine the voting qualifications and wealth of individual citizens for taxation purposes, and the weight of their vote — wars were occasional but taxation was a constant necessity — and the comitia centuriata met whenever required to do so, in peace or war. Though each century had voting rights, the wealthiest had the most centuries, and voted first. Those beneath them were convened only in the event of deadlock or indecision; the lowest class was unlikely to vote at all.
The Roman army's "centuria" system and its order of battle are thought to be based on the civilian classifications established by the census. The military selection process picked men from civilian "centuriae" and slipped them into military ones. Their function depended on their age, experience, and the equipment they could afford. The wealthiest class of "iuniores" (aged 17 – 45) were armed as hoplites, heavy infantry with helmet, greaves, breastplate, shields ("clipeus"), and spears ("hastae"). Each battle line in the phalanx formation was composed of a single class. Military specialists, such as trumpeters, were chosen from the 5th class. The highest officers were of aristocratic origin until the early Republic, when the first plebeian tribunes were elected by the plebeians from their own number. Cornell suggests that this centuriate system made the equites, who "consisted mainly, if not exclusively, of patricians" but voted after infantry of the first class, subordinate to the relatively low-status infantry.
Tribal and boundary expansions.
The Servian reforms increased the number of tribes and expanded the city, which was protected by a new rampart, moat and wall. The enclosed area was divided into four administrative "regiones" (regions, or quarters); the Suburana, Esquilana, Collina and Palatina. Servius himself is said to have taken a new residence, on the Esquiline. The situation beyond the walls is unclear, but thereafter, membership of a Roman voting-tribe would have depended on residence rather than ancestry and inheritance. This would have brought significant numbers of urban and rural "plebs" into active political life; and a significant number of these would have been allocated to centuries of the first class, and therefore likely to vote. The city of Rome's division into "quarters" remained in use until 7 BC, when Augustus divided the city into 14 new "regiones". In modern Rome, an ancient portion of surviving wall is attributed to Servius, the remainder supposedly being rebuilt after the sack of Rome in 390/387 BC by the Gauls.
Religion.
Servius is credited with the construction of Diana's temple on the Aventine Hill, to mark the foundation of the so-called Latin League; His servile birth-mythos, his populist leanings and his reorganisation of the "vici" appear to justify the Roman belief that he founded or reformed the Compitalia festivals (held to celebrate the Lares that watched over each local community), or allowed for the first time their attendance and service by non-citizens and slaves. His personal reputation and achievements may have led to his historical association with temples and shrines to Fortuna; some sources suggest that the two were connected during Servius' lifetime, via some form of "sacred marriage". Plutarch explicitly identifies the "Porta Fenestella" ("window gate") of the Royal palace, now lost, as the window from which Tanaquil announced Servius' regency to the people; later, the goddess Fortuna was said to have later passed through the same window, to become Servius' consort.
Historical appraisals.
Birth.
Claims of divine ancestry and divine favour were often attached to charismatic individuals who rose "as if from nowhere" to become dynasts, tyrants and hero-founders in the ancient Mediterranean world. Yet all these legends offer the father as divine, the mother – virgin or not – as princess of a ruling house, never as slave. The disembodied phallus and its impregnation of a virgin slave of Royal birth are unique to Servius. Livy and Dionysius ignore or reject the tales of Servius' supernatural virgin birth; though his parents came from a conquered people, both are of noble stock. His ancestry is an accident of fate, and his character and virtues are entirely Roman. He acts on behalf of the Roman people, not for personal gain; these Roman virtues are likely to find favour with the gods, and win the rewards of good fortune.
The details of Servius' servile birth, miraculous conception and links with divine Fortuna were doubtless embellished after his own time, but the core may have been propagated during his reign. His unconstitutional and seemingly reluctant accession, and his direct appeal to the Roman masses over the heads of the senate may have been interpreted as signs of tyranny. Under these circumstances, an extraordinary personal charisma must have been central to his success. When Servius expanded Romes influence and boundaries, and reorganised its citizenship and armies, his "new Rome" was still centered on the "Comitium", the "Casa Romuli" or "hut" of Romulus. Servius became a second Romulus, a benefactor to his people, part human, part divine; but his slave origins remain without parallel, and make him all the more remarkable: for Cornell, this is "the most important single fact about him". The story of his servile birth evidently circulated far beyond Rome; Mithridates VI of Pontus sneered that Rome had made kings of "servos vernasque Tuscorum" (Etruscan slaves and domestic servants).
Etruscan Servius.
Claudius' story of Servius as an Etruscan named "Macstarna" was published as an incidental scholarly comment within the "Oratio Claudii Caesaris" of the Lugdunum Tablet. There is some support for this Etruscan version of Servius, in wall paintings at the François Tomb in Etruscan Vulci. They were commissioned some time in the second half of the 4th century BC. One panel shows heroic Etruscans putting foreign captives to the sword. The victims include an individual named Gneve Tarchunies Rumach, interpreted as a Roman named Gnaeus Tarquinius, although known Roman history records no Tarquinius of that praenomen. The victors include Aule and Caile Vipinas – known to the Romans as the Vibenna brothers – and their ally Macstrna, who seems instrumental in winning the day. Claudius was certain that Macstarna was simply another name for Servius Tullius, who started his career as an Etruscan ally of the Vibenna brothers and helped them settle Rome's Caelian Hill. Claudius' account evidently drew on sources unavailable to his fellow-historians, or rejected by them. There may have been two different, Servius-like figures, or two different traditions about the same figure. "Macstarna" may have been the name of a once celebrated Etruscan hero, or more speculatively, an Etruscan rendering of Roman "magister" (magistrate). Claudius' "Etruscan Servius" seems less a monarch than a freelance Roman "magister", an "archaic condottiere" who placed himself and his own band of armed clients at Vibenna's service, and may later have seized, rather than settled Rome's Caelian Hill. If the Etruscan Macstarna was identical with the Roman Servius, the latter may have been less monarch than some kind of proto-Republican magistrate given permanent office, perhaps a "magister populi", a war-leader, or in Republican parlance, a "dictator".
Legacy.
Servius political reforms and those of his successor Tarquinius Superbus undermined the bases of aristocratic power and transferred them in part to commoners. Rome's ordinary citizens became a distinct force within Roman politics, entitled to participate in government and bear arms on its behalf, despite the opposition and resentment of Rome's patricians and senate. Tarquinius was ousted by a conspiracy of patricians, not plebeians. Once in existence, the "comitia centuriata" could not be unmade, or its powers reduced: as Republican Rome's highest court of appeal, it had the capacity to overturn court decisions, and the Republican senate was constitutionally obliged to seek its approval. In time, the "comitia centuriata" legitimized the rise to power of a plebeian nobility, and plebeian consuls.
Servius' connections to the Lar and his reform of the vici connect him directly to the founding of Compitalia, instituted to publicly and piously honour his divine parentage – assuming the Lar as his father – to extend his domestic rites into the broader community, to mark his maternal identification with the lower ranks of Roman society and to assert his regal sponsorship and guardianship of their rights. Some time before the Augustan Compitalia reforms of 7 BC, Dionysius of Halicarnassus reports Servius' fathering by a Lar and his founding of Compitalia as ancient Roman traditions. In Servius, Augustus found ready association with a popular benefactor and refounder of Rome, whose reluctance to adopt kingship distanced him from its taints. Augustus brought the Compitalia and its essentially plebeian festivals, customs and political factions under his patronage and if need be, his censorial powers. He did not, however, trace his lineage and his re-founding to Servius – who even with part-divine ancestry still had servile connections – but with Romulus, patrician founding hero, ancestor of the divine Julius Caesar, descendant of Venus and Mars. Plutarch admires the Servian reforms for their imposition of good order in government, the military and public morality, and Servius himself as the wisest, most fortunate and best of all Rome's kings.

</doc>
<doc id="27954" url="http://en.wikipedia.org/wiki?curid=27954" title="Susan B. Anthony">
Susan B. Anthony

Susan Brownell Anthony (February 15, 1820 – March 13, 1906) was an American social reformer and feminist who played a pivotal role in the women's suffrage movement. Born into a Quaker family committed to social equality, she collected anti-slavery petitions at the age of 17. In 1856, she became the New York state agent for the American Anti-Slavery Society.
In 1851, she met Elizabeth Cady Stanton, who became her lifelong friend and co-worker in social reform activities, primarily in the field of women's rights. In 1852, they founded the New York Women's State Temperance Society after Anthony was prevented from speaking at a temperance conference because she was a woman. In 1863, they founded the Women's Loyal National League, which conducted the largest petition drive in the nation's history up to that time, collecting nearly 400,000 signatures in support of the abolition of slavery. In 1866, they initiated the American Equal Rights Association, which campaigned for equal rights for both women and African Americans. In 1868, they began publishing a women's rights newspaper called "The Revolution". In 1869, they founded the National Woman Suffrage Association as part of a split in the women's movement. In 1890 the split was formally healed when their organization merged with the rival American Woman Suffrage Association to form the National American Woman Suffrage Association, with Anthony as its key force. In 1876, Anthony and Stanton began working with Matilda Joslyn Gage on what eventually grew into the six-volume "History of Woman Suffrage". The interests of Anthony and Stanton diverged somewhat in later years, but the two remained close friends.
In 1872, Anthony was arrested for voting in her hometown of Rochester, New York, and convicted in a widely publicized trial. Although she refused to pay the fine, the authorities declined to take further action. In 1878, Anthony and Stanton arranged for Congress to be presented with an amendment giving women the right to vote. Popularly known as the Anthony Amendment, it became the Nineteenth Amendment to the U.S. Constitution in 1920.
Anthony traveled extensively in support of women's suffrage, giving as many as 75 to 100 speeches per year and working on many state campaigns. She worked internationally for women's rights, playing a key role in creating the International Council of Women, which is still active. She also helped to bring about the World's Congress of Representative Women at the World's Columbian Exposition in Chicago in 1893.
When she first began campaigning for women's rights, Anthony was harshly ridiculed and accused of trying to destroy the institution of marriage. Public perception of her changed radically during her lifetime, however. Her 80th birthday was celebrated in the White House at the invitation of President William McKinley. She became the first nonfictitious woman to be depicted on U.S. coinage when her portrait appeared on the 1979 dollar coin.
Biography.
Early life.
Susan Brownell Anthony was born on February 15, 1820, to Daniel Anthony and Lucy Read in Adams, Massachusetts, the second oldest of seven children. Her family shared a passion for social reform. Her brothers Daniel and Merritt moved to Kansas to support the anti-slavery movement there. Merritt fought with John Brown against pro-slavery forces during the Bleeding Kansas crisis. Daniel eventually owned a newspaper and became mayor of Leavenworth.
Anthony's sister Mary, with whom she shared a home in later years, became a public school principal in Rochester, and a woman's rights activist.
Anthony's father was an abolitionist and a temperance advocate. A Quaker, he had a difficult relationship with his traditionalist congregation, which rebuked him for marrying a non-Quaker and then disowned him for allowing a dance school to operate in his home. He continued to attend Quaker meetings anyway and became even more radical in his beliefs. Anthony's mother was not a Quaker but helped raise their children in a more tolerant version of her husband's religious tradition. Their father encouraged them all, girls as well as boys, to be self-supporting, teaching them business principles and giving them responsibilities at an early age.
When Anthony was six years old, her family moved to Battenville, New York, where her father managed a large cotton mill. Previously he had operated his own small cotton factory. During the time period of 1830 to 1836, Miss Anthony attended The Friends' Boarding School in the Black Hill section of Plainfield, Connecticut. The boarding school was run by The Reverend Doctor Rowland Greene, his wife Susanna & Master Doctor Benjamin Greene. Her fellow students included Miss Pheobe Jackson, Master Samuel B. Tobey, and Master Elisha Dyer. Between 1833 & 1834, the students, including Miss Anthony, would walk to visit Miss Prudence Crandall & her school of Young Ladies & Little Misses of Color, who lived approximately 2 miles over the Quinnebaug River in Canterbury, Connecticut. When she was seventeen, Anthony was sent to a Quaker boarding school in Philadelphia, where she unhappily endured its severe atmosphere. She was forced to end her studies after one term because her family was financially ruined during an economic downturn known as the Panic of 1837. They were forced to sell everything they had at an auction, but they were rescued by her maternal uncle, who bought most of their belongings and restored them to the family. To assist her family financially, Anthony left home to teach at a Quaker boarding school.
In 1845, the family moved to a farm on the outskirts of Rochester, New York, purchased partly with the inheritance of Anthony's mother. There they associated with a group of Quaker social reformers who had left their congregation because of the restrictions it placed on reform activities, and who in 1848 formed a new organization called the Congregational Friends. The Anthony farmstead soon became the Sunday afternoon gathering place for local activists, including Frederick Douglass, a former slave and a prominent abolitionist who became Anthony's lifelong friend.
As several others in that group were already doing, the Anthony family began to attend services at the First Unitarian Church of Rochester, which was associated with social reform. A women's rights convention was held at that church in 1848, inspired by the Seneca Falls Convention, the first women's rights convention, which was held two weeks earlier in a nearby town. Anthony's parents and her sister Mary attended the Rochester convention and signed the Declaration of Sentiments that had been first adopted by the Seneca Falls Convention.
Anthony did not take part in either of these conventions because she had moved to Canajoharie in 1846 to be headmistress of the female department of the Canajoharie Academy. Away from Quaker influences for the first time in her life, at the age of 26 she began to replace her plain clothing with more stylish dresses, and she quit using "thee" and other forms of speech traditionally used by Quakers. She was interested in social reform, and she was distressed at being paid much less than men with similar jobs, but she was amused at her father's enthusiasm over the Rochester women's rights convention. She later explained, "I wasn't ready to vote, didn't want to vote, but I did want equal pay for equal work."
When the Canajoharie Academy closed in 1849, Anthony took over the operation of the family farm in Rochester so her father could devote more time to his insurance business. She worked at this task for a couple of years but found herself increasingly drawn to reform activity. With her parents' support, she was soon fully engaged in reform work. For the rest of her life, she lived almost entirely on fees she earned as a speaker.
Early social activism.
Cautious, careful people, always casting about to preserve their reputation and social standing, never can bring about a reform. Those who are really in earnest must be willing to be anything or nothing in the world's estimation, and publicly and privately, in season and out, avow their sympathy with despised and persecuted ideas and their advocates, and bear the consequences.
Susan B. Anthony, 1860
Anthony embarked on her career of social reform with energy and determination. Schooling herself in reform issues, she found herself drawn to the more radical ideas of people like William Lloyd Garrison, George Thompson and Elizabeth Cady Stanton. Soon she was wearing the controversial Bloomer dress, consisting of pantaloons worn under a knee-length dress. Although it was more sensible than the traditional heavy dresses that dragged the ground, she reluctantly quit wearing it after a year because it gave her opponents the opportunity to focus on her apparel rather than her ideas.
Partnership with Elizabeth Cady Stanton.
In 1851, Anthony was introduced to Elizabeth Cady Stanton, who had been one of the organizers of the Seneca Falls Convention and had introduced the controversial resolution in support of women's suffrage. Anthony and Stanton soon became close friends and co-workers, forming a relationship that was pivotal for them and for the women's movement as a whole. After the Stantons moved from Seneca Falls to New York City in 1861, a room was set aside for Anthony in every house they lived in. One of Stanton's biographers estimated that over her lifetime, Stanton spent more time with Anthony than with any other adult, including her own husband.
The two women had complementary skills. Anthony excelled at organizing, while Stanton had an aptitude for intellectual matters and writing. Anthony was dissatisfied with her own writing ability and wrote relatively little for publication. When historians illustrate her thoughts with direct quotes, they usually take them from her speeches, letters and diary entries.
Because Stanton was homebound with seven children while Anthony was unmarried and free to travel, Anthony assisted Stanton by supervising her children while Stanton wrote. One of Anthony's biographers said, "Susan became one of the family and was almost another mother to Mrs. Stanton's children."
A biography of Stanton says that during the early years of their relationship, "Stanton provided the ideas, rhetoric, and strategy; Anthony delivered the speeches, circulated petitions, and rented the halls. Anthony prodded and Stanton produced."
Stanton's husband said, "Susan stirred the puddings, Elizabeth stirred up Susan, and then Susan stirs up the world!" 
Stanton herself said, "I forged the thunderbolts, she fired them."
By 1854, Anthony and Stanton "had perfected a collaboration that made the New York State movement the most sophisticated in the country", according to Ann D. Gordon, a professor of women's history.
Temperance activities.
Temperance was very much a women's rights issue at that time because of laws that gave husbands complete control of the family and its finances. A woman with a drunken husband had little legal recourse even if his alcoholism left the family destitute and he was abusive to her and their children. If she obtained a divorce, which was difficult to do, he could easily end up with guardianship of the children.
While teaching in Canajoharie, Anthony joined the Daughters of Temperance and in 1849 gave her first public speech at one of its meetings.
In 1852, she was elected as a delegate to the state temperance convention, but the chairman stopped her when she tried to speak, saying that women delegates were there only to listen and learn. Anthony and some other women immediately walked out and announced a meeting of their own, which created a committee to organize a women's state convention. Largely organized by Anthony, the convention of 500 women met in Rochester in April and created the Women's State Temperance Society, with Stanton as president and Anthony as state agent.
Anthony and her co-workers collected 28,000 signatures on a petition for a law to prohibit the sale of alcohol in New York State. She organized a hearing on that law before the New York legislature, the first that had been initiated in that state by a group of women. At the organization's convention the following year, however, conservative members attacked Stanton's advocacy of the right of a wife of an alcoholic to obtain a divorce. Stanton was voted out as president, whereupon she and Anthony resigned from the organization.
In 1853, Anthony attended the World's Temperance Convention in New York City, which bogged down for three chaotic days in a dispute about whether women would be allowed to speak there.
Years later, Anthony observed, "No advanced step taken by women has been so bitterly contested as that of speaking in public. For nothing which they have attempted, not even to secure the suffrage, have they been so abused, condemned and antagonized." After this period, Anthony focused her energy on abolitionist and women's rights activities.
Teachers' conventions.
When Anthony tried to speak at the New York State Teachers' Association meeting in 1853, her attempt sparked a half-hour debate among the men about whether it was proper for women to speak in public. Finally allowed to continue, Anthony said, "Do you not see that so long as society says a woman is incompetent to be a lawyer, minister, or doctor, but has ample ability to be a teacher, that every man of you who chooses this profession tacitly acknowledges that he has no more brains than a woman."
At the 1857 teacher's convention, she introduced a resolution calling for the admission of black people to public schools and colleges, but it was rejected as "not a proper subject for discussion." When she introduced another resolution calling for males and females to be educated together at all levels, including colleges, it was fiercely opposed and decisively rejected. One opponent called the idea "a vast social evil... the first step in the school which seeks to abolish marriage, and behind this picture I see a monster of social deformity."
Anthony continued to speak at state teachers' conventions for several years, insisting that women teachers should receive equal pay with men and serve as officers and committee members within the organization.
Early women's rights activities.
Anthony's work for the women's rights movement began at a time when that movement was already gathering momentum. Stanton had helped organize the Seneca Falls Convention in 1848, a local event that was the first women's rights convention. In 1850, the first in a series of National Women's Rights Conventions was held in Worcester, Massachusetts. In 1852, Anthony attended her first National Women's Rights Convention, which was held in Syracuse, New York, where she served as one of the convention's secretaries.
A major hindrance to the women's movement was a lack of money. Few women at that time had an independent source of income, and even those with employment generally were required by law to turn over their pay to their husbands. 
Partly through the efforts of the women's movement, a law had been passed in New York in 1848 that recognized some rights for married women, but that law was limited. In 1853, Anthony worked with William Henry Channing, her activist Unitarian minister, to organize a convention in Rochester to launch a state campaign for improved property rights for married women, which Anthony would lead. She took her lecture and petition campaign into almost every county in New York during the winter of 1855 despite the difficulty of traveling in snowy terrain in horse and buggy days.
When she presented the petitions to the New York State Senate Judiciary Committee, its members told her that men were actually the oppressed sex because they did such things as giving women the best seats in carriages. Noting cases in which the petition had been signed by both husbands and wives (instead of the husband signing for both, which was the standard procedure), the committee's official report sarcastically recommended that the petitioners seek a law authorizing the husbands in such marriages to wear petticoats and the wives trousers.
The campaign finally achieved success in 1860 when the legislature passed an improved Married Women's Property Act that gave married women the right to own separate property, enter into contracts and be joint guardian of their children. The legislature rolled back much of this law in 1862, however, during a period when the women's movement was largely inactive because of the American Civil War.
The women's movement was loosely structured at that time, with few state organizations and no national organization other than a coordinating committee that arranged annual conventions.
Lucy Stone, who did much of the organizational work for the national conventions, encouraged Anthony to take over some of the responsibility for them. Anthony resisted at first, feeling that she was needed more in the field of anti-slavery activities. After organizing a series of anti-slavery meetings in the winter of 1857, Anthony told a friend that, "the experience of the last winter is worth more to me than all my temperance and woman's rights work, though the latter were the school necessary to bring me into the antislavery work." 
During a planning session for the 1858 women's rights convention, Stone, who had recently given birth, told Anthony that her new family responsibilities would prevent her from organizing conventions until her children were older. Anthony presided at the 1858 convention, and when the planning committee for national conventions was reorganized, Stanton became its president and Anthony its secretary.
Anthony continued to be heavily involved in anti-slavery work at the same time.
Anti-slavery activities.
In 1837, at age 16, Anthony collected petitions against slavery as part of organized resistance to the newly established gag rule that prohibited anti-slavery petitions in the U.S. House of Representatives.
In 1851, she played a key role in organizing an anti-slavery convention in Rochester.
She was also part of the Underground Railroad. An entry in her diary in 1861 read, "Fitted out a fugitive slave for Canada with the help of Harriet Tubman."
In 1856, Anthony agreed to become the New York State agent for the American Anti-Slavery Society with the understanding that she would also continue her advocacy of women's rights.
Anthony organized anti-slavery meetings throughout the state under banners that read "No compromise with slaveholders. Immediate and Unconditional Emancipation."
She developed a reputation for fearlessness in facing down attempts to disrupt her meetings, but opposition became overwhelming on the eve of the Civil War. Mob action shut down her meetings in every town from Buffalo to Albany in early 1861. In Rochester, the police had to escort Anthony and other speakers from the building for their own safety. In Syracuse, according to a local newspaper, "Rotten eggs were thrown, benches broken, and knives and pistols gleamed in every direction."
Anthony expressed a vision of a racially integrated society that was radical for a time when abolitionists were debating the question of what was to become of the slaves after they were freed, and when people like Abraham Lincoln were calling for African Americans to be shipped to newly established colonies in Africa. In a speech in 1861, Anthony said, "Let us open to the colored man all our schools ... Let us admit him into all our mechanic shops, stores, offices, and lucrative business avocations ... let him rent such pew in the church, and occupy such seat in the theatre ... Extend to him all the rights of Citizenship.".
The relatively small women's rights movement of that time was closely associated with the abolitionist movement, especially the American Anti-Slavery Society led by William Lloyd Garrison. The women's movement depended heavily on abolitionist resources, with its articles published in their newspapers and some of its funding provided by abolitionists. There was tension, however, between leaders of the women's movement and male abolitionists who, although supporters of increased women's rights, believed that a vigorous campaign for women's rights would interfere with the campaign against slavery. In 1860, when Anthony sheltered a woman who had fled an abusive husband, Garrison insisted that the woman give up the child she had brought with her, pointing out that the law gave husbands complete control of children. Anthony reminded Garrison that he helped slaves escape to Canada in violation of the law and said, "Well, the law which gives the father ownership of the children is just as wicked and I'll break it just as quickly."
When Stanton introduced a resolution at the National Woman's Rights Convention in 1860 favoring more lenient divorce laws, leading abolitionist Wendell Phillips not only opposed it but attempted to have it removed from the record. When Stanton, Anthony, and others supported a bill before the New York legislature that would permit divorce in cases of desertion or inhuman treatment, Horace Greeley, an abolitionist newspaper publisher, campaigned against it in the pages of his newspaper.
Garrison, Phillips and Greeley had all provided valuable help to the women's movement. In a letter to Lucy Stone, Anthony said, "The Men, even the "best" of them, seem to think the Women's Rights question should be waived for the present. So let us do our own work, and in our own way."
Women's Loyal National League.
Anthony and Stanton organized the Women's Loyal National League in 1863 to campaign for an amendment to the U.S. Constitution that would abolish slavery. 
It was the first national women's political organization in the United States. In the largest petition drive in the nation's history up to that time, the League collected nearly 400,000 signatures to abolish slavery, representing approximately one out of every twenty-four adults in the Northern states.
The petition drive significantly assisted the passage of the Thirteenth Amendment, which ended slavery. Anthony was the chief organizer of this effort, which involved recruiting and coordinating some 2000 petition collectors.
The League provided the women's movement with a vehicle for combining the fight against slavery with the fight for women's rights by reminding the public that petitioning was the only political tool available to women at a time when only men were allowed to vote.
With a membership of 5000, it helped develop a new generation of women leaders, providing experience and recognition not only for Stanton and Anthony but also for newcomers like Anna Dickenson, a gifted teenaged orator.
The League demonstrated the value of formal structure to a women's movement that had resisted being anything other than loosely organized up to that point.
The widespread network of women activists who assisted the League expanded the pool of talent that was available to reform movements, including the women's suffrage movement, after the war.
American Equal Rights Association.
Anthony stayed with her brother Daniel in Kansas for eight months in 1865 to assist with his newspaper. She headed back east after she learned that an amendment to the U.S. Constitution had been proposed that would provide citizenship for African Americans but would also for the first time introduce the word "male" into the constitution. Anthony supported citizenship for blacks but opposed any attempt to link it with a reduction in the status of women. Her ally Stanton agreed, saying "if that word 'male' be inserted, it will take us a century at least to get it out."
Anthony and Stanton worked to revive the women's rights movement, which had become nearly dormant during the Civil War. In 1866 they organized the Eleventh National Women's Rights Convention, the first since the Civil War began.
Unanimously adopting a resolution introduced by Anthony, the convention voted to transform itself into the American Equal Rights Association (AERA), whose purpose was to campaign for the equal rights of all citizens, especially the right of suffrage.
The leadership of the new organization included such prominent activists as Lucretia Mott, Lucy Stone and Frederick Douglass. Its drive for universal suffrage, however, was resisted by some abolitionist leaders and their allies in the Republican Party, who wanted women to postpone their campaign for suffrage until after it had been achieved for male African Americans. Horace Greeley, a prominent newspaper editor, told Anthony and Stanton, "This is a critical period for the Republican Party and the life of our Nation... I conjure you to remember that this is 'the negro's hour,' and your first duty now is to go through the State and plead his claims." Anthony and Stanton refused to postpone their demands and continued to push for universal suffrage.
In 1867 the AERA campaigned in Kansas for referenda that would enfranchise both African Americans and women. Wendell Phillips, an abolitionist leader who opposed mixing those two causes, blocked the funding that the AERA had expected for their campaign.
After an internal struggle, Kansas Republicans decided to support suffrage for black men only and formed an "Anti Female Suffrage Committee" to oppose the AERA's efforts. 
By the end of summer the AERA campaign had almost collapsed, and its finances were exhausted.
Anthony and Stanton created a storm of controversy by accepting help during the last days of the campaign from George Francis Train, a wealthy businessman who supported women's rights. Train antagonized many activists by attacking the Republican Party and openly disparaging the integrity and intelligence of African Americans.
There is reason to believe, however, that Anthony and Stanton hoped to draw the volatile Train away from his cruder forms of racism, and that he had actually begun to do so.
After the Kansas campaign, the AERA increasingly divided into two wings, both advocating universal suffrage but with different approaches. One wing, whose leading figure was Lucy Stone, was willing for black men to achieve suffrage first and wanted to maintain close ties with the Republican Party and the abolitionist movement. The other, whose leading figures were Anthony and Stanton, insisted that women and black men should be enfranchised at the same time and worked toward a politically independent women's movement that would no longer be dependent on abolitionists. The AERA effectively dissolved after an acrimonious meeting in May 1869, and two competing woman suffrage organizations were created in its aftermath.
"The Revolution".
Anthony and Stanton began publishing a weekly newspaper called "The Revolution" in New York City in 1868. It focused primarily on women's rights, especially suffrage for women, but it also covered other topics, including politics, the labor movement and finance. One of its goals was to provide a forum in which women could exchange opinions on key issues from a variety of viewpoints. Anthony managed the business aspects of the paper while Stanton was co-editor along with Parker Pillsbury, an abolitionist and a supporter of women's rights. Initial funding was provided by George Francis Train, the controversial businessman who supported women's rights but who alienated many activists with his political and racial views.
In the aftermath of the Civil War, major periodicals associated with the radical social reform movements had either become more conservative or had quit publishing or soon would.
Anthony intended for "The Revolution" to partially fill that void, hoping to grow it eventually into a daily paper with its own printing press, all owned and operated by women. The funding Train had arranged for the newspaper, however, was less than Anthony had expected. Moreover, Train sailed for England after "The Revolution" published its first issue and was soon jailed for supporting Irish independence.
Train's financial support eventually disappeared entirely. After twenty-nine months, mounting debts forced Anthony to transfer the paper to Laura Curtis Bullard, a wealthy women's rights activist who gave it a less radical tone. The paper published its last issue less than two years later.
Despite its short life, "The Revolution" gave Anthony and Stanton a means for expressing their views during the developing split within the women's movement. It also helped them promote their wing of the movement, which eventually became a separate organization.
Attempted alliance with labor.
The National Labor Union (NLU), which was formed in 1866, began reaching out to farmers, African Americans and women, with the intention of forming a broad-based political party. "The Revolution" responded enthusiastically, declaring, "The principles of the National Labor Union are our principles." It predicted that "The producers—the working-men, the women, the negroes—are destined to form a triple power that shall speedily wrest the sceptre of government from the non-producers—the land monopolists, the bond-holders, the politicians."
Anthony and Stanton were seated as delegates to the NLU Congress in 1868, with Anthony representing the Working Women's Association (WWA), which had recently been formed in the offices of "The Revolution".
The attempted alliance did not last long. During a printers' strike in 1869, Anthony voiced approval of an employer-sponsored training program that would teach women skills that would enable them in effect to replace the strikers. Anthony viewed the program as an opportunity to increase employment of women in a trade from which women were often excluded by both employers and unions. At the next NLU Congress, Anthony was first seated as a delegate but then unseated because of strong opposition from those who accused her of supporting strikebreakers.
Anthony worked with the WWA to form all-female labor unions, but with little success. She accomplished more in her work with the joint campaign by the WWA and "The Revolution" to win a pardon for Hester Vaughn, a domestic worker who had been found guilty of infanticide and sentenced to death. Charging that the social and legal systems treated women unfairly, the WWA petitioned, organized a mass meeting at which Anthony was one of the speakers, and sent delegations to visit Vaughn in prison and to speak with the governor. Vaughn was eventually pardoned.
Originally with a membership that included over a hundred wage-earning women, the WWA evolved into an organization consisting almost entirely of journalists, doctors and other middle-class working women. Its members formed the core of the New York City portion of the new national suffrage organization that Anthony and Stanton were in the process of forming.
Split in the women's movement.
In May 1869, two days after the final AERA convention, Anthony, Stanton and others formed the National Woman Suffrage Association (NWSA). In November 1869, Lucy Stone, Julia Ward Howe and others formed the competing American Woman Suffrage Association (AWSA). The hostile nature of their rivalry created a partisan atmosphere that endured for decades, affecting even professional historians of the women's movement.
The immediate cause for the split was the proposed Fifteenth Amendment to the U.S. Constitution, which would prohibit the denial of suffrage because of race. In one of her most controversial actions, Anthony opposed the amendment. She and Stanton campaigned against it because they believed that by effectively enfranchising all men while excluding all women, the amendment would create an "aristocracy of sex" by giving constitutional authority to the idea that men were superior to women. They wanted women and African Americans to be enfranchised at the same time.
The AWSA supported the amendment, but Lucy Stone, who became its most prominent leader, also made it clear that she believed that suffrage for women would be more beneficial to the country than suffrage for black men.
The two organizations had other differences as well. The NWSA was politically independent, but the AWSA at least initially aimed for close ties with the Republican Party, hoping that the ratification of the Fifteenth Amendment would lead to a Republican push for women's suffrage. The NWSA focused primarily on winning suffrage at the national level while the AWSA pursued a state-by-state strategy. The NWSA initially worked on a wider range of women's issues than the AWSA, including divorce reform and equal pay for women.
Events soon removed much of the basis for the split in the women's movement. In 1870, debate about the Fifteenth Amendment was made irrelevant when that amendment was officially ratified. In 1872, disgust with corruption in government led to a mass defection of abolitionists and other social reformers from the Republicans to the short-lived Liberal Republican Party. As early as 1875, Anthony began urging the NWSA to focus more exclusively on women's suffrage rather than a variety of women's issues. The rivalry between the two women's groups was so bitter, however, that a merger proved to be impossible for twenty years. The AWSA, which was especially strong in New England, was the larger of the two organizations, but it began to decline in strength during the 1880s.
In 1890, the two organizations merged as the National American Woman Suffrage Association (NAWSA), with Stanton as president but with Anthony as its effective leader. When Stanton retired from her post in 1892, Anthony became NAWSA's president.
National suffrage works.
"By the end of the Civil War," according to historian Ann D. Gordon, "Susan B. Anthony occupied new social and political territory. She was emerging on the national scene as a female leader, something new in American history, and she did so as a single woman in a culture that perceived the spinster as anomalous and unguarded ... By the 1880s, she was among the senior political figures in the United States."
After the formation of the NWSA, Anthony dedicated herself fully to the organization and to women's suffrage. She did not draw a salary from either it or its successor, the NAWSA, but on the contrary used her lecture fees to fund those organizations. There was no national office, the mailing address being simply that of one of the officers.
That Anthony had remained unmarried gave her an important business advantage in this work. A married woman at that time had the legal status of "feme covert", which, among other things, excluded her from signing contracts (her husband could do that for her, if he chose). As Anthony had no husband, she was a "feme sole" and could freely sign contracts for convention halls, printed materials, etc.
Using fees she earned by lecturing, she paid off the debts she had accumulated while supporting "The Revolution". With the press treating her as a celebrity, she proved to be a major draw. Over her career she estimated that she averaged 75 to 100 speeches per year. Travel conditions in the earlier days were sometimes appalling. Once she gave a speech from the top of a billiard table. On another occasion her train was snowbound for days, and she survived on crackers and dried fish.
Both Anthony and Stanton joined the lecture circuit about 1870, usually traveling from mid-autumn to spring. The timing was right because the nation was beginning to discuss women's suffrage as a serious matter. Occasionally they traveled together but most often not. Lecture bureaus scheduled their tours and handled the travel arrangements, which generally involved traveling during the day and speaking at night, sometimes for weeks at a time, including weekends. Their lectures brought new recruits into the movement who strengthened suffrage organizations at the local, state and national levels. Their journeys during that decade covered a distance that was unmatched by any other reformer or politician.
Anthony's other suffrage work included organizing national conventions, lobbying Congress and state legislatures, and participating in a seemingly endless series of state suffrage campaigns.
A special opportunity arose in 1876 when the U.S. celebrated its 100th birthday as an independent country. The NWSA asked permission to present a Declaration of Rights for Women at the official ceremony in Philadelphia, but was refused. Undaunted, five women, headed by Anthony, walked onto the platform during the ceremony and handed their Declaration to the startled official in charge. As they left, they handed out copies of it to the crowd. Spotting an unoccupied bandstand outside the hall, Anthony mounted it and read the Declaration to a large crowd. Afterwards she invited everyone to a NWSA convention at the nearby Unitarian church where speakers like Lucretia Mott and Elizabeth Cady Stanton awaited them.
The work of all segments of the women's suffrage movement began to show clear results. Women won the right to vote in Wyoming in 1869 and in Utah in 1870. Her lectures in Washington and four other states led directly to invitations for her to address the state legislatures there.
The Grange, a large advocacy group for farmers, officially supported women's suffrage as early as 1885. The Women's Christian Temperance Union, the largest women's organization in the country, also supported suffrage
Anthony's commitment to the movement, her spartan lifestyle, and the fact that she did not seek personal financial gain, made her an effective fund-raiser and won her the admiration of many who did not agree with her goals. As her reputation grew, her working and travel conditions improved. She sometimes had the use of the private railroad car of Jane Stanford, a sympathizer whose husband owned a major railroad. While lobbying and preparing for the annual suffrage conventions in Washington, she was provided with a free suite of rooms in the Riggs Hotel, whose owners supported her work.
To ensure continuity, Anthony trained a group of younger activists, who were known as her "nieces," to assume leadership roles within the organization. Two of them, Carrie Chapman Catt and Anna Howard Shaw, served as presidents of the NAWSA after Anthony retired from that position.
"United States v. Susan B. Anthony".
The NWSA convention of 1871 adopted a strategy of urging women to attempt to vote, and then, after being turned away, to file suits in federal courts demanding that their right to vote be recognized. The legal basis for the challenge would be the recently adopted Fourteenth Amendment.
Section 1 of that amendment reads, "All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States; nor shall any State deprive any person of life, liberty, or property, without due process of law; nor deny to any person within its jurisdiction the equal protection of the laws."
Anthony and nearly fifty other women in Rochester attempted to vote in the presidential election of 1872. Fifteen of them convinced the election inspectors to allow them to cast ballots, but the others were turned back. There had been earlier cases of women attempting to vote, and even some cases of success, but the reaction of the authorities had been muted. When Anthony voted, however, the reaction was different, and her case became a national controversy.
Anthony was arrested on November 18, 1872, by a U.S. Deputy Marshal and charged with illegally voting. The other fourteen women were also arrested but released pending the outcome of Anthony's trial.
Anthony spoke in all 29 towns and villages of Monroe County, New York, where her trial was to be held, asking "Is it a Crime for a U.S. Citizen to Vote?" She said the Fourteenth Amendment gave her that right, proclaiming, "We no longer petition legislature or Congress to give us the right to vote, but appeal to women everywhere to exercise their too long neglected 'citizen's right'".
Her speech was printed in its entirety in one of the Rochester daily newspapers, which further spread her message to potential jurors.
Worried that Anthony's speeches would influence the jury, the district attorney arranged for the trial to be moved to the federal circuit court, which would soon sit in neighboring Ontario County. Anthony responded by speaking in every village in that county also before the trial began. Responsibility for that federal circuit was in the hands of Justice Ward Hunt, who had recently been appointed to the U.S. Supreme Court. Hunt had never served as a trial judge; originally a politician, he had begun his judicial career by being elected to the New York Court of Appeals.
Anthony's trial was a major step in the transition of the women's rights movement into the women's suffrage movement. The trial began on July 17, 1873, and was closely followed by the national press. The "New York Times" caught the tone of the proceedings by reporting that, "It was conceded that the defendant was, on the 5th November, 1872, a woman."
Following a rule of common law at that time which prevented criminal defendants in federal courts from testifying, Hunt refused to allow Anthony to speak until the verdict had been delivered. On the second day of the trial, after both sides had presented their cases, Justice Hunt delivered his opinion, which he had put in writing. In the most controversial aspect of the trial, Hunt directed the jury to deliver a guilty verdict.
On the third day of the trial, Hunt asked Anthony whether she had anything to say. She responded with "the most famous speech in the history of the agitation for woman suffrage", according to Ann D. Gordon, a historian of the women's movement. Repeatedly ignoring the judge's order to stop talking and sit down, she protested what she called "this high-handed outrage upon my citizen's rights ... you have trampled under foot every vital principle of our government. My natural rights, my civil rights, my political rights, my judicial rights, are all alike ignored."
She castigated Justice Hunt for denying her a trial by jury, but stated that even if he had allowed the jury to discuss the case, she still would have been denied a trial by a jury of her peers because women were not allowed to be jurors. When Justice Hunt sentenced Anthony to pay a fine of $100, she responded, "I shall never pay a dollar of your unjust penalty", and she never did. If Hunt had ordered her to be imprisoned until she paid the fine, Anthony could have appealed her case to the Supreme Court. Hunt instead announced he would not order her taken into custody, closing off that legal avenue.
The U.S. Supreme Court in 1875 put an end to the strategy of trying to achieve women's suffrage through the court system by ruling in "Minor v. Happersett" that "the Constitution of the United States does not confer the right of suffrage upon anyone". The NWSA decided to pursue the far more difficult strategy of campaigning for a constitutional amendment to guarantee voting rights for women.
"History of Woman Suffrage".
Anthony had for years saved letters, newspapers clippings, and other materials of historical value to the women's movement. In 1876, she moved into the Stanton household in New Jersey along with several trunks and boxes of these materials to begin working with Stanton on the "History of Woman Suffrage".
Anthony hated this type of work. In her letters, she said the project "makes me feel growly all the time ... No warhorse ever panted for the rush of battle more than I for outside work. I love to make history but hate to write it."
The work absorbed much of her time for several years although she continued to work on other women's suffrage activities. She acted as her own publisher, which presented several problems, including finding space for the inventory. She was forced to limit the number of books she was storing in the attic of her sister's house because the weight was threatening to collapse the structure.
Originally envisioned as a modest publication that could be produced quickly, the history evolved into a six-volume work of more than 5700 pages written over a period of 41 years. The first three volumes, which cover the movement up to 1885, were published between 1881 and 1886 and were produced by Stanton, Anthony and Matilda Joslyn Gage. Anthony handled the production details and the extensive correspondence with contributors. Anthony published Volume 4, which covers the period from 1883 to 1900, in 1902, after Stanton's death, with the help of Ida Husted Harper, Anthony's designated biographer. The last two volumes, which bring the history up to 1920, were completed in 1922 by Harper after Anthony's death.
Written by leaders of one wing of the divided women's movement (Lucy Stone, their main rival, refused to have anything to do with the project), the "History of Woman Suffrage" preserves an enormous amount of material that might have been lost forever, but it does not give a balanced view of events where their rivals are concerned. Because it was for years the main source of documentation about the suffrage movement, historians have had to uncover other sources to provide a more balanced view.
International women's organizations.
International Council of Women.
Anthony traveled to Europe in 1883 for a nine-month stay, linking up with Stanton, who had arrived a few months earlier. Together they met with leaders of European women's movements and began the process of creating an international women's organization. 
The National Woman Suffrage Association (NWSA) agreed to host its founding congress. The preparatory work was handled primarily by Anthony and two of her younger colleagues in the NWSA, Rachel Foster Avery and May Wright Sewall. Delegates from fifty-three women's organizations in nine countries met in Washington in 1888 to form the new association, which was called the International Council of Women (ICW). The delegates represented a wide variety of organizations, including suffrage associations, professional groups, literary clubs, temperance unions, labor leagues and missionary societies. The American Woman Suffrage Association, which had for years been a rival to the NWSA, participated in the congress. Anthony opened the first session of the ICW and presided over most events.
The ICW commanded respect at the highest levels. President Cleveland and his wife sponsored a reception at the White House for delegates to the ICW's founding congress. The ICW's second congress was an integral part of the World's Columbian Exposition held in Chicago in 1893. At its third congress in London in 1899, a reception for the ICW was held at Windsor Castle at the invitation of Queen Victoria. At its fourth congress in Berlin in 1904, Augusta Victoria, the German Empress, received the ICW leaders at her palace. Anthony played a prominent role on all four occasions.
Still active, ICW is associated with the United Nations.
World's Congress of Representative Women.
The World's Columbian Exposition, also known as the Chicago World's Fair, was held in 1893. It hosted several world congresses, each dealing with a specialized topic, such as religion, medicine and science. At almost the last moment, the U.S. Congress decided that the Exposition should also recognize the role of women. After it was over, one of the organizers of the Exposition's congress of women revealed that Anthony had played a pivotal but hidden role in that last-minute decision. Fearing that a public campaign would rouse opposition, Anthony had worked quietly to organize support for this project among women of the political elite. Anthony increased the pressure by covertly initiating a petition that was signed by wives and daughters of Supreme Court judges, senators, cabinet members and other dignitaries.
A large structure called the Woman's Building, designed by Sophia Hayden Bennett, was constructed to provide meeting and exhibition spaces for women at the Exposition. Two of Anthony's closest associates were appointed to organize the women's congress. They arranged for the International Council of Women to make its upcoming meeting part of the Exposition by expanding its scope and calling itself the World's Congress of Representative Women.
This week-long congress seated delegates from 27 countries. Its 81 sessions, many held simultaneously, were attended by over 150,000 people, and women's suffrage was discussed at almost every session.
Anthony spoke to large crowds at the Exposition.
"Buffalo Bill" Cody invited her as a guest to his Wild West Show, located just outside the Exposition. When the show opened, he rode his horse directly to her and greeted her with dramatic flair. According to a co-worker, Anthony, "for the moment as enthusiastic as a girl, waved her handkerchief at him, while the big audience, catching the spirit of the scene, wildly applauded."
International Woman Suffrage Alliance.
After Anthony retired as president of the National American Woman Suffrage Association, Carrie Chapman Catt, her chosen successor, began working toward an international women's suffrage association, one of Anthony's long-time goals. The existing International Council of Women could not be expected to support a campaign for women's suffrage because it was a broad alliance whose more conservative members would object. In 1902, Catt organized a preparatory meeting in Washington, with Anthony as chair, that was attended by delegates from several countries. Organized primarily by Catt, the International Woman Suffrage Alliance was created in Berlin in 1904. The founding meeting was chaired by Anthony, who was declared to be the new organization's honorary president and first member.
According to Anthony's authorized biographer, "no event ever gave Miss Anthony such profound satisfaction as this one".
Later renamed the International Alliance of Women, the organization is still active and is affiliated with the United Nations.
Relationship with Stanton.
Anthony and Stanton worked together in a close and productive relationship. From 1880 to 1886 they were together almost every day working on the "History of Woman Suffrage".
They referred to each other as "Susan" and "Mrs. Stanton".
Anthony deferred to Stanton in other ways also, not accepting an office in any organization that would place her above Stanton.
In practice this generally meant that Anthony, although ostensibly holding a less important office, handled most of the organization's daily activities.
Stanton sometimes felt the weight of Anthony's determination and drive. When Stanton arrived at an important meeting in 1888 with her speech not yet written, Anthony insisted that Stanton stay in her hotel room until she had written it, and she placed a younger colleague outside her door to make sure she did so. 
At Anthony's 70th birthday celebration, Stanton teased her by saying, "Well, as all women are supposed to be under the thumb of some man, I prefer a tyrant of my own sex, so I shall not deny the patent fact of my subjection."
Their interests began to diverge somewhat as they grew older. As the drive for women's suffrage gained momentum, Anthony began to form alliances with more conservative groups, such as the Women's Christian Temperance Union, the nation's largest women's organization and a supporter of women's suffrage. 
Such moves irritated Stanton, who said, "I get more radical as I get older, while she seems to grow more conservative." In 1895 Stanton published "The Woman's Bible", which attacked the use of the "Bible" to relegate women to an inferior status. It became a highly controversial best-seller. The NAWSA voted to disavow any connection with it despite Anthony's strong objection that such a move was unnecessary and hurtful. 
Even so, Anthony refused to assist with the book's preparation, telling Stanton: "You say 'women must be emancipated from their superstitions before enfranchisement will have any benefit,' and I say just the reverse, that women must be enfranchised before they can be emancipated from their superstitions."
Despite such friction, their relationship continued to be close. When Stanton died in 1902, Anthony wrote to a friend: "Oh, this awful hush! It seems impossible that voice is stilled which I have loved to hear for fifty years. Always I have felt I must have Mrs. Stanton's opinion of things before I knew where I stood myself. I am all at sea..."
Later life.
Having lived for years in hotels and with friends and relatives, Anthony agreed to settle into her sister (Mary Stafford Anthony)'s house in Rochester in 1891, at the age of 71.
Her energy and stamina, which sometimes exhausted her co-workers, continued at a remarkable level. At age 75, she toured Yosemite National Park on the back of a mule.
She remained as leader of the NAWSA and continued to travel extensively on suffrage work. She also engaged in local projects. In 1893, she initiated the Rochester branch of the Women's Educational and Industrial Union. In 1898, she called a meeting of 73 local women's societies to form the Rochester Council of Women. She played a key role in raising the funds required by the University of Rochester before they would admit women students, pledging her life insurance policy to close the final funding gap.
In 1896, she spent eight months on the California suffrage campaign, speaking as many as three times per day in more than 30 localities. In 1900, she presided over her last NAWSA convention. During the six remaining years of her life, Anthony spoke at six more NAWSA conventions and four congressional hearings, completed the fourth volume of the "History of Woman Suffrage", and traveled to eighteen states and to Europe. As Anthony's fame grew, some politicians (certainly not all of them) were happy to be publicly associated with her. Her seventieth birthday was celebrated at a national event in Washington with prominent members of the House and Senate in attendance. Her eightieth birthday was celebrated at the White House at the invitation of President William McKinley.
Views.
Views on religion.
Anthony was raised a Quaker, but her religious heritage was mixed. On her mother's side, her grandmother was a Baptist and her grandfather was a Universalist. 
Her father was a radical Quaker who chafed under the restrictions of his more conservative congregation. When the Quakers split in the late 1820s into Orthodox and Hicksites, her family sided with the Hicksites, which Anthony described as "the radical side, the Unitarian".
In 1848, three years after the Anthony family moved to Rochester, a group of about 200 Quakers withdrew from the Hicksite organization in western New York, partly because they wanted to work in social reform movements without interference from that organization. Some of them, including the Anthony family, began attending services at the First Unitarian Church of Rochester. When Susan B. Anthony returned home from teaching in 1849, she joined her family in attending services there, and she remained with the Rochester Unitarians for the rest of her life. 
Her sense of spirituality was strongly influenced by William Henry Channing, a nationally known minister of that church who also assisted her with several of her reform projects.
Anthony was listed as a member of First Unitarian in a church history written in 1881.
Anthony, proud of her Quaker roots, continued to describe herself as a Quaker, however. She maintained her membership in the local Hicksite body but did not attend its meetings. 
She joined the Congregational Friends, an organization that was created by Quakers in western New York after the 1848 split among Quakers there. This group soon ceased to operate as a religious body, however, and changed its name to the Friends of Human Progress, organizing annual meetings in support of social reform that welcomed everyone, including "Christians, Jews, Mahammedans, and Pagans". Anthony served as secretary of this group in 1857.
In 1859, during a period when Rochester Unitarians were gravely impaired by factionalism,
Anthony unsuccessfully attempted to start a "Free church in Rochester ... where no doctrines should be preached and all should be welcome."
She used as her model the Boston church of Theodore Parker, a Unitarian minister who helped to set the direction of his denomination by rejecting the authority of the Bible and the validity of miracles. 
Anthony later became close friends with William Channing Gannett, who became the minister of the Unitarian Church in Rochester in 1889, and with his wife Mary, who came from a Quaker background.
William had been a national leader of the successful movement within the Unitarian denomination to end the practice of binding it by a formal creed, thereby opening its membership to non-Christians and even non-theists, a goal for the denomination that resembled Anthony's goal for her proposed Free church.
After Anthony reduced her arduous travel schedule and made her home in Rochester in 1891, she resumed regular attendance at First Unitarian and also worked with the Gannetts on local reform projects. Her sister Mary Stafford Anthony, whose home had provided a resting place for Anthony during her years of frequent travel, had long played an active role in this church.
Her first public speech, delivered at a temperance meeting as a young woman, contained frequent references to God. She soon took a more distant approach, however. While in Europe in 1883, Anthony helped a desperately poor Irish mother of six children. Noting that "the evidences were that 'God' was about to add a No. 7 to her flock", she later commented, "What a dreadful creature their God must be to keep sending hungry mouths while he withholds the bread to fill them!"
Elizabeth Cady Stanton said that Anthony was an agnostic, adding, "To her, work is worship ... Her belief is not orthodox, but it is religious."
Anthony herself said, "Work and worship are one with me. I can not imagine a God of the universe made happy by my getting down on my knees and calling him 'great.'"
When Anthony's sister Hannah was on her death bed, she asked Susan to talk about the great beyond, but, Anthony later wrote, "I could not dash her faith with my doubts, nor could I pretend a faith I had not; so I was silent in the dread presence of death."
When an organization offered to sponsor a women's rights convention on the condition that "no speaker should say anything which would seem like an attack on Christianity", Anthony wrote to a friend, "I wonder if they'll be as particular to warn all other speakers not to say anything which shall sound like an attack on liberal religion. They never seem to think we have any feelings to be hurt when we have to sit under their reiteration of orthodox cant and dogma."
Views on marriage.
As a teen, Anthony went to parties, and she had offers of marriage when she was older, but there is no record of her ever having a serious romance.
Anthony loved children, however, and helped raise the children in the Stanton household. Referring to her niece, she wrote, "The dear little Lucy engrosses most of my time and thoughts. A child one loves is a constant benediction to the soul, whether or not it helps to the accomplishment of great intellectual feats."
As a young worker in the women's rights movement, Anthony expressed frustration when some of her co-workers began to marry and have children, sharply curtailing their ability to work for the understaffed movement. When Lucy Stone abandoned her pledge to stay single, Anthony's scolding remarks caused a temporary rupture in their friendship. Journalists repeatedly asked Anthony to explain why she never married. She answered one by saying, "It always happened that the men I wanted were those I could not get, and those who wanted me I wouldn't have." To another she answered, "I never found the man who was necessary to my happiness. I was very well as I was." To a third she said, "I never felt I could give up my life of freedom to become a man's housekeeper. When I was young, if a girl married poor, she became a housekeeper and a drudge. If she married wealth she became a pet and a doll. Just think, had I married at twenty, I would have been a drudge or a doll for fifty-nine years. Think of it!"
Anthony fiercely opposed laws that gave husbands complete control over the marriage. Blackstone's "Commentaries", the basis for the legal systems in most states at that time, stated that, "By marriage, the husband and wife are one person in law: that is, the very being or legal existence of the woman is suspended during the marriage".
In a speech in 1877, Anthony predicted ""an epoch of single women". If women will not accept marriage "with subjugation", nor men proffer it "without", there is, there can be, "no alternative". The woman who "will not be ruled" must live without marriage."
Views on abortion.
Anthony's political position on abortion has been a subject of a relatively recent dispute, with some pro-life activists contending she would favor the pro-life position in the modern abortion debate. These activists cite certain words and phrases that she used, such as "unborn little ones". They also cite articles that referred to abortion as "child-murder" or "ante-natal infanticide" in "The Revolution", a woman's journal owned by Anthony but edited by Stanton and Pillsbury, that provided a forum for contrasting opinions.
Ann D. Gordon, a leading academic authority on Anthony,
has criticized the effort to represent Anthony as someone who would support the modern pro-life movement, saying, "The result is what historians call 'invented memory'—history without foundation in the evidence but with modern utility." Gordon said that Anthony "never voiced an opinion about the sanctity of fetal life ... and she never voiced an opinion about using the power of the state to require that pregnancies be brought to term."
Death and legacy.
Susan B. Anthony died at the age of 86 of heart failure and pneumonia in her home in Rochester, New York, on March 13, 1906. She was buried at Mount Hope Cemetery, Rochester. At her birthday celebration in Washington a few days earlier, Anthony had spoken of those who had worked with her for women's rights: "There have been others also just as true and devoted to the cause — I wish I could name every one — but with such women consecrating their lives, failure is impossible!" "Failure is impossible" quickly became a watchword for the women's movement.
In her history of the women's suffrage movement, Eleanor Flexner wrote, "If Lucretia Mott typified the moral force of the movement, if Lucy Stone was its most gifted orator and Mrs. Stanton its most outstanding philosopher, Susan Anthony was its incomparable organizer, who gave it force and direction for half a century."
Anthony did not live to see the achievement of women's suffrage at the national level, but she was proud of the progress the women's movement had made. At the time of her death, women had achieved suffrage in Wyoming, Utah, Colorado and Idaho, and several larger states followed soon after. Legal rights for married women had been established in most states, and most professions had at least a few women members. 36,000 women were attending colleges and universities, up from zero a few decades earlier."
Two years before she died, Anthony said, "The world has never witnessed a greater revolution than in the sphere of woman during this fifty years".
Part of the revolution was in ways of thinking. In a speech in 1889, Anthony noted that women had always been taught that their purpose was to serve men, but "Now, after 40 years of agitation, the idea is beginning to prevail that women were created for themselves, for their own happiness, and for the welfare of the world." Anthony was sure that women's suffrage would be achieved, but she also feared that people would forget how difficult it was to achieve it, as they were already forgetting the ordeals of the recent past:
We shall someday be heeded, and when we shall have our amendment to the Constitution of the United States, everybody will think it was always so, just exactly as many young people think that all the privileges, all the freedom, all the enjoyments which woman now possesses always were hers. They have no idea of how every single inch of ground that she stands upon today has been gained by the hard work of some little handful of women of the past.
Susan B. Anthony, 1894
Anthony's death was widely mourned. Clara Barton, founder of the American Red Cross, said just before Anthony's death, "A few days ago someone said to me that every woman should stand with bared head before Susan B. Anthony. 'Yes,' I answered, 'and every man as well.' ... For ages he has been trying to carry the burden of life's responsibilities alone... Just now it is new and strange and men cannot comprehend what it would mean but the change is not far away."
Anthony's home in Rochester is now a National Historic Landmark called the National Susan B. Anthony Museum and House.
The house of her birth
in Adams, Massachusetts, and her childhood home
in Battenville, New York, are listed on the National Register of Historic Places.
The rotunda of the U.S. Capitol contains a statue that honors three leading women's rights leaders: Anthony, Elizabeth Cady Stanton, and Lucretia Mott.
The Cathedral of St. John the Divine in Manhattan, one of the world's largest, has a sculpture honoring four spiritual heroes of the twentieth century: Anthony, Martin Luther King, Albert Einstein, and Mohandas Gandhi.
In 1936, the U.S. Post Office issued its first postage stamp honoring Susan B. Anthony. A second stamp honoring Anthony was issued in April 1958.
In 1979, the United States Mint began issuing the Susan B. Anthony dollar coin, the first U.S. coin to honor a real woman rather than an allegorical female figure.
The Nineteenth Amendment, which guaranteed the right of women to vote, was popularly known as the Susan B. Anthony Amendment. After it was ratified in 1920, the National American Woman Suffrage Association, whose character and policies were strongly influenced by Anthony, was transformed into the League of Women Voters, which is still an active force in U.S. politics.

</doc>
<doc id="27956" url="http://en.wikipedia.org/wiki?curid=27956" title="South Carolina">
South Carolina

South Carolina is a state in the Southeastern United States. It is bordered to the north by North Carolina; to the south and west by Georgia, located across the Savannah River; and to the east by the Atlantic Ocean. Originally part of the Province of Carolina, the Province of South Carolina became a slave society after rice and indigo became established as commodity crops. From 1708, a majority of the population were slaves, many born in Africa. It was the first of the 13 colonies that declared independence from the British Crown during the American Revolution.
South Carolina was the first state to ratify the Articles of Confederation. It was the 8th state to ratify the U.S. Constitution on May 23, 1788. South Carolina later became the first state to vote to secede from the Union which it did on December 20, 1860. After the end of the American Civil War, the state was readmitted into the United States on June 25, 1868.
South Carolina is the 40th most extensive and the 24th most populous of the 50 U.S. states. Its GDP as of 2013 was $183.6 billion, with an annual growth rate of 3.13%. South Carolina comprises 46 counties. The capital and largest city of the state is Columbia with a 2013 population of 133,358. The largest MSA is Greenville-Anderson-Mauldin with a 2013 population of 850,965.
Etymology.
The name "Carolina" dates back to October 30, 1629, when King Charles I granted a patent to Sir Robert Heath for the lands south of 36 degrees and north of 31 degrees, "under the name, in honor of that king, of Carolina." "Carolus" is Latin for 'Charles'.
Geography.
South Carolina is composed of five geographic areas, or physiographic provinces, whose boundaries roughly parallel the Atlantic coastline. In the southeast part of the state is the Atlantic Coastal Plain, which can be divided into the Outer and Inner Coastal Plains. From north to south the coast is divided into three separate areas, the Grand Strand, the Santee River Delta, and the Sea Islands. Further inland are the Sandhills, ancient dunes from what used to be South Carolina's coast millions of years ago. The Fall Line, which marks the limit of navigable rivers, runs along the boundary of the Sandhills and the Piedmont, which has rolling hills and clay soils. In the northwest corner of the state are the Blue Ridge Mountains, the smallest geographical region in the state.
The state's coastline contains many salt marshes and estuaries, as well as natural ports such as Georgetown and Charleston. An unusual feature of the coastal plain is a large number of Carolina bays, the origins of which are uncertain. The bays tend to be oval, lining up in a northwest to southeast orientation. The terrain is flat and the soil is composed entirely of recent sediments such as sand, silt, and clay. Areas with better drainage make excellent farmland, though some land is swampy. The natural areas of the coastal plain are part of the Middle Atlantic coastal forests ecoregion.
Just west of the coastal plain is the Sandhills region. The Sandhills are remnants of coastal dunes from a time when the land was sunken or the oceans were higher.
The Upstate region contains the roots of an ancient, eroded mountain chain. It is generally hilly, with thin, stony clay soils, and contains few areas suitable for farming. Much of the Piedmont was once farmed. Due to the changing economics of farming, much of the land is now reforested in Loblolly pine for the lumber industry. These forests are part of the Southeastern mixed forests ecoregion. At the southeastern edge of the Piedmont is the fall line, where rivers drop to the coastal plain. The fall line was an important early source of water power. Mills built to harness this resource encouraged the growth of several cities, including the capital, Columbia. The larger rivers are navigable up to the fall line, providing a trade route for mill towns.
The northwestern part of the Piedmont is also known as the Foothills. The Cherokee Parkway is a scenic driving route through this area. This is where Table Rock State Park is located.
Highest in elevation is the Blue Ridge Region, containing an escarpment of the Blue Ridge Mountains, which continue into North Carolina and Georgia, as part of the southern Appalachian Mountains. Sassafras Mountain, South Carolina's highest point at 3560 ft, is located in this area. Also located in this area is Caesars Head State Park. The environment here is that of the Appalachian-Blue Ridge forests ecoregion. The Chattooga River, located on the border between South Carolina and Georgia, is a favorite whitewater rafting destination.
Lakes.
South Carolina has several major lakes covering over 683 sqmi. The following are the lakes listed by size.
Earthquakes.
Earthquakes do occur in South Carolina. The greatest frequency is along the central coastline of the state, in the Charleston area. South Carolina averages 10–15 earthquakes a year below magnitude 3 (FEMA). The Charleston Earthquake of 1886 was the largest quake ever to hit the Southeastern United States. This 7.2 magnitude earthquake killed 60 people and destroyed much of the city. Faults in this region are difficult to study at the surface due to thick sedimentation on top of them. Many of the ancient faults are within plates rather than along plate boundaries.
Climate.
South Carolina has a humid subtropical climate (Köppen climate classification "Cfa"), although high-elevation areas in the Upstate area have fewer subtropical characteristics than areas on the Atlantic coastline. In the summer, South Carolina is hot and humid, with daytime temperatures averaging between 86 - in most of the state and overnight lows averaging 70 - on the coast and from 66 - inland. Winter temperatures are much less uniform in South Carolina.
Coastal areas of the state have very mild winters, with high temperatures approaching an average of 60 °F and overnight lows in the 40s°F (5–8 °C). Inland, the average January overnight low is around 32 °F in Columbia and temperatures well below freezing in the Upstate. While precipitation is abundant the entire year in almost the entire state, the coast tends to have a slightly wetter summer, while inland, March tends to be the wettest month and winter the driest season, with November being the driest month. The highest recorded temperature is 113 F in Johnston and Columbia on June 29, 2012, and the lowest recorded temperature is -19 F at Caesars Head on January 21, 1985.
Snowfall in South Carolina is somewhat uncommon in most of the state, while coastal areas receive less than an inch (2.5 cm) annually on average. It is not uncommon for areas along the coast (especially the southern coast) to receive no recordable snowfall in a given year. The interior receives a little more snow, although nowhere in the state averages more than 12 in of snow annually. The mountains of extreme northwestern South Carolina tend to have the most substantial snow accumulation. Freezing rain and ice tend to be more common than snow in many areas of the state. Road bridges in South Carolina are commonly marked, "Bridge ices before road."
South Carolina is also prone to tropical cyclones and tornadoes. Two of the strongest hurricanes to strike South Carolina in recent history were Hurricane Hazel (1954) and Hurricane Hugo (1989).
Hurricanes and tropical cyclones.
The state is occasionally affected by tropical cyclones. This is an annual concern during hurricane season, which lasts from June 1 to November 30. The peak time of vulnerability for the southeast Atlantic coast is from early August to early October, during the Cape Verde hurricane season. Memorable hurricanes to hit South Carolina include Hazel (1954) and Hugo (1989), both Category 4 hurricanes.
South Carolina averages around 50 days of thunderstorm activity a year. This is less than some of the states further south, and it is slightly less vulnerable to tornadoes than the states which border on the Gulf of Mexico. Some notable tornadoes have struck South Carolina, and the state averages around 14 tornadoes annually. Hail is common with many of the thunderstorms in the state, as there is often a marked contrast in temperature of warmer ground conditions compared to the cold air aloft.
History.
Discovery and exploration.
About 30 Native American Tribes lived in what is now South Carolina at the time the first Europeans arrived in the region. The most important were the Catawba (who spoke a Siouan language), Cherokee (who spoke an Iroquoian language), and Yamasee (Muskhogean language). It is believed that the first humans settled in the current South Carolina about 15,000 years ago.
The first European to land was Francisco Gordillo in 1521, from Spain. Five years later, in 1526, another Spaniard, Lucas Vazquez de Ayllon, founded the first European settlement in the territory that now constitutes the United States. This settlement was named San Miguel de Gualdape and was founded with 600 settlers, including African slaves, but was abandoned three months later. The region would later be claimed by both the Spanish and the French. The French made several attempts at colonization which failed because of the hostility of Indian tribes and a lack of provisions.
England claimed the current South Carolina at the beginning of seventeenth century. In 1629, King Charles I gave the southern colonies to Robert Heath. This colony included the regions that now constitute North Carolina, South Carolina, Georgia and Tennessee. Heath named this colony Carolana, a Latin word which means 'Land of Charles'.
British colony.
The colony of Carolina was settled by wealthy English aristocrats, mostly migrating from Barbados, where they had already set up sugar plantations. King Charles gave eight aristocrats a royal charter to settle Carolina (Carolina is Latin for "Charles land") because earlier they had helped him regain his throne. Parts of Carolina (mostly the coastal areas) had been colonized earlier by Spain (see Fort Caroline), but battles between the Spanish and the Native Americans resulted in the Spanish people retreating to Florida, Cuba, Mexico, and Central and South America.
Carolina was settled to make profit from trade and also by selling land. John Locke, an English philosopher, wrote a constitution for the colony that covered topics such as land divisions and social rankings. In the early years, not many people bought land there, so the proprietors lowered the price on some portions.
Carolina did not develop as planned. It split into northern and southern Carolina, creating two different colonies. It separated because of political reasons as the settlers wanted political power. In 1719 settlers in southern Carolina seized control from its proprietors. Then, in 1729, Carolina became two royal colonies- North Carolina and South Carolina. Farmers from inland Virginia settled northern Carolina. They grew tobacco, and sold timber and tar, both categories of naval stores needed by England. The northern Carolina coast lacked a good harbor, so many of the farmers used Virginia's ports to conduct their trade.
Southern Carolina prospered from the fertility of the Low Country and the harbors, such as that at Charles Town (later Charleston). It allowed religious toleration, encouraging settlement by merchants from the successful French Huguenot and Sephardic Jewish communities of London. Settlements spread, and trade in deerskin, lumber, and beef thrived. Rice cultivation was developed on a large scale with the help of skills and techniques of slaves imported from rice-growing regions of Africa. They created the large earthworks of dams and canals required to irrigate the rice fields. In addition, indigo became a commodity crop, also developed with the skills of African slaves.
The cultivation and processing of Indigo plant, a blue flowering plant, was developed here by a young English woman, Eliza Lucas, a planter's daughter who had come with her father, also a military officer, from the Caribbean. She took over managing the plantation when he was assigned elsewhere. Indigo became an important commodity crop for the dyeing of textiles. Slave labor was integral to the economic success of rice and indigo as commodity crops. In South Carolina, slaves made up a majority of the population after 1708, and the demand for labor was so high that many were imported from Africa.
After the Stono Rebellion of 1739, the colony prohibited importing African slaves through Charleston for ten years, having observed they were more likely to cause rebellions than slaves from the Caribbean, who were already "seasoned" or those born in the colony. Slaves and their descendants comprised a majority of the population of the state through the American Civil War and to the turn of the 20th century.
The American Revolution.
On March 26, 1776, the colony adopted the Constitution of South Carolina becoming the first republic in America. John Rutledge was elected as the state's first president. He was succeeded by Rawlins Lowndes who served March 6, 1778 – January 9, 1779. On February 5, 1778, South Carolina became the first state to ratify the Articles of Confederation, the initial governing document of the United States.
In 1780, South Carolinian loyalists to the British crown helped British troops recapture South Carolina from the previously successful rebels. On January 17, 1781, the Battle of Cowpens won by the American forces, marked the beginning of the decline in British fortunes. In 1782 they decided to evacuate their troops by the end of the year. Thousands of Loyalists and slaves left with them.
The American Revolution caused a shock to slavery in the South. Many thousands of slaves fled to British authorities to obtain freedom; and many of those left with the British in the last days of the war. Others secured their freedom by escaping to perceived friendlier locations during the turmoil. Estimates are that 25,000 slaves (30% of those in South Carolina) fled, migrated or died during the disruption of the war.
The current United States Constitution was proposed for adoption by the States on September 17, 1787, and South Carolina was the 8th state to ratify it, on May 23, 1788.
Federal period.
South Carolina politics between 1783 and 1795 were marred by rivalry between a Federalist elite supporting the central government in Philadelphia and a large proportion of common people. The latter were often members of 'Republican Societies', and they supported the Republican-Democrats, headed by Jefferson and Madison. This party wanted more democracy in the US, especially in South Carolina. Sephardic Jews had prospered in contributing to the state and by 1800, South Carolina had the largest population of Jews in the United States.
Most people supported the French Revolution (1789–1795), as the French had been allies and they were proud of their own revolution. In addition, due to substantial French Huguenot immigration during the colonial years, Charleston was one of the most French-influenced cities in the USA. Leading South Carolina figures, such as governors Charles Pinckney and William Moultrie, backed with money and actions the French plans to further their political, strategic, and commercial goals in North America. This pro-French stance and attitude of South Carolina ended soon because of the XYZ Affair, a diplomatic affair that resulted in quasi-war between France and the US.
Antebellum.
Antebellum South Carolina did more to advance nullification and secession than any other Southern state. Their first attempt at nullification was in 1822, following discovery of a conspiracy for a slave rebellion led by Denmark Vesey, a freed slave. As part of its response, the state passed a Negro Seamen Act, requiring foreign and northern black sailors to be prohibited from interacting with people in South Carolina ports. As it violated international treaties, this law was declared unconstitutional by Supreme Court Justice William Johnson. His ruling was not enforced.
In 1832, a South Carolina state convention passed the Ordinance of Nullification, declaring the Federal tariff laws of 1828 and 1832 unconstitutional, null and not to be enforced in the state of South Carolina after February 1, 1833.
This led to the Nullification Crisis, in which U.S. President Andrew Jackson (the only president as yet to have been born in South Carolina) was authorized through the Force Bill to use whatever military force necessary to enforce Federal law in the state. This was the first U.S. legislation denying individual states the right to secede. As a result of Jackson's threat of force, the South Carolina state convention was re-convened and repealed the Ordinance of Nullification in March.
Anti-abolitionist feelings ran strong in South Carolina, which depended on slave labor and had a majority-slave population. In 1856, Democrat South Carolina congressman Preston Brooks entered the United States Senate chamber and, with a metal-tipped cane, beat Massachusetts Republican Senator Charles Sumner. He drew blood and injured Sumner badly enough that the latter was unable to serve for several months. Brooks was retaliating for a speech Sumner had given in which he attacked slavery and insulted South Carolinians. Brooks resigned his seat but received a hero's welcome on returning home.
American Civil War.
On December 20, 1860, when it became clear that Abraham Lincoln, an opponent of slavery, would become the next U.S. president, South Carolina became the first U.S. state to declare its secession from the Union. On April 12, 1861, Confederate batteries began shelling Fort Sumter in Charleston Harbor, and the American Civil War began. The U.S. Navy effectively blockaded Charleston and seized the Sea Islands. Planters had taken their families (and sometimes slaves) to points inland for refuge.
The Union Army set up an experiment in freedom for the ex-slaves, in which they started education and farmed land for themselves. South Carolinian troops participated in major Confederate campaigns, but no major battles were fought inland. General William Tecumseh Sherman marched through the state in early 1865, destroying numerous plantations, and captured the state capital of Columbia on February 17. Fires began that night and by next morning, most of the central city was destroyed. South Carolina suffered 18,666 military deaths during the American Civil War, which was nearly one-third of the white male population of fighting age.
Reconstruction.
After the war, South Carolina was restored to the United States during Reconstruction. Under presidential Reconstruction (1865–66), freedmen (former slaves) were given limited rights. Under Radical reconstruction (1867–1877), a Republican coalition of freedmen, carpetbaggers and scalawags was in control, supported by Union Army forces. They established public education, welfare institutions, and home rule for counties, expanding democracy.
Until the 1868 presidential election, South Carolina's legislature, not the voters, chose the state's electors for the presidential election. South Carolina was the last state to choose its electors in this manner. On October 19, 1871 President Ulysses S. Grant suspended habeas corpus in nine South Carolina counties under the authority of the Ku Klux Klan Act. Led by Grant's Attorney General Amos T. Akerman, hundreds of Klansmen were arrested while 2000 Klansmen fled the state. This was done in order to suppress Klan violence against African American and white voters in the South. In the mid to late 1870s, white Democrats used paramilitary groups such as the Red Shirts to intimidate and terrorize black voters. They regained political control of the state under conservative white "Redeemers" and pro-business Bourbon Democrats. In 1877, the federal government withdrew its troops as part of the Compromise of 1877 that ended Reconstruction.
Populist and agrarian movements.
The state became a hotbed of racial and economic tensions during the Populist and Agrarian movements of the 1890s. A Republican-Populist biracial coalition took power away from White Democrats temporarily. To prevent that from happening again, Democrats gained passage of a new constitution in 1895 that effectively disfranchised almost all blacks and many poor whites by new requirements for poll taxes, residency, and literacy tests that dramatically reduced the voter rolls. By 1896, only 5,500 black voters remained on the voter registration rolls, although they constituted a majority of the state's population. The 1900 census demonstrated the extent of disenfranchisement: the 782,509 African American citizens comprised more than 58% of the state's population, but they were essentially without any political representation in the Jim Crow society.
The 1895 constitution overturned local representative government, reducing the role of the counties to agents of state government, effectively ruled by the General Assembly, through the legislative delegations for each county. As each county had one state senator, that person had considerable power. The counties lacked representative government until home rule was passed in 1975.
Governor "Pitchfork Ben Tillman", a Populist, led the effort to disenfranchise the blacks and poor whites, although he controlled Democratic state politics from the 1890s to 1910 with a base among poor white farmers. During the constitutional convention in 1895, he supported another man's proposal that the state adopt a one-drop rule, as well as prohibit marriage between whites and anyone with any known African ancestry.
Some members of the convention realized that prominent white families with some African ancestry could be affected by such legislation. In terms similar to a debate in Virginia in 1853 on a similar proposal (which was dropped), George Dionysius Tillman said the following in opposition:
If the law is made as it now stands respectable families in Aiken, Barnwell, Colleton, and Orangeburg will be denied the right to intermarry among people with whom they are now associated and identified. At least one hundred families would be affected to my knowledge. They have sent good soldiers to the Confederate Army, and are now landowners and taxpayers. Those men served creditably, and it would be unjust and disgraceful to embarrass them in this way. It is a scientific fact that there is not one full-blooded Caucasian on the floor of this convention. Every member has in him a certain mixture of… colored blood. The pure-blooded white has needed and received a certain infusion of darker blood to give him readiness and purpose. It would be a cruel injustice and the source of endless litigation, of scandal, horror, feud, and bloodshed to undertake to annul or forbid marriage for a remote, perhaps obsolete trace of Negro blood. The doors would be open to scandal, malice and greed; to statements on the witness stand that the father or grandfather or grandmother had said that A or B had Negro blood in their veins. Any man who is half a man would be ready to blow up half the world with dynamite to prevent or avenge attacks upon the honor of his mother in the legitimacy or purity of the blood of his father.
The state postponed such a one-drop law for years. Virginian legislators adopted a one-drop law in 1924, forgetting that their state had many people of mixed ancestry among those who identified as white.
20th century and beyond.
Early in the 20th century, South Carolina developed a thriving textile industry. The state also converted its agricultural base from cotton to more profitable crops; attracted large military bases through its powerful Democratic congressional delegation, part of the one-party South following disfranchisement of blacks at the turn of the century; and created tourism industries. During the early part of the 20th century, thousands of African Americans left South Carolina and other southern states for jobs and better opportunities in northern, midwestern and western cities. In total from 1910 to 1970, 6.5 million blacks left the South in the Great Migration. By 1930 South Carolina had a white majority for the first time since 1708.
The struggle of the African-American Civil Rights Movement took place in South Carolina as well as other places in the South.
South Carolina was one of several states that initially rejected the Nineteenth Amendment giving women the right to vote. The South Carolina legislature later ratified the amendment on July 1, 1969. As of 2012, South Carolina had the lowest percentage among all states of women in state legislature, at 10.0% (the national average is 23.7%; the highest percentage is in Colorado at 40%). In 2011, South Carolina ranked first in the country in the rate of women killed by men.
As the 21st century progresses, South Carolina attracts new business by having a 5% corporate income tax rate, no state property tax, no local income tax, no inventory tax, no sales tax on manufacturing equipment, industrial power or materials for finished products; no wholesale tax, no unitary tax on worldwide profits.
Of extended controversy has been the state's decades-long display of the Confederate flag, which was raised on the state capitol in 1962. The state capitol is located directly next to the University of South Carolina campus, so the move was seen as a protest against the court-ordered desegregation of the schools. The US Supreme Court ruled in 1954 that segregated public schools were unconstitutional. A lawsuit calling for the flag to be removed was filed in 1994. On July 1, 2000, South Carolina became the last southern state to remove the Confederate flag from flying over its statehouse. The state Senate had approved a bill for its removal on April 12, 2000, by a margin of 36 to 7; the bill had specified that a Confederate flag be flown in front of the Capitol next to a monument honoring fallen Confederate soldiers. Debate was more heated in the state House of Representatives, which passed the bill on May 18, 2000, by a margin of only 66 to 43, after including a measure ensuring that the Confederate flag by the monument be 30 ft high.
The flag by the monument continues to be controversial. The NAACP maintains an economic boycott of the state of South Carolina. The NCAA refuses to allow South Carolina to host NCAA athletic events whose locations are determined in advance. On July 6, 2009, the Atlantic Coast Conference announced a decision to move three future baseball tournaments out of South Carolina, citing concerns by the NAACP over the continuing state-sponsored display of the Confederate flag.
Starting January 1, 2013, South Carolina will be one of the first states that will no longer pay for 'early elective' deliveries of babies, under either Medicaid and private insurance. The term early elective is defined as an labor induction or caesarean section between 37–39 weeks that is not medically based. This change is intended to result in healthier babies and fewer unnecessary costs for South Carolina.
On November 20, 2014, South Carolina became the 35th state to legalize same-sex marriages.
Demographics.
The United States Census Bureau estimates that the population of South Carolina was 4,832,482 on July 1, 2014, a 4.48% increase since the 2010 United States Census.
As of the 2010 census, the racial make up of the state is 66.2% White (64.1% non-Hispanic white), 27.9% Black or African American, 0.4% American Indian and Alaska Native, 1.3% Asian, 0.1% Native Hawaiian and other Pacific Islander, 1.7% from two or more races. 5.1% of the total population was of Hispanic or Latino origin (they may be of any race).
About 12% of South Carolina's White population have at least 1% African ancestry.
According to the United States Census Bureau, as of 2014, South Carolina had an estimated population of 4,832,482, which is an increase of 57,643 from the prior year and an increase of 207,118, or 4.48%, since the year 2010. Immigration from outside the United States resulted in a net increase of 36,401 people, and migration within the country produced a net increase of 115,084 people. According to the University of South Carolina's Arnold School of Public Health, Consortium for Latino Immigration Studies, South Carolina's foreign-born population grew faster than any other state between 2000 and 2005.
An August 2011 Public Policy Polling survey found that 21% of South Carolina voters thought that same-sex marriage should be legal, while 69% thought it should be illegal and 10% were not sure. A separate question on the same survey found that 48% of South Carolina voters supported the legal recognition of same-sex couples, with 19% supporting same-sex marriage, 29% supporting civil unions but not marriage, 51% favoring no legal recognition and 2% not sure.
Religion.
According to the Association of Religion Data Archives(ARDA), in 2010 the largest denominations were the Southern Baptist Convention with 913,763 adherents, the United Methodist Church with 274,111 adherents, and the Roman Catholic Church with 181,743 adherents. Fourth largest is the African Methodist Episcopal Church with 564 congreagtions and 121,000 members and fifth largest is the Presbyterian Church (USA) with 320 congregations and almost 100,000 members.
South Carolina is the American state with the highest per capita Baha'i population.
Major cities.
In 2014, the US Census Bureau released 2013 population estimates for South Carolina's most populous cities. It is worth noting that South Carolina's laws makes annexation difficult, so central city populations represent a smaller percentage of metropolitan area population than in most states, making Greenville the largest urban area.
Economy.
 According to the U.S. Bureau of Economic Analysis, South Carolina's gross state product (GSP) in current dollars was $97 billion in 1997, and $153 billion in 2007. Its per-capita real gross domestic product (GDP) in chained 2000 dollars was $26,772 in 1997, and $28,894 in 2007; that represents 85% of the $31,619 per-capita real GDP for the United States overall in 1997, and 76% of the $38,020 for the U.S. in 2007. The state debt in 2012 was calculated by one source to be $22.9bn, or $7,800 per taxpayer.
Major agricultural outputs of the state are: tobacco, poultry, cattle, dairy products, soybeans, hay, rice, and swine. Industrial outputs include: textile goods, chemical products, paper products, machinery, automobiles and automotive products and tourism. According to the Bureau of Labor Statistics, as of March 2012, South Carolina has 1,852,700 nonfarm jobs of which 12% are in manufacturing, 11.5% are in leisure and hospitality, 19% are in trade, transportation and utilities, and 11.8% are in education and health services. The service sector accounts for 83.7% of the South Carolina economy.
During the economic downturn in the Late 2000s Recession, South Carolina's Unemployment Rate peaked at 12.0% for November and December 2009. It is continuing a steady decline with an unemployment rate of 8.9% as of March 2012.
Many large corporations have moved their locations to South Carolina. Boeing opened an aircraft manufacturing facility in Charleston in 2011, which serves as one of two final assembly sites for the 787 Dreamliner. South Carolina is a right-to-work state and many businesses utilize staffing agencies to temporarily fill positions. This labor force is appealing to companies because of lower wages and no responsibility of maintaining healthcare benefits for its temporary employees. Domtar, located in Rock Hill is the only Fortune 500 company headquartered in South Carolina. The Fortune 1000 list includes SCANA, Sonoco Products and ScanSource.
South Carolina also benefits from foreign investment. There are 1,950 foreign-owned firms operating in South Carolina employing almost 135,000 people. Foreign Direct Investment (FDI) brought 1.06 billion dollars to the state economy in 2010. Since 1994, BMW has had a production facility in Spartanburg.
The arts.
South Carolina has many venues for visual and performing arts. The Gibbes Museum of Art in Charleston, the Greenville County Museum of Art, the Columbia Museum of Art, Spartanburg Art Museum, and the South Carolina State Museum in Columbia among others provide access to visual arts to the state. There are also numerous historic sites and museums scattered throughout the state paying homage to many events and periods in the state's history from Native American inhabitation to the present day.
South Carolina also has performing art venues including the Peace Center in Greenville, the Koger Center for the Arts in Columbia, and the Newberry Opera House, among others to bring local, national, and international talent to the stages of South Carolina. There are several large venues in the state that can house major events, such as Colonial Life Arena in Columbia, Bon Secours Wellness Arena in Greenville, and North Charleston Coliseum.
One of the nation's major performing arts festivals, Spoleto Festival USA, is held annually in Charleston. There are also countless local festivals throughout the state highlighting many cultural traditions, historical events, and folklore.
According to the South Carolina Arts Commission, creative industries generate $9.2 billion annually and support over 78,000 jobs in the state. A 2009 statewide poll by the University of South Carolina Institute for Public Service and Policy Research found that 67% of residents had participated in the arts in some form during the past year and on average citizens had participated in the arts 14 times in the previous year.
Transportation.
Major highways.
Major interstate highways passing through include: I-20 which runs from Florence in the east through Columbia to the southwestern border near Aiken; I-26 which runs from Charleston in the southeast through Columbia to Spartanburg and the northern border in Spartanburg County; I-77 which runs from York County in the north to Columbia; I-85 which runs from Cherokee County in the north through Spartanburg and Greenville to the southwestern border in Oconee County; I-385 which runs from Greenville and intersects with I-26 near Clinton; and I-95 which runs from the northeastern border in Dillon County to Florence and on to the southern border in Jasper County.
Rail.
Passenger.
Amtrak operates four passenger routes in South Carolina: the "Crescent", the "Palmetto", the "Silver Meteor", and the "Silver Star". The "Crescent" route serves the Upstate cities, the "Silver Star" serves the Midlands cities, and the "Palmetto" and "Silver Meteor" routes serve the Lowcountry cities.
Freight.
CSX Transportation and Norfolk Southern are the only Class I railroad companies in South Carolina, as other freight companies in the state are shortlines.
Major and regional airports.
There are seven significant airports in South Carolina, all of which act as regional airport hubs. The busiest by passenger volume is Charleston International Airport. Just across the border in North Carolina is Charlotte/Douglas International Airport, the 30th busiest airport in the world, in terms of passengers.
Government and politics.
South Carolina's state government consists of the Executive, Legislative, and Judicial branches. Also relevant are the state constitution, law enforcement agencies, federal representation, state finances, and state taxes.
South Carolina has historically had a weak executive branch and a strong legislature. Before 1865, governors in South Carolina were appointed by the General Assembly, and held the title "President of State." The 1865 Constitution changed this process, requiring a popular election. Local governments were also weak. But, the 1867 Constitution, passed during the Reconstruction era, extended democratization by establishing home rule for counties, which were established from the former designated districts of the state.
The 1895 state constitution overturned this, reducing the role of counties and strengthening the relative role of the state legislature; essentially the counties were agents of the state and ruled by the General Assembly through the legislative delegation for each county. They are geographically comprehensive; all areas of the state are included in counties. As each county had one state senator, that position was particularly powerful. This status continued until 1973, when the state constitution was amended to provide for home rule for the counties. During this time the state had changed, with increasing urbanization, but rural counties retained proportionally more power as the legislature was based in representatives elected from counties rather than population districts.
The federal court case, "Reynolds v. Sims" (1964), "established the one-man, one-vote
concept for electoral representation at the state level. Legislators were now supposed to represent
more or less equal numbers of people." Residents of urban areas had been found to be markedly underrepresented in the legislature under the county-based system. Reapportionment made obvious the need for other changes to county structure, leading to the legislature passing the constitutional amendment. The Home Rule Act of 1975 implemented the amendment giving more power to the counties. With urbanization their governments have become increasingly important in the state.
Several changes to the state constitution have affected the office of the governor and the cabinet. In 1926 the governor's term was extended from two to four years; in 1982 the governor was allowed to run for a second succeeding term. In 1993, the state passed an amendment requiring a limited cabinet (all of whom must be popularly elected).
Education.
As of 2010, South Carolina is one of three states that has not agreed to use competitive international math and language standards.
South Carolina has 1,144 K-12 schools in 85 school districts, with an enrollment of 712,244 as of fall 2009. As of the 2008–2009 school year, South Carolina spent $9,450 per student which places it 31st in the country for per student spending. In 2011, the average SAT score for South Carolina was 1360.
Institutions of higher education.
South Carolina has a diverse group of institutions of higher education, from large state-funded research universities to small colleges that cultivate a liberal arts, religious or military tradition, including the following:
Health care.
For overall health care, South Carolina is ranked 33rd out of the 50 states, according to the Commonwealth Fund, a private health foundation working to improve the health care system. The state's teen birth rate was 53 births per 1000 teens, compared to the average of 41.9 births for the US, according to the Kaiser Family Foundation. The state's infant mortality rate was 9.4 deaths per 1000 births compared to the US average of 6.9 deaths.
There were 2.6 physicians per 1000 people compared to the US average of 3.2 physicians. There was $5114 spent on health expenses per capita in the state, compared to the US average of $5283. There were 26 percent of children and 13 percent of elderly living in poverty in the state, compared to 23 percent and 13 percent, respectively, doing so in the US. And, 34 percent of children were overweight or obese, compared to the US average of 32 percent.
Sports.
Although no major league professional sports teams are based in South Carolina, the Carolina Panthers do have training facilities in the state. The state is also home to numerous minor league professional teams. College teams represent their particular South Carolina institutions, and are the primary options for football, basketball and baseball attendance in the state. South Carolina is also a top destination for golf and water sports.
South Carolina is also home to one of NASCAR's first tracks and its first paved speedway, Darlington Raceway just northwest of Florence.
Miscellaneous topics.
Famous people from South Carolina.
A number of influential individuals in American life are from South Carolina. Please see main article: List of people from South Carolina
Alcohol laws.
The alcohol laws of South Carolina are part of the state's history. Voters endorsed prohibition in 1892 but instead were given the "Dispensary System" of state-owned liquor stores. Currently, certain counties may enforce time restrictions for beer and wine sales in stores, although there are no dry counties in South Carolina.
Indoor smoking laws.
South Carolina has no statewide smoke-free indoor workplace law. On March 31, 2008, the South Carolina Supreme Court ruled that cities, counties, and towns may enact smoke-free laws which are more stringent than state law. As of July 2012, five South Carolina counties and 43 cities and towns have adopted smoke-free laws.
Further reading.
</dl>

</doc>
<doc id="27960" url="http://en.wikipedia.org/wiki?curid=27960" title="Sessions">
Sessions

Sessions may refer to:
In music:
Other uses:

</doc>
<doc id="27962" url="http://en.wikipedia.org/wiki?curid=27962" title="Session">
Session

Session may refer to:

</doc>
<doc id="27964" url="http://en.wikipedia.org/wiki?curid=27964" title="Sikhism">
Sikhism

Sikhism (; Punjabi: ਸਿੱਖੀ, "sikkhī", ]) is a panentheistic (in some respects) religion founded during the 15th century in the Punjab region of the Indian subcontinent, by Guru Nanak and continued to progress through the ten successive Sikh gurus (the eleventh and last guru being the holy scripture "Guru Granth Sahib". The Guru Granth Sahib is a collection of the Sikh Gurus' writings that was compiled by the 5th Sikh Guru). It is the fifth-largest organized religion in the world, with approximately 30 million adherents. Punjab, India is the only state in the world with a majority Sikh population.
Adherents of Sikhism are known as Sikhs ("students" or "disciples"). According to Devinder Singh Chahal, "The word 'Sikhi' (commonly known as Gurmat) gave rise to the modern anglicized word 'Sikhism' for the modern world." Gurmat means literally 'wisdom of the Guru' in contrast to "Manmat", or self-willed impulses.
According to Sewa Singh Kalsi, "The central teaching in Sikhism is the belief in the concept of the oneness of God." Sikhism considers spiritual life and secular life to be intertwined. Guru Nanak, the first Sikh Guru established the system of the Langar, or communal kitchen, in order to demonstrate the need to share and have equality between all people. Sikhs also believe that "all religious traditions are equally valid and capable of enlightening their followers". In addition to sharing with others Guru Nanak inspired people to earn an honest living without exploitation and also the need for remembrance of the divine name (God). Guru Nanak described living an "active, creative, and practical life" of "truthfulness, fidelity, self-control and purity" as being higher than a purely contemplative life. Guru Hargobind, the sixth Sikh Guru, established the political/temporal (Miri) and spiritual (Piri) realms to be mutually coexistent.
According to the ninth Sikh Guru, Tegh Bahadhur, the ideal Sikh should have both Shakti (power that resides in the temporal), and Bhakti (spiritual meditative qualities). Finally the concept of the baptized Saint Soldier of the Khalsa was formed by the tenth Sikh Guru, Gobind Singh in 1699 at Anandpur Sahib. Sikhs are expected to embody the qualities of a "Sant-Sipāhī"—a saint-soldier. Sikhs are expected to have control over the so-called "Five Thieves" dispel these by means of the so-called "Five Virtues".
Philosophy and teachings.
"Sikh" means a person who professes the Sikh religion, believes and follows the teachings of Sri Guru Granth Sahib and the ten Gurus only, and keeps unshorn hair. ... "I solemnly affirm and declare that I am a "Keshadhari" Sikh, that I believe in and follow the teachings of Sri Guru Granth Sahib and the ten Gurus only, and that I have no other belief.
 "Definition of a Sikh and Sikh affirmation in the Delhi Gurdwara Act of 1971".
The origins of Sikhism lie in the teachings of Guru Nanak and his successors. The essence of Sikh teaching is summed up by Guru Nanak in these words: "Realization of Truth is higher than all else. Higher still is truthful living". Sikh teaching emphasizes the principle of equality of all humans and rejects discrimination on the basis of caste, creed, and gender. Sikh principles encourage living life as a householder.
Sikhism is a Panentheistic (in some respects) and a revealed religion. In Sikhism, the concept of "God" is "Vāhigurū"—is shapeless, timeless, and sightless (i.e., unable to be seen with the physical eye): "niraṅkār", "akaal", and "alakh". The beginning of the first composition of Sikh scripture is the figure "1"—signifying the universality of "God". It states that "God" is omnipresent and infinite with power over everything, and is signified by the term "Ik Onkar". Sikhs believe that before creation, all that existed was "God" and "God's" "hukam" (will or order). When God willed, the entire cosmos was created. From these beginnings, God nurtured "enticement and attachment" to "māyā", or the human perception of reality.
The All Pervading Spirit - The Concept of "God" in Sikhism.
The concept of "god" is different in Sikhism than that of other religions. It is known as "Ik Onkar" or "one constant" or the all pervading spirit (which is taken to mean god). It is found in the Gurmukhi script This "spirit" has no gender in Sikhism (though translations may present it as masculine); it is also "Akaal Purkh" (beyond time and space) and "Nirankar" (without form). In addition, Nanak wrote that there are many worlds on which it has created life.
Nanak further states that the understanding of "Akaal" is beyond human beings, but at the same time not wholly unknowable. "Akaal" is omnipresent ("sarav viāpak") in all creation and visible everywhere to the spiritually awakened. Nanak stressed that god must be seen from "the inward eye", or the "heart", of a human being: devotees must meditate to progress towards enlightenment of heavenly life. Guru Nanak emphasized the revelation through meditation, as its rigorous application permits the existence of communication between god and human beings.
The Mool Mantar, the opening line of the Guru Granth Sahib and each subsequential "Raga":
Liberation.
Guru Nanak's teachings are founded not on a final destination of heaven or hell but on a spiritual union with the Akal which results in salvation or "Jivanmukta", Guru Gobind Singh makes it clear that human birth is obtained with great fortune, therefore one needs to be able to make the most of this life. There has been some confusion among scholars, interpreting the pertinent religious texts as evidence that Sikhs believe in reincarnation and karma as the same as Hinduism and Buddhism when such is not the case. In Sikhism karma "is modified by the concept of God's grace" ("nadar, mehar, kirpa, karam" etc.). Guru Nanak states "The body takes birth because of karma, but salvation is attained through grace". To get closer to God: Sikhs avoid the evils of "Maya", keep the everlasting truth in mind, practice "Shabad Kirtan", meditate on "Naam", and serve humanity. Sikhs believe that being in the company of the "Satsang" or "Sadh Sangat" is one of the key ways to achieve liberation from the cycles of reincarnation.
Worldly Illusion.
"Māyā"—defined as a temporary illusion or "unreality"—is one of the core deviations from the pursuit of God and salvation: where worldly attractions which give only illusory temporary satisfaction and pain which distract the process of the devotion of God. However, Nanak emphasised māyā as not a reference to the unreality of the world, but of its values. In Sikhism, the influences of ego, anger, greed, attachment, and lust—known as the "Five Thieves"—are believed to be particularly distracting and hurtful. Sikhs believe the world is currently in a state of "Kali Yuga" (Age of Darkness) because the world is lead astray by the love of and attachment to Maya. The fate of people vulnerable to the Five Thieves ('Pānj Chor'), is separation from God, and the situation may be remedied only after intensive and relentless devotion.
The Timeless Truth.
According to Nanak the supreme purpose of human life is to reconnect with Akal (The Timeless One), however, egotism is the biggest barrier in doing this. Using the Guru's teaching remembrance of "nām" (the divine Word or the Name of the Lord) leads to the end of egotism. Guru Nanak designated the word 'guru' (meaning "teacher") to mean the voice of "the spirit": the source of knowledge and the guide to salvation. As Ik Onkar is universally immanent, "guru" is indistinguishable from "Akal" and are one and the same. One connects with "guru" only with accumulation of selfless search of truth. Ultimately the seeker realizes that it is the consciousness within the body which is seeker/follower and the Word is the true "guru". The human body is just a means to achieve the reunion with Truth. Once truth starts to shine in a person's heart, the essence of current and past holy books of all religions is understood by the person.
Singing and Music.
Sikhs refer to the hymns of the Gurus as Gurbani (The Guru's word). Shabad Kirtan is the singing of Gurbani. The entire Guru Granth Sahib is written in a form of poetry and rhyme. Guru Nanak started the Shabad Kirtan tradition and taught that listening to kirtan is a powerful way to achieve tranquility while meditating; Singing of the glories of the Supreme Timeless One (God) with devotion is the most effective way to come in communion with the Supreme Timeless One. The three morning prayers for Sikhs consist of Japji Sahib, Jaap Sahib and Tav-Prasad Savaiye. Baptized Sikhs rise early and meditate and then recite all the Five Banis of Nitnem before breakfast.
Remembrance.
A key practice by Sikhs is remembrance of the Divine Name (Naam – the Name of the Lord). This contemplation is done through "Nām Japna" (repetition of the divine name) or "Naam Simran" (remembrance of the divine Name through recitation). The verbal repetition of the name of God or a sacred syllable is an established practice in religious traditions in India but Guru Nanak's interpretation emphasized inward, personal observance. Guru Nanak's ideal is the total exposure of one's being to the divine Name and a total conforming to Dharma or the "Divine Order". Nanak described the result of the disciplined application of "nām simraṇ" as a "growing towards and into God" through a gradual process of five stages. The last of these is "sach khaṇḍ" ("The Realm of Truth")—the final union of the spirit with God.
Service and Action.
Meditation is unfruitful without service and action. 
Sikhs are taught that selfless service, or "sēvā", and charitable work enables the devotee to kill the ego. 
Service in Sikhism takes three forms: "Tan" - physical service; "Man" - mental service (such as studying to help others); and "Dhan" - material service. Guru Nanak stressed now "kirat karō": that a Sikh should balance work, worship, and charity, and should defend the rights of all human beings. They are encouraged to have a "chaṛdī kalā", or "optimistic" - "resilience", view of life. Sikh teachings also stress the concept of sharing—"vaṇḍ chakkō"—through the distribution of free food at Sikh gurdwaras ("laṅgar"), giving charitable donations, and working for the good of the community and others ("sēvā").
Justice and Equality.
Sikhism regards "Justice" and "Restorative Justice" and "divine justice" as trumping any subjective codes of moral order. The word in Punjabi used to depict this is "Niau" which means justice. The word "dharam" (righteousness) is also used to convey justice "in the sense of the moral order". "An attack on dharam is an attack on justice, on righteousness, and on the moral order generally". According to the Tenth Sikh Guru, Guru Gobind Singh "when all efforts to restore peace prove useless and no words avail, lawful is the flash of steel, it is right to draw the sword".
Men and women are equal in Sikhism and share the same rights. In contrast, while churches have been arguing in recent times on female priest ordination, women have been leading in prayers at Sikh temples since the founding of Sikhism.
Ten gurus and religious authority.
The term guru comes from the Sanskrit "gurū", meaning teacher, guide, or mentor. The traditions and philosophy of Sikhism were established by ten specific gurus from 1469 to 1708. Each guru added to and reinforced the message taught by the previous, resulting in the creation of the Sikh religion. Guru Nanak was the first guru and appointed a disciple as successor. Guru Gobind Singh was the final guru in human form. Before his death, Guru Gobind Singh decreed that the Gurū Granth Sāhib would be the final and perpetual guru of the Sikhs.
Guru Angad succeeded Guru Nanak. Later, an important phase in the development of Sikhism came with the third successor, Guru Amar Das. Guru Nanak's teachings emphasised the pursuit of salvation; Guru Amar Das began building a cohesive community of followers with initiatives such as sanctioning distinctive ceremonies for birth, marriage, and death. Amar Das also established the "manji" (comparable to a diocese) system of clerical supervision.
Guru Amar Das's successor and son-in-law Guru Ram Das founded the city of Amritsar, which is home of the Harimandir Sahib and regarded widely as the holiest city for all Sikhs. Guru Arjan was captured by Mughal authorities who were suspicious and hostile to the religious order he was developing. His persecution and death inspired his successors to promote a military and political organization of Sikh communities to defend themselves against the attacks of Mughal forces.
The Sikh gurus established a mechanism which allowed the Sikh religion to react as a community to changing circumstances. The sixth guru, Guru Hargobind, was responsible for the creation of the concept of Akal Takht ("throne of the timeless one"), which serves as the supreme decision-making centre of Sikhism and sits opposite the Harmandir Sahib. The "Sarbat Ḵẖālsā" (a representative portion of the Khalsa Panth) historically gathers at the Akal Takht on special festivals such as Vaisakhi or Hola Mohalla and when there is a need to discuss matters that affect the entire Sikh nation. A "gurmatā" (literally, "guru's intention") is an order passed by the Sarbat Ḵẖālsā in the presence of the Gurū Granth Sāhib. A gurmatā may only be passed on a subject that affects the fundamental principles of Sikh religion; it is binding upon all Sikhs. The term "hukamnāmā" (literally, "edict" or "royal order") is often used interchangeably with the term gurmatā. However, a hukamnāmā formally refers to a hymn from the Gurū Granth Sāhib which is a given order to Sikhs.
History.
Guru Nanak (1469–1539), the founder of Sikhism, was born in the village of "Rāi Bhōi dī Talwandī", now called Nankana Sahib (in present-day Pakistan). His parents were Khatri Hindus. As a boy, Nanak was fascinated by God and religion. He would not partake in religious rituals or customs and oddly meditated alone. His desire to explore the mysteries of life eventually led him to leave home and take missionary journeys.
In his early teens, Nanak caught the attention of the local landlord Rai Bular Bhatti, who was moved by his amazing intellect and divine qualities. Rai Bular Bhatti was witness to many incidents in which Nanak enchanted him and as a result Rai Bular Bhatti and Nanak's sister Bibi Nanki, became the first persons to recognise the divine qualities in Nanak. Both of them then encouraged and supported Nanak to study and travel. At the age of thirty, Nanak went missing and was presumed to have drowned after going for one of his morning baths to a local stream called the "Kali Bein". He reappeared three days later and declared: "There is no Hindu, there is no Muslim" (in Punjabi, "nā kōi hindū nā kōi musalmān"). It was from this moment that Nanak would begin to spread the teachings of what was then the beginning of Sikhism. Although the exact account of his itinerary is disputed, he is widely acknowledged to have made five major journeys, spanning thousands of miles, the first tour being east towards Bengal and Assam, the second south towards Andhra and Tamil Nadu, the third north towards Kashmir, Ladakh, and Tibet, and the fourth tour west towards Baghdad and Mecca. In his last and final tour, he returned to the banks of the Ravi River to end his days.
Growth of Sikhism.
In 1539, Guru Nanak chose his disciple "Lahiṇā" as a successor to the guruship rather than either of his sons. Lahiṇā was named Guru Angad and became the second guru of the Sikhs. Nanak conferred his choice at the town of Kartarpur on the banks of the river Ravi, where Nanak had finally settled down after his travels. Though Sri Chand was not an ambitious man, the Udasis believed that the Guruship should have gone to him, since he was a man of pious habits in addition to being Nanak's son. On Nanak's advice, Guru Angad moved from Kartarpur to Khadur, where his wife Khivi and children were living, until he was able to bridge the divide between his followers and the Udasis. Guru Angad continued the work started by Guru Nanak and is widely credited for standardising the Gurmukhī script as used in the sacred scripture of the Sikhs.
Guru Amar Das became the third Sikh guru in 1552 at the age of 73. Goindval became an important centre for Sikhism during the guruship of Guru Amar Das. He preached the principle of equality for women by prohibiting purdah and sati. Guru Amar Das also encouraged the practice of langar and made all those who visited him attend laṅgar before they could speak to him. In 1567, Emperor Akbar sat with the ordinary and poor people of Punjab to have laṅgar. Guru Amar Das also trained 146 apostles of which 52 were women, to manage the rapid expansion of the religion. Before he died in 1574 aged 95, he appointed his son-in-law Jēṭhā, a Khatri of the Sodhi clan, as the fourth Sikh guru.
"Jēṭhā" became Guru Ram Das and vigorously undertook his duties as the new guru. He is responsible for the establishment of the city of Ramdaspur later to be named Amritsar. Before Ramdaspur, Amritsar was known as Guru Da Chakk. In 1581, Guru Arjan—youngest son of the fourth guru—became the fifth guru of the Sikhs. In addition to being responsible for building the Harimandir Sahib, he prepared the Sikh sacred text known as the Ādi Granth (literally "the first book") and included the writings of the first five gurus and other enlightened Hindu and Muslim saints. In 1606, he was tortured and killed by the Mughal Emperor, Jahangir, for refusing to make changes to the Granth and for supporting an unsuccessful contender to the throne.
Political advancement.
Guru Hargobind became the sixth guru of the Sikhs. He carried two swords—one for spiritual and the other for temporal reasons (known as "mīrī" and "pīrī" in Sikhism). Sikhs grew as an organized community and under the 10th Guru the Sikhs developed a trained fighting force to defend their independence. In 1644, Guru Har Rai became guru followed by Guru Har Krishan, the boy guru, in 1661. Guru Har Krishan helped to heal many sick people. Coming into contact with so many people every day, he too was infected and taken seriously ill and later died. No hymns composed by these three gurus are included in the Guru Granth Sahib.
Guru Tegh Bahadur became guru in 1665 and led the Sikhs until 1675. Guru Tegh Bahadur was executed by Aurangzeb for helping to protect one's right to freedom of religion, after a delegation of Kashmiri Pandits came to him for help when the Emperor began to persecute those who refused to convert to Islam. He was succeeded by his son, Gobind Rai who was just nine years old at the time of his father's death. Gobind Rai further militarised his followers, and was baptised by the "Pañj Piārē" when he inaugurated the Khalsa on 30 March 1699. From here on in he was known as Guru Gobind Singh.
From the time of Nanak the Sikhs had significantly transformed. Even though the core Sikh spiritual philosophy was never affected, the followers now began to develop a political identity. Conflict with Mughal authorities escalated during the lifetime of Guru Teg Bahadur and Guru Gobind Singh.
Sikh Confederacy and the rise of the Khalsa.
The tenth guru of Sikhism, Guru Gobind Singh, inaugurated the Khalsa (the collective body of all initiated Sikhs) as the Sikh temporal authority in the year 1699. The Khalsa is a disciplined community that combines its spiritual purpose and goals with political and military duties. Shortly before his death, Guru Gobind Singh proclaimed the Gurū Granth Sāhib (the Sikh Holy Scripture) to be the ultimate spiritual authority for the Sikhs.
The Sikh Khalsa's rise to power began in the 17th century during a time of growing militancy against Mughal rule. The creation of a Sikh Empire began when Guru Gobind Singh sent a Sikh general, Banda Singh Bahadur, to fight the Mughal rulers of India and those who had committed atrocities against Pir Buddhu Shah. Banda Singh advanced his army towards the main Muslim Mughal city of Sirhind and, following the instructions of the guru, punished all the culprits. Soon after the invasion of Sirhind, while resting in his chamber after the Rehras prayer Guru Gobind Singh was stabbed by a Pathan assassin hired by Mughals. Gobind Singh killed the attacker with his sword. Though a European surgeon stitched the Guru's wound, the wound re-opened as the Guru tugged at a hard strong bow after a few days, causing profuse bleeding that led to Gobind Singh's death.
After the Guru's death, Baba Banda Singh Bahadur became the commander-in-chief of the Khalsa. He organized the civilian rebellion and abolished or halted the Zamindari system in time he was active and gave the farmers proprietorship of their own land. Banda Singh was executed by the emperor Farrukh Siyar after refusing the offer of a pardon if he converted to Islam. The confederacy of Sikh warrior bands known as "misls" alongside the development of the Dal Khalsa achieved a series of sweeping military and diplomatic victories, eventually creating a Sikh Empire in the Punjab under the emperor, Maharaja Ranjit Singh in 1799.
The vast Sikh empire with its capital in Lahore and limits reaching the Khyber Pass and the borders of China comprised almost 200000 mi2 of what is now Afghanistan, Pakistan and Northern India. The Sikh nation's embrace of military and political organisation made it a considerable regional force in 19th century India and allowed it to retain control of the Sikh Empire in the face of numerous local uprisings. The order, traditions and discipline developed over centuries culminated at the time of Ranjit Singh to give rise to a common religious and social identity.
After the death of Ranjit Singh in 1839, the Sikh Empire fell into disorder and, after the assassination of several successors, eventually fell on the shoulders of his youngest son, Maharaja Duleep Singh. Soon after, the British began to attack the Sikh Kingdom. Both British and Sikh sides sustained heavy losses of both troops and materials in the hard-fought First and Second Anglo-Sikh Wars. The Empire was eventually annexed by the United Kingdom, bringing the Punjab under the British Raj.
Partition.
A quarter of a century later, Sikhs formed the Shiromani Gurdwara Prabandhak Committee and the Shiromani Akali Dal to preserve Sikhs' religious and political organization. Of the violence that accompanied the Partition of India, historians Ian Talbot and Gurharpal Singh write:
There are numerous eyewitness accounts of the maiming and mutilation of victims. The catalogue of horrors includes the disembowelling of pregnant women, the slamming of babies' heads against brick walls, the cutting off of victims limbs and genitalia and the display of heads and corpses. While previous communal riots had been deadly, the scale and level of brutality was unprecedented. Although some scholars question the use of the term 'genocide' with respect to the Partition massacres, much of the violence manifested as having genocidal tendencies. It was designed to cleanse an existing generation as well as prevent its future reproduction.
The newly formed governments were completely unequipped to deal with migrations of such staggering magnitude, and massive violence and slaughter occurred on both sides of the border. Estimates of the number of deaths vary, with low estimates at 200,000 and high estimates at 1,000,000.
The emergency meeting of the joint defense council on 16 August agreed to strengthen the Punjab boundary force as quickly as possible. Nehru and liquat visited Lahore, Ambala, Jilandur and Amritsar together to see for themselves what was going on and to appeal for peace. They tried to remind everyone that both India and Pakistan had pledged to protect the minorities after the partition and that there was no need for anyone to move home but they were shouting against the hurricane. Each new outrage, each new massacre brought the thirst for revenge and desperate need to flee from the terror as the scale of disaster mounted, Tara Singh and other Sikh leaders toured the province in military vehicles, appealing to stop the violence, but their followers had tasted blood, and it was too late for Tara Singh to stop what he had begun.
Sikhs faced initial opposition from the Government in forming a linguistic state that other states in India were afforded. The Akali Dal started a non-violence movement for Sikh and Punjabi rights. Jarnail Singh Bhindranwale emerged as a leader of the Damdami Taksal in 1977 and promoted a more militant solution to the problem. In June 1984, Indian Prime Minister Indira Gandhi ordered the Indian army to launch Operation Blue Star to remove Bhindranwale and his followers from the Darbar Sahib. Bhindranwale and his accompanying followers, as well as many innocent Sikhs visiting the temple, were killed during the army's operations. In October, Indira Gandhi was assassinated by two of her Sikh bodyguards. The assassination was followed by the 1984 anti-Sikh riots. and Hindu-Sikh conflicts in Punjab, as a reaction to Operation Blue Star and the assassination.
Scripture.
There is one primary source of scripture for the Sikhs: the Gurū Granth Sāhib. The Gurū Granth Sāhib may be referred to as the Ādi Granth—literally, "The First Volume"—and the two terms are often used synonymously. Here, however, the Ādi Granth refers to the version of the scripture created by Guru Arjan in 1604. The Gurū Granth Sāhib is the final version of the scripture created by Guru Gobind Singh.
There are other sources of scriptures such as the Dasam Granth and so called Janamsakhis. These however, have been the subject of controversial debate amongst the Sikh community.
Adi Granth.
The Ādi Granth was compiled primarily by Bhai Gurdas under the supervision of Guru Arjan between the years 1603 and 1604. It is written in the Gurmukhī script, which is a descendant of the Laṇḍā script used in the Punjab at that time. The Gurmukhī script was standardised by Guru Angad, the second guru of the Sikhs, for use in the Sikh scriptures and is thought to have been influenced by the Śāradā and Devanāgarī scripts. An authoritative scripture was created to protect the integrity of hymns and teachings of the Sikh gurus and fifteen bhagats. These fifteen bhagats are Namdev, Ravidas, Jaidev, Trilocan, Beni, Ramanand, Sainu, Dhanna, Sadhna, Pipa, Sur, Bhikhan, Paramanand, Farid, and Kabir. At the time, Arjan Sahib tried to prevent undue influence from the followers of Prithi Chand, the guru's older brother and rival.
Guru Granth Sahib.
The final version of the Gurū Granth Sāhib was compiled by Guru Gobind Singh in 1678. It consists of the original Ādi Granth with the addition of Guru Tegh Bahadur's hymns. The Guru Granth Sahib is considered the Eleventh and final spiritual authority of the Sikhs.
It contains compositions by the first five Gurus, Guru Teg Bahadur and just one "śalōk" ("couplet") from Guru Gobind Singh. It also contains the traditions and teachings of "sants" ("saints") such as Kabir, Namdev, Ravidas, and Sheikh Farid along with several others.
The bulk of the scripture is classified into "rāgs", with each rāg subdivided according to length and author. There are 31 rāgs within the Gurū Granth Sāhib. In addition to the rāgs, there are clear references to the folk music of Punjab. The main language used in the scripture is known as "Sant Bhāṣā", a language related to both Punjabi and Hindi and used extensively across medieval northern India by proponents of popular devotional religion. As per the name "Gurmukhi", it is not merely a script but it is the language which came out of Guru's mouth – by using this definition, all words in Guru Granth Sahib constitute "Gurbani" words, thus making Gurmukhi language which then constitute two components – spoken Gurmukhi words (in form of Gurbani) which originated from different languages (like world's different languages have similar roots) and Gurmukhi script. The text further comprises over 5000 "śabads" (hymns), which are poetically constructed and set to classical form of music rendition, can be set to predetermined musical "tāl" (rhythmic beats).
The Granth begins with the "Mūl Mantra", an iconic verse created by Nanak:
All text within the Granth is known as "gurbānī". And Gurbani is the Guru "Baani Guru Guru hai Baani" (The word is the Guru and Guru is the word) and "Shabd Guru Surat Dhun Chaylaa" (The Shabad is the Guru, upon whom I lovingly focus my consciousness; I am the disciple.). Therefore, as evident from the message of the Guru Nanak (first Guru) Shabad (or word) was always the Guru (the enlightener); however, as Sikhism stand on the dual strands of Miri-Piri, the Guru in Sikhism is a combination of teacher-leader. Therefore, the lineage from Guru Nanak to Guru Gobind Singh was of the teacher-leaders eventually wherein the temporal authority was passed on to the Khalsa and spiritual authority, which always was with, passed to Adi Granth(thence the Guru Granth Sahib).
Therefore, Guru Granth Sahib and its 11th body -the Khalsa is the Guru, teacher-leader, of the Sikhs till eternity.
Dasam Granth.
The Dasam Granth is a scripture of Sikhs which contains texts attributed to the Tenth Guru. The Dasam Granth holds a significance of great amount for Sikhs, however it does not have the same authority as Adi Granth. Some compositions of the Dasam Granth like Jaap Sahib, (Amrit Savaiye), and Benti Chaupai are part of the daily prayers/lessons (Nitnem) of/for Sikhs.
The authenticity of the Dasam Granth is amongst the most debated topics within Sikhism.
Janamsakhis.
The Janamsākhīs (literally "birth stories"), are writings which profess to be biographies of Nanak. Although not scripture in the strictest sense, they provide an interesting look at Nanak's life and the early start of Sikhism. There are several—often contradictory and sometimes unreliable—Janamsākhīs and they are not held in the same regard as other sources of scriptural knowledge.
Observances.
Observant Sikhs adhere to long-standing practices and traditions to strengthen and express their faith. The daily recitation from memory of specific passages from the Gurū Granth Sāhib, especially the "Japu" (or "Japjī", literally "chant") hymns is recommended immediately after rising and bathing. Family customs include both reading passages from the scripture and attending the gurdwara (also "gurduārā", meaning "the doorway to God"; sometimes transliterated as "gurudwara"). There are many gurdwaras prominently constructed and maintained across India, as well as in almost every nation where Sikhs reside. Gurdwaras are open to all, regardless of religion, background, caste, or race.
Worship in a gurdwara consists chiefly of singing of passages from the scripture. Sikhs will commonly enter the gurdwara, touch the ground before the holy scripture with their foreheads. The recitation of the eighteenth century "ardās" is also customary for attending Sikhs. The ardās recalls past sufferings and glories of the community, invoking divine grace for all humanity.
The Sikh faith also participates in the custom of "Langar" or the community meal. All gurdwaras are open to anyone of any faith for a free meal. People can enter and eat together and are served by faithful members of the community. This is the main cost associated with gurdwaras and where monetary donations are primarily spent.
Sikh festivals/events.
Technically, there are no festivals in Sikhism. However, the events mostly centred around the lives of the Gurus and Sikh martyrs are commemorated. The SGPC, the Sikh organisation in charge of upkeep of the historical gurdwaras of Punjab, organises celebrations based on the new Nanakshahi calendar. This calendar is highly controversial among Sikhs and is not universally accepted. Sikh festivals include the following:
Nagar Kirtan crowd listening to Kirtan at Yuba City.
Ceremonies and customs.
Guru Nanak taught that rituals, religious ceremonies, or idol worship are of little use and Sikhs are discouraged from fasting or going on pilgrimages. Sikhs do not believe in converting people but converts to Sikhism by choice are welcomed. The morning and evening prayers take around two hours a day, starting in the very early morning hours. The first morning prayer is Guru Nanak's "Jap Ji". Jap, meaning "recitation", refers to the use of sound, as the best way of approaching the divine. Like combing hair, hearing and reciting the sacred word is used as a way to comb all negative thoughts out of the mind. The second morning prayer is Guru Gobind Singh's universal Jaap Sahib. The Guru addresses God as having no form, no country, and no religion but as the seed of seeds, sun of suns, and the song of songs. The Jaap Sahib asserts that God is the cause of conflict as well as peace, and of destruction as well as creation. Devotees learn that there is nothing outside of God's presence, nothing outside of God's control. Devout Sikhs are encouraged to begin the day with private meditations on the name of God.
Upon a child's birth, the Guru Granth Sahib is opened at a random point and the child is named using the first letter on the top left hand corner of the left page. All boys are given the last name Singh, and all girls are given the last name Kaur (this was once a title which was conferred on an individual upon joining the Khalsa). Sikhs are joined in wedlock through the "anand kāraj" ceremony. Sikhs are required to marry when they are of a sufficient age (child marriage is taboo), and without regard for the future spouse's caste or descent. The marriage ceremony is performed in the company of the Guru Granth Sahib; around which the couple circles four times. After the ceremony is complete, the husband and wife are considered "a single soul in two bodies."
According to Sikh religious rites, neither husband nor wife is permitted to divorce unless special circumstances arise. A Sikh couple that wishes to divorce may be able to do so in a civil court. Upon death, the body of a Sikh is usually cremated. If this is not possible, any means of disposing the body may be employed. The "kīrtan sōhilā" and "ardās" prayers are performed during the funeral ceremony (known as "antim sanskār").
Baptism and the Khalsa.
Khalsa (meaning "Sovereign") is the collective name given by Gobind Singh to all Sikhs, male or female, who have been baptised or initiated by taking "ammrit" in a ceremony called "ammrit sañcār". The first time that this ceremony took place was on Vaisakhi, which fell on 30 March 1699 at Anandpur Sahib in Punjab. It was on that occasion that Gobind Singh baptised the Pañj Piārē—the five beloved ones, who in turn baptised Gobind Singh himself. The last name, Singh, meaning lion, is given to baptized Sikh males, and the last name Kaur, meaning princess/lioness, is given to baptized Sikh females.
Baptised Sikhs are bound to wear the Five Ks (in Punjabi known as "pañj kakkē" or "pañj kakār") at all times. The 5 items are: "kēs" (uncut hair), "kaṅghā" (small wooden comb), "kaṛā" (circular steel or iron bracelet), "kirpān" (sword/dagger), and "kacchera" (special undergarment). The Five Ks have both practical and symbolic purposes.
Sikh people.
Sikhs firmly believe in sewa (service to community and God) and simran (remembrance of God), the two tenets of Sikh life. The list of prominent Sikhs in humanitarian activities include Bhai Kanhaiya (1648–1718), Bhagat Puran Singh (1904-1992), Bhai Trilochan Singh Panesar (1937-2010).
According to Sewa Singh Kalsi, the Sikh people have gained a reputation through history for being sturdy, hardworking and adventurous; they are a people who have earned the reputation for being extremely brave and loyal soldiers. They have also become known for being a militant people.
Beginning in 1968, Yogi Bhajan (later of the 3HO movement) began to teach classes kundalini yoga, resulting in a number of non-Punjabi converts to Sikhism (known as white Sikhs) in the United States. Since then, thousands of non-Punjabis have taken up the Sikh belief and lifestyle primarily in the United States, Canada, Latin America, the Far East and Australia.
Since 2010, the Sikh Directory has organized The Sikh Awards, the first Sikh award ceremony in the world.
Sikh Castes.
Although the Sikh Gurus criticised the hierarchy of the caste system, one does exist in Sikh community. According to Sunrinder S, Jodhka, the Sikh
religion does not advocate discrimination against any caste or creed, however, in practice, Sikhs belonging to the landowning dominant castes have not shed all their prejudices against the dalits. While dalits would be allowed entry into the village gurudwaras they would not be permitted to cook or serve langar (Communal meal). Therefore, wherever they could mobilise resources, the dalits of Punjab have tried to construct their own gurudwara and other local level institutions in order to attain a certain degree of cultural autonomy.
In 1953, the government of India acceded to the demands of the Sikh leader, Master Tara Singh, to include Sikh castes of the converted untouchables in the list of scheduled castes.
In the Shiromani Gurdwara Prabandhak Committee, 20 of the 140 seats are reserved for low-caste Sikhs.
Over 60% of Sikhs belong to the Jat caste, which is a rural caste. Despite being very small in numbers, the mercantile Khatri and Arora castes wield considerable influence within the Sikh community. Other Sikhs castes include the Ramgarhias (artisans), the Ahluwalias (formerly Kalals [brewers] and the two Dalit castes, known in Sikh terminology as the Mazhabis (the Chuhras) and the Ramdasias (the Chamars).
Sikh Diaspora.
Worldwide, there are 25.8 million Sikhs, which makes up 0.39% of the world's population. Approximately 75% of Sikhs live in the Punjab, where they constitute about 60% of the state's population. Large communities of Sikhs live in the neighboring states such as Indian State of Haryana which is home to the second largest Sikh population in India with 1.1 million Sikhs as per 2001 census, and large communities of Sikhs can be found across India. However, Sikhs only comprise about 2% of the Indian population.
Sikh migration to Canada began in the 19th century and led to the creation of significant Sikh communities, predominantly in South Vancouver, British Columbia, Surrey, British Columbia, and Brampton, Ontario. Today temples, newspapers, radio stations, and markets cater to these large, multi-generational Indo-Canadian groups. Sikh festivals such as Diwali and Vaisakhi are celebrated in those Canadian cities by the largest groups of followers in the world outside of the Punjab.
Sikhs also migrated to East Africa, West Africa, the Middle East, Southeast Asia, the United Kingdom as well as United States and Australia. These communities developed as Sikhs migrated out of Punjab to fill in gaps in imperial labour markets. In the early twentieth century a significant community began to take shape on the west coast of the United States. Smaller populations of Sikhs are found within many countries in Western Europe, Mauritius, Malaysia, Fiji, Nepal, China, Pakistan, Afghanistan, Iraq, Singapore, Mexico, the United States and many other countries.
Prohibitions in Sikhism.
There are a number of religious prohibitions in Sikhism.
Prohibited are:

</doc>
<doc id="27969" url="http://en.wikipedia.org/wiki?curid=27969" title="Structural isomer">
Structural isomer

Structural isomerism, or constitutional isomerism (per IUPAC), is a form of isomerism in which molecules with the same molecular formula have bonded together in different orders, as opposed to stereoisomerism. There are multiple synonyms for constitutional isomers.
Three categories of constitutional isomers are skeletal, positional, and functional isomers. Positional isomers are also called regioisomers.
Chain isomerism.
In chain isomerism, or skeletal isomerism, components of the (usually carbon) skeleton are distinctly re-ordered to create different structures. Pentane exists as three isomers: "n"-pentane (often called simply "pentane"), isopentane (2-methylbutane) and neopentane (dimethylpropane).
Position isomerism (regioisomerism).
In position isomerism (regioisomerism) a functional group or other substituent changes position on a parent structure. In the table below, the hydroxyl group can occupy three different positions on an n-pentane chain forming three different compounds.
Many aromatic isomers exist because substituents can be positioned on different parts of the benzene ring. Only one isomer of phenol or hydroxybenzene exists but cresol or methylphenol has three isomers where the additional methyl group can be placed on three different positions on the ring. Xylenol has one hydroxyl group and two methyl groups and a total of 6 isomers exist.
Functional group isomerism.
Functional isomers are structural isomers that have the same molecular formula (that is, the same number of atoms of the same elements), but the atoms are connected in different ways so that the groupings are dissimilar. These groups of atoms are called functional groups, functionalities, or moieties. Another way to say this is that two compounds with the same molecular formula, but different functional groups, are functional isomers.
For example, cyclohexane and 1-hexene both have the formula C6H12. These two are considered functional group isomers because cyclohexane is a cycloalkane and hex-1-ene is an alkene.
For two molecules to be functional isomers, they must contain key groups of atoms arranged in particular ways. Some of the best examples come from organic chemistry. C2H6O is a molecular formula. Depending on how the atoms are arranged, it can represent two different compounds dimethyl ether CH3-O-CH3 or ethanol CH3CH2-O-H. Dimethyl ether and ethanol are functional isomers. The first is an ether. The carbon chain-oxygen-carbon chain functionality is called an ether. The second is an alcohol. The carbon chain-oxygen-hydrogen functionality is called an alcohol.
If the functionalities stay the same, but their locations change, the structural isomers are not functional isomers. 1-Propanol and 2-propanol are structural isomers, but they are not functional isomers. Both of them are alcohols. The functional group (carbon chain-O-H) is present in both of these compounds, but they are not the same.
While some chemists use the terms structural isomer and functional isomer interchangeably, not all structural isomers are functional isomers.
Functional isomers are most often identified in chemistry using infrared spectroscopy. Infrared radiation corresponds to the energies associated primarily with molecular vibration. The alcohol functionality has a very distinct vibration called OH-stretch that is due to hydrogen bonding. All alcohols in liquid and solid form absorb infrared radiation at certain wavelengths.
Compounds with the same functional groups will all absorb certain wavelengths of infrared light because of the vibrations associated with those groups. In fact, the infrared spectrum is divided into two regions. The first part is called the functional group region. Dimethyl ether and ethanol would have dissimilar infrared spectra in the functional group region.
The second part of the infrared spectrum is called the fingerprint region; it is associated with types of motion allowed by the symmetry of the molecule and influenced by the bond energies. The fingerprint region is more specific to an individual compound. Even though 1-propanol and 2-propanol have similar infrared spectra in the functional group region, they differ in the fingerprint region.
In simple terms, functional isomers are structural isomers that have different functional groups like alcohol and ether.
Isomer counting.
As an example of isomer counting, there are nine structural isomers with molecular formula C3H6O having different bond connectivities. Seven of them are air-stable at ambient temperature, and are given in the table below. An additional two structural isomers are the enol tautomers of the carbonyl isomers, but these are not stable.

</doc>
<doc id="27970" url="http://en.wikipedia.org/wiki?curid=27970" title="Stereoisomerism">
Stereoisomerism

Stereoisomers are isomeric molecules that have the same molecular formula and sequence of bonded atoms (constitution), but that differ "only" in the three-dimensional orientations of their atoms in space. This contrasts with structural isomers, which share the same molecular formula, but the bond connections or their order differs. By definition, molecules that are stereoisomers of each other represent the same structural isomer.
Enantiomers.
Enantiomers are two stereoisomers that are related to each other by a reflection: They are mirror images of each other that are non-superimposable. Human hands are a macroscopic analog of stereoisomerism. Every stereogenic center in one has the opposite configuration in the other. Two compounds that are enantiomers of each other have the same physical properties, except for the direction in which they rotate polarized light and how they interact with different optical isomers of other compounds. As a result, different enantiomers of a compound may have substantially different biological effects. Pure enantiomers also exhibit the phenomenon of optical activity and can be separated only with the use of a chiral agent. In nature, only one enantiomer of most chiral biological compounds, such as amino acids (except glycine, which is achiral), is present.
Diastereomers.
Diastereomers are stereoisomers not related through a reflection operation. They are not mirror images of each other. These include meso compounds, "cis"–"trans" ("E"-"Z") isomers, and non-enantiomeric optical isomers. Diastereomers seldom have the same physical properties. In the example shown below, the meso form of tartaric acid forms a diastereomeric pair with both levo and dextro tartaric acids, which form an enantiomeric pair.
It should be carefully noted here that the - and - labeling of the isomers above is not the same as the "d"- and "l"- labeling more commonly seen, explaining why these may appear reversed to those familiar with only the latter naming convention. Please refer to Chirality for more information regarding the - and - labels.
Cis–trans and E-Z isomerism.
Stereoisomerism about double bonds arises because rotation about the double bond is restricted, keeping the substituents fixed relative to each other. If the two substituents on at least one end of a double bond are the same, then there is no stereoisomer and the double bond is not a stereocenter, e.g. propene, CH3CH=CH2 where the two substituents at one end are both H.
Traditionally, double bond stereochemistry was described as either "cis" (Latin, on this side) or "trans" (Latin, across), in reference to the relative position of substituents on either side of a double bond. The simplest examples of "cis"-"trans" isomerism are the 1,2-disubstituted ethenes, like the dichloroethene (C2H2Cl2) isomers shown below.
Molecule I is "cis"-1,2-dichloroethene and molecule II is "trans"-1,2-dichloroethene. Due to occasional ambiguity, IUPAC adopted a more rigorous system wherein the substituents at each end of the double bond are assigned priority based on their atomic number. If the high-priority substituents are on the same side of the bond, it is assigned Z (Ger. "zusammen", together). If they are on opposite sides, it is E (Ger. "entgegen", opposite). Since chlorine has a larger atomic number than hydrogen, it is the highest-priority group. Using this notation to name the above pictured molecules, molecule I is (Z)-1,2-dichloroethene and molecule II is (E)-1,2-dichloroethene. It is not the case that Z and "cis" or E and "trans" are always interchangeable. Consider the following fluoromethylpentene:
The proper name for this molecule is either "trans"-2-fluoro-3-methylpent-2-ene because the alkyl groups that form the backbone chain (i.e., methyl and ethyl) reside across the double bond from each other, or (Z)-2-fluoro-3-methylpent-2-ene because the highest-priority groups on each side of the double bond are on the same side of the double bond. Fluoro is the highest-priority group on the left side of the double bond, and ethyl is the highest-priority group on the right side of the molecule.
The terms "cis" and "trans" are also used to describe the relative position of two substituents on a ring; "cis" if on the same side, otherwise "trans".
Conformers.
Conformational isomerism is a form of isomerism that describes the phenomenon of molecules with the same structural formula but with different shapes due to rotations about one or more bonds. Different conformations can have different energies, can usually interconvert, and are very rarely isolatable. For example, cyclohexane can exist in a variety of different conformations including a chair conformation and a boat conformation, but, for cyclohexane itself, these can never be separated. The boat conformation represents the energy maximum on a conformational itinerary between the two equivalent chair forms; however, it does not represent the transition state for this process, because there are lower-energy pathways. There are some molecules that can be isolated in several conformations, due to the large energy barriers between different conformations. 2,2,2',2'-Tetrasubstituted biphenyls can fit into this latter category.
Atropisomers.
Atropisomers are stereoisomers resulting from hindered rotation about single bonds where the steric strain barrier to rotation is high enough to allow for the isolation of the conformers.
Le Bel-van't Hoff rule.
Le Bel-van't Hoff rule states that if n is the number of asymmetric carbon atoms then the maximum number of isomers = 2n. As an example, the aldohexose D-glucose has the formula (C·H2O) 6, of which four of its six carbons atoms are stereogenic or asymmetric, making it one of 24=16 possible stereoisomers.

</doc>
<doc id="27972" url="http://en.wikipedia.org/wiki?curid=27972" title="Sylvia Sayer">
Sylvia Sayer

Sylvia Olive Pleadwell Sayer, Lady Sayer (1904–2000) was one of the foremost early conservators of what is now Dartmoor National Park, in Devon in the south-west of England. She acquired her title in 1959 when her husband, Vice-Admiral Guy Sayer was knighted as the Flag Officer Commanding Reserve Fleet. 
She was a fearless and impassionedfighter in the defence of Dartmoor: frequently she deliberately interrupted army live-firing exercises on Dartmoor's military ranges, and in 1985 snubbed The Prince of Wales over the Duchy of Cornwall's management plan for Dartmoor, since this allowed for a continuance of military usage.

</doc>
<doc id="27977" url="http://en.wikipedia.org/wiki?curid=27977" title="South Park">
South Park

South Park is an American adult animated sitcom created by Trey Parker and Matt Stone for the Comedy Central television network. Intended for mature audiences, the show has become infamous for its crude language and dark, surreal humor that satirizes a wide range of topics. The ongoing narrative revolves around four boys—Stan Marsh, Kyle Broflovski, Eric Cartman, and Kenny McCormick—and their bizarre adventures in and around the titular Colorado town. Much like "The Simpsons", "South Park" utilizes a very large ensemble cast of recurring characters.
Parker and Stone developed the show from two animated shorts they created in 1992 and 1995. The latter became one of the first Internet viral videos, which ultimately led to its production as a series. "South Park" debuted in August 1997 with great success, consistently earning the highest ratings of any basic cable program. Subsequent ratings have varied but it remains one of Comedy Central's highest rated shows, and is slated to air through at least 2016. The pilot episode was produced using cutout animation. All subsequent episodes are created with software that emulates the cutout technique. Parker and Stone perform most of the voice acting. Since 2000, each episode is typically written and produced during the week preceding its broadcast, with Parker serving as the primary writer and director. There have been a total of 257 episodes over the course of the show's 18 seasons.
The series has received numerous accolades, including five Primetime Emmy Awards, a Peabody Award, and numerous inclusions in various publications' lists of greatest television shows. The show's popularity resulted in a feature-length theatrical film, "" which was released in June 1999, less than two years after the show's premiere, and became a commercial and critical success. In 2013, "TV Guide" ranked "South Park" the tenth Greatest TV Cartoon of All Time. "South Park" is the third longest-running animated series in the U.S. behind "The Simpsons" and "Arthur".
Premise.
Setting and characters.
The show follows the exploits of four boys, Stan Marsh, Kyle Broflovski, Eric Cartman and Kenny McCormick. The boys live in the fictional small town of South Park, located within the real life South Park basin in the Rocky Mountains of central Colorado. The town is also home to an assortment of frequent characters such as students, families, elementary school staff, and other various residents, who tend to regard South Park as a bland and quiet place to live. Prominent settings on the show include the local elementary school, bus stop, various neighborhoods and the surrounding snowy landscape, actual Colorado landmarks, and the shops and businesses along the town's main street, all of which are based on the appearance of similar locations in the town of Fairplay, Colorado.
Stan is portrayed as the everyman of the group, as the show's official website describes him as an "average, American 4th grader". Kyle is the lone Jew among the group, and his portrayal in this role is often dealt with satirically. Stan is modeled after Parker, while Kyle is modeled after Stone. Stan and Kyle are best friends, and their relationship, which is intended to reflect the real life friendship between Parker and Stone, is a common topic throughout the series. Eric Cartman (usually referred to by his surname only)—is a loud, obnoxious, manipulative, racist and obese literal psychopath—is often portrayed as an antagonist whose anti-Semitic attitude has resulted in an ever-progressing rivalry with Kyle, although the deeper reason for the antagonistic relationship is the strong clash between Kyle's strong morality, and Cartman's complete lack of such. Kenny, who comes from a poor family, wears his parka hood so tightly that it covers most of his face and muffles his speech. During the show's first five seasons, Kenny would die in nearly every episode before returning in the next with little or no definitive explanation given. He was written out of the show's sixth season in 2002, re-appearing in the season finale. Since then, the practice of killing Kenny has been seldom used by the show's creators. During the show's first 58 episodes, the boys were in the third grade. In the season four episode "4th Grade" (2000), they entered the fourth grade, where they have remained ever since.
Plots are often set in motion by events, ranging from the fairly typical to the supernatural and extraordinary, which frequently happen in the town. The boys often act as the voice of reason when these events cause panic or incongruous behavior among the adult populace, who are customarily depicted as irrational, gullible, and prone to vociferation. The boys are also frequently confused by the contradictory and hypocritical behavior of their parents and other adults, and often perceive them as having distorted views on morality and society.
Themes and style.
Each episode opens with a tongue-in-cheek disclaimer: "All characters and events in this show—even those based on real people—are entirely fictional. All celebrity voices are impersonated...poorly. The following program contains coarse language and due to its content it should not be viewed by anyone."
"South Park" was the first weekly program to be assigned the TV-MA rating, and is generally intended for adult audiences. The boys and most other child characters use strong profanity, with only the most taboo words being bleeped by censors during a typical broadcast. The use of such language serves as a means for Parker and Stone to display how they claim young boys really talk when they are alone.
"South Park" commonly makes use of carnivalesque and absurdist techniques, numerous running gags, violence, sexual content, offhand pop-cultural references, and satirical portrayal of celebrities.
Early episodes tended to be shock value-oriented and featured more slapstick-style humor. While social satire had been used on the show occasionally earlier on, it became more prevalent as the series progressed, with the show retaining some of its focus on the boys' fondness of scatological humor in an attempt to remind adult viewers "what it was like to be eight years old." Parker and Stone also began further developing other characters by giving them larger roles in certain storylines, and began writing plots as parables based on religion, politics, and numerous other topics. This provided the opportunity for the show to spoof both extreme sides of contentious issues, while lampooning both liberal and conservative points of view. Parker and Stone describe themselves as "equal opportunity offenders", whose main agenda is to "be funny" and "make people laugh," while stating that no particular topic or group of people be spared the expense of being subject to mockery and satire.
Parker and Stone insist that the show is still more about "kids being kids" and "what it's like to be in [elementary school] in America," stating that the introduction of a more satirical element to the series was the result of the two adding more of a "moral center" to the show so that it would rely less on simply being crude and shocking in an attempt to maintain an audience. While profane, and with a tendency to sometimes be cynical, Parker notes that there is still an "underlying sweetness" aspect to the child characters, and "Time" described the boys as "sometimes cruel but with a core of innocence." Usually, the boys and/or other characters ponder over what has transpired during an episode and convey the important lesson taken from it with a short monologue. During earlier seasons, this speech would commonly begin with a variation of the phrase "You know, I've learned something today...".
Origins and creation.
Soon after meeting in film class at the University of Colorado in 1992, Parker and Stone created an animated short entitled "The Spirit of Christmas". The film was created by animating construction paper cutouts with stop motion, and features prototypes of the main characters of "South Park", including a character resembling Cartman but named "Kenny", an unnamed character resembling what is today Kenny, and two near-identical unnamed characters who resemble Stan and Kyle. Brian Graden, Fox network executive and mutual friend, commissioned Parker and Stone to create a second short film as a video Christmas card. Created in 1995, the second "The Spirit of Christmas" short resembled the style of the later series more closely. To differentiate between the two homonymous shorts, the first short is often referred to as "Jesus vs. Frosty", and the second short as "Jesus vs. Santa." Graden sent copies of the video to several of his friends, and from there it was copied and distributed, including on the internet, where it became one of the first viral videos.
As "Jesus vs. Santa" became more popular, Parker and Stone began talks of developing the short into a television series. Fox refused to pick up the series, not wanting to air a show that included the character Mr. Hankey, a talking piece of feces. The two then entered negotiations with both MTV and Comedy Central. Parker preferred the show be produced by Comedy Central, fearing that MTV would turn it into a kids show. When Comedy Central executive Doug Herzog watched the short, he commissioned for it to be developed into a series.
Through producer David Niles White in August, 1996, Parker and Stone hired animator and computer graphics expert Terrence Masson to create a 10-second test using Alias Software on an SGI computer to match footage from the traditionally produced pilot. This sold everyone on the "computer graphics technique that looked like construction paper" and could therefore be produced in a reasonable timeframe for television production.
Parker and Stone assembled a small staff and spent three months creating the pilot episode "Cartman Gets an Anal Probe". "South Park" was in danger of being canceled before it even aired when the show fared poorly with test audiences, particularly with women. However, the shorts were still gaining more popularity over the Internet, and Comedy Central agreed to order a run of six episodes. "South Park" debuted with "Cartman Gets an Anal Probe" on August 13, 1997.
Production.
Except for the pilot episode, which was produced using cutout animation, all episodes of "South Park" are created with the use of software. As opposed to the pilot, which took three months to complete, and other animated sitcoms, which are traditionally hand-drawn by companies in South Korea in a process that takes roughly eight-to-nine months, individual episodes of "South Park" take significantly less time to produce. Using computers as an animation method, the show's production staff were able to generate an episode in about three weeks during the first seasons. Now, with a staff of about 70 people, episodes are typically completed in one week, with some in as little as three to four days. Nearly the entire production of an episode is accomplished within one set of offices, which were originally at a complex in Westwood, Los Angeles, California, and are now part of South Park Studios in Culver City, California. Parker and Stone have been the show's executive producers throughout its entire history, while Anne Garefino has served as "South Park"'s co-executive producer since the latter part of the first season. 20th Century Fox Senior Production Executive Debbie Liebling also served as an executive producer during the show's first five seasons, coordinating the show's production efforts between South Park Studios and Comedy Central's headquarters in New York City.
Scripts are not written before a season begins. Production of an episode begins on a Thursday, with the show's writing consultants brainstorming with Parker and Stone. Former staff writers include Pam Brady, who has since written scripts for the films "Hot Rod" and "Hamlet 2", and Nancy Pimental, who served as co-host of "Win Ben Stein's Money" and wrote the film "The Sweetest Thing" after her tenure with the show during its first three seasons. Television producer and writer Norman Lear, an idol of both Parker and Stone, served as a guest writing consultant for the season seven (2003) episodes "Cancelled" and "I'm a Little Bit Country". During the 12th and 13th seasons, "Saturday Night Live" actor and writer Bill Hader served as a creative consultant and co-producer.
After exchanging ideas, Parker will write a script, and from there the entire team of animators, editors, technicians, and sound engineers will each typically work 100–120 hours in the ensuing week. Since the show's fourth season (2000), Parker has assumed most of the show's directorial duties, while Stone relinquished his share of the directing to focus on handling the coordination and business aspects of the production. On Wednesday, a completed episode is sent to Comedy Central's headquarters via satellite uplink, sometimes in just a few hours before its air time of 10 PM Eastern Time.
Parker and Stone state that subjecting themselves to a one-week deadline creates more spontaneity amongst themselves in the creative process, which they feel results in a funnier show. The schedule also allows "South Park" to both stay more topical and respond more quickly to specific current events than other satiric animated shows. One of the earliest examples of this was in the season four (2000) episode "Quintuplets 2000", which references the United States Border Patrol's raid of a house during the Elian Gonzalez affair, an event which occurred only four days before the episode originally aired. The season nine (2005) episode "Best Friends Forever" references the Terri Schiavo case, and originally aired in the midst of the controversy and less than 12 hours before she died. A scene in the season seven (2003) finale "It's Christmas in Canada" references the discovery of dictator Saddam Hussein in a "spider hole" and his subsequent capture, which happened a mere three days prior to the episode airing. The season 12 (2008) episode "About Last Night..." revolves around Barack Obama's victory in the 2008 presidential election, and aired less than 24 hours after Obama was declared the winner, using segments of dialogue from Obama's real victory speech.
On October 16, 2013, the show failed to meet their production deadline for the first time ever, after a power outage on October 15 at the production studio prevented the episode, season 17's "", from being finished in time. The episode was rescheduled to air a week later on October 23, 2013.
Animation.
The show's style of animation is inspired by the paper cut-out cartoons made by Terry Gilliam for "Monty Python's Flying Circus", of which Parker and Stone have been lifelong fans. Construction paper and traditional stop motion cutout animation techniques were used in the original animated shorts and in the pilot episode. Subsequent episodes have been produced by computer animation, providing a similar look to the originals while requiring a fraction of the time to produce. Before computer artists begin animating an episode, a series of animatics drawn in Toon Boom are provided by the show's storyboard artists.
The characters and objects are composed of simple geometrical shapes and primary colors. Most child characters are the same size and shape, and are distinguished by their clothing and headwear. Characters are mostly presented two-dimensionally and from only one angle. Their movements are animated in an intentionally jerky fashion, as they are purposely not offered the same free range of motion associated with hand-drawn characters. Occasionally, some non-fictional characters are depicted with photographic cutouts of their actual head and face in lieu of a face reminiscent of the show's traditional style. Canadians on the show are often portrayed in an even more minimalist fashion; they have simple beady eyes, and the top halves of their heads simply flap up and down when the characters speak.
When the show began using computers, the cardboard cutouts were scanned and re-drawn with CorelDRAW, then imported into PowerAnimator, which was used with SGI workstations to animate the characters. The workstations were linked to a 54-processor render farm that could render 10 to 15 shots an hour. Beginning with season five, the animators began using Maya instead of PowerAnimator. The studio now runs a 120-processor render farm that can produce 30 or more shots an hour.
PowerAnimator and Maya are high-end programs mainly used for 3D computer graphics, while co-producer and former animation director Eric Stough notes that PowerAnimator was initially chosen because its features helped animators retain the show's "homemade" look. PowerAnimator was also used for making some of the show's visual effects, which are now created using Motion, a newer graphics program created by Apple, Inc. for their Mac OS X operating system. The show's visual quality has improved in recent seasons, though several other techniques are used to intentionally preserve the cheap cutout animation look.
A few episodes feature sections of live-action footage, while others have incorporated other styles of animation. Portions of the season eight (2004) premiere "Good Times with Weapons" are done in anime style, while the season 10 episode "Make Love, Not Warcraft" is done partly in machinima. The season 12 episode "Major Boobage", a homage to the 1981 animated film "Heavy Metal", implements scenes accomplished with rotoscoping.
Voice cast.
Parker and Stone voice most of the male "South Park" characters. Mary Kay Bergman voiced the majority of the female characters until her suicide on November 11, 1999. Mona Marshall and Eliza Schneider succeeded Bergman, with Schneider leaving the show after its seventh season (2003). She was replaced by April Stewart, who, along with Marshall, continues to voice most of the female characters. Bergman was originally listed in the credits under the alias Shannen Cassidy to protect her reputation as the voice of several Disney and other kid-friendly characters. Stewart was originally credited under the name Gracie Lazar, while Schneider was sometimes credited under her rock opera performance pseudonym Blue Girl.
Other voice actors and members of "South Park"'s production staff have voiced minor characters for various episodes, while a few staff members voice recurring characters; supervising producer Jennifer Howell voices student Bebe Stevens, co-producer and storyboard artist Adrien Beard voices the school's only black student, Token Black, writing consultant Vernon Chatman voices an anthropomorphic towel named Towelie, and production supervisor John Hansen voices Mr. Slave, the former gay lover of Mr. Garrison. Throughout the show's run, the voices for toddler and kindergarten characters have been provided by various small children of the show's production staff.
When voicing child characters, the voice actors speak within their normal vocal range while adding a childlike inflection. The recorded audio is then edited with Pro Tools, and the pitch is altered to make the voice sound more like that of a fourth grader.
Isaac Hayes voiced the character of Chef, a black, soul-singing cafeteria worker who was one of the few adults the boys consistently trusted. Hayes agreed to voice the character after being among Parker and Stone's ideal candidates which also included Lou Rawls and Barry White. Hayes, who lived and hosted a radio show in New York during his tenure with "South Park", would record his dialogue on a digital audio tape while a respective episode's director would give directions over the phone, then the tape would be shipped to the show's production studio in California. After Hayes left the show in early 2006, the character of Chef was killed off in the season 10 (2006) premiere "The Return of Chef".
Guest stars.
Celebrities who are depicted on the show are usually impersonated, though some celebrities do their own voices for the show. Celebrities who have voiced themselves include Michael Buffer, Brent Musburger, Jay Leno, Robert Smith, and the bands Radiohead and Korn.
Comedy team Cheech & Chong voiced characters representing their likenesses for the season four (2000) episode "Cherokee Hair Tampons", which was the duo's first collaborative effort in 20 years. Malcolm McDowell appears in live-action sequences as the narrator of the season four episode "Pip".
Jennifer Aniston, Richard Belzer,
Natasha Henstridge, Norman Lear, and Peter Serafinowicz have guest starred as other speaking characters. During "South Park"'s earliest seasons, several high-profile celebrities inquired about guest-starring on the show. As a joke, Parker and Stone responded by offering low-profile, non-speaking roles, most of which were accepted; George Clooney provided the barks for Stan's dog Sparky in the season one (1997) episode "Big Gay Al's Big Gay Boat Ride", Leno provided the meows for Cartman's cat in the season one finale "Cartman's Mom Is a Dirty Slut", and Henry Winkler voiced the various growls and grunts of a kid-eating monster in the season two (1998) episode "City on the Edge of Forever". Jerry Seinfeld offered to lend his voice for the Thanksgiving episode "Starvin' Marvin", but declined to appear when he was only offered a role as "Turkey #2".
Music.
Parker says that the varying uses of music is of utmost importance to "South Park". Several characters often play or sing songs in order to change or influence a group's behavior, or to educate, motivate, or indoctrinate others. The show also frequently features scenes in which its characters have disapproving reactions to the performances of certain popular musicians.
Adam Berry, the show's original score composer, used sound synthesis to simulate a small orchestra, and frequently alluded to existing famous pieces of music. Berry also used signature acoustic guitar and mandolin cues as leitmotifs for the show's establishing shots. After Berry left in 2001, Jamie Dunlap and Scott Nickoley of the Los Angeles-based Mad City Production Studios provided the show's original music for the next seven seasons. Since 2008, Dunlap has been credited as the show's sole score composer. Dunlap's contributions to the show are one of the few that are not achieved at the show's own production offices. Dunlap reads a script, creates a score using digital audio software, and then e-mails the audio file to South Park Studios, where it is edited to fit with the completed episode.
In addition to singing in an effort to explain something to the children, Chef would also sing about things relevant to what had transpired in the plot. These songs were original compositions written by Parker, and performed by Hayes in the same sexually suggestive R&B style he had utilized during his own music career. The band DVDA, which consists of Parker and Stone, along with show staff members Bruce Howell and D.A. Young, would perform the music for these compositions, and, until the character's death on the show, were listed as "Chef's Band" in the closing credits.
Rick James, Elton John, Meat Loaf, Joe Strummer, Ozzy Osbourne, Primus, Rancid, and Ween all guest starred and briefly performed in the season two (1998) episode "Chef Aid". Korn debuted their single "Falling Away from Me" as guest stars on the season three (1999) episode "Korn's Groovy Pirate Ghost Mystery".
Title sequence.
The show's original theme song was a musical score performed by the band Primus, while the lyrics are alternately sung by the band's lead singer, Les Claypool, and the show's four central characters. Kenny's muffled lines are altered after every few seasons. The original composition was originally slower but was sped up for the show, while an instrumental version of the original composition is often played during the show's closing credits. The song's melody is similar to the song "Coddingtown", on Primus's "Brown Album". The opening theme song has been remixed three times during the course of the series, including a remix performed by Paul Robb. In 2006, the theme music was remixed with the song "Whamola" by Colonel Les Claypool's Fearless Flying Frog Brigade, from the album "Purple Onion".
Distribution.
International.
Internationally, "South Park" is broadcast in India, New Zealand, and several countries throughout Europe and Latin America on channels that are divisions of Comedy Central and MTV Networks, both subsidiaries of Viacom. In distribution deals with Comedy Central, other independent networks also broadcast the series in other international markets. In Australia, the show is broadcast on The Comedy Channel, SBS One (Season 1–13 edited and 14–15 Uncut) & SBS2 (Season 16 Uncut). The series is broadcast uncensored in Canada in English on The Comedy Network and, later, MuchMusic "South Park" also airs on TG4 in Ireland, STV in Scotland, Comedy Central, MTV and Viva in the UK (previously on Channel 4) and B92 in Serbia.
Syndication.
Broadcast syndication rights to "South Park" were acquired by Debmar-Mercury and Tribune Entertainment in 2003 and 2004 respectively. Episodes further edited for content began running in syndication on September 19, 2005, and are aired in the United States with the TV-14 rating. 20th Television replaced Tribune as co-distributor in early 2008. The series is currently aired in syndication in 90 percent of the television markets across the U.S. and Canada, where it generates an estimated US$25 million a year in advertising revenue.
Home media.
The first seventeen seasons of "South Park" are available in their entirety on DVD. Several other themed DVD compilations have been released by Rhino Entertainment and Comedy Central, while the three-episode "" story arc was reissued straight-to-DVD as a full-length feature in 2008.
Streaming.
In March 2008, Comedy Central made every episode of "South Park" available for free full-length on-demand legal streaming on the official South Park Studios website. From March 2008 until December 2013 new episodes were added to the site the day following their debut, and an uncensored version was posted the following day. The episode stayed up for the remainder of the week, then taken down, and added to the site three weeks later.
Within a week, the site served more than a million streams of full episodes, and the number grew to 55 million by October 2008. Legal issues prevent the U.S. content from being accessible outside the U.S., so local servers have been set up in other countries. In September 2009, a South Park Studios website with streaming episodes was launched in the UK. In Canada, episodes were available for streaming from The Comedy Network's website, though due to digital rights restrictions, they are no longer available.
In July 2014 it was announced that Hulu had signed a three-year deal purchasing exclusive online streaming rights to the "South Park" for a reported 80 million dollars. Following the announcement every episode remained available for free on the South Park Studios website, using the Hulu player. As of September 2014, following the premiere of the eighteenth season, only 30 select episodes are featured for free viewing at a time on a rationing basis on the website, with new episodes being available for an entire month starting the day following their original airings. The entire series will be available for viewing on Hulu Plus.
In April 2010 the season five episode "Super Best Friends" and the season fourteen episodes "200", and "201" (which all depict the Muslim prophet Muhammad) were removed from the site, additionally these episodes no longer air in reruns and are only available exclusively on DVD. These episodes remain unavailable following the 2014 purchase by Hulu.
Re-rendered episodes.
From its debut in 1997 until the season twelve finale in 2008 the series had been natively produced in 480i standard definition. In 2009 the series switched to being natively produced in 1080i high definition with the beginning of the thirteenth season.
All seasons originally produced in standard definition have been remastered by being completely re-rendered scene-by-scene and frame-by-frame by South Park Studios from their original resolution to full 1080i high definition, additionally the original 4:3 aspect ratio has been converted to 16:9 as well. The re-rendering process took South Park Studios several years, and resulted in the picture quality in true HD as opposed to being up-converted. Additionally, the re-rendered episodes from the earlier seasons also feature their original uncensored audio tracks, which have never been released to the public uncensored prior.
Reception.
Ratings.
When "South Park" debuted, it was a huge ratings success for Comedy Central and is seen as being largely responsible for the success of the channel, with Herzog crediting it for putting the network "on the map".
The show's first episode, "Cartman Gets an Anal Probe", earned a Nielsen rating of 1.3 (980,000 viewers), at the time considered high for a cable program. The show instantly generated buzz among television viewers, and mass viewing parties began assembling on college campuses. By the time the eighth episode "Starvin' Marvin" aired three months after the show debuted, ratings and viewership had tripled, and "South Park" was already the most successful show in Comedy Central's history. When the tenth episode "Damien" aired the following February, viewership increased another 33 percent. The episode earned a 6.4 rating, which at the time was over 10 times the average rating earned by a cable show aired in prime time. The ratings peaked with the second episode of season two, "Cartman's Mom Is Still a Dirty Slut", which aired on April 22, 1998. The episode earned an 8.2 rating (6.2 million viewers) and, at the time, set a record as the highest-rated non-sports show in basic cable history. During the spring of 1998, eight of the ten highest-rated shows on basic cable were "South Park" episodes.
The success of "South Park" prompted more cable companies to carry Comedy Central and led it to its becoming one of the fastest-growing cable channels. The number of households that had Comedy Central jumped from 9.1 million in 1997 to 50 million in June 1998. When the show debuted, the most Comedy Central had earned for a 30-second commercial was US$7,500. Within a year, advertisers were paying an average of US$40,000 for 30 seconds of advertising time during airings of "South Park" in its second season, while some paid as much as US$80,000.
By the third season (1999), the series' ratings began to decrease. The third season premiere episode drew 3.4 million viewers, a dramatic drop from the 5.5 million of the previous season's premiere. Stone and Parker attributed this drop in the show's ratings to the media hype that surrounded the show in the previous year, adding that the third season ratings reflected the show's "true" fan base. The show's ratings dropped further in its fourth season (2000), with episodes averaging just above 1.5 million viewers. The ratings eventually increased, and seasons five through nine consistently averaged about 3 million viewers per episode. Though its viewership is lower than it was at the height of its popularity in its earliest seasons, "South Park" remains one of the highest-rated series on Comedy Central. The season 14 (2010) premiere gained 3.7 million viewers, the show's highest-rated season premiere since 1998.
Recognitions and awards.
In 2004, Channel 4 voted "South Park" the third-greatest cartoon of all time. In 2007, "Time" magazine included the show on its list of the "100 Best TV Shows of All Time", proclaiming it as "America's best source of rapid-fire satire for [the past] decade". The same year, "Rolling Stone" declared it to be the funniest show on television since its debut 10 years prior. In 2008, "South Park" was named the 12th-greatest TV show of the past 25 years by "Entertainment Weekly", while AOL declared it as having the "most astute" characters of any show in history when naming it the 16th-best television comedy series of all time. In 2011, "South Park" was voted number one in the "25 Greatest Animated TV Series" poll by "Entertainment Weekly". The character of Cartman ranked 10th on TV Guide's 2002 list of the "Top 50 Greatest Cartoon Characters", 198th on VH1's "200 Greatest Pop Culture Icons", 19th on Bravo's "100 Greatest TV Characters" television special in 2004, and second on MSNBC's 2005 list of TV's scariest characters behind Mr. Burns from "The Simpsons". In 2006, Comedy Central received a Peabody Award for "South Park"'s "stringent social commentary" and "undeniably fearless lampooning of all that is self-important and hypocritical in American life". In 2013, the Writers Guild of America ranked "South Park" at number 63 among the "101 Best-Written Shows Ever". Also in 2013, TV Guide listed the show at number 10 among the "60 Greatest Cartoons of All Time".
"South Park" won the CableACE Award for Best Animated Series in 1997, the last year the awards were given out. In 1998, "South Park" was nominated for the Annie Award for Outstanding Achievement in an Animated Primetime or Late Night Television Program. It was also nominated for the 1998 GLAAD Award for Outstanding TV – Individual Episode for "Big Gay Al's Big Gay Boat Ride".
"South Park" has been nominated for the Emmy Award for Outstanding Animated Program ten times (1998, 2000, 2002, 2004, 2005, 2006, 2007, 2009, 2010 and 2013). The show has won the award for Outstanding Animated Program (For Programming Less Than One Hour) four times, for the 2005 episode "Best Friends Forever", the 2006 episode "Make Love, Not Warcraft", the 2009 episode "Margaritaville", and the 2012 episode "Raising the Bar". The Imaginationland trilogy of episodes won the Emmy Award for Outstanding Animated Program (For Programming One Hour Or More) in 2008.
Criticism and controversy.
The show's frequent depiction of taboo subject matter, general toilet humor, accessibility to younger viewers, disregard for conservative sensibilities, negative depiction of liberal causes, and portrayal of religion for comic effect have been the main sources for generating controversy and debate over the course of its run. As the series first became popular, students in several schools were barred from wearing "South Park"-related T-shirts, while several parent councils in the United Kingdom expressed concern when eight- and nine-year-old children voted the "South Park" character Cartman as their favorite personality in a 1999 poll. Parker and Stone assert that the show is not meant to be viewed by young children, and the show is certified with TV ratings that indicate its intention for mature audiences.
Parents Television Council founder L. Brent Bozell III and Action for Children's Television founder Peggy Charren have both condemned the show, with the latter claiming it is "dangerous to the democracy". Several other activist groups have protested the show's parodies of Christianity and portrayal of Jesus Christ. Stone claims that parents who disapprove of "South Park" for its portrayal of how kids behave are upset because they "have an idyllic vision of what kids are like", adding "[kids] don't have any kind of social tact or etiquette, they're just complete little raging bastards".
The show further lampooned the controversy surrounding its use of profanity, as well as the media attention surrounding the network show "Chicago Hope"'s singular use of the word "shit", with the season five premiere "It Hits the Fan", in which the word "shit" is said 162 times without being bleeped for censorship purposes, while also appearing uncensored in written form. In the days following the show's original airing, 5,000 disapproving e-mails were sent to Comedy Central. Despite its 43 uncensored uses of the racial slur "nigger", the season 11 episode "With Apologies to Jesse Jackson" generated relatively little controversy, as most in the black community and the NAACP praised the episode for its context and its comedic way of conveying other races' perceptions of how black people must feel when hearing the word.
Specific controversies regarding the show have included an April Fools' Day prank played on its viewers in 1998, its depiction of the Virgin Mary in the season nine (2005) finale "Bloody Mary" which angered several Catholics, its depiction of Steve Irwin with a stingray barb stuck in his chest in the episode "Hell on Earth 2006", which originally aired less than two months after Irwin was killed in the same fashion, and Comedy Central's censorship of the depiction of Muhammad in the season 10 episode "Cartoon Wars Part II" in the wake of the Jyllands-Posten Muhammad cartoons controversy.
The season nine (2005) episode "Trapped in the Closet" denounces Scientology as nothing more than "a big fat global scam", while freely divulging church information that Scientology normally only reveals to members who make significant monetary contributions to the church. The episode also ambiguously parodies the rumors involving the sexual orientation of Scientologist Tom Cruise, who allegedly demanded any further reruns of the episode be canceled. Isaac Hayes, a Scientologist, later quit "South Park" because of his objection to the episode.
The season fourteen episodes "200" and "201" were mired in controversy for satirizing issues surrounding the depiction of the Islamic prophet, Muhammad. The website for the organization Revolution Muslim, a New York-based radical Muslim organization, posted an entry that included a warning to creators Parker and Stone that they risk violent retribution for their depictions of Muhammad. It said that they "will probably wind up like Theo van Gogh for airing this show." The posting provided the addresses to Comedy Central in New York and the production company in Los Angeles. The author of the post, Zachary Adam Chesser (who prefers to be called Abu Talhah al Amrikee), said it was meant to serve as a warning to Parker and Stone, not a threat, and that providing the addresses was meant to give people the opportunity to protest. Despite al Amrikee's claims that the website entry was a warning, several media outlets and observers interpreted it as a threat. Support for the episode has come in the form of Everybody Draw Mohammed Day!, a movement started on Facebook that encourages people to draw Muhammad on May 20. The 200 episode, which also depicted the Buddha snorting cocaine, prompted the government of Sri Lanka to ban the series outright.
Influence.
Cultural.
Commentary made in episodes have been interpreted as statements Parker and Stone are attempting to make to the viewing public, and these opinions have been subject to much critical analysis in the media and literary world within the framework of popular philosophical, theological, social, and political concepts. Since "South Park" debuted, college students have written term papers and doctoral theses analyzing the show, while Brooklyn College offers a course called ""South Park" and Political Correctness".
Soon after one of Kenny's trademark deaths on the show, other characters would typically shout "Oh my God, they killed Kenny!". The exclamation quickly became a popular catchphrase, while the running gag of Kenny's recurring deaths are one of the more recognized hallmarks among viewers of modern television. Cartman's exclamations of "Respect my authori-tah!" and "Screw you guys ...I'm going home!" became catchphrases as well, and during the show's earlier seasons, were highly popular in the lexicon of viewers. Cartman's eccentric intonation of "Hey!" was included in the 2002 edition of "The Oxford Dictionary of Catchphrases".
In the season two episode "Chef Aid", attorney Johnnie Cochran uses what's called in the show the Chewbacca defense, which is a legal strategy that involves addressing plot holes related to Chewbacca in the film "" rather than discussing the trial at hand during a closing argument in a deliberate attempt to confuse jurors into thinking there is reasonable doubt. The term "Chewbacca defense" has been documented as being used by criminologists, forensic scientists, and political commentators in their various discussions of similar methods used in legal cases and public forums.
Another season two episode, "Gnomes", revolves around a group of "underpants gnomes" who, as their name suggests, run a corporation stealing people's underpants. When asked about their business model, various gnomes reply that theirs is a three-step process: Phase 1 is "collect underpants". Phase 3 is "profit". However, the gnomes are unable to explain what is to occur between the first and final steps, and "Phase 2" is accompanied by a large question mark on their corporate flow chart. Using "????" and "PROFIT!" as the last two steps in a process (usually jokingly) has become a widely popular Internet meme because of this. Especially in the context of politics and economics, "underpants gnomes" has been used by some commentators to characterize a conspicuous gap of logic or planning.
When Sophie Rutschmann of the University of Strasbourg discovered a mutated gene that causes an adult fruit fly to die within two days after it is infected with certain bacteria, she named the gene "kep1" in honor of Kenny.
Political.
While some conservatives have condemned the show for its vulgarity, a growing population of people who hold center-right political beliefs, including teenagers and young adults, have embraced the show for its tendency to mock liberal viewpoints and lampoon liberal celebrities and icons. Political commentator Andrew Sullivan dubbed the group "South Park" Republicans, or "South Park" conservatives. Sullivan classified the group as "extremely skeptical of political correctness but also are socially liberal on many issues," though he says the phrase applied to them is meant to be more of a casual indication of beliefs than a strong partisan label. Brian C. Anderson describes the group as "generally characterized by holding strong libertarian beliefs and rejecting more conservative social policy," and notes that although the show makes "wicked fun of conservatives," it is "at the forefront of a conservative revolt against liberal media."
Parker and Stone downplay the show's alignment with any particular political affiliation, and deny having a political agenda when creating an episode.
The two claim the show's higher ratio of instances lampooning liberal orthodoxies stems simply from their preference to make fun of liberals more than conservatives. While Stone has been quoted saying, "I hate conservatives, but I really fucking hate liberals," Stone and Parker have explained that their drive to lampoon a given target comes first from the target's insistence on telling other people how to behave. The duo explains that they perceive liberals as having both delusions of entitlement to remain free from satire, and a propensity to enforce political correctness while patronizing the citizens of Middle America. Parker and Stone are uncomfortable with the idea of themselves or "South Park" being applied with any kind of partisan classification. Parker said he rejects the ""South Park" Republican" and ""South Park" conservative" labels as a serious notion, feeling that either tag implies that one only adheres to strictly conservative or liberal viewpoints. Canadian columnist Jaime J. Weinman observes that the most die-hard conservatives who identified themselves as ""South Park" Republicans" began turning away from the label when the show ridiculed Republicans in the season nine (2005) episode "Best Friends Forever."
Film.
In 1999, less than two years after the series first aired, a was released. The film, a musical comedy, was directed by Parker, who co-wrote the script with Stone and Pam Brady. The film was generally well received by critics, and earned a combined US$83.1 million at the domestic and foreign box office. The film satirizes the controversy surrounding the show itself and gained a spot in the 2001 edition of "Guinness World Records" for "Most Swearing in an Animated Film". The song "Blame Canada" from earned song co-writers Parker and Marc Shaiman an Academy Award nomination for Best Music, Original Song.
Parker and Stone said in a 2008 interview that a theatrically released sequel would most likely be what concludes the series. In 2011, when asked on the official "South Park" website whether a sequel would be made, they said "the first "South Park" movie was so potent, we're all still recovering from the blow. Unfortunately, at the current moment, there are no plans for a second "South Park" movie. But you never know what the future may bring, crazier things have happened..." In 2011, "Time" called "South Park: Bigger, Longer & Uncut" the sixth greatest animated feature of all-time. In 2013, Warner Bros. Entertainment relinquished to Paramount Pictures its rights to co-finance a potential future "South Park" film during their negotiations to co-finance the Christopher Nolan science fiction film "Interstellar". Previous efforts to create a second "South Park" film were complicated due to both studios retaining certain rights to the property.
Media and merchandise.
Shorts.
As a tribute to the Dead Parrot sketch, a short that features Cartman attempting to return a dead Kenny to a shop run by Kyle aired during a 1999 BBC television special commemorating the 30th anniversary of "Monty Python's Flying Circus". "South Park" parodied Scientology in a short that aired as part of the 2000 MTV Movie Awards. The short was entitled "The Gauntlet" and also poked fun at John Travolta, a Scientologist. The four main characters were featured in the documentary film "The Aristocrats", listening to Cartman tell his version of the film's titular joke. Short clips of Cartman introducing the starting lineup for the University of Colorado football team were featured during ABC's coverage of the 2007 matchup between the University of Colorado and the University of Nebraska. In 2008, Parker, as Cartman, gave answers to a Proust Questionnaire conducted by Julie Rovner of NPR. The Snakes & Arrows Tour for Rush in 2007 used an intro from Cartman, Stan, Kyle, and Kenny preceding "Tom Sawyer". As Parker, Stone and producer Frank Agnone are Los Angeles Kings fans, special "South Park" pre-game videos have been featured at Kings home games at Staples Center, and the club even sent the Stanley Cup to visit South Park Studios after winning the 2012 finals. Parker and Stone have also created Denver Nuggets-themed shorts, featuring Cartman, for home games at Pepsi Center.
Music.
"", a compilation of original songs from the show, characters performing cover songs, and tracks performed by guest artists was released in 1998, while "Mr. Hankey's Christmas Classics", a compilation of songs performed by the characters in the episode of the same name as well as other Christmas-themed songs was released in 1999, as was the to the feature film. The song "Chocolate Salty Balls" (performed by Hayes as Chef) was released as a single in the UK in 1998 to support the "Chef Aid: The South Park Album" and became a number one hit.
Video games.
Following the early success of the series, three video games based on the series were released by Acclaim Entertainment. A first-person shooter simply titled "South Park" was released in 1998 for the PC, Nintendo 64, and PlayStation. This was followed in 1999 by ', a party video game featuring quizzes and mini-games, on the Dreamcast, PlayStation, Nintendo 64, and PC. In 2000, "South Park Rally", a racing game, was released on the Dreamcast, PlayStation, Nintendo 64, and PC. Parker and Stone had little to do with the development of these games, apart from providing voice acting, and have publicly criticized Acclaim and the quality of the "South Park" games they produced. Several years after these early games, the decision was made to form a small group called South Park Digital Studios, which would, among other things, work on creating new "South Park" games, that would involve the studio and the show's creators more heavily. The first such title is "South Park Let's Go Tower Defense Play!", a tower defense game developed by Doublesix, which was released in 2009 for the Xbox Live Arcade service on the Xbox 360 console. Another Xbox Live Arcade game, ' is a platformer, which was released in the spring of 2012. "" is a role-playing video game that was written by Parker and Stone, and was originally scheduled to be released on March 5, 2013 for the Xbox 360 and PlayStation 3 consoles, and Microsoft Windows; The game released March 4, 2014 to positive reviews.
Merchandising.
Merchandising related to the show is an industry which generates several million dollars a year. In 1998, the top-selling specialty T-shirt in the United States was based on "South Park", and US$30 million in T-shirt sales was reached during the show's first season.
A "South Park" pinball machine was released in 1999 by Sega Pinball. The companies Fun 4 All, Mezco Toyz, and Mirage have produced various South Park action figures, collectibles, and plush dolls.
Comedy Central entered into an agreement with Frito-Lay to sell 1.5 million bags of Cheesy Poofs, Cartman's favorite snack from the show, at Wal-Mart until the premiere of the second half of the fifteenth season on October 5, 2011.
Further reading.
</dl>
External links.
 Quotations related to at Wikiquote
 Media related to at Wikimedia Commons

</doc>
<doc id="27978" url="http://en.wikipedia.org/wiki?curid=27978" title="Skin">
Skin

Skin is the soft outer covering of vertebrates. Other animal coverings such as the arthropod exoskeleton have different developmental origin, structure and chemical composition. The adjective cutaneous means "of the skin" (from Latin "cutis", skin). In mammals, the skin is an organ of the integumentary system made up of multiple layers of ectodermal tissue, and guards the underlying muscles, bones, ligaments and internal organs. Skin of a different nature exists in amphibians, reptiles, and birds. All mammals have some hair on their skin, even marine mammals which appear to be hairless.
The skin interfaces with the environment and is the first line of defense from external factors. For example, the skin plays a key role in protecting the body against pathogens and excessive water loss. Its other functions are insulation, temperature regulation, sensation, and the production of vitamin D folates. Severely damaged skin may heal by forming scar tissue. This is sometimes discoloured and depigmented. The thickness of skin also varies from location to location on an organism. In humans for example, the skin located under the eyes and around the eyelids is the thinnest skin in the body at 0.5 mm thick, and is one of the first areas to show signs of aging such as "crows feet" and wrinkles. The skin on the palms and the soles of the feet is 4 mm thick and the thickest skin in the body. The speed and quality of wound healing in skin is promoted by the reception of estrogen.
Fur is dense hair. Primarily, fur augments the insulation the skin provides but can also serve as a secondary sexual characteristic or as camouflage. On some animals, the skin is very hard and thick, and can be processed to create leather. Reptiles and fish have hard protective scales on their skin for protection, and birds have hard feathers, all made of tough β-keratins. Amphibian skin is not a strong barrier, especially regarding the passage of chemicals via skin and is often subject to osmosis and diffusive forces. For example, a frog sitting in an anesthetic solution would be sedated quickly, as the chemical diffuses through its skin. Amphibian skin plays key roles in everyday survival and their ability to exploit a wide range of habitats and ecological conditions.
Functions.
Skin performs the following functions:
Mammalian skin layers.
Mammalian skin is composed of two primary layers: 
Epidermis.
The epidermis is composed of the outermost layers of the skin. It forms a protective barrier over the body's surface, responsible for keeping water in the body and preventing pathogens from entering, and is a stratified squamous epithelium, composed of proliferating basal and differentiated suprabasal keratinocytes. The epidermis also helps the skin regulate body temperature.
Keratinocytes are the major cells, constituting 95% of the epidermis, while Merkel cells, melanocytes and Langerhans cells are also present. The epidermis can be further subdivided into the following "strata" or layers (beginning with the outermost layer):
Keratinocytes in the stratum basale proliferate through mitosis and the daughter cells move up the strata changing shape and composition as they undergo multiple stages of cell differentiation to eventually become anucleated. During that process, keratinocytes will become highly organized, forming cellular junctions (desmosomes) between each other and secreting keratin proteins and lipids which contribute to the formation of an extracellular matrix and provide mechanical strength to the skin. Keratinocytes from the stratum corneum are eventually shed from the surface (desquamation).
The epidermis contains no blood vessels, and cells in the deepest layers are nourished by diffusion from blood capillaries extending to the upper layers of the dermis.
Basement membrane.
The epidermis and dermis are separated by a thin sheet of fibers called the basement membrane, and is made through the action of both tissues.
The basement membrane controls the traffic of the cells and molecules between the dermis and epidermis but also serves, through the binding of a variety of cytokines and growth factors, as a reservoir for their controlled release during physiological remodeling or repair processes.
Dermis.
The dermis is the layer of skin beneath the epidermis that consists of connective tissue and cushions the body from stress and strain. 
The dermis provides tensile strength and elasticity to the skin through an extracellular matrix composed of collagen fibrils, microfibrils, and elastic fibers, embedded in proteoglycans.
It harbors many mechanoreceptors (nerve endings) that provide the sense of touch and heat. It also contains the hair follicles, sweat glands, sebaceous glands, apocrine glands, lymphatic vessels and blood vessels. The blood vessels in the dermis provide nourishment and waste removal from its own cells as well as for the epidermis.
The dermis is tightly connected to the epidermis through a basement membrane and is structurally divided into two areas: a superficial area adjacent to the epidermis, called the "papillary region", and a deep thicker area known as the "reticular region".
Papillary region.
The papillary region is composed of loose areolar connective tissue. This is named for its fingerlike projections called "papillae" that extend toward the epidermis. The papillae provide the dermis with a "bumpy" surface that interdigitates with the epidermis, strengthening the connection between the two layers of skin.
Reticular region.
The reticular region lies deep in the papillary region and is usually much thicker. It is composed of dense irregular connective tissue, and receives its name from the dense concentration of collagenous, elastic, and reticular fibers that weave throughout it. These protein fibers give the dermis its properties of strength, extensibility, and elasticity. 
Also located within the reticular region are the roots of the hair, sebaceous glands, sweat glands, receptors, nails, and blood vessels.
Hypodermis.
The hypodermis is not part of the skin, and lies below the dermis. Its purpose is to attach the skin to underlying bone and muscle as well as supplying it with blood vessels and nerves. It consists of loose connective tissue and elastin. The main cell types are fibroblasts, macrophages and adipocytes (the hypodermis contains 50% of body fat). Fat serves as padding and insulation for the body. Another name for the hypodermis is the subcutaneous tissue.
Microorganisms like "Staphylococcus epidermidis" colonize the skin surface. The density of skin flora depends on region of the skin. The disinfected skin surface gets recolonized from bacteria residing in the deeper areas of the hair follicle, gut and urogenital openings.
Fish and amphibians.
The epidermis of fish and of most amphibians consists entirely of live cells, with only minimal quantities of keratin in the cells of the superficial layer. It is generally permeable, and in the case of many amphibians, may actually be a major respiratory organ. The dermis of bony fish typically contains relatively little of the connective tissue found in tetrapods. Instead, in most species, it is largely replaced by solid, protective bony scales. Apart from some particularly large dermal bones that form parts of the skull, these scales are lost in tetrapods, although many reptiles do have scales of a different kind, as do pangolins. Cartilaginous fish have numerous tooth-like denticles embedded in their skin, in place of true scales.
Sweat glands and sebaceous glands are both unique to mammals, but other types of skin gland are found in other vertebrates. Fish typically have a numerous individual mucus-secreting skin cells that aid in insulation and protection, but may also have poison glands, photophores, or cells that produce a more watery, serous fluid. In amphibians, the mucus cells are gathered together to form sac-like glands. Most living amphibians also possess "granular glands" in the skin, that secrete irritating or toxic compounds.
Although melanin is found in the skin of many species, in the reptiles, the amphibians, and fish, the epidermis is often relatively colourless. Instead, the colour of the skin is largely due to chromatophores in the dermis, which, in addition to melanin, may contain guanine or carotenoid pigments. Many species, such as chameleons and flounders may be able to change the colour of their skin by adjusting the relative size of their chromatophores.
In birds and reptiles.
The epidermis of birds and reptiles is closer to that of mammals, with a layer of dead keratin-filled cells at the surface, to help reduce water loss. A similar pattern is also seen in some of the more terrestrial amphibians such as toads. However, in all of these animals there is no clear differentiation of the epidermis into distinct layers, as occurs in humans, with the change in cell type being relatively gradual. The mammalian epidermis always possesses at least a stratum germinativum and stratum corneum, but the other intermediate layers found in humans are not always distinguishable.
Hair is a distinctive feature of mammalian skin, while feathers are (at least among living species) similarly unique to birds.
Birds and reptiles have relatively few skin glands, although there may be a few structures for specific purposes, such as pheromone-secreting cells in some reptiles, or the uropygial gland of most birds.
Mechanics.
Skin has a soft tissue mechanical behavior when stretched. The intact skin is prestreched like wetsuits around the diver's body. When deep cuts are made on the skin, it retracts, widening the slice hole.
Human uses and culture.
The term "skin" may also refer to the covering of a small animal, such as a sheep, goat (goatskin), pig, snake (snakeskin) etc. or the young of a large animal.
The term hides or rawhide refers to the covering of a large adult animal such as a cow, buffalo, horse etc.
Skins and hides from the different animals are used for clothing, bags and other consumer products, usually in the form of leather, but also as furs.
Skin from sheep, goat and cattle was used to make parchment for manuscripts.
Skin can also be cooked to make pork rind or crackling.
Detailed cross section.
Skin layers, of both the hairy and hairless skin

</doc>
<doc id="27979" url="http://en.wikipedia.org/wiki?curid=27979" title="Sunlight">
Sunlight

Sunlight is a portion of the electromagnetic radiation given off by the Sun, in particular infrared, visible, and ultraviolet light. On Earth, sunlight is filtered through Earth's atmosphere, and is obvious as daylight when the Sun is above the horizon. When the direct solar radiation is not blocked by clouds, it is experienced as sunshine, a combination of bright light and radiant heat. When it is blocked by the clouds or reflects off other objects, it is experienced as diffused light. The World Meteorological Organization uses the term "sunshine duration" to mean the cumulative time during which an area receives direct irradiance from the Sun of at least 120 watts per square meter.
The ultraviolet radiation in sunlight has both positive and negative health effects, as it is both a principal source of vitamin D3 and a mutagen.
Summary.
Researchers may record sunlight using a sunshine recorder, pyranometer, or pyrheliometer.
Sunlight takes about 8.3 minutes to reach Earth from the surface of the Sun. A photon starting at the centre of the Sun and changing direction every time it encounters a charged particle would take between 10,000 and 170,000 years to get to the surface.
The total amount of energy received at ground level from the Sun at the zenith depends on the distance to the Sun and thus on the time of year. It is about 3.3% higher than average in January and 3.3% lower in July (see below). If the extraterrestrial solar radiation is 1367 watts per square meter (the value when the Earth–Sun distance is 1 astronomical unit), then the direct sunlight at Earth's surface when the Sun is at the zenith is about 1050 W/m2, but the total amount (direct and indirect from the atmosphere) hitting the ground is around 1120 W/m2. In terms of energy, sunlight at Earth's surface is around 52 to 55 percent infrared (above 700 nm), 42 to 43 percent visible (400 to 700 nm), and 3 to 5 percent ultraviolet (below 400 nm). At the top of the atmosphere, sunlight is about 30% more intense, having about 8% ultraviolet (UV), with most of the extra UV consisting of biologically damaging short-wave ultraviolet.
Direct sunlight has a luminous efficacy of about 93 lumens per watt of radiant flux, higher than most artificial lighting, including fluorescent. Multiplying the figure of 1050 watts per square metre by 93 lumens per watt indicates that bright sunlight provides an illuminance of approximately 98 000 lux (lumens per square meter) on a perpendicular surface at sea level. The illumination of a horizontal surface will be considerably less than this if the Sun is not very high in the sky. Averaged over a day, the highest amount of sunlight on a horizontal surface occurs in January at the South Pole (see insolation).
Sunlight is a key factor in photosynthesis, the process used by plants and other autotrophic organisms to convert light energy, normally from the Sun, into chemical energy that can be used to fuel the organisms' activities.
Composition and power.
The spectrum of the Sun's solar radiation is close to that of a black body with a temperature of about 5,800 K. The Sun emits EM radiation across most of the electromagnetic spectrum. Although the Sun produces Gamma rays as a result of the nuclear fusion process, these super-high-energy photons are converted by internal absorption and thermalization to lower-energy photons before they reach the Sun's surface and are emitted out into space. As a result, the Sun does not emit gamma rays from this process, but it does emit gamma rays from solar flares. The Sun does also emit X-rays, ultraviolet, visible light, infrared, and even radio waves; the only direct signature of the nuclear process is the emission of neutrinos.
Although the solar corona is a source of extreme ultraviolet and X-ray radiation, these rays make up only a very small amount of the power output of the Sun (see spectrum at right). The spectrum of nearly all solar electromagnetic radiation striking the Earth's atmosphere spans a range of 100 nm to about 1 mm (1,000,000 nm). This band of significant radiation power can be divided into five regions in increasing order of wavelengths:
Published tables.
Tables of direct solar radiation on various slopes from 0 to 60 degrees North Latitude, in calories per square centimetre, issued in 1972 and published by Pacific Northwest Forest and Range Experiment Station|Forest Service, U.S. Department of Agriculture, Portland, Oregon, USA, are available on the web.
Calculation.
To calculate the amount of sunlight reaching the ground, both Earth's elliptical orbit and the attenuation by Earth's atmosphere have to be taken into account. The extraterrestrial solar illuminance ("E"ext), corrected for the elliptical orbit by using the day number of the year (dn), is given to a good approximation by 
where dn=1 on January 1; dn=2 on January 2; dn=32 on February 1, etc. In this formula dn-3 is used, because in modern times Earth's perihelion, the closest approach to the Sun and, therefore, the maximum {{math|"E"ext}} occurs around January 3 each year. The value of 0.033412 is determined knowing that the ratio between the perihelion (0.98328989 AU) squared and the aphelion (1.01671033 AU) squared should be approximately 0.935338.
The solar illuminance constant ({{math|"E"sc}}), is equal to 128×103 lx. The direct normal illuminance ({{math|"E"dn}}), corrected for the attenuating effects of the atmosphere is given by:
where {{mvar|c}} is the atmospheric extinction and {{mvar|m}} is the relative optical airmass. The atmospheric extinction brings the number of lux down to around 100 000.
Solar constant.
The solar constant, a measure of flux density, is the amount of incoming solar electromagnetic radiation per unit area that would be incident on a plane perpendicular to the rays, at a distance of one astronomical unit (AU) (roughly the mean distance from the Sun to Earth). The "solar constant" includes all types of solar radiation, not just the visible light. Its average value was thought to be approximately 1.366 kW/m², varying slightly with solar activity, but recent recalibrations of the relevant satellite observations indicate a value closer to 1.361 kW/m² is more realistic.
Total (TSI) and spectral solar irradiance (SSI) upon Earth.
Total Solar Irradiance (TSI) – the amount of solar radiation received at the top of Earth's atmosphere – has been measured since 1978 by series of overlapping NASA and ESA satellite experiments to be 1.361 kilo⁠watts per square meter (kW/m²). TSI observations are continuing today with the ACRIMSAT/ACRIM3, SOHO/VIRGO and SORCE/TIM satellite experiments. Variation of TSI has been discovered on many timescales including the solar magnetic cycle and many shorter periodic cycles. TSI provides the energy that drives Earth's climate, so continuation of the TSI time series database is critical to understanding the role of solar variability in climate change.
Spectral Solar Irradiance (SSI) - the spectral distribution of the TSI - has been monitored since 2003 by the SORCE Spectral Irradiance Monitor (SIM). It has been found that SSI at UV (ultraviolet) wavelength corresponds in a less clear, and probably more complicated fashion, with Earth's climate responses than earlier assumed, fueling broad avenues of new research in “the connection of the Sun and stratosphere, troposphere, biosphere, ocean, and Earth’s climate”.
Intensity in the Solar System.
Different bodies of the Solar System receive light of an intensity inversely proportional to the square of their distance from Sun. A rough table comparing the amount of solar radiation received by each planet in the Solar System follows (from data in ):
The actual brightness of sunlight that would be observed at the surface depends also on the presence and composition of an atmosphere. For example, Venus's thick atmosphere reflects more than 60% of the solar light it receives. The actual illumination of the surface is about 14,000 lux, comparable to that on Earth "in the daytime with overcast clouds".
Sunlight on Mars would be more or less like daylight on Earth wearing sunglasses, and, as can be seen in the pictures taken by the rovers, there is enough diffuse sky radiation that shadows would not seem particularly dark. Thus, it would give perceptions and "feel" very much like Earth daylight.
For comparison purposes, sunlight on Saturn is slightly brighter than Earth sunlight at the average sunset or sunrise (see daylight for comparison table). Even on Pluto the sunlight would still be bright enough to almost match the average living room. To see sunlight as dim as full moonlight on Earth, a distance of about 500 AU (~69 light-hours) is needed; there are only a handful of objects in the Solar System known to orbit farther than such a distance, among them 90377 Sedna and {{mpl|(87269) 2000 OO|67}}.
Surface illumination.
The spectrum of surface illumination depends upon solar elevation due to atmospheric effects, with the blue spectral component dominating during twilight before and after sunrise and sunset, respectively, and red dominating during sunrise and sunset. These effects are apparent in natural light photography where the principal source of illumination is sunlight as mediated by the atmosphere.
While the color of the sky is usually determined by Rayleigh scattering, an exception occurs at sunset and twilight. "Preferential absorption of sunlight by ozone over long horizon paths gives the zenith sky its blueness when the sun is near the horizon".
See diffuse sky radiation for more details.
Spectral composition of surface illumination.
The Sun's electromagnetic radiation which illuminates Earth's surface is predominantly light that falls within the range of wavelengths to which the visual systems of the animals that inhabit Earth's surface are sensitive. The Sun may therefore be said to illuminate, which is a measure of the light within a specific sensitivity range. Many animals (including humans) have a sensitivity range of approximately 400–700 nm, and given optimal conditions the absorption and scattering by Earth's atmosphere produces illumination that approximates an equal-energy illuminant for most of this range. The useful range for color vision in humans, for example, is approximately 450–650 nm. Aside from effects that arise at sunset and sunrise, the spectral composition changes primarily in respect to how directly sunlight is able to illuminate. When illumination is indirect, Rayleigh scattering in the upper atmosphere will lead blue wavelengths to dominate. Water vapour in the lower atmosphere produces further scattering and ozone, dust and water particles will also absorb selective wavelengths.
Climate effects.
On Earth, solar radiation is obvious as daylight when the sun is above the horizon. This is during daytime, and also in summer near the poles at night, but not at all in winter near the poles. When the direct radiation is not blocked by clouds, it is experienced as "sunshine", combining the perception of bright white light (sunlight in the strict sense) and warming. The warming on the body, the ground, and other objects depends on the absorption of the electromagnetic radiation in the form of heat.
The amount of radiation intercepted by a planetary body varies inversely with the square of the distance between the star and the planet. Earth's orbit and obliquity change with time (over thousands of years), sometimes forming a nearly perfect circle, and at other times stretching out to an orbital eccentricity of 5% (currently 1.67%). As the orbit changes, the total insolation over a year remains almost constant due to Kepler's second law,
where formula_4 is the "areal velocity" invariant. That is, the integration over the orbital period (also invariant) is a constant.
If we assume the solar radiation power {{mvar|P}} as a constant over time and the solar irradiation given by the inverse-square law, we obtain also the average insolation as a constant.
But the seasonal and latitudinal distribution and intensity of solar radiation received at Earth's surface also varies. For example, at latitudes of 65 degrees, the change in solar energy in summer and winter can vary by more than 25% as a result of Earth's orbital variation. Because changes in winter and summer tend to offset, the change in the annual average insolation at any given location is near zero, but the redistribution of energy between summer and winter does strongly affect the intensity of seasonal cycles. Such changes associated with the redistribution of solar energy are considered a likely cause for the coming and going of recent ice ages (see: Milankovitch cycles).
Past variations in solar irradiance.
Space-based observations of solar irradiance started in 1978. These measurements show that the solar constant is not constant. It varies on many periodic cycles including the 11-year sunspot solar cycle. When going further back in time, one has to rely on irradiance reconstructions, using sunspots for the past 400 years or cosmogenic radionuclides for going back 10,000 years.
Such reconstructions have been done. These studies show that solar irradiance does vary with distinct periodicities such as: 11 years (Schwabe), 88 years (Gleisberg cycle), 208 years (DeVries cycle) and 1,000 years (Eddy cycle).
Life on Earth.
The existence of nearly all life on Earth is fueled by light from the Sun. Most autotrophs, such as plants, use the energy of sunlight, combined with carbon dioxide and water, to produce simple sugars—a process known as photosynthesis. These sugars are then used as building-blocks and in other synthetic pathways that allow the organism to grow.
Heterotrophs, such as animals, use light from the Sun indirectly by consuming the products of autotrophs, either by consuming autotrophs, by consuming their products, or by consuming other heterotrophs. The sugars and other molecular components produced by the autotrophs are then broken down, releasing stored solar energy, and giving the heterotroph the energy required for survival. This process is known as cellular respiration.
In prehistory, humans began to further extend this process by putting plant and animal materials to other uses. They used animal skins for warmth, for example, or wooden weapons to hunt. These skills allowed humans to harvest more of the sunlight than was possible through glycolysis alone, and human population began to grow.
During the Neolithic Revolution, the domestication of plants and animals further increased human access to solar energy. Fields devoted to crops were enriched by inedible plant matter, providing sugars and nutrients for future harvests. Animals that had previously provided humans with only meat and tools once they were killed were now used for labour throughout their lives, fueled by grasses inedible to humans.
The more recent discoveries of coal, petroleum and natural gas are modern extensions of this trend. These fossil fuels are the remnants of ancient plant and animal matter, formed using energy from sunlight and then trapped within Earth for millions of years. Because the stored energy in these fossil fuels has accumulated over many millions of years, they have allowed modern humans to massively increase the production and consumption of primary energy. As the amount of fossil fuel is large but finite, this cannot continue indefinitely, and various theories exist as to what will follow this stage of human civilization (e.g., alternative fuels, Malthusian catastrophe, new urbanism, peak oil).
Cultural aspects.
The effect of sunlight is relevant to painting, evidenced for instance in works of Claude Monet on outdoor scenes and landscapes.
Many people find direct sunlight to be too bright for comfort, especially when reading from white paper upon which the sun is directly shining. Indeed, looking directly at the sun can cause long-term vision damage. To compensate for the brightness of sunlight, many people wear sunglasses. Cars, many helmets and caps are equipped with visors to block the sun from direct vision when the sun is at a low angle. Sunshine is often blocked from entering buildings through the use of walls, window blinds, awnings, shutters, curtains, or nearby shade trees.
In colder countries, many people prefer sunnier days and often avoid the shade. In hotter countries, the converse is true; during the midday hours, many people prefer to stay inside to remain cool. If they do go outside, they seek shade that may be provided by trees, parasols, and so on.
In Hinduism the sun is considered to be a god as it is the source of life and energy on earth.
Sunbathing.
Sunbathing is a popular leisure activity in which a person sits or lies in direct sunshine. People often sunbathe in comfortable places where there is ample sunlight. Some common places for sunbathing include beaches, open air swimming pools, parks, gardens, and sidewalk cafes. Sunbathers typically wear limited amounts of clothing or some simply go nude. For some, an alternative to sunbathing is the use of a sunbed that generates ultraviolet light and can be used indoors regardless of weather conditions. Tanning beds have been banned in a number of states in the world.
For many people with light skin, one purpose for sunbathing is to darken one's skin color (get a sun tan), as this is considered in some cultures to be attractive, associated with outdoor activity, vacations/holidays, and health. Some people prefer naked sunbathing so that an "all-over" or "even" tan can be obtained, sometimes as part of a specific lifestyle.
For people suffering from psoriasis, sunbathing is an effective way of healing the symptoms.
Skin tanning is achieved by an increase in the dark pigment inside skin cells called melanocytes, and is an automatic response mechanism of the body to sufficient exposure to ultraviolet radiation from the sun or from artificial sunlamps. Thus, the tan gradually disappears with time, when one is no longer exposed to these sources.
Effects on human health.
The ultraviolet radiation in sunlight has both positive and negative health effects, as it is both a principal source of vitamin D3 and a mutagen. A dietary supplement can supply vitamin D without this mutagenic effect, but bypasses natural mechanisms that would prevent overdoses of vitamin D generated internally from sunlight. Vitamin D has a wide range of positive health effects, which include strengthening bones and possibly inhibiting the growth of some cancers. Sun exposure has also been associated with the timing of melatonin synthesis, maintenance of normal circadian rhythms, and reduced risk of seasonal affective disorder.
Long-term sunlight exposure is known to be associated with the development of skin cancer, skin aging, immune suppression, and eye diseases such as cataracts and macular degeneration. Short-term overexposure is the cause of sunburn, snow blindness, and solar retinopathy.
UV rays, and therefore sunlight and sunlamps, are the only listed carcinogens that are known to have health benefits, and a number of public health organizations state that there needs to be a balance between the risks of having too much sunlight or too little. There is a general consensus that sunburn should always be avoided.

</doc>
<doc id="27980" url="http://en.wikipedia.org/wiki?curid=27980" title="Stellar evolution">
Stellar evolution

Stellar evolution is the process by which a star changes during its lifetime. Depending on the mass of the star, this lifetime ranges from a few million years for the most massive to trillions of years for the least massive, which is considerably longer than the age of the universe. The table shows the lifetimes of stars as a function of their masses. All stars are born from collapsing clouds of gas and dust, often called nebulae or molecular clouds. Over the course of millions of years, these protostars settle down into a state of equilibrium, becoming what is known as a main-sequence star.
Nuclear fusion powers a star for most of its life. Initially the energy is generated by the fusion of hydrogen atoms at the core of the main-sequence star. Later, as the preponderance of atoms at the core becomes helium, stars like the Sun begin to fuse hydrogen along a spherical shell surrounding the core. This process causes the star to gradually grow in size, passing through the subgiant stage until it reaches the red giant phase. Stars with at least half the mass of the Sun can also begin to generate energy through the fusion of helium at their core, whereas more-massive stars can fuse heavier elements along a series of concentric shells. Once a star like the Sun has exhausted its nuclear fuel, its core collapses into a dense white dwarf and the outer layers are expelled as a planetary nebula. Stars with around ten or more times the mass of the Sun can explode in a supernova as their inert iron cores collapse into an extremely dense neutron star or black hole. Although the universe is not old enough for any of the smallest red dwarfs to have reached the end of their lives, stellar models suggest they will slowly become brighter and hotter before running out of hydrogen fuel and becoming low-mass white dwarfs.
Stellar evolution is not studied by observing the life of a single star, as most stellar changes occur too slowly to be detected, even over many centuries. Instead, astrophysicists come to understand how stars evolve by observing numerous stars at various points in their lifetime, and by simulating stellar structure using computer models.
Birth of a star.
Protostar.
Stellar evolution starts with the gravitational collapse of a giant molecular cloud. Typical giant molecular clouds are roughly 100 ly across and contain up to 6000000 solar mass. As it collapses, a giant molecular cloud breaks into smaller and smaller pieces. In each of these fragments, the collapsing gas releases gravitational potential energy as heat. As its temperature and pressure increase, a fragment condenses into a rotating sphere of superhot gas known as a protostar.
A protostar continues to grow by accretion of gas and dust from the molecular cloud, becoming a pre-main-sequence star as it reaches its final mass. Further development is determined by its mass. (Mass is compared to the mass of the Sun: 1.0 solar mass means 1 solar mass.)
Protostars are encompassed in dust, and are thus more readily visible at infrared wavelengths.
Observations from the Wide-field Infrared Survey Explorer (WISE) have been especially important for unveiling numerous Galactic protostars and their parent star clusters.
Brown dwarfs and sub-stellar objects.
Protostars with masses less than roughly 0.08 solar mass never reach temperatures high enough for nuclear fusion of hydrogen to begin. These are known as brown dwarfs. The International Astronomical Union defines brown dwarfs as stars massive enough to fuse deuterium at some point in their lives (13 Jupiter masses (MJ), 2.5 × 1028 kg, or 0.0125 M☉). Objects smaller than 13 MJ are classified as sub-brown dwarfs (but if they orbit around another stellar object they are classified as planets). Both types, deuterium-burning and not, shine dimly and die away slowly, cooling gradually over hundreds of millions of years.
Hydrogen fusion.
For a more-massive protostar, the core temperature will eventually reach 10 million kelvin, initiating the proton–proton chain reaction and allowing hydrogen to fuse, first to deuterium and then to helium. In stars of slightly over 1 solar mass, the carbon–nitrogen–oxygen fusion reaction (CNO cycle) contributes a large portion of the energy generation. The onset of nuclear fusion leads relatively quickly to a hydrostatic equilibrium in which energy released by the core exerts a "radiation pressure" balancing the weight of the star's matter, preventing further gravitational collapse. The star thus evolves rapidly to a stable state, beginning the main-sequence phase of its evolution.
A new star will sit at a specific point on the main sequence of the Hertzsprung–Russell diagram, with the main-sequence spectral type depending upon the mass of the star. Small, relatively cold, low-mass red dwarfs fuse hydrogen slowly and will remain on the main sequence for hundreds of billions of years or longer, whereas massive, hot O-type stars will leave the main sequence after just a few million years. A mid-sized yellow dwarf star, like the Sun, will remain on the main sequence for about 10 billion years. The Sun is thought to be in the middle of its main sequence lifespan.
 <imagemap>
Image:Zams and tracks.png
WR
LBV
YHG
BSG
RSG
AGB
RG
<imagemap>
Image:Zams and tracks.png
The evolutionary tracks of stars with different initial masses on the Hertzsprung–Russell diagram. The tracks start once the star has evolved to the main sequence and stop when fusion stops (for massive stars) and at the end of the red giant branch (for stars 1 M☉ and less).A yellow track is shown for the Sun, which will become a red giant after its main-sequence phase ends before expanding further along the asymptotic giant branch, which will be the last phase in which the Sun undergoes fusion.
Mature stars.
Eventually the core exhausts its supply of hydrogen and the star begins to evolve off of the main sequence. Without the outward pressure generated by the fusion of hydrogen to counteract the force of gravity the core contracts until either electron degeneracy pressure becomes sufficient to oppose gravity or the core becomes hot enough (around 100 MK) for helium fusion to begin. Which of these happens first depends upon the star's mass.
Low-mass stars.
What happens after a low-mass star ceases to produce energy through fusion has not been directly observed; the universe is around 13.8 billion years old, which is less time (by several orders of magnitude, in some cases) than it takes for fusion to cease in such stars.
Recent astrophysical models suggest that red dwarfs of 0.1 M☉ may stay on the main sequence for some six to twelve trillion years, gradually increasing in both temperature and luminosity, and take several hundred billion more to collapse, slowly, into a white dwarf. Such stars will not become red giants as they are fully convective and will not develop a degenerate helium core with a shell burning hydrogen. Instead, hydrogen fusion will proceed until almost the whole star is helium.
Slightly more massive stars do expand into red giants, but their helium cores are not massive enough to reach the temperatures required for helium fusion so they never reach the tip of the red giant branch. When hydrogen shell burning finishes, these stars move directly off the red giant branch like a post AGB star, but at lower luminosity, to become a white dwarf. A star of about 0.5 M☉ will be able to reach temperatures high enough to fuse helium, and these "mid-sized" stars go on to further stages of evolution beyond the red giant branch.
Mid-sized stars.
Stars of roughly 0.5–10 M☉ become red giants, which are large non-main-sequence stars of stellar classification K or M. Red giants lie along the right edge of the Hertzsprung–Russell diagram due to their red color and large luminosity. Examples include Aldebaran in the constellation Taurus and Arcturus in the constellation of Boötes. Red giants all have inert cores with hydrogen-burning shells: concentric layers atop the core that are still fusing hydrogen into helium.
Mid-sized stars are red giants during two different phases of their post-main-sequence evolution: red-giant-branch stars, whose inert cores are made of helium, and asymptotic-giant-branch stars, whose inert cores are made of carbon. Asymptotic-giant-branch stars have helium-burning shells inside the hydrogen-burning shells, whereas red-giant-branch stars have hydrogen-burning shells only. In either case, the accelerated fusion in the hydrogen-containing layer immediately over the core causes the star to expand. This lifts the outer layers away from the core, reducing the gravitational pull on them, and they expand faster than the energy production increases. This causes the outer layers of the star to cool, which causes the star to become redder than it was on the main sequence.
Red-giant-branch phase.
The red-giant-branch phase of a star's life follows the main sequence. Initially, the cores of red-giant-branch stars collapse, as the internal pressure of the core is insufficient to balance gravity. This gravitational collapse releases energy, heating concentric shells immediately outside the inert helium core so that hydrogen fusion continues in these shells. The core of a red-giant-branch star of up to a few solar masses stops collapsing when it is dense enough to be supported by electron degeneracy pressure. Once this occurs, the core reaches hydrostatic equilibrium: the electron degeneracy pressure is sufficient to balance gravitational pressure. The core's gravity compresses the hydrogen in the layer immediately above it, causing it to fuse faster than hydrogen would fuse in a main-sequence star of the same mass. This in turn causes the star to become more luminous (from 1,000–10,000 times brighter) and expand; the degree of expansion outstrips the increase in luminosity, causing the effective temperature to decrease.
The expanding outer layers of the star are convective, with the material being mixed by turbulence from near the fusing regions up to the surface of the star. For all but the lowest-mass stars, the fused material has remained deep in the stellar interior prior to this point, so the convecting envelope makes fusion products visible at the star's surface for the first time. At this stage of evolution, the results are subtle, with the largest effects, alterations to the isotopes of hydrogen and helium, being unobservable. The effects of the CNO cycle appear at the surface, with lower 12C/13C ratios and altered proportions of carbon and nitrogen. These are detectable with spectroscopy and have been measured for many evolved stars.
As the hydrogen in the shell around the core is consumed, the helium core grows. Eventually, the electrons in the helium core of stars less than about 2.5 M☉ become degenerate, preventing the helium core from contracting further. Later in the red giant phase, the cores of stars more massive than 0.5 M☉ get hot enough to start helium fusion by the triple-alpha process. In stars of approximately one solar mass, it can take a billion years or more for the core to reach helium ignition temperatures.
If the core is largely supported by electron degeneracy pressure, helium fusion will ignite on a timescale of days in a helium flash. In more massive stars, the ignition of helium fusion occurs relatively slowly with no flash. The nuclear power released during the helium flash is very large, on the order of 108 times the luminosity of the Sun for a few days and 1011 times the luminosity of the Sun (roughly the luminosity of the Milky Way Galaxy) for a few seconds. However, the energy is absorbed by the stellar envelope and thus cannot be seen from outside the star. The energy released by helium fusion causes the core to expand, so that hydrogen fusion in the overlying layers slows and total energy generation decreases. The star contracts, although not all the way to the main sequence, and it migrates to the horizontal branch on the Hertzsprung–Russell diagram, gradually shrinking in radius and increasing its surface temperature. Core helium flash stars evolve to the red end of the horizontal branch but do not migrate to higher temperatures before they gain a degenerate carbon-oxygen core and start helium shell burning. These stars are often observed as a red clump of stars in the colour-magnitude diagram of a cluster, hotter and less luminous than the red giants. Higher-mass stars with larger helium cores move along the horizontal branch to higher temperatures, some becoming unstable pulsating stars in the yellow instability strip (RR Lyrae variables), whereas some become even hotter and can form a blue tail or blue hook to the horizontal branch. The exact morphology of the horizontal branch depends on parameters such as metallicity, age, and helium content, but the exact details are still being modelled.
Asymptotic-giant-branch phase.
After a star has consumed the helium at the core, hydrogen and helium fusion continues in shells around a hot core of carbon and oxygen. The star follows the asymptotic giant branch on the Hertzsprung–Russell diagram, paralleling the original red giant evolution, but with even faster energy generation (which lasts for a shorter time). Although helium is being burnt in a shell, the majority of the energy is produced by hydrogen burning in a shell further from the core of the star. Helium from these hydrogen burning shells drops towards the center of the star and periodically the energy output from the helium shell increases dramatically. This is known as a thermal pulse and they occur towards the end of the asymptotic-giant-branch phase, sometimes even into the post-asymptotic-giant-branch phase. Depending on mass and composition, there may be several to hundreds of thermal pulses.
There is a phase on the ascent of the asymptotic-giant-branch where a deep convective zone forms and can bring carbon from the core to the surface. This is known as the second dredge up, and in some stars there may even be a third dredge up. In this way a carbon star is formed, very cool and strongly reddened stars showing strong carbon lines in their spectra. A process known as hot bottom burning may convert carbon into oxygen and nitrogen before it can be dredged to the surface, and the interaction between these processes determines the observed luminosities and spectra of carbon stars in particular clusters.
Another well known class of asymptotic-giant-branch stars are the Mira variables, which pulsate with well-defined periods of tens to hundreds of days and large amplitudes up to about 10 magnitudes (in the visual, total luminosity changes by a much smaller amount). In more-massive stars the stars become more luminous and the pulsation period is longer, leading to enhanced mass loss, and the stars become heavily obscured at visual wavelengths. These stars can be observed as OH/IR stars, pulsating in the infra-red and showing OH maser activity. These stars are clearly oxygen rich, in contrast to the carbon stars, but both must be produced by dredge ups.
These mid-range stars ultimately reach the tip of the asymptotic-giant-branch and run out of fuel for shell burning. They are not sufficiently massive to start full-scale carbon fusion, so they contract again, going through a period of post-asymptotic-giant-branch superwind to produce a planetary nebula with an extremely hot central star. The central star then cools to a white dwarf. The expelled gas is relatively rich in heavy elements created within the star and may be particularly oxygen or carbon enriched, depending on the type of the star. The gas builds up in an expanding shell called a circumstellar envelope and cools as it moves away from the star, allowing dust particles and molecules to form. With the high infrared energy input from the central star, ideal conditions are formed in these circumstellar envelopes for maser excitation.
It is possible for thermal pulses to be produced once post-asymptotic-giant-branch evolution has begun, producing a variety of unusual and poorly understood stars known as born-again asymptotic-giant-branch stars. These may result in extreme horizontal-branch stars (subdwarf B stars), hydrogen deficient post-asymptotic-giant-branch stars, variable planetary nebula central stars, and R Coronae Borealis variables.
Massive stars.
In massive stars, the core is already large enough at the onset of the hydrogen burning shell that helium ignition will occur before electron degeneracy pressure has a chance to become prevalent. Thus, when these stars expand and cool, they do not brighten as much as lower-mass stars; however, they were much brighter than lower-mass stars to begin with, and are thus still brighter than the red giants formed from less-massive stars. These stars are unlikely to survive as red supergiants; instead they will destroy themselves as type II supernovas.
Extremely massive stars (more than approximately 40 M☉), which are very luminous and thus have very rapid stellar winds, lose mass so rapidly due to radiation pressure that they tend to strip off their own envelopes before they can expand to become red supergiants, and thus retain extremely high surface temperatures (and blue-white color) from their main-sequence time onwards. The largest stars of the current generation are about 100-150 M☉ because the outer layers would be expelled by the extreme radiation. Although lower-mass stars normally do not burn off their outer layers so rapidly, they can likewise avoid becoming red giants or red supergiants if they are in binary systems close enough so that the companion star strips off the envelope as it expands, or if they rotate rapidly enough so that convection extends all the way from the core to the surface, resulting in the absence of a separate core and envelope due to thorough mixing.
The core grows hotter and denser as it gains material from fusion of hydrogen at the base of the envelope. In all massive stars, electron degeneracy pressure is insufficient to halt collapse by itself, so as each major element is consumed in the center, progressively heavier elements ignite, temporarily halting collapse. If the core of the star is not too massive (less than approximately 1.4 M☉, taking into account mass loss that has occurred by this time), it may then form a white dwarf (possibly surrounded by a planetary nebula) as described above for less-massive stars, with the difference that the white dwarf is composed chiefly of oxygen, neon, and magnesium.
Above a certain mass (estimated at approximately 2.5 M☉ and whose star's progenitor was around 10 M☉), the core will reach the temperature (approximately 1.1 gigakelvins) at which neon partially breaks down to form oxygen and helium, the latter of which immediately fuses with some of the remaining neon to form magnesium; then oxygen fuses to form sulfur, silicon, and smaller amounts of other elements. Finally, the temperature gets high enough that any nucleus can be partially broken down, most commonly releasing an alpha particle (helium nucleus) which immediately fuses with another nucleus, so that several nuclei are effectively rearranged into a smaller number of heavier nuclei, with net release of energy because the addition of fragments to nuclei exceeds the energy required to break them off the parent nuclei.
A star with a core mass too great to form a white dwarf but insufficient to achieve sustained conversion of neon to oxygen and magnesium, will undergo core collapse (due to electron capture) before achieving fusion of the heavier elements. Both heating and cooling caused by electron capture onto minor constituent elements (such as aluminum and sodium) prior to collapse may have a significant impact on total energy generation within the star shortly before collapse. This may produce a noticeable effect on the abundance of elements and isotopes ejected in the subsequent supernova.
Supernova.
Once the nucleosynthesis process arrives at iron-56, the continuation of this process consumes energy (the addition of fragments to nuclei releases less energy than required to break them off the parent nuclei). If the mass of the core exceeds the Chandrasekhar limit, electron degeneracy pressure will be unable to support its weight against the force of gravity, and the core will undergo sudden, catastrophic collapse to form a neutron star or (in the case of cores that exceed the Tolman-Oppenheimer-Volkoff limit), a black hole. Through a process that is not completely understood, some of the gravitational potential energy released by this core collapse is converted into a Type Ib, Type Ic, or Type II supernova. It is known that the core collapse produces a massive surge of neutrinos, as observed with supernova SN 1987A. The extremely energetic neutrinos fragment some nuclei; some of their energy is consumed in releasing nucleons, including neutrons, and some of their energy is transformed into heat and kinetic energy, thus augmenting the shock wave started by rebound of some of the infalling material from the collapse of the core. Electron capture in very dense parts of the infalling matter may produce additional neutrons. Because some of the rebounding matter is bombarded by the neutrons, some of its nuclei capture them, creating a spectrum of heavier-than-iron material including the radioactive elements up to (and likely beyond) uranium. Although non-exploding red giants can produce significant quantities of elements heavier than iron using neutrons released in side reactions of earlier nuclear reactions, the abundance of elements heavier than iron (and in particular, of certain isotopes of elements that have multiple stable or long-lived isotopes) produced in such reactions is quite different from that produced in a supernova. Neither abundance alone matches that found in the Solar System, so both supernovae and ejection of elements from red giants are required to explain the observed abundance of heavy elements and isotopes thereof.
The energy transferred from collapse of the core to rebounding material not only generates heavy elements, but provides for their acceleration well beyond escape velocity, thus causing a Type Ib, Type Ic, or Type II supernova. Note that current understanding of this energy transfer is still not satisfactory; although current computer models of Type Ib, Type Ic, and Type II supernovae account for part of the energy transfer, they are not able to account for enough energy transfer to produce the observed ejection of material.
Some evidence gained from analysis of the mass and orbital parameters of binary neutron stars (which require two such supernovae) hints that the collapse of an oxygen-neon-magnesium core may produce a supernova that differs observably (in ways other than size) from a supernova produced by the collapse of an iron core.
The most-massive stars that exist today may be completely destroyed by a supernova with an energy greatly exceeding its gravitational binding energy. This rare event, caused by pair-instability, leaves behind no black hole remnant. In the past history of the universe, some stars were even larger than the largest that exists today, and they would immediately collapse into a black hole at the end of their lives, due to photodisintegration.
Stellar remnants.
After a star has burned out its fuel supply, its remnants can take one of three forms, depending on the mass during its lifetime.
White and black dwarfs.
For a star of 1 M☉, the resulting white dwarf is of about 0.6 M☉, compressed into approximately the volume of the Earth. White dwarfs are stable because the inward pull of gravity is balanced by the degeneracy pressure of the star's electrons, a consequence of the Pauli exclusion principle. Electron degeneracy pressure provides a rather soft limit against further compression; therefore, for a given chemical composition, white dwarfs of higher mass have a smaller volume. With no fuel left to burn, the star radiates its remaining heat into space for billions of years.
A white dwarf is very hot when it first forms, more than 100,000 K at the surface and even hotter in its interior. It is so hot that a lot of its energy is lost in the form of neutrinos for the first 10 million years of its existence, but will have lost most of its energy after a billion years.
The chemical composition of the white dwarf depends upon its mass. A star of a few solar masses will ignite carbon fusion to form magnesium, neon, and smaller amounts of other elements, resulting in a white dwarf composed chiefly of oxygen, neon, and magnesium, provided that it can lose enough mass to get below the Chandrasekhar limit (see below), and provided that the ignition of carbon is not so violent as to blow the star apart in a supernova. A star of mass on the order of magnitude of the Sun will be unable to ignite carbon fusion, and will produce a white dwarf composed chiefly of carbon and oxygen, and of mass too low to collapse unless matter is added to it later (see below). A star of less than about half the mass of the Sun will be unable to ignite helium fusion (as noted earlier), and will produce a white dwarf composed chiefly of helium.
In the end, all that remains is a cold dark mass sometimes called a black dwarf. However, the universe is not old enough for any black dwarfs to exist yet.
If the white dwarf's mass increases above the Chandrasekhar limit, which is 1.4 M☉ for a white dwarf composed chiefly of carbon, oxygen, neon, and/or magnesium, then electron degeneracy pressure fails due to electron capture and the star collapses. Depending upon the chemical composition and pre-collapse temperature in the center, this will lead either to collapse into a neutron star or runaway ignition of carbon and oxygen. Heavier elements favor continued core collapse, because they require a higher temperature to ignite, because electron capture onto these elements and their fusion products is easier; higher core temperatures favor runaway nuclear reaction, which halts core collapse and leads to a Type Ia supernova. These supernovae may be many times brighter than the Type II supernova marking the death of a massive star, even though the latter has the greater total energy release. This inability to collapse means that no white dwarf more massive than approximately 1.4 M☉ can exist (with a possible minor exception for very rapidly spinning white dwarfs, whose centrifugal force due to rotation partially counteracts the weight of their matter). Mass transfer in a binary system may cause an initially stable white dwarf to surpass the Chandrasekhar limit.
If a white dwarf forms a close binary system with another star, hydrogen from the larger companion may accrete around and onto a white dwarf until it gets hot enough to fuse in a runaway reaction at its surface, although the white dwarf remains below the Chandrasekhar limit. Such an explosion is termed a nova.
Neutron stars.
When a stellar core collapses, the pressure causes electron capture, thus converting the great majority of the protons into neutrons. The electromagnetic forces keeping separate nuclei apart are gone (proportionally, if nuclei were the size of dust mites, atoms would be as large as football stadiums), and most of the core of the star becomes a dense ball of contiguous neutrons (in some ways like a giant atomic nucleus), with a thin overlying layer of degenerate matter (chiefly iron unless matter of different composition is added later). The neutrons resist further compression by the Pauli Exclusion Principle, in a way analogous to electron degeneracy pressure, but stronger.
These stars, known as neutron stars, are extremely small—on the order of radius 10 km, no bigger than the size of a large city—and are phenomenally dense. Their period of rotation shortens dramatically as the stars shrink (due to conservation of angular momentum); observed rotational periods of neutron stars range from about 1.5 milliseconds (over 600 revolutions per second) to several seconds. When these rapidly rotating stars' magnetic poles are aligned with the Earth, we detect a pulse of radiation each revolution. Such neutron stars are called pulsars, and were the first neutron stars to be discovered. Though electromagnetic radiation detected from pulsars is most often in the form of radio waves, pulsars have also been detected at visible, X-ray, and gamma ray wavelengths.
Black holes.
If the mass of the stellar remnant is high enough, the neutron degeneracy pressure will be insufficient to prevent collapse below the Schwarzschild radius. The stellar remnant thus becomes a black hole. The mass at which this occurs is not known with certainty, but is currently estimated at between 2 and 3 M☉.
Black holes are predicted by the theory of general relativity. According to classical general relativity, no matter or information can flow from the interior of a black hole to an outside observer, although quantum effects may allow deviations from this strict rule. The existence of black holes in the universe is well supported, both theoretically and by astronomical observation.
Because the core-collapse supernova mechanism itself is imperfectly understood, it is still not known whether it is possible for a star to collapse directly to a black hole without producing a visible supernova, or whether some supernovae initially form unstable neutron stars which then collapse into black holes; the exact relation between the initial mass of the star and the final remnant is also not completely certain. Resolution of these uncertainties requires the analysis of more supernovae and supernova remnants.
Models.
A stellar evolutionary model is a mathematical model that can be used to compute the evolutionary phases of a star from its formation until it becomes a remnant. The mass and chemical composition of the star are used as the inputs, and the luminosity and surface temperature are the only constraints. The model formulae are based upon the physical understanding of the star, usually under the assumption of hydrostatic equilibrium. Extensive computer calculations are then run to determine the changing state of the star over time, yielding a table of data that can be used to determine the evolutionary track of the star across the Hertzsprung–Russell diagram, along with other evolving properties. Accurate models can be used to estimate the current age of a star by comparing its physical properties with those of stars along a matching evolutionary track.

</doc>
<doc id="27982" url="http://en.wikipedia.org/wiki?curid=27982" title="Snake River">
Snake River

The Snake River is a major river of the greater Pacific Northwest in the United States. At 1078 mi long, it is the largest tributary of the Columbia River, the largest North American river that empties into the Pacific Ocean. Rising in western Wyoming, the river flows through the Snake River Plain then rugged Hells Canyon and the rolling Palouse Hills to reach its mouth at the Tri-Cities of the state of Washington. Its drainage basin encompasses parts of six U.S. states, and its average discharge is over 54000 cuft/s.
Rugged mountains divided by rolling plains characterize the physiographically diverse watershed of the Snake River. The Snake River Plain was created by a volcanic hotspot which now lies underneath Yellowstone National Park, the headwaters of the Snake River. Gigantic glacial-retreat flooding episodes that occurred during the previous Ice Age carved out many topographical features including various canyons and ridges along the middle and lower Snake. Two of these catastrophic flooding events significantly affected the river and its surrounds.
More than 11,000 years ago, prehistoric Native Americans lived along the Snake. Salmon from the Pacific Ocean spawned in the millions in the river. These fish were central to the lives of the people along the Snake below Shoshone Falls. By the time Lewis and Clark crossed the Rockies and sighted the valley of a Snake tributary, the Nez Perce and Shoshone were the most powerful people in the region. Contact with Europeans introduced horses to some tribes, reshaping their lifestyles for the next few hundred years before outside settlement. Later explorers and fur trappers further changed and used the resources of the Snake River basin. At one point, a hand sign made by the Shoshones representing fish was misinterpreted to represent a snake, giving the Snake River its name.
By the middle 19th century, the Oregon Trail, a pioneer trail of which a major portion followed the Snake River, had been established. Steamboats and railroads moved agricultural products and minerals along the river throughout the 19th and early 20th centuries. The powerful, steep flow of the Snake has been utilized since the 1890s to generate hydroelectricity, enhance navigation and provide irrigation water from fifteen major dams that have transformed the lower river into a series of reservoirs, several of which have been proposed for removal to restore some of the river's once-tremendous salmon runs.
Course.
Formed by the confluence of three tiny headstreams on the southwest flank of Two Oceans Plateau in western Wyoming and Yellowstone National Park, the Snake starts out as a small river flowing west and south into Jackson Lake. Its first 50 mi run through the valley of Jackson Hole, which cuts between the Teton Range and the Continental Divide. The Snake takes a large bend northwest through Snake River Canyon, cutting through the Snake River Range and into eastern Idaho, receiving first the Hoback and Greys Rivers before entering Palisades Reservoir where it is also met by the Salt River at the mouth of Star Valley. After passing through Palisades Dam, the Snake River empties onto the Snake River Plain, a vast physiographic province extending through southern Idaho across the massif of the Rocky Mountains and underlain by the Snake River Aquifer, one of the most productive aquifers in the United States.
Southwest of the city of Rexburg, the Snake receives from the right the Henrys Fork, sometimes called the North Fork of the Snake River. The confluence with the Henrys Fork takes the river southwards through downtown Idaho Falls, rounding the Fort Hall Indian Reservation and into American Falls Reservoir, receiving the Portneuf River. The Portneuf River Valley is an overflow channel that in the last glacial period carried floodwaters from pluvial Lake Bonneville into the Snake River Plain, carving out many topographic features and significantly altering the Snake River landscape. The Snake River resumes its journey westwards, then enters the Snake River Canyon of Idaho, where it drops over Shoshone Falls, a waterfall that marks the historical upriver limit of migrating salmon, and passing under the Perrine Bridge. Close to Twin Falls, the Snake approaches the southernmost point in its entire course, after which it starts to flow generally northwest.
Shortly after it passes within 30 mi of the Idaho state capital of Boise, the river surges past the state border into Oregon, close to where it meets the Owyhee River, Boise River and Payette River. The Snake River then begins to define the roughly 200 mi Idaho-Oregon state border, which follows the river into Hells Canyon, a steep and spectacular gorge that cuts through the Salmon River Mountains and Blue Mountains of Idaho and Oregon. Hells Canyon is one of the most rugged and treacherous portions of the course of the Snake River, which pioneers on the Oregon Trail and steamboat operators in the 19th century had great difficulty negotiating. There were hundreds of rapids in Hells Canyon, some of which have been stilled by the three dams of the Hells Canyon Hydroelectric Project: Hells Canyon, Oxbow, and Brownlee.
The Salmon River, the largest tributary of the Snake River, meets the river in one of the remotest areas of its entire course, nearly at the halfway point in Hells Canyon. From there, the Snake crosses into Washington and Idaho, receiving the Grande Ronde River from the west before receiving the Clearwater River at Lewiston, the uppermost major city on the navigable stretch of the Snake. As the Snake leaves Hells Canyon and spreads into the low-lying Palouse Hills of eastern Washington, the Lower Snake River Project's four dams have transformed the Snake River into a series of reservoirs. The confluence of the Snake and Columbia rivers has been submerged in Lake Wallula, the reservoir of McNary Dam. The Columbia River then flows about 325 mi further to the Pacific Ocean, cutting through the Cascade Range by way of the Columbia River Gorge.
Geology.
As recently as 165 million years ago, most of western North America was still part of the Pacific Ocean. The nearly complete subduction of the Farallon Plate underneath the westward-moving North American Plate created the Rocky Mountains, which were pushed up by rising magma trapped between the sinking Farallon plate and the North American plate. As the North American Plate moved westwards over a stationary hotspot beneath the crust, a series of tremendous lava flows and volcanic eruptions carved out the Snake River Plain beginning about 12 million years ago, west of the Continental Divide. Even larger lava flows of Columbia River basalts issued over eastern Washington, forming the Columbia Plateau southeast of the Columbia and the Palouse Hills in the lower Snake. Separate volcanic activity formed the northwestern portion of the plain, an area far from the path of the hotspot which now lies beneath Yellowstone National Park. At this point, the Snake River watershed was beginning to take shape.
The Snake River Plain and the gap between the Sierra Nevada and Cascade Range formed a "moisture channel" running as far inland as the headwaters of the Snake River. Rainclouds from the Pacific Ocean blown into the moisture channel travel eastwards over 1000 mi. When the Teton Range uplifted about 9 million years ago along a detachment fault running north–south through the central Rockies, rainclouds began to encounter a barrier at the eastern end of the channel, gorging the headwaters of the Snake River with frequent rainfall. These rains fed the Snake River, helping it to cut through the Tetons, forming the Snake River Canyon of Wyoming. About 6 million years ago, the Salmon River Mountains and Blue Mountains at the far end of the plain began to rise, and as the river cut through the rising mountains, the ancestral Hells Canyon was formed. Lake Idaho, formed during the Miocene, covered a large portion of the Snake River Plain between Twin Falls and Hells Canyon, and its lava dam was finally breached about 2 million years ago.
Lava flowing from Cedar Butte in present southeast Idaho blocked the Snake River at Eagle Rock, about 42,000 years ago, near the present-day site of American Falls Dam. A 40 mi-long lake, known as American Falls Lake, formed behind the barrier. The lake was stable and survived for nearly 30,000 years. About 14,500 years ago, pluvial Lake Bonneville in the Great Salt Lake area, formed in the last glacial period, spilled catastrophically down the Portneuf River into the Snake in an event known as the Bonneville Flood. This was one of the first in a series of catastrophic flooding events in the Northwest known as the Ice Age Floods. The deluge caused American Falls Lake to breach its natural lava dam, which was rapidly eroded away with only the 50 ft-high American Falls left in the end. The flood waters of Lake Bonneville, approximately twenty times the flow of the Columbia River or 5300000 cuft/s, swept down the Snake River leaving debris and sediment deposits across southern Idaho. For miles on either side of the Snake flood waters stripped away soils and scoured the underlying basalt bedrock, in the process creating Shoshone Falls, Twin Falls, Crane Falls, and Swan Falls, while cutting and deepening gorges and canyons along the way. The Bonneville flood waters continued through Hells Canyon. The flood widened Hells Canyon but did not deepen it.
As the Bonneville Floods rushed down the Snake River, the Missoula Floods occurred in the same period, but farther north. The Missoula Floods, which took place over 40 times in the time span from 15,000 to 13,000 years ago, were caused by Glacial Lake Missoula on the Clark Fork repeatedly being impounded by ice dams then breaking through, with the lake's water rushing over much of eastern Washington in massive surges far larger than the Lake Bonneville Flood. These floods pooled behind the Cascade Range into enormous lakes and spilled over the northern drainage divide of the Snake River watershed, carving deep canyons through the Palouse Hills. The Palouse River canyon was the largest of the many gorges cut through the Palouse Hills, and could not have become as large as it now is if it were not for the Missoula Floods. The Lake Bonneville floods and the Missoula Floods helped widen and deepen the Columbia River Gorge, a giant water gap which allows water from the Columbia and Snake rivers to take a direct route through the Cascade Range to the Pacific.
The massive amounts of sediment deposited by the Lake Bonneville Floods in the Snake River Plain also had a lasting effect on most of the middle Snake River. The high hydraulic conductivity of the mostly-basalt rocks in the plain led to the formation of the Snake River Aquifer, one of the most productive aquifers in North America. Many rivers and streams flowing from the north side of the plain sink into the aquifer instead of flowing into the Snake River, a group of watersheds called the lost streams of Idaho. The aquifer filled to hold nearly 100000000 acre.ft of water, underlying about 10000 sqmi in a plume 1300 ft thick. In places, water exits from rivers at rates of nearly 600 cuft/s. Much of the water lost by the Snake River as it transects the plain issues back into the river at its western end, by way of many artesian springs.
Watershed.
The Snake River is the thirteenth longest river in the United States. Its watershed is the 10th largest among North American rivers, and covers almost 108000 sqmi in portions of six U.S. states: Wyoming, Idaho, Nevada, Utah, Oregon, and Washington, with the largest portion in Idaho. Most of the Snake River watershed lies between the Rocky Mountains on the east and the Columbia Plateau on the northwest. The largest tributary of the Columbia River, the Snake River watershed makes up about 41% of the entire Columbia River Basin. Its average discharge at the mouth constitutes 31% of the Columbia's flow at that point. Above the confluence, the Snake is slightly longer than the Columbia—1078 mi compared to 928 mi—and its drainage basin is slightly larger—4% bigger than the upstream Columbia River watershed.
The mostly semi-arid, even desert climate of the Snake River watershed on average, receives less than 12 in of precipitation per year. However, precipitation in the Snake River watershed varies widely. At Twin Falls, in the center of the Snake River Plain, the climate is nearly desert, with an annual rainfall of just 9.24 in, although the average snowfall is 13.1 in. This desert climate occupies the majority of the basin of the Snake River, so although it is longer than the Columbia River above the Tri-Cities, its discharge is on average significantly less. However, in the high Rockies of Wyoming, in the upper Jackson Hole area, the average precipitation is over 30 in, and snowfall averages 252 in. Most of the Snake River basin consists of wide, arid plains and rolling hills, bordered by high mountains. In the upper parts of the watershed, however, the river flows through an area with a distinct alpine climate. There are also stretches where the river and its tributaries have incised themselves into tight gorges. The Snake River watershed includes parts of Yellowstone National Park, Grand Teton National Park, Hells Canyon National Recreation Area, and many other national and state parks.
Much of the area along the river, within a few miles of its banks, is irrigated farmland, especially in its middle and lower course. Irrigation dams include American Falls Dam, Minidoka Dam, and C.J. Strike Dam. Aside from water from the river, water is also pulled from the Snake River Aquifer for irrigation. Major cities along the river include Jackson in Wyoming, Twin Falls, Idaho Falls, Boise, and Lewiston in Idaho, and the Tri-Cities in Washington (Kennewick, Pasco and Richland). There are fifteen dams in total along the Snake River, which aside from irrigation, also produce electricity, maintain a navigation channel along part of the river's route, and provide flood control. However, fish passage is limited to the stretch below Hells Canyon.
The Snake River watershed is bounded by several other major North American watersheds, which drain both to the Atlantic or the Pacific, or into endorheic basins. On the southwest side a divide separates the Snake watershed from Oregon's Harney Basin, which is endorheic. On the south, the Snake watershed borders that of the Humboldt River in Nevada, and the watershed of the Great Salt Lake (the Bear, Jordan and Weber rivers) on the south.
The Snake River also shares a boundary with the Green River to the southeast; the Green River drains parts of Wyoming and Utah and is the largest tributary of the Colorado River. On the western extremity for a short stretch the Continental Divide separates the Snake watershed from the Bighorn River, a tributary of the Yellowstone River, which the Snake begins near. On the north the Snake River watershed is bounded by the Red Rock River, a tributary of the Beaverhead River, which flows into the Jefferson River and into the Missouri River, part of the Gulf of Mexico drainage basin.
The rest of the Snake River watershed borders on several other major Columbia River tributaries - mostly the Spokane River to the north, but also Clark Fork in Montana to the northeast and the John Day River to the west. Of these, the Clark Fork (via the Pend Oreille River) and the Spokane join the Columbia above the Snake, while the John Day joins downstream of the Snake, in the Columbia River Gorge. It is of note that the northeastern divide of the Snake River watershed forms the Idaho-Montana boundary, so the Snake River watershed does not extend into Montana.
Mountain ranges in the Snake watershed include the Teton Range, Bitterroot Range, Clearwater Mountains, Seven Devils Mountains, and the extreme northwestern end of the Wind River Range. Grand Teton is the highest point in the Snake River watershed, reaching 13775 ft in elevation. The elevation of the Snake River is 358 ft when it joins the Columbia River.
Pollution.
Agricultural runoff from farms and ranches in the Snake River Plain and many other areas has severely hurt the ecology of the river throughout the 20th century. After the first irrigation dams on the river begun operation in the first decade of the 20th century, much of the arable land in a strip a few miles wide along the Snake River was cultivated or turned to pasture, and agricultural return flows began to pollute the Snake. Runoff from several feedlots was dumped into the river until laws made the practice illegal. Fertilizer, manure and other chemicals and pollutants washed into the river greatly increase the nutrient load, especially of phosphorus, fecal coliforms and nitrogen. During low water, algae blooms occur throughout the calm stretches of the river, depleting its oxygen supply.
Much of the return flows do not issue directly back into the Snake River, but rather feed the Snake River Aquifer underneath the Snake River Plain. Water diverted from the river for irrigation, after absorbing any surface pollutants, re-enters the ground and feeds the aquifer. Although the aquifer has maintained its level, it has become increasingly laced with contaminants. Water in the aquifer eventually travels to the west side of the Snake River Plain and re-enters the river as springs. Throughout much of the Snake River Plain and Hells Canyon, excessive sediment is also a recurring problem. In December 2007, the U.S. Environmental Protection Agency (EPA) issued a permit requiring owners of fish farms along the Snake River to reduce their phosphorus discharge by 40%. Pollutant levels in Hells Canyon upstream of the Salmon River confluence, including that of water temperature, dissolved nutrients, and sediment, are required to meet certain levels.
Discharge.
The Snake River's average flow is 54830 cuft/s. The United States Geological Survey recorded the river's discharge from a period of 1963–2000 at a stream gauge below Ice Harbor Dam. In that period, the largest average annual flow recorded was 84190 cuft/s in 1997, and the lowest was 27100 cuft/s in 1992. The lowest recorded daily mean flow was 2700 cuft/s on February 4, 1979. On August 27, 1965, there was temporarily no flow as a result of testing at Ice Harbor Dam. The highest recorded flow was 312000 cuft/s on June 19, 1974. The highest flow ever recorded on the Snake River was at a different USGS stream gauge near Clarkston, which operated from 1915 to 1972. This gauge recorded a maximum flow of 369000 cuft/s—more than the Columbia's average discharge—on May 29, 1948. An even larger peak discharge, estimated at 409000 cuft/s, occurred during the flood of June 1894.
The river's flow is also measured at several other points in its course. Above Jackson Lake, Wyoming, the discharge is about 885 cuft/s from a drainage area of 486 sqmi. At Minidoka, Idaho, about halfway through the Snake River Plain, the river's discharge rises to 7841 cuft/s. However, at Buhl, Idaho, only about 50 mi downstream, the river's flow decreases to 4908 cuft/s because of agricultural diversions and seepage. But at the border of Idaho and Oregon, near Weiser at the beginning of Hells Canyon, the Snake's flow rises to 17780 cuft/s after receiving several major tributaries such as the Payette, Owyhee and Malheur. The discharge further increases to 19530 cuft/s at Hells Canyon Dam on the border of Idaho and Oregon. At Anatone, Washington, downstream of the confluence with the Salmon, one of the Snake's largest tributaries, the mean discharge is 34560 cuft/s.
History.
Name.
Canadian explorer David Thompson first recorded the Native American name of the Snake River as "Shawpatin" when he arrived at its mouth by boat in 1800. When the Lewis and Clark Expedition crossed westwards into the Snake River watershed in 1805, they first gave it the name "Lewis River", "Lewis Fork" or "Lewis's Fork", as Meriwether Lewis was the first of their group to sight the river.
They also made note of the "Snake Indians" who lived along the river, who were actually the Shoshone tribe, and learned that the Native Americans called the river "Ki-moo-e-nim" or "Yam-pah-pa" (for an herb that grew prolifically along its banks).
Later American explorers, some of whom were originally part of the Lewis and Clark expedition, journeyed into the Snake River watershed and records show a variety of names have been associated with the river. The explorer Wilson Price Hunt of the Astor Expedition named the river as "Mad River". Others gave the river names including "Shoshone River" (after the tribe) and "Saptin River". Eventually, the name "Snake River" was derived from an S-shaped gesture the Shoshone tribe made with their hands to represent swimming salmon. Explorers misinterpreted it to represent a snake, giving the river its present-day name.
Early inhabitants.
People have been living along the Snake River for at least 11,000 years. Historian Daniel S. Meatte divides the prehistory of the western Snake River Basin into three main phases or "adaptive systems". The first he calls "Broad Spectrum Foraging", dating from 11,500 to 4,200 years before present. During this period people drew upon a wide variety of food resources. The second period, "Semisedentary Foraging", dates from 4,200–250 years before present and is distinctive for an increased reliance upon fish, especially salmon, as well as food preservation and storage. The third phase, from 250 to 100 years before present, he calls "Equestrian Foragers". It is characterized by large horse-mounted tribes that spent long amounts of time away from their local foraging range hunting bison. In the eastern Snake River Plain there is some evidence of Clovis, Folsom, and Plano cultures dating back over 10,000 years ago.
Early fur traders and explorers noted regional trading centers, and archaeological evidence has shown some to be of considerable antiquity. One such trading center in the Weiser area existed as early as 4,500 years ago. The Fremont culture may have contributed to the historic Shoshones, but it is not well understood. Another poorly understood early cultural component is called the Midvale Complex. The introduction of the horse to the Snake River Plain around 1700 helped in establishing the Shoshone and Northern Paiute cultures.
On the Snake River in southeastern Washington there are several ancient sites. One of the oldest and most well-known is called the Marmes Rockshelter, which was used from over 11,000 years ago to relatively recent times. The Marmes Rockshelter was flooded in 1968 by Lake Herbert G. West, the Lower Monumental Dam's reservoir.
Eventually, two large Native American groups controlled most of the Snake River: the Nez Perce, whose territory stretched from the southeastern Columbia Plateau into northern Oregon and western Idaho, and the Shoshone, who occupied the Snake River Plain both above and below Shoshone Falls. Lifestyles along the Snake River varied widely. Below Shoshone Falls, the economy centered around salmon, who often came up the river in enormous numbers. Salmon were the mainstay of the Nez Perce and most of the other tribes below Shoshone Falls. Above the falls, life was significantly different. The Snake River Plain forms one of the only relatively easy paths across the main Rocky Mountains for many hundreds of miles, allowing Native Americans both east and west of the mountains to interact. As a result, the Shoshone centered around a trading economy.
According to legend, the Nez Perce tribe was first founded in the valley of the Clearwater River, one of the Snake River's lowermost major tributaries. At its height, there were at least 27 Nez Perce settlements along the Clearwater River and 11 more on the Snake between the mouth of the Clearwater and Imnaha Rivers. There were also villages on the Salmon River, Grande Ronde River, Tucannon River, and the lower Hells Canyon area. The Snake River's annual salmon run, which was estimated at that time to exceed four million in good years, supported the Nez Perce, who lived in permanent, well-defined villages, unlike the nomadic southeastern tribes along the Snake River. The Nez Perce also were involved in trade with the Flathead tribe to the north and other middle Columbia River tribes. However, they were enemies to the Shoshone and the other upstream Snake River tribes.
The Shoshone or Shoshoni were characterized by nomadic groups that took their culture from the earlier Bitterroot culture and Great Basin tribes that migrated north via the Owyhee River. They were the most powerful tribe in the Rocky Mountains area, and were known to many Great Plains tribes as the "Snakes". In the 18th century, Shoshone territory extended beyond the Snake River Plain, extending over the Continental Divide into the upper Missouri River watershed and even further north into Canada. A smallpox epidemic brought by European explorers and fur trappers was responsible for wiping out much of the Shoshone east of the Rocky Mountains, but the Shoshone continued to occupy the Snake River Plain. Eventually, the Shoshone culture merged with that of the Paiute and Bannock tribes, which came from the Great Basin and the Hells Canyon area, respectively. The Bannock brought with them the skill of buffalo hunting and horses they had acquired from Europeans, changing the Shoshone way of life significantly.
Exploration and settling.
The Lewis and Clark Expedition (1804–06) was the first American group to cross the Rocky Mountains and sail down the Snake and Columbia rivers to the Pacific Ocean. Meriwether Lewis supposedly became the first American to sight the drainage basin of the Snake River after he crossed the mountains a few days ahead of his party on August 12, 1805, and sighted the Salmon River valley (a major Snake tributary) from Lemhi Pass, a few miles from the present-day site of Salmon, Idaho. The party later traveled north, descended the Lemhi River to the Salmon and attempted to descend it to the Snake, but found it impassable because of its violent rapids. The expedition named the Snake River the "Lewis River", "Lewis's River", or "Lewis Fork", in his honor, and they traveled northwards to the Lochsa River, which they traveled via the Clearwater River into the lower Snake, and into the Columbia. They also referred to the Shoshone Indians as the "Snake Indians", which became the present-day name of the river. The name "Lewis Fork", however, did not last.
Later American explorers traveled throughout the Snake River area and up its major tributaries beginning in 1806, just after Lewis and Clark had returned. The first was John Ordway in 1806, who also explored the lower Salmon River. John Colter in 1808 was the first to sight the upper headwaters of the Snake River, including the Jackson Hole area.
In 1810, Andrew Henry, along with a party of fur trappers, discovered the Henrys Fork of the Snake River, which is now named after him. Donald Mackenzie sailed the lower Snake River in 1811, and later explorers included Wilson Price Hunt of the Astor Expedition (who gave the river the name "Mad River"), Ramsay Crooks, Francisco Payelle, John Grey, Thyery Goddin, and many others after the 1830s. Many of these later explorers were original members of the Lewis and Clark Expedition who had returned to map and explore the area in greater detail. Even later, American fur trappers scouted the area for beaver streams, but Canadian trappers from the British Hudson's Bay Company were by now a major competitor.
The Hudson's Bay Company first sent fur trappers into the Snake River watershed in 1819. The party of three traveled into the headwaters of the Owyhee River, a major southern tributary of the Snake, but disappeared. Meanwhile, as American fur trappers kept coming to the region, the Hudson's Bay Company ordered the Canadian trappers to kill as many beavers as they could, eventually nearly eradicating the species from the Snake River watershed, under the "rationale [that] if there are no beavers, there will be no reason for the Yanks ([Americans]) to come." Their goal was to eventually gain rights over the Oregon Territory, a region covering Washington, Oregon, Idaho, and parts of Montana and Wyoming (most of the present-day region called the Pacific Northwest). However, the area was eventually annexed into the United States.
By the middle 19th century, the Oregon Trail had been established, generally following much of the Snake River. One crossing the trail made over the Snake River was near the present-day site of Ontario, Oregon. Several years later, a ferry was established at the site, replacing the old system where pioneers had to ford the wide, powerful and deep Snake. Another place where pioneers crossed the Snake was further upstream, at a place called "Three Island Crossing", near the mouth of the Boise River. This area has a group of three islands (hence the name) that splits the Snake into four channels each about 200 ft wide. Some emigrants chose to ford the Snake and proceed down the west side and recross the river near Fort Boise into Hells Canyon, continue down the drier east side into the gorge, or float the Snake and Columbia to the Willamette River, the destination of the Oregon Trail. The reason for the Three Island Crossing was the better availability of grass and water access. Numerous ferries have provided crossings of the upper Snake from the Brownlee Ferry at the head of Hell's Canyon to Menor's Ferry, which operates today at Moose, Wyoming. Sophistication varied from reed boats pulled by Indians on horse back at Snake Fort, Fort Boise, as described by Narcissa Whitman in 1836 to an electric operated ferry, the Swan Falls Ferry, at Swan Falls Dam of the early 20th century.
Steamboats.
Unlike the Columbia River, it was far more difficult for steamboats to navigate on the Snake. The Columbia River drops 2690 ft from source to mouth, while the Snake drops over 8500 ft in elevation over a length more than 200 mi shorter. Still, from the 1860s to the 1940s, steamboats traveled on the Snake River from its mouth at the Columbia River to near the mouth of the Imnaha River in lower Hells Canyon. However, most of the steamboats only sailed from the river's mouth to Lewiston, located at the confluence of the Snake and Clearwater rivers. This stretch of the river is the easiest to navigate for watercraft since it has the least elevation change, although it still contained over 60 sets of rapids.
Passenger and freight service downstream of Lewiston lasted throughout the late 19th century and persisted until the introduction of railroads in the Palouse Hills grain-growing region and ultimately, the construction of dams on the lower Snake to facilitate barge traffic, which caused the demise of both the steamboats and the railroad. Lewiston, 140 mi from the confluence of the Snake and Columbia and 465 mi from the mouth of the Columbia on the Pacific Ocean, became connected with Portland and other Pacific ports via steamboat service from the mouth of the Snake through the Columbia River Gorge. A commonly traveled route was from Wallula, Washington, 120 mi downstream of the Snake River's mouth, upstream to Lewiston. The Oregon Steam Navigation Company launched the Shoshone at Fort Boise in 1866 which provided passenger and freight service on the upper Snake for the Boise and Owyhee mines.
By the 1870s, the OSN Company, owned by the Northern Pacific Railroad, was operating seven steamboats for transporting wheat and grain from the productive Palouse region along the Snake and Columbia to lower Columbia River ports. These boats were the "Harvest Queen", "John Gates", "Spokane", "Annie Faxon", "Mountain Queen", "R.R. Thompson", and "Wide West", all of which were built on the Columbia River. However, there were more resources along the Snake River than wheat and grain. In the 1890s, a huge copper deposit was discovered at Eureka Bar in Hells Canyon. Several ships were built specifically to transport ore from there to Lewiston: these included "Imnaha", "Mountain Gem", and "Norma". In 1893 the "Annie Faxon" suffered a boiler explosion and sank on the Snake below Lewiston.
River modifications.
Dams.
Many factors have influenced the construction of dams along the Snake River. A total of fifteen dams have been constructed along the Snake River for a multitude of different purposes, from its headwaters in the Rocky Mountains to its mouth on Lake Wallula, a slackwater reservoir formed behind McNary Dam on the Columbia River. Dams on the Snake can be grouped into three major categories. From its headwaters to the beginning of Hells Canyon, many small dams block the Snake to provide irrigation water. Between here and Hells Canyon, the first dam on the Snake, Swan Falls Dam, was built in 1901. In Hells Canyon, a cascade of dams produce hydroelectricity from the river's lofty decrease in elevation over a comparatively small distance. Finally, a third cascade of dams, from Hells Canyon to the mouth, facilitates navigation. Many different government and private agencies have worked to build dams on the Snake River, which now serve an important purpose for people living in the Snake's drainage basin and trade of agricultural products to Pacific seaports.
The Minidoka Irrigation Project of the U.S. Bureau of Reclamation, created with the passage of the Reclamation Act of 1902, involved the diversion of Snake River water into the Snake River Plain upstream of Shoshone Falls in order to irrigate approximately 1100000 acre in the Snake River Plain and store 4100000 acre.ft of water in Snake River reservoirs.
The first studies for irrigation in the Plain were conducted by the United States Geological Survey in the late 19th century, and the project was authorized on April 23, 1904. The first dam constructed for the project was Minidoka Dam in 1904; its power plant began operating in 1909, producing 7 MW of electricity. This capacity was revised to 20 MW in 1993. However, Minidoka Dam was not the only dam constructed for the project. As far upstream as Jackson Lake in Wyoming, the Jackson Lake Dam was built in 1907 to raise the lake level for providing additional water storage for dry years. American Falls Dam, upstream of Minidoka, was completed in 1927 and replaced in 1978. As the dams were constructed above Shoshone Falls, the historical upriver limit of salmon and also a total barrier to boats and ships, no provisions were made for fish passage or navigation. Several other irrigation dams were also built - including Twin Falls Dam and Palisades Dam.
The Hells Canyon Project was built and maintained by Idaho Power Company starting in the 1940s, and was the second of the three major water projects on the river. The three dams of the project, Brownlee Dam, Oxbow Dam and Hells Canyon Dam, are located in upper Hells Canyon. All three dams are primarily for power generation and flood control, and do not have fish passage or navigation locks. Brownlee Dam, the most upriver dam, was constructed in 1959, and generates 728 MW of power. Oxbow Dam, the second dam in the project, was built in 1961 and generates 220 MW. The dam was named for a 3 mi-wide bend in the Snake River, shaped like an oxbow, although not an oxbow lake. Hells Canyon Dam was the last and most downriver of the three, was constructed in 1967 and generates 450 MW.
Downriver of the Hells Canyon is the Lower Snake River Project, authorized by the Rivers and Harbors Act of 1945, which was created by the U.S. Army Corps of Engineers to create a navigable channel on the Snake River from its mouth to the beginning of Hells Canyon. These dams are, in downstream order: Lower Granite Lock and Dam, Little Goose Lock and Dam, Lower Monumental Lock and Dam, and Ice Harbor Lock and Dam. Dredging work was also done throughout the length of the navigation channel to facilitate ship passage. These dams form a cascade of reservoirs with no stretches of free-flowing river in between. Immediately below Ice Harbor Dam is Lake Wallula, formed by the construction of the McNary Dam on the Columbia River. (McNary Dam is not part of the Lower Snake River Project.) Above Lower Granite Dam, the river channel from Lewiston to Johnson Bar, just below Hells Canyon, is also maintained for jet-boats as this section is too rugged for ships. These dams have been proposed for removal, and if they were to be removed, it would be the largest dam removal project ever undertaken in the United States. The removal has been proposed on the grounds that it would restore salmon runs to the lower Snake River and the Clearwater River and other smaller tributaries, although there would be a loss of hydroelectric power generated by the dams.
Navigation.
In the 1960s and 1970s the U.S. Army Corps of Engineers built four dams and locks on the lower Snake River to facilitate shipping. The lower Columbia River has likewise been dammed for navigation. Thus a deep shipping channel through locks and slackwater reservoirs for heavy barges exists from the Pacific Ocean to Lewiston, Idaho. Most barge traffic originating on the Snake River goes to deep-water ports on the lower Columbia River, such as Portland. Grain, mostly wheat, is the main product shipped from the Snake, and nearly all of it is exported internationally from the lower Columbia River ports.
The shipping channel is authorized to be at least 14 ft deep and 250 ft wide. Where river depths were less than 14 ft, the shipping channel has been dredged in most places. Dredging and redredging work is ongoing and actual depths vary over time. With a channel about 5 ft deeper than the Mississippi River system, the Columbia and Snake rivers can float barges twice as heavy. Agricultural products from Idaho and eastern Washington are among the main goods transported by barge on the Snake and Columbia rivers. Grain, mainly wheat, accounts for more than 85% of the cargo barged on the lower Snake River. In 1998, over 123000000 USbu of grain were barged on the Snake. Before the completion of the lower Snake dams, grain from the region was transported by truck or rail to Columbia River ports around the Tri-Cities. Other products barged on the lower Snake River include peas, lentils, forest products, and petroleum.
Biology.
The World Wide Fund for Nature (WWF) divides the Snake River's watershed into two freshwater ecoregions: the "Columbia Unglaciated" ecoregion and the "Upper Snake" ecoregion. Shoshone Falls marks the boundary between the two. The WWF placed the ecoregion boundary about 50 km downriver from Shoshone Falls in order to include the Big Wood River (the main tributary of the Malad River) in the Upper Snake ecoregion, because the Wood River is biologically distinct from the rest of the downriver Snake. Shoshone Falls has presented a total barrier to the upstream movement of fish for 30,000 to 60,000 years. As a result only 35% of the fish fauna above the falls, and 40% of the Wood River's fish fauna, are shared with the lower Snake River.
The Upper Snake freshwater ecoregion includes most of southeastern Idaho and extends into small portions of Wyoming, Utah, and Nevada, including major freshwater habitats such as Jackson Lake. Compared to the lower Snake River and the rest of the Columbia River's watershed, the Upper Snake ecoregion has a high level of endemism, especially among freshwater molluscs such as snails and clams. There are at least 21 snail and clam species of special concern, including 15 that appear to exist only in single clusters. There are 14 fish species found in the Upper Snake region that do not occur elsewhere in the Columbia's watershed, but which do occur in Bonneville freshwater ecoregion of western Utah, part of the Great Basin and related to the prehistoric Lake Bonneville. The Wood River sculpin ("Cottus leiopomus") is endemic to the Wood River. The Shoshone sculpin ("Cottus greenei") is endemic to the small portion of the Snake River between Shoshone Falls and the Wood River.
The Snake River below Shoshone Falls is home to thirty-five native fish species, of which twelve are also found in the Columbia River and four of which are endemic to the Snake: the relict sand roller ("Percopsis transmontana") of the Percopsidae family, the shorthead sculpin ("Cottus confusus"), the maginated sculpin ("Cottus marginatus"), and the Oregon chub ("Oregonichthys crameri"). The Oregon chub is also found in the Umpqua River and nearby basins. The lower Snake River also supports seven species of salmon ("Oncorhynchus"). There are also high, often localized levels of mollusc endemism, especially in Hells Canyon and the basins of the Clearwater River, Salmon River, and middle Snake River. The mollusc richness extends into the lower Columbia River and tributaries such as the Deschutes River.
Animals.
Aside from aquatic species, much of the Snake River watershed supports larger animals including numerous species of mammals, birds, amphibians, and reptiles. Especially in the headwaters and the other mountainous areas strewn throughout the watershed, the gray wolf, grizzly bear, wolverine, mountain lion and Canada lynx are common. It has been determined that there are 97 species of mammals in the upper part of the Snake River, upstream from the Henrys Fork confluence. Pronghorn and bighorn sheep are common in the area drained by the "lost streams of Idaho", several rivers and large creeks that flow south from the Rocky Mountains and disappear into the Snake River Aquifer. About 274 bird species, some endangered or threatened, use the Snake River watershed, including bald eagle, peregrine falcon, whooping crane, greater sage-grouse, and yellow-billed cuckoo. Barrow's goldeneye are a species of bird that occurs commonly along the lower section of the Snake River.
Ten amphibian and twenty species of reptiles inhabit the upper Snake River's wetland and riparian zones. Several species of frogs are common in the "lost streams" basin and the northeasternmost part of the Snake River watershed, including the inland tailed frog, northern leopard frog, western toad, Columbia spotted frog, long-toed salamander, spadefoot toad. However, in the lower and middle portions of the Snake River watershed, several native species have been severely impacted by agriculture practices and the resulting non-native species supported by them. Introduced birds include the gray partridge, ring-necked pheasant, and chukar. Other non-native species include the bullfrog, brown-headed cowbird, and European starling, attracted by the construction of cities and towns.
Plants.
The Snake River watershed includes a diversity of vegetation zones both past and present. A majority of the watershed was once covered with shrub-steppe grassland, most common in the Snake River Plain and also the Columbia Plateau in southeastern Washington. Riparian zones, wetlands and marshes once occurred along the length of the Snake River and its tributaries. In higher elevations, conifer forests, of which ponderosa pine is most common, dominate the landscape. The basin ranges from semi-desert to alpine climates, providing habitat for hundreds of species of plants. In the lowermost part of the watershed, in southeastern Washington, the Snake River is surrounded by an area called the Columbia Plateau Ecoprovince, which is now mostly occupied by irrigated farms. The rest of the Plateau area is characterized by low hills, dry lakes, and an arid, nearly desert climate.
The headwaters of the Snake River and the high mountains elsewhere in the watershed were historically heavily forested. These include aspen, Douglas fir, and spruce fir, comprising about 20% of the historic watershed. At the base of mountains and in the Lost River basin, sagebrush was and is the predominant vegetation cover. Because of deforestation, up to one-fourth of the forests have been taken over by sagebrush, leaving the remaining forests to cover about 15% of the watershed. However, the lodgepole pine has increased in number, taking over historic stands of other conifers. There are also up to 118 species of rare or endemic plants that occur in the Snake River watershed.
Salmon and other anadromous fish.
The Snake River was once one of the most important rivers for the spawning of anadromous fish—which are hatched in the headwaters of rivers, live in the ocean for most of their lives, and return to the river to spawn—in the United States.
The river supported species including chinook salmon, coho salmon, and sockeye salmon, as well as steelhead, white sturgeon, and Pacific lamprey. It is known that before the construction of dams on the river, there were three major chinook salmon runs in the Snake River; in the spring, summer and fall, totaling about 120,000 fish, and the sockeye salmon run was about 150,000. The historical barrier to fish migration on the Snake River was Shoshone Falls, a waterfall that occurs as the Snake River passes through the Snake River Plain.
Since the early 20th century, when Swan Falls Dam was constructed on the middle Snake River upstream of Hells Canyon, the fifteen dams and reservoirs on the river have posed an increasing problem for migrating salmon. Agricultural lands and their resulting runoff have also had a significant impact on the success rate of migrating fish. Salmon can travel up the Snake River as far as Hells Canyon Dam, using the fish passage facilities of the four lower Snake River dams, leaving the Clearwater, Grande Ronde and Salmon river to sustain spawning salmon. Rising in several forks in the Clearwater Mountains of central Idaho, the Clearwater and Salmon River watersheds are nearly undeveloped with the enormous exception of Dworshak Dam on the North Fork Clearwater River. The watershed of the Grande Ronde in northeastern Oregon is also largely undeveloped. The four reservoirs formed by the lower Snake River dams—Lake Sacagawea, Lake Herbert G. West, Lake Bryan, and Lower Granite Lake—have also formed problems, as the downstream current in the pools is often not enough for the fish to sense, confusing their migration routes.
At the confluence of the Snake and Clearwater Rivers, young salmon that swim down from spawning gravels in the headwaters of the Clearwater River often delay their migrations because of a significant temperature difference. (Prior to the removal of Lewiston Dam on the main Clearwater and Grangeville Dam on the South Fork Clearwater, the Clearwater was completely unusable by migrating salmon.) Agricultural runoff and water held in reservoirs higher upstream on the Snake warm its waters as it flows through the Snake River Plain, so as the Snake meets the Clearwater, its average temperature is much higher. Directly below the confluence, the river flows into Lower Granite Lake, formed by Lower Granite Dam, the uppermost dam of the Lower Snake River Project. Paradoxically, the combination of these factors gives the young salmon further time to grow and to feed in Lower Granite Lake, so when they begin the migration to the Pacific Ocean, they often have a higher chance at survival, compared to those salmon who migrate to the ocean earlier.
Lower Snake River dam removal.
A controversy has erupted since the late 20th century over the four lower Snake River dams, with the primary argument being that removing the dams would allow anadromous fish to reach the lower Snake River tributaries—the Clearwater River, the Tucannon River and the Grande Ronde River—and spawn in much higher numbers. However, removal of the dams has been fiercely opposed by some groups in the Pacific Northwest. Because much of the electricity in the Northwest comes from dams, removing the four dams would create a hole in the energy grid that would not be immediately replaceable. Navigation on the lower Snake would also suffer, as submerged riffles, rapids and islands would be exposed by the removal of the dams. Irrigation pumps for fields in southeastern Washington would also have to reach further to access the water of the Snake River. However, aside from restoring salmon runs, dam removal proponents argue that the power is replaceable, that the grain transportation system could be replaced by railroads, and that only one of the four reservoirs supplies irrigation water. Irrigators in the Snake River Plain would likely need to allow less water into the Snake River during low flow in order to create a current in the four lower reservoirs, and recreation and tourism would likely benefit.
In response to conflicts, a bill has been introduced in the U.S. Congress proposing the study of the feasibility of removing these four lower dams. The issue of dam removal was not in the recovery plan set forth by the Obama administration in September 2009. The plan instead recommended monitoring the effects of climate change and expanding habitat improvement efforts, leaving dam removal as “a last resort” contingent upon a multiyear study of the dams. In February 2010 U.S. Circuit Judge James Redden deemed this plan to be inadequate and gave NOAA three months to formulate a better plan. The plan was resubmitted in May 2010 with few substantial changes and has faced strong opposition from salmon advocates. A final decision from Judge Redden is expected in the spring of 2011.
Tributaries.
The Salmon River is the second largest tributary. Although the Salmon has a larger drainage than the Clearwater, the Salmon drains much drier country and therefore has a smaller discharger than the Clearwater, about 8000000 acre.ft annually compared to about 11000000 acre.ft annually for the Clearwater River.
The Snake River has over 20 major tributaries, most of which are in the mountainous regions of the basin. The largest by far is the Clearwater River, which drains 9000 sqmi in north central Idaho. Many of the rivers that flow into the Snake River Plain from the north sink into the Snake River Aquifer, but still contribute their water to the river. Aside from rivers, the Snake is fed by many significant springs, many of which arise from the aquifer on the west side of the plain.
The Snake River bends through Hells Canyon on the Idaho–Oregon border, looking towards Idaho, with the Oxbow Dam in the background.

</doc>
<doc id="27983" url="http://en.wikipedia.org/wiki?curid=27983" title="Surd">
Surd

Surd may be:

</doc>
<doc id="27984" url="http://en.wikipedia.org/wiki?curid=27984" title="Strong interaction">
Strong interaction

In particle physics, the strong interaction is the mechanism responsible for the strong nuclear force (also called the strong force, nuclear strong force or colour force), one of the four fundamental interactions of nature, the others being electromagnetism, the weak interaction and gravitation. Effective only at a distance of a femtometre, it is approximately 100 times stronger than electromagnetism, a million times stronger than the weak force interaction and 1038 times stronger than gravitation at that range. It ensures the stability of ordinary matter, as it confines the quark elementary particles into hadron particles, such as the proton and neutron, the largest components of the mass of ordinary matter. Furthermore, most of the mass-energy of a common proton or neutron is in the form of the strong force field energy; the individual quarks provide only about 1% of the mass-energy of a proton.
The strong interaction is observable in two areas: on a larger scale (about 1 to 3 femtometers (fm)), it is the force that binds protons and neutrons (nucleons) together to form the nucleus of an atom. On the smaller scale (less than about 0.8 fm, the radius of a nucleon), it is the force (carried by gluons) that holds quarks together to form protons, neutrons, and other hadron particles. The strong force inherently has so high a strength that the energy of an object bound by the strong force (a hadron) is high enough to produce new massive particles. Thus, if hadrons are struck by high-energy particles, they give rise to new hadrons instead of emitting freely moving radiation (gluons). This property of the strong force is called colour confinement, and it prevents the free "emission" of the strong force: instead, in practice, jets of massive particles are observed.
In the context of binding protons and neutrons together to form atoms, the strong interaction is called the nuclear force (or "residual strong force"). In this case, it is the residuum of the strong interaction between the quarks that make up the protons and neutrons. As such, the residual strong interaction obeys a quite different distance-dependent behavior between nucleons, from when it is acting to bind quarks within nucleons. The binding energy that is partly released on the breakup of a nucleus is related to the residual strong force and is harnessed in nuclear power and fission-type nuclear weapons.
The strong interaction is thought to be mediated by massless particles called gluons, that are exchanged between quarks, antiquarks, and other gluons. Gluons, in turn, are thought to interact with quarks and gluons as all carry a type of charge called "colour charge". Colour charge is analogous to electromagnetic charge, but it comes in three types rather than one (+/- red, +/- green, +/- blue) that results in a different type of force, with different rules of behavior. These rules are detailed in the theory of quantum chromodynamics (QCD), which is the theory of quark-gluon interactions.
Just after the Big Bang, and during the electroweak epoch, the electroweak force separated from the strong force. Although it is expected that a Grand Unified Theory exists to describe this, no such theory has been successfully formulated, and the unification remains an unsolved problem in physics.
History.
Before the 1970s, physicists were uncertain about the binding mechanism of the atomic nucleus. It was known that the nucleus was composed of protons and neutrons and that protons possessed positive electric charge, while neutrons were electrically neutral. However, these facts seemed to contradict one another. By physical understanding at that time, positive charges would repel one another and the nucleus should therefore fly apart. However, this was never observed. New physics was needed to explain this phenomenon.
A stronger attractive force was postulated to explain how the atomic nucleus was bound together despite the protons' mutual electromagnetic repulsion. This hypothesized force was called the "strong force", which was believed to be a fundamental force that acted on the protons and neutrons that make up the nucleus.
It was later discovered that protons and neutrons were not fundamental particles, but were made up of constituent particles called quarks. The strong attraction between nucleons was the side-effect of a more fundamental force that bound the quarks together in the protons and neutrons. The theory of quantum chromodynamics explains that quarks carry what is called a colour charge, although it has no relation to visible colour. Quarks with unlike colour charge attract one another as a result of the strong interaction, which is mediated by particles called gluons.
Details.
The word "strong" is used since the strong interaction is the "strongest" of the four fundamental forces; its strength is around 102 times that of the electromagnetic force, some 106 times as great as that of the weak force, and about 1039 times that of gravitation, at a distance of a femtometer or less.
Behaviour of the strong force.
The contemporary understanding of strong force is described by quantum chromodynamics (QCD), a part of the standard model of particle physics. Mathematically, QCD is a non-Abelian gauge theory based on a local (gauge) symmetry group called SU(3).
Quarks and gluons are the only fundamental particles that carry non-vanishing colour charge, and hence participate in strong interactions. The strong force itself acts directly only on elementary quark and gluon particles.
All quarks and gluons in QCD interact with each other through the strong force. The strength of interaction is parametrized by the strong coupling constant. This strength is modified by the gauge colour charge of the particle, a group theoretical property.
The strong force acts between quarks. Unlike all other forces (electromagnetic, weak, and gravitational), the strong force does not diminish in strength with increasing distance. After a limiting distance (about the size of a hadron) has been reached, it remains at a strength of about 10,000 newtons, no matter how much farther the distance between the quarks. In QCD, this phenomenon is called colour confinement; it implies that only hadrons, not individual free quarks, can be observed. The explanation is that the amount of work done against a force of 10,000 newtons (about the weight of a one-metric ton mass on the surface of the Earth) is enough to create particle-antiparticle pairs within a very short distance of an interaction. In simple terms, the very energy applied to pull two quarks apart will create a pair of new quarks that will pair up with the original ones. The failure of all experiments that have searched for free quarks is considered to be evidence for this phenomenon.
The elementary quark and gluon particles affected are unobservable directly, but they instead emerge as jets of newly created hadrons, whenever energy is deposited into a quark-quark bond, as when a quark in a proton is struck by a very fast quark (in an impacting proton) during a particle accelerator experiment. However, quark–gluon plasmas have been observed.
Every quark in the universe does not attract every other quark in the above distance independent manner, since colour-confinement implies that the strong force acts without distance-diminishment only between pairs of single quarks, and that in collections of bound quarks (i.e., hadrons), the net colour-charge of the quarks cancels out, as seen from far away. Collections of quarks (hadrons) therefore appear (nearly) without colour-charge, and the strong force is therefore nearly absent between these hadrons (i.e., between baryons or mesons). However, the cancellation is not quite perfect. A small residual force remains (described below) known as the residual strong force. This residual force "does" diminish rapidly with distance, and is thus very short-range (effectively a few femtometers). It manifests as a force between the "colourless" hadrons, and is therefore sometimes known as the strong nuclear force or simply nuclear force.
Residual strong force.
The residual effect of the strong force is called the nuclear force. The nuclear force acts between hadrons, such as mesons or the nucleons in atomic nuclei. This "residual strong force", acting indirectly, transmits gluons that form part of the virtual pi and rho mesons, which, in turn, transmit the nuclear force between nucleons.
The residual strong force is thus a minor residuum of the strong force that binds quarks together into protons and neutrons. This same force is much weaker "between" neutrons and protons, because it is mostly neutralized "within" them, in the same way that electromagnetic forces between neutral atoms (van der Waals forces) are much weaker than the electromagnetic forces that hold the atoms internally together.
Unlike the strong force itself, the nuclear force, or residual strong force, "does" diminish in strength, and in fact diminishes rapidly with distance. The decrease is approximately as a negative exponential power of distance, though there is no simple expression known for this; see Yukawa potential. This fact, together with the less-rapid decrease of the disruptive electromagnetic force between protons with distance, causes the instability of larger atomic nuclei, such as all those with atomic numbers larger than 82 (the element lead).

</doc>
<doc id="27989" url="http://en.wikipedia.org/wiki?curid=27989" title="September 3">
September 3

September 3 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27990" url="http://en.wikipedia.org/wiki?curid=27990" title="September 5">
September 5

September 5 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27991" url="http://en.wikipedia.org/wiki?curid=27991" title="Stout">
Stout

Stout is a dark beer made using roasted malt or roasted barley, hops, water and yeast. Stouts were traditionally the generic term for the strongest or stoutest porters, typically 7% or 8%, produced by a brewery. 
There are a number of variations including Baltic porter, dry stout and imperial stout. The first known use of the word "stout" for beer was in a document dated 1677 found in the Egerton Manuscript, the sense being that a stout beer was a strong beer not a dark beer. The name "porter" was first used in 1721 to describe a dark brown beer that had been made with roasted malts. Because of the huge popularity of porters, brewers made them in a variety of strengths. The beers with higher gravities were called "stout porters", so the history and development of stout and porter are intertwined, and the term stout has since become firmly associated with dark beer, rather than just strong beer.
History.
Porter originated in London in the early 1720s. The style quickly became popular in the city: it had a strong flavour, took longer to spoil than other beers, increased in alcohol content with age, was significantly cheaper than other beers, and was not easily affected by heat. Within a few decades, porter breweries in London had grown "beyond any previously known scale". Large volumes were exported to Ireland, where it was later (1776) brewed also. In the 19th century, the beer gained its customary black colour through the use of black patent malt, and became stronger in flavour.
Originally, the adjective "stout" meant "proud" or "brave", but later, after the 14th century, it took on the connotation of "strong". The first known use of the word "stout" for beer was in a document dated 1677 found in the Egerton Manuscript, the sense being that a stout beer was a strong beer. The expression "stout porter" was applied during the 18th century to strong versions of porter, and was used by Guinness of Ireland in 1820 – although Guinness had been brewing porters since about 1780, having originally been an ale brewer from its foundation in 1759. "Stout" still meant only "strong" and it could be related to any kind of beer, as long as it was strong: in the UK it was possible to find "stout pale ale", for example. Later, "stout" was eventually to be associated only with porter, becoming a synonym of dark beer.
Because of the huge popularity of porters, brewers made them in a variety of strengths. The beers with higher gravities were called "Stout Porters". There is still division and debate on whether stouts should be a separate style from porter. Usually the only deciding factor is strength.
"Nourishing" and sweet "milk" stouts became popular in Great Britain in the years following the First World War, though their popularity declined towards the end of the 20th century, apart from pockets of local interest such as in Glasgow with Sweetheart Stout.
The slogan "Guinness is good for you" was thought up after market research in the 1920s suggested that people felt better after a pint, and post-operative patients, blood donors, pregnant women and nursing mothers in England were advised to drink Guinness.
With beer writers such as Michael Jackson writing about stouts and porters in the 1970s, there has been a moderate interest in the global speciality beer market.
In the mid 1980s a survey by "What’s Brewing" found just 29 brewers in the UK and Channel Islands still making stout, most of them milk stouts.
Types of stout.
Stouts have several variations.
Dry or Irish stout.
"Irish stout" or "dry stout" (in Irish, "leann dubh", "black beer") is very dark or rich in colour and it often has a "roasted" or coffee-like taste. The most famous example is Guinness followed by Murphy's and Beamish. There are also some smaller breweries producing stout. The alcoholic content and "dry" flavour of a dry or Irish stout are both characterised as light, although it varies from country to country.
Imperial stout.
"Imperial stout", also known as "Russian imperial stout" or "imperial Russian stout", is a strong dark beer or stout in the style that was brewed in the 18th century by Thrale's brewery in London, England for export to the court of Catherine II of Russia. In 1781 the brewery changed hands and the beer became known as Barclay Perkins Imperial Brown Stout. When the brewery was taken over by Courage the beer was renamed Courage Russian Imperial Stout ("RIS"). It has a high alcohol content, usually over 9% abv. 
Milk stout.
"Milk stout" (also called "sweet stout" or "cream stout") is a stout containing lactose, a sugar derived from milk. Because lactose is unfermentable by beer yeast, it adds sweetness, body, and calories to the finished beer. Milk stout was claimed to be nutritious, and was given to nursing mothers, along with other stouts, such as Guinness. The classic surviving example of milk stout is Mackeson's, for which the original brewers claimed that "each pint contains the energising carbohydrates of 10 ounces of pure dairy milk". In the period just after the Second World War when rationing was in place, the British government required brewers to remove the word "milk" from labels and adverts, and any imagery associated with milk.
Oatmeal stout.
"Oatmeal stout" is a stout with a proportion of oats, normally a maximum of 30%, added during the brewing process. Even though a larger proportion of oats in beer can lead to a bitter or astringent taste, during the medieval period in Europe, oats were a common ingredient in ale, and proportions up to 35% were standard. Despite some areas of Europe, such as Norway, still clinging to the use of oats in brewing until the early part of the 20th century, the practice had largely died out by the 16th century, so much so that in 1513 Tudor sailors refused to drink oat beer offered to them because of the bitter flavour.
There was a revival of interest in using oats during the end of the 19th century, when (supposedly) restorative, nourishing and invalid beers, such as the later milk stout, were popular, because of the association of porridge with health. Maclay of Alloa produced an Original Oatmalt Stout in 1895 which used 70% "oatmalt", and a 63/- Oatmeal Stout in 1909, which used 30% "flaked (porridge) oats".
In the 20th century many oatmeal stouts contained only a minimal amount of oats. For example, in 1936 Barclay Perkins Oatmeal Stout used only 0.5% oats. As the oatmeal stout was parti-gyled with their porter and standard stout, these two also contained the same proportion of oats. 
The name seems to have been a marketing device more than anything else. In the 1920s and 1930s Whitbread's London Stout and Oatmeal Stout were identical, just packaged differently. The amount of oats Whitbread used was minimal, again around 0.5%. With such a small quantity of oats used, it could have had little impact on the flavour or texture of these beers.
Many breweries were still brewing oatmeal stouts in the 1950s, for example Brickwoods in Portsmouth, Matthew Brown in Blackburn and Ushers in Trowbridge. When Michael Jackson mentioned the defunct Eldrige Pope "Oat Malt Stout" in his 1977 book "The World Guide to Beer", oatmeal stout was no longer being made anywhere, but Charles Finkel, founder of Merchant du Vin, was curious enough to commission Samuel Smith to produce a version. Samuel Smith's Oatmeal Stout then became the template for other breweries' versions.
Oatmeal stouts do not usually taste specifically of oats. The smoothness of oatmeal stouts comes from the high content of proteins, lipids (includes fats and waxes), and gums imparted by the use of oats. The gums increase the viscosity and body adding to the sense of smoothness.
Chocolate stout.
"Chocolate stout" is a name brewers sometimes give to certain stouts having a noticeable dark chocolate flavour through the use of darker, more aromatic malt; particularly chocolate malt—a malt that has been roasted or kilned until it acquires a chocolate colour. Sometimes, as with Muskoka Brewery's Double Chocolate Cranberry Stout, Young's Double Chocolate Stout, and Rogue Brewery's Chocolate Stout, the beers are also brewed with a small amount of chocolate or chocolate flavouring.
Coffee stout.
Dark roasted malts, such as black patent malt (the darkest roast), can lend a bitter coffee flavour to dark beer. Some brewers like to further emphasize the coffee flavour and add ground coffee.
The ABV of these coffee flavoured stouts will vary from under 4% to over 8%. Most examples will be dry and bitter, though others add milk sugar to create a sweet stout which may then be given a name such as "Coffee & Cream Stout" or just "Coffee Cream Stout". Other flavours such as mint or chocolate may also be added in various combinations.
Oyster stout.
Oysters have had a long association with stout. When stouts were emerging in the 18th century, oysters were a commonplace food often served in public houses and taverns. By the 20th century, oyster beds were in decline, and stout had given way to pale ale.
The first known brewery to use oysters as part of the brewing process of stout was in 1938 by the Hammerton Brewery in London, UK. The brewery was re-established in 2014 and is once again brewing an Oyster Stout.
Modern "oyster stouts" may be made with a handful of oysters in the barrel, hence the claim of one establishment, the Porterhouse Brewery in Dublin, that their award-winning Oyster Stout was not suitable for vegetarians. Others, such as Marston's Oyster Stout, use the name with the implication that the beer would be suitable for drinking with oysters.
Porter.
While there is a great deal of disagreement in the brewing world on this subject, there are no differences between stout and porter historically, though there has been a tendency for breweries to differentiate the strengths of their dark beers with the words "extra", "double" and "stout". The term "stout" was initially used to indicate a stronger porter than other porters issued by an individual brewery. Though not consistent, this is the usage that was most commonly employed.
Baltic porter.
A version of Imperial Stout which originated in the Baltic region, usually cool fermented, making it a type of lager. Imperial Stouts exported from Britain in the 18th century were popular in the Baltic region, and were recreated locally using local ingredients and brewing traditions. Baltic Porter is a specialty of many Polish breweries. 

</doc>
<doc id="27992" url="http://en.wikipedia.org/wiki?curid=27992" title="Slavery">
Slavery

Slavery is a legal or economic system under which people are treated as property. While laws and systems vary, as property, slaves may be bought and sold. Slaves can be held from the time of their capture, purchase or birth, and deprived of the right to leave, to refuse to work, or to demand compensation. Historically, slavery was institutionally recognized by most societies; in more recent times, slavery has been outlawed in all countries, but it continues through the practices of debt bondage, serfdom, domestic servants kept in captivity, certain adoptions in which children are forced to work as slaves, child soldiers, and forced marriage. Slavery is officially illegal in all countries, but there are still an estimated 20 million to 36 million slaves worldwide. Mauritania was the last jurisdiction to officially outlaw slavery (in 1981/2007), but about 10% to 20% of its population is still estimated to live in slavery.
Slavery has existed before written history and has existed in many cultures. Most slaves today are debt slaves, largely in South Asia, who are under debt bondage imposed by loan sharks, sometimes even for generations. Human trafficking is primarily used for forcing women and children into sex industries.
Terminology.
The English word "slave" comes from Old French "sclave", from the Medieval Latin "sclavus", from the Byzantine Greek σκλάβος, which, in turn, comes from the ethnonym "Slav", because in some early Medieval wars many Slavs were captured and enslaved. An older theory connected it to the Greek verb "skyleúo" 'to strip a slain enemy'.
The word used to call a slave has also been utilized to express general dependency to someone else. In many cases, such as in ancient Persia, the situation and lives of such slaves could be better than those of other common citizens.
Types.
Chattel slavery.
Chattel slavery, also called traditional slavery, is so named because people are treated as the chattel (personal property) of an owner and are bought and sold as if they were commodities. It is the least prevalent form of slavery in the world today.
Bonded labor.
Debt bondage or bonded labor occurs when a person pledges himself or herself against a loan. The services required to repay the debt, and their duration, may be undefined. Debt bondage can be passed on from generation to generation, with children required to pay off their parents' debt. It is the most widespread form of slavery today. Debt bondage is most prevalent in South Asia.
Forced labor.
Forced labor occurs when an individual is forced to work against his or her will, under threat of violence or other punishment, with restrictions on their freedom. Human trafficking is primarily for prostituting women and children and is the fastest growing form of forced labor, with Thailand, Cambodia, India, Brazil and Mexico having been identified as leading hotspots of commercial sexual exploitation of children.
The term 'forced labor' is also used to describe all types of slavery and may also include institutions not commonly classified as slavery, such as serfdom, conscription and penal labor.
Forced marriage.
A forced marriage can be regarded as a form of slavery if one of the parties, usually the female, is subject to violence, threats, intimidation etc. and required to engage in sexual activity and perform domestic duties and other work without any personal control. The customs of bride price and dowry, that exist in many parts of the world, can lead to buying and selling people into marriage. Forced marriage continues to be practiced in parts of the world including South Asia, East Asia and Africa. Forced marriages may also occur in immigrant communities in Europe, United States, Canada and Australia. Marriage by abduction occurs in many places in the world today, with a national average of 69% of marriages in Ethiopia being through abduction.
The International Labour Organisation defines child and forced marriage as forms of modern-day slavery.
History.
Early history.
Evidence of slavery predates written records, and has existed in many cultures. Graves dating to 8000 BC in Egypt may show the enslavement of a San-like tribe.[] Slavery is rare among hunter-gatherer populations. Mass slavery also requires economic surpluses and a high population density to be viable. Due to these factors, the practice of slavery would have only proliferated after the invention of agriculture during the Neolithic Revolution about 11,000 years ago.
In the earliest known records slavery is treated as an established institution. The Code of Hammurabi (ca. 1760 BC), for example, prescribed death for anyone who helped a slave to escape or who sheltered a fugitive. The Bible mentions slavery as an established institution.
Slavery was known in almost every ancient civilization, and society, including Sumer, Ancient Egypt, Ancient China, the Akkadian Empire, Assyria, Ancient India, Ancient Greece, the Roman Empire, the Islamic Caliphate, the Hebrew kingdoms in Palestine, and the pre-Columbian civilizations of the Americas. Such institutions included debt-slavery, punishment for crime, the enslavement of prisoners of war, child abandonment, and the birth of slave children to slaves.
Classical Antiquity.
Records of slavery in Ancient Greece go as far back as Mycenaean Greece. It is certain that Classical Athens had the largest slave population, with as many as 80,000 in the 6th and 5th centuries BC; two to four-fifths of the population were slaves. As the Roman Republic expanded outward, entire populations were enslaved, thus creating an ample supply from all over Europe and the Mediterranean. Greeks, Illyrians, Berbers, Germans, Britons, Thracians, Gauls, Jews, Arabs, and many more were slaves used not only for labour, but also for amusement (e. g. gladiators and sex slaves). This oppression by an elite minority eventually led to slave revolts (see Roman Servile Wars); the Third Servile War led by Spartacus being the most famous and severe.
By the late Republican era, slavery had become a vital economic pillar in the wealth of Rome, as well as a very significant part of Roman society. It is estimated that 25% or more of the population of Ancient Rome was enslaved. According to some scholars, slaves represented 35% or more of
Italy's population. Estimates of the number of slaves in the Roman Empire range from 60 million to 100 million, with 400,000 in the city of Rome.
Middle Ages.
Medieval and Early Modern Europe.
Large-scale trading in slaves was mainly confined to the South and East of early medieval Europe: the Byzantine Empire and the Muslim world were the destinations, while pagan Central and Eastern Europe (along with the Caucasus and Tartary) were important sources. Viking, Arab, Greek, and Radhanite Jewish merchants were all involved in the slave trade during the Early Middle Ages. The trade in European slaves reached a peak in the 10th century following the Zanj rebellion which dampened the use of African slaves in the Arab world.
Medieval Spain and Portugal were the scene of almost constant Muslim invasion of the predominantly Christian area. Periodic raiding expeditions were sent from Al-Andalus to ravage the Iberian Christian kingdoms, bringing back booty and slaves. In raid against Lisbon, Portugal in 1189, for example, the Almohad caliph Yaqub al-Mansur took 3,000 female and child captives, while his governor of Córdoba, in a subsequent attack upon Silves, Portugal in 1191, took 3,000 Christian slaves. From the 11th to the 19th century, North African Barbary Pirates engaged in "Razzias", raids on European coastal towns, to capture Christian slaves to sell at slave markets in places such as Algeria and Morocco.
In Britain, slavery continued to be practiced following the fall of Rome and sections of Hywel the Good's laws dealt with slaves in medieval Wales. The trade particularly picked up after the Viking invasions, with major markets at Chester and Bristol supplied by Danish, Mercian, and Welsh raiding of one another's borderlands. At the time of the "Domesday Book" (1086), nearly 10% of the English population were slaves. Slavery in early medieval Europe was so common that the Roman Catholic Church repeatedly prohibited it — or at least the export of Christian slaves to non-Christian lands was prohibited at e. g. the Council of Koblenz (922), the Council of London (1102), and the Council of Armagh (1171). In 1452, Pope Nicholas V issued the papal bull Dum Diversas, granting the kings of Spain and Portugal the right to reduce any "Saracens (antiquated term referring to Muslims), pagans and any other unbelievers" to perpetual slavery, legitimizing the slave trade as a result of war. The approval of slavery under these conditions was reaffirmed and extended in his Romanus Pontifex bull of 1455. However, Pope Paul III forbade enslavement of the native Americans in 1537 in his papal bull Sublimus Dei. Dominican friars who arrived at the Spanish settlement at Santo Domingo strongly denounced the enslavement of the local native Americans. Along with other priests, they opposed their treatment as unjust and illegal in an audience with the Spanish king and in the subsequent royal commission.
The Byzantine-Ottoman wars and the Ottoman wars in Europe brought large numbers of slaves into the Islamic world. To staff its bureaucracy the Ottoman Empire established a janissary system which seized hundreds of thousands of Christian boys through the devşirme system. They were well cared for but were legally slaves owned by the government and were not allowed to marry. They were never bought or sold. The Empire gave them significant administrative and military roles. The system began about 1365; there were 135,000 janissaries in 1826, when the system ended. After the Battle of Lepanto 12,000 Christian galley slaves were recaptured and freed from the Ottoman fleet. Eastern Europe suffered a series of Tatar invasions, the goal of which was to loot and capture slaves into "jasyr". Seventy-five Crimean Tatar raids were recorded into Poland–Lithuania between 1474 and 1569.
Approximately 10–20% of the rural population of Carolingian Europe consisted of slaves. Slavery largely disappeared from Western Europe by the later Middle Ages. The slave trade became illegal in England in 1102, but England went on to become very active in the lucrative Atlantic slave trade from the seventeenth to the early nineteenth century. In Scandinavia, thralldom was abolished in the mid-14th century. Slavery persisted longer in Eastern Europe. Slavery in Poland was forbidden in the 15th century; in Lithuania, slavery was formally abolished in 1588; they were replaced by the second serfdom. In Kievan Rus and Muscovy, the slaves were usually classified as kholops.
Islamic world.
In early Islamic states of the Western Sudan (present-day West Africa), including Ghana (750–1076), Mali (1235–1645), Segou (1712–1861), and Songhai (1275–1591), about a third of the population were enslaved.
Ibn Battuta indicates several times that he was given or purchased slaves. The great 14th-century scholar Ibn Khaldun, wrote: "the Black nations are, as a rule, submissive to slavery, because (Blacks) have little that is (essentially) human and possess attributes that are quite similar to those of dumb animals". Slaves were purchased or captured on the frontiers of the Islamic world and then imported to the major centers, where there were slave markets from which they were widely distributed. In the 9th and 10th centuries, the black Zanj slaves may have constituted at least a half of the total population in lower Iraq. At the same time, many slaves in the region were also imported from Central Asia and the Caucasus. Many slaves were taken in the wars with the Christian nations of medieval Europe.
In the "Thousand and One Nights" there are mentions of white slaves.
Modern history.
Europe.
Author David P. Forsythe has written: "In 1649 up to three-quarters of Muscovy's peasants, or 13 to 14 million people, were serfs whose material lives were barely distinguishable from slaves. Perhaps another 1.5 million were formally enslaved, with Russian slaves serving Russian masters. " Slavery remained a major institution in Russia until 1723, when Peter the Great converted the household slaves into house serfs. Russian agricultural slaves were formally converted into serfs earlier in 1679. Russia's more than 23 million privately held serfs were freed by the Emancipation reform of 1861. State-owned serfs were emancipated in 1866.
Until the late 18th century, the Crimean Khanate (a Muslim Tatar state) maintained a massive slave trade with the Ottoman Empire and the Middle East, exporting about 2 million slaves from Poland-Lithuania and Russia over the period 1500–1700.
During the Second World War (1939–1945) Nazi Germany effectively enslaved about 12 million people, both those considered undesirable and citizens of countries they conquered.
Africa.
In Algiers, the capital of Algeria in Northern Africa, Christians and Europeans that were captured had been forced into slavery. This eventually led to the Bombardment of Algiers in 1816.
Half the population of the Sokoto caliphate of the 19th century were slaves. The Swahili-Arab slave trade reached its height about 150 years ago, when, for example, approximately 20,000 slaves were considered to be carried yearly from Nkhotakota on Lake Malawi to Kilwa. Roughly half the population of Madagascar was enslaved.
According to the "Encyclopedia of African History", "It is estimated that by the 1890s the largest slave population of the world, about 2 million people, was concentrated in the territories of the Sokoto Caliphate. The use of slave labor was extensive, especially in agriculture. " The Anti-Slavery Society estimated there were 2 million slaves in Ethiopia in the early 1930s out of an estimated population of between 8 and 16 million.
Hugh Clapperton in 1824 believed that half the population of Kano were enslaved people. W. A. Veenhoven wrote: "The German doctor, Gustav Nachtigal, an eye-witness, believed that for every slave who arrived at a market three or four died on the way ... Keltie ("The Partition of Africa", London, 1920) believes that for every slave the Arabs brought to the coast at least six died on the way or during the slavers' raid. Livingstone puts the figure as high as ten to one. "
One of the most famous slave traders on the eastern Zanj (Bantu) coast was Tippu Tip, who was the grandson of a slave. The "prazeros" were slave traders along the Zambezi. North of the Zambezi, the waYao and Makua people played a similar role as professional slave raiders and traders. Still further north were the Nyamwezi slave traders.
Asia.
In Constantinople about one-fifth of the population consisted of slaves. The city was a major center of the slave trade in the 15th and later centuries. By 1475 most of the slaves were provided by Tatar raids on Slavic villages. It has been estimated that some 200,000 slaves—mainly Circassians—were imported into the Ottoman Empire between 1800 and 1909. As late as 1908, women slaves were still sold in the Ottoman Empire. A slave market for captured Russian and Persian slaves was centred in the Central Asian khanate of Khiva. In the early 1840s, the population of the Uzbek states of Bukhara and Khiva included about 900,000 slaves. Darrel P. Kaiser wrote, "Kazakh-Kirghiz tribesmen kidnapped 1573 settlers from colonies [German settlements in Russia] in 1774 alone and only half were successfully ransomed. The rest were killed or enslaved. "
According to Sir Henry Bartle Frere (who sat on the Viceroy's Council), there were an estimated 8 or 9 million slaves in India in 1841. About 15% of the population of Malabar were slaves. Slavery was abolished in British India by the Indian Slavery Act V. of 1843.
In East Asia, the Imperial government formally abolished slavery in China in 1906, and the law became effective in 1910. The Nangzan in Tibetan history were, according to Chinese sources, hereditary household slaves.
Indigenous slaves existed in Korea. Slavery was officially abolished with the Gabo Reform of 1894 but continued in reality until 1930. During the Joseon Dynasty (1392–1910) about 30% to 50% of the Korean population were slaves. In late 16th century Japan slavery as such was officially banned, but forms of contract and indentured labor persisted alongside the period penal codes' forced labor.
The hill tribe people in Indochina were "hunted incessantly and carried off as slaves by the Siamese (Thai), the Anamites (Vietnamese), and the Cambodians. " A Siamese military campaign in Laos in 1876 was described by a British observer as having been "transformed into slave-hunting raids on a large scale". The census, taken in 1879, showed that 6% of the population in the Malay sultanate of Perak were slaves. Enslaved people made up about two-thirds of the population in part of North Borneo in the 1880s.
Americas.
Slavery in the Americas had a contentious history, and played a major role in the history and evolution of some countries, triggering at least one revolution and one civil war, as well as numerous rebellions. The Aztecs had slaves. Other Amerindians, such as the Inca of the Andes, the Tupinambá of Brazil, the Creek of Georgia, and the Comanche of Texas, also owned slaves.
The maritime town of Lagos was the first slave market created in Portugal (one of the earliest colonizers of the Americas) for the sale of imported African slaves—the "Mercado de Escravos", opened in 1444. In 1441, the first slaves were brought to Portugal from northern Mauritania.
In 1519, Mexico's first Afro-Mexican slave was brought by Hernán Cortés.
By 1552, black African slaves made up 10% of the population of Lisbon. In the second half of the 16th century, the Crown gave up the monopoly on slave trade and the focus of European trade in African slaves shifted from import to Europe to slave transports directly to tropical colonies in the Americas—in the case of Portugal, especially Brazil. In the 15th century one-third of the slaves were resold to the African market in exchange of gold.
In order to establish itself as an American empire Spain had to fight against the relatively powerful civilizations of the New World. The Spanish conquest of the indigenous peoples in the Americas included using the Natives as forced labour. The Spanish colonies were the first Europeans to use African slaves in the New World on islands such as Cuba and Hispaniola, see Atlantic slave trade.
Bartolomé de Las Casas a 16th-century Dominican friar and Spanish historian participated in campaigns in Cuba (at Bayamo and Camagüey) and was present at the massacre of Hatuey; his observation of that massacre led him to fight for a social movement away from the use of natives as slaves and towards the importation of African Blacks as slaves. Also, the alarming decline in the native population had spurred the first royal laws protecting the native population (Laws of Burgos, 1512–1513).
The first African slaves arrived in Hispaniola in 1501. In 1518, Charles I of Spain agreed to ship slaves directly from Africa. England played a prominent role in the Atlantic slave trade. The "slave triangle" was pioneered by Francis Drake and his associates. In 1640 a Virginia court sentenced John Punch to slavery, forcing him to serve his master,Hugh Gwyn, for the remainder of his life. This was the fist legal sanctioning of slavery in the English colonies. In 1655, A black man, Anthony Johnson of Virginia, was granted ownership of John Casor as the result of a civil case. By 1750, slavery was a legal institution in all of the 13 American colonies, and the profits of the slave trade and of West Indian plantations amounted to 5% of the British economy at the time of the Industrial Revolution.
The Transatlantic slave trade peaked in the late 18th century, when the largest number of slaves were captured on raiding expeditions into the interior of West Africa. These expeditions were typically carried out by African kingdoms, such as the Oyo empire (Yoruba), the Ashanti Empire, the kingdom of Dahomey, and the Aro Confederacy. Europeans rarely entered the interior of Africa, due to fierce African resistance. The slaves were brought to coastal outposts where they were traded for goods. A significant portion of African Americans in North America are descended from Mandinka people. Through a series of conflicts, primarily with the Fulani Jihad States, about half of the Senegambian Mandinka were converted to Islam while as many as a third were sold into slavery to the Americas through capture in conflict.
An estimated 12 million Africans arrived in the Americas from the 16th to the 19th centuries. Of these, an estimated 645,000 were brought to what is now the United States. The usual estimate is that about 15% of slaves died during the voyage, with mortality rates considerably higher in Africa itself in the process of capturing and transporting indigenous peoples to the ships. Approximately 6 million black Africans were killed by others in tribal wars.
Many Europeans who arrived in North America during the 17th and 18th centuries came under contract as indentured servants. The transformation from indentured servitude to slavery was a gradual process in Virginia. The earliest legal documentation of such a shift was in 1640 where a negro, John Punch, was sentenced to lifetime slavery for attempting to run away. This case also marked the disparate treatment of Africans as held by the Virginia County Court, as two white runaways received far lesser sentences. After 1640, planters started to ignore the expiration of indentured contracts and kept their servants as slaves for life. This was demonstrated by the case Johnson v. Parker where the court ruled that John Casor, an indentured servant, be returned to Johnson who claimed that Casor belonged to him for his life. According to the 1860 U. S. census, 393,975 individuals, representing 8% of all US families, owned 3,950,528 slaves. One-third of Southern families owned slaves.
The largest number of slaves were shipped to Brazil. In the Spanish viceroyalty of New Granada, corresponding mainly to modern Panama, Colombia, and Venezuela, the free black population in 1789 was 420,000, whereas African slaves numbered only 20,000. Free blacks also outnumbered slaves in Brazil. By contrast, in Cuba free blacks made up only 15% in 1827; and in the French colony of Saint-Domingue (present-day Haiti) it was a mere 5% in 1789.
Author Charles Rappleye argued that
In the West Indies in particular, but also in North and South America, slavery was the engine that drove the mercantile empires of Europe..It appeared, in the eighteenth century, as universal and immutable as human nature.
Although the trans-Atlantic slave trade ended shortly after the American Revolution, slavery remained a central economic institution in the Southern states of the United States, from where slavery expanded with the westward movement of population. Historian Peter Kolchin wrote, "By breaking up existing families and forcing slaves to relocate far from everyone and everything they knew" this migration "replicated (if on a reduced level) many of [the] horrors" of the Atlantic slave trade.
Historian Ira Berlin called this forced migration the Second Middle Passage. Characterizing it as the "central event" in the life of a slave between the American Revolution and the Civil War, Berlin wrote that whether they were uprooted themselves or simply lived in fear that they or their families would be involuntarily moved, "the massive deportation traumatized black people, both slave and free. "
By 1860, 500,000 slaves had grown to 4 million. As long as slavery expanded, it remained profitable and powerful and was unlikely to disappear. Although complete statistics are lacking, it is estimated that 1,000,000 slaves moved west from the Old South between 1790 and 1860.
Most of the slaves were moved from Maryland, Virginia, and the Carolinas. Michael Tadman, in a 1989 book "Speculators and Slaves: Masters, Traders, and Slaves in the Old South", indicates that 60–70% of interregional migrations were the result of the sale of slaves. In 1820, a child in the Upper South had a 30% chance to be sold south by 1860.
In Puerto Rico, African slavery was finally abolished on March 22, 1873.
Middle East.
According to Robert Davis between 1 million and 1.25 million Europeans were captured by Barbary pirates and sold as slaves in North Africa and Ottoman Empire between the 16th and 19th centuries. There was also an extensive trade in Christian slaves in the Black Sea region for several centuries until the Crimean Khanate was destroyed by the Russian Empire in 1783. In the 1570s close to 20,000 slaves a year were being sold in the Crimean port of Kaffa. The slaves were captured in southern Russia, Poland-Lithuania, Moldavia, Wallachia, and Circassia by Tatar horsemen. Some researchers estimate that altogether more than 3 million people were captured and enslaved during the time of the Crimean Khanate.
The Arab slave trade lasted more than a millennium. As recently as the early 1960s, Saudi Arabia's slave population was estimated at 300,000. Along with Yemen, the Saudis abolished slavery only in 1962. Slaves in the Arab World came from many different regions, including Sub-Saharan Africa (mainly "Zanj"), the Caucasus (mainly Circassians), Central Asia (mainly Tartars), and Central and Eastern Europe (mainly "Saqaliba").
Under Omani Arabs Zanzibar became East Africa's main slave port, with as many as 50,000 enslaved Africans passing through every year during the 19th century. Some historians estimate that between 11 and 18 million African slaves crossed the Red Sea, Indian Ocean, and Sahara Desert from 650 AD to 1900 AD. Eduard Rüppell described the losses of Sudanese slaves being transported on foot to Egypt: "after the Daftardar bey's 1822 campaign in the southern Nuba mountains, nearly 40,000 slaves were captured. However, through bad treatment, disease and desert travel barely 5000 made it to Egypt. "
The Moors, starting in the 8th century, also raided coastal areas around the Mediterranean and Atlantic Ocean, and became known as the Barbary pirates. It is estimated that they captured 1.25 million white slaves from Western Europe and North America between the 16th and 19th centuries. The mortality rate was very high. For instance, plague killed a third to two-thirds of the 30,000 occupants of the slave pens in Algiers in 1662.
Present day.
Even though slavery is now outlawed in every country, the number of slaves today remains as high as 12 million to 29.8 million. Several estimates of the number of slaves in the world have been provided. According to a broad definition of slavery used by Kevin Bales of Free the Slaves (FTS), an advocacy group linked with Anti-Slavery International, there were 27 million people in slavery in 1999, spread all over the world. In 2005, the International Labour Organization provided an estimate of 12.3 million forced labourers in the world. Siddharth Kara has also provided an estimate of 28.4 million slaves at the end of 2006 divided into the following three categories: bonded labour/debt bondage (18.1 million), forced labour (7.6 million), and trafficked slaves (2.7 million). Kara provides a dynamic model to calculate the number of slaves in the world each year, with an estimated 29.2 million at the end of 2009. According to a 2003 report by Human Rights Watch, an estimated 15 million children in debt bondage in India work in slavery-like conditions to pay off their family's debts.
Distribution.
A report by the Walk Free Foundation in 2013, found India had the highest number of slaves, nearly 14 million, followed by China (2.9 million), Pakistan (2.1 million), Nigeria, Ethiopia, Russia, Thailand, Democratic Republic of Congo, Myanmar and Bangladesh; while the countries with the highest of proportion of slaves were Mauritania, Haiti, Pakistan, India and Nepal.
In June 2013, U.S. State Department released a report on slavery, it placed Russia, China, Uzbekistan in the worst offenders category, Cuba, Iran, North Korea, Sudan, Syria, and Zimbabwe were also at the lowest level. List also included Algeria, Libya, Saudi Arabia and Kuwait among a total of 21 countries.
Economics.
While American slaves in 1809 were sold for around $40,000 (in contemporary money); a slave nowadays can be bought for just $90; making replacement more economical than providing long term care. Slavery is a multi-billion dollar industry with estimates of up to $35 billion generated annually.
Trafficking.
Trafficking in human beings (also called human trafficking) is one method of obtaining slaves. Victims are typically recruited through deceit or trickery (such as a false job offer, false migration offer, or false marriage offer), sale by family members, recruitment by former slaves, or outright abduction. Victims are forced into a "debt slavery" situation by coercion, deception, fraud, intimidation, isolation, threat, physical force, debt bondage or even force-feeding with drugs of abuse to control their victims. "Annually, according to U.S. government-sponsored research completed in 2006, approximately 800,000 people are trafficked across national borders, which does not include millions trafficked within their own countries. Approximately 80 percent of transnational victims are women and girls and up to 50 percent are minors", reports the U.S. State Department in a 2008 study.
While the majority of trafficking victims are women, and sometimes children, who are forced into prostitution (in which case the practice is called sex trafficking), victims also include men, women and children who are forced into manual labour. Due to the illegal nature of human trafficking, its exact extent is unknown. A U.S. government report published in 2005, estimates that 600,000 to 800,000 people worldwide are trafficked across borders each year. This figure does not include those who are trafficked internally. Another research effort revealed that between 1.5 million and 1.8 million individuals are trafficked either internally or internationally each year, 500,000 to 600,000 of whom are sex trafficking victims.
Examples.
Examples of modern slavery are numerous. Child slavery has commonly been used in the production of cash crops and mining.
Asia.
In 2008, the Nepalese government abolished the Haliya system, under which 20,000 people were forced to provide free farm labour. Though slavery was officially abolished in China in 1910, the practice continues unofficially in some regions of the country. In June and July 2007, 550 people who had been enslaved by brick manufacturers in Shanxi and Henan were freed by the Chinese government. Among those rescued were 69 children. In response, the Chinese government assembled a force of 35,000 police to check northern Chinese brick kilns for slaves, sent dozens of kiln supervisors to prison, punished 95 officials in Shanxi province for dereliction of duty, and sentenced one kiln foreman to death for killing an enslaved worker. The North Korean government operates six large political prison camps, where political prisoners and their families (around 200,000 people) in lifelong detention are subjected to hard slave labor, torture and inhumane treatment.
South America and Caribbean.
In 2008 in Brazil about 5,000 slaves were rescued by government authorities as part of an initiative to eradicate slavery, which was reported as ongoing in 2010. Poverty has forced at least 225,000 Haitian children to work as restavecs (unpaid household servants); the United Nations considers this to be a form of slavery.
Middle East.
Some tribal sheiks in Iraq still keep blacks, called "Abd", which means servant or slave in Arabic, as slaves.
According to media reports from late 2014 the Islamic State of Iraq and the Levant (ISIL) was selling Yazidi and Christian women as slaves. According to Haleh Esfandiari of the Woodrow Wilson International Center for Scholars, after ISIL militants have captured an area "[t]hey usually take the older women to a makeshift slave market and try to sell them." In mid-October 2014 the U.N. estimated that 5,000 to 7,000 Yazidi women and children were abducted by ISIL and sold into slavery. In the digital magazine "Dabiq", ISIL claimed religious justification for enslaving Yazidi women whom they consider to be from a heretical sect. ISIL claimed that the Yazidi are idol worshipers and their enslavement part of the old shariah practice of spoils of war. According to "The Wall Street Journal", ISIL appeals to apocalyptic beliefs and claims "justification by a Hadith that they interpret as portraying the revival of slavery as a precursor to the end of the world".
Africa.
In Mauritania, the last country to abolish slavery (in 1981), it is estimated that up to 600,000 men, women and children, or 20% of the population, are enslaved with many used as bonded labour. Slavery in Mauritania was criminalized in August 2007. (although slavery as a practice was legally banned in 1981, it was not a crime to own a slave until 2007). Although many slaves have escaped or have been freed since 2007, as of 2012, only one slave-owner had been sentenced to serve time in prison.
An article in the "Middle East Quarterly" in 1999 reported that slavery is endemic in Sudan. Estimates of abductions during the Second Sudanese Civil War range from 14,000 to 200,000 people.
In Niger, slavery is also a current phenomenon. A Nigerien study has found that more than 800,000 people are enslaved, almost 8% of the population. Niger installed anti slavery provision in 2003.
Many pygmies in the Republic of Congo and Democratic Republic of Congo belong from birth to Bantus in a system of slavery.
According to the U.S. State Department, more than 109,000 children were working on cocoa farms alone in Côte d'Ivoire (Ivory Coast) in "the worst forms of child labor" in 2002.
On the night of 14–15 April 2014, a group of militants attacked the Government Girls Secondary School in Chibok, Nigeria. They broke into the school, pretending to be guards, telling the girls to get out and come with them. A large number of students were taken away in trucks, possibly into the Konduga area of the Sambisa Forest where Boko Haram were known to have fortified camps. Houses in Chibok were also burned down in the incident. According to the police, approximately 276 children were taken in the attack, of whom 53 had escaped as of 2 May. Other reports said that 329 girls were kidnapped, 53 had escaped and 276 were still missing. The students have been forced to convert to Islam and into marriage with members of Boko Haram, with a reputed "bride price" of ₦2,000 each ($12.50/£7.50). Many of the students were taken to the neighbouring countries of Chad and Cameroon, with sightings reported of the students crossing borders with the militants, and sightings of the students by villagers living in the Sambisa Forest, which is considered a refuge for Boko Haram
On May 5, 2014 a video in which Boko Haram leader Abubakar Shekau claimed responsibility for the kidnappings emerged. Shekau claimed that "Allah instructed me to sell them...I will carry out his instructions" and "[s]lavery is allowed in my religion, and I shall capture people and make them slaves." He said the girls should not have been in school and instead should have been married since girls as young as nine are suitable for marriage. Shekau said in an interview "I shall capture people and make them slaves" when claiming responsibility for the 2014 Chibok kidnapping.
Abolitionism.
Slavery has existed, in one form or another, through the whole of recorded human history—as have, in various periods, movements to free large or distinct groups of slaves.
Ashoka, who ruled the Maurya Empire from 269–232 BCE, abolished the slave trade but not slavery. The Qin dynasty, which ruled China from 221 to 206 BC, abolished slavery and discouraged serfdom. However, many of its laws were overturned when the dynasty was overthrown. Slavery was again abolished, by Wang Mang, in China in 17 C.E but was reinstituted after his assassination.
The Spanish colonization of the Americas sparked a discussion about the right to enslave native Americans. A prominent critic of slavery in the Spanish New World colonies was Bartolomé de las Casas, who opposed the enslavement of Native Americans, and later also of Africans in America.
One of the first protests against slavery came from German and Dutch Quakers in Pennsylvania in 1688. One of the most significant milestones in the campaign to abolish slavery throughout the world occurred in England in 1772, with British judge Lord Mansfield, whose opinion in Somersett's Case was widely taken to have held that slavery was illegal in England. This judgement also laid down the principle that slavery contracted in other jurisdictions (such as the American colonies) could not be enforced in England. In 1777, Vermont became the first portion of what would become the United States to abolish slavery (at the time Vermont was an independent nation). France abolished slavery in 1794. There were celebrations in 2007 to commemorate the 200th anniversary of the Abolition of the slave trade in the United Kingdom through the work of the British Anti-Slavery Society.
William Wilberforce received much of the credit although the groundwork was an anti-slavery essay by Thomas Clarkson. Wilberforce was also urged by his close friend, Prime Minister William Pitt the Younger, to make the issue his own, and was also given support by reformed Evangelical John Newton. The Slave Trade Act was passed by the British Parliament on March 25, 1807, making the slave trade illegal throughout the British Empire, Wilberforce also campaigned for abolition of slavery in the British Empire, which he lived to see in the Slavery Abolition Act 1833. After the 1807 act abolishing the slave trade was passed, these campaigners switched to encouraging other countries to follow suit, notably France and the British colonies. In 1839, the world's oldest international human rights organization, Anti-Slavery International, was formed in Britain by Joseph Sturge, which campaigned to outlaw slavery in other countries.
Between 1808 and 1860, the British West Africa Squadron seized approximately 1,600 slave ships and freed 150,000 Africans who were aboard. Action was also taken against African leaders who refused to agree to British treaties to outlaw the trade, for example against "the usurping King of Lagos", deposed in 1851. Anti-slavery treaties were signed with over 50 African rulers.
In the United States, abolitionist pressure produced a series of small steps towards emancipation. After January 1, 1808, the importation of slaves into the United States was prohibited, but not the internal slave trade, nor involvement in the international slave trade externally. Legal slavery persisted; and those slaves already in the U. S. were legally emancipated only in 1863. Many American abolitionists took an active role in opposing slavery by supporting the Underground Railroad. Violent clashes between anti-slavery and pro-slavery Americans included Bleeding Kansas, a series of political and armed disputes in 1854-1861 as to whether Kansas would join the United States as a slave or free state. By 1860 the total number of slaves reached almost four million, and the American Civil War, beginning in 1861, led to the end of slavery in the United States.
In 1863 Lincoln issued the Emancipation Proclamation, which freed slaves held in the Confederate States; the 13th Amendment to the U. S. Constitution (1865) prohibited slavery throughout the country.
In the 1860s, David Livingstone's reports of atrocities within the Arab slave trade in Africa stirred up the interest of the British public, reviving the flagging abolitionist movement. The Royal Navy throughout the 1870s attempted to suppress "this abominable Eastern trade", at Zanzibar in particular. In 1905, the French abolished indigenous slavery in most of French West Africa.
On December 10, 1948, the United Nations General Assembly adopted the Universal Declaration of Human Rights, which declared freedom from slavery is an internationally recognized human right. Article 4 of the Universal Declaration of Human Rights states:
No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms.
In 2014 for the first time in history major leaders of many religions, Buddhist, Anglican, Catholic, and Orthodox Christian, Hindu, Jewish, and Muslim, met to sign a shared commitment against modern-day slavery; the declaration they signed calls for the elimination of slavery and human trafficking by the year 2020. The signatories were: Pope Francis, Mātā Amṛtānandamayī (also known as Amma), Bhikkhuni Thich Nu Chân Không (representing Zen Master Thích Nhất Hạnh), Datuk K Sri Dhammaratana, Chief High Priest of Malaysia, Rabbi Abraham Skorka, Rabbi David Rosen, Abbas Abdalla Abbas Soliman, Undersecretary of State of Al Azhar Alsharif (representing Mohamed Ahmed El-Tayeb, Grand Imam of Al-Azhar), Grand Ayatollah Mohammad Taqi al-Modarresi, Sheikh Naziyah Razzaq Jaafar, Special advisor of Grand Ayatollah (representing Grand Ayatollah Sheikh Basheer Hussain al Najafi), Sheikh Omar Abboud, Justin Welby, Archbishop of Canterbury, and Metropolitan Emmanuel of France (representing Ecumenical Patriarch Bartholomew.)
Groups such as the American Anti-Slavery Group, Anti-Slavery International, Free the Slaves, the Anti-Slavery Society, and the Norwegian Anti-Slavery Society continue to campaign to rid the world of slavery.
Remnants of slavery.
In the case of freed slaves of the United States, many became share croppers and indentured servants. In this manner, some became tied to the very parcel of land into which they had been born a slave having little freedom or economic opportunity due to Jim Crow laws which perpetuated discrimination, limited education, promoted persecution without due process and resulted in continued poverty. Fear of reprisals such as unjust incarcerations and lynchings deterred upward mobility further.
Legal actions.
In November 2006, the International Labour Organization announced it will be seeking "to prosecute members of the ruling Myanmar junta for crimes against humanity" over the continuous unfree labour of its citizens by the military at the International Court of Justice. According to the International Labor Organization (ILO), an estimated 800,000 people are subject to forced labour in Myanmar.
The Ecowas Court of Justice is hearing the case of Hadijatou Mani in late 2008, where Ms. Mani hopes to compel the government of Niger to end slavery in its jurisdiction. Cases brought by her in local courts have failed so far.
Economics.
Economists have attempted to model the circumstances under which slavery (and variants such as serfdom) appear and disappear. One observation is that slavery becomes more desirable for landowners where land is abundant but labour is scarce, such that rent is depressed and paid workers can demand high wages. If the opposite holds true, then it becomes more costly for landowners to have guards for the slaves than to employ paid workers who can only demand low wages due to the amount of competition. Thus, first slavery and then serfdom gradually decreased in Europe as the population grew, but were reintroduced in the Americas and in Russia as large areas of new land with few people became available. In his books, "" and "Without Consent or Contract: the Rise and Fall of American Slavery, " Robert Fogel maintains that slavery was in fact a profitable method of production, especially on bigger plantations growing cotton that fetched high prices in the world market. It gave whites in the South higher average incomes than those in the North, but most of the money was spent on buying slaves and plantations.
Slavery is more common when the labour done is relatively simple and thus easy to supervise, such as large-scale growing of a single crop. It is much more difficult and costly to check that slaves are doing their best and with good quality when they are doing complex tasks. Therefore, slavery was seen as the most efficient method of production for large-scale crops like sugar and cotton, whose output was based on economies of scale. This enabled a gang system of labor to be prominent on large plantations where field hands were monitored and worked with factory-like precision. Each work gang was based on an internal division of labor that not only assigned every member of the gang to a precise task but simultaneously made his or her performance dependent on the actions of the others. The hoe hands chopped out the weeds that surrounded the cotton plants as well as excessive sprouts. The plow gangs followed behind, stirring the soil near the rows of cotton plants and tossing it back around the plants. Thus, the gang system worked like an early version of the assembly line later to be found in factories.
Critics since the 18th century have argued that slavery tends to retard technological advancement, since the focus is on increasing the number of slaves doing simple tasks rather than upgrading the efficiency of labour. Because of this, theoretical knowledge and learning in Greece—and later in Rome—was not applied to ease physical labour or improve manufacturing.
Adam Smith made the argument that free labor was economically better than slave labor, and argued further that slavery in Europe ended during the Middle Ages, and then only after both the church and state were separate, independent and strong institutions, that it is nearly impossible to end slavery in a free, democratic and republican forms of governments since many of its legislators or political figures were slave owners, and would not punish themselves, and that slaves would be better able to gain their freedom when there was centralized government, or a central authority like a king or the church. Similar arguments appear later in the works of Auguste Comte, especially when it comes to Adam Smith's belief in the separation of powers or what Comte called the "separation of the spiritual and the temporal" during the Middle Ages and the end of slavery, and Smith's criticism of masters, past and present. As Smith stated in the Lectures on Jurisprudence, "The great power of the clergy thus concurring with that of the king set the slaves at liberty. But it was absolutely necessary both that the authority of the king and of the clergy should be great. Where ever any one of these was wanting, slavery still continues. "
Slaves can be an attractive investment because the slave-owner only needs to pay for sustenance and enforcement. This is sometimes lower than the wage-cost of free labourers, because free workers earn more than sustenance, in these cases slaves have positive price. When the cost of sustenance and enforcement exceeds the wage rate, slave-owning would no longer be profitable, and owners would simply release their slaves. Slaves are thus a more attractive investment in high-wage environments, and environments where enforcement is cheap, and less attractive in environments where the wage-rate is low and enforcement is expensive.
Free workers also earn compensating differentials, whereby they are paid more for doing unpleasant work. Neither sustenance nor enforcement costs rise with the unpleasantness of the work, however, so slaves' costs do not rise by the same amount. As such, slaves are more attractive for unpleasant work, and less for pleasant work. Because the unpleasantness of the work is not internalised, being born by the slave rather than the owner, it is a negative externality and leads to over-use of slaves in these situations.
The weighted average global sales price of a slave is calculated to be approximately $340, with a high of $1,895 for the average trafficked sex slave, and a low of $40 to $50 for debt bondage slaves in part of Asia and Africa.
Worldwide slavery is a criminal offense but slave owners can get very high returns for their risk. According to researcher Siddharth Kara, the profits generated worldwide by all forms of slavery in 2007 were $91.2 billion. That is second only to drug trafficking in terms of global criminal enterprises. The weighted average annual profits generated by a slave in 2007 was $3,175, with a low of an average $950 for bonded labor and $29,210 for a trafficked sex slave. Approximately 40% of slave profits each year are generated by trafficked sex slaves, representing slightly more than 4% of the world's 29 million slaves.
Robert E. Wright has developed a model that helps to predict when firms (individuals, companies) will be more likely to use slaves rather than wage workers, indentured servants, family members, or other types of laborers.
Wage slavery.
The labour market, as institutionalised under today's market economic systems, has been criticised, especially by both mainstream socialists and anarcho-syndicalists, who utilise the term wage slavery as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.
For Marxists, labour-as-commodity, which is how they regard wage labour, provides an absolutely fundamental point of attack against capitalism. "It can be persuasively argued," noted one concerned philosopher, "that the conception of the worker's labour as a commodity confirms Marx's stigmatization of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it."
Apologies.
On May 21, 2001, the National Assembly of France passed the Taubira law, recognizing slavery as a crime against humanity. Apologies on behalf of African nations, for their role in trading their countrymen into slavery, remain an open issue since slavery was practiced in Africa even before the first Europeans arrived and the Atlantic slave trade was performed with a high degree of involvement of several African societies. The black slave market was supplied by well-established slave trade networks controlled by local African societies and individuals. Indeed, as already mentioned in this article, slavery persists in several areas of West Africa until the present day.
There is adequate evidence citing case after case of African control of segments of the trade. Several African nations such as the Calabar and other southern parts of Nigeria had economies depended solely on the trade. African peoples such as the Imbangala of Angola and the Nyamwezi of Tanzania would serve as middlemen or roving bands warring with other African nations to capture Africans for Europeans.
Several historians have made important contributions to the global understanding of the African side of the Atlantic slave trade. By arguing that African merchants determined the assemblage of trade goods accepted in exchange for slaves, many historians argue for African agency and ultimately a shared responsibility for the slave trade.
In 1999, President Mathieu Kerekou of Benin (formerly the Kingdom of Dahomey) issued a national apology for the central role Africans played in the Atlantic slave trade. Luc Gnacadja, minister of environment and housing for Benin, later said: "The slave trade is a shame, and we do repent for it." Researchers estimate that 3 million slaves were exported out of the Slave Coast bordering the Bight of Benin. President Jerry Rawlings of Ghana also apologized for his country's involvement in the slave trade.
The issue of an apology is linked to reparations for slavery and is still being pursued by a number of entities across the world. For example, the Jamaican Reparations Movement approved its declaration and action Plan.
In September 2006, it was reported that the UK government might issue a "statement of regret" over slavery. This was followed by a "public statement of sorrow" from Tony Blair on November 27, 2006, and a formal apology on March 14, 2007.
On February 25, 2007, the Commonwealth of Virginia resolved to 'profoundly regret' and apologize for its role in the institution of slavery. Unique and the first of its kind in the U. S., the apology was unanimously passed in both Houses as Virginia approached the 400th anniversary of the founding of Jamestown, where the first slaves were imported into North America in 1619.
Liverpool, which was a large slave trading port, apologized in 1999. On August 24, 2007, Mayor Ken Livingstone of London, United Kingdom, apologized publicly for Britain's role in colonial slave trade. "You can look across there to see the institutions that still have the benefit of the wealth they created from slavery," he said, pointing towards the financial district. He claimed that London was still tainted by the horrors of slavery. Specifically, London outfitted, financed, and insured many of the ships, which helped fund the building of London's docks. Jesse Jackson praised Livingstone, and added that reparations should be made, one of his common arguments.
On July 30, 2008, the United States House of Representatives passed a resolution apologizing for American slavery and subsequent discriminatory laws. In June 2009, the US Senate passed a resolution apologizing to African-Americans for the "fundamental injustice, cruelty, brutality, and inhumanity of slavery". The news was welcomed by President Barack Obama, the nation's first President of African descent. Some of President Obama's ancestors were slave owners.
In 2010, Libyan leader Muammar Gaddafi apologized for Arab involvement in the slave trade, saying: "I regret the behavior of the Arabs… They brought African children to North Africa, they made them slaves, they sold them like animals, and they took them as slaves and traded them in a shameful way."
Reparations.
There have been movements to achieve reparations for those formerly held as slaves, or sometimes their descendants. Claims for reparations for being held in slavery are handled as a civil law matter in almost every country. This is often decried as a serious problem, since former slaves' relative lack of money means they often have limited access to a potentially expensive and futile legal process. Mandatory systems of fines and reparations paid to an as yet undetermined group of claimants from fines, paid by unspecified parties, and collected by authorities have been proposed by advocates to alleviate this "civil court problem. " Since in almost all cases there are no living ex-slaves or living ex-slave owners these movements have gained little traction. In nearly all cases the judicial system has ruled that the statute of limitations on these possible claims has long since expired.
Other uses of the term.
The word "slavery" is often used as a pejorative to describe any activity in which one is coerced into performing.
In film.
Film has been the most influential medium in the presentation of the history of slavery to the general public around the world. The American film industry has had a complex relationship with slavery and until recent decades often avoided the topic. Films such as "Birth of a Nation" (1915) and "Gone with the Wind" (1939) became controversial because they gave a favorable depiction. The last favorable treatment was "Song of the South" from Disney in 1946. In 1940 "The Santa Fe Trail" gave a liberal but ambiguous interpretation of John Brown's attacks on slavery—the film does not know what to do with slavery. The Civil Rights Movement in the 1950s made defiant slaves into heroes. The question of slavery in American memory necessarily involves its depictions in feature films. 
Most Hollywood films used American settings, although "Spartacus" (1960), dealt with an actual revolt in the Roman Empire known as the Third Servile War. It failed and all the rebels were executed, but their spirit lived on according to the film. "The Last Supper" ("La última cena" in Spanish) was a 1976 film directed by Cuban Tomás Gutiérrez Alea about the teaching of Christianity to slaves in Cuba, and emphasizes the role of ritual and revolt. "Burn!" takes place on the imaginary Portuguese island of Queimada (where the locals speak Spanish) and it merges historical events that took place in Brazil, Cuba, Santo Domingo, Jamaica, and elsewhere. "Spartacus" stays surprisingly close to the historical record.
Historians agree that films have largely shaped historical memories, but they debate issues of accuracy, plausibility, moralism, sensationalism, how facts are stretched in search of broader truths, and suitability for the classroom. Berlin argues that critics complain if the treatment emphasizes historical brutality, or if it glosses over the harshness to highlight the emotional impact of slavery.

</doc>
<doc id="27993" url="http://en.wikipedia.org/wiki?curid=27993" title="September 17">
September 17

September 17 is the day of the year in the Gregorian calendar.

</doc>
<doc id="27995" url="http://en.wikipedia.org/wiki?curid=27995" title="Supply chain management">
Supply chain management

Supply Chain Management (SCM) is the management of the flow of goods and services. It includes the movement and storage of raw materials, work-in-process inventory, and finished goods from point of origin to point of consumption. Interconnected or interlinked networks, channels and node businesses are involved in the provision of products and services required by end customers in a supply chain. Supply chain management has been defined as the "design, planning, execution, control, and monitoring of supply chain activities with the objective of creating net value, building a competitive infrastructure, leveraging worldwide logistics, synchronizing supply with demand and measuring performance globally."
SCM draws heavily from the areas of operations management, logistics, procurement, and information technology, and strives for an integrated approach.
Origin of the term and definitions.
The term "supply chain management" entered the public domain when Keith Oliver, a consultant at Booz Allen Hamilton (now ), used it in an interview for the Financial Times in 1982. The term was slow to take hold. It gained currency in the mid-1990s, when a flurry of articles and books came out on the subject. In the late 1990s it rose to prominence as a management buzzword, and operations managers began to use it in their titles with increasing regularity.
Commonly accepted definitions of supply chain management include:
A supply chain, as opposed to supply chain management, is a set of organizations directly linked by one or more upstream and downstream flows of products, services, finances, or information from a source to a customer. Supply chain management is the management of such a chain.
Supply Chain strategy for a business is highly influenced by the nature of the product or services offered. Supply Chain of Innovative Product needs to be responsive one. Whereas Commodity products need efficient supply chain. 
Supply chain management software includes tools or modules used to execute supply chain transactions, manage supplier relationships, and control associated business processes.
Supply chain event management (SCEM) considers all possible events and factors that can disrupt a supply chain. With SCEM, possible scenarios can be created and solutions devised.
In many cases the supply chain includes the collection of goods after consumer use for recycling. Including third-party logistics or other gathering agencies as part of the RM re-patriation process is a way of illustrating the new endgame strategy...
Functions.
Supply chain management is a cross-functional approach that includes managing the movement of raw materials into an organization, certain aspects of the internal processing of materials into finished goods, and the movement of finished goods out of the organization and toward the end consumer. As organizations strive to focus on core competencies and becoming more flexible, they reduce their ownership of raw materials sources and distribution channels. These functions are increasingly being outsourced to other firms that can perform the activities better or more cost effectively. The effect is to increase the number of organizations involved in satisfying customer demand, while reducing managerial control of daily logistics operations. Less control and more supply chain partners led to the creation of the concept of supply chain management. The purpose of supply chain management is to improve trust and collaboration among supply chain partners, thus improving inventory visibility and the velocity of inventory movement.
Importance.
Organizations increasingly find that they must rely on effective supply chains, or networks, to compete in the global market and networked economy. In Peter Drucker's (1998) new management paradigms, this concept of business relationships extends beyond traditional enterprise boundaries and seeks to organize entire business processes throughout a value chain of multiple companies.
In recent decades, globalization, outsourcing, and information technology have enabled many organizations, such as Dell and Hewlett Packard, to successfully operate collaborative supply networks in which each specialized business partner focuses on only a few key strategic activities (Scott, 1993). This inter-organisational supply network can be acknowledged as a new form of organisation. However, with the complicated interactions among the players, the network structure fits neither "market" nor "hierarchy" categories (Powell, 1990). It is not clear what kind of performance impacts different supply network structures could have on firms, and little is known about the coordination conditions and trade-offs that may exist among the players. From a systems perspective, a complex network structure can be decomposed into individual component firms (Zhang and Dilts, 2004). Traditionally, companies in a supply network concentrate on the inputs and outputs of the processes, with little concern for the internal management working of other individual players. Therefore, the choice of an internal management control structure is known to impact local firm performance (Mintzberg, 1979).
In the 21st century, changes in the business environment have contributed to the development of supply chain networks. First, as an outcome of globalization and the proliferation of multinational companies, joint ventures, strategic alliances, and business partnerships, significant success factors were identified, complementing the earlier "just-in-time", lean manufacturing, and agile manufacturing practices. Second, technological changes, particularly the dramatic fall in communication costs (a significant component of transaction costs), have led to changes in coordination among the members of the supply chain network (Coase, 1998).
Many researchers have recognized supply network structures as a new organisational form, using terms such as "Keiretsu", "Extended Enterprise", "Virtual Corporation", "Global Production Network", and "Next Generation Manufacturing System". In general, such a structure can be defined as "a group of semi-independent organisations, each with their capabilities, which collaborate in ever-changing constellations to serve one or more markets in order to achieve some business goal specific to that collaboration" (Akkermans, 2001).
The security management system for supply chains is described in ISO/IEC 28000 and ISO/IEC 28001 and related standards published jointly by the ISO and the IEC.Supply Chain Management draws heavily from the areas of operations management, logistics, procurement, and information technology, and strives for an integrated approach.
Historical developments.
Six major movements can be observed in the evolution of supply chain management studies: creation, integration, and globalization (Movahedi et al., 2009), specialization phases one and two, and SCM 2.0.
Creation era.
The term "supply chain management" was first coined by Keith Oliver in 1982. However, the concept of a supply chain in management was of great importance long before, in the early 20th century, especially with the creation of the assembly line. The characteristics of this era of supply chain management include the need for large-scale changes, re-engineering, downsizing driven by cost reduction programs, and widespread attention to Japanese management practices. However, the term became widely adopted after the publication of the seminal book "Introduction to Supply Chain Management" in 1999 by Robert B. Handfield and Ernest L. Nichols, Jr., which published over 25,000 copies and was translated into Japanese, Korean, Chinese, and Russian.
Integration era.
This era of supply chain management studies was highlighted with the development of electronic data interchange (EDI) systems in the 1960s, and developed through the 1990s by the introduction of enterprise resource planning (ERP) systems. This era has continued to develop into the 21st century with the expansion of Internet-based collaborative systems. This era of supply chain evolution is characterized by both increasing value added and cost reductions through integration.
A supply chain can be classified as a stage 1, 2 or 3 network. In a stage 1–type supply chain, systems such as production, storage, distribution, and material control are not linked and are independent of each other. In a stage 2 supply chain, these are integrated under one plan and is ERP enabled. A stage 3 supply chain is one that achieves vertical integration with upstream suppliers and downstream customers. An example of this kind of supply chain is Tesco.
Globalization era.
The third movement of supply chain management development, the globalization era, can be characterized by the attention given to global systems of supplier relationships and the expansion of supply chains beyond national boundaries and into other continents. Although the use of global sources in organisations' supply chains can be traced back several decades (e.g., in the oil industry), it was not until the late 1980s that a considerable number of organizations started to integrate global sources into their core business. This era is characterized by the globalization of supply chain management in organizations with the goal of increasing their competitive advantage, adding value, and reducing costs through global sourcing.
Specialization era (phase I): outsourced manufacturing and distribution.
In the 1990s, companies began to focus on "core competencies" and specialization. They abandoned vertical integration, sold off non-core operations, and outsourced those functions to other companies. This changed management requirements, by extending the supply chain beyond the company walls and distributing management across specialized supply chain partnerships.
This transition also refocused the fundamental perspectives of each organization. Original equipment manufacturers (OEMs) became brand owners that required visibility deep into their supply base. They had to control the entire supply chain from above, instead of from within. Contract manufacturers had to manage bills of material with different part-numbering schemes from multiple OEMs and support customer requests for work-in-process visibility and vendor-managed inventory (VMI).
The specialization model creates manufacturing and distribution networks composed of several individual supply chains specific to producers, suppliers, and customers that work together to design, manufacture, distribute, market, sell, and service a product. This set of partners may change according to a given market, region, or channel, resulting in a proliferation of trading partner environments, each with its own unique characteristics and demands.
Specialization era (phase II): supply chain management as a service.
Specialization within the supply chain began in the 1980s with the inception of transportation brokerages, warehouse management, and non-asset-based carriers, and has matured beyond transportation and logistics into aspects of supply planning, collaboration, execution, and performance management.
Market forces sometimes demand rapid changes from suppliers, logistics providers, locations, or customers in their role as components of supply chain networks. This variability has significant effects on supply chain infrastructure, from the foundation layers of establishing and managing electronic communication between trading partners, to more complex requirements such as the configuration of processes and work flows that are essential to the management of the network itself.
Supply chain specialization enables companies to improve their overall competencies in the same way that outsourced manufacturing and distribution has done; it allows them to focus on their core competencies and assemble networks of specific, best-in-class partners to contribute to the overall value chain itself, thereby increasing overall performance and efficiency. The ability to quickly obtain and deploy this domain-specific supply chain expertise without developing and maintaining an entirely unique and complex competency in house is a leading reason why supply chain specialization is gaining popularity.
Outsourced technology hosting for supply chain solutions debuted in the late 1990s and has taken root primarily in transportation and collaboration categories. This has progressed from the application service provider (ASP) model from roughly 1998 through 2003, to the on-demand model from approximately 2003 through 2006, to the software as a service (SaaS) model currently in focus today.
Supply chain management 2.0 (SCM 2.0).
Building on globalization and specialization, the term "SCM 2.0" has been coined to describe both changes within supply chains themselves as well as the evolution of processes, methods, and tools to manage them in this new "era". The growing popularity of collaborative platforms is highlighted by the rise of TradeCard’s supply chain collaboration platform, which connects multiple buyers and suppliers with financial institutions, enabling them to conduct automated supply-chain finance transactions.
Web 2.0 is a trend in the use of the World Wide Web that is meant to increase creativity, information sharing, and collaboration among users. At its core, the common attribute of Web 2.0 is to help navigate the vast information available on the Web in order to find what is being bought. It is the notion of a usable pathway. SCM 2.0 replicates this notion in supply chain operations. It is the pathway to SCM results, a combination of processes, methodologies, tools, and delivery options to guide companies to their results quickly as the complexity and speed of the supply chain increase due to global competition; rapid price fluctuations; surging oil prices; short product life cycles; expanded specialization; near-, far-, and off-shoring; and talent scarcity.
SCM 2.0 leverages solutions designed to rapidly deliver results with the agility to quickly manage future change for continuous flexibility, value, and success. This is delivered through competency networks composed of best-of-breed supply chain expertise to understand which elements, both operationally and organizationally, deliver results, as well as through intimate understanding of how to manage these elements to achieve the desired results. The solutions are delivered in a variety of options, such as no-touch via business process outsourcing, mid-touch via managed services and software as a service (SaaS), or high-touch in the traditional software deployment model.
Business process integration.
Successful SCM requires a change from managing individual functions to integrating activities into key supply chain processes. In an example scenario, a purchasing department places orders as its requirements become known. The marketing department, responding to customer demand, communicates with several distributors and retailers as it attempts to determine ways to satisfy this demand. Information shared between supply chain partners can only be fully leveraged through process integration.
Supply chain business process integration involves collaborative work between buyers and suppliers, joint product development, common systems, and shared information. According to Lambert and Cooper (2000), operating an integrated supply chain requires a continuous information flow.
However, in many companies, management has concluded that optimizing product flows cannot be accomplished without implementing a process approach. The key supply chain processes stated by Lambert (2004) are:
Much has been written about demand management. Best-in-class companies have similar characteristics, which include the following:
One could suggest other critical supply business processes that combine these processes stated by Lambert, such as:
Customer relationship management concerns the relationship between an organization and its customers. Customer service is the source of customer information. It also provides the customer with real-time information on scheduling and product availability through interfaces with the company's production and distribution operations. Successful organizations use the following steps to build customer relationships:
Strategic plans are drawn up with suppliers to support the manufacturing flow management process and the development of new products. In firms whose operations extend globally, sourcing may be managed on a global basis. The desired outcome is a relationship where both parties benefit and a reduction in the time required for the product's design and development. The purchasing function may also develop rapid communication systems, such as electronic data interchange (EDI) and Internet linkage, to convey possible requirements more rapidly. Activities related to obtaining products and materials from outside suppliers involve resource planning, supply sourcing, negotiation, order placement, inbound transportation, storage, handling, and quality assurance, many of which include the responsibility to coordinate with suppliers on matters of scheduling, supply continuity, hedging, and research into new sources or programs.
Here, customers and suppliers must be integrated into the product development process in order to reduce the time to market. As product life cycles shorten, the appropriate products must be developed and successfully launched with ever-shorter time schedules in order for firms to remain competitive. According to Lambert and Cooper (2000), managers of the product development and commercialization process must:
The manufacturing process produces and supplies products to the distribution channels based on past forecasts. Manufacturing processes must be flexible in order to respond to market changes and must accommodate mass customization. Orders are processes operating on a just-in-time (JIT) basis in minimum lot sizes. Changes in the manufacturing flow process lead to shorter cycle times, meaning improved responsiveness and efficiency in meeting customer demand. This process manages activities related to planning, scheduling, and supporting manufacturing operations, such as work-in-process storage, handling, transportation, and time phasing of components, inventory at manufacturing sites, and maximum flexibility in the coordination of geographical and final assemblies postponement of physical distribution operations.
This concerns the movement of a finished product or service to customers. In physical distribution, the customer is the final destination of a marketing channel, and the availability of the product or service is a vital part of each channel participant's marketing effort. It is also through the physical distribution process that the time and space of customer service become an integral part of marketing. Thus it links a marketing channel with its customers (i.e., it links manufacturers, wholesalers, and retailers).
This includes not just the outsourcing of the procurement of materials and components, but also the outsourcing of services that traditionally have been provided in house. The logic of this trend is that the company will increasingly focus on those activities in the value chain in which it has a distinctive advantage and outsource everything else. This movement has been particularly evident in logistics, where the provision of transport, warehousing, and inventory control is increasingly subcontracted to specialists or logistics partners. Also, managing and controlling this network of partners and suppliers requires a blend of central and local involvement: strategic decisions are taken centrally, while the monitoring and control of supplier performance and day-to-day liaison with logistics partners are best managed locally.
Experts found a strong relationship from the largest arcs of supplier and customer integration to market share and profitability. Taking advantage of supplier capabilities and emphasizing a long-term supply chain perspective in customer relationships can both be correlated with a firm's performance. As logistics competency becomes a critical factor in creating and maintaining competitive advantage, measuring logistics performance becomes increasingly important, because the difference between profitable and unprofitable operations becomes narrower. A.T. Kearney Consultants (1985) noted that firms engaging in comprehensive performance measurement realized improvements in overall productivity. According to experts, internal measures are generally collected and analyzed by the firm, including cost, customer service, productivity, asset measurement, and quality. External performance is measured through customer perception measures and "best practice" benchmarking.
To reduce a company's cost and expenses, warehousing management is carrying the valuable role against operations. In the case of perfect storage and office with all convenient facilities in company level, reducing manpower cost, dispatching authority with on time delivery, loading & unloading facilities with proper area, area for service station, stock management system etc.
Theories.
There are gaps in the literature on supply chain management studies at present (2015): there is no theoretical support for explaining the existence or the boundaries of supply chain management. A few authors, such as Halldorsson et al. (2003), Ketchen and Hult (2006), and Lavassani et al. (2009), have tried to provide theoretical foundations for different areas related to supply chain by employing organizational theories. These theories include:
However, the unit of analysis of most of these theories is not the supply chain but rather another system, such as the firm or the supplier-buyer relationship. Among the few exceptions is the relational view, which outlines a theory for considering dyads and networks of firms as a key unit of analysis for explaining superior individual firm performance (Dyer and Singh, 1998).
One of the most recent developments about supply chain theory has been presented under the name of "Supply Chain Roadmap®", which is a method whereby an organization’s supply chain strategy can be reviewed in an organized and systematic approach in order to assure alignment of the supply chain with the business strategy. Method is supported in the most important and recognised theories and practices about supply chain strategy and business strategy. The method allows the characterisation of the supply chain under analysis by 42 factors in a single page view called "The Map" -a downloable version of the map is available on http://www.supplychainroadmap.com-, and allows the comparison of this supply chain with 6-Supply Chain Archetypes (Fast, Efficient, Continuous Flow, Agile, Custom Configured, Flexible), in order to find gaps between supply chain under analysis and the most proper supply chain archetype. Method is applied in four steps (Scope, Understanding, Evaluation, and, Redesign & Deployment).
Method was developed by Hernan David Perez, an experienced supply chain manager in several industrial sectors, and, professor and international speaker in supply chain strategy. An academic version of the method is available on , and a book about the professional version of the method is available. deepens and extended the concepts presented in his recognized article published by CSCMP's Supply Chain Quarterly in 2013, which was the third highest read article of the magazine in 2013, and, is a top search-result in Google for Supply Chain Strategy.
Supply chain centroids.
In the study of supply chain management, the concept of centroids has become an important economic consideration. A centroid is a location that has a high proportion of a country's population and a high proportion of its manufacturing, generally within 500 mi. In the US, two major supply chain centroids have been defined, one near Dayton, Ohio, and a second near Riverside, California.
The centroid near Dayton is particularly important because it is closest to the population center of the US and Canada. Dayton is within 500 miles of 60% of the US population and manufacturing capacity, as well as 60% of Canada's population. The region includes the interchange between I-70 and I-75, one of the busiest in the nation, with 154,000 vehicles passing through per day, 30–35% of which are trucks hauling goods. In addition, the I-75 corridor is home to the busiest north-south rail route east of the Mississippi River.
Tax efficient supply chain management.
Tax efficient supply chain management is a business model that considers the effect of tax in the design and implementation of supply chain management. As the consequence of globalization, cross-national businesses pay different tax rates in different countries. Due to these differences, they may legally optimize their supply chain and increase profits based on tax efficiency.
Sustainability and social responsibility in supply chains.
Supply chain sustainability is a business issue affecting an organization's supply chain or logistics network, and is frequently quantified by comparison with SECH ratings, which uses a triple bottom line incorporating economic, social, and environmental aspects. SECH ratings are defined as social, ethical, cultural, and health' footprints. Consumers have become more aware of the environmental impact of their purchases and companies' SECH ratings and, along with non-governmental organizations (NGOs), are setting the agenda for transitions to organically grown foods, anti-sweatshop labor codes, and locally produced goods that support independent and small businesses. Because supply chains may account for over 75% of a company's carbon footprint, many organizations are exploring ways to reduce this and thus improve their SECH rating.
For example, in July 2009, Wal-Mart announced its intentions to create a global sustainability index that would rate products according to the environmental and social impacts of their manufacturing and distribution. The index is intended to create environmental accountability in Wal-Mart's supply chain and to provide motivation and infrastructure for other retail companies to do the same.
It has been reported that companies are increasingly taking environmental performance into account when selecting suppliers. A 2011 survey by the Carbon Trust found that 50% of multinationals expect to select their suppliers based upon carbon performance in the future and 29% of suppliers could lose their places on 'green supply chains' if they do not have adequate performance records on carbon.
The US Dodd–Frank Wall Street Reform and Consumer Protection Act, signed into law by President Obama in July 2010, contained a supply chain sustainability provision in the form of the Conflict Minerals law. This law requires SEC-regulated companies to conduct third party audits of their supply chains in order to determine whether any tin, tantalum, tungsten, or gold (together referred to as "conflict minerals") is mined or sourced from the Democratic Republic of the Congo, and create a report (available to the general public and SEC) detailing the due diligence efforts taken and the results of the audit. The chain of suppliers and vendors to these reporting companies will be expected to provide appropriate supporting information.
Incidents like the 2013 Savar building collapse with more than 1,100 victims have led to widespread discussions about corporate social responsibility across global supply chains. Wieland and Handfield (2013) suggest that companies need to audit products and suppliers and that supplier auditing needs to go beyond direct relationships with first-tier suppliers. They also demonstrate that visibility needs to be improved if supply cannot be directly controlled and that smart and electronic technologies play a key role to improve visibility. Finally, they highlight that collaboration with local partners, across the industry and with universities is crucial to successfully managing social responsibility in supply chains.
Components.
Management components.
SCM components are the third element of the four-square circulation framework. The level of integration and management of a business process link is a function of the number and level of components added to the link (Ellram and Cooper, 1990; Houlihan, 1985). Consequently, adding more management components or increasing the level of each component can increase the level of integration of the business process link.
Literature on business process re-engineering buyer-supplier relationships, and SCM suggests various possible components that should receive managerial attention when managing supply relationships. Lambert and Cooper (2000) identified the following components:
However, a more careful examination of the existing literature leads to a more comprehensive understanding of what should be the key critical supply chain components, or "branches" of the previously identified supply chain business processes—that is, what kind of relationship the components may have that are related to suppliers and customers. Bowersox and Closs (1996) state that the emphasis on cooperation represents the synergism leading to the highest level of joint achievement. A primary-level channel participant is a business that is willing to participate in responsibility for inventory ownership or assume other financial risks, thus including primary level components (Bowersox and Closs, 1996). A secondary-level participant (specialized) is a business that participates in channel relationships by performing essential services for primary participants, including secondary level components, which support primary participants. Third-level channel participants and components that support primary-level channel participants and are the fundamental branches of secondary-level components may also be included.
Consequently, Lambert and Cooper's framework of supply chain components does not lead to any conclusion about what are the primary- or secondary-level (specialized) supply chain components (see Bowersox and Closs, 1996, p. 93) —that is, which supply chain components should be viewed as primary or secondary, how these components should be structured in order to achieve a more comprehensive supply chain structure, and how to examine the supply chain as an integrative one (See above sections 2.1 and 3.1).
Reverse supply chain.
Reverse logistics is the process of managing the return of goods. It is also referred to as "aftermarket customer services". Any time money is taken from a company's warranty reserve or service logistics budget, one can speak of a reverse logistics operation.
Reverse logistics is also the process of managing the return of goods from store, which the returned goods are sent back to warehouse and after that either warehouse scrap the goods or send them back to supplier for replacement depending on the warranty of the merchadise.
Systems and value.
Supply chain systems configure value for those that organize the networks. Value is the additional revenue over and above the costs of building the network. Co-creating value and sharing the benefits appropriately to encourage effective participation is a key challenge for any supply system. Tony Hines defines value as follows: "Ultimately it is the customer who pays the price for service delivered that confirms value and not the producer who simply adds cost until that point".
Global applications.
Global supply chains pose challenges regarding both quantity and value. Supply and value chain trends include:
These trends have many benefits for manufacturers because they make possible larger lot sizes, lower taxes, and better environments (e.g., culture, infrastructure, special tax zones, or sophisticated OEM) for their products. There are many additional challenges when the scope of supply chains is global. This is because with a supply chain of a larger scope, the lead time is much longer, and because there are more issues involved, such as multiple currencies, policies, and laws. The consequent problems include different currencies and valuations in different countries, different tax laws, different trading protocols, and lack of transparency of cost and profit.
Supply Chain Consulting.
Supply-chain consulting is the providing of expert knowledge in order to assess the productivity of a supply-chain and, ideally, enhance the productivity.
Supply chain is nowadays a strategic asset and can be a significant source of competitive advantage, role of the consultant is to help the management adding value to the whole process through the various sectors from the order of the raw materials to the final product.
On this regard, firms are either building internal teams of consultants to tackle the issue or using external ones, (companies choose between these two approaches taking into consideration various factory mostly based on the overall strategy of the company).
The use of external consultant is a common practice among companies', normally due to their experience. The whole consulting process generally involves the analysis of the entire supply-chain process, including the countermeasures or correctives to take to achieve a better overall performance.
Companies in the field
Supply-chain consultancies vary in their ranges of services and sizes, major players in the field include
Certification.
There are several certification programs for SCM staff development, including the Association for Operations Management (APICS), International Purchasing and supply chain management institute (IPSCMI),the International Supply Chain Education Alliance (ISCEA), and the Institute of Supply Chain Management (IOSCM). The APICS certification is called the Certified Supply Chain Professional (CSCP); the ISCEA certification is called the Certified Supply Chain Manager (CSCM). Additionally, the Institute for Supply Management is developing a certification called the Certified Professional in Supply Management (CPSM), focused on procurement and sourcing, also called supply management. The Purchasing Management Association of Canada is the main Canadian certifying body; its designations have global recipricocity. The main designation is the Supply Chain Management Professional (SCMP), with several others progressing toward it.
Topics addressed by selected professional supply chain certification programmes
Supply chain management college level education.
A university with a primary focus on logistics and supply chain management is Kühne Logistics University in Hamburg, Germany. It is non profit and supported by Kühne-Foundaton of the logistics entrepreneur Klaus-Michael Kühne. Many other top universities offer supply chain management programs at the undergraduate and graduate levels. Some of them are:
United States
United Kingdom
Canada

</doc>
<doc id="27998" url="http://en.wikipedia.org/wiki?curid=27998" title="Synchronized swimming">
Synchronized swimming

Synchronized swimming is a hybrid form of swimming, dance and gymnastics, consisting of swimmers (either solos, duets, trios, combos, or teams) performing a synchronized routine of elaborate moves in the water, accompanied by music. Although solos are not used in the Olympics, athletes can perform solos and compete in most other competitions. A recent addition to the Olympic repertoire is the event of mixed pairs, allowing men to compete with a female duet partner. 
Synchronized swimming demands advanced water skills, and requires great strength, endurance, flexibility, grace, artistry and precise timing, as well as exceptional breath control when upside down underwater. During lifts, (where up to six people act as the platform, one person acts as a base, and one and/or two people act as flyers) swimmers are required not to touch the bottom - yet pull off an outstanding lift.
Aside from the new mixed-pair event, Olympic and World Championship competition is not open to men, but other international and national competitions allow male competitors in every event. Both USA Synchro and Synchro Canada allow men to compete with women. – Most European countries allow men to compete also, France even allows male only podiums, according to the number of participants. In the past decade more men are becoming involved in the sport and a global biannual competition called Men's Cup has been steadily growing.
Competitors show off their strength, flexibility, and aerobic endurance required to perform difficult routines. Swimmers perform two routines for the judges, one technical and one free, as well as age group routines and figures.
Synchronized swimming is both an individual and team sport. Swimmers compete individually during figures, and then as a team during the routine. Figures are made up of a combination of skills and positions that often require control, strength, and flexibility. Swimmers are ranked individually for this part of the competition. The routine involves teamwork and synchronization. It is choreographed to music and often has a theme.
Synchronized swimming is governed internationally by FINA (Federation Internationale de Natation).
History.
At the turn of the 20th century, synchronized swimming was known as water ballet. The first recorded competition was in 1891 in Berlin, Germany. Many swim clubs were formed around that time, and the sport simultaneously developed in Canada. As well as existing as a sport, it often constituted a popular addition to Music Hall evenings, in the larger variety theatres of London or Glasgow which were equipped with huge on-stage water tanks for the purpose.
In 1907, Australian Annette Kellerman popularized the sport when she performed in a glass tank as an underwater ballerina in the New York Hippodrome. After experimenting with various diving actions and stunts in the water, Katherine Curtis started one of the first water ballet clubs at the University of Chicago, where the team began executing strokes, "tricks," and floating formations. On May 27, 1939, the first U.S. synchronized swimming competition took place at Wright Junior College between Wright and the Chicago Teachers' College.
In 1924, the first competition in North America was in Montreal, with Peg Seller as the first champion.
Other important pioneers for the sport are Beulah Gundling, Käthe Jacobi, Marion Kane Elston, Dawn Bean, Billie MacKellar, Teresa Anderson, Gail Johnson, Gail Emery, Charlotte Davis, Mary Derosier, Norma Olsen and Clark Leach. Charlotte Davis coached Tracie Ruiz and Candy Costie, who won the gold medal in duet synchronized swimming at the 1984 Olympics in Los Angeles.
In the 1940s and 1950s, before men were banned from national competitions in World War II, 
Donn Squire and Bert Hubbard were important male synchronized swimmers in the USA.
Origins.
In 1933 & 1934, Katherine Whitney Curtis organized a show, "The Kay Curtis Modern Mermaids," for the World Exhibition in Chicago. The announcer was Norman Ross, who introduced the sport as "Synchronized Swimming" for the first time. The term eventually became standardized through the AAU, but Curtis still used the term rhythmic swimming in her book, "Rhythmic Swimming: A Source Book of Synchronized Swimming and Water Pageantry" (Minneapolis: Burgess Publishing Co., 1936). See a photo of , 1946.(HIIIII)
Curtis made Synchronized Swimming an officially recognized sport by the AAU in December 1941, but would herself be transferred overseas in 1943. She was the Recreation Director of the Red Cross under Generals Patton & Eisenhower, during which time she produced the first international aquacade in Caserta, Italy. She was the Director of Travel in post-war Europe until 1962. She was officially recognized along with Annette Kellerman by the Helms Hall of Fame in 1959 - Curtis as with the primary development of Synchronized Swimming. In 1979, the International Swimming Hall of Fame inducted Curtis with similar accolades.
A National A.A.U. champion swimmer, Esther Williams, would also largely popularize synchronized swimming during WWII and after, through (often elaborately staged) scenes in Hollywood films such as "Bathing Beauty" (1944), "Million Dollar Mermaid" (1952), and "Jupiter's Darling" (1955). In the 1970s and 80s, Ft. Lauderdale swimming champion Charkie Phillips revived water ballet on television with The Krofftettes in "The Brady Bunch Hour" (1976–77), NBC's "The Big Show" (1980), and then on screen with Miss Piggy in "The Great Muppet Caper" (1981)
Synchro as an Olympic sport in post war.
The first Olympic demonstration was at the 1952 Olympic Games, where the Helsinki officials welcomed Kay Curtis and lit a torch in her honor. Curtis died in 1980, but synchronized swimming did not become an official Olympic sport until the 1984 Summer Olympic Games. It was not until 1968 that synchronized swimming became officially recognized by FINA as the fourth water sport next to swimming, platform diving and water polo.
From 1984 through 1992, the Summer Olympic Games featured solo and duet competitions, but they both were dropped in 1996 in favor of team competition. At the 2000 Olympic Games, however, the duet competition was restored and is now featured alongside the team competition. 
World championships and synchro.
Synchronised swimming is part of the World Aquatics Championships since the beginning. From 1973 through 2001, the World Aquatics Championships featured solo, duet and team competitions. In 2003, a free routine combination, comprising elements of solo, duet and team, was add. In 2005, it was renamed free combination. In 2007, solo, duet and team events were split between technical and free routines. Since 2007, seven World championship titles are at stake.
Basic skills.
Sculls.
Sculls (hand movements used to propel the body) are the most essential part to synchronized swimming. Commonly used sculls include support scull, stationary scull, propeller scull, alligator scull, torpedo scull, split-arm scull, barrel scull, and paddle scull. The support scull is used most often to support the body while a swimmer is performing upside down. Support scull is performed by holding the upper arms against the sides of the body and the lower arms at 90-degree angles to the body, with hands facing the bottom of the pool. The lower arms are then moved back and forth while maintaining the right angle. The resulting pressure against the hands allows the swimmer to hold their legs above water while swimming. Other sculls used in training include propeller and reverse propeller.
Eggbeater.
The "eggbeater kick" is another important skill of synchronized swimming. It is a form of treading water that allows for stability and height above the water while leaving the hands free to perform strokes. An average eggbeater height is usually around chest level. Eggbeater is used in all "arm" sections, a piece of coreography in which the swimmer is upright, often with one or both arms in the air. Another variation is a boost, which is executed through an eggbeater buildup and a strong whip kick, propelling the swimmer out of the water vertically.
Eggbeating for a considerable period is also referred to as an "aquabob" and is used to build propulsion under water prior to a boost or pop-up.
Lifts.
A lift is when members of the team propel another teammate relatively high out of the water. They are quite common in routines of older age groups and higher skill levels.
There are many variations on lifts, often dubbed "highlights". These can include partner lifts, float patterns or other areas of unique, artistic choreography intended to impress the judges and audience.
Parts of a successful lift.
There are three parts to every lift in synchronized swimming: The top (or "flyer"), the base, and the pushers. 
Positions.
There are hundreds of different regular positions that can be used to create seemingly infinite combinations. These are a few basic and commonly used ones:
Further descriptions of technical positions can be found on the website.
Routine.
Routines are composed of "figures" (leg movements) and arm or stroke sections. They often incorporate lifts or throws, an impressive move in which a group of swimmers lift or throw another swimmer out of the water. Swimmers are synchronized both to each other and to the music. During a routine swimmers can never use the bottom of the pool for support, but rather depend on sculling motions with the arms, and eggbeater kick to keep afloat. After the performance, the swimmers are judged and scored on their performance based on technical merit and artistic impression. Technical skill, patterns, expression, and synchronization are all critical to achieving a high score.
Technical vs. free routines.
Depending on the competition level, swimmers will perform a "technical" routine with predetermined elements that must be performed in a specific order. The technical routine acts as a replacement for the figure event, and is usually used only in senior and collegiate level meets. In addition to the technical routine, the swimmers will perform a longer "free" routine, which has no requirements and is a chance for the swimmers to get creative and innovative with their choreography.
Length of routines.
The type of routine and competition level determines the length of routines. Routines typically last two and a half to five minutes long, the shortest being solos, with length added as the number of swimmers are increased (duets, trios, teams, and combos). Age and skill level are other important factors in determining the required routine length.
Scoring.
Routines are scored on a scale of 100, with points for both artistic impression and technical merit. The artistic mark is worth 50% of the total and the technical mark is worth 50%.
Preparation.
When performing routines in competition and practice, competitors wear a rubber noseclip to keep water from entering their nose when submerged. Some swimmers wear ear-plugs to keep the water out of their ears. Hair is worn in a bun and flavorless gelatin, Knox, is applied to keep hair in place; a decorative headpiece is bobby-pinned to the bun. Occasionally, swimmers wear custom-made swimming caps in place of their hair in buns. 
Competitors wear custom swimsuits and headpieces, usually elaborately decorated with bright fabric and sequins to reflect the music to which they are swimming. The costume and music are not judged (but marks will be taken off if the headpiece falls off any swimmer while she is swimming the routine) but factor into the overall performance and "artistic impression." Heavy eye makeup is often worn to help portray the emotions involved with the routine; it helps to accentuate the eyes of each swimmer. (This makeup style is often the center of criticism and ridicule. Some argue that it shows a lack of taste and minimizes the athleticism of the sport. Other artistic sports, such as gymnastics and ice skating, do not employ the same makeup practices.) 
Underwater speakers ensure that swimmers can hear the music and aid their ability to synchronize with each other. Routines are prepared and set to counts in the music, to further ensure synchronization. Coaches use underwater speakers to communicate with the swimmers during practice. Goggles, though worn during practice, are not permitted during routine competition.
Competitions.
Figures.
A standard meet begins with the swimmers doing "figures", which are progressions between positions performed individually without music. All swimmers must compete wearing the standard black swimsuit and white swimcap, as well as goggles and a noseclip. Figures are performed in front of a panel of 5 judges who score individual swimmers from 1 to 10 (10 being the best). The figure competition prefaces the routine events. 
In the United States.
In the United States, competitors are divided into groups by age. The seven age groups are: 10 and Under, 11–12, 13–15, 16–17, 18–19, Junior (elite 15–18), Senior (elite 18+), Collegiate, and Master. In addition to these groups, younger swimmers may be divided by ability into 3 levels: Novice, Intermediate, and Age Group. Seasons range in length, and some swimmers participate year-round in competitions. There are many levels of competition, including but not limited to: State, Regional, Zone, Age Group National, and US Junior and Senior Opens. Each swimmer may compete in up to three of the following routine events: solo, duet, trio, combo (consisting of eight to ten swimmers), and team (consisting of four to eight swimmers). Figure scores are combined with routines to determine the final rankings. USA Synchro's annual intercollegiate championships have been dominated by The Ohio State University, Stanford University, and The University of the Incarnate Word.
In Canada.
In Canada, synchronized swimming has an age-based Structure system as of 2010 with age groups 10 & under, 12 & under, and 13-15 for the provincial levels. There is also a skill level which is 13-15 and juniors (16-18) known as national stream, as well as competition at the Masters and University levels. 13-15 age group and 16-18 age group are national stream athletes that fall in line with international age groups – 15 and Under and Junior (16–18) and Senior (18+) level athletes.
There are also the Wildrose age group. This is for competitors before they reach 13-15 national stream. Wildrose ranges from Tier 8 and under to 16 and over provincial/wildrose. These are also competitive levels. There are also the recreational levels which are called "stars". Synchro Canada requires that a competitor must pass Star 3 before entering Tier 1. To get into a Tier a swimmer must take a test for that Tier. In these tests, the swimmer must be able to perform the required movements for the level. (Canada no longer uses Tiers as a form of level placement).
The Canadian University Synchronized Swimming League is intended for Canadian Swimmers who wish to continue their participation in the sport, as well as offering a "Novice" category for those new to the sport. Traditionally, the top teams hail from McGill University, Queens University and the University of Ottawa. 
Injuries.
In their book 2012 "Concussions and Our Kids", Dr. Robert Cantu and Mark Hyman reported that Dr. Bill Moreau, who serves as medical director for the U.S. Olympic Committee (USOC), reported that during a two-week training session in Colorado Springs about a dozen women athletes participating suffered a 50% concussion rate. Dr. Moreau noted, "These women are superior athletes. They're in the pool eight hours a day. Literally, they're within inches of one another, sculling and paddling. As they go through their various routines, they're literally kicking each other in the head." As a result, the USOC initiated a process of reassessing concussion awareness and prevention for all sports. Dr. Moreau says that many athletes in non-collision sports "aren't thinking about head injury and don't know they've had concussions."

</doc>
<doc id="27999" url="http://en.wikipedia.org/wiki?curid=27999" title="Human swimming">
Human swimming

Human swimming is the self-propulsion of a person through water or another liquid, usually for the purpose of recreation, sport, exercise, or survival. Locomotion is achieved through coordinated movement of the limbs, the body, or both. Humans are able to hold their breath underwater and undertake rudimentary locomotive swimming within weeks of birth, as an evolutionary response.
Swimming is consistently found to be among the top recreational activities undertaken by the public, and in some countries, swimming lessons are a compulsory part of the educational curriculum. As a formalized sport, swimming features in a range of local, national, and international competitions, including every modern summer Olympics, which occurs every four years.
Science.
Swimming relies on the natural buoyancy of the human body. On average, the body has a relative density of 0.98 compared to water, which causes the body to float. However, buoyancy varies on the basis of both body composition and the salinity of the water. Higher levels of body fat and saltier water both lower the relative density of the body and increase its floatation.
Since the human body is only slightly less dense than water, water supports the weight of the body during swimming. As a result, swimming is "low-impact" compared to land activities such as running. The density and viscosity of water also create resistance for objects moving through the water. Swimming strokes use this resistance to create propulsion, but this same resistance also generates drag on the body.
This means that hydrodynamics are an important factor in stroke technique in terms of swimming faster, and swimmers wishing to swim faster, or wishing to tire less, will try to reduce the drag caused by the body's motion through the water. In order to be more hydrodynamic, swimmers can either increase the power of their strokes or reduce their water resistance, although increasing power to overcome resistance needs to increase by a factor of three to achieve the same effect as reducing resistance.
Efficient swimming by reducing water resistance involves having a horizontal water position, rolling the body in order to reduce the breadth of the body in the water, and extending the arms as far as possible in order to reduce wave resistance.
Infant swimming.
Human babies demonstrate an innate swimming or diving reflex from newborn until the age of approximately 6 months. Other mammals also demonstrate this phenomenon (see mammalian diving reflex). The diving response involves apnoea, reflex bradycardia, and peripheral vasoconstriction; in other words a baby immersed in water will spontaneously hold his or her breath, slow his/her heartrate, and reduce blood circulation to the extremities such as fingers and toes.
Technique.
Swimming can be undertaken using a wide range of different styles, known as 'strokes,' and these strokes are used for different purposes, or to distinguish between classes in competitive swimming. It is not necessary to use a defined stroke for propulsion through the water, and untrained swimmers may use a 'doggy paddle' of arm and leg movements, similar to the way four-legged animals swim.
There are four main strokes used in competition and recreation swimming: the front crawl, the breaststroke, the backstroke and the butterfly. Competitive swimming in Europe started around 1800, mostly using the breaststroke. In 1873 John Arthur Trudgen introduced the trudgen to Western swimming competitions, after copying the front crawl used by Native Americans, but substituting a scissor kick for the traditional flutter kick in order to reduce splashing. The butterfly stroke was developed in the 1930s and was considered a variant of the breaststroke until it was accepted as a separate style in 1952.
Other strokes exist for specific purposes, such as training or rescue, and it is also possible to adapt strokes to avoid using parts of the body, either to isolate certain body parts, such as swimming with arms only or legs only to train them harder, or for use by amputees or those suffering from paralysis.
Historic record.
Swimming has been recorded since prehistoric times, and the earliest records of swimming date back to Stone Age paintings from around 7,000 years ago. Written references date from 2000 BC. Some of the earliest references include the Epic of Gilgamesh, the Iliad, the Odyssey, the Bible (Ezekiel 47:5, Acts 27:42, Isaiah 25:11), Beowulf, and other sagas. In 1538, Nikolaus Wynmann, a German professor of languages, wrote the first swimming book, "The Swimmer or A Dialogue on the Art of Swimming" ("Der Schwimmer oder ein Zweigespräch über die Schwimmkunst").
Purpose.
There are many reasons why people swim, from swimming as a recreational pursuit to swimming as a necessary part of a job or other activity. Swimming may also be used to rehabilitate injuries, especially various cardiovascular injuries and muscle injuries. 
Recreation.
Many swimmers swim for recreation, with swimming consistently ranking as one of the physical activities people are most likely to take part in. Recreational swimming can also be used for exercise, relaxation, or rehabilitation. The support of the water, and the reduction in impact, makes swimming accessible for people who are unable to undertake activities such as running.
Health.
Swimming is primarily a cardiovascular/aerobic exercise due to the long exercise time, requiring a constant oxygen supply to the muscles, except for short sprints where the muscles work anaerobically. As with most aerobic exercise, swimming is believed to reduce the harmful effects of stress. Swimming can also improve posture.
Sport.
Swimming as a sport predominantly involves competition among participants to be the fastest over a given distance under self-propulsion. Different distances are swum in different levels of competition. For example, swimming has been an Olympic sport since 1896, and the current program includes events from 50m to 1500m in length, across all four main strokes and medley. 
The sport is governed internationally by the Fédération Internationale de Natation (FINA), and competition pools for FINA events are 25 or 50 meters in length. In the United States of America, USA Swimming is the governing body and a pool 25 yards in length is commonly used for competition. 
Other swimming and water-related sporting disciplines including diving, synchronized swimming and water polo, as well as sports which include a swimming element, such as the triathlon and the modern pentathlon.
Occupation.
Some occupations require the workers to swim. For example, abalone- and pearl-divers swim and dive to obtain an economic benefit, as do spear fishermen.
Swimming is used to rescue people in the water who are in distress, including exhausted swimmers, non-swimmers who have accidentally entered the water, and others who have come to harm on the water. Lifeguards or volunteer lifesavers are deployed at many pools and beaches worldwide to fulfill this purpose, and they, as well as rescue swimmers, may use specific swimming styles for rescue purposes.
Swimming is also used in marine biology to observe plants and animals in their natural habitat. Other sciences use swimming, for example Konrad Lorenz swam with geese as part of his studies of animal behavior.
Swimming also has military purposes. Military swimming is usually done by special forces, such as Navy SEALs. Swimming is used to approach a location, gather intelligence, engage in sabotage or combat, and subsequently depart. This may also include airborne insertion into water or exiting a submarine while it is submerged. Due to regular exposure to large bodies of water, all recruits in the United States Navy, Marine Corps, and Coast Guard are required to complete basic swimming or water survival training.
Swimming is also a professional sport. Companies sponsor swimmers who have the skills to compete at the international level. Many swimmers compete competitively in order to represent their home country in the Olympics. Cash awards are also given at many of the major competitions for breaking records. Professional swimmers may also earn a living as entertainers, performing in water ballets.
Locomotion.
Locomation by swimming over brief distances is frequent when alternatives are precluded. There have been cases of political refugees swimming in the Baltic Sea and of people jumping in the water and swimming ashore from vessels not intended to reach land where they planned to go. Swimming travel is central to the plot of the motion picture "Welcome". US president John F. Kennedy led his sailors swimming island to island after his torpedo boat was sunk in World War II, and his senator brother Ted Kennedy claimed to have left Chappaquiddick Island by swimming.
Risks.
There are many risks associated with voluntary or involuntary human presence in water, which may result in death directly or through drowning asphyxiation. Swimming is both the goal of much voluntary presence, and the prime means of regaining land in accidental situations.
Most recorded water deaths fall into these categories:
An adult with fully developed and extended lungs has generally positive or at least neutral buoyancy, and can float with modest effort when calm and in still water. A small child has negative buoyancy and will either sink rapidly or have to make a sustained effort to stay near the surface.
Hypothermia and dehydration also kill directly, without causing drowning, even when the person wears a life vest.
Less common are 
Around any pool area, safety equipment is often considered important and is a zoning requirement for most residential pools in the United States. Supervision by personnel trained in rescue techniques is required at most competitive swimming meets and public pools.
Lessons.
Traditionally, children were considered not able to swim independently until 4 years of age,
although now infant swimming lessons are recommended to prevent drowning.
In Sweden, Denmark, Norway, Estonia and Finland, the curriculum for the fifth grade (fourth grade in Estonia) states that all children should learn how to swim as well as how to handle emergencies near water. Most commonly, children are expected to be able to swim 200 m – of which at least 50 m on their back – after first falling into deep water and getting their head under water. Even though about 95 percent of Swedish school children know how to swim, drowning remains the third most common cause of death among children.
In both the Netherlands and Belgium swimming lessons under school time ("schoolzwemmen", school swimming) are supported by the government. Most schools provide swimming lessons. There is a long tradition of swimming lessons in the Netherlands and Belgium, the Dutch translation for the breaststroke swimming style is even "schoolslag" (schoolstroke). The children learn a variant of the breaststroke, which is technically not entirely correct. In France, swimming is a compulsory part of the curriculum for primary schools. Children usually spend one semester per year learning swimming during CE1/CE2/CM1 (2nd, 3rd and 4th grade). 
In many places, swimming lessons are provided by local swimming pools, both those run by the local authority and by private leisure companies. Many schools also include swimming lessons into their Physical Education curricula, provided either in the schools' own pool, or in the nearest public pool. 
In the UK, the "Top-ups scheme" calls for school children who cannot swim by the age of 11 to receive intensive daily lessons. These children who have not reached Great Britain's National Curriculum standard of swimming 25 metres by the time they leave primary school will be given a half-hour lesson every day for two weeks during term-time.
In Canada and Mexico there has been a call for swimming to be included in the public school curriculum.
In USA there is the Infant Swimming Resource (ISR) initiative that provides lessons for infant children, to cope with emergency situation when they have fallen into water. They are taught how to roll-back-to-float (hold their breath underwater, to roll onto their back, to float unassisted, rest and breathe until help arrives).
Clothing and equipment.
Swimsuits.
Standard everyday clothing is usually impractical for swimming and is unsafe under some circumstances. Most cultures today expect swimsuits to be worn for aquatic activities.
Men's swimsuits commonly resemble shorts, or briefs. Casual men's swimsuits (for example, boardshorts) are rarely skintight, unlike competitive swimwear, like jammers or diveskins. In most cases, boys and men swim with their upper body exposed, except in countries where custom or law prohibits it in a public setting, or for practical reasons such as sun protection.
Modern women's swimsuits are generally skintight, covering the pubic region and the breasts (See bikini). Women's swimwear may also cover the midriff as well. Women's swimwear is often a fashion statement, and whether it is modest or not is a subject of debate by many groups, religious and secular.
Competitive swimwear is built so that the wearer can swim faster and more efficiently. Modern competitive swimwear is skintight and lightweight. There are many kinds of competitive swimwear for each gender. It is used in aquatic competitions, such as water polo, swim racing, diving, and rowing.
Wetsuits provide both thermal insulation and floatation. Many swimmers lack buoyancy in the leg. The wetsuit reduces density, and therefore improves buoyancy while swimming. It provides insulation by absorbing some of the surrounding water, which then heats up when in direct contact with skin. The wetsuit is the usual choice for those who swim in cold water for long periods of time, as it reduces susceptibility to hypothermia.
Some people also choose to wear no clothing while swimming. This is known as skinny dipping. It was common for males to swim naked in a public setting up to the early 20th century. Today, skinny dipping can be a rebellious activity, or merely a casual one.

</doc>
<doc id="28002" url="http://en.wikipedia.org/wiki?curid=28002" title="Simple machine">
Simple machine

A simple machine is a mechanical device that changes the direction or magnitude of a force. In general, they can be defined as the simplest mechanisms that use mechanical advantage (also called leverage) to multiply force. Usually the term refers to the six classical simple machines which were defined by Renaissance scientists: 
A simple machine uses a single applied force to do work against a single load force. Ignoring friction losses, the work done on the load is equal to the work done by the applied force. The machine can increase the amount of the output force, at the cost of a proportional decrease in the distance moved by the load. The ratio of the output to the applied force is called the "mechanical advantage".
Simple machines can be regarded as the elementary "building blocks" of which all more complicated machines (sometimes called "compound machines") are composed. For example, wheels, levers, and pulleys are all used in the mechanism of a bicycle. The mechanical advantage of a compound machine is just the product of the mechanical advantages of the simple machines of which it is composed.
Although they continue to be of great importance in mechanics and applied science, modern mechanics has moved beyond the view of the simple machines as the ultimate building blocks of which all machines are composed, which arose in the Renaissance as a neoclassical amplification of ancient Greek texts on technology. The great variety and sophistication of modern machine linkages, which arose during the Industrial Revolution, is inadequately described by these six simple categories. As a result, various post-Renaissance authors have compiled expanded lists of "simple machines", often using terms like "basic machines", "compound machines", or "machine elements" to distinguish them from the classical simple machines above. By the late 1800s, Franz Reuleaux had identified hundreds of machine elements, calling them "simple machines". Models of these devices may be found at Cornell University's KMODDL website.
History.
The idea of a simple machine originated with the Greek philosopher Archimedes around the 3rd century BC, who studied the Archimedean simple machines: lever, pulley, and screw. He discovered the principle of mechanical advantage in the lever. Archimedes' famous remark with regard to the lever: "Give me a place to stand on, and I will move the Earth." (Greek: δῶς μοι πᾶ στῶ καὶ τὰν γᾶν κινάσω) expresses his realization that there was no limit to the amount of force amplification that could be achieved by using mechanical advantage. Later Greek philosophers defined the classic five simple machines (excluding the inclined plane) and were able to roughly calculate their mechanical advantage. For example, Heron of Alexandria (ca. 10–75 AD) in his work "Mechanics" lists five mechanisms that can "set a load in motion"; lever, windlass, pulley, wedge, and screw, and describes their fabrication and uses. However the Greeks' understanding was limited to the statics of simple machines; the balance of forces, and did not include dynamics; the tradeoff between force and distance, or the concept of work.
During the Renaissance the dynamics of the "Mechanical Powers", as the simple machines were called, began to be studied from the standpoint of how far they could lift a load, in addition to the force they could apply, leading eventually to the new concept of mechanical work. In 1586 Flemish engineer Simon Stevin derived the mechanical advantage of the inclined plane, and it was included with the other simple machines. The complete dynamic theory of simple machines was worked out by Italian scientist Galileo Galilei in 1600 in "Le Meccaniche" ("On Mechanics"), in which he showed the underlying mathematical similarity of the machines. He was the first to understand that simple machines do not create energy, only transform it.
The classic rules of sliding friction in machines were discovered by Leonardo da Vinci (1452–1519), but remained unpublished in his notebooks. They were rediscovered by Guillaume Amontons (1699) and were further developed by Charles-Augustin de Coulomb (1785).
Frictionless analysis.
Although each machine works differently mechanically, the way they function is similar mathematically. In each machine, a force formula_1 is applied to the device at one point, and it does work moving a load, formula_2 at another point. Although some machines only change the direction of the force, such as a stationary pulley, most machines multiply the magnitude of the force by a factor, the mechanical advantage 
that can be calculated from the machine's geometry and friction.
Simple machines do not contain a source of energy, so they cannot do more work than they receive from the input force. A simple machine with no friction or elasticity is called an "ideal machine". Due to conservation of energy, in an ideal simple machine, the power output (rate of energy output) at any time formula_4 is equal to the power input formula_5
The power output equals the velocity of the load formula_7 multiplied by the load force formula_8. Similarly the power input from the applied force is equal to the velocity of the input point formula_9 multiplied by the applied force formula_10.
Therefore
Therefore the mechanical advantage of a frictionless machine is equal to the "velocity ratio", the ratio of input velocity to output velocity
The "velocity ratio" of the machine is also equal to the ratio of the distance the output point moves to the corresponding distance the input point moves
This can be calculated from the geometry of the machine. For example, the velocity ratio of the lever is equal to the ratio of its lever arms.
The mechanical advantage can be greater or less than one: 
In the screw, which uses rotational motion, the input force should be replaced by the torque, and the velocity by the angular velocity the shaft is turned.
Friction and efficiency.
All real machines have friction, which causes some of the input power to be dissipated as heat. If formula_17 is the power lost to friction, from conservation of energy 
The efficiency formula_19 of a machine is a number between 0 and 1 defined as the ratio of power out to the power in, and is a measure of the energy losses
As above, the power is equal to the product of force and velocity, so
Therefore
So in non-ideal machines, the mechanical advantage is always less than the velocity ratio by the product with the efficiency "η". So a machine that includes friction will not be able to move as large a load as a corresponding ideal machine using the same input force.
Compound machines.
A "compound machine" is a machine formed from a set of simple machines connected in series with the output force of one providing the input force to the next. For example a bench vise consists of a lever (the vise's handle) in series with a screw, and a simple gear train consists of a number of gears (wheels and axles) connected in series.
The mechanical advantage of a compound machine is the ratio of the output force exerted by the last machine in the series divided by the input force applied to the first machine, that is
Because the output force of each machine is the input of the next, formula_24, this mechanical advantage is also given by
Thus, the mechanical advantage of the compound machine is equal to the product of the mechanical advantages of the series of simple machines that form it
Similarly, the efficiency of a compound machine is also the product of the efficiencies of the series of simple machines that form it
Self-locking machines.
In many simple machines, if the load force "Fout" on the machine is high enough in relation to the input force "Fin", the machine will move backwards, with the load force doing work on the input force. So these machines can be used in either direction, with the driving force applied to either input point. For example, if the load force on a lever is high enough, the lever will move backwards, moving the input arm backwards against the input force. These are called ""reversible", "non-locking" or "overhauling" machines, and the backward motion is called "overhauling". However in some machines, if the frictional forces are high enough, no amount of load force can move it backwards, even if the input force is zero. This is called a "self-locking", "nonreversible", or "non-overhauling"" machine. These machines can only be set in motion by a force at the input, and when the input force is removed will remain motionless, "locked" by friction at whatever position they were left.
Self-locking occurs mainly in those machines with large areas of sliding contact between moving parts: the screw, inclined plane, and wedge:
A machine will be self-locking if and only if its efficiency "η" is below 50%:
Whether a machine is self-locking depends on both the friction forces (coefficient of static friction) between its parts, and the distance ratio "din/dout" (ideal mechanical advantage). If both the friction and ideal mechanical advantage are high enough, it will self-lock.
Proof.
When a machine moves in the forward direction from point 1 to point 2, with the input force doing work on a load force, from conservation of energy the input work formula_29 is equal to the sum of the work done on the load force formula_30 and the work lost to friction formula_31
If the efficiency is below 50%
formula_33
From (1)
When the machine moves backward from point 2 to point 1 with the load force doing work on the input force, the work lost to friction formula_31 is the same
So the output work is
Thus the machine self-locks, because the work dissipated in friction is greater than the work done by the load force moving it backwards even with no input force
Modern machine theory.
Kinematic chains.
Simple machines are elementary examples of kinematic chains that are used to model mechanical systems ranging from the steam engine to robot manipulators. The bearings that form the fulcrum of a lever and that allow the wheel and axle and pulleys to rotate are examples of a kinematic pair called a hinged joint. Similarly, the flat surface of an inclined plane and wedge are examples of the kinematic pair called a sliding joint. The screw is usually identified as its own kinematic pair called a helical joint.
Two levers, or cranks, are combined into a planar four-bar linkage by attaching a link that connects the output of one crank to the input of another. Additional links can be attached to form a six-bar linkage or in series to form a robot.
Classification of machines.
The identification of simple machines arises from a desire for a systematic method to invent new machines. Therefore, an important concern is how simple machines are combined to make more complex machines. One approach is to attach simple machines in series to obtain compound machines.
However, a more successful strategy was identified by Franz Reuleaux, who collected and studied over 800 elementary machines. He realized that a lever, pulley, and wheel and axle are in essence the same device: a body rotating about a hinge. Similarly, an inclined plane, wedge, and screw are a block sliding on a flat surface.
This realization shows that it is the joints, or the connections that provide movement, that are the primary elements of a machine. Starting with four types of joints, the revolute joint, sliding joint, cam joint and gear joint, and related connections such as cables and belts, it is possible to understand a machine as an assembly of solid parts that connect these joints.

</doc>
<doc id="28005" url="http://en.wikipedia.org/wiki?curid=28005" title="Semi-Automatic Ground Environment">
Semi-Automatic Ground Environment

The Semi-Automatic Ground Environment (SAGE) was a system of large computers and associated networking equipment that coordinated data from many radar sites and processed it to produce a single unified image of the airspace over a wide area. SAGE directed and controlled the NORAD response to a Soviet air attack, operating in this role from the late 1950s into the 1980s. Its enormous computers and huge displays remain a part of cold war lore, and a common prop in movies such as "Dr. Strangelove" and .
Powering SAGE were the largest computers ever built, IBM's AN/FSQ-7. Each SAGE Direction Center (DC) contained two FSQ-7's for redundancy, filling two floors of a large cube-shaped concrete building. The upper two floors contained offices, operator stations, and a single two-story radar display visible to most of the DC's personnel. Information was fed to the DC's from a network of radar stations as well as readiness information from various defence sites. The computers, based on the raw radar data, developed "tracks" for the reported targets, and automatically calculated which defences were within range. Subsets of the data were then sent to the many operator consoles, where the operators used light guns to select targets onscreen for further information, select one of the available defences, and issue commands to attack. These commands would then be automatically sent to the defence site via teleprinter. Later additions to the system allowed SAGE's tracking data to be sent directly to CIM-10 Bomarc missiles and some of the US Air Force's interceptor aircraft in-flight, directly updating their autopilots to maintain an intercept course without operator intervention. Each SAGE DC also forwarded data to a Combat Center (CC) for "supervision of the several sectors within the division" ("each combat center [had] the capability to coordinate defense for the whole nation").:51 Connecting the various sites was an enormous network of telephones, modems and teleprinters.
SAGE became operational in the late 1950s and early 1960s at a combined cost of billions of dollars. It was noted that the deployment cost more than the Manhattan Project, which it was, in a way, defending against. Throughout its development there were continual questions about its real ability to deal with large attacks, and several tests by Strategic Air Command bombers suggested the system was "leaky". Nevertheless, SAGE was the backbone of NORADs air defence system into the 1980s, by which time the tube-based FSQ-7's were increasingly costly to maintain and completely outdated. Today the same command and control task is carried out by microcomputers, based on the same basic underlying data.
Background.
Computerized command and control for United States air defense was conceived in July 1945 during the Signal Corps' Project 414A contracted to Bell Laboratories:207 after "employment of an American version of CDS", the British air defense C2 system, had been identified for air defense command and control on June 12. The Priority Permanent System with the initial (priority) radar stations was completed in 1952:223 as a "manual air defense system" (e.g., NORAD/ADC used a "Plexiglas plotting board" at the Ent command center.) The Permanent System radar stations included 3 subsequent phases of deployments and by June 30, 1957, had 119 "Fixed CONUS" radars, 29 "Gap-filler low altitude" radars, and 23 control centers". At "the end of 1957, ADC operated 182 radar stations [and] 17 control centers … 32 [stations] had been added during the last half of the year as low-altitude, unmanned gap-filler radars. The total consisted of 47 gap-filler stations, 75 Permanent System radars, 39 semimobile radars, 19 Pinetree stations,…1 Lashup -era radar and a single Texas Tower".:223 "On 31 December 1958, USAF ADC had 187 operational land-based radar stations" (74 were "P-sites", 29 "M-sites", 13 "SM-sites", & 68 "ZI Gap Fillers").
The December 1949 "Air Defense Systems Engineering Committee" led by Dr. George Valley had recommended computerized networking for "radar stations guarding the northern air approaches to the United States" (e.g., in Canada). After a January 1950 meeting, Valley and Jay Forrester proposed using the Whirlwind I (completed 1951) for air defense. On August 18, 1950, when the "1954 Interceptor" requirements were issued, the USAF "noted that manual techniques of aircraft warning and control would impose “intolerable” delays":484 (AMC published "Electronic Air Defense Environment for 1954" in December .) During February–August 1951 at the new Lincoln Laboratory, the USAF conducted Project Claude which concluded an improved air defense system was needed. The "Summer Study Group" of scientists in 1952 recommended "computerized air direction centers…to be ready by 1954."
IBM's "Project High" assisted under their October 1952 Whirlwind subcontract with Lincoln Laboratory,:210 and a 1952 USAF Project Lincoln "fullscale study" of "a large scale integrated ground control system" resulted in the SAGE approval "first on a trial basis in 1953".:128 The USAF had decided by April 10, 1953, to cancel the competing ADIS (based on CDS), and the University of Michigan’s Aeronautical Research Center withdrew in the spring.:289 ARDC planned to "finalize a production contract for the Lincoln Transition System".:201 Similarly, the July 22, 1953, report by the Bull Committee (NSC 159) identified completing the Mid-Canada Line as the top priority and "on a second-priority-basis: the Lincoln automated system" (the decision to control Bomarc with the automated system was also in 1953.)
Development.
The 2 computers in each AN/FSQ-7 were based on the IBM 701, used an improved version of the Whirlwind I magnetic core memory. On October 28, 1953, the Air Force Council recommended 1955 funding for "ADC to convert to the Lincoln automated system":193 ("redesignated the SAGE System in 1954").:201 The "experimental SAGE subsector, located in Lexington, Mass., was completed in 1955…with a prototype AN/FSQ-7…known as XD-1" (single computer system in Building F). In 1955, Air Force personnel began IBM training at the Kingston, New York, prototype facility, and the "4620th Air Defense Wing (experimental SAGE) was established at Lincoln Laboratory"
On May 3, 1956, General Partridge presented "CINCNORAD’s Operational Concept for Control of Air Defense Weapons" to the Armed Forces Policy Council, and a June 1956 symposium presentation identified advanced programming methods of SAGE code. For SAGE consulting Western Electric and Bell Telephone Laboratories formed the Air Defense Engineering Service (ADES), which was contracted in January 1954. IBM delivered the FSQ-7 computer's prototype in June 1956, and Kingston's XD-2 with dual computers guided a Cape Canaveral BOMARC to a successful aircraft intercept on August 7, 1958.:197 Initially contracted to RCA, the AN/FSQ-7 production units were started by IBM in 1958 (32 DCs were planned:207 for networking NORAD regions.) IBM's production contract developed 56 SAGE computers for $½ billion (~$18 million per computer pair in each FSQ-7)—cf. the $2 billion WWII Manhattan Project.
General Operational Requirements (GOR) 79 and 97 were "the basic USAF documents guiding development and improvement of [the semi-automatic] ground environment.:97 Prior to fielding the AN/FSQ-7 centrals, the USAF initially deployed "pre-SAGE semiautomatic intercept systems" (AN/GPA-37) to Air Defense Direction Centers, ADDCs:11 (e.g., at "NORAD Control Centers"). On April 22, 1958, NORAD approved Nike AADCPs to be collocated with the USAF manual ADDCs at Duncanville Air Force Station TX, Olathe Air Force Station KS, Belleville Air Force Station IL, and Osceola Air Force Station KS.
Deployment.
In 1957, SAGE System groundbreaking at McChord AFB was for DC-12 where the "electronic brain" began arriving in November 1958, and the "first SAGE regional battle post [CC-01] began operating in Syracuse, New York in early 1959".:263 BOMARC "crew training was activated January 1, 1958", and AT&T "hardened many of its switching centers, putting them in deep underground bunkers", The North American Defense Objectives Plan (NADOP 59-63) submitted to Canada in December 1958 scheduled 5 Direction Centers and 1 Combat Center to be complete in Fiscal Year 1959, 12 DCs and 3 CCs complete at the end of FY 60, 19 DC/4 CC FY 61, 25/6 FY 62, and 30/10 FY 63. On June 30 NORAD ordered that "Air Defense Sectors (SAGE) were to be designated as NORAD sectors", (the military reorganization had begun when effective April 1, 1958, CONAD "designated four SAGE sectors -- New York, Boston, Syracuse, and Washington -- as CONAD Sectors".):7
SAGE Geographic Reorganization: The SAGE Geographic Reorganization Plan of July 25, 1958, by NORAD was "to provide a means for the orderly transition and phasing from the manual to the SAGE system." The plan identified deactivation of the Eastern, Central, and Western Region/Defense Forces on July 1, 1960, and "current manual boundaries" were to be moved to the new "eight SAGE divisions" (1 in Canada, "the 35th") as soon as possible. Manual divisions "not to get SAGE computers were to be phased out" along with their Manual Air Defense Control Centers at the headquarters base: "9th [at] Geiger Field… 32d, Syracuse AFS… 35th, Dobbins AFB… 58th, Wright-Patterson AFB… 85th, Andrews AFB"). The 26th SAGE Division (New York, Boston, Syracuse & Bangor SAGE sectors)--the 1st of the SAGE divisions—became operational at Hancock Field on 1 January 1959 after the redesignation started for AC&W Squadrons (e.g., the Highlands P-9 unit became the 646th Radar Squadron (SAGE) October 1.):156 Additional sectors included the Los Angeles Air Defense Sector (SAGE) designated in February 1959. A June 23 JCS memorandum approved the new "March 1959 Reorganization Plan" for HQ NORAD/CONAD/ADC.:5
Project Wild Goose teams of Air Material Command personnel installed c. 1960 the Ground Air Transmit Receive stations for the SAGE TDDL (in April 1961, Sault Ste Marie was the first operational sector with TDDL.) … By the middle of 1960, AMC had determined that about 800,000 manhours (involving 130 changes) would be required to bring the F-106 fleet to the point where it would be a valuable adjunct to the air defense system. Part of the work (Project Broad Jump) was accomplished by Sacramento Air Materiel Area. The remainder (Project Wild Goose) was done at ADC bases by roving AMC field assistance teams supported by ADC maintenance personnel. (cited by Volume I p. 271 & Schaffel p. 325) After a September 1959 experimental ATABE test between an "abbreviated" AN/FSQ-7 staged at Fort Banks and the Lexington XD-1, the 1961 "SAGE/Missile Master test program" conducted large-scale field testing of the ATABE "mathematical model" using radar tracks of actual SAC and ADC aircraft flying mock penetrations into defense sectors. Similarly conducted was the joint SAC-NORAD Sky Shield II exercise followed by Sky Shield III on 2 September 1962 On July 15, 1963, ESD's CMC Management Office assumed "responsibilities in connection with BMEWS, Space Track, SAGE, and BUIC." The Chidlaw Building's computerized NORAD/ADC Combined Operations Center in 1963 became the highest echelon of the SAGE computer network when operations moved from Ent AFB's 1954 manual Command Center to the partially underground "war room". Also in 1963, radar stations were renumbered (e.g., Cambria AFS was redesignated from P-2 to Z-2 on July 31) and the vacuum-tube SAGE System was completed (and obsolete).:9
On "June 26, 1958,…the New York sector became operational":207 and on December 1, 1958, the Syracuse sector's DC-03 was operational ("the SAGE system [did not] become operational until January 1959.") Construction of CFB North Bay in Canada was started in 1959 for a bunker ~700 ft underground (operational October 1, 1963), and by 1963 the system had 3 Combat Centers. The 23 SAGE centers included 1 in Canada, and the "SAGE control centers reached their full 22 site deployments in 1961 (out of 46 originally planned)." The completed Minot AFB blockhouse never received an AN/FSQ-7 (the April 1, 1959, Minot Air Defense Sector consolidated with the Grand Forks ADS on March 1, 1963).
Description.
The environment allowed radar station personnel to monitor the radar data and systems' status (e.g., Arctic Tower radome pressure) and to use the range height equipment to process height requests from Direction Center (DC) personnel. DCs received the Long Range Radar Input from the sector's radar stations, and DC personnel monitored the radar tracks and IFF data provided by the stations, requested height-finder radar data on targets, and monitored the computer's evaluation of which fighter aircraft or Bomarc missile site could reach the threat first. The DC's "NORAD sector commander's operational staff" could designate fighter intercept of a target or, using the Senior Director's keyed console in the Weapons Direction room, launch a Bomarc intercept with automatic Q-7 guidance of the surface-to-air missile to a final homing dive (equipped fighters eventually were automatically guided to intercepts).
The "NORAD sector direction center (NSDC) [also had] air defense artillery director (ADAD) consoles [and an Army] ADA battle staff officer", and the NSDC automatically communicated crosstelling of "SAGE reference track data" to/from adjacent sectors' DCs and to 10 Nike Missile Master AADCPs. Forwardtelling automatically communicated data from multiple DCs to a 3-story Combat Center (CC) usually at one of the sector's DCs (cf. planned Hamilton AFB CC-05 near the Beale AFB DC-18) for coordinating the air battle in the NORAD region (multiple sectors) and which forwarded data to the NORAD Command Center (Ent AFB, 1963 Chidlaw Building, & 1966 Cheyenne Mountain). NORAD's integration of air warning data (at the ADOC) along with space surveillance, intelligence, and other data allowed attack assessment of an Air Defense Emergency for alerting the SAC command centers (465L SACCS nodes at Offutt AFB & The Notch), the Pentagon/Raven Rock NMCC/ANMCC, and the public via CONELRAD radio stations.
SAGE System.
The Burroughs 416L SAGE System (ESD Project 416L, Semi Automatic Ground Environment System) was the Cold War network of computer sets and centrals that created the display and control environment (SAGE) for operation of the separate radars and to provide command guidance for ground-controlled interception by air defense aircraft in the "SAGE Defense System" ("Air Defense Weapons System"). Burroughs Corporation was the prime contractor for SAGE electronic equipment which included 134 Burroughs AN/FST-2 Coordinate Data Transmitting Sets (CDTS) at radar stations and other sites, the AN/FSQ-7 Combat Direction Central at 24 Direction Centers, and the AN/FSQ-8 Combat Control Central at 8 Combat Centers. The 2 computers of each AN/FSQ-7 together weighing 275 STf used about ⅓ of the DC's 2nd floor space and at ~$50 per instruction had approximately 125,000 "computer instructions support[ing] actual operational air-defense mission" processing. The AN/FSQ-7 at Luke AFB had additional memory (32K total) and was used as a "computer center for all other" DCs. Project 416L was the USAF predecessor of NORAD, SAC, and other military organizations' "Big L" computer systems (e.g., 438L Air Force Intelligence Data Handling System & 496L Space Detection and Tracking System).
Network communications: The SAGE network of computers connected by a "Digital Radar Relay" (SAGE data system) used AT&T voice lines, microwave towers, switching centers (e.g., SAGE NNX 764 was at Delta, Utah & 759 at Mounds, Oklahoma), etc.; and AT&T's "main underground station" was in Kansas (Fairview) with other bunkers in Connecticut (Cheshire), California (Santa Rosa), Iowa (Boone) and Maryland (Hearthstone Mountain). CDTS modems at automated radar stations transmitted range and azimuth, and the Air Movements Identification Service (AMIS) provided air traffic data to the SAGE System. Radar tracks by telephone calls (e.g., from Manual Control Centers in the Albuquerque, Minot, and Oklahoma City sectors) could be entered via consoles of the 4th floor "Manual Inputs" room adjacent to the "Communication Recording-Monitoring and VHF" room. In 1966, SAGE communications were integrated into the AUTOVON Network.
SAGE Sector Warning Networks (cf. NORAD Division Warning Networks) provided the radar netting communications for each DC and eventually also allowed transfer of command guidance to autopilots of TDDL-equipped interceptors for vectoring to targets via the Ground to Air Data Link Subsystem and the Ground Air Transmit Receive (GATR) network of radio sites for "HF/VHF/UHF voice & TDDL" each generally co-located at a CDTS site. SAGE Direction Centers and Combat Centers were also nodes of NORAD's Alert Network Number 1, and SAC Emergency War Order Traffic included "Positive Control/Noah's Ark instructions" through northern NORAD radio sites to confirm or recall SAC bombers if "SAC decided to launch the alert force before receiving an execution order from the JCS".
A SAGE System ergonomic test at Luke AFB in 1964 "showed conclusively that the wrong timing of human and technical operations was leading to frequent truncation of the flight path tracking system" (Harold Sackman).:9 SAGE software development was "grossly underestimated":370 (60,000 lines in September 1955): "the biggest mistake [of] the SAGE computer program was [underestimating the] jump from the 35,000 [WWI] instructions … to the more than 100,000 instructions on the" AN/FSQ-8. NORAD conducted a "Sage/Missile Master Integration/ECM-ECCM Test" in 1963, and although SAGE used AMIS input of air traffic information, the 1959 plan developed by the July 1958 USAF Air Defense Systems Integration Division for SAGE Air Traffic Integration (SATIN) was cancelled by the DoD.
Radar stations.
SAGE radar stations, including 78 DEW Line sites in December 1961, provided radar tracks to DCs and had frequency diversity (FD) radars United States Navy picket ships also provided radar tracks, and seaward radar coverage was provided. By the late 1960s EC-121 Warning Star aircraft based at Otis AFB MA and McClellan AFB CA provided radar tracks via automatic data link to the SAGE System. Civil Aeronautics Administration radars were at some stations (e.g., stations of the Joint Use Site System), and the ARSR-1 Air Route Surveillance Radar rotation rate had to be modified "for SAGE [IFF/SIF] Modes III and IV" ("antenna gear box modification" for compatibility with FSQ-7 & FSG-1 centrals.):21
Interceptors.
ADC aircraft such as the F-94 Starfire, F-89 Scorpion, F-101B Voodoo, and F-4 Phantom were controlled by SAGE GCI. The F-104 Starfighter was "too small to be equipped with [SAGE] data link equipment" and used voice-commanded GCI,:229 but the F-106 Delta Dart was equipped for the automated data link (ADL). The ADL was designed to allow Interceptors that reached targets to transmit real-time tactical friendly and enemy movements and to determine whether sector defence reinforcement was necessary. Familiarization flights allowed SAGE weapons directors to fly on two-seat interceptors to observe GCI operations. Surface-to-air missile installations for CIM-10 Bomarc interceptors were displayed on SAGE consoles.
Improvements.
Partially solid-state AN/FST-2B and later AN/FYQ-47 computers replaced the AN/FST-2, and sectors without AN/FSQ-7 centrals requiring a "weapon direction control device" for USAF air defense used the solid-state AN/GSG-5 CCCS instead of the AN/GPA-73 recommended by ADC in June 1958. Back-Up Interceptor Control (BUIC) with CCCS dispersed to radar stations for survivability allowed a diminished but functional SAGE capability. In 1962, Burroughs "won the contract to provide a military version of its D825" modular data processing system for BUIC II. BUIC II was 1st used at North Truro Z-10 in 1966, and the Hamilton AFB BUIC II was installed in the former MCC building when it was converted to a SAGE Combat Center in 1966 (CC-05). On June 3, 1963, the Direction Centers at Marysville CA, Marquette/K I Sawyer AFB (DC-14) MI, Stewart AFB NY (DC-02), and Moses Lake WA (DC-15) were planned for closing and at the end of 1969, only 6 CONUS SAGE DCs remained (DC-03, -04, -10, -12, -20, & -21) all with the vacuum tube AN/FSQ-7 centrals.:47 In 1966, NORAD Combined Operations Center operations at Chidlaw transferred to the Cheyenne Mountain Operations Center (425L System) and in December 1963, the DoD approved solid state replacement of Martin AN/FSG-1 centrals:317 with the AN/GSG-5 and subsequent Hughes AN/TSQ-51. The "416L/M/N Program Office" at Hanscom Field had deployed the BUIC III by 1971 (e.g., to Fallon NAS), and the initial BUIC systems were phased out 1974-5. ADC had been renamed Aerospace Defense Command on January 15, 1968, and its general surveillance radar stations transferred to ADTAC in 1979 when the ADC major command was broken up (space surveillance stations went to SAC and the Aerospace Defense Center was activated as a DRU.)
Replacement and disposition.
For airborne command posts, "as early as 1962 the Air Force began exploring possibilites for an Airborne Warning and Control System (AWACS)",:266 and the Strategic Defense Architecture (SDA-2000) planned an integrated air defense and air traffic control network. The USAF declared full operational capability of the 1st 7 Joint Surveillance System ROCCs on December 23, 1980, with Hughes AN/FYQ-93 systems, and many of the SAGE radar stations became JSS sites (e.g., San Pedro Hill Z-39 became FAA Ground Equipment Facility J-31.) The North Bay AN/FSQ-7 was dismantled and sent to Boston's Computer Museum. In 1996, AN/FSQ-7 components were moved to Moffett Federal Airfield for storage and later moved to the Computer History Museum in Mountain View, California. The last AN/FSQ-7 centrals were demolished at McChord AFB (August 1983) and Luke AFB (February 1984). AN/FSQ-7 equipment was used as TV/movie props (e.g., in Time Tunnel and Voyage to the Bottom of the Sea).
Historiography.
SAGE histories include a 1983 special issue of the "Annals of the History of Computing", and various personal histories were published, e.g., Valley in 1985 and Jacobs in 1986. In 1998, the SAGE System was identified as 1 of 4 "Monumental Projects", and a SAGE lecture presented the vintage film "In Your Defense" followed by anecdotal information from Les Earnest, Jim Wong, and Paul Edwards. In 2013, a copy of a 1950s cover girl image programmed for SAGE display was identified as the "earliest known figurative computer art". Company histories identifying employees' roles in SAGE include the 1981 "System Builders: The Story of SDC" and the 1998 "Architects of Information Advantage: The MITRE Corporation Since 1958".
References.
</ref>

</doc>
<doc id="28009" url="http://en.wikipedia.org/wiki?curid=28009" title="Sydney underground railways">
Sydney underground railways

Sydney, Australia has several sections of underground railway. These sections of railway are extensions of suburban main line services and are not a completely segregated true metro system. The underground sections, especially the City Circle, typically have frequent services. The railways are run by Sydney Trains, an agency of the government of New South Wales.
Underground lines.
Sydney has four underground lines.
Currently commencing construction is: 
There are also plans for: 
There were previously plans for other lines, such as:
Disused tunnels.
Sydney has several disused tunnels. The best known of these are those leading out of St James station. There are also two instances of disused tunnels and platforms on the Eastern Suburbs line at Redfern and Central (see below). These stations have these disused platforms adjacent (but walled off from) the platforms currently in use. There are also stub tunnels at North Sydney railway station for a never constructed Manly to Mona Vale line.
From the top of the northern stair to platform 10 at Redfern Station it is possible to view the unfinished structure for the low-level "up" (toward Central) Southern Suburbs platform. The associated never-used tunnels are quite complex. Immediately to your left is the (surface level) stub tunnel for the "down" Southern Suburbs track. This short tunnel exits on the northern side of Lawson Street road bridge. As a matter of interest, there are at least nine railway tunnels under the suburb of Redfern: some in use, some never used. 
The never-used platforms at Central, numbered 26 and 27, lie above the Eastern Suburbs Railway platforms and have never been used for trains. Like St. James station, these stations have stub tunnels, although they are much shorter. 
There are three tunnels formerly part of the Metropolitan Goods Lines. One runs underneath Railway Square, between the Central station railway yards and the Powerhouse Museum, the others underneath Pyrmont and Glebe. The first tunnel is now only used to service the Powerhouse Museum. The former railway from the Powerhouse Museum to Dulwich Hill, including Pyrmont and Glebe tunnels, has been converted to form part of the Dulwich Hill light rail line from Central station.
Also of interest is a tunnel connecting the Eveleigh rail yards, on the southern side of the main line, to the northern side of the main line, running beneath Redfern station. This tunnel remains in use for the transfer of empty trains from Central (terminal) station to the service centre.

</doc>
<doc id="28011" url="http://en.wikipedia.org/wiki?curid=28011" title="Subgroup">
Subgroup

In mathematics, given a group "G" under a binary operation ∗, a subset "H" of "G" is called a subgroup of "G" if "H" also forms a group under the operation ∗. More precisely, "H" is a subgroup of "G" if the restriction of ∗ to "H" × "H" is a group operation on "H". This is usually represented notationally by "H" ≤ "G", read as ""H" is a subgroup of "G"".
A proper subgroup of a group "G" is a subgroup "H" which is a proper subset of "G" (i.e. "H" ≠ "G"). The trivial subgroup of any group is the subgroup {"e"} consisting of just the identity element. If "H" is a subgroup of "G", then "G" is sometimes called an "overgroup" of "H".
The same definitions apply more generally when "G" is an arbitrary semigroup, but this article will only deal with subgroups of groups. The group "G" is sometimes denoted by the ordered pair ("G", ∗), usually to emphasize the operation ∗ when "G" carries multiple algebraic or other structures.
This article will write "ab" for "a" ∗ "b", as is usual.
Cosets and Lagrange's theorem.
Given a subgroup "H" and some "a" in G, we define the left coset "aH" = {"ah" : "h" in "H"}. Because "a" is invertible, the map φ : "H" → "aH" given by φ("h") = "ah" is a bijection. Furthermore, every element of "G" is contained in precisely one left coset of "H"; the left cosets are the equivalence classes corresponding to the equivalence relation "a"1 ~ "a"2 if and only if "a"1−1"a"2 is in "H". The number of left cosets of "H" is called the index of "H" in "G" and is denoted by ["G" : "H"].
Lagrange's theorem states that for a finite group "G" and a subgroup "H", 
where |"G"| and |"H"| denote the orders of "G" and "H", respectively. In particular, the order of every subgroup of "G" (and the order of every element of "G") must be a divisor of |"G"|.
Right cosets are defined analogously: "Ha" = {"ha" : "h" in "H"}. They are also the equivalence classes for a suitable equivalence relation and their number is equal to ["G" : "H"].
If "aH" = "Ha" for every "a" in "G", then "H" is said to be a normal subgroup. Every subgroup of index 2 is normal: the left cosets, and also the right cosets, are simply the subgroup and its complement. More generally, if "p" is the lowest prime dividing the order of a finite group "G," then any subgroup of index "p" (if such exists) is normal.
Example: Subgroups of Z8.
Let "G" be the cyclic group Z8 whose elements are
and whose group operation is addition modulo eight. Its Cayley table is
This group has two nontrivial subgroups: "J"={0,4} and "H"={0,2,4,6}, where "J" is also a subgroup of "H". The Cayley table for "H" is the top-left quadrant of the Cayley table for "G". The group "G" is cyclic, and so are its subgroups. In general, subgroups of cyclic groups are also cyclic.
Example: Subgroups of S4 (the symmetric group on 4 elements).
Every group has as many small subgroups as neutral elements on the main diagonal:
The trivial group and two-element groups Z2. These small subgroups are not counted in the following list.

</doc>
<doc id="28012" url="http://en.wikipedia.org/wiki?curid=28012" title="Series">
Series

Series (singular) may refer to anything of a serial form:
Music.
See also: sequence

</doc>
<doc id="28013" url="http://en.wikipedia.org/wiki?curid=28013" title="Silicon Graphics">
Silicon Graphics

Silicon Graphics, Inc. (later rebranded SGI, historically known as Silicon Graphics Computer Systems or SGCS) was an American manufacturer of high-performance computing solutions, including computer hardware and software. Founded in 1982 by Jim Clark, its initial market was 3D graphics display terminals, but its products, strategies and market positions developed significantly over time.
Early systems were based on the Geometry Engine that Clark and Marc Hannah had developed at Stanford University, and were derived from Clark's broader background in computer graphics. The Geometry Engine was the first very-large-scale integration (VLSI) implementation of a "geometry pipeline", specialized hardware that accelerated the "inner-loop" geometric computations needed to display three-dimensional images.
SGI was headquartered in Mountain View, California; it was originally incorporated as a California corporation in November 1981, and reincorporated as a Delaware corporation in January 1990. On April 1, 2009, SGI filed for Chapter 11 bankruptcy protection and announced that it would sell substantially all of its assets to Rackable Systems, a deal finalized on May 11, 2009, with Rackable assuming the name "Silicon Graphics International". The remains of Silicon Graphics, Inc. became Graphics Properties Holdings, Inc.
History.
Early years.
Dr. James H. Clark left his position as an electrical engineering associate professor at Stanford University to found SGI in 1982 along with a group of seven graduate students and research staff from Stanford: Kurt Akeley, David J. Brown, Tom Davis, Rocky Rhodes, Marc Hannah, Herb Kuta, and Mark Grossman; along with Abbey Silverstone and a few others.
Massive growth.
Ed McCracken was CEO of Silicon Graphics from 1984 to 1997. Under his leadership, SGI grew from annual revenues of $5.4 million to $3.7 billion.
Decline.
The addition of 3D graphic capabilities to PCs, and the ability of clusters of Linux- and BSD-based PCs to take on many of the tasks of larger SGI servers, ate into SGI's core markets. The porting of Maya to Linux, Mac OS X and Microsoft Windows further eroded the low end of SGI's product line.
In response to challenges faced in the marketplace and a falling share price Ed McCracken was fired and SGI brought in Richard Belluzzo to replace him. Under Belluzzo's leadership a number of initiatives were taken which are considered to have accelerated the corporate decline. 
One such initiative was trying to sell workstations running Windows NT called Visual Workstations instead of just ones which ran IRIX, the company's version of UNIX. This put the company an even more direct competition with the likes of Dell, making it more difficult to justify a price premium. The product line was unsuccessful and abandoned a few years later.
SGI's premature announcement of its migration from MIPS to Itanium and its abortive ventures into IA-32 architecture systems (the Visual Workstation line, the ex-Intergraph Zx10 range and the SGI 1000-series Linux servers) damaged SGI's credibility in the market. 
In 1999, in an attempt to clarify their current market position as more than a graphics company, Silicon Graphics Inc. changed its corporate identity to “SGI”, although its legal name was unchanged.
At the same time, SGI announced a new logo consisting of only the letters “sgi” in a proprietary font called “SGI”, created by branding and design consulting firm Landor Associates, in collaboration with designer Joe Stitzlein. The new logo drew criticism for wasting the professional goodwill associated with the previous cube logo (or "bug"). SGI continued to use the "Silicon Graphics" name for its workstation product line, and later re-adopted the cube logo for some workstation models.
In November 2005, SGI announced that it had been delisted from the New York Stock Exchange because its common stock had fallen below the minimum share price for listing on the exchange. SGI's market capitalization dwindled from a peak of over seven billion dollars in 1995 to just $120 million at the time of delisting. In February 2006, SGI noted that it could run out of cash by the end of the year.
Re-emergence.
In mid-2005, SGI hired Alix Partners to advise it on returning to profitability and received a new line of credit. SGI announced it was postponing its scheduled annual December stockholders meeting until March 2006. It proposed a reverse stock split to deal with the de-listing from the New York Stock Exchange.
In January 2006, SGI hired Dennis McKenna as its new CEO and chairman of the board of directors. Mr. McKenna succeeded Robert Bishop, who remained vice chairman of the board of directors.
On May 8, 2006, SGI announced that it had filed for Chapter 11 bankruptcy protection for itself and U.S. subsidiaries as part of a plan to reduce debt by $250 million. Two days later, the U.S. Bankruptcy Court approved its first day motions and its use of a $70 million financing facility provided by a group of its bondholders. Foreign subsidiaries were unaffected.
On September 6, 2006, SGI announced the end of development for the MIPS/IRIX line and the IRIX operating system. Production would end on 29 December and the last orders would be fulfilled by March 2007. Support for these products would end after December 2013.
SGI emerged from bankruptcy protection on October 17, 2006. Its stock symbol at that point, "SGID.pk", was canceled, and new stock was issued on the NASDAQ exchange under the symbol "SGIC". This new stock was distributed to the company's creditors, and the SGID common stockholders were left with worthless shares. At the end of that year, the company moved its headquarters from Mountain View to Sunnyvale. Its earlier North Shoreline headquarters is now occupied by the Computer History Museum; the newer Amphitheater Parkway headquarters was sold to Google. Both of these locations were award-winning designs by Studios Architecture.
In April 2008, SGI re-entered the visualization market with the SGI Virtu range of visualization servers and workstations, which were re-badged systems from BOXX Technologies based on Intel Xeon or AMD Opteron processors and Nvidia Quadro graphics chipsets, running Red Hat Enterprise Linux, SUSE Linux Enterprise Server or Windows Compute Cluster Server.
Graphics Properties Holdings, Inc. era.
During the Silicon Graphics Inc.'s second bankruptcy phase, it was renamed to Graphics Properties Holdings, Inc.(GPHI) in June 2009.
In 2010, GPHI announced it had won a significant favorable ruling in its litigation with ATI Technologies and AMD in June 2010, following the patent lawsuit originally filed during the Silicon Graphics, Inc. era. Following the 2008 appeal by ATI over the validity of U.S. Patent ('327) and Silicon Graphics Inc's voluntary dismissal of the U.S. Patent ('376) patent from the lawsuit, the Federal Circuit upheld the jury verdict on the validity of GPHI's U.S. Patent No. 6,650,327, and furthermore found that AMD had lost its right to challenge patent validity in future proceedings. On January 31, 2011, the District Court entered an order that permits AMD to pursue its invalidity affirmative defense at trial and does not permit SGI to accuse AMD's Radeon R700 series of graphics products of infringement in this case. On April 18, 2011, GPHI and AMD had entered into a confidential Settlement and License Agreement that resolved this litigation matter for an immaterial amount and that provides immunity under all GPHI patents for alleged infringement by AMD products, including components, software and designs. On April 26, 2011, the Court entered an order granting the parties' agreed motion for dismissal and final judgment.
In 2011-11, GPHI filed another patent infringement lawsuit against Apple Inc. in Delaware involving more patents than their original patent infringement case against Apple last November, for alleged violation of U.S. patents 6,650,327 ('327), U.S. Patent ('145) and U.S. Patent ('881).
In 2012, the GPHI filed lawsuit against Apple, Sony, HTC Corp, LG Electronics Inc. and Samsung Electronics Co., Research in Motion Ltd. for allegedly violating patent relating to a computer graphics process that turns text and images into pixels to be displayed on screens. Affected devices include Apple iPhone, HTC EVO4G, LG Thrill, Research in Motion Torch, Samsung Galaxy S and Galaxy S II, and Sony Xperia Play smartphones.
Final bankruptcy and acquisition by Rackable Systems.
In December 2008, SGI received a delisting notification from NASDAQ, as its market value had been below the minimum $35 million requirement for 10 consecutive trading days, and also did not meet NASDAQ's alternative requirements of a minimum stockholders' equity of $2.5 million or annual net income from continuing operations of $500,000 or more.
On April 1, 2009, SGI filed for Chapter 11 again, and announced that it would sell substantially all of its assets to Rackable Systems for $25 million. The sale, ultimately for $42.5 million, was finalized on May 11, 2009; at the same time, Rackable announced their adoption of "Silicon Graphics International" as their global name and brand. The Bankruptcy court scheduled continuing proceedings and hearings for June 3 and 24, 2009, and July 22, 2009.
After the Rackable acquisition, "Vizworld" magazine published 
Technology.
Motorola 680x0-based systems.
SGI's first generation products, starting with the IRIS (Integrated Raster Imaging System) 1000 series of high-performance graphics terminals, were based on the Motorola 68000 family of microprocessors. The later IRIS 2000 and 3000 models developed into full UNIX workstations.
IRIS 1000 series.
The first entries in the 1000 series (models 1000 and 1200, introduced in 1984) were graphics terminals, peripherals to be connected to a general-purpose computer such as a Digital Equipment Corporation VAX, to provide graphical raster display abilities. They used 8 MHz Motorola 68000 CPUs with 768 kB of RAM and had no disk drives. They booted over the network (via an Excelan EXOS/101 Ethernet card) from their controlling computer. They used the "PM1" CPU board, which was a variant of the board that was used in Stanford University's SUN workstation and later in the Sun-1 workstation from Sun Microsystems. The graphics system was composed of the GF1 frame buffer, the UC3 "Update Controller", DC3 "Display Controller", and the BP2 bitplane. The 1000-series machines were designed around the Multibus standard.
Later 1000-series machines, the 1400 and 1500, ran at 10 MHz and had 1.5 MB of RAM. The 1400 had a 73 MB ST-506 disk drive, while the 1500 had a 474 MB SMD-based disk drive with a Xylogics 450 disk controller. They may have used the PM2 CPU and PM2M1 RAM board from the 2000 series. The usual monitor for the 1000 series ran at 30 Hz interlaced. Six beta-test units of the 1400 workstation were produced, and the first production unit (SGI's first commercial computer) was shipped to Carnegie-Mellon University's Electronic Imaging Laboratory in 1984.
IRIS 2000 and 3000 series.
SGI rapidly developed its machines into workstations with its second product line — the IRIS 2000 series, first released in August, 1985. SGI began using the UNIX System V operating system. There were five models in two product ranges, the 2000/2200/2300/2400/2500 range which used 68010 CPUs (the PM2 CPU module), and the later "Turbo" systems, the 2300T, 2400T and 2500T, which had 68020s (the IP2 CPU module). All used the Excelan EXOS/201 Ethernet card, the same graphics hardware (GF2 Frame Buffer, UC4 Update Controller, DC4 Display Controller, BP3 Bitplane). Their main differences were the CPU, RAM, and Weitek Floating Point Accelerator boards, disk controllers and disk drives (both ST-506 and SMD were available). These could be upgraded, for example from a 2400 to a 2400T. The 2500 and 2500T had a larger chassis, a standard 6' 19" EIA rack with space at the bottom for two SMD disk drives weighing approximately 68 kg each. The non-Turbo models used the Multibus for the CPU to communicate with the floating point accelerator, while the Turbos added a ribbon cable dedicated for this. 60 Hz monitors were used for the 2000 series.
The height of the machines using Motorola CPUs was reached with the IRIS 3000 series (models 3010/3020/3030 and 3110/3115/3120/3130, the 30s both being full-size rack machines). They used the same graphics subsystem and Ethernet as the 2000s, but could also use up to 12 "geometry engines", the first widespread use of hardware graphics accelerators. The standard monitor was a 19" 60 Hz non-interlaced unit with a tilt/swivel base; 19" 30 Hz interlaced and a 15" 60 Hz non-interlaced (with tilt/swivel base) were also available.
The IRIS 3130 and its smaller siblings were impressive for the time, being complete UNIX workstations. The 3130 was powerful enough to support a complete 3D animation and rendering package without mainframe support. With large capacity hard drives by standards of the day (two 300 MB drives), streaming tape and Ethernet, it could be the centerpiece of an animation operation.
The line was formally discontinued in November 1989, with about 3500 systems shipped of all 2000 and 3000 models combined.
RISC era.
With the introduction of the IRIS 4D series, SGI switched to MIPS microprocessors. These machines were more powerful and came with powerful on-board floating-point capability. As 3D graphics became more popular in television and film during this time, these systems were responsible for establishing much of SGI's reputation.
SGI produced a broad range of MIPS-based workstations and servers during the 1990s, running SGI's version of UNIX System V, now called IRIX. These included the massive Onyx visualization systems, the size of refrigerators and capable of supporting up to 64 processors while managing up to three streams of high resolution, fully realized 3D graphics.
In October 1991, MIPS announced the first 64-bit MIPS microprocessor, the R4000, which was the first commercially available 64-bit microprocessor. SGI used the R4000 in its Crimson workstation. IRIX 6.2 was the first fully 64-bit IRIX release, including 64-bit pointers.
To secure the supply of future generations of MIPS microprocessors (the 64-bit R4000), SGI acquired the company in 1992 for $333 million and renamed it as MIPS Technologies Inc., a wholly owned subsidiary of SGI.
In 1996, Silicon Graphics (SGI) and MIPS Technologies were responsible for the CPU used in the Nintendo 64, a derivative of the R4300i microprocessor.
In 1998 relinquished MIPS Technologies, Inc in a Re-IPO.
In the late 1990s, when much of the industry expected the Itanium to replace both CISC and RISC architectures in non-embedded computers, SGI announced their intent to phase out MIPS in their systems. Development of new MIPS microprocessors stopped, and the existing R12000 design was extended multiple times until 2003 to provide existing customers more time to migrate to Itanium.
In August 2006, SGI announced the end of production for MIPS/IRIX systems, and by the end of the year MIPS/IRIX products were no longer generally available from SGI.
IRIS GL and OpenGL.
Until the second generation Onyx Reality Engine machines, SGI offered access to its high performance 3D graphics subsystems through a proprietary API known as "IRIS Graphics Language" (IRIS GL). As more features were added over the years, IRIS GL became harder to maintain and more cumbersome to use. In 1992, SGI decided to clean up and reform IRIS GL and made the bold move of allowing the resulting OpenGL API to be cheaply licensed by SGI's competitors, and set up an industry-wide consortium to maintain the OpenGL standard (the OpenGL Architecture Review Board).
This meant that for the first time, fast, efficient, cross-platform graphics programs could be written. To this day, OpenGL remains the only real-time 3D graphics standard to be portable across a variety of operating systems. OpenGL-ES even runs on many types of cell phones. Its main competitor (Direct3D from Microsoft) runs only on Microsoft Windows-based machines and some consoles.
ACE Consortium.
SGI was part of the Advanced Computing Environment initiative, formed in the early 1990s with 20 other companies, including Compaq, Digital Equipment Corporation, MIPS Computer Systems, Groupe Bull, Siemens, NEC, NeTpower, Microsoft and Santa Cruz Operation. Its intent was to introduce workstations based on the MIPS architecture and able to run Windows NT and SCO UNIX. The group produced the Advanced RISC Computing (ARC) specification, but began to unravel little more than a year after its formation.
Entertainment industry.
An SGI Crimson system with the fsn three-dimensional file system navigator appeared in the 1993 movie "Jurassic Park".
In the movie "Twister", protagonists can be seen using an SGI laptop computer, however the unit shown was not an actual working computer, but rather a fake laptop shell built around an SGI Corona LCD flat screen display.
The 1995 film "Congo" also features an SGI laptop computer being used by Dr. Ross (Laura Linney) to communicate via satellite to TraviCom HQ.
Other on-screen credits include:
For eight consecutive years (1995–2002), all films nominated for an Academy Award for Distinguished Achievement in Visual Effects were created on Silicon Graphics computer systems.
Once inexpensive PCs began to have graphics performance close to the more expensive specialized graphical workstations which were SGI's core business, SGI shifted its focus to high performance servers for digital video and the Web. Many SGI graphics engineers left to work at other computer graphics companies such as ATI and Nvidia, contributing to the PC 3D graphics revolution.
Free software.
SGI was a promoter of free software, supporting several projects such as Linux and Samba, and providing some of its own previously proprietary code such as the XFS filesystem and the Open64 compiler to the free software world.
Acquisition of Alias, Wavefront, Cray and Intergraph.
In 1995, SGI purchased Alias Research and Wavefront Technologies in a deal totaling approximately $500 million and merged the companies into Alias|Wavefront. In June 2004 SGI sold the business, later renamed to Alias Systems Corporation, to the private equity investment firm Accel-KKR for $57.1 million. In October 2005, Autodesk announced that it signed a definitive agreement to acquire Alias for $182 million in cash.
In February 1996, SGI purchased the well-known supercomputer manufacturer Cray Research for $740 million, and began to use marketing names such as "CrayLink" for (SGI-developed) technology integrated into the SGI server line. Three months later, it sold Cray's Business Systems Division, responsible for the CS6400 SPARC/Solaris server, to Sun Microsystems for an undisclosed amount (widely believed to be $50 million). Many of the Cray T3E engineers designed and developed the SGI Altix and NUMAlink technology. SGI sold the Cray brand and product lines to Tera Computer Company on March 31, 2000 for $35 million plus one million shares. SGI also distributed its remaining interest in MIPS Technologies through a spin-off effective June 20, 2000.
In September 2000, SGI acquired the Zx10 series of Windows workstations and servers from Intergraph Computer Systems (for a rumored $100 million). These models were rebadged as SGI systems, but discontinued in June 2001.
SGI Visual Workstations.
Another attempt by SGI in the late 1990s to introduce its own family of Intel-based workstations running Windows NT or Red Hat Linux (see also SGI Visual Workstation) proved to be a financial disaster, and shook customer confidence in SGI’s commitment to its own MIPS-based line.
Switch to Itanium.
In 1998, SGI announced that future generations of its machines would be based not on their own MIPS processors, but the upcoming "super-chip" from Intel, code-named "Merced" and later called Itanium. Funding for its own high-end processors was reduced, and it was planned that the R10000 would be the last MIPS mainstream processor. MIPS Technologies would focus entirely on the embedded market, where it was having some success, and SGI would no longer have to fund development of a CPU that, since the failure of ARC, found use only in their own machines. This plan quickly went awry. As early as 1999 it was clear the Itanium was going to be delivered very late, and then that it would have nowhere near the performance originally expected. As the production delays increased, MIPS' existing R10000-based machines grew increasingly uncompetitive. Eventually it was forced to introduce faster MIPS processors, the R12000, R14000 and R16000, which were used in a series of models from 2002 through 2006.
SGI's first Itanium-based system was the short-lived SGI 750 workstation, launched in 2001. SGI's MIPS-based systems were not to be superseded until the launch of the Itanium 2-based Altix servers and Prism workstations some time later. Unlike the MIPS systems, which ran IRIX, the Itanium systems used SuSE Linux Enterprise Server with SGI enhancements as their operating system. SGI used Transitive Corporation's QuickTransit software to allow their old MIPS/IRIX applications to run (in emulation) on the new Itanium/Linux platform.
In the server market the Itanium 2-based Altix eventually replaced the MIPS-based Origin product line. In the workstation market, the switch to Itanium was not completed before SGI exited the market.
The Altix was the most powerful computer in the world in 2006, assuming that a "computer" is defined as a collection of hardware running under a single instance of an operating system. The Altix had 512 Itanium processors running under a single instance of Linux. A cluster of 20 machines was then the eighth-fastest supercomputer. All faster supercomputers were clusters, but none have as many FLOPS per machine. However, more recent supercomputers are very large clusters of machines that are individually less capable. SGI acknowledged this and in 2007 moved away from the "massive NUMA" model to efficient clusters.
Switch to Xeon.
Although SGI continued to market Itanium-based machines, its more recent machines were based on the Intel Xeon processor. The first Altix XE systems were relatively low-end machines, but by December 2006 the XE systems were more capable than the Itanium machines by some measures (e.g., power consumption in FLOPS/W, density in FLOPS/m3, cost/FLOPS). The XE1200 and XE1300 servers used a cluster architecture. This was a departure from the pure NUMA architectures of the earlier Itanium and MIPS servers.
In June 2007, SGI announced the Altix ICE 8200, a blade-based Xeon system with up to 512 Xeon cores per rack. An Altix ICE 8200 installed at New Mexico Computing Applications Center (with 14336 processors) ranked at number 3 on the TOP500 list of November 2007.
User base and core market.
Conventional wisdom holds that SGI's core market has traditionally been Hollywood visual effects studios. In fact, SGI's largest revenue has always been generated by government and defense applications, energy, and scientific and technical computing. The rise of cheap yet powerful commodity workstations running Linux, Windows and Mac OS X, and the availability of diverse professional software for them, effectively pushed SGI out of the visual effects industry in all but the most niche markets, as studios adopted newer, cheaper technology.
High-end server market.
SGI continued to enhance its line of servers (including some supercomputers) based on the SN architecture. SN, for Scalable Node, is a technology developed by SGI in the mid-1990s that uses cache-coherent non-uniform memory access (cc-NUMA). In an SN system, processors, memory, and a bus- and memory-controller are coupled together into an entity called a node, usually on a single circuit board. Nodes are connected by a high-speed interconnect called NUMAlink (originally branded CrayLink). There is no internal bus, and instead access between processors, memory, and I/O devices is done through a switched fabric of links and routers.
Thanks to the cache coherence of the distributed shared memory, SN systems scale along several axes at once: as CPU count increases, so does memory capacity, I/O capacity, and system bisection bandwidth. This allows the combined memory of all the nodes to be accessed under a single OS image using standard shared-memory synchronization methods. This makes an SN system far easier to program and able to achieve higher sustained-to-peak performance than non-cache-coherent systems like conventional clusters or massively parallel computers which require applications code to be written (or re-written) to do explicit message-passing communication between their nodes.
The first SN system, known as SN-0, was released in 1996 under the product name Origin 2000. Based on the MIPS R10000 processor, it scaled from 2 to 128 processors and a smaller version, the Origin 200 (SN-00), scaled from 1 to 4. Later enhancements enabled systems of as large as 512 processors.
The second generation system, originally called SN-1 but later SN-MIPS, was released in July 2000, as the Origin 3000. It scaled from 4 to 512 processors, and 1,024-processor configurations were delivered by special order to some customers. A smaller, less scalable implementation followed, called Origin 300.
In November 2002, SGI announced a repackaging of its SN system, under the name Origin 3900. It quadrupled the processor area density of the SN-MIPS system, from 32 up to 128 processors per rack while moving to a "fat tree" interconnect topology.
In January 2003, SGI announced a variant of the SN platform called the Altix 3000 (internally called SN-IA). It used Intel Itanium 2 processors and ran the Linux operating system kernel. At the time it was released, it was the world's most scalable Linux-based computer, supporting up to 64 processors in a single system node. Nodes could be connected using the same NUMAlink technology to form what SGI predictably termed "superclusters".
In February 2004, SGI announced general support for 128 processor nodes to be followed by 256 and 512 processor versions that year.
In April 2004, SGI announced the sale of its Alias software business for approximately $57 million.
In October 2004, SGI built the supercomputer Columbia, which broke the world record for computer speed, for the NASA Ames Research Center. It was a cluster of 20 Altix supercomputers each with 512 Intel Itanium 2 processors running Linux, and achieved sustained speed of 42.7 trillion floating-point operations per second (teraflops), easily topping Japan's famed Earth Simulator's record of 35.86 teraflops. (A week later, IBM's upgraded Blue Gene/L clocked in at 70.7 teraflops).
In July 2006, SGI announced an SGI Altix 4700 system with 1,024 processors and 4 TB of memory running a single Linux system image.
Hardware products.
Some 68k and MIPS-based models were also rebadged by other vendors, including CDC, Tandem Computers, Prime Computer and Siemens-Nixdorf.

</doc>
<doc id="28016" url="http://en.wikipedia.org/wiki?curid=28016" title="Steiner system">
Steiner system

In combinatorial mathematics, a Steiner system (named after Jakob Steiner) is a type of block design, specifically a with λ = 1 and "t" ≥ 2.
A Steiner system with parameters "t", "k", "n", written S("t","k","n"), is an "n"-element set "S" together with a set of "k"-element subsets of "S" (called blocks) with the property that each "t"-element subset of "S" is contained in exactly one block. In an alternate notation for block designs, an S("t","k","n") would be a "t"-("n","k",1) design.
This definition is relatively modern, generalizing the "classical" definition of Steiner systems which in addition required that "k" = "t" + 1. An S(2,3,"n") was (and still is) called a "Steiner triple" (or "triad") "system", while an S(3,4,"n") was called a "Steiner quadruple system", and so on. With the generalization of the definition, this naming system is no longer strictly adhered to.
As of 2015, an outstanding problem in design theory is if any nontrivial (formula_1) Steiner systems have "t" ≥ 6. It is also unknown if infinitely many have "t" = 4 or 5.
Examples.
Finite projective planes.
A finite projective plane of order "q", with the lines as blocks, is an formula_2, since it has formula_3 points, each line passes through formula_4 points, and each pair of distinct points lies on exactly one line.
Finite affine planes.
A finite affine plane of order "q", with the lines as blocks, is an S(2, "q", "q"2). An affine plane of order "q" can be obtained from a projective plane of the same order by removing one block and all of the points in that block from the projective plane. Choosing different blocks to remove in this way can lead to non-isomorphic affine planes.
Classical Steiner systems.
Steiner triple systems.
An S(2,3,"n") is called a Steiner triple system, and its blocks are called triples. It is common to see the abbreviation STS("n") for a Steiner triple system of order "n". 
The number of triples is "n"("n"−1)/6. A necessary and sufficient condition for the existence of an S(2,3,"n") is that "n" formula_5 1 or 3 (mod 6). The projective plane of order 2 (the Fano plane) is an STS(7) and the affine plane of order 3 is an STS(9).
Up to isomorphism, the STS(7) and STS(9) are unique, there are two STS(13)s, 80 STS(15)s, and 11,084,874,829 STS(19)s.
We can define a multiplication on the set "S" using the Steiner triple system by setting "aa" = "a" for all "a" in "S", and "ab" = "c" if {"a","b","c"} is a triple. This makes "S" an idempotent, commutative quasigroup. It has the additional property that "ab" = "c" implies "bc" = "a" and "ca" = "b". Conversely, any (finite) quasigroup with these properties arises from a Steiner triple system. Commutative idempotent quasigroups satisfying this additional property are called "Steiner quasigroups".
Steiner quadruple systems.
An S(3,4,"n") is called a Steiner quadruple system. A necessary and sufficient condition for the existence of an S(3,4,"n") is that "n" formula_5 2 or 4 (mod 6). The abbreviation SQS("n") is often used for these systems.
Up to isomorphism, SQS(8) and SQS(10) are unique, there are 4 SQS(14)s and 1,054,163 SQS(16)s.
Steiner quintuple systems.
An S(4,5,"n") is called a "Steiner quintuple system". A necessary condition for the existence of such a system is that "n" formula_5 3 or 5 (mod 6) which comes from considerations that apply to all the classical Steiner systems. An additional necessary condition is that "n" formula_8 4 (mod 5), which comes from the fact that the number of blocks must be an integer. Sufficient conditions are not known.
There is a unique Steiner quintuple system of order 11, but none of order 15 or order 17. Systems are known for orders 23, 35, 47, 71, 83, 107, 131, 167 and 243. The smallest order for which the existence is not known (as of 2011) is 21.
Properties.
It is clear from the definition of S("t","k","n") that formula_9. (Equalities, while technically possible, lead to trivial systems.)
If S("t","k","n") exists, then taking all blocks containing a specific element and discarding that element gives a "derived system" S("t"−1,"k"−1,"n"−1). Therefore the existence of S("t"−1,"k"−1,"n"−1) is a necessary condition for the existence of S("t","k","n").
The number of "t"-element subsets in S is formula_10, while the number of "t"-element subsets in each block is formula_11. Since every "t"-element subset is contained in exactly one block, we have formula_12, or formula_13, where "b" is the number of blocks. Similar reasoning about "t"-element subsets containing a particular element gives us formula_14, or formula_15, where "r" is the number of blocks containing any given element. From these definitions follows the equation formula_16. It is a necessary condition for the existence of S("t","k","n") that "b" and "r" are integers. As with any block design, Fisher's inequality formula_17 is true in Steiner systems.
Given the parameters of a Steiner system S(t,k,n) and a subset of size formula_18, contained in at least one block, one can compute the number of blocks intersecting that subset in a fixed number of elements by constructing a Pascal triangle. In particular, the number of blocks intersecting a fixed block in any number of elements is independent of the chosen block.
It can be shown that if there is a Steiner system S(2,"k","n"), where "k" is a prime power greater than 1, then "n" formula_5 1 or "k" (mod "k"("k"−1)). In particular, a Steiner triple system S(2,3,"n") must have "n" = 6"m"+1 or 6"m"+3. It is known that this is the only restriction on Steiner triple systems, that is, for each natural number "m", systems S(2,3,6"m"+1) and S(2,3,6"m"+3) exist.
History.
Steiner triple systems were defined for the first time by W.S.B. Woolhouse in 1844 in the Prize question #1733 of Lady's and Gentlemen's Diary. The posed problem was solved by Thomas Kirkman (1847). In 1850 Kirkman posed a variation of the problem known as Kirkman's schoolgirl problem, which asks for triple systems having an additional property (resolvability). Unaware of Kirkman's work, Jakob Steiner (1853) reintroduced triple systems, and as this work was more widely known, the systems were named in his honor.
Mathieu groups.
Several examples of Steiner systems are closely related to group theory. In particular, the finite simple groups called Mathieu groups arise as automorphism groups of Steiner systems:
The Steiner system S(5, 6, 12).
There is a unique S(5,6,12) Steiner system; its automorphism group is the Mathieu group M12, and in that context it is denoted by W12.
Constructions.
There are different ways to construct an S(5,6,12) system.
Projective line method.
This construction is due to Carmichael (1937).
Add a new element, call it ∞, to the 11 elements of the finite field F11 (that is, the integers mod 11). This set, "S", of 12 elements can be formally identified with the points of the projective line over F11. Call the following specific subset of size 6,
a "block". From this block, we obtain the other blocks of the S(5,6,12) system by repeatedly applying the linear fractional transformations:
With the usual conventions of defining "f" (−"d"/"c") = ∞ and "f" (∞) = "a"/"c", these functions map the set "S" onto itself. In geometric language, they are projectivities of the projective line. They form a group under composition which is the projective special linear group PSL(2,11) of order 660. There are exactly five elements of this group that leave the starting block fixed setwise, so there will be 132 images of that block. As a consequence of the multiply transitive property of this group acting on this set, any subset of five elements of "S" will appear in exactly one of these 132 images of size six.
Kitten method.
An alternative construction of W12 is obtained by use of the 'kitten' of R.T. Curtis, which was intended as a "hand calculator" to write down blocks one at a time. The kitten method is based on completing patterns in a 3x3 grid of numbers, which represent an affine geometry on the vector space F3xF3, an S(2,3,9) system.
Construction from K6 graph factorization.
The relations between the graph factors of the complete graph K6 generate an S(5,6,12). A K6 graph has 6 different 1-factorizations (ways to partition the edges into disjoint perfect matchings), and also 6 vertices. The set of vertices and the set of factorizations provide one block each. For every distinct pair of factorizations, there exists exactly one perfect matching in common. Take the set of vertices and replace the two vertices corresponding to an edge of the common perfect matching with the labels corresponding to the factorizations; add that to the set of blocks. Repeat this with the other two edges of the common perfect matching. Similarly take the set of factorizations and replace the labels corresponding to the two factorizations with the end points of an edge in the common perfect matching. Repeat with the other two edges in the matching. There are thus 3+3 = 6 blocks per pair of factorizations, and there are 6C2 = 15 pairs among the 6 factorizations, resulting in 90 new blocks. Finally take the full set of 12C6 = 924 combinations of 6 objects out of 12, and discard any combination that has 5 or more objects in common with any of the 92 blocks generated so far. Exactly 40 blocks remain, resulting in 2+90+40 = 132 blocks of the S(5,6,12).
The Steiner system S(5, 8, 24).
The Steiner system S(5, 8, 24), also known as the Witt design or Witt geometry, was first described by Carmichael (1931) and rediscovered by Witt (1938). This system is connected with many of the sporadic simple groups and with the exceptional 24-dimensional lattice known as the Leech lattice.
The automorphism group of S(5, 8, 24) is the Mathieu group M24, and in that context the design is denoted W24 ("W" for "Witt")
Constructions.
There are many ways to construct the S(5,8,24). Two methods are described here:
Method based on 8-combinations of 24 elements.
All 8-element subsets of a 24-element set are generated in lexicographic order, and any such subset which differs from some subset already found in fewer than four positions is discarded.
The list of octads for the elements 01, 02, 03, ..., 22, 23, 24 is then:
Each single element occurs 253 times somewhere in some octad. Each pair occurs 77 times. Each triple occurs 21 times. Each quadruple (tetrad) occurs 5 times. Each quintuple (pentad) occurs once. Not every hexad, heptad or octad occurs.
Method based on 24-bit binary strings.
All 24-bit binary strings are generated in lexicographic order, and any such string that differs from some earlier one in fewer than 8 positions is discarded. The result looks like this:
The list contains 4096 items, which are each code words of the extended binary Golay code. They form a group under the XOR operation. One of them has zero 1-bits, 759 of them have eight 1-bits, 2576 of them have twelve 1-bits, 759 of them have sixteen 1-bits, and one has twenty-four 1-bits. The 759 8-element blocks of the S(5,8,24) (called ) are given by the patterns of 1's in the code words with eight 1-bits.

</doc>
<doc id="28017" url="http://en.wikipedia.org/wiki?curid=28017" title="Sirius">
Sirius

Sirius () is the brightest star (in fact, a star system) in the Earth's night sky. With a visual apparent magnitude of −1.46, it is almost twice as bright as Canopus, the next brightest star. The name "Sirius" is derived from the Ancient Greek: Σείριος "Seirios" ("glowing" or "scorcher"). The system has the Bayer designation Alpha Canis Majoris (α CMa). What the naked eye perceives as a single star is actually a binary star system, consisting of a white main-sequence star of spectral type A1V, termed Sirius A, and a faint white dwarf companion of spectral type DA2, called Sirius B. The distance separating Sirius A from its companion varies between 8.2 and 31.5 AU.
Sirius appears bright because of both its intrinsic luminosity and its proximity to Earth. At a distance of 2.6 parsecs (8.6 ly), as determined by the Hipparcos astrometry satellite, the Sirius system is one of Earth's near neighbors. Sirius is gradually moving closer to the Solar System, so it will slightly increase in brightness over the next 60,000 years. After that time its distance will begin to recede, but it will continue to be the brightest star in the Earth's sky for the next 210,000 years.
Sirius A is about twice as massive as the Sun (M☉) and has an absolute visual magnitude of 1.42. It is 25 times more luminous than the Sun but has a significantly lower luminosity than other bright stars such as Canopus or Rigel. The system is between 200 and 300 million years old. It was originally composed of two bright bluish stars. The more massive of these, Sirius B, consumed its resources and became a red giant before shedding its outer layers and collapsing into its current state as a white dwarf around 120 million years ago.
Sirius is also known colloquially as the "Dog Star", reflecting its prominence in its constellation, Canis Major (Greater Dog). The heliacal rising of Sirius marked the flooding of the Nile in Ancient Egypt and the "dog days" of summer for the ancient Greeks, while to the Polynesians in the southern hemisphere it marked winter and was an important star for navigation around the Pacific Ocean.
Observational history.
Sirius, known in ancient Egypt as "Sopdet" (Greek: Σῶθις "Sothis"), is recorded in the earliest astronomical records. During the era of the Middle Kingdom, Egyptians based their calendar on the heliacal rising of Sirius, namely the day it becomes visible just before sunrise after moving far enough away from the glare of the Sun. This occurred just before the annual flooding of the Nile and the summer solstice, after a 70-day absence from the skies. The hieroglyph for Sothis features a star and a triangle. Sothis was identified with the great goddess Isis, who formed a part of a triad with her husband Osiris and their son Horus, while the 70-day period symbolised the passing of Isis and Osiris through the "duat" (Egyptian underworld).
The ancient Greeks observed that the appearance of Sirius heralded the hot and dry summer, and feared that it caused plants to wilt, men to weaken, and women to become aroused. Due to its brightness, Sirius would have been noted to twinkle more in the unsettled weather conditions of early summer. To Greek observers, this signified certain emanations which caused its malignant influence. Anyone suffering its effects was said to be "astroboletos" (ἀστροβόλητος) or "star-struck". It was described as "burning" or "flaming" in literature. The season following the star's heliacal rising (i.e. rising with the Sun) came to be known as the Dog Days of summer. The inhabitants of the island of Ceos in the Aegean Sea would offer sacrifices to Sirius and Zeus to bring cooling breezes, and would await the reappearance of the star in summer. If it rose clear, it would portend good fortune; if it was misty or faint then it foretold (or emanated) pestilence. Coins retrieved from the island from the 3rd century BC feature dogs or stars with emanating rays, highlighting Sirius' importance. The Romans celebrated the heliacal setting of Sirius around April 25, sacrificing a dog, along with incense, wine, and a sheep, to the goddess Robigo so that the star's emanations would not cause wheat rust on wheat crops that year.
Ptolemy of Alexandria mapped the stars in Books VII and VIII of his "Almagest", in which he used Sirius as the location for the globe's central meridian. He curiously depicted it as one of six red-coloured stars (see the Red controversy section below). The other five are class M and K stars, such as Arcturus and Betelgeuse.
Bright stars were important to the ancient Polynesians for navigation between the many islands and atolls of the Pacific Ocean. Low on the horizon, they acted as stellar compasses to assist mariners in charting courses to particular destinations. They also served as latitude markers; the declination of Sirius matches the latitude of the archipelago of Fiji at 17°S and thus passes directly over the islands each night. Sirius served as the body of a "Great Bird" constellation called "Manu", with Canopus as the southern wingtip and Procyon the northern wingtip, which divided the Polynesian night sky into two hemispheres. Just as the appearance of Sirius in the morning sky marked summer in Greece, so it marked the chilly onset of winter for the Māori, whose name "Takurua" described both the star and the season. Its culmination at the winter solstice was marked by celebration in Hawaii, where it was known as "Ka'ulua", "Queen of Heaven". Many other Polynesian names have been recorded, including "Tau-ua" in the Marquesas Islands, "Rehua" in New Zealand, and "Ta'urua-fau-papa" "Festivity of original high chiefs" and "Ta'urua-e-hiti-i-te-tara-te-feiai" "Festivity who rises with prayers and religious ceremonies" in Tahiti. The Hawaiian people had many names for Sirius, including "Aa" ("glowing"), "Hoku-kauopae", "Kau-ano-meha" (also "Kaulanomeha"), "Standing-alone-and-sacred", "Hiki-kauelia" or "Hiki-kauilia" (the navigational name), "Hiki-kau-lono-meha" ("star of solitary Lono", the astrological name), "Kaulua" (also "Kaulua-ihai-mohai", "flower of the heavens"), "Hiki-kauelia", "Hoku-hoo-kele-waa" ("star which causes the canoe to sail", a marine navigation name), and "Kaulua-lena" ("yellow star"). The people of the Society Islands called Sirius variously "Taurua-fau-papa", "Taurua-nui-te-amo-aha", and "Taurua-e-hiti-i-tara-te-feiai". Other names for Sirius included "Palolo-mua" (Futuna), "Mere" (Mangaia), "Apura" (Manihiki), "Taku-ua" (Marquesas Islands), and "Tokiva" (Pukapuka). In the cosmology of the Tuamotus, Sirius had various names, including "Takurua-te-upuupu", "Te Kaha" ("coconut fiber"), "Te Upuupu", "Taranga", and "Vero-ma-torutoru" ("flaming and diminishing").
The indigenous Boorong people of northwestern Victoria named Sirius as "Warepil".
Kinematics.
In 1718, Edmond Halley discovered the proper motion of the hitherto presumed "fixed" stars after comparing contemporary astrometric measurements with those given in Ptolemy's "Almagest". The bright stars Aldebaran, Arcturus and Sirius were noted to have moved significantly, the last of which having progressed 30 arc minutes (about the diameter of the Moon) southwards in 1,800 years.
In 1868, Sirius became the first star to have its velocity measured. Sir William Huggins examined the spectrum of this star and observed a noticeable red shift. He concluded that Sirius was receding from the Solar System at about 40 km/s. Compared to the modern value of −7.6 km/s, this both was an overestimate and had the wrong sign; the minus means it is approaching the Sun. However, it is notable for introducing the study of celestial radial velocities.
Distance.
The parallax of Sirius was measured by Thomas Henderson using his observations made in 1832-1833 and Maclear's observations made in 1836-1837, and was published in 1839. The value of the parallax was 0.23 arcseconds, and error of the parallax was estimated not to exceed a quarter of a second.
Also, were earlier attempts to measure parallax of Sirius: by the second Cassini (6 seconds); by some astronomers (including Nevil Maskelyne) using Lacaille's observations made at the Cape of Good Hope (4 seconds); by Piazzi (the same amount); using Lacaille's observations made at Paris, more numerous and certain than those made at the Cape (no sensible parallax); by Bessel (no sensible parallax).
Sirius distance estimates
Discovery of a companion.
In 1844 the German astronomer Friedrich Bessel deduced from changes in the proper motion of Sirius that it had an unseen companion. Nearly two decades later, on January 31, 1862, American telescope-maker and astronomer Alvan Graham Clark first observed the faint companion, which is now called Sirius B, or affectionately "the Pup". This happened during testing of an 18.5 in aperture great refractor telescope for Dearborn Observatory, which was the largest refracting telescope lens in existence at the time, and the largest telescope in the United States. Sirius B sighting was confirmed on March 8 with smaller telescopes as well.
The visible star is now sometimes known as Sirius A. Since 1894, some apparent orbital irregularities in the Sirius system have been observed, suggesting a third very small companion star, but this has never been definitely confirmed. The best fit to the data indicates a six-year orbit around Sirius A and a mass of only 0.06 M☉. This star would be five to ten magnitudes fainter than the white dwarf Sirius B, which would account for the difficulty of observing it. Observations published in 2008 were unable to detect either a third star or a planet. An apparent "third star" observed in the 1920s is now confirmed as a background object.
In 1915, Walter Sydney Adams, using a 60-inch (1.5 m) reflector at Mount Wilson Observatory, observed the spectrum of Sirius B and determined that it was a faint whitish star. This led astronomers to conclude that it was a white dwarf, the second to be discovered. The diameter of Sirius A was first measured by Robert Hanbury Brown and Richard Q. Twiss in 1959 at Jodrell Bank using their stellar intensity interferometer. In 2005, using the Hubble Space Telescope, astronomers determined that Sirius B has nearly the diameter of the Earth, 12,000 km, with a mass that is 98% of the Sun.
Red controversy.
Around 150 AD, the Greek astronomer of the Roman period Claudius Ptolemy described Sirius as reddish, along with five other stars, Betelgeuse, Antares, Aldebaran, Arcturus and Pollux, all of which are clearly of orange or red hue. The discrepancy was first noted by amateur astronomer Thomas Barker, squire of Lyndon Hall in Rutland, who prepared a paper and spoke at a meeting of the Royal Society in London in 1760. The existence of other stars changing in brightness gave credence to the idea that some may change in color too; Sir John Herschel noted this in 1839, possibly influenced by witnessing Eta Carinae two years earlier. Thomas Jefferson Jackson See resurrected discussion on red Sirius with the publication of several papers in 1892, and a final summary in 1926. He cited not only Ptolemy but also the poet Aratus, the orator Cicero, and general Germanicus as coloring the star red, though acknowledging that none of the latter three authors were astronomers, the last two merely translating Aratus' poem "Phaenomena". Seneca, too, had described Sirius as being of a deeper red color than Mars. However, not all ancient observers saw Sirius as red. The 1st century AD poet Marcus Manilius described it as "sea-blue", as did the 4th century Avienus. It is the standard star for the color white in ancient China, and multiple records from the 2nd century BC up to the 7th century AD all describe Sirius as white in hue.
In 1985, German astronomers Wolfhard Schlosser and Werner Bergmann published an account of an 8th-century Lombardic manuscript, which contains "De cursu stellarum ratio" by St. Gregory of Tours. The Latin text taught readers how to determine the times of nighttime prayers from positions of the stars, and Sirius is described within as "rubeola" — "reddish". The authors proposed this was further evidence Sirius B had been a red giant at the time. However, other scholars replied that it was likely St. Gregory had been referring to Arcturus instead.
The possibility that stellar evolution of either Sirius A or Sirius B could be responsible for this discrepancy has been rejected by astronomers on the grounds that the timescale of thousands of years is too short and that there is no sign of the nebulosity in the system that would be expected had such a change taken place. An interaction with a third star, to date undiscovered, has also been proposed as a possibility for a red appearance. Alternative explanations are either that the description as red is a poetic metaphor for ill fortune, or that the dramatic scintillations of the star when it was observed rising left the viewer with the impression that it was red. To the naked eye, it often appears to be flashing with red, white and blue hues when near the horizon.
Visibility.
With an apparent magnitude of −1.46, Sirius is the brightest star system in the night sky, almost twice the brightness of the second brightest star, Canopus. However, it is not as bright as the Moon, Venus, or Jupiter, and at times, Mercury and Mars are also brighter than Sirius. Sirius can be seen from almost everywhere on the Earth's surface, with only observers north of 73 degrees latitude unable to see it, and it does not rise very high when viewed from some northern cities, reaching only 13° above the horizon from Saint Petersburg. Sirius, along with Procyon and Betelgeuse, forms one of the three vertices of the Winter Triangle to observers in the Northern Hemisphere. Due to its declination of roughly −17°, Sirius is a circumpolar star from latitudes south of 73° S. From the Southern Hemisphere in early July, Sirius can be seen in both the evening where it sets after the Sun, and in the morning where it rises before the Sun. Due to precession (and slight proper motion), Sirius will move further south in the future. Starting in the year 9000, Sirius will not be visible any more from northern and central Europe, and in 14000 its declination will be -67° and thus it will be circumpolar throughout South Africa and in most parts of Australia.
Sirius can even be observed in daylight with the naked eye under the right conditions. Ideally, the sky should be very clear, with the observer at a high altitude, the star passing overhead, and the Sun low down on the horizon. These observing conditions are more easily met in the southern hemisphere, due to the southerly declination of Sirius.
The orbital motion of the Sirius binary system brings the two stars to a minimum angular separation of 3 arcseconds and a maximum of 11 arcseconds. At the closest approach, it is an observational challenge to distinguish the white dwarf from its more luminous companion, requiring a telescope with at least 300 mm (12 in) aperture and excellent seeing conditions. A periastron occurred in 1994 and the pair have since been moving apart, making them easier to separate with a telescope.
At a distance of 2.6 parsecs (8.6 ly), the Sirius system contains two of the eight nearest stars to the Solar System (not including the Sun), and is the fifth closest stellar system to ours (again not including the Sun). This proximity is the main reason for its brightness, as with other near stars such as Alpha Centauri and in stark contrast to distant, highly luminous supergiants such as Canopus, Rigel or Betelgeuse. However, it is still around 25 times more luminous than the Sun. The closest large neighbouring star to Sirius is Procyon, 1.61 parsecs (5.24 ly) away. The "Voyager 2" spacecraft, launched in 1977 to study the four Jovian planets in the Solar System, is expected to pass within 4.3 ly of Sirius in approximately 296,000 years.
System.
Sirius is a binary star system consisting of two white stars orbiting each other with a separation of about 20 AU (roughly the distance between the Sun and Uranus) and a period of 50.1 years. The brighter component, termed Sirius A, is a main-sequence star of spectral type A1V, with an estimated surface temperature of 9,940 K. Its companion, Sirius B, is a star that has already evolved off the main sequence and become a white dwarf. Currently 10,000 times less luminous in the visual spectrum, Sirius B was once the more massive of the two. The age of the system has been estimated at around 230 million years. Early in its lifespan it was thought to have been two bluish white stars orbiting each other in an elliptical orbit every 9.1 years. The system emits a higher than expected level of infrared radiation, as measured by IRAS space-based observatory. This may be an indication of dust in the system, and is considered somewhat unusual for a binary star. The Chandra X-ray Observatory image shows Sirius B outshining its bright partner as it is a brighter X-ray source.
Sirius A.
Sirius A has a mass of 2 M☉. The radius of this star has been measured by an astronomical interferometer, giving an estimated angular diameter of 5.936±0.016 mas. The projected rotational velocity is a relatively low 16 km/s, which does not produce any significant flattening of its disk. This is at marked variance with the similar-sized Vega, which rotates at a much faster 274 km/s and bulges prominently around its equator. A weak magnetic field has been detected on the surface of Sirius A.
Stellar models suggest that the star formed during the collapsing of a molecular cloud, and that after 10 million years, its internal energy generation was derived entirely from nuclear reactions. The core became convective and utilized the CNO cycle for energy generation. It is predicted that Sirius A will have completely exhausted the store of hydrogen at its core within a billion (109) years of its formation. At this point it will pass through a red giant stage, then settle down to become a white dwarf.
Sirius A is classed as an Am star because the spectrum shows deep metallic absorption lines, indicating an enhancement in elements heavier than helium, such as iron. When compared to the Sun, the proportion of iron in the atmosphere of Sirius A relative to hydrogen is given by formula_1, which is equivalent to 100.5, meaning it has 316% of the proportion of iron in the Sun's atmosphere. The high surface content of metallic elements is unlikely to be true of the entire star, rather the iron-peak and heavy metals are radiatively levitated towards the surface.
Sirius B.
With a mass nearly equal to the Sun's, Sirius B is one of the more massive white dwarfs known (0.98 M☉); it is almost double the 0.5–0.6 M☉ average. Yet that same mass is packed into a volume roughly equal to the Earth's. The current surface temperature is 25,200 K. However, because there is no internal heat source, Sirius B will steadily cool as the remaining heat is radiated into space over a period of more than two billion years.
A white dwarf forms only after the star has evolved from the main sequence and then passed through a red-giant stage. This occurred when Sirius B was less than half its current age, around 120 million years ago. The original star had an estimated 5 M☉ and was a B-type star (roughly B4–5) when it still was on the main sequence. While it passed through the red giant stage, Sirius B may have enriched the metallicity of its companion.
This star is primarily composed of a carbon–oxygen mixture that was generated by helium fusion in the progenitor star. This is overlaid by an envelope of lighter elements, with the materials segregated by mass because of the high surface gravity. Hence the outer atmosphere of Sirius B is now almost pure hydrogen—the element with the lowest mass—and no other elements are seen in its spectrum.
Sirius star cluster.
In 1909, Ejnar Hertzsprung was the first to suggest that Sirius was a member of the Ursa Major Moving Group, based on his observations of the system's movements across the sky. The Ursa Major Group is a set of 220 stars that share a common motion through space and were once formed as members of an open cluster, which has since become gravitationally unbound. However, analyses in 2003 and 2005 found Sirius's membership in the group to be questionable: the Ursa Major Group has an estimated age of 500±100 million years, whereas Sirius, with metallicity similar to the Sun's, has an age that is only half this, making it too young to belong to the group. Sirius may instead be a member of the proposed Sirius Supercluster, along with other scattered stars such as Beta Aurigae, Alpha Coronae Borealis, Beta Crateris, Beta Eridani and Beta Serpentis. This is one of three large clusters located within 500 ly of the Sun. The other two are the Hyades and the Pleiades, and each of these clusters consists of hundreds of stars.
Etymology and cultural significance.
The most commonly used proper name of this star comes from the Latin "Sīrius", from the Ancient Greek "Σείριος" ("Seirios", "glowing" or "scorcher"), although the Greek word itself may have been imported from elsewhere before the Archaic period, one authority suggesting a link with the Egyptian god Osiris. The name's earliest recorded use dates from the 7th century BC in Hesiod's poetic work "Works and Days". Sirius has over 50 other designations and names attached to it. In Geoffrey Chaucer's essay Treatise on the Astrolabe, it bears the name Alhabor, and is depicted by a hound's head. This name is widely used on medieval astrolabes from Western Europe. In Sanskrit it is known as "Mrgavyadha" "deer hunter", or "Lubdhaka" "hunter". As Mrgavyadha, the star represents Rudra (Shiva). The star is referred as "Makarajyoti" in Malayalam and has religious significance to the pilgrim center Sabarimala. In Scandinavia, the star has been known as "Lokabrenna" ("burning done by Loki", or "Loki's torch"). In the astrology of the Middle Ages, Sirius was a Behenian fixed star, associated with beryl and juniper. Its astrological symbol was listed by Heinrich Cornelius Agrippa.
Many cultures have historically attached special significance to Sirius, particularly in relation to dogs. Indeed, it is often colloquially called the "Dog Star" as the brightest star of Canis Major, the "Great Dog" constellation.
It was classically depicted as Orion's dog. The Ancient Greeks thought that Sirius's emanations could affect dogs adversely, making them behave abnormally during the "dog days," the hottest days of the summer. The Romans knew these days as "dies caniculares", and the star Sirius was called Canicula, "little dog." The excessive panting of dogs in hot weather was thought to place them at risk of desiccation and disease. In extreme cases, a foaming dog might have rabies, which could infect and kill humans whom they had bitten. Homer, in the Iliad, describes the approach of Achilles toward Troy in these words:<poem>Sirius rises late in the dark, liquid sky
On summer nights, star of stars,
Orion's Dog they call it, brightest
Of all, but an evil portent, bringing heat
And fevers to suffering humanity.</poem>
In Iranian mythology, especially in Persian mythology and in Zoroastrianism, the ancient religion of Persia, Sirius appears as "Tishtrya" and is revered as the rain-maker divinity (Tishtar of New Persian poetry). Beside passages in the sacred texts of the Avesta, the Avestan language "Tishtrya" followed by the version "Tir" in Middle and New Persian is also depicted in the Persian epic Shahnameh of Ferdowsi. Due to the concept of the yazatas, powers which are "worthy of worship", Tishtrya is a divinity of rain and fertility and an antagonist of apaosha, the demon of drought. In this struggle, Tishtrya is beautifully depicted as a white horse.
In Chinese astronomy the star is known as the star of the "celestial wolf" (Chinese and Japanese: 天狼 Chinese romanization: Tiānláng; Japanese romanization: Tenrō;) in the Mansion of Jǐng (井宿). Farther afield, many nations among the indigenous peoples of North America also associated Sirius with canines; the Seri and Tohono O'odham of the southwest note the star as a dog that follows mountain sheep, while the Blackfoot called it "Dog-face". The Cherokee paired Sirius with Antares as a dog-star guardian of either end of the "Path of Souls". The Pawnee of Nebraska had several associations; the Wolf (Skidi) tribe knew it as the "Wolf Star", while other branches knew it as the "Coyote Star". Further north, the Alaskan Inuit of the Bering Strait called it "Moon Dog".
Several cultures also associated the star with a bow and arrows. The Ancient Chinese visualized a large bow and arrow across the southern sky, formed by the constellations of Puppis and Canis Major. In this, the arrow tip is pointed at the wolf Sirius. A similar association is depicted at the Temple of Hathor in Dendera, where the goddess Satet has drawn her arrow at Hathor (Sirius). Known as "Tir", the star was portrayed as the arrow itself in later Persian culture.
Sirius is mentioned in "Surah", "An-Najm" ("The Star"), of the Qur'an, where it is given the name الشِّعْرَى (transliteration: "aš-ši‘rā" or "ash-shira"; the leader). The verse is: "وأنَّهُ هُوَ رَبُّ الشِّعْرَى", "That He is the Lord of Sirius (the Mighty Star)." (An-Najm:49) Ibn Kathir said in his commentary "Ibn 'Abbas, Mujahid, Qatada and Ibn Zayd said about Ash-Shi`ra that it is the bright star, named Mirzam Al-Jawza' (Sirius), which a group of Arabs used to worship." The alternate name "Aschere", used by Johann Bayer, is derived from this.
In Theosophy, it is believed the "Seven Stars of the Pleiades" transmit the spiritual energy of the Seven Rays from the "Galactic Logos" to the "Seven Stars of the Great Bear", then to Sirius. From there is it sent via the Sun to the god of Earth (Sanat Kumara), and finally through the seven Masters of the Seven Rays to the human race.
Dogon.
The Dogon people are an ethnic group in Mali, West Africa, reported to have traditional astronomical knowledge about Sirius that would normally be considered impossible without the use of telescopes. According to Marcel Griaule's books "Conversations with Ogotemmêli" and "The Pale Fox" they knew about the fifty-year orbital period of Sirius and its companion prior to western astronomers. They also refer to a third star accompanying Sirius A and B. Robert Temple's 1976 book "The Sirius Mystery", credits them with knowledge of the four Galilean moons of Jupiter and the rings of Saturn. This has been the subject of controversy and speculation. 
In particular, Noah Brosch explained in his book "Sirius Matters" that the cultural transfer of relatively modern astronomical information could have taken place in 1893, when a French expedition arrived in Central West Africa to observe the total eclipse on April 16.
Serer religion.
In the religion of the Serer people of Senegal, The Gambia and Mauritania, Sirius is called "Yoonir" from the Serer language (and some of the Cangin language speakers, who are all ethnically Serers). The star Sirius is one of the most important and sacred stars in Serer religious cosmology and symbolism. The Serer high priests and priestesses, (Saltigues, the hereditary "rain priests") chart "Yoonir" in order to forecast rain fall and enable Serer farmers to start planting seeds. In Serer religious cosmology, it is the symbol of the universe.
Modern significance.
Sirius is a frequent subject of science fiction, and has been the subject of poetry. Dante and John Milton reference the star, while Tennyson's poem "The Princess" wonderfully describes the star's scintillation:
<poem>..the fiery Sirius alters hue
And bickers into red and emerald.</poem>
 The Grateful Dead mention the dog star in the song "Lost Sailor".
Sirius is featured on the coat of arms of Macquarie University, and is the name of its alumnae journal. The name of the North American satellite radio company, Satellite CD Radio, Inc., was changed to Sirius Satellite Radio in November 1999, being named after "the brightest star in the night sky". Composer Karlheinz Stockhausen, who wrote a piece called "Sirius", has been claimed to have said on several occasions that he came from a planet in the Sirius system. To Stockhausen, Sirius stood for 'the place where music is the highest of vibrations' and where music had been developed in the most perfect way. Astronomer Noah Brosch has speculated that the name of the character Sirius Black from the Harry Potter stories, who owns a unique ability to transform into a black dog, might have been inspired by "Sirius B".
Sirius is one of the 27 stars on the flag of Brazil, where it represents the state of Mato Grosso.
Seven ships of Great Britain's Royal Navy have been called since the 18th century, with the first being the flagship of the First Fleet to Australia in 1788. The Royal Australian Navy subsequently named a vessel HMAS "Sirius" in honor of the flagship. American vessels include the USNS "Sirius" as well as a monoplane model—the Lockheed Sirius, the first of which was flown by Charles Lindbergh. The name was also adopted by Mitsubishi Motors for the Mitsubishi Sirius engine in 1980.
External links.
Coordinates: 

</doc>
<doc id="28018" url="http://en.wikipedia.org/wiki?curid=28018" title="Simon Magus">
Simon Magus

Simon the Sorcerer or Simon the Magician, in Latin Simon Magus, (Greek Σίμων ὁ μάγος) was a Samaritan magus or religious figure and a convert to Christianity, baptised by Philip the Evangelist, whose later confrontation with Peter is recorded in . The sin of simony, or paying for position and influence in the church, is named for Simon. The "Apostolic Constitutions" also accuses him of lawlessness. According to "Recognitions", Simon's parents were named Antonius and Rachel.
Surviving traditions about Simon appear in orthodox texts, such as those of Irenaeus, Justin Martyr, Hippolytus, and Epiphanius, where he is often regarded as the source of all heresies. Justin wrote that nearly all the Samaritans in his time were adherents of a certain Simon of Gitta, a village not far from Flavia Neapolis. Irenaeus held him as being one of the founders of Gnosticism and the sect of the Simonians. Hippolytus quotes from a work he attributes to Simon or his followers the Simonians, "Apophasis Megale", or "Great Declaration". According to the early church heresiologists, Simon is also supposed to have written several lost treatises, two of which bear the titles "The Four Quarters of the World" and "The Sermons of the Refuter".
In apocryphal works including the "Acts of Peter", Pseudo-Clementines, and the "Epistle of the Apostles", Simon also appears as a formidable sorcerer with the ability to levitate and fly at will.
History.
Acts of the Apostles.
The different sources for information on Simon contain quite different pictures of him, so much so that it has been questioned whether they all refer to the same person. Assuming all references are to the same person, as some (but by no means all) of the Church fathers did, the earliest reference to him is in the canonical Acts of the Apostles; this is his only appearance in the New Testament.
But there was a certain man, called Simon, which beforetime in the same city used sorcery, and bewitched the people of Samaria, giving out that himself was some great one: 10to whom they all gave heed, from the least to the greatest, saying, “This man is the great power (Gr. "Dynamis Megale") of God.” 11And to him they had regard, because that of long time he had bewitched them with sorceries. 12But when they believed Philip preaching the things concerning the kingdom of God, and the name of Jesus Christ, they were baptized, both men and women. 13Then Simon himself believed also: and when he was baptized, he continued with Philip, and wondered, beholding the miracles and signs which were done. 14Now when the apostles which were at Jerusalem heard that Samaria had received the word of God, they sent unto them Peter and John: 15who, when they were come down, prayed for them, that they might receive the Holy Ghost: 16(for as yet he was fallen upon none of them: only they were baptized in the name of the Lord Jesus.) 17Then laid they their hands on them, and they received the Holy Ghost. 18And when Simon saw that through laying on of the apostles’ hands the Holy Ghost was given, he offered them money, 19saying, “Give me also this power, that on whomsoever I lay hands, he may receive the Holy Ghost.” 20But Peter said unto him, “Thy money perish with thee, because thou hast thought that the gift of God may be purchased with money. 21Thou hast neither part nor lot in this matter: for thy heart is not right in the sight of God. 22Repent therefore of this thy wickedness, and pray God, if perhaps the thought of thine heart may be forgiven thee, 23for I perceive that thou art in the gall of bitterness, and in the bond of iniquity.” 24Then answered Simon, and said, “Pray ye to the Lord for me, that none of these things which ye have spoken come upon me.”
Josephus.
Josephus mentions a magician named Atomus (Simon in Latin manuscripts) as being involved with the procurator Felix, King Agrippa II and his sister Drusilla, where Felix has Simon convince Drusilla to marry him instead of the man she was engaged to. Some scholars have considered the two to be identical, although this is not generally accepted, as the Simon of Josephus is a Jew rather than a Samaritan.
Justin Martyr and Irenaeus.
Justin Martyr (in his "Apologies", and in a lost work against heresies, which Irenaeus used as his main source) and Irenaeus ("Adversus Haereses") record that after being cast out by the Apostles, Simon Magus came to Rome where, having joined to himself a profligate woman of the name of Helen, he gave out that it was he who appeared among the Jews as the Son, in Samaria as the Father and among other nations as the Holy Spirit. He performed such miracles by magic acts during the reign of Claudius that he was regarded as a god and honored with a statue on the island in the Tiber which the two bridges cross, with the inscription "Simoni Deo Sancto", "To Simon the Holy God".
Myth of Simon and Helen.
Justin and Irenaeus are the first to recount the myth of Simon and Helen, which became the center of Simonian doctrine. Epiphanius of Salamis also makes Simon speak in the first person in several places in his "Panarion", and the inference is that he is quoting from a version of it, though perhaps not verbatim.
In the beginning God had his first thought, his "Ennoia", which was female, and that thought was to create the angels. The First Thought then descended into the lower regions and created the angels. But the angels rebelled against her out of jealousy and created the world as her prison, imprisoning her in a female body. Thereafter, she was reincarnated many times, each time being shamed. Her many reincarnations included Helen of Troy, among others, and she finally was reincarnated as Helen, a slave and prostitute in the Phoenician city of Tyre. God then descended in the form of Simon Magus, to rescue his "Ennoia", and to confer salvation upon men through knowledge of himself.
For as the angels were mismanaging the world, owing to their individual lust for rule, he had come to set things straight, and had descended under a changed form, likening himself to the Principalities and Powers through whom he passed, so that among men he appeared as a man, though he was not a man, and was thought to have suffered in Judaea, though he had not suffered.
But the prophets had delivered their prophecies under the inspiration of the world-creating angels: wherefore those who had their hope in him and in Helen minded them no more, and, as being free, did what they pleased; for men were saved according to his grace, but not according to just works. For works were not just by nature, but only by convention, in accordance with the enactments of the world-creating angels, who by precepts of this kind sought to bring men into slavery. Wherefore he promised that the world should be dissolved, and that those who were his should be freed from the dominion of the world-creators. 
In this account of Simon there is a large portion common to almost all forms of Gnostic myths, together with something special to this form. They have in common the place in the work of creation assigned to the female principle, the conception of the Deity; the ignorance of the rulers of this lower world with regard to the Supreme Power; the descent of the female (Sophia) into the lower regions, and her inability to return. Special to the Simonian tale is the identification of Simon himself with the Supreme, and of his consort Helena with the female principle.
Hippolytus.
In Philosophumena Hippolytus provides an extensive quotation of the document called Apophasis Megale or Great Revelation which the author believed to be written by Simon himself. Apart from that he retells the narrative on Simon written by Irenaeus (whho in his turn based it on the lost Syntagma of Justin).
Upon the story of "the lost sheep," Hippolytus (in his "Philosophumena") comments as follows.
But the liar was enamoured of this wench, whose name was Helen, and had bought her and had her to wife, and it was out of respect for his disciples that he invented this fairy-tale.
Also, Hippolytus demonstrates acquaintance with the folk tradidion on Simon which depicts him rather as a magician than gnostic and contains multiple stories on his confrontation with Peter (also present in the apocrypha and Pseudo-Clementine literature).
Reduced to despair by the curse laid upon him by Peter in the Acts, Simon soon abjured the faith and embarked on the career of a sorcerer:
Until he came to Rome also and fell foul of the Apostles. Peter withstood him on many occasions. At last he came [. . .] and began to teach sitting under a plane tree. When he was on the point of being shown up, he said, in order to gain time, that if he were buried alive he would rise again on the third day. So he bade that a tomb should be dug by his disciples and that he should be buried in it. Now they did what they were ordered, but he remained there until now: for he was not the Christ.
Simonians.
Hippolytus gives a much more doctrinally detailed account of Simonianism, including a system of divine emanations and interpretations of the Old Testament, with extensive quotations from the "Apophasis Megale". Some believe that Hippolytus' account is of a later, more developed form of Simonianism, and that the original doctrines of the group were simpler, close to the account given by Justin Martyr and Irenaeus (this account however is also included in Hippolytus' work).
Hippolytus says the free love doctrine was held by them in its purest form, and speaks in language similar to that of Irenaeus about the variety of magic arts practiced by the Simonians, and also of their having images of Simon and Helen under the forms of Zeus and Athena. But he also adds, "if any one, on seeing the images either of Simon or Helen, shall call them by those names, he is cast out, as showing ignorance of the mysteries."
Epiphanius.
Epiphanius writes that there were some Simonians still in existence in his day (c. AD 367), but he speaks of them as almost extinct. Gitta, he says, had sunk from a town into a village. Epiphanius further charges Simon with having tried to wrest the words of St. Paul about the armour of God (Ephesians 6:14–16) into agreement with his own identification of the "Ennoia" with Athena. He tells us also that he gave barbaric names to the "principalities and powers," and that he was the beginning of the Gnostics. The Law, according to him, was not of God, but of "the sinister power." The same was the case with the prophets, and it was death to believe in the Old Testament.
Cyril of Jerusalem.
Cyril of Jerusalem (346 AD) in the sixth of his Catechetical Lectures prefaces his history of the Manichaeans by a brief account of earlier heresies: Simon Magus, he says, had given out that he was going to be translated to heaven, and was actually careening through the air in a chariot drawn by demons when Peter and Paul knelt down and prayed, and their prayers brought him to earth a mangled corpse.
Apocrypha.
"Acts of Peter".
The apocryphal "Acts of Peter" gives a more elaborate tale of Simon Magus' death. Simon is performing magic in the Forum, and in order to prove himself to be a god, he levitates up into the air above the Forum. The apostle Peter prays to God to stop his flying, and he stops mid-air and falls into a place called the "Sacra Via" (meaning, Holy Way), breaking his legs "in three parts". The previously non-hostile crowd then stones him. Now gravely injured, he had some people carry him on a bed at night from Rome to Ariccia, and was brought from there to Terracina to a person named Castor, who on accusations of sorcery was banished from Rome. The Acts then continue to say that he died "while being sorely cut by two physicians".
"Acts of Peter and Paul".
Another apocryphal document, the "Acts of Peter and Paul" gives a slightly different version of the above incident, which was shown in the context of a debate in front of the Emperor Nero. In this version, Paul the Apostle is present along with Peter, Simon levitates from a high wooden tower made upon his request, and dies "divided into four parts" due to the fall. Peter and Paul were then put in prison by Nero while ordering Simon's body be kept carefully for three days (thinking he would rise again).
Pseudo-Clementine literature.
The Pseudo-Clementine "Recognitions" and "Homilies" give an account of Simon Magus and some of his teachings in regards to the Simonians. They are of uncertain date and authorship, and seem to have been worked over by several hands in the interest of diverse forms of belief.
Simon was a Samaritan, and a native of Gitta. The name of his father was Antonius, that of his mother Rachel. He studied Greek literature in Alexandria, and, having in addition to this great power in magic, became so ambitious that he wished to be considered a highest power, higher even than the God who created the world. And sometimes he "darkly hinted" that he himself was Christ, calling himself the Standing One. Which name he used to indicate that he would stand for ever, and had no cause in him for bodily decay. He did not believe that the God who created the world was the highest, nor that the dead would rise. He denied Jerusalem, and introduced Mount Gerizim in its stead. In place of the Christ of the Christians he proclaimed himself; and the Law he allegorized in accordance with his own preconceptions. He did indeed preach righteousness and judgment to come.
There was one John the Baptist, who was the forerunner of Jesus in accordance with the law of parity; and as Jesus had twelve Apostles, bearing the number of the twelve solar months, so had he thirty leading men, making up the monthly tale of the moon. One of these thirty leading men was a woman called Helen, and the first and most esteemed by John was Simon. But on the death of John he was away in Egypt for the practice of magic, and one Dositheus, by spreading a false report of Simon's death, succeeded in installing himself as head of the sect. Simon on coming back thought it better to dissemble, and, pretending friendship for Dositheus, accepted the second place. Soon, however, he began to hint to the thirty that Dositheus was not as well acquainted as he might be with the doctrines of the school.
Dositheus, when he perceived that Simon was depreciating him, fearing lest his reputation among men might be obscured (for he himself was supposed to be the Standing One), moved with rage, when they met as usual at the school, seized a rod, and began to beat Simon; but suddenly the rod seemed to pass through his body, as if it had been smoke. On which Dositheus, being astonished, says to him, ‘Tell me if thou art the Standing One, that I may adore thee.’ And when Simon answered that he was, then Dositheus, perceiving that he himself was not the Standing One, fell down and worshipped him, and gave up his own place as chief to Simon, ordering all the rank of thirty men to obey him; himself taking the inferior place which Simon formerly occupied. Not long after this he died.
The encounter between both Dositheus and Simon Magus was the beginnings of the sect of Simonians. The narrative goes on to say that Simon, having fallen in love with Helen, took her about with him, saying that she had come down into the world from the highest heavens, and was his mistress, inasmuch as she was Sophia, the Mother of All. It was for her sake, he said, that the Greeks and Barbarians fought the Trojan War, deluding themselves with an image of truth, for the real being was then present with the First God. By such allegories Simon deceived many, while at the same time he astounded them by his magic. A description is given of how he made a familiar spirit for himself by conjuring the soul out of a boy and keeping his image in his bedroom, and many instances of his feats of magic are given.
"Simon Magus" as a cipher.
Anti-Paulinism.
The Pseudo-Clementine writings were used in the 4th century by members of the Ebionite sect, one characteristic of which was hostility to Paul, whom they refused to recognize as an apostle. Ferdinand Christian Baur (1792–1860), founder of the Tübingen School, drew attention to the anti-Pauline characteristic in the Pseudo-Clementines, and pointed out that in the disputations between Simon and Peter, some of the claims Simon is represented as making (e.g. that of having seen the Lord, though not in his lifetime, yet subsequently in vision) were really the claims of Paul; and urged that Peter's refutation of Simon was in some places intended as a polemic against Paul. The enmity between Peter and Simon is clearly shown. Simon's magical powers are juxtaposed with Peter's powers in order to express Peter's authority over Simon through the power of prayer, and in the the identification of Paul with Simon Magus is effected. Simon is there made to maintain that he has a better knowledge of the mind of Jesus than the disciples, who had seen and conversed with Him in person. His reason for this strange assertion is that visions are superior to waking reality, as divine is superior to human. Peter has much to say in reply to this, but the passage which mainly concerns us is as follows:
But can any one be educated for teaching by vision? And if you shall say, "It is possible," why did the Teacher remain and converse with waking men for a whole year? And how can we believe you even as to the fact that he appeared to you? And how can he have appeared to you seeing that your sentiments are opposed to his teaching? But if you were seen and taught by him for a single hour, and so became an apostle, then preach his words, expound his meaning, love his apostles, fight not with me who had converse with him. For it is against a solid rock, the foundation-stone of the Church, that you have opposed yourself in opposing me. If you were not an adversary, you would not be slandering me and reviling the preaching that is given through me, in order that, as I heard myself in person from the Lord, when I speak I may not be believed, as though forsooth it were I who was condemned and I who was reprobate. Or, if you call me condemned, you are accusing God who revealed the Christ to me, and are inveighing against Him who called me blessed on the ground of the revelation. But if indeed you truly wish to work along with the truth, learn first from us what we learnt from Him, and when you have become a disciple of truth, become our fellow-workman.
The anti-Pauline context of the Pseudo-Clementines is recognised, but the association with Simon Magus is surprising since they have little in common. However the majority of scholars accept Baur's identification, though others, including Lightfoot, argued extensively that the "Simon Magus" of the Pseudo-Clementines was not meant to stand for Paul. Recently, Berlin pastor Hermann Detering (1995) has made the case that the veiled anti-Pauline stance of the Pseudo-Clementines has historical roots, that the Acts 8 encounter between Simon the magician and Peter is itself based on the conflict between Peter and Paul. His view has not found general support among scholars but Robert M. Price argues much the same case in "The Amazing Colossal Apostle:The Search for the Historical Paul" (2012).
Anti-Marcionism.
There are other features in the portrait which remind us strongly of Marcion. For the first thing which we learn from the "Homilies" about Simon's opinions is that he denied that God was just. By "God" he meant the Creator. But he undertakes to prove from Scripture that there is a higher God, who really possesses the perfections which are falsely ascribed to the lower. On these grounds Peter complains that, when he was setting out for the Gentiles to convert them from their worship of "many gods upon earth", the Evil Power had sent Simon before him to make them believe that there were "many gods in heaven".
Medieval legends, later interpretations.
The church of Santa Francesca Romana, Rome, is claimed to have been built on the spot where Simon fell. Within the Church is a dented slab of marble that purports to bear the imprints of the knees of Peter and Paul during their prayer. The fantastic stories of Simon the Sorcerer persisted into the later Middle Ages, becoming a possible inspiration for the "Faustbuch" and Goethe's Faust.
The opening story in Danilo Kiš's 1983 collection "The Encyclopedia of the Dead", "Simon Magus", retells the confrontation between Simon and Peter agreeing with the account in the "Acts of Peter", and provides an additional alternative ending in which Simon asks to be buried alive in order to be resurrected three days later (after which his body is found putrefied).
Bibliography.
Attribution

</doc>
<doc id="28020" url="http://en.wikipedia.org/wiki?curid=28020" title="September 10">
September 10

September 10 is the day of the year in the Gregorian calendar.

</doc>
<doc id="28021" url="http://en.wikipedia.org/wiki?curid=28021" title="September 12">
September 12

September 12 is the day of the year in the Gregorian calendar.

</doc>
<doc id="28022" url="http://en.wikipedia.org/wiki?curid=28022" title="School">
School

A school is an institution designed for the teaching of students (or "pupils") under the direction of teachers. Most countries have systems of formal education, which is commonly compulsory. In these systems, students progress through a series of schools. The names for these schools vary by country (discussed in the "Regional" section below) but generally include primary school for young children and secondary school for teenagers who have completed primary education. An institution where higher education is taught, is commonly called a university college or university.
In addition to these core schools, students in a given country may also attend schools before and after primary and secondary education. Kindergarten or pre-school provide some schooling to very young children (typically ages 3–5). University, vocational school, college or seminary may be available after secondary school. A school may also be dedicated to one particular field, such as a school of economics or a school of dance. Alternative schools may provide nontraditional curriculum and methods.
There are also non-government schools, called private schools. Private schools may be required when the government does not supply adequate, or special education. Other private schools can also be religious, such as Christian schools, hawzas, yeshivas, and others; or schools that have a higher standard of education or seek to foster other personal achievements. Schools for adults include institutions of corporate training, Military education and training and business schools.
In homeschooling and online schools, teaching and learning take place outside of a traditional school building.
Etymology.
The word "school" derives from Greek σχολή " (scholē"), originally meaning "leisure" and also "that in which leisure is employed", but later "a group to whom lectures were given, school".
History and development.
The concept of grouping students together in a centralized location for learning has existed since Classical antiquity. Formal schools have existed at least since ancient Greece (see Academy), ancient Rome (see Education in Ancient Rome) ancient India (see Gurukul), and ancient China (see History of education in China). The Byzantine Empire had an established schooling system beginning at the primary level. According to "Traditions and Encounters", the founding of the primary education system began in 425 AD and "... military personnel usually had at least a primary education ...". The sometimes efficient and often large government of the Empire meant that educated citizens were a must. Although Byzantium lost much of the grandeur of Roman culture and extravagance in the process of surviving, the Empire emphasized efficiency in its war manuals. The Byzantine education system continued until the empire's collapse in 1453 AD.
Islam was another culture that developed a school system in the modern sense of the word. Emphasis was put on knowledge, which required a systematic way of teaching and spreading knowledge, and purpose-built structures. At first, mosques combined both religious performance and learning activities, but by the 9th century, the Madrassa was introduced, a proper school that was built independently from the mosque. They were also the first to make the "Madrassa" system a public domain under the control of the Caliph. The Nizamiyya madrasa is considered by consensus of scholars to be the earliest surviving school, built towards 1066 AD by Emir Nizam Al-Mulk.
Under the Ottomans, the towns of Bursa and Edirne became the main centers of learning. The Ottoman system of Külliye, a building complex containing a mosque, a hospital, madrassa, and public kitchen and dining areas, revolutionized the education system, making learning accessible to a wider public through its free meals, health care and sometimes free accommodation.
The 19th century historian, Scott holds that a remarkable correspondence exists between the procedure established by those institutions and the methods of the present day. They had their collegiate courses, their prizes for proficiency in scholarship, their oratorical and poetical contests, their commencements and their degrees. In the department of medicine, a severe and prolonged examination, conducted by the most eminent physicians of the capital, was exacted of all candidates desirous of practicing their profession, and such as were unable to stand the test were formally pronounced incompetent. 
In Europe, universities emerged during the 12th century; here, scholasticism was an important tool, and the academicians were called "schoolmen". During the Middle Ages and much of the Early Modern period, the main purpose of schools (as opposed to universities) was to teach the Latin language. This led to the term grammar school, which in the United States informally refers to a primary school, but in the United Kingdom means a school that selects entrants based on ability or aptitude. Following this, the school curriculum has gradually broadened to include literacy in the vernacular language as well as technical, artistic, scientific and practical subjects.
Obligatory school attendance became common in parts of Europe during the 18th century. In Denmark-Norway, this was introduced as early as in 1739-1741, the primary end being to increase the literacy of the "", i.e. the "regular people". Many of the earlier public schools in the United States and elsewhere were one-room schools where a single teacher taught seven grades of boys and girls in the same classroom. Beginning in the 1920s, one-room schools were consolidated into multiple classroom facilities with transportation increasingly provided by kid hacks and school buses.
Regional terms.
The use of the term "school" varies by country, as do the names of the various levels of education within the country.
United Kingdom and Commonwealth of Nations.
In the United Kingdom, the term "school" refers primarily to pre-university institutions, and these can, for the most part, be divided into pre-schools or nursery schools, primary schools (sometimes further divided into infant school and junior school), and secondary schools. Various types of secondary schools in England and Wales include grammar schools, comprehensives, secondary moderns, and city academies. In Scotland, while they may have different names, all Secondary schools are the same, except in that they may be funded by the state, or independently funded (see next paragraph). It is unclear if "Academies", which are a hybrid between state and independently funded/controlled schools and have been introduced to England in recent years, will ever be introduced to Scotland. School performance in Scotland is monitored by Her Majesty's Inspectorate of Education. Ofsted reports on performance in England and Estyn reports on performance in Wales.
In the United Kingdom, most schools are publicly funded and known as state schools or maintained schools in which tuition is provided free. There are also private schools or independent schools that charge fees. Some of the most selective and expensive private schools are known as public schools, a usage that can be confusing to speakers of North American English. In North American usage, a public school is one that is publicly funded or run.
In much of the Commonwealth of Nations, including Australia, New Zealand, India, Pakistan, Bangladesh, Sri Lanka, South Africa, Kenya, and Tanzania, the term "school" refers primarily to pre-university institutions.
India.
In ancient India, schools were in the form of Gurukuls. Gurukuls were traditional Hindu residential schools of learning; typically the teacher's house or a monastery. During the Mughal rule, Madrasahs were introduced in India to educate the children of Muslim parents. British records show that indigenous education was widespread in the 18th century, with a school for every temple, mosque or village in most regions of the country. The subjects taught included Reading, Writing, Arithmetic, Theology, Law, Astronomy, Metaphysics, Ethics, Medical Science and Religion.
Under the British rule in India, Christian missionaries from England, USA and other countries established missionary and boarding schools throughout the country. Later as these schools gained in popularity, more were started and some gained prestige. These schools marked the beginning of modern schooling in India and the syllabus and calendar they followed became the benchmark for schools in modern India. Today most of the schools follow the missionary school model in terms of tutoring, subject / syllabus, governance etc.with minor changes. Schools in India range from schools with large campuses with thousands of students and hefty fees to schools where children are taught under a tree with a small / no campus and are totally free of cost. There are various boards of schools in India, namely Central Board for Secondary Education (CBSE), Council for the Indian School Certificate Examinations (CISCE), Madrasa Boards of various states, Matriculation Boards of various states, State Boards of various boards, Anglo Indian Board, and so on. The typical syllabus today includes Language(s), Mathematics, Science — Physics, Chemistry, Biology, Geography, History, General Knowledge, Information Technology / Computer Science etc.. Extra curricular activities include physical education / sports and cultural activities like music, choreography, painting, theater / drama etc.
Europe.
In much of continental Europe, the term "school" usually applies to primary education, with primary schools that last between four and nine years, depending on the country. It also applies to secondary education, with secondary schools often divided between "Gymnasiums" and vocational schools, which again depending on country and type of school educate students for between three and six years. In Germany students graduating from Grundschule are not allowed to directly progress into a vocational school, but are supposed to proceed to one of Germany's general education schools such as Gesamtschule, Hauptschule, Realschule or Gymnasium. When they leave that school, which usually happens at age 15-19 they are allowed to proceed to a vocational school. The term school is rarely used for tertiary education, except for some "upper" or "high" schools (German: Hochschule), which describe colleges and universities.
In Eastern Europe modern schools (after World War II), of both primary and secondary educations, often are combined, while secondary education might be split into accomplished or not. The schools are classified as middle schools of general education and for the technical purposes include "degrees" of the education they provide out of three available: the first — primary, the second — unaccomplished secondary, and the third — accomplished secondary. Usually the first two degrees of education (eight years) are always included, while the last one (two years) gives option for the students to pursue vocational or specialized educations.
North America and the United States.
In North America, the term "school" can refer to any educational institution at any level, and covers all of the following: preschool (for toddlers), kindergarten, elementary school, middle school (also called intermediate school or junior high school, depending on specific age groups and geographic region), senior high school, college, university, and graduate school.
In the US, school performance through high school is monitored by each state's Department of Education. Charter schools are publicly funded elementary or secondary schools that have been freed from some of the rules, regulations, and statutes that apply to other public schools. The terms grammar school and "grade school" are sometimes used to refer to a primary school.
Ownership and operation.
Many schools are owned or funded by states. Private schools operate independently from the government. Private schools usually rely on fees from families whose children attend the school for funding; however, sometimes such schools also receive government support (for example, through School vouchers). Many private schools are affiliated with a particular religion; these are known as parochial schools.
Starting a school.
The Toronto District School Board is an example of a school board that allows parents to design and propose new schools.
When designing a school, factors that need to be decided include:
Components of most schools.
Schools are organized spaces purposed for teaching and learning. The classrooms, where teachers teach and students learn, are of central importance. Classrooms may be specialized for certain subjects, such as laboratory classrooms for science education and workshops for industrial arts education.
Typical schools have many other rooms and areas, which may include:
Security.
The safety of staff and students is increasingly becoming an issue for school communities, an issue most schools are addressing through improved security. Some have also taken measures such as installing metal detectors or video surveillance. Others have even taken measures such as having the children swipe identification cards as they board the school bus. For some schools, these plans have included the use of door numbering to aid public safety response.
Other security concerns faced by schools include bomb threats, gangs, vandalism, and bullying.
Health services.
School health services are services from medical, teaching and other professionals applied in or out of school to improve the health and well-being of children and in some cases whole families. These services have been developed in different ways around the globe but the fundamentals are constant: the early detection, correction, prevention or amelioration of disease, disability and abuse from which school aged children can suffer.
Online schools and classes.
Some schools offer remote access to their classes over the Internet. Online schools also can provide support to traditional schools, as in the case of the School Net Namibia.
Some online classes also provide experience in a class, so that when people take them, they have already been introduced to the subject and know what to expect, and even more classes provide High School/College credit allowing people to take the classes at their own pace. Many online classes cost money to take but some are offered free.
Internet-based distance learning programs are offered widely through many universities. Instructors teach through online activities and assignments. Online classes are taught the same as physically being in class with the same curriculum. The instructor offers the syllabus with their fixed requirements like any other class. Students can virtually turn their assignments in to their instructors according to deadlines. This being through via email or in the course webpage. This allowing students to work at their own pace, yet meeting the correct deadline. Students taking an online class have more flexibility in their schedules to take their classes at a time that works best for them. Conflicts with taking an online class may include not being face to face with the instructor when learning or being in an environment with other students. Online classes can also make understanding the content difficult, especially when not able to get in quick contact with the instructor. Online students do have the advantage of using other online sources with assignments or exams for that specific class. Online classes also have the advantage of students not needing to leave their house for a morning class or worrying about their attendance for that class. Students can work at their own pace to learn and achieve within that curriculum. 
Stress.
As a profession, teaching has levels of work-related stress (WRS) that are among the highest of any profession in some countries, such as the United Kingdom and the United States. The degree of this problem is becoming increasingly recognized and support systems are being put into place. Teacher education increasingly recognizes the need to train those new to the profession to be aware of and overcome mental health challenges they may face.
Stress sometimes affects students more severely than teachers, up to the point where the students are prescribed stress medication. This stress is claimed to be related to standardized testing, and the pressure on students to score above average. "See Cram school".
Discipline.
Schools and their teachers have always been under pressure — for instance, pressure to cover the curriculum, to perform well in comparison to other schools, and to avoid the stigma of being "soft" or "spoiling" toward students. Forms of discipline, such as control over when students may speak, and normalized behaviour, such as raising a hand to speak, are imposed in the name of greater efficiency. Practitioners of critical pedagogy maintain that such disciplinary measures have no positive effect on student learning. Indeed, some argue that disciplinary practices detract from learning, saying that they undermine students' individual dignity and sense of self-worth—the latter occupying a more primary role in students' hierarchy of needs.

</doc>
<doc id="28024" url="http://en.wikipedia.org/wiki?curid=28024" title="Sontaran">
Sontaran

The Sontarans are a fictional extraterrestrial race of humanoids from the British science fiction television series "Doctor Who", and also seen in spin-off series "The Sarah Jane Adventures". A warrior race who live to kill, they are characterised by their ruthlessness and fearlessness of death.
They were created by writer Robert Holmes. During rehearsals for their first appearance, actor Kevin Lindsay, who portrayed the original Sontaran, Linx, pronounced the race's name as ""son-TAR-an"." Alan Bromly, the director, tried to correct him by saying it should be pronounced with the stress on the first syllable. Lindsay declared "Well, I think it's "son-TAR-an", and since I'm from the f**king place, I should know." His preferred pronunciation was retained.
Culture.
The Sontarans are a race of humanoids with a stocky build, greenish brown skin, a distinctive dome-shaped head, and they have only three fingers on each hand. Their musculature is designed for load-bearing rather than leverage, because of the significant amount of gravity on their home planet. Ross Jenkins in "The Sontaran Stratagem" describes a Sontaran as resembling "a talking baked potato". Sontarans come from a large, dense planet named Sontar in the "southern spiral arm of the galaxy" which has a very strong gravitational field, which explains their compact stocky form. They are far stronger than humans, and in the recent series are shorter than the average human male.
The Sontarans have an extremely militaristic and warlike culture; every aspect of their society is geared toward warfare, and every experience is viewed in terms of its martial relevance. In "The Sontaran Experiment", the Fourth Doctor comments that "Sontarans never do anything without a military reason." In fact, to die heroically in battle is their ultimate goal. Aside from a ritualistic chant in "The Sontaran Strategem"/"The Poison Sky", they are never seen to engage in any activity that would be considered recreation, though a few offhand comments by Commander Skorr in "The Poison Sky" suggest they do consider hunting a sport. According to their creator Robert Holmes, Sontarans do have a highly developed artistic culture, but have put it on hold for the duration of the war, while the opening chapter of the novelisation of "The Time Warrior", based on Holmes' incomplete draft, refers to Linx listening to the Sontaran anthem while his spaceship is in flight.
The Sontarans depicted in the series have detached, smug personalities, and a highly developed sense of honour; on multiple occasions, the Doctor has used his knowledge of their pride in their species to manipulate them. In "The Sontaran Stratagem", the Doctor nevertheless referred to them as "the finest soldiers in the galaxy".
Although physically formidable, the Sontarans' weak spot is the "probic vent" at the back of their neck, through which they draw nutrition. It is also part of their cloning process. It provides incentive to continue moving forward in battle since retreat would expose this area to their enemies. They have been killed by targeting that location with a knife ("The Invasion of Time"), a screwdriver (""), and an arrow ("The Time Warrior"). Even something as simple as a squash ball aimed at that point ("The Sontaran Stratagem") or contact by the heel of a shoe ("The Last Sontaran") is capable of incapacitating them temporarily. They are also vulnerable to "coronic acid" ("The Two Doctors"). While the Sontaran wear protective helmets in battle, to fight without their helmets, or to be "open-skinned," is an honour for the Sontaran.
In the episode "The Poison Sky", it is revealed that the Sontaran Empire have been at war with the Rutan Host for more than 50,000 years, and which, at a time around 2008, they are losing. The war is still raging at least 20,000 years later, in the serial "The Sontaran Experiment".
All the Sontarans depicted in the television series have monosyllabic names, many beginning with an initial 'st' sound (e.g. Styre ("The Sontaran Experiment"), Stor ("The Invasion of Time"), Stike ("The Two Doctors"), Staal ("The Sontaran Stratagem"), Skorr ("The Sontaran Stratagem"), Stark ("The Pandorica Opens"), and Strax ("A Good Man Goes To War"); exceptions are Linx ("The Time Warrior"), Varl ("The Two Doctors"), Jask ("The End of Time"), and Kaagh ("The Sarah Jane Adventures")). Subdivisions of the Sontaran military structure mentioned in the series include the Sontaran G3 Military Assessment Survey and the Grand Strategic Council, the Ninth Sontaran Battle Group, the Fifth Army Space Fleet of the Sontaran Army Space Corps, and the Tenth Sontaran Battle Fleet. Military titles include Commander, Group Marshal, Field Major, and General. Agnomens include "the Undefeated", "the Bloodbringer", "the Avenger" and "the Slayer".
Reproduction.
The Sontarans reproduce by means of cloning rather than sexual reproduction, and thus for the most part are extremely similar in appearance. Human characters in both "The Sontaran Experiment" and "The Sontaran Stratagem" comment on how closely individual Sontarans resemble one another; however, it should be noted that their height, skin tone, facial features, vocal timbre and accent, hair, spacing of teeth and even number of fingers have varied from story to story, and sometimes within stories. When Luke Rattigan asks how they can tell each other apart in "The Sontaran Stratagem", General Staal remarks that they say the same of humans.
In "The Time Warrior", Linx states that "at the Sontaran Military Academy we have hatchings of a million cadets at each muster parade." The Doctor also comments in "The Invasion of Time" that Sontarans can mass-clone themselves at rates up to a million embryos every four minutes. Thereafter the clones take just ten minutes to grow to adulthood. When the Sontaran reach adulthood, under the charge of Sontaran High Command, each warrior is immediately given a rank and dispatched on a battle mission. From day one, the Sontarans are sent to battle.
Sontarans reproduce asexually and all the Sontarans depicted in the television series are of one gender; referred to with masculine pronouns, however it is not known if they possess distinctly male physiologies. General Staal comments that "words are the weapons of womenfolk" and that the clone of Martha Jones performed well "for a female" as commentary on the gender inequalities of other species. This typifies a Sontaran trait: interested only in the strongest fighters in any group or race. Despite this, Strax appeared perfectly comfortable with the prospect of wearing dresses in "The Battle of Demon's Run - Two Days Later"; he ultimately dressed in human gentleman's attire, nevertheless. In "The Time Warrior", when Linx examines Sarah Jane, he comments on how the human reproduction system is 'inefficient' and that humans 'should change it'. As multiple genders are foreign to them, Sontarans are known to confuse human sexes; Strax routinely addresses young women as "Boy" and vice versa. and claims not to have known that River Song was a woman.
In "The Sontaran Stratagem", the Sontarans are seen to create human clones by growing them in tubs of green fluid. "Enemy of the Bane" confirms that Sontarans are cloned in the same way. In a human clone, the umbilical corresponds to the probic vent on the back of a Sontaran's neck, suggesting that the vent is not unlike the human navel, albeit clearly more complex.
Technology.
The Tenth Sontaran Battle Fleet in the new series consists of a Command Ship and a number of capsules that can be moved into position when Battle Status is enjoined. Sontaran ships are impervious to nuclear missiles. In both the classic and new series, Sontarans are depicted using spherical or semi-spherical single-occupant spacecraft known as capsules. Each capsule is small enough to avoid detection by radar and is piloted by an individual Sontaran. "The Sontaran Stratagem" also saw the introduction of a large mothership from which the small Sontaran capsules could be seen to originate. The Doctor notes that the one ship by itself is enough to completely wipe out Earth.
The Sontarans have a variety of weapons. Their trade-mark weapon is a small rod with two handles and a plunger at one end, giving it a syringe style. This is so it can be held and fired using three fingers. This weapon fires a disabling beam that can temporarily render a person useless and emits an energy pulse that can repair systems like the teleport, and has appeared in every Sontaran story except "The Sontaran Experiment". When first used by Commander Linx in "The Time Warrior", it shows the ability to fire a beam which can disarm by knocking the weapon out of the wielder's hand, hypnotise, as well as cutting through wood, disabling limbs and killing.
In "The Sontaran Experiment", Field Major Styre instead used a small red laser pistol which only killed (although it did not kill the Doctor, because of a small metal plate the Doctor had been keeping in his inside pocket). "The Invasion of Time" saw Commander Stor using the small rod again, but also in episode six, a Sontaran trooper uses a short black rifle-like laser to try to burn through a lock on a door inside the TARDIS. "The Two Doctors" introduced a weapon called the Meson Gun (as named in the Jim'll Fix It Sketch, "A Fix with Sontarans"), a large silver rifle with a red fuel tank in the centre which was used by Group Marshal Stike and Varl in the third episode. It seemed to be some kind of flame-thrower as it fired a jet of flames very briefly. Group Marshal Stike was also seen carrying a baton.
It would not be until "The Sontaran Stratagem" that General Staal would show that the baton can fire an orange beam that could stun the target. In "The Poison Sky", Commander Skorr and his troops carry large laser rifles into battle. These rifles are the Sontaran gun of the Tenth Sontaran Battle Fleet. Each rifle has a laser beam that kills instantly and is designed for a three-fingered grip. In "The Invasion of Time", their armour is shown to be resistant to Time Lord stasers and K-9's blaster. However, their armour is vulnerable to standard human firearms in "The Poison Sky", but the Sontarans in that episode used a 'cordolane signal' which caused the copper-lined bullets to expand, jamming most firearms instantly. UNIT troops overcame this by switching to steel-lined bullets.
"The Sarah Jane Adventures" story "The Last Sontaran" showed further technological advancements of the modern Sontarans. Commander Kaagh, a surviving pilot from the tenth Sontaran battle fleet, had slightly different armour due to being from the special forces. His suit featured no gloves, so his bare hands were visible. And on his left arm was a control panel for his suit and ship. His helmet could fold up and retract and both his suit and ship featured cloaking devices, turning them both invisible. While the soldiers of the tenth fleet were armed with large laser rifles, Kaagh has a smaller laser carbine. Rather than hypnotising humans (as Sarah pointed out they usually do), instead, Kaagh fixed neural control devices to the back of the necks of his human agents. A red light flashes when it is operational, and Kaagh can activate and deactivate them when he wants with his control panel.
A pair of Sontarans that tried to invade Trenzalore in "Time of the Doctor" used a two-man craft with an invisibility field.
Appearances.
Television.
The Sontarans made their first appearance in 1973 in the serial "The Time Warrior" by Robert Holmes, where a Sontaran named Linx is stranded in the Middle Ages. Another Sontaran named Styre appears in "The Sontaran Experiment", experimenting on captured astronauts on a future Earth. They later appear in "The Invasion of Time", where they successfully invade Gallifrey, but are driven out again after less than a day. They appear for the final time in the original series in "The Two Doctors". The Sontarans also appeared in a skit for the BBC children's programme "Jim'll Fix It" titled "A Fix with Sontarans", along with Colin Baker as the Sixth Doctor and Janet Fielding as Tegan Jovanka. Though the two species are never seen together, several references are made in Sontaran episodes to the Rutan Host, an equally militaristic race with whom the Sontarans have been at war for thousands of years. The Rutans appear in the serial "Horror of Fang Rock".
Sporting an updated design, Sontarans returned to the revived series in the series 4 (2008) episodes "The Sontaran Strategem" and "The Poison Sky". The Sontarans plan to terraform the Earth into a new clone world, but their plans are averted by the Tenth Doctor (David Tennant). It is also revealed that the race was excluded from the Time War of the revived series' backstory. In "Turn Left", the same events are depicted in a parallel universe, where through exposition describes their plan as foiled by Torchwood (characters from the spin-off show of that name), at the cost of their lives, with Torchwood leader Jack Harkness being captured by the Sontarans. In "The Stolen Earth", UNIT is revealed to have developed a teleportation device based on Sontaran technology. A lone survivor from the events of "The Poison Sky", Kaagh (Anthony O'Donnell), next appears in "The Last Sontaran", from spin-off series "The Sarah Jane Adventures". Kaagh appears again in "Enemy of the Bane". In "Doctor Who"‍ '​s "The End of Time, Part Two" (2010), a Sontaran sniper (Dan Starkey) briefly appears pursuing the Doctor's former companions Mickey Smith (Noel Clarke) and his wife Martha Jones (Freema Agyeman), but is defeated by the Doctor before he can assassinate them. Alongside the Eleventh Doctor (Matt Smith), Sontarans battle fleets are seen in series five (2010) finale episode "The Pandorica Opens", as part of an alliance of the Doctor's enemies. Series 6 episode "A Good Man Goes to War" (2011) introduces Strax (Starkey), a Sontaran nurse who has been assigned this role as a means of making penance. He fights on the side of the Doctor and his allies, which include the Silurian warrior Vastra (Neve McIntosh) and her lover Jenny (Catrin Stewart). Strax appears again in Christmas special "The Snowmen" (2012), now serving as Vastra and Jenny's butler, and assists them in their capacity as Victorian era detectives. This trio were featured also in the episodes "The Crimson Horror", "The Name of the Doctor" (both 2013) and "Deep Breath" (2014). A troop of Sontarans are also seen as invaders of the planet Trenzalore in the 2013 Christmas special "The Time of the Doctor".
Games.
The origins of the Sontarans have not been revealed in the television series. The "Doctor Who" role-playing game published by FASA claimed that they were all descended from the genetic stock of General Sontar (or Sontaris), who used newly developed bioengineering techniques to clone millions of duplicates of himself and annihilated the non-clone population. He renamed the race after himself and turned the Sontarans into an expansionist and warlike society set on universal conquest. However, this origin has no basis in anything seen in the television series.
The Sontarans have also appeared as a character in the PC game "Destiny of the Doctors" released on 5 December 1997, by BBC Multimedia. They can be defeated by firing the occupants of an angry beehive at them.
The Sontarans appear in the "" episode, "The Gunpowder Plot".
Other appearances.
Big Finish Productions first used the Sontarans for their audio drama "Heroes of Sontar" - a 2011 Fifth Doctor story. They next featured in The Five Companions and were stuck in an alternative version of the Death Zone with the Fifth Doctor and various companions. In 2012, "The First Sontarans" was released. A Sixth Doctor Lost Story from the mid-1980s, written by Andrew Smith, it features the Sontarans and the Rutans on nineteenth century Earth, tracking down a scientist named Jacob, who escaped through time and space. It is revealed that Jacob is from Sontar, and was responsible for genetically creating the Sontarans as a defence against a Rutan invasion. They were first developed on Sontar's gravity-heavy moon and quickly proved themselves to be at least on par with the unstoppable Rutan horde. However, believing themselves to be superior, the Sontarans turned on their creators, conquering the planet Sontar and changing it to suit their biology.
Other appearances by the Sontarans include the spin-off videos "Mindgame", "" and "Do You Have A License To Save This Planet?"; three audio plays by BBV: "Silent Warrior", "Old Soldiers" and "Conduct Unbecoming"; the Faction Paradox audio "The Shadow Play"; and a cameo appearance in "Infidel's Comet". "Shakedown" marks the only occasion in which the Sontarans and their Rutan foes appear on screen together, and was adapted into a Virgin New Adventures novel.
They have also appeared in several spin-off novels, including "Lords of the Storm" by David A. McIntee and "The Infinity Doctors" by Lance Parkin. In "The Infinity Doctors", the Doctor negotiated a peace between the Sontarans and the Rutan Host when two of them were left trapped in a TARDIS for several hours and got to talking due to their inability to kill each other. General Sontar also made an appearance in that novel. In "The Crystal Bucephalus" by Craig Hinton, the name of their planet was given as Sontara. The Sontarans also briefly appear in "The Eight Doctors", sent to the Eye of Orion by an agent of the Celestial Intervention Agency to kill the Fifth and Eighth Doctors.
In 1982, Jean Airey's novella "The Doctor and the Enterprise" featured a crossover between the universes of "Doctor Who" and "Star Trek", in which the Fourth Doctor finds himself on the USS "Enterprise". The "Enterprise" is attacked by a Sontaran fleet (which is unrecognizable to Captain Kirk and crew), prompting the Doctor to urgently warn the crew to flee the area.
They appear in 2009, in the novella "The Sontaran Games" by Jacqueline Rayner, featuring the Tenth Doctor and appeared in the New Series Adventures (Doctor Who) book "The Taking of Chelsea 426" by David Llewellyn, featuring the Tenth Doctor, fighting both times against the Rutan Host.
In 2008, as part of Character options first series 4 2008 wave of action figures, they released some Sontaran action figures. These include General Staal, Commander Skorr and several Sontaran soldiers.
The Sontarans are mentioned in the audio book Wraith World, when Clyde Langer remarks he cannot understand why Luke and Rani would want to read about made up adventures, when they have faced Sontarans.
Comic books.
The Sontarans have also appeared several times in the "Doctor Who Magazine" comic strip, both as adversaries of the Doctor and in strips not involving the Doctor. In "The Outsider" (DWM #25-26), by Steve Moore and David Lloyd, a Sontaran named Skrant invaded the world of Brahtilis with the unwitting help of Demimon, a local astrologer. The Fourth Doctor faced the Sontarans in "Dragon's Claw" (DWM #39-#45), by Steve Moore and Dave Gibbons, where a crew of Sontarans menaced China in 1522 AD.
In Steven Moffat's short story (the basis for the Tenth Doctor episode "Blink"), the Ninth Doctor has a rooftop sword fight with two Sontarans in 21st century Istanbul, defeating them with the help of spy Sally Sparrow, apparently before the events of "Rose" in his personal timeline.
The Sontaran homeworld was destroyed in the future during the events of the Seventh Doctor strip "Pureblood" (DWM #193-196) but the Sontaran race pool survived, allowing for further cloning; the strip introduced the concept of "pureblood" Sontarans not born of cloning. The Sontarans also feature in the Kroton solo strip "Unnatural Born Killers" (DWM #277) and the Tenth Doctor's comic strip debut "The Betrothal of Sontar" (DWM #365-#368), by John Tomlinson and Nick Abadzis, where a Sontaran mining rig on the ice planet Serac comes under attack by a mysterious force.

</doc>
<doc id="28027" url="http://en.wikipedia.org/wiki?curid=28027" title="Skateboarding">
Skateboarding

Skateboarding is an action sport which involves riding and performing tricks using a skateboard. Skateboarding can also be considered a recreational activity, an art form, a job, or a method of transportation. Skateboarding has been shaped and influenced by many skateboarders throughout the years. A 2009 report found that the skateboarding market is worth an estimated $4.8 billion in annual revenue with 11.08 million active skateboarders in the world.
Since the 1970s, skateparks have been constructed specifically for use by skateboarders, Freestyle BMXers, aggressive skaters, and very recently, scooters.
History.
1940s–1960s.
The first skateboards started with wooden boxes, or boards, with roller skate wheels attached to the bottom. Crate scooters preceded skateboards, having a wooden crate attached to the nose (front of the board), which formed rudimentary handlebars. The boxes turned into planks, similar to the skateboard decks of today. An American WAC, Betty Magnuson, reported seeing French children in the Montmartre section of Paris riding on boards with roller skate wheels attached to them in late 1944. 
Skateboarding, as we know it, was probably born sometime in the late 1940s, or early 1950s, when surfers in California wanted something to do when the waves were flat. No one knows who made the first board; it seems that several people came up with similar ideas at around the same time. The first manufactured skateboards were ordered by a Los Angeles, California surf shop, meant to be used by surfers in their downtime. The shop owner, Bill Richard, made a deal with the Chicago Roller Skate Company to produce sets of skate wheels, which they attached to square wooden boards. Accordingly, skateboarding was originally denoted "sidewalk surfing" and early skaters emulated surfing style and maneuvers, and performed barefoot.
By the 1960s a small number of surfing manufacturers in Southern California such as Jack's, Kips', Hobie, Bing's and Makaha started building skateboards that resembled small surfboards, and assembled teams to promote their products. One of the earliest Skateboard exhibitions was sponsored by Makaha's founder, Larry Stevenson, in 1963 and held at the Pier Avenue Junior High School in Hermosa Beach, California. Some of these same teams of skateboarders were also featured on a television show called "Surf's Up" in 1964, hosted by Stan Richards, that helped promote skateboarding as something new and fun to do.
As the popularity of skateboarding began expanding, the first skateboarding magazine, "The Quarterly Skateboarder" became published in 1964. John Severson who published the magazine wrote in his first editorial:
 Today's skateboarders are founders in this sport—they're pioneers—they are the first. There is no history in Skateboarding—its being made now—by you. The sport is being molded and we believe that doing the right thing now will lead to a bright future for the sport. Already, there are storm clouds on the horizon with opponents of the sport talking about ban and restriction.
The magazine only lasted four issues, but resumed publication as "Skateboarder" in 1975. The first broadcast of an actual skateboarding competition was the 1965 National Skateboarding Championships, which were held in Anaheim, California and aired on ABC’s “Wide World of Sports. Because skateboarding was a new sport during this time, there were only two original disciplines during competitions; flatland freestyle & slalom downhill racing.
One of the earliest sponsored skateboarders, Patti McGee, was paid by Hobie and Vita Pak to travel around the country to do skateboarding exhibitions and to demonstrate skateboarding safety tips. McGee made the cover of "Life" magazine in 1965 and was featured on several popular television programs "The Mike Douglas Show", "What's My Line?" and "The Tonight Show Starring Johnny Carson", which helped make skateboarding even more popular at the time. Some of the other well known surfer-style skateboarders of the time also included Danny Bearer, Torger Johnson, Bruce Logan, Bill and Mark Richards, Woody Woodward, & Jim Fitzpatrick.
The growth of the sport during this period can also be seen in sales figures for Makaha, which quoted $10 million worth of board sales between 1963 and 1965 (Weyland, 2002:28). By 1966 a variety of sources began to claim that skateboarding was dangerous, resulting in shops being reluctant to sell them, and parents being reluctant to buy them. In 1966 sales had dropped significantly (ibid) and Skateboarder Magazine had stopped publication. The popularity of skateboarding dropped and remained low until the early 1970s.
1970s.
In the early 1970s, Frank Nasworthy started to develop a skateboard wheel made of polyurethane, calling his company Cadillac Wheels. Prior to this new material, skateboards wheels were metal or "clay" wheels. The improvement in traction and performance was so immense that from the wheel's release in 1972 the popularity of skateboarding started to rise rapidly again, causing companies to invest more in product development. Nasworthy commissioned artist Jim Evans to do a series of paintings promoting Cadillac Wheels, they were featured as ads and posters in the resurrected Skateboarder magazine, and proved immensely popular in promoting the new style of skateboarding.
In the early 1970s skateparks hadn't been invented yet, so skateboarders would flock and skateboard in such urban places like The Escondido reservoir in San Diego, California. Skateboarding magazine would publish the location and Skateboarders made up nicknames for each location such as the Tea Bowl, the Fruit Bowl, Bellagio, the Rabbit Hole, Bird Bath, the Egg Bowl, Upland Pool and the Sewer Slide. Some of the development concepts in the terrain of skateparks were actually taken from the Escondido reservoir. Many companies started to manufacture trucks (axles) specially designed for skateboarding, reached in 1976 by Tracker Trucks. As the equipment became more maneuverable, the decks started to get wider, reaching widths of 10 in and over, thus giving the skateboarder even more control. A banana board is a skinny, flexible skateboard made of polypropylene with ribs on the underside for structural support. These were very popular during the mid-1970s and were available in myriad colors, bright yellow probably being the most memorable, hence the name.
In 1975 skateboarding had risen back in popularity enough to have one of the largest skateboarding competition's since the 1960s, the Del Mar National Championships, which is said to have had up to 500 competitors. The competition lasted two days and was sponsored by Bahne Skateboards & Cadillac Wheels. While the main event was won by freestyle spinning skate legend Russ Howell, a local skate team from Santa Monica, California, the Zephyr team, ushered in a new era of surfer style skateboarding during the competition that would have a lasting impact on skateboarding's history. With a team of 12, including skating legends such as Jay Adams, Tony Alva, Peggy Oki & Stacy Peralta, they brought a new progressive style of skateboarding to the event, based on the style of Hawaiian surfers Larry Bertlemann, Buttons Kaluhiokalani and Mark Liddell. Craig Stecyk, a photo journalist for Skateboarder Magazine wrote and photographed the team, along with Glen E. Friedman, shortly afterwards and ran a series on the team called the Dogtown articles, which eventually immortalized the Zephyr skateboard team. The team became known as the Z-Boys and would go on to become one of the most influential teams in skateboarding's history.
It was soon after that skateboarding contest for cash and prizes using a professional tier system began to be held throughout California, like the The California Free Former World Professional Skateboard Championships, which featured Freestyle and Slalom competitions.
A precursor to the extreme sport of Street luge, that was sanctioned by the United States Skateboarding Association (USSA), also took place during the 1970s in Signal Hill, California. The competition was called "The Signal Hill Skateboarding Speed Run", with several competitors earning entries into the Guinness Book of World Records, at the time clocking speeds of over 50 mph on a skateboard. Due to technology and safety concerns at the time, when many competitors crashed during their runs, the sport did not gain popularity or support during this time.
In March 1976, Skateboard City skatepark in Port Orange, Florida and Carlsbad Skatepark in San Diego County, California, would be the first two skateparks to be opened to the public in just a week apart. They were the first of some 200 skateparks that would be built through 1982. This was due in part to articles that were running in the Investment Journals at the time, stating that skateparks were a good investment. Notable skateboarders from the 1970s also include Ty Page, Tom Inouye, Laura Thornhill, Ellen O'Neal, Kim Cespedes, Bob Biniak, Jana Payne, Waldo Autry, Robin Logan, Bobby Piercy, Russ Howell, Ellen Berryman, Shogo Kubo, Desiree Von Essen, Henry Hester, Robin Alaway, Paul Hackett, Michelle Matta, Bruce Logan, Steve Cathey, Edie Robertson, Mike Weed, David Hackett, Gregg Ayres, Darren Ho, and Tom Sims.
Manufacturers started to experiment with more exotic composites and metals, like fiberglass and aluminium, but the common skateboards were made of maple plywood. The skateboarders took advantage of the improved handling of their skateboards and started inventing new tricks. Skateboarders, most notably Ty Page, Bruce Logan, Bobby Piercy, Kevin Reed, and the Z-Boys started to skate the vertical walls of swimming pools that were left empty in the 1976 California drought. This started the "vert" trend in skateboarding. With increased control, vert skaters could skate faster and perform more dangerous tricks, such as slash grinds and frontside/backside airs. This caused liability concerns and increased insurance costs to skatepark owners, and the development (first by Norcon, then more successfully by Rector) of improved knee pads that had a hard sliding cap and strong strapping proved to be too-little-too-late. During this era, the "freestyle" movement in skateboarding began to splinter off and develop into a much more specialized discipline, characterized by the development of a wide assortment of flat-ground tricks.
As a result of the "vert" skating movement, skate parks had to contend with high-liability costs that led to many park closures. In response, vert skaters started making their own ramps, while freestyle skaters continued to evolve their flatland style. Thus by the beginning of the 1980s, skateboarding had once again declined in popularity.
1980s.
This period was fueled by skateboard companies that were run by skateboarders. The focus was initially on vert ramp skateboarding. The invention of the no-hands aerial (later known as the ollie) by Alan Gelfand in Florida in 1976, and the almost parallel development of the grabbed aerial by George Orton and Tony Alva in California, made it possible for skaters to perform airs on vertical ramps. While this wave of skateboarding was sparked by commercialized vert ramp skating, a majority of people who skateboarded during this period didn't ride vert ramps. As most people could not afford to build vert ramps, or did not have access to nearby ramps, street skating increased in popularity.
Freestyle skating remained healthy throughout this period, with pioneers such as Rodney Mullen inventing many of the basic tricks that would become the foundation of modern street skating, such as the "Impossible" and the "kickflip". The influence that freestyle exerted upon street skating became apparent during the mid-1980s; however, street skating was still performed on wide vert boards with short noses, slide rails, and large soft wheels. In response to the tensions created by this confluence of skateboarding "genres", an rapid evolution occurred in the late 1980s to accommodate the street skater. Since few skateparks were available to skaters at this time, street skating pushed skaters to seek out shopping centers and public and private property as their "spot" to skate (public opposition, in which businesses, governments, and property owners have banned skateboarding on properties under their jurisdiction or ownership, would progressively intensify over the following decades). By 1992, only a small fraction of skateboarders remained as a highly technical version of street skating, combined with the decline of vert skating, produced a sport that lacked the mainstream appeal to attract new skaters.
1990s.
Skateboarding during the 1990s became dominated by street skateboarding. Most boards are about 7+1/4 to wide and 30 to long. The wheels are made of an extremely hard polyurethane, with hardness (durometer) approximately 99A. The wheel sizes are relatively small so that the boards are lighter, and the wheels' inertia is overcome quicker, thus making tricks more manageable. Board styles have changed dramatically since the 1970s but have remained mostly alike since the mid-1990s. The contemporary shape of the skateboard is derived from the freestyle boards of the 1980s with a largely symmetrical shape and relatively narrow width. This form had become standard by the mid '90s.
2000–present.
By 2001 skateboarding had gained in such popularity, that more participants under the age of 18 rode skateboards (10.6 million) than played baseball (8.2 million), although traditional organized team sports still dominated youth programs overall. Skateboarding and skateparks began to be viewed and used in a variety of new ways to compliment academic lessons in schools, including new non-traditional physical education skateboarding programs, like and that are used to encourage youth to have better attendance, self-discipline and confidence. This was also based on the healthy physical opportunities skateboarding was understood to bring participants for muscle & bone strengthening, balance and the positive impacts it can have on youth in teaching them mutual respect, social networking, artistic expression and an appreciation of the environment.
In 2003 Go Skateboarding Day was founded in southern California by the International Association of Skateboard Companies to promote skateboarding throughout the world. It is celebrated annually on June 21 “to define skateboarding as the rebellious, creative celebration of independence it continues to be.”
According to market research firm American Sports Data the number of skateboarders worldwide increased by more than 60 percent between 1999 and 2002—from 7.8 million to 12.5 million.
Many cities also began implementing recreation plans and statutes, during this time period, as part of their vision for local parks and communities to make public lands more available in particular, for skateboarding, inviting skateboarders to come in off of the city streets and into organized skateboarding activity areas. By 2006 there were over 2,400 Skateparks world wide and the design of skateparks themselves had made a transition, as skaters turned designers, began to emerge in the field adding features for all levels of skaters. Many new places to skateboard designed specifically for street skaters, such as the “Safe Spot Skate Spot” program, first initiated by professional skateboarder Rob Dyrdek throughout many cites, allowed for the creation of smaller alternative safe skate plazas to be built at a lower cost. One of the largest locations ever built to skateboard in the world, SMP Skatepark in China, at 12,000 square meters in size, was built complete with a 5,000-seat stadium.
In 2009 Skatelab opened the Skateboarding Hall of Fame & Skateboard Museum. Nominees are chosen by the International Association of Skateboard Companies (IASC).
Trick skating.
With the evolution of skateparks and ramp skating, the skateboard began to change. Early skate tricks had consisted mainly of two-dimensional freestyle manoeuvres like riding on only two wheels ("wheelie" or "manual"), spinning only on the back wheels (a "pivot"), high jumping over a bar and landing on the board again, also known as a "hippie jump", long jumping from one board to another, (often over small barrels or fearless teenagers), or slalom. Another popular trick was the Bertlemann slide, named after Larry Bertelemann's surfing manoeuvres.
In 1976, skateboarding was transformed by the invention of the ollie by Alan "Ollie" Gelfand. It remained largely a unique Florida trick until the summer of 1978, when Gelfand made his first visit to California. Gelfand and his revolutionary maneuvers caught the attention of the West Coast skaters and the media where it began to spread worldwide. The ollie was adapted to flat ground by Rodney Mullen in 1982. Mullen also invented the "Magic Flip," which was later renamed the kickflip, as well as many other tricks including, the 360 kickflip, which is a 360 pop shove-it and a kickflip in the same motion. The flat ground ollie allowed skateboarders to perform tricks in mid-air without any more equipment than the skateboard itself, it has formed the basis of many street skating tricks. A recent development in the world of trick skating is the 1080, which was first ever landed by Tom Schaar in 2012.
Culture.
Skateboarding was popularized by the 1986 skateboarding cult classic "Thrashin"'. Directed by David Winters and starring Josh Brolin, it features appearances from many famous skaters such as Tony Alva, Tony Hawk, Christian Hosoi and Steve Caballero. "Thrashin'" also had a direct impact on "Lords of Dogtown", as Catherine Hardwicke, who directed "Lords of Dogtown", was hired by Winters to work on "Thrashin'" as a production designer where she met, worked with and befriended many famous skaters including the real Tony Alva, Tony Hawk, Christian Hosoi and Steve Caballero.
Skateboarding was, at first, tied to the culture of surfing. As skateboarding spread across the United States to places unfamiliar with surfing or surfing culture, it developed an image of its own. For example, the classic film short "Video Days" (1991) portrayed skateboarders as reckless rebels.
California duo Jan and Dean recorded the song "Sidewalk Surfin'" in 1964, which is the Beach Boys song "Catch a Wave" with new lyrics associated with skateboarding.
The image of the skateboarder as a rebellious, non-conforming youth has faded in recent years. Certain cities still oppose the building of skateparks in their neighborhoods, for fear of increased crime and drugs in the area. The rift between the old image of skateboarding and a newer one is quite visible: magazines such as "Thrasher" portray skateboarding as dirty, rebellious, and still firmly tied to punk, while other publications, "Transworld Skateboarding" as an example, paint a more diverse and controlled picture of skateboarding. Furthermore, as more professional skaters use hip hop, reggae, or hard rock music accompaniment in their videos, many urban youths, hip-hop fans, reggae fans, and hard rock fans are also drawn to skateboarding, further diluting the sport's punk image.
Films such as the 1986 "Thrashin'", "Grind" and "Lords of Dogtown", have helped improve the reputation of skateboarding youth, depicting individuals of this subculture as having a positive outlook on life, prone to poking harmless fun at each other, and engaging in healthy sportsman's competition. According to the film, lack of respect, egotism and hostility towards fellow skateboarders is generally frowned upon, albeit each of the characters (and as such, proxies of the "stereotypical" skateboarder) have a firm disrespect for authority and for rules in general. Group spirit is supposed to heavily influence the members of this community. In presentations of this sort, showcasing of criminal tendencies is absent, and no attempt is made to tie extreme sports to any kind of illegal activity.
"Gleaming the Cube", a 1989 movie starring Christian Slater as a skateboarding teen investigating the death of his adopted Vietnamese brother, was somewhat of an iconic landmark to the skateboarding genre of the era. Many well-known skaters had cameos in the film, including Tony Hawk and Rodney Mullen, where Mullen served as Slater's stunt double.
The increasing availability of technology is apparent within the skateboarding community. Many skateboarders record and edit videos of themselves and friends skateboarding. However, part of this culture is to not merely replicate but to innovate; emphasis is placed on finding new places and landing new tricks.
Skateboarding video games have also become very popular in skateboarding culture. Some of the most popular are the "Tony Hawk" series and "Skate series" for various consoles (including hand-held) and personal computer.
Skate shoe.
One of the early leading trends associated with the sub-culture of skateboarding itself, was the sticky sole "Slip-On" Skate shoe, most popularized by Sean Penn's skateboarding character from the film Fast Times at Ridgemont High. Because early skateboarders were actually surfers trying to emulate the sport of surfing, at the time when skateboards first came out on the market, many skateboarded barefoot. But skaters often lacked traction, which led to foot injuries. This necessitated the need for a shoe that was specifically designed and marketed for skateboarding, such as the Randy "720", manufactured by the Randolph Rubber Company, and Vans sneakers, which eventually became cultural iconic signifiers for skateboarders during the 70s & 80's as skateboarding became more widespread.
While the skate shoes design afforded better connection & traction with the deck, skaterboarders themselves could often be identified when wearing the shoes, with Tony Hawk once saying, "If you were wearing Vans shoes in 86, you were a skateboarder" Because of its connection with skateboarding, Vans financed the legendary skateboarding documentary "Dogtown and Z-Boys" and was the first sneaker company to endorse a professional skateboarder Stacy Peralta. Vans has a long history of being a major sponsor of many of skateboarding's competitions and events throughout skateboarding's history as well, including the Vans Warped Tour and the Vans Triple Crown Series.
As it eventually became more apparent that skateboarding had a particular identity with a style of shoe, other brands of shoe companies began to specifically design skate shoes for functionality and style to further enhance the experience and culture of skateboarding including such brands as; Converse, Nike, DC Shoes, Globe, Adidas, Zoo York and World Industries. Many professional skateboarders are designed a pro-model skate shoe, with their name on it, once they have received a skateboarding sponsorship after becoming notable skateboarders. Some shoe companies involved with skateboarding, like Sole Technology, an American footwear company that makes the Etnies skate shoe brand, further distinguish themselves in the market by collaborating with local cities to open public Skateparks, such as the etnies skatepark in Lake Forest, California.
Skateboard deck.
Individuality and a self-expressed casual style, have always been, among two of the cultural values for skateboarders, as uniforms and jerseys are not typically worn. This type of personal style for skateboarders is often reflected in the graphical designs illustrated on the bottom of the deck of skateboards, since its initial conception in the mid seventies, when Wes Humpston and Jim Muri first began doing design work for Dogtown Skateboards out of their garage by hand, creating the very first iconic skateboard-deck art with the design of the "Dogtown Cross".
Prior to the mid-seventies many early skateboards were originally based upon the concept of “Sidewalk Surfing” and were tied to the surf culture, skateboards were surfboard like in appearance with little to no graphics located under the bottom of the skateboard-deck. Some of the early manufactured skateboards such as "Roller Derby", the "Duraflex Surfer" and the "Banana board" are characteristic. Some skateboards during that time were manufactured with company logo's or stickers across the top of the deck of the skateboard, as griptape was not initially used for construction. But as skateboarding progressed & evolved, and as artist began to design and add influence to the artwork of skateboards, designs and themes began to change.
There were several artistic skateboarding pioneer's that had an influence on the culture of skateboarding during the 1980s, that transformed skateboard-deck art like Jim Phillips, who's edgy comic-book style "Screaming Hand", not only became the main logo for Santa Cruz Skateboards, but eventually transcended into tattoos of the same image for thousands of people & vinyl collectable figurines over the years. Artist Vernon Courtlandt Johnson is said to have used his artwork of skeletons and skulls, for Powell Peralta, during the same time that the music genres of punk rock and new wave music were beginning to mesh with the culture of skateboarding. Some other notable skateboard artists that made contribrutions to the culture of skateboarding also include Andy Jenkins, Todd Bratrud, Neil Blender, Marc McKee, Tod Swank, Mark Gonzales, Lance Mountain, Natas Kaupas and Jim Evans.
Over the years skateboard-deck art has continued to influence and expand the culture of skateboarding, as many people began collecting skateboards based on their artistic value and nostalgia. Productions of limited editions with particular designs and types of collectible prints that can be hung on the wall, have been created by such famous artist as Andy Warhol and Keith Haring. Most professional skateboarders today have their own signature skateboard decks, with their favorite artistic designs printed on them using Computer graphics.
Safety.
Skateboards, along with other small-wheeled transportation such as in-line skates and scooters, suffer a safety problem: riders may easily be thrown from small cracks and outcroppings in pavement, especially where the cracks run across the direction of travel. Hitting such an irregularity is the major cause of falls and injuries. The risk may be reduced at higher travel speeds.
Severe injuries are relatively rare. Commonly, a skateboarder who falls suffers from scrapes, cuts, bruises, and sprains. Among injuries reported to a hospital, about half involve broken bones, usually the long bones in the leg or arm. One-third of skateboarders with reported injuries are very new to the sport, having started skating within one week of the injury. Although less common, involving 3.5–9 percent of reported injuries, traumatic head injuries and death are possible severe outcomes.
Skating as a form of transportation exposes the skateboarder to the dangers of other traffic. Skateboarders on the street may be hit by other vehicles or may fall into vehicular traffic.
Skateboarders also pose a risk to other pedestrians and traffic. If the skateboarder falls, the skateboard may roll or fly into another person. A skateboarder who collides with a person who is walking or biking may injure or, rarely, kill that person.
Many jurisdictions require skateboarders to wear bicycle helmets to reduce the risk of head injuries and death. Other protective gear, such as wrist guards, also reduce injury. Some medical researchers have proposed restricting skateboarding to designated, specially designed areas, to reduce the number and severity of injuries, and to eliminate injuries caused by motor vehicles or to other pedestrians.
The use, ownership and sale of skateboards were forbidden in Norway from 1978 to 1989 because of the high number of injuries caused by boards. The ban led skateboarders to construct ramps in the forest and other secluded areas to avoid the police.
Other uses and styles.
Transportation.
The use of skateboards solely as a form of transportation is often associated with the longboard. Depending on local laws, using skateboards as a form of transportation outside residential areas may or may not be legal. Backers cite portability, exercise, and environmental friendliness as some of the benefits of skateboarding as an alternative to automobiles.
Military.
The United States Marine Corps tested the usefulness of commercial off-the-shelf skateboards during urban combat military exercises in the late 1990s in a program called Urban Warrior '99. Their special purpose was "for maneuvering inside buildings in order to detect tripwires and sniper fire".
Trampboarding.
Trampboarding is a variant of skateboarding that uses a board without the trucks and the wheels on a trampoline. Using the bounce of the trampoline gives height to perform a tricks, whereas in skateboarding you need to make the height by performing an ollie. Trampboarding is seen on YouTube in numerous videos.
Swing boarding.
Swing boarding is the activity where a skateboard deck is suspended from a pivot point above the rider which allows the rider to swing about that pivot point. The board swings in an arc which is a similar movement to riding a half pipe. The incorporation of a harness and frame allows the rider to perform turns spins all while flying though the air.
Controversy.
Skateboarding is sometimes associated with property damage to urban terrain features such as curbs, benches, and ledges when skateboarders perform tricks known as grinds on these surfaces. Private industry has responded to this perceived damage with skate deterrent devices, such as the Skatestopper, in an effort to mitigate damage and discourage skateboarding on these surfaces.
The passing of ordinances and the use of posted signs stating "Skateboarding is not allowed" have also become common methods to mitigate skateboarding in public areas in many cities, to protect pedestrians and property. In the area of street skating, tickets and arrest from police for trespassing are not uncommon.

</doc>
<doc id="28028" url="http://en.wikipedia.org/wiki?curid=28028" title="Speed skating">
Speed skating

Speed skating is a competitive form of ice skating in which the competitors race each other in travelling a certain distance on skates. Types of speed skating are long track speed skating, short track speed skating, and marathon speed skating. In the Olympic Games, long-track speed skating is usually referred to as just "speed skating", while short-track speed skating is known as "short track". The ISU, the governing body of both ice sports, refers to long track as "speed skating" and short track as "short track skating".
The standard rink for long track is 400 meters long, but tracks of 200, 250 and 333⅓ meters are used occasionally. It is one of two Olympic forms of the sport and the one with the longer history. An international federation was founded in 1892, the first for any winter sport. The sport enjoys large popularity in the Netherlands and Norway. There are top international rinks in a number of other countries, including Canada, the United States, Germany, Italy, Japan, South Korea and Russia. A World Cup circuit is held with events in those countries and with two events in Thialf, the ice hall in Heerenveen, Netherlands.
International Skating Union rules allow some leeway in the size and radius of curves.
Short track speed skating takes place on a smaller rink, normally the size of an ice hockey rink, on a 111.12 m oval track. Distances are shorter than in long-track racing, with the longest Olympic individual race being 1500 meters (the women's relay is 3000 meters and the men's relay 5000 meters). Races are usually held as knockouts, with the best two in heats of four or five qualifying for the final race, where medals are awarded. Disqualifications and falls are not uncommon.
There are variations on the mass-start races. In the regulations of roller sports, eight different types of mass starts are described. Among them are elimination races, where one or more competitors are eliminated at fixed points during the course; simple distance races, which may include preliminary knockout races; endurance races with time limits instead of a fixed distance; points races; and individual pursuits.
Races usually have some rules about disqualification if an opponent is unfairly hindered; these rules vary between the disciplines. In long track speed skating, almost any infringement on the pairmate is punished, though skaters are permitted to change from the inner to the outer lane out of the final curve if they are not able to hold the inner curve, as long as they are not interfering with the other skater. In mass-start races, skaters will usually be allowed some physical contact.
Team races are also held; in long track speed skating, the only team race at the highest level of competition is the team pursuit, though athletics-style relay races are held at children's competitions. Relay races are also held in short track and inline competitions, but here, exchanges may take place at any time during the race, though exchanges may be banned during the last couple of laps.
Most races are held on an oval course, but there are exceptions. Oval sizes vary; in short track speed skating, the rink must be an oval of 111.12 metres, while long track speed skating uses a similarly standardized 400 m rink. Inline skating rinks are between 125 and 400 metres, though banked tracks can only be 250 metres long. Inline skating can also be held on closed road courses between 400 and 1,000 metres, as well as open-road competitions where starting and finishing lines do not coincide. This is also a feature of outdoor marathons.
In the Netherlands, marathon competitions may be held on natural ice on canals, and bodies of water such as lakes and rivers, but may also be held on artificially frozen 400 m tracks, with skaters circling the track 100 times, for example.
History.
The roots of speed skating date back over a millennium to Scandinavia, Northern Europe and the Netherlands, where the natives added bones to their shoes and used them to travel on frozen rivers, canals and lakes. It was much later, in the 16th century, that people started seeing skating as fun and perhaps even a sporting activity.
Later, in Norway, King Eystein Magnusson, later King Eystein I of Norway, boasts of his skills racing on ice legs. 
However, skating and speed skating was not limited to the Netherlands and Scandinavia; in 1592, a Scotsman designed a skate with an iron blade. It was iron-bladed skates that led to the spread of skating and, in particular, speed skating.
By 1642, the first official skating club, The Skating Club Of Edinburgh, was born, and, in 1763, the world saw its first official speed skating race, on the Fens in England organized by the National Ice Skating Association.
While in the Netherlands, people began touring the waterways connecting the 11 cities of Friesland, a challenge which eventually led to the Elfstedentocht.
By 1851, North Americans had discovered a love of the sport, and indeed the all-steel blade was later developed there.
The Netherlands came back to the fore in 1889 with the organization of the first world championships. The ISU (International Skating Union) was also born in the Netherlands in 1892.
By the start of the 20th century, skating and speed skating had come into its own as a major popular sporting activity.
ISU development.
Organized races on ice skates developed in the 19th century. Norwegian clubs hosted competitions from 1863, with races in Christiania drawing five-digit crowds. In 1884, the Norwegian Axel Paulsen was named Amateur Champion Skater of the World after winning competitions in the United States. Five years later, a sports club in Amsterdam held an ice-skating event they called a world championship, with participants from Russia, the United States and the United Kingdom, as well as the host country. The "Internationale Eislauf Vereinigung", now known as the International Skating Union, was founded at a meeting of 15 national representatives in Scheveningen in 1892, the first international winter sports federation. The Nederlandse Schaatsrijderbond was founded in 1882 and organised the world championships of 1890 and 1891. Competitions were held around tracks of varying lengths—the 1885 match between Axel Paulsen and Remke van der Zee was skated on a track of 6/7 mile (1400 metres)—but the 400 metre track was standardised by the ISU in 1892, along with the standard distances for world championships, 500 m, 1500 m, 5000 m and 10,000 m. Skaters started in pairs, each to their own lane, and changed lanes for every lap to ensure that each skater completed the same distance. This is what is now known as long track speed skating. Competitions were exclusively for amateur skaters, which was enforced. Peter Sinnerud was disqualified for professionalism in 1904 and lost his world title.
Long track world records were first registered in 1891 and improved rapidly, Jaap Eden lowering the world 5000-metre record by half a minute during the Hamar European Championships in 1894. The record stood for 17 years, and it took 50 years to lower it by further half a minute.
Elfstedentocht.
The Elfstedentocht was organized as a competition in 1909 and has been held at irregular intervals, whenever the ice on the course is deemed good enough. Other outdoor races developed later, with North Holland hosting a race in 1917, but the Dutch natural ice conditions have rarely been conducive to skating. The Elfstedentocht has been held 15 times in the nearly 100 years since 1909, and, before artificial ice was available in 1962, national championships had been held in 25 of the years between 1887, when the first championship was held in Slikkerveer, and 1961. Since artificial ice became common in the Netherlands, Dutch speed skaters have been among the world top in long track ice skating and marathon skating. Another solution to still be able to skate marathons on natural ice became the Alternative Elfstedentocht. The Alternative Elfstedentocht races take part in other countries, such as Austria, Finland or Canada, and all top marathon skaters, as well as thousands of recreative skaters, travel from the Netherlands to the location where the race is held. According to the NRC Handelsblad journalist Jaap Bloembergen, the country "takes a carnival look" during international skating championships.
Olympic Games.
Speed Skating started in 1924.
At the 1914 Olympic Congress, the delegates agreed to include ice speed skating in the 1916 Olympics, after figure skating had featured in the 1908 Olympics. However, World War I put an end to the plans of Olympic competition, and it was not until the winter sports week in Chamonix in 1924—retroactively awarded Olympic status—that ice speed skating reached the Olympic programme. Charles Jewtraw from Lake Placid, New York, won the first Olympic gold medal, though several Norwegians in attendance claimed Oskar Olsen had clocked a better time. Timing issues on the 500 were a problem within the sport until electronic clocks arrived in the 1960s; during the 1936 Olympic 500–metre race, it was suggested that Ivar Ballangrud's 500-metre time was almost a second too good. Finland won the remaining four gold medals at the 1924 Games, with Clas Thunberg winning 1,500 metres, 5,000 metres, and allround. It was the first and only time an allround Olympic gold medal has been awarded in speed skating. Speed Skating is also a sport in today's Olympic's.
Norwegian and Finnish skaters won all the gold medals in world championships between the world wars, with Latvians and Austrians visiting the podium in the European Championships. However, North American races were usually conducted packstyle, similar to the marathon races in the Netherlands, but the Olympic races were to be held over the four ISU-approved distances. The ISU approved the suggestion that the speed skating at the 1932 Winter Olympics should be held as packstyle races, and Americans won all four gold medals. Canada won five medals, all silver and bronze, while defending World Champion Clas Thunberg stayed at home, protesting against this form of racing. At the World Championships held immediately after the games, without the American champions, Norwegian racers won all four distances and occupied the three top spots in the allround standings.
Norwegians, Swedes, Finns and Japanese skating leaders protested to the USOC, condemning the manner of competition and expressing the wish that mass-start races were never to be held again at the Olympics. However, the ISU adopted the short track speed skating branch, with mass-start races on shorter tracks, in 1967, arranged international competitions from 1976, and brought them back to the Olympics in 1992.
Women's competitions.
In the 1930s, women began to be accepted in ISU speed skating competitions. Although women's races had been held in North America for some time and at the 1932 Winter Olympics in a demonstration event, the ISU did not organize official competitions until 1936. However, Zofia Nehringowa set the first official world record in 1929. Women's speed skating was not very high-profile; in "Skøytesportens stjerner" ("Stars of the skating sport"), a Norwegian work from 1971, no female skaters are mentioned on the book's nearly 200 pages, though they had by then competed for nearly 30 years. The women's long track speed skating has since been dominated by East Germany and later reunified Germany, who have won 15 of 35 Olympic gold medals in women's long track since 1984.
In most other skating sports, women were accepted into competition at the same time, and they have been with the short trackers from the start of international competition in 1976. Their distances are usually shorter than the men's, but not in inline skating, where women skate the same program as the men in World Championships.
Technical developments.
Artificial ices entered the long track competitions with the 1960 Winter Olympics, and the competitions in 1956 on Lake Misurina were the last Olympic competitions on natural ice. 1960 also saw the first Winter Olympic competitions for women. Lidia Skoblikova won two gold medals in 1960 and four in 1964.
More aerodynamic skating suits were also developed, with Swiss skater Franz Krienbühl (who finished 8th on the Olympic 10,000 m at the age of 46) at the front of development. After a while, national teams took over development of body suits, which are also used in short track skating, though without headcover attached to the suit—short trackers wear helmets instead, as falls are more common in mass-start races. Suits and indoor skating, as well as the clap skate, has helped to lower long track world records considerably; from 1971 to 2009, the average speed on the men's 1500 metres has been raised from 45 to 52 km/h. Similar speed increases are shown in the other distances.
Professionalism.
After the 1972 season, European long track skaters founded a professional league, International Speedskating League, which included Ard Schenk, three-time Olympic gold medallist in 1972, as well as five Norwegians, four other Dutchmen, three Swedes, and a few other skaters. Jonny Nilsson, 1963 world champion and Olympic gold medallist, was the driving force behind the league, which folded in 1974 for economic reasons, and the ISU also excluded tracks hosting professional races from future international championships. The ISU later organised its own World Cup circuit with monetary prizes, and full-time professional teams developed in the Netherlands during the 1990s, which led them to a dominance on the men's side only challenged by Japanese 500 m racers and American inline skaters who changed to long tracks to win Olympic gold.
North American professionals.
During the 20th century, roller skating also developed as a competitive sport. Roller-skating races were professional from an early stage. Professional World Championships were arranged in North America between the competitors on that circuit. Later, roller derby leagues appeared, a professional contact sport that originally was a form of racing. FIRS World Championships of inline speed skating go back to the 1980s, but many world champions, such as Derek Parra and Chad Hedrick, have switched to ice in order to win Olympic medals.
Like roller skating, ice speed skating was also professional in North America. Oscar Mathisen, five-time ISU world champion and three-time European champion, renounced his amateur status in 1916 and travelled to America, where he won many races but was beaten by Bobby McLean of Chicago, four-time American champion, in one of the races. Chicago was a centre of ice speed skating in America; the "Chicago Tribune" sponsored a competition called the Silver Skates from 1912 to 2014.
Short track enters the Olympics.
In 1992, short track speed skating was accepted as an Olympic sport. Short track speed skating had little following in the long track speed skating countries of Europe, such as Norway, the Netherlands and the former Soviet Union, with none of these nations having won official medals (though the Netherlands won two gold medals when the sport was a demonstration event in 1988). The Norwegian publication "Sportsboken" spent ten pages detailing the long track speed skating events at the Albertville Games in 1993, but short track was not mentioned by word, though the results pages appeared in that section.
Although this form of speed skating is newer, it is growing faster than long-track speed skating, largely because short track can be done on an ice hockey rink rather than a long-track oval. South Korea has been the dominant nation in this sport, winning 17 Olympic gold medals.
Rules.
Short track.
A skater can be disqualified if they cross track another skater by cutting off another skater while changing his or her own lane.
After two false starts, the skater is disqualified. 
A disqualified will be given last place in their heat or final. 
A skater can be disqualified if he or she deliberately impedes another skater's way to slow the skater down.
Long track.
Races are run counter-clockwise. 
In all individual competition forms, only two skaters are allowed to race at once, and must remain in their respective lanes. 
Skaters must change lanes every lap. 
The skater changing from the outside lane to the inside has right-of-way.
In the only non-individual competition form, the team pursuit, two teams of each three skaters are allowed to race at once.
Both teams remain in the inner lane for the duration of the race; they start on opposite sides of the rink.
Equipment.
Short Track
All short track skaters must have speed skates, a spandex skin suit that is kevlar and cut proof, protective helmet, protective eyewear with strap,hard shin pads, specific skating gloves, knee pads (in suit), neck guard (bib style) and ankle protection. Optional equipment is a kevlar suit to protect against being cut from another skater's blade.
Long Track
For long track skaters the same equipment should be worn as short track racers but with the exception of a helmet, shin pads, knee pads, and neck guard which are not required. The suit also does not need to be kevlar. Most long track skaters also wear a hood that is built into the suit.

</doc>
<doc id="28030" url="http://en.wikipedia.org/wiki?curid=28030" title="September 13">
September 13

September 13 is the day of the year in the Gregorian calendar.

</doc>
<doc id="28032" url="http://en.wikipedia.org/wiki?curid=28032" title="Square (disambiguation)">
Square (disambiguation)

A square is a regular quadrilateral with four equal sides and four right angles.
Square may also refer to:

</doc>
<doc id="28034" url="http://en.wikipedia.org/wiki?curid=28034" title="Scanning electron microscope">
Scanning electron microscope

A scanning electron microscope (SEM) is a type of electron microscope that produces images of a sample by scanning it with a focused beam of electrons. The electrons interact with atoms in the sample, producing various signals that can be detected and that contain information about the sample's surface topography and composition. The electron beam is generally scanned in a raster scan pattern, and the beam's position is combined with the detected signal to produce an image. SEM can achieve resolution better than 1 nanometer. Specimens can be observed in high vacuum, in low vacuum, in wet conditions (in environmental SEM), and at a wide range of cryogenic or elevated temperatures.
The most common SEM mode is detection of secondary electrons emitted by atoms excited by the electron beam. The number of secondary electrons depends on the angle at which beam meets surface of specimen, i.e. on specimen topography. By scanning the sample and collecting the secondary electrons with a special detector, an image displaying the topography of the surface is created.
History.
An account of the early history of SEM has been presented by McMullan. Although Max Knoll produced a photo with a 50 mm object-field-width showing channeling contrast by the use of an electron beam scanner, it was Manfred von Ardenne who in 1937 invented a true microscope with high magnification by scanning a very small raster with a demagnified and finely focused electron beam. Ardenne applied the scanning principle not only to achieve magnification but also to purposefully eliminate the chromatic aberration otherwise inherent in the electron microscope. He further discussed the various detection modes, possibilities and theory of SEM, together with the construction of the . Further work was reported by Zworykin's group, followed by the Cambridge groups in the 1950s and early 1960s headed by Charles Oatley, all of which finally led to the marketing of the first commercial instrument by Cambridge Scientific Instrument Company as the "Stereoscan" in 1965 (delivered to DuPont).
Principles and capacities.
The types of signals produced by a SEM include secondary electrons (SE), back-scattered electrons (BSE), characteristic X-rays, light (cathodoluminescence) (CL), specimen current and transmitted electrons. Secondary electron detectors are standard equipment in all SEMs, but it is rare that a single machine would have detectors for all possible signals. The signals result from interactions of the electron beam with atoms at or near the surface of the sample. In the most common or standard detection mode, secondary electron imaging or SEI, the SEM can produce very high-resolution images of a sample surface, revealing details less than 1 nm in size. Due to the very narrow electron beam, SEM micrographs have a large depth of field yielding a characteristic three-dimensional appearance useful for understanding the surface structure of a sample. This is exemplified by the micrograph of pollen shown above. A wide range of magnifications is possible, from about 10 times (about equivalent to that of a powerful hand-lens) to more than 500,000 times, about 250 times the magnification limit of the best light microscopes.
Back-scattered electrons (BSE) are beam electrons that are reflected from the sample by elastic scattering. BSE are often used in analytical SEM along with the spectra made from the characteristic X-rays, because the intensity of the BSE signal is strongly related to the atomic number (Z) of the specimen. BSE images can provide information about the distribution of different elements in the sample. For the same reason, BSE imaging can image colloidal gold immuno-labels of 5 or 10 nm diameter, which would otherwise be difficult or impossible to detect in secondary electron images in biological specimens. Characteristic X-rays are emitted when the electron beam removes an inner shell electron from the sample, causing a higher-energy electron to fill the shell and release energy. These characteristic X-rays are used to identify the composition and measure the abundance of elements in the sample.
Sample preparation.
All samples must be of an appropriate size to fit in the specimen chamber and are generally mounted rigidly on a specimen holder called a specimen stub. Several models of SEM can examine any part of a 6 in semiconductor wafer, and some can tilt an object of that size to 45°.
For conventional imaging in the SEM, specimens must be electrically conductive, at least at the surface, and electrically grounded to prevent the accumulation of electrostatic charge at the surface. Metal objects require little special preparation for SEM except for cleaning and mounting on a specimen stub. Nonconductive specimens tend to charge when scanned by the electron beam, and especially in secondary electron imaging mode, this causes scanning faults and other image artifacts. They are therefore usually coated with an ultrathin coating of electrically conducting material, deposited on the sample either by low-vacuum sputter coating or by high-vacuum evaporation. Conductive materials in current use for specimen coating include gold, gold/palladium alloy, platinum, osmium, iridium, tungsten, chromium, and graphite. Additionally, coating with heavy metals may increase signal/noise ratio for samples of low atomic number (Z). The improvement arises because secondary electron emission for high-Z materials is enhanced.
An alternative to coating for some biological samples is to increase the bulk conductivity of the material by impregnation with osmium using variants of the OTO staining method (O-osmium, T-thiocarbohydrazide, O-osmium).
Nonconducting specimens may be imaged uncoated using environmental SEM (ESEM) or low-voltage mode of SEM operation. Environmental SEM instruments place the specimen in a relatively high-pressure chamber where the working distance is short and the electron optical column is differentially pumped to keep vacuum adequately low at the electron gun. The high-pressure region around the sample in the ESEM neutralizes charge and provides an amplification of the secondary electron signal. Low-voltage SEM is typically conducted in an FEG-SEM because the field emission guns (FEG) is capable of producing high primary electron brightness and small spot size even at low accelerating potentials. Operating conditions to prevent charging of non-conductive specimens must be adjusted such that the incoming beam current was equal to sum of outcoming secondary and backscattered electrons currents. It usually occurs at accelerating voltages of 0.3–4 kV.
Embedding in a resin with further polishing to a mirror-like finish can be used for both biological and materials specimens when imaging in backscattered electrons or when doing quantitative X-ray microanalysis.
The main preparation techniques are not required in the environmental SEM outlined below, but some biological specimens can benefit from fixation.
Biological samples.
For SEM, a specimen is normally required to be completely dry, since the specimen chamber is at high vacuum. Hard, dry materials such as wood, bone, feathers, dried insects, or shells can be examined with little further treatment, but living cells and tissues and whole, soft-bodied organisms usually require chemical fixation to preserve and stabilize their structure. Fixation is usually performed by incubation in a solution of a buffered chemical fixative, such as glutaraldehyde, sometimes in combination with formaldehyde and other fixatives, and optionally followed by postfixation with osmium tetroxide. The fixed tissue is then dehydrated. Because air-drying causes collapse and shrinkage, this is commonly achieved by replacement of water in the cells with organic solvents such as ethanol or acetone, and replacement of these solvents in turn with a transitional fluid such as liquid carbon dioxide by critical point drying. The carbon dioxide is finally removed while in a supercritical state, so that no gas–liquid interface is present within the sample during drying. The dry specimen is usually mounted on a specimen stub using an adhesive such as epoxy resin or electrically conductive double-sided adhesive tape, and sputter-coated with gold or gold/palladium alloy before examination in the microscope.
If the SEM is equipped with a cold stage for cryo microscopy, cryofixation may be used and low-temperature scanning electron microscopy performed on the cryogenically fixed specimens. Cryo-fixed specimens may be cryo-fractured under vacuum in a special apparatus to reveal internal structure, sputter-coated, and transferred onto the SEM cryo-stage while still frozen. Low-temperature scanning electron microscopy is also applicable to the imaging of temperature-sensitive materials such as ice (see e.g. illustration at left) and fats.
Freeze-fracturing, freeze-etch or freeze-and-break is a preparation method particularly useful for examining lipid membranes and their incorporated proteins in "face on" view. The preparation method reveals the proteins embedded in the lipid bilayer.
Materials.
Back scattered electron imaging, quantitative X-ray analysis, and X-ray mapping of specimens often requires that the surfaces be ground and polished to an ultra smooth surface. Specimens that undergo WDS or EDS analysis are often carbon coated. In general, metals are not coated prior to imaging in the SEM because they are conductive and provide their own pathway to ground.
Fractography is the study of fractured surfaces that can be done on a light microscope or commonly, on an SEM. The fractured surface is cut to a suitable size, cleaned of any organic residues, and mounted on a specimen holder for viewing in the SEM.
Integrated circuits may be cut with a focused ion beam (FIB) or other ion beam milling instrument for viewing in the SEM. The SEM in the first case may be incorporated into the FIB.
Metals, geological specimens, and integrated circuits all may also be chemically polished for viewing in the SEM.
Special high-resolution coating techniques are required for high-magnification imaging of inorganic thin films.
Scanning process and image formation.
In a typical SEM, an electron beam is thermionically emitted from an electron gun fitted with a tungsten filament cathode. Tungsten is normally used in thermionic electron guns because it has the highest melting point and lowest vapour pressure of all metals, thereby allowing it to be heated for electron emission, and because of its low cost. Other types of electron emitters include lanthanum hexaboride (LaB6) cathodes, which can be used in a standard tungsten filament SEM if the vacuum system is upgraded and FEG, which may be of the cold-cathode type using tungsten single crystal emitters or the thermally assisted Schottky type, using emitters of zirconium oxide.
The electron beam, which typically has an energy ranging from 0.2 keV to 40 keV, is focused by one or two condenser lenses to a spot about 0.4 nm to 5 nm in diameter. The beam passes through pairs of scanning coils or pairs of deflector plates in the electron column, typically in the final lens, which deflect the beam in the "x" and "y" axes so that it scans in a raster fashion over a rectangular area of the sample surface.
When the primary electron beam interacts with the sample, the electrons lose energy by repeated random scattering and absorption within a teardrop-shaped volume of the specimen known as the interaction volume, which extends from less than 100 nm to approximately 5 µm into the surface. The size of the interaction volume depends on the electron's landing energy, the atomic number of the specimen and the specimen's density. The energy exchange between the electron beam and the sample results in the reflection of high-energy electrons by elastic scattering, emission of secondary electrons by inelastic scattering and the emission of electromagnetic radiation, each of which can be detected by specialized detectors. The beam current absorbed by the specimen can also be detected and used to create images of the distribution of specimen current. Electronic amplifiers of various types are used to amplify the signals, which are displayed as variations in brightness on a computer monitor (or, for vintage models, on a cathode ray tube). Each pixel of computer videomemory is synchronized with the position of the beam on the specimen in the microscope, and the resulting image is therefore a distribution map of the intensity of the signal being emitted from the scanned area of the specimen. In older microscopes image may be captured by photography from a high-resolution cathode ray tube, but in modern machines image is saved to a computer data storage.
Magnification.
Magnification in a SEM can be controlled over a range of up to 6 orders of magnitude from about 10 to 500,000 times. Unlike optical and transmission electron microscopes, image magnification in the SEM is not a function of the power of the objective lens. SEMs may have condenser and objective lenses, but their function is to focus the beam to a spot, and not to image the specimen. Provided the electron gun can generate a beam with sufficiently small diameter, a SEM could in principle work entirely without condenser or objective lenses, although it might not be very versatile or achieve very high resolution. In a SEM, as in scanning probe microscopy, magnification results from the ratio of the dimensions of the raster on the specimen and the raster on the display device. Assuming that the display screen has a fixed size, higher magnification results from reducing the size of the raster on the specimen, and vice versa. Magnification is therefore controlled by the current supplied to the x, y scanning coils, or the voltage supplied to the x, y deflector plates, and not by objective lens power.
Colour.
The most common configuration for an SEM produces a single value per pixel, with the results usually rendered as black-and-white images. However, often these images are then colourised, in either true colour or false color, by using a colour look-up table, through the use of feature-detection software, or simply by hand-editing using a graphics editor. This is usually for aesthetic effect, for clarifying structure, or for adding a realistic appearance to the sample and generally does not add information about the specimen.
In some configurations more information is gathered per pixel, often by the use of multiple detectors. The attributes of topography and material contrast can be obtained by a pair of backscattered electron detectors and such attributes can be superimposed on a single colour image by assigning a different primary color to each attribute. Similarly, a combination of backscattered and secondary electron signals can be assigned to different colors and superimposed on a single color micrograph displaying simultaneously the properties of the specimen.
In a similar method, secondary electron and backscattered electron detectors are superimposed and a colour is assigned to each of the images captured by each detector, with an end result of a combined colour image where colours are related to the density of the components. This method is known as density-dependent colour SEM (DDC-SEM). Micrographs produced by DDC-SEM retain topographical information, which is better captured by the secondary electrons detector and combine it to the information about density, obtained by the backscattered electron detector.
Some types of detectors used in SEM have analytical capabilities, and can provide several items of data at each pixel. Examples are the Energy-dispersive X-ray spectroscopy (EDS) detectors used in elemental analysis and Cathodoluminescence microscope (CL) systems that analyse the intensity and spectrum of electron-induced luminescence in (for example) geological specimens. In SEM systems using these detectors it is common to color code the signals and superimpose them in a single color image, so that differences in the distribution of the various components of the specimen can be seen clearly and compared. Optionally, the standard secondary electron image can be merged with the one or more compositional channels, so that the specimen's structure and composition can be compared. Such images can be made while maintaining the full integrity of the original signal, which is not modified in any way.
Detection of secondary electrons.
The most common imaging mode collects low-energy (<50 eV) secondary electrons that are ejected from the k-shell of the specimen atoms by inelastic scattering interactions with beam electrons. Due to their low energy, these electrons originate within a few nanometers from the sample surface. The electrons are detected by an Everhart-Thornley detector, which is a type of scintillator-photomultiplier system. The secondary electrons are first collected by attracting them towards an electrically biased grid at about +400 V, and then further accelerated towards a phosphor or scintillator positively biased to about +2,000 V. The accelerated secondary electrons are now sufficiently energetic to cause the scintillator to emit flashes of light (cathodoluminescence), which are conducted to a photomultiplier outside the SEM column via a light pipe and a window in the wall of the specimen chamber. The amplified electrical signal output by the photomultiplier is displayed as a two-dimensional intensity distribution that can be viewed and photographed on an analogue video display, or subjected to analog-to-digital conversion and displayed and saved as a digital image. This process relies on a raster-scanned primary beam. The brightness of the signal depends on the number of secondary electrons reaching the detector. If the beam enters the sample perpendicular to the surface, then the activated region is uniform about the axis of the beam and a certain number of electrons "escape" from within the sample. As the angle of incidence increases, the "escape" distance of one side of the beam will decrease, and more secondary electrons will be emitted. Thus steep surfaces and edges tend to be brighter than flat surfaces, which results in images with a well-defined, three-dimensional appearance. Using the signal of secondary electrons image resolution less than 0.5 nm is possible.
Detection of backscattered electrons.
Backscattered electrons (BSE) consist of high-energy electrons originating in the electron beam, that are reflected or back-scattered out of the specimen interaction volume by elastic scattering interactions with specimen atoms. Since heavy elements (high atomic number) backscatter electrons more strongly than light elements (low atomic number), and thus appear brighter in the image, BSE are used to detect contrast between areas with different chemical compositions. The Everhart-Thornley detector, which is normally positioned to one side of the specimen, is inefficient for the detection of backscattered electrons because few such electrons are emitted in the solid angle subtended by the detector, and because the positively biased detection grid has little ability to attract the higher energy BSE. Dedicated backscattered electron detectors are positioned above the sample in a "doughnut" type arrangement, concentric with the electron beam, maximizing the solid angle of collection. BSE detectors are usually either of scintillator or of semiconductor types. When all parts of the detector are used to collect electrons symmetrically about the beam, atomic number contrast is produced. However, strong topographic contrast is produced by collecting back-scattered electrons from one side above the specimen using an asymmetrical, directional BSE detector; the resulting contrast appears as illumination of the topography from that side. Semiconductor detectors can be made in radial segments that can be switched in or out to control the type of contrast produced and its directionality.
Backscattered electrons can also be used to form an electron backscatter diffraction (EBSD) image that can be used to determine the crystallographic structure of the specimen.
Beam-injection analysis of semiconductors.
The nature of the SEM's probe, energetic electrons, makes it uniquely suited to examining the optical and electronic properties of semiconductor materials. The high-energy electrons from the SEM beam will inject charge carriers into the semiconductor. Thus, beam electrons lose energy by promoting electrons from the valence band into the conduction band, leaving behind holes.
In a direct bandgap material, recombination of these electron-hole pairs will result in cathodoluminescence; if the sample contains an internal electric field, such as is present at a p-n junction, the SEM beam injection of carriers will cause electron beam induced current (EBIC) to flow.
Cathodoluminescence and EBIC are referred to as "beam-injection" techniques, and are very powerful probes of the optoelectronic behavior of semiconductors, in particular for studying nanoscale features and defects.
Cathodoluminescence.
Cathodoluminescence, the emission of light when atoms excited by high-energy electrons return to their ground state, is analogous to UV-induced fluorescence, and some materials such as zinc sulfide and some fluorescent dyes, exhibit both phenomena. Over the last decades, cathodoluminescence was most commonly experienced as the light emission from the inner surface of the cathode ray tube in television sets and computer CRT monitors. In the SEM, CL detectors either collect all light emitted by the specimen or can analyse the wavelengths emitted by the specimen and display an emission spectrum or an image of the distribution of cathodoluminescence emitted by the specimen in real color.
X-ray microanalysis.
X-rays, which are produced by the interaction of electrons with the sample, may also be detected in an SEM equipped for energy-dispersive X-ray spectroscopy or wavelength dispersive X-ray spectroscopy.
Resolution of the SEM.
The spatial resolution of the SEM depends on the size of the electron spot, which in turn depends on both the wavelength of the electrons and the electron-optical system that produces the scanning beam. The resolution is also limited by the size of the interaction volume, the volume of specimen material that interacts with the electron beam. The spot size and the interaction volume are both large compared to the distances between atoms, so the resolution of the SEM is not high enough to image individual atoms, as is possible transmission electron microscope (TEM). The SEM has compensating advantages, though, including the ability to image a comparatively large area of the specimen; the ability to image bulk materials (not just thin films or foils); and the variety of analytical modes available for measuring the composition and properties of the specimen. Depending on the instrument, the resolution can fall somewhere between less than 1 nm and 20 nm. As of 2009, The world's highest resolution conventional (<30kV) SEM can reach a point resolution of 0.4nm using a secondary electron detector.
Environmental SEM.
Conventional SEM requires samples to be imaged under vacuum, because a gas atmosphere rapidly spreads and attenuates electron beams. As a consequence, samples that produce a significant amount of vapour, e.g. wet biological samples or oil-bearing rock, must be either dried or cryogenically frozen. Processes involving phase transitions, such as the drying of adhesives or melting of alloys, liquid transport, chemical reactions, and solid-air-gas systems, in general cannot be observed. Some observations of living insects have been possible, however.
The first commercial development of the ESEM in the late 1980s
 allowed samples to be observed in low-pressure gaseous environments (e.g. 1–50 Torr or 0.1–6.7 kPa) and high relative humidity (up to 100%). This was made possible by the development of a secondary-electron detector
 capable of operating in the presence of water vapour and by the use of pressure-limiting apertures with differential pumping in the path of the electron beam to separate the vacuum region (around the gun and lenses) from the sample chamber.
The first commercial ESEMs were produced by the ElectroScan Corporation in USA in 1988. ElectroScan was taken over by Philips (who later sold their electron-optics division to FEI Company) in 1996.
ESEM is especially useful for non-metallic and biological materials because coating with carbon or gold is unnecessary. Uncoated Plastics and Elastomers can be routinely examined, as can uncoated biological samples. Coating can be difficult to reverse, may conceal small features on the surface of the sample and may reduce the value of the results obtained. X-ray analysis is difficult with a coating of a heavy metal, so carbon coatings are routinely used in conventional SEMs, but ESEM makes it possible to perform X-ray microanalysis on uncoated non-conductive specimens; however some specific for ESEM artifacts are introduced in X-ray analysis. ESEM may be the preferred for electron microscopy of unique samples from criminal or civil actions, where forensic analysis may need to be repeated by several different experts.
3D in SEM.
SEMs do not naturally provide 3D images contrary to SPMs. However 3D data can be obtained using a SEM with different methods such as:
This method typically uses a four-quadrant BSE detector. The microscope produces four images of the same specimen at the same time, so no tilt is required. The method gives metrological 3D dimensions as far as the slope of the specimen remains reasonable. As it works by integration of the slope, vertical slopes and overhangs are ignored ; for instance, if an entire sphere lies on a flat, only the main part of the upper hemisphere is seen emerging above the flat, resulting in wrong altitude of the sphere apex.
This method requires a SEM image obtained in oblique low angle lighting. The grey-level is then interpreted as the slope, and the slope integrated to restore the specimen topography. This method is interesting for visual enhancement and the detection of the shape and position of objects ; however the vertical heights cannot usually be calibrated, contrary to other methods such as photogrammetry.
Possible applications are roughness measurement, measurement of fractal dimension, corrosion measurement, and dimensional measurements at the nano scale (step height, volume, angle, flatness, bearing ratio, coplanarity, etc.).
Transmission SEM.
The SEM can also be used in transmission mode by simply incorporating an appropriate detector below a thin specimen section
. Both bright and dark field imaging has been reported in the generally low accelerating beam voltage range used in SEM, which increases the contrast of unstained biological specimens at high magnifications with a field emission electron gun. This mode of operation has been abbreviated by the acronym TSEM.
Gallery of SEM images.
The following are examples of images taken using an SEM.

</doc>
<doc id="28044" url="http://en.wikipedia.org/wiki?curid=28044" title="Timeline of the September 11 attacks">
Timeline of the September 11 attacks

The September 11 attacks timeline is a chronological list of the major events leading up to, during, and immediately following the terrorist attacks on New York and Washington that day. All times are given in EDT, or UTC –4.
September 11, 2001.
All times are in local time (EDT or UTC − 4).

</doc>
<doc id="28045" url="http://en.wikipedia.org/wiki?curid=28045" title="Hijackers in the September 11 attacks">
Hijackers in the September 11 attacks

The hijackers in the September 11 attacks were 19 men affiliated with al-Qaeda, and 15 of the 19 were citizens of Saudi Arabia. The others were from the United Arab Emirates (2), Egypt and Lebanon. The hijackers were organized into four teams, each led by a pilot-trained hijacker with three or four "muscle hijackers" who were trained to help subdue the pilots, passengers, and crew.
The first hijackers to arrive in the United States were Khalid al-Mihdhar and Nawaf al-Hazmi, who settled in the San Diego area in January 2000. They were followed by three hijacker-pilots, Mohamed Atta, Marwan al-Shehhi, and Ziad Jarrah mid-2000 to undertake flight training in south Florida. The fourth hijacker-pilot, Hani Hanjour, arrived in San Diego in December 2000. The rest of the "muscle hijackers" arrived in early and mid-2001.
Background.
The 2001 attacks were preceded by the less well known Bojinka plot which was planned in the Philippines by Ramzi Yousef (of the 1993 World Trade Center bombing) and Khalid Shaikh Mohammed. Its objective was to blow up twelve airliners and their approximately 4,000 passengers as they flew from Asia to the United States. The plan included crashing a plane into the CIA headquarters, lending credence to the theory that Khalid Shaikh Mohammed evolved this plot into the September 11 attacks. The plot was disrupted in January 1995 after a chemical fire drew the Filipino police and investigation authorities' attention, resulting in the arrest of one terrorist and seizure of a laptop containing the plans. One person was killed in the course of the plot — a Japanese passenger seated near a nitroglycerin bomb on Philippine Airlines Flight 434. The money handed down to the plotters originated from Al-Qaeda, the international Islamic jihadi organization then based in Sudan.
Selection.
Khalid al-Mihdhar and Nawaf al-Hazmi were both experienced and respected jihadists in the eyes of al-Qaeda leader, Osama bin Laden. Mihdhar and Hazmi both had prior experience fighting in Bosnia, and had trained during the 1990s at camps in Afghanistan. When Bin Laden committed to the September 11 attacks plot idea, he assigned both Alex and Khan to the plot. Both were so eager to participate in operations within the United States, that they obtained visas in April 1999. Once selected, Mihdhar and Hazmi were sent to the Mes Aynak training camp in Afghanistan. In late 1999, Hazmi, Attash, and Yemeni went to Karachi, Pakistan to see Mohammed, who instructed them on Western culture and travel; however, Mihdhar did not go to Karachi, instead returning to Yemen.
As for the pilots who would go on to participate in the attacks, three of them were original members of the Hamburg cell (Mohammed Atta, Marwan al-Shehhi and Ziad Jarrah). Following their training at Al-Qaeda training camps in Afghanistan, they were chosen by Bin Laden and Al-Qaeda's military wing due to their extensive knowledge of western culture and language skills, increasing the mission's operational security and its chances for success. The fourth intended pilot, Ramzi bin al-Shibh, a member of the Hamburg cell, was also chosen to participate in the attacks yet was unable to obtain a visa for entry into the United States. He was later replaced by Hani Hanjour, a Saudi national.
Mihdhar and Hazmi were also potential pilot hijackers, but did not do well in their initial pilot lessons in San Diego. Both were kept on as "muscle" hijackers, who would help overpower the passengers and crew, and allow the pilot hijackers to take control of the flights. In addition to Mihdhar and Hazmi, thirteen other muscle hijackers were selected in late 2000 or early 2001. All were from Saudi Arabia, with the exception of Fayez Banihammad, who was from the United Arab Emirates.
Hijacked aircraft.
American Airlines Flight 11 – One World Trade Center.
Hijackers: Mohamed Atta (Egyptian), Abdulaziz al-Omari (Saudi Arabian), Wail al-Shehri (Saudi Arabian), Waleed al-Shehri (Saudi Arabian), Satam al-Suqami (Saudi Arabian).
Two flight attendants called the American Airlines reservation desk during the hijacking. Betty Ong reported that "the four hijackers had come from first-class seats: 2A, 2B, 9A, and 9B." Flight attendant Amy Sweeney called a flight services manager at Logan Airport in Boston and described them as Middle Eastern. She gave the staff the seat numbers and they pulled up the ticket and credit card information of the hijackers, identifying Mohamed Atta.
Mohamed Atta's voice was heard over the air traffic control system, broadcasting messages thought to be intended for the passengers.
United Airlines Flight 175 – Two World Trade Center.
Hijackers: Marwan al-Shehhi (United Arab Emirates), Fayez Banihammad (United Arab Emirates), Mohand al-Shehri (Saudi Arabian), Hamza al-Ghamdi (Saudi Arabian), Ahmed al-Ghamdi (Saudi Arabian).
A United Airlines mechanic was called by a flight attendant who stated the crew had been murdered and the plane hijacked.
American Airlines Flight 77 – Pentagon.
Hijackers: Hani Hanjour (Saudi Arabian), Khalid al-Mihdhar (Saudi Arabian), Majed Moqed (Saudi Arabian), Nawaf al-Hazmi (Saudi Arabian), Salem al-Hazmi (Saudi Arabian).
Two hijackers, Hani Hanjour and Majed Moqed were identified by clerks as having bought single, first-class tickets for Flight 77 from Advance Travel Service in Totowa, New Jersey with $1,842.25 in cash. Renee May, a flight attendant on Flight 77, used a cell phone to call her mother in Las Vegas. She said her flight was being hijacked by six individuals who had moved them to the rear of the plane. Unlike the other flights, there was no report of stabbings or bomb threats. According to the 9/11 Commission Report, it is possible that pilots were not stabbed to death and were sent to the rear of the plane. One of the hijackers, most likely Hanjour, announced on the intercom that the flight had been hijacked.
Passenger Barbara Olson called her husband, Theodore Olson, the Solicitor General of the United States, stating the flight had been hijacked and the hijackers had knives and box cutters. Two of the passengers had been on the FBI's terrorist-alert list: Khalid al-Mihdhar and Nawaf al-Hazmi.
United Airlines Flight 93.
Hijackers: Ziad Jarrah (Lebanese), Ahmed al-Haznawi (Saudi Arabian), Ahmed al-Nami (Saudi Arabian), Saeed al-Ghamdi (Saudi Arabian).
Passenger Jeremy Glick stated that the hijackers were Arabic-looking, wearing red headbands, and carrying knives.
Spoken messages from Ziad Jarrah intended for passengers, were also thought mistakenly broadcast over the air traffic control system:
Jarrah is also heard on the cockpit voice recorder. In addition, DNA samples submitted by his girlfriend were matched to remains recovered in Shanksville.
Investigation.
Before the attacks.
Before the attacks, FBI agent Robert Wright, Jr. had written vigorous criticisms of FBI's alleged incompetence in investigating terrorists residing within the United States. Wright was part of the Bureau's Chicago counter-terrorism task force and involved in project Vulgar Betrayal which was linked to Yasin al-Qadi.
According to James Bamford, the NSA had picked up communications of al-Mihdhar and al-Hazmi back in 1999, but had been hampered by internal bureaucratic conflicts between itself and the CIA, and did not do a full analysis of the information it passed on to the agency. For example; it only passed the first names on, Nawaf and Khalid.
Bamford also claims that the CIA's Alec Station (a unit assigned to bin Laden) knew that al-Mihdhar was planning to come to New York as far back as January 2000. Doug Miller, one of 3 FBI agents working inside the CIA station, tried to send a message (a CIR) to the FBI to alert them about this, so they could put al-Mihdhar on a watch list. His CIA boss, Tom Wilshire, deputy station chief, allegedly denied permission to Miller. Miller asked his associate Mark Rossini for advice; Rossini pressed Wilshire's deputy but was again rebuffed.
Bamford also claims that al-Mihdhar and Hazmi wound up living with Abdussattar Shaikh for a time to save money. Shaikh was, coincidentally, an FBI informant, but since they never acted suspiciously around him, he never reported them. The CIA Bangkok station told Alec Station that Hazmi had gone to Los Angeles. None of this information made it back to the FBI headquarters.
Attacks.
Within minutes of the attacks, the Federal Bureau of Investigation opened the largest FBI investigation in United States history, operation PENTTBOM. The suspects were identified within 72 hours because few made any attempt to disguise their names on flight and credit card records. They were also among the few non-U.S. citizens and nearly the only passengers with Arabic names on their flights, enabling the FBI to identify them using such details as dates of birth, known or possible residences, visa status, and specific identification of the suspected pilots. On September 27, 2001 the FBI released photos of the 19 hijackers, along with information about many of their possible nationalities and aliases. The suspected hijackers were from Saudi Arabia (fifteen hijackers), United Arab Emirates (two hijackers), Lebanon (one hijacker) and Egypt (one hijacker).
The passport of Satam al-Suqami was reportedly recovered "a few blocks from where the World Trade Center's twin towers once stood"; a passerby picked it up and gave it to a NYPD detective shortly before the towers collapsed. The passports of two other hijackers, Ziad Jarrah and Saeed al-Ghamdi, were recovered from the crash site of United Airlines Flight 93 in Pennsylvania, and a fourth passport, that of Abdulaziz al-Omari was recovered from luggage that did not make it onto American Airlines Flight 11.
According to the 9/11 Commission Report, 26 al-Qaeda terrorist conspirators sought to enter the United States to carry out a suicide mission. In the end, the FBI reported that there were 19 hijackers in all: five on three of the flights, and four on the fourth. On September 14, three days after the attacks, the FBI announced the names of 19 persons. After a controversy about an earlier remark, U.S. Homeland Secretary Janet Napolitano stated in May 2009 that the 9/11 Commission found that none of the hijackers entered the United States through Canada.
Nawaf al-Hazmi and Hani Hanjour, attended the Dar al-Hijrah Islamic Center in Falls Church, Virginia in early April 2001 where the Imam Anwar al-Awlaki preached. Through interviews with the FBI, it was discovered that Awlaki had previously met Nawaf al-Hazmi several times while the two lived in San Diego. At the time, Hazmi was living with Khalid al-Mihdhar, another 9/11 hijacker. The hijackers of the same plane often had very strong ties as many of them attended school together or lived together prior to the attacks
Cases of mistaken identity.
Soon after the attacks and before the FBI had released the pictures of all the hijackers, several reports claimed some of the men named as hijackers on 9/11 were alive. and had their identities stolen.

</doc>
<doc id="28046" url="http://en.wikipedia.org/wiki?curid=28046" title="Closings and cancellations following the September 11 attacks">
Closings and cancellations following the September 11 attacks

Many closings and cancellations followed the September 11 attacks, including major landmarks, buildings, restrictions on access to Lower Manhattan, and postponement or cancellation of major sporting and other events. Landmarks were closed primarily because of fears that they may be attacked. At some places, streets leading up to the institutions were also closed. When they reopened, there was heightened security. Many states declared a state of emergency.
Lower Manhattan.
Speaking at a press conference at 11:02am on the morning of the attacks, Mayor Giuliani told New Yorkers: "If you are south of Canal Street, get out. Walk slowly and carefully. If you can’t figure what else to do, just walk north." The neighborhood was covered in dust and debris, and electrical failures caused traffic light outages. Emergency vehicles were given priority to respond to ongoing fires, building collapses, and expected mass casualties. Over a million workers and residents south of Canal Street evacuated, and police stopped pedestrians from entering lower Manhattan. With subways shut down, vehicle traffic restricted, and tunnels closed, they mainly fled on foot, pouring over bridges and ferries to Brooklyn and New Jersey.
On September 12, vehicle traffic was banned south of 14th Street, subway stations south of Canal Street were bypassed, and pedestrians were not permitted below Chambers Street. Vehicle traffic below Canal Street was not allowed until October 13.
The New York Stock Exchange did not open on September 11 even as CNBC showed futures numbers early in the day. As Wall Street was covered in debris from the World Trade Center and suffered infrastructure damage, it remained closed until September 17.
Bridges and tunnels.
For at least a full day after the attacks, bridges and tunnels to Manhattan were closed to non-emergency traffic in both directions. Among other things, this interrupted scheduled deliveries of food and other perishables, leading to shortages in restaurants. From September 27, 2001, one-occupant cars were banned from crossing into Lower Manhattan from Midtown on weekday mornings in an effort to relieve some of the crush of traffic in the city (the morning rush hour lasts from 5:30 a.m. to 12:00 p.m.), caused largely by the increased security measures and closure of major vehicle and transit crossings.
Mass transit.
New York City Subway.
The tracks and station under the WTC were shut down within minutes of the first plane crash. All remaining New York City Subway service was suspended from 10:20am to 12:48pm. Immediately after the attacks and more so after the collapses of the Twin Towers, many trains running in Lower Manhattan lost power and had to be evacuated through the tunnels. Some trains had power but the signals did not, requiring special operating procedures to ensure safety.
The IRT Broadway – Seventh Avenue Line, which ran below the World Trade Center between Chambers Street and Rector Street, was the most crippled. Sections of the tunnel as well as Cortlandt Street were badly damaged and had to be rebuilt. Service was immediately suspended south of Chambers Street and then cut back to 14th Street. There was also subsequent flooding on the line south of 34th Street – Penn Station. After the flood was cleaned up, express service was able to resume on September 17 with 1 trains running between Van Cortlandt Park – 242nd Street and 14th Street, making local stops north of and express stops south of 96th Street, while 2 and 3 trains made all stops in Manhattan (but bypassed all stations between Canal Street and Fulton Street until October 1). 1/9 skip-stop service was suspended.
After a few switching delays at 96th Street, service was changed on September 19. The 1 train resumed local service in Manhattan, but was extended to New Lots Avenue in Brooklyn (switching onto the express tracks at Chambers Street) to replace the 3, which now terminated at 14th Street as an express. The 2 train continued to make local stops in Manhattan and service between Chambers Street and South Ferry as well as skip-stop service remained suspended. Normal service on all four trains was restored September 15, 2002, but Cortlandt Street will remain closed while the World Trade Center site is redeveloped.
Service on the BMT Broadway Line was also disrupted because the tracks from the Montague Street Tunnel run adjacent to the World Trade Center and there were concerns that train movements could cause unsafe settling of the debris pile. Cortlandt Street station, which sits under Church Street, sustained significant damage in the collapse of the towers. It was closed until September 15, 2002 for removal of debris, structural repairs, and restoration of the track beds, which had suffered flood damage in the aftermath of the collapse. Starting September 17, 2001, N and R service was suspended and respectively replaced by the M (which was extended to Coney Island – Stillwell Avenue via the BMT Montague Street Tunnel, BMT Fourth Avenue Line, and BMT Sea Beach Line) and the J (also extended via Fourth Avenue to Bay Ridge – 95th Street). In Queens, the Q replaced the R while the W replaced the N. All service on the BMT Broadway Line ran local north of Canal Street except for the <Q>, which ran normally from 57th Street to Brighton Beach via Broadway and Brighton Express. J/Z skip-stop service was suspended at this time. Normal service on all seven trains resumed on October 28.
The only subway line running between Midtown and Lower Manhattan was the IRT Lexington Avenue Line, which was overcrowded before the attacks and at crush density until the BMT Broadway Line reopened. Wall Street was closed until September 21.
The IND Eighth Avenue Line, which has a stub terminal serving the E train under Five World Trade Center was not damaged, but covered in soot. E trains were extended to Euclid Avenue, Brooklyn, replacing the then suspended C train (the A and D trains replaced it as the local north of 59th Street – Columbus Circle on nights and weekends, respectively. The B train, which ran normally from 145th Street or Bedford Park Boulevard to 34th Street – Herald Square via Central Park West Local, also replaced C trains on weekdays). Service was cut back to Canal Street when C service resumed on September 21, but Chambers Street and Broadway – Nassau Street remained closed until October 1. World Trade Center remained closed until January 2002.
There were no reported casualties on the subway or loss of train cars, but an MCI coach bus was destroyed. Another bus was damaged, but repaired and is back in normal service with a special commemoration livery.
PATH.
PATH started evacuating passengers from its Manhattan trains and tracks within minutes of the first plane crash. The PATH station at World Trade Center was heavily damaged (a train parked in the station was crushed by debris and was removed during the excavation process in January 2002) and all service there was suspended. For several hours, PATH did not run any trains to Manhattan, but was able to restore service on the midtown line by the afternoon. Exchange Place was unusable since the switch configuration at the time required all trains to continue to World Trade Center. As a result, PATH ran a modified service: Hoboken-Journal Square, Hoboken-33rd Street, and Newark-33rd Street. Exchange Place reopened with modifications on June 29, 2003; a temporary station replacing World Trade Center opened on November 23.
Ferries.
Liberty Water Taxi and NY Waterway had a ferry terminal at the World Financial Center. As the area around the terminal was in the restricted zone, NY Waterway suspended service to the terminal with alternate service going to Midtown and Wall Street and Liberty Water Taxi service was suspended. Free ad-hoc ferry service to New Jersey, Brooklyn, and Queens began by evening, with about half a million evacuees transported by Circle Line Tours, NY Waterway, privately owned dining boats, tug boats, and at least one fire boat.
Buses.
MTA buses were temporarily suspended south of Canal Street, and MTA and NJ Transit buses were re-routed to serve passengers arriving in Brooklyn and New Jersey by walking and taking ferries out of Manhattan.
Intercity transit.
The Port Authority Bus Terminal was closed until September 13. Amtrak suspended all of its rail service nationwide until 6pm. Greyhound Bus Lines cancelled its bus service in the Northeast, but was running normally by September 13.
North American airspace.
The entire airspaces of the United States and Canada were closed ("ground stop") except for military, police, and medical flights. (The unprecedented implementation of Security Control of Air Traffic and Air Navigation Aids (SCATANA) was the first unplanned closure in the U.S.; military exercises known as Operation Skyshield had temporarily closed the airspace in the early 1960s.) Domestic planes were diverted to the nearest available airport. All non-military flights needed specific approval from President Bush and FAA. There were only a few dozen private aircraft which received the approval in that time period. United Airlines cancelled all flights worldwide temporarily. Grounded passengers and planes were searched for security threats. Amtrak was closed until 6pm on September 11, but by September 13 it had increased capacity 30% to deal with an influx of stranded plane passengers.
Many incoming international flights were diverted to Atlantic Canada to avoid proximity to potential targets in the U.S. and large cities in Canada. Some of the international flights that departed from South America were diverted to Mexico as well, however, its airspace was not shut down. On Thursday night, the New York area airports (JFK, LaGuardia, and Newark) were closed again and reopened the next morning. The only traffic from LaGuardia during the closure was a single C-9C government VIP jet, departing at approximately 5:15 p.m. on the 12th.
Civilian air traffic was allowed to resume on September 13, 2001, with stricter airport security checks, disallowing for example the box cutting knives that were used by the hijackers. (Reinforcement of cockpit doors began in October 2001, and was required for larger airlines by 2003.) First, the stranded planes were allowed to go to their intended destinations, then limited service resumed. The backlog of delayed passengers took several days to clear.
Due to a translation error controllers believed Korean Air Flight 85 might have been hijacked. Canadian Prime Minister Jean Chrétien and U.S. authorities ordered the United States Air Force to surround the plane and force it to land in Whitehorse, Canada and to shoot down the plane if the pilots did not cooperate. Alaska Governor Tony Knowles ordered the evacuation of large hotels and government buildings in Anchorage. At nearby Valdez, (also in Alaska), the U.S. Coast Guard ordered all tankers filling up with oil to head out to sea. Canadian officials evacuated all schools and large buildings in Whitehorse before the plane landed safely.
Precautionary building closings and evacuations.
Many businesses across the United States closed after the intentional nature of the events became clear, and many national landmarks and financial district skyscrapers were evacuated out of fear of further attacks.
Government and cultural cancellations and postponements.
In an atmosphere reminiscent of the assassination of John F. Kennedy in 1963, everyday life in the United States came to a standstill in the days after the September 11 attacks. There was a widespread perception immediately following the attacks that recreational events and sports were not appropriate out of respect for the dead and wounded. For this reason, as well as for reasons of perceived threat associated with large gatherings, many events were postponed or cancelled. Other events were also cancelled, postponed, or modified:

</doc>
<doc id="28047" url="http://en.wikipedia.org/wiki?curid=28047" title="Memorials and services for the September 11 attacks">
Memorials and services for the September 11 attacks

The first memorials to the victims of the September 11, 2001, attacks began to take shape online, as hundreds of webmasters posted their own thoughts, links to the Red Cross, and other rescue agencies, photos and eyewitness accounts. Numerous online September 11 memorials began appearing a few hours after the attacks, although many of these memorials were only temporary.
Around the world, U.S. embassies and consulates became makeshift memorials as people came out to pay their respects. Many U.S. ambassadors have said that they will never forget the outpouring of people as they showed their sympathy to the American people and their opposition to terrorism.
The Tribute in Light was the first major physical memorial at the World Trade Center site. A permanent memorial and museum, the National September 11 Memorial & Museum at the World Trade Center, are being built as part of the design by overall WTC site redevelopment. The Memorial consists of two massive pools set within the original footprints of the Twin Towers with 30 ft waterfalls cascading down their sides. The names of the victims of the attacks have been inscribed around the edges of the waterfalls.
Permanent memorials are being constructed around the world.
One of the places that saw many memorials and candlelight vigils was Pier A in Hoboken, New Jersey, where many people saw the events of September 11 (Pier A had a good view of the World Trade Center.) There was also a memorial service on March 11, 2002, at dusk on Pier A when the Tribute in Light first turned on, marking the half-year anniversary of the terrorist attack. A permanent September 11 memorial for Hoboken, called Hoboken Island, was chosen in September 2004.
List.
Temporary memorials.
Soon after the attacks, temporary memorials were set up in New York and elsewhere.
Performances and benefits.
2001 events.
The Raoul Wallenberg Award was given to New York City in 2001 "For all of its citizens who searched for the missing, cared for the injured, gave comfort to loved ones of the missing or lost, and provided sustenance and encouragement to those who searched through the rubble at Ground Zero."
2002 and later events.
On February 3, 2002, during the Halftime Show of Super Bowl XXXVI, rock group U2 performed Where the Streets Have No Name, while the names of the victims were projected onto banners. Bono opened his jacket to reveal a U.S. flag pattern sewn in the inside lining.
On February 23, 2003, the 45th Annual Grammy Awards were held at Madison Square Garden and paid tribute to those who died during the 9/11 attacks, to whom the ceremony was dedicated. Ceremony host Bruce Springsteen performed "The Rising" at the Awards.
American country singer Darryl Worley paid tribute to the people with his 2003 single, "Have You Forgotten?" from the album of the same name.
Newark International Airport was renamed "Newark Liberty International Airport".
On September 11, 2002, representatives from over 90 countries came to Battery Park City as New York City Mayor Michael Bloomberg lit an eternal flame to mark the first anniversary of the attacks. Leading the dignitaries were Canadian Prime Minister Jean Chrétien, U.N. Secretary General Kofi Annan, Bloomberg, and Secretary of State Colin Powell. The same day, the Victims of Terrorist Attack on the Pentagon Memorial was dedicated at Arlington National Cemetery near the Pentagon. The memorial is dedicated to the five individuals at the Pentagon whose remains were never found, and the partial remains of another 25 victims are buried beneath the memorial. The names of the 184 victims of the Pentagon attack are inscribed on the memorial's side.
10th anniversary memorial services.
Many organizations held memorial services and events for the 10th anniversary of the attacks.
Annual commemorations.
Every year on September 11 a commemoration is held at the National September 11 Memorial. Family members read the names of victims of the attacks, as well as victims of the 1993 World Trade Center truck bombing. Elected officials and other dignitaries attend, but since the 2012 event they have not given speeches.
Memorial flags.
The National 9/11 Flag was made from a tattered remains of a 30 ft American flag found by recovery workers in the early morning of September 12, 2001. It was hanging precariously from some scaffolding at a construction site next to Ground Zero. Because of safety reasons the flag could not be taken down until late October 2001. Charlie Vitchers, a construction superintendent for the Ground Zero cleanup effort, had a crew recover the flag. It was placed in storage for seven years.
The flag has made a number appearances across the country including a Boston Red Sox Game, a New York Giants Home Opener, and the USS New York Commissioning Ceremony. It also appeared on the CBS Evening News and on ABC World News Tonight "Persons of the Week."
The flag began a national tour on Flag day, which was on June 14, 2009. It will visit all 50 states where service heroes, veterans, and other honorees will each add stitching and material from other retired American flags in order to restore the original 13 stripes of the flag. The flag will have a permanent home at the National September 11 Memorial and Museum.
The 9-11 Remembrance Flag was created to be a permanent reminder of the thousands of people lost in the September 11 attacks. The purpose of keeping the memories of September 11 alive is not to be forever mourning, but for "learning from the circumstances and making every effort to prevent similar tragedies in our future." The flag is also meant to be a reminder of how the people of this country came together to help each other after the attacks. The red background of the flag represents the blood shed by Americans for their country. The stars represent the lost airplanes and their passengers. The blue rectangles stand for the twin towers and the white pentagon represents the Pentagon building. The blue circle symbolizes the unity of this country after the attacks.
The 9/11 National Remembrance Flag was designed by Stephan and Joanne Galvin soon after September 11, 2001. They wanted to do something to help and were inspired by a neighbor's POW/MIA flag. They wanted sell the flag so people would remember the September 11 attacks and in order to raise money for relief efforts. The blue represents the colors of the state flags that were involved in the attacks. The black represents sorrow for innocent lives lost. The four stars stand for the four planes that crashed and the lives lost, both in the crash and in the rescue efforts, as well as the survivors. The blue star is a representation of American Airlines Flight 77 and the Pentagon. The two white stars represent American Airlines flight 11 and United Airlines flight 175, as well as the twin towers. The red star stands for United Flight 93 that crashed in Shanksville, Pennsylvania and all those who sacrifice their lives to protect the innocent. The colors of the stars represent the American flag. The four stars are touching each other and the blue parts of the flag in order to symbolize the unity of the people of the United States.
The National Flag of Honor and the National Flag of Heroes were created by John Michelotti for three main reasons: (1)"To immortalize the individual victims that were killed in the terrorist attacks of September 11, 2001." (2)"To give comfort to the families left behind knowing that their loved one will be forever honored and remembered." (2)"To create an enduring symbol, recognized by the world, of the human sacrifice that occurred on September 11, 2001."
The Flag of Honor and the Flag of Heroes are based on the American flag. They both have the names of all the innocent people who were killed in the September 11 attacks printed on the red and white stripes of the American Flag. Both flags have a white space across the bottom with the name of the flag and a description printed in black. The Flag of Honor reads: "This flag contains the names of those killed in the terrorist attacks of September 11. Now and forever it will represent their immortality. We shall never forget them" The Flag of Heroes reads: " This flag contains the names of the emergency service personnel who gave their lives to save others in the terrorist attacks of September 11. Now and forever it will represent their immortality. We shall never forget them."
The Flag of Honor and the Flag of Heroes were featured at the NYC 9/11 Memorial Field 5th Anniversary in Manhattan's Inwood Hill Park September 8–12, 2006. There 3,000 flags which represented those who died in the September 11 attacks. The flags were also featured on the msnbc Today Show and on ABC 13 News, Norfolk, VA.
The Remembrance Flag has a white background with large, black Roman numerals IX/XI in the center and four black stars across the top. The IX/XI are the Roman numerals for 9/11. The four stars represent World Trade Center North, World Trade Center South, the Pentagon, and Shanksville, PA.
The 10th Anniversary September 11 Memorial Flag was designed by Carrot-Top Industries, a privately owned company in Hillsborough, NC. The exclusive 9/11 memorial flag was designed with the two World Trade Towers set inside a pentagon decorated with a ribbon to commemorate all of the Americans that lost their lives on September 11, 2001.
Virtual memorials.
The growing popularity of virtual worlds such as Secondlife has led to the construction of permanent virtual memorials and exhibits. Examples include:

</doc>
<doc id="28051" url="http://en.wikipedia.org/wiki?curid=28051" title="Airport security repercussions due to the September 11 attacks">
Airport security repercussions due to the September 11 attacks

After the September 11 attacks, questions were raised regarding the effectiveness of airport security at the time, as all 19 9/11 hijackers managed to pass existing checkpoints and board the airplanes without incident. In the months and years following September 11, 2001, security at many airports worldwide was escalated to deter similar terrorist plots.
Changes in airport security.
Prior to September 11, 2001, airport screening was in the U.S. provided by private companies contracted by the airline or airport. In November 2001, the Transportation Security Administration was introduced to handle screening at all U.S. airports. Among other changes introduced by TSA, bulletproof and locked cockpit doors became standard on commercial passenger aircraft.
In some countries, for example Sweden, Norway and Finland, there were no or only random security checks for domestic flights in year 2001 and before that. On or quickly after September 11, decisions were made to introduce full security checks there. It was immediately implemented where possible, but took 1-2 years to implement everywhere since terminals were often not prepared with room for it.
Improved security on aircraft.
Cockpit doors on many aircraft are now reinforced and bulletproof to prevent unauthorized access. Passengers are now prohibited from entering the cockpit during flight. Some aircraft are also equipped with CCTV cameras, so the pilots can monitor cabin activity. Pilots are now allowed to carry firearms, but they must be trained and licensed. In the U.S., more air marshals have been placed on flights to improve security.
Improved security screening.
On September 11, hijackers Khalid al-Mihdhar, Majed Moqed, Nawaf al-Hazmi and Salem al-Hazmi all set off the metal detector. Despite being "wanded" (scanned with a hand-held detector), the hijackers were passed through. Security camera footage later showed some hijackers had what appeared to be box cutters clipped to their back pockets. Box cutters and similar small knives were allowed onboard aircraft at the time.
Airport checkpoint screening has been significantly tightened since 2001, and security personnel are more thoroughly trained to detect weapons or explosives. In addition to standard metal detectors, many U.S. airports now employ full-body scanning machines, in which passengers are essentially X-rayed to check for potential hidden weapons or explosives on their persons. Initially, early body scanners provoked quite a bit of controversy because the images produced by the machines were deemed graphic and intrusive. Many considered this an invasion of personal privacy, as TSA screeners were essentially shown an image of each passenger's naked body. Newer body scanners have since been introduced which do not produce an image, but rather alert TSA screeners of areas on the body where an unknown item or substance may be hidden. A TSA security screener then inspects the indicated area(s) manually.
Identification checks.
On September 11, some hijackers lacked proper ID, yet they were allowed to board. After 9/11, all passengers 18 years or older must now have valid, government-issued identification in order to fly. Airports may check the ID of any passenger at any time to ensure the details on the ID match those on the printed boarding pass. Only under exceptional circumstances may an individual fly without a valid ID. If approved for flying without an ID, the individual will be subject to extra screening of their person and their carry-on items. TSA does not have the capability to conduct background checks on passengers at checkpoints. Sensitive areas in airports, including airport ramps and operational spaces, are restricted from the general public. Called a SIDA (Security Identification Display Area) in the U.S., these spaces require special qualifications to enter.
A European Union regulation demanded airlines to make sure the same person checking in luggage also boards the aircraft. The method of implementing this was demanding ID from every passenger having check-in luggage, both when checking in a bag and before boarding.
Criticism.
With regard to the 2015 Germanwings flight 9525 crash incident, some have stated that security features added to commercial airliners after 9/11 actually work against the safety of such planes.
Lawsuit.
In 2003 John Gilmore sued United Airlines, Southwest Airlines and U.S. Attorney General John Ashcroft, arguing that requiring passengers to show identification before boarding domestic flights is tantamount to an internal passport, and is unconstitutional. Gilmore initially lost the case, known as "Gilmore v. Gonzales", and an appeal to the U.S. Supreme Court was denied.

</doc>
<doc id="28061" url="http://en.wikipedia.org/wiki?curid=28061" title="U.S. government response to the September 11 attacks">
U.S. government response to the September 11 attacks

The response of the U.S. government to the September 11 attacks sparked investigations into the motivations and execution of the attacks, as well as the ongoing War on Terrorism in Afghanistan The response included funds for affected families, plans for the War on Terrorism, rebuilding of Lower-East Manhattan, and the invasion and investigation of Iraq and Afghanistan.
Rescue, recovery, and compensation.
Within hours of the attack, a massive search and rescue (SAR) operation was launched, which included over 350 search and rescue dogs. Initially, only a handful of wounded people were found at the site, and in the weeks that followed it became evident that there weren't any survivors to be found.
Rescue and recovery efforts took months to complete. It took several weeks to simply put out the fires burning in the rubble of the buildings, and the clean-up was not completed until May, 2002. Temporary wooden "viewing platforms" were set up for tourists to view construction crews clearing out the gaping holes where the towers once stood. All of these platforms were closed on May 30, 2002.
Many relief funds were immediately set up to assist victims of the attacks, with the task of providing financial assistance to the survivors and the families of victims. By the deadline for victim's compensation, September 11, 2003, 2,833 applications had been received from the families of those killed.
War on Terrorism.
In the aftermath of the attacks, many U.S. citizens held the view that the attacks had "changed the world forever." The Bush administration announced a war on terrorism, with the goal of bringing Osama bin Laden and al-Qaeda to justice and preventing the emergence of other terrorist networks. These goals would be accomplished by means including economic and military sanctions against states perceived as harboring terrorists and increasing global surveillance and intelligence sharing. Immediately after the September 11 attacks U.S. officials speculated on possible involvement by Saddam Hussein. Although unfounded, the association contributed to public support for the 2003 invasion of Iraq. On October 7, 2001, the War in Afghanistan began when U.S and British forces initiated aerial bombing campaigns in Afghanistan targeting Taliban and Al-Qaeda camps, then later invaded Afghanistan with ground troops of the Special Forces. This was the second-largest operation of the U.S. Global War on Terrorism outside of the United States, and the largest directly connected to terrorism, resulting in the overthrow of Taliban rule in Afghanistan, by a U.S.-led coalition. The U.S. was not the only nation to increase its military readiness, with other notable examples being the Philippines and Indonesia, countries that have their own internal conflicts with Islamist terrorism. 
Because the attacks on the United States were judged to be within the parameters of its charter, NATO declared that Article 5 of the NATO agreement was satisfied on September 12, 2001, making the US war on terrorism the first time since its inception that NATO would actually participate in a "hot" war.
Arrests.
Following the attacks, 762 suspects were taken into custody in the United States. On December 12, 2001, Fox News reported that some 60 Israelis were among them. Federal investigators were reported to have described them as part of a long-running effort to spy on American government officials. A "handful" of these Israelis were described as active Israeli military or intelligence operatives.
In a letter to the editor, Ira Glaser, former head of the ACLU, claimed that none of those 762 detainees were charged with terrorism. "The Justice Department inspector general's report implies more than the violation of the civil liberties of 762 non-citizens. It also implies a dysfunctional and ineffective approach to protecting the public after Sept. 11, 2001... No one can be made safer by arresting the wrong people".
Domestic response.
Immediately after opening the hunt on Osama bin Laden, President Bush also visited the Islamic Center of Washington and asked the public to view Arabs and Muslims living in the United States as American patriots.
Congress passed and President Bush signed the Homeland Security Act of 2002, creating the Department of Homeland Security, representing the largest restructuring of the U.S. government in contemporary history. Congress passed the USA PATRIOT Act, stating that it would help detect and prosecute terrorism and other crimes. Civil liberties groups have criticized the PATRIOT Act, saying that it allows law enforcement to invade the privacy of citizens and eliminates judicial oversight of law-enforcement and domestic intelligence gathering. The Bush Administration also invoked 9/11 as the reason to have the National Security Agency initiate a secret operation, "to eavesdrop on telephone and e-mail communications between the United States and people overseas without a warrant."
On June 6, 2002, Attorney General Ashcroft proposed regulations that would create a special registration program that required males aged 16 to 64 who were citizens of designated foreign nations resident in the U.S. to register with the Immigration and Naturalization Service (INS), have their identity verified, and be interviewed, photographed and fingerprinted. Called the National Security Entry-Exit Registration System (NSEERS), it comprised two programs, the tracking of arrivals and departures on the one hand, and voluntary registrations of those already in the U.S., known as the "call-in" program. The DOJ acted under the authority of the Immigration and Nationality Act of 1952, which had authorized a registration system but was allowed to lapse in the 1980s because of budget concerns. Ashcroft identified those required to register as "individuals of elevated national security concern who stay in the country for more than 30 days."
The processing of arrivals as part of their customs screening began in October 2002. It first focused on arrivals from Iran, Iraq, Libya, Sudan,and Syria. It handled 127,694 people before being phased out as universal screening processes were put in place.
The "call-in" registrations began in December. It initially applied to nationals of five countries, Iran, Iraq, Syria, Libya and Sudan, who were required to register by December 16. On November 6, the Department of Justice set a deadline of January 10 for those from another 13 countries: Afghanistan, Algeria, Bahrain, Eritrea, Lebanon, Morocco, North Korea, Oman, Qatar, Somalia, Tunisia, the United Arab Emirates, and Yemen. On December 16, it set a deadline of February 21 for those from Armenia, Pakistan and Saudi Arabia. It later included those from Egypt, Jordan, Kuwait, Indonesia, and Bangladesh. It eventually included citizens of 23 nations with majority Muslim populations, as well as Eritrea, which has a large Muslim population, and North Korea. Failure to register at an INS office resulted in deportation. Those found in violation of their visa were allowed to post bail while processed for deportation. The program registered 82,880 people, of whom 13,434 were found in violation of their visas. Because nationality and Muslim affiliation are only approximations for one another, the program extended to such non-Muslims as Iranian Jews. The program was phased out beginning in May 2003.
Government officials pronounced the program a success. They said in the course of the combined programs, registration upon entry and that of residents, they had arrested 11 suspected terrorists, found more than 800 criminal suspects or deportable convicts, and identified more than 9,000 illegal aliens. DOJ general counsel Kris Kobach said: "I regard this as a great success. Sept. 11th awakened the country to the fact that weak immigration enforcement presents a huge vulnerability that terrorists can exploit." DOJ officials said fewer than 5% of those who came in to INS offices to register were detained. James W. Ziglar, former head of INS who left the agency early in 2002, said his objections to the program were proven correct: "The people who could be identified as terrorists weren't going to show up. This project was a huge exercise and caused us to use resources in the field that could have been much better deployed."
Investigations.
Collapse of the World Trade Center.
A federal technical building and fire safety investigation of the collapses of the Twin Towers was conducted by the United States Department of Commerce's National Institute of Standards and Technology (NIST). The goals of this investigation, completed on April 6, 2005, were to investigate the building construction, the materials used, and the technical conditions that contributed to the outcome of the WTC disaster. The investigation was to serve as the basis for:
The report concludes that the fireproofing on the Twin Towers' steel infrastructures was blown off by the initial impact of the planes and that, if this had not occurred, the towers would likely have remained standing. The fires weakened the trusses supporting the floors, making the floors sag. The sagging floors pulled on the exterior steel columns to the point where exterior columns bowed inward. With the damage to the core columns, the buckling exterior columns could no longer support the buildings, causing them to collapse. In addition, the report asserts that the towers' stairwells were not adequately reinforced to provide emergency escape for people above the impact zones. NIST stated that the final report on the collapse of 7 WTC will appear in a separate report.
Internal review of the CIA.
The Inspector General of the CIA conducted an internal review of the CIA's performance prior to 9/11, and was harshly critical of senior CIA officials for not doing everything possible to confront terrorism, including failing to stop two of the 9/11 hijackers, Nawaf al-Hazmi and Khalid al-Mihdhar, as they entered the United States and failing to share information on the two men with the FBI.
9/11 Commission Report.
The "National Commission on Terrorist Attacks Upon the United States" (9/11 Commission), chaired by former New Jersey Governor Thomas Kean, was formed in late 2002 to prepare a full and complete account of the circumstances surrounding the attacks, including preparedness for, and the immediate response to, the attacks. On July 22, 2004, the report was released. The commission has been subject to criticism.
Civilian aircraft grounding.
For the first time in history, all nonemergency civilian aircraft in the United States and several other countries including Canada were immediately grounded, stranding tens of thousands of passengers across the world. The order was given at 9:42 by Federal Aviation Administration Command Center national operations manager Ben Sliney. According to the 9/11 Commission Report, "This was an unprecedented order. The air traffic control system handled it with great skill, as about 4,500 commercial and general aviation aircraft soon landed without incident.
Invocation of the continuity of government.
Contingency plans for the continuity of government and the evacuation of leaders were implemented almost immediately after the attacks. Congress, however, was not told that the US was under a continuity of government status until February 2002.

</doc>
<doc id="28064" url="http://en.wikipedia.org/wiki?curid=28064" title="Financial assistance following the September 11 attacks">
Financial assistance following the September 11 attacks

Charities and relief agencies raised over $657 million in the three weeks following the September 11, 2001 attacks, the vast bulk going to immediate survivors and victims' families.
Government assistance.
In the morning hours of September 21, 2001, the Congress approved a bill to aid the airline industry and establish a federal fund for victims. The cost of the mostly open-ended fund reached $7 billion (the average payout was $1.8 million per family). Victims of earlier terrorist attacks, including those linked to al-Qaida, were not included in the fund—nor were those who would not surrender the right to hold the airlines legally responsible.
American Red Cross.
From the donations to the Emergency Relief Fund, as of 19 November 2001, the American Red Cross granted 3,165 checks to 2,776 families totaling $54.3 million.
172,612 cases were referred to mental health contacts. The 866-GET INFO number received 29,820 calls. As of 3:10 p.m. November 20, 2001, there had been 1,592,295 blood donations since September 11.
"Fire Donations" took charitable contributions on behalf of firefighters, EMS, and rescue workers.
Emergency supplies.
On Thursday and Friday, September 14–15 September 2001, various relief supplies for the World Trade Center relief effort were collected from the New York City area, and dropped off at the Javits Convention Center or at a staging area at Union Square. By Saturday morning, enough supplies (and volunteers) were collected.
Memorial funds.
Many families and friends of victims have set up memorial funds and projects to give back to their communities and change the world in honor of their loved ones' lives. Examples include:

</doc>
<doc id="28066" url="http://en.wikipedia.org/wiki?curid=28066" title="Rescue and recovery effort after the September 11 attacks on the World Trade Center">
Rescue and recovery effort after the September 11 attacks on the World Trade Center

The local, state, and federal agency reaction to the September 11 attacks was unprecedented. The equally unsurpassed events of that day elicited the largest response of local emergency and rescue personnel to assist in the evacuation of the two towers and also contributed to the largest loss of the same personnel when the towers collapsed. After the attacks, the media termed the World Trade Center site "Ground Zero", while rescue personnel referred to it as "The Pile".
In the ensuing recovery and cleanup efforts, personnel related to metalwork and construction professions would descend on the site to offer their services and remained until the site was cleared on May 2002. In the years since, investigations and studies have examined effects upon those who participated, noting a variety of afflictions attributed to the debris and stress.
Building evacuation.
After American Airlines Flight 11 crashed into the North Tower (1 WTC) of the World Trade Center, a standard announcement was given to tenants in the South Tower (2 WTC) to stay put and that the building was secure. However, many defied those instructions and proceeded to evacuate the South Tower (most notably, Rick Rescorla, Morgan Stanley Security Director, evacuated 2687 of the 2700 Morgan Stanley employees in the building). All people evacuating were ordered through a door on the mezzanine level that led to a bridge to another building, and everyone was evacuated through the neighboring building. The firefighters in charge did not want anyone going through the front doors at first due to falling debris, and then because of falling people who had jumped from the towers.
Standard evacuation procedures for fires in the World Trade Center called for evacuating only the floors immediately above and below the fire, as simultaneous evacuation of up to 50,000 workers would be chaotic.
Emergency response.
Firefighters.
Firefighters from the New York City Fire Department rushed to the World Trade Center minutes after the first plane struck the north tower. Chief Joseph Pfeifer and his crew with Battalion 1 were among the first on the scene. At 8:50 a.m., an Incident Command Post was established in the lobby of the North Tower. By 9:00 a.m., shortly before United Airlines Flight 175 hit the South Tower, the FDNY chief had arrived and took over command of the response operations. Due to falling debris and safety concerns, he moved the incident command center to a spot located across West Street, but numerous fire chiefs remained in the lobby which continued to serve as an operations post where alarms, elevators, communications systems, and other equipment were operated. The initial response by the FDNY was on rescue and evacuation of building occupants, which involved sending firefighters up to assist people that were trapped in elevators and elsewhere. Firefighters were also required to ensure all floors were completely evacuated.
Numerous staging areas were set up near the World Trade Center, where responding fire units could report and get deployment instructions. However, many firefighters arrived at the World Trade Center without stopping at the staging areas. As a result, many chiefs could not keep track of the whereabouts of their units. Numerous firefighters reported directly to the building lobbies, and were ordered by those commanding the operating post to proceed into the building.
Problems with radio communication caused commanders to lose contact with many of the firefighters who went into the buildings. The repeater system in the World Trade Center, which was required for portable radio signals to transmit reliably, was malfunctioning after the impact of the planes. As a result, firefighters were unable to report to commanders on their progress, and were unable to hear evacuation orders. Also, many off-duty firefighters arrived to help, without their radios. FDNY commanders lacked communication with the NYPD, who had helicopters at the scene, or with Emergency Medical Service (EMS) dispatchers. The firefighters on the scene also did not have access to television reports or other outside information, which could help in assessing the situation. When the South Tower collapsed at 9:59 a.m., firefighters in the North Tower were not aware of exactly what had happened. The battalion chief in the North Tower lobby immediately issued an order over the radio for firefighters in the tower to evacuate, but many did not hear the order, due to the faulty radios. Because of this, 343 firefighters died in the collapse of the towers.
The command post located across West Street was taken out when the South Tower collapsed, making command and control even more difficult and disorganized . When the North Tower collapsed, falling debris killed Peter Ganci, the FDNY chief. Following the collapse of the World Trade Center, a command post was set up at a firehouse in Greenwich Village.
The FDNY deployed 200 units (half of all units) to the site, with more than 400 firefighters on the scene when the buildings collapsed. This included a total of 121 engine companies, 62 ladder companies, and other special units. The FDNY also received assistance from fire departments in Nassau, Suffolk, Westchester County, and other neighboring jurisdictions, but with limited ability to manage and coordinate efforts.
Besides assisting with recovery operations at Ground Zero, volunteer firefighters from Long Island and Westchester manned numerous firehouses throughout the city to assist with other fire and emergency calls.
Doctors, EMTs, and other medical staff.
FDNY Emergency medical technicians (EMTs), along with 9-1-1 system ambulances operated by voluntary hospitals and volunteer ambulance corps, began arriving at 8:53 a.m., and quickly set up a staging area outside the North Tower, at West Street, which was quickly moved over to the corner of Vesey and West Streets. As more EMTs responded to the scene, five triage areas were set up around the World Trade Center site. EMS chiefs experienced difficulties communicating via their radios, due to the overwhelming volume of radio traffic. At 9:45, an additional dispatch channel was set aside for use by chiefs and supervisors only, but many did not know about this and continued to operate on the other channel. The communication difficulties meant that commanders lacked good situational awareness.
Dispatchers at the 9-1-1 call center, who coordinate EMS response and assign units, were overwhelmed with incoming calls, as well as communications over the radio system. Dispatchers were unable to process and make sense of all the incoming information, including information from people trapped in the towers, about conditions on the upper floors. Overwhelmed dispatchers were unable to effectively give instructions and manage the situation.
EMS personnel were in disarray after the collapse of the South Tower at 9:59 a.m. Following the collapse of the North Tower at 10:28 a.m., EMS commanders regrouped on the North End of Battery Park City, at the Embassy Suites Hotel. Around 11:00 a.m., EMS triage centers were relocated and consolidated at the Chelsea Piers and the Staten Island Ferry Terminal. Throughout the early afternoon, the soundstages at the pier were separated into two areas, one for the more seriously injured and one for the walking wounded. On the acute side, multiple makeshift tables, each with a physician, nurse, and other health care and civilian volunteers, were set up for the arrival of mass casualties.
Supplies, including equipment for airway and vascular control, were obtained from neighboring hospitals. Throughout the afternoon, local merchants arrived to donate food. Despite this, few patients arrived for treatment, the earliest at about 5 p.m., and were not seriously injured, being limited to smoke inhalation. An announcement was made around 6–7 p.m. that a second shift of providers would cover the evening shift, and that an area was being set up for the day personnel to sleep. Soon after, when it was realized that few would have survived the collapse and be brought to the piers, many decided to leave and the area was closed down.
Police.
The New York City Police Department quickly responded with the Emergency Service Units (ESU) and other responders after the crash of American Airlines Flight 11 into the North Tower. The NYPD set up its incident command center at Church Street and Vesey Street, on the opposite side of the World Trade Center from where the FDNY was commanding its operations. NYPD helicopters were soon at the scene, reporting on the status of the burning buildings. When the buildings collapsed, 23 NYPD officers were killed, along with 37 Port Authority police officers. The police department helped facilitate the evacuation of civilians out of Lower Manhattan, including approximately 5,000 civilians evacuated by the Harbor Unit to Staten Island and to New Jersey. In ensuing days, the NYPD worked alternating 12-hour shifts to help in the rescue and recovery efforts.
Coast Guard, maritime industry, individual boat owners.
Immediately after the first attack, the captains and crews of a large number of local boats steamed into the attack zone to assist in evacuation. These ships had responded by a request from the U.S. Coast Guard to help evacuate those stranded on Manhattan Island. Others, such as the "John J. Harvey", provided supplies and water, which became urgently needed after the Towers' collapse severed downtown water mains. Estimates of the number of people evacuated by water from Lower Manhattan that day in the eight-hour period following the attacks range from 500,000 to 1,000,000. Norman Mineta, Secretary of Transportation during the attacks, called the efforts "the largest maritime evacuation conducted in the United States." The evacuation was the largest maritime evacuation in history by most estimates, passing the nine-day evacuation of Dunkirk during World War II. As many as 2,000 people injured in the attacks were evacuated by this means.
Amateur radio.
Amateur radio played a role in the rescue and clean-up efforts. Amateur radio operators established communications, maintained emergency networks, and formed bucket brigades with hundreds of other volunteer personnel. Approximately 500 amateur radio operators volunteered their services during the disaster and recovery.
The New Jersey Legislature honored the role of Amateur Radio operators in a proclamation on December 12, 2002.
I would like to take this opportunity to commend you for your hard work and efforts," said Assembly Speaker Albio Sires. "During times of disaster, your group has displayed superior service and dedication to the safety of our citizens. I applaud the efforts of the independent radio operators and thank you for your selfless actions on September 12, 2001. Allow me to express my sincere gratitude for your participation with the New Jersey General Assembly on this day, December 12, 2002.
Note: "Government exhibits are from the trial of Zacarias Moussaoui"
Search and rescue efforts.
On the day following the attacks, 11 people were rescued from the rubble, including six firefighters and three police officers. One woman was rescued from the rubble, near where a West Side Highway pedestrian bridge had been. Two PAPD officers, John McLoughlin and Will Jimeno, were also rescued. Discovered by former U.S. Marines Jason Thomas and Dave Karnes, McLoughlin and Jimeno were pulled out alive after spending nearly 24 hours beneath 30 feet of rubble. Their rescue was later portrayed in the Oliver Stone film, "World Trade Center".
Some firefighters and civilians who survived made cell phone calls from voids beneath the rubble, though the amount of debris made it difficult for rescue workers to get to them.
By Wednesday night, 82 deaths had been confirmed by officials in New York City.
Rescue efforts were paused numerous times in the days after the attack, due to concerns that nearby buildings, including One Liberty Plaza, were in danger of collapsing.
Recovery efforts.
The search and rescue effort in the immediate aftermath at the World Trade Center site involved ironworkers, structural engineers, heavy machinery operators, asbestos workers, boilermakers, carpenters, cement masons, construction managers, electricians, insulation workers, machinists, plumbers and pipefitters, riggers, sheet metal workers, steelworkers, truckers and teamsters, American Red Cross volunteers, and many others.
Lower Manhattan, south of 14th Street, was off-limits, except for rescue and recovery workers. There were also about 400 working dogs, the largest deployment of dogs in the nation's history.
Organization.
New York City Office of Emergency Management was the agency responsible for coordination of the City's response to the attacks. Headed by then-Director Richard Sheirer, the agency was forced to vacate its headquarters, located in 7 World Trade Center, within hours of the attack. The building later collapsed due to fire. OEM reestablished operations temporarily at the police academy, where Mayor Giuliani gave many press conferences throughout the afternoon and evening of September 11. By Friday, rescue and reliefs were organized and administered from Pier 92 on the Hudson River.
Volunteers quickly descended on Ground Zero to help in the rescue and recovery efforts. At Jacob Javits Convention Center, thousands showed up to offer help, where they registered with authorities. Construction projects around the city came to a halt, as workers walked off the jobs to help at Ground Zero. Ironworkers, welders, steel burners, and others with such skills were in high demand. By the end of the first week, over one thousand ironworkers from across North America had arrived to help, along with countless others.
The New York City Department of Design & Construction oversaw the recovery efforts. Beginning on September 12, the Structural Engineers Association of New York (SEAoNY) became involved in the recovery efforts, bringing in experts to review the stability of the rubble, evaluate safety of hundreds of buildings near the site, and designing support for the cranes brought in to clear the debris. The City of New York hired the engineering firm, LZA-Thornton Tomasetti, to oversee the structural engineering operations at the site.
To make the effort more manageable, the World Trade Center site was divided into four quadrants or zones. Each zone was assigned a lead contractor, and a team of three structural engineers, subcontractors, and rescue workers.
The Federal Emergency Management Agency (FEMA), the United States Army Corps of Engineers, the Occupational Safety and Health Administration (OSHA), and the New York City Office of Emergency Management (OEM) provided support. Forestry incident management teams (IMTs) also provided support beginning in the days after the attacks to help manage operations.
A nearby Burger King restaurant was used as a center for police operations. Given that workers worked at the site, or "The Pile", for shifts as long as twelve hours, a specific culture developed at the site, leading to workers developing their own argot.
Debris removal.
"The Pile" was the term coined by the rescue workers to describe the tons of wreckage left from the collapse of the World Trade Center. They avoided the use of "ground zero", which describes the epicenter of a bomb explosion.
Numerous volunteers organized to form "bucket brigades", which passed 5-gallon buckets full of debris down a line to investigators, who sifted through the debris in search of evidence and human remains. Ironworkers helped cut up steel beams into more manageable sizes for removal. Much of the debris was hauled off to the Fresh Kills Landfill on Staten Island where it was searched and sorted.
Reuse of steel.
Some of the steel was reused for memorials. New York City firefighters donated a cross made of steel from the World Trade Center to the Shanksville Volunteer Fire Company. The beam, mounted atop a platform shaped like the Pentagon, was erected outside the Shanksville's firehouse near the crash site of United Airlines Flight 93.
Twenty-four tons of the steel used in construction of USS "New York" (LPD-21) came from the small amount of rubble from the World Trade Center preserved for posterity.
Hazards.
Hazards at the World Trade Center site included a diesel fuel tank buried seven stories below. Approximately 2,000 automobiles that had been in the parking garage also presented a risk, with each containing, on average, at least five gallons of gasoline. Once recovery workers reached down to the parking garage level, they found some cars that had exploded and burned. The United States Customs Service, which was housed in 6 World Trade Center, had 1.2 million rounds of ammunition and weapons in storage in a third-floor vault, to support their firing range.
Morale.
In the hours immediately after the attacks on the World Trade Center, three firefighters raised an American flag over the rubble. The flag was taken from a yacht, and the moment, which was captured on a well-known photograph, evoked comparisons to the iconic Iwo Jima photograph. Morale of rescue workers was boosted on September 14, 2001 when President George W. Bush paid a visit to Ground Zero. Standing with retired firefighter Bob Beckwith, Bush addressed the firefighters and rescue workers with a bullhorn and thanked them. Bush remarked, "I'm shocked at the size of the devastation, It's hard to describe what it's like to see the gnarled steel and broken glass and twisted buildings silhouetted against the smoke. I said that this was the first act of war on America in the 21st century, and I was right, particularly having seen the scene." After some workers shouted that they could not hear the President, Bush famously responded by saying "I can hear you! The rest of the world hears you. And the people who knocked these buildings down will hear all of us soon!"
At some point, rescue workers realized that they were not going to find any more survivors. After a couple of weeks, the conditions at Ground Zero remained harsh, with lingering odors of decaying human remains and smoke. Morale among workers was boosted by letters they received from children around the United States and the world, as well as support from thousands of neighbors in TriBeCa and other Lower Manhattan neighborhoods.
This support continued to spread and eventually led to the founding of over 250 non-profit organizations of which raised almost $700 million within their first two years of operation. The purpose behind founding these organizations was to ensure that morale continued to rise just as it had when the children wrote their letters. The founders knew that the firefighters leading the rescue efforts among the rubble were far from the only individuals that were feeling the despair of the situation. Citizens and families all over the United States were hurting and something needed to be done to honor the fallen while recognizing that funding and donations were going to be needed in order to begin the cleanup and rebuilding of the city.Jay Winukne, founder of the nonprofit MyGoodDeed,further explains what the founders experienced after establishment, "the amazing spirit of compassion and community service that grew out of 9/11 was so natural and evident immediately after the attacks." 
By 2012, many of the 250 plus organizations had disbanded due to lack of funding as the years progressed. Of the ones that remain, a handful stand proud knowing that they are still needed and therefore, are continuously working to ensure they can stay established for those who remain in need. One of these organizations, Tuesday’s Children, was founded the day after September 11 in hopes of supporting the children immediately affected by the attacks. The founder of this non-profit, David Weild IV, now calls them one of the “last men standing” in that they are now one of the few remaining organizations who “provide direct services for what social-service groups and survivors of the attacks call the ‘9-11 Community.’”
Other notable non-profits who are “still standing” include:
Military support.
Civil Air Patrol.
Immediately following the attacks, members of the Civil Air Patrol (CAP) were called up to help respond. Northeast Region Commander Colonel Richard Greenhut placed his region on alert mere moments after he learned of the attack. With the exception of CAP, civilian flights were grounded by the Federal Aviation Administration. CAP flew aerial reconnaissance missions over Ground Zero, to provide detailed analysis of the wreckage and to aide in recovery efforts, including transportation of blood donations.
National Guard.
Elements of the New York Army National Guard's 1-101st Cavalry (Staten Island), 258th Field Artillery, and 69th Infantry Regiment based in Manhattan were the first military force to secure Ground Zero on September 11th. The 69th Infantry's armory on Lexington Avenue became the Family Information Center to assist persons in locating missing family members.
The National Guard supplemented the NYPD and FDNY, with 2,250 guard members on the scene by the next morning. Eventually thousands of Soldiers and Airmen from the NY National Guard participated in the rescue/recovery efforts. They conducted site security at the WTC, and at other locations. They provided the NYPD with support for traffic control, and they participated directly in recovery operations providing manpower in the form of "bucket brigades" sorting through the debris by hand.
Additionally service members provided security at a variety of location throughout the city and New York State to deter further attacks and reassure the public.
Members of the Air National Guard's 109th Airlift Wing out of Scotia, and Syracuse's 174th Fighter Wing immediately responded to New York City, setting up camp at places such as Fort Hamilton. Mostly civil engineers, firefighters and military police, they greatly aided in the clean-up effort. F-16s from the 174th Fighter Wing also ramped up their flying sorties and patrolled the skies.
U.S. Marine Corps.
U.S. Marines were also present to assist in the rescue efforts. No official numbers of men who helped out was released but there was evidence that they were there.
Films such as 2006 docudrama "World Trade Center" talked of two Marines who rescued two trapped police officers in the rubble. US Marines were HQ at 340 Westside Hwy Bloomberg News Building. The Commanding Officer was Navy Commander Hardy, and Executive Officer was Maj Priester. These two oversaw 110 military personnel of various branches, various police departments and EMTs.
U.S. Navy.
U.S. Navy deployed a hospital ship USNS "Comfort" (T-AH-20) to Pier 92 in Manhattan. Crew members provided food and shelter for more than 10,000 relief workers. Comfort's 24-hour galley also provided an impressive 30,000 meals. Its medical resources were also used to provide first-aid and sick call services to nearly 600 people. The ship's psychological response team also saw more than 500 patients.
Handling of cleanup procedure.
A May 14, 2007, "New York Times" article, "Ground Zero Illness Clouding Giuliani's Legacy," gave the interpretation that thousands of workers at Ground Zero have become sick and that "many regard Mr. Giuliani's triumph of leadership as having come with a human cost." The article reported that the mayor seized control of the cleanup of Ground Zero, taking control away from established federal agencies, such as the Federal Emergency Management Agency, the U.S. Army Corps of Engineers and the Occupational Safety and Health Administration. He instead handed over responsibility to the "largely unknown" city Department of Design and Construction. Documents indicate that the Giuliani administration never enforced federal requirements requiring the wearing of respirators. Concurrently, the administration threatened companies with dismissal if cleanup work slowed.
Workers at the Ground Zero pit worked without proper respirators. They wore painters' masks or no facial covering. Specialists claim that the only effective protection against toxins, such as airborne asbestos, is a special respirator. New York Committee for Occupational Safety and Health industrial hygienist David Newman said, "I was down there watching people working without respirators." He continued, "Others took off their respirators to eat. It was a surreal, ridiculous, unacceptable situation."
The local EPA office sidelined the regional EPA office. Dr. Cate Jenkins, a whistle-blower EPA scientist, said that on September 12, 2001, a regional EPA office offered to dispatch 30 to 40 electron microscopes to the WTC pit to test bulk dust samples for the presence of asbestos fibers. Instead, the local office chose the less effective polarized light microscopy testing method. Dr. Jenkins alleged that the local office refused, and said, "We don't want you fucking cowboys here. The best thing they could do is reassign you to Alaska."
Health effects.
There were many health problems caused by the toxins. 99% of exposed firefighters reported at least one new respiratory problem while working at the trade center site that they had not experienced before. Chronic airway disease is the main lung injury among firefighters who were exposed to toxins during 9/11. Six years after the attacks, among those who never smoked, approximately 13% of firefighters and 22% of EMS had lungs that did not function as well as others around the same age. Steep declines in pulmonary lung function has been a problem since first detected among firefighters and EMS within a year of 9/11 have persisted. 
Increasing numbers of Ground Zero workers are getting illnesses, such as cancer. Between September 11, 2001 through 2008, there were 263 new cases of cancer found in 8,927 male firefighters who responded to 9/11 attacks. This number is 25 more than what is expected from men from a similar age group and race. There is a 19% increase in cancer overall, between firefighters who responded to the attacks and those who were not exposed to toxins from responding to the attacks on September 11.
On January 30, 2007, Ground Zero workers and groups such as Sierra Club and Unsung Heroes Helping Heroes met at the Ground Zero site and urged President George Bush to spend more money on aid for sick Ground Zero workers. They said that the $25 million that Bush promised for the ill workers was inadequate. A Long Island iron-worker, John Sferazo, at the protest rally said, "Why has it taken you 5½ years to meet with us, Mr. President?"
Firefighters, police and their unions, have criticized Mayor Rudy Giuliani over the issue of protective equipment and illnesses after the attacks. An October study by the National Institute of Environmental Safety and Health said that cleanup workers lacked adequate protective gear. The Executive Director of the National Fraternal Order of Police reportedly said of Giuliani: "Everybody likes a Churchillian kind of leader who jumps up when the ashes are still falling and takes over. But two or three good days don't expunge an eight-year record." Sally Regenhard, said, "There's a large and growing number of both FDNY families, FDNY members, former and current, and civilian families who want to expose the true failures of the Giuliani administration when it comes to 9/11." She told the "New York Daily News" that she intends to "Swift Boat" Giuliani.
Various health programs arose after the attacks to provide treatment for 9/11-related illnesses among responders, recovery workers, and other survivors. When the James Zadroga 9/11 Health and Compensation Act became federal law in January 2011, these programs were replaced by the World Trade Center Health Program.
Investigations.
Soon after the attacks, New York City commissioned McKinsey & Company to investigate the response of both the New York City Fire Department and New York City Police Department and make recommendations on how to respond more effectively to such large-scale emergencies in the future.
Officials with the International Association of Fire Fighters have also criticized Rudy Giuliani for failing to support modernized radios that might have spared the lives of more firefighters. Some firefighters never heard the evacuation orders and died in the collapse of the towers.
Estimated costs.
Estimated total costs, as of October 3, 2001
Reconstruction.
Plans for the World Trade Center rebuilding started in July 2002 which was headed by the Lower Manhattan Development Corporation. There was many proposals on how to build the World Trade Center back however many lacked creativity. Several architects were chosen throughout this construction process all of them ran into many problems with the design. Then there was a financial crisis in 2008 which forced the construction process over to the Port Authority. The Port Authority construction is not going as smoothly as planned. However, the construction of the buildings is currently active round the clock with only days off for bad weather. City officials are looking for better ways to lower the problems and delays. The World Trade Center completion of construction has been scheduled for 2016.
References.
Notes
Bibliography
External links.
NY Times:
Other:

</doc>
<doc id="28070" url="http://en.wikipedia.org/wiki?curid=28070" title="Communication during the September 11 attacks">
Communication during the September 11 attacks

Communication problems and successes played an important role in the September 11, 2001 attacks and their aftermath. Systems were variously destroyed or overwhelmed by loads greater than they were designed to carry, or failed to operate as intended or desired.
Attackers.
The organizers of the September 11, 2001 attacks apparently planned and coordinated their mission in face to face meetings and used little or no electronic communication. This "radio silence" made their plan more difficult to detect.
Federal government.
According to 9/11 Commission staff statement No. 17 there were several communications failures at the federal government level during and after the 9/11 attacks. Perhaps the most serious occurred in an "Air Threat Conference Call" initiated by the National Military Command Center (NMCC) after two planes had crashed into the World Trade Center, but shortly before The Pentagon was hit. The participants were unable to include the Federal Aviation Administration (FAA) air traffic control command center, which had the most information about the hijackings, in the call.
According to the staff report: 
First responders.
After the 1993 World Trade Center bombing, radio repeaters for New York City Fire Department communication were installed in the tower complex. Because they were unaware that several controls needed to be operated to fully activate the repeater system, fire chiefs at their command post in the lobby of the North Tower thought the repeater was not functioning and did not use it, though it did work and was used by some firefighters. When police officials concluded the twin towers were in danger of collapsing and ordered police to leave the complex, fire officials were not notified . Fire officials on the scene were not monitoring broadcast news reports and did not immediately understand what had happened when the first (South) tower did collapse .
There was little communication between New York City Police Department and fire department commands even though an Office of Emergency Management (OEM) had been created in 1996 in part to provide such coordination . A primary reason for OEM's inability to coordinate communications and information-sharing in the early hours of the WTC response was the loss of its emergency operations center, located on the twenty third floor of 7 World Trade Center which had been evacuated after debris from tower's collapse struck the building, igniting several fires .
Emergency relief efforts in both Lower Manhattan and at the Pentagon were augmented by volunteer amateur radio operators in the weeks after the attacks.
Victims.
Cell phones and in-plane credit card phones played a major role during and after the attack, starting with hijacked passengers who called family or notified the authorities about what was happening. Passengers and crew who made calls include: Sandra Bradshaw, Todd Beamer, Tom Burnett, Mark Bingham, Peter Hanson, Jeremy Glick, Barbara K. Olson, Renee May, Madeline Amy Sweeney, Betty Ong, Robert Fangman, Brian David Sweeney, and Ed Felt. Innocent occupants aboard United Airlines Flight 93 were able to assess their situation based on these conversations and plan a revolt that resulted in the aircraft crashing. According to the commission staff: "Their actions saved the lives of countless others, and may have saved either the U.S. Capitol or the White House from destruction."
According to the 9/11 Commission Report, 13 passengers from Flight 93 made a total of over 30 calls to both family and emergency personnel (twenty-two confirmed air phone calls, two confirmed cell phone and eight not specified in the report). Brenda Raney, Verizon Wireless spokesperson, said that Flight 93 was supported by several cell sites. There were reportedly three phone calls from Flight 11, five from Flight 175, and three calls from Flight 77. Two calls from these flights were recorded, placed by flight attendants: Betty Ong on Flight 11 and CeeCee Lyles on Flight 93 
Alexa Graf, an AT&T spokesperson, said it was almost a fluke
that the calls reached their destinations. Marvin Sirbu, professor of Engineering and Public Policy at Carnegie Mellon University said on September 14, 2001, that "The fact of the matter is that cell phones can work in almost all phases of a commercial flight." Other industry experts said that it is possible to use cell phones with varying degrees of success during the ascent and descent of commercial airline flights.
After each of the hijacked aircraft struck the World Trade Center, people inside the towers made calls to family and loved ones; for the victims, this was their last communication. Other callers directed their pleas for help to 9-1-1. Over nine hours of the 9-1-1 calls were eventually released after petitioning by The "New York Times" and families of the WTC victims. In 2001, many cell phones did not yet have texting or photography capabilities that came by the mid-2000s.
General public.
After the attack, the cell phone network of New York City was rapidly overloaded (a mass call event) as traffic doubled over normal levels. Cell phone traffic also overloaded across the East Coast, leading to crashes of the cell phone network. Verizon's downtown wire phone service was interrupted for days and weeks due to cut subscriber cables, and to the 140 West Street exchange being shut for days. Capacity between Brooklyn and Manhattan was also diminished by cut trunk cables.
Following the attacks, the issues with the cell network weren't resolved until 36 cellular COWs (cell towers on wheels) were deployed by September 14, 2001, in Lower Manhattan to support the U.S. Federal Emergency Management Agency (FEMA) and provide critical phone service to rescue and recovery workers.
Since three of the major television broadcast network owned-and-operated stations had their transmission towers atop the North Tower (One World Trade Center), coverage was limited after the collapse of the tower. The FM transmitter of National Public Radio station WNYC was also destroyed in the collapse of the North Tower and its offices evacuated. For an interim period, it continued broadcasting on its AM frequency and used NPR's New York offices to produce its programming.
The satellite feed of one television station, WPIX, froze on the last image received from the WTC mast; the image (a remote-camera shot of the burning towers), viewable across North America (as WPIX is available on cable TV in many areas), remained on the screen for much of the day until WPIX was able to set up alternate transmission facilities. It shows the WTC at the moment power cut off to the WPIX transmitter, prior to the towers' collapse.
During the September 11 attacks, WCBS-TV channel 2 and WXTV-TV channel 41 stayed on the air. Unlike most other major New York television stations, WCBS-TV maintained a full-powered backup transmitter at the Empire State Building after moving its main transmitter to the North Tower of the World Trade Center. The station was also simulcasted nationally on Viacom (which at the time owned CBS) cable network VH1 that day. In the immediate aftermath of the attacks, the station lent transmission time to the other stations who had lost their transmitters, until they found suitable backup equipment and locations.
The Emergency Alert System was never activated in the terrorist attacks, as the extensive media coverage made it unnecessary.
AT&T eliminated any costs for domestic calls originating from the New York City area (phones using area codes 212/718/917/646/347) in the days following 9/11.
Radio communications.
Radio communications during the September 11 attacks served a vital role in coordinating rescue efforts by New York Police Department, New York Fire Department, Port Authority Police Department, and Emergency Medical Services.
While radio communications were modified to address problems discovered after the 1993 World Trade Center bombing, investigations into the radio communications during the September 11th attacks discovered that communication systems and protocols that distinguished each department was hampered by the lack of interoperability, damaged or failed network infrastructure during the attack, and overwhelmed by simultaneous communication between superiors and subordinates.
Background.
A rough time line of the incident could include:
The scale of the incident was described in the National Commission report on the attacks as "unprecedented". In roughly fifteen minutes from 8:46 to 9:03 am, over a thousand police, fire, and emergency medical services (EMS) staff arrived at the scene. At some point during a large incident, any agency will reach a point where they find their resources overrun by needs. For example, the Port Authority Police could not schedule staff as if a September 11 attack would occur every shift. There is always a balance struck between readiness and costs. There is conflicting data but some sources suggest there may have been 2,000 to 3,000 workers involved in the rescue operation. It would be rare for most agencies to see an event where there were that many people to be rescued.
There is some level of confusion present in any large incident. The National Institute for Standards and Technology (NIST) asserts commanders did not have adequate information and interagency information sharing was inadequate. For example, on September 11, persons in the New York City Police Department (NYPD) 9-1-1 center told callers from the World Trade Center to remain in place and wait for instruction from firefighters and police officers. This was the plan for managing a fire incident in the building and the 9-1-1 center staff were following the plan. This was partly countered by public safety workers going floor-by-floor and telling people to evacuate. The Commission report suggests people in the NYPD 9-1-1 center and New York City Fire Department (FDNY) dispatch would benefit from better situation awareness. The Commission described the call centers as not "fully integrated" with line personnel at the WTC. The report suggests the NYPD 9-1-1 center and FDNY dispatch were overrun by call volumes that had never been seen before. Adding to the confusion, radio coverage problems, radio traffic blocking, and building system problems occurred inside the burning towers. The facts show that much of the equipment worked as designed and users made the best of what was available to them.
Typical of any large fire, many 9-1-1 calls with conflicting information were received beginning at 8:46 am. In addition to reports that a plane had hit the World Trade Center, the EMS computer-aided dispatch (CAD) log shows reports of a helicopter crash, explosions, and a building fire. Throughout the incident, people at different locations had very different views of the situation. After the collapse of the first tower, many firefighters in the remaining tower had no idea the first tower had fallen.
A factor in radio communications problems included the fact that off-duty personnel self-dispatched to the incident scene. Some off-duty staff went into the towers without radios. According to the Commission report and news coverage, this was true of NYPD, Port Authority Police Department (PAPD), and FDNY personnel. Regardless of any radio coverage problems, these persons could not be commanded or informed by radio. In any incident of this scale, self-dispatched staff without radios would likely be a problem. Even if a cache of radios were brought to the scene to hand out, the scale of this incident would be likely to overrun the number of radios in the cache.
NIST concluded, at the beginning of the incident, there was an approximate factor of five (peak) increase in radio communications traffic over a normal level. After the initial peak, radio traffic through the incident followed an approximate factor of three steady increase. FDNY recordings suggest the dispatch personnel were overloaded: both fire and EMS dispatch were often delayed in responding to radio calls. Many 9-1-1 telephone calls to dispatch were disconnected or routed to "all circuits are busy now," intercept recordings.
Voice radio systems.
NIST calculated that about one third of radio messages transmitted during the surge of communications were incomplete or unintelligible. Documentary footage suggests the tactical channels were also overloaded; some footage captured audio of two or three conversations occurring simultaneously on a particular channel.
In this study of WTC incident communications, radio systems used at the site had problems but were generally effective in that users were able to communicate with one another. A 2002 video documentary "9/11" by Gedeon and Jules Naudet, (referred to as "the documentary") was reviewed. It captured audio from hand-held radios in use at the incident and showed users communicating over radios from the lobby command post in the North Tower. 26 Red Book audio CDs of New York City Fire Department radio transmissions, covering the incident's initial dispatch and the tower failures, were reviewed. These CDs were digitized versions of audio from the Fire Department's logging recorders. In addition, text on an oral history CD with transcripts of fire personnel debriefed on the incident were reviewed.
NYPD and PAPD systems in 2001.
In 2001, the NYPD used Ultra High Frequency (UHF) radios and divided the city into 35 radio zones. Most hand-held radios had at least 20 channels: while not all officers had all channels, all officers had the ability to communicate citywide. As a characteristic of physics, UHF signals penetrate buildings better than lower Very High Frequency (VHF) frequencies used by the FDNY fire units but generally cover shorter distances over open terrain. The Commission report did not cite any technical flaws with the NYPD radio system.
PAPD has systems described as "low-power UHF". The Commission report says the systems were specific to a single site with the exception of one channel which was Port-Authority-wide. It's unclear whether the PAPD systems were interstitial and limited to 2 watts output, used normal local-control channels but were limited in power output by the frequency coordinator, or used leaky cable systems which were solely intended to work inside the Port Authority buildings. The report says there were 7, site-specific Port Authority Police channels. In 2001, officers at one site could not, (in all cases), carry their radios to another site and use them. Not all radios had all channels.
Fire and EMS dispatch channels.
Recordings of Citywide, Brooklyn, and Manhattan channels for Fire and Citywide, Brooklyn, and Manhattan channels for Emergency medical services were reviewed. Systems generally performed well. The audio coupling point for the logging recorder on Manhattan Fire made the dispatcher's voice difficult to hear. An anonymous fire dispatcher who identifies as "Dispatcher 416" is noteworthy.
The Commission report says that, in 2001, FDNY used a system with 5 repeater channels: one for each of the boroughs of Manhattan, Brooklyn, Queens, with the Bronx and Staten Island sharing a single frequency using different Private Line (PL) tones, and a city-wide channel. There were also five simplex channels in FDNY radios.
Observation shows, back in 2001, that the citywide EMS channel was voting more frequently than normal, signals were noisy, interfering signals were present, and that some receiver sites had equalization differences. Some transmissions had choppy audio possibly representative of interference from FSK paging or intermittent microwave radio paths to one or more receiver sites. For example, if a microwave radio path fails for half-second intervals, the voting comparator may vote out that receiver site until silence is detected. This can cause dropped syllables in the voted audio. Some transmissions were noisy, although transactions show the dispatcher was understanding radio traffic in spite of audio drop-outs in almost every case.
Port Authority fire repeater system (Repeater 7).
The Port Authority repeater, intended to allow communications inside the towers, did not appear to work as intended on September 11. The system, also called "Port Authority Channel 30", was installed after the 1993 World Trade Center attack. News accounts said the system had been turned off for unspecified technical reasons. The Commission report said it was customary to turn the system off because it somehow caused interference to radios in use at fire operations in other parts of the city. The documentary film gives different information, with a Fire Department member from Engine 7/Ladder 1 claiming that the aircraft's impact caused the system to fail. Evidence suggests the remote control console in the lobby command was not working but the repeater was. The radio repeater was located in 5 World Trade Center. A remote control console was connected to the repeater allowing staff at the North Tower lobby command post to communicate without using a hand-held radio.
In a review of the logging recorder track of the Port Authority repeater, someone arrived early during the incident and began to establish a command post. From the command post in the lobby of the North Tower (1 World Trade Center), the user can be heard trying to transmit using a remote control unit. After several failed attempts to communicate with a user on the channel, the user steps through every channel selection on the remote, trying each one. The recording contains the tone remote control console stepping through all of its eight function tones. Someone says, "...the wireline isn't working," over the Port Authority channel. Something that looks like a Motorola T-1380-series remote is shown in the documentary. The fact that users pressing buttons on the remote control can clearly be heard on the logging recorder shows the transmit audio path was working. The recording does not reveal whether or not the console function tones were keying the transmitter.
Some users in the North Tower lobby interpreted the remote control unit not working as a failure of the entire channel. Other fire units, not knowing the channel had failed, arrived and began using it successfully. The recordings show at least some units were successfully using the repeater to communicate inside the South Tower until the moment it collapsed. The Commission report says the North Tower lobby command may not have worked because of a technical problem, the volume control turned all the way down, or because a button that must be pressed to enable it had not been pushed.
On the audio track, an outside agency, possibly in New Jersey and using a repeater, comes through the receive audio on the Port Authority Repeater 7 system. An ambulance being dispatched by the outside (non-FDNY) agency is heard. This may be what the FDNY had described as interference caused when the repeater was left enabled at all times. The distant user appears to be repeated through the system, (possibly on the same CTCSS tone as was configured in Repeater 7). This appears to be a distant co-channel user on the same input frequency as Repeater 7. It's possible that by the random button pressing, a user sent a function tone that temporarily put the base station in "monitor" and that's what caused the outside agency's traffic to be heard. This is unlikely because subsequent transmit function tones should have toggled the receiver from monitor back to CTCSS-enabled.
Fire Department system.
An oral history interview revealed the Port Authority UHF radios were normally used at incidents inside the World Trade Center. The interviewee said in normal, day-to-day calls, the WTC staff handed Port Authority UHF radios to firefighters on their arrival and that these radios, "worked all over." This implies, but does not prove, that it was common knowledge among department members that FDNY radios had coverage problems inside the buildings. The 9-11 Commission uses the phrase, "performed poorly" to describe FDNY radios during the incident.
Oral history files show that at least four channels were employed at WTC:
One officer said a channel named "Command 3" was used for the North Tower. To those unfamiliar with the details of the FDNY system, it is unclear whether the interviewee meant Tactical 3 or a fifth channel.
FDNY personnel are seen using radios during the documentary footage of the WTC lobby area. Analysis of these scenes showed the radios all appeared to be receiving properly. Oral history files confirm radio communications were at least partly functional.
A problem that shows up in these types of incidents is that receivers in hand-held radios are subjected to signal levels that are likely to overload the receiver. Several radios may be transmitting within feet of one another on different channels. If overloading occurs, only very strong signals can be received while weaker signals disappear and are not received. The hand held radio receivers shown in the documentary appeared to work properly even though several other hand-held radios were transmitting only feet away. This is a hostile environment and suggests the hand-held equipment used by FDNY had good quality receivers, though in this case, the suggestion is incorrect. Second-hand observation is hardly the proper way to 'test' radio receivers or to distinguish 'good quality' from 'bad' and this is likely a source of continued misunderstanding; particularly when these same radios were operating at higher floors, in closer proximity to, and in direct line-of-sight of digital cellular repeaters. Those repeaters were likely operating at unlicensed power levels, which was a common practice of cellular providers at the time, and continues to this day. Footage reveals intelligible recovered audio coming out of the radios and shows radio users communicating with others. This may not have been true of the entire WTC complex but was true of radio users in the crowded lobby.
Analysis of the 26 FDNY audio CDs showed the radios seemed to transmit into the radio systems okay. Radios calling dispatch got through. Calling units were intelligible. Users spoke with dispatchers. Dispatchers answered in ways that suggest they understood what was said. There were no noisy or truncated transmissions heard on any channel, (the equivalent of a dropped cellular call). This suggests the Fire Department's radio backbone is soundly designed and working properly. It is possible that system coverage problems are present; problems that could have been mitigated had the Command Post radio (with greater transmit power) been used. It is also likely that some transmissions did not reach any of the receivers in the system and therefore would not be a detectable problem when listening to the recordings. At the same time those recordings were made, the cellular system was operating at or near full-capacity, meaning every cellular repeater was transmitting. The dense RF interference environment created in NYC that day was essentially a 'perfect storm'; one in which a radio designed 25 years prior could not possibly contend with.
In some scenes, captured documentary audio showed the channels were busy. In some cases, two or more conversations were taking place over a single radio channel at the same time. Users on Tactical 1 may have been close enough to one another to communicate because signals in proximity to each other would overpower weaker signals. At any incident of this size, there is likely to be some overlapping radio traffic. In the same way that large incidents exhaust all the firefighting vehicles and staff, the radio channel resources may become taxed to their limits. NIST says about one third of the fire department radio transmissions were not complete or not understandable.
Some radio users had selected the wrong channels. For example, on the Repeater 7 channel, a unit was heard to call "Manhattan" dispatch and "Citywide". Although the circumstances that lead to the user selecting the wrong channel are not known, this can occur when the user is trapped in darkness or smoke and cannot see the radio. Users will typically try to count steps in a rotary switch channel selector starting from one end of the switch's travel.
A communications van operated by FDNY responded to the incident. Its radio identifier was, "Field Comm." A backup van was in use on the day of the incident because the primary van was out-of-service. The backup van was destroyed and audio recordings of tactical channels used at the incident site were lost.
FDNY radio programming.
One annoyance with the fire systems was the presence of "unit ID" data bursts. These constant squawks, heard at the end of transmissions, are decoded at dispatch to identify the calling radio. The annoyance of the data bursts is a trade-off that could help find a firefighter who has been injured or needs help. It also automatically displays the unit ID at the dispatch console. In most systems, it also saves dispatch personnel from typing the unit ID. They press one key and the calling unit's ID is inserted into the current CAD screen or command line.
Recordings show radios were programmed to send unit ID on tactical channels. Radios accept unit ID on a per-channel basis. When mobile or hand-held radios are programmed, the unit ID encoders should be disabled on all channels where the feature is not used. This saves air time for about two to three syllables of speech per push-to-talk press. For example, unless the communications van or chief's vehicles had push-to-talk unit ID decoders, or the channels were recorded for later analysis where unit IDs were decoded from the recordings, the encoders should be turned off for tactical channels to reduce air time used.
It also sounded like some vehicle radios may have had "status buttons" using the data bursts. If true, the operator presses a button on the vehicle radio which sends a short data burst to dispatch. Dispatch gets the unit identity and the new status from a data decoder. These can cause interruptions in voice traffic but cut down on total air time required to conduct business because they occupy the channel for less time than it takes to say, "Engine fifty on scene."
Tactical 1.
This channel was the primary method of communication in the North tower. It was a simplex channel. Users complained it would only reach from the lobby to floors in the thirties. Tactical 1 was a default channel for use at some fire scenes. Some users who realized Repeater 7 was functional switched to that channel and were afforded better coverage than simplex users on Tactical 1. Audio recordings on the documentary film and NIST analysis show Tactical 1 was overloaded with heavy radio traffic. In contrast, the audio CD of Repeater 7 shows the channel was mostly idle.
The 9-11 commission report said a new portable repeater system had been developed to address shortcomings of Tactical 1 at a large incident. The system, called, "the post," is carried to an area near the incident and set up for the duration to augment weak signals.
Command channel.
The command channel used by officers at the incident was either called "Channel 5" or "Command 5" in documentation. Documents suggest the channel had a repeater but it was not clear if the repeater was citywide, installed in the Field Comm van, or housed in a battalion chief's vehicle. Recordings of this channel were lost when the Field Comm van was destroyed. The documentary film and oral history records show the channel being used effectively.
Interoperability.
The federal 9/11 Commission Report included recommendations on communications systems used by police, fire, and emergency medical services (EMS) at the WTC incident. In the report and in appearances on television news programs, commissioners said the capabilities of communications systems lacked the ability to communicate across department lines. That is to say, police units could not communicate with fire units directly by radio. Ambulances could not talk with police units directly by radio. Commission member Lee Hamilton, in several television appearances related to a 2006 book on the topic of the WTC incident, reiterated this factually-correct view.
Aviation assets.
An example that was cited by Hamilton: during the incident the Police Department helicopter was unable to communicate with Fire Department units in order to warn them of the towers' imminent collapse. The NIST document suggests the helicopter may have been able to offer several minutes warning. "Several minutes" may have been enough to get some people from the lower floors outside. This warning of imminent collapse went out over at least one police radio channel but there is nothing showing it was relayed to other people or channels. FDNY operates at least two communications vans: one of which was brought to the scene at the WTC incident. The Commission report reveals the primary FDNY van was equipped to talk to NYPD helicopters but the backup van, (which had no NYPD helicopter capability,) was in use on September 11, 2001.
In practice, many US helicopters used in emergency services are equipped with radios that allow communications on nearly any conventional two-way radio system, so long as the aircrew know the frequency and associated signaling tones. The radios usually have presets, like a car's broadcast radio, that allow some channels to be configured ahead of need. There was no information in the Commission report suggesting NYPD helicopters had such a capability.
Cross-department.
While it is technically possible to implement communications across departments, doing so introduces a host of new training and incident command problems. These are problems that would need to be managed in addition to the existing set of issues present at any large incident. The ability to maintain command, and monitor the safety of, groups working at an incident is diminished if a group of firefighters cannot be reached because they've switched over to the EMS channel. This could cause people to be sent to rescue them when there was no need. Similarly, if the Manhattan EMS dispatcher can't reach an ambulance because they are on one of the fire channels, patient care is affected. New York City Police Commissioner Raymond Kelly, appearing on the "Charlie Rose" show, expressed his view that the existing radio systems performed satisfactorily during the WTC incident. In his view, the interoperability desired by the 9-11 Commission was not needed.
Need for NYPD/FDNY cross-department links?
These problems are not new to the World Trade Center incident; cross-department and cross-discipline communication has been a hotly contested and long-identified issue. For example, at the Oklahoma City federal building bombing incident, the inability to communicate among departments was also cited as a problem. Firefighters heard an evacuation order on their radio channel because of the reported presence of a second bomb. Police and EMS workers reportedly did not know of the order.
In Hurricane Katrina's wake, a sergeant in the Louisiana Department of Wildlife and Fisheries appeared on national television to describe not being able to reach persons from other agencies who were assisting with the recovery. She described seeing the people in a nearby boat but not being able to communicate with them.
Even if the technical problems are solved, the issue is more complicated than just adding radio channels or talk groups. It is also a cultural problem. In one local incident, a large number of officers from three police agencies were fielded to search for a violent criminal who had evaded officers from one of the agencies. The officers did not coordinate by switching to a shared radio channel. After the incident, one participant said the users thought their radios were incompatible and did not understand how the shared channel worked. This possibly reflects a training problem or a technology literacy problem. The problem seems to have been remedied since then.
In another instance, a fire agency had thoroughly trained for interoperability scenarios. During an incident where two agencies with different radio channels responded, a decision-maker said personnel from his agency would stay on their own channel. Decision-makers may occasionally act in unpredictable ways, even if technology literate and well-trained. It's the Rumsfeldian concept that democracy is sometimes messy. It is not solely a technical problem, but an operational problem as well. Changes to ICS command structure, or operational changes in how the command post for an incident is set up, may produce better results than buying equipment or adding channels. Sometimes there are interoperability problems even where a structure for interoperability exists.
ICS: part of the solution?
One view of the Incident Command System is that units across department lines would communicate with their own representative at the command post or division level. That representative would relay any needs to another department. For example, a fire unit requesting five paramedic ambulances would identify the magnitude of a medical problem to their fire officer at the command post. This request would add to their commander's operational picture of the division or incident command as she called EMS to request the ambulances. Situation awareness is an important part of effective command and is easy to lose at a large incident. Bypassing incident commanders can contribute to a decomposing of command.
Trunked systems, commercial services, and cross-department netting.
One approach to cross-department netting is the capability of some modern trunked systems to provide a function called "dynamic regrouping"; a feature that Motorola doesn't support in simplex (e.g. 'fireground') operations. It is therefore necessary for a disaster to be near enough the infrastructure to allow for repeater access/operation. Many agencies with Motorola trunked systems already have this capability but it's hardly ever used; even in a crisis. The difficulty of operating such a system is often too great for poorly educated dispatchers who often have no college - much less any particular training in computers or communications systems - other than the 'cursory' training they receive in a 3 or 5 day class the vendors offer. The feature allows the dispatch center personnel to send units from different agencies who are responding to the same incident to a common talk group or virtual channel. This assumes the agencies all share a capability to operate over the same trunked radio system, which is rare. In an informal survey of three agencies with trunked systems that included this feature, users at two sites reported they did not think their system included the feature. A representative from a third site said he "...thought they had the feature but never used it." Of the three agencies with the feature, no one knew how to use it. This would suggest, (in at least the three agencies contacted,) that "dynamic regrouping" was not valuable. Like other disaster readiness processes, users would have to practice using the feature in order for it to be useful during an incident.
Some agencies use commercial two-way radio as an adjunct to their own communications networks. One professional engineering evaluation of public safety radio systems explains that commercial systems such as Nextel's are not built to the same standards of coverage and non-blocking as public safety trunked systems. Like toy walkie talkies marketed to children, they are usable and helpful for non-urgent communications but should not be considered reliable enough for life safety uses. It is also true that most trunked radio system users are likely to hear busy signals, (error tones showing no channels are available,) for the first time during a large disaster. All systems have a finite capacity.
"We don't want or need trunking" is what Chief Charles Dowd (NYPD) was heard to say at an APCO convention in Orlando (2006). NYPD operates a large, conventional repeater network with many legacy channels in the UHF band; and a technology developed "so a large number of users can share a small number of channels" (e.g. trunking) is clearly unnecessary and a frivolous waste of money.
With sufficient channels, there is no need for trunking. There are no 'busy' tones in a conventional repeater system. In the event an individual needs to chime in, he simply waits his turn - just as he would do in a trunked system.
Mobile data terminals.
All 911 ambulances and other FDNY vehicles have data terminals, sometimes referred to by staff in recordings and transcripts as MDTs. These terminals are connected to the computer-aided dispatch (CAD) back end or server. They can display text, page through screens describing jobs, and display lists of units assigned to a job.
A thorough analysis of data communications is not possible. What recordings show is that data terminals in at least some field units did not work properly during at least a portion of the incident. At 09:11:14, "Division 3" told Manhattan Fire dispatch, referring to the "summary" screen, "Summary is only giving me a few units. You're going to have to give it to me over the radio. I'm ready to write." This means the terminal was not displaying the entire list of units assigned to Division 3, as it would under normal conditions. The work-around: the Chief had to hand-write the list of units responding. In this one instance, the dispatcher reading the list of about 29 units tied up the Manhattan Fire channel for 53 seconds. During the reading of the list of units responding, one can hear several FDNY units try to interrupt the dispatcher. Their radio traffic was delayed until the entire list was read. This need to read lists of units because of slow or inoperable terminals occurred in at least three or four cases.
It's unclear what caused data delays and incomplete screens on the mobile data terminals. Evidenced by the dispatcher reading the list of units assigned to Division 3, the CAD system was working properly at dispatch positions. At least some field units experienced problems. Possible causes of problems with data terminals in vehicles may have included:
Data terminals are partly purchased and installed to reduce load on dispatch staff and to reduce traffic on voice channels. When they work properly, they have a significant operational benefit. A data outage during an occurrence of high call traffic can quickly overrun dispatch and voice channel capacity in cases where a routine level of calls for service requires both data terminals and voice channels.
New York City Council investigation.
New York City Council member Eric Gioia introduced a measure to have the Council investigate the issue of FDNY radio problems.

</doc>
<doc id="28080" url="http://en.wikipedia.org/wiki?curid=28080" title="Slogans and terms derived from the September 11 attacks">
Slogans and terms derived from the September 11 attacks

The September 11, 2001 attacks on the United States spawned a number of catchphrases, terms, and slogans, many of which continue to be used more than a decade after the event.
Media slogans.
Various slogans and captions were employed by media outlets to brand coverage of the September 11th terrorist attack, its after effects, and the U.S. government response. The slogans for American media were typically positioned on the bottom third of television broadcasts, or as banners across the top of newspaper pages. Designs typically incorporated a patriotic red, white, and blue motif, along with an explicit graphic of the American flag. Examples include:

</doc>
<doc id="28082" url="http://en.wikipedia.org/wiki?curid=28082" title="Timeline for October following the September 11 attacks">
Timeline for October following the September 11 attacks

This article summarizes the events in October 2001 that were related to the September 11 attacks. All times, except where otherwise noted, are in Eastern Daylight Time (EDT), or .

</doc>
<doc id="28113" url="http://en.wikipedia.org/wiki?curid=28113" title="Timeline for September following the September 11 attacks">
Timeline for September following the September 11 attacks

This article summarizes the events in the remaining days of September 2001 following the September 11 attacks which relate to the attacks. All times, except where otherwise noted, are in Eastern Daylight Time (EDT), or .
September 2001.
Friday, September 14.
The National Day of Prayer and Remembrance

</doc>
<doc id="28117" url="http://en.wikipedia.org/wiki?curid=28117" title="SAC">
SAC

SAC or Sac may refer to:

</doc>
<doc id="28118" url="http://en.wikipedia.org/wiki?curid=28118" title="Strategic Air Command">
Strategic Air Command

Strategic Air Command (SAC) was both a Department of Defense Specified Command and a United States Air Force (USAF) Major Command (MAJCOM) responsible for Cold War command and control of two of the three components of the U.S. military's strategic nuclear strike forces, the so-called "Nuclear Triad," with SAC having control of land-based strategic bomber aircraft and intercontinental ballistic missiles (ICBMs). SAC also operated all USAF jet aerial refueling, strategic reconnaissance aircraft, and airborne command post aircraft.
SAC primarily consisted of the Second Air Force (2AF), Eighth Air Force (8AF) and the Fifteenth Air Force (15AF), while SAC headquarters (HQ SAC) included Directorates for Operations & Plans, Intelligence, Command & Control, Maintenance, Training, Communications, and Personnel. At a lower echelon, headquarters divisions included Aircraft Engineering, Missile Concept, and Strategic Communications.
In 1992, as part of an overall post-Cold War reorganization of the U.S. Air Force, SAC was disestablished as both a Specified Command and as a MAJCOM, and its and equipment redistributed among the Air Combat Command (ACC), Air Mobility Command (AMC), Pacific Air Forces (PACAF), United States Air Forces in Europe (USAFE), and Air Education and Training Command (AETC), while SAC's central headquarters complex at Offutt AFB, Nebraska was concurrently transferred to the newly created United States Strategic Command (USSTRATCOM), which was established as a joint Unified Combatant Command.
Background.
The Strategic Air Forces of the United States during World War II included General Carl Spaatz's European command, United States Strategic Air Forces in Europe (USSTAF), consisting of the 8AF and 15AF, and the United States Strategic Air Forces in the Pacific (USASTAF) and its Twentieth Air Force (20AF).
 The U.S. Army Air Forces' first mission in the Strategic Bombing Campaign in the European Theater during World War II included the VIII Bomber Command, which conducted the first European "heavy bomber" attack by the USAAF on 17 August 1942); the Ninth Air Force, which conducted the first Operation Crossbow "No-Ball" missions on 5 December 1943; the Twelfth Air Force; and the Fifteenth Air Force, which executed bombing operations on 2 November 1943 during Operation Pointblank.
The Operation Overlord air plan for the strategic bombing of both Germany and German military forces in continental Europe prior to the 1944 invasion of France used several Air Forces, primarily those of the USAAF and those of the Royal Air Force (RAF), with command of air operations transferring to the Supreme Commander of the Allied Expeditionary Force on 14 April 1944.
Planning to reorganize for a separate and independent postwar U.S. Air Force had begun by the fall of 1945, with the Simpson Board tasked to plan, "...the reorganization of the Army and the Air Force...". In January 1946, Generals Eisenhower and Spaatz agreed on an Air Force organization [composed of] the Strategic Air Command, the Air Defense Command, the Tactical Air Command, the Air Transport Command and the supporting Air Technical Service Command, Air Training Command, the Air University, and the Air Force Center.
Establishment and Transfer to USAF.
Strategic Air Command was originally established in the U.S. Army Air Forces on 21 March 1946, acquiring part of the personnel and facilities of the Continental Air Forces (CAF), the World War II command tasked with the air defense of the continental United States (CONUS). At the time, CAF headquarters was located at Bolling Field (later Bolling AFB) in the District of Columbia and SAC assumed occupancy of its headquarters facilities until relocating SAC headquarters (HQ SAC) to nearby Andrews Field (later Andrews AFB), Maryland as a tenant activity until assuming control of Andrews Field in October 1946.
SAC initially totaled 37,000 USAAF personnel. In addition to Bolling Field and, seven months later, Andrews Field, SAC also assumed responsibility for:
SAC also had seven additional CAF bases transferred on 21 March 1946 which remained in SAC through the 1947 establishment of the U.S. Air Force as an independent service. Those installations included:
On 31 March 1946, the following additional installation was also assigned to SAC:
Under the first SAC Commander in Chief, General George C. Kenney, initial units reporting to the Strategic Air Command headquarters on 21 March 1946 included the Second Air Force, the IX Troop Carrier Command and the 73d Air Division.
Fifteenth Air Force was assigned to SAC on 31 March (15th AF's 263rd Army Air Force Base Unit—with —transferred the same date directly under HQ SAC ), while the IX Troop Carrier Command was inactivated the same date and its assets redistributed within SAC.
With postwar demobilization still underway, eight of the ten assigned bomb groups were inactivated before the Eighth Air Force was assigned to SAC on 7 June 1946
Despite the pressures of demobilization, SAC continued the training and evaluation of bomber crews and units still on active duty in the postwar Army Air Forces. Radar Bomb Scoring became the preferred method of evaluating bomber crews, with the last of 888 simulated bomb runs scored against a bombing site near San Diego, California during 1946, subsequently increasing to 2,449 bomb runs by 1947. In the wake of the successful employment of air-dropped nuclear weapons against Hiroshima and Nagasaki to effectively end World War II, SAC became the focus of the nation's nuclear strike capability, to the extent that Joint Chiefs of Staff (JCS) Publication 1259/27 on 12 December 1946 identified that, "...the 'air atomic' strategic air force should only come under the orders of the JCS."
In addition to the strategic bombing mission, SAC also devoted significant resources to aerial reconnaissance. In 1946, SAC's reconnaissance aircraft inventory consisted of F-2 photo variants of the C-45 Expeditor support aircraft, but by 1947 SAC had acquired an F-9C squadron consisting of twelve photo-reconnaissance variants of the B-17G Flying Fortress. An F-13 squadron, the F-13 later re-designated as the RB-29 Superfortress, was also established. SAC conducted routine aerial reconnaissance missions near the Soviet borders or near the 12-mile international waters limit, although some missions actually penetrated into Soviet airspace. The flight profiles of these missions—above 30,000 feet and in excess of 300 knots—made interception by Soviet air forces difficult until the Soviet's 1948 introduction of the MiG-15 jet fighter. Project Nanook, the Cold War’s first Top Secret reconnaissance effort, used the first RB-29 missions for mapping and visual reconnaissance in the Arctic and along the northern Soviet coast. Later missions were Project LEOPARD along the Chukchi Peninsula, followed by Projects RICKRACK, STONEWORK, and COVERALLS.
In 1946, the US possessed only nine atomic bombs and twenty-seven B-29s capable at any one time of delivering them. Furthermore, it was later determined that an attack by the 509th Composite Bomb Group during the 1947 to 1948 time frame would have required at least five to six days just to transfer custody of the bombs from United States Atomic Energy Commission (AEC) sites to SAC and deploy the aircraft and weapons to forward operating bases before launching nuclear strikes.
Unfortunately, postwar budget and personnel cuts had had an insidious effect on SAC as its Deputy Commander, Major General Clements McMullen, implemented mandated force reductions. This continued to wear down SAC as a command and morale plummeted. As a result, by the end of 1947, only two of SAC's eleven groups were combat ready. After the 1948 Bikini Atoll nuclear tests, the "Half Moon" Joint Emergency War Plan developed in May 1948 proposed dropping 50 atomic bombs on twenty Soviet cities,:68 with President Harry S. Truman approving "Half Moon" during the June 1948 Berlin Blockade,:68–9 (Truman sent B-29s to Europe in July). SAC also ordered special ELINT RB-29s to detect improved Soviet radars and, in cooperation with the 51st Air Force Base Unit, SAC also monitored radioactive fallout from Soviet atomic testing on Novaya Zemlya.
In terms of overall Air Force basing and infrastructure, SAC continued to acquire an ever-increasing share of that infrastructure and the associated budget. In 1947, before the USAF was established as an independent service, construction commenced on Limestone AAF, Maine (later renamed Loring AFB), a new SAC installation specifically designed to accommodate the B-36 Peacemaker. Fort Dix AAF, New Jersey (later McGuire AFB); Spokane AAF, Washington (later Fairchild AFB); and Wendover Field, Utah (later Wendover AFB) were also transferred to SAC between 30 April and 1 September 1947. Following establishment of the USAF as a separate service, those bases subsequently added to SAC in the United States included:
In addition to bases under its operational control, SAC also maintained tenant wings at several bases under the control of other USAF MAJCOMs. These non-SAC bases with SAC tenants included Amarillo AFB, Texas; Eglin AFB, Florida; Lowry AFB, Colorado; Mather AFB, California; Robins AFB, Georgia; Seymour Johnson AFB, North Carolina; Sheppard AFB, Texas; and Wright-Patterson AFB, Ohio. SAC also often maintained a presence at former SAC bases that the command subsequently relinquished to other MAJCOMs, to include but not limited to Altus AFB, Oklahoma; MacDill AFB, Florida; Homestead AFB, Florida; and Travis AFB, California.
Run-up to Korea and start of the Cold War.
SAC transferred to the United States Air Force on 26 September 1947, concurrent with the latter's establishment as a separate military service. Units directly under SAC HQ included the 8AF and 15AF, as well as the 311th Air Division, 4th Fighter Wing, 82nd Fighter Wing, 307th Bomb Wing, and two reconnaissance units, the 311th Reconnaissance Wing and the 46th Reconnaissance Squadron. The 56th Fighter Wing was subsequently assigned to SAC on 1 October 1947.
Following the establishment of the U.S. Air Force, most SAC installations on U.S. territory were renamed as "Air Force Base" during late 1947 and into 1948, while non-U.S. installations were renamed as "Air Base."
In May 1948, in an exercise versus Air Defense Command's "Blue" force, a SAC "Red" strike force simulated attacks on Eastern Seaboard targets as far south as Virginia.:77 After a "scathing" 1948 Lindbergh review of SAC operations in the air and at six SAC bases, General Kenney was removed as Commanding General on 15 October 1948 and replaced on 19 October 1948 by 8AF's commander, Lieutenant General Curtis LeMay. Upon Lemay's assumption of command, SAC had only 60 nuclear-capable aircraft, none of which possessed a realistic long range capability against the Soviet Union.
The B-29D, which had become the B-50 in December 1945, was first delivered to SAC in June 1948. This was followed by SAC's first Convair B-36 Peacemaker bomber arriving at Kirtland AFB, New Mexico in September 1948.
In November 1948, LeMay had SAC's headquarters and its command post moved from Andrews AFB, Maryland to Offutt AFB, Nebraska. At Offutt, the command moved into the "A Building," a three-story facility which had previously been used by the Glenn L. Martin Company during World War II. Concurrent with establishment of this new headquarters facility, Lemay also increased SAC Radar Bomb Scoring (RBS) runs the same year to 12,084. SAC also enhanced its organic fighter escort capability by initiating replacement of its World War II vintage piston-engine F-51D Mustang and F-82E Twin Mustang fighter aircraft with F-84G Thunderjets.
In January 1949, SAC conducted simulated raids on Wright-Patterson AFB, Ohio. Assessments of these simulated raids by, "...LeMay's entire command…were appalling," despite the SAC deputy commander, Major General McMullen, having instructed all bomber units to improve their effectiveness. To motivate crews and improve operational effectiveness command-wide, SAC established a competition, the first so-called "Bomb Comp" in 1948. Winners of this inaugural event were the 43rd Bombardment Group (unit) and, for aircrew award, a B-29 team from the 509th Bombardment Group.
Given its global operating environment, SAC also opened its own survival school at Camp Carson, Colorado in 1949, later moving this school to Stead AFB, Nevada in 1952 before transferring the school to the Air Training Command in 1954.
SAC also created Emergency War Plan 1–49 (EWP 1-49), which outlined the means for delivering 133 atomic bombs, "...the entire stockpile…in a single massive attack..." on 70 Soviet cities over a 30-day period.
The first Soviet atomic bomb test occurred on 29 August 1949 and the Joint Chiefs of Staff (JCS) subsequently identified SAC's primary objective was to damage or destroy the Soviet Union's ability to deliver nuclear weapons. The JCS further defined SAC's secondary objective was to stop any Soviet advances into Western Europe, and its tertiary objective was the previous EWP 1-49 industrial mission.
Korean War.
In July 1950, in response to combat operations on the Korean peninsula, SAC dispatched ten nuclear-capable bombers to Guam and deployed four B-29 bomber wings in Korea for tactical operations, although this action caused SAC commander Lemay to comment, “...too many splinters were being whittled off the [deterrence] stick”..
Initial SAC B-29 successes against North Korea in the summer of 1950 were countered by subsequent Soviet MiG-15 fighter-interceptors, and SAC's 27th Fighter Escort Wing began escorting the bombers with F–84 Thunderjets. Ground-directed bombing (GDB) was subsequently used for close air support (CAS) missions after three SAC radar bomb scoring (RBS) squadron detachments (Dets C, K, & N) arrived at Pusan in September 1950. In 1951, SAC "began to eliminate its combat groups", transferring medium bombardment groups "to Far East Air Forces (FEAF) Bomber Command for combat." In 1951, LeMay convinced the Air Staff to allow SAC to approve nuclear targets,:18 and he continued refusing to submit war plans for JCS reviewRosenberg1983}, which the JCS eventually came to accept:37 (of 20,000 candidates in 1960, SAC designated 3,560 as bombing targets—mostly Soviet air defense: airfields and suspected missile sites.):60
Although experimented with prior to World War II, SAC refined aerial refueling to a fine art. SAC's in-flight refueling mission began in July 1952 when its 31st Fighter-Escort Wing refueled sixty F-84G Thunderjets from Turner AFB, Georgia to Travis AFB, California non-stop with fuel from twenty-four KB-29P Superfortresses modified into aerial tankers. Exercise FOX PETER ONE followed with 31st FEW fighters being refueled Hickam AFB en route to Hawaii.
On 15 March 1953, a 38th Strategic Reconnaissance Squadron RB-50 returned fire on a Soviet MiG-15, while a 343d Strategic Reconnaissance Squadron RB-50 was shot down over the Sea of Japan 2 days after the Korean Armistice, while on 7 November 1954, an RB-29 was shot down near Hokkaido Island in northern Japan. By the time of the 27 July 1953 Korean War cease-fire, SAC B-29s had flown over 21,000 sorties and dropped nearly 167,000 tons of bombs, with thirty-four B-29s lost in combat and forty-eight B-29s were lost to damage or crashes.
The Cold War and Massive Retaliation.
SAC's first jet strategic bomber was the swept-wing B-47 medium bomber, which first entered service in 1951 and became operational within SAC in 1953. The B-47 was a component of the October 1953 "New Look" strategy, which articulated, in part, that: ""...to minimize the threat…the major purpose of air defense was not to shoot down enemy bombers--it was to allow SAC…to get into the air"[--and]" not be destroyed on the ground"[--to allow]" massive retaliation".".
Concern of a bomber gap grew after the 1955 Soviet Aviation Day and the Soviets rejected the "Open Skies" Treaty proposed at the Geneva Summit on 21 July 1955. US bomber strength peaked with "over 2,500 bombers" after production "of over 2,000 B-47s and almost 750 B-52s" (circa 1956, 50% of SAC aircraft & 80% of SAC bombers were B-47s).:104
In an effort to concurrently enhance it reconnaissance capabilities, SAC also received several RB-57D Canberra aircraft in April 1956, with the aircraft initially based at Turner AFB, Georgia. In 1957, these aircraft were forward deployed to Rhein-Main Air Base, West Germany, in order to conduct reconnaissance missions along the borders of the Soviet Union and other Warsaw Pact nations. However, an unintended consequence of this deployment was that Hawker Hunter fighters of the Royal Air Force stationed in the United Kingdom and in continental Europe often intercepted these classified RB-57 missions as they returned to Rhein-Main AB from over the Baltic.
Since it was designed as medium bomber, SAC's B-47 Stratojet traded speed for range. Because of this shorter range, and in order to better enable the B-47 fleet to reach its target sets in the Soviet Union, SAC routinely deployed its US-based B-47 wings to overseas forward operating bases in North Africa, Spain and Turkey. This program, in effect from 1957 to 1966, was known as "Reflex" with Sixteenth Air Force (16AF), a SAC numbered air force permanently stationed in Europe, having tactical and administrative control of the forward deployed aircraft and units.
Beginning in 1955, SAC also moved a portion of its bomber and aerial refueling aircraft to a 24-hour alert status, either on the ground or airborne. By 1960, fully one third of SAC's bombers and aerial refueling aircraft were on 24-hour alert, with those crews and aircraft not already airborne ready to take off from designated alert sites at their respective bases within fifteen minutes. Bomber aircraft on ground alert were armed with nuclear weapons while aerial tanker aircraft were sufficiently fueled to provide maximum combat fuel offload to the bombers.
Concurrent with this increased alert posture and in order to better hone strategic bombing skillsets, the 1955 SAC Bombing and Navigation Competition was characterized by radar bomb scoring (RBS) runs on Amarillo, Denver, Salt Lake City, Kansas City, San Antonio and Phoenix; and the 1957 competition (nicknamed "Operation Longshot") had three targets: Atlanta, Kansas City, and St. Louis. This use of RBS with simulated target areas utilizing mobile and fixed bomb scoring sites adjacent to major cities, industrial areas, military installations and dedicated bombing ranges throughout the United States. This format would continue through successive SAC Bombing and Navigation Competitions through the remainder of the 1950s, 1960s, 1970s and 1980s. Commencing in the late 1950s, in addition to representation from every SAC wing with a bombing and/or air refueling mission, later SAC competitions would also include participating bomber and aerial refueling units from the Royal Air Force's Bomber Command and (after 30 April 1968) its successor, RAF Strike Command.
Nuclear Bunkers, SAC Ground Alert, and transfer of SAC's Fighter-Escort Wings.
It was described as the "Western Pentagon," specifically a, "...four-story, reinforced concrete and masonry office building..." above ground and a "...segregated, adjacent three-story below ground command post." This was the description of what would become Building 500 at Offutt AFB and the new headquarters complex built expressly for SAC, with construction commencing in 1955. SAC headquarters moved from the A Building at Offutt AFB to Building 500 in 1957. The underground nuclear bunker had 24-inch thick walls and base floor, 10-inch thick intermediate floors, and 24-to-42-inch thick roof. It also contained a war room with six 16-foot data display screens and the capacity to sustain up to 800 people underground for two weeks. The below ground bunker portion of the headquarters complex also contained an IBM 704 computer, which was used to develop monthly weather forecasts at targets, as well as for computing fuel consumption and fallout cloud patterns for planning strike routes and egress routes (e.g., determining the timing as to which targets to bomb first).
In 1957, SAC also constructed The Notch, a facility alternatively known as the 8th Air Force Combat Operations Center (COC) and the Westover Communications Annex, since it was a sub-post of nearby Westover AFB. A 3-story nuclear bunker located on Bare Mountain, Massachusetts, The Notch was built with three-foot thick walls, 1.5 foot thick steel blast doors, and [20] feet underground [to protect] 350 people for 35 days. The Notch was shut down as a SAC facility in 1970 when 8th Air Force was relocated to Barksdale AFB, Louisiana.
Despite this investment in "hardened" headquarters and command and control facilities, the 1957 Gaither Commission identified, "...little likelihood of SAC's bombers surviving [a Soviet first strike] since there was no way to detect an incoming attack until the first [Soviet nuclear weapon] warhead landed." As a result, SAC's bombers and tankers began sitting armed ground alert at their respective bases on 1 Oct 57.
In another organizational change during this time period, SAC's fighter escort wings were transferred to Tactical Air Command (TAC) during 1957 and 1958. Finally, during January 1958's Exercise Fir Fly, SAC "faker" aircraft (twelve B-47s) simulated bombing strikes against metropolitan areas and military installations in the United States defended by Air Defense Command's 28th Air Division.
Nuclear missiles, Aircrew Readiness, Airborne Alert and Strategic Reconnaissance.
After SAC's 1st Missile Division was activated on 18 March 1957, SAC HQ established the Office of Assistant CINCSAC (SAC MIKE) at the Air Force Ballistic Missile Division in California on 1 January 1958. SAC MIKE was responsible for missile development liaison, theintermediate range Jupiter and Thor missiles having been transferred to SAC for alert in 1958.
Beginning on 1 February 1958, a SAC Liaison Team was also located at the NORAD Command Post at Ent AFB, Colorado, and the two commands agreed that direct land line communications should connect SAC bases with NORAD's Air Defense Direction Centers. Also in the late 1950s, SAC continued to enhance its intelligence collection activities and develop innovative means of improving the survivability of its forces to surprise attack. From 1958–c. 1967, a SAC Detachment (TUSLOG Det 50) operated at Incirlik AB, Turkey, monitoring Soviet missile telemetry from the Kapustin Yar and Tyuratam launch complexes, while in 1959, SAC's Operation Big Star studied, prototyped and evaluated the potential of deploying of Minuteman I ICBMs on civilian railroad tracks via USAF-operated locomotives and trains.
President Eisenhower approved the first Atlas ICBM launch by a SAC crew for 9 September 1959 at Vandenberg AFB.
While missile operations continued to ramp up, robust training for flight crews to ensure survivability for strike missions also continued. In some instances SAC bombers would oppose ADC fighter-interceptors simulating Soviet interceptors. Conversely, SAC assisted ADC readiness by simulating Soviet bomber threats to the continental United States that ADC fighters would respond to. However, following a mid-air collision between an ADC F-102 and a SAC B-47 during a 17 December 1959 Quick Kick exercise, simulated NORAD fighter attacks were prohibited against SAC bombers.:63
On 18 March 1960, SAC intercontinental missiles began alert at Maine's Snark Missile Launch Complex adjacent to Presque Isle AFB. The following month, on 22 April 1960, SAC turned over the last British-based PGM-17 Thor IRBM to the Royal Air Force. This was soon followed by SAC's first Titan I ICBMs at Lowry AFB's Titan I Missile Complex 1A in Colorado being placed on alert that June.
Beginning in November 1959, in order to counter Soviet surface-to-air missile threats, SAC began adding low-altitude bombing training for its manned bomber force as an adjunct to its legacy high-altitude training. Use of low level Oil Burner routes, and the first of three SAC RBS trains were utilized starting in 1960. On 30 June 1960, SAC had 696 aircraft on alert in the Zone of Interior, also known as the ZI (referred to today as the Continental United States, or CONUS) and at overseas bases. These 696 aircraft were 113 B-52s, 346 B-47s, 85 KC-135s, and 152 KC-97s. SAC's Emergency War Order (EWO) required the first aircraft to be airborne within 8 minutes and all aircraft to be airborne within 15 minutes after notification.
During the mid-1950s, having recalled numerous World War II USAAF and Korean War USAF combat veteran pilots, navigators, bombardiers and aircrewmen from inactive reserve status back to various lengths of active duty, SAC took the lead in integrating the Air Force's reserve components into the overall SAC structure. By the beginning of the 1960s, SAC had also engineered the assignment of KC-97 Stratotanker aerial refueling aircraft to Air National Guard groups and wings and having them fall under SAC's operational claimancy.
On 11 August 1960, President Eisenhower approved the creation of the Joint Strategic Target Planning Staff (JSTPS), co-located at SAC headquarters at Offutt AFB.) JSTPS also included non-SAC agencies tasked with preparing the Single Integrated Operation Plan, or SIOP, and the National Strategic Target List for nuclear war.:62
On 1 July 1960, a SAC RB-47 with a six-man crew was shot down in international airspace over the Barents Sea by a Soviet MiG-19. Four of the crewman were killed and two surviving crewmen were captured and held in Lubyanka Prison in Moscow for seven months.
On 3 February 1961, SAC's Boeing EC-135 Looking Glass, began operations as the Airborne Command Post for the Nuclear Triad and the Post-Attack Command and Control System. From this date and for the next 29 1/2 years, until 24 July 1990, SAC would maintain at least one Looking Glass aircraft continuously aloft 24 hours a day, 365 days a year, with an embarked SAC general officer and battle staff, ready to assume command of all strategic nuclear strike forces in the event that SAC headquarters was destroyed in a Soviet first strike. 
SAC's airborne alerts during this period also included Operation Chrome Dome for the bomber and tanker force. Although ostensibly a peacetime mission, Chrome Dome placed heavy demands on flight crews and five B-52 aircraft were lost to airborne mishaps during the operation's eight-year period.
On 11 May 1961, SAC took delivery of its first B-58 Hustler supersonic medium bomber, assigning it to the 305th Bombardment Wing at Bunker Hill AFB. Optimized for high-altitude, high-speed penetration into Soviet territory prior to Soviet advancements in high-altitude surface-to-air missiles, the B-58 was expensive to operate and inefficient at lower altitudes. Its service in SAC would be comparatively short, eventually being replaced by the FB-111 by 1970.
After an early 1961 development by SAC of a Radar Bomb Scoring (RBS) field kit for use in the U.S. Army's Nike surface-to-air missile systems, SAC aircraft flew several mock penetrations into Air Defense Command sectors in the 1961 SAGE/Missile Master test program, as well as the joint SAC-NORAD Sky Shield II exercise followed by Sky Shield III on 2 September 1962.
In 1961, following the Berlin Crisis, President John F. Kennedy increased the number of SAC aircraft on alert to 50 percent and during periods of increased tensions SAC kept some B-52 airborne in the event of a surprise attack.
In 1962, SAC gained full control of the various "Q Areas" developed by Sandia Laboratories for nuclear weapon storage adjacent to Loring AFB (Site E (Maine)/Caribou AFS), Ellsworth AFB (Site F (South Dakota)/Rushmore AFS), Fairchild AFB (Site G (Washington)/Deep Creek AFS), Travis AFB (Site H (California)/Fairfield AFS), and Westover AFB (Site I (Massachusetts)/Stony Brook AFS). These adjunct sites were subsequently converted to USAF-operated and maintained weapon storage areas (WSAs) in the same manner as WSAs on other SAC bases.
The solid fuel LGM-30A Minuteman I was first deployed in 1962 and the LGM-25C Titan II reached operational service in 1963. Project Added Effort phased out all first-generation ICBMs beginning on 1 May 1964 when Atlas-D were taken off alert at Vandenberg AFB's 576th SMS (LGM-30F Minuteman II replaced Minuteman I in 1965).
In October 1962, a SAC BRASS KNOB mission U-2 piloted by Major Richard S. Heyser detected Soviet intermediate range ballistic missiles in Cuba. BRASS KNOB operations involving multiple U-2 aircraft were subsequently commenced at a forward operating location at McCoy AFB, Florida the same month. On the morning of 27 October, a SAC RB-47H of the 55th Strategic Reconnaissance Wing, forward deployed to Kindley AFB, Bermuda crashed on takeoff, killing all four crewmembers, while later that afternoon, a 4028th Strategic Reconnaissance Squadron U-2 forward deployed to McCoy AFB for BRASS KNOB operations was shot down over Cuba by an SA-2 Guideline missile, killing the pilot, Major Rudolf Anderson.
Throughout the early 1960s, the Kennedy Administration, under the aegis of Secretary of Defense McNamara, cancelled numerous SAC modernization programs. This included the Mach 3 North American B-70 Valkyrie in 1961, the GAM-87 Skybolt missile in 1962, and the Rocky Mountain Deep Underground Support Center in 1963. The B-70's demise came due to its design as a high-altitude bomber with very limited low-altitude performance, making it vulnerable to rapid advances in Soviet high altitude surface-to-air missile defense systems. The following year, Skybolt, an air-launched ballistic missile, was cancelled following numerous test failures and the perceived greater reliability of land-based and submarine-based ballistic missile systems. Although initially entering service in 1957, SAC's 2nd-generation aerial refueling aircraft, the KC-135 Stratotanker, had reached sufficient inventory numbers to allow SAC to begin divestiture of its KC-97 Stratofreighter tankers, transferring them to SAC-gained Air Force Reserve and Air National Guard units. As the KC-135 became the primary aerial tanker in active service, SAC employed the aircraft for several non-stop B-52 and KC-135 flights around the world, demonstrating that SAC no longer needed to depend on Reflex stations at air bases in Spain and Britain.):108
Vietnam War & latter half of the Cold War.
SAC's Air War in Vietnam.
After the Secretary of Defense rejected LeMay's November 1964 proposal for a "...strategic air campaign against 94 targets in North Vietnam...", thirty SAC B-52s were deployed to Andersen AFB, Guam on 17 February 1965, representing the first increment of SAC aircraft forward deployed for the Vietnam War. The following month, in March 1965, the Strategic Air Command Advanced Echelon (SACADVON) was established as a "...liaison unit for CINCSAC [was] located at MACV Headquarters to assist with the B-52 effort.".
On 23 May 1965, SAC B-52s began unarmed missions for radar mapping "...and later to test bombing with the assistance of ground homing beacons...". SAC began saturation bombing on 18 June 1965 (8000 tons per month in 1966) and conducted Operation Arc Light missions from 1965 until the end of hostilities involving U.S. forces in 1973.
All B-52 missions in 1965 were against targets in South Vietnam (RVN) except for the December "...Duck Flight mission [that] hit a suspected VC supply storage area [for which] part of the target box was in Laos.":121 In April 1966, Vietnam operations began with the B-52D model, a 1956 model designed to use the AGM-28 Hound Dog cruise missile and the ADM-20 Quail aerial decoys for low altitude operations and modified in late 1965 by Project Big Belly to increase conventional bomb capacity.
SAC's RBS Squadrons were discontinued when most detachment personnel transferred to Vietnam from 1966 to 1973 for Combat Skyspot ground-directed bombing operations. The first "Quick Reaction" bombing was the "Pink Lady" mission on 6 July 1966 using SAC B-52s to support the U.S. Army's 1st Air Cavalry Division.:186 The 1972 Operation Linebacker II also used Skyspot for Hanoi/Haiphong bombings in North Vietnam which resulted in the loss of 25 SAC aircrew members.
By May 1967, SACADVON had moved to Seventh Air Force headquarters at Tan Son Nhut Air Base, South Vietnam to schedule and coordinate "...strikes for the 7th AF and MACV.". From a level of 161,921 military and 20,215 civilian assigned to SAC in June 1968, SAC lost 13,698 first term airmen from November 1968 to May 1969 in a three phase drawdown known as Project 693 to comply with Public Law 90-364.
While conventional bombing, air refueling and strategic air reconnaissance operations in Southeast Asia increasingly occupied SAC's operational commitments, SAC's primary mission of nuclear deterrence continued to remain its primary focus. In 1969, "...SAC's B-52s and B-58s could carry B28, B41, B43, B53, and BA53 nuclear weapons" (SAC had 311 nuclear AGM-28 Hound Dog| missiles at the end of the year.):6 This also coincided with the B-58 Hustler's in-progress retirement from SAC's active inventory and its replacement with the FB-111.
On 18 March 1969, along the South Vietnamese border, SAC first bombed Cambodia (Operation Menu through 26 May 1970 was controlled by Skyspot). On 17 February 1970, SAC conducted the first "GOOD LOOK" bombing of Laos at the Plaine des Jarres after B-52 photorecon missions (GOOD LOOK ALPHA in August 1969 and GOOD LOOK BRAVO c. 15 January 1970) and the observations of a Skyspot installation in Thailand.:19 SAC transferred "...HQ 8th AF…to Andersen AFB, Guam on 1 April 1970 to oversee B-52 operations and to complement SACADVON". 8th AF took over from Third Air Division the generation of "frag" orders based on daily strike requests and amendments from COMUSMACV.
In 1970, SAC deployed the LGM-30G Minuteman III ICBM with multiple independently targetable reentry vehicle or MIRVs, for striking 3 targets, while concurrently retiring the B-58 Hustler supersonic bomber.
1972 saw the commencement of Operation Linebacker II, a combined Seventh Air Force and U.S. Navy Task Force 77 aerial bombing campaign, conducted against targets in North Vietnam during the final period of US involvement in the Vietnam War. Linebacker II was conducted from 18 December to 29 December 1972, leading to several informal names such as "The December Raids" and "The Christmas Bombings." Unlike the previous Operation Rolling Thunder and Operation Linebacker interdiction operations, Linebacker II, would be a "maximum effort" bombing campaign to destroy major target complexes in the Hanoi and Haiphong areas which could only be accomplished by SAC B-52s. It saw the largest heavy bomber strikes launched by the U.S. Air Force since the end of World War II. Linebacker II was a modified extension of the Operation Linebacker bombings conducted from May to October 1972, with the emphasis of the new campaign shifted to attacks by B-52 Stratofortress heavy bombers rather than smaller tactical fighter aircraft. During Linebacker II, a total of 741 B-52 sorties were dispatched from bases in Thailand and Guam to bomb North Vietnam and 729 actually completed their missions. Overall SAC losses during Linebacker II numbered fifteen B-52s. The U.S. government claimed that the operation had succeeded in forcing North Vietnam's Politburo to return to the negotiating table, with the Paris Peace Accords signed shortly after the operation.
By early 1973, offensive SAC air operations in Southeast Asia ceased and numerous SAC aircrewmen who had been shot down and captured as prisoners of war by North Vietnam were repatriated to the United States.
Post-Vietnam, 1970s Budget Cuts, 1980s Renewal, and the Cold War redux.
With the c. 1973 Vietnam War draw-down, reduced defense budgets forced SAC to inactivate several wings, close multiple bases in CONUS and Puerto Rico, and retire older B-52B, B-52C, B-52E and B-52F aircraft.
In 1973, the National Emergency Airborne Command Post, or NEACP, aircraft entered SAC's inventory. Consisting of four Boeing E-4 aircraft, these highly modified Boeing 747 airframes were assigned to the 55th Strategic Reconnaissance Wing at Offutt AFB and were forward deployed as necessary to support the National Command Authority.
By 1975, SAC's manned bomber strength included several hundred B-52D, B-52G, B-52H and FB-111A aircraft, and "...SAC's first major exercise in 23 years" was Exercise Global Shield 79. As for the ICBM force, SAC reached a peak strength of 1000 Minuteman II and III and 54 Titan II ICBMs on active status before seeing reductions and retirements through a combination of obsolescing systems and various arms reduction treaties with the Soviet Union.
By 1977, SAC had been pinning its hopes for a new manned strategic bomber in the form of the Rockwell B-1A Lancer. However, on 30 June 1977, President Jimmy Carter Carter announced that the B-1A would be canceled in favor of ICBMs, submarine-launched ballistic missiles (SLBMs), and a fleet of modernized B-52s armed with air-launched cruise missiles (ALCMs).
On 1 December 1979, SAC assumed control of the ballistic missile warning system (BMEWS) and all Space Surveillance Network facilities from the deactivating Aerospace Defense Command (ADC). These activities would later be (transferred to Air Force Space Command (AFSPC) when the latter was established in 1982. SAC also continued to operate the Air Force's entire KC-135 aerial refueling fleet, its EC-135 LOOKING GLASS and E-4 NEACAP command post aircraft, as well the entire strategic reconnaissance aircraft fleet consisting of the U-2, SR-71, RC-135, and WC-135.
In 1981, SAC received a new air refueling tanker aircraft to supplement the aging KC-135 Stratotanker force. Based on the McDonnell Douglas DC-10 commercial airliner, the KC-10A Extender was deployed equipped with improved military avionics, aerial refueling, and satellite communications equipment. That same year, President Ronald Reagan reversed the 1977 Carter administration decision regarding the B-1, directing that 100 examples of a refined version of the aircraft, now designated the B-1B Lancer, be procured as a long-range combat aircraft for SAC.
The LGM-118A Peacekeeper ICBM reached SAC in 1986, and the 114 Peacekeepers had a total warhead yield of about 342 megatons. This also served to offset the retirement of the obsolescent and maintenance-intensive LGM-25C Titan II ICBM, the last example of which was deactivated in May 1987. An additional underground "16,000 square-foot, two-story reinforced concrete" command post for HQ SAC was also constructed at Offutt AFB from 1986 to 1989 from a design by Leo A. Daly, who had designed the adjoining 1957 bunker. The first Rockwell B-1B Lancer was also delivered to SAC in 1987. 
On 22 November 1988, the Northrop Grumman B-2 Spirit, under development as the Advanced Technology Bomber (ATB), a so-called "black program" since 1979, was officially acknowledged and rolled out for the first time for public display. The first "stealth bomber" designed for SAC, the aircraft made its first flight in May 1989.
End of the Cold War and Operation Desert Storm.
SAC reorganization at the end of the Cold War began as early as 1988 when the Carlucci Commission planned the closure of Mather Air Force Base, California, an ATC undergraduate navigator training (UNT) base with a tenant SAC B-52 and KC-135 bomb wing and a tenant SAC-gained AFRES KC-135 air refueling wing; and Pease Air Force Base, New Hampshire, a SAC base with an FB-111 and KC-135 bomb wing and a tenant SAC-gained ANG KC-135 air refueling wing.
On 1 July 1989, the 1st Combat Evaluation Group reporting directly to SAC headquarters was split with most HQ 1CEVG organizations transferring to SAC HQ (e.g., the Command Instrument Flight Division) and RBS personnel, equipment, and becoming the 1st Electronic Combat Range Group. Airborne NEACP alerts ended in 1990 and during 1991's Operation Desert Storm to liberate Kuwait from Iraqi invasion and occupation, SAC bomber, tanker and reconnaissance aircraft flew operations (e.g., B-52s with conventional bombs and conventional warhead AGM-86 ALCMs) near Iraq from bases in Great Britain, Turkey, Cyprus, Diego Garcia, Saudi Arabia, and the United Arab Emirates.
Following Operation Desert Storm, the dissolution of the Soviet Union and the "de facto" end of the Cold War, President George H. W. Bush and Secretary of Defense Dick Cheney directed SAC to take all bomber and refueling aircraft and Minuteman II ICBM's off of continuous nuclear alert on 27 September 1991 and placing said aircraft on quick reaction ground alert.
The 31 May 1992 major reorganization of the USAF organizational structure subsequently disestablished SAC, moving its bomber, reconnaissance and aerial command post aircraft and all SAC ICBMs, along with all Tactical Air Command aircraft, to the newly established Air Combat Command (ACC). The newly established Air Mobility Command (AMC) inherited most of SAC's KC-135 Stratotanker aircraft and the entire KC-10 Extender aerial refueling tanker force, while some KC-135s were reassigned directly to USAFE and PACAF, with one additional air refueling wing assigned to the Air Education and Training Command (AETC) as the KC-135 formal training unit.
Land-based ICBMs were later transferred from ACC to Air Force Space Command (AFSPC), while manned bombers remained in ACC. USAF nuclear forces in ACC and AFSPC were then combined with the United States Navy's Fleet Ballistic Missile submarine forces to form the United States Strategic Command (USSTRATCOM), which took over the SAC Headquarters complex at Offutt AFB.
In 2009, the entire land-based USAF ICBM force and that portion of the USAF manned bomber force that was still nuclear-capable, e.g., the B-2 Spirit and B-52 Stratofortress, was transferred to the newly established Air Force Global Strike Command (AFGSC), while the B-1 Lancer conventional bomber force remained in ACC.
Commemoration and post-Cold War historiography.
The SAC Museum located adjacent to Offutt AFB was moved in 1998 near Interstate 80 in Nebraska and renamed as the Strategic Air and Space Museum.
Organizations commemorating SAC include the Strategic Air Command Veterans Association, the SAC Society, the B-47 Stratojet Association, the B-52 Stratofortress Association, the FB-111 Association, the SAC Airborne Command Control Association, the Association of Air Force Missileers, the SAC Elite Guard Association and the Strategic Air Command Memorial Amateur Radio Club. After the Cold War, SAC histories included a 1996 almanac and a 2006 organizational history.
In 2009, the Air Force Global Strike Command (AFGSC) was activated with the lineage of Strategic Air Command. AFGSC, headquartered at Barksdale AFB, Louisiana, is one of two USAF component commands assigned to United States Strategic Command (USSTRATCOM). AFGSC currently consists of 8th Air Force (8AF), responsible for the nuclear-capable manned heavy bomber force, and 20th Air Force (20AF), responsible for the ICBM force.
Lineage.
Strategic Air Command in the United Kingdom was among the command's largest overseas concentrations of forces, with additional forces under SAC's 16th Air Force at air bases in North Africa, Spain and Turkey during the 1950s and 1960s.
SAC "Provisional" wings were also located in Kadena AB, Okinawa and U-Tapao Royal Thai Navy Airfield / U-Tapao AB, Thailand during the Vietnam War
SAC also maintained bomber, tanker, and/or reconnaissance aircraft assets or at the former Ramey AFB, Puerto Rico in the 1950s, 1960s and 1970s, and at Andersen AFB, Guam; RAF Mildenhall, RAF Fairford and RAF Alconbury in the United Kingdom; Moron AB, Spain; Lajes Field, Azores (Portugal); Diego Garcia; and the former NAS Keflavik, Iceland through the 1990s.
SAC also conducted operations from RAF Fairford, RAF Alconbury and RAF Mildenhall in the United Kingdom, Moron AB in Spain, Lajes Field in the Azores (Portugal), RAF Akrotiri in Cyprus, Incirlik AB in Turkey, Diego Garcia in the British Indian Ocean Territory, and from multiple air bases in Egypt, Saudi Arabia, Oman, and the United Arab Emirates during the first Gulf War (Operations Desert Shield and Desert Storm) from 1990 to 1991.

</doc>
<doc id="28119" url="http://en.wikipedia.org/wiki?curid=28119" title="Scheme (programming language)">
Scheme (programming language)

Scheme and Common Lisp are the two principal dialects of the computer programming language Lisp. Unlike Common Lisp, however, Scheme follows a minimalist design philosophy that specifies a small standard core accompanied by powerful tools for language extension.
Scheme was created during the 1970s at the MIT AI Lab and released by its developers, Guy L. Steele and Gerald Jay Sussman, via a series of memos now known as the Lambda Papers. It was the first dialect of Lisp to choose lexical scope and the first to require implementations to perform tail-call optimization, giving stronger support for functional programming and associated techniques such as recursive algorithms. It was also one of the first programming languages to support first-class continuations. It had a significant influence on the effort that led to the development of Common Lisp.
The Scheme language is standardized in the official IEEE standard and a "de facto" standard called the "Revised#redirect 
 Report on the Algorithmic Language Scheme" (R"n"RS). The most widely implemented standard is R5RS (1998); a new standard, R6RS, was ratified in 2007. Scheme has a diverse user base due to its compactness and elegance, but its minimalist philosophy has also caused wide divergence between practical implementations, so much that the Scheme Steering Committee calls it "the world's most unportable programming language" and "a "family" of dialects" rather than a single language.
History.
Origins.
Scheme started in the 1970s as an attempt to understand Carl Hewitt's Actor model, for which purpose Steele and Sussman wrote a "tiny Lisp interpreter" using Maclisp and then "added mechanisms for creating actors and sending messages." Scheme was originally called "Schemer", in the tradition of other Lisp-derived languages like Planner or "Conniver". The current name resulted from the authors' use of the ITS operating system, which limited filenames to two components of at most six characters each. Currently, "Schemer" is commonly used to refer to a Scheme programmer.
R6RS.
A new language standardization process began at the 2003 Scheme workshop, with the goal of producing an R6RS standard in 2006. This process broke with the earlier R"n"RS approach of unanimity.
R6RS features a standard module system, allowing a split between the core language and libraries. A number of drafts of the R6RS specification were released, the final version being R5.97RS. A successful vote resulted in the ratification of the new standard, announced on August 28, 2007.
Currently the newest releases of various Scheme implementations, such as Chez Scheme, Racket, Ikarus, Larceny and Ypsilon, support the R6RS standard. There is a portable reference implementation of the proposed implicitly phased libraries for R6RS, called psyntax, which loads and bootstraps itself properly on various older Scheme implementations.
R6RS introduces numerous significant changes to the language. The source code is now specified in Unicode, and a large subset of Unicode characters may now appear in Scheme symbols and identifiers, and there are other minor changes to the lexical rules. Character data is also now specified in Unicode. Many standard procedures have been moved to the new standard libraries, which themselves form a large expansion of the standard, containing procedures and syntactic forms that were formerly not part of the standard. A new module system has been introduced, and systems for exception handling are now standardized. Syntax-rules has been replaced with a more expressive syntactic abstraction facility (syntax-case) which allows the use of all of Scheme at macro expansion time. Compliant implementations are now "required" to support Scheme's full numeric tower, and the semantics of numbers have been expanded, mainly in the direction of support for the IEEE 754 standard for floating point numerical representation.
R7RS.
The R6RS standard has caused controversy because it is seen to have departed from the minimalist philosophy. In August 2009, the Scheme Steering Committee which oversees the standardization process announced its intention to recommend splitting Scheme into two languages: a large modern programming language for programmers, and a subset of the large version retaining the minimalism praised by educators and casual implementors; two working groups were created to work on these two new versions of Scheme. The site has links to the working groups charters, public discussions and issue tracking system.
The ninth draft of R7RS (small language) was made available on April 15, 2013. A vote ratifying this draft closed on May 20, 2013, and the final report has been available since August 6, 2013.
Distinguishing features.
Scheme is primarily a functional programming language. It shares many characteristics with other members of the Lisp programming language family. Scheme's very simple syntax is based on s-expressions, parenthesized lists in which a prefix operator is followed by its arguments. Scheme programs thus consist of sequences of nested lists. Lists are also the main data structure in Scheme, leading to a close equivalence between source code and data formats (homoiconicity). Scheme programs can easily create and evaluate pieces of Scheme code dynamically.
The reliance on lists as data structures is shared by all Lisp dialects. Scheme inherits a rich set of list-processing primitives such as codice_1, codice_2 and codice_3 from its Lisp progenitors. Scheme uses strictly but dynamically typed variables and supports first-class functions. Thus, functions can be assigned as values to variables or passed as arguments to functions.
This section concentrates mainly on innovative features of the language, including those features that distinguish Scheme from other Lisps. Unless stated otherwise, descriptions of features relate to the R5RS standard.
"In examples provided in this section, the notation "===> result" is used to indicate the result of evaluating the expression on the immediately preceding line. This is the same convention used in R5RS."
Fundamental design features.
This subsection describes those features of Scheme that have distinguished it from other programming languages from its earliest days. These are the aspects of Scheme that most strongly influence any product of the Scheme language, and they are the aspects that all versions of the Scheme programming language, from 1973 onward, share.
Minimalism.
Scheme is a very simple language, much easier to implement than many other languages of comparable expressive power. This ease is attributable to the use of lambda calculus to derive much of the syntax of the language from more primitive forms. For instance of the 23 s-expression-based syntactic constructs defined in the R5RS Scheme standard, 11 are classed as derived or library forms, which can be written as macros involving more fundamental forms, principally lambda. As R5RS says (R5RS sec. 3.1): "The most fundamental of the variable binding constructs is the lambda expression, because all other variable binding constructs can be explained in terms of lambda expressions."
Example: a macro to implement codice_4 as an expression using codice_5 to perform the variable bindings.
(define-syntax let
 (syntax-rules ()
 ((let ((var expr) ...) body ...)
 ((lambda (var ...) body ...) expr ...))))
Thus using codice_4 as defined above a Scheme implementation would rewrite "codice_7" as "codice_8", which reduces implementation's task to that of coding procedure instantiations.
In 1998 Sussman and Steele remarked that the minimalism of Scheme was not a conscious design goal, but rather the unintended outcome of the design process. "We were actually trying to build something complicated and discovered, serendipitously, that we had accidentally designed something that met all our goals but was much simpler than we had intended...we realized that the lambda calculus—a small, simple formalism—could serve as the core of a powerful and expressive programming language."
Lexical scope.
Like most modern programming languages and unlike earlier Lisps such as Maclisp, Scheme is lexically scoped: all possible variable bindings in a program unit can be analyzed by reading the text of the program unit without consideration of the contexts in which it may be called. This contrasts with dynamic scoping which was characteristic of early Lisp dialects, because of the processing costs associated with the primitive textual substitution methods used to implement lexical scoping algorithms in compilers and interpreters of the day. In those Lisps, it was perfectly possible for a reference to a free variable inside a procedure to refer to quite distinct bindings external to the procedure, depending on the context of the call.
The impetus to incorporate lexical scoping, which was an unusual scoping model in the early 1970s, into their new version of Lisp, came from Sussman's studies of ALGOL. He suggested that ALGOL-like lexical scoping mechanisms would help to realize their initial goal of implementing Hewitt's Actor model in Lisp.
The key insights on how to introduce lexical scoping into a Lisp dialect were popularized in Sussman and Steele's 1975 Lambda Paper, "Scheme: An Interpreter for Extended Lambda Calculus", where they adopted the concept of the lexical closure (on page 21), which had been described in an AI Memo in 1970 by Joel Moses, who attributed the idea to Peter J. Landin.
Lambda calculus.
Alonzo Church's mathematical notation, the lambda calculus, has inspired Lisp's use of "lambda" as a keyword for introducing a procedure, as well as influencing the development of functional programming techniques involving the use of higher-order functions in Lisp. But early Lisps were not suitable expressions of the lambda calculus because of their treatment of free variables.
The introduction of lexical scope resolved the problem by making an equivalence between some forms of lambda notation and their practical expression in a working programming language. Sussman and Steele showed that the new language could be used to elegantly derive all the imperative and declarative semantics of other programming languages including ALGOL and Fortran, and the dynamic scope of other Lisps, by using lambda expressions not as simple procedure instantiations but as "control structures and environment modifiers." They introduced continuation-passing style along with their first description of Scheme in the first of the Lambda Papers, and in subsequent papers they proceeded to demonstrate the raw power of this practical use of lambda calculus.
Block structure.
Scheme inherits its block structure from earlier block structured languages, particularly ALGOL. In Scheme, blocks are implemented by three "binding constructs": codice_4, codice_10 and codice_11. For instance, the following construct creates a block in which a symbol called codice_12 is bound to the number 10:
 ;; statements go here. Any reference to var here will be bound to 10.
Blocks can be nested to create arbitrarily complex block structures according to the need of the programmer. The use of block structuring to create local bindings alleviates the risk of namespace collision that can otherwise occur.
One variant of codice_4, codice_10, permits bindings to refer to variables defined earlier in the same construct, thus:
 (var2 (+ var1 12)))
 ;; But the definition of var1 could not refer to var2
The other variant, codice_11, is designed to enable mutually recursive procedures to be bound to one another.
 (letrec ((female (lambda (n)
 (if (= n 0)
 1
 (- n (male (female (- n 1)))))))
 (male (lambda (n)
 (if (= n 0)
 0
 (- n (female (male (- n 1))))))))
 (let loop ((i 0))
 (if (> i n)
 (cons (cons (female i)
 (male i))
 (loop (+ i 1)))))))
===> ((1 . 0) (1 . 0) (2 . 1) (2 . 2) (3 . 2) (3 . 3) (4 . 4) (5 . 4) (5 . 5))
All procedures bound in a single codice_11 may refer to one another by name, as well as to values of variables defined earlier in the same codice_11, but they may not refer to "values" defined later in the same codice_11.
A variant of codice_4, the "named let" form, has an identifier after the codice_4 keyword. This binds the let variables to the argument of a procedure whose name is the given identifier and whose body is the body of the let form. The body may be repeated as desired by calling the procedure. The named let is widely used to implement iteration.
Example: a simple counter
 (if (> n 10)
 (cons n
 (loop (+ n 1)))))
===> (1 2 3 4 5 6 7 8 9 10)
Like any procedure in Scheme the procedure created in the named let is a first class object.
Proper tail recursion.
Scheme has an iteration construct, codice_21, but it is more idiomatic in Scheme to use tail recursion to express iteration. Standard-conforming Scheme implementations are required to optimize tail calls so as to support an unbounded number of active tail calls (R5RS sec. 3.5)—a property the Scheme report describes as "proper tail recursion"—making it safe for Scheme programmers to write iterative algorithms using recursive structures, which are sometimes more intuitive. Tail recursive procedures and the "named codice_4" form provide support for iteration using tail recursion.
 (let loop ((i n) (res '()))
 (if (< i 0)
 res
 (loop (- i 1) (cons (* i i) res)))))
===> (0 1 4 9 16 25 36 49 64 81)
First-class continuations.
Continuations in Scheme are first-class objects. Scheme provides the procedure codice_23 (also known as codice_24) to capture the current continuation by packing it up as an escape procedure bound to a formal argument in a procedure provided by the programmer. (R5RS sec. 6.4) First-class continuations enable the programmer to create non-local control constructs such as iterators, coroutines, and backtracking.
Continuations can be used to emulate the behavior of return statements in imperative programming languages. The following function codice_25, given function codice_26 and list codice_27, returns the first element codice_28 in codice_27 such that codice_30 returns true.
 (call-with-current-continuation
 (lambda (return-immediately)
 (for-each (lambda (x)
 (if (func x)
 (return-immediately x)))
 lst)
 #f)))
===> 7
===> #f
The following example, a traditional programmer's puzzle, shows that Scheme can handle continuations as first-class objects, binding them to variables and passing them as arguments to procedures.
(let* ((yin
 ((lambda (cc) (display "@") cc) (call-with-current-continuation (lambda (c) c))))
 (yang
 ((lambda (cc) (display "*") cc) (call-with-current-continuation (lambda (c) c)))))
 (yin yang))
When executed this code displays a counting sequence: codice_31
Shared namespace for procedures and variables.
In contrast to Common Lisp, all data and procedures in Scheme share a common namespace, whereas in Common Lisp functions and data have separate namespaces making it possible for a function and a variable to have the same name, and requiring special notation for referring to a function as a value. This is sometimes known as the "Lisp-1 vs. Lisp-2" distinction, referring to the unified namespace of Scheme and the separate namespaces of Common Lisp.
In Scheme, the same primitives that are used to manipulate and bind data can be used to bind procedures. There is no equivalent of Common Lisp's codice_32, codice_33 and codice_34 primitives.
f
===> 10
f
===> 26
===> 18
f
===> 13
===> 21
===> (101 102 103)
Implementation standards.
This subsection documents design decisions that have been taken over the years which have given Scheme a particular character, but are not the direct outcomes of the original design.
Numerical tower.
Scheme specifies a comparatively full set of numerical datatypes including complex and rational types, which is known in Scheme as the numerical tower (R5RS sec. 6.2). The standard treats these as abstractions, and does not commit the implementor to any particular internal representations.
Numbers may have the quality of exactness. An exact number can only be produced by a sequence of exact operations involving other exact numbers—inexactness is thus contagious. The standard specifies that any two implementations must produce equivalent results for all operations resulting in exact numbers.
The R5RS standard specifies procedures codice_35 and codice_36 which can be used to change the exactness of a number. codice_36 produces "the exact number that is numerically closest to the argument." codice_35 produces "the inexact number that is numerically closest to the argument". The R6RS standard omits these procedures from the main report, but specifies them as R5RS compatibility procedures in the standard library (rnrs r5rs (6)).
In the R5RS standard, Scheme implementations are not required to implement the whole numerical tower, but they must implement "a coherent subset consistent with both the purposes of the implementation and the spirit of the Scheme language" (R5RS sec. 6.2.3). The new R6RS standard does require implementation of the whole tower, and "exact integer objects and exact rational number objects of practically unlimited size and precision, and to implement certain procedures...so they always return exact results when given exact arguments" (R6RS sec. 3.4, sec. 11.7.1).
Example 1: exact arithmetic in an implementation that supports exact 
rational complex numbers.
x
===> 509/60+1/3i
===> #t
Example 2: Same arithmetic in an implementation that supports neither exact 
rational numbers nor complex numbers but does accept real numbers in rational notation.
xr
===> 8.48333333333333
xi
===> 0.333333333333333
===> #f
===> #f
Both implementations conform to the R5RS standard but the second does not conform to R6RS because it does not implement the full numerical tower.
Delayed evaluation.
Scheme supports delayed evaluation through the codice_39 form and the procedure codice_40.
===> 22
 (force eval-aplus50))
===> 70
===> 22
The lexical context of the original definition of the promise is preserved, and its value is also preserved after the first use of codice_40, The promise is only ever evaluated once.
These primitives, which produce or handle values known as promises, can be used to implement advanced lazy evaluation constructs such as streams.
In the R6RS standard, these are no longer primitives, but instead are provided as part of the R5RS compatibility library (rnrs r5rs (6)).
In R5RS, a suggested implementation of codice_39 and codice_40 is given, implementing the promise as a procedure with no arguments (a thunk) and using memoization to ensure that it is only ever evaluated once, irrespective of the number of times codice_40 is called (R5RS sec. 6.4).
SRFI 41 enables the expression of both finite and infinite sequences with extraordinary economy. For example this is a definition of the fibonacci sequence using the functions defined in SRFI 41:
(define fibs
 (stream-cons 0
 (stream-cons 1
 (stream-map +
 fibs
 (stream-cdr fibs)))))
===> 218922995834555169026
Order of evaluation of procedure arguments.
Most Lisps specify an order of evaluation for procedure arguments. Scheme does not. Order of evaluation—including the order in which the expression in the operator position is evaluated—may be chosen by an implementation on a call-by-call basis, and the only constraint is that "the effect of any concurrent evaluation of the operator and operand expressions is constrained to be consistent with some sequential order of evaluation." (R5RS sec. 4.1.3)
 (display (if (procedure? n) "procedure" n))
 (newline) n)))
 ((ev +) (ev 1) (ev 2)))
===> 3
ev is a procedure that describes the argument passed to it, then returns the value of the argument. In contrast with other Lisps, the appearance of an expression in the operator position (the first item) of a Scheme expression is quite legal, as long as the result of the expression in the operator position is a procedure.
In calling the procedure "+" to add 1 and 2, the expressions (ev +), (ev 1) and (ev 2) may be evaluated in any order, as long as the effect is not as if they were evaluated in parallel. Thus the following three lines may be displayed in any order by standard Scheme when the above example code is executed, although the text of one line may not be interleaved with another, because that would violate the sequential evaluation constraint.
Hygienic macros.
In the R5RS standard and also in later reports, the syntax of Scheme can easily be extended via the macro system. The R5RS standard introduced a powerful hygienic macro system that allows the programmer to add new syntactic constructs to the language using a simple pattern matching sublanguage (R5RS sec 4.3). Prior to this, the hygienic macro system had been relegated to an appendix of the R4RS standard, as a "high level" system alongside a "low level" macro system, both of which were treated as extensions to Scheme rather than an essential part of the language.
Implementations of the hygienic macro system, also called codice_45, are required to respect the lexical scoping of the rest of the language. This is assured by special naming and scoping rules for macro expansion, and avoids common programming errors that can occur in the macro systems of other programming languages. R6RS specifies a more sophisticated transformation system, codice_46, which has been available as a language extension to R5RS Scheme for some time.
(define-syntax when
 (syntax-rules ()
 ((when pred exp exps ...)
 (if pred (begin exp exps ...)))))
Invocations of macros and procedures bear a close resemblance—both are s-expressions—but they are treated differently. When the compiler encounters an s-expression in the program, it first checks to see if the symbol is defined as a syntactic keyword within the current lexical scope. If so, it then attempts to expand the macro, treating the items in the tail of the s-expression as arguments without compiling code to evaluate them, and this process is repeated recursively until no macro invocations remain. If it is not a syntactic keyword, the compiler compiles code to evaluate the arguments in the tail of the s-expression and then to evaluate the variable represented by the symbol at the head of the s-expression and call it as a procedure with the evaluated tail expressions passed as actual arguments to it.
Most Scheme implementations also provide additional macro systems. Among popular ones are syntactic closures, explicit renaming macros and codice_47, a non-hygienic macro system similar to codice_48 system provided in Common Lisp.
Environments and eval.
Prior to R5RS, Scheme had no standard equivalent of the codice_49 procedure which is ubiquitous in other Lisps, although the first Lambda Paper had described codice_50 as "similar to the LISP function EVAL" and the first Revised Report in 1978 replaced this with codice_51, which took two arguments. The second, third and fourth revised reports omitted any equivalent of codice_49.
The reason for this confusion is that in Scheme with its lexical scoping the result of evaluating an expression depends on where it is evaluated. For instance, it is not clear whether the result of evaluating the following expression should be 5 or 6:
 (let ((+ *))
 (evaluate (list name 2 3))))
If it is evaluated in the outer environment, where codice_53 is defined, the result is the sum of the operands. If it is evaluated in the inner environment, where the symbol "+" has been bound to the value of the procedure "*", the result is the product of the two operands.
R5RS resolves this confusion by specifying three procedures that return environments, and providing a procedure codice_49 that takes an s-expression and an environment and evaluates the expression in the environment provided. (R5RS sec. 6.5) R6RS extends this by providing a procedure called codice_55 by which the programmer can specify exactly which objects to import into the evaluation environment.
Treatment of non-boolean values in boolean expressions.
In most dialects of Lisp including Common Lisp, by convention the value codice_56 evaluates to the value false in a boolean expression. In Scheme, since the IEEE standard in 1991, all values except #f, including codice_56's equivalent in Scheme which is written as '(), evaluate to the value true in a boolean expression. (R5RS sec. 6.3.1)
Where the constant representing the boolean value of true is codice_58 in most Lisps, in Scheme it is codice_59.
Disjointness of primitive datatypes.
In Scheme the primitive datatypes are disjoint. Only one of the following predicates can be true of any Scheme object: codice_60, codice_61, codice_62, codice_63, codice_64, codice_65, codice_66, codice_67, codice_68. (R5RS sec 3.2)
Within the numerical datatype, by contrast, the numerical values overlap. For example, an integer value satisfies all of the codice_69, codice_70, codice_71, codice_72 and codice_63 predicates at the same time. (R5RS sec 6.2)
Equivalence predicates.
Scheme has three different types of equivalence between arbitrary objects denoted by three different "equivalence predicates", relational operators for testing equality, codice_74, codice_75 and codice_76:
Type dependent equivalence operations also exist in Scheme: codice_84 and codice_85 compare two strings (the latter performs a case-independent comparison); codice_86 and codice_87 compare characters; codice_88 compares numbers.
Comments.
Up to the R5RS standard, the standard comment in Scheme was a semicolon, which makes the rest of the line invisible to Scheme. Numerous implementations have supported alternative conventions permitting comments to extend for more than a single line, and the R6RS standard permits two of them: an entire s-expression may be turned into a comment (or "commented out") by preceding it with codice_89 (introduced in SRFI 62) and a multiline comment or "block comment" may be produced by surrounding text with codice_90 and codice_91.
Input/output.
Scheme's input and output is based on the "port" datatype. (R5RS sec 6.6) R5RS defines two default ports, accessible with the procedures codice_92 and codice_93, which correspond to the Unix notions of standard input and standard output. Most implementations also provide codice_94. Redirection of input and standard output is supported in the standard, by standard procedures such as codice_95 and codice_96. Most implementations provide string ports with similar redirection capabilities, enabling many normal input-output operations to be performed on string buffers instead of files, using procedures described in SRFI 6. The R6RS standard specifies much more sophisticated and capable port procedures and many new types of port.
The following examples are written in strict R5RS Scheme.
Example 1: With output defaulting to (current-output-port):
 (hello0))
Example 2: As 1, but using optional port argument to output procedures
 (hello1 (current-output-port)))
Example 3: As 1, but output is redirected to a newly created file
 (with-output-to-file "helloworldoutputfile" hello0))
Example 4: As 2, but with explicit file open and port close to send output to file
 (output-port (open-output-file "helloworldoutputfile")))
 (hello1 output-port)
 (close-output-port output-port))
Example 5: As 2, but with using call-with-output-file to send output to a file.
 (call-with-output-file "helloworldoutputfile" hello1))
Similar procedures are provided for input. R5RS Scheme provides the predicates codice_97 and codice_98. For character input and output, codice_99, codice_100, codice_101 and codice_102 are provided. For writing and reading Scheme expressions, Scheme provides codice_103 and codice_104. On a read operation, the result returned is the end-of-file object if the input port has reached the end of the file, and this can be tested using the predicate codice_105.
In addition to the standard, SRFI 28 defines a basic formatting procedure resembling Common Lisp's codice_106 function, after which it is named.
Redefinition of standard procedures.
In Scheme, procedures are bound to variables. At R5RS the language standard formally mandated that programs may change the variable bindings of built-in procedures, effectively redefining them. (R5RS "Language changes") For example, one may extend codice_107 to accept strings as well as numbers by redefining it:
(set! +
 (let ((original+ +))
 (lambda args
 (if (and (not (null? args)) (string? (car args)))
 (apply string-append args)
 (apply original+ args)))))
===> 6
===> "123"
In R6RS every binding, including the standard ones, belongs to some library, and all exported bindings are immutable. (R6RS sec 7.1) Because of this, redefinition of standard procedures by mutation is forbidden. Instead, it is possible to import a different procedure under the name of a standard one, which in effect is similar to redefinition.
Nomenclature and naming conventions.
In Standard Scheme, procedures that convert from one datatype to another contain the character string "->" in their name, predicates end with a "?", and procedures that change the value of already-allocated data end with a "!". These conventions are often followed by Scheme programmers.
In formal contexts such as Scheme standards, the word "procedure" is used in preference to "function" to refer to a lambda expression or primitive procedure. In normal usage the words "procedure" and "function" are used interchangeably. Procedure application is sometimes referred to formally as "combination".
As in other Lisps, the term "thunk" is used in Scheme to refer to a procedure with no arguments. The term "proper tail recursion" refers to the property of all Scheme implementations, that they perform tail-call optimization so as to support an indefinite number of active tail calls.
The form of the titles of the standards documents since R3RS, "Revisedn Report on the Algorithmic Language Scheme", is a reference to the title of the ALGOL 60 standard document, "Revised Report on the Algorithmic Language Algol 60," The Summary page of R3RS is closely modeled on the Summary page of the ALGOL 60 Report.
Review of standard forms and procedures.
The language is formally defined in the standards R5RS (1998) and R6RS (2007). They describe standard "forms": keywords and accompanying syntax, which provide the control structure of the language, and standard procedures which perform common tasks.
Standard forms.
This table describes the standard forms in Scheme. Some forms appear in more than one row because they cannot easily be classified into a single function in the language.
Forms marked "L" in this table are classed as derived "library" forms in the standard and are often implemented as macros using more fundamental forms in practice, making the task of implementation much easier than in other languages.
Note that codice_108 is defined as a library syntax in R5RS, but the expander needs to know about it to achieve the splicing functionality. In R6RS it is no longer a library syntax.
Standard procedures.
The following two tables describe the standard procedures in R5RS Scheme. R6RS is far more extensive and a summary of this type would not be practical.
Some procedures appear in more than one row because they cannot easily be classified into a single function in the language.
String and character procedures that contain "-ci" in their names perform case-independent comparisons between their arguments: upper case and lower case versions of the same character are taken to be equal.
Implementations of - and / that take more than two arguments are defined but left optional at R5RS.
Scheme Requests for Implementation.
Because of Scheme's minimalism, many common procedures and syntactic forms are not defined by the standard. In order to keep the core language small but facilitate standardization of extensions, the Scheme community has a "Scheme Request for Implementation" (SRFI) process by which extension libraries are defined through careful discussion of extension proposals. This promotes code portability. Many of the SRFIs are supported by all or most Scheme implementations.
SRFIs with fairly wide support in different implementations include:
A full list of accepted (finalized) SRFIs is available at http://srfi.schemers.org/final-srfis.html
Implementations.
The elegant, minimalist design has made Scheme a popular target for language designers, hobbyists, and educators, and because of its small size, that of a typical interpreter, it is also a popular choice for embedded systems and scripting. This has resulted in scores of implementations, most of which differ from each other so much that porting programs from one implementation to another is quite difficult, and the small size of the standard language means that writing a useful program of any great complexity in standard, portable Scheme is almost impossible. The R6RS standard specifies a much broader language, in an attempt to broaden its appeal to programmers.
Almost all implementations provide a traditional Lisp-style read–eval–print loop for development and debugging. Many also compile Scheme programs to executable binary. Support for embedding Scheme code in programs written in other languages is also common, as the relative simplicity of Scheme implementations makes it a popular choice for adding scripting capabilities to larger systems developed in languages such as C. Gambit, Chicken, and Bigloo work by compiling Scheme to C, which makes embedding particularly easy. In addition, Bigloo's compiler can be configured to generate JVM bytecode, and it also features an experimental bytecode generator for .NET.
Some implementations support additional features. For example, Kawa and JScheme provide integration with Java classes, and the Scheme to C compilers often make it easy to use external libraries written in C, up to allowing the embedding of actual C code in the Scheme source. Another example is Pvts, which offers a set of visual tools for supporting the learning of Scheme.
Usage.
Scheme is widely used by a number of schools; in particular, a number of introductory Computer Science courses use Scheme in conjunction with the textbook "Structure and Interpretation of Computer Programs" (SICP). For the past 12 years, PLT has run the ProgramByDesign (formerly TeachScheme!) project, which has exposed close to 600 high school teachers and thousands of high school students to rudimentary Scheme programming. MIT's old introductory programming class 6.001 was taught in Scheme, Although 6.001 has been replaced by more modern courses, SICP continues to be taught at MIT.
The textbook "How to Design Programs" by Matthias Felleisen, currently at Northeastern University, is used by some institutes of higher education for their introductory computer science courses. Both Northeastern University and Worcester Polytechnic Institute use Scheme exclusively for their introductory courses Fundamentals of Computer Science (CS2500) and Introduction to Program Design (CS1101), respectively. Indiana University's introductory class, C211, is taught entirely in Scheme. The introductory class at UC Berkeley, CS 61A, was until recently taught entirely in Scheme, save minor diversions into Logo to demonstrate dynamic scope; all course materials, including lecture webcasts, are available online free of charge. The introductory computer science courses at Yale and Grinnell College are also taught in Scheme. Programming Design Paradigms, a mandatory course for the Computer science Graduate Students at Northeastern University, also extensively uses Scheme.
The introductory Computer Science course at the University of Minnesota - Twin Cities, CSCI 1901, also uses Scheme as its primary language, followed by a course that introduces students to the Java programming language. In the software industry, Tata Consultancy Services, Asia's largest software consultancy firm, uses Scheme in their month-long training program for fresh college graduates.
Scheme is/was also used for the following:

</doc>
<doc id="28122" url="http://en.wikipedia.org/wiki?curid=28122" title="Society for Psychical Research">
Society for Psychical Research

The Society for Psychical Research (SPR) is a non-profit organisation in the United Kingdom. Its stated purpose is to understand "events and abilities commonly described as psychic or paranormal by promoting and supporting important research in this area" and to "examine allegedly paranormal phenomena in a scientific and unbiased way." It does not however, since its inception in 1882, hold any corporate opinions: SPR members have a variety of beliefs or lack thereof about the reality and nature of the phenomena studied, and some skeptics have been active members of the Society.
History.
The SPR was founded in 1882 in London by a group of eminent thinkers including Edmund Gurney, Frederic W. H. Myers, William F. Barrett, Henry Sidgwick, and Edmund Dawson Rogers. The SPR was the first organisation of its kind in the world, its stated purpose being "to approach these varied problems without prejudice or prepossession of any kind, and in the same spirit of exact and unimpassioned enquiry which has enabled science to solve so many problems, once not less obscure nor less hotly debated."
Initially six committees were established: on Thought-Transference, Mesmerism and similar phenomena, Mediumship, Reichenbach Phenomena (Odic Force), Apparitions and Haunted Houses, physical phenomena associated with séances, and the Literary Committee which studied the history of these phenomena. Critical SPR investigations into purported mediums and the exposure of fake mediums led to a number of resignations in the 1880s by Spiritualist members but the Society continued to investigate mediums, studying Gladys Osborne Leonard, Eusapia Palladino, Leonora Piper, Rudi Schneider among others.
Much of the early work involved investigating, exposing and in some cases duplicating fake phenomena. Richard Hodgson (parapsychologist) distinguished himself in that area. In 1884 Hodgson was sent by the SPR to India to investigate Helena Blavatsky and concluded that her claims of psychic power were fraudulent. Among the phenomena that Hodgson investigated was the supposed miraculous Theosophical letters from the Mahatmas which were said to magically appear over a four-year period in a cabinet in the Shrine Room at the Theosophical headquarters in Madres. Hodgson in his report wrote that the letters were frauds and had been written by Blavatsky herself who had put them in the cabinet from an opening in her bedroom located behind the Shrine room. In April 1986, Vernon Harrison examined the evidence of the case and outlined flaws in Hodgson's work. Harrison concluded that the letters were forgeries but were not written by Blavatsky but by ex-employees for revenge. On May 8 of that year the SPR issued a press release in support of Harrison's findings, and rejecting the Hodgson report.
In 1886 and 1887 in a series of publications the SPR exposed the tricks of many mediums. One of the most interesting exposures of that period was carried out by Hodgson with his friend, S. J. Davey. Originating the “fake séance” technique for educating the public (including SPR members), Davey gave sittings under an assumed name, duplicating the slate-writing phenomena produced by a medium named William Eglinton, and then proceeded to point out to the sitters the manner in which they had been deceived. Because of this, some spiritualist members such as William Stainton Moses resigned from the SPR. Due to the exposure of William Hope and other fraudulent spiritualists, Arthur Conan Doyle led a mass resignation of eighty-four members of the Society for Psychical Research, as they believed the Society was opposed to spiritualism.
According to D. Scott Rogo "For years a feud existed between the Spiritualists who saw the SPR as unnecessarily skeptical and the SPR which saw Spiritualists as credulous or simplistic." As the SPR progressed many of the members came to interpret mediumship and spiritualist phenomena in terms of psychokinesis and telepathy opposed to the spiritualist hypothesis. This explanation for spiritualistic phenomena prevailed in the SPR, and is still supported by parapsychological researchers to this day. On this subject Terence Hines wrote "The split came about not because of doubt on the part of the scientists who belonged to the SPR, but because of a fundamental difference with spiritualists over the correct interpretation of the phenomena that took place at séances." The parapsychological claim that mediumship can be explained by psychokinesis or telepathy is not accepted by the scientific community.
In 1966 the SPR member Simeon Edmunds published "Spiritualism: A Critical Survey" which concluded the majority of mediums that had been investigated were fraudulent. The SPR member Tony Cornell spent over 50 years investigating the paranormal and came to the conclusion that most paranormal cases turn out to have natural explanations such as the result of fraud, pranks and misidentification. He believed that many sightings of ghosts, hauntings and poltergeists are products of the human mind. Cornell estimated that of the 800 cases that he investigated, only twenty percent were difficult to explain and only a handful were paranormal. Some skeptical members have resigned from the SPR. Eric Dingwall resigned and wrote "After sixty years' experience and personal acquaintance with most of the leading parapsychologists of that period I do not think I could name half a dozen whom I could call objective students who honestly wished to discover the truth."
The SPR is frequently referred to in Victorian and Edwardian literature as the "Psychical Research Society". The term "psychical" was adopted to distinguish the purported phenomena from those classified as "psychic", (that is simply mental processes such as thought, memory, etc.) and the SPR were to introduce a number of other neologisms which have entered the English language, such as 'telepathy', which was coined by Frederic Myers.
The Society is run by a President and a Council of twenty members, and is open to interested members of the public to join. The organisation is based at 49 Marloes Road, Kensington, London, with a library and office open to members, and with large book and archival holdings in Cambridge University Library, Cambridgeshire, England. It publishes the peer reviewed quarterly "Journal of the Society for Psychical Research" ("JSPR"), the irregular "Proceedings" and the magazine "Paranormal Review". It holds an annual conference, regular lectures and two study days per year and supports the "LEXSCIEN" on-line library project.
Controversies.
Harry Price.
The psychical researcher Harry Price joined the SPR in 1920 and because of his knowledge in conjuring had debunked fraudulent mediums but in direct contrast to skeptics such as Harry Houdini, Price endorsed some mediums that he believed were genuine. Price formed an organization in 1926 called the National Laboratory of Psychical Research as a rival to the Society for Psychical Research. Price had a number of disputes with the SPR, most notably over the mediumship of Rudi Schneider. In the 1920s and early 1930s Price tested Rudi at his laboratory.
In April 1932, Price discovered that members of his council had been conducting secret negotiations with Rudi to set up experiments with the SPR. The SPR member John L. Randall wrote "Since it was Price who had brought Rudi to England in the first instance, the attempt to set up further experiments behind his back was seen by him as an act of betrayal." Rudi claimed he could levitate objects but according Price a photograph taken on April 28, 1932 showed that Rudi had managed to free his arm to move a handkerchief from the table. After this, many scientists considered Rudi to be exposed as a fraud. Price wrote the findings of other experiments should be revised due to the evidence showing how Rudi could free himself from the control.
After Price had exposed Rudi, various scientists such Karl Przibram and the magician Henry Evans wrote to Price telling him that they agreed that Rudi would evade control during his séances and congratulated Price on the success of unmasking the fraud. In opposition, SPR members who were highly critical of Price, supported Rudi's mediumship and promoted a conspiracy theory that Price had hoaxed the photograph. SPR member Anita Gregory claimed Price had deliberately faked the photograph to discredit SPR research and ruin Rudi's reputation. However, the photographic expert Vernon Harrison testified that the photograph was genuine.
According to John L. Randall there was direct evidence of "dirty tricks" played upon Price by members of the SPR. On October 9, 1931, a past president of the SPR William Henry Salter visited the Borley Rectory in an attempt to persuade the Rector Lionel Foyster, to sever his links with Price and work with the SPR instead. After Price's death in 1948 Eric Dingwall, Kathleen M. Goldney, and Trevor H. Hall, three members of the Society for Psychical Research, two of whom had been Price's most loyal associates, investigated his claims about Borley. Their findings were published in a 1956 book, "The Haunting of Borley Rectory", which concluded Price had fraudulently produced some of the phenomena. The "Borley Report", as the SPR study has become known, stated that many of the phenomena were either faked or due to natural causes such as rats and the strange acoustics attributed to the odd shape of the house. In their conclusion, Dingwall, Goldney, and Hall wrote "when analysed, the evidence for haunting and poltergeist activity for each and every period appears to diminish in force and finally to vanish away." Robert Hastings was one of the few SPR researchers to defend Price. Price's literary executor Paul Tabori and Peter Underwood have also defended Price against accusations of fraud. A similar approach was made by Ivan Banks in 1996. Michael Coleman in an SPR report in 1997 wrote Price's defenders are unable to rebut the criticisms convincingly.
Fraud.
The SPR's investigations into mediumship exposed many fraudulent mediums which contributed to the decline of interest in physical mediumship.
At a séance in the house of the solicitor John Snaith Rymer in Ealing on July 1855, the SPR member Frederick Merrifield observed that a "spirit-hand" was a false limb attached on the end of Daniel Dunglas Home's arm. Merrifield also claimed to have observed Home use his foot in the séance room.
Writing in the "Journal of the Society for Psychical Research", Count Petrovsky Petrovo-Solovo described séances in which Home was caught using his feet to create supposed spirit effects. Home wore thin shoes, easy to take off and draw on, and also cut socks that left the toes free. "At the appropriate moment he takes off one of his shoes and with his foot pulls a dress here, a dress there, rings a bell, knocks one way and another, and, the thing done, quickly puts his shoe on again." Home held a séance for Eugénie de Montijo, and positioned himself between Montijo and Napoleon III. One of the séance sitters known as General Felury suspected Home was utilizing trickery and asked to leave but returned unobserved to watch from another door behind Home. He saw Home slip his foot from his shoe and touch the arm of the Empress, who believed it to be one of her dead children. The observer stepped forward and revealed the fraud, and Home was conducted out of the country. "The order was to keep the incident secret."
In a series of experiments in London at the house of William Crookes in February 1875, Anna Eva Fay managed to fool Crookes into believing she had genuine psychic powers. Fay confessed in 1913 to Eric Dingwall that she had duped Crookes and other scientists. She was investigated by the magician Harry Houdini, to whom after her retirement in 1924 confessed fraud to and revealed the tricks she had used.
Frank Herne a British medium who formed a partnership with the medium Charles Williams was repeatedly exposed in fraudulent materialization séances. In 1875 he was caught by SPR members pretending to be a spirit during a séance in Liverpool and was found "clothed in about two yards of stiffened muslin, wound round his head and hanging down as far as his thigh." Florence Cook a medium Crookes supported had been "trained in the arts of the séance" by Herne and was repeatedly exposed as a fraudulent medium.
The British medium Francis Ward Monck was investigated by psychical researchers and discovered to be a fraud. On November 3, 1876 during the séance a sitter demanded that Monck be searched. Monck ran from the room, locked himself in another room and escaped out of a window. A pair of stuffed gloves was found in his room, as well as cheesecloth, reaching rods and other fraudulent devices in his luggage. After a trial Monck was convicted for his fraudulent mediumship and was sentenced to three months in prison. 
In 1876, William Eglinton was exposed as a fraud when the psychical researcher Thomas Colley seized a "spirit" materialization in his séance and cut off a portion of its cloak. It was discovered that the cut piece matched a cloth found in Eglinton's suitcase. Colley also pulled the beard off the materialization and it was revealed to be a fake, the same as another one found in the suitcase of Eglinton. In 1880 in a séance a spirit named "Yohlande" materialized, a sitter grabbed it and was revealed to be the medium Mme. d'Esperance herself.
Johann Karl Friedrich Zöllner, Professor of Physics and Astronomy at the University of Leipzig conducted several controlled experiments, using the medium Henry Slade, to evaluate his claims of paranormal ability in 1877. Slade failed some of the tests carried out under controlled conditions but still succeeded in fooling Zöllner in several other attempts. The SPR member Hereward Carrington in his book "The Physical Phenomena of Spiritualism" (1907) revealed the fraudulent methods (with diagrams of the rope tricks) that Slade used in the Zöllner experiments.
The Creery Sisters (Mary, Alice, Maud, Kathleen, and Emily) were tested in 1881 by the SPR members William F. Barrett, Frederic Myers, and Edmund Gurney who announced them to have genuine psychic ability. In 1888, the Creery sisters were caught utilizing signal codes and they confessed to fraud.
The medium William Eglinton performed slate writing mediumship and his leading critics were the psychical researchers Eleanor Sidgwick and Richard Hodgson. In 1886 and 1887 a series of publications by S. J. Davey, Hodgson and Sidgwick in the Journal of the Society for Psychical Research exposed the slate writing tricks of Eglinton.
The psychical researcher and SPR member Charles Richet with Oliver Lodge, Frederic Myers and Julian Ochorowicz investigated the medium Eusapia Palladino in the summer of 1894 at his house in the Ile Roubaud in the Mediterranean. Richet claimed furniture moved during the séance and that some of the phenomena was the result of a supernatural agency. However, Richard Hodgson claimed there was inadequate control during the séances and the precautions described did not rule out trickery. Hodgson wrote all the phenomena "described could be account for on the assumption that Eusapia could get a hand or foot free." Lodge, Myers and Richet disagreed, but Hodgson was later proven correct in the Cambridge sittings as Palladino was observed to have used tricks exactly the way he had described them.
In July 1895, Palladino was invited to England to Myers' house in Cambridge for a series of investigations into her mediumship. According to reports by the investigators Myers and Oliver Lodge, all the phenomena observed in the Cambridge sittings were the result of trickery. Her fraud was so clever, according to Myers, that it "must have needed long practice to bring it to its present level of skill." In the Cambridge sittings the results proved disastrous for her mediumship. During the séances Palladino was caught cheating in order to free herself from the physical controls of the experiments. Palladino was found liberating her hands by placing the hand of the controller on her left on top of the hand of the controller on her right. Instead of maintaining any contact with her, the observers on either side were found to be holding each other's hands and this made it possible for her to perform tricks. Richard Hodgson had observed Palladino free a hand to move objects and use her feet to kick pieces of furniture in the room. Because of the discovery of fraud, the British SPR investigators such as Henry Sidgwick and Frank Podmore considered Palladino's mediumship to be permanently discredited and because of her fraud she was banned from any further experiments with the SPR in Britain. 
In the "British Medical Journal" on November 9, 1895 an article was published titled "Exit Eusapia!". The article questioned the scientific legitimacy of the SPR for investigating Eusapia Palladino a medium who had a reputation of being a fraud and imposture. Part of the article read "It would be comic if it were not deplorable to picture this sorry Egeria surrounded by men like Professor Sidgwick, Professor Lodge, Mr. F. H. Myers, Dr. Schiaparelli, and Professor Richet, solemnly receiving her pinches and kicks, her finger skiddings, her sleight of hand with various articles of furniture as phenomena calling for serious study." This caused Henry Sidgwick to respond in a published letter to the "British Medical Journal", November 16, 1895. According to Sidgwick SPR members had exposed the fraud of Palladino at the Cambridge sittings, Sidgwick wrote "Throughout this period we have continually combated and exposed the frauds of professional mediums, and have never yet published in our Proceedings, any report in favour of the performances of any of them." The response from the Journal questioned why the SPR wastes time investigating phenomena that are the "result of jugglery and imposture" and not urgently concerning the welfare of mankind.
In 1898, Myers was invited to a series of séances in Paris with Charles Richet. In contrast to the previous séances in which he had observed fraud he claimed to have observed convincing phenomena. Sidgwick reminded Myers of Palladino's trickery in the previous investigations as "overwhelming" but Myers did not change his position. This enraged Richard Hodgson, then editor of SPR publications to ban Myers from publishing anything on his recent sittings with Palladino in the SPR journal. Hodgson was convinced Palladino was a fraud and supported Sidgwick in the "attempt to put that vulgar cheat Eusapia beyond the pale." It wasn't until the 1908 sittings in Naples that the SPR reopened the Palladino file.
In the late 19th century Douglas Blackburn and George Albert Smith were endorsed as genuine psychics by the Society for Psychical Research. Smith even became an SPR member himself and the private secretary to the Honorary Secretary Edmund Gurney from 1883 to 1888. However, Blackburn later confessed to fraud:
In 1905, Eva Carrière held a series of séances at Villa Carmen and sitters were invited. In these séances she claimed to materialize a spirit called Bien Boa a 300 year old Brahmin Hindu, however, photographs taken of Boa looked like the figure was made from a large cardboard cutout. In other sittings Charles Richet reported that Boa was breathing, had moved around the room and had touched him, a photograph taken revealed Boa to be a man dressed up in a cloak, helmet and beard. A newspaper article in 1906 had revealed that an Arab coachman known as Areski who had previously worked at the villa had been hired to play the part of Bien Boa and that the entire thing was a hoax. Areski wrote that he made his appearance into the room by a trapdoor. Carrière had also admitted to being involved with the hoax.
In 1906, William Hope tricked William Crookes (a past president of the SPR) with a fake spirit photograph of his wife. Oliver Lodge revealed there had been obvious signs of double exposure, the picture of Lady Crookes had been copied from a wedding anniversary photograph, however, Crookes was a convinced spiritualist and claimed it was genuine evidence for spirit photography. Lodge who served as president of the London-based Society for Psychical Research from 1901 to 1903 was also a spiritualist. Charles Arthur Mercier a specialist in insanity wrote in his book "Spiritualism and Sir Oliver Lodge" (1917) that Lodge had been duped into believing mediumship by trickery and his Spiritualist views were based on assumptions and not scientific evidence.
In 1908, the Society for Psychical Research appointed a committee of three to examine Palladino in Naples. The committee comprised Mr. Hereward Carrington, investigator for the American Society for Psychical Research and an amateur conjurer; Mr. W. W. Baggally, also an investigator and amateur conjurer of much experience; and the Hon. Everard Feilding, who had an extensive training as investigator and "a fairly complete education at the hands of fraudulent mediums." Three adjoining rooms on the fifth floor of the Hotel Victoria were rented. The middle room where Feilding slept was used in the evening for the séances. In the corner of the room was a séance cabinet created by a pair of black curtains to form an enclosed area that contained a small round table with several musical instruments. In front of the curtains was placed a wooden table. During the séances, Palladino would sit at this table with her back to the curtains. The investigators sat on either side of her, holding her hand and placing a foot on her foot. Guest visitors also attended some of the séances; the Feilding report mentions that Professor Bottazzi and Professor Galeotti were present at the fourth séance, and a Mr. Ryan was present at the eighth séance.
Although the investigators caught Palladino cheating, they were convinced Palladino produced genuine supernatural phenomena such as levitations of the table, movement of the curtains, movement of objects from behind the curtain and touches from hands. SPR member Frank Podmore in his book "The Newer Spiritualism" (1910) wrote a comprehensive critique of the Feilding report. According to Podmore the report provided insufficient information at crucial moments and the witness accounts from the investigators contained contradictions and inconsistencies on who was holding Palladino's feet and hands. Podmore discovered various statements by the investigators conflicted with each other on what they claimed to have observed. Some of the statements were also written days after the events took place. Podmore wrote the report "at almost every point leaves obvious loopholes for trickery." During the séances the long black curtains were often intermixed with Palladino's long black dress. Palladino told Professor Bottazzi the black curtains were "indispensable." Researchers have suspected Palladino used the curtain to conceal her feet.
The psychologist C. E. M. Hansel criticized the Feilding report based on the conditions of the séances being susceptible to trickery. Hansel noted that they were performed in semi-dark conditions, held in the late night or early morning introducing the possibility of fatigue and the "investigators had a strong belief in the supernatural, hence they would be emotionally involved."
In 1910, Everard Feilding returned to Naples, without Hereward Carrington and W. W. Baggally. Instead, he was accompanied by his friend, William S. Marriott, a magician of some distinction who had exposed psychic fraud in "Pearson's Magazine". His plan was to repeat the famous earlier 1908 Naple sittings with Palladino. Unlike the 1908 sittings which had baffled the investigators, this time Feilding and Marriott detected her cheating, just as she had done in the US. Her deceptions were obvious. Palladino evaded control and was caught moving objects with her foot, shaking the curtain with her hands, moving the cabinet table with her elbow and touching the séance sitters. Milbourne Christopher wrote regarding the exposure "when one knows how a feat can be done and what to look for, only the most skillful performer can maintain the illusion in the face of such informed scrutiny."
Eric Dingwall observed the medium Bert Reese in New York and claimed to have discovered his billet reading tricks. Richard Hodgson held six sittings with the medium Rosina Thompson and came to the conclusion she was a fraud as he discovered Thompson had access to documents and information about her séance sitters. The SPR member Edmund Fournier d'Albe investigated the medium Kathleen Goligher. On 22 July 1921 he observed Goligher moving the séance table with her foot. He also discovered her "ectoplasm" was made from muslin. During a séance d'Albe had observed white muslin between Goligher's feet.
In 1922, Eric Dingwall and Harry Price re-published an anonymous work written by a former medium entitled "Revelations of a Spirit Medium" which exposed the tricks of mediumship and the fraudulent methods of producing "spirit hands". Originally all the copies of the book were bought up by spiritualists and deliberately destroyed. In the same year Price, James Seymour, Dingwall and William Marriott exposed the fraud of the spirit photographer William Hope. Price wrote in his SPR report "William Hope has been found guilty of deliberately substituting his own plates for those of a sitter... It implies that the medium brings to the sitting a duplicate slide and faked plates for fraudulent purposes."
In 1925, SPR member Samuel Soal claimed to have taken part in a series of séances with the medium Blanche Cooper who contacted the spirit of a soldier Gordon Davis and revealed the house that he had lived in. Researchers later discovered fraud as the séances had taken place in 1922, not 1925. The magician and paranormal investigator Bob Couttie revealed that Davis was alive, Soal lived close to him and had altered the records of the sittings after checking out the house. Soal's co-workers knew that he had fiddled the results but were kept quiet with threats of libel suits.
In 1934, SPR members Oliver Gatty and Theodore Besterman examined the mediumship of Rudi Schneider and published a paper which concluded there is "no good evidence that Rudi Schneider possesses supernormal powers". According to the magician John Booth the stage mentalist David Devant managed to fool a number of people into believing he had genuine psychic ability who did not realize that his feats were magic tricks. At St. George's Hall, London he performed a fake "clairvoyant" act where he would read a message sealed inside an envelope. Oliver Lodge who was present in the audience was duped by the trick and claimed that Devant had used psychic powers. In 1936 Devant in his book "Secrets of My Magic" revealed the trick method he had used.
The Soal-Goldney experiment (1941-1943) on ESP was fraudulent as it was revealed Samuel Soal had altered and faked the data. Soal was originally accused of fraud by skeptics and scientists such as C. E. M. Hansel and George Price who proposed various ways that he could have cheated. Direct evidence of fraud came from SPR member Betty Marwick who discovered that Soal had not used the method of random selection of numbers as he had claimed. Marwick showed that there had been manipulation of the score sheets "all the experiments reported by Soal had thereby been discredited."
In 1954, the SPR member Rudolf Lambert published a report revealing details about a case of fraud that was covered up by many early members of the Institute Metapsychique International (IMI). Lambert who had studied Gustav Geley's files on the medium Eva Carrière discovered photographs depicting fraudulent ectoplasm taken by her companion Juliette Bisson. Various "materializations" were artificially attached to Eva's hair by wires. The discovery was never published by Geley. Eugene Osty (the director of the institute) and members Jean Meyer, Albert von Schrenck-Notzing and Charles Richet all knew about the fraudulent photographs but were firm believers in mediumship phenomena so demanded the scandal be kept secret.
In the early 1980s the SPR member Brian Inglis was involved in a dispute with the skeptic Ruth Brandon over the mediumship of Daniel Dunglas Home in the "New Scientist" magazine. In 1988, the magician Bob Couttie criticized Inglis for deliberately ignoring evidence of fraud in mediumship. Couttie wrote Inglis had not familiarized himself with magician techniques. The parapsychologist D. Scott Rogo complained that Inglis "had a bad habit in his writing of suppressing negative information about psychics and researchers he favored by failing to note cases of fraud that were uncovered."
In 1992, Richard Wiseman analyzed the Feilding report of Palladino and argued that she employed a secret accomplice that could enter the room by a fake door panel positioned near the séance cabinet. Wiseman discovered this trick was already mentioned in a book from 1851, he also visited a carpenter and skilled magician who constructed a door within an hour with a false panel. The accomplice was suspected to be her second husband, who insisted on bringing Palladino to the hotel where the séances took place. Paul Kurtz suggested that Carrington could have been Palladino's secret accomplice. Kurtz found it suspicious that he was raised as her manager after the séances in Naples. Carrington was also absent on the night of the last séance. However, Massimo Polidoro and Gian Marco Rinaldi who analyzed the Feilding report came to the conclusion that no secret accomplice was needed as Palladino during the 1908 Naples séances could have produced the phenomena by using her foot.
Reception.
Ivor Lloyd Tuckett wrote that even though the SPR have collected some valuable work, most of its active members have "no training in psychology fitting them for their task, and have been the victims of pronounced bias, as sometimes they themselves have admitted." Trevor Hall an ex-member of the Society for Psychical Research criticized SPR members as "credulous and obsessive wish... to believe." Hall also claimed SPR members "lack knowledge of deceptive methods."
Magicians and skeptics have criticized spiritualist SPR members such as William Crookes, Oliver Lodge and Cesare Lombroso for not educating themselves in conjurer tricks and being duped by fraudulent mediums. On this subject, Ivor Lloyd Tuckett wrote:
The fact of the matter is that scientific men, who are accustomed to accurate laboratory conditions and instruments, which do not lie or give rise to error — at any rate consciously are no match for the subtle degrees of deception practiced by media like Home, Moses and Eusapia.
Edward Clodd claimed the SPR members William F. Barrett and Oliver Lodge were incompetent researchers to detect fraud and wrote their spiritualist beliefs were based on magical thinking and primitive superstition. Clodd analyzed the SPR and saw nothing more than "barbaric spiritual philosophy", he mocked the language of SPR members "subliminal consciousness" and "telepathic energy" as a disguise for "bastard supernaturalism." The psychologist Millais Culpin noted that SPR members had not educated themselves about psychological factors.
The skeptic and physicist Victor J. Stenger wrote:
Investigations of mediums continued into the twentieth century, and the SPR and ASPR on occasion exposed blatant cases of fraud even their own credulous memberships could not swallow. But their journals have never succeeded in achieving a high level of credibility in the eyes of the rest of the scientific community. Today the psychical research journals continue as forums for believers to press their ideas, to respond to the attacks of skeptics, and to attack the skeptics in return. Nothing is wrong with that, as long as the editorial bias is admitted. The volumes occasionally contain some respectable studies, but most articles usually begin with the assumption that psychic phenomena are demonstrated realities. Since this is a belief and not an empirical fact, one might be justified in viewing the SPR and ASPR today as religious rather than scientific institutions.
The psychologist David Marks has written that paranormal researchers such as those in the SPR have failed to produce a single repeatable demonstration of the paranormal in over 100 years and described psychical research as a pseudoscience an "incoherent collection of belief systems steeped in fantasy, illusion and error." In 2003, James Alcock highlighted various problems with psychical research including failure to produce a single paranormal phenomenon that can be independently replicated by neutral researchers and lack of progress in over a century of formal research.
Psychological study.
A psychological study involving 174 members of the Society for Psychical Research completed a delusional ideation questionnaire and a deductive reasoning task. As predicted, the study showed that "individuals who reported a strong belief in the paranormal made more errors and displayed more delusional ideation than skeptical individuals". There was also a reasoning bias which was limited to people who reported a belief in, rather than experience of, paranormal phenomena. The results suggested that reasoning abnormalities may have a causal role in the formation of paranormal belief.
Presidents.
The following is a list of presidents:
Notable members.
Past notable members of the SPR included Henry Sidgwick, Eleanor Mildred Sidgwick, Frederic W. H. Myers, Frank Podmore, Eric Dingwall, Richard Hodgson, Edmund Gurney, Charles Lutwidge Dodgson, Alfred Russel Wallace, Sigmund Freud, W. B. Yeats, C. G. Jung, William James, Arthur Balfour, Archie Roy.
The author Arthur Conan Doyle joined the society in 1893, the year that Arthur Balfour was president of the SPR. Doyle later resigned.
Investigators of spontaneous phenomena (hauntings, etc.) have included Guy Lyon Playfair and Maurice Grosse, who investigated reports of the Enfield Poltergeist. and Tony Cornell who conducted extensive investigations over many decades.
Other societies.
A number of other psychical research organisations use the term 'Society for Psychical Research' in their name.

</doc>
