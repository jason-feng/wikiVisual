<doc id="37605" url="http://en.wikipedia.org/wiki?curid=37605" title="Norfolk">
Norfolk

Norfolk is a low-lying county in the East of England. It has borders with Lincolnshire to the west, Cambridgeshire to the west and southwest and Suffolk to the south. Its northern and eastern boundaries are the North Sea coast and to the north-west the county is bordered by the Wash. The city of Norwich is the county town of Norfolk which is the fifth largest ceremonial county in England, with an area of 5,371 km2.
Of the 34 non-metropolitan English counties, Norfolk is the seventh most populous, with a population of 859,400. However, as a largely rural county it has a low population density: 401 per square mile (or 155 people per square kilometre). Norfolk has about one-thirtieth the population density of central London, the tenth lowest density county in the country, with 40% of the county’s population living in the four major built up areas of Norwich (213,000), Great Yarmouth (63,000), King's Lynn (46,000) and Thetford (25,000). The Broads, a well known network of rivers and lakes, is located towards the county's east coast, extending south into Suffolk. The area has the status of a National Park and is protected by the Broads Authority. Historical sites, such as those in the centre of Norwich, also contribute to tourism.
History.
Norfolk was settled in pre-Roman times, with camps along the higher land in the west where flints could be quarried. A Brythonic tribe, the Iceni, inhabited the county from the 1st century BC to the end of the 1st century AD. The Iceni revolted against the Roman invasion in 47 AD, and again in 60 AD led by Boudica. The crushing of the second rebellion opened the county to the Romans. During the Roman era in Norfolk roads and ports were constructed throughout the county and farming took place.
Situated on the east coast, Norfolk was vulnerable to invasion from Scandinavia and Northern Europe, and forts were built to defend against the Angles and Saxons. By the 5th century the Angles, after whom East Anglia and England itself are named, had established control of the region and later became the "north folk" and the "south folk", hence, "Norfolk" and "Suffolk". Norfolk, Suffolk and several adjacent areas became the kingdom of East Anglia, which later merged with Mercia and then Wessex. The influence of the Early English settlers can be seen in the many place names ending in "-ton", and "-ham". Endings such as "-by" or "-thorpe" are also common, indicating Danish place names: in the 9th century the region again came under attack, this time from Danes who killed the king, Edmund the Martyr. In the centuries before the Norman Conquest the wetlands of the east of the county began to be converted to farmland, and settlements grew in these areas. Migration into East Anglia must have been high as by the time of the Conquest and Domesday Book survey it was one of the most densely populated parts of the British Isles. During the high and late Middle Ages the county developed arable agriculture and woollen industries. Norfolk's prosperity at that time is evident from the county's large number of mediaeval churches: of an original total of over one thousand, 659 survive, more than in the whole of the rest of Great Britain. The economy was in decline by the time of the Black Death, which dramatically reduced the population in 1349. Over one-third of the population of Norwich died during a plague epidemic in 1579. By the 16th century Norwich had grown to become the second largest city in England, but in 1665 the Great Plague again killed around one third of the population. During the English Civil War Norfolk was largely Parliamentarian. The economy and agriculture of the region declined somewhat. During the Industrial Revolution Norfolk developed little industry except in Norwich and was a late addition to the railway network.
In the 20th century the county developed a role in aviation. The first development in airfields came with the First World War; there was then a massive expansion during the Second World War with the growth of the Royal Air Force and the influx of the American USAAF 8th Air Force which operated from many Norfolk Airfields. During the Second World War agriculture rapidly intensified, and it has remained very intensive since with the establishment of large fields for growing cereals and oil seed rape.
Norfolk's low-lying land and easily eroded cliffs, many of which are chalk and clay, make it vulnerable to the sea, the most recent major event being the North Sea flood of 1953. The low-lying section of coast between Kelling and Lowestoft Ness in Suffolk is currently managed by the Environment Agency to protect the Broads from sea flooding. Management policy for the North Norfolk coastline is described in the North Norfolk Shoreline Management Plan which was published in 2006 but has yet to be accepted by the local authorities. The Shoreline Management Plan states that the stretch of coast will be protected for at least another 50 years, but that in the face of sea level rise and post-glacial lowering of land levels in the South East, there is an urgent need for further research to inform future management decisions, including the possibility that the sea defences may have to be realigned to a more sustainable position. Natural England have contributed some research into the impacts on the environment of various realignment options. The draft report of their research was leaked to the press, who created great anxiety by reporting that Natural England plan to abandon a large section of the Norfolk Broads, villages and farmland to the sea to save the rest of the Norfolk coastline from the impact of climate change.
Economy and industry.
In 1998 Norfolk had a Gross Domestic Product of £9,319 million, making it 1.5% of England's economy and 1.25% of the United Kingdom's economy. The GDP per head was £11,825, compared to £13,635 for East Anglia, £12,845 for England and £12,438 for the United Kingdom. In 1999–2000 the county had an unemployment rate of 5.6%, compared to 5.8% for England and 6.0% for the UK.
Important business sectors include tourism, energy (oil, gas and renewables), advanced engineering and manufacturing, and food and farming.
Much of Norfolk's fairly flat and fertile land has been drained for use as arable land. The principal arable crops are sugar beet, wheat, barley (for brewing) and oil seed rape. The county also boasts a saffron grower. Over 20% of employment in the county is in the agricultural and food industries.
Well-known companies in Norfolk are Aviva (formerly Norwich Union), Colman's (part of Unilever), Lotus Cars and Bernard Matthews Farms. The Construction Industry Training Board is based on the former airfield of RAF Bircham Newton. The BBC East region is centred on Norwich, although it covers an area as far west as Milton Keynes; the BBC does however provide BBC Radio Norfolk solely for the county.
 Local Enterprise Partnership has been recently established by business leaders to help grow jobs across Norfolk and Suffolk. They have secured an enterprise zone to help grow businesses in the energy sector and established the two counties as being a centre for growing services and products for the green economy.
To help local industry in Norwich, Norfolk, the local council offered a wireless internet service but this has now been withdrawn following the end of the funding period.
Education.
Primary and secondary education.
Norfolk has a completely comprehensive state education system, with secondary school age from 11 to 16 or in some schools with sixth forms, 18 years old. In many of the rural areas, there is no nearby sixth form and so sixth form colleges are found in larger towns. There are twelve independent, or private schools, including Gresham's School in Holt in the north of the county, Thetford Grammar School in Thetford which is Britain's fifth oldest extant school, Langley School in Loddon, and several in the city of Norwich itself, namely Norwich School and Norwich High School for Girls. The King's Lynn district has the largest school population. Norfolk is also home to Wymondham College, the UK's largest remaining state boarding school.
Tertiary education.
The University of East Anglia is located on the outskirts of Norwich and Norwich University of the Arts is based in seven buildings in and around St George's Street in the city centre, next to the River Wensum.
The City College Norwich and the College of West Anglia are colleges covering Norwich and King's Lynn as well as Norfolk as a whole. Easton College, 7 mi west of Norwich, provides agriculture-based courses for the county, parts of Suffolk and nationally.
University Campus Suffolk also run higher education courses in Norfolk, from multiple locations including Great Yarmouth College.
Politics.
Local.
Norfolk is under the control of Norfolk County Council and is also divided into seven local government districts, Breckland District, Broadland District, Great Yarmouth Borough, King's Lynn and West Norfolk Borough, North Norfolk District, Norwich City and South Norfolk District. As of 2014 the Conservatives control five of the six districts outside Norwich, while Norwich and Great Yarmouth are controlled by Labour.
The county is traditionally a stronghold for the Conservatives, who have always won at least 50% of Norfolk's constituencies since 1979. The countryside is mostly solid Conservative territory, with a few areas being strong for the Liberal Democrats. From 1995 to 2007, South Norfolk was run by the Liberal Democrats but the district switched back to the Conservatives in a landslide in 2007.
Norfolk's urban areas are more mixed, although Norwich and central parts of Great Yarmouth and King's Lynn are strong for the Labour Party. This said, Labour's dominance in Norwich has recently been stemmed by the Green Party, who are now the official opposition on Norwich City Council and also hold several divisions within the city on Norfolk County Council.
Norfolk County Council, which was under Conservative control since 1997, became under no overall control following the 2013 election which resulted in 20 seats being lost by the Conservatives and 14 gained by UKIP. There are currently 40 Conservative councillors, 15 UKIP, 14 Labour, 10 Liberal Democrats, 4 Green Party and one independent. Although it had been expected for the Conservatives to form a minority administration or seek a coalition with the Liberal Democrats, both scenarios failed to materialise. Eventually, a rainbow alliance between Labour, the Liberal Democrats, Greens and UKIP was formed, with the cabinet composed solely of Labour and Liberal Democrats.
Norwich Unitary Authority dispute.
In October 2006, the Department for Communities and Local Government produced a Local Government White Paper inviting councils to submit proposals for unitary restructuring. In January 2007 Norwich submitted its proposal, which was rejected in December 2007 as it did not meet the criteria for acceptance. In February 2008, the Boundary Committee for England (from 1 April 2010 incorporated in the Local Government Boundary Commission for England) was asked to consider alternative proposals for the whole or part of Norfolk, including whether Norwich should become a unitary authority, separate from Norfolk County Council. In December 2009, the Boundary Committee recommended a single unitary authority covering all of Norfolk, including Norwich.
However, on 10 February 2010, it was announced that, contrary to the December 2009 recommendation of the Boundary Committee, Norwich would be given separate unitary status. The proposed change was strongly resisted, principally by Norfolk County Council and the Conservative opposition in Parliament. Reacting to the announcement, Norfolk County Council issued a statement that it would seek leave to challenge the decision in the courts. A letter was leaked to the local media in which the Permanent Secretary for the Department for Communities and Local Government noted that the decision did not meet all the criteria and that the risk of it "being successfully challenged in judicial review proceedings is very high". The Shadow Local Government and Planning Minister, Bob Neill, stated that should the Conservative Party win the 2010 general election, they would reverse the decision.
Following the 2010 general election, Eric Pickles was appointed Secretary of State for Communities and Local Government on 12 May 2010 in a Conservative–Liberal Democrat coalition government. According to press reports, he instructed his department to take urgent steps to reverse the decision and maintain the status quo in line with the Conservative Party manifesto. However, the unitary plans were supported by the Liberal Democrat group on the city council, and by Simon Wright, LibDem MP for Norwich South, who intended to lobby the party leadership to allow the changes to go ahead.
The Local Government Act 2010 to reverse the unitary decision for Norwich (and Exeter and Suffolk) received Royal Assent on 16 December 2010. The disputed award of unitary status had meanwhile been referred to the High Court, and on 21 June 2010 the court (Mr. Justice Ouseley, judge) ruled it unlawful, and revoked it. The city has therefore failed to attain permanent unitary status, and the previous two-tier arrangement of County and District Councils (with Norwich City Council counted among the latter) remains the status quo.
Westminster.
Following the May 2015 General Election, Norfolk is represented in the House of Commons by seven Conservative Members of Parliament, one Labour Member of Parliament and one Liberal Democrat. 
[1] Green, LCA, Independents, Others
[2] UKIP, LCA, Independents, Others
Settlements.
Norfolk's county town and only city is Norwich, one of the largest settlements in England during the Norman era. Norwich is home to the University of East Anglia, and is the county's main business and culture centre. Other principal towns include the port-town of King's Lynn and the seaside resort and Broads gateway town of Great Yarmouth.
Based on the 2011 Census the county's largest centres of population are:
Norwich (213,166),
Great Yarmouth (63,434),
Kings Lynn (46,093),
Thetford (24,883),
Dereham (20,651),
Wymondham (13,587),
North Walsham (12,463),
Attleborough (10,549),
Downham Market (9,994),
Diss (9,829),
Fakenham (8,285),
Cromer (7,749),
Sheringham (7,367)
and Swaffham (7,258).
There are also several smaller market towns: Aylsham (6,016), Harleston (4,458) and Holt (3,810).
Transport.
Norfolk is one of the few counties in England that does not have a motorway. The A11 connects Norfolk to Cambridge and London via the M11. From the west there only two routes from Norfolk that have a direct link with the A1, the A47 which runs into the East Midlands and to Birmingham via Peterborough and the A17 which runs into the East Midlands via Lincolnshire. These two routes meet at King's Lynn which is also the starting place for the A10 which provides West Norfolk with a direct link to London via Ely, Cambridge and Hertford . The Great Eastern Main Line is a major railway from London Liverpool Street Station to Essex, Suffolk and Norfolk. Norwich International Airport, offers flights within Europe including a link to Amsterdam which offers onward flights throughout the world.
Dialect, accent and nickname.
The Norfolk dialect is also known as "Broad Norfolk", although over the modern age much of the vocabulary and many of the phrases have died out due to a number of factors, such as radio, TV and people from other parts of the country coming to Norfolk. As a result, the speech of Norfolk is more of an accent than a dialect, though one part retained from the Norfolk dialect is the distinctive grammar of the region. 
People from Norfolk are sometimes known as Norfolk Dumplings, an allusion to the flour dumplings that were traditionally a significant part of the local diet.
More cutting, perhaps, was the pejorative medical slang term "Normal for Norfolk", alluding to the county's perceived status as an illiterate incestuous backwater. The term has never been official, and is now discredited, its use discouraged by the profession.
Tourism.
Norfolk is a popular tourist destination and has several major examples of holiday attractions. There are many seaside resorts, including some of the finest British beaches, such as those at Great Yarmouth, Cromer and Holkham. Norfolk contains the Broads and other areas of outstanding natural beauty and many areas of the coast are wild bird sanctuaries and reserves with some areas designated as National Parks such as the Norfolk Coast AONB. Great Yarmouth has in recent years been the centre of significant investment in wind technology.
The Queen's residence at Sandringham House in Sandringham, Norfolk provides an all year round tourist attraction whilst the coast and some rural areas are popular locations for people from the conurbations to purchase weekend holiday homes. Arthur Conan Doyle first conceived the idea for The Hound Of The Baskervilles whilst holidaying in Cromer with Bertram Fletcher Robinson after hearing local folklore tales regarding the mysterious hound known as Black Shuck.
Amusement parks and zoos.
Norfolk has several amusement parks and zoos.
Theatres.
The Pavilion Theatre (Cromer) is a 510-seater venue perched on the end of Cromer Pier, best known for hosting the famous' end-of-the-pier' show, the Seaside Special. The theatre also presents a high-quality mix of comedy, music, dance, opera, musicals and community shows.
The Britannia Pier Theatre (Great Yarmouth) hosts mainly popular comedy acts such as the Chuckle Brothers and Jim Davidson. The theatre has 1,200 seats and is one of the largest in Norfolk.
The Theatre Royal (Norwich) has been on its present site for nearly 250 years, the Act of Parliament in the tenth year of the reign of George II having been rescinded in 1761. The 1,300-seat theatre, the largest in the city, hosts a mix of national touring productions including musicals, dance, drama, family shows, stand-up comedians, opera and pop.
The Norwich Playhouse (Norwich) is a venue in the heart of the city for theatre, comedy, music and other performing arts. It has a seating capacity of 300.
The Maddermarket Theatre (Norwich) opened in 1921 and was the first permanent recreation of an Elizabethan theatre. The founder was Nugent Monck who had worked with William Poel. The theatre is a world class Shakespearean style playhouse and has a seating capacity of 310.
The Norwich Puppet Theatre (Norwich) was founded in 1979 by Ray and Joan DaSilva as a permanent base for their touring company and was first opened as a public venue in 1980, following the conversion of the medieval church of St. James in the heart of Norwich. Under subsequent artistic directors – Barry Smith and Luis Z. Boy – the theatre established its current pattern of operation. It is a nationally unique venue dedicated to puppetry, and currently houses a 185-seat raked auditorium, 50 seat Octagon Studio, workshops, an exhibition gallery, shop and licensed bar. It is the only theatre in the Eastern region with a year-round programme of family-centred entertainment.
The Garage studio theatre (Norwich) can seat up to 110 people in a range of different layouts. It can also be used for standing events and can accommodate up to 180 people. The high specification of equipment and design means that it is particularly versatile, and can be adapted to a variety of layouts offering a wide choice for performances or events.
The Platform Theatre (Norwich) is in the grounds of (CCN), and has a large stage with raked seating for an audience of around 200. The theatre plays host to a diverse range of performances by both student and professional companies.
The Sewell Barn Theatre (Norwich) is the smallest theatre in Norwich and has a seating capacity of just 100. The auditorium features raked seating on three sides of an open acting space. This unusual staging helps to draw the audience deeply into the performance.
The Norwich Arts Centre (Norwich) theatre opened in 1977 in St. Benedict's Street, and has a capacity of 290.
The Princess Theatre (Hunstanton) stands overlooking the Wash and green in the busy East Coast resort of Hunstanton. The Princess Theatre is a 472-seat venue dubbed as one of the friendliest theatres in the country by artists who have performed there. Open all year round, the theatre plays host to a wide variety of shows from comedy to drama, celebrity shows to music for all tastes and children's productions. The venue also has a six-week summer season plus an annual Christmas pantomime.
Sheringham Little Theatre (Sheringham) provides intimate and comfortable seating for 180. The theatre programmes a wide variety of plays, musicals, music and also shows films.
The Gorleston Pavilion (Gorleston) is an original Edwardian building with a seating capacity of 300, situated on the Norfolk coast. The theatre stages plays, pantomimes, musicals, concerts as well as the popular 26 week summer season.
People associated with Norfolk.
The following people were not born or brought up in Norfolk but are long-term residents of Norfolk, are well known for living in Norfolk at some point in their lives, or have contributed in some significant way to the county.

</doc>
<doc id="37608" url="http://en.wikipedia.org/wiki?curid=37608" title="Putamen">
Putamen

The putamen is a round structure located at the base of the forebrain (telencephalon). The putamen and caudate nucleus together form the dorsal striatum. It is also one of the structures that comprises the basal ganglia. Through various pathways, the putamen is connected to the substantia nigra and globus pallidus. The main function of the putamen is to regulate movements and influence various types of learning. It employs GABA, acetylcholine, and enkephalin to perform its functions. The putamen also plays a role in degenerative neurological disorders, such as Parkinson's disease.
History.
The word "putamen" is from Latin, referring to that which "falls off in pruning", from "putare", meaning "to prune, to think, or to consider". It is pronounced "pyu-ta'men".
Until recently, very few studies were conducted that were focused specifically on the putamen. However, many studies have been done on the basal ganglia and the interactions among the brain structures it comprises. In the 1970s, the first single unit recordings were done with monkeys monitoring pallidal neuron activity related to movement.
Anatomy.
The putamen is a structure in the forebrain. Along with the caudate nucleus it forms the dorsal striatum. The caudate and putamen contain the same types of neurons and circuits - many neuroanatomists consider the dorsal striatum to be a single structure, divided into two parts by a large fiber tract, the internal capsule, passing through the middle. The putamen, together with the globus pallidus, makes up the lenticular nucleus. The putamen is the outer most portion of the basal ganglia. These are a group of nuclei in the brain that are interconnected with the cerebral cortex, thalamus, and brain stem. Basal ganglia include the dorsal striatum, substantia nigra, nucleus accumbens, and the subthalamic nucleus.
In mammals, the basal ganglia are associated with motor control, cognition, emotions, and learning. The basal ganglia are located on the left and right sides of the brain, and have rostral and caudal divisions. The putamen is located in the rostral division as part of the striatum. The basal ganglia receive input from the cerebral cortex, via the striatum.
The putamen is interconnected with the following structures:
Caudate Nucleus.
The caudate works with the putamen to receive the input from cerebral cortex. They can be considered the "entrance" to the basal ganglia. The nucleus accumbens and medial caudate receive input from frontal cortex and limbic regions. The putamen and caudate are jointly connected with the substantia nigra, but most of their output goes to the globus pallidus.
Substantia Nigra.
The substantia nigra contains two parts: the substantia nigra pars compacta (SNpc) and the substantia nigra pars reticulata (SNpr). The SNpc obtains input from the putamen and caudate, and sends information back. The SNpr also obtains input from the putamen and caudate. However, it sends the input outside the basal ganglia to control head and eye movements. The SNpc produces dopamine, which is crucial for movements. The SNpc is the part that degenerates during Parkinson's disease.
Globus Pallidus.
The globus pallidus contains two parts: the globus pallidus pars externa (GPe) and the globus pallidus pars interna (GPi). Both regions acquire input from the putamen and caudate and communicate with the subthalamic nucleus. However, mostly the GPi sends the inhibitory output from the basal ganglia to the thalamus. The GPi also sends a few projections to parts of the midbrain, which have been assumed to affect posture control.
Physiology.
Types of Pathways.
In order to control movement, the putamen must interact with the other structures that make up the basal ganglia. These include the caudate nucleus and globus pallidus. These two structures, along with the putamen, interact through a series of direct and indirect inhibitory pathways. The direct pathway consists of two inhibitory pathways from the putamen to the substantia nigra and the internal region of the globus pallidus. This pathway uses the neurotransmitters dopamine, GABA and substance P. The indirect pathway consists of three inhibitory pathways that go from the putamen and caudate nucleus to the external region of the globus pallidus. This pathway uses dopamine, GABA and enkephalin. When there is interplay between the direct and indirect pathways, involuntary movements occur.
Dopamine.
One of the main neurotransmitters that is regulated by the putamen is dopamine. When a cell body of a neuron (in the putamen or caudate nuclei) fires an action potential, dopamine is released from the presynaptic terminal. Since projections from the putamen and caudate nuclei modulate the dendrites of the substantia nigra, the dopamine influences the substantia nigra, which affects motor planning. This same mechanism is involved in drug addiction. In order to control the amount of dopamine in the synaptic cleft, and the amount of dopamine binding to post synaptic terminals, presynaptic dopaminergic neurons function to reuptake the excess dopamine.
Other Neurotransmitters.
The putamen also plays a role in modulation of other neurotransmitters. It releases GABA, enkephalin, substance P, and acetylcholine. It receives serotonin and glutamate. The majority of these neurotransmitters play a role in motor control.
Function: Motor Skills.
While the putamen has many functions, it has been concluded that it has no specific specialization. However, since the putamen is interconnected with so many other structures, it works in conjunction with them to control many types of motor skills. These include controlling motor learning, motor performance and tasks, motor preparation, specifying amplitudes of movement, and movement sequences.
Some neurologists hypothesize that the putamen also plays a role in the selection of movement (e.g. Tourette Syndrome) and the "automatic" performance of previously learned movements (e.g. Parkinson's disease).
In one study it was found that the putamen controls limb movement. The goal of this study was to determine whether particular cell activity in the putamen of primates was related to the direction of limb movement or to the underlying pattern of muscular activity. Two monkeys were trained to perform tasks that involved the movement of loads. The tasks were created so that movement could be distinguished from muscle activity. Neurons in the putamen were selected for monitoring only if they were related both to the task and to arm movements outside the task. It was shown that 50% of the neurons that were monitored were related to the direction of movement, independent of the load.
Another study was done to investigate movement extent and speed using PET mapping of regional cerebral blood flow in 13 humans. Movement tasks were performed with a joystick-controlled cursor. Statistical tests were done to calculate the extent of movements and what regions of the brain the movements correlate to. It was found that "increasing movement extent was associated with parallel increases of rCBF in bilateral basal ganglia (BG; putamen and globus pallidus) and ipsilateral cerebellum." This not only shows that the putamen affects movement but it also shows that the putamen integrates with other structures in order to perform tasks.
One study was done in order to specifically investigate how the basal ganglia influences the learning of sequential movements. Two monkeys were trained to press a series of buttons in sequence. The methods used were designed to be able to monitor the well-learned tasks versus the new tasks. Muscimol was injected into various parts of the basal ganglia, and it was found that "the learning of new sequences became deficient after injections in the anterior caudate and putamen, but not the middle-posterior putamen." This shows that different areas of the striatum are utilized when performing various aspects of the learning of sequential movements
Role in learning.
In many studies, it has become apparent that the putamen plays a role in many types of learning. Some examples are listed below:
Reinforcement and implicit learning.
Along with various types of movement, the putamen also affects reinforcement learning and implicit learning.
Reinforcement learning is interacting with the environment and catering actions to maximize the outcome. Implicit learning is a passive process where people are exposed to information and acquire knowledge through exposure. Although the exact mechanisms are not known, it is clear that dopamine and tonically active neurons play a key role here. Tonically active neurons are cholinergic interneurons that fire during the entire duration of the stimulus and fire at about 0.5-3 impulses per second. Phasic neurons are the opposite and only fire an action potential when movement occurs.
Category Learning.
One particular study used patients with focal lesions on the basal ganglia (specifically the putamen) due to stroke in order to study category learning. The advantage to using these types of patients is that dopaminergic projections to the prefrontal cortex are more likely to be intact. Also, in these patients, it is easier to relate specific brain structures to function because the lesion only occurs in a specific place. The goal of this study was to determine whether or not these lesions affect rule-based and information-integration task learning. Rule-based tasks are learned via hypothesis-testing dependent on working memory. Information-integration tasks are ones wherein the accuracy is maximized when information from two sources are integrated at a pre-decisional stage, which follows a procedural-based system.
Seven participants with basal ganglia lesions were used in the experiment, along with nine control participants. It is important to note that the caudate was not affected. The participants were tested for each type of learning during separate sessions, so the information processes would not interfere with each other. During each session, participants sat in front of a computer screen and various lines were displayed. These lines were created by using a randomization technique where random samples were taken from one of four categories. For ruled-based testing, these samples were used to construct lines of various length and orientation that fell into these four separate categories. After the stimulus was displayed, the subjects were asked to press 1 of 4 buttons to indicate which category the line fell into. The same process was repeated for information-integration tasks, and the same stimuli were used, except that the category boundaries were rotated 45°. This rotation causes the subject to integrate the quantitative information about the line before determining what category it is in.
It was found that subjects in the experimental group were impaired while performing rule-based tasks, but not information-integration ones. After statistical testing, it was also hypothesized that the brain began using information-integration techniques to solve the rule-based learning tasks. Since rule-based tasks use the hypothesis-testing system of the brain, it can be concluded that the hypothesis-testing system of the brain was damaged/weakened. It is known that the caudate and working memories are part of this system. Therefore, it was confirmed that the putamen is involved category learning, competition between the systems, feed-back processing in rule-based tasks, and is involved in the processing of pre-frontal regions (which relate to working memory and executive functioning). Now it is known that not only the basal ganglia and caudate affect category learning.
Role in "hate circuit".
Recent, tentative studies have suggested that the putamen may play a role in the so-called "hate circuit" of the brain. A recent study was done in London by the department of cell and developmental biology at University College London. An fMRI was done on patients while they viewed a picture of people they hated and people who were "neutral". During the experiment, a "hate score" was recorded for each picture. The activity in sub-cortical areas of the brain implied that the "hate circuit" involves the putamen and the insula. It has been theorized that the "putamen plays a role in the perception of contempt and disgust, and may be part of the motor system that's mobilized to take action." It was also found that the amount of activity in the hate circuit correlates with the amount of hate a person declares, which could have legal implications concerning malicious crimes.
Role in Transgender Individuals.
The putamen was found to have significantly larger amounts of grey matter in male to female transgender individuals compared to the putamen of a typical cisgender male. This possibly suggests that a fundamental difference in brain composition may exist between Trans women and cismen.
Pathology.
Parkinson's disease.
After discovering the function of the putamen, it has become apparent to neurologists that the putamen and basal ganglia play an important role in Parkinson's disease and other diseases that involve the degeneration of neurons.
Parkinson's disease is the slow and steady loss of dopaminergic neurons in substantia nigra pars compacta. In Parkinson's disease the putamen plays a key role because its inputs and outputs are interconnected to the substantia nigra and the globus pallidus. In Parkinson's disease the activity in direct pathways to interior globus pallidus decreases and activity in indirect pathways to external globus pallidus increases. Together these actions cause excessive inhibition of the thalamus. This is why Parkinson’s patients have tremors and have trouble performing voluntary movements. It has also been noted that Parkinson’s patients have a difficult time with motor planning. They must think about everything they do and cannot perform instinctive tasks without focusing on what they are doing.
Other diseases and disorders.
The following diseases and disorders are linked with the putamen:
In other animals.
The putamen in humans is similar in structure and function to other animals. Therefore, many studies on the putamen have been done on animals (monkeys, rats, etc.), as well as humans.

</doc>
<doc id="37609" url="http://en.wikipedia.org/wiki?curid=37609" title="Striatum">
Striatum

The striatum, also known as the neostriatum or striate nucleus, is a subcortical part of the forebrain. It receives input from the cerebral cortex and is the primary input to the basal ganglia system. In all primates, the striatum is divided by a white matter tract called the internal capsule into two sectors called the caudate nucleus and the putamen. The lenticular nucleus refers to the putamen together with the globus pallidus.
Functionally, the striatum helps coordinate motivation with body movement. Body movements can be as simple as controlling fine-motor functions, or as complex as inhibiting one's behavior depending upon social interactions.
Structure.
Cell types.
The striatum is heterogeneous in terms of its component neurons.
Adult humans continuously produce new neurons in the striatum, and these neurons could play a possible role in new treatments for neurodegenerative disorders.
Anatomical subdivisions.
The observable anatomical subdivisions of the dorsal striatum (caudate nucleus and putamen), in essence induced by the internal capsule, do not completely overlap with now-accepted anatomo-functional subdivisions. The selective distribution of the axonal terminal arborisations of cortical sources differentiate the sensorimotor striatum, mainly putaminal but located in its dorsal part and in the lateroinferior part of the caudate. A great part of the remaining volume (in essence, caudate) receives axonal endings from the frontal, parietal, and temporal cortex, forming the associative striatum. The separation between these two territories is rather clearcut and observable using calbindin immunochemistry. A third entity, the most inferomedial, raises more problems, as there is no general agreement about its border with the associative striatum.
The striatum can also be differentiated based on immunochemical characteristics—in particular with regard to acetylcholinesterase and calbindin —into "compartments", consisting of "striosomes" and the surrounding "matrix" (See figure "Matrix and Striosome Compartments").
Inputs (afferent connections).
The most important afferent in terms of quantity of axons is the corticostriatal connection. Many parts of the neocortex innervate the dorsal striatum. The cortical pyramidal neurons projecting to the striatum are located in layers II-VI, but the most dense projections come from layer V. They end mainly on the spines of the spiny neurons. They are glutamatergic, exciting striatal neurons.
Another well-known afferent is the nigrostriatal connection arising from the neurons of the substantia nigra pars compacta. While cortical axons synapse mainly on spine heads of spiny neurons, nigral axons synapse mainly on spine shafts.
In primates, the thalamostriatal afferent comes from the central median-parafascicular complex of the thalamus (see primate basal ganglia system). This afferent is glutamatergic. The participation of truly intralaminar neurons is much more limited.
The striatum also receives afferents from other elements of the basal ganglia such as the subthalamic nucleus (glutamatergic) or the external globus pallidus (GABAergic).
Targets (efferent connections).
The basal ganglia core is made up of the striatum along with the regions to which it projects directly, via the striato-pallidonigral bundle. The striato-pallidonigral bundle is a very dense bundle of sparsely myelinated axons, giving a whitish appearance. This projection comprises successively the external globus pallidus (GPe), the internal globus pallidus (GPi), the pars compacta of the substantia nigra (SNc), and the pars reticulata of substantia nigra (SNr). The neurons of this projection are inhibited by GABAergic synapses from the dorsal striatum. Among these targets, the GPe does not send axons outside the system. Others send axons to the superior colliculus. Two others comprise the output to the thalamus, forming two separate channels: one through the internal segment of the globus pallidus to the ventral oralis nuclei of the thalamus and from there to the cortical supplementary motor area (SMA) and another through the substantia nigra to the ventral anterior nuclei of the thalamus and from there to the frontal cortex and the oculomotor cortex.
Function.
The striatum is best known for its role in the planning and modulation of movement pathways, but is also potentially involved in a variety of other cognitive processes involving executive function, such as working memory.
Metabotropic dopamine receptors are present both on spiny neurons and on cortical axon terminals. Second messenger cascades triggered by activation of these dopamine receptors can modulate pre- and postsynaptic function, both in the short term and in the long term. In humans, the striatum is activated by stimuli associated with reward, but also by aversive, novel, unexpected, or intense stimuli, and cues associated with such events. fMRI evidence suggests that the common property linking these stimuli, to which the striatum is reacting, is salience under the conditions of presentation. A number of other brain areas and circuits are also related to reward, such as frontal areas. The striatum is also associated with novelty-related decision-making behaviors. Functional maps of the striatum reveal interactions with widely distributed regions of the cerebral cortex important to a diverse range of functions.
The ventral tegmental dopaminergic neurons that innervate portions of the striatum are the primary site of rewarding feeling. Intracranial stimulation studies first done by James Olds and collaborators in the 1950s showed that implants in this brain area will elicit bar pressing from rats for many hours at a time. Interference with dopamine neurotransmission impairs behavioral reward processes and their underlying neuronal mechanisms.
Clinical significance.
Parkinson's disease.
Parkinson's disease results in loss of dopaminergic innervation to the striatum (and other basal ganglia) and a cascade of subsequent consequences. Atrophy of the striatum is also involved in Huntington's disease, choreas, choreoathetosis, and dyskinesias. It is also thought that addiction involves plasticity at striatal synapses.
Bipolar disorder.
There is an association between striatal expression of the PDE10A gene and some bipolar disorder I patients.
History.
In the seventeenth and eighteenth centuries, the term "corpus striatum" was used to designate many distinct, deep, infracortical elements of the hemisphere. In 1941, Cécile and Oskar Vogt simplified the nomenclature by proposing the term striatum for all elements built with striatal elements (see primate basal ganglia system): the caudate, the putamen, and the fundus striati, that ventral part linking the two preceding together ventrally to the inferior part of the internal capsule.
The term "neostriatum" was forged by comparative anatomists comparing the subcortical structures between vertebrates, because it was thought to be a phylogenetically newer section of the corpus striatum. The term is still used by some sources, including Medical Subject Headings.

</doc>
<doc id="37612" url="http://en.wikipedia.org/wiki?curid=37612" title="Voicelessness">
Voicelessness

In linguistics, voicelessness is the property of sounds being pronounced without the larynx vibrating. Phonologically, this is a type of phonation, which contrasts with other states of the larynx, but some object that the word "phonation" implies voicing, and that voicelessness is the "lack" of phonation.
The International Phonetic Alphabet has distinct letters for many voiceless and modally voiced pairs of consonants (the obstruents), such as [p b], [t d], [k ɡ], [q ɢ], [f v], and [s z]. In addition, there are diacritics for voicelessness, and , which is used for letters with a descender. Diacritics are typically used with letters for prototypically voiced sounds, such as vowels and sonorant consonants: [ḁ], [l̥], [ŋ̊].
Voiceless vowels and other sonorants.
Sonorants are those sounds, such as vowels and nasals, that are voiced in most of the world's languages. However, in some languages sonorants may be voiceless, usually allophonically. For example, the Japanese word "sukiyaki" is pronounced [su̥ciɐci]. This may sound like [sciɐci] to an English speaker, but the lips can be seen compressing for the [u̥]. Something similar happens in English with words like "peculiar" [pʰə̥ˈkʰjuːliɚ] and "potato" [pʰə̥ˈtʰeɪtoʊ].
Sonorants may also be contrastively voiceless, not just voiceless due to their environment. Standard Tibetan, for example, has a voiceless /l̥/ in "Lhasa," which sounds similar to, but is not as noisy as, the voiceless lateral fricative /ɬ/ in Welsh, and which contrasts with a modally voiced /l/. Welsh contrasts several voiceless sonorants: /m, m̥/, /n, n̥/, /ŋ, ŋ̊/, and /r, r̥/, the latter represented by "rh".
In the Moksha language there is even a voiceless palatal approximant /j̊/ (written in Cyrillic as <йх> "jh") along with /l̥/ and /r̥/ (written as <лх> "lh" and <рх> "rh"). The last two have palatalized counterparts /l̥ʲ/ and /r̥ʲ/ (<льх> and <рьх>). In the Kildin Sami language there is also /j̊/ <ҋ>.
On the other hand, although contrastively voiceless vowels have been reported several times, they have never been verified (L&M 1996:315).
Lack of voicing contrast in obstruents.
Many languages lack a distinction between voiced and voiceless obstruents (stops, affricates, and fricatives). This is nearly universal in Dravidian languages and Australian languages, but is widely found elsewhere, for example in Mandarin Chinese, Korean, Finnish, and the Polynesian languages. Consider Hawaiian, which has a /p/ and /k/, but no /b/ or /ɡ/. In many such languages, obstruents are realized as voiced in voiced environments, such as between vowels or between a vowel and a nasal, and voiceless elsewhere, such as at the beginning or end of the word or next to another obstruent. This is the case in Dravidian and Australian languages and Korean, but not in Mandarin or Polynesian. Usually, these variable sounds are transcribed with the voiceless IPA letters, though in Australia the letters for voiced consonants are often used.
It appears that voicelessness is not a single phenomenon in such languages. In some, such as the Polynesian languages, the vocal cords are required to actively open to allow an unimpeded (silent) airstream. This is sometimes called a "breathed" (/ˈbrɛθt/) phonation (not to be confused with breathy voice). In others, such as many Australian languages, voicing ceases during the hold of a stop (few Australian languages have any other kind of obstruent) because airflow is insufficient to sustain it, and if the vocal cords open this is due to passive relaxation. Correspondingly, Polynesian stops are reported to be held for longer than Australian stops, and are seldom voiced, whereas Australian stops are prone to having voiced variants (L&M 1996:53), and the languages are often represented as having no phonemically voiceless consonants at all. In Southeast Asia, when stops occur at the end of a word they are voiceless because the glottis is closed, not open, and so these are said to be unphonated (have no phonation) by some phoneticians who considered "breathed" voicelessness to be a phonation.
Yidiny consonants, with no underlyingly voiceless consonants posited.

</doc>
<doc id="37613" url="http://en.wikipedia.org/wiki?curid=37613" title="BBC World News">
BBC World News

BBC World News is the BBC's international news and current affairs television channel. It has the largest audience of any BBC channel, with an estimated 76 million viewers weekly in 2014. Launched on 11 March 1991 as BBC World Service Television outside Europe, its name was changed to BBC World on 16 January 1995 and to BBC World News on 21 April 2008. It broadcasts television programming including BBC News bulletins, documentaries, lifestyle programmes and interviews. It employs more correspondents and reporters and has more international bureaux than any other news channel. Unlike the BBC's domestic channels, BBC World News is owned and operated by BBC Global News Ltd., part of the BBC's commercial group of companies and is funded by subscription and advertising revenues, and not by the United Kingdom television licence. It is not owned by BBC Worldwide.
History.
The channel originally launched as BBC World Service Television, though unlike BBC World Service radio which has always been government funded, the British government refused to extend the Foreign Office grant-in-aid. It was launched on 11 March 1991, after two weeks of real-time pilots, initially as a half-hour bulletin once a day at 19:00 GMT. The programme editor was Johan "John" Ramsland from World Service Radio News with John Exelby from domestic BBC TV News as his managing editor. The original picture editing team consisted of Bob Scholes, Peter Hodge and Mike Casey.
On Thursday, 26 January 1995 at 19:00 GMT, BBC World Service Television was split into 2-television stations:
Since 1995, the service has gone through several branding changes. From 1995 to 1997, the channel used relatively few graphics to display the name of the channel, with the studio modelled on that used for BBC News in the United Kingdom.
As part of a major BBC corporate redesign (which included a new logo for the corporation on 4 October 1997) the channel received its first main refresh on 9 November 1997, the day BBC News 24 was launched. Various fictional flags with some real ones were used. The idents were computer generated and developed by the Lambie-Nairn design agency.
Another large relaunch for BBC World took place on 3 April 2000, which brought it in line with the BBC's UK news channel which was relaunched in 1999. The new uniform look was made up of red and cream designed by Lambie-Nairn, with music based on a style described as 'drums and beeps' composed by David Lowe, a departure from the general orchestral versions of other news programmes.
On 8 December 2003 a second makeover, using the same 'drums and beeps' style music but new graphics took place, although on a much smaller scale to that of 1999. The music was changed slightly while the main colour scheme became black and red, with studios using frosted glass, white and red colours. Later in 2004, the channel's slogan became "Putting News First", replacing "Demand a Broader View". The graphical refresh introduced in 2003 was refreshed in May 2006 with a more red output. In 22 January 2007 a new refresh was presented based on the previous graphics, a red coloured labels covering a red and black earthglobe along with the BBC World logo.
The channel's present name was introduced on 21 April 2008 as part of a £550,000 rebranding of the BBC's news output and visual identity. BBC World News later moved to the renovated former studio of BBC News 24 (now BBC News). New graphics were produced by the Lambie-Nairn design agency and music reworked by David Lowe.
Move to Broadcasting House.
BBC World News relocated to Broadcasting House from its previous home at BBC Television Centre on 14 January 2013. This is a part of the move of BBC News and other audio and vision departments of the BBC into one building in Central London. Broadcasting House was refurbished at a cost of £1 billion with a new newsroom and several state-of-the-art news television studios being built.
Broadcasting.
Live news output originates from studios B and C in Broadcasting House with some recorded programming from Broadcasting House studio A and the BBC Millbank studio. The BBC World News newsroom is now part of the new consolidated BBC Newsroom in Broadcasting House along with BBC World Service and UK domestic News services.
Previously, the channel was broadcast in 4:3, with the news output fitted into a frame for both digital and analogue broadcasting, resulting in black bands at the top and bottom of the screen. On 13 January 2009 at 09:57 GMT, BBC World News switched its broadcast to format, initially in Europe on Astra 1L satellite, and Eutelsat Hot Bird 6 satellite to other broadcast feeds in the Asian region from 20 January 2009.
High-definition.
As a result of the move to Broadcasting House, BBC World News gained high-definition studios and equipment to be able to broadcast in high-definition. On 5 August 2013, BBC World News will be offered as a High Definition (HD) feed across the Middle East when it launches its international HD channel on Arabsat. Arabsat will be the BBC's first distribution partner in the Middle East to offer the award-winning news channel in HD.
On April 1, 2015 BBC World News in English started broadcasting in high definition from the 11.229GHz/V transponder on Astra 1KR at the 19.2°E orbital position, available free-to-air to viewers with 60cm dishes across Europe and coastal North Africa.
Worldwide.
BBC World News claims to be watched by a weekly audience of 74 million in over 200 countries and territories worldwide. BBC World News is most commonly watched as a free-to-air (FTA) channel. The channel is available in Europe and many parts of the world via satellite (FTA) or cable platforms.
In the United States, the channel is available through various providers such as Cablevision, Comcast, Time Warner Cable, Verizon, AT&T U-verse, DirecTV and others.
Online.
In mid-2012, Livestation made BBC World News available as part of a subscription package with Sky International, Al Jazeera English, and EuroNews. As of 3 January 2013, the channel is not available in the United States via the website.
Worldwide, the station is available free of charge and without geographical limitations through the free Readon Player software. There are usually at least two links to the feed. It can be found using the channel search feature or in the United Kingdom and News & Information sections. In Bahrain and the United Arab Emirates, it is additionally available as a subscription mobile phone service, having also been available as a terrestrial channel.
More recently, ad-supported mobile phone apps have been providing free access. TVGO Live TV provides a very clear and stable stream to Android devices; LiveTV also carries a stream but tends to suffer from stability issues in both the stream and the app itself.
United Kingdom.
The channel is not officially available as a stand-alone, full-time channel in the United Kingdom because it carries and is funded by advertising (BBC's domestic channels are funded by a television licence fee which households and establishments that want to watch television programmes as they are being broadcast must pay), although it can be easily received due to its 'free-to-air' status on many European satellite systems, including Astra and Hot Bird and is available in selected London hotels. BBC World News can also be viewed in the public areas of Broadcasting House (the lobby and cafe).
However, some BBC World News programmes are available to UK audiences. There is a simulcast of the 05:00 UK edition of "BBC World News" on BBC One and the BBC News channel, followed by an edition of "World Business Report". This programme was previously branded as 'The World Today'. While international audiences see advertisements during the break, UK viewers see domestic headlines. This simulcast is in addition to overnight simulcasts of the top of the hour from 01.00 to 05.00 UK time on both BBC World News and BBC News channel and are simply branded as "BBC News" (except for Newsday which simulcasts 01.00 UK time weekdays), even if they are produced by BBC World News. The 11:30 UK edition of "BBC World News" is shown on BBC Two Mon-Fri but not on Wednesdays when Parliament is sitting and there is Prime Minister's Questions. This forms BBC News at 11 on BBC Two, which is made up of half an hour of BBC News and then half an hour of BBC World News. This can also happen during big news events and the News Channel presenter will join the BBC World News presenter in Studio C as it used by both channels. This was done for example for coverage of events such as the Glasgow Helicopter Crash, Election of Pope Francis and Boston Marathon Bombings. Previously "GMT" was shown at 12:30 on the channel. On weekdays, BBC World News also produces a version of "World News Today" at 19:00 UK time. The first half-hour of this programme can be seen in the UK on BBC Four. The edition of the programme replaced "The World", which had been broadcast as a simulcast on the channel between 2002 and 2007. Both World and the BBC News channel have also occasionally had to simulcast the same news program due to technical issues; this occurred in 2003 when Television Centre in London was affected by electrical problems.
Programming.
Live news programmes:
Other live programmes:
Pre-recorded programmes include:
World News Bulletins.
Half-hour "BBC World News" bulletins are made available to Public Broadcasting Service member stations in the United States through Los Angeles' KCET, a non-commercial independent public television station separate from PBS since the beginning of 2011 due to a rights fee dispute. 80 to 90% of Americans are able to receive them, though broadcast times vary between different localities, with it airing on several PBS stations in markets such as New York City and Washington DC.
On PBS stations, "BBC World News" does not appear with commercials (the breaks are replaced with news stories) but omits the Met Office international weather forecast at the end, replacing it with underwriting announcements. The PBS airings are tape-delayed on some stations.
BBC America airs a 3-hour block of BBC World News coverage from 05:00 to 08:00 on weekdays. Met Office forecasts are removed, and is broadcast with advertisements. Another BBC World News programme, the hour-long "BBC World News America", aired on BBC America at 19:00 Eastern Time. A second broadcast at 22:00 Eastern Time ended in 2010 when BBC America introduced a second feed for the western time zones of the US on 18 February 2011, it was announced that "BBC World News America" would be discontinued on BBC America and would instead be airing only on BBC World and local PBS stations in the United States as a 30-minute program.
"BBC World News" bulletins also appear on Hong Kong TVB English Channel instead of: "NBC Nightly News with Brian Williams" simulcasting on NBC News by WNBC-4 from 07:30 until 08:00 Hong Kong Time (18:30 until 19:00 New York City Time), CCTV English News Live simulcasting on CCTV News from 10:00 until 11:00 and 12:00 until 13:00 Beijing/Hong Kong Time and from 19:30 until 20:00 Hong Kong Time. In Singapore, the English daily evening-nightly flagship mainly news bulletins appear on: MediaCorp TV HD5 instead of News 5 Tonight from 21:30 until 22:00 Singapore Standard Time and MediaCorp News Channel NewsAsia instead of Singapore Lens Night / Lensa Singapura Malam from 19:00 until 20:00 Singapore Standard Time.
Previously, bulletins also featured on select rail services in both cities:
These broadcasts are treated to a specially recorded namecheck of "Welcome to BBC World News on board the Singapore Mass Rapid Transit and Hong Kong Mass Transit Railway". This short bulletin was updated twice a day, and has since been replaced by a similar programme from Cable News Network (CNN).
Travellers on the Heathrow Express rail service from London Paddington to London Heathrow Airport ware also treated to a specially recorded BBC World News bulletin—introduced with a namecheck of "Welcome to BBC World News on board the Heathrow Express"—during the fifteen-minute journey. This short bulletin was updated twice a day, and was shown in both classes on LCD televisions throughout the train. A similar programme from Sky News is now shown instead.
Many airlines from across the world also play pre-recorded extracts of the BBC World News, have text headlines from it or have a full bulletin available on the in-flight entertainment systems. Airlines with BBC World News include Emirates Airlines, Malaysia Airlines, Singapore Airlines, Cathay Pacific, Qatar Airways, Etihad Airways, Qantas, Air Macau and American Airlines. Travellers can watch the bulletins on Independent Television News shortly after take-off on British Airways flights from the United Kingdom. Air France also broadcasts the full bulletin instead of France 2 News, on flights operated from Kuala Lumpur, Toronto-Lester Bowles Pearson, Singapore-Changi, London-Heathrow, Hong Kong-Chek Lap Kok, Sydney, Macau, Los Angeles, San Francisco and New York-John Fitzgerald Kennedy.
Presentation.
BBC World News is, for the most part, the same channel all over the world; the commercials are intended to be the only differences. However, there are some regional programming variations. For example, a number of programmes are made exclusively for regional viewings, such as Indian feeds, and "The Record Europe", which is only broadcast in Europe.
On most feeds of BBC World News, when there are no commercials being inserted by the cable or satellite provider similar to other channels, the break filler shows promotions for upcoming programmes on the channel. During BBC News, a news story that has not been promoted airs during what would be the commercial break. This is the case on the broadband versions of BBC World News, and on versions of BBC World News aired in the United States on Public Broadcasting Service (PBS) stations. However, there are some global commercials and sponsorships which air throughout the network.
On 11 September 2007, the break filler was redesigned and now more closely resembles previous versions. The promotional videos now fill the entire screen and are interspersed with news and market updates, schedules, and other information. There is also no longer a unifying music composition. Instead, each 20-second promotional video uses music selected from a handful of themes, which have some unifying musical characteristics. The information screens, such as the 10-second plug for the website or YouTube channel, and the 15-second weather/time/coming up screens each feature their own theme. The colour theme was updated following the relaunch of the channel in April 2008.
Since its inception, and more so since its extensive association with the BBC News channel, the countdown to the hourly news bulletin has been a feature of the channel's presentation, accompanied by music composed by David Lowe. The current style of countdown features reporters and technical staff in many different locations working to bring news stories to air.
Awards.
BBC World News was named "Best International News Channel" at the Association for International Broadcasting Awards in November 2006. It won a Peabody Award in 2007 for "White Horse Village" and another in 2009 for "Where Giving Life is a Death Sentence.""

</doc>
<doc id="37618" url="http://en.wikipedia.org/wiki?curid=37618" title="Finger">
Finger

A finger is a limb of the human body and a type of digit, an organ of manipulation and found in the hands of humans and other primates.
Normally humans have five digits, the bones of which are termed phalanges, on each hand (exceptions are polydactyly, oligodactyly and digit loss). The first digit is the thumb, followed by index finger, middle finger, ring finger, and little finger or pinky. According to different definitions, the thumb can be called a finger, or not.
Anatomy.
Skeleton.
The thumb (connected to the trapezium) is located on one of the sides, parallel to the arm.
The palm has five bones known as metacarpal bones, one to each of the 5 digits. Human hands contain fourteen digital bones, also called phalanges, or phalanx bones: two in the thumb (the thumb has no middle phalanx) and three in each of the four fingers. These are the distal phalanx, carrying the nail, the middle phalanx, and the proximal phalanx.
Sesamoid bones are small ossified nodes embedded in the tendons to provide extra leverage and reduce pressure on the underlying tissue. Many exist around the palm at the bases of the digits; the exact number varies between different people.
The articulations are: interphalangeal articulations between phalangeal bones, and metacarpophalangeal joints connecting the phalanges to the metacarpal bones.
The "pulp of a finger" is the fleshy mass on the palmar aspect of the extremity of the finger.
Muscles.
Each finger may flex and extend, abduct and adduct, and so also circumduct. Flexion is by far the strongest movement. In humans, there are two large muscles that produce flexion of each finger, and additional muscles that augment the movement. Each finger may move independently of the others, though the muscle bulks that move each finger may be partly blended, and the tendons may be attached to each other by a net of fibrous tissue, preventing completely free movement.
Fingers do not contain muscles (other than arrector pili). The muscles that move the finger joints are in the palm and forearm. The long tendons that deliver motion from the forearm muscles may be observed to move under the skin at the wrist and on the back of the hand.
Muscles of the fingers can be subdivided into extrinsic and intrinsic muscles.
The extrinsic muscles are the long flexors and extensors. They are called extrinsic because the muscle belly is located on the forearm.
The fingers have two long flexors, located on the underside of the forearm. They insert by tendons to the phalanges of the fingers. The deep flexor attaches to the distal phalanx, and the superficial flexor attaches to the middle phalanx. The flexors allow for the actual bending of the fingers. The thumb has one long flexor and a short flexor in the thenar muscle group. The human thumb also has other muscles in the thenar group (opponens and abductor brevis muscle), moving the thumb in opposition, making grasping possible.
The extensors are located on the back of the forearm and are connected in a more complex way than the flexors to the dorsum of the fingers. The tendons unite with the interosseous and lumbrical muscles to form the extensorhood mechanism. The primary function of the extensors is to straighten out the digits. The thumb has two extensors in the forearm; the tendons of these form the anatomical snuff box. Also, the index finger and the little finger have an extra extensor, used for instance for pointing. The extensors are situated within 6 separate compartments. The 1st compartment contains abductor pollicis longus and extensor pollicis brevis. The 2nd compartment contains extensors carpi radialis longus and brevis. The 3rd compartment contains extensor pollicis longus. The extensor digitorum indicis and extensor digititorum communis are within the 4th compartment. Extensor digiti minimi is in the fifth, and extensor carpi ulnaris is in the 6th.
The intrinsic muscle groups are the thenar and hypothenar muscles (thenar referring to the thumb, hypothenar to the small finger), the dorsal and palmar interossei muscles (between the metacarpal bones) and the lumbrical muscles. The lumbricals arise from the deep flexor (and are special because they have no bony origin) and insert on the dorsal extensor hood mechanism.
Skin.
Aside from the genitals, the fingertips possess the highest concentration of touch receptors and thermoreceptors among all areas of the human skin, making them extremely sensitive to temperature, pressure, vibration, texture and moisture. Recent studies suggest fingers can feel nano-scale wrinkles on a seemingly smooth surface, a level of sensitivity not previously recorded. Thus fingers are commonly used as sensory probes to ascertain properties of objects encountered in the world, and so they are prone to injury.
Fingertip wrinkling in water.
Although a common phenomenon, the underlying functions and mechanism of fingertip wrinkling following immersion in water are relatively unexplored. Originally it was assumed that the wrinkles were simply the result of the skin swelling in water, but it is now understood that the furrows are caused by the blood vessels constricting due to signalling by the sympathetic nervous system in response to water exposure. One hypothesis for why this occurs, the “rain tread” hypothesis, posits that the wrinkles may help the fingers grip things when wet, possibly being an adaption from a time when humans dealt with rain and dew in forested primate habitats. A 2013 study supporting this hypothesis found that the wrinkled fingertips provided better handling of wet objects but gave no advantage for handling dry objects. However, a 2014 study attempting to reproduce these results was unable to demonstrate any improvement of handling wet objects with wrinkled fingertips.
Brain representation.
Each finger has an orderly somatotopic representation on the cerebral cortex in the somatosensory cortex area 3b, part of area 1 and a distributed, overlapping representations in the supplementary motor area and primary motor area.
The somatosensory cortex representation of the hand is a dynamic reflection of the fingers on the external hand: in syndactyly people have a clubhand of webbed, shortened fingers. However, not only are the fingers of their hands fused, but the cortical maps of their individual fingers also form a club hand. The fingers can be surgically divided to make a more useful hand. Surgeons did this at the Institute of Reconstructive Plastic Surgery in New York to a 32-year-old man with the initials O. G.. They touched O. G.’s fingers before and after surgery while using MRI brain scans. Before the surgery, the fingers mapped onto his brain were fused close together; afterward, the maps of his individual fingers did indeed separate and take the layout corresponding to a normal hand.
Other animals.
Chimpanzees have lower limbs that are specialized for manipulation, and (arguably) have fingers on their lower limbs as well. The term 'finger' is not applied to the digits of most other animals, such as canines, felines, or ungulates, none of which can engage in fine manipulation with their forelimbs as a primate can.
Clinical significance.
Anomalies, injuries and diseases.
A rare anatomical variation affects 1 in 500 humans, in which the individual has more than the usual number of digits; this is known as polydactyly. A human may also be born without one or more fingers or underdevelopment of some fingers such as symbrachydactyly. Extra fingers can be functional. One individual with seven fingers not only used them but claimed that they "gave him some advantages in playing the piano".
Phalanges are commonly fractured. A damaged tendon can cause significant loss of function in fine motor control, such as with a mallet finger.
The fingers are commonly affected by diseases such as rheumatoid arthritis and gout. Diabetics often use the fingers to obtain blood samples for regular blood sugar testing. Raynaud's phenomenon is a neurovascular disorder that affects the fingers.
Research has linked the ratio of lengths between the index and ring fingers to higher levels of testosterone, and to various physical and behavioral traits such as penis length and risk for development of alcohol dependence or video game addiction.
History.
Etymology.
English dictionaries describe finger as meaning either one of the five digits including the thumb, or one of the four excluding the thumb (in which case they are numbered from 1 to 4 starting with the index finger closest to the thumb). Linguistically, it appears that the original sense was to include the thumb as a finger: the word is derived from "*‍penkwe-ros" (also rendered as "*penqrós") which was, in the Proto-Indo-European language, a suffixed form of "*penkwe" (or "*penqe"), "five", which has given rise to many Indo-European-family words (tens of them defined in English dictionaries) that involve or flow from concepts of fiveness. In English only the digits on the hand are known as fingers. However, in some languages the translated version of fingers can mean either the digits on the hand or feet. In English a digit on a foot has the distinct name of toe.
References.
</dl>

</doc>
<doc id="37622" url="http://en.wikipedia.org/wiki?curid=37622" title="Venus (mythology)">
Venus (mythology)

Venus (, Classical Latin: ) is the Roman goddess whose functions encompassed love, beauty, sex, fertility, prosperity and desire. In Roman mythology, she was the mother of the Roman people through her son, Aeneas, who survived the fall of Troy and fled to Italy. Julius Caesar claimed her as his ancestor. Venus was central to many religious festivals, and was revered in Roman religion under numerous cult titles.
The Romans adapted the myths and iconography of her Greek counterpart Aphrodite for Roman art and Latin literature. In the later classical tradition of the West, Venus becomes one of the most widely referenced deities of Greco-Roman mythology as the embodiment of love and sexuality.
Name and attributes.
Venus embodies sex, love, beauty, enticement, seduction, and persuasive female charm among the community of immortal gods; in Latin orthography, her name is indistinguishable from the Latin noun "venus" ("sexual love" and "sexual desire"), from which it derives. Venus has been described as perhaps "the most original creation of the Roman pantheon", and "an ill-defined and assimilative" native goddess, combined "with a strange and exotic Aphrodite".
Her cults may represent the religiously legitimate charm and seduction of the divine by mortals, in contrast to the formal, contractual relations between most members of Rome's official pantheon and the state, and the unofficial, illicit manipulation of divine forces through magic. The ambivalence of her function is suggested in the etymological relationship of the root "*venes-" with Latin "venenum" (poison), in the sense of "a charm, magic philtre".
In myth, Venus-Aphrodite was born of sea-foam. Roman theology presents Venus as the yielding, watery female principle, essential to the generation and balance of life. Her male counterparts in the Roman pantheon, Vulcan and Mars, are active and fiery. Venus absorbs and tempers the male essence, uniting the opposites of male and female in mutual affection. She is essentially assimilative and benign, and embraces several otherwise quite disparate functions. She can give military victory, sexual success, good fortune and prosperity. In one context, she is a goddess of prostitutes; in another, she turns the hearts of men and women from sexual vice to virtue.
Images of Venus have been found in domestic murals, mosaics and household shrines ("lararia"). Petronius, in his Satyricon, places an image of Venus among the Lares (household gods) of the freedman Trimalchio's "lararium". Prospective brides offered Venus a gift "before the wedding"; the nature of the gift, and its timing, are unknown. Some Roman sources say that girls who come of age offer their toys to Venus; it is unclear where the offering is made, and others say this gift is to the Lares. In dice-games, a popular pastime among Romans of all classes, the luckiest, best possible roll was known as "Venus".
Signs and symbols.
Venus' signs were for the most part the same as Aphrodite's. They include roses, which were offered in Venus' Porta Collina rites, and above all, myrtle (Latin "murtos"), which was cultivated for its white, sweetly scented flowers, aromatic, evergreen leaves and its various medical-magical properties. Venus' statues, and her worshipers, wore myrtle crowns at her festivals. Before its adoption into Venus' cults, myrtle was used in the purification rites of Cloacina, the Etruscan-Roman goddess of Rome's main sewer; later, Cloacina's association with Venus' sacred plant made her Venus Cloacina. Likewise, Roman folk-etymology transformed the ancient, obscure goddess Murcia into "Venus of the Myrtles, whom we now call Murcia".
Myrtle was thought a particularly potent aphrodisiac. The female pudendum, particularly the clitoris, was known as "murtos" (myrtle). As goddess of love and sex, Venus played an essential role at Roman prenuptial rites and wedding nights, so myrtle and roses were used in bridal bouquets. Marriage itself was not a seduction but a lawful condition, under Juno's authority; so myrtle was excluded from the bridal crown. Venus was also a patron of the ordinary, everyday wine drunk by most Roman men and women; the seductive powers of wine were well known. In the rites to Bona Dea, a goddess of female chastity, Venus, myrtle and anything male were not only excluded, but unmentionable. The rites allowed women to drink the strongest, sacrificial wine, otherwise reserved for the Roman gods and Roman men; the women euphemistically referred to it as "honey". Under these special circumstances, they could get virtuously, religiously drunk on strong wine, safe from Venus' temptations. Outside of this context, ordinary wine (that is, Venus' wine) tinctured with myrtle oil was thought particularly suitable for women.
Roman generals given an ovation, a lesser form of Roman triumph, wore a myrtle crown, perhaps to purify themselves and their armies of blood-guilt. The ovation ceremony was assimilated to Venus Victrix ("Victorious Venus"), who was held to have granted and purified its relatively "easy" victory.
Cult history and temples.
The first known temple to Venus was promised to "Venus Obsequens" ("Indulgent Venus") by Q. Fabius Gurges in the heat of a battle against the Samnites. It was dedicated in 295 BC, at a site near the Aventine Hill, and was supposedly funded by fines imposed on Roman women for sexual misdemeanours. Its rites and character were probably influenced by or based on Greek Aphrodite's cults, which were already diffused in various forms throughout Italian Magna Graeca. Its dedication date connects "Venus Obsequens" to the "Vinalia rustica" festival.
In 217 BC, in the early stages of the Second Punic War with Carthage, Rome suffered a disastrous defeat at the battle of Lake Trasimene. The Sibylline oracle suggested that if the "Venus Erycina" ("Venus of Eryx"), patron goddess of Carthage's Sicillian allies, could be persuaded to change her allegiance, Carthage might be defeated. Rome laid siege to Eryx, offered its goddess a magnificent temple, captured her image and brought it to Rome, where it was installed in a temple on the Capitoline Hill, as one of Rome's twelve Dii consentes. Shorn of her more overtly Carthaginian characteristics, this "foreign Venus" became Rome's "Venus Genetrix" ("Venus the Mother"), As far as the Romans were concerned, this was the homecoming of an ancestral goddess to her people. Roman tradition made Venus the mother and protector of the Trojan prince Aeneas, ancestor of the Roman people. Soon after, Rome's defeat of Carthage confirmed Venus's goodwill to Rome, her links to its mythical Trojan past, and her support of its political and military hegemony.
The Capitoline cult to Venus seems to have been reserved to higher status Romans. A separate cult to "Venus Erycina" as a fertility deity, was established in 181 BC, in a traditionally plebeian district just outside Rome's sacred boundary, near the Colline Gate. The temple, cult and goddess probably retained much of the original's character and rites. Likewise, a shrine to Venus Verticordia ("Venus the changer of hearts"), established in 114 BC but with links to an ancient cult of Venus-Fortuna, was "bound to the peculiar milieu of the Aventine and the Circus Maximus" - a strongly plebeian context for Venus's cult, in contrast to her aristocratic cultivation as a Stoic and Epicurian "all-goddess".
Towards the end of the Roman Republic, some leading Romans laid personal claims to Venus' favour. The general and dictator Sulla adopted "Felix" ("Lucky") as a surname, acknowledging his debt to heaven-sent good fortune and his particular debt to "Venus Felix", for his extraordinarily fortunate political and military career. His protégé Pompey competed for Venus' support, dedicating (in 55 BC) a large temple to "Venus Victrix" as part of his lavishly appointed new theatre, and celebrating his triumph of 54 BC with coins that showed her crowned with triumphal laurels.
Pompey's erstwhile friend, ally, and later opponent Julius Caesar went still further. He claimed the favours of "Venus Victrix" in his military success and "Venus Genetrix" as a personal, divine ancestress – apparently a long-standing family tradition among the Julii. When Caesar was assassinated, his heir, Augustus, adopted both claims as evidence of his inherent fitness for office, and divine approval of his rule. Augustus' new temple to Mars Ultor, divine father of Rome's legendary founder Romulus, would have underlined the point, with the image of avenging Mars "almost certainly" accompanied by that of his divine consort Venus, and possibly a statue of the deceased and deified Caesar.
In 135 AD the Emperor Hadrian inaugurated a temple to Venus and "Roma Aeterna" (Eternal Rome) on Rome's Velian Hill, underlining the Imperial unity of Rome and its provinces, and making Venus the protective "genetrix" of the entire Roman state, its people and fortunes. It was the largest temple in Ancient Rome.
Vitruvius recommends that any new temple to Venus be sited according to rules laid down by the Etruscan haruspices, and built "near to the gate" of the city, where it would be less likely to contaminate "the matrons and youth with the influence of lust". He finds the Corinthian style, slender, elegant, enriched with ornamental leaves and surmounted by volutes, appropriate to Venus' character and disposition. Vitruvius recommends the widest possible spacing between the temple columns, producing a light and airy space, and he offers Venus's temple in Caesar's forum as an example of how not to do it; the densely spaced, thickset columns darken the interior, hide the temple doors and crowd the walkways, so that matrons who wish to honour the goddess must enter her temple in single file, rather than arm-in arm.
Festivals.
Venus was offered official (state-sponsored) cult in certain festivals of the Roman calendar. Her sacred month was April (Latin "Mensis Aprilis") which Roman etymologists understood to derive from "aperire", "to open," with reference to the springtime blossoming of trees and flowers.
Veneralia (April 1) was held in honour of "Venus Verticordia" ("Venus the Changer of Hearts"), and Fortuna Virilis (Virile or strong Good Fortune), whose cult was probably by far the older of the two. Venus Verticordia was invented in 220 BC, in response to advice from a Sibylline oracle during Rome's Punic Wars, when a series of prodigies was taken to signify divine displeasure at sexual offenses among Romans of every category and class, including several men and three Vestal Virgins. Her statue was dedicated by a young woman, chosen as the most "pudica" (sexually pure) in Rome by a committee of Roman matrons. At first, this statue was probably housed in the temple of "Fortuna Virilis", perhaps as divine reinforcement against the perceived moral and religious failings of its cult. In 114 BC "Venus Verticordia" was given her own temple. She was meant to persuade Romans of both sexes and every class, whether married or unmarried, to cherish the traditional sexual proprieties and morality known to please the gods and benefit the State. During her rites, her image was taken from her temple to the men's baths, where it was undressed and washed in warm water by her female attendants, then garlanded with myrtle. Women and men asked Venus Verticordia's help in affairs of the heart, sex, betrothal and marriage. For Ovid, Venus's acceptance of the epithet and its attendant responsibilities represented a change of heart in the goddess herself.
Vinalia urbana (April 23), a wine festival shared by Venus and Jupiter, king of the gods. Venus was patron of "profane" wine, for everyday human use. Jupiter was patron of the strongest, purest, sacrificial grade wine, and controlled the weather on which the autumn grape-harvest would depend. At this festival, men and women alike drank the new vintage of ordinary, non-sacral wine in honour of Venus, whose powers had provided humankind with this gift. Upper-class women gathered at Venus's Capitoline temple, where a libation of the previous year's vintage, sacred to Jupiter, was poured into a nearby ditch. Common girls ("vulgares puellae") and prostitutes gathered at Venus' temple just outside the Colline gate, where they offered her myrtle, mint, and rushes concealed in rose-bunches and asked her for "beauty and popular favour", and to be made "charming and witty".
Vinalia Rustica (August 19), originally a rustic Latin festival of wine, vegetable growth and fertility. This was almost certainly Venus' oldest festival and was associated with her earliest known form, "Venus Obsequens". Kitchen gardens and market-gardens, and presumably vineyards were dedicated to her. Roman opinions differed on whose festival it was. Varro insists that the day was sacred to Jupiter, whose control of the weather governed the ripening of the grapes; but the sacrificial victim, a female lamb ("agna"), may be evidence that it once belonged to Venus alone.
A festival of Venus Genetrix (September 26) was held under state auspices from 46 BC at her Temple in the Forum of Caesar, in fulfillment of a vow by Julius Caesar, who claimed her personal favour as his divine patron, and ancestral goddess of the Julian clan. Caesar dedicated the temple during his unprecedented and extraordinarily lavish quadruple triumph. At the same time, he was pontifex maximus and Rome's senior magistrate; the festival is thought to mark the unprecedented promotion of a personal, family cult to one of the Roman state. Caesar's heir, Augustus, made much of these personal and family associations with Venus as an Imperial deity. The festival's rites are not known.
Epithets of Venus.
Like other major Roman deities, Venus was given a number of epithets that referred to her different cult aspects, roles, and her functional similarities to other deities. Her "original powers seem to have been extended largely by the fondness of the Romans for folk-etymology, and by the prevalence of the religious idea "nomen-omen" which sanctioned any identifications made in this way."
Venus Caelestis (Celestial or Heavenly Venus), used from the 2nd century AD for Venus as an aspect of a syncretised supreme goddess. "Venus Caelestis" is the earliest known Roman recipient of a taurobolium (a form of bull sacrifice), performed at her shrine in Pozzuoli on 5 October 134. This form of the goddess, and the taurobolium, are associated with the "Syrian Goddess", understood as a late equivalent to Astarte, or the Roman Magna Mater, another supposedly "Trojan Mother of the Romans"
Venus Calva ("Venus the bald one"), a legendary form of Venus, attested only by post-Classical Roman writings which offer several traditions to explain this appearance and epithet. In one, it commemorates the virtuous offer by Roman matrons of their own hair to make bowstrings during a siege of Rome. In another, king Ancus Marcius' wife and other Roman women lost their hair during an epidemic; in hope of its restoration, unafflicted women sacrificed their own hair to Venus.
Venus Cloacina ("Venus the Purifier"); a fusion of Venus with the Etruscan water goddess Cloacina, who had an ancient shrine above the outfall of the Cloaca Maxima, originally a stream, later covered over to function as Rome's main sewer. The shrine contained a statue of Venus, whose rites were probably meant to purify the culvert's polluted waters and noxious airs. Pliny the Elder, remarking Venus as a goddess of union and reconciliation, identifies the shrine with a legendary episode in Rome's earliest history, when the warring Romans and Sabines, carrying branches of myrtle, met there to make peace.
Venus Erycina ("Venus of Eryx"), captured from Sicily and worshiped in Romanised form by the elite, and respectable matrons, at a temple on the Capitoline Hill. A later temple, outside the Porta Collina and Rome's sacred boundary, may have preserved some Erycinian features of her cult. It was considered suitable for "common girls" and prostitutes.
Venus Frutis honoured by all the Latins with a federal cult at the temple named "Frutinal" in Lavinium. Inscriptions found at Lavinium attest the presence of federal cults, without giving precise details.
Venus Felix ("Lucky Venus"), probably a traditional epithet, later adopted by the dictator Sulla. It was Venus's cult title at Hadrian's temple to "Venus Felix et Roma Aeterna" on the Via Sacra. This epithet is also used for a specific sculpture at the Vatican Museums.
Venus Genetrix ("Venus the Mother"), as a goddess of motherhood and domesticity, with a festival on September 26, a personal ancestress of the Julian lineage and, more broadly, the divine ancestress of the Roman people. Julius Caesar dedicated a Temple of Venus Genetrix in 46 BC. This name has attached to an iconological type of statue of Aphrodite/Venus.
Venus Kallipygos ("Venus with the pretty bottom"), worshiped at Syracuse.
Venus Libertina ("Venus the Freedwoman"), probably arising through the semantic similarity and cultural inks between "libertina" (as "a free woman") and "lubentina" (possibly meaning "pleasurable" or "passionate"). Further titles or variants acquired by Venus through the same process, or through orthographic variance, include Libentia, Lubentina, and Lubentini. Venus Libitina links Venus to a patron-goddess of funerals and undertakers, Libitina; a temple was dedicated to Venus Libitina in Libitina's grove on the Esquiline Hill, "hardly later than 300 BC."
Venus Murcia ("Venus of the Myrtle"), merging Venus with the little-known deity Murcia (or Murcus, or Murtia). Murcia was associated with Rome's Mons Murcia (the Aventine's lesser height), and had a shrine in the Circus Maximus. Some sources associate her with the myrtle-tree. Christian writers described her as a goddess of sloth and laziness.
Venus Obsequens ("Indulgent Venus"), Venus' first attested Roman epithet. It was used in the dedication of her first Roman temple, on August 19 in 295 BC during the Third Samnite War by Quintus Fabius Maximus Gurges. It was sited somewhere near the Aventine Hill and Circus Maximus, and played a central role in the Vinalia Rustica. It was supposedly funded by fines imposed on women found guilty of adultery.
Venus Physica: Venus as a universal, natural creative force that informs the physical world. She is addressed as "Alma Venus" ("Mother Venus") by Lucretius in the introductory lines of his vivid, poetic exposition of Epicurean physics and philosophy, "De Rerum Natura". She seems to have been a favourite of Lucretius' patron, Memmius. Pompeii's protective goddess was "Venus Physica Pompeiana", who had a distinctive, local form as a goddess of the sea, and trade. When Sulla captured Pompeii from the Samnites, he resettled it with his veterans and renamed it for his own family and divine protector Venus, as "Colonia Veneria Cornelia" (for Sulla's claims of Venus' favour, see "Venus Felix" above).
Venus Urania ("Heavenly Venus"), used as the title of a book by Basilius von Ramdohr, a relief by Pompeo Marchesi, and a painting by Christian Griepenkerl. (cf. Aphrodite Urania.)
Venus Verticordia ("Venus the Changer of Hearts"). See Veneralia in this article and main article, Veneralia.
Venus Victrix ("Venus the Victorious"), a Romanised aspect of the armed Aphrodite that Greeks had inherited from the East, where the goddess Ishtar "remained a goddess of war, and Venus could bring victory to a Sulla or a Caesar." Pompey, Sulla's protégé, vied with his patron and with Caesar for public recognition as her protégé. In 55 BC he dedicated a temple to her at the top of his theater in the Campus Martius. She had a shrine on the Capitoline Hill, and festivals on August 12 and October 9. A sacrifice was annually dedicated to her on the latter date. In neo-classical art, her epithet as Victrix is often used in the sense of 'Venus Victorious over men's hearts' or in the context of the Judgement of Paris (e.g. Canova's "Venus Victrix", a half-nude reclining portrait of Pauline Bonaparte).
Mythology and literature.
As with most major gods and goddesses in Roman mythology, the literary concept of Venus is mantled in whole-cloth borrowings from the literary Greek mythology of her counterpart, Aphrodite. In some Latin mythology Cupid was the son of Venus and Mars, the god of war. At other times, or in parallel myths and theologies, Venus was understood to be the consort of Vulcan. Virgil, in compliment to his patron Augustus and the "gens Julia", embellished an existing connection between Venus, whom Julius Caesar had adopted as his protectress, and Aeneas. Vergil's Aeneas is guided to Latium by Venus in her heavenly form, the morning star, shining brightly before him in the daylight sky; much later, she lifts Caesar's soul to heaven. In Ovid's "Fasti" Venus came to Rome because she "preferred to be worshipped in the city of her own offspring". In Vergil's poetic account of Octavian's victory at the sea-battle of Actium, the future emperor is allied with Venus, Neptune and Minerva. Octavian's opponents, Antony, Cleopatra and the Egyptians, assisted by bizarre and unhelpful deities such as "barking" Anubis, lose the battle.
In the "interpretatio romana" of the Germanic pantheon during the early centuries AD, Venus became identified with the Germanic goddess "Frijjo", giving rise to the loan translation "Friday" for "dies Veneris". The historical cognate of the dawn goddess in Germanic tradition, however, would be Ostara.
In art.
Classical art.
Roman and Hellenistic art produced many variations on the goddess, often based on the Praxitlean type Aphrodite of Cnidus. Many female nudes from this period of sculpture whose subjects are unknown are in modern art history conventionally called 'Venus'es, even if they originally may have portrayed a mortal woman rather than operated as a cult statue of the goddess.
Examples include:
Art in the classical tradition.
Venus became a popular subject of painting and sculpture during the Renaissance period in Europe. As a "classical" figure for whom nudity was her natural state, it was socially acceptable to depict her unclothed. As the goddess of sexuality, a degree of erotic beauty in her presentation was justified, which appealed to many artists and their patrons. Over time, "venus" came to refer to any artistic depiction in post-classical art of a nude woman, even when there was no indication that the subject was the goddess.
In the field of prehistoric art, since the discovery in 1908 of the so-called "Venus of Willendorf" small Neolithic sculptures of rounded female forms have been conventionally referred to as Venus figurines. Although the name of the actual deity is not known, the knowing contrast between the obese and fertile cult figures and the classical conception of Venus has raised resistance to the terminology.
Medieval and modern music.
In Wagner's opera "Tannhäuser", which draws on the medieval German legend of the knight and poet Tannhäuser, Venus lives beneath the Venusberg mountain. Tannhäuser breaks his knightly vows by spending a year there with Venus, under her enchantment. When he emerges, he has to seek penance for his sins.
The Dutch band Shocking Blue had a number one hit on the Billboard Top Ten in 1970 with the song titled "Venus." There is also a song named "Venus" written, produced and sung by Lady Gaga, as well as a song named "Birth of Venus Illegitima" by the Swedish symphonic metal Therion, on the album Vovin. The group Bananarama also did a version of Shocking Blue's song Venus in 1986. There is also the song "Venus as a Boy" by the Icelandic artist Björk.

</doc>
<doc id="37625" url="http://en.wikipedia.org/wiki?curid=37625" title="Hildegard Knef">
Hildegard Knef

Hildegard Frieda Albertine Knef (28 December 1925 – 1 February 2002) was a German actress, singer, and writer. She was billed in some English language films as Hildegard Neff or Hildegarde Neff.
Early years.
Hildegard Knef was born in Ulm. Her parents were Hans Theodor and Friede Augustine Knef. Her father, who was a decorated First World War veteran, died of syphilis when she was only six months. Then her mother moved to Berlin and worked in a factory. Knef began studying acting at the age of 14, in 1940. She left school when she was 15 to become an apprentice animator with Universum Film AG. After she had a successful screen test, she went to the State Film School at Babelsberg, Berlin, where she studied acting, ballet and elocution. Josef Goebbels, who was Hitler's propaganda minister, wrote to her and ask to meet her, but Knef's friends wanted her to stay away from him. 
Knef appeared in several films before the fall of the Third Reich, but most were released only afterward. During the Battle of Berlin, Knef dressed as a soldier in order to stay with her lover Ewald von Demandowsky, and joined him in the defence of Schmargendorf. The Soviets captured her and sent her to a prison camp. The prisoners of the jail where she was, helped her to escape in order she could come back to Berlin. Ewald von Demandowsky was then killed. But before that, he helped Knef to get protection from the well-known character actor Viktor de Kowa in Berlin. De Kowa gave her the opportunity to be a mistress of ceremonies in the theatre that he had opened. Knef also got a part in Marcel Pagnol's "Marius," which was directed by Boleslaw Barlog. It was one of the German theatre's greats. De Kowa also directed Knef in plays by Shakespeare, Pagnol and George Abbott.
Her two best known film roles were "Susanne Wallner" in Wolfgang Staudte's film "Die Mörder sind unter uns" ("The Murderers Are Among Us"), produced in 1946 by the East German state film company, and the first film released after the Second World War in East Germany; and "Marina" in "Die Sünderin" ("The Sinner"), in which she performed a brief nude scene, the first in German film history, which caused a scandal in 1950. The film was also criticised by the Catholic Church which protested against the nude scene. Knef stated that she didn't understand the tumult that the film was creating. She wrote that it was totally absurd that people reacted in that manner and made a scandal because of her nudity as Germany was a country that had Auschwitz and had caused so much horror. She also wrote, "I had the scandal, the producers got the money." 
She performed in many films. In 1948, she received the award for best actress from the Locarno Film Festival because of her role in the film "Film Without a Title". Her successful career as a singer started in the 1960s once her film career was not going very well. She wrote some songs by herself. She performed in television shows such as in episodes of "Scarecrow and Mrs. King", and in a 2000 documentary in which she was playing by herself "Marlene Dietrich: Her Own Song".
In the 1960s, she appeared in a number of such low-budget films as "The Lost Continent".
She appeared in the 1975 screen adaptation of the Hans Fallada novel, "Every Man Dies Alone" directed by Alfred Vohrer, released in English as "Everyone Dies Alone" in 1976, and for which she won an award for best actress at the International Film Festival in Carlsbad, then Czechoslovakia.
United States.
David O. Selznick invited her to Hollywood, but she refused to agree to the conditions of the contract which reportedly included changing her name to Gilda Christian and pretending to be Austrian rather than German.
Knef starred in the Hollywood film "Decision Before Dawn" (1951) directed by Anatole Litvak. She co-starred with Richard Basehart and Oskar Werner in a story about the last days of the German war.
Years later, Knef's first husband, an American named Kurt Hirsch, encouraged her to try again for success in the U.S. She changed her name from Knef to Neff. But she was only offered a supporting role in the Hemingway adaptation of "The Snows of Kilimanjaro" (1952). Knef became a leading lady in films of Germany, France and Britain.
Her reputation in the U.S. was hurt because of her nude scenes in the German film "Die Sünderin" (1950) and because at the age of 19 she fell in love with a Nazi.
Finally, in 1955, Knef was offered an important role in America in the musical "Silk Stockings" by Cole Porter, which was based on the film "Ninotchka" (1939) which starred Greta Garbo in the title role. Knef had acted in at least 30 films in the United States and Europe, but her triumph was in New York when she performed the role of Ninotchka, an unemotional Soviet commissar. The New York Times' drama critic, Brooks Atkinson qualified Cole Porter's film as one of his best films and considered that Knef's stage transformation as a corrupted commissar was a very masterful performance. Knef played the role of "Ninotchka" from 1954 to 1956. She sang Cole Porter tunes in her 675 performances.
Chanteuse.
In the 1960s, Knef made a pause in her acting career. That is when she started writing lyrics. Then she started a successful concert and recording career. 
She began her singing career in the United States on Broadway. She began her new career in 1963 as a singer and surprised her audiences with the deep, smoky quality of her voice and the many lyrics, which she wrote herself. Fans around the world rallied in her support as she defeated cancer several times. She returned to Berlin after the reunification. In her peak, entertainment columnist called her the ""willowy blonde" who had "dusty voice" and "generous mouth." 
In the 1960s and 1970s, she enjoyed considerable success as a singer of German chansons, which she often co-wrote. The song she is mostly remembered for is "Für mich soll's rote Rosen regnen" ("Red roses are to rain for me"). She is also known for her version of the song "Ich hab noch einen Koffer in Berlin" ("I still have a suitcase in Berlin") and "Mackie Messer" ("Mack the knife"). She sold more than three million records in total.
She launched 23 original albums which counted for 320 different songs. She wrote by herself 130 of the lyrics.
Publications.
She published several books. Her autobiography "Der geschenkte Gaul - Bericht aus einem Leben" ("The Gift Horse - Report on a Life", 1970) was a candid recount of her life in Germany during and after the Second World War, and reportedly became the best-selling German book in the post-war years. Her second book "Das Urteil" ("The Verdict", 1975) was a moderate success, and dealt with her struggle with breast cancer. Knef not only achieved international best-seller status, her books also received incredible amount of praises from critics because her autobiographies were "better-than-average celebrity's." Arthur Cooper of "Newsweek" claimed that the way in which Knef accounted in "The Gift Horse: Report on a Life" her childhood and difficult life being an actress and singer while Hitler's Berlin and after the war in Europe and America, was "a bitterly honest book and a very good one." The book is not considered a book of "Hollywood-Broadway gossip. The book doesn't try to persuade the public depicting a made up celebrity's adventures. It seems a book that tells the real life of Knef. It refers to her struggles as a German woman who grew up in Berlin under the Nazis. "The Gift Horse: Report on a Life" was translated to English by Knef's second husband David Anthony Palastanga. In "The Verdict" which was also translate Palastanga, Knef looked at her life in another perspective because she knew that she had cancer. Rachel MacKenzie wrote that Knef got her 56th operation in Salzburg on 10 August 1973. In that operation she was performed a mastectomy. MacKenzie stated that from that operation from cancer, life had to be thought of in terms of pre-verdict and post- verdict. The book is divided in these two sections but they are not chronically ordered because Knef wrote the two sections in a way that the reader is moved forward and backward in time and space. "The Verdict" describes in great detail the hospital scenes as well as the doctors and nurses in New York, Los Angeles, Zürich and Hamburg where she was hospitalised.
During her career, she performed in over 50 films. Nineteen of her films were produced in different countries other than Germany; They were produced in the United States, Britain, France, Italy, Austria and Spain.
Family.
She was married three times and divorced twice. Her first marriage was in 1947 to Kurt Hirsch. He was an U.S. information officer. But they got divorced in 1952. She married for the second time, to the actor and record producer David Anthony Palastanga, on 30 June 1962. Knef had a daughter with him. They named her Christina Antonia. She attended public schools in Germany. When knef was 40, she wrote a letter for her 5-year old daughter. She wrote what she had learned; of beauty; of her grandfather’s legacy about anti-human beings, of unconditional love and truth. She also wrote that the only mission of humans in this world was to serve in one form or other because she had noticed that those who didn’t serve ended up as slaves. When she died, she was still married to her third husband, Paul von Schell.
Death.
Knef died in Berlin where she moved after German reunification. The Associated Press reported that she died of a lung infection at the age of 76. Knef smoked heavily for most of her life and suffered from emphysema.

</doc>
<doc id="37627" url="http://en.wikipedia.org/wiki?curid=37627" title="BBC World Service">
BBC World Service

The BBC World Service is the world's largest international broadcaster, broadcasting news, speech and discussions in 28 languages to many parts of the world on analogue and digital shortwave platforms, internet streaming, podcasting, satellite, FM and MW relays. The World Service was reported to have reached 188 million people a week on average in June 2009. The English language service broadcasts 24 hours a day.
The World Service is funded by the United Kingdom's television licence fee, limited advertising and the profits of BBC Worldwide Ltd. The World Service was funded for decades by grant-in-aid through the Foreign and Commonwealth Office of the British Government until 1 April 2014.
The Director of the BBC World Service is Francesca Unsworth.
History.
The BBC World Service began as the BBC Empire Service in 1932 as a shortwave service aimed principally at English speakers in the outposts of the British Empire. In his first Christmas Message, King George V stated that the service was intended for "men and women, so cut off by the snow, the desert, or the sea, that only voices out of the air can reach them." First hopes for the Empire Service were low. The Director General, Sir John Reith (later Lord Reith) said in the opening programme: "Don't expect too much in the early days; for some time we shall transmit comparatively simple programmes, to give the best chance of intelligible reception and provide evidence as to the type of material most suitable for the service in each zone. The programmes will neither be very interesting nor very good." This address was read out five times as it was broadcast live to different parts of the world.
On 3 January 1938, the first foreign language service, Arabic, was launched. German programmes commenced on 29 March 1938 and by the end of 1942 broadcasts were being made in all major European languages. As a result, the Empire Service was renamed the BBC Overseas Service in November 1939, and a dedicated BBC European Service was added in 1941. These broadcasting services, financed not from the domestic licence fee but from government grant-in-aid (from the Foreign Office budget), were known administratively as the External Services of the BBC.
The External Services broadcast propaganda during the Second World War. George Orwell broadcast many news bulletins on the Eastern Service during World War II.
By the end of the 1940s the number of languages broadcast had expanded and reception had improved following the opening of a relay in modern day Malaysia and of the Limassol relay, Cyprus, in 1957. On 1 May 1965 the service took its current name of BBC World Service and the service itself expanded its reach with the opening of the Ascension Island relay in 1966, serving African audiences with greater signal and reception, and the later relay on the Island of Masirah.
In August 1985, the service went off the air for the first time when workers struck in protest at the British government's decision to ban a documentary featuring an interview with Martin McGuinness of Sinn Féin. The External Services were renamed under the BBC World Service brand in 1988.
In recent years, the number and type of services offered by the BBC has decreased through financial pressures. Due to the launch of internet based services, the need for a radio station is less frequent in countries where the population has easy access to the internet news sites of the BBC. The German broadcasts were stopped in March 1999 after research showed that the majority of German listeners tuned into the English version of the service. Broadcasts in Dutch, Finnish, French for Europe, Hebrew, Italian, Japanese and Malay were stopped for similar reasons.
On 25 October 2005 it was announced that the Bulgarian, Croatian, Czech, Greek, Hungarian, Kazakh, Polish, Slovak, Slovene and Thai language radio services would end by March 2006 to finance the launch of an Arabic and Persian language TV news channel in 2007. Additionally, Romanian broadcasts ceased on 1 August 2008.
More service closures came in January 2011 when the closing of five language services was announced as a result of the financial situation the corporation was facing following the eventual financial transfer of responsibility for the World Service from the Foreign Office to the BBC licence fee. The Albanian, Macedonian, Portuguese for Africa, Serbian, and English for the Caribbean services were closed; the Russian, Ukrainian, Mandarin Chinese, Turkish, Vietnamese, Azeri and Spanish for Cuba services ceased broadcasting a radio service and the Hindi, Indonesian, Kyrgyz, Nepali, Swahili, Kinyarwanda and Kirundi services ceased transmission on the short wave band. The British government announced that the three Balkan countries had luxuriant access to international information and continuation of broadcast in the local tongues had become unnecessary. 650 jobs went as part of the cuts and the service is facing a sixteen percent budget cut.
In March 2011 "The Guardian" published an article concerning an agreement between BBC Media Action (the BBC's broadcasting development charity) and the US State Department, in which the latter would provide the charity with a "low six figure" sum so that new technology could be developed that would stop jamming and to educate people on how to avoid state censorship should they want to. However, the agreement has caused accusations that these measures would encourage a pro-American bias within the service and would help America win the 'Information War'.
Operation.
The BBC World Service broadcasts from Broadcasting House in London, headquarters of the corporation as a whole. The service is located in the new constructions of the building and contains radio and television studios for use by the several language services. The building also contains an integrated newsroom used by the international World Service, the international television channel BBC World News, the domestic television and radio BBC News bulletins, the BBC News Channel and the BBC Website service to the World Wide Web.
Upon launch, the service was located, along with nearly all Radio output, in Broadcasting House. However, following the explosion of a parachute mine outside the building on 8 December 1940, the services relocated to new premises away from the likely target of Broadcasting House. The Overseas service relocated to premises in Oxford Street while the European service moved temporarily to the emergency broadcasting facilities at Maida Vale Studios. The European services moved permanently into Bush House towards the end of 1940, completing the move in 1941, with the Overseas services joining them in 1958. Bush House subsequently became the home of the BBC World Service and the building itself has gained a global reputation with the audience of the service. However, the building was vacated in 2012 as a result of the Broadcasting House changes and the end of the building's lease that year; the first service to move was the Burmese Service on 11 March 2012 and the final broadcast was a news bulletin broadcast at 11.00GMT on 12 July 2012.
The BBC World Service is used to describe an English 24-hour global radio network and separate services in 27 languages. News and information is available on all these languages on the BBC Website with many having RSS feeds and specific versions for use on mobile phones and some also using email notification of stories. In addition to the English service, 18 of the language services broadcast a radio service using the Short wave, AM or the FM band. These programmes are also available to listen live over the internet, can be listened to again over the internet for seven days or indefinitely in some cases and, in the case of seven language services, can be downloaded as podcasts. One can also listen to the news from the BBC News app, which is available on both iTunes and the Google Play Store. In recent years, video content has also been used by the World Service; 16 language services now show video reports in that language on the service's website and two services now have dedicated television channels – BBC Arabic launched in 2008 and BBC Persian launched in 2009. Television services are also used to broadcast the radio service, with local cable and satellite television operators providing the English network and occasionally some local language services free to air on their services. The English language service is also available on digital radio in the UK and Europe.
Traditionally, the BBC World Service relied on shortwave broadcasts, because of its ability to overcome barriers of censorship, distance and spectrum scarcity. To this end, the BBC has maintained a worldwide network of shortwave relay stations since the 1940s, mainly in former British colonies. These cross border broadcasts have also been used in special circumstances to broadcast emergency messages to British subjects abroad, such as the advice to evacuate Jordan during the Black September incidents of September 1970. These facilities were privatised in 1997 as Merlin Communications, which were later acquired and operated as part of a wider network for multiple broadcasters by VT Communications (now part of Babcock International Group). It is also common for BBC programmes to air on traditionally Voice of America or ORF transmitters, while their programming is relayed by a station physically located in the UK. However, since the 1980s, satellite distribution has made it possible for local stations to relay BBC programming.
The World Service aims to be "the world's best-known and most-respected voice in international broadcasting, thereby bringing benefit to the UK, the BBC and to audiences around the world" while retaining a "balanced British view" of international developments. Like the rest of the BBC, the World Service is a Crown corporation of the UK Government. Until 2014,
unlike the rest of the corporation, which is funded through a television licence fee, the World Service was funded through a Parliamentary grant-in-aid given by the Foreign and Commonwealth Office. In 2008/9 the BBC World Service received 12.4% of the department's £2.2 billion budget and in the financial year 2011/12, the service received £255.2 million from this grant.
In addition to broadcasting, the BBC World Service also devotes resources to the BBC Learning English programme which helps people learn English.
Languages.
Current.
In addition to the BBC World Service broadcasts in English, the service also provides services catering for 27 other languages. These are:
Of these languages, a television service operates for the Arabic and Persian languages with a smaller service on IPTV for the Russian language. A radio service exists for 18 of the language services:
Previous.
The World Service has previously operated a number of different language services, targeted to different audiences. The table lists all of the current and former language services and when they operated.
Programming.
At present, the English language service of the World Service offers a schedule consisting mainly of news and background programmes with some other cultural programmes also featuring. Mainstays of the current BBC World Service schedule include the news programmes "Newsday", "World Update", "Newshour" and "The Newsroom", and the daily arts and entertainment news programme "The Strand", which started in late 2008. There are daily science programmes, including "Health Check", the technology programme "Click" and "Science in Action". At the weekends, some of the schedule is taken up by "Sportsworld", which often includes live commentary of Premier League football matches. Other weekend sport shows include Sportshour and Stumped, a cricket partnership with All India Radio and The Australian Broadcasting Corporation. On Sundays the international, interdisciplinary discussion programme 'The Forum' is broadcast. On weekdays, an hour of the schedule is given over to "" which encourages listeners to participate in discussing current events via text message, phone calls, emails and blog postings.
Previously, other programming was broadcast including music programmes, such as those presented by John Peel, classical music programmes presented by Edward Greenfield, religious programmes with mostly Anglican celebrations, often from the Church of St. Martin in the Fields, weekly drama, educational programmes such as English-language lessons, and humour, with programmes such as "Just A Minute". Other notable previous programmes included "Letter from America" by Alistair Cooke, which was broadcast for over 50 years; "Off the Shelf", which featured a daily reading from a novel, biography or history book; and "Outlook", a long running human interest story programme, first broadcast in July 1966 and presented for more than thirty years by John Tidmarsh. Further examples of the broad range of programmes for the audience can be seen through programmes included "A Jolly Good Show", a musical requests programme presented by Dave Lee Travis; "Waveguide", a radio reception guide for listeners; "The Merchant Navy Programme", a show for seafarers presented by Malcolm Billings.
While some of this range of programming is still retained, since the late 1990s, the focus of the station has been as a news network, with news bulletins added every half-hour following the outbreak of the Iraq War.
News.
The core feature of much World Service scheduling is the news. This is almost always transmitted at one minute past the hour, where there is a five-minute bulletin, and on the half-hour where there is a two-minute summary. Sometimes these bulletins are separated from the programmes being transmitted, whilst at other times they are integral to the programme (such as with "The Newsroom", "Newshour" or "The World Today"). As part of the BBC's policy for breaking news, the BBC World Service is the first service to receive a full report for foreign news.
The BBC World Service employs a team of 7 staff announcer/newsreaders.
The following relief newsreaders can also be heard on the network:
Availability.
Africa.
Broadcasts have traditionally come from the UK, Cyprus, the large BBC Atlantic Relay Station on Ascension Island, and the smaller Lesotho Relay Station and Indian Ocean Relay Station on Seychelles. A large part of the English schedule is taken up by specialist programming from and for Africa, for example "Network Africa", "Focus on Africa" and "Africa Have Your Say". In the 1990s, the BBC added FM facilities in many African capital cities.
Americas.
BBC shortwave broadcasts to this region were traditionally enhanced by the Atlantic Relay Station and the Caribbean Relay Company, a station in Antigua run jointly with Deutsche Welle. In addition, an exchange agreement with Radio Canada International gave access to their station in New Brunswick. However, "changing listening habits" led the World Service to end shortwave radio transmission directed to North America and Australasia on 1 July 2001. A shortwave listener coalition formed to oppose the change. Both XM Radio and Sirius Satellite Radio rebroadcast the World Service over commercial satellite radio to Canada and the United States, and more than 300 public radio stations across the US carry World Service news broadcasts—mostly during the overnight and early-morning hours—over AM and FM radio, through American Public Media (APM). Listeners also have the option of calling a US number to listen to a live stream, 712-432-6580. The BBC and Public Radio International (PRI) co-produce the programme The World with WGBH Radio Boston, and the BBC is also involved with The Takeaway morning news programme based at WNYC in New York City. BBC World Service programming also airs as part of CBC Radio One's CBC Radio Overnight schedule in Canada.
The BBC continues to broadcast to Central America and South America in several languages. It is possible to receive the Western African shortwave radio broadcasts from eastern North America, but the BBC does not guarantee reception in this area. It has ended its specialist programming to the Falkland Islands but continues to provide a stream of World Service programming to the Falkland Islands Radio Service.
Asia.
For several decades, the World Service's largest audiences have been in Asia, the Middle East, Near East and South Asia. Transmission facilities in the UK and Cyprus have been supplemented by the former BBC Eastern Relay Station in Oman and the Far Eastern Relay Station in Singapore. The East Asian Relay Station moved to Thailand in 1997 when Hong Kong was handed over to Chinese sovereignty. Together, these facilities have given the BBC World Service an easily accessible signal in regions where shortwave listening has traditionally been popular. The English shortwave frequencies of 6195, 9740, 15310/360 and 17790/760 kHz are widely known.
The largest audiences are in English, Hindi, Urdu, Nepali, Bengali, Tamil, Sinhala and other major languages of South Asia, where BBC broadcasters are household names. The Persian service is the "de facto" national broadcaster of Afghanistan, along with its Iranian audience. The World Service is available up to eighteen hours a day in English across most parts of Asia, and in Arabic for the Middle East. With the addition of relays in Afghanistan and Iraq these services are accessible in most of the Middle and Near East in the evening. In Hong Kong and Singapore, the BBC World Service in English is essentially treated as a domestic broadcaster, easily available 24/7 through long-term agreements with Radio Television Hong Kong and MediaCorp Radio. In the Philippines, DZRJ 810 AM broadcasts the BBC World Service in English from 12:00–05:00 PHT (GMT+8).
Although this region has seen the launch of the only two foreign language television channels, several other services have had their radio services closed as a result of budget cuts and redirection of resources.
Jamming.
Iran, Iraq and Myanmar/Burma have all jammed the BBC in the past. Mandarin was heavily jammed by the People's Republic of China until short wave transmissions for that service ceased but China continues to jam transmissions in Uzbek and has since started to jam transmissions in English throughout Asia.
Europe.
The World Service employed a medium wave transmitter at Orford Ness to provide English-language coverage to Europe, including on the frequency 648 kHz (which could be heard in parts of the south-east of England). Transmissions on this frequency were stopped on 27 March 2011, as a consequence of the budgetary constraints imposed on the BBC World Service in the 2010 budget review. A second channel (1296 kHz) traditionally broadcast in various Central European languages, but in 2005 it began regular English-language transmissions via the Digital Radio Mondiale (DRM) format. This is a digital shortwave technology that VT expects to become the standard for cross-border transmissions in developed countries.
In the 1990s, the BBC purchased and constructed large medium wave and FM networks in the former Soviet bloc, particularly the Czech (BBC Czech Section), Slovak Republics (BBC Slovak Section), Poland (BBC Polish Section) (where it was a national network) and Russia (BBC Russian Service). It had built up a strong audience during the Cold War, whilst economic restructuring made it difficult for these governments to refuse Western investment. Many of these facilities have now returned to domestic control, as economic and political conditions have changed.
On Monday 18 February 2008, the BBC World Service stopped analogue shortwave transmissions to Europe. The notice stated, "Increasing numbers of people around the world are choosing to listen to radio on a range of other platforms including FM, satellite and online, with fewer listening on shortwave." It is sometimes possible to pick up the BBC World Service in Europe on SW frequencies targeted at North Africa. The BBC's powerful 198 kHz LW, which broadcasts the domestic BBC Radio 4 to Britain during the day (and carries the World Service during the night) can also be heard in nearby parts of Europe, including the Republic of Ireland, the Netherlands, Belgium and parts of France, Germany and Scandinavia.
On Wednesday, 10 December 2008, BBC World Service and Deutsche Welle started broadcasting a joint DRM digital radio station. It broadcasts a mix of English-language news and information programmes produced by each partner, and is aimed at an audience in mainland Europe. The station hopes, among other things, to stimulate the production of DRM radio receivers.
Former BBC shortwave transmitters are located in the United Kingdom at Rampisham, Woofferton and Skelton. The former BBC East Mediterranean Relay Station is in Cyprus.
Pacific.
Shortwave relays from Singapore (see Asia, above) continue, but historic relays via Australian Broadcasting Corporation (ABC) and Radio New Zealand International were wound down in the late 1990s. The World Service is available as part of the subscription Digital Air package (available from Foxtel and Austar) in Australia. ABC NewsRadio, SBS Radio, and various community radio stations also broadcast many programmes. Many of these stations broadcast a straight feed during the midnight to dawn period. It is also available via the satellite service Optus Aurora, which is encrypted but available without subscription.
Japan and Korea have little tradition of World Service listening, although during the 1970s to 1980s, shortwave listening was popular in Japan. In those two countries, the BBC World Service was only available via shortwave and the Internet. As of September 2007, a satellite transmission (subscription required) became available by Skylife (Channel 791) in South Korea.
In Sydney, Australia a transmission of the service can be received at 152.025 MHz. It is also available on the DAB+ Network in Australia under the name of SBS6.
BBC World Service relays on Radio Australia now carry the BBC Radio news programmes. 2MBS-FM 102.5, a classical music station in Sydney, also carries the BBC World Service news programmes at 7am and 8am on weekdays, during its 'Music for a New Day' breakfast programme.
In New Zealand, stations of the Auckland Radio Trust and the Association of Community Access Broadcasters carry some BBC World Service content including a 24/7 transmission on an AM Frequency (810 kHz) in Auckland. The BBC World Service was previously available on 1233AM in Wellington between 1990-1994, and again from 1996-1997.
UK.
The BBC World Service does not receive funding for broadcasts to the UK, and reliable medium wave reception was possible in only southeast of England from the 648 kHz service which ceased in 2011 as a cost-cutting measure. Since the introduction of digital broadcasting, the World Service's output has been made more widely available in the UK with the service now being carried on DAB, Freeview, Virgin Media and Sky platforms. The World Service is also broadcast overnight on the frequencies of BBC Radio 4 following the latter's closedown at 0100 British time.
Presentation.
The World Service uses several tunes and sounds to represent the station. The current signature tune of the station is a five note motif, composed by David Arnold and which comprises a variety of voices declaim "This is the BBC in..." before going on to name various cities (e.g. Kampala, Milan, Delhi, Johannesburg), followed by the station's slogan and the Greenwich Time Signal. This is heard throughout the network with a few variations – in the UK the full service name is spoken whereas just the name of the BBC is used outside the UK. The phrase "This is London" was used previously in place of the station slogan.
The tune "Lillibullero" is another well known signature tune of the network following its broadcast previously as part of the top-of-the-hour sequence. This piece of music is still heard before certain bulletins and as a shortened version elsewhere, but it is used less often than previously. The use of the tune has gained some controversy because of its background as a Protestant marching song in Northern Ireland.
In addition to these tunes, the BBC World Service also uses several interval signals. The English service uses a recording of the Bow Bells, made in 1926 and used a symbol of hope during the Second World War, only replaced for a brief time during the 1970s with the tune to the nursery rhyme Oranges and Lemons. The morse code of the letter "V" has also been used as a signal and was introduced in January 1941 and had several variations including timpani, the first four notes of Beethoven's Fifth Symphony (which coincide with the letter "V"), and electronic tones which until recently remained in use for some Western European services. In other languages, the interval signal is three notes, pitched B–B-C. However, these symbols have been used less frequently.
The network operates using GMT, regardless of the time zone and time of year, and is announced on the hour on the English service as "13 hours Greenwich Mean Time" (1300 GMT) or "Midnight Greenwich Mean Time" (0000 GMT). At the start of the new year, as part of an annual tradition, the BBC World Service broadcasts the chimes of Big Ben in London.
Magazine publishing.
At various times in its history, the BBC World Service has published magazines and programme guides:
Of these, only "BBC Focus on Africa" is still being published.

</doc>
<doc id="37630" url="http://en.wikipedia.org/wiki?curid=37630" title="Neutron bomb">
Neutron bomb

A neutron bomb, officially known as one type of Enhanced Radiation Weapon, is a low yield fission-fusion thermonuclear weapon (hydrogen bomb) in which the burst of neutrons generated by a fusion reaction is intentionally allowed to escape the weapon, rather than being absorbed by its other components. The weapon's radiation case, usually made from relatively thick uranium, lead or steel in a standard bomb, is, instead, made of as thin a material as possible, to facilitate the greatest escape of fusion produced neutrons. The "usual" nuclear weapon yield—expressed as kilotons of TNT equivalent—is not a measure of a neutron weapon's destructive power. It refers only to the energy released (mostly heat and blast), and does not express the lethal effect of neutron radiation on living organisms.
Compared to a pure fission bomb with an identical explosive yield, a neutron bomb would emit about ten times the amount of neutron radiation. In a fission bomb, at sea level, the total radiation pulse energy which is composed of both gamma rays and neutrons is approximately 5% of the entire energy released; in the neutron bomb it would be closer to 40%. Furthermore, the neutrons emitted by a neutron bomb have a much higher average energy level (close to 14 MeV) than those released during a fission reaction (1–2 MeV). Technically speaking, all low yield nuclear weapons are radiation weapons, that is including the non-enhanced variant. Up to about 10 kilotons in yield, all nuclear weapons have prompt neutron radiation as their most far reaching lethal component, after which point the lethal blast and thermal effects radius begins to out-range the lethal ionizing radiation radius. Enhanced radiation weapons also fall into this same yield range and simply enhance the intensity and range of the neutron dose for a given yield.
History & deployment to present.
Conception of the neutron bomb is generally credited to Samuel T. Cohen of the Lawrence Livermore National Laboratory, who developed the concept in 1958. Testing was authorized and carried out in 1963 at an underground Nevada test facility. Development was subsequently postponed by President Jimmy Carter in 1978 following protests against his administration's plans to deploy neutron warheads to ground forces in Europe. On November 17, 1978, in a test the USSR detonated its first similar-type bomb. President Ronald Reagan restarted production in 1981. The Soviet Union began a propaganda campaign against the US's neutron bomb in 1981 following Reagan's announcement. In 1983 Reagan then announced the Strategic Defense Initiative, which surpassed neutron bomb production in ambition and vision and with that the neutron bomb quickly faded from the center of the public's attention.
Three types of enhanced radiation weapons (ERW) were built by the United States. The W66 warhead, for the anti-ICBM Sprint missile system, was deployed in 1975 and retired the next year, along with the missile system. The W70 Mod 3 warhead was developed for the short-range, tactical Lance missile, and the W79 Mod 0 was developed for artillery shells. The latter two types were retired by President George H. W. Bush in 1992, following the end of the Cold War. The last W70 Mod 3 warhead was dismantled in 1996, and the last W79 Mod 0 was dismantled by 2003, when the dismantling of all W79 variants was completed.
In addition to the two superpowers, France and China are known to have tested neutron or enhanced radiation bombs. France conducted an early test of the technology in 1967 and tested an "actual" neutron bomb in 1980. China conducted a successful test of neutron bomb principles in 1984 and a successful test of a neutron bomb in 1988. However, neither country chose to deploy the neutron bomb. Chinese nuclear scientists stated prior to the 1988 test that China had no need for the neutron bomb, but it was developed to serve as a "technology reserve," in case the need arose in the future.
Although no country is currently known to deploy them in an offensive manner, all thermonuclear dial-a-yield warheads that have about 10 kiloton and lower as one dial option, with a considerable fraction of that yield derived from fusion reactions, can be considered capable of being neutron bombs in actuality if not in name. The only country definitively known to deploy dedicated (that is, not Dial-a-yield) neutron warheads for any length of time is Russia, which inherited the USSRs neutron warhead equipped ABM-3 Gazelle missile program, this Anti-ballistic missile (ABM) system contains at least 68 neutron warheads of yield 10 kiloton and it has been in service since 1995, with inert missile testing approximately every other year since then (2014). The system is designed to destroy incoming "endo-atmospheric" level nuclear warheads aimed at Moscow etc. and is the lower-tier/ last umbrella of the A-135 anti-ballistic missile system (NATO reporting name: ABM-3).
By 1984, according to Mordechai Vanunu, Israel was mass-producing neutron bombs. A number of analysts believe that the Vela incident was an Israeli neutron bomb experiment.
Considerable controversy arose in the U.S. and Western Europe following a June 1977 "Washington Post" exposé describing U.S. government plans to purchase the bomb. The article focused on the fact that it was the first weapon specifically intended to kill humans with radiation. Lawrence Livermore National Laboratory director Harold Brown and Soviet General Secretary Leonid Brezhnev both described the neutron bomb as a "capitalist bomb", because it was designed to destroy people while preserving property. Science fiction author Isaac Asimov also stated that "Such a neutron bomb or N bomb seems desirable to those who worry about property and hold life cheap."
Use of neutron bomb.
Neutron bombs are purposely designed with explosive yields lower than other nuclear weapons. Since neutrons are absorbed by air, neutron radiation effects drop off very rapidly with distance in air, there is a sharper distinction, as opposed to thermal effects, between areas of high lethality and areas with minimal radiation doses. All high yield (more than ~10 kiloton) "neutron bombs", such as the extreme example of a device that derived 97% of its energy from fusion, the 50 megaton Tsar Bomba, are not able to radiate sufficient neutrons beyond their lethal blast range when detonated as a surface burst or low altitude air burst and so are no longer classified as neutron bombs, thus limiting the yield of neutron bombs to a maximum of about 10 kilotons. The intense pulse of high-energy neutrons generated by a neutron bomb are the principal killing mechanism, not the fallout, heat or blast.
The inventor of the neutron bomb, Samuel Cohen, criticized the description of the W70 as a "neutron bomb" since it could be configured to yield 100 kilotons:
the W-70 ... is not even remotely a "neutron bomb." Instead of being the type of weapon that, in the popular mind, "kills people and spares buildings" it is one that both kills and physically destroys on a massive scale. The W-70 is not a discriminate weapon, like the neutron bomb—which, incidentally, should be considered a weapon that "kills enemy personnel while sparing the physical fabric of the attacked populace, and even the populace too."
Although neutron bombs are commonly believed to "leave the infrastructure intact", with current designs that have explosive yields in the low kiloton range, the detonation of which, in a built up area, would still cause considerable, although not total, destruction through blast and heat effects out to a considerable radius.
Neutron bombs could be used as strategic anti-ballistic missile weapons, or as tactical weapons intended for use against armored forces. The neutron bomb was originally conceived by the U.S. military as a weapon that could stop massed Soviet armored divisions from overrunning allied nations without destroying the infrastructure of the allied nation. As the Warsaw Pact tank strength was over twice that of NATO, and Soviet Deep Battle doctrine was likely to be to use this numerical advantage to rapidly sweep across continental Europe if the Cold War ever turned hot, any weapon that could break up their intended mass tank formation deployments and force them to deploy their tanks in a thinner, more easily dividable manner, would aid ground forces in the task of hunting down solitary tanks and firing anti-tank missiles upon them, such as the contemporary M47 Dragon and BGM-71 TOW missiles.
Effects of a neutron bomb in the open & in a city.
Upon detonation, a 1 kiloton neutron bomb near the ground, in an airburst would produce a large blast wave, and a powerful pulse of both thermal radiation and ionizing radiation, mostly in the form of fast (14.1 MeV) neutrons. The thermal pulse would cause third degree burns to unprotected skin out to approximately 500 meters. The blast would create at least 4.6 PSI out to a radius of 600 meters, which would severely damage all non-reinforced concrete structures, at the conventional effective combat range against modern main battle tanks and armored personnel carriers (<690–900 m) the blast from a 1 kt neutron bomb will destroy or damage to the point of non-usability almost all un-reinforced civilian building. Thus the use of neutron bombs to stop an enemy armored attack by rapidly incapacitating the crew with a dose of 8000+ Rads of radiation, which would require exploding large numbers of them to blanket the enemy forces, would also destroy all normal civilian buildings in the same immediate area ~600 meters, and via neutron activation it would make many building materials in the city radioactive, such as Zinc coated steel/galvanized steel(see Area denial use below). Although at this ~600 meter distance the 4-5 PSI blast overpressure would cause very few direct casualties as the human body is resistant to sheer overpressure, the powerful winds produced by this overpressure are capable of throwing human bodies into objects or throwing objects-including window glass at high velocity, both with potentially lethal results, rendering casualties highly dependent on surroundings, including on if the building they are in collapses. The pulse of neutron radiation would cause immediate and permanent incapacitation to unprotected outdoor humans in the open out to 900 meters, with death occurring in one or two days. The lethal dose(LD50) of 600 Rads would extend to about 1350–1400 meters for those unprotected and outdoors, where approximately half of those exposed would die of radiation sickness after several weeks.
However a human residing within, or is simply shielded by at least 1 of the aforementioned concrete buildings with walls and ceilings 30 centimeters/12 inches thick, or alternatively of damp soil 24 inches thick, the neutron radiation exposure would be reduced by a factor of 10.
Furthermore the neutron absorption spectra of air is disputed by some authorities and depends in part on absorption by hydrogen from water vapor. It therefore might vary exponentially with humidity, making neutron bombs immensely more deadly in desert climates than in humid ones.
Questionable effectiveness in modern anti-tank role.
The questionable effectiveness of ER weapons against modern tanks is cited as one of the main reasons that these weapons are no longer fielded or stockpiled. With the increase in average tank armor thickness since the first ER weapons were fielded, tank armor protection approaches the level where tank crews are now almost completely protected from radiation effects. Therefore for an ER weapon to incapacitate a modern tank crew through irradiation, the weapon must now be detonated at such a close proximity to the tank that the nuclear explosion's blast would now be equally effective at incapacitating it and its crew. However this assertion was regarded as dubious in a reply in 1986 by a member of the Royal Military College of Science as neutron radiation from a 1 kiloton neutron bomb would incapacitate the crew of a tank with a Protection Factor of 35 out to a range of 280 meters, but the incapacitating blast range, depending on the exact weight of the tank, is much less, from 70 to 130 meters. However although the author did note that effective neutron absorbers and neutron poisons such as Boron carbide can be incorporated into conventional armor and strap on neutron moderating hydrogenous material (hydrogen atom containing substances), such as Explosive Reactive Armor can both increase the protection factor, the author holds that in practice combined with neutron scattering, the actual average total tank area protection factor is rarely higher than 15.5 to 35. According to the Federation of American Scientists, the neutron protection factor of a "tank" can be as low as 2, without qualifying the tank statement is for a light tank(tankette) or medium tank/main battle tank.
A composite high density concrete, or alternatively, a laminated Graded Z shield, 24 units thick of which 16 units are iron and 8 units are polyethylene containing boron (BPE) and additional mass behind it to attenuate neutron capture gamma rays is more effective than just 24 units of pure iron or BPE alone, due to the advantages of both iron and BPE in combination. Iron is effective in slowing down/scattering high-energy neutrons in the 14-MeV energy range and attenuating gamma rays, while the hydrogen in polyethylene is effective in slowing down these now slower fast neutrons in the few MeV range, and boron 10 has a high absorption cross section for thermal neutrons and a low production yield of gamma rays when it absorbs a neutron. The Soviet T72 tank, in response to the neutron bomb threat, is cited as having fitted a boronated, polyethylene liner, which has had its neutron shielding properties simulated.
However as some tank armor material contains depleted uranium(DU), common in the US's M1A1 Abrams tank, which "incorporates steel-encased depleted uranium armour", a substance that will fast fission when it captures a fast, fusion generated neutron, and therefore upon fissioning it will produce fission neutrons and fission products embedded within the armor, products which emit amongst other things, penetrating gamma rays. Although the neutrons emitted by the neutron bomb may not penetrate to the tank crew in lethal quantities, the fast fission of DU within the armor could still ensure a lethal environment for the crew and maintenance personnel by fission neutron and gamma ray exposure, largely depending on the exact thickness and elemental composition of the armor - information usually hard to attain. Despite this, DUCRETE - which has an elemental composition similar to, but not identical to the ceramic 2nd generation heavy metal Chobham armor of the Abrams tank- DUCRETE is an effective radiation shield, to both "fission" neutrons and gamma rays due to it being a graded Z material. Uranium being about twice as dense as lead is thus nearly twice as effective at shielding gamma ray radiation per unit thickness.
Use against ballistic missiles.
As an anti-ballistic missile weapon, the first fielded ER warhead, the W66, was developed for the Sprint missile system as part of the Safeguard Program to protect United States cities and missile silos from incoming Soviet warheads by damaging their electronic components with the intense neutron flux. Ionization greater than 5,000 rads in silicon chips delivered over seconds to minutes will degrade the function of semiconductors for long periods. Due to the rarefied atmosphere encountered high above the earth at the most likely intercept point of an incoming warhead by a neutron bomb/warhead, whether it be the retired Sprint missile's W66 neutron warhead or the still in service Russian counterpart, the ABM-3 Gazelle, at the Terminal phase point(10–30 km) of the incoming warheads flight, the neutrons generated by a Mid to High-altitude nuclear explosion(HANE) have an even greater range than that encountered after a low altitude air burst, where there is a lower density of air molecules that produces, by comparison, an appreciable reduction in the air shielding effect/half-value thickness.
However, although this neutron transparency advantage attained only increases at increased altitudes, neutron effects lose importance in the exoatmospheric environment, being overtaken by the range of another effect of a nuclear detonation, at approximately the same altitude as the end of the incoming missile's boost phase(~150 km), ablation producing soft x-rays are the chief nuclear effects threat to the survival of incoming missiles and warheads rather than neutrons. A factor exploited by the other warhead of the Safeguard Program, the enhanced (X-ray) radiation W71 and its USSR/Russian counterpart, the warhead on the A-135 Gorgon missile.
Another method by which neutron radiation can be used to destroy incoming nuclear warheads is by serving as an intense neutron generator and to thus initiate fission in the incoming warheads fissionable components by fast fission, potentially causing the incoming warhead to prematurely detonate in a Fizzle if within sufficient proximity, but in most likely interception ranges, requiring only that enough fissionable material in the warhead fissions to interfere with the functioning of the incoming warhead when it is later fuzed to explode(see related physics:Subcritical reactor).
Lithium-6 Hydride("Li6H") is cited as being used as a countermeasure to reduce the vulnerability/"harden" nuclear warheads from the effects of externally generated neutrons.
Radiation hardening of the warheads electronic components as a countermeasure to high altitude neutron warheads, somewhat reduces the range that a neutron warhead could successfully cause an unrecoverable glitch by the "TREE"(Transient Radiation effects on Electronics) mechanism.
Use as an area denial weapon.
In November 2012, during the planning stages of Operation Hammer of God, it was suggested by a British parliamentarian that multiple enhanced radiation reduced blast (ERRB) warheads could be detonated in the mountain region of the Afghanistan/Pakistan border to prevent infiltration. He proposed to warn the inhabitants to evacuate, then irradiate the area, making it unusable and impassable. Used in this manner, the neutron bomb(s), regardless of burst height, would release neutron activated casing materials used in the bomb, and depending on burst height, create radioactive soil activation products.
In much the same fashion as the area denial effect resulting from fission product (the substances that make up the majority of fallout) contamination in an area following a conventional surface burst nuclear explosion, as considered in the Korean War by Douglas MacArthur, it would thus be a form of Radiological warfare - with the difference that neutron bombs produce 1/2, or less, of the quantity of fission products when compared to the same-yield pure fission bomb. Radiological warfare with neutron bombs that rely on fission primaries would therefore still produce fission fallout, albeit a comparatively "cleaner" and shorter lasting version of it in the area if air bursts were utilized, as little to no fission products would be deposited on the direct immediate area, instead becoming diluted global fallout.
However the most effective use of a neutron bomb with respect to area denial would be to encase it in a thick shell of material that could be neutron activated, and use a surface burst. In this manner the neutron bomb would be turned into a "salted bomb", a case of Zinc-64, produced as a byproduct of depleted zinc oxide enrichment, would for example probably be the most attractive from a military point of view, as when activated the Zinc-65 that is created is a gamma emitter, with a half life of 244 days.
Maintenance.
Neutron bombs/warheads require considerable maintenance for their capabilities, requiring some tritium for fusion boosting and tritium in the secondary stage (yielding more neutrons), in amounts on the order of a few tens of grams (10–30 grams estimated). Because tritium has a relatively short half-life of 12.32 years (after that time, half the tritium has decayed), it is necessary to replenish it periodically in order to keep the bomb effective. (For instance: to maintain a constant level of 24 grams of tritium in a warhead, about 1 gram per bomb per year must be supplied.) Moreover, tritium decays into helium-3, which absorbs neutrons and will thus further reduce the bomb's neutron yield.

</doc>
<doc id="37632" url="http://en.wikipedia.org/wiki?curid=37632" title="Fighting Fantasy">
Fighting Fantasy

Fighting Fantasy is a series of single-player roleplay gamebooks created by Steve Jackson and Ian Livingstone. The first volume in the series was published by Puffin in 1982, with the rights to the series eventually being purchased by Wizard Books in 2002. The series distinguished itself by featuring a role-playing element, with the caption on many of the covers claiming each title was an adventure "in which YOU are the hero!" The majority of the titles followed a fantasy theme, although science fiction, post-apocalyptic, superhero, and modern horror also featured. The popularity of the series led to the creation of merchandise such as action figures, board games, role-playing game systems, magazines, novels and video games.
Overview.
The "Fighting Fantasy" gamebooks were created by British writers Steve Jackson and Ian Livingstone, co-founders of Games Workshop, and provide an original twist on traditional fiction in that the reader takes control of the story's protagonist, being required to make choices that will affect the outcome.
The text does not progress in a linear fashion but rather is divided into a series of numbered sections (usually between 300-400). Beginning at the first section, the reader chooses a non-sequential option (e.g. Section 1 to Section 180) which in turn provides an outcome for the decision and advances the story. The story continues in this fashion, the player continuing to choose other numbered sections, until their character is either stopped, killed, or completes the quest.
"Fighting Fantasy" books typically feature a system whereby the protagonist is randomly assigned scores in three statistics (named Skill, Stamina, and Luck) which, in conjunction with the player rolling a six-sided die, are used to resolve combats and test the protagonist's success in certain situations. Some titles use additional statistics or additional conflict resolution mechanics. A typical "Fighting Fantasy" gamebook tasks players with completing a quest, with players then making choices in an attempt to successfully finish the adventure. A successful play of a "Fighting Fantasy" gamebook usually ends with the player reaching the final numbered section of the book. Many of the titles only feature one path to the solution, and in some cases this can only be achieved by obtaining various story items (e.g. gems in "Deathtrap Dungeon").
There were 59 books in the original series, beginning with "The Warlock of Firetop Mountain" (Steve Jackson & Ian Livingstone, 1982) and concluding with "Curse of the Mummy" (Jonathan Green, 1995).
Jackson also wrote a self-contained four-part series titled "Sorcery!" (1983-1985). Andrew Chapman and Martin Allen also wrote a two book, two-player adventure titled the "Clash of the Princes" (1986). There were also several supplemental books produced that provided more information about the Fighting Fantasy universe, including a comprehensive bestiary of monsters and a sample adventure.
The majority of the Fighting Fantasy titles are set in the fictional medieval world of Titan, which consists of three giant continents. Other titles are set in fantasy, horror, modern day, and sci-fi environments.
Wizard Books acquired the rights to the Fighting Fantasy series in 2002, and have since published reprints of older titles and several new titles in a revised order.
All "Fighting Fantasy" gamebooks are illustrated, including full-page pieces and smaller, generic images scattered at random throughout the book, often serving as breaks or space fillers between sections. Regular contributors included Les Edwards, Terry Oakes, Russ Nicholson, Leo Hartas, Ian Miller, John Blanche, Martin McKenna, and Iain McCaig.
Publication history.
In 1980, Steve Jackson and Ian Livingstone attended a Games Day, and after meeting with a Penguin editor decided to create a series of single-player gamebooks. Their first submission, "The Magic Quest", was a short adventure intended to demonstrate the style of game. "The Magic Quest" was eventually accepted by Penguin Books, although the authors devoted a further six months to expanding and improving upon the original concept. The end result was "The Warlock of Firetop Mountain", and after several rewrites, the book was accepted and published in 1982 under Penguin's children's imprint, Puffin Books.
Following the success of the first Fighting Fantasy title, Jackson and Livingstone began writing individually to create additional Fighting Fantasy gamebooks. In 1983, "The Citadel of Chaos" and "The Forest of Doom" were published, by Jackson and Livingstone respectively. Four more titles followed: "Starship Traveller" (the first title with a science fiction setting), "City of Thieves", "Deathtrap Dungeon" and "Island of the Lizard King". In 1984, a decision was made to hire more writers to continue the series: Steve Jackson (the United States-based founder and owner of Steve Jackson Games),
Andrew Chapman, Carl Sargent (aka Keith Martin), Marc Gascoigne and Peter Darvill-Evans.
Jackson and Livingstone, however, continued to be involved and approved all cover and internal illustrations within the UK. Regular contributors included Les Edwards; Terry Oakes; Russ Nicholson; Leo Hartas; Ian Miller, John Blanche and Iain McCaig. Covers were rarely consistent and due to printing errors and different markets many different versions exist. Once Wizard acquired the franchise different versions with a new logo were printed, the rationale being that the old covers did not suit the modern market.
The Fighting Fantasy Gamebooks published in the US by Dell/Laurel Leaf featured a new cover design and illustrations by Richard Corben.
Jackson wrote a self-contained four-part series titled "Sorcery!" (1983-1985), that combined the use of combat and sorcery. The books also featured dice images at the bottom of each page, making it possible for the player to randomly "flick" through the pages for the equivalent of a dice roll. The Fighting Fantasy titles published by Wizard Books use the same device.
Although the Fighting Fantasy titles had successful sales the increasing dominance of video games in the 1990s caused a gradual decline. The series was scheduled to conclude with "Return to Firetop Mountain" (Book 50, Livingstone, 1992), but due to increased sales ten more books were written. Nine were published, the series ending with the "Curse of the Mummy" (1995). The tenth title "Bloodbones" (Book 60 in the overall series numbering), was eventually published by Wizard Books.
In 1989, Fighting Fantasy was reworked into a multiplayer system referred to as "Advanced Fighting Fantasy", with a number of support titles explaining the concept.
In 2002, Wizard Books acquired the rights to the "Fighting Fantasy" series and reprinted many of the original titles in a revised order to fit the reduced number of books (initially only the gamebooks by Jackson and Livingstone were published) and to incorporate the "Sorcery!" miniseries into the core series.
A new "Fighting Fantasy" title, "Eye of the Dragon" (by Ian Livingstone) was released by Wizard Books in 2005, with reprints of original titles commencing the following year. 2007 marked the twenty-fifth anniversary of "Fighting Fantasy", and to commemorate the event Wizard Books published a special hardcover edition of "The Warlock of Firetop Mountain" that used the original 1982 cover image and contained extra material such as the dungeon solution and a commentary on "Fighting Fantasy" by Livingstone. Wizard Books has since released several new titles including "Blood of the Zombies" by Ian Livingstone to celebrate the thirtieth anniversary in 2012.
Other media.
Warlock magazine (first published by Puffin Books and later Games Workshop) provided additional information on the "Fighting Fantasy" universe, and each issue featured a gamebook, new rules, monsters, reviews and comic strips. It was published from 1983-1986 and ran for 13 issues.
In 1984, Steve Jackson published a roleplaying game, "Fighting Fantasy - The Introductory Role-playing Game". A second version was published in 1989 as "Advanced Fighting Fantasy" (AFF).
In 1985, Steve Jackson wrote a picture gamebook with the title "Tasks of Tantalon", in which the player was required to solve a series of puzzles which were presented as large, full colour pictures containing hidden clues to be located and assembled.
"The Warlock of Firetop Mountain" (1986) and "Legend of Zagor" (1993) were released as board games by Games Workshop and Parker Brothers respectively.
In 1992, a "Fighting Fantasy" "10th Anniversary Yearbook" (a diary with articles, trivia and a gamebook) complete with a boxed set of dice and character sheets was published.
Several of the Fighting Fantasy titles have been released as video games, including seven "Fighting Fantasy" titles ("The Warlock of Firetop Mountain", "The Citadel of Chaos", "The Forest of Doom", "Temple of Terror", "Seas of Blood", "Appointment with F.E.A.R." and "Rebel Planet") for the Commodore 64, Amstrad, BBC, and Sinclair ZX Spectrum (1984) and "Deathtrap Dungeon" for the PC and PlayStation by Eidos Interactive (1998). On August 18, 2011 an adaption of "Talisman of Death" was released by UK developer Laughing Jackal for the "PlayStation Minis" platform (playable on the PlayStation Portable and PlayStation 3). On December 5, 2006, it was announced that Jackson and Livingstone were planning to release a new series of video games based on "Fighting Fantasy" for Nintendo DS and Sony's PSP. The first of these, "", was released for the DS in the United States on November 25, 2009, and for the Apple iPhone and iPod in early January 2010.
In 2010, Super Team Film Prods secured the rights to "House of Hell", with the intention to make a motion picture based on the title.
On February 10, 2011 an Amazon Kindle edition of "The Warlock of Firetop Mountain" was launched by UK developer Worldweaver Ltd, for the US market. "Warlock" and four other gamebooks were released on iOS by Big Blue Bubble, but retracted from the app store in 2012 when they lost the licence. Australian game developers "Tin Man Games" have since published several iOS and Android versions of Fighting Fantasy books, including "Blood of the Zombies", "House of Hell", "Forest of Doom", "Island of the Lizard King" and "Starship Traveller", and Cambridge-based studio Inkle released an interactive version of "The Shamutanti Hills", the first part of the Sorcery! series, for iOS in May 2013. The second instalment is also available on iOS, while the first is available on Android and Kindle. Another iOS version of the same instalment was released by Bright Al Ltd in 2010.

</doc>
<doc id="37633" url="http://en.wikipedia.org/wiki?curid=37633" title="Mount Aetna">
Mount Aetna

Mount Aetna may refer to:

</doc>
<doc id="37635" url="http://en.wikipedia.org/wiki?curid=37635" title="National Academies (United States)">
National Academies (United States)

The National Academies serve (collectively) as the scientific national academy for the United States (US). The National Academies comprises four organizations: the National Academy of Sciences (NAS), the National Academy of Engineering (NAE), the Institute of Medicine (IOM), and the National Research Council (NRC)
The US National Academy of Sciences was created by an Act of Incorporation in 1863, which was signed by the President of the United States Abraham Lincoln. Under this congressional charter, the National Research Council was created in 1916, the National Academy of Engineering in 1964, and the Institute of Medicine in 1970.
Honorary societies.
The NAS, NAE, and IOM are honorary membership organizations, with a total membership of over 6,300 scientists, engineers, and health professionals. New members for each organization are elected annually by current members, based on their distinguished and continuing achievements in original research. The organizations serve "pro bono" as "advisers to the nation on science, engineering, and medicine."
National Research Council.
The NRC is the "working arm" of the Academies, which serves to collect, analyze, and share information through studies and reports.
The National Academies produce independent recommendations and policy reports by enlisting top scientists, engineers, health professionals, and other experts (not limited to those in Academies membership) to address the scientific and technical aspects of some of society's problems. These experts volunteer to serve on study committees that are convened to answer specific sets of questions. All committee members serve without pay.
The National Academies do not perform original research; rather they provide independent advice. Federal agencies are the primary financial sponsors of the Academies' work; additional studies are funded by state agencies, foundations, other private sponsors, and the National Academies endowment. The external sponsors have no control over the conduct or results of a study, once the statement of task and budget are finalized.
Study committees gather information from many sources in public meetings but deliberate in private in order to avoid political, special interest, and sponsor influence.
Through this study process, the National Academies produce around 200 reports each year. Recent reports cover such topics as addressing the obesity epidemic, the use of forensics in the courtroom, invasive plants, pollinator collapse, underage drinking, the Hubble Telescope, vaccine safety, the hydrogen economy, transportation safety, climate change, and homeland security. Many reports influence policy decisions; some are instrumental in enabling new research programs; others provide independent program reviews.
Other activities.
The National Academies Press is the publisher for the National Academies, and makes its publications available for free online reading, as it has since 1994, the first self-sustaining book publisher to do so.
The National Academies also administer the Marian Koshland Science Museum.
The Christine Mirzayan Science and Technology Policy Fellowship is an annual program for current or recent graduate students to spend three months working in the National Academies.

</doc>
<doc id="37636" url="http://en.wikipedia.org/wiki?curid=37636" title="Encephalitis">
Encephalitis

Encephalitis (from Ancient Greek ἐγκέφαλος, "enképhalos" “brain”, composed of ἐν, "en", “in” and κεφαλή, "kephalé", “head”, and the medical suffix "-itis" “inflammation”) is an acute inflammation of the brain. Encephalitis with meningitis is known as meningoencephalitis. Symptoms include headache, fever, confusion, drowsiness, and fatigue. More advanced and serious symptoms include seizures or convulsions, tremors, hallucinations, stroke, hemorrhaging, and memory problems.
In 2013 encephalitis was estimated to have resulted in 77,000 deaths down from 92,000 in 1990. 
Signs and symptoms.
Adult patients with encephalitis present with acute onset of fever, headache, confusion, and sometimes seizures. Younger children or infants may present irritability, poor appetite and fever.
Neurological examinations usually reveal a drowsy or confused patient. Stiff neck, due to the irritation of the meninges covering the brain, indicates that the patient has either meningitis or meningoencephalitis.
Cause.
Viral.
Viral encephalitis can occur either as a direct effect of an acute infection, or as one of the sequelae of a latent infection. The most common causes of acute viral encephalitis are rabies virus, Herpes simplex, poliovirus, measles virus, varicella zoster virus, and JC virus. Other causes include infection by flaviviruses such as Japanese encephalitis virus, St. Louis encephalitis virus or West Nile virus, or by Togaviridae such as Eastern equine encephalitis virus (EEE virus), Western equine encephalitis virus (WEE virus) or Venezuelan equine encephalitis virus (VEE virus), variola minor virus and variola major virus. Henipaviruses; Hendra (HeV) and Nipah (NiV), are also known to cause viral encephalitis.
Bacterial and other.
It can be caused by a bacterial infection, such as bacterial meningitis, spreading directly to the brain (primary encephalitis), or may be a complication of a current infectious disease syphilis (secondary encephalitis). Certain parasitic or protozoal infestations, such as toxoplasmosis, malaria, or primary amoebic meningoencephalitis, can also cause encephalitis in people with compromised immune systems. Lyme disease and/or "Bartonella henselae" may also cause encephalitis. "Cryptococcus neoformans" is notorious for causing fungal encephalitis in the immunocompromised. "Streptococci", "Staphylococci" and certain Gram-negative bacilli cause cerebritis prior to the formation of a brain abscess.
Limbic system encephalitis.
In a large number of cases, called limbic encephalitis, the pathogens responsible for encephalitis attack primarily the limbic system (a collection of structures at the base of the brain responsible for emotions and many other basic functions).
Autoimmune encephalitis.
It has recently been recognised that there are types of encephalitis resulting from an attack of the brain by the body's immune system. These autoimmune conditions include but are not limited to VGKC antibody associated encephalitis, Anti-GAD antibody associated encephalitis, NMDA receptor antibody associated encephalitis, and Hashimoto's encephalitis.
The majority of patients with autoimmune encephalitis do not harbor a tumor and the etiology of the disease in these patients is less clear, often leading to a delayed diagnosis.
Encephalitis lethargica.
Encephalitis lethargica is an atypical form of encephalitis which caused an epidemic from 1918 to 1930. Those who survived sank into a semi-conscious state that lasted for decades. Neurologist Oliver Sacks used the Parkinson's drug L-DOPA to revive those still alive in the late 1960s.
There have been only a small number of isolated cases in the years since, though in recent years a few patients have shown very similar symptoms. The cause is now thought to be either a bacterial agent or an autoimmune response following infection.
Diagnosis.
Examination of the cerebrospinal fluid obtained by a lumbar puncture procedure usually reveals increased amounts of protein and white blood cells with normal glucose, though in a significant percentage of patients, the cerebrospinal fluid may be normal. CT scan often is not helpful, as cerebral abscess is uncommon. Cerebral abscess is more common in patients with meningitis than encephalitis. Bleeding is also uncommon except in patients with herpes simplex type 1 encephalitis. Magnetic resonance imaging offers better resolution. In patients with herpes simplex encephalitis, electroencephalograph may show sharp waves in one or both of the temporal lobes. Lumbar puncture procedure is performed only after the possibility of prominent brain swelling is excluded by a CT scan examination. Diagnosis is often made with detection of antibodies in the cerebrospinal fluid against a specific viral agent (such as herpes simplex virus) or by polymerase chain reaction that amplifies the RNA or DNA of the virus responsible (such as varicella zoster virus). Serological tests may show high antibody titre against the causative antigen.
Treatment.
Treatment is usually symptomatic. Reliably tested specific antiviral agents are few in number (e.g. acyclovir for herpes simplex virus) and are used with limited success in treatment of viral infection, with the exception of herpes simplex encephalitis. In patients who are very sick, supportive treatment, such as mechanical ventilation, is equally important. Corticosteroids (e.g., methylprednisolone) are used to reduce brain swelling and inflammation. Sedatives may be needed for irritability or restlessness. For "Mycoplasma" infection, parenteral tetracycline is given. Encephalitis due to "Toxoplasma" is treated by giving a combination of pyrimethamine and sulphadimidine.
Prevention.
Vaccination is available against tick-borne and Japanese encephalitis and should be considered for at-risk individuals.
Post-infectious encephalomyelitis complicating small pox vaccination is avoidable as small pox is now eradicated. Contraindication to Pertussis immunisation should be observed in patients with encephalitis. An immunodeficient patient who has had contact with chicken pox virus should be given prophylaxis with hyperimmune zoster immunoglobulin.
Epidemiology.
The incidence of acute encephalitis in Western countries is 7.4 cases per 100,000 population per year. In tropical countries, the incidence is 6.34 per 100,000 per year. In 2013 encephalitis was estimated to have resulted in 77,000 deaths down from 92,000 in 1990.
Herpes simplex encephalitis has an incidence of 2–4 per million population per year.

</doc>
<doc id="37637" url="http://en.wikipedia.org/wiki?curid=37637" title="Nucleophile">
Nucleophile

A nucleophile is a chemical species that donates an electron pair to an electrophile to form a chemical bond in relation to a reaction. All molecules or ions with a free pair of electrons or at least one pi bond can act as nucleophiles. Because nucleophiles donate electrons, they are by definition Lewis bases.
Nucleophilic describes the affinity of a nucleophile to the nuclei. Nucleophilicity, sometimes referred to as nucleophile strength, refers to a substance's nucleophilic character and is often used to compare the affinity of atoms.
Neutral nucleophilic reactions with solvents such as alcohols and water are named solvolysis. Nucleophiles may take part in nucleophilic substitution, whereby a nucleophile becomes attracted to a full or partial positive charge.
History.
The terms "nucleophile" and "electrophile" were introduced by Christopher Kelk Ingold in 1929, replacing the terms "anionoid" and "cationoid" proposed earlier by A. J. Lapworth in 1925.
The word nucleophile is derived from nucleus and the Greek word φιλος, philos for love.
Properties.
In general, in a row across the periodic table, the more basic the ion (the higher the pKa of the conjugate acid) the more reactive it is as a nucleophile. In a given group, polarizability is more important in the determination of the nucleophilicity: The easier it is to distort the electron cloud around an atom or molecule the more readily it will react; e.g., the iodide ion (I−) is more nucleophilic than the fluoride ion (F−).
Nucleophilicity.
Many schemes attempting to quantify relative nucleophilic strength have been devised. The following empirical data have been obtained by measuring reaction rates for a large number of reactions involving a large number of nucleophiles and electrophiles. Nucleophiles displaying the so-called alpha effect are usually omitted in this type of treatment.
Swain-Scott equation.
The first such attempt is found in the Swain–Scott equation derived in 1953:
This free-energy relationship relates the pseudo first order reaction rate constant (in water at 25 °C), "k", of a reaction, normalized to the reaction rate, "k"0, of a standard reaction with water as the nucleophile, to a nucleophilic constant "n" for a given nucleophile and a substrate constant "s" that depends on the sensitivity of a substrate to nucleophilic attack (defined as 1 for methyl bromide).
This treatment results in the following values for typical nucleophilic anions: acetate 2.7, chloride 3.0, azide 4.0, hydroxide 4.2, aniline 4.5, iodide 5.0, and thiosulfate 6.4. Typical substrate constants are 0.66 for ethyl tosylate, 0.77 for β-propiolactone, 1.00 for 2,3-epoxypropanol, 0.87 for benzyl chloride, and 1.43 for benzoyl chloride.
The equation predicts that, in a nucleophilic displacement on benzyl chloride, the azide anion reacts 3000 times faster than water.
Ritchie equation.
The Ritchie equation, derived in 1972, is another free-energy relationship:
where "N"+ is the nucleophile dependent parameter and "k"0 the reaction rate constant for water. In this equation, a substrate-dependent parameter like "s" in the Swain–Scott equation is absent. The equation states that two nucleophiles react with the same relative reactivity regardless of the nature of the electrophile, which is in violation of the Reactivity–selectivity principle. For this reason this equation is also called the "constant selectivity relationship".
In the original publication the data were obtained by reactions of selected nucleophiles with selected electrophilic carbocations such as tropylium or diazonium cations:
or (not displayed) ions based on Malachite green. Many other reaction types have since been described.
Typical Ritchie N+ values (in methanol) are: 0.5 for methanol, 5.9 for the cyanide anion, 7.5 for the methoxide anion, 8.5 for the azide anion, and 10.7 for the thiophenol anion. The values for the relative cation reactivities are -0.4 for the malachite green cation, +2.6 for the benzenediazonium cation, and +4.5 for the tropylium cation.
Mayr-Patz equation.
In the Mayr-Patz equation (1994):
The second order reaction rate constant k at 20°C for a reaction is related to a nucleophilicity parameter N, an electrophilicity parameter E, and a nucleophile-dependent slope parameter s. The constant s is defined as 1 with "2-methyl-1-pentene" as the nucleophile.
Many of the constants have been derived from reaction of so-called benzhydrylium ions as the electrophiles:
and a diverse collection of π-nucleophiles:
Typical E values are +6.2 for R = chlorine, +5.90 for R = hydrogen, 0 for R = methoxy and -7.02 for R = dimethylamine.
Typical N values with s in parenthesis are -4.47 (1.32) for electrophilic aromatic substitution to toluene (1), -0.41 (1.12) for electrophilic addition to 1-phenyl-2-propene (2), and 0.96 (1) for addition to 2-methyl-1-pentene (3), -0.13 (1.21) for reaction with triphenylallylsilane (4), 3.61 (1.11) for reaction with 2-methylfuran (5), +7.48 (0.89) for reaction with isobutenyltributylstannane (6) and +13.36 (0.81) for reaction with the enamine 7.
The range of organic reactions also include SN2 reactions:
With E = -9.15 for the "S-methyldibenzothiophenium ion", typical nucleophile values N (s) are 15.63 (0.64) for piperidine, 10.49 (0.68) for methoxide, and 5.20 (0.89) for water. In short, nucleophilicities towards sp2 or sp3 centers follow the same pattern.
Unified equation.
In an effort to unify the above described equations the Mayr equation is rewritten as:
with sE the electrophile-dependent slope parameter and sN the nucleophile-dependent slope parameter. This equation can be rewritten in several ways:
Types.
Examples of nucleophiles are anions such as Cl−, or a compound with a lone pair of electrons such as NH3 (ammonia).
In the example below, the oxygen of the hydroxide ion donates an electron pair to bond with the carbon at the end of the bromopropane molecule. The bond between the carbon and the bromine then undergoes heterolytic fission, with the bromine atom taking the donated electron and becoming the bromide ion (Br−), because a SN2 reaction occurs by backside attack. This means that the hydroxide ion attacks the carbon atom from the other side, exactly opposite the bromine ion. Because of this backside attack, SN2 reactions result in a reversal of the configuration of the electrophile. If the electrophile is chiral, it typically maintains its chirality, though the SN2 product's configuration is flipped as compared to that of the original electrophile.
An ambident nucleophile is one that can attack from two or more places, resulting in two or more products. For example, the thiocyanate ion (SCN−) may attack from either the S or the N. For this reason, the SN2 reaction of an alkyl halide with SCN− often leads to a mixture of RSCN (an alkyl thiocyanate) and RNCS (an alkyl isothiocyanate). Similar considerations apply in the Kolbe nitrile synthesis.
Carbon.
Carbon nucleophiles are alkyl metal halides found in the Grignard reaction, Blaise reaction, Reformatsky reaction, and Barbier reaction, organolithium reagents, and anions of a terminal alkyne.
Enols are also carbon nucleophiles. The formation of an enol is catalyzed by acid or base. Enols are ambident nucleophiles, but, in general, nucleophilic at the alpha carbon atom. Enols are commonly used in condensation reactions, including the Claisen condensation and the aldol condensation reactions.
Oxygen.
Examples of oxygen nucleophiles are water (H2O), hydroxide anion, alcohols, alkoxide anions, hydrogen peroxide, and carboxylate anions
Nuclophilic attack does not take place during intermolecular hydrogen bonding.
Sulfur.
Of sulfur nucleophiles, hydrogen sulfide and its salts, thiols (RSH), thiolate anions (RS−), anions of thiolcarboxylic acids (RC(O)-S−), and anions of dithiocarbonates (RO-C(S)-S−) and dithiocarbamates (R2N-C(S)-S−) are used most often.
In general, sulfur is very nucleophilic because of its large size, which makes it readily polarizable, and its lone pairs of electrons are readily accessible.
Nitrogen.
Nitrogen nucleophiles include ammonia, azide, amines, and nitrites.

</doc>
<doc id="37638" url="http://en.wikipedia.org/wiki?curid=37638" title="National Research Council (United States)">
National Research Council (United States)

The National Research Council (NRC) is the working arm of the United States National Academies, which produces reports that shape policies, inform public opinion, and advance the pursuit of science, engineering, and medicine.
The National Academies include: 
Unlike the other three organizations of the National Academies, the National Research Council is not a membership organization.
History.
The National Research Council was organized on June 19, 1916 by the National Academy of Sciences under its congressional charter at the request of then President Woodrow Wilson. The purpose of the Council (originally called the National Research Foundation) was in part to foster and encourage ..."the increased use of scientific research in the development of American industries...the employment of scientific methods in strengthening the national defense ...and such other applications of science as will promote the national security and welfare." At that same time, the Academy's first effort to support that national defense readiness was created, the Committee on Nitric Acid Supply, approved by Secretary of War Baker. Nitric acid was the substance basic in the making of propellants such as Cordite, high explosives, dyes, fertilizers, and other products but availability was limited due to the War. The NRC thru its committee recommended importing Chilean saltpeter and the construction of four new ordnance plants. These recommendations were accepted by the War Department in June 1917 although the plants were not completed prior to the end of the war. Wilson then formalized the NRC's existence in executive order 2859 in 1918.
During the period that the United States was at war, the National Research Council operated as the Department of Science and Research of the Council of National Defense; also, as the Science and Research Division of the United States Army Signal Corps. When war was first declared, the Council had organized committees on
antisubmarine and gas warfare.
In June 1, 1917, the council convened a meeting of scientific representatives of the UK and France with interested parties from the US on the subject of submarine detection. The results obtained and the problems in the work were discussed. A further meeting with the British and French was held in Paris in October 1918 at which more details of their work was disclosed. As a result of this, the council recommended that US scientists be brought together to work on the problems. A New York Group worked on "supersonics" as did a San Pedro Group. A New London Group worked on binaural receivers, while Chicago and Wisconsin Groups were assigned various problems in support of the other groups.
Due to the success of Council-directed research in producing a sound-based method of detecting submarines, as well as other military innovations, the NRC was retained at the end of the war, though it was gradually decoupled from the military. The Research Council is currently administered jointly by the National Academy of Sciences, the National Academy of Engineering, and the Institute of Medicine, and its work is overseen by a Governing Board and an Executive Committee.
Organization.
The National Research Council or NRC, performs its studies and workshops through six major divisions; Behavioral and Social Sciences and Education, Earth and Life Studies, Engineering and Physical Sciences, Policy and Global Affairs, Transportation Research Board, and the Gulf Research Program.
Ralph J. Cicerone is the president of the National Academy of Sciences and the chair of the NRC.
C. Daniel Mote, Jr. was the President of the National Academy of Engineering and Vice Chair of the NRC.
NRC volunteers are drawn from the councils of the National Academy of Sciences, the National Academy of Engineering, the Institute of Medicine as well as the wider scientific population. The members of its committees are chosen for their special competences and with regard for appropriate balance and serve pro-bono. All NRC reports go through an extensive external review facilitated by the NRC internal Report Review Committee (also consisting of members from the NAS, NAE, and IOM).
Report on climate change.
In 2001, the Committee on the Science of Climate Change of the National Research Council published "Climate Change Science: An Analysis of Some Key Questions". This report explicitly endorsed the Intergovernmental Panel on Climate Change's findings as representing the view of the scientific community:
In 2013, the NRC published the report, "Abrupt Impacts of Climate Change: Anticipating Surprises".
Report on Sexual assault.
In 2013, council published report on unreported cases of rape and sexual assault in the US.
The research council, noting that some 80 percent of sexual assaults go unreported to law enforcement, recommends the National Crime Victimization Survey adopt new approaches to interviews, including changing the wording of questions.
Amber Stevenson, clinical supervisor and therapist at the sexual assault center, said one reason above others was responsible for stopping victims from coming forward.
"As long as we as a community continue to make victim-blaming statements, such as, 'She put herself in this situation,' … 'She didn't fight back, she must have wanted it,' we will continue to see rapes go unreported," Stevenson said. "We have to stop blaming the victim. The conversation needs to shift to the person who chose to rape."

</doc>
<doc id="37640" url="http://en.wikipedia.org/wiki?curid=37640" title="Lumbar disc disease">
Lumbar disc disease

Lumbar disc disease is the drying out of the spongy interior matrix of an intervertebral disc in the spine. Many physicians and patients use the term lumbar disc disease to encompass several different causes of back pain or sciatica. In this article, the term is used to describe a lumbar herniated disc. It is thought that lumbar disc disease causes about one-third of all back pain.
Symptoms.
Pain, loss of muscle strength and loss of touch sensation may occur if this herniation causes the compression of the most proximal part of the nerve closely neighbouring the intervertebral disc material. Pain is in the distribution of the nerve compressed, usually down the back of the leg, side of the calf and inside of the foot (sciatica). Most commonly, the nerve root between the fourth and fifth lumbar vertebrae or between the fifth lumbar vertebra and first sacral segment are impinged.
In symptomatic cases the diagnosis should be confirmed by an MRI scan. However, in cases with slight symptoms, a faster and cheaper CT scan (although it is inferior to MRI scan) may be recommended. While a CT scan can show the bony structures in more detail, an MRI scan can better portray soft tissue.
Treatment.
Initial treatment in lumbar disc disease is one or two days of bedrest (although growing number of studies shows that it makes little difference) and pain relieving medications. In cases with ongoing pain despite conservative treatments, a surgical operation that will remove the compressing disc material, a microdiscectomy or discectomy may be recommended to treat a lumbar disc herniation.
Genetics.
An inheritable gene variation may cause increased susceptibility. People with a variation in a gene that encodes the cartilage intermediate-layer protein (CILP) were 1.6 times more likely to have the disease than persons without the variation. CILP is a normal component of disc tissue. The gene variant was hypothesized to disrupt normal building and maintenance of cartilage. However, this association was not replicated in a followup study of Finnish and Chinese individuals.

</doc>
<doc id="37641" url="http://en.wikipedia.org/wiki?curid=37641" title="Head injury">
Head injury

Any injury that results in trauma to the skull or brain can be classified as a head injury. The terms "traumatic brain injury" and "head injury" are often used interchangeably in the medical literature. This broad classification includes neuronal injuries, hemorrhages, vascular injuries, cranial nerve injuries, and subdural hygromas, among many others. These classifications can be further categorized as open (penetrating) or closed head injuries. This depends on if the skull was broken or not. Because head injuries cover such a broad scope of injuries, there are many causes—including accidents, falls, physical assault, or traffic accidents—that can cause head injuries. Many of these are minor, but some can be severe enough to require hospitalization.
The incidence (number of new cases) of head injury is 1.7 million people in the United States alone each year. About 3% of these incidents lead to death. Adults suffer head injuries more frequently than any age group. Their injuries tend to be due to falls, motor vehicle crashes, colliding or being struck by an object, and assaults. Children, however, tend to experience head injuries due to accidental falls and intentional causes (such as being struck or shaken). Head injury usually occurs in toddlers as they learn to walk. Head trauma is a common cause of childhood hospitalization.
Unlike a broken bone where trauma to the body is obvious, head trauma can sometimes be obvious or discrete. In the case of an open head injury, the skull is cracked and broken by an object that makes contact with the brain. This leads to bleeding. Other obvious symptoms can be neurological in nature. The person may become sleepy, behave abnormally, lose consciousness, vomit, develop a severe headache, have mismatched pupil sizes, and/or be unable to move certain parts of the body. While these symptoms happen right after head injury occurs, many problems can develop later in life. Alzheimer’s disease, for example, is much more likely to develop in a person who has experienced a head injury.
Classification.
Head injuries include both injuries to the brain and those to other parts of the head, such as the scalp and skull.
Head injuries can be closed or open. A closed (non-missile) head injury is where the dura mater remains intact. The skull can be fractured, but not necessarily. A penetrating head injury occurs when an object pierces the skull and breaches the dura mater. Brain injuries may be diffuse, occurring over a wide area, or focal, located in a small, specific area.
A head injury may cause skull fracture, which may or may not be associated with injury to the brain. Some patients may have linear or depressed skull fractures.
If intracranial hemorrhage occurs, a hematoma within the skull can put pressure on the brain. Types of intracranial hemorrage include subdural, subarachnoid, extradural, and intraparenchymal hematoma. Craniotomy surgeries are used in these cases to lessen the pressure by draining off blood.
Brain injury can be at the site of impact, but can also be at the opposite side of the skull due to a "contrecoup" effect (the impact to the head can cause the brain to move within the skull, causing the brain to impact the interior of the skull opposite the head-impact).
If the impact causes the head to move, the injury may be worsened, because the brain may ricochet inside the skull causing additional impacts, or the brain may stay relatively still (due to inertia) but be hit by the moving skull (both are contrecoup injuries).
Specific problems after head injury can include:
Concussion.
Traumatic brain injury (TBI) is an exchangeable word used for the word concussion. This term refers to a mild brain injury. This injury is a result due to a blow to the head that could make the person’s physical, cognitive, and emotional behaviors irregular.
Symptoms may include:
Clumsiness, Fatigue, Confusion, Nausea, Blurry Vision, Headaches, and others.
Mild concussions are associated with sequelae. Severity is measured using various concussion grading systems.
A slightly greater injury is associated with both anterograde and retrograde amnesia (inability to remember events before or after the injury). The amount of time that the amnesia is present correlates with the severity of the injury. In all cases the patients develop postconcussion syndrome, which includes memory problems, dizziness, tiredness, sickness and depression.
Cerebral concussion is the most common head injury seen in children.
Intracranial hemorrhage.
Types of intracranial hemorrhage are roughly grouped into intra-axial and extra-axial. The hemorrhage is considered a focal brain injury; that is, it occurs in a localized spot rather than causing diffuse damage over a wider area.
Intra-axial hemorrhage.
Intra-axial hemorrhage is bleeding within the brain itself, or cerebral hemorrhage. This category includes intraparenchymal hemorrhage, or bleeding within the brain tissue, and intraventricular hemorrhage, bleeding within the brain's ventricles (particularly of premature infants). Intra-axial hemorrhages are more dangerous and harder to treat than extra-axial bleeds.
Extra-axial hemorrhage.
Extra-axial hemorrhage, bleeding that occurs within the skull but outside of the brain tissue, falls into three subtypes:
Cerebral contusion.
Cerebral contusion is bruising of the brain tissue. The majority of contusions occur in the frontal and temporal lobes. Complications may include cerebral edema and transtentorial herniation. The goal of treatment should be to treat the increased intracranial pressure. The prognosis is guarded.
Diffuse axonal injury.
Diffuse axonal injury, or DAI, usually occurs as the result of an acceleration or deceleration motion, not necessarily an impact. Axons are stretched and damaged when parts of the brain of differing density slide over one another. Prognoses vary widely depending on the extent of damage.
Signs and symptoms.
Presentation varies according to the injury. Some patients with head trauma stabilize and other patients deteriorate. A patient may present with or without neurological deficit.
Patients with concussion may have a history of seconds to minutes unconsciousness, then normal arousal. Disturbance of vision and equilibrium may also occur.
Common symptoms of head injury include coma, confusion, drowsiness, personality change, seizures, nausea and vomiting, headache and a lucid interval, during which a patient appears conscious only to deteriorate later.
Symptoms of skull fracture can include:
Because brain injuries can be life-threatening, even people with apparently slight injuries, with no noticeable signs or complaints, require close observation; They have a chance for severe symptoms later on. The caretakers of those patients with mild trauma who are released from the hospital are frequently advised to rouse the patient several times during the next 12 to 24 hours to assess for worsening symptoms.
The Glasgow Coma Scale (GCS) is a tool for measuring degree of unconsciousness and is thus a useful tool for determining severity of injury. The Pediatric Glasgow Coma Scale is used in young children. The widely used PECARN Pediatric Head Injury/Trauma Algorithm helps physicians weigh risk-benefit of imaging in a clinical setting given multiple factors about the patient - including mechanism/location of injury, age of patient, and GCS score.
Causes.
Common causes of head injury are motor vehicle traffic collisions, home and occupational accidents, falls, and assaults. Wilson's disease has also been indicative of head injury.
According to the United States CDC, 32% of traumatic brain injuries (another, more specific, term for head injuries) are caused by falls, 10% by assaults, 16.5% by being struck or against something, 17% by motor vehicle accidents, 21% by other/unknown ways. In addition, the highest rate of injury is among children ages 0–14 and adults age 65 and older.
Diagnosis.
The need for imaging in patients who have suffered a minor head injury is debated. A non-contrast CT of the head should be performed immediately in all those who have suffered a moderate or severe head injury,an MRI is also an option.
Computed tomography (CT) has become the diagnostic modality of choice for head trauma due to its accuracy, reliability, safety, and wide availability. The changes in microcirculation, impaired auto-regulation, cerebral edema, and axonal injury start as soon as head injury occurs and manifest as clinical, biochemical, and radiological changes.
Management.
Most head injuries are of a benign nature and require no treatment beyond analgesics and close monitoring for potential complications such as intracranial bleeding. If the brain has been severely damaged by trauma, neurosurgical evaluation may be useful. Treatments may involve controlling elevated intracranial pressure. This can include sedation, paralytics, cerebrospinal fluid diversion. Second line alternatives include decompressive craniectomy (Jagannathan et al. found a net 65% favorable outcomes rate in pediatric patients), barbiturate coma, hypertonic saline and hypothermia. Although all of these methods have potential benefits, there has been no randomized study that has shown unequivocal benefit.
Clinicians will often consult clinical decision support rules such as the Canadian CT Head Rule or the New Orleans/Charity Head injury/Trauma Rule to decide if the patient needs further imaging studies or observation only. Rules like these are usually studied in depth by multiple research groups with large patient cohorts to ensure accuracy given the risk of adverse events in this area.
Prognosis.
In children with uncomplicated minor head injuries the risk of intra cranial bleeding over the next year is rare at 2 cases per 1 million.
In some cases transient neurological disturbances may occur, lasting minutes to hours. Malignant post traumatic cerebral swelling can develop unexpectedly in stable patients after an injury, as can post traumatic seizures. Recovery in children with neurologic deficits will vary. Children with neurologic deficits who improve daily are more likely to recover, while those who are vegetative for months are less likely to improve. Most patients without deficits have full recovery. However, persons who sustain head trauma resulting in unconsciousness for an hour or more have twice the risk of developing Alzheimer's disease later in life.
Head injury may be associated with a neck injury. Bruises on the back or neck, neck pain, or pain radiating to the arms are signs of cervical spine injury and merit spinal immobilization via application of a cervical collar and possibly a long board.
If the neurological exam is normal this is reassuring. Reassessment is needed if there is a worsening headache, seizure, one sided weakness, or has persistent vomiting.
To combat overuse of Head CT Scans yielding negative intracranial hemorrhage, which unnecessarily expose patients to radiation and increase time in the hospital and cost of the visit, multiple clinical decision support rules have been developed to help clinicians weigh the option to scan a patient with a head injury. Among these are the Canadian Head CT rule, the PECARN Head Injury/Trauma Algorithm, and the New Orleans/Charity Head Injury/Trauma Rule all help clinicians make these decisions using easily obtained information and noninvasive practices.
Epidemiology.
Head injury is the leading cause of death in many countries.
External links.
 

</doc>
<doc id="37642" url="http://en.wikipedia.org/wiki?curid=37642" title="Tremor">
Tremor

A tremor is an involuntary, somewhat rhythmic, muscle contraction and relaxation involving oscillations or twitching movements of one or more body parts. It is the most common of all involuntary movements and can affect the hands, arms, eyes, face, head, vocal folds, trunk, and legs. Most tremors occur in the hands. In some people, a tremor is a symptom of another neurological disorder. A very common tremor is the chattering of teeth, usually induced by cold temperatures or by fear.
Causes.
Tremor can be a symptom associated with disorders in those parts of the brain that control muscles throughout the body or in particular areas, such as the hands. Neurological disorders or conditions that can produce tremor including multiple sclerosis, stroke, traumatic brain injury, chronic kidney disease and a number of neurodegenerative diseases that damage or destroy parts of the brainstem or the cerebellum, Parkinson's disease being the one most often associated with tremor. Other causes include the use of drugs (such as amphetamines, cocaine, caffeine, corticosteroids, SSRI), alcohol, mercury poisoning; or the withdrawal of drugs such as alcohol or benzodiazepine. Tremors can also be seen in infants with phenylketonuria (PKU), overactive thyroid or liver failure. Tremors can be an indication of hypoglycemia, along with palpitations, sweating and anxiety.
Tremor can also be caused from lack of sleep, lack of vitamins, or increased stress. Deficiencies of magnesium and thiamine have also been known to cause tremor or shaking, which resolves when the deficiency is corrected. See magnesium in biology. Some forms of tremor are inherited and run in families, while others have no known cause. Tremors can also be caused by some spider bites, e.g. the redback spider of Australia.
Characteristics may include a rhythmic shaking in the hands, arms, head, legs, or trunk; shaky voice; and problems holding things such as a fork or pen. Some tremors may be triggered by or become exacerbated during times of stress or strong emotion, when the individual is physically exhausted, or during certain postures or movements.
Tremor may occur at any age but is most common in middle-age and older persons. It may be occasional, temporary, or occur intermittently. Tremor affects men and women equally.
Etiologies.
Tremor is most commonly classified by clinical features and cause or origin. Some of the better known forms of tremor, with their symptoms, include the following:
Tremor can result from other conditions as well:
Diagnosis.
During a physical exam a doctor can determine whether the tremor occurs primarily during action or at rest. The doctor will also check for tremor symmetry, any sensory loss, weakness or muscle atrophy, or decreased reflexes. A detailed family history may indicate if the tremor is inherited. Blood or urine tests can detect thyroid malfunction, other metabolic causes, and abnormal levels of certain chemicals that can cause tremor. These tests may also help to identify contributing causes, such as drug interaction, chronic alcoholism, or another condition or disease. Diagnostic imaging using CT or MRI imaging may help determine if the tremor is the result of a structural defect or degeneration of the brain.
The doctor will perform a neurological examination to assess nerve function and motor and sensory skills. The tests are designed to determine any functional limitations, such as difficulty with handwriting or the ability to hold a utensil or cup. The patient may be asked to place a finger on the tip of her or his nose, draw a spiral, or perform other tasks or exercises.
The doctor may order an electromyogram to diagnose muscle or nerve problems. This test measures involuntary muscle activity and muscle response to nerve stimulation. The selection of the sensors used is important. In addition to studies of muscle activity, tremor can be assessed with accuracy using accelerometers .
Categories.
The degree of tremor should be assessed in four positions. The tremor can then be classified by which position most accentuates the tremor:
Treatment.
There is no cure for most tremors. The appropriate treatment depends on accurate diagnosis of the cause. Some tremors respond to treatment of the underlying condition. For example, in some cases of psychogenic tremor, treating the patient’s underlying psychological problem may cause the tremor to disappear. A few medications can help relieve symptoms temporarily. 
Medications.
Medications remain the basis of therapy in many cases. Symptomatic drug therapy is available for several forms of tremor:
Lifestyle.
Eliminating tremor “triggers” such as caffeine and other stimulants from the diet is often recommended.
Essential tremor may benefit from slight doses of ethanol, but the potential negative consequences of regular ethanol intake need to be taken into account. Beta blockers have been used as an alternative to alcohol in sports such as competitive dart playing and carry less potential for addiction.
Physical therapy may help to reduce tremor and improve coordination and muscle control for some patients. A physical therapist will evaluate the patient for tremor positioning, muscle control, muscle strength, and functional skills. Teaching the patient to brace the affected limb during the tremor or to hold an affected arm close to the body is sometimes useful in gaining motion control. Coordination and balancing exercises may help some patients. Some therapists recommend the use of weights, splints, other adaptive equipment, and special plates and utensils for eating.
Surgery.
Surgical intervention such as thalamotomy and deep brain stimulation may ease certain tremors. These surgeries are usually performed only when the tremor is severe and does not respond to drugs. Response can be excellent.
Thalamotomy, involving the creation of lesions in the brain region called the thalamus, is quite effective in treating patients with essential, cerebellar, or Parkinsonian tremor. This in-hospital procedure is performed under local anesthesia, with the patient awake. After the patient’s head is secured in a metal frame, the surgeon maps the patient’s brain to locate the thalamus. A small hole is drilled through the skull and a temperature-controlled electrode is inserted into the thalamus. A low-frequency current is passed through the electrode to activate the tremor and to confirm proper placement. Once the site has been confirmed, the electrode is heated to create a temporary lesion. Testing is done to examine speech, language, coordination, and tremor activation, if any. If no problems occur, the probe is again heated to create a 3-mm permanent lesion. The probe, when cooled to body temperature, is withdrawn and the skull hole is covered. The lesion causes the tremor to permanently disappear without disrupting sensory or motor control.
Deep brain stimulation (DBS) uses implantable electrodes to send high-frequency electrical signals to the thalamus. The electrodes are implanted as described above. The patient uses a hand-held magnet to turn on and turn off a pulse generator that is surgically implanted under the skin. The electrical stimulation temporarily disables the tremor and can be “reversed,” if necessary, by turning off the implanted electrode. Batteries in the generator last about 5 years and can be replaced surgically. DBS is currently used to treat parkinsonian tremor and essential tremor. It is also applied successfully for other rare causes of tremor.
The most common side effects of tremor surgery include dysarthria (problems with motor control of speech), temporary or permanent cognitive impairment (including visual and learning difficulties), and problems with balance.
Biomechanical loading.
As well as medication, rehabilitation programmes and surgical interventions, the application of biomechanical loading on tremor movement has been shown to be a technique that is able to suppress the effects of tremor on the human body. It has been established in the literature that most of the different types of tremor respond to biomechanical loading. In particular, it has been clinically tested that the increase of damping and/or inertia in the upper limb leads to a reduction of the tremorous motion. Biomechanical loading relies on an external device that either passively or actively acts mechanically in parallel to the upper limb to counteract tremor movement. This phenomenon gives rise to the possibility of an orthotic management of tremor.
Starting from this principle, the development of upper-limb non-invasive ambulatory robotic exoskeletons is presented as a promising solution for patients who cannot benefit from medication to suppress the tremor. In this area robotic exoskeletons have emerged, in the form of orthoses, to provide motor assistance and functional compensation to disabled people. An orthosis is a wearable device that acts in parallel to the affected limb. In the case of tremor management, the orthosis must apply a damping or inertial load to a selected set of limb articulations.
Recently, some studies demonstrated that exoskeletons could achieve a consistent 40% of tremor power reduction for all users, being able to attain a reduction ratio in the order of 80% tremor power in specific joints of users with severe tremor. In addition, the users reported that the exoskeleton did not affect their voluntary motion. These results indicate the feasibility of tremor suppression through biomechanical loading.
The main drawbacks of this mechanical management of tremor are (1) the resulting bulky solutions, (2) the inefficiency in transmitting loads from the exoskeleton to the human musculo-skeletal system and (3) technological limitations in terms of actuator technologies. In this regard, current trends in this field are focused on the evaluation of the concept of biomechanical loading of tremor through selective Functional Electrical Stimulation (FES) based on a (Brain-to-Computer Interaction) BCI-driven detection of involuntary (tremor) motor activity.

</doc>
<doc id="37645" url="http://en.wikipedia.org/wiki?curid=37645" title="Rationalism (disambiguation)">
Rationalism (disambiguation)

Rationalism may refer to:

</doc>
<doc id="37647" url="http://en.wikipedia.org/wiki?curid=37647" title="Tiscali (disambiguation)">
Tiscali (disambiguation)

Tiscali may refer to:

</doc>
<doc id="37649" url="http://en.wikipedia.org/wiki?curid=37649" title="Amplitude">
Amplitude

The amplitude of a periodic variable is a measure of its change over a single period (such as time or spatial period). There are various definitions of amplitude (see below), which are all functions of the magnitude of the difference between the variable's extreme values. In older texts the phase is sometimes called the amplitude.
Definitions of the term.
Peak-to-peak amplitude.
Peak-to-peak amplitude is the change between peak (highest amplitude value) and trough (lowest amplitude value, which can be negative). With appropriate circuitry, peak-to-peak amplitudes of electric oscillations can be measured by meters or by viewing the waveform on an oscilloscope. Peak-to-peak is a straightforward measurement on an oscilloscope, the peaks of the waveform being easily identified and measured against the graticule. This remains a common way of specifying amplitude, but sometimes other measures of amplitude are more appropriate.
Peak amplitude.
In audio system measurements, telecommunications and other areas where the measurand is a signal that swings above and below a zero value but is not sinusoidal, peak amplitude is often used. This is the maximum absolute value of the signal.
Semi-amplitude.
Semi-amplitude means half the peak-to-peak amplitude. It is the most widely used measure of orbital amplitude in astronomy and the measurement of small semi-amplitudes of nearby stars is important in the search for exoplanets.
Some scientists use "amplitude" or "peak amplitude" to mean semi-amplitude, that is, half the peak-to-peak amplitude.
Root mean square amplitude.
Root mean square (RMS) amplitude is used especially in electrical engineering: the RMS is defined as the square root of the mean over time of the square of the vertical distance of the graph from the rest state.
For complicated waveforms, especially non-repeating signals like noise, the RMS amplitude is usually used because it is both unambiguous and has physical significance. For example, the average power transmitted by an acoustic or electromagnetic wave or by an electrical signal is proportional to the square of the RMS amplitude (and not, in general, to the square of the peak amplitude).
For alternating current electric power, the universal practice is to specify RMS values of a sinusoidal waveform. One property of root mean square voltages and currents is that they produce the same heating effect as direct current in a given resistance.
The peak-to-peak voltage of a sine wave is about 2.8 times the RMS value. The peak-to-peak value is used, for example, when choosing rectifiers for power supplies, or when estimating the maximum voltage that insulation must withstand. Some common voltmeters are calibrated for RMS amplitude, but respond to the average value of a rectified waveform. Many digital voltmeters and all moving coil meters are in this category. The RMS calibration is only correct for a sine wave input since the ratio between peak, average and RMS values is dependent on waveform. If the wave shape being measured is greatly different from a sine wave, the relationship between RMS and average value changes. True RMS-responding meters were used in radio frequency measurements, where instruments measured the heating effect in a resistor to measure current. The advent of microprocessor controlled meters capable of calculating RMS by sampling the waveform has made true RMS measurement commonplace.
Ambiguity.
In general, the use of peak amplitude is simple and unambiguous only for symmetric periodic waves, like a sine wave, a square wave, or a triangular wave. For an asymmetric wave (periodic pulses in one direction, for example), the peak amplitude becomes ambiguous. This is because the value is different depending on whether the maximum positive signal is measured relative to the mean, the maximum negative signal is measured relative to the mean, or the maximum positive signal is measured relative to the maximum negative signal (the "peak-to-peak amplitude") and then divided by two. In electrical engineering, the usual solution to this ambiguity is to measure the amplitude from a defined reference potential (such as ground or 0 V). Strictly speaking, this is no longer amplitude since there is the possibility that a constant (DC component) is included in the measurement.
Pulse amplitude.
In telecommunication, "pulse amplitude" is the magnitude of a pulse parameter, such as the voltage level, current level, field intensity, or power level.
Pulse amplitude is measured with respect to a specified reference and therefore should be modified by qualifiers, such as "average", "instantaneous", "peak", or "root-mean-square".
Pulse amplitude also applies to the amplitude of frequency- and phase-modulated waveform envelopes.
Formal representation.
In this simple wave equation
"A" is the peak amplitude of the wave,
"x" is the oscillating variable,
ω is angular frequency,
"t" is time,
"K" and "b" are arbitrary constants representing time and displacement offsets respectively.
Units.
The units of the amplitude depend on the type of wave, but are always in the same units as the oscillating variable. A more general representation of the wave equation is more complex, but the role of amplitude remains analogous to this simple case.
For waves on a string, or in medium such as water, the amplitude is a displacement.
The amplitude of sound waves and audio signals (which relates to the volume) conventionally refers to the amplitude of the air pressure in the wave, but sometimes the amplitude of the displacement (movements of the air or the diaphragm of a speaker) is described. The logarithm of the amplitude squared is usually quoted in dB, so a null amplitude corresponds to −∞ dB. Loudness is related to amplitude and intensity and is one of most salient qualities of a sound, although in general sounds can be recognized independently of amplitude. The square of the amplitude is proportional to the intensity of the wave.
For electromagnetic radiation, the amplitude of a photon corresponds to the changes in the electric field of the wave. However radio signals may be carried by electromagnetic radiation; the intensity of the radiation (amplitude modulation) or the frequency of the radiation (frequency modulation) is oscillated and then the individual oscillations are varied (modulated) to produce the signal.
Waveform and envelope.
The amplitude as defined above is a constant and the wave is said to be continuous. If this condition does not hold, amplitude-like variations with time and/or position may be quantified in terms of the envelope of the wave.
Sinusoids.
If the waveform is a pure sine wave, the relationships between peak-to-peak, peak, mean, and RMS amplitudes are fixed and known, as they are for any continuous periodic wave. However, this is not true for an arbitrary waveform which may or may not be periodic or continuous.
For a sine wave, the relationship between RMS and peak-to-peak amplitude is:
See Root mean square#RMS of common waveforms for more.
For other waveforms the relationships are not (necessarily) arithmetically the same as they are for sine waves.

</doc>
<doc id="37650" url="http://en.wikipedia.org/wiki?curid=37650" title="Period">
Period

Period (from Greek περίοδος) or "periodic" may refer to:

</doc>
<doc id="37652" url="http://en.wikipedia.org/wiki?curid=37652" title="Kyoto">
Kyoto

Kyoto (京都市, Kyōto-shi, ]; , , or ; formerly known in the West as Meaco) is a city located in the central part of the island of Honshu, Japan. It has a population close to 1.5 million. Formerly the imperial capital of Japan for more than one thousand years, it is now the capital city of Kyoto Prefecture located in the Kansai region, as well as a major part of the Kyoto-Osaka-Kobe metropolitan area. Kyoto is also known as the "City of Ten Thousand Shrines".
Name.
In Japanese, the city has been called Kyō (京), Miyako (都), or Kyō no Miyako (京の都). In the 11th century, the city was renamed Kyoto ("capital city"), after the Chinese word for capital city, "jingdu" (京都). After Edo was renamed Tokyo (meaning "Eastern Capital") in 1868, Kyoto was known for a short time as Saikyō (西京, meaning "Western Capital").
An obsolete spelling for the city's name is Kioto; it was formerly known to the West as Meaco (; Japanese: 都; miyako, meaning "the seat of Imperial palace" or "capital".) Another term commonly used to refer to the city in the pre-modern period was Keishi (京師), meaning "metropolis" or "capital".
History.
Origins.
Although archaeological evidence suggests human settlement in Kyoto basin as early as the Paleolithic period, relatively little is known about human activity in the area before the 6th century AD, around which time the Shimogamo Shrine is believed to have been established.
Heian-kyō.
During the 8th century, when powerful Buddhist clergy became involved in the affairs of the Imperial government, the Emperor chose to relocate the capital to a region far from the Buddhist influence. Emperor Kammu selected the village of Uda, at the time in the Kadono district of Yamashiro Province, for this honour.
The new city, Heian-kyō (平安京, "tranquility and peace capital"), a scaled replica of the then Tang capitals Luoyang and Chang'an, became the seat of Japan's imperial court in 794, beginning the Heian period of Japanese history. Although military rulers established their governments either in Kyoto (Muromachi shogunate) or in other cities such as Kamakura (Kamakura shogunate) and Edo (Tokugawa shogunate), Kyoto remained Japan's capital until the transfer of the imperial court to Tokyo in 1869 at the time of the Imperial Restoration. (Some believe that it is still a legal capital: see Capital of Japan.)
The city suffered extensive destruction in the Ōnin War of 1467-1477, and did not really recover until the mid-16th century. Battles between samurai factions spilled into the streets, and came to involve the court nobility ("kuge") and religious factions as well. Nobles' mansions were transformed into fortresses, deep trenches dug throughout the city for defense and as firebreaks, and numerous buildings burned. The city has not seen such widespread destruction since.
In the late 16th century, Toyotomi Hideyoshi restructured the city by building new streets to double the number of north-south streets in central Kyoto, creating rectangle blocks superseding ancient square blocks. Hideyoshi also built earthwork walls called Odoi (御土居)　encircling the city. Teramachi Street in central Kyoto is a Buddhist temple quarter where Hideyoshi gathered temples in the city. Throughout the Edo period, the economy of the city flourished as one of three major cities in Japan, the others being Osaka and Edo.
The Hamaguri rebellion of 1864 burnt down 28,000 houses in the city, and the subsequent move of the Emperor to Tokyo in 1869 weakened the economy. The modern city of Kyoto was formed on April 1, 1889. The construction of Lake Biwa Canal in 1890 is one measure taken to revive the city. The population of the city exceeded one million in 1932.
There was some consideration by the United States of targeting Kyoto with an atomic bomb at the end of World War II because, as an intellectual center of Japan, it had a population "better able to appreciate the significance of the weapon." In the end, at the insistence of Henry L. Stimson, Secretary of War in the Roosevelt and Truman administrations, the city was removed from the list of targets and replaced by Nagasaki. The city was largely spared from conventional bombing as well, although small-scale air raids did result in casualties.
As a result, the Imperial City (Emeritus), of Kyoto is one of the few Japanese cities that still have an abundance of prewar buildings, such as the traditional townhouses known as "machiya". However, modernization is continually breaking down the traditional Kyoto in favor of newer architecture, such as the Kyōto Station complex.
Kyoto became a city designated by government ordinance on September 1, 1956. In 1997, Kyoto hosted the conference that resulted in the protocol on greenhouse gas emissions that bears the city's name.
Geography.
Kyoto is located in a valley, part of the Yamashiro (or Kyoto) Basin, in the eastern part of the mountainous region known as the Tamba highlands. The Yamashiro Basin is surrounded on three sides by mountains known as Higashiyama, Kitayama and Nishiyama, with a height just above 1000 m above sea level. This interior positioning results in hot summers and cold winters. There are three rivers in the basin, the Ujigawa to the south, the Katsuragawa to the west, and the Kamogawa to the east. Kyoto City takes up 17.9% of the land in the prefecture with an area of 827.9 km².
The original city was arranged in accordance with traditional Chinese feng shui following the model of the ancient Chinese capital of Chang'an (present-day Xi'an). The Imperial Palace faced south, resulting in Ukyō (the right sector of the capital) being on the west while Sakyō (the left sector) is on the east. The streets in the modern-day wards of Nakagyō, Shimogyō, and Kamigyō-ku still follow a grid pattern.
Today, the main business district is located to the south of the old Imperial Palace, with the less-populated northern area retaining a far greener feel. Surrounding areas do not follow the same grid pattern as the center of the city, though streets throughout Kyoto share the distinction of having names.
Kyoto sits atop a large natural water table that provides the city with ample freshwater wells. Due to large-scale urbanization, the amount of rain draining into the table is dwindling and wells across the area are drying at an increasing rate.
Demographics.
Historically, Kyoto was the largest city in Japan, later surpassed by Osaka and Edo (Tokyo) towards the end of the 16th century. In the pre-war years, Kyoto traded places with Kobe and Nagoya ranking as the 4th and 5th largest city. In 1947, it went back to being 3rd, but its population has gradually declined ever since. By 1960 it had fallen to 5th again, and by 1990 it had fallen to 7th, in 2012 it is now 8th. If current trends continue it could fall to 9th after Kawasaki.
Climate.
Kyoto has a humid subtropical climate (Köppen "Cfa"), featuring a marked seasonal variation in temperature and precipitation. Summers are hot and humid, though contrarily, winters are relatively cold with occasional snowfall. Kyoto's rain season begins around the middle of June and lasts until the end of July, yielding to a hot and sunny latter half of the summer. Kyoto, along with most of the Pacific coast and central areas of Japan is prone to typhoons during September and October.
Politics and government.
The directly elected executive mayor in Kyoto as of 2013 is Daisaku Kadokawa, an independent supported by Democratic Party of Japan, Liberal Democratic Party, New Komeito Party, Your Party and Social Democratic Party. The legislative city assembly has 69 elected members.
Kyoto Protocol.
The Kyoto Protocol to the United Nations Framework Convention on Climate Change (UNFCCC) is an international treaty that sets binding obligations on industrialized countries to reduce emissions of greenhouse gases.
The Kyoto Protocol was adopted at the third session of the Conference of Parties to the UNFCCC (COP 3) held in Kyoto in 1997.
Wards.
Kyoto has eleven wards. They are
Together, they make up the city of Kyoto. Like other cities in Japan, Kyoto has a single mayor and a city council.
Culture.
Although ravaged by wars, fires, and earthquakes during its eleven centuries as the imperial capital, Kyoto was spared from much of the destruction of World War II. It was removed from the atomic bomb target list (which it had headed) by the personal intervention of Secretary of War Henry L. Stimson, as Stimson wanted to save this cultural center which he knew from his honeymoon and later diplomatic visits.
With its 2000 religious places- 1600 Buddhist temples and 400 Shinto shrines, as well as palaces, gardens and architecture intact, it is one of the best preserved cities in Japan. Among the most famous temples in Japan are Kiyomizu-dera, a magnificent wooden temple supported by pillars off the slope of a mountain; Kinkaku-ji, the Temple of the Golden Pavilion; Ginkaku-ji, the Temple of the Silver Pavilion; and Ryōan-ji, famous for its rock garden. The Heian Jingū is a Shinto shrine, built in 1895, celebrating the Imperial family and commemorating the first and last emperors to reside in Kyoto. Three special sites have connections to the imperial family: the Kyoto Gyoen area including the Kyoto Imperial Palace and Sento Imperial Palace, homes of the Emperors of Japan for many centuries; Katsura Imperial Villa, one of the nation's finest architectural treasures; and Shugaku-in Imperial Villa, one of its best Japanese gardens. In addition, the temple of Sennyu-ji houses the tombs of the emperors from Shijō to Kōmei.
Other sites in Kyoto include Arashiyama, the Gion and Pontochō geisha quarters, the Philosopher's Walk, and the canals which line some of the older streets.
The "Historic Monuments of Ancient Kyoto" are listed by the UNESCO as a World Heritage Site. These include the Kamo Shrines (Kami and Shimo), Kyō-ō-Gokokuji (Tō-ji), Kiyomizu-dera, Daigo-ji, Ninna-ji, Saihō-ji (Kokedera), Tenryū-ji, Rokuon-ji (Kinkaku-ji), Jishō-ji (Ginkaku-ji), Ryōan-ji, Hongan-ji, Kōzan-ji and the Nijō Castle, primarily built by the Tokugawa shoguns. Other sites outside the city are also on the list.
Kyoto is renowned for its abundance of delicious Japanese foods and cuisine. The special circumstances of Kyoto as a city away from the sea and home to many Buddhist temples resulted in the development of a variety of vegetables peculiar to the Kyoto area ("kyōyasai", 京野菜).
Japan's television and film industry has its center in Kyoto. Many "jidaigeki", action films featuring samurai, were shot at Toei Uzumasa Eigamura. A film set and theme park in one, Eigamura features replicas of traditional Japanese buildings which are used for "jidaigeki". Among the sets are a replica of the old Nihonbashi (the bridge at the entry to Edo), a traditional courthouse, a Meiji Period police box and part of the former Yoshiwara red-light district. Actual film shooting takes place occasionally, and visitors are welcome to observe the action.
The dialect spoken in Kyoto is known as "Kyō-kotoba" or "Kyōto-ben", a constituent dialect of the Kansai dialect. When Kyoto was the capital of Japan, the Kyoto dialect was the "de facto" standard Japanese and influenced the development of Tokyo dialect, the modern standard Japanese. Famous Kyoto expressions are a polite copula "dosu", an honorific verb ending "-haru", a greeting phrase "okoshi-yasu" "welcome", etc.
Economy.
The key industry of Kyoto is information technology and electronics: the city is home to the headquarters of Nintendo, Intelligent Systems, Dainippon Screen, TOSE, OMRON, Kyocera, Shimadzu Corp., Rohm, Horiba, Nidec Corporation, Nichicon, Nissin Electric, and GS Yuasa.
Tourism also forms a large base of Kyoto's economy. The city's cultural heritages are constantly visited by school groups from across Japan, and many foreign tourists also stop in Kyoto. In 2014, the city government announced that a record number of tourists had visited Kyoto, and it was chosen as the world's best city by U.S. travel magazine.
Traditional Japanese crafts are also major industry of Kyoto, most of which are run by artisans in small plants. Kyoto's kimono weavers are particularly renowned, and the city remains the premier center of kimono manufacturing. Such businesses, vibrant in past centuries, have declined in recent years as sales of traditional goods stagnate.
Sake brewing is Kyoto's traditional industry. Gekkeikan and Takara Holdings are major sake brewers headquartered in Kyoto.
Other notable businesses headquartered in Kyoto includes Aiful, Ishida, MK, Nissen Holdings, Oh-sho, Sagawa Express, Volks and Wacoal.
The concentration of population to the capital city area is 55% which is highest among the prefectures. The economic difference between the coastal area and inland area including Kyoto basin is significant.
Colleges and universities.
Home to 37 institutions of higher education, Kyoto is one of the academic centers in Japan.Kyoto University is considered to be one of the top national universities nationwide. According to The Times Higher Education Supplement top-ranking university, Kyoto University is ranked the second university in Japan after University of Tokyo, and 25th overall in the world as of 2010. The Kyoto Institute of Technology is also among the most famous universities in Japan and is considered to be one of the best universities for architecture and design in the country. Popular private universities, such as Doshisha University and Ritsumeikan University are also located in the city.
Kyoto also has a unique higher education network called the Consortium of Universities in Kyoto, which consists of three national, three public (prefectural and municipal), and 45 private universities, as well as the city and five other organizations. The combination does not offer a degree, but offers the courses as part of a degree at participating universities.
In addition to Japanese universities and colleges, selected American universities also operates in the city for education and research. Kyoto Consortium for Japanese Studies (KCJS) is a combination of 14 American universities that sponsors a two-semester academic program for undergraduates who wish to do advanced work in Japanese language and cultural studies. The American university, Stanford University, operates a "Japan Center" in Kyoto.
Transportation.
Rail.
Kyoto Station is the center for transportation in the city. The second-largest in Japan, it houses a shopping mall, hotel, movie theater, Isetan department store, and several local government facilities all under one fifteen-story roof. The Tōkaidō Shinkansen Line (see below) as well as all conventional rail lines operated by JR West connect here.
The Keihan, Hankyu, Kintetsu, and other rail networks also offer frequent service to other cities in the Kansai region. JR West and Kintetsu connect at Kyoto Station. Hankyu has a terminal at the intersection of Shijō Kawaramachi, Kyoto's most thriving shopping and amusement district. Keihan has a station at Sanjō Keihan which is not far from Shijō Kawaramachi.
Subway.
The Kyoto Municipal Transportation Bureau operates the Kyoto Municipal Subway consisting of two lines: the Karasuma Line and the Tōzai Line.
Karasuma Line.
The Karasuma Line is colored green, and its stations are given numbers following the letter "K".
The line has following stations, from north to south: Kokusaikaikan (terminal) and Matsugasaki in Sakyō-ku; Kitayama and Kitaōji in Kita-ku; Kuramaguchi and Imadegawa in Kamigyō-ku; Marutamachi and Karasuma Oike in Nakagyō-ku; Shijō, Gojō and Kyōto in Shimogyō-ku; Kujō and Jūjō in Minami-ku; and Kuinabashi and Takeda (terminal) in Fushimi-ku.
Between Kitaōji and Jūjō, trains run beneath the north-south Karasuma Street (, "Karasuma-dori"), hence the name. They link to the other subway line, the Tozai Line, at Karasuma Oike. They also connect to the JR lines at Kyoto Station and the Hankyu Kyoto Line running cross-town beneath Shijō Street at the intersection of Shijō Karasuma, Kyoto's central business district. At Shijō Karasuma, the subway station is named Shijō, whereas Hankyu's station is called Karasuma.
The Transportation Bureau and Kintetsu jointly operate through services, which continue to the Kintetsu Kyoto Line to Kintetsu Nara Station in Nara. The Karasuma Line and the Kintetsu Kyoto Line connect at Kyoto and Takeda. All the stations are located in the city proper.
Tozai Line.
The Tōzai Line is coloured vermilion, and its stations are given numbers following the letter "T". This line runs from the southeastern area of the city, then east to west (i.e. "tōzai" in Japanese) through the Kyoto downtown area where trains run beneath the three east-west streets: Sanjō Street (, "Sanjō-dori"), Oike Street (, "Oike-dori") and Oshikōji Street (, "Oshikōji-dori").
The line has following stations, from east to west: Rokujizō (terminal) in Uji; Ishida and Daigo in Fushimi-ku; Ono, Nagitsuji, Higashino, Yamashina and Misasagi in Yamashina-ku; Keage, Higashiyama and Sanjō Keihan in Higashiyama-ku; Kyoto Shiyakusho-mae, Karasuma Oike, Nijōjō-mae, Nijō and Nishiōji Oike in Nakagyō-ku; and Uzumasa Tenjingawa (terminal) in Ukyō-ku.
The Keihan Keishin Line has been integrated into this line, and thus Keihan provides through services from Hamaōtsu in the neighbouring city of Ōtsu, the capital of Shiga Prefecture.
The Tōzai Line connects to the Keihan lines at Rokujizō, Yamashina, Misasagi and Sanjō Keihan, to the JR lines at Nijō, Yamashina and Rokujizō, and to the Keifuku Electric Railroad at Uzumasa Tenjingawa. All the stations except Rokujizō are located in Kyoto.
High-speed rail.
The Tōkaidō Shinkansen operated by JR Central provides high-speed rail service linking Kyoto with Nagoya, Yokohama and Tokyo to the east of Kyoto and with nearby Osaka and points west on the San'yo Shinkansen, such as Kobe, Okayama, Hiroshima, Kitakyushu, and Fukuoka. The trip from Tokyo takes about two hours and twenty-two minutes. From Hakata in Fukuoka, Nozomi takes you to Kyoto in just over three hours. All trains including Nozomi stop at Kyoto Station, serving as a gateway to not only Kyoto Prefecture but also northeast Osaka, south Shiga and north Nara.
Airport.
Although Kyoto does not have its own airport, travelers can get to the city via Kansai International Airport and Osaka International Airport in Osaka Prefecture. The Haruka Express operated by JR West carries passengers from Kansai Airport to Kyoto Station in 73 minutes.
Osaka Airport Transport buses connect Itami Airport and Kyoto Station Hachijo Gate in 50 minutes and cost 1,280 yen for a one-way trip. Some buses go further, make stops at major hotels and terminals in downtown area.
Buses.
Kyoto's municipal bus network is extensive. Private carriers also operate within the city. Many tourists join commuters on the public buses, or take tour buses. Kyoto's buses have announcements in English and electronic signs with stops written in the Latin alphabet.
Most city buses have a fixed fare. A one-day bus pass and a combined unlimited train and bus pass are also available. These are especially useful for visiting many different points of interest within Kyoto. The bus information center just outside the central station handles tickets and passes. The municipal transport company publishes a very useful leaflet called "Bus Navi." It contains a route map for the bus lines to most sights and fare information. This too is available at the information center in front of the main station.
Buses operating on routes within the city, the region, and the nation stop at Kyoto Station. In addition to Kyoto Station, bus transfer is available at the intersections of Shijō Kawaramachi and Sanjō Keihan. The intersection of Karasuma Kitaōji to the north of downtown has a major bus terminal serving passengers who take the Karasuma Line running beneath Karasuma Street, Kyoto's main north-south street.
Cycling.
Cycling is a very important form of personal transportation in the city. The geography and scale of the city are such that the city may be easily navigated on a bicycle. Bicycle theft is not common, but finding permitted bicycle parking areas can be difficult. Bicycles parked in non-permitted areas are impounded.
Roads.
The city is connected with other part of Japan by the Meishin Expressway, which has two interchanges in the city: Kyoto Higashi (Kyoto East) in Yamashina-ku and Kyoto Minami (Kyoto South) in Fushimi-ku. The Kyoto Jūkan Expressway connects the city to northern regions of Kyoto Prefecture. The Daini Keihan Road is a new bypass (completed in 2010) to Osaka.
Although Kyoto has fewer toll-highways than other comparable Japanese cities, it is served with dual and even triple-carriageway national roads. As of 2010, only 8.2 km of the Hanshin Expressway Kyoto Route is in operation.
There are nine national highways in the city of Kyoto:
Route 1, Route 8, Route 9, Route 24, Route 162, Route 171, Route 367, Route 477 and Route 478.
Waterways.
There are a number of rivers, canals and other navigable waterways in Kyoto. The Seta and Uji rivers (Yodo River), Kamogawa and Katsura river flow through Kyoto. Lake Biwa Canal was a significant infrastructural development. In present days, however, the waterways are not used for passenger or goods transportation except for limited sightseeing purpose such as Hozugawa Kudari boat on the Hozu River.
Tourism.
Kyoto contains roughly 2,000 temples and shrines, and receives over 30 million tourists annually.
UNESCO World Heritage Site.
About 20% of Japan's National Treasures and 14% of Important Cultural Properties exist in the city proper. The UNESCO World Heritage Site Historic Monuments of Ancient Kyoto (Kyoto, Uji and Otsu Cities) includes 17 locations in Kyoto, Uji in Kyoto Prefecture, and Ōtsu in Shiga Prefecture. The site was designated as World Heritage in 1994.
Festivals.
Kyoto is well known for its traditional festivals which have been held for over 1000 years and are a major tourist attraction. The first is the Aoi Matsuri on May 15. Two months later (July 1 to 31) is the Gion Matsuri known as one of the 3 great festivals of Japan, culminating in a massive parade on July 17. Kyoto marks the Bon Festival with the Gozan no Okuribi, lighting fires on mountains to guide the spirits home (August 16). The October 22 Jidai Matsuri, Festival of the Ages, celebrates Kyoto's illustrious past.
Sports.
Football.
In football, Kyoto is represented by Kyoto Sanga F.C. who won the Emperor's Cup in 2002, and rose to J. League's Division 1 in 2005. Kyoto Sanga has a long history as an amateur non-company club, although it was only with the advent of professionalization that it was able to compete in the Japanese top division.
Amateur football clubs such as F.C. Kyoto BAMB 1993 and Kyoto Shiko Club (both breakaway factions of the original Kyoto Shiko club that became Kyoto Sanga) as well as unrelated AS Laranja Kyoto compete in the regional Kansai soccer league.
Baseball.
Between 1951 and 1952 the Central League team Shochiku Robins played their franchised games at Kinugasa Ballpark (, "Kinugasa Kyujo") in Kita-ku. In 2010, Nishikyogoku Stadium in Ukyo-ku became the home of a newly formed girls professional baseball team, the Kyoto Asto Dreams.
Additionally, Kyoto's high school baseball teams are strong, with Heian and Toba in particular making strong showings recently at the annual tournament held in Koshien Stadium, Nishinomiya, near Osaka.
Horse racing.
Kyoto Racecourse in Fushimi-ku is one of ten racecourses operated by the Japan Racing Association. It hosts notable horse races including the Kikuka-shō, Spring Tenno Sho, and Queen Elizabeth II Commemorative Cup.
International relations.
Kyoto, having been the capital city of Japan, a seat of learning and culture, has long-established ties with other great cities around the world. Many foreign scholars, artists and writers have stayed in Kyoto over the centuries.
Twin towns and sister cities.
The city of Kyoto has sister city relationships with the following nine cities.
 Paris, France (Friendship Pledge City)
 Prague, Czech Republic

</doc>
<doc id="37653" url="http://en.wikipedia.org/wiki?curid=37653" title="CBS">
CBS

CBS (an initialism of the network's former name, the Columbia Broadcasting System; corporate name CBS Broadcasting, Inc.) is an American commercial broadcast television and radio network that is the flagship property of CBS Corporation. The company is headquartered at the CBS Building in New York City, with major production facilities and operations in New York City (at the CBS Broadcast Center) and Los Angeles (at CBS Television City, CBS Columbia Square and the CBS Studio Center).
CBS is sometimes referred to as the "Eye Network", in reference to the company's iconic logo, in use since 1951. It has also been called the "Tiffany Network", alluding to the perceived high quality of CBS programming during the tenure of its founder William S. Paley. It can also refer to some of CBS's first demonstrations of color television, which were held in a former Tiffany & Co. building in New York City in 1950.
The network has its origins in United Independent Broadcasters Inc., a collection of 16 radio stations that was purchased by Paley in 1928, and renamed the Columbia Broadcasting System. Under Paley's guidance, CBS would first become one of the largest radio networks in the United States, and eventually one of the Big Three American broadcast television networks. In 1974, CBS dropped its full name and became known simply as CBS, Inc. The Westinghouse Electric Corporation acquired the network in 1995, renamed its corporate entity to the current name CBS Broadcasting, Inc. in 1997, and eventually adopted the name of the company it had acquired to become CBS Corporation. In 2000, CBS came under the control of Viacom, which was formed as a spin-off of CBS in 1971. In late 2005, Viacom split itself into two separate companies, and re-established CBS Corporation – through the spin-off of its broadcast television, radio and select cable television and non-broadcasting assets – with the CBS television network at its core. CBS Corporation is controlled by Sumner Redstone through National Amusements, which also controls the current Viacom.
CBS continues to operate a radio network, which now mainly provides news and features content for its portfolio of owned-and-operated radio stations in large and mid-sized markets, and affiliated radio stations in various other markets. The television network has more than 240 owned-and-operated and affiliated television stations throughout the United States.
History.
Radio years.
The origins of CBS date back to January 27, 1927, with the creation of the "United Independent Broadcasters" network in Chicago by New York City talent-agent Arthur Judson. The fledgling network soon needed additional investors though, and the Columbia Phonograph Company, manufacturers of Columbia Records, rescued it in April 1927; as a result, the network was renamed the "Columbia Phonographic Broadcasting System" on September 18 of that year. Columbia Phonographic went on the air on September 18, 1927, with a presentation by the Howard Barlow Orchestra from flagship station WOR in Newark, New Jersey, and fifteen affiliates.
Operational costs were steep, particularly the payments to AT&T for use of its land lines, and by the end of 1927, Columbia Phonograph wanted out. In early 1928, Judson sold the network to brothers Isaac and Leon Levy, owners of the network's Philadelphia affiliate WCAU, and their partner Jerome Louchenheim. None of the three were interested in assuming day-to-day management of the network, so they installed wealthy 26-year-old William S. Paley, son of a Philadelphia cigar family and in-law of the Levys, as president. With the record company out of the picture, Paley quickly streamlined the corporate name to "Columbia Broadcasting System". He believed in the power of radio advertising since his family's "La Palina" cigars had doubled their sales after young William convinced his elders to advertise on radio. By September 1928, Paley bought out the Louchenheim share of CBS and became its majority owner with 51% of the business.
Turnaround: Paley's first year.
During Louchenheim's brief regime, Columbia paid $410,000 to A.H. Grebe's Atlantic Broadcasting Company for a small Brooklyn station, WABC (no relation to the current WABC), which would become the network's flagship station. WABC was quickly upgraded, and the signal relocated to 860 kHz. The physical plant was relocated also – to Steinway Hall on West 57th Street in Manhattan, where much of CBS's programming would originate. Other owned-and-operated stations were KNX in Los Angeles, KCBS in San Francisco (originally KQW), WBBM in Chicago, WCAU in Philadelphia, WJSV in Washington, D.C. (later WTOP, which moved to the FM band in 2005; the AM facility is now WFED, also a secondary CBS affiliate), KMOX in St. Louis, and WCCO in Minneapolis. These remain the core affiliates of the CBS Radio Network today, with WCBS (the original WABC) still the flagship, and all except WTOP and WFED (both Hubbard Broadcasting properties) owned by CBS Radio. By the turn of 1929, the network could boast to sponsors of having 47 affiliates.
Paley moved right away to put his network on a firmer financial footing. In the fall of 1928, he entered into talks with Adolph Zukor of Paramount Pictures, who planned to move into radio in response to RCA's forays into motion pictures with the advent of talkies. The deal came to fruition in September 1929: Paramount acquired 49% of CBS in return for a block of its stock worth $3.8 million at the time. The agreement specified that Paramount would buy that same stock back by March 1, 1932 for a flat $5 million, provided CBS had earned $2 million during 1931 and 1932. For a brief time there was talk that the network might be renamed "Paramount Radio", but it only lasted a month – the 1929 stock market crash sent all stock value tumbling. It galvanized Paley and his troops, who "had no alternative but to turn the network around and earn the $2,000,000 in two years... This is the atmosphere in which the CBS of today was born." The near-bankrupt movie studio sold its CBS shares back to CBS in 1932. In the first year of Paley's watch, CBS's gross earnings more than tripled, going from $1.4 million to $4.7 million.
Much of the increase was a result of Paley's second upgrade to the CBS business plan – improved affiliate relations. There were two types of program at the time: "sponsored" and "sustaining", i.e., unsponsored. Rival NBC paid affiliates for every sponsored show they carried and charged them for every sustaining show they ran. It was onerous for small and medium stations, and resulted in both unhappy affiliates and limited carriage of sustaining programs. Paley had a different idea, designed to get CBS programs emanating from as many radio sets as possible: he would "give" the sustaining programs away for free, provided the station would run every sponsored show, and accept CBS's check for doing so. CBS soon had more affiliates than either NBC Red or NBC Blue.
Paley was a man who valued style and taste, and in 1929, once he had his affiliates happy and his company's creditworthiness on the mend, he relocated his concern to sleek, new 485 Madison Avenue, the "heart of the advertising community, right where Paley wanted his company to be" and where it would stay until its move to its own Eero Saarinen-designed headquarters, the CBS Building, in 1965. When his new landlords expressed skepticism about the network and its fly-by-night reputation, Paley overcame their qualms by inking a lease for $1.5 million.
CBS takes on the Red and the Blue (1930s).
Since NBC was the broadcast arm of radio set manufacturer RCA, its chief David Sarnoff approached his decisions as both a broadcaster and as a hardware executive; NBC's affiliates had the latest RCA equipment, and were often the best-established stations, or were on "clear channel" frequencies. Yet Sarnoff's affiliates were mistrustful of him. Paley had no such split loyalties: his – and his affiliates' – success rose and fell with the quality of CBS programming.
Paley had an innate, pitch-perfect, sense of entertainment, "a gift of the gods, an ear totally pure", wrote David Halberstam. "[H]e knew what was good and would sell, what was bad and would sell, and what was good and would not sell, and he never confused one with another." As the 1930s loomed, Paley set about building the CBS talent stable. The network became the home of many popular musical and comedy stars, among them Jack Benny, ("Your Canada Dry Humorist"), Al Jolson, George Burns & Gracie Allen, and Kate Smith, whom Paley personally selected for his family's "La Palina Hour" because she was not the type of woman to provoke jealousy in American wives. When, on a mid-ocean voyage, Paley heard a phonograph record of a young unknown crooner, he rushed to the ship's radio room and "cabled" New York to sign Bing Crosby immediately to a contract for a daily radio show.
While the CBS prime-time lineup featured music, comedy and variety shows, the daytime schedule was a direct conduit into American homes – and into the hearts and minds of American women; for many, it was the bulk of their adult human contact during the course of the day. CBS time salesmen recognized early on that this intimate connection could be a bonanza for advertisers of female-interest products. Starting in 1930, astrologer Evangeline Adams would consult the heavens on behalf of listeners who sent in their birthdays, a description of their problems – and a box-top from sponsor Forhan's toothpaste. The low-key murmuring of smooth-voiced Tony Wons, backed by a tender violin, "made him a soul mate to millions of women" on behalf of the R. J. Reynolds tobacco company, whose cellophane-wrapped Camel cigarettes were "as fresh as the dew that dawn spills on a field of clover". The most popular radio-friend of all was M. Sayle Taylor, "The Voice Of Experience", though his name was never uttered on air. Women mailed descriptions of the most intimate of relationship problems to The Voice in the tens of thousands per week; sponsors Musterole ointment and Haley's M–O laxative enjoyed sales increases of several hundred percent in just the first month of "The Voice Of Experience"‍ '​s run.
As the decade progressed, a new genre joined the daytime lineup: serial dramas – soap operas, so named for the products that sponsored them, by way of the ad agencies that actually produced them. Although the form, usually in quarter-hour episodes, proliferated widely in the mid- and late 1930s, they all had the same basic premise: that characters "fell into two categories: 1) those in trouble and 2) those who helped people in trouble. The helping-hand figures were usually older." At CBS, "Just Plain Bill" brought human insight and Anacin pain reliever into households; "Your Family and Mine" came courtesy of Sealtest Dairy products; "Bachelor's Children" first hawked Old Dutch Cleanser, then Wonder Bread; "Aunt Jenny's Real Life Stories" was sponsored by Spry Vegetable Shortening. "Our Gal Sunday" (Anacin again), "The Romance of Helen Trent" (Angélus cosmetics), "Big Sister" (Rinso laundry soap) and many others filled the daytime ether.
Thanks to its daytime and primetime schedules, CBS prospered in the 1930s. In 1935, gross sales were $19.3 million, yielding a profit of $2.27 million. By 1937, the network took in $28.7 million and had 114 affiliates, almost all of which cleared 100% of network-fed programming, thus keeping ratings, and revenue, high. In 1938, CBS even acquired the American Record Corporation, parent of its one-time investor Columbia Records.
In 1938, NBC and CBS each opened studios in Hollywood to attract the entertainment industry's top talent to their networks – NBC at Radio City on Sunset Boulevard and Vine Street, CBS two blocks away at Columbia Square.
CBS launches an independent news division.
The extraordinary potential of radio news showed itself in 1930, when CBS suddenly found itself with a live telephone connection to a prisoner called "The Deacon" who described, from the inside and in real time, a riot and conflagration at the Ohio Penitentiary; for CBS, it was "a shocking journalistic coup". Yet as late as 1934, there was still no regularly scheduled newscast on network radio: "Most sponsors did not want network news programming; those that did were inclined to expect veto rights over it." There had been a longstanding wariness between radio and the newspapers as well; the papers had rightly concluded that the upstart radio business would compete with them on two counts – advertising dollars and news coverage. By 1933, they fought back, many no longer publishing radio schedules for readers' convenience, or allowing "their" news to be read on the air for radio's profit. Radio, in turn, pushed back when urban department stores, newspapers' largest advertisers and themselves owners of many radio stations, threatened to withhold their ads from print. A short-lived attempted truce in 1933 even saw the papers proposing that radio be forbidden from running news before 9:30 a.m., and then only after 9:00 p.m. – and that no news story could air until it was 12 hours old.
It was in this climate that Paley set out to "enhance the prestige of CBS, to make it seem in the public mind the more advanced, dignified and socially aware network". He did it through sustaining programming like the New York Philharmonic, the thoughtful drama of Norman Corwin – and an in-house news division to gather and present news, free of fickle suppliers like newspapers and wire services. In the fall of 1934, CBS launched an independent news division, shaped in its first years by Paley's vice-president, former "New York Times" columnist Ed Klauber, and news director Paul White. Since there was no blueprint or precedent for real-time news coverage, early efforts of the new division used the shortwave link-up CBS had been using for five years to bring live feeds of European events to its American air.
A key early hire was Edward R. Murrow in 1935; his first corporate title was Director of Talks. He was mentored in microphone technique by Robert Trout, the lone full-time member of the News Division, and quickly found himself in a growing rivalry with boss White. Murrow was glad to "leave the hothouse atmosphere of the New York office behind" when he was dispatched to London as CBS's European Director in 1937, a time when the growing Hitler menace underscored the need for a robust European Bureau. Halberstam described Murrow in London as "the right man in the right place in the right era". Murrow began assembling the staff of broadcast journalists – including William L. Shirer, Charles Collingwood and Eric Sevareid – who would become known as "Murrow's Boys". They were "in [Murrow's] own image, sartorially impeccable, literate, often liberal, and prima donnas all". They covered history in the making, and sometimes made it themselves: on March 12, 1938, Hitler boldly annexed nearby Austria and Murrow and Boys quickly assembled coverage with Shirer in London, Edgar Ansel Mowrer in Paris, Pierre Huss in Berlin, Frank Gervasi in Rome and Trout in New York. This bore the "News Round-Up" format, which is still ubiquitous today in broadcast news.
Murrow's nightly reports from the rooftops during the dark days of the London Blitz galvanized American listeners: even before Pearl Harbor, the conflict became "the story of the survival of Western civilization, the most heroic of all possible wars and stories. He was indeed reporting on the survival of the English-speaking peoples." With his "manly, tormented voice", Murrow contained and mastered the panic and danger he felt, thereby communicating it all the more effectively to his audience. Using his trademark self-reference "This reporter", he did not so much report news as interpret it, combining simplicity of expression with subtlety of nuance. Murrow himself said he tried "to describe things in terms that make sense to the truck driver without insulting the intelligence of the professor". When he returned home for a visit late in 1941, Paley threw an "extraordinarily elaborate reception" for Murrow at the Waldorf-Astoria. Of course, its goal was more than just honoring CBS's latest "star" – it was an announcement to the world that Mr. Paley's network was finally more than just a pipeline carrying other people's programming: it had now become a cultural force in its own right.
Once the war was over and Murrow returned for good, it was as "a superstar with prestige and freedom and respect within his profession and within his company". He possessed enormous capital within that company, and as the unknown form of television news loomed large, he would spend it freely, first in radio news, then in television, taking on Senator Joseph McCarthy first, then eventually William S. Paley himself, and with a foe that formidable, even the vast Murrow account would soon run dry.
Panic: "The War of the Worlds" radio broadcast.
On October 30, 1938, CBS gained a taste of infamy when "The Mercury Theatre on the Air" broadcast a radio adaptation of H. G. Wells's "The War of the Worlds", performed by Orson Welles. Its unique format, a contemporary version of the story in the form of "faux" news broadcasts, had panicked many listeners into believing invaders from Mars were actually invading and devastating Grover's Mill, New Jersey, despite "three" disclaimers during the broadcast that it was a work of fiction. The flood of publicity after the broadcast had two effects: an FCC ban on "faux" news bulletins within dramatic programming, and sponsorship for "The Mercury Theatre on the Air" – the former sustaining program became "The Campbell Playhouse" to sell soup. Welles, for his part, summarized the episode as "the "Mercury Theater's" own radio version of dressing up in a sheet and jumping out of a bush and saying 'Boo!'"
CBS recruits Edmund A. Chester.
Before the onset of World War II, in 1940, CBS recruited Edmund A. Chester from his position as Bureau Chief for Latin America at the Associated Press to serve as Director of Latin American Relations and Director of Short Wave Broadcasts for the CBS radio network. In this capacity, Mr. Chester coordinated the development of the Network of the Americas (La Cadena de las Americas) with the Department of State, the Office for Inter-American Affairs (as chaired by Nelson Rockefeller) and Voice of America. This network provided vital news and cultural programming throughout South America and Central America during the crucial World War II era and fostered diplomatic relations between the United States and the less developed nations of the continent. It featured such popular radio broadcasts as "Viva América" which showcased leading musical talent from both North and South America, accompanied by the CBS Pan American Orchestra under the musical direction of Alfredo Antonini. The post-war era also marked the beginning of CBS's dominance in the field of radio as well.
Zenith of network radio (1940s).
As 1939 wound down, Bill Paley announced that 1940 would "be the greatest year in the history of radio in the United States." He turned out to be right by more than anyone could imagine: the decade of the 1940s would indeed be the apogee of network radio by every gauge. Nearly 100% of the advertisers who made sponsorship deals in 1939 renewed their contracts for 1940; manufacturers of farm tractors made radios standard equipment on their machines. Wartime rationing of paper limited the size of newspapers – and effectively advertisements – and when papers turned them away, they migrated to radio sponsorship. A 1942 act by Congress made advertising expenses a tax benefit and that sent even automobile and tire manufacturers – who had no products to sell since they had been converted to war production – scurrying to sponsor symphony orchestras and serious drama on radio. In 1940, only one-third of radio programs were sponsored, while two-thirds were sustaining; by the middle of the decade, the statistics had swapped – two out of three shows now had cash-paying sponsors and only one-third were sustaining.
The CBS of the 1940s was vastly different from that of the early days; many of the old guard veterans had died, retired or simply left the network. No change was greater than that in Paley himself: he had become difficult to work for, and had "gradually shifted from leader to despot". He spent much of his time seeking social connections and in cultural pursuits; his "hope was that CBS could somehow learn to run itself". His brief to an interior designer remodeling his townhouse included a requirement for closets that would accommodate 300 suits, 100 shirts and had special racks for a hundred neckties.
As Paley grew more remote, he installed a series of buffer executives who sequentially assumed more and more power at CBS: first Ed Klauber, then Paul Kesten, and finally Frank Stanton. Second only to Paley as the author of CBS's style and ambitions in its first half-century, Stanton was "a magnificent mandarin who functioned as company superintendent, spokesman, and image-maker". He had come to the network in 1933 after sending copies of his Ph.D. thesis "A Critique Of Present Methods and a New Plan for Studying Radio Listening Behavior" to CBS top brass and they responded with a job offer. He scored an early hit with his study "Memory for Advertising Copy Presented Visually vs. Orally," which CBS salesmen used to great effect bringing in new sponsors. In 1946, Paley appointed Stanton as President of CBS and promoted himself to Chairman. Stanton's colorful, but impeccable, wardrobe – slate-blue pinstripe suit, ecru shirt, robin's egg blue necktie with splashes of saffron – made him, in the mind of one sardonic CBS vice-president, "the greatest argument we have for color television".
Despite the influx of advertisers and their cash, or perhaps because of them, the 1940s were not without bumps for the radio networks. The biggest challenge came in the form of the FCC's "chain broadcasting investigation" – the "monopoly probe", as it was often called. Though it started in 1938, the investigation only gathered steam in 1940 under new-broom chairman James L. Fly. By the time the smoke had cleared in 1943, NBC had already spun off its Blue Network, which became the American Broadcasting Company (ABC). CBS was also hit, though not as severely: Paley's brilliant 1928 affiliate contract which had given CBS first claim on local stations' air during sponsored time – the "network option" – came under attack as being restrictive to local programming. The final compromise permitted the network option for three out of four hours during certain dayparts, but the new regulations had virtually no practical effect, since most all stations accepted the network feed, especially the sponsored hours that earned them money. Fly's panel also forbade networks from owning artists' representation bureaus, so CBS sold its bureau to Music Corporation of America and it became Management Corporation of America.
On the air, the war had an impact on almost every show. Variety shows wove patriotism through their comedy and music segments; dramas and soaps had characters join the service and go off to fight. Even before hostilities commenced in Europe, one of the most played songs on radio was Irving Berlin's "God Bless America", popularized by CBS personality Kate Smith. Although an Office of Censorship sprang up within days of Pearl Harbor, censorship would be totally voluntary. A few shows submitted scripts for review; most did not. The guidelines that the Office did issue banned weather reports (including announcement of sports rainouts), news about troop, ship or plane movements, war production and live man-on-the-street interviews. The ban on ad-libbing caused quizzes, game shows and amateur hours to wither for the duration.
Surprising was "the granite permanence" of the shows at the top of the ratings. The vaudevillians and musicians who were hugely popular after the war were the same stars who had been huge in the 1930s: Jack Benny, Bing Crosby, Burns and Allen, and Edgar Bergen all had been on the radio almost as long as there had "been" network radio. A notable exception to this was relative newcomer Arthur Godfrey who, as late as 1942, was still doing a local morning show in Washington, D.C. Godfrey, who had been a cemetery-lot salesman and a cab driver, pioneered the style of talking directly to the listener as an "individual", with a singular "you" rather than phrases like "Now, folks..." or "Yes, friends...". His combined shows contributed as much as 12% of "all" CBS revenues; by 1948, he was pulling down $500,000 a year.
In 1947, Paley, still the undisputed "head talent scout" of CBS, led a much-publicized "talent raid" on NBC. One day, while Freeman Gosden and Charles Correll were hard at work at NBC writing their venerable "Amos and Andy" show, a knock came on the door; it was Paley himself, with an astonishing offer: "Whatever you are getting now I will give you twice as much." Capturing NBC's cornerstone show was enough of a "coup", but Paley repeated in 1948 with longtime NBC stars Edgar Bergen, Charlie McCarthy and Red Skelton, as well as former CBS defectors Jack Benny, radio's top-rated comedian, and Burns and Allen. Paley achieved this rout with a legal agreement reminiscent of his 1928 contract that caused some NBC radio affiliates to jump ship and join CBS. CBS would buy the stars' names as a property, in exchange for a large lump sum and a salary. The plan relied on the vastly different tax rates between income and capital gains, so not only would the stars enjoy more than twice their income after taxes, but CBS would preclude any NBC counterattack because CBS owned the performers' names.
As a result of this, Paley got in 1949 something he had sought for 20 years: CBS finally beat NBC in the ratings. But it was not just to one-up rival Sarnoff that Paley led his talent raid; he, and all of radio, had their eye on the coming force that threw a shadow over radio throughout the 1940s – television.
Prime time radio gives way to television (1950s).
In the spring of 1940, CBS staff engineer Peter Goldmark devised a system for color television that CBS management hoped would leapfrog the network over NBC and its existing black-and-white RCA system. The CBS system "gave brilliant and stable colors", while NBC's was "crude and unstable but 'compatible'". Ultimately, the FCC rejected the CBS system because it was incompatible with RCA's; that, and the fact that CBS had moved to secure many UHF, not VHF, television licenses, left CBS flatfooted in the early television age. In 1946, only 6,000 television sets were in operation, most in greater New York City where there were already three stations; by 1949, the number had increased to 3 million sets, and by 1951, had risen to 12 million. 64 American cities had television stations, though most of them only had one.
Radio continued to be the backbone of the company, at least in the "early" 1950s, but it was "a strange, twilight period". NBC's venerable Fred Allen saw his ratings plummet when he was pitted against upstart ABC's game show "Stop The Music!"; within weeks, he was dropped by longtime sponsor Ford Motor Company and was shortly gone from the scene. Radio powerhouse Bob Hope's ratings plunged from a 23.8 share in 1949 to 5.4 in 1953. By 1952, "death seemed imminent for network radio" in its familiar form; most telling of all, the big sponsors were eager for the switch.
Gradually, as the television network took shape, radio stars began to migrate to the new medium. Many programs ran on both media while making the transition. The radio soap opera "The Guiding Light" moved to television in 1952 and ran another 57 years; Burns & Allen, back "home" from NBC, made the move in 1950; Lucille Ball a year later; "Our Miss Brooks" in 1952 (though it continued simultaneously on radio for its full television life). The high-rated "Jack Benny Program" ended its radio run in 1955, and Edgar Bergen's Sunday night show went off the air in 1957. When CBS announced in 1956 that its radio operations had lost money, while the television network had made money, it was clear where the future lay. When the soap opera "Ma Perkins" went off the air on November 25, 1960, only eight, relatively minor series remained. Prime time radio ended on September 30, 1962, when "Yours Truly, Johnny Dollar" and "Suspense" aired for the final time.
CBS's radio programming after 1972.
The retirement of Arthur Godfrey in April 1972 marked the end of long-form programming on CBS radio; programming thereafter consisted of hourly news summaries and news features, known in the 1970s as "Dimension", and commentaries, including the "Spectrum" series that evolved into the "Point/Counterpoint" feature on the television network's "60 Minutes" and "First Line Report", a news and analysis feature delivered by CBS correspondents. The network also continued to offer traditional radio programming through its nightly "CBS Radio Mystery Theater", the lone holdout of old-style programming, from 1974 to 1982. The CBS Radio Network continues to this day, offering hourly newscasts, including its centerpiece "CBS World News Roundup" in the morning and evening, weekend sister program "CBS News Weekend Roundup", the news-related feature segment "The Osgood File", "What's In the News", a one-minute summary of one story, and various other segments such as commentary from Seattle radio personality Dave Ross, tip segments from various other sources, and technology coverage from CBS Interactive property CNET.
CBS is the last of the original Big Four radio networks that is still owned and operated by its founding company; ABC Radio was sold to Citadel Broadcasting in 2007 (and is now a part of Cumulus Media) while Mutual (now defunct) and NBC Radio were acquired by Westwood One in the 1980s (Westwood One and CBS were under common ownership from 1993 to 2007; the former would be acquired outright by Dial Global in October 2011).
Television years: expansion and growth.
CBS's involvement in television dates back to the opening of experimental station W2XAB in New York City on July 21, 1931, using the mechanical television system that had been more-or-less perfected in the late 1920s. Its initial broadcast featured New York Mayor Jimmy Walker, Kate Smith, and George Gershwin. The station boasted the first regular seven-day broadcasting schedule in American television, broadcasting 28 hours a week.
Announcer-director Bill Schudt was the station's only paid employee; all other talent was volunteer. W2XAB pioneered program development including small-scale dramatic acts, monologues, pantomime, and the use of projection slides to simulate sets. Engineer Bill Lodge devised the first synchronized sound wave for a television station in 1932, enabling W2XAB to broadcast picture and sound on a single shortwave channel instead of the two previously needed. On November 8, 1932, W2XAB broadcast the first television coverage of presidential election returns. The station suspended operations on February 20, 1933, as monochrome television transmission standards were in flux, and in the process of changing from a mechanical to an all-electronic system. W2XAB returned to the air with an all-electronic system in 1939 from a new studio complex in Grand Central Station and a transmitter atop the Chrysler Building, broadcasting on channel 2. W2XAB transmitted the first color broadcast in the United States on August 28, 1940.
On June 24, 1941, W2XAB received a commercial construction permit and program authorization as WCBW. The station went on the air at 2:30 p.m. on July 1, one hour after rival WNBT (channel 1, formerly W2XBS and now WNBC), making it the second authorized fully commercial television station in the United States. The FCC issued permits to CBS and NBC at the same time, and intended WNBT and WCBW to sign on simultaneously on July 1, so no one station could claim to be the "first".
During the World War II years, commercial television broadcasting was reduced dramatically. Toward the end of the war, commercial television began to ramp up again, with an increased level of programming evident from 1944 to 1947 on the three New York television stations which operated in those years (the local stations of NBC, CBS and DuMont). But as RCA and DuMont raced to establish networks and offer upgraded programming, CBS lagged, advocating an industry-wide shift and restart to UHF for their incompatible (with black and white) color system; the FCC putting an indefinite "freeze" on television licenses that lasted until 1952 also did not help matters. Only in 1950, when NBC was dominant in television and black and white transmission was widespread, did CBS begin to buy or build their own stations (outside of New York City) in Los Angeles, Chicago and other major cities. Up to that point, CBS programming was seen on such stations as KTTV in Los Angeles, which CBS – as a bit of insurance and to guarantee program clearance in that market – quickly purchased a 50% interest in that station, partnering with the "Los Angeles Times" newspaper. CBS then sold its interest in KTTV (now the West Coast flagship of the Fox network) and purchased outright Los Angeles pioneer station KTSL in 1950, renaming it KNXT (after CBS's existing Los Angeles radio property, KNX), later to become KCBS-TV. In 1953, CBS bought pioneer television station WBKB in Chicago, which had been signed on by former investor Paramount Pictures (and would become a sister company to CBS again decades later) as a commercial station in 1946, and changed that station's call sign to WBBM-TV, moving the CBS affiliation away from WGN-TV.
WCBS-TV would ultimately be the only station (as of 2013) built and signed on by CBS. The rest of the stations would be acquired by CBS, either in an ownership stake or outright purchase. In television's early years, the network bought Washington, D.C. affiliate WOIC (now WUSA) in a joint venture with "The Washington Post" in 1950, only to sell its stake to the "Post" in 1954 due to then-tighter FCC ownership regulations. CBS would also temporarily return to relying on its own UHF technology by owning WXIX in Milwaukee (now CW affiliate WVTV) and WHCT in Hartford, Connecticut (now Univision affiliate WUVN), but as UHF was not viable for broadcasting at the time (due to the fact that most television sets of the time were not equipped with UHF tuners), CBS decided to sell those stations off and affiliate with VHF stations WITI and WTIC-TV (now WFSB), respectively (ironically, CBS would later be forced back onto UHF in Milwaukee due to the affiliation agreement with New World Communications that resulted in WITI disaffiliating from the network in 1994 to join Fox; it is now affiliated with WDJT-TV in that market). More long-term, CBS bought stations in Philadelphia (WCAU, now owned by NBC) and St. Louis (KMOX-TV, now KMOV), but CBS would eventually sell these stations off as well; before buying KMOX-TV, CBS had attempted to purchase and sign on the channel 11 license in St. Louis, now KPLR-TV.
CBS did attempt to sign on a station in Pittsburgh after the "freeze" was lifted, as that city was then the sixth-largest market but only had one commercial VHF station in DuMont-owned WDTV, while the rest were either on UHF (the modern-day WPGH-TV and WINP-TV) or public television (WQED). Although the FCC turned down CBS's request to buy the channel 9 license in nearby Steubenville, Ohio and move it to Pittsburgh (that station, initially CBS affiliate WSTV-TV, is now NBC affiliate WTOV-TV), CBS did score a major coup when Pittsburgh-based Westinghouse Electric (a co-founder of NBC with RCA) bought WDTV from struggling DuMont and opted to affiliate the now-recalled KDKA-TV with CBS instead of NBC (like KDKA radio) due to NBC extorting and coercing Westinghouse to trade KYW radio and WPTZ (now KYW-TV) for Cleveland stations WTAM, WTAM-FM (now WMJI), and WNBK (now WKYC); the trade ended up being reversed in 1965 by order of the FCC and the United States Department of Justice after an eight-year investigation. Had CBS not been able to affiliate with KDKA-TV, it would have affiliated with eventual NBC affiliate WIIC-TV (now WPXI) once it signed on in 1957 instead. This coup would eventually lead to a much stronger relationship between Westinghouse and CBS decades later.
The "talent raid" on NBC of the mid-1940s had brought over established radio stars, who became stars of CBS television programs as well. One reluctant CBS star refused to bring her radio show, "My Favorite Husband", to television unless the network would recast the show with her real-life husband in the lead. Paley and network president Frank Stanton had so little faith in the future of Lucille Ball's series, redubbed "I Love Lucy", that they granted her wish and allowed her husband, Desi Arnaz, to take financial control of the comedy's production. This was the making of the Ball-Arnaz Desilu empire, and became the template for series production to this day; it also served as the template for some television conventions that continue to exist including the use of a multiple cameras to film scenes, the use of a studio audience and the airing of past episodes for syndication to other television outlets.
In 1949, CBS offered the first live television coverage of the proceedings of the United Nations General Assembly. This journalistic tour-de-force was under the direction of Edmund A. Chester, who was appointed to the post of Director for News, Special Events and Sports at CBS Television in 1948.
As television came to the forefront of American entertainment and information, CBS dominated television as it once had radio. In 1953, the CBS television network would make its first profit, and would maintain dominance on television between 1955 and 1976 as well. By the late 1950s, the network often controlled seven or eight of the slots on the "top ten" ratings list with well-respected shows like "Route 66". This success would continue for many years, with CBS being bumped from first place only due to the rise of ABC in the mid-1970s. Perhaps because of its status as the top-rated network, during the late 1960s and early 1970s CBS felt freer to gamble with controversial properties like the "Smothers Brothers Comedy Hour" and "All in the Family" (and its many spinoffs) during this period.
CBS begins television news operations.
Upon becoming commercial station WCBW in 1941, the pioneer CBS television station in New York City broadcast two daily news programs, at 2:30 and 7:30 p.m. weekdays, anchored by Richard Hubbell. Most of the newscasts featured Hubbell reading a script with only occasional cutaways to a map or still photograph. When Pearl Harbor was bombed on December 7, 1941, WCBW (which was usually off-the-air on Sundays to give the engineers a day off), took to the air at 8:45 p.m. that evening with an extensive special report. The national emergency even broke down the unspoken wall between CBS radio and television. WCBW executives convinced radio announcers and experts such as George Fielding Elliot and Linton Wells to come down to the station's Grand Central Station studios during the evening, and give information and commentary on the attack. Although WCBW's special report that night lasted less than 90 minutes, that special broadcast pushed the limits of live television in 1941 and opened up new possibilities for future broadcasts. As CBS wrote in a special report to the FCC, the unscheduled live news broadcast on December 7 "was unquestionably the most stimulating challenge and marked the greatest advance of any single problem faced up to that time". Additional newscasts were scheduled in the early days of the war.
In May 1942, WCBW (like almost all television stations) sharply cut back its live program schedule and cancelled its newscasts, as the station temporarily suspended studio operations, resorting exclusively to the occasional broadcast of films. This was primarily due to the fact that much of the staff had either joined the service or were redeployed to war-related technical research, and to prolong the life of the early, unstable cameras which were now impossible to repair due to the lack of parts available during wartime. In May 1944, as the war began to turn in favor of the Allies, WCBW reopened its studios and resumed production of its newscasts, which were briefly anchored by Ned Calmer, and then by Everett Holles. After the war, WCBW (which changed its call letters to WCBS-TV in 1946) introduced expanded news programs on its schedule – first anchored by Milo Boulton, and later by Douglas Edwards. On May 3, 1948, Edwards began anchoring "CBS Television News", a regular 15-minute nightly newscast on the rudimentary CBS television network, including WCBS-TV. Airing every weeknight at 7:30 p.m., it was the first regularly scheduled, network television news program featuring an anchor (the nightly Lowell Thomas NBC radio network newscast was simulcast on television locally on NBC's WNBT (now WNBC) for a time in the early 1940s and Hubbell, Calmer, Holles and Boulton on WCBW in the early and mid-1940s, but these were local television broadcasts seen only in the New York City market).
The NBC television network's offering at the time "NBC Television Newsreel" (premiering in February 1948) was simply film footage with voice narration to provide illustration of the stories. In 1950, the nightly newscast was retitled "Douglas Edwards with the News", and the following year, it became the first news program to be broadcast on both coasts, thanks to a new coaxial cable connection, prompting Edwards to use the greeting, "Good evening everyone, coast to coast" to begin each edition. The broadcast was renamed the "CBS Evening News" when Walter Cronkite replaced Edwards in 1962. Edwards remained with CBS News as anchor/reporter for various daytime television and radio news broadcasts until his retirement on April 1, 1988.
Color telecasts (1953–1965).
Although CBS Television was the first with a working color television system, the network lost out to RCA in 1953, due in part because the CBS color system was incompatible with existing black-and-white sets. Although RCA – then-parent company of NBC – made its color system available to CBS, the network was not interested in boosting RCA's profits and televised only a few specials in color for the rest of the decade. The specials included the "Ford Star Jubilee" programs (which included the first telecast ever of Metro-Goldwyn-Mayer (MGM)'s 1939 film classic "The Wizard of Oz") as well as the 1957 telecast of Rodgers and Hammerstein's "Cinderella"; Cole Porter's musical version of "Aladdin"; and "Playhouse 90"‍ '​s only color broadcast, the 1958 production of "The Nutcracker", featuring choreography by George Balanchine. The "Nutcracker" telecast was based on the famous production staged annually since 1954 in New York, and performed by the New York City Ballet. CBS would later show two other versions of the ballet, a semi-forgotten one-hour German-American version hosted by Eddie Albert, shown annually for three years beginning in 1965, and the well-loved Mikhail Baryshnikov production from 1977 to 1981 (this production later moved to PBS).
Beginning in 1959, "The Wizard of Oz", now telecast by CBS as a family special in its own right (after the cancellation of "Ford Star Jubilee"), became an annual tradition on color television. However, it was the success of NBC's 1955 telecast of the musical "Peter Pan", starring Mary Martin, the most watched television special of its time, that inspired CBS to telecast "The Wizard of Oz", "Cinderella" and "Aladdin".
1960–1967.
From 1960 to 1965, the CBS television network limited its color broadcasts to only a few special presentations such as "The Wizard of Oz", and only then if the sponsor would pay for it. Red Skelton was the first CBS host to telecast his weekly programs in color, using a converted movie studio, in the early 1960s; he tried unsuccessfully to persuade the network to use his facility for other programs, and was then forced to sell it. Color was being pushed hard by rival NBC; even ABC had several color programs, beginning in the fall of 1962, however those were limited because of financial and technical issues that the network was going through at the time. One particularly notable television special aired by CBS during this era was the Charles Collingwood-hosted tour of the White House with First Lady Jackie Kennedy, which was broadcast in black-and-white.
Beginning in 1963, at least one CBS show, "The Lucy Show", began filming in color at the insistence of its star and producer Lucille Ball; she realized that color episodes would command more money when they were eventually sold into syndication, but even it was broadcast in black and white through the end of the 1964–65 season. This would all change by the mid-1960s, when market pressure forced CBS Television to being adding color programs to its regular schedule for the 1965–66 season and complete the transition to the format during the 1966–67 season. By the fall of 1967, nearly all of CBS's television programs were in color, as was the case with those aired by NBC and ABC. A notable exception was "The Twentieth Century", which consisted mostly of newsreel archival footage, though even this program used at least some color footage by the late 1960s.
In 1965, CBS telecast a new color version of Rodgers and Hammerstein's "Cinderella". This version, starring Lesley Ann Warren and Stuart Damon in the roles formerly played by Julie Andrews and Jon Cypher, was shot on videotape rather than being telecast live, and would become an annual tradition on the network for the next nine years.
In 1967, NBC outbid CBS for the rights to the annual telecast of "The Wizard of Oz", with the film moving to NBC beginning the following year. However, the network quickly realized their mistake in allowing what was then one of its prime ratings winners to be acquired by another network, and by 1976, CBS reacquired the television rights to the film, with the network continuing to broadcast it through the end of 1997. CBS aired "The Wizard of Oz" twice in 1991, in March and again the night before Thanksgiving. Thereafter, it was broadcast on the night before Thanksgiving.
"Rural purge" and success in the 1970s and early-mid 1980s (1971–86).
By the end of the 1960s, CBS was broadcasting virtually its entire programming lineup in color, but many of its shows (including "The Beverly Hillbillies", "Mayberry R.F.D.", "Petticoat Junction", "Hee Haw" and "Green Acres") were appealing more to older and more rural audiences and less to the young, urban and more affluent audiences that advertisers sought to target. Fred Silverman (who would later head ABC, and then later NBC) made the decision to cancel most of those otherwise hit shows by mid-1971 in what became colloquially referred to as the "Rural Purge", with "Green Acres" cast member Pat Buttram remarking that the network cancelled "anything with a tree in it".
While the "rural" shows got the axe, new hits, like "The Mary Tyler Moore Show", "All in the Family", "The Bob Newhart Show", "Cannon", "Barnaby Jones", "Kojak" and "The Sonny & Cher Comedy Hour" took their place on the network's schedule and kept CBS at the top of the ratings through the early 1970s. The majority of these hits were overseen by then East Coast vice president Alan Wagner. "60 Minutes" also moved to the 7:00 p.m. Eastern Time slot on Sundays in 1976 and became the first ever prime time television news program to enter the Nielsen Top 10 in 1978.
One of CBS's most popular shows during the period was "M*A*S*H", a dramedy that ran for 11 seasons from 1972 to 1983 and was based on the hit Robert Altman film; as with the film, the series was set during the Korean War in a Mobile Army Surgical Hospital. The 2½-hour series finale, in its initial airing on February 28, 1983, had peak viewership of up to 125 million Americans (77% of all television viewership in the U.S. that night), which established it as the all-time most watched single U.S. television episode; it also held the ubiquitous distinction of having the largest single-night primetime viewership of any television program in U.S. history until it was surpassed by the Super Bowl, which have taken the record consistently since 2010 (through the annual championship game's alternating telecasts by CBS and rival networks Fox and NBC).
Silverman also first developed his strategy of spinning new shows off from established hit series while at CBS, with "Rhoda" and "Phyllis" spun from "The Mary Tyler Moore Show", "Maude" and "The Jeffersons" spun from "All in the Family" and "Good Times" from "Maude". After Silverman's departure, CBS dropped behind ABC for second place in the 1976–77 season, but still rated strongly, based on its earlier hits and some new ones: "One Day at a Time", "Alice", "Lou Grant", "WKRP in Cincinnati", "The Dukes of Hazzard" (a suspiciously "rural" series) and, the biggest hit of the early 1980s, "Dallas", the latter of which holds the record for the all-time most watched non-series finale single U.S. television episode - the November 21, 1980 primetime telecast of the resolution episode of the internationally prominent "Who Shot J.R.?" cliffhanger.
By 1982, ABC had run out of steam, NBC was in dire straits with many failed programming efforts greenlighted by Silverman during his tenure as network president (a four-year run which began in 1978), and CBS once more nosed ahead, courtesy of the major success of "Dallas" (and its spin-off "Knots Landing"), as well as hits in "Falcon Crest", "Magnum, P.I.", "Simon & Simon" and "60 Minutes". CBS also acquired the broadcast rights to the NCAA Men's Division I Basketball Tournament in 1982 (taking over for NBC), which the network has broadcast every March since. CBS was takeover the Dennis B. Kane's production company and formed new company CBS/Kane Productions International (CKPI). The network managed to pull out a few new hits over the next couple of years – namely "Kate & Allie", "Newhart", "Cagney & Lacey", "Scarecrow and Mrs. King", "Murder, She Wrote" – however this resurgence would be short-lived. CBS had become mired in debt as a result of a failed takeover effort by Ted Turner, which CBS chairman Thomas Wyman successfully helped to fend off. The network sold its St. Louis owned-and-operated station KMOX-TV, and allowed the purchase of a large portion of its shares (under 25 percent) by Loew's Inc. chairman Laurence Tisch. Consequently, collaboration between Paley and Tisch led to the slow dismissal of Wyman, with Tisch taking over as chief operating officer, and Paley returning as chairman.
Tiffany Network in distress (1986–2002).
In 1984, "The Cosby Show" and "Miami Vice" debuted on NBC and immediately garnered high ratings, helping to bring that network back to first place by the 1985–86 season with a slate that included several other hits (such as "Amen", "Family Ties", "Cheers", "The Golden Girls", "L.A. Law" and "227"). ABC had in turn also rebounded with hits such as "Dynasty", "Who's the Boss?", "Hotel", "Growing Pains" and "Roseanne". By the end of the 1987–88 season, CBS, in contrast, had fallen to third place behind both ABC and NBC for the first time, and had some major rebuilding to do.
Ironically, some of the groundwork had been laid as CBS fell in the ratings, with hits "Simon & Simon", "Falcon Crest", "Murder, She Wrote", "Kate & Allie" and "Newhart" still on the schedule from the most recent resurgence, and future hits "Designing Women", "Murphy Brown", "Jake and the Fatman" and newsmagazine "48 Hours" having debuted during the late 1980s. The network was also still getting decent ratings for "60 Minutes", "Dallas" and "Knots Landing", however the ratings for "Dallas" were a far cry from what they were in the early 1980s. During the early 1990s, the network would bolster its sports lineup by obtaining the broadcast television rights to Major League Baseball from ABC and NBC and the Winter Olympics from ABC.
Under network president Jeff Sagansky, the network was able to earn strong ratings from new shows "", "Touched by an Angel", "Dr. Quinn, Medicine Woman", "Walker, Texas Ranger", and a resurgent "Jake and the Fatman" during this period, and CBS was able to reclaim the first place crown briefly, in the 1992–93 season; however, a drawback for the network during this timeframe was that its programming slate skewed towards an older demographic than ABC, NBC or even Fox, with its relatively limited presence at that time. In 1993, the network made a breakthrough in establishing a successful late-night talk show franchise to compete with NBC's "The Tonight Show" when it signed David Letterman away from NBC after the "Late Night" host was passed over as Johnny Carson's successor on "Tonight" in favor of Jay Leno. However, CBS would soon suffer a major blow in a move that would change American television forever.
1993 saw the network lose the rights to two major sports leagues: the network terminated its contract with Major League Baseball (after losing approximately US$500 million over a four-year span), with the league reaching a new contract with NBC and ABC. Then on December 17 of that year, in a move that surprised many media analysts and television viewers, Fox – then a fledgling network that in its then-seven years on the air had begun to accrue several popular programs in the Nielsen Top 20 alongside its established counterparts – outbid CBS for the broadcast rights to the National Football Conference, stripping the elder network of National Football League game telecasts for the first time since CBS began broadcasting games from the pre-merger NFL in 1955; Fox bid $1.58 billion for the NFC television rights, significantly higher than CBS' reported offer of $290 million to retain the contract.
The acquisition of the NFC rights, which took effect with the 1994 NFL season, resulted in Fox striking a series of affiliation deals with longtime affiliates of each of the Big Three networks; CBS bore the brunt of the switches, with many of its existing affiliates being lured away by Fox (especially those owned by New World Communications, which Fox struck its largest affiliation deal with) while most of the stations that CBS ended up affiliating with to replace the previous affiliates it lost to Fox were former Fox affiliates and independent stations, most of which had limited to no local news presence prior to joining CBS. The network attempted to fill the loss of NFL by going after the rights to the National Hockey League; however when CBS countered with a bid, Fox also outbid the network for the NHL rights.
The loss of the NFL, along with an ill-fated effort to court younger viewers, led to a drop in CBS' ratings. One of the shows that was affected was the "Late Show with David Letterman", which saw its viewership decline in large part due to the affiliation switches, at times even landing in third place in its timeslot behind ABC's "Nightline"; as a result, NBC's "The Tonight Show with Jay Leno", which the "Late Show" often dominated over during the first two years of that show's run, became the top-rated late-night talk show. Still, CBS was able to produce some hits during the mid-1990s, such as "The Nanny", "JAG" (which moved to the network from NBC), "Cosby", "Cybill" and "Everybody Loves Raymond".
CBS attempted to court families on Fridays with the launch of a family-oriented comedy block, the "CBS Block Party", in the 1997–98 season (consisting of "Family Matters", "Step by Step", "Meego" and "The Gregory Hines Show", all but the latter coming from Miller-Boyett Productions, which had maintained a relationship with ABC during the late 1980s and 1990s). The lineup failed to compete against ABC's "TGIF" lineup (which saw its own viewership erode that season): "Meego" and "Hines" were cancelled by November, while "Family Matters" and "Step by Step" were put on hiatus and ended their runs in the summer of 1998. That winter, CBS aired its last Olympic Games to date with its telecast of the 1998 Winter Games in Nagano; NBC, which had already held the rights to the Summer Olympics since 1988, took over coverage of the Winter Olympics beginning with the 2002 Games.
The building blocks for the network's return to the top of the ratings were put in place in 1997, when CBS regained the NFL through its acquisition of the broadcast television rights to the American Football Conference (stripping that package from NBC after 32 years), effective with the 1998 season. The contract was struck shortly before the AFC's emergence as the dominant NFL conference over the NFC, spurred in part by the turnaround of the New England Patriots in the 2000s. With the help of the AFC package, CBS surpassed NBC for first place in the 1999–2000 season; however, it was beaten by ABC the following year. The network gained additional hits in the late 1990s and early 2000s with series such as "The King of Queens", "Nash Bridges", "Judging Amy", "Becker" and "Yes, Dear".
Return to first place and rivalry with Fox (2002–present).
Another turning point for CBS came in the summer of 2000 when it debuted the summer reality shows "Survivor" and "Big Brother", which became surprise summer hits for the network. In January 2001, CBS debuted the second season of "Survivor" after its broadcast of Super Bowl XXXV and scheduled it on Thursdays at 8:00 p.m. Eastern Time; it also moved the investigative crime drama "" (which had debuted that fall in the Friday 9:00 p.m. time slot) to follow "Survivor" at 9:00 p.m. on Thursdays. The pairing of the two shows was both able to chip away at and eventually beat NBC's Thursday night lineup, and attract younger viewers to the network.
During the 2000s, CBS found additional successes with a slew of police procedurals (several of which were produced by Jerry Bruckheimer) including "Cold Case", "Without a Trace", "Criminal Minds", "NCIS" and "The Mentalist", along with "CSI" spinoffs ' and ' as well as sitcoms "Still Standing", "Two and a Half Men", "How I Met Your Mother", "The New Adventures of Old Christine", "Rules of Engagement" and "The Big Bang Theory". The network's programming slate, buoyed largely by the success of "CSI", briefly led the network to retake first place in the ratings from NBC in the 2002–03 season. The decade also saw CBS finally make ratings headway on Friday nights, a perennial weak spot for the network, with a focus toward drama series such as "Ghost Whisperer" and the relatively short-lived but critically acclaimed "Joan of Arcadia".
CBS became the most watched American broadcast television network once again in the 2005–06 season, an achievement that the network proclaimed in on-air promotions as being "America's Most Watched Network" (a term it would use again in the 2011–12 season). This lasted until the 2007–08 season, when Fox overtook CBS for first, becoming the first non-Big Three network to earn the title as the most watched network overall in the United States; despite CBS' continued strong lineup, Fox's first-place finish that season was primarily due to its reliance on "American Idol" (the longest reigning #1 prime time U.S. television program from 2004 to 2011). CBS retook its place as the top-rated network in the 2008–09 season, where it has remained every season since. Fox and CBS, both having ranked as the highest rated of the major broadcast networks during the 2000s, tend to nearly equal one another in the 18–34, 18–49 and 25–54 demographics, with either network alternating in placing first in either of these groups by very close margins. "NCIS", which has been the flagship of CBS' Tuesday lineup for much of its run, became the network's highest-rated drama by the 2007–08 season.
The 2010s saw additional hits for the network including drama series "The Good Wife"; police procedurals "Person of Interest", "Blue Bloods", "Elementary", "Hawaii Five-0" and "NCIS" spin-off ""; reality series "Undercover Boss"; and sitcoms "Two Broke Girls" and "Mike & Molly". "The Big Bang Theory", one of several sitcoms from veteran writer/producer Chuck Lorre, started off with modest ratings but saw its viewership skyrocket (earning per episode ratings of up to 17 million viewers) to become the top-rated network sitcom in the U.S. by the 2010–11 season, as well as the second most watched U.S. television program starting from the 2013-14 season, when the series became the anchor of the network's Thursday lineup. Meanwhile, the Lorre-produced series it overtook for the position, "Two and a Half Men", saw its ratings decline to respectable levels for its final four seasons following the 2011 firing of original star Charlie Sheen (due to a dispute with Lorre) and the addition of Ashton Kutcher as its primary lead.
Until 2012, CBS ranked in second place among adults 18-49, but after the ratings declines Fox experienced during the 2012–13 fall season, the network was able to take the top spot in the demographic as well as in total viewership (for the fifth year in a row) by the start of 2013. At the end of the 2012–13 season, the tenth season of "NCIS" took the top spot among the season's most watched network programs, which gave CBS its top-rated show after "American Idol" ended its eight-year nationwide primetime lead (with "NBC Sunday Night Football" taking over the top spot from "Idol" the year before and from "NCIS" the year after), for the first time since the 2002–03 season (when "CSI: Crime Scene Investigation" led Nielsen's seasonal prime time network ratings).
The strength of its 2013–14 slate led to a surplus of series on CBS' 2014–15 schedule, with 21 series held over from the previous season, along with eight new series including moderate hits in "Madam Secretary", "" and "Scorpion". The network also expanded its NFL coverage through a partnership with NFL Network to carry "Thursday Night Football" games during the first eight weeks of the NFL season. 2014 also saw end of CBS' 14-year conversion to an entirely high definition schedule, with "Big Brother" and "Let's Make a Deal" becoming the final two network series to convert from standard definition to HD (in contrast, NBC, Fox and The CW were already airing their entire programming schedules – outside of Saturday mornings – in high definition by the 2010–11 season, while ABC was broadcasting its entire schedule in HD by the 2011–12 midseason).
Conglomerate.
Prior to the 1960s, CBS's acquisitions had been related mainly to its broadcasting business; these had included the purchases of American Record Corporation and Hytron. During the 1950s and early 1960s, CBS operated a CBS-Columbia division, manufacturing phonographs, radios and television sets; however, the company had problems with product quality, which partly hindered any possibility of success in that field. In 1955, CBS purchased animation studio Terrytoons Inc. from its founder Paul Terry, not only acquiring Terry's backlog of cartoons for the network but continuing the studio's ongoing contract to provide theatrical cartoons for 20th Century Fox well into the 1960s.
During the 1960s, CBS began an effort to diversify its portfolio, and looked for suitable investments. In 1965, it acquired electric guitar maker Fender from Leo Fender, who agreed to sell his company due to health problems. The purchase also included that of Rhodes electric pianos, which had already been acquired by Fender. This and other acquisitions led to a restructuring of the corporation into various operating groups and divisions; the quality of the products manufactured by these acquired companies fell dramatically, resulting in the terms "pre-CBS" to refer to products of higher, sought after quality and "CBS" for products of mass-produced lower quality.
In other diversification attempts, CBS would buy (and later sell) a varied number of other properties including sports teams (especially the New York Yankees baseball club), book and magazine publishers (Fawcett Publications including "Woman's Day", and Holt, Rinehart and Winston), map-makers and toy manufacturers (Gabriel Toys, Child Guidance, Wonder Products, Gym Dandy and Ideal). CBS developed an early home video system called EVR (Electronic Video Recording), but was never able to launch it successfully.
As William Paley aged, he tried to find the one person who could follow in his footsteps. However, numerous successors-in-waiting came and went. By the mid-1980s, investor Laurence Tisch had begun to acquire substantial holdings in CBS. Eventually he gained Paley's confidence, and with his support, took control of CBS in 1986. Tisch's primary interest was turning profits. When CBS faltered, underperforming units were given the axe. Among the first properties to be jettisoned was the Columbia Records group, which had been part of the company since 1938. In 1986, Tisch also shut down the CBS Technology Center in Stamford, which had started in New York City in the 1930s as CBS Laboratories and evolved to be the company's technology research and development unit.
Columbia Records.
Columbia Records was a record label acquired by CBS in 1938. In 1962, CBS launched CBS Records International to market Columbia recordings outside of North America, where the Columbia name was controlled by other entities. In 1966, CBS Records was made a separate subsidiary of Columbia Broadcasting System, Inc. CBS sold the CBS Records Group to Sony in 1988, initiating the Japanese buying spree of U.S. companies (such as MCA, Pebble Beach Co., Rockefeller Center and the Empire State Building) that continued into the 1990s. The record label company was rechristened Sony Music Entertainment in 1991, as Sony had a short term license on the CBS name.
Sony purchased from EMI its rights to the Columbia Records name outside the U.S., Canada, Spain and Japan. Sony now uses Columbia Records as a label name in all countries except Japan, where Sony Records remains their flagship label. Sony acquired the Spanish rights when Sony Music merged with Bertelsmann subsidiary BMG in 2004 as Sony BMG, co-owned by Sony and Bertelsmann; Sony bought out BMG's share in 2008. CBS Corporation formed a new record label named CBS Records in 2006.
Publishing.
CBS entered the publishing business in 1967 by acquiring Holt, Rinehart & Winston, a publisher of trade books and textbooks as well as the magazine "Field & Stream". The following year, CBS acquired the medical publishing company Saunders and merged it into Holt, Rinehart & Winston. In 1971, CBS acquired Bond/Parkhurst, the publisher of "Road & Track" and "Cycle World". CBS greatly expanded its magazine business by purchasing Fawcett Publications in 1974, bringing in such magazines as "Woman's Day". In 1984, it acquired the majority of the publications owned by Ziff Davis.
CBS sold its book publishing businesses in 1985. The educational publishing division, which retained the Holt, Rinehart & Winston name, was sold to Harcourt Brace Jovanovich; the trade book division, renamed Henry Holt and Company, was sold to the West German publisher Holtzbrinck. CBS exited the magazine business through the sale of the unit to its executive Peter Diamandis, who later sold the magazines to Hachette Filipacchi Médias in 1988, forming Hachette Filipacchi Media U.S.
CBS Musical Instruments division.
Forming the CBS Musical Instruments division, the company also acquired Fender (1965–1983), Electro-Music Inc. (Leslie speakers) (1965–1980), Rogers Drums (1966–1983), Steinway pianos (1972–), Gemeinhardt flutes, Lyon & Healy harps (in the late 1970s), Rodgers (institutional) organs, and Gulbransen home organs. The company's last musical instrument manufacturer purchase was its 1981 acquisition of the assets of then-bankrupt ARP Instruments, a developer of electronic synthesizers.
Between 1965 and 1985, the quality of Fender guitars and amplifiers declined significantly. Encouraged by outraged Fender fans, CBS Musical Instruments division executives executed a leveraged buyout in 1985 and created Fender Musical Instruments Corporation. At the same time, CBS divested itself of Rodgers, along with Steinway and Gemeinhardt, all of which were purchased by Steinway Musical Properties. The other musical instrument manufacturing properties were also liquidated.
Film production.
CBS made a brief, unsuccessful move into film production in the late 1960s, through the creation of Cinema Center Films. This profit-free unit was shut down in 1972; the distribution rights to the Cinema Center library today rest with Paramount Pictures for home video (via CBS Home Entertainment) and theatrical release, and with CBS Television Distribution for television syndication (most other ancillary rights remain with CBS). The studio released such films as the 1969 Steve McQueen drama "The Reivers" and the 1970 Albert Finney musical "Scrooge".
Ten years after Cinema Center ceased operations, in 1982, CBS made another attempt at a venture in the film industry, in a joint venture with Columbia Pictures and HBO called TriStar Pictures. Despite releasing such box office successes as "The Natural", "Places in the Heart" and "", CBS felt the studio was not making a profit and in 1985, sold its stake in TriStar to Columbia Pictures' then-corporate parent The Coca-Cola Company.
In 2007, CBS Corporation announced its intent to get back into the feature film business, slowly launching CBS Films and hiring key executives in the spring of 2008 to start up the new venture. The CBS Films name was actually used previously in 1953, when it was briefly used for CBS's distributor of off-network and first-run syndicated programming to local television stations in the United States and internationally.
Home video.
CBS entered into the home video market, when it partnered with Metro-Goldwyn-Mayer to form MGM/CBS Home Video in 1978; the joint venture was dissolved by 1982. CBS later partnered with another studio, 20th Century Fox, to form CBS/Fox Video. CBS's duty was to release some of the film title released by TriStar Pictures under the CBS/Fox Video label.
Gabriel Toys.
CBS entered the video game market briefly, through its acquisition of Gabriel Toys (renamed CBS Toys), publishing several arcade adaptations and original titles under the name "CBS Electronics", for the Atari 2600, and other consoles and computers; it also produced one of the first karaoke recording/players. CBS Electronics also distributed all Coleco-related video game products in Canada, including the ColecoVision. CBS later sold Gabriel Toys to View-Master, which eventually ended up as part of Mattel.
New owners.
By the early 1990s, profits had fallen as a result of competition from cable television and video rentals, and in consequence of the high cost of programming. About 20 former CBS affiliates switched to the rapidly rising Fox network in the mid-1990s, while many television markets across the United States (KDFX in Palm Springs, California and KECY in Yuma, Arizona were reportedly the first to switch in August 1994) lost their CBS affiliate for a while. The network's ratings were acceptable, but it struggled with an image of stodginess. Laurence Tisch lost interest and sought a new buyer.
Westinghouse Electric Corporation.
In the mid-1990s, CBS formed an affiliate relationship with Westinghouse Electric Corporation as a partial result of losing many longtime affiliates owned by New World Communications through an affiliation agreement with Fox that New World signed in May 1994. The New World deal resulted in CBS affiliating with UHF stations in Detroit and Cleveland – former Fox affiliate WOIO and low-rated ethnic independent WGPR-TV (now WWJ-TV), the latter of which was purchased by the network – after a failed attempt to woo the respective longtime ABC affiliates in those markets, WXYZ-TV and WEWS-TV (the latter of which had previously been a CBS affiliate from 1947 to 1955) to respectively replace departing affiliates WJBK and WJW-TV, a situation that the E. W. Scripps Company actually used as leverage to sign a group-wide affiliation deal with ABC that kept the network on WXYZ and WEWS.
Included in the Scripps deal was Baltimore NBC affiliate WMAR-TV (which had been affiliated with CBS from 1948 to 1981), displacing longtime ABC affiliate WJZ-TV, despite the fact that Westinghouse-owned WJZ-TV had long been the Baltimore market's dominant station while WMAR-TV had long been in a distant third and even nearly lost its license in 1991. This did not sit well with Westinghouse, who even before the New World deal was already seeking a group-wide affiliation deal of its own, but accelerated the process after the Scripps-ABC agreement.
In 1994, Westinghouse signed a long-term deal to affiliate all five of its television stations with CBS. Of the other four stations, two of the stations (KPIX in San Francisco and KDKA-TV in Pittsburgh) were already longtime affiliates of the network, while two others (KYW-TV in Philadelphia and WBZ-TV in Boston) were longtime affiliates of NBC. The network decided to sell off existing O&O in Philadelphia, WCAU, which would eventually be purchased by NBC, despite at the time being much higher rated locally than KYW-TV. While WJZ-TV and WBZ-TV switched to CBS in January 1995, the swap was delayed in Philadelphia when CBS discovered that an outright sale of channel 10 would have forced it to pay massive taxes on the proceeds from the deal. To solve this problem, CBS, NBC and Group W entered into a complex ownership/affiliation deal in the summer of 1995. NBC traded KCNC-TV in Denver and KUTV in Salt Lake City to CBS in return for WCAU, which for legal reasons would be an even trade. CBS then traded controlling interest in KCNC and KUTV to Group W in return for a minority stake in KYW-TV. As compensation for the loss of stations, NBC and CBS traded transmitter facilities in Miami, with NBC-owned WTVJ moving to channel 6 and CBS-owned WCIX moving to channel 4 as WFOR-TV.
On August 1, 1995, Westinghouse acquired CBS outright for $5.4 billion. As one of the major broadcasting group owners of commercial radio and television stations (as Group W) since 1920, Westinghouse sought to transition from a station operator into a major media company with its purchase of CBS. Except for KUTV (which CBS sold to Four Points Media Group in 2007, and is now owned by the Sinclair Broadcast Group), all of the stations involved in the initial Westinghouse deal as well as WWJ-TV remain owned-and-operated stations of the network to this day.
Westinghouse's acquisition of CBS had the effect of suddenly turning the combined company's all-news radio stations in New York City (WCBS and WINS) and Los Angeles (KNX and KFWB) from bitter rivals to sister stations. While KFWB switched from all-news to news/talk in 2009, WINS and WCBS remain all-news stations, with WINS (which pioneered the all-news format in 1965) concentrating its news coverage on the five core New York City boroughs and WCBS, with its much more powerful signal, covering the surrounding tri-state metropolitan area. In Chicago, the situation started out with Westinghouse's WMAQ beginning to feature long-form stories and discussions about the news, along with a business news focus to differentiate from WBBM until 2000, when an FCC ownership situation had CBS Radio deciding to move its all sports WSCR to WMAQ's signal to sell off the former WSCR facility.
In 1997, Westinghouse acquired the Infinity Broadcasting Corporation, owner of more than 150 radio stations, for $4.9 billion. Also that year, Westinghouse created CBS Cable, a division formed through the acquisition of two existing cable channels from the Gaylord Entertainment Company (The Nashville Network (now Spike) and Country Music Television) and starting a new one (CBS Eye on People, which was later sold to Discovery Communications). CBS also owned the Spanish-language news network CBS Telenoticias.
Following the Infinity purchase, operation and sales responsibilities for the CBS Radio Network was handed to Infinity, which turned management over to Westwood One, a major radio program syndicator that Infinity managed which had previously purchased the Mutual Broadcasting System, NBC's radio networks and the rights to use the "NBC Radio Networks" name. For a time, CBS Radio, NBC Radio Networks and CNN's radio news services were all under the Westwood One umbrella. s of 2008[ [update]], Westwood One continues to distribute CBS radio programming, but as a self-managed company that put itself up for sale and found a buyer for a significant amount of its stock.
Also in 1997, Westinghouse changed its name to CBS Corporation, and corporate headquarters were moved from Pittsburgh to New York City. To underline the change in emphasis, all non-entertainment assets were put up for sale. Another 90 radio stations were added to Infinity's portfolio in 1998 with the acquisition of American Radio Systems Corporation for $2.6 billion.
In 1999, CBS paid $2.5 billion to acquire King World Productions, a television syndication company whose programs included "The Oprah Winfrey Show", "Jeopardy!" and "Wheel of Fortune". By the end of 1999, all pre-CBS elements of Westinghouse's industrial past (beyond retaining rights to the name for brand licensing purposes) were gone.
Viacom.
By the 1990s, CBS had become a broadcasting giant; however in 1999, entertainment conglomerate Viacom – a company that ironically was created by CBS in 1952 as CBS Films, Inc. to syndicate old CBS series and was spun off under the Viacom name in 1971 – announced it was taking over its former parent in a deal valued at $37 billion. Following completion of this effort in 2000, Viacom became the second-largest entertainment company in the world. Coincidentally, Viacom had purchased Paramount Pictures, which had once invested in CBS, in 1994.
CBS Corporation and CBS Studios.
Having assembled all the elements of a communications empire, Viacom found that the promised synergy was not there; in 2005, Viacom announced that it would split the company into two separately operated but commonly controlled entities. CBS became the center of a new company, CBS Corporation. The legal successor to the old Viacom, the company's properties included the broadcasting entities (CBS and UPN, the latter of which later merged with Time Warner-owned The WB to form The CW; the Viacom Television Stations Group, which became CBS Television Stations; and CBS Radio); Paramount Television's production operations (now known as CBS Television Studios); Viacom Outdoor advertising (renamed CBS Outdoor); Showtime Networks; Simon & Schuster; and Paramount Parks, which the company sold in May 2006. The other company, which retained the Viacom name, kept Paramount Pictures, assorted MTV Networks, BET Networks, and Famous Music (the latter of which was sold to Sony/ATV Music Publishing in May 2007).
As a result of the Viacom/CBS corporate split, as well as other acquisitions over recent years, CBS (under the moniker CBS Studios) owns a massive film and television library spanning nine decades; these include not acquired material from Viacom and CBS in-house productions and network programs, as well as programs originally aired on competing networks. Shows and other material in this library include among others, "I Love Lucy", "The Honeymooners", "The Twilight Zone", "Hawaii Five-O" (both the original and current remake), "Gunsmoke", "The Fugitive", "The Love Boat", "Little House on the Prairie" (U.S. television rights only), "Cheers", "Becker", "Family Ties", "Happy Days" and its spin-offs, "The Brady Bunch", "Star Trek", "The Young Indiana Jones Chronicles" (distribution rights on behalf of copyright holder Lucasfilm), "Evening Shade", "Duckman", "CSI: Crime Scene Investigation" and its spin-offs, the CBS theatrical library (including "My Fair Lady" and "Scrooge"), and the entire Terrytoons library from 1921 forward.
Both CBS Corporation and the new Viacom are owned by National Amusements, the Sumner Redstone-owned company that controlled the original Viacom prior to the split. As such, Paramount Home Media Distribution (formerly Paramount Home Entertainment) continues to handle DVD and Blu-ray distribution for the CBS library.
Programming.
s of 2013[ [update]], CBS provides 87½ hours of regularly scheduled network programming each week. The network provides 22 hours of prime time programming to affiliated stations Monday through Saturdays from 8:00–11:00 p.m. Eastern and Pacific (7:00–10:00 p.m. in all other time zones) and Sundays from 7:00–11:00 p.m. (6:00–10:00 p.m. elsewhere).
Daytime programming is also provided from 10:00 a.m. to 3:00 p.m. weekdays (with a half-hour break at 12:00 p.m. Eastern/Pacific for CBS stations to air local newscasts or syndicated programs; usage of the 10:00 a.m. and 2:00 p.m. hours for network programming vary depending on the affiliate and on time zone) featuring the game shows "The Price Is Right" and "Let's Make a Deal", soap operas "The Young and the Restless" and "The Bold and the Beautiful", and talk show "The Talk". CBS News programming includes "CBS This Morning" from 7:00 to 9:00 a.m. weekdays and Saturdays; nightly editions of "CBS Evening News" (whose weekend editions are occasionally subject to abbreviation or preemption due to sports telecasts overrunning into the program's timeslot), the Sunday political talk show "Face the Nation", early morning news programs "Up to the Minute" and "CBS Morning News" and the newsmagazines "60 Minutes", "CBS News Sunday Morning" and "48 Hours". Late nights feature the weeknight talk shows "Late Show with David Letterman" and "The Late Late Show".
Sports programming is also provided weekend afternoons at any time between 12:00 and 7:00 p.m. (9:00 a.m.-4:00 p.m. Pacific Time). Due to the unpredictable length of sporting events, CBS will occasionally delay scheduled primetime programs to allow the programs to air in their entirety (this is particularly prevalent on Sunday evenings during the NFL season, on weeks when CBS is scheduled to broadcast a late afternoon game). In addition to rights to sports events from the NFL, PGA and NCAA among other major sports organizations, CBS broadcasts the "CBS Sports Spectacular", a sports anthology series which fills certain weekend afternoon time slots prior to – or in some cases, in lieu of – a major sporting event.
Daytime.
CBS's daytime schedule (the longest among the major networks, in terms of total time, at 4½ hours) is the home of the long-running game show "The Price Is Right", which began production in 1972 and is the longest continuously running daytime game show on network television. After being hosted by Bob Barker for 35 years, the show has been hosted since 2007 by actor/comedian Drew Carey. The network is also home to the current incarnation of "Let's Make a Deal", hosted by singer/comedian Wayne Brady, which originated in 1964 on NBC and was revived by CBS in 2009 (after a 19-year absence as a regular series). s of 2015[ [update]], CBS is the only commercial broadcast network that continues to broadcast daytime game shows. Notable game shows that once aired as part of the network's daytime lineup include "Match Game", "Tattletales", "The $10/25,000 Pyramid", "Press Your Luck", "Card Sharks", "Family Feud" and "Wheel of Fortune". Past game shows that have had both daytime and prime time runs on the network include "Beat the Clock", "To Tell the Truth" and "Password". Two long-running prime time-only games were the panel shows "What's My Line?" and "I've Got a Secret".
The network is also home to "The Talk", a panel talk show similar in format to ABC's "The View", which debuted in October 2010 (as of 2012[ [update]], the program is hosted by moderator Julie Chen, series creator/executive producer Sara Gilbert, Sharon Osbourne, Aisha Tyler and Sheryl Underwood).
s of 2013[ [update]], CBS Daytime airs two daytime soap operas each weekday: the hour-long series "The Young and the Restless" and half-hour series "The Bold and the Beautiful". CBS has aired the most soap operas out of the Big Three networks, carrying 3½ hours of soaps on its daytime lineup from 1982 to 2009. After "Guiding Light" ended in September 2009, ABC overtook CBS as the network with the most daily hours dedicated to soap operas; however CBS reclaimed this distinction in January 2012, following the conclusion of two of ABC's three remaining soap operas, "All My Children" and "One Life to Live", which were cancelled the year before. Other than "Guiding Light", notable daytime soap operas that once aired on CBS include "As the World Turns", "Love of Life", "Search for Tomorrow", "The Secret Storm", "The Edge of Night" and "Capitol".
Children's programming.
CBS broadcast the live-action series "Captain Kangaroo" on weekday mornings from 1955 to 1982, and on Saturdays through 1984. From 1971 to 1986, CBS News produced a series of one-minute segments titled "In the News", which aired between other Saturday morning programs. Otherwise, in regards to children's programming, CBS has aired mostly animated series for children, such as reruns of "Mighty Mouse", "Bugs Bunny" and "Tom and Jerry" cartoons, as well as the original version of "Scooby-Doo", "Fat Albert and the Cosby Kids", "Jim Henson's Muppet Babies", "Garfield and Friends", and "Teenage Mutant Ninja Turtles". In 1997, CBS premiered "Wheel 2000" (a children's version of the syndicated game show "Wheel of Fortune"), which aired simultaneously on the Game Show Network.
In September 1998, CBS began contracting the time period out to other companies to provide programming and material for its Saturday morning schedule. The first of these outsourced blocks was the "CBS Kidshow", which ran until 2000 and featured programming from Canadian studio Nelvana (such as "Anatole", "Mythic Warriors", "Rescue Heroes" and "Flying Rhino Junior High").
After its agreement with Nelvana ended, the network then entered into a deal with Nickelodeon (which by the time of the deal was a corporate sister to CBS, through the latter's then parent company Viacom, as a result of its 2000 merger with CBS Corporation) to air programming from its Nick Jr. block beginning in September 2000, under the banner "Nick Jr. on CBS". From 2002 to 2005, live-action and animated Nickelodeon series aimed at older children also aired as part of the block, under the sub-brand "Nick on CBS".
Following the Viacom-CBS split that resulted in the network deciding to discontinue the Nickelodeon content deal, in March 2006, CBS entered into a three-year agreement with DIC Entertainment (which was acquired later that year by the Cookie Jar Group, which assumed the rights to the deal) to program the Saturday morning time slot, as part of a deal which included distribution of select tape delayed Formula One auto races. The "KOL Secret Slumber Party on CBS" replaced "Nick Jr. on CBS" that September, with the inaugural lineup featuring two new first-run live-action programs, one animated series that originally aired in syndication in 2005 and three shows produced prior to 2006. In mid-2007, KOL (the children's service of AOL) withdrew sponsorship from CBS's Saturday morning block, which was subsequently renamed "KEWLopolis". Complimenting CBS's 2007 lineup was "Care Bears", "Strawberry Shortcake" and "Sushi Pack". On February 24, 2009, it was announced that CBS renewed its contract with Cookie Jar for another three seasons, running through 2012. On September 19, 2009, "KEWLopolis" was renamed "Cookie Jar TV".
On July 24, 2013, CBS entered into an agreement with Litton Entertainment (which already programmed a syndicated Saturday morning block exclusive to ABC stations and would later produce a block for CBS sister network The CW that debuted the following year) to launch a new Saturday morning block featuring live-action reality-based lifestyle, wildlife and sports series. The Litton-produced "CBS Dream Team" block, which is aimed at teenagers 13 to 16 years old, debuted on September 28, 2013, replacing "Cookie Jar TV".
Specials.
Animated primetime holiday specials.
CBS was the original broadcast network home of the animated primetime holiday specials based on the "Peanuts" comic strip, beginning with "A Charlie Brown Christmas" in 1965. Over 30 holiday Peanuts specials (each for a specific holiday such as Halloween) were broadcast on CBS from that time until 2000, when the broadcast rights were acquired by ABC. CBS also aired several primetime animated specials based on the works of Dr. Seuss (Theodor Geisel), beginning with "How the Grinch Stole Christmas" in 1966, as well as several specials based on the "Garfield" comic strip during the 1980s (which led to Garfield getting his own Saturday morning cartoon on the network, "Garfield and Friends", which ran from 1988 to 1995). "Rudolph the Red-Nosed Reindeer", produced in stop motion by the Rankin/Bass studio, has been another annual holiday staple of CBS since 1972; however, that special originated on NBC in 1964. As of 2011, "Rudolph" and "Frosty the Snowman" are the only two pre-1990 animated specials remaining on CBS; the broadcast rights to the "Charlie Brown" specials and "The Grinch" are now held by ABC, while that network's cable sister ABC Family owns the rights to the "Garfield" specials.
All of these animated specials, from 1973 to 1990, began with a fondly remembered seven-second animated opening sequence, in which the words "A CBS Special Presentation" were displayed in colorful lettering (the ITC Avant Garde typeface, widely used in the 1970s, was used for the title logo). The word "SPECIAL", in all caps and repeated multiple times in multiple colors, slowly zoomed out from the frame in a spinning counterclockwise motion against a black background, and rapidly zoomed back into frame as a single word, in white, at the end; the sequence was accompanied by a jazzy though majestic up-tempo fanfare with dramatic horns and percussion (which was edited incidental music from the CBS crime drama "Hawaii Five-O", titled "Call to Danger" on the Capitol Records soundtrack LP). This opening sequence appeared immediately before all CBS specials of the period (such as the Miss USA pageants and the annual presentation of the Kennedy Center Honors), in addition to animated specials (this opening was presumably designed by, or under the supervision of, longtime CBS creative director Lou Dorfsman, who oversaw print and on-air graphics for CBS for nearly 30 years, replacing William Golden, who died in 1959).
Classical music specials.
CBS was also responsible for airing the series of "Young People's Concerts" conducted by Leonard Bernstein. Telecast every few months between 1958 and 1972, first in black-and-white and then broadcast in color beginning in 1966, these programs introduced millions of children to classical music through the eloquent commentaries by Maestro Bernstein. The specials were nominated for several Emmy Awards, and were among the first programs ever broadcast from Lincoln Center for the Performing Arts.
Over the years, CBS has broadcast three different productions of Tchaikovsky's famous ballet "The Nutcracker" – two live telecasts of the George Balanchine New York City Ballet production in 1957 and 1958 respectively, a little-known German-American filmed production in 1965 (which was subsequently repeated three times and starred Edward Villella, Patricia McBride and Melissa Hayden), and beginning in 1977, the Mikhail Baryshnikov staging of the ballet, starring the Russian dancer along with Gelsey Kirkland – a version that would become a television classic, and remains so today (the broadcast of this production later moved to PBS).
In April 1986, CBS presented a slightly abbreviated version of "Horowitz in Moscow", a live piano recital by legendary pianist Vladimir Horowitz, which marked Horowitz's return to Russia after more than 60 years. The recital was televised as an episode of "CBS News Sunday Morning" (televised at 9:00 a.m. Eastern Time in the U.S., as the recital was performed simultaneously at 4:00 p.m. in Russia). It was so successful that CBS repeated it a mere two months later by popular demand, this time on videotape, rather than live. In later years, the program was shown as a standalone special on PBS; the current DVD of the telecast omits the commentary by Charles Kuralt, but includes additional selections not heard on the CBS telecast.
In 1986, CBS telecast "Carnegie Hall: The Grand Reopening" in primetime, in what was now a rare move for a commercial broadcast network, since most primetime classical music specials were relegated to PBS and A&E by this time. The program was a concert commemorating the re-opening of Carnegie Hall after its complete renovation. It featured, along with luminaries such as Leonard Bernstein, popular music artists such as Frank Sinatra.
Cinderella.
In order to compete with NBC, which produced the now-legendary televised version of the Mary Martin Broadway production of "Peter Pan", CBS responded with a musical production of "Cinderella", with music composed by Richard Rodgers and a book and lyrics by Oscar Hammerstein II. Based upon the classic French fairy tale of the same title, it is the only Rodgers and Hammerstein musical ever to have been written for television. It was originally broadcast live in color on CBS on March 31, 1957 as a vehicle for Julie Andrews, who played the title role; that broadcast was seen by over 100 million people. It was subsequently remade by CBS in 1965, with Lesley Ann Warren, Stuart Damon, Ginger Rogers and Walter Pidgeon among its stars; the remake also included a new song, "Loneliness of Evening", which was originally composed in 1949 for "South Pacific", but was not performed in that musical. This version was rebroadcast several times on CBS into the early 1970s, and is occasionally broadcast on various cable networks to this day; both versions are available on DVD.
National Geographic.
CBS was also the original broadcast home for the primetime specials produced by the National Geographic Society. The Geographic series in the U.S. started on CBS in 1964, before moving to ABC in 1973 (the specials subsequently moved to PBS – under the production of Pittsburgh member station WQED – in 1975 and TBS in 1995, before returning to PBS in 2000). The specials have featured stories on many scientific figures such as Louis Leakey, Jacques Cousteau and Jane Goodall, that not only featured their work but helped make them internationally known and accessible to millions. A majority of the specials were narrated by various actors, notably Alexander Scourby during the CBS run. The success of the specials led in part to the creation of the National Geographic Channel, a cable channel launched in January 2001 as a joint venture between the National Geographic Society and Fox Cable Networks. The specials' distinctive theme music, by Elmer Bernstein, was also adopted by the National Geographic Channel.
Other notable specials.
From 1949 to 2002, the Pillsbury Bake-Off, an annual national cooking contest, was broadcast on CBS as a special. Hosts for the broadcast included Arthur Godfrey, Art Linkletter, Bob Barker, Gary Collins and Alex Trebek.
The Miss USA beauty pageant aired on CBS from 1963 to 2002; during a large portion of that period, the telecast was often emceed by the host of one of the network's game shows. John Charles Daly hosted the show from 1963 to 1966, succeeded by Bob Barker from 1967 to 1987 (at which point Barker, an animal rights activist who eventually convinced producers of "The Price Is Right" to cease offering fur coats as prizes on the program, quit in a dispute over their use), Alan Thicke in 1988, Dick Clark from 1989 to 1993, and Bob Goen from 1994 to 1996. The pageant's highest viewership was recorded in the early 1980s, when it regularly topped the Nielsen ratings on the week of its broadcast. Viewership dropped sharply throughout the 1990s and 2000s, from an estimated viewership of 20 million to an average of 7 million from 2000 to 2001. In 2002, Donald Trump (owner of the Miss USA pageant's governing body, the Miss Universe Organization) brokered a new deal with NBC, giving it half-ownership of the Miss USA, Miss Universe and Miss Teen USA pageants and moving them to that network as part of an initial five-year contract, which began in 2003.
On June 1, 1977, it was announced that Elvis Presley had signed a deal with CBS to appear in a new television special. Under the agreement, CBS would videotape Presley's concerts during the summer of 1977; the special was filmed during Presley's final tour at stops in Omaha, Nebraska (on June 19) and Rapid City, South Dakota (on June 21 of that year). CBS aired the special, "Elvis in Concert", on October 3, 1977, nearly two months after Death of Elvis Presley#Final year and deathPresley'sdeath in his Graceland mansion on August 16.
Stations.
s of March 2015[ [update]], CBS has 16 owned-and-operated stations, and current and pending affiliation agreements with 222 additional television stations encompassing 49 states, the District of Columbia, two U.S. possessions, Bermuda and St. Vincent and the Grenadines. The network has a national reach of 96.37% of all households in the United States (or 301,123,135 Americans with at least one television set). Currently, New Jersey, New Hampshire and Delaware are the only U.S. states where CBS does not have a locally licensed affiliate (New Jersey is served by New York City O&O WCBS-TV and Philadelphia O&O KYW-TV; Delaware is served by KYW and Salisbury, Maryland affiliate WBOC-TV; and New Hampshire is served by Boston O&O WBZ-TV and Burlington, Vermont affiliate WCAX-TV).
As a newer broadcast network, CBS maintains affiliations with low-power stations (broadcasting either in analog or digital) in a few markets, such as Harrisonburg, Virginia (WSVF-CD), Palm Springs, California (KPSP-CD) and Parkersburg, West Virginia (WIYE-LD). In some markets, including both of those mentioned, these stations also maintain digital simulcasts on a subchannel of a co-owned/co-managed full-power television station. CBS also maintains a sizeable number of subchannel-only affiliations, the majority of which are with stations in cities located outside of the 50 largest Nielsen-designated markets; the largest CBS subchannel affiliate by market size is KOGG in Wailuku, Hawaii, which serves as a repeater of Honolulu affiliate KGMB (the sister station of KOGG parent KHNL).
Media General is the largest operator of CBS stations by numerical total, owning 26 CBS affiliates; the Gannett Company is the largest operator of CBS stations in terms of overall market reach, owning 11 CBS-affiliated stations (including affiliates in the larger markets in Houston, Tampa and Washington, D.C.).
Brand identity.
Logos.
The CBS television network's initial logo, used from the 1940s to 1951, consisted of an oval spotlight which shone on the block letters "C-B-S". The present-day Eye device was conceived by William Golden, based on a Pennsylvania Dutch hex sign as well as a Shaker drawing (while commonly attributed to Golden, there is speculation that at least some design work on the symbol may have been done by another CBS staff designer, Georg Olden, one of the first African-Americans to attract some attention in the postwar graphic design field). The Eye device made its broadcast debut on October 20, 1951. The following season, as Golden prepared a new "ident", CBS President Frank Stanton insisted on keeping the Eye device and using it as much as possible (Golden died unexpectedly in 1959, and was replaced by one of his top assistants, Lou Dorfsman, who would go on to oversee all print and on-air graphics for CBS for the next 30 years).
The CBS eye has since become an American icon. While the symbol's settings have changed, the Eye device itself has not been redesigned in its entire history. As part of a new graphical identity created by Trollbäck + Company that was introduced by the television network in 2006, the eye was placed in a "trademark" position on show titles, days of the week and descriptive words, an approach highly respecting the value of the design. The logo is alternately known as the "Eyemark", which was also the name of CBS's domestic and international syndication divisions in the mid-to-late 1990s before the King World acquisition and Viacom merger.
The eye logo has frequently been copied or borrowed by television networks around the world. Notable examples include the Austrian Broadcasting System (ORF), which formerly used a red version of the eye logo; Associated TeleVision in the United Kingdom; Frecuencia Latina in Peru; Nippon Television in Japan; Rede Bandeirantes and Rede Globo in Brazil; and Saeta TV Channel 10 in Uruguay.
The network celebrated the 60th anniversary of the introduction of the Eye logo in October 2011, featuring special IDs shown during the network's prime time lineup of logo versions from previous CBS image campaigns.
Image campaigns.
1980s.
Through the years, CBS has developed several notable image campaigns, and several of the network's most well-known slogans were introduced in the 1980s. The "Reach for the Stars" campaign used during the 1981–82 season feature a space theme used to capitalize on both CBS's stellar improvement in the ratings and the historic launch of the space shuttle Columbia. 1982's "Great Moments" juxtaposed scenes from classic CBS programs such as "I Love Lucy" with scenes from the network's then-current classics such as "Dallas" and "M*A*S*H". From 1983 to 1986, CBS (by now firmly atop the ratings) featured a campaign based on the slogan "We've Got the Touch". Vocals for the campaign's jingle were contributed by Richie Havens (1983–84; one occasion in 1984–85) and Kenny Rogers (1985–86).
The 1986–87 season ushered in the "Share the Spirit of CBS" campaign, the network's first to completely use computer graphics and DVE effects. Unlike most network campaign promos, the full-length version of "Share the Spirit" not only showed a brief clip preview of each new fall series, but also utilized CGI effects to map out the entire fall schedule by night. The success of that campaign led to the 1987–88 "CBS Spirit" (or "CBSPIRIT") campaign. Like with its predecessor campaign, most "CBSpirit" promos utilized a procession of clips from the network's programs. However, the new graphic motif was a swirling (or "swishing") blue line, that was used to represent "the spirit." The full length promo, like the previous year, had a special portion that identified new fall shows, but the mapped-out fall schedule shot was abandoned.
For the 1988–89 season, CBS unveiled a new image campaign, officially known as "Television You Can Feel", but more commonly identified as "You Can Feel It On CBS". The goal was to convey a more sensual, new-age image through distinguished, advanced-looking computer graphics and soothing music, backgrounding images and clips of emotionally powerful scenes and characters. However, it was this season in which CBS began its ratings freefall, the deepest in the network's history. CBS ended the decade with "Get Ready for CBS," introduced with the 1989–90 season. The initial version was a very ambitious campaign that attempted to elevate CBS out of last place (among the major networks); the motif centered around network stars interacting with each other in a remote studio set, getting ready for photo and television shoots, as well as for the new season on CBS. The high-energy promo song and the campaign's practices saw many customized variations by all of CBS' owned-and-operated stations and affiliates, which participated in the campaign per a network mandate. In addition, for the first time in history, CBS became the first broadcast network to partner with a national retailer (in this case, Kmart) to encourage viewership, with the "CBS/Kmart Get Ready Giveaway".
1990s.
For the 1990–91 season, the campaign featured a new jingle performed by The Temptations, which offered an altered version of their hit "Get Ready". The early 1990s featured less-than-memorable campaigns, with simplified taglines such as "This is CBS" (1992) and "You're On CBS" (1995). Eventually, the promotions department gained momentum again late in the decade with "Welcome Home to a CBS Night" (1996–1997), simplified to "Welcome Home" (1997–1999) and succeeded by the spin-off campaign "The Address is CBS" (1999–2000). During the "Welcome Home" campaign, a three-note sound mark was introduced, which was used in network's IDs and production company vanity cards following the closing credits of most of its programs.
2000s.
Throughout the first decade of the 21st century, CBS's ratings resurgence was backed by the network's "It's All Here" campaign (which introduced the current audio signature used during certain promotions and production company vanity cards during the closing credits of programs); in 2005, the network's strategy led to the proclamation that it was "America's Most Watched Network". The network's 2006 campaign introduced the slogan "We Are CBS", with Don LaFontaine providing the voiceover for the IDs (as well as certain network promos) during this period. In 2009, the network introduced a campaign entitled "Only CBS," in which network promotions proclaim several unique qualities it has (the slogan was also used in program promotions following the announcement of the timeslot of a particular program). The "America's Most Watched Network" was re-introduced by CBS in 2011, used alongside the "Only CBS" slogan.
Promos.
Especially during the 1960s, CBS as well as its two major network competitors, NBC, and ABC, utilized elaborate promos during the summer months to promote their upcoming fall schedules. In 1961, CBS took the unusual step of airing a program titled "CBS Fall Preview Special: Seven Wonderful Nights", using stars of several CBS shows – such as Ed Sullivan ("The Ed Sullivan Show"), Rod Serling ("The Twilight Zone"), and Raymond Burr and Barbara Hale ("Perry Mason") – to promote the upcoming fall lineup, instead the network's continuity announcers, showing previews of the entire lineup for one specific day of the week. Fall preview specials hosted by network stars would become commonplace among the broadcast networks in subsequent years.
International broadcasts.
CBS programs are shown outside the United States, through various branded international networks and content agreements, and in two North American countries, through U.S.-based CBS stations.
Canada.
In Canada, CBS network programming is carried on cable, satellite and IPTV providers in Canada through affiliates and owned-and-operated stations of the network that are located within proximity to the Canada–United States border (such as KIRO-TV/Seattle, KDLH/Duluth, Minnesota, WWJ-TV/Detroit and WIVB-TV/Buffalo, New York), some of which may also be receivable over-the-air in parts of southern Canada depending on the signal coverage of the station. Most programming is generally the same as it airs in the United States, however some CBS programming on U.S.-based affiliates permitted for carriage by the Canadian Radio-television and Telecommunications Commission by Canadian cable and satellite providers are subject to simultaneous substitutions, a practice in which a pay television provider supplants an American station's signal with a feed from a Canadian station/network airing a particular program in the same time slot to protect domestic advertising revenue.
Mexico.
CBS programming is available in Mexico through affiliates in markets located within proximity to the Mexico–United States border (such as KSWT/Yuma, Arizona; KVTV/Laredo, Texas; KDBC-TV/El Paso, Texas; KGBT-TV/Harlingen, Texas; and KFMB-TV/San Diego), whose signals are readily receivable over-the-air in border areas of northern Mexico.
Guam.
In the U.S. territory of Guam, the network is affiliated with low-power station KUAM-LP in Hagåtña. Entertainment and non-breaking news programming is shown day and date on a one-day tape delay, as Guam is located on the west side of the International Date Line (for example, "NCIS", which airs on Tuesday nights, is carried Wednesdays on KUAM-LP, and is advertised by the station as airing on the latter night in on-air promotions), with live programming and breaking news coverage airing as scheduled, meaning live sports coverage often airs early in the morning.
Europe.
CBS News programs are broadcast for a few hours a day on Orbit News in Europe, Africa and the Middle East. Sky News broadcasts the "CBS Evening News" on its channels serving the United Kingdom, Ireland, Australia, New Zealand and Italy.
United Kingdom.
On September 14, 2009, the international arm of CBS, CBS Studios International, reached a joint venture deal with Chellomedia to launch six CBS-branded channels in the United Kingdom – which would respectively replace Zone Romantica, Zone Thriller, Zone Horror and Zone Reality, as well as timeshift services Zone Horror +1 and Zone Reality +1 – during the fourth quarter of that year. On October 1, 2009, it was announced that the first four channels, CBS Reality, CBS Reality +1, CBS Drama and CBS Action, would launch on November 16 – respectively replacing Zone Reality, Zone Reality +1, Zone Romantica and Zone Thriller. On April 5, 2010, Zone Horror and Zone Horror +1 were rebranded as Horror Channel and Horror Channel +1.
Australia.
In Australia, Network Ten (which CBS owns 33% of its shares) maintains a distribution agreement with CBS Television Distribution that gives the network rights to carry programs such as "Entertainment Tonight", "Dr. Phil", "Late Show with David Letterman", "NCIS" and "Scorpion". Nine Network maintains the rights to story content sourced from "60 Minutes", used on the domestic program of the same title, while reports provided by Network Ten are used in the United States by CBS for supplementary coverage of Australian topics. It also maintains a joint venture that allows ONE HD and Eleven to air CBS programs.
Asia.
Bermuda.
In Bermuda, CBS maintains an affiliation with Hamilton-based ZBM-TV, locally owned by Bermuda Broadcasting Company.
Hong Kong.
In Hong Kong, the "CBS Evening News" is broadcast live during the early morning hours; networks in that country maintains agreement to rebroadcast portions of the program 12 hours after the initial broadcast to provide additional content in the event that their affiliates have insufficient news content to fill time during their local news programs.
The Philippines.
In the Philippines, the "CBS Evening News" is broadcast on satellite network Q-TV (a sister channel of GMA Network), while "CBS This Morning" is shown in that country on the Lifestyle Network. The "Late Show with David Letterman" is broadcast by Studio 23 and Maxx, which are both owned by ABS-CBN.
India.
In India, CBS maintains a brand licensing agreement with Reliance Broadcast Network Ltd. for three CBS-branded channels: Big CBS Prime, Big CBS Spark and Big CBS Love.
Controversies.
Brown & Williamson interview.
In 1995, CBS refused to air a "60 Minutes" segment that featured an interview with a former president of research and development for Brown & Williamson, the U.S.'s third largest tobacco company. The controversy raised questions about the legal roles in decision-making and whether journalistic standards should be compromised despite legal pressures and threats. The decision nevertheless sent shockwaves throughout the television industry, the journalism community, and the country. This incident was the basis for the 1999 Michael Mann-directed drama film, "The Insider".
Bernard Goldberg.
In 2001, Bernard Goldberg, who served as a correspondent for CBS News for 28 years, authored "Bias: A CBS Insider Exposes How the Media Distort the News". The book heavily criticized the media, and some CBS anchors and correspondents in particular (such as Dan Rather). Goldberg accused CBS of having a liberal bias in most of their news coverage; Goldberg now works as a commentator for Fox News.
Super Bowl XXXVIII halftime show incident.
In 2004, the Federal Communications Commission imposed a record $550,000 fine, the largest fine ever for a violation of federal decency laws, against CBS for an incident during its broadcast of Super Bowl XXXVIII in which singer Janet Jackson's right breast (which was partially covered by a piece of nipple jewelry) was briefly and accidentally exposed by guest performer Justin Timberlake at the end of a duet performance of Timberlake's 2003 single "Rock Your Body" during the halftime show (produced by then sister cable network MTV). Following the incident, CBS apologized to its viewers and denied foreknowledge of the incident, which was televised live. The incident resulted in a period of increased regulation of broadcast television and radio outlets (including self-imposed content regulation by networks and syndicators), which raised concerns surrounding censorship and freedom of speech, and resulted in the FCC voting to increase its maximum fine for indecency violations from US$27,500 to US$325,000. In 2008, a Philadelphia federal court annulled the fine imposed on CBS, labelling it "arbitrary and capricious".
Killan documents controversy.
On September 8, 2004, less than two months before the Presidential election in which he defeated Democratic candidate John Kerry, CBS aired a controversial episode of "60 Minutes Wednesday", which questioned then-President George W. Bush's service in the Air National Guard in 1972 and 1973. Following allegations of forgery, CBS News admitted that four of the documents used in the story had not been properly authenticated and admitted that their source, Bill Burkett, had admitted to having "deliberately misled" a CBS News producer who worked on the report, about the documents' origins out of a confidentiality promise to the actual source. The following January, CBS fired four people connected to the preparation of the segment. Former CBS news anchor Dan Rather filed a $70 million lawsuit against CBS and former corporate parent Viacom in September 2007, contending the story, and his termination (he resigned as CBS News chief anchor in 2005), were mishandled. Parts of the suit were dismissed in 2008; subsequently in 2010, the entire suit was dismissed and Rather's motion to appeal was denied.
John Batiste firing.
In 2007, retired Army Major Gen. and CBS News consultant John Batiste appeared in a political ad for VoteVets.org that was critical of President George W. Bush and the war in Iraq. Two days later, CBS stated that appearing in the ad violated Batiste's contract with the network, which was terminated as a result.
Hopper controversy.
In January 2013, CNET named Dish Network's "Hopper with Sling" digital video recorder as a nominee for the CES "Best in Show" award (which is decided by CNET on behalf of its organizers, the Consumer Electronics Association), and named it the winner in a vote by the site's staff. However, CBS division CBS Interactive disqualified the Hopper, and vetoed the results as CBS was in active litigation with Dish Network over its AutoHop technology (which allows users to skip commercial advertisements during recorded programs). CNET announced that it would no longer review any product or service provided by companies that CBS Corporation was in litigation with. The "Best in Show" award was instead given to the Razer Edge tablet. On January 14, 2013, CNET editor-in-chief Lindsey Turrentine said in a statement that its staff was in an "impossible" situation due to the conflict of interest posed by the lawsuit, and promised to prevent a similar incident from occurring again. The conflict also prompted the resignation of CNET senior writer Greg Sandoval. As a result of the controversy, the CEA announced on January 31, 2013 that CNET will no longer decide the CES Best in Show award winner due to the interference of CBS (with the position being offered to other technology publications), and the "Best in Show" award was jointly awarded to both the Hopper with Sling and Razer Edge.
Presidents of CBS Entertainment.
 "This film, television or video-related list is ; you can help by [ expanding it] with additions".

</doc>
<doc id="37654" url="http://en.wikipedia.org/wiki?curid=37654" title="Owl">
Owl

Owls are birds from the order Strigiformes, which includes about 200 species of mostly solitary and nocturnal birds of prey typified by an upright stance, a large, broad head, binocular vision, binaural hearing and feathers adapted for silent flight. Exceptions include the diurnal northern hawk-owl and the gregarious burrowing owl.
Owls hunt mostly small mammals, insects, and other birds although a few species specialize in hunting fish. They are found in all regions of the Earth except Antarctica and some remote islands.
Owls are divided into two families: the true owls, Strigidae; and the barn-owls, Tytonidae.
Anatomy.
Owls have large forward-facing eyes and ear-holes; a hawk-like beak; a flat face; and usually a conspicuous circle of feathers, a "facial disc", around each eye. The feathers making up this disc can be adjusted in order to sharply focus sounds that come from varying distances onto the owls' asymmetrically placed ear cavities. Most birds of prey have eyes on the sides of their heads, but the stereoscopic nature of the owl's forward-facing eyes permits the greater sense of depth perception necessary for low-light hunting. Although owls have binocular vision, their large eyes are fixed in their sockets—as are those of other birds—so they must turn their entire head to change views. As owls are farsighted, they are unable to see clearly anything within a few centimeters of their eyes. Caught prey can be felt by owls with the use of filoplumes—like feathers on the beak and feet that act as "feelers". Their far vision, particularly in low light, is exceptionally good.
Owls can rotate their heads and necks as much as 270 degrees. Owls have fourteen neck vertebrae as compared to 7 in humans which makes their necks more flexible. They also have adaptations to their circulatory systems, permitting rotation without cutting off blood to the brain: the foramina in their vertebrae through which the vertebral arteries pass are about 10 times the diameter of the artery, instead of about the same size as the artery as in humans; the vertebral arteries enter the cervical vertebrae higher than in other birds, giving the vessels some slack; and the carotid arteries unite in a very large anastomosis or junction, the largest of any bird's, preventing blood supply from being cut off while the neck is rotated. Other anastomoses between the carotid and vertebral arteries support this effect.
The smallest owl—weighing as little as 31 g and measuring some 13.5 cm—is the elf owl ("Micrathene whitneyi"). Around the same diminutive length, although slightly heavier, are the lesser known long-whiskered owlet ("Xenoglaux loweryi") and Tamaulipas pygmy owl ("Glaucidium sanchezi"). The largest owl by length is the great grey owl ("Strix nebulosa"), which measures around 70 cm on average and can attain a length of 84 cm. However, the heaviest (and largest winged) owls are two similarly-sized eagle owls; the Eurasian eagle-owl ("Bubo bubo") and Blakiston's fish owl ("B. blakistoni"). These two species, which are on average about 2.53 cm shorter in length than the great grey, can both attain a wingspan of 2 m (6.6 ft) and a weight of 4.5 kg (10 lb) in the largest females.
Different species of owls make different sounds; this wide range of calls aids owls in finding mates or announcing their presence to potential competitors, and also aids ornithologists and birders in locating these birds and recognizing species. As noted above, the facial disc helps owls to funnel the sound of prey to their ears. In many species, these discs are placed asymmetrically, for better directional location.
The plumage of owls is generally cryptic, but many species have facial and head markings, including face masks, ear tufts and brightly coloured irises. These markings are generally more common in species inhabiting open habitats, and are thought to be used in signaling with other owls in low light conditions.
Breeding and reproduction.
Owl eggs usually have a white color and an almost spherical shape, and range in number from a few to a dozen, depending on species and the particular season; for most, three or four is the more common number. Eggs are laid at intervals of 1 to 3 days and do not hatch at the same time.
Behavior.
Most owls are nocturnal, actively hunting their prey only in darkness. Several types of owl, however, are crepuscular—active during the twilight hours of dawn and dusk; one example is the pygmy owl ("Glaucidium"). A few owls are active during the day also; examples are the burrowing owl ("Speotyto cunicularia)" and the short-eared owl ("Asio flammeus").
Much of the owls' hunting strategy depends on stealth and surprise. Owls have at least two adaptations that aid them in achieving stealth. First, the dull coloration of their feathers can render them almost invisible under certain conditions. Secondly, serrated edges on the leading edge of owls' remiges muffle an owl's wing beats, allowing an owl's flight to be practically silent. Some fish-eating owls, for which silence has no evolutionary advantage, lack this adaptation.
An owl's sharp beak and powerful talons allow it to kill its prey before swallowing it whole (if it is not too big). Scientists studying the diets of owls are helped by their habit of regurgitating the indigestible parts of their prey (such as bones, scales, and fur) in the form of pellets. These "owl pellets" are plentiful and easy to interpret, and are often sold by companies to schools for dissection by students as a lesson in biology and ecology.
Adaptations for hunting.
All owls are carnivorous birds of prey and live mainly on a diet of insects and small rodents such as mice, rats and hares. Some owls are also specifically adapted to hunt fish. They are very adept in hunting in their respective environments. Since owls can be found in nearly all parts of the world and across a multitude of ecosystems, their hunting skills and characteristics vary slightly from species to species, though most characteristics are shared among all species.
Flight and feathers.
Most owls share an innate ability to fly almost silently and also more slowly in comparison to other birds of prey. Most owls live a mainly nocturnal lifestyle and being able to fly without making any noise gives them a strong advantage over their prey that are listening for the slightest sound in the night. A silent, slow flight is not as necessary for diurnal and crepuscular owls given that prey can usually see an owl approaching. While the morphological and biological mechanisms of this silent flight are more or less unknown, the structure of the feather has been heavily studied and accredited to a large portion of why they have this ability. Owls’ feathers are generally larger than the average birds’ feathers, have fewer radiates, longer pennulum, and achieve smooth edges with different rachis structures. Serrated edges along the owl’s remiges bring the flapping of the wing down to a nearly silent mechanism. Research has shown that the serrations are more likely reducing aerodynamic disturbances, rather than simply reducing noise. The surface of the flight feathers is covered with a velvety structure that absorbs the sound of the wing moving. These unique structures reduce noise frequencies above 2 kHz, making the sound level emitted drop below the typical hearing spectrum of the owl’s usual prey and also within the owl’s own best hearing range . This optimizes the owl’s ability to silently fly in order to capture prey without the prey hearing the owl first as it flies in. It also allows the owl to monitor the sound output from its flight pattern.
Vision.
Another characteristic of the owl which aids in their nocturnal prey capture is their eyesight. Owls are part of a small group of birds that live nocturnally, but do not use echolocation to guide them in flight in low-light situations. Owls are known for their disproportionally large eyes in comparison to their skull. An apparent consequence of the evolution of an absolutely large eye in a relatively small skull is that the eye of the owl has become tubular in shape. This shape is found in other so-called nocturnal eyes, such as the eyes of strepsirrhine primates and bathypelagic fishes. Since the eyes are fixed into these sclerotic tubes, they are unable to move the eyes in any direction. Instead of moving their eyes, owls swivel their head to visualize their surroundings. Owls' heads are capable of swiveling through an angle of approximately 270°, easily enabling them to see behind them without relocating the torso. This ability keeps bodily movement at a minimum and thus reduces the amount of sound the owl makes as it waits for its prey. Owls are regarded as having the most frontally placed eyes among all avian groups, which gives them some of the largest binocular fields of vision. However, owls are farsighted and cannot focus on objects within a few centimeters of their eyes. While it is commonly believed that owls have great nocturnal vision due to their large (and thus very light-gathering) eyes and pupils and/or extremely sensitive rod receptors, the true cause for their ability to see in the night is due to neural mechanisms which mediate the extraction of spatial information gathered from the retinal image throughout the nocturnal luminance range. These mechanisms are only able to function due to the large-sized retinal image. Thus, the primary nocturnal function in the vision of the owl is due to its large posterior nodal distance; retinal image brightness is only maximized to the owl within secondary neural functions. These attributes of the owl cause its nocturnal eyesight to be far superior to that of its average prey.
Hearing.
Owls exhibit specialized hearing functions and ear shapes that also aid in hunting. They are noted for asymmetrical ear placements on the skull in some genera. Owls can have either internal or external ears, both of which are asymmetrical . Asymmetry has not been reported to extend to the middle or internal ear of the owl. Asymmetrical ear placement on the skull allows the owl to pinpoint the location of its prey. This is especially true for strictly nocturnal species such as the barn owls 'Tyto' or Tengmalm's owl. With ears set at different places on its skull, an owl is able to determine the direction from which the sound is coming by the minute difference in time that it takes for the sound waves to penetrate the left and right ears. The owl turns its head until the sound reaches both ears at the same time, at which point it is directly facing the source of the sound. This time difference between ears is a matter of about 0.00003 seconds, or 30 millionths of a second. Like the eyes, which utilize feather movements to focus light, the ears are surrounded by feathers to maximize hearing capabilities. Behind the ear openings there are modified, dense feathers, densely packed to form a facial ruff, which creates an anteriorly-facing concave wall that cups the sound into the ear structure. This facial ruff is poorly defined in some species and prominent, nearly encircling the face, in other species. The facial disk also acts to direct sound into the ears, and a downward-facing, sharply triangular beak minimizes sound reflection away from the face. The shape of the facial disk is adjustable at will to focus sounds more effectively.
Talons.
While the auditory and visual capabilities of the owl allow it to locate and pursue its prey, the talons and beak of the owl do the final work. The owl kills its prey by using these talons to crush the skull and knead the body. The crushing power of an owl’s talons varies according to prey size and type, and by the size of the owl. The burrowing owl ("Athene cunicularia"), a small partly insectivorous owl, has a release force of only 5 N. The larger barn owl ("Tyto alba") needs a force of 30 N to release its prey, and one of the largest owls, the great horned owl ("Bubo virginianus") needs a force of over 130 N to release prey in its talons. An owl’s talons, like those of most birds of prey, can seem massive in comparison to the body size outside of flight. The masked owl has some of the proportionally longest talons of any bird of prey; they appear enormous in comparison to the body when fully extended to grasp prey. An owl’s claws are sharp and curved. The family Tytonidae have inner and central toes of about equal length, while the family Strigidae have an inner toe that is distinctly shorter than the central one. These different morphologies allow efficiency in capturing prey specific to the different environments they inhabit.
Beak.
The beak of the owl is short, curved and downward-facing, and typically hooked at the tip for gripping and tearing its prey. Once prey is captured, the scissor motion of the top and lower bill is used to tear the tissue and kill. The sharp lower edge of the upper bill works in coordination with the sharp upper edge of the lower bill to deliver this motion. The downward-facing beak allows the owl’s field of vision to be clear, as well as directing sound into the ears without deflecting sound waves away from the face.
Camouflage.
The coloration of the owl’s plumage plays a key role in its ability to sit still and blend into the environment, making it nearly invisible to prey. Owls tend to mimic the colorations and sometimes even the texture patterns of their surroundings, the common barn owl being an exception. "Nyctea scandiaca", or the snowy owl, appears nearly bleach-white in color with a few flecks of black, mimicking their snowy surroundings perfectly. Likewise, the mottled wood-owl ("Strix ocellata") displays shades of brown, tan and black, making the owl nearly invisible in the surrounding trees, especially from behind. Usually, the only tell-tale sign of a perched owl will be its vocalizations or its vividly colored eyes.
Evolution and systematics.
The systematic placement of owls is disputed. For example, the Sibley-Ahlquist taxonomy finds that, based on DNA-DNA hybridization, owls are more closely related to the nightjars and their allies (Caprimulgiformes) than to the diurnal predators in the order Falconiformes; consequently, the Caprimulgiformes are placed in the Strigiformes, and the owls in general become a family Strigidae. A recent study indicates that the drastic rearrangement of the genome of the accipitrids may have obscured any close relationship of theirs with groups such as the owls.
In any case, the relationships of the Caprimulgiformes, the owls, the falcons and the accipitrid raptors are not resolved to satisfaction; currently there is an increasing trend to consider each group (with the possible exception of the accipitrids) a distinct order.
There are some 220 to 225 extant species of owls, subdivided into two families: typical owls (Strigidae) and barn-owls (Tytonidae). Some entirely extinct families have also been erected based on fossil remains; these differ much from modern owls in being less specialized or specialized in a very different way (such as the terrestrial Sophiornithidae). The Paleocene genera "Berruornis" and "Ogygoptynx" show that owls were already present as a distinct lineage some 60–57 mya (million years ago), and, hence, possibly also some 5 million years earlier, at the extinction of the non-avian dinosaurs. This makes them one of the oldest known groups of non-Galloanserae landbirds. The supposed "Cretaceous owls" "Bradycneme" and "Heptasteornis" are apparently non-avialan maniraptors.
During the Paleogene, the Strigiformes radiated into ecological niches now mostly filled by other groups of birds. The owls as we know them today, on the other hand, evolved their characteristic morphology and adaptations during that time, too. By the early Neogene, the other lineages had been displaced by other bird orders, leaving only barn-owls and typical owls. The latter at that time were usually a fairly generic type of (probably earless) owl similar to today's North American spotted owl or the European tawny owl; the diversity in size and ecology found in typical owls today developed only subsequently.
Around the Paleogene-Neogene boundary (some 25 mya), barn-owls were the dominant group of owls in southern Europe and adjacent Asia at least; the distribution of fossil and present-day owl lineages indicates that their decline is contemporary with the evolution of the different major lineages of typical owls, which for the most part seems to have taken place in Eurasia. In the Americas, there was rather an expansion of immigrant lineages of ancestral typical owls.
The supposed fossil herons ""Ardea" perplexa" (Middle Miocene of Sansan, France) and ""Ardea" lignitum" (Late Pliocene of Germany) were more probably owls; the latter was apparently close to the modern genus "Bubo". Judging from this, the Late Miocene remains from France described as ""Ardea" aureliensis" should also be restudied. The Messelasturidae, some of which were initially believed to be basal Strigiformes, are now generally accepted to be diurnal birds of prey showing some convergent evolution towards owls. The taxa often united under "Strigogyps" were formerly placed in part with the owls, specifically the Sophiornithidae; they appear to be Ameghinornithidae instead.
For fossil species and paleosubspecies of extant taxa, see the genus and species articles.
Unresolved and basal forms (all fossil)
Tytonidae: barn-owls.
Fossil genera
Placement unresolved
Strigidae: typical owls.
Fossil genera
Placement unresolved
Symbolism and mythology.
Africa.
Among the Kikuyu of Kenya it was believed that owls were harbingers of death. If one saw an owl or heard its hoot, someone was going to die. In general, owls are viewed as harbingers of bad luck, ill health, or death. The belief is widespread even today.
The Americas.
In the culture of the Uto-Aztec tribe, the Hopi, taboos surround owls, which are associated with sorcery and other evils. The Aztecs and Maya, along with other natives of Mesoamerica, considered the owl a symbol of death and destruction. In fact, the Aztec god of death, Mictlantecuhtli, was often depicted with owls. There is an old saying in Mexico that is still in use: "Cuando el tecolote canta, el indio muere" ("When the owl cries/sings, the Indian dies"). The Popol Vuh, a Mayan religious text, describes owls as messengers of Xibalba (the Mayan "Place of Fright"). The belief that owls are messengers and harbingers of the dark powers is also found among the Hočągara (Winnebago) of Wisconsin. When in earlier days the Hočągara committed the sin of killing enemies while they were within the sanctuary of the chief's lodge, an owl appeared and spoke to them in the voice of a human, saying, "From now on the Hočągara will have no luck." This marked the beginning of the decline of their tribe. An owl appeared to Glory of the Morning, the only female chief of the Hočąk nation, and uttered her name. Soon afterwards she died. People often allude to the reputation of owls as bearers of supernatural danger when they tell misbehaving children, "the owls will get you." Also, in the Cherokee culture, as well as many other Native American cultures, owls are a very bad omen. It is said that if you are outside in the broad day light and an owl flies over your head a family member or loved one would die within the coming week.
Middle East.
In Arab mythology, owls are seen as bad omens.
Hinduism.
In Hinduism, an owl is the "vahana", mount, of the Goddess Lakshmi.
Western culture.
The modern West generally associates owls with wisdom. This link goes back at least as far as Ancient Greece, where Athens, noted for art and scholarship, and Athena, Athens' patron goddess and the goddess of wisdom, had the owl as a symbol. Marija Gimbutas traces veneration of the owl as a goddess, among other birds, to the culture of Old Europe, long pre-dating Indo-European cultures.
T. F. Thiselton-Dyer in his "Folk-lore of Shakespeare" says that "from the earliest period it has been considered a bird of ill-omen," and Pliny tells us how, on one occasion, even Rome itself underwent a lustration, because one of them strayed into the Capitol. He represents it also as a funereal bird, a monster of the night, the very abomination of human kind. Virgil describes its death-howl from the top of the temple by night, a circumstance introduced as a precursor of Dido's death. Ovid, too, constantly speaks of this bird's presence as an evil omen; and indeed the same notions respecting it may be found among the writings of most of the ancient poets." A list of "omens drear" in John Keats' "Hyperion" includes the "gloom-bird's hated screech." Pliny the Elder reports that owl's eggs were commonly used as a hangover cure.
In France, Belgium and the Netherlands, where owls are divided into eared owls (fr. "hiboux" / d. "oehoes") and earless owls (fr. "chouettes"/ d. "bosuilen"), the former are seen as symbols of wisdom while the latter are assigned the grimmer meaning.
Three Canadian provinces have owls as provincial symbols: the great horned owl in Alberta, the great grey owl in Manitoba, and the snowy owl in Quebec.
Three owls appear on the coat of arms of the English city of Leeds, as the crest and the two supporters. They are derived from the arms of the city's first alderman, Sir John Saville.
In contrast, in Finnish culture, the owl has been considered a stupid animal, probably due to its wide-open eyes. The word "pöllö" means both "owl" and "idiot", and "silmät pöllöllään" "eyes owl-y" means "disoriented, dazed".
Use as rodent control.
Encouraging natural predators to control rodent population is a natural form of pest control, along with excluding food sources for rodents. Placing a nest box for owls on a property can help control rodent populations (one family of hungry barn owls can consume more than 3,000 rodents in a nesting season) while maintaining the naturally balanced food chain.
Attacks on humans.
Although humans and owls frequently live together in harmony, there have been incidents when owls have attacked humans. In January 2013, a man from Inverness, Scotland went into shock and suffered heavy bleeding after being attacked by an owl, which was likely a two-foot tall eagle owl. The photographer Eric Hosking lost his left eye after attempting to photograph a tawny owl, which inspired the title of his 1970 autobiography, "An Eye for a Bird".
Conservation issues.
All owls are listed in Appendix II of the international CITES treaty (the Convention on Illegal Trade in Endangered Species of Wild Fauna and Flora). Although owls have long been hunted, a 2008 news story from Malaysia indicates that the magnitude of owl poaching may be on the rise. In November 2008, TRAFFIC reported the seizure of 900 plucked and "oven-ready" owls in Peninsular Malaysia. Said Chris Shepherd, Senior Programme Officer for TRAFFIC's Southeast Asia office, "This is the first time we know of where 'ready-prepared' owls have been seized in Malaysia, and it may mark the start of a new trend in wild meat from the region. We will be monitoring developments closely." TRAFFIC commended the Department of Wildlife and National Parks in Malaysia for the raid that exposed the huge haul of owls. Included in the seizure were dead and plucked barn owls, spotted wood owls, crested serpent eagles, barred eagles, and brown wood owls, as well as 7,000 live lizards.
External links.
 Media related to at Wikimedia Commons
Eurasia:
North America:
Oceania:

</doc>
<doc id="37656" url="http://en.wikipedia.org/wiki?curid=37656" title="Concurrent Versions System">
Concurrent Versions System

The Concurrent Versions System (CVS), also known as the Concurrent Versioning System, is a client-server free software revision control system in the field of software development. A version control system keeps track of all work and all changes in a set of files, and allows several developers (potentially widely separated in space and time) to collaborate. Dick Grune developed CVS as a series of shell scripts in July 1986.
In addition to commercial software developers, CVS became popular with the open source software world and was released under the GNU General Public License. While there was regular development to add features and fix bugs in the past, including regular builds and test results, there have been no new releases since 2008. The product is mature: new releases are not produced until there are requests for new features or bug reports.<ref name="Requests for fixes/features"></ref>
Features.
CVS uses a client–server architecture: a server stores the current version(s) of a project and its history, and clients connect to the server in order to "check out" a complete copy of the project, work on this copy and then later "check in" their changes. Typically, the client and server connect over a LAN or over the Internet, but client and server may both run on the same machine if CVS has the task of keeping track of the version history of a project with only local developers. The server software normally runs on Unix (although at least the CVSNT server also supports various flavours of Microsoft Windows), while CVS clients may run on any major operating-system platform.
Several developers may work on the same project concurrently, each one editing files within their own "working copy" of the project, and sending (or "checking in") their modifications to the server. To avoid the possibility of people stepping on each other's toes, the server only accepts changes made to the most recent version of a file. Developers are therefore expected to keep their working copy up-to-date by incorporating other people's changes on a regular basis. This task is mostly handled automatically by the CVS client, requiring manual intervention only when an edit conflict arises between a checked-in modification and the yet-unchecked local version of a file.
If the check in operation succeeds, then the version numbers of all files involved automatically increment, and the CVS-server writes a user-supplied description line, the date and the author's name to its log files. CVS can also run external, user-specified log processing scripts following each commit. These scripts are installed by an entry in CVS's loginfo file, which can trigger email notification or convert the log data into a Web-based format.
Clients can also compare versions, request a complete history of changes, or check out a historical snapshot of the project as of a given date or as of a revision number.
Anonymous CVS.
Many open-source projects allow "anonymous read access", a feature pioneered by OpenBSD. This means that clients may check out and compare versions with either a blank or simple published password (e.g., "anoncvs"); only the check-in of changes requires a personal account and password in these scenarios.
Clients can also use the "update" command to bring their local copies up-to-date with the newest version on the server. This eliminates the need for repeated downloading of the whole project.
CVS can also maintain different "branches" of a project. For instance, a released version of the software project may form one branch, used for bug fixes, while a version under current development, with major changes and new features, can form a separate branch.
CVS uses delta compression for efficient storage of different versions of the same file. This works well with large text files with few changes from one version to the next. This is usually the case for source code files. On the other hand, when CVS is told to store a file as binary, it will keep each individual version on the server. Storing files as binary is important in order to avoid corruption of binary files.
 In the world of open source software, the Concurrent Version System (CVS) has long been the tool of choice for version control. And rightly so. CVS itself is free software, and its non-restrictive "modus operandi" and support for networked operation – which allow dozens of geographically dispersed programmers to share their work – fits the collaborative nature of the open-source world very well. CVS and its semi-chaotic development model have become cornerstones of open-source.
 — Collins-Sussman, "Version Control with Subversion For Subversion 1.1, 2005"
Terminology.
CVS labels a single project (set of related files) that it manages as a "module". A CVS server stores the modules it manages in its "repository". Programmers acquire copies of modules by "checking out". The checked-out files serve as a "working copy", "sandbox" or "workspace". Changes to the working copy are reflected in the repository by "committing" them. To "update" is to acquire or "merge" the changes in the repository with the working copy.
History and status.
CVS developed from an earlier versioning-system called Revision Control System (RCS) (still[ [update]] in use) that manages individual files but not whole projects. Dick Grune provides some about CVS on his site. To quote:
 I created CVS to be able to cooperate with my students, Erik Baalbergen and Maarten Waage, on the ACK (Amsterdam Compiler Kit) C compiler. The three of us had vastly different schedules (one student was a steady 9-5 worker, the other was irregular, and I could work on the project only in the evenings). Their project ran from July 1984 to August 1985. CVS was initially called cmt, for the obvious reason that it allowed us to commit versions independently.
 — Dick Grune, ""
Grune publicly released the code to mod.sources on June 23, 1986: Google Groups continues to archive and serve the original .
The code that eventually evolved into the current version of CVS started with Brian Berliner in April 1989, with later input from Jeff Polk and many other contributors. Brian Berliner wrote introducing his improvements to the CVS program—which describes how the tool was extended and used internally by Prisma, a third-party developer working on the SunOS kernel, and was released for the benefit of the community under the GPL. On November 19, 1990, CVS version 1.0 was submitted to the Free Software Foundation for development and distribution.
CVS supports distributed, multi-site and offline operations due to the unreliability of the few computer networks that existed at the time CVS evolved.
Development status.
There have been no official recent announcements indicating the project status.
Development of the Microsoft Windows, Linux, Solaris, HPUX, I5os and Mac OS X port of CVS has split off into a separate project named CVSNT, which is under current, active development.
Relationship with GNU.
The relationship between CVS and the GNU project has long been somewhat ambiguous: the GNU web site distributed the program, labelling it "GNU package" on one page and "other GPL-licensed project" on another. In 2008, when development of CVS was transferred from the old website (cvshome.org) to the GNU Savannah hosting platform, it was placed in the "non-GNU" section. Further, on GNU's FTP download server, CVS is distributed in the "non-gnu" directory.
Successors.
Over time, developers have created new version control systems based on CVS in order to add features, alter the operational model, and improve developers' productivity. This has occurred frequently enough to lead to the phrase YACC: "Yet Another CVS Clone" (a play on the Unix command named codice_1, which stands for "yet another compiler compiler"). CVS replacement projects include CVSNT (first released 1998), Subversion (initially released in 2004), (first released 2008), and numerous systems that support distributed revision control.
Criticism.
Several characteristics of CVS have been frequently criticized.
 Defenders argue that many of these are the result of deliberate design decisions, some of which were made at a time when the software and hardware landscape were different than they are now. They also point to the existence of workarounds or approaches to the development process that can mitigate problems.
References.
</dl>

</doc>
<doc id="37657" url="http://en.wikipedia.org/wiki?curid=37657" title="CVS">
CVS

CVS may refer to:

</doc>
<doc id="37660" url="http://en.wikipedia.org/wiki?curid=37660" title="List of parasitic organisms">
List of parasitic organisms

"This is an incomplete list of organisms that are true parasites upon other organisms. For information on parasitoids, see main article: Parasitoid.
Endoparasites.
Parasitic worms.
These can be categorized into three groups; cestodes, nematodes and trematodes. Examples include:

</doc>
<doc id="37661" url="http://en.wikipedia.org/wiki?curid=37661" title="Alfred Kinsey">
Alfred Kinsey

Alfred Charles Kinsey (; June 23, 1894 – August 25, 1956) was an American biologist, professor of entomology and zoology, and sexologist who in 1947 founded the Institute for Sex Research at Indiana University, now known as the Kinsey Institute for Research in Sex, Gender, and Reproduction. He is best known for writing "Sexual Behavior in the Human Male" (1948) and "Sexual Behavior in the Human Female" (1953), also known as the Kinsey Reports, as well as the Kinsey scale. Kinsey's research on human sexuality, foundational to the field of sexology, provoked controversy in the 1940s and 1950s. His work has influenced social and cultural values in the United States, as well as internationally.
Early life and education.
Kinsey was born on June 23, 1894, in Hoboken, New Jersey, the son of Sarah Ann (née Charles) and Alfred Seguine Kinsey. Kinsey was the eldest of three children. His mother received little formal education; his father was a professor at Stevens Institute of Technology.
Kinsey's parents were poor for most of his childhood, often unable to afford proper medical care. This may have led to a young Kinsey receiving inadequate treatment for a variety of diseases including rickets, rheumatic fever, and typhoid fever. His health records indicate that Kinsey received suboptimal exposure to sunlight (often the cause of rickets, before milk and other foods were fortified with vitamin D) and lived in unsanitary conditions for at least part of his childhood. Rickets led to a curvature of the spine, which resulted in a slight stoop that prevented Kinsey from being drafted in 1917 for World War I.
Kinsey's parents were devout Christians. His father was known as one of the most devout members of the local Methodist church. Most of Kinsey's social interactions were with other members of the church, often as a silent observer, while his parents discussed religion. Kinsey's father imposed strict rules on the household, including mandating Sunday as a day of prayer and little else.
At age 10, Kinsey moved with his family to South Orange, New Jersey. Also at a young age, he showed great interest in nature and camping. He worked and camped with the local YMCA throughout his early years, and enjoyed these activities to such an extent that he intended to work for the YMCA after completing his education. Kinsey's senior undergraduate thesis for psychology, a dissertation on the group dynamics of young boys, echoed this interest. He joined the Boy Scouts when a troop was formed in his community. His parents strongly supported this (and joined as well) because the Boy Scouts was an organization that was based on the principles of Christianity. Kinsey worked his way up through the Scouting ranks to earn Eagle Scout in 1913, making him one of the earliest Eagle Scouts. Despite earlier disease having weakened his heart, Kinsey followed an intense sequence of difficult hikes and camping expeditions throughout his early life.
In high school, Kinsey was a quiet but hard-working student. While attending Columbia High School, he devoted his energy to academic work and playing the piano. At one time, Kinsey had hoped to become a concert pianist, but decided to concentrate on his scientific pursuits instead. Kinsey's ability to spend immense amounts of time deeply focused on study was a trait that would serve him well in college and during his professional career. He seems not to have formed strong social relationships during high school, but earned respect for his academic ability. While there, Kinsey became interested in biology, botany and zoology. Kinsey was later to claim that his high school biology teacher, Natalie Roeth, was the most important influence on his decision to become a scientist. Kinsey approached his father with plans to study botany at college. His father demanded that he study engineering at Stevens Institute of Technology instead. Kinsey was not successful there, and decided engineering was not a field he was good at. He switched to Bowdoin College in Brunswick, Maine, where he majored in biology.
Regardless, he resumed his commitment to study. At Stevens, he primarily took courses related to English and engineering, but was unable to satisfy his interest in biology. At the end of two years at Stevens, Kinsey gathered the courage to confront his father about his interest in biology and his intent to continue studying at Bowdoin College in Maine.
In the fall of 1914, Kinsey entered Bowdoin College, where he studied entomology under Manton Copeland, and was admitted to the Zeta Psi fraternity, in whose house he lived for much of his time at college. In 1916 Kinsey was elected to the Phi Beta Kappa society and graduated magna cum laude, with degrees in biology and psychology. Alfred Seguine didn't attend his son's graduation ceremony from Bowdoin, possibly as another sign of disapproval of his son's choice of career and studies. He continued his graduate studies at Harvard University's Bussey Institute, which had one of the most highly regarded biology programs in the United States. It was there that Kinsey studied applied biology under William Morton Wheeler, a scientist who made outstanding contributions to entomology. Under Wheeler, Kinsey worked almost completely autonomously, which suited both men quite well.
Kinsey chose to do his doctoral thesis on gall wasps, and began zealously collecting samples of the species. He traveled widely and took 26 detailed measurements of hundreds of thousands of gall wasps; his methodology was itself an important contribution to entomology as a science. Kinsey was granted a Sc.D. degree in 1919 by Harvard University, and published several papers in 1920 under the auspices of the American Museum of Natural History in New York City, introducing the gall wasp to the scientific community and describing its phylogeny. Of the more than 18 million insects in the museum's collection, some 5 million are gall wasps collected by Kinsey.
Kinsey wrote a widely used high-school textbook, "An Introduction to Biology", which was published in October 1926. The book endorsed evolution and unified, at the introductory level, the previously separate fields of zoology and botany. Kinsey also co-wrote "Edible Wild Plants of Eastern North America" with Merritt Lyndon Fernald, published in 1943. The original draft of the book was written in 1919–1920, while Kinsey was still a doctoral student at the Bussey Institute and Fernald was working at the Arnold Arboretum.
Personal life.
Marriage and family.
Kinsey married Clara Bracken McMillen in 1921, whose ceremony, like his college graduation, was also avoided by Alfred Sr. They had four children. Their first-born, Donald, died from the acute complications of juvenile diabetes in 1927, just before his fifth birthday. His daughter, Anne, was born in 1924, followed by Joan in 1925, and Bruce in 1928.
Kinsey was bisexual. He and his wife agreed that both could sleep with other people as well as with each other. He himself slept with other men, including his student Clyde Martin.
Kinsey designed his own house, which was built in the Vinegar Hill neighborhood of Bloomington, Indiana at 1320 First Street. There he practiced his deep interest in gardening.
Personal habits.
As a young man, Kinsey began inserting objects into his urethra - initially drinking straws before moving on to pipe cleaners, pencils and finally a toothbrush - to punish himself for having homoerotic feelings, and inserting toothbrushes continued throughout his adult life. After becoming accustomed to the pain of urethral insertions, Kinsey circumcised himself without anaesthesia. As an adult, he had a "furious hatred" of potatoes.
Sexology.
The Kinsey Reports.
Kinsey is widely regarded as the first major figure in American sexology; his research is cited as having paved the way for a deeper exploration into sexuality among sexologists and the general public, and as having liberated female sexuality. For example, Kinsey's work disputed the notions that women generally are not sexual and that female orgasms experienced vaginally are superior to clitoral orgasms. He initially became interested in different forms of sexual practices in 1933, after discussing the topic extensively with a colleague, Robert Kroc. Kinsey had been studying the variations in mating practices among gall wasps. During this time, he developed a scale measuring sexual orientation, now known as the Kinsey scale, which ranges from 0 to 6, where 0 is exclusively heterosexual and 6 is exclusively homosexual; a rating of X for "no socio-sexual contacts or reactions" was later added.
In 1935, Kinsey delivered a lecture to a faculty discussion group at Indiana University, his first public discussion of the topic, wherein he attacked the "widespread ignorance of sexual structure and physiology" and promoted his view that "delayed marriage" (that is, delayed sexual experience) was psychologically harmful. Kinsey obtained research funding from the Rockefeller Foundation, which enabled him to further study human sexual behavior. He published "Sexual Behavior in the Human Male" in 1948, followed in 1953 by "Sexual Behavior in the Human Female", both of which reached the top of the bestseller lists and turned Kinsey into a celebrity. These publications later became known as the Kinsey Reports. Articles about him appeared in magazines such as "Time", "Life", "Look", and "McCall's". The Kinsey Reports, which led to a storm of controversy, are regarded by many as a precursor to the sexual revolution of the 1960s and 1970s.
Controversial aspects.
Kinsey's research went beyond theory and interview to include observation of and participation in sexual activity, sometimes involving co-workers. Some of the data published in the two "Kinsey Reports" books is controversial in the scientific and psychiatric communities, due to the low amount of research that was done and Kinsey's decision to interview and sexually experiment with volunteers who may not have been representative of the general population. Kinsey justified this sexual experimentation as being necessary to gain the confidence of his research subjects. He encouraged his staff to do likewise, and to engage in a wide range of sexual activity, to the extent that they felt comfortable; he argued that this would help his interviewers understand the participant's responses. Kinsey filmed sexual acts which included co-workers in the attic of his home as part of his research; Biographer Jonathan Gathorne-Hardy explains that this was done to ensure the films' secrecy, which would have caused a scandal had it become public knowledge. James H. Jones, author of "Alfred C. Kinsey: A Public/Private Life", and British psychiatrist Theodore Dalrymple, amongst others, have speculated that Kinsey was driven by his own sexual needs.
Kinsey collected sexual material from around the world, which brought him to the attention of U.S. Customs when they seized some pornographic films in 1956; he died before this matter was resolved legally.
Kinsey wrote about pre-adolescent orgasms using data in tables 30 to 34 of the male volume, which report observations of orgasms in over three-hundred children between the ages of five months and fourteen years. This information was said to have come from adults' childhood memories, or from parent or teacher observation. Kinsey said he also interviewed nine men who had sexual experiences with children, and who told him about the children's responses and reactions. Little attention was paid to this part of Kinsey's research at the time, but where Kinsey had gained this information began to be questioned nearly 40 years later. It was later revealed that Kinsey used data from a single pedophile and presented it as being from various sources. Kinsey had seen the need for participant confidentiality and anonymity as necessary to gain "honest answers on such taboo subjects". The Kinsey Institute wrote that the data on children in tables 31–34 came from one man's journal (started in 1917) and that the events concerned predated the Kinsey Reports.
Jones wrote that Kinsey's sexual activity influenced his work, that he over-represented prisoners and prostitutes, classified some single people as "married", and that he included a disproportionate number of homosexual men, which may have distorted his studies. While he has been criticized for omitting African-Americans from his research, his report on the human male includes numerous references to African American participants. Historian Vern Bullough writes that the data was later reinterpreted, excluding prisoners and data derived from an exclusively gay sample, and the results indicate that it does not appear to have skewed the data. Kinsey may have over-represented homosexuals, but Bullough considers that this may have been because homosexual behavior was stigmatized and needed to be better understood. Paul Gebhard, who was Kinsey’s colleague from 1946 to 1956 and who also succeeded Kinsey as Director of the Kinsey Institute following his death, attempted to justify Kinsey's work in the 1970s by removing some of the suspect data he alleged showed a bias towards homosexuality. After he recalculated the findings in Kinsey's work, he found only slight differences between the original and updated figures.
In the media.
The popularity of "Sexual Behavior in the Human Male" prompted widespread media interest in 1948. "Time" magazine declared, "Not since "Gone With the Wind" had booksellers seen anything like it." The first pop culture references to Kinsey appeared not long after the book's publication; Martha Raye [sold] a half-million copies of 'Ooh, Dr. Kinsey!'" Cole Porter's song "Too Darn Hot", from the Tony Award–winning Broadway musical "Kiss Me, Kate", devoted its bridge to an analysis of the Kinsey report and the "average man's favorite sport." In 1949 Mae West, reminiscing on the days when the word "sex" was rarely uttered, said of Kinsey, "That guy merely makes it easy for me. Now I don't have to draw 'em any blueprints...We are both in the same business...Except I saw it first."
The publication of "Sexual Behavior in the Human Female" prompted even more intensive news coverage: Kinsey appeared on the cover of the August 24, 1953, issue of "Time". The national news magazine featured two articles on the scientist, one focusing on his research, career and new book, the other on his background, personality, and lifestyle. In the magazine's cover portrait, "Flowers, birds, and a bee surround Kinsey; the mirror-of-Venus female symbol decorates his bow tie." The lead article concludes with the following observation: "'Kinsey...has done for sex what Columbus did for geography,' declared a pair of enthusiasts...forgetting that Columbus did not know where he was when he got there... Kinsey's work contains much that is valuable, but it must not be mistaken for the last word." That same year, Kinsey appeared as a character in an episode of the Jack Benny TV program (September 15, 1953), in which he and his research were written into a sketch about Benny's 'fantasy' about Marilyn Monroe, a guest on the program.
Death.
Kinsey died on August 25, 1956, at the age of 62. The cause of death was reported to be a heart ailment and pneumonia. The "New York Times" ran the following editorial on August 27, 1956:
The untimely death of Dr. Alfred C. Kinsey takes from the American scene an important and valuable, as well as controversial, figure. Whatever may have been the reaction to his findings—and to the unscrupulous use of some of them—the fact remains that he was first, last, and always a scientist. In the long run it is probable that the values of his contribution to contemporary thought will lie much less in what he found out than in the method he used and his way of applying it. Any sort of scientific approach to the problems of sex is difficult because the field is so deeply overlaid with such things as moral precept, taboo, individual and group training, and long established behavior patterns. Some of these may be good in themselves, but they are no help to the scientific and empirical method of getting at the truth. Dr. Kinsey cut through this overlay with detachment and precision. His work was conscientious and comprehensive. Naturally, it will receive a serious setback with his death. Let us earnestly hope that the scientific spirit that inspired it will not be similarly impaired.
Legacy.
After the publication of "Sexual Behavior in the Human Female", a character called "Dr. Kinsey" appeared on the September 15, 1953 television episode of The Jack Benny Program as a bow-tied man interviewing a young woman on board a cruise ship that has left Hawaii. When "Dr. Kinsey" identifies himself to Jack Benny, Benny steps away in embarrassment.
The early 2000s saw a renewed interest in Kinsey. In 2003 Theatre of NOTE produced the Steve Morgan Haskell play titled "Fucking Wasps" which followed Kinsey's life from childhood until death. Matt Sesow's paintings adorned the theatre along with David Bickford playing piano live. Written and directed by Steve Morgan Haskell, "Fucking Wasps" received many accolades, including a Playwriting of the Year nomination from Backstage West. Premiering in 2003, the musical "Dr. Sex" focuses on the relationship between Kinsey, his wife, and their shared lover Wally Matthews (based on Clyde Martin). The play had a score by Larry Bortniker, a book by Bortniker and Sally Deering, and won seven Jeff Awards. It was produced off-Broadway in 2005. The 2004 biographical film "Kinsey", written and directed by Bill Condon, stars Liam Neeson as the scientist and Laura Linney as his wife. In 2004 T. Coraghessan Boyle's novel about Kinsey, "The Inner Circle", was published. The following year, PBS produced the documentary "Kinsey" in cooperation with the Kinsey Institute, which allowed access to many of its files. "Mr. Sex", a BBC radio play by Steve Coombes concerning Kinsey and his work, won the 2005 Imison Award.
In 2012 Kinsey was inducted into the Legacy Walk, an outdoor public display which celebrates LGBT history and people.

</doc>
<doc id="37662" url="http://en.wikipedia.org/wiki?curid=37662" title="Pope Leo II">
Pope Leo II

Pope Leo II (611 – 28 June 683) reigned from 17 August 682 to his death in 683.
Background and early activity in the Church.
He was a Sicilian by birth (the son of a man named Paulus). He may have ended up being among the many Sicilian clergy in Rome, at that time, due to the Islamic Caliphate attacks on Sicily in the mid-7th century. Though elected pope a few days after the death of Pope St. Agatho (10 January 681), he was not consecrated till after the lapse of a year and seven months (17 August 682). Leo was known as an eloquent preacher who was interested in music, and noted for his charity to the poor.
Reign as Bishop of Rome.
Elected shortly after the death of Agatho, Leo was not consecrated for over a year and a half. The reason may have been due to negotiations regarding imperial control of papal elections.
These negotiations were undertaken by Leo's predecessor Agatho between the Holy See and Emperor Constantine IV. They concerned the relations of the Byzantine Court to papal elections. Constantine IV had already promised Agatho to abolish or reduce the tax that the popes had been paying to the imperial treasury at the time of their consecration, an imperial policy that had been in force for about a century.
Leo's short-lived pontificate did not allow him to accomplish much, but there was one achievement of major importance: he confirmed the acts of the Sixth Ecumenical Council (680–1). This council had been held in Constantinople against the Monothelite controversy, and had been presided over by the legates of Pope Agatho. After Leo had notified the Emperor that the decrees of the council had been confirmed, he made them known to the nations of the West. In letters written to the king, the bishops, and the nobles of Spain, he explained what the council had effected, and he called upon the bishops to subscribe to its decrees.
During this council, Pope Honorius I was anathematised for his views in the Monothelite controversy as tolerant of heresy. Leo took great pains to make it clear that in condemning Honorius, he did so not because Honorius taught heresy, but because he was not active enough in opposing it. In accordance with the papal mandate, a synod was held at Toledo (684) in which the Council of Constantinople was accepted.
Regarding the decision of the council, Leo wrote once and again in approbation of the decision of the council and in condemnation of Honorius, whom he regarded as one who "profana proditione immaculatem fidem subvertare conatus est" (roughly, "one who by betrayal has tried to overthrow the immaculate faith"). In their bearing upon the question of papal infallibility these words have caused considerable attention and controversy, and prominence is given to the circumstance that in the Greek text of the letter to the Emperor which the phrase occurs, the milder expression "subverti permisit" ("allowed to be overthrown...") is used for "subvertare conatus est".
At this time Leo put an end to the attempts of the Ravenna archbishops to get away from the control of the Bishop of Rome. The Pope sweetened the deal for the Ravenna bishops by abolishing the tax it had been customary for them to pay when they received the pallium.
Also, in apparent response to Lombard raids, Leo transferred the relics of a number of martyrs from the catacombs to churches inside the walls of the city. He also dedicated two churches, St. Paul's and Sts. Sebastian and George.
Burial.
Leo was originally buried in his own monument; however, some years after his death, his remains were put into a tomb that contained the first four of his papal namesakes.
References.
 

</doc>
<doc id="37663" url="http://en.wikipedia.org/wiki?curid=37663" title="Pope Leo IV">
Pope Leo IV

Pope Saint Leo IV (790 – 17 July 855) was Pope from 10 April 847 to his death in 855.
Life.
A Roman by birth, he was unanimously chosen to succeed Sergius II. When he was elected, on 10 April 847, he was cardinal of Santi Quattro Coronati and had been subdeacon of Gregory IV and archpriest under his predecessor. His pontificate was chiefly distinguished by his efforts to repair the damage done by the Saracens during the reign of his predecessor to various churches of the city, especially those of St Peter and St Paul.
The Saracens were besieging Gaeta, which led to Leo's order that the walls of the city be restored and strengthened between 848 and 849. When the Muslims approached Portus, he summoned the Repubbliche Marinare (or mariner cities of Italy) – Naples, Gaeta and Amalfi – to form a league. The command of the unified fleet was given to Cesarius, son of Duke Sergius I of Naples. The subsequent Battle of Ostia was one of the most famous in history of the papacy of the Middle Ages and is celebrated in a famous fresco by Raphael and his pupils in his Rooms of the Vatican Palace in the Vatican City. Another episode of Leo's life celebrated by the Urbinate in his series of frescoes for the "Incendio di Borgo" is the burning of the pilgrims' district of Rome (the "Borgo"), which, according to the legend, was stopped by Leo simply making the sign of the cross.
In order to counter the Saracen menace definitively, Leo ordered a new line of walls encompassing the suburb on the right bank of the Tiber to be built, including St. Peter's Basilica, which had been undefended until this time. The district enclosed by the walls is still known as the Leonine City, and corrensponds to the later rione of Borgo. He also restored and embellished the damaged Basilica di San Paolo fuori le Mura and St. Peter's: the latter's altar again received its gold covering (after being stolen), which weighed 206 lb. and was studded with precious gems. Following the restoration of St. Peter's, Leo appealed to the Christian kingdoms to confront the Arab raiders.
Leo held three synods, one in 850 that was distinguished by the presence of Holy Roman Emperor Louis II, but the other two of little importance. The history of the papal struggle with Hincmar of Reims, which began during Leo's pontificate, belongs properly to that of Nicholas I.
Leo died on 17 July 855 and was buried in St. Peter's Basilica. Benedict III was Leo's immediate successor. A medieval tradition claimed that a woman, Pope Joan, succeeded him, disguising herself as a man, but Joan is generally believed to be fictitious.
Burial.
Leo was originally buried in his own monument, however some years after his death, his remains were put into a tomb that contained the first four Pope Leos. In the 18th century, the relics of Leo the Great were separated from the other Leos and given their own chapel.
Iconography.
Leo IV had the figure of the rooster placed on the Old St. Peter's Basilica or old Constantinian basilica and has served as a religious icon and reminder of Peter's denial of Christ since that time, with some churches still having the cockerel on the steeple today. It is reputed that Pope Gregory I had previously said that the cock (rooster) "was the most suitable emblem of Christianity", being "the emblem of St Peter". After Leo IV, Pope Nicholas I, who had been made a deacon by Leo IV, decreed that the figure of the cock (rooster) should be placed on every church.

</doc>
<doc id="37665" url="http://en.wikipedia.org/wiki?curid=37665" title="Pope Leo V">
Pope Leo V

Pope Leo V (died c. February 904) was Pope from July 903 to his death in 904. He was pope during the period known as the Saeculum obscurum. He was thrown into prison in September 903 by the Antipope Christopher, and was probably killed at the start of the pontificate of Pope Sergius III. If his deposition is not considered valid (as in the modern Vatican list), then his papacy may be considered to have ended with his death in 904.
Pontificate.
Leo V was born at a place called Priapi, near Ardea. Although he was a priest when he was elected pope following the death of Pope Benedict IV (900–903), he was not a Cardinal priest of Rome.
During his brief pontificate, Leo granted the canons of Bologna a special papal bull "(epistola tuitionis)" where he exempted them from the payment of taxes. However, after a reign of a little over two months, Leo was captured by Christopher, the Cardinal-priest of San Lorenzo in Damaso, and thrown into prison. Christopher then had himself elected pope (903–904), and although now considered an antipope, he had until recently been considered a legitimate pope. If Leo never acquiesced to his deposition, then he can be considered Pope until his death in 904.
Leo died whilst in prison. He was either murdered on the orders of Christopher, who was in turn executed by Pope Sergius III (904–911) in 904, or, more likely, both were ordered to be killed at the beginning of Sergius’ pontificate, either on the orders of Sergius himself, or by the direction of the "sacri palatii vestararius", Theophylact, Count of Tusculum.

</doc>
<doc id="37666" url="http://en.wikipedia.org/wiki?curid=37666" title="Pope Leo VI">
Pope Leo VI

Pope Leo VI (died February 929) was Pope for just over seven months, from June 928 to his death in February 929. His pontificate occurred during the period known as the Saeculum obscurum.
Biography.
Leo VI was born into Roman family, and his father was Christophorus, who had been Primicerius under Pope John VIII around the year 876. Tradition has it that he was a member of the Sanguini family. Just immediately prior to his election as pope, Leo had been serving as the Cardinal-Priest of the church of Santa Susanna.
Leo was elected pope around June 928, during a period of anarchy. He was chosen by the "senatrix" Marozia, who had gained control of Rome via the domination of her husband Guy, Margrave of Tuscany, and who had ordered the imprisonment and death of Leo’s predecessor, Pope John X.
During his brief pontificate, Leo confirmed the decisions of the Synod of Split. He completed his predecessor’s investigations into the ecclesiastical situation in Dalmatia, and proceeded to give the pallium to John, Archbishop of Salona, and ordered all the bishops of Dalmatia to obey him. He also ordered the Bishop of Nona and others to limit themselves to the extent of their dioceses. Leo then issued a ban on castrati entering into a union of marriage. He also issued an appeal for help against the Arab raiders who were threatening Rome, stating that:
”Whoever died faithful in this struggle will not see himself refused entry into the heavenly kingdom.”
The French chronicler Flodoard said of him:
”Through the virtue of Peter, Leo the sixth was taken and received, he was preserved for seven months and five days, and like his predecessors, he joined the company of the prophets.” 
Leo died in February 929, and was succeeded by Pope Stephen VII. He was buried at St. Peter’s Basilica.

</doc>
<doc id="37667" url="http://en.wikipedia.org/wiki?curid=37667" title="Pope Leo VII">
Pope Leo VII

Pope Leo VII (Latin: "Leo VII"; died 13 July 939) was Pope from 3 January 936 to his death in 939. He was preceded by Pope John XI and followed by Pope Stephen VIII. Leo VII's election to the papacy was secured by Alberic II of Spoleto, the ruler of Rome at the time. Alberic wanted to choose the pope so that the papacy would continue to yield to his authority. Leo was the priest of the church of St. Sixtus in Rome, thought to be a Benedictine monk. He had little ambition towards the papacy, but consented under pressure.
As pope, Leo VII reigned for only three years. Most of his bulls were grants of privilege to monasteries, especially including the Abbey of Cluny. Leo called for Odo of Cluny to mediate between Alberic and Hugh of Italy, Alberic's stepfather, the King of Italy. Odo was successful in negotiating a truce after arranging a marriage between Hugh's daughter Alda and Alberic. Leo VII also appointed Frederick, Archbishop of Mainz, as a reformer in Germany. Leo allowed Frederick to drive out Jews that refused to be baptized, but he did not endorse the forced baptism of Jews.
The circumstance of his death is unrecorded, although a spurious legend, from centuries after, maintains that he died of a heart attack while in congress with his mistress.
After his death in July 939, Leo VII was interred at St. Peter's Basilica.

</doc>
<doc id="37669" url="http://en.wikipedia.org/wiki?curid=37669" title="William Tyndale">
William Tyndale

William Tyndale (; sometimes spelled "Tynsdale", "Tindall", "Tindill", "Tyndall"; c. 1494–1536) was an English scholar who became a leading figure in Protestant reform in the years leading up to his execution. He is well known for his translation of the Bible into English. He was influenced by the work of Desiderius Erasmus, who made the Greek New Testament available in Europe, and by Martin Luther. While a number of partial translations had been made from the seventh century onward, the spread of Wycliffe's Bible resulted in a death sentence for any unlicensed possession of Scripture in English—even though translations in all other major European languages had been accomplished and made available. Tyndale's translation was the first English Bible to draw directly from Hebrew and Greek texts, the first English one to take advantage of the printing press, and first of the new English Bibles of the Reformation. It was taken to be a direct challenge to the hegemony of both the Roman Catholic Church and the laws of England to maintain the church's position. In 1530, Tyndale also wrote "The Practyse of Prelates", opposing Henry VIII's divorce from Catherine of Aragon on the grounds that it contravened Scripture.
Reuchlin's Hebrew grammar was published in 1506. Tyndale worked in an age in which Greek was available to the European scholarly community for the first time in centuries. Erasmus compiled and edited Greek Scriptures into the Textus Receptus—ironically, to improve upon the Latin Vulgate—following the Renaissance-fueling Fall of Constantinople in 1453 and the dispersion of Greek-speaking intellectuals and texts into a Europe which previously had access to none. When a copy of "The Obedience of a Christian Man" fell into the hands of Henry VIII, the king found the rationale to break the Church in England from the Roman Catholic Church in 1534.
In 1535, Tyndale was arrested and jailed in the castle of Vilvoorde (Filford) outside Brussels for over a year. In 1536 he was convicted of heresy and executed by strangulation, after which his body was burnt at the stake. His dying prayer that the King of England's eyes would be opened seemed to find its fulfillment just two years later with Henry's authorization of The Great Bible for the Church of England—which was largely Tyndale's own work. Hence, the Tyndale Bible, as it was known, continued to play a key role in spreading Reformation ideas across the English-speaking world and, eventually, to the British Empire.
In 1611, the 54 scholars who produced the King James Bible drew significantly from Tyndale, as well as from translations that descended from his. One estimate suggests the New Testament in the King James Version is 83% Tyndale's and the Old Testament 76%. With his translation of the Bible the first to be printed in English, and a model for subsequent English translations, in 2002, Tyndale was placed at number 26 in the BBC's poll of the 100 Greatest Britons.
Life.
Tyndale was born at some time in the period 1484–96, in Melksham Court, Stinchcombe, a village near Dursley, Gloucestershire. The Tyndale family also went by the name Hychyns (Hitchins), and it was as William Hychyns that Tyndale was enrolled at Magdalen College School, Oxford. Tyndale's family had migrated to Gloucestershire at some point in the 15th century – probably as a result of the Wars of the Roses. The family derived from Northumberland via East Anglia. Tyndale's brother, Edward, was receiver to the lands of Lord Berkeley as attested to in a letter by Bishop Stokesley of London. Tyndale is recorded in two genealogies as having been the brother of Sir William Tyndale, of Deane, Northumberland, and Hockwald, Norfolk, who was knighted at the marriage of Arthur, Prince of Wales to Catherine of Aragon. Tyndale's family was thus derived from Baron Adam de Tyndale, a tenant-in-chief of Henry I (see Tyndall). William Tyndale's niece, Margaret Tyndale, was married to the Protestant martyr Rowland Taylor, burnt during the Marian Persecutions.
At Oxford.
Tyndale began a Bachelor of Arts degree at Magdalen Hall (later Hertford College) of Oxford University in 1506 and received his B.A. in 1512; the same year becoming a subdeacon. He was made Master of Arts in July 1515 and was held to be a man of virtuous disposition, leading an unblemished life. The M.A. allowed him to start studying theology, but the official course did not include the systematic study of Scripture. As Tyndale later complained:
They have ordained that no man shall look on the Scripture, until he be noselled in heathen learning eight or nine years and armed with false principles, with which he is clean shut out of the understanding of the Scripture.
A gifted linguist, over the years he became fluent in French, Greek, Hebrew, German, Italian, Latin, and Spanish, in addition to English. Between 1517 and 1521, he went to the University of Cambridge. Erasmus had been the leading teacher of Greek there from August 1511 to January 1512, but not during Tyndale's time at the university.
Tyndale became chaplain at the home of Sir John Walsh at Little Sodbury and tutor to his children around 1521. His opinions proved controversial to fellow clergymen, and the next year he was summoned before John Bell, the Chancellor of the Diocese of Worcester, although no formal charges were laid at the time. After the harsh meeting with Bell and other church leaders, and near the end of Tyndale's time at Little Sodbury, John Foxe describes an argument with a "learned" but "blasphemous" clergyman, who had asserted to Tyndale that, "We had better be without God's laws than the Pope's." Tyndale responded: "I defy the Pope, and all his laws; and if God spares my life, ere many years, I will cause the boy that driveth the plow to know more of the Scriptures than thou dost!"
Tyndale left for London in 1523 to seek permission to translate the Bible into English. He requested help from Bishop Cuthbert Tunstall, a well-known classicist who had praised Erasmus after working together with him on a Greek New Testament. The bishop, however, declined to extend his patronage, telling Tyndale he had no room for him in his household. Tyndale preached and studied "at his book" in London for some time, relying on the help of a cloth merchant, Humphrey Monmouth. During this time he lectured widely, including at St Dunstan-in-the-West.
In Europe.
Tyndale left England and landed on the continent, perhaps at Hamburg, in the spring of 1524, possibly traveling on to Wittenberg. The entry of the name "Guillelmus Daltici ex Anglia“ in the matriculation registers of the University of Wittenberg has been taken to be a Latinization of "William Tyndale from England". At this time, possibly in Wittenberg, he began translating the New Testament, completing it in 1525, with assistance from Observant friar William Roy.
In 1525, publication of the work by Peter Quentell, in Cologne, was interrupted by the impact of anti-Lutheranism. It was not until 1526 that a full edition of the New Testament was produced by the printer Peter Schoeffer in Worms, a free imperial city then in the process of adopting Lutheranism. More copies were soon printed in Antwerp. The book was smuggled into England and Scotland, and condemned in October 1526 by Bishop Tunstall, who issued warnings to booksellers and had copies burned in public. Marius notes that the "spectacle of the scriptures being put to the torch. . .provoked controversy even amongst the faithful." Cardinal Wolsey condemned Tyndale as a heretic, his first mention in open court being named a heretic in January 1529.
From an entry in George Spalatin's Diary, on 11 August 1526, Tyndale apparently remained at Worms for about a year. It is not clear exactly when he moved to Antwerp. The colophon to Tyndale's translation of Genesis and the title pages of several pamphlets from this time are purported to have been printed by Hans Luft at Marburg, but this is a false address. Hans Luft, the printer of Luther's books, never had a printing press at Marburg.
Around 1529, it is possible that Tyndale intended to move to Hamburg, carrying on his work. He revised his New Testament and began translating the Old Testament and writing various treatises. 
Opposition to Henry VIII's divorce.
In 1530, he wrote "The Practyse of Prelates", opposing Henry VIII's planned divorce from Catherine of Aragon, in favour of Anne Boleyn, on the grounds that it was unscriptural and was a plot by Cardinal Wolsey to get Henry entangled in the papal courts of Pope Clement VII. The king's wrath was aimed at Tyndale: Henry asked the Emperor Charles V to have the writer apprehended and returned to England under the terms of the Treaty of Cambrai; however, the Emperor responded that formal evidence was required before extradition. Tyndale developed his case in "An Answer unto Sir Thomas More's Dialogue".
Betrayal and death.
Eventually, Tyndale was betrayed by Henry Phillips
to the imperial authorities, seized in Antwerp in 1535, and held in the castle of Vilvoorde (Filford) near Brussels. He was tried on a charge of heresy in 1536 and condemned to be burned to death, despite Thomas Cromwell's intercession on his behalf. Tyndale "was strangled to death while tied at the stake, and then his dead body was burned". His final words, spoken "at the stake with a fervent zeal, and a loud voice", were reported as "Lord! Open the King of England's eyes." The traditional date of commemoration is 6 October, but records of Tyndale's imprisonment suggest the actual date of his execution might have been some weeks earlier. Foxe gives 6 October as the date of commemoration (left-hand date column), but gives no date of death (right-hand date column).
Within four years, at the same king's behest, four English translations of the Bible were published in England, including Henry's official Great Bible. All were based on Tyndale's work.
Theological views.
Tyndale denounced the practice of prayer to saints. He taught justification by faith, the return of Christ, and mortality of the soul.
Printed works.
Best known for his translation of the Bible, Tyndale was an active writer and translator. As well as his focus on the ways in which religion should be lived, he also had a focus on political issues.
Legacy.
Impact on the English language.
In translating the Bible, Tyndale introduced new words into the English language, and many were subsequently used in the King James Bible:
Coinage of the word "atonement" (a concatenation of the words 'At One' to describe Christ's work of restoring a good relationship—a reconciliation—between God and people) is also sometimes ascribed to Tyndale. However, the word was probably in use by at least 1513, before Tyndale's translation. Similarly, sometimes Tyndale is said to have coined the term "mercy seat." While it is true that Tyndale introduced the word into English, "mercy seat" is more accurately a translation of Martin Luther's German "Gnadenstuhl".
As well as individual words, Tyndale also coined such familiar phrases as:
Controversy over new words and phrases.
The hierarchy of the Roman Catholic Church did not approve of some of the words and phrases introduced by Tyndale, such as "overseer", where it would have been understood as "bishop", "elder" for "priest", and "love" rather than "charity". Tyndale, citing Erasmus, contended that the Greek New Testament did not support the traditional Roman Catholic readings. More controversially, Tyndale translated the Greek "ekklesia", (literally "called out ones") as "congregation" rather than "church". It has been asserted this translation choice "was a direct threat to the Church's ancient—but so Tyndale here made clear, non-scriptural—claim to be the body of Christ on earth. To change these words was to strip the Church hierarchy of its pretensions to be Christ's terrestrial representative, and to award this honour to individual worshipers who made up each congregation."
Contention from Roman Catholics came not only from real or perceived errors in translation but also a fear of the erosion of their social power if Christians could read the Bible in their own language. "The Pope's dogma is bloody", Tyndale wrote in "The Obedience of a Christian Man". Thomas More (since 1935 in the Roman Catholic Church, Saint Thomas More) commented that searching for errors in the Tyndale Bible was similar to searching for water in the sea, and charged Tyndale's translation of "The Obedience of a Christian Man" with having about a thousand falsely translated errors. Bishop Tunstall of London declared that there were upwards of 2,000 errors in Tyndale's Bible, having already in 1523 denied Tyndale the permission required under the Constitutions of Oxford (1409), which were still in force, to translate the Bible into English.
In response to allegations of inaccuracies in his translation in the New Testament, Tyndale in the "Prologue" to his 1525 translation wrote that he never intentionally altered or misrepresented any of the Bible in his translation, but that he had sought to "interpret the sense of the scripture and the meaning of the spirit."
While translating, Tyndale followed Erasmus' (1522) Greek edition of the New Testament. In his preface to his 1534 New Testament ("WT unto the Reader"), he not only goes into some detail about the Greek tenses but also points out that there is often a Hebrew idiom underlying the Greek. The Tyndale Society adduces much further evidence to show that his translations were made directly from the original Hebrew and Greek sources he had at his disposal. For example, the Prolegomena in Mombert's "William Tyndale's Five Books of Moses" show that Tyndale's Pentateuch is a translation of the Hebrew original. His translation also drew on the Latin Vulgate and Luther's 1521 September Testament.
Of the first (1526) edition of Tyndale's New Testament only three copies survive. The only complete copy is part of the Bible Collection of Württembergische Landesbibliothek, Stuttgart. The copy of the British Library is almost complete, lacking only the title page and list of contents. Another rarity of Tyndale's is the Pentateuch of which only nine remain.
Impact on the English Bible.
The translators of the Revised Standard Version in the 1940s noted that Tyndale's translation inspired the translations that followed, including the Great Bible of 1539, the Geneva Bible of 1560, the Bishops' Bible of 1568, the Douay-Rheims Bible of 1582–1609, and the King James Version of 1611, of which the RSV translators noted: "It [the KJV] kept felicitous phrases and apt expressions, from whatever source, which had stood the test of public usage. It owed most, especially in the New Testament, to Tyndale". Many scholars today believe that such is the case. Moynahan writes: "A complete analysis of the Authorised Version, known down the generations as "the AV" or "the King James" was made in 1998. It shows that Tyndale's words account for 84% of the New Testament and for 75.8% of the Old Testament books that he translated. Joan Bridgman makes the comment in the "Contemporary Review" that, "He [Tyndale] is the mainly unrecognised translator of the most influential book in the world. Although the Authorised King James Version is ostensibly the production of a learned committee of churchmen, it is mostly cribbed from Tyndale with some reworking of his translation."
Many of the English versions since then have drawn inspiration from Tyndale, such as the Revised Standard Version, the New American Standard Bible, and the English Standard Version. Even the paraphrases like the Living Bible have been inspired by the same desire to make the Bible understandable to Tyndale's proverbial ploughboy.
George Steiner in his book on translation "After Babel" refers to "the influence of the genius of Tyndale, the greatest of English Bible translators..." ["After Babel" p. 366]. He has also appeared as a character in two plays dealing with the King James Bible, Howard Brenton's "Anne Boleyn" (2010) and David Edgar's "Written on the Heart" (2011).
Memorials.
A memorial to Tyndale stands in Vilvoorde, where he was executed. It was erected in 1913 by Friends of the Trinitarian Bible Society of London and the Belgian Bible Society There is also a small William Tyndale Museum in the town, attached to the Protestant church.
A bronze statue by Sir Joseph Boehm commemorating the life and work of Tyndale was erected in Victoria Embankment Gardens on the Thames Embankment, London in 1884. It shows his right hand on an open Bible, which is itself resting on an early printing press.
The Tyndale Monument was built in 1866 on a hill above his supposed birthplace, North Nibley, Gloucestershire.
A stained-glass window commemorating Tyndale was made in 1911 for the British and Foreign Bible Society by James Powell. In 1994, when the Society moved their offices, the window was reinstalled in the chapel of Hertford College, Oxford. Tyndale was at Magdalen Hall, Oxford, which became Hertford College in 1874. The window depicts a full-length portrait of Tyndale, a cameo of a printing shop in action, some words of Tyndale, the opening words of Genesis in Hebrew, the opening words of John's Gospel in Greek, and the names of other pioneering Bible translators. The portrait is based on the oil painting that hangs in the college's dining hall.
A number of colleges, schools and study centres have been named in his honour, including Tyndale House (Cambridge), Tyndale University College and Seminary (Toronto), the Tyndale-Carey Graduate School affiliated to the Bible College of New Zealand, William Tyndale College (Farmington Hills, Michigan), and Tyndale Theological Seminary (Shreveport, Louisiana, and Fort Worth, Texas), the independent Tyndale Theological Seminary in Badhoevedorp, near Amsterdam, The Netherlands, Tyndale Christian School in South Australia and Tyndale Park Christian School in New Zealand.
An American Christian publishing house, also called Tyndale House, was named after Tyndale.
A life sized bronze statue of a seated William Tyndale at work on his translation by Lawrence Holofcener (2000) was placed in the Millennium Square, Bristol, United Kingdom. In 2008, vandals attacked the statue, which was taken away, repaired, and reinstalled.
Liturgical commemoration.
By tradition Tyndale's death is commemorated on 6 October. There are commemorations on this date in the church calendars of members of the Anglican Communion, initially as one of the "days of optional devotion" in the American Book of Common Prayer (1979), and a "black-letter day" in the Church of England's Alternative Service Book. The Common Worship that came into use in the Church of England in 2000 provides a collect proper to 6 October, beginning with the words:
Lord, give your people grace to hear and keep your word that, after the example of your servant William Tyndale, we may not only profess your gospel but also be ready to suffer and die for it, to the honour of your name;
See the "List of Anglican Church Calendars".
Tyndale is also honoured in the Calendar of Saints of the Evangelical Lutheran Church in America as a translator and martyr the same day.
Tyndale's pronunciation.
Tyndale was writing at the beginning of the Early Modern English period. His pronunciation must have differed in its phonology from that of Shakespeare at the end of the period. The linguist David Crystal has made a transcription and a sound recording of Tyndale's translation of the whole of Saint Matthew's Gospel in what he believes to be the pronunciation of the day, using the term "original pronunciation". The recording has been published by The British Library on two compact discs with an introductory essay by Crystal.
Sources.
</dl>

</doc>
<doc id="37670" url="http://en.wikipedia.org/wiki?curid=37670" title="Pope John XXII">
Pope John XXII

Pope John XXII (Latin: "Ioannes XXII"; 1244 – 4 December 1334), born Jacques Duèze (or d'Euse), was Pope from 7 August 1316 to his death in 1334. He was the second Avignon Pope, elected by a conclave in Lyon assembled by King Louis X's brother Philip, the Count of Poitiers, later King Philip V of France. Like his predecessor, Clement V, he centralized power and income in the Papacy and lived a princely life in Avignon. He opposed the political policies of Louis IV of Bavaria as Holy Roman Emperor, which prompted Louis to invade Italy and set up an antipope, Nicholas V. Pope John XXII faced controversy in theology involving his views on the Beatific Vision, and he opposed the Franciscan understanding of the poverty of Christ and his apostles. He canonized St. Thomas Aquinas.
Early life and election.
The son of a shoemaker in Cahors, Jacques Duèze studied medicine in Montpellier and law in Paris, yet could not read a regal letter written to him in French.
Duèze taught both canon and civil law at Toulouse and Cahors. On the recommendation of Charles II of Naples he was made Bishop of Fréjus in 1300. In 1309 he was appointed chancellor of Charles II, and in 1310 he was transferred to Avignon. He delivered legal opinions favorable to the suppression of the Templars, but he also defended Boniface VIII and the Bull "Unam Sanctam". On 23 December 1312, Clement V made him Cardinal-Bishop of Porto-Santa Rufina.
The death of Pope Clement V in 1314 was followed by an interregnum of two years due to disagreements between the cardinals, who were split into two factions. After two years, Philip, in 1316, finally managed to arrange a papal conclave of twenty-three cardinals in Lyon. This conclave elected Duèze, who took the name John XXII and was crowned in Lyon. He set up his residence in Avignon rather than Rome, continuing the Avignon Papacy of his predecessor.
John XXII involved himself in the politics and religious movements of many European countries in order to advance the interests of the Church. His close links with the French crown created widespread distrust of the papacy.
Papacy.
Pope John XXII was an excellent administrator and efficient at reorganizing the Church. He had sent a letter of thanks to the Muslim ruler Uzbeg Khan, who was very tolerant of Christians and treated Christians kindly.
John XXII has traditionally been credited with having composed the prayer "Anima Christi", which has become the English "Soul of Christ, sanctify me ..." and the basis for the hymn "Soul of Christ, Sanctify My Breast".
On 27 March 1329 John XXII condemned many writings of Meister Eckhart as heretical in his papal bull "In Agro Dominico".
Conflict with Louis IV.
Prior to John XXII's election a contest had begun for the Holy Roman Empire's crown between Louis IV of Bavaria and Frederick I of Austria. John XXII was neutral at first, but in 1323, when Louis IV became Holy Roman Emperor, the Guelph (papal) party and the Ghibelline (imperial) party quarreled, which was partly provoked by John XXII's extreme claims of authority over the empire and partly by Louis IV's support of the spiritual Franciscans, whom John XXII condemned in the Papal bull "Quorumdam exigit". Louis IV was assisted in his doctrinal dispute with the papacy by Marsilius of Padua and later by the English Franciscan friar and scholar William of Ockham. Louis IV invaded Italy, entered Rome and set up Pietro Rainalducci as Antipope Nicholas V in 1328. The project was a fiasco. Guelphic predominance at Rome was later restored, and Pope John excommunicated William of Ockham. However, Louis IV had silenced the papal claims and John XXII stayed the rest of his life in Avignon.
Franciscan poverty.
Pope John XXII was determined to suppress what he considered to be the excesses of the Spirituals, who contended eagerly for the view that Christ and his apostles had possessed absolutely nothing, citing "Exiit qui seminat" in support of their view. In 1317, John XXII formally condemned the group of them known as the Fraticelli. On 26 March 1322, with "Quia nonnunquam", he removed the ban on discussion of Nicholas III's bull and commissioned experts to examine the idea of poverty based on belief that Christ and the apostles owned nothing. The experts disagreed among themselves, but the majority condemned the idea on the grounds that it would condemn the Church's right to have possessions. The Franciscan chapter held in Perugia in May 1322 declared on the contrary: "To say or assert that Christ, in showing the way of perfection, and the Apostles, in following that way and setting an example to others who wished to lead the perfect life, possessed nothing either severally or in common, either by right of ownership and "dominium" or by personal right, we corporately and unanimously declare to be not heretical, but true and catholic." By the bull "Ad conditorem canonum" of 8 December 1322, John XXII, declared it ridiculous to pretend that every scrap of food given to the friars and eaten by them belonged to the pope, refused to accept ownership over the goods of the Franciscans in future and granted them exemption from the rule that absolutely forbade ownership of anything even in common, thus forcing them to accept ownership. On 12 November 1323, he issued the bull "Quum inter nonnullos", which declared "erroneous and heretical" the doctrine that Christ and his apostles had no possessions whatever.
Influential members of the order protested, such as the minister general Michael of Cesena, the English provincial William of Ockham, and Bonagratia of Bergamo. In 1324, Louis the Bavarian sided with the Spirituals and accused the Pope of heresy. In reply to the argument of his opponents that Nicholas III's bull "Exiit qui seminat" was fixed and irrevocable, John XXII issued the bull "Quia quorundam" on 10 November 1324, in which he declared that it cannot be inferred from the words of the 1279 bull that Christ and the apostles had nothing, adding: "Indeed, it can be inferred rather that the Gospel life lived by Christ and the Apostles did not exclude some possessions in common, since living 'without property' does not require that those living thus should have nothing in common."
In 1328 Michael of Cesena was summoned to Avignon to explain the Order's intransigence in refusing the Pope's orders and its complicity with Louis of Bavaria. Michael was imprisoned in Avignon, together with Francesco d'Ascoli, Bonagratia and William of Ockham. In January of that year Louis entered Rome and had himself crowned Holy Roman Emperor. Three months later, he declared John XXII deposed and installed the Spiritual Franciscan Pietro Rainalducci as Pope. The Franciscan chapter that opened in Bologna on 28 May reelected Michael of Cesena, who two days before had escaped with his companions from Avignon. In August Louis the Bavarian and his pope had to flee Rome before an attack by Robert, King of Naples. Only a small part of the Franciscan Order joined the opponents of John XXII, and at a general chapter held in Paris in 1329 the majority of all the houses declared their submission to the Pope. With the bull "Quia vir reprobus" of 16 November 1329, John XXII replied to Michael of Cesena's attacks on "Ad conditorem canonum", "Quum inter nonnullos", and "Quia quorundam". In 1330, Antipope Nicholas V submitted, followed later by the ex-general Michael, and finally, just before his death, by Ockham.
Beatific vision controversy.
Pope John XXII was involved in a theological controversy concerning the beatific vision. Even before he was pope, John XXII argued that those who died in the faith did not see the presence of God until the Last Judgment. He continued this argument for a time in sermons while he was pope, although he never taught it in official documents. He eventually backed down from his position, and agreed that those who died in grace do indeed immediately enjoy the beatific vision.
Despite holding for many years a view widely held to be heretical, John XXII is not considered a heretic because the doctrine he had contradicted had not been formally defined by the Church until his successor, Benedict XII, addressed by the encyclical "Benedictus Deus", which formally defined this doctrine as part of Church teaching.

</doc>
<doc id="37671" url="http://en.wikipedia.org/wiki?curid=37671" title="Aristocracy">
Aristocracy

Aristocracy (Greek ἀριστοκρατία "aristokratía", from ἄριστος "aristos" "excellent," and κράτος "kratos" "power") is a form of government that places power in the hands of a small, privileged ruling class. The term derives from the Greek "aristokratia", meaning "rule of the best". 
At the time of the word's origins in Ancient Greece, the Greeks conceived it as rule by the best qualified citizens—and often contrasted it favourably with monarchy, rule by an individual. In later times, aristocracy was usually seen as rule by a privileged group, the aristocratic class, and was contrasted with democracy.
Concept.
The concept evolved in Ancient Greece, whereby a council of leading citizens was commonly empowered and contrasted with direct democracy, in which a council of male citizens was appointed as the "senate" of a city state or other political unit. The Greeks did not like the concept of monarchy, and as their democratic system fell, aristocracy was upheld.
In Ancient Rome, the Republic consisted of an aristocracy—as well as consuls, a senate, and a tribal assembly. In the Middle Ages and early modern era, aristocracies primarily consisted of an influential aristocratic class, privileged by birth, and often by wealth. Since the French Revolution, aristocracy has generally been contrasted with democracy, in which all citizens should hold some form of political power. However, this distinction is often oversimplified.The concept evolved in Ancient Greece, whereby a council of leading citizens was commonly empowered and contrasted with direct democracy, in which a council of male citizens was appointed as the "senate" of a city state or other political unit.
In his 1651 book "Leviathan", Thomas Hobbes describes an aristocracy as a commonwealth in which the representative of the citizens is an assembly by part. It is a system in which only a small part of the population represents the government. Modern depictions of aristocracy tend to regard it not as the ancient Greek concept of rule by the best, but more as a plutocracy—rule by the rich.

</doc>
<doc id="37673" url="http://en.wikipedia.org/wiki?curid=37673" title="Symbol">
Symbol

A symbol is an object that represents, stands for, or suggests an idea, visual image, belief, action, or material entity. Symbols take the form of words, sounds, gestures, or visual images and are used to convey ideas and beliefs. For example, a red octagon may be a symbol for "STOP". On a map, a picture of a tent might represent a campsite. Numerals are symbols for numbers. Alphabetic letters are symbols for sounds. Personal names are symbols representing individuals. A red rose symbolizes love and compassion. 
In cartography, an organized collection of symbols forms a legend for a map.
Etymology.
The word derives from the Greek "symbolon" meaning token or watchword. It is an amalgam of syn- "together" + bole "a throwing, a casting, the stroke of a missile, bolt, beam." The sense evolution in Greek is from "throwing things together" to "contrasting" to "comparing" to "token used in comparisons to determine if something is genuine." Hence, "outward sign" of something. The meaning "something which stands for something else" was first recorded in 1590, in Edmund Spenser's "Faerie Queene".
Definitions.
In considering the effect of a symbol on the psyche, in his seminal essay "The Symbol without Meaning" Joseph Campbell proposes the following definition:
"A symbol is an energy evoking, and directing, agent".
Later, expanding on what he means by this definition Campbell says:
Heinrich Zimmer gives a concise overview of the nature, and perennial relevance, of symbols.
In the book "Signs and Symbols, "it is stated that "A symbol ... is a visual image or sign representing an idea -- a deeper indicator of a universal truth."
Symbols are a means of complex communication that often can have multiple levels of meaning. This separates symbols from signs, as signs have only one meaning.
Human cultures use symbols to express specific ideologies and social structures and to represent aspects of their specific culture. Thus, symbols carry meanings that depend upon one’s cultural background; in other words, the meaning of a symbol is not inherent in the symbol itself but is culturally learned.
Symbols are the basis of all human understanding and serve as vehicles of conception for all human knowledge. Symbols facilitate understanding of the world in which we live, thus serving as the grounds upon which we make judgments. In this way, people use symbols not only to make sense of the world around them, but also to identify and cooperate in society through constitutive rhetoric.
Symbols and semiotics.
Semiotics is the study of signs, symbols, and signification as communicative behavior. Semiotics studies focus on the relationship of the signifier and the signified, also taking into account interpretation of visual cues, body language, sound, and other contextual clues. Semiotics is linked with both linguistics and psychology. Semioticians thus not only study what a symbol implies, but also how it got its meaning and how it functions to make meaning in society. Symbols allow the human brain continuously to create meaning using sensory input and decode symbols through both denotation and connotation.
Psychoanalysis, rhetoric, and archetypes.
Swiss psychoanalyst Carl Jung, who studied archetypes, proposed an alternative definition of symbol, distinguishing it from the term "sign". In Jung's view, a sign stands for something known, as a word stands for its referent. He contrasted this with "symbol", which he used to stand for something that is unknown and that cannot be made clear or precise. An example of a symbol in this sense is Christ as a symbol of the archetype called "self". For example, written languages are composed of a variety of different symbols that create words. Through these written words humans communicate with each other. Kenneth Burke described "Homo sapiens" as a "symbol-using, symbol making, and symbol misusing animal" to suggest that a person creates symbols as well as misuses them. One example he uses to indicate what he means by the misuse of symbol is the story of a man who, when told that a particular food item was whale blubber, could barely keep from throwing it up. Later, his friend discovered it was actually just a dumpling. But the man's reaction was a direct consequence of the symbol of "blubber" representing something inedible in his mind. In addition, the symbol of "blubber" was created by the man through various kinds of learning.
Burke goes on to describe symbols as also being derived from Sigmund Freud's work on condensation and displacement, further stating that symbols are not just relevant to the theory of dreams but also to "normal symbol systems". He says they are related through "substitution", where one word, phrase, or symbol is substituted for another in order to change the meaning. In other words, if one person does not understand a certain word or phrase, another person may substitute a synonym or symbol in order to get the meaning across. However, upon learning the new way of interpreting a specific symbol, the person may change his or her already-formed ideas to incorporate the new information.
Jean Dalby Clift says that people not only add their own interpretations to symbols, they also create personal symbols that represent their own understanding of their lives: what she calls "core images" of the person. She argues that symbolic work with these personal symbols or core images can be as useful as working with dream symbols in psychoanalysis or counseling.
William Indick suggests that the symbols that are commonly found in myth, legend, and fantasy fulfill psychological functions and hence are why archetypes such as "the hero," "the princess" and "the witch" have remained popular for centuries.
Paul Tillich.
Paul Tillich argued that, while signs are invented and forgotten, symbols are born and die. There are, therefore, dead and living symbols. A living symbol can reveal to an individual hidden levels of meaning and transcendent or religious realities. For Tillich a symbol always "points beyond itself" to something that is unquantifiable and mysterious: the symbol's "depth dimension". Symbols are complex, and their meanings can evolve as the individual or culture evolves. When a symbol loses its meaning and power for an individual or culture, it becomes a dead symbol. The Greek Gods might be an example of symbols that were once living for the ancient Greeks but whose meaning and power are now gone.
When a symbol becomes identified with the deeper reality to which it refers, it becomes idolatrous as the "symbol is taken for reality." The symbol itself is substituted for the deeper meaning it intends to convey. The unique nature of a symbol is that it gives access to deeper layers of reality which are otherwise inaccessible.
Role of context in symbolism.
A symbol's meaning may be modified by various factors including popular usage, history, and contextual intent.
Historical meaning.
This history of a symbol is one of many factors in determining a particular symbol's apparent meaning. Consequently, symbols with emotive power carry problems analogous to false etymologies.
Context.
The context of a symbol may change its meaning. Similar five-pointed stars might signify a law enforcement officer or a member of the armed services, depending upon the uniform.
Symbolic action.
A symbolic action is an action that has no, or little, practical effect but symbolizes, or signals, what the actor wants or believes. The action conveys meaning to the viewers.
Symbolic action may overlap with symbolic speech, such as the use of flag burning to express hostility or saluting the flag to express patriotism.
In response to intense public criticism, businesses, organizations, and governments may take symbolic actions rather than, or in addition to, directly addressing the identified problems.
Symbolic actions are sometimes derided as slacktivism.

</doc>
<doc id="37674" url="http://en.wikipedia.org/wiki?curid=37674" title="Duck">
Duck

Duck is the common name for a large number of species in the Anatidae family of birds which also includes swans and geese. The ducks are divided among several subfamilies in the Anatidae family; they do not represent a monophyletic group (the group of all descendants of a single common ancestral species) but a form taxon, since swans and geese are not considered ducks. Ducks are mostly aquatic birds, mostly smaller than the swans and geese, and may be found in both fresh water and sea water.
Ducks are sometimes confused with several types of unrelated water birds with similar forms, such as loons or divers, grebes, gallinules, and coots.
Etymology.
 The word "duck" comes from Old English *"dūce" "diver", a derivative of the verb *"dūcan" "to duck, bend down low as if to get under something, or dive", because of the way many species in the dabbling duck group feed by upending; compare with Dutch "duiken" and German "tauchen" "to dive".
This word replaced Old English "ened/ænid" "duck", possibly to avoid confusion with other Old English words, like "ende" "end" with similar forms. Other Germanic languages still have similar words for "duck", for example, Dutch "eend" "duck" and German "Ente" "duck". The word "ened/ænid" was inherited from Proto-Indo-European; compare: Latin "anas" "duck", Lithuanian "ántis" "duck", Ancient Greek "nēssa"/"nētta" (νῆσσα, νῆττα) "duck", and Sanskrit "ātí" "water bird", among others.
A duckling is a young duck in downy plumage or baby duck; but in the food trade young adult ducks ready for roasting are sometimes labelled "duckling".
A male duck is called a drake and the female duck is called a duck, or in ornithology a hen.
Morphology.
The overall body plan of ducks is elongated and broad, and the ducks are also relatively long-necked, albeit not as long-necked as the geese and swans. The body shape of diving ducks varies somewhat from this in being more rounded. The bill is usually broad and contains serrated lamellae, which are particularly well defined in the filter-feeding species. In the case of some fishing species the bill is long and strongly serrated. The scaled legs are strong and well developed, and generally set far back on the body, more so in the highly aquatic species. The wings are very strong and are generally short and pointed, and the flight of ducks requires fast continuous strokes, requiring in turn strong wing muscles. Three species of steamer duck are almost flightless, however. Many species of duck are temporarily flightless while moulting; they seek out protected habitat with good food supplies during this period. This moult typically precedes migration.
The drakes of northern species often have extravagant plumage, but that is moulted in summer to give a more female-like appearance, the "eclipse" plumage. Southern resident species typically show less sexual dimorphism, although there are exceptions like the paradise shelduck of New Zealand which is both strikingly sexually dimorphic and where the female's plumage is brighter than that of the male. The plumage of juvenile birds generally resembles that of the female.
Behaviour.
Feeding.
Ducks exploit a variety of food sources such as grasses, aquatic plants, fish, insects, small amphibians, worms, and small molluscs.
Dabbling ducks feed on the surface of water or on land, or as deep as they can reach by up-ending without completely submerging. Along the edge of the beak there is a comb-like structure called a pecten. This strains the water squirting from the side of the beak and traps any food. The pecten is also used to preen feathers and to hold slippery food items.
Diving ducks and sea ducks forage deep underwater. To be able to submerge more easily, the diving ducks are heavier than dabbling ducks, and therefore have more difficulty taking off to fly.
A few specialized species such as the mergansers are adapted to catch and swallow large fish.
The others have the characteristic wide flat beak adapted to dredging-type jobs such as pulling up waterweed, pulling worms and small molluscs out of mud, searching for insect larvae, and bulk jobs such as dredging out, holding, turning head first, and swallowing a squirming frog. To avoid injury when digging into sediment it has no cere, but the nostrils come out through hard horn.
Breeding.
The ducks are generally monogamous, although these bonds generally last only a single year. Larger species and the more sedentary species (like fast river specialists) tend to have pair-bonds that last numerous years. Most duck species breed once a year, choosing to do so in favourable conditions (spring/summer or wet seasons). Ducks also tend to make a nest before breeding, and after hatching to lead their ducklings to water. Mother ducks are very caring and protective of their young, but may abandon some of their ducklings if they are physically stuck in an area they cannot get out of (including nesting in an enclosed courtyard) or are not prospering due to genetic defects or sickness brought about by hypothermia, starvation, or disease. Ducklings can also be orphaned by inconsistent late hatching where a few eggs hatch after the mother has abandoned the nest and led her ducklings to water.
Most domestic ducks neglect their eggs and ducklings, and their eggs must be hatched under a broody hen or artificially.
Communication.
Females of most dabbling ducks make the classic "quack" sound, but despite widespread misconceptions, most species of duck do not "quack". In general, ducks make a wide range of calls, ranging from whistles, cooing, yodels and grunts. For example, the scaup – which are diving ducks – make a noise like "scaup" (hence their name). Calls may be loud displaying calls or quieter contact calls.
A common urban legend claims that duck quacks do not echo; however, this has been shown to be false. This myth was first debunked by the Acoustics Research Centre at the University of Salford in 2003 as part of the British Association's Festival of Science. It was also debunked in one of the earlier episodes of the popular Discovery Channel television show "MythBusters".
Distribution and habitat.
The ducks have a cosmopolitan distribution. A number of species manage to live on sub-Antarctic islands like South Georgia and the Auckland Islands. Numerous ducks have managed to establish themselves on oceanic islands such as Hawaii, New Zealand and Kerguelen, although many of these species and populations are threatened or have become extinct.
Some duck species, mainly those breeding in the temperate and Arctic Northern Hemisphere, are migratory; those in the tropics, however, are generally not. Some ducks, particularly in Australia where rainfall is patchy and erratic, are nomadic, seeking out the temporary lakes and pools that form after localised heavy rain. 
Predators.
Worldwide, ducks have many predators. Ducklings are particularly vulnerable, since their inability to fly makes them easy prey not only for predatory birds but also large fish like pike, crocodilians, and other aquatic hunters, including fish-eating birds such as herons. Ducks' nests are raided by land-based predators, and brooding females may be caught unaware on the nest by mammals, such as foxes, or large birds, such as hawks or owls.
Adult ducks are fast fliers, but may be caught on the water by large aquatic predators including big fish such as the North American muskie and the European pike. In flight, ducks are safe from all but a few predators such as humans and the peregrine falcon, which regularly uses its speed and strength to catch ducks.
Relationship with humans.
Domestication.
Ducks have many economic uses, being farmed for their meat, eggs, feathers, (particularly their down). They are also kept and bred by aviculturists and often displayed in zoos. Almost all the varieties of domestic ducks are descended from the mallard ("Anas platyrhynchos"), apart from the Muscovy duck ("Cairina moschata").
In many areas, wild ducks of various species (including ducks farmed and released into the wild) are hunted for food or sport, by shooting, or formerly by decoys. Because an idle floating duck or a duck squatting on land cannot react to fly or move quickly, "a sitting duck" has come to mean "an easy target".
Cultural references.
In 2002, psychologist Richard Wiseman and colleagues at the University of Hertfordshire, UK, finished a year-long LaughLab experiment, concluding that of all animals, ducks attract the most humor and silliness; he said, "If you're going to tell a joke involving an animal, make it a duck." The word "duck" may have become an inherently funny word in many languages, possibly because ducks are seen as silly in their looks or behavior. Of the many ducks in fiction, many are cartoon characters, such as Walt Disney's Donald Duck, and Warner Bros.' Daffy Duck. Howard the Duck started as a comic book character in 1973, made in 1986 into a movie. The 1992 Disney film "The Mighty Ducks", starring Emilio Estevez chose the duck as the mascot for the fictional youth hockey team who are protagonists of the movie, based on the duck being described as a fierce fighter. This led to the duck becoming the nickname and mascot for the eventual National Hockey League professional team Anaheim Ducks. The duck is also the nickname of the University of Oregon sports teams as well as the Long Island Ducks minor league baseball team.

</doc>
<doc id="37678" url="http://en.wikipedia.org/wiki?curid=37678" title="Denver (disambiguation)">
Denver (disambiguation)

Denver is the capital of the U.S. state of Colorado
Denver may also refer to:

</doc>
<doc id="37684" url="http://en.wikipedia.org/wiki?curid=37684" title="Libertarian Movement (Costa Rica)">
Libertarian Movement (Costa Rica)

The Libertarian Movement Party (Spanish: "Partido Movimiento Libertario"; PML) is a political party based on classical liberalism in Costa Rica.
It was founded in May 1994 and has since enjoyed a number of victories. It succeeded in getting attorney Otto Guevara elected to the Legislative Assembly in its first campaign in 1998. In 2002, Guevara ran for president (unsuccessfully, 1.7% of the vote), and the party at the legislative elections won 9.3% of the popular vote and 6 out of 57 seats. A few weeks after taking office, one Congressman left the party and became independent, leaving PML with five seats. In 2006, Guevara again ran for president (unsuccessfully, 8.4% of the vote), and the party at the legislative elections won 9.1% of the popular vote and 6 out of 57 seats. In the 2010 general election Guevara was again the PML's presidential candidate and received 20% of the popular vote.
In its 2014 electoral campaign, the party has taken a more socially conservative position, totally opposing the legalisation of abortion and rejecting homosexual couples' right to a marriage license.
Purpose.
The party claims to represent hundreds of thousands of Costa Rican citizens from all walks of life, tired of politics, parties, traditional politicians, and the country's deteriorating situation.

</doc>
<doc id="37686" url="http://en.wikipedia.org/wiki?curid=37686" title="Disabled sports">
Disabled sports

Disabled sports also adaptive sports or parasports, are sports played by persons with a disability, including physical and intellectual disabilities. As many disabled sports are based on existing able bodied sports, modified to meet the needs of persons with a disability, they are sometimes referred to as "adapted sports". However, not all disabled sports are adapted; several sports that have been specifically created for persons with a disability have no equivalent in able-bodied sports. Disability exists in four categories: physical, mental, permanent and temporary.
Organization and history.
Organized sport for athletes with a disability is generally divided into three broad disability groups: the deaf, people with physical disabilities, and people with intellectual disabilities. Each group has a distinct history, organization, competition program, and approach to sport.
Formal international competition in deaf sport began with the 1924 Paris "Silent Games", organized by the Comité International des Sports des Sourds, CISS (The International Committee of Sports for the Deaf). These games evolved into the modern Deaflympics, governed by the CISS. The CISS maintains separate games for deaf athletes based on their numbers, their special communication needs on the sports field, and the social interaction that is a vital part of sports.
Organized sport for persons with physical disabilities existed as early as 1911, when the "Cripples Olympiad" was held in the U.S.A. One of the successful athletes was Walter William Francis, a Welshman, who won both the running and wrestling championships. Later, events often developed out of rehabilitation programs. Following the Second World War, in response to the needs of large numbers of injured ex-service members and civilians, sport was introduced as a key part of rehabilitation. Sport for rehabilitation grew into recreational sport and then into competitive sport. The pioneer of this approach was Sir Ludwig Guttmann of the Stoke Mandeville Hospital in England. In 1948, while the Olympic Games were being held in London, he organized a sports competition for wheelchair athletes at Stoke Mandeville. This was the origin of the Stoke Mandeville Games, which evolved into the modern Paralympic Games. Currently, Paralympic sport is governed by the International Paralympic Committee, in conjunction with a wide range of other international sport organizations.
Sport for persons with intellectual disabilities began to be organized in the 1960s through the Special Olympics movement. This grew out of a series of summer camps organized by Eunice Kennedy Shriver, beginning in 1962. In 1968 the first international Special Olympics were held, in Chicago. Today, Special Olympics provides training and competition in a variety of sports for persons with intellectual disabilities.
Sport for persons with physical disabilities began to be organized in the US in the late 1960s through Disabled Sports USA. Disabled Sports USA was established in 1967 by disabled military veterans to help rehabilitate the war injured returning from Vietnam and originally named the National Amputee Skiers Association. Since then, Disabled Sports USA has become one of the largest national multi-sport, multi-disability organizations in the United States, serving more than 60,000 wounded warriors, youth and adults annually.
In 1986, the International Sports Federation for Persons with Intellectual Disability (INAS-FID) was formed to support elite competition for athletes with intellectual disabilities. This was established in contrast to the more participative, "sport for all" approach of Special Olympics. For a time, athletes with intellectual disabilities were included in the Paralympic Games. After a cheating scandal at the 2000 Summer Paralympics, where a number of athletes participating in intellectual disability events were revealed to not be disabled, INAS-FID athletes were banned from Paralympic competition, but the ban on intellectually disabled athletes has since been lifted.
In 2006, the Extremity Games was formed for people with limb loss or limb difference to compete in extreme sports. The College Park Industries, a manufacturer of prosthetic feet, organized this event to give amputee athletes a venue to compete in this increasingly popular sports genre also referred to as action sports. This annual event held in the summer in Orlando, FL includes competitions in skateboarding, wakeboarding, rock climbing, mountain biking, surfing, moto-x and kayaking. Various organizations, such as , have arisen to help empower and inspire disabled people through equipping and welcoming them into the extreme sports community.
In 2007, a group of San Diego, California-based athletes, coaches, volunteers, and parents split from Special Olympics Southern California to gain local control over disabled athletics programs. This group -- SPORTS for Exceptional Athletes (S4EA) -- serves people with developmental disabilities within the age range of 5 years old through adults. By combining people with and without disabilities, S4EA hopes that participating athletes will interact and form lasting bonds of friendship through shared sports and recreational activities in S4EA's served communities. Although the organization's focus is primarily San Diego County, S4EA has grown from this base to satellite programs in Ventura and Temecula, California.
Since 1988, the International Olympic Committee have chosen to validate Disabled Sports (physical disabilities) and incorporate it as a part of the Games: the staging of the Paralympic Games immediately follows the Olympic Games. This scheduling helps to foster greater interest in disabled sports. An investigation published on a Swiss website has shown that more and more International Sports Federations list disabled athletes than any other sportsmen or sportswomen.
Sports.
A wide range of sports have been adapted to be played by people with various disabilities, as well as several that are unique to disabled athletes. Within each movement, different sports are practised at different levels; for example, not all sports in the Paralympic movement are part of the Paralympic Games. In addition, many sports are practiced by persons with a disability outside the formal sports movements.
Inclusion.
Beginning in the late 1980s and early 1990s, work began within several countries and organizations to include athletes with disabilities in the able-bodied sport system. This included adding events for athletes with disabilities to major games such as the Olympic Games and the Commonwealth Games, and integration of these athletes into able-bodied sports organizations.
Since 1984, the Olympics have included exhibition events for Paralympic athletes. However, integration of full medal events has not taken place, and the status of athletes with a disability in the Olympic movement remains controversial.
Within the Commonwealth Games, athletes with a disability were first included in exhibition events in 1994, and at the 2002 Manchester Commonwealth Games they were included as full members of their national teams, making these the first fully inclusive international multi-sport games. This policy has continued with the 2006 Melbourne Commonwealth Games, where Canadian Chantal Petitclerc became the first athlete with a disability to carry her country's flag in the Opening Ceremonies of an integrated games.
Individual athletes such as swimmer Natalie du Toit and track athlete Oscar Pistorius have competed as equals against able bodied athletes at various events including the Olympic Games.
2013 the FIFA decided that Austrian footballer Martin Hofbauer can continue to play competitive football with prosthetics after he lost his right lower leg due to cancer.
The Self-Determination Theory has been one of the most proven theories on how athletes participate in competitions of this level. Studies have supported this theory especially in intellectually or developmentally disabled athletes. Studies have continued to question the motivation for joining such competitions like the Special Olympics as well as the Paralympic Games. The Motivations for joining the Special Olympics uncover themes among individuals and families for their participation or abstention from these Olympic programs.
Unified sports.
"Unified sports" involve teams made up of athletes with and without disabilities. Since the 1990s, Special Olympics Unified Sports have been promoting social inclusion through shared sports training and competition. This initiative has expanded globally and now involves more than 700,000 players in 127 countries worldwide. The principle behind Unified Sports is simple: training together and playing together is a quick path to friendship and understanding.
The NBA has been a major supporter of Unified Sports, sponsoring the annual NBA Cares Special Olympics Unified Basketball Game during the NBA All-Star Weekend. The Walt Disney Company, ESPN and Special Olympics are also working on a two-year global initiative that will leverage the power of sports to promote an environment of social inclusion and acceptance.

</doc>
<doc id="37688" url="http://en.wikipedia.org/wiki?curid=37688" title="Gaelic football">
Gaelic football

Gaelic football (Irish: "Peil Ghaelach"; short name "Peil" or "Caid"), commonly referred to as football or Gaelic, is an Irish team sport. It is a form of football derived from traditional Irish ball games. It is played between two teams of 15 players on a rectangular grass pitch. The objective of the sport is to score by passing the ball through the other team's goals (3 points) or a set of two upright posts separated by a crossbar 2.5 m above the ground (1 point).
Players advance the football, a spherical leather ball, up the field with a combination of carrying, bouncing, kicking, hand-passing, and soloing (dropping the ball and then toe-kicking the ball upward into the hands). In the game, two types of scores are possible: points and goals. A point is awarded for kicking or hand-passing the ball over the crossbar, signalled by the umpire raising a white flag. A goal is awarded for kicking the ball under the crossbar into the net, signalled by the umpire raising a green flag. Positions in Gaelic football are similar to that in other football codes, and comprise one goalkeeper, six backs, two midfielders, and six forwards, with a variable number of substitutes.
Gaelic football is one of four sports (collectively referred to as the "Gaelic games") controlled by the Gaelic Athletic Association (GAA), the largest sporting organisation in Ireland. Along with hurling and camogie, Gaelic football is one of the few remaining strictly amateur sports in the world, with players, coaches, and managers prohibited from receiving any form of payment. Gaelic football is mainly played on the island of Ireland, although units of the Association exist in other areas such as Great Britain and North America.
Gaelic football is the most popular sport in Ireland in terms of attendance, with the 2011 All-Ireland Senior Championship Final, held at Croke Park, Dublin, drawing an attendance of 82,300 people. Outside of Ireland, football is mainly played among members of the Irish diaspora. Gaelic Park in New York City is the largest purpose-built Gaelic sports venue outside of Ireland. Three major football competitions operate throughout the year: the National Football League and the All-Ireland Senior Championship operate on an inter-county basis, while the All-Ireland Club Championship is contested by individual clubs. The All-Ireland Senior Championship is run as a knock-out competition, with the top two counties meeting in the All-Ireland Football Final, considered the most prestigious event in Gaelic football.
Under the auspices of the GAA, Gaelic football is a male-only sport; however, the related sport of ladies' Gaelic football is governed by the Ladies' Gaelic Football Association. Similarities between Gaelic football and Australian rules football have allowed the development of international rules football, a hybrid sport, and a series of Test matches has been held regularly since 1998.
History.
Gaelic football was first codified in 1887, although it has links to older varieties of football played in Ireland and known collectively as "caid". Consequently, the name "caid" is used by some people to refer to present day Gaelic football.
The first legal reference of football in Ireland was in 1308, when John McCrocan, a spectator at a football game at "Novum Castrum de Leuan" (the New Castle of the Lyons or Newcastle) was charged with accidentally stabbing a player named William Bernard. A field near Newscastle, Co. Dublin is still known as the football field.
The Statute of Galway of 1527 allowed the playing of "foot balle" and archery but banned "'hokie' — the hurling of a little ball with sticks or staves" as well as other sports.
By the 17th century, the situation had changed considerably. The games had grown in popularity and were widely played. This was due to the patronage of the gentry. Now instead of opposing the games it was the gentry and the ruling class who were serving as patrons of the games. Games were organised between landlords with each team comprising 20 or more tenants. Wagers were commonplace with purses of up to 100 guineas (Prior, 1997).
The earliest record of a recognised precursor to the modern game date from a match in County Meath in 1670, in which catching and kicking the ball was permitted.
However even "foot-ball" was banned by the severe Sunday Observance Act of 1695, which imposed a fine of one shilling (a substantial amount at the time) for those caught playing sports. It proved difficult, if not impossible, for the authorities to enforce the Act and the earliest recorded inter-county match in Ireland was one between Louth and Meath, at Slane, in 1712, about which the poet James Dall McCuairt wrote a poem of 88 verses beginning "Ba haigeanta".
A six-a-side version was played in Dublin in the early 18th century, and 100 years later there were accounts of games played between County sides (Prior, 1997).
By the early 19th century, various football games, referred to collectively as "caid", were popular in Kerry, especially the Dingle Peninsula. Father W. Ferris described two forms of "caid": the "field game" in which the object was to put the ball through arch-like goals, formed from the boughs of two trees, and; the epic "cross-country game", which lasted the whole of a Sunday (after mass) and was won by taking the ball across a parish boundary. "Wrestling", "holding" opposing players, and carrying the ball were all allowed.
During the 1860s and 1870s, Rugby football started to become popular in Ireland. Trinity College, Dublin was an early stronghold of Rugby, and the rules of the (English) Football Association were codified in 1863 and distributed widely. By this time, according to Gaelic football historian Jack Mahon, even in the Irish countryside, "caid" had begun to give way to a "rough-and-tumble game", which even allowed tripping. Association football started to take hold, especially in Ulster, in the 1880s.
Limerick was the stronghold of the native game around this time, and the Commercials Club, founded by employees of Cannock's Drapery Store, was one of the first to impose a set of rules, which was adapted by other clubs in the city. Of all the Irish pastimes the GAA set out to preserve and promote, it is fair to say that Gaelic football was in the worst shape at the time of the association's foundation (GAA Museum, 2001).
Irish forms of football were not formally arranged into an organised playing code by the Gaelic Athletic Association (GAA) until 1887. The GAA sought to promote traditional Irish sports, such as hurling and to reject "foreign" (particularly English) imports. The first Gaelic football rules, showing the influence of hurling and a desire to differentiate from association football – for example in their lack of an offside rule — were drawn up by Maurice Davin and published in the "United Ireland" magazine on 7 February 1887. The rules of the aforementioned Commercials Club became the basis for these official (Gaelic Football) rules who, unsurprisingly, won the inaugural All-Ireland Senior Football Final (representing County Limerick)
On Bloody Sunday in 1920, during the Anglo-Irish War, a football match at Croke Park was attacked by British forces. 14 people were killed and 65 were injured. Among the dead was Tipperary footballer Michael Hogan, for whom the Hogan Stand at Croke Park (completed in 1924) was named.
Ladies' Gaelic football has become increasingly popular with women since the 1970s.
The relationship between Gaelic football and Australian rules football and the question of whether they have shared origins is a matter of historical controversy. Games are held between an Irish representative team and an Australian team, under compromise rules known as international rules football.
Rules.
Playing field.
A Gaelic pitch is similar in some respects to a rugby pitch but larger. The grass pitch is rectangular, stretching 130 - long and 80 - wide. There are H-shaped goalposts at each end, formed by two posts, which are usually 6 - high, set 6.5 m apart, and connected 2.5 m above the ground by a crossbar. A net extending behind the goal is attached to the crossbar and lower goal posts. The same pitch is used for hurling; the GAA, which organises both sports, decided this to facilitate dual usage. Lines are marked at distances of 13 metres, 20 metres and 45 metres (65m in Hurling) from each end-line. Shorter pitches and smaller goals are used by youth teams.
Duration.
The majority of adult football and all minor and under-21 matches last for 60 minutes, divided into two halves of 30 minutes, with the exception of senior inter-county games, which last for 70 minutes (two halves of 35 minutes). Draws are decided by replays or by playing 20 minutes of extra time (two halves of 10 minutes). Juniors have a half of 20 minutes or 25 minutes in some cases. Half-time lasts for about 5 or 10 minutes.
Teams.
Teams consist of fifteen players (a goalkeeper, two corner backs, a full back, two wing backs, a centre back, two mid fielders, two wing forwards, a centre forward, two corner forwards and a full forward) plus up to fifteen substitutes, of which five may be used. Each player is numbered 1–15, starting with the goalkeeper, who must wear a jersey colour different from that of his or her teammates. Up to fifteen substitutes may be named on the team sheet, number 16 usually being the reserve goalkeeper.
Ball.
The game is played with a round leather football made of 18 stitched leather panels, similar in appearance to a traditional volleyball (but larger), with a circumference of 69 -, weighing between 370 - when dry. It may be kicked or "hand passed". A hand pass is not a punch but rather a strike of the ball with the side of the closed fist, using the knuckle of the thumb.
Types of Fouls.
There are three main types of fouls in Gaelic Football, which can result in the ball being given to the other team, a player being cautioned, a player being removed from the field, or even the game being terminated.
Technical fouls.
The following are considered technical fouls ("fouling the ball"):
Aggressive Fouls.
Aggressive fouls are physical or verbal fouls committed by a player against an opponent or the referee. The player can be cautioned (shown a yellow card), ordered off the pitch without a substitute (red card), or (beginning 1 January 2014) ordered off the pitch with a substitution (Black Card).
Dissent Fouls.
A dissent foul is a foul where a player fails to comply with the officials' judgment and/or instructions. The player can be cautioned (shown a yellow card), ordered off the pitch without a substitute (red card), the free kick placement moved 13m further down-field, or in certain circumstances, the game can be terminated.
The following are considered dissent fouls:
Scoring.
If the ball goes over the crossbar, a "point" is scored and a white flag is raised by an umpire. A point is scored by either kicking the ball over the crossbar, or fisting it over, in which case the hand must be closed while striking the ball. If the ball goes below the crossbar, a "goal", worth three points, is scored, and a green flag is raised by an umpire. A goal is scored by kicking the ball into the net, not by fist passing the ball into it. However, a player can strike the ball into the net with a closed fist if the ball was played to him by another player or came in contact with the post/crossbar/ground prior to connection. The goal is guarded by a goalkeeper. Scores are recorded in the format Goal Total-Point Total. To determine the score-line goals must be converted to points and added to the other points. For example, in a match with a final score of Team A 0–21 Team B 4–8, Team A is the winner with 21 points, as Team B scored only 20 points (4 times 3, plus 8).
Tackling.
The level of tackling allowed is more robust than in association football, but less than rugby.
Shoulder to shoulder contact and slapping the ball out of an opponent's hand are permitted, but the following are all fouls:
Officials.
A football match is overseen by up to eight officials:
The referee is responsible for starting and stopping play, recording the score, awarding frees and booking and sending off players.
Linesmen are responsible for indicating the direction of line balls to the referee.
The fourth official is responsible for overseeing substitutions, and also indicating the amount of stoppage time (signalled to him by the referee) and the players substituted using an electronic board.
The umpires are responsible for judging the scoring. They indicate to the referee whether a shot was: wide (spread both arms), a 45m kick (raise one arm), a point (wave white flag), square ball (cross arms) or a goal (wave green flag). A disallowed score is indicated by crossing the green and white flags.
Other officials are not obliged to indicate any misdemeanours to the referee; they are only permitted to inform the referee of violent conduct they have witnessed that has occurred without the referee's knowledge. A linesman/umpire is not permitted to inform the referee of technical fouls such as a "double bounce" or an illegal pick up of the ball. Such decisions can only be made at the discretion of the referee.
Team of the Century.
The Team of the Century was nominated in 1984 by "Sunday Independent" readers and selected by a panel of experts including journalists and former players. It was chosen as part of the Gaelic Athletic Association's centenary year celebrations. The goal was to single out the best ever 15 players who had played the game in their respective positions. Naturally many of the selections were hotly debated by fans around the country.
Team of the Millennium.
The Team of the Millennium was a team chosen in 1999 by a panel of GAA past presidents and journalists. The goal was to single out the best ever 15 players who had played the game in their respective positions, since the foundation of the GAA in 1884 up to the Millennium year, 2000. Naturally many of the selections were hotly debated by fans around the country.
Gaelic football rankings.
The Gaelic football rankings is an unofficial ranking system for men's county teams in Gaelic football. The county teams are ranked based on their game results, with the most successful teams being ranked highest.
In this exchange-based point system, points are awarded based on the results of National Football League and All-Ireland Senior Football Championship games, with more recent results and more significant matches being more heavily weighted to help reflect the current competitive state of a team. The rankings have been computed based on results from 1 May 1994.
Competition structure.
Gaelic sports at all levels are amateur, in the sense that the athletes – even those playing at elite level – do not receive payment for their performance "per se". Easing the strictness with which this is interpreted is advocated by the Gaelic Players Association.
The main competitions at all levels of Gaelic football are the League and the Championship. Of these it is the Championship (a knock-out tournament) that tends to attain the most prestige.
The basic unit of each game is organised at the club level, which is usually arranged on a parochial basis. Local clubs compete against other clubs in their county with the intention of winning the County Championship at senior, junior or intermediate levels (for adults) or under-21, minor or under-age levels (for children). A club may field more than one team, for example a club may field a team at senior level and a "seconds" team at junior or intermediate level. This format is laid out in the table below:
Though the island of Ireland was partitioned between two states by the British parliament in 1920, the organisation of Gaelic games (like that of most cultural organisations and religions) continues on an All-Ireland basis. At national level, Ireland's Gaelic games are organised in 32 GAA counties, most of which are identical in name and extent to the 32 administrative counties on which local government throughout the island was based until the late 20th century. The term "county" is also used for some overseas GAA areas, such as London and New York. Clubs are also located throughout the world, in other parts of the United States, in Britain, in Canada, in Asia, in Australasia and in continental Europe.
The level at which county teams compete against each other is referred to as inter-county (i.e. similar to international) A county panel – a team of 15 players, plus a similar number of substitutes – is formed from the best players playing at club level in each county. The most prestigious inter-county competition in Gaelic football is the All-Ireland Championship. The highest level national championship is called the All-Ireland Senior Football Championship. Nearly all counties contest this tournament on an annual basis, with crowds of people thronging venues the length and breadth of Ireland – the most famous of these stadiums being Croke Park – to support their local county team, a team comprising players selected from the clubs in that county. These modified knock-out games start as provincial championships contested by counties against other counties in their respective province, the four Irish provinces of Ulster, Munster, Leinster and Connacht. The four victors in these then progress automatically to the All-Ireland series.
In the past, the team winning each provincial championship would play one of the others, at a stage known as the All-Ireland semi-finals, with the winning team from each game playing each other in the famed All-Ireland Final to determine the outright winner. A recent (1990s/2000s) re-organisation created a "back door" method of qualifying, with teams knocked out during the provincial rounds of the All-Ireland Championship now acquiring a second chance at glory. Now the four victorious teams at provincial level enter the recently created All-Ireland quarter-finals instead, where they compete against the four remaining teams from the All-Ireland Qualifiers to progress to the All-Ireland semi-finals and then the All-Ireland Final. This re-organisation means that one team may defeat another team in an early stage of the championship, yet be defeated and knocked out of the tournament by the same team at a later stage. It also means a team may be defeated in an early stage of the championship, yet be crowned All-Ireland champions—as Tyrone were in 2005 and 2008.
The secondary competition at inter-county level is the National League. The National Football League is held every spring and groups counties in four divisions according to their relative strength. As at local (county) levels of Gaelic football, the League at national level is less prestigious than the Championship—however, in recent years attendances have grown, as has interest from the public and from players. This is due in part to the 2002 adoption of a February–April timetable, in place of the former November start, as well as the provision of Division 2 final stages. Live matches are aired on the international channel Setanta Sports and the Irish language channel TG4, with highlights shown on RTÉ Two.
There are also All-Ireland championships for county teams at Junior, Under-21 and Minor levels, and provincial and national club championships, contested by the teams that win their respective county championships.

</doc>
<doc id="37689" url="http://en.wikipedia.org/wiki?curid=37689" title="Martin Brennan (engineer)">
Martin Brennan (engineer)

Martin Brennan is a computer engineer who developed pioneering personal computers such as the Loki (for Sinclair Research) and the Atari Jaguar video game console.
A physics graduate of Cambridge University, he was a co-founder of Flare Technology, a design house involved in the design of the ill-fated Konix Multisystem.
Brennan initially worked for Sinclair Research where he designed the digital electronics and software in ZX Interface 1 before going on to found Flare with ex-Sinclair colleagues John Mathieson and Ben Cheese. After working at Flare on the "Flare 1" and its development into the Konix Multisystem he went on to work for Atari developing the Atari Panther and the Atari Jaguar.
In 1997 Brennan founded the "Cheap & Cheerful Chip Company" which later went on to become Global Silicon Limited
In 2007 Brennan designed the Brennan JB7 digital jukebox produced by 3GA Ltd (Third Generation Audio)

</doc>
<doc id="37694" url="http://en.wikipedia.org/wiki?curid=37694" title="Seed">
Seed

A seed is an embryonic plant enclosed in a protective outer covering called the seed coat, usually with some stored food. It is a characteristic of spermatophytes (gymnosperm and angiosperm plants) and the product of the ripened ovule which occurs after fertilization and some growth within the mother plant. The formation of the seed completes the process of reproduction in seed plants (started with the development of flowers and pollination), with the embryo developed from the zygote and the seed coat from the integuments of the ovule.
Seeds have been an important development in the reproduction and spread of gymnosperm and angiosperm plants, relative to more primitive plants such as ferns, mosses and liverworts, which do not have seeds and use other means to propagate themselves. This can be seen by the success of seed plants (both gymnosperms and angiosperms) in dominating biological niches on land, from forests to grasslands both in hot and cold climates.
The term "seed" also has a general meaning that antedates the above—anything that can be sown, e.g. "seed" potatoes, "seeds" of corn or sunflower "seeds". In the case of sunflower and corn "seeds", what is sown is the seed enclosed in a shell or husk, whereas the potato is a tuber.
Many structures commonly referred to as "seeds" are actually dry fruits. Plants producing berries are called baccate. Sunflower seeds are sometimes sold commercially while still enclosed within the hard wall of the fruit, which must be split open to reach the seed. Different groups of plants have other modifications, the so-called stone fruits (such as the peach) have a hardened fruit layer (the endocarp) fused to and surrounding the actual seed. Nuts are the one-seeded, hard-shelled fruit of some plants with an indehiscent seed, such as an acorn or hazelnut.
Production.
Seeds are produced in several related groups of plants, and their manner of production distinguishes the angiosperms ("enclosed seeds") from the gymnosperms ("naked seeds"). Angiosperm seeds are produced in a hard or fleshy structure called a fruit that encloses the seeds, hence the name. (Some fruits have layers of both hard and fleshy material). In gymnosperms, no special structure develops to enclose the seeds, which begin their development "naked" on the bracts of cones. However, the seeds do become covered by the cone scales as they develop in some species of conifer.
Seed production in natural plant populations vary widely from year-to-year in response to weather variables, insects and diseases, and internal cycles within the plants themselves. Over a 20-year period, for example, forests composed of loblolly pine and shortleaf pine produced from 0 to nearly 5 million sound pine seeds per hectare. Over this period, there were six bumper, five poor, and nine good seed crops, when evaluated in regard to producing adequate seedlings for natural forest reproduction.
Development.
Angiosperm (flowering plants) seeds consist of three genetically distinct constituents: (1) the embryo formed from the zygote, (2) the endosperm, which is normally triploid, (3) the seed coat from tissue derived from the maternal tissue of the ovule. In angiosperms, the process of seed development begins with double fertilization, which involves the fusion of two male gametes with the egg cell and the central cell to form the primary endosperm and the zygote. Right after fertilization, the zygote is mostly inactive, but the primary endosperm divides rapidly to form the endosperm tissue. This tissue becomes the food the young plant will consume until the roots have developed after germination.
Ovule.
After fertilization the ovules develop into the seeds. The ovule consists of a number of components:
The shape of the ovules as they develop often affects the final shape of the seeds. Plants generally produce ovules of four shapes: the most common shape is called anatropous, with a curved shape. Orthotropous ovules are straight with all the parts of the ovule lined up in a long row producing an uncurved seed. Campylotropous ovules have a curved megagametophyte often giving the seed a tight "C" shape. The last ovule shape is called amphitropous, where the ovule is partly inverted and turned back 90 degrees on its stalk (the funicle or funiculus).
In the majority of flowering plants, the zygote's first division is transversely oriented in regards to the long axis, and this establishes the polarity of the embryo. The upper or chalazal pole becomes the main area of growth of the embryo, while the lower or micropylar pole produces the stalk-like suspensor that attaches to the micropyle. The suspensor absorbs and manufacturers nutrients from the endosperm that are used during the embryo's growth.
Embryo.
The main components of the embryo are:
Monocotyledonous plants have two additional structures in the form of sheaths. The plumule is covered with a coleoptile that forms the first leaf while the radicle is covered with a coleorhiza that connects to the primary root and adventitious roots form from the sides. Here the hypocotyl is a rudimentary axis between radicle and plumule. The seeds of corn are constructed with these structures; pericarp, scutellum (single large cotyledon) that absorbs nutrients from the endosperm, plumule, radicle, coleoptile and coleorhiza—these last two structures are sheath-like and enclose the plumule and radicle, acting as a protective covering.
Seed coat.
The maturing ovule undergoes marked changes in the integuments, generally a reduction and disorganisation but occasionally a thickening. The seed coat forms from the two integuments or outer layers of cells of the ovule, which derive from tissue from the mother plant, the inner integument forms the tegmen and the outer forms the testa. (The seed coats of some mononocotyledon plants, such as the grasses, are not distinct structures, but are fused with the fruit wall to form a pericarp.) The testae of both monocots and dicots are often marked with patterns and textured markings, or have wings or tufts of hair. When the seed coat forms from only one layer, it is also called the testa, though not all such testae are homologous from one species to the next. The funiculus abscises (detaches at fixed point - abscission zone), the scar forming an oval depression, the hilum. Anatropous ovules have a portion of the funiculus that is adnate (fused to the seed coat), and which forms a longitudinal ridge, or raphe, just above the hilum. In bitegmic ovules (e.g. "Gossypium" described here) both inner and outer integuments contribute to the seed coat formation. With continuing maturation the cells enlarge in the outer integument. While the inner epidermis may remain a single layer, it may also divide to produce two to three layers and accumulates starch, and is referred to as the colourless layer. By contrast the outer epidermis becomes tanniferous. The inner integument may consist of eight to fifteen layers. (Kozlowski 1972)
As the cells enlarge, and starch is deposited in the outer layers of the pigmented zone below the outer epidermis, this zone begins to lignify, while the cells of the outer epidermis enlarge radially and their walls thicken, with nucleus and cytoplasm compressed into the outer layer. these cells which are broader on their inner surface are called palisade cells. In the inner epidermis the cells also enlarge radially with plate like thickening of the walls. The mature inner integument has a palisade layer, a pigmented zone with 15-20 layers, while the innermost layer is known as the fringe layer. (Kozlowski 1972)
Gymnosperms.
In gymnosperms, which do not form ovaries, the ovules and hence the seeds are exposed. This is the basis for their nomenclature - naked seeded plants (gymnosperms). Two sperm cells transferred from the pollen do not develop seed by double fertilization, but one sperm nucleus unites with the egg nucleus and the other sperm is not used. Sometimes each sperm fertilizes an egg cell and one zygote is then aborted or absorbed during early development. The seed is composed of the embryo (the result of fertilization) and tissue from the mother plant, which also form a cone around the seed in coniferous plants such as pine and spruce.
Shape and appearance.
A large number of terms are used to describe seed shapes, many of which are largely self-explanatory such as "Bean-shaped" (reniform) - resembling a kidney, with lobed ends on either side of the hilum, "Square" or "Oblong" - angular with all sides more or less equal or longer than wide, "Triangular" - three sided, broadest below middle, "Elliptic" or "Ovate" or "Obovate" - rounded at both ends, or egg shaped (ovate or obovate, broader at one end), being rounded but either symmetrical about the middle or broader below the middle or broader above the middle.
Other less obvious terms include discoid (resembling a disc or plate, having both thickness and parallel faces and with a rounded margin), ellipsoid, globose (spherical), or subglobose (Inflated, but less than spherical), lenticular, oblong, ovoid, reniform and sectoroid. Striate seeds are striped with parallel, longitudinal lines or ridges. The commonest colours are brown and black, other colours are infrequent. The surface varies from highly polished to considerably roughened. The surface may have a variety of appendages (see Seed coat). A seed coat with the consistency of cork is referred to as suberose. Other terms include crustaceous (hard, thin or brittle).
Structure.
A typical seed includes two basic parts:
In addition, the Endosperm forms a supply of nutrients for the embryo in most monocotyledons and the endospermic dicotyledons.
Seed types.
Seed have been considered to occur in twelve separate types (Martin 1946). These are based on a number of criteria, of which the dominant one is the "embryo to seed" size ratios. This reflects the degree to which the developing cotyledons absorb the nutrients of the endosperm, and this obliterate it. (The Seed Biology Place)
Six types occur amongst the monocotyledons, ten in the dicotyledons, and two in the gymnosperms (Linear and spatulate). This classification is based on three characteristics: embryo morphology, amount of endosperm and the position of the embryo relative to the endosperm. These types are:
Embryo.
In endospermic seeds, there are two distinct regions inside the seed coat, an upper and larger endosperm and a lower smaller embryo. The embryo is the fertilised ovule, an immature plant from which a new plant will grow under proper conditions. The embryo has one cotyledon or seed leaf in monocotyledons, two cotyledons in almost all dicotyledons and two or more in gymnosperms. In the fruit of grains (caryopses) the single monocotyledon is shield shaped and hence called a scutellum. The scutellum is pressed closely against the endosperm from which it absorbs food, and passes it to the growing parts. Embryo descriptors include small, straight, bent, curved and curled.
Nutrient storage.
Within the seed, there usually is a store of nutrients for the seedling that will grow from the embryo. The form of the stored nutrition varies depending on the kind of plant. In angiosperms, the stored food begins as a tissue called the endosperm, which is derived from the mother plant and the pollen via double fertilization. It is usually triploid, and is rich in oil or starch, and protein. In gymnosperms, such as conifers, the food storage tissue (also called endosperm) is part of the female gametophyte, a haploid tissue. The endosperm is surrounded by the aleurone layer (peripheral endosperm), filled with proteinaceous aleurone grains.
Originally, by analogy with the animal ovum, the outer nucellus layer (perisperm) was referred to as albumen, and the inner endosperm layer as vitellus. Although misleading, the term began to be applied to all the nutrient matter. This terminology persists in referring to endospermic seeds as 'albuminous'. The nature of this material is used in both describing and classifying seeds, in addition to the embryo to endosperm size ratio. The endosperm may be considered to be farinaceous (or mealy) in which the cells are filled with starch, as for instance cereal grains, or not (non-farinaceous). The endosperm may also be referred to as 'fleshy' or 'cartilaginous' with thicker soft cells such as coconut, but may also be oily as in "Ricinus" (castor oil), "Croton" and Poppy. The endosperm is called 'horny' when the cell walls are thicker such as date and coffee, or 'ruminated' if mottled, as in nutmeg, palms and Anonaceae.
In most monocotyledons (such as grasses and palms) and some (endospermic or albuminous) dicotyledons (such as Brazil nuts and castor beans) the embryo is embedded in the endosperm (and nucellus, which the seedling will use upon germination. In the non-endospermic dicotyledons the endosperm is absorbed by the embryo as the latter grows within the developing seed, and the cotyledons of the embryo become filled with stored food. At maturity, seeds of these species have no endosperm and are also referred to as exalbuminous seeds. The exalbuminous seeds include the legumes (such as beans and peas), trees such as the oak and walnut, vegetables such as squash and radish, and sunflowers. All gymnosperm seeds are albuminous.
Seed coat.
The seed coat develops from the material tissue, the integuments, originally surrounding the ovule. The seed coat in the mature seed can be a paper-thin layer (e.g. peanut) or something more substantial (e.g. thick and hard in honey locust and coconut), or fleshy as in the sarcotesta of pomegranate. The seed coat helps protect the embryo from mechanical injury, predators and drying out. Depending on its development, the seed coat is either bitegmic or unitegmic. Bitegmic seeds form a testa from the outer integument and a tegmen from the inner integument while unitegmic seeds have only one integument. Usually parts of the testa or tegmen form a hard protective mechanical layer. The mechanical layer may prevent water penetration and germination. Amongst the barriers may be the presence of lignified sclereids.
The outer integument has a number of layers, generally between four and eight organised into three layers: (a) outer epidermis, (b) outer pigmented zone of two to five layers containing tannin and starch, and (c) inner epidermis. The endotegmen is derived from the inner epidermis of the inner integument, the exotegmen from the outer surface of the inner integument. The endotesta is derived from the inner epidermis of the outer integument, and the outer layer of the testa from the outer surface of the outer integument is referred to as the exotesta. If the exotesta is also the mechanical layer, this is called an exotestal seed, but if the mechanical layer is the endotegmen, then the seed is endotestal. The exotesta may consist of one or more rows of cells that are elongated and pallisade like (e.g. Fabaceae), hence 'palisade exotesta'.
In addition to the three basic seed parts, some seeds have an appendage, an aril, a fleshy outgrowth of the funicle (funiculus), (as in yew and nutmeg) or an oily appendage, an elaiosome (as in "Corydalis"), or hairs (trichomes). In the latter example these hairs are the source of the textile crop cotton. Other seed appendages include the raphe (a ridge), wings, caruncles (a soft spongy outgrowth from the outer integument in the vicinity of the micropyle), spines, or tubercles.
A scar also may remain on the seed coat, called the hilum, where the seed was attached to the ovary wall by the funicle. Just below it is a small pore, representing the micropyle of the ovule.
Size and seed set.
Seeds are very diverse in size. The dust-like orchid seeds are the smallest, with about one million seeds per gram; they are often embryonic seeds with immature embryos and no significant energy reserves. Orchids and a few other groups of plants are mycoheterotrophs which depend on mycorrhizal fungi for nutrition during germination and the early growth of the seedling. Some terrestrial orchid seedlings, in fact, spend the first few years of their lives deriving energy from the fungi and do not produce green leaves. At over 20 kg, the largest seed is the "coco de mer". Plants that produce smaller seeds can generate many more seeds per flower, while plants with larger seeds invest more resources into those seeds and normally produce fewer seeds. Small seeds are quicker to ripen and can be dispersed sooner, so fall blooming plants often have small seeds. Many annual plants produce great quantities of smaller seeds; this helps to ensure at least a few will end in a favorable place for growth. Herbaceous perennials and woody plants often have larger seeds; they can produce seeds over many years, and larger seeds have more energy reserves for germination and seedling growth and produce larger, more established seedlings after germination.
Functions.
Seeds serve several functions for the plants that produce them. Key among these functions are nourishment of the embryo, dispersal to a new location, and dormancy during unfavorable conditions. Seeds fundamentally are means of reproduction, and most seeds are the product of sexual reproduction which produces a remixing of genetic material and phenotype variability on which natural selection acts.
Embryo nourishment.
Seeds protect and nourish the embryo or young plant. They usually give a seedling a faster start than a sporeling from a spore, because of the larger food reserves in the seed and the multicellularity of the enclosed embryo.
Dispersal.
Unlike animals, plants are limited in their ability to seek out favorable conditions for life and growth. As a result, plants have evolved many ways to disperse their offspring by dispersing their seeds (see also vegetative reproduction). A seed must somehow "arrive" at a location and be there at a time favorable for germination and growth. When the fruits open and release their seeds in a regular way, it is called dehiscent, which is often distinctive for related groups of plants; these fruits include capsules, follicles, legumes, silicles and siliques. When fruits do not open and release their seeds in a regular fashion, they are called indehiscent, which include the fruits achenes, caryopsis, nuts, samaras, and utricles.
Seed dispersal is seen most obviously in fruits; however, many seeds aid in their own dispersal. Some kinds of seeds are dispersed while still inside a fruit or cone, which later opens or disintegrates to release the seeds. Other seeds are expelled or released from the fruit prior to dispersal. For example, milkweeds produce a fruit type, known as a "follicle", that splits open along one side to release the seeds. Iris capsules split into three "valves" to release their seeds.
By wind (anemochory).
Other seeds are enclosed in fruit structures that aid wind dispersal in similar ways:
By animals (zoochory).
Myrmecochory is the dispersal of seeds by ants. Foraging ants disperse seeds which have appendages called elaiosomes (e.g. bloodroot, trilliums, Acacias, and many species of Proteaceae). Elaiosomes are soft, fleshy structures that contain nutrients for animals that eat them. The ants carry such seeds back to their nest, where the elaiosomes are eaten. The remainder of the seed, which is hard and inedible to the ants, then germinates either within the nest or at a removal site where the seed has been discarded by the ants. This dispersal relationship is an example of mutualism, since the plants depend upon the ants to disperse seeds, while the ants depend upon the plants seeds for food. As a result, a drop in numbers of one partner can reduce success of the other. In South Africa, the Argentine ant ("Linepithema humile") has invaded and displaced native species of ants. Unlike the native ant species, Argentine ants do not collect the seeds of "Mimetes cucullatus" or eat the elaiosomes. In areas where these ants have invaded, the numbers of "Mimetes" seedlings have dropped.
Dormancy.
Seed dormancy has two main functions: the first is synchronizing germination with the optimal conditions for survival of the resulting seedling; the second is spreading germination of a batch of seeds over time so a catastrophe after germination (e.g. late frosts, drought, herbivory) does not result in the death of all offspring of a plant (bet-hedging). Seed dormancy is defined as a seed failing to germinate under environmental conditions optimal for germination, normally when the environment is at a suitable temperature with proper soil moisture. This true dormancy or innate dormancy is therefore caused by conditions within the seed that prevent germination. Thus dormancy is a state of the seed, not of the environment. Induced dormancy, enforced dormancy or seed quiescence occurs when a seed fails to germinate because the external environmental conditions are inappropriate for germination, mostly in response to conditions being too dark or light, too cold or hot, or too dry.
Seed dormancy is not the same as seed persistence in the soil or on the plant, though even in scientific publications dormancy and persistence are often confused or used as synonyms.
Often, seed dormancy is divided into four major categories: exogenous; endogenous; combinational; and secondary. A more recent system distinguishes five classes: morphological, physiological, morphophysiological, physical and combinational dormancy.
Exogenous dormancy is caused by conditions outside the embryo, including:
Endogenous dormancy is caused by conditions within the embryo itself, including:
The following types of seed dormancy do not involve seed dormancy, strictly speaking, as lack of germination is prevented by the environment, not by characteristics of the seed itself (see Germination):
Not all seeds undergo a period of dormancy. Seeds of some mangroves are viviparous; they begin to germinate while still attached to the parent. The large, heavy root allows the seed to penetrate into the ground when it falls. Many garden plant seeds will germinate readily as soon as they have water and are warm enough; though their wild ancestors may have had dormancy, these cultivated plants lack it. After many generations of selective pressure by plant breeders and gardeners, dormancy has been selected out.
For annuals, seeds are a way for the species to survive dry or cold seasons. Ephemeral plants are usually annuals that can go from seed to seed in as few as six weeks.
Germination.
Seed germination is a process by which a seed embryo develops into a seedling. It involves the reactivation of the metabolic pathways that lead to growth and the emergence of the radicle or seed root and plumule or shoot. The emergence of the seedling above the soil surface is the next phase of the plant's growth and is called seedling establishment.
Three fundamental conditions must exist before germination can occur. (1) The embryo must be alive, called seed viability. (2) Any dormancy requirements that prevent germination must be overcome. (3) The proper environmental conditions must exist for germination.
Seed viability is the ability of the embryo to germinate and is affected by a number of different conditions. Some plants do not produce seeds that have functional complete embryos, or the seed may have no embryo at all, often called empty seeds. Predators and pathogens can damage or kill the seed while it is still in the fruit or after it is dispersed. Environmental conditions like flooding or heat can kill the seed before or during germination. The age of the seed affects its health and germination ability: since the seed has a living embryo, over time cells die and cannot be replaced. Some seeds can live for a long time before germination, while others can only survive for a short period after dispersal before they die.
Seed vigor is a measure of the quality of seed, and involves the viability of the seed, the germination percentage, germination rate and the strength of the seedlings produced.
The germination percentage is simply the proportion of seeds that germinate from all seeds subject to the right conditions for growth. The germination rate is the length of time it takes for the seeds to germinate. Germination percentages and rates are affected by seed viability, dormancy and environmental effects that impact on the seed and seedling. In agriculture and horticulture quality seeds have high viability, measured by germination percentage plus the rate of germination. This is given as a percent of germination over a certain amount of time, 90% germination in 20 days, for example. 'Dormancy' is covered above; many plants produce seeds with varying degrees of dormancy, and different seeds from the same fruit can have different degrees of dormancy. It's possible to have seeds with no dormancy if they are dispersed right away and do not dry (if the seeds dry they go into physiological dormancy). There is great variation amongst plants and a dormant seed is still a viable seed even though the germination rate might be very low.
Environmental conditions effecting seed germination include; water, oxygen, temperature and light.
Three distinct phases of seed germination occur: water imbibition; lag phase; and radicle emergence.
In order for the seed coat to split, the embryo must imbibe (soak up water), which causes it to swell, splitting the seed coat. However, the nature of the seed coat determines how rapidly water can penetrate and subsequently initiate germination. The rate of imbibition is dependent on the permeability of the seed coat, amount of water in the environment and the area of contact the seed has to the source of water. For some seeds, imbibing too much water too quickly can kill the seed. For some seeds, once water is imbibed the germination process cannot be stopped, and drying then becomes fatal. Other seeds can imbibe and lose water a few times without causing ill effects, but drying can cause secondary dormancy.
Repair of DNA damage.
During seed dormancy, often associated with unpredictable and stressful environments, DNA damages accumulate as the seeds age. In rye seeds, the reduction of DNA integrity due to damage is associated with loss of seed viability during storage. Upon germination, seeds of "Vicia faba" undergo DNA repair. A plant DNA ligase that is involved in repair of single- and double-strand breaks during seed germination is an important determinant of seed longevity. Also, in Arabidopsis seeds, the activities of the DNA repair enzymes Poly ADP ribose polymerases (PARP) are likely needed for successful germination. Thus DNA damages that accumulate during dormancy appear to be a problem for seed survival, and the enzymatic repair of DNA damages during germination appears to be important for seed viability.
Inducing germination.
A number of different strategies are used by gardeners and horticulturists to break seed dormancy.
Scarification allows water and gases to penetrate into the seed; it includes methods to physically break the hard seed coats or soften them by chemicals, such as soaking in hot water or poking holes in the seed with a pin or rubbing them on sandpaper or cracking with a press or hammer. Sometimes fruits are harvested while the seeds are still immature and the seed coat is not fully developed and sown right away before the seed coat become impermeable. Under natural conditions, seed coats are worn down by rodents chewing on the seed, the seeds rubbing against rocks (seeds are moved by the wind or water currents), by undergoing freezing and thawing of surface water, or passing through an animal's digestive tract. In the latter case, the seed coat protects the seed from digestion, while often weakening the seed coat such that the embryo is ready to sprout when it is deposited, along with a bit of fecal matter that acts as fertilizer, far from the parent plant. Microorganisms are often effective in breaking down hard seed coats and are sometimes used by people as a treatment; the seeds are stored in a moist warm sandy medium for several months under nonsterile conditions.
Stratification, also called moist-chilling, breaks down physiological dormancy, and involves the addition of moisture to the seeds so they absorb water, and they are then subjected to a period of moist chilling to after-ripen the embryo. Sowing in late summer and fall and allowing to overwinter under cool conditions is an effective way to stratify seeds; some seeds respond more favorably to periods of oscillating temperatures which are a part of the natural environment.
Leaching or the soaking in water removes chemical inhibitors in some seeds that prevent germination. Rain and melting snow naturally accomplish this task. For seeds planted in gardens, running water is best—if soaked in a container, 12 to 24 hours of soaking is sufficient. Soaking longer, especially in stagnant water, can result in oxygen starvation and seed death. Seeds with hard seed coats can be soaked in hot water to break open the impermeable cell layers that prevent water intake.
Other methods used to assist in the germination of seeds that have dormancy include prechilling, predrying, daily alternation of temperature, light exposure, potassium nitrate, the use of plant growth regulators, such as gibberellins, cytokinins, ethylene, thiourea, sodium hypochlorite, and others. Some seeds germinate best after a fire. For some seeds, fire cracks hard seed coats, while in others, chemical dormancy is broken in reaction to the presence of smoke. Liquid smoke is often used by gardeners to assist in the germination of these species.
Sterile seeds.
Seeds may be sterile for few reasons: they may have been irradiated, unpollinated, cells lived past expectancy, or bred for the purpose.
Evolution and Origin of seeds.
The origin of seed plants is a problem that still remains unsolved. However, more and more data tends to place this origin in the middle Devonian. The description in 2004 of the proto-seed "Runcaria heinzelinii" in the Givetian of Belgium is an indication of that ancient origin of seed-plants. As with modern ferns, most land plants before this time reproduced by sending spores into the air, that would land and become whole new plants.
The first "true" seeds are described from the upper Devonian, which is probably the theater of their true first evolutionary radiation. The seed plants progressively became one of the major elements of nearly all ecosystems.
Economic importance.
Edible seeds.
Many seeds are edible and the majority of human calories comes from seeds, especially from cereals, legumes and nuts. Seeds also provide most cooking oils, many beverages and spices and some important food additives. In different seeds the seed embryo or the endosperm dominates and provides most of the nutrients. The storage proteins of the embryo and endosperm differ in their amino acid content and physical properties. For example the gluten of wheat, important in providing the elastic property to bread dough is strictly an endosperm protein.
Seeds are used to propagate many crops such as cereals, legumes, forest trees, turfgrasses and pasture grasses. Particularly in developing countries, a major constraint faced is the inadequacy of the marketing channels to get the seed to poor farmers. Thus the use of farmer-retained seed remains quite common.
Seeds are also eaten by animals, and are fed to livestock. Many seeds are used as birdseed.
Poison and food safety.
While some seeds are edible, others are harmful, poisonous or deadly. Plants and seeds often contain chemical compounds to discourage herbivores and seed predators. In some cases, these compounds simply taste bad (such as in mustard), but other compounds are toxic or break down into toxic compounds within the digestive system. Children, being smaller than adults, are more susceptible to poisoning by plants and seeds.
A deadly poison, ricin, comes from seeds of the castor bean. Reported lethal doses are anywhere from two to eight seeds,
though only a few deaths have been reported when castor beans have been ingested by animals.
In addition, seeds containing amygdalin—apple, apricot, bitter almond, peach, plum, cherry, quince, and others—when consumed in sufficient amounts, may cause cyanide poisoning.
Other seeds that contain poisons include annona, cotton, custard apple, datura, uncooked durian, golden chain, horse-chestnut, larkspur, locoweed, lychee, nectarine, rambutan, rosary pea, sour sop, sugar apple, wisteria, and yew. The seeds of the strychnine tree are also poisonous, containing the poison strychnine.
The seeds of many legumes, including the common bean ("Phaseolus vulgaris"), contain proteins called lectins which can cause gastric distress if the beans are eaten without cooking. The common bean and many others, including the soybean, also contain trypsin inhibitors which interfere with the action of the digestive enzyme trypsin. Normal cooking processes degrade lectins and trypsin inhibitors to harmless forms.
Please see the category for further relevant articles.
Other uses.
Cotton fiber grows attached to cotton plant seeds. Other seed fibers are from kapok and milkweed.
Many important nonfood oils are extracted from seeds. Linseed oil is used in paints. Oil from jojoba and crambe are similar to whale oil.
Seeds are the source of some medicines including castor oil, tea tree oil and the cancer drug, Laetrile.
Many seeds have been used as beads in necklaces and rosaries including Job's tears, Chinaberry, rosary pea, and castor bean. However, the latter three are also poisonous.
Other seed uses include:
In religion.
The Book of Genesis in the Old Testament begins with an explanation of how all plant forms began: 
The Qur'an speaks about seed germination: 

</doc>
<doc id="37699" url="http://en.wikipedia.org/wiki?curid=37699" title="History of East Asia">
History of East Asia

The history of East Asia goes back as far as 7500 BC in the prehistoric Neolithic period, includes the empire period of China and continues into the present day. 
Prehistory.
Homo erectus ("upright man") is believed to have lived in East and Southeast Asia from 1.8 million to 40,000 years ago. Their regional distinction is classified as "Homo erectus sensu stricto".
Fossils representing 40 "Homo erectus" individuals, known as Peking Man, were found near Beijing at Zhoukoudian that date to about 400,000 years ago. The species was believed to have lived for at least several hundred thousand years in China, and possibly until 200,000 years ago in Indonesia. They may have been the first to use fire and cook food.
Homo sapiens migrated into inland Asia, likely by following herds of bison and mammoth and arrived in southern Siberia by about 43,000 years ago and some people move south or east from there.
The earliest sites of neolithic culture include Nanzhuangtou culture around 9500 BC to 9000 BC, Pengtoushan culture around 7500 BC to 6100 BC, Peiligang culture around 7000 BC to 5000 BC.
The Jeulmun pottery period is sometimes labeled the "Korean Neolithic", but since intensive agriculture and evidence of European-style 'Neolithic' lifestyle is sparse at best, such terminology is misleading. The Jeulmun was a period of hunting, gathering, and small-scale cultivation of plants. Archaeologists sometimes refer to this life-style pattern as 'broad-spectrum hunting-and-gathering'.
The Jōmon period occurred in Japan from circa 14,000 BC to 300BC, with some characteristics of both Neolithic and Mesolithic culture.
Ancient civilizations in East Asia.
Ancient Chinese dynasties.
The Xia dynasty of China (from c. 2100 to c. 1600 BC) is the first dynasty to be described in ancient historical records such as Sima Qian's "Records of the Grand Historian" and "Bamboo Annals".
Following this was the Shang dynasty, which ruled in the Yellow River valley. The classic account of the Shang comes from texts such as the "Classic of History", "Bamboo Annals" and "Records of the Grand Historian". According to the traditional chronology, the Shang ruled from 1766 BC to 1122 BC, but according to the chronology based upon the "current text" of "Bamboo Annals", they ruled from 1556 BC to 1046 BC.
The Zhou dynasty of (c. 1046–256 BC lasted longer than any other dynasty in Chinese history. However, the actual political and military control of China by the dynasty, surnamed Ji (), lasted only until 771 BC, a period known as the Western Zhou. This period of Chinese history produced what many consider the zenith of Chinese bronze-ware making. The dynasty also spans the period in which the written script evolved into its modern form with the use of an archaic clerical script that emerged during the late Warring States period.
Confucianism.
Confucianism is an ethical and philosophical system developed during the Spring and Autumn Period. It later developed metaphysical and cosmological elements in the Han Dynasty. Following the official abandonment of Legalism in China after the Qin Dynasty, Confucianism became the official state ideology of the Han. Nonetheless, from the Han period onwards, most Chinese emperors have used a mix of Legalism and Confucianism as their ruling doctrine. The disintegration of the Han in the second century CE opened the way for the soteriological doctrines of Buddhism and Taoism to dominate intellectual life at that time.
A Confucian revival began during the Tang dynasty. In the late Tang, Confucianism developed aspects on the model of Buddhism and Taoism and was reformulated as Neo-Confucianism. This reinvigorated form was adopted as the basis of the imperial exams and the core philosophy of the scholar official class in the Song dynasty. The abolition of the examination system in 1905 marked the end of official Confucianism. The New Culture intellectuals of the early twentieth century blamed Confucianism for China's weaknesses. They searched for new doctrines to replace Confucian teachings, some of these new ideologies include the "Three Principles of the People" with the establishment of the Republic of China, and then Maoism under the People's Republic of China.
Historically, cultures and countries strongly influenced by Confucianism include mainland China, Taiwan, Hong Kong, Macau, Korea, Japan, and Vietnam, as well as various territories settled predominantly by Chinese people, such as Singapore. In the 20th century, Confucianism’s influence has been greatly reduced. More recently, there have been talks of a "Confucian Revival" in the academia and the scholarly community. 
Buddhism.
Buddhism has also been a major influence on east Asian culture. It was introduced to China during the Han dynasty.
Taoism.
The first organized form of Taoism, the Tianshi (Celestial Masters') school (later known as Zhengyi school), developed from the Five Pecks of Rice movement at the end of the 2nd century CE; the latter had been founded by Zhang Daoling, who claimed that Laozi appeared to him in the year 142. The Tianshi school was officially recognized by ruler Cao Cao in 215, legitimizing Cao Cao's rise to power in return. Laozi received imperial recognition as a divinity in the mid-2nd century BCE.
Taoism, in form of the Shangqing school, gained official status in China again during the Tang Dynasty (618–907), whose emperors claimed Laozi as their relative. The Shangqing movement, however, had developed much earlier, in the 4th century, on the basis of a series of revelations by gods and spirits to a certain Yang Xi in the years between 364 to 370.
Qin and Han Dynasties.
In 221 BC, the state of Qin succeeded in conquering the other six states, creating the first imperial dynasty of China for the first time. Following the death of the emperor Qin Shi Huangdi, the Qin dynasty collapsed and control was taken over by the Han dynasty in 206 BC. In AD 220, the Han empire collapsed into the Three Kingdoms. The series of trade routes known as Silk Road began during the Han dynasty.
Divisions and re-unification of China.
Three Kingdoms Period.
The Three Kingdoms Period consisted of the kingdom of Wei, Shu, and Wu. It began when the ruler of Wei, Cao Cao, was defeated by Liu Bei and Sun Quan at the Battle of Red Cliffs. After Cao Cao's death in AD 220, his son Cao Pi became emperor of Wei. Liu Bei and Sun Quan declared themselves emperor of Shu and Wu respectively. Many famous personages in Chinese history were born during this period, including Hua Tuo and the great military strategist Zhuge Liang. Buddhism, which was introduced during the Han Dynasty, also became popular in this period. Two years after Wei conquered Shu in AD 263, Sima Yan, Wei's Imperial Chancellor, overthrew Wei and started the Western Jin Dynasty. The conquest of Wu by the Western Jin Dynasty ended the Three Kingdoms period, and China was unified again. However, the Western Jin did not last long. Following the death of Sima Yan, the War of the Eight Princes began. This war weakened the Jin Dynasty, and it soon fell to the kingdom of Han Zhao. This ushered in the Sixteen Kingdoms.
Southern and Northern Dynasties.
The Northern Wei was established by the Tuoba clan of the Xianbei people in AD 386, when they united the northern part of China. During the Northern Wei, Buddhism flourished, and became an important tool for the emperors of the Northern Wei, since they were believed to be living incarnations of Buddha. Soon, the Northern Wei was divided into the Eastern Wei and Western Wei. These were followed by the Northern Zhou and Northern Qi. In the south, the dynasties were much less stable than the Northern Dynasties. The four dynasties were weakened by conflicts between the ruling families.
Buddhism.
Buddhism, also one of the major religions in East Asia, was introduced into China during the Han dynasty from Nepal in the 1st century BC. Buddhism was originally introduced to Korea from China in 372, and eventually arrived in Japan around the turn of the 6th century.
For a long time Buddhism remained a foreign religion with a few believers in China, mainly taught by immigrant Indian teachers. During the Tang dynasty, a fair amount of translations from Sanskrit into Chinese were done by Chinese priests, and Buddhism became one of the major religions of the Chinese along with the other two indigenous religions.
In Korea, Buddhism was not seen to conflict with the rites of nature worship; it was allowed to blend in with Shamanism. Thus, the mountains that were believed to be the residence of spirits in pre-Buddhist times became the sites of Buddhist temples. Though Buddhism initially enjoyed wide acceptance, even being supported as the state ideology during the Goguryeo, Silla, Baekje, Balhae, and Goryeo periods, Buddhism in Korea suffered extreme repression during the Joseon Dynasty.
In Japan, Buddhism and Shinto were combined by a theological theory "Ryōbushintō", which says Shinto deities are avatars of various Buddhist entities, including Buddhas and Bodhisattvas. This became the mainstream notion of Japanese religion. In fact until the Meiji government declared their separation in the mid-19th century, many Japanese people believed that Buddhism and Shinto were one religion.
In Mongolia, Buddhism flourished two times; first in the Mongol Empire (13th-14th centuries), and finally in the Manchu Qing Dynasty (16th-19th centuries) from Tibet in the last 2000 years. It was mixed in with Tengeriism and Shamanism.
Sui Dynasty.
In AD 581, Yang Jian overthrew the Northern Zhou, and established the Sui Dynasty. Later, Yang Jian, who became Sui Wendi, conquered the Chen Dynasty, and united China. However, this dynasty was short-lived. Sui Wendi's successor, Sui Yangdi, expanded the Grand Canal, and launched four disastrous wars against the Goguryeo. These projects depleted the resources and the workforce of the Sui. In AD 618, Sui Yangdi was murdered. Li Yuan, the former governor of Taiyuan, declared himself the emperor, and founded the Tang Dynasty.
Three Kingdoms of Korea.
B.C 58, the Korean peninsula was divided into three kingdoms, Baekje, Silla and Goguryeo. Although they shared a similar language and culture, these three kingdoms constantly fought with each other for control of the peninsula. Furthermore, Goguryeo had been engaged in constant wars with the Chinese. This included the Goguryeo-Sui Wars, where the Kingdom of Goguryeo managed to repel the invading forces of the Sui Dynasty.
As the Kingdom of Silla conquered nearby city-states, they gained access to the Yellow Sea, making direct contact with the Tang Dynasty possible. The Tang Dynasty teamed up with Silla and formed a strategy to invade Goguryeo. Since Goguryeo had been able to repel earlier Chinese invasions from the North, perhaps Gorguryeo would fall if it were attacked by Silla from the south at the same time. However, in order to do this, the Tang-Silla alliance had to eliminate Goguryeo's nominal ally Baekje and secure a base of operations in southern Korea for a second front.
In 660, the coalition troops of Silla and Tang of China attacked Baekje, resulting in the annexation of Baekje by Silla. Together, Silla and Tang effectively eliminated Baekje when they captured the capital of Sabi, as well as Baekje's last king, Uija, and most of the royal family.
However, Yamato Japan and Baekje had been long-standing and very close allies. In 663, Baekje revival forces and a Japanese naval fleet convened in southern Baekje to confront the Silla forces in the Battle of Baekgang. The Tang dynasty also sent 7,000 soldiers and 170 ships. After five naval confrontations that took place in August 663 at Baekgang, considered the lower reaches of Tongjin river, the Silla-Tang forces emerged victorious.
The Silla-Tang forces turned their attention to Goguryeo. Although Goguryeo had repelled the Sui Dynasty a century earlier, attacks by the Tang Dynasty from the west proved too formidable. The Silla-Tang alliance emerged victorious in the Goguryeo-Tang Wars. Silla thus unified most of the Korean peninsula in 668.
But the kingdom's reliance on China's Tang Dynasty had its price. Silla had to forcibly resist the imposition of Chinese rule over the entire peninsula. Silla then fought for nearly a decade to expel Chinese forces to finally establish a unified kingdom as far north as modern Pyongyang.
Silla'a unification of Korea was short lived. The northern region of the defunct Goguryeo state later reemerged as Balhae, due to the leadership of former Goguryeo General Dae Joyeong.
Civil service.
A government system supported by a large class of Confucian literati selected through civil service examinations was perfected under Tang rule. This competitive procedure was designed to draw the best talents into government. But perhaps an even greater consideration for the Tang rulers, aware that imperial dependence on powerful aristocratic families and warlords would have destabilizing consequences, was to create a body of career officials having no autonomous territorial or functional power base. As it turned out, these scholar-officials acquired status in their local communities, family ties, and shared values that connected them to the imperial court. From Tang times until the closing days of the Qing Dynasty in 1911, scholar officials functioned often as intermediaries between the grassroots level and the government. This model of government had an influence on Korea and Japan.
Printing press.
The first known movable type system was invented in China around 1040 AD by Pi Sheng (990-1051) (spelled Bi Sheng in the Pinyin system). Pi Sheng's type was made of baked clay. As described by the Chinese scholar Shen Kuo (1031–1095)
The world's first metal-based movable type printing press was invented in Korea in 1234. That was 210 years before Johannes Gutenberg from Germany did.
Jikji is the world's oldest extant movable metal print book. it was published in Heungdeok Temple in 1377, 78 years prior to Johannes Gutenberg's "42-Line Bible" printed during the years 1452-1455.
Gunpowder.
 Most sources credit the discovery of gunpowder to Chinese alchemists in the 9th century searching for an elixir of immortality. The discovery of gunpowder was probably the product of centuries of alchemical experimentation. Saltpetre was known to the Chinese by the mid-1st century AD and there is strong evidence of the use of saltpetre and sulfur in various largely medicine combinations. A Chinese alchemical text from 492 noted that saltpeter gave off a purple flame when ignited, providing for the first time a practical and reliable means of distinguishing it from other inorganic salts, making it possible to evaluate and compare purification techniques. By most accounts, the earliest Arabic and Latin descriptions of the purification of saltpeter do not appear until the 13th century.
The first reference to gunpowder is probably a passage in the "Zhenyuan miaodao yaolüe", a Taoism text tentatively dated to the mid-9th century:
Some have heated together sulfur, realgar and saltpeter with honey; smoke and flames result, so that their hands and faces have been burnt, and even the whole house where they were working burned down.
The earliest surviving recipes for gunpowder can be found in the Chinese military treatise "Wujing zongyao" of 1044 AD, which contains three: two for use in incendiary bombs to be thrown by siege engines and one intended as fuel for poison smoke bombs. The formulas in the "Wujing zongyao" range from 27 to 50 percent nitrate. Experimenting with different levels of saltpetre content eventually produced bombs, grenades, and land mines, in addition to giving fire arrows a new lease on life. By the end of the 12th century, there were cast iron grenades filled with gunpowder formulations capable of bursting through their metal containers. The 14th century "Huolongjing" contains gunpowder recipes with nitrate levels ranging from 12 to 91 percent, six of which approach the theoretical composition for maximal explosive force.
In China, the 13th century saw the beginnings of rocketry and the manufacture of the oldest gun still in existence, a descendant of the earlier fire-lance, a gunpowder-fueled flamethrower that could shoot shrapnel along with fire. The "Huolongjing" text of the 14th century also describes hollow, gunpowder-packed exploding cannonballs.
In the 13th century contemporary documentation shows gunpowder beginning to spread from China by the Mongols to the rest of the world, starting with Europe and the Islamic world. The Arabs acquired knowledge of saltpetre—which they called "Chinese snow" (Arabic: ثلج الصين‎ thalj al-ṣīn) —around 1240 and, soon afterward, of gunpowder; they also learned of fireworks ("Chinese flowers") and rockets ("Chinese arrows"). Persians called saltpeter "Chinese salt" or "salt from Chinese salt marshes" (namak shūra chīnī Persian: نمک شوره چيني‎). Historian Ahmad Y. al-Hassan argues—"contra" the general notion—that the Chinese technology passed through Arabic alchemy and chemistry before the 13th century. Gunpowder arrived in India by the mid-14th century, but could have been introduced by the Mongols perhaps as early as the mid-13th century.
See also.
Histories for East Asia are listed by area in alphabetical order:

</doc>
<doc id="37701" url="http://en.wikipedia.org/wiki?curid=37701" title="Outline of South Asian history">
Outline of South Asian history

The term South Asia refers to the contemporary political entities of the Indian subcontinent and associated islands. These are the states of India, Pakistan, Bangladesh, Nepal, Afghanistan, Bhutan, and the island nations of Sri Lanka and the Maldives.
The following is a list of articles on the history of the various regions of South Asia. See History of India for a general history of the entire subcontinent.
Sources.
</dl>

</doc>
<doc id="37702" url="http://en.wikipedia.org/wiki?curid=37702" title="History of Southeast Asia">
History of Southeast Asia

The history of Southeast Asia has been characterized as interaction between regional players and foreign powers. Each country was intertwined with all the others as depicted in the Southeast Asian political model. For instance, the Malay empires of Srivijaya and Malacca covered modern day Indonesia, Malaysia, the Philippines, and Singapore while the Burmese, Vietnamese and Khmer peoples governed much of Indochina.
At the same time, opportunities and threats from the east and the west shaped the direction of Southeast Asia. The history of the countries within the region only started to develop independently of each other after European colonialization was at full steam between the 17th and the 20th centuries.
Prehistory.
Paleolithic.
Archaeologists have found stone tools in Malaysia which have been dated to be 1.83 million years old. With other evidence found across the Mainland of South east Asia, which include Hominid skeletal and teeth remains, Hominid stone artefacts such as chopper-chopping tools and stone blades, contemporaneous faunal bone remains and palaeo-environment analyses, the occupation of Hominids into South East Asia is believed to occur between 1.5 to 1 Ma. The occupation was firstly taken place in the upland region in the northern part of the Mainland South East Asia where the climate was stable and the natural resource was richer. During the cooler periods occurred intermittently between warm and humid conditions, which prevailed from 240 to180 ka and again between 130 and 100 ka, many warm-adapted species such as primates moved southward.
Before the latest ice period, much of the archipelago was not under water. Sometime around the Pleistocene period, the Sunda Shelf was flooded as thawing occurred and thus revealing current geographical features. The area's first known human-like inhabitant some 500,000 years ago was "Java Man" (first classified as Pithecanthropus erectus, then subsequently named a part of the species Homo erectus). Recently discovered was a species of human, dubbed "Flores Man" (Homo floresiensis), a miniature hominid that grew only three feet tall. Flores Man seems to have shared some islands with Java Man until only 10,000 years ago, when they became extinct. Extensive archeological work has been done at Sangiran in Central Java where a museum and visitors' centre has been established.
The oldest human settlement in Malaysia has been discovered in Niah Caves. The human remains found there have been dated back to 40,000 BC. Another remain dated back to 9000 BC dubbed the "Perak Man" and tools as old as 75,000 years have been discovered in Lenggong, Malaysia.
The oldest habitation discovered in the Philippines is located at the Tabon Caves and dates back to approximately 50,000 years; while items there found such as burial jars, earthenware, jade ornaments and other jewelry, stone tools, animal bones, and human fossils dating back to 47,000 years ago. Human remains are from approximately 24,000 years ago.
Mesolithic and early agricultural societies.
Agriculture was a development based on necessity. Before agriculture, hunting and gathering sufficed to provide food. The chicken and pig were domesticated here, millennia ago. So much food was available that people could gain status by giving food away in feasts and festivals, where all could eat their fill. These "big men" (Malay: "orang kaya") would work for years, accumulating the food (wealth) needed for the festivals provided by the "orang kaya". These individual acts of generosity or kindness are remembered by the people in their oral histories, which serves to provide "credit" in more dire times.
These customs ranged throughout Southeast Asia, stretching, for example, to the island of New Guinea. The agricultural technology was exploited after population pressures increased to the point that systematic intensive farming was required for mere survival, say of yams (in Papua) or rice (in Indonesia). Rice paddies are well-suited for the monsoons of Southeast Asia. The rice paddies of Southeast Asia have existed for millennia, with evidence for their existence coeval with the rise of agriculture in other parts of the globe.
Yam cultivation in Papua, for example, consists of placing the tubers in prepared ground, heaping vegetation on them, waiting for them to propagate, and harvesting them. This work sequence is still performed by the women in the traditional societies of Southeast Asia; the men might perform the heavier duties of preparing the ground, or of fencing the area to prevent predation by pigs.
Though cultivation emerged in the beginning of Holocene, hunting and gathering was not replaced but co-existed with farming. Early inhabitant groups might led a life mixed with cultivation and foraging that lasted for a rather long period, and they might as well relied on wild plant food production.
From Burma around 1500 BC, the Mon and ancestors of the Khmer people started to move in into the mainland while the Tai people later came from southern China to reside there in the 1st millennium AD.
Early metal phases in Southeast Asia.
It was around 2500 BC that the Austronesian people started to populate the archipelago and introduced primitive ironworks technology that they had mastered to the region.
By around the 5th century BC, people of the Dong Son culture, who lived in what is now Vietnam, had mastered basic metal working. Their works are the earliest known metal object to be found by archeologists in Southeast Asia.
Ancient and classical kingdoms.
The communities in the region evolved to form complex cultures with varying degrees of influence from India and China.
The ancient kingdoms can be grouped into two distinct categories. The first is agrarian kingdoms. Agrarian kingdoms had agriculture as the main economic activity. Most agrarian states were located in mainland Southeast Asia. Examples are the Van Lang, based on the Red River delta and the Khmer Empire around the Tonle Sap. The second type is maritime states. Maritime states were dependent on sea trade. Srivijaya and Malacca were maritime states.
Văn Lang was the first nation of the ancient Vietnamese people, founded in 2879 BC and existing until 258 BC. It was ruled by the Hùng Kings of the Hồng Bàng Dynasty. There is, however, little reliable historical information available.
A succession of trading systems dominated the trade between China and India. First, goods were shipped through Funan centered in Mekong delta to the Isthmus of Kra, portaged across the narrow, and then transhipped for India and points west. This trading link allowed the development of polities around the Mekong delta in today Southern Vietnam and Cambodia, such as Funan and its successor Chenla. Funan was started around the 1st century CE and replaced by Chenla that existed in the 6th to 8th centuries. The trade via Isthmus of Kra also spurred the development of trading polities on Malay peninsula near the isthmus (today southern Thailand and northern Malaysia), such as Langkasuka on eastern coast and Kedah on western coast.
Numbers of port towns in maritime Southeast Asia also began to receive Hindu and Buddhist influences from India, and developed to be a Hindu or Buddhist kingdoms ruled by native dynasties. Early Hindu kingdoms in Indonesia are 4th century Kutai that rose in East Kalimantan, Tarumanagara in West Java and Kalingga in Central Java.
Around the 6th century CE, merchants began sailing to Srivijaya where goods were transhipped directly on Sumatran port. The limits of technology and contrary winds during parts of the year made it difficult for the ships of the time to proceed directly from the Indian Ocean to the South China Sea. The third system involved direct trade between the Indian and Chinese coasts.
In the 7th century CE on central coast of today Vietnam, a Hindu kingdom of Champa flourished. Just like Funan, benefited from the lucrative trading between China, Southeast Asia and India.
Very little is known about Southeast Asian religious beliefs and practices before the advent of Indian merchants and religious influences from the 2nd century BC onwards. It is believed that prior to the advent of Hinduism and Buddhism, native Southeast Asian are tribal animist. Prior to the 13th century, Buddhism and Hinduism were the main religions in Southeast Asia.
The first dominant power to arise in the archipelago was Srivijaya in Sumatra. From the 5th century, the capital, Palembang, became a major seaport and functioned as an entrepot on the Spice Route between India and China. Srivijaya was also a notable center of Vajrayana Buddhist learning and influence. Srivijaya's wealth and influence faded when changes in nautical technology in the 10th century enabled Chinese and Indian merchants to ship cargo directly between their countries and also enabled the Chola state in southern India to carry out a series of destructive attacks on Srivijaya's possessions, ending Palembang's entrepot function.
From the 7th to 15th centuries Sumatra was ruled by kaleidoscope of Buddhist kingdoms, from Kantoli, Srivijaya, Malayu, Pannai and Dharmasraya kingdom. Most of its history from the 6th to 13th centuries, Sumatra was dominated by Srivijaya empire.
After the fall of Tarumanagara, West Java was ruled by Sunda Kingdom. While Central and Eastern Java was dominated by a kaleidoscope of competing agrarian kingdoms including the Sailendras, Mataram, Kediri, Singhasari, and finally Majapahit. In the 8th to 9th centuries, the Sailendra dynasty that ruled Medang i Bhumi Mataram kingdom built numbers massive monuments in Central Java, includes Sewu and Borobudur temple.
In the Philippines, the Laguna Copperplate Inscription dating from 900 CE relates a granted debt from a Maharlika caste nobleman named "Namwaran" who lived in the Maynila area. This document mentions a leader of Medang in Java.
In mainland Southeast Asia, after the fall of Chenla, the Khmer Empire, centered on the plain north of Tonle Sap lake, flourished in 9th until 15th century to become a regional hegemon. The Khmers built numbers of massive monuments in and around Angkor. While on central plains of today Thailand the kingdom of Dvaravati arose since 6th to 13th century. By the 10th century, Dvaravati began to come under the influence of the Khmer Empire. Later the plains of Central Thailand was dominated by Sukhothai in the 13th century and later Ayutthaya Kingdom in the 14th century.
According to the Nagarakertagama, around the 13th century, Majapahit's vassal states spread throughout much of today's Indonesia, making it the largest empire ever to exist in Southeast Asia. The empire declined in the 15th century after the rise of Islamic states in coastal Java, Malay peninsula and Sumatra.
European colonization.
Europeans first came to Southeast Asia in the 16th century. It was the lure of trade that brought Europeans to Southeast Asia while missionaries also tagged along the ships as they hoped to spread Christianity into the region.
Portugal was the first European power to establish a bridgehead on the lucrative maritime Southeast Asia trade route, with the conquest of the Sultanate of Malacca in 1511. The Netherlands and Spain followed and soon superseded Portugal as the main European powers in the region. In 1599, Spain began to colonize the Philippines. In 1619, acting through the Dutch East India Company, the Dutch took the city of Sunda Kelapa, renamed it Batavia (now Jakarta) as a base for trading and expansion into the other parts of Java and the surrounding territory. In 1641, the Dutch took Malacca from the Portuguese. Economic opportunities attracted Overseas Chinese to the region in great numbers. In 1775, the Lanfang Republic, possibly the first republic in the region, was established in West Kalimantan, Indonesia, as a tributary state of the Qing Empire; the republic lasted until 1884, when it fell under Dutch occupation as Qing influence waned.
Englishmen of the United Kingdom, in the guise of the Honourable East India Company led by Josiah Child, had little interest or impact in the region, and were effectively expelled following the Siam–England war (1687). Britain, in the guise of the British East India Company, turned their attention to the Bay of Bengal following the Peace with France and Spain (1783). During the conflicts, Britain had struggled for naval superiority with the French, and the need of good harbours became evident. Penang Island had been brought to the attention of the Government of India by Francis Light. In 1786 a settlement was formed under the administration of Sir John Macpherson, which formally began British expansion into the Malay States of Southeast Asia.
The British also temporarily possessed Dutch territories during the Napoleonic Wars; and Spanish areas in the Seven Years' War. In 1819, Stamford Raffles established Singapore as a key trading post for Britain in their rivalry with the Dutch. However, their rivalry cooled in 1824 when an Anglo-Dutch treaty demarcated their respective interests in Southeast Asia. British rule in Burma began with the first Anglo-Burmese War (1824–1826).
Early United States entry into what was then called the East Indies (usually in reference to the Malay Archipelago) was low key. In 1795, a secret voyage for pepper set sail from Salem, Massachusetts on an 18-month voyage that returned with a bulk cargo of pepper, the first to be so imported into the country, which sold at the extraordinary profit of seven hundred per cent. In 1831, the merchantman "Friendship" of Salem returned to report the ship had been plundered, and the first officer and two crewmen murdered in Sumatra. The Anglo-Dutch Treaty of 1824 obligated the Dutch to ensure the safety of shipping and overland trade in and around Aceh, who accordingly sent the Royal Netherlands East Indies Army on the punitive expedition of 1831. President Andrew Jackson also ordered America's first Sumatran punitive expedition of 1832, which was followed by a punitive expedition in 1838. The "Friendship" incident thus afforded the Dutch a reason to take over Ache; and Jackson, to dispatch diplomatist Edmund Roberts, who in 1833 secured the Roberts Treaty with Siam. In 1856 negotiations for amendment of this treaty, Townsend Harris stated the position of the United States:The United States does not hold any possessions in the East, nor does it desire any. The form of government forbids the holding of colonies. The United States therefore cannot be an object of jealousy to any Eastern Power. Peaceful commercial relations, which give as well as receive benefits, is what the President wishes to establish with Siam, and such is the object of my mission.
From the end of the 1850s onwards, while the attention of the United States shifted to maintaining their union, the pace of European colonization shifted to a significantly higher gear.
This phenomenon, denoted New Imperialism, saw the conquest of nearly all Southeast Asian territories by the colonial powers. The Dutch East India Company and British East India Company were dissolved by their respective governments, who took over the direct administration of the colonies. Only Thailand was spared the experience of foreign rule, though Thailand, too, was greatly affected by the power politics of the Western powers. The Monthon reforms of the late 19th Century continuing up till around 1910, imposed a Westernized form of government on the country's partially independent cities called Mueang, such that the country could be said to have successfully colonized itself. Western powers did, however, continue to interfere in both internal and external affairs.
By 1913, the British had occupied Burma, Malaya and the northern Borneo territories, the French controlled Indochina, the Dutch ruled the Netherlands East Indies while Portugal managed to hold on to Portuguese Timor. In the Philippines, the 1872 Cavite Mutiny was a precursor to the Philippine Revolution (1896–1898). When the Spanish–American War began in Cuba in 1898, Filipino revolutionaries declared Philippine independence and established the First Philippine Republic the following year. In the Treaty of Paris of 1898 that ended the war with Spain, the United States gained the Philippines and other territories; in refusing to recognize the nascent republic, America effectively reversed her position of 1856. This led directly to the Philippine–American War, in which the First Republic was defeated; wars followed with the Republic of Zamboanga, the Republic of Negros and the Republic of Katagalugan, all of which were also defeated.
Colonial rule had had a profound effect on Southeast Asia. While the colonial powers profited much from the region's vast resources and large market, colonial rule did develop the region to a varying extent. Commercial agriculture, mining and an export based economy developed rapidly during this period. The introduction Christianity bought by the colonist also have profound effect in the societal change.
Increased labor demand resulted in mass immigration, especially from British India and China, which brought about massive demographic change. The institutions for a modern nation state like a state bureaucracy, courts of law, print media and to a smaller extent, modern education, sowed the seeds of the fledgling nationalist movements in the colonial territories. In the inter-war years, these nationalist movements grew and often clashed with the colonial authorities when they demanded self-determination.
Japanese invasion and occupations.
In September 1940, following the Fall of France and pursuant to the Pacific war goals of Imperial Japan, the Japanese Imperial Army invaded Vichy French Indochina, which ended in the abortive Japanese coup de main in French Indochina of 9 March 1945. On 5 January 1941, Thailand launched the Franco-Thai War, ended on 9 May 1941 by a Japanese-imposed treaty signed in Tokyo. On 7/8 December, Japan's entry into World War II began with the invasion of Thailand, the only invaded country to maintain nominal independence, due to her political and military alliance with the Japanese—on 10 May 1942, her northwestern Payap Army invaded Burma during the Burma Campaign. From 1941 until war's end, Japanese occupied Cambodia and Malaya, which ended in independence movements. Japanese occupation of the Philippines led to the forming of the Second Philippine Republic, formally dissolved in Tokyo on 17 August 1945. Also on 17 August, a proclamation of Indonesian Independence was read at the conclusion of Japanese occupation of the Dutch East Indies since March 1942.
Post-war decolonization.
With the rejuvenated nationalist movements in wait, the Europeans returned to a very different Southeast Asia after World War II. Indonesia declared independence in 17 August 1945 and subsequently fought a bitter war against the returning Dutch; the Philippines was granted independence by the United States in 1946; Burma secured their independence from Britain in 1948, and the French were driven from Indochina in 1954 after a bitterly fought war (the Indochina War) against the Vietnamese nationalists. The newly established United Nations provided a forum both for nationalist demands and for the newly demanded independent nations.
During the Cold War, countering the threat of communism was a major theme in the decolonization process. After suppressing the communist insurrection during the Malayan Emergency from 1948 to 1960, Britain granted independence to Malaya and later, Singapore, Sabah and Sarawak in 1957 and 1963 respectively within the framework of the Federation of Malaysia. In one of the most bloody single incidents of violence in Cold War Southeast Asia, General Suharto seized power in Indonesia in 1965 and initiated a massacre of approximately 500,000 alleged members of the Indonesian Communist Party (PKI).
Following the independence of the Indochina states, North Vietnamese attempts to conquer South Vietnam resulted in the Vietnam War. The conflict spread to Laos and Cambodia and heavy intervention from the United States. By the war's end in 1975, all these countries were controlled by communist parties. After the communist victory, two wars between communist states—the Cambodian–Vietnamese War of 1975–89 and the Sino-Vietnamese War of 1979—were fought in the region. The victory of the Khmer Rouge in Cambodia resulted in the Cambodian Genocide.
In 1975, Portuguese rule ended in East Timor. However, independence was short-lived as Indonesia annexed the territory soon after. However, after more than 20 years of fighting Indonesia, East Timor won its independence and is recognized by the UN as the world's newest nation. Finally, Britain ended its protectorate of the Sultanate of Brunei in 1984, marking the end of European rule in Southeast Asia.
Contemporary Southeast Asia.
Modern Southeast Asia has been characterized by high economic growth by most countries and closer regional integration. Indonesia, Malaysia, the Philippines, Singapore and Thailand have traditionally experienced high growth and are commonly recognized as the more developed countries of the region. As of late, Vietnam too had been experiencing an economic boom. However, Myanmar, Cambodia, Laos and the newly independent East Timor are still lagging economically.
On August 8, 1967, the Association of Southeast Asian Nations (ASEAN) was founded by Thailand, Indonesia, Malaysia, Singapore, and the Philippines. Since Cambodian admission into the union in 1999, East Timor is the only Southeast Asian country that is not part of ASEAN, although plans are under way for eventual membership. The association aims to enhance cooperation among Southeast Asian community. ASEAN Free Trade Area has been established to encourage greater trade among ASEAN members. ASEAN has also been a front runner in greater integration of Asia-Pacific region through East Asia Summits.
See also.
By country:
General:

</doc>
<doc id="37706" url="http://en.wikipedia.org/wiki?curid=37706" title="Covalent radius">
Covalent radius

The covalent radius, "r"cov, is a measure of the size of an atom that forms part of one covalent bond. It is usually measured either in picometres (pm) or angstroms (Å), with 1 Å = 100 pm.
In principle, the sum of the two covalent radii should equal the covalent bond length between two atoms, "R"(AB) = "r"(A) + "r"(B). Moreover, different radii can be introduced for single, double and triple bonds (r1, r2 and r3 below), in a purely operational sense. These relationships are certainly not exact because the size of an atom is not constant but depends on its chemical environment. For heteroatomic A–B bonds, ionic terms may enter. Often the polar covalent bonds are shorter than would be expected on the basis of the sum of covalent radii. Tabulated values of covalent radii are either average or idealized values, which nevertheless show a certain transferability between different situations, which makes them useful.
The bond lengths "R"(AB) are measured by X-ray diffraction (more rarely, neutron diffraction on molecular crystals). Rotational spectroscopy can also give extremely accurate values of bond lengths. For homonuclear A–A bonds, Linus Pauling took the covalent radius to be half the single-bond length in the element, e.g. "R"(H–H, in H2) = 74.14 pm so "r"cov(H) = 37.07 pm: in practice, it is usual to obtain an average value from a variety of covalent compounds, although the difference is usually small. Sanderson has published a recent set of non-polar covalent radii for the main-group elements, but the availability of large collections of bond lengths, which are more transferable, from the Cambridge Crystallographic Database has rendered covalent radii obsolete in many situations.
Table of covalent radii.
The values in the table below are based on a statistical analysis of more than 228,000 experimental bond lengths from the Cambridge Structural Database. The numbers in parentheses are the estimated standard deviations for the last digit. This fit pre-fixes the radii for C, N and O.
A different approach is to make a self-consistent fit for all elements in a smaller set of molecules. This was done separately for single,
double,
and triple bonds
up to superheavy elements. Both experimental and computational data were used. 
The single-bond results are often similar to those of Cordero et al. When they are different, the coordination numbers used can be different. This is notably the case for most (d and f) transition metals. Normally one expects that "r"1 > "r"2 > "r"3. Deviations may occur for weak multiple bonds, if the differences of the ligand are larger than the differences of "R" in the data used.<br>
Note that elements up to E118 have now been experimentally produced and that there are chemical studies on an increasing number of them.
<br>
The same, self-consistent approach was used to fit tetrahedral covalent radii for 30 elements in 48 crystals with subpicometer accuracy.

</doc>
<doc id="37708" url="http://en.wikipedia.org/wiki?curid=37708" title="Flare">
Flare

A flare, also sometimes called a fusee, is a type of pyrotechnic that produces a brilliant light or intense heat without an explosion. Flares are used for signalling, illumination, or defensive countermeasures in civilian and military applications. Flares may be ground pyrotechnics, projectile pyrotechnics, or parachute-suspended to provide maximum illumination time over a large area. Projectile pyrotechnics may be dropped from aircraft, fired from rocket or artillery, or deployed by flare guns or handheld percussive tubes.
History.
The earliest recorded use of gunpowder for signalling purposes was the 'signal bomb' used by the Song Dynasty Chinese as the Mongol-led Yuan Dynasty besieged Yangzhou in 1276. These soft-shelled bombs, timed to explode in mid-air, were used to send messages to a detachment of troops far in the distance. Another mention of the signal bomb appears in a text dating from 1293 requesting their collection from those still stored in Zhejiang. A signal gun appears in Korea by 1600. The "Wu I Thu Phu Thung Chih" or "Illustrated Military Encyclopedia" written in 1791 depicts a signal gun in an illustration.
Chemistry.
Flares produce their light through the combustion of a pyrotechnic composition. The ingredients are varied, but often based on strontium nitrate, potassium nitrate, or potassium perchlorate and mixed with a fuel such as charcoal, sulfur, sawdust, aluminium, magnesium, or a suitable polymeric resin. Flares may be colored by the inclusion of pyrotechnic colorants. Calcium flares are used underwater to illuminate submerged objects.
Non-perchlorate flares.
Many in-service colored signal flares and spectrally balanced decoy flares contain perchlorate oxidizers. Perchlorate, a type of salt in its solid form, dissolves and moves rapidly in groundwater and surface water. Even in low concentrations in drinking water supplies, perchlorate is known to inhibit the uptake of iodine by the thyroid gland. While there are currently no US federal drinking water standards for perchlorate, some states have established public health goals, or action levels, and some are in the process of establishing state maximum contaminant levels. For example, the US Environmental Protection Agency have studied the impacts of perchlorate on the environment as well as drinking water. California has also issued guidance regarding perchlorate use.
US courts have taken action regarding the use of perchlorate in manufacturing pyrotechnic devices such as flares. For example, in 2003, a federal district court in California found that Comprehensive Environmental Response, Compensation and Liability Act (CERCLA) applied because perchlorate is ignitable and therefore a “characteristic” hazardous waste. (see Castaic Lake Water Agency v. Whittaker, 272 F. Supp. 2d 1053, 1059–61 (C.D. Cal. 2003)).
Civilian use.
In the civilian world, flares are commonly used as signals, and may be ignited on the ground or fired as an aerial signal from a pistol-like flare gun, or launched from a self-contained tube. Flares are commonly found in marine survival kits.
Maritime distress signal.
Red flares, either sent as a rocket or held in the hand, are widely recognized as a maritime distress signal. One notable example of this is during the sinking of the "RMS Titanic".
Fusee.
Another type of flare is the "fusee", which burns for 10–60 minutes with a bright red light. Fusees are commonly used to indicate obstacles or advise caution on roadways at night; in this usage they are also called "highway flares", "road flares", or "ground flares". They are commonly found in roadside emergency kits.
Fusees are also known as "railroad flares" and are commonly used to perform hand signals in rail transport applications. Since they can be used only once, fusees nowadays are usually intended for emergency use (as opposed to the incandescent lanterns typically used during normal operating conditions). However, in the days before train radio communications, fusees were used to keep trains apart on un-signalled lines. A railroad fusee was timed to burn for ten minutes and quantities were dropped behind a train to ensure a safe spacing. If a following train encountered a burning fusee it was not to pass until the fusee burned out. Fusees made specifically for railroad use can be distinguished from highway fusees by a sharp steel spike at one end, used to embed the fusee upright in a wooden railroad tie.
In forestry and firefighting, fusees are sometimes used in wildland fire suppression and in the ignition of controlled burns. They ignite at 191 C and burn as hot as 1600 C. They are especially effective in igniting burnouts or backburns in very dry conditions, but not so effective when fuel conditions are moist. Since controlled burns are often done during relatively high humidity levels (on the grounds that they could not be safely contained during periods of very low humidity), the driptorch is more effective and more often used. Fusees are also commonly carried by wildland firefighters for emergency use, to ignite an escape fire in surrounding fuels in case of being overrun by a fire if no other escape routes are available.
Calcium phosphide is often used in naval flares, as in contact with water it liberates phosphine which self-ignites in contact with air; it is often used together with calcium carbide which releases acetylene.
Flares and football.
Maritime flares and other pyrotechnics are often used by Ultras at football & and other sporting events to increase atmosphere, even though it is illegal to do so in most countries.
Because of increased focus on the area, some fans resort to cutting off the safety handles of the flares in order to make them easier to smuggle into a football stadium, which just adds to the potential safety hazard of bringing fireworks to a crowded stand.
Military use.
Illumination.
In 1922, a "landing flare" was an aerial candle attached to a parachute and used for landing an airplane in the dark. The flare burned for less than 4 minutes and the candle power was about 40,000.
Countermeasure.
A special variety of flare is used in military aircraft as a defensive countermeasure against heat-seeking missiles. These flares are usually discharged individually or in salvoes by the pilot or automatically by tail-warning devices, and are accompanied by vigorous evasive maneuvering. Since they are intended to deceive infrared missiles, these flares burn at temperatures of thousands of degrees, incandescing in the visible spectrum as well. Soids are floating flares that are effective only in the terminal phase of missiles with infrared signature seeker heads.
Criticism.
Pyrotechnic flares are classified as class 1.4 explosives, and as such have been utilized in training exercises by explosive disposal units within police forces." 
Due to the presence of potassium perchlorate, traditional pyrotechnic flares have further been labeled as hazardous materials. If improperly stored, this chemical can lead to long-term contamination of drinking water and have a further negative biological and environmental impact.
Several U.S. states, including California and Massachusetts, have begun regulating levels of potassium perchlorate, which can be unsafe at certain levels in drinking water. Contaminated drinking water can lead to such symptoms as gastric irritation, nausea, vomiting, fever, skin rashes, and even fatal aplastic anemia.

</doc>
<doc id="37710" url="http://en.wikipedia.org/wiki?curid=37710" title="Enthalpy of vaporization">
Enthalpy of vaporization

The enthalpy of vaporization, (symbol ∆Hvap) also known as the (latent) heat of vaporization or heat of evaporation, is the enthalpy change required to transform a given quantity of a substance from a liquid into a gas at a given pressure (often atmospheric pressure, as in STP). 
It is often measured at the normal boiling point of a substance; although tabulated values are usually corrected to 298 K, the correction is often smaller than the uncertainty in the measured value. 
The heat of vaporization is temperature-dependent, though a constant heat of vaporization can be assumed for small temperature ranges and for reduced temperature Tr«1.0. The heat of vaporization diminishes with increasing temperature and it vanishes completely at the critical temperature (Tr=1) because above the critical temperature the liquid and vapor phases no longer exist, since the substance is a supercritical fluid.
Units.
Values are usually quoted in J/mol or kJ/mol (molar enthalpy of vaporization), although kJ/kg or J/g (specific heat of vaporization), and older units like kcal/mol, cal/g and Btu/lb are sometimes still used, among others.
Physical model for vaporization.
A simple physical model for the liquid–gas phase transformation was proposed in 2009 by Jozsef Garai. It is suggested that the energy required to free an atom from the liquid is equivalent to the energy needed to overcome the surface resistance of the liquid. The model allows calculating the latent heat by multiplying the maximum surface area covering an atom (Fig. 1) with the surface tension and the number of atoms in the liquid. The calculated latent heat of vaporization values for the investigated 45 elements agrees well with experiments. Another model which utilizes the data set from Jozsef Garai's model shows that the liquid–gas phase change can be explained in terms of kinetic theory by considering that the energy required for vaporization is extracted from all six of the vaporizing molecule's neighbours. This includes a required rethink of the probability of vaporization, and has consequences to the Clausius-Clapeyron equation. Moreover, it does resolve the issue of the latent heat of vaporization being significantly greater than the thermal energy exchanged between molecules, i.e. at boiling point the latent heat for water is approximately 13.2 times kT (Boltzmann's factor multiplied by boiling temperature.)
Enthalpy of condensation.
The enthalpy of condensation (or heat of condensation) is by definition equal to the enthalpy of vaporization with the opposite sign: enthalpy changes of vaporization are always positive (heat is absorbed by the substance), whereas enthalpy changes of condensation are always negative (heat is released by the substance).
Thermodynamic background.
The enthalpy of vaporization can be written as 
It is equal to the increased internal energy of the vapor phase compared with the liquid phase, plus the work done against ambient pressure. The increase in the internal energy can be viewed as the energy required to overcome the intermolecular interactions in the liquid (or solid, in the case of sublimation). Hence helium has a particularly low enthalpy of vaporization, 0.0845 kJ/mol, as the van der Waals forces between helium atoms are particularly weak. On the other hand, the molecules in liquid water are held together by relatively strong hydrogen bonds, and its enthalpy of vaporization, 40.65 kJ/mol, is more than five times the energy required to heat the same quantity of water from 0 °C to 100 °C ("c"p = 75.3 J K−1 mol−1). Care must be taken, however, when using enthalpies of vaporization to "measure" the strength of intermolecular forces, as these forces may persist to an extent in the gas phase (as is the case with hydrogen fluoride), and so the calculated value of the bond strength will be too low. This is particularly true of metals, which often form covalently bonded molecules in the gas phase: in these cases, the enthalpy of atomization must be used to obtain a true value of the bond energy.
An alternative description is to view the enthalpy of condensation as the heat which must be released to the surroundings to compensate for the drop in entropy when a gas condenses to a liquid. As the liquid and gas are in equilibrium at the boiling point ("T"b), Δv"G" = 0, which leads to:
As neither entropy nor enthalpy vary greatly with temperature, it is normal to use the tabulated standard values without any correction for the difference in temperature from 298 K. A correction must be made if the pressure is different from 100 kPa, as the entropy of a gas is proportional to its pressure (or, more precisely, to its fugacity): the entropies of liquids vary little with pressure, as the compressibility of a liquid is small.
These two definitions are equivalent: the boiling point is the temperature at which the increased entropy of the gas phase overcomes the intermolecular forces. As a given quantity of matter always has a higher entropy in the gas phase than in a condensed phase (formula_3 is always positive), and from
the Gibbs free energy change falls with increasing temperature: gases are favored at higher temperatures, as is observed in practice.
Vaporization enthalpy of electrolyte solutions.
Estimation of the enthalpy of vaporization of electrolyte solutions can be simply carried out using equations based on the chemical thermodynamic models, such as Pitzer model or TCPC model.
Selected values.
Other common substances.
Enthalpies of vaporization of common substances, measured at their respective standard boiling points:

</doc>
<doc id="37712" url="http://en.wikipedia.org/wiki?curid=37712" title="Chemical patent">
Chemical patent

A chemical patent, pharmaceutical patent or drug patent is a patent for an invention in the chemical or pharmaceuticals industry. Strictly speaking, in most jurisdictions, there are essentially no differences between the legal requirements to obtain a patent for an invention in the chemical or pharmaceutical fields, in comparison to obtaining a patent in the other fields, such as in the mechanical field. A chemical patent or a pharmaceutical patent is therefore "not" a "sui generis" right, i.e. a special legal type of patent.
In the pharmaceutical industry, the patent protection of drugs and medicines is accorded a particular importance, because drugs and medicines can easily be copied or imitated (by analyzing a pharmaceutical substance) and because of the significant research and development spending and the high risks associated with the development of a new drug.
Chemical patents are different from other sources of technical information because of the generic, Markush structures contained within them, named after the inventor Eugene Markush who won a claim in the US in 1925 to allow such structures to be used in patent claims. These generic structures are used to make the patent claim as broad as possible.

</doc>
<doc id="37713" url="http://en.wikipedia.org/wiki?curid=37713" title="The Merchant of Venice">
The Merchant of Venice

The Merchant of Venice is a play by William Shakespeare in which a merchant in 16th century Venice must default on a large loan provided by an abused Jewish moneylender. It is believed to have been written between 1596 and 1598. Though classified as a comedy in the First Folio and sharing certain aspects with Shakespeare's other romantic comedies, the play is perhaps most remembered for its dramatic scenes, and is best known for Shylock and the famous "Hath Not a Jew eyes?" speech. Also notable is Portia's speech about "the quality of mercy". Bassanio is considered as the central hero of the story, and his dearest friend Antonio, mainly described as the kindest man in this world.
The title character is the merchant Antonio, not the Jewish moneylender Shylock, who is the play's most prominent and most famous character. This is made explicit by the title page of the first quarto: "The most excellent History of the Merchant of Venice. With the extreme cruelty of Shylock the Jew towards the said Merchant, ..."
Summary.
Bassanio, a young Venetian of noble rank, wishes to woo the beautiful and wealthy heiress Portia of Belmont. Having squandered his estate, he needs 3,000 ducats to subsidise his expenditures as a suitor. Bassanio approaches his friend Antonio, a wealthy merchant of Venice who has previously and repeatedly bailed him out. Antonio agrees, but since he is cash-poor – his ships and merchandise are busy at sea – he promises to cover a bond if Bassanio can find a lender, so Bassanio turns to the Jewish moneylender Shylock and names Antonio as the loan's guarantor.
Antonio has already antagonized Shylock through his outspoken antisemitism, and because Antonio's habit of lending money without interest forces Shylock to charge lower rates. Shylock is at first reluctant to grant the loan, citing abuse he has suffered at Antonio's hand. He finally agrees to lend the sum to Antonio without interest upon one condition: if Antonio is unable to repay it at the specified date, Shylock may take a pound of Antonio's flesh. Bassanio does not want Antonio to accept such a risky condition; Antonio is surprised by what he sees as the moneylender's generosity (no "usance" – interest – is asked for), and he signs the contract. With money at hand, Bassanio leaves for Belmont with his friend Gratiano, who has asked to accompany him. Gratiano is a likeable young man, but is often flippant, overly talkative, and tactless. Bassanio warns his companion to exercise self-control, and the two leave for Belmont and Portia.
Meanwhile in Belmont, Portia is awash with suitors. Her father left a will stipulating each of her suitors must choose correctly from one of three caskets – one each of gold, silver and lead. If he picks the right casket, he gets Portia. The first suitor, the Prince of Morocco, chooses the gold casket, interpreting its slogan, "Who chooseth me shall gain what many men desire," as referring to Portia. The second suitor, the conceited Prince of Arragon, chooses the silver casket, which proclaims, "Who chooseth me shall get as much as he deserves", as he believes he is full of merit. Both suitors leave empty-handed, having rejected the lead casket because of the baseness of its material and the uninviting nature of its slogan, "Who chooseth me must give and hazard all he hath." The last suitor is Bassanio, whom Portia wishes to succeed, having met him before. As Bassanio ponders his choice, members of Portia's household sing a song which says that "fancy" (not true love) is "engend'red in the eyes, With gazing fed.", Bassanio chooses the lead casket and wins Portia's hand.
At Venice, Antonio's ships are reported lost at sea so the merchant cannot repay the bond. Shylock has become more determined to exact revenge from Christians because his daughter Jessica eloped with the Christian Lorenzo and converted. She took a substantial amount of Shylock's wealth with her, as well as a turquoise ring which Shylock had been given by his late wife, Leah. Shylock has Antonio brought before court.
At Belmont, Bassanio receives a letter telling him that Antonio has been unable to repay the loan from Shylock. Portia and Bassanio marry, as do Gratiano and Portia's handmaid Nerissa. Bassanio and Gratiano leave for Venice, with money from Portia, to save Antonio's life by offering the money to Shylock. Unknown to Bassanio and Gratiano, Portia sent her servant, Balthazar, to seek the counsel of Portia's cousin, Bellario, a lawyer, at Padua.
The climax of the play takes place in the court of the Duke of Venice. Shylock refuses Bassanio's offer of 6,000 ducats, twice the amount of the loan. He demands his pound of flesh from Antonio. The Duke, wishing to save Antonio but unable to nullify a contract, refers the case to a visitor. He identifies himself as Balthazar, a young male "doctor of the law", bearing a letter of recommendation to the Duke from the learned lawyer Bellario. The doctor is Portia in disguise, and the law clerk who accompanies her is Nerissa, also disguised as a man. As Balthazar, Portia repeatedly asks Shylock to show mercy in a famous speech, advising him that mercy "is twice blest: It blesseth him that gives and him that takes" (IV, i, 185). However, Shylock adamantly refuses any compensations and insists on the pound of flesh.
As the court grants Shylock his bond and Antonio prepares for Shylock's knife, Portia deftly appropriates Shylock's argument for 'specific performance.' She says that the contract allows Shylock only to remove the "flesh", not the "blood", of Antonio (see quibble). Thus, if Shylock were to shed any drop of Antonio's blood, his "lands and goods" would be forfeited under Venetian laws. She tells him that he must cut precisely one pound of flesh, no more, no less; she advises him that "if the scale do turn, But in the estimation of a hair, Thou diest and all thy goods are confiscate."
Defeated, Shylock concedes to accepting Bassanio's offer of money for the defaulted bond, first his offer to pay "the bond thrice", which Portia rebuffs, telling him to take his bond, and then merely the principal, which Portia also prevents him from doing on the ground that he has already refused it "in the open court." She cites a law under which Shylock, as a Jew and therefore an "alien", having attempted to take the life of a citizen, has forfeited his property, half to the government and half to Antonio, leaving his life at the mercy of the Duke. The Duke pardons Shylock's life. Antonio asks for his share "in use" until Shylock's death, when the principal will be given to Lorenzo and Jessica. At Antonio's request, the Duke grants remission of the state's half of forfeiture, but on the condition that Shylock convert to Christianity and bequeath his entire estate to Lorenzo and Jessica (IV,i).
Bassanio does not recognise his disguised wife, but offers to give a present to the supposed lawyer. First she declines, but after he insists, Portia requests his ring and Antonio's gloves. Antonio parts with his gloves without a second thought, but Bassanio gives the ring only after much persuasion from Antonio, as earlier in the play he promised his wife never to lose, sell or give it. Nerissa, as the lawyer's clerk, succeeds in likewise retrieving her ring from Gratiano, who does not see through her disguise.
At Belmont, Portia and Nerissa taunt and pretend to accuse their husbands before revealing they were really the lawyer and his clerk in disguise (V). After all the other characters make amends, Antonio learns from Portia that three of his ships were not stranded and have returned safely after all.
Sources.
The forfeit of a merchant's deadly bond after standing surety for a friend's loan was a common tale in England in the late 16th century. In addition, the test of the suitors at Belmont, the merchant's rescue from the "pound of flesh" penalty by his friend's new wife disguised as a lawyer, and her demand for the betrothal ring in payment are all elements present in the 14th-century tale "" by Giovanni Fiorentino, which was published in Milan in 1558. Elements of the trial scene are also found in "The Orator" by Alexandre Sylvane, published in translation in 1596. The story of the three caskets can be found in "Gesta Romanorum", a collection of tales probably compiled at the end of the 13th century.
Date and text.
The date of composition for "The Merchant of Venice" is believed to be between 1596 and 1598. The play was mentioned by Francis Meres in 1598, so it must have been familiar on the stage by that date. The title page of the first edition in 1600 states that it had been performed "divers times" by that date. Salerino's reference to his ship the "Andrew" (I,i,27) is thought to be an allusion to the Spanish ship "St. Andrew," captured by the English at Cádiz in 1596. A date of 1596–97 is considered consistent with the play's style.
The play was entered in the Register of the Stationers Company, the method at that time of obtaining copyright for a new play, by James Roberts on 22 July 1598 under the title "The Merchant of Venice", otherwise called "The Jew of Venice". On 28 October 1600 Roberts transferred his right to the play to the stationer Thomas Heyes; Heyes published the first quarto before the end of the year. It was printed again in a pirated edition in 1619, as part of William Jaggard's so-called False Folio. (Afterward, Thomas Heyes' son and heir Laurence Heyes asked for and was granted a confirmation of his right to the play, on 8 July 1619.) The 1600 edition is generally regarded as being accurate and reliable. It is the basis of the text published in the 1623 First Folio, which adds a number of stage directions, mainly musical cues.
Themes.
Shylock and the antisemitism debate.
The play is frequently staged today, but is potentially troubling to modern audiences due to its central themes, which can easily appear antisemitic. Critics today still continue to argue over the play's stance on antisemitism.
Shylock as a villain.
English society in the Elizabethan era has been described as "judeophobic". English Jews had been expelled under Edward I in 1290 and were not permitted to return until 1656 under the rule of Oliver Cromwell. In Venice and in some other places, Jews were required to wear a red hat at all times in public to make sure that they were easily identified, and had to live in a ghetto protected by Christian guards. On the Elizabethan stage, Jews were often presented in an Orientalist caricature, with hooked noses and bright red wigs, and were usually depicted as avaricious usurers; an example is Christopher Marlowe's play "The Jew of Malta", which features a comically wicked Jewish villain called Barabas. They were usually characterised as evil, deceitful and greedy.
Shakespeare's play may be seen as a continuation of this tradition. The title page of the Quarto indicates that the play was sometimes known as "The Jew of Venice" in its day, which suggests that it was seen as similar to Marlowe's "The Jew of Malta". One interpretation of the play's structure is that Shakespeare meant to contrast the mercy of the main Christian characters with the vengefulness of a Jew, who lacks the religious grace to comprehend mercy. Similarly, it is possible that Shakespeare meant Shylock's forced conversion to Christianity to be a "happy ending" for the character, as, to a Christian audience, it saves his soul and allows him to enter Heaven.
Regardless of what Shakespeare's authorial intent may have been, the play has been made use of by antisemites throughout the play's history. One must note that the end of the title in the 1619 edition "With the Extreme Cruelty of Shylock the Jew..." must aptly describe how Shylock was viewed by the English public. The Nazis used the usurious Shylock for their propaganda. Shortly after Kristallnacht in 1938, "The Merchant of Venice" was broadcast for propagandistic ends over the German airwaves. Productions of the play followed in Lübeck (1938), Berlin (1940), and elsewhere within the Nazi Territory.
In a series of articles called "Observer", first published in 1785, British playwright Richard Cumberland created a character named Abraham Abrahams who is quoted as saying, "I verily believe the odious character of Shylock has brought little less persecution upon us, poor scattered sons of Abraham, than the Inquisition itself." Cumberland later wrote a successful play, "The Jew" (1794), in which his title character, Sheva, is portrayed sympathetically, as both a kindhearted and generous man. This was the first known attempt by a dramatist to reverse the negative stereotype that Shylock personified.
The depiction of Jews in literature throughout the centuries bears the close imprint of Shylock. With slight variations much of English literature up until the 20th century depicts the Jew as "a monied, cruel, lecherous, avaricious outsider tolerated only because of his golden hoard".
Shylock as a sympathetic character.
Many modern readers and theatregoers have read the play as a plea for tolerance, noting that Shylock is a sympathetic character. They cite as evidence that Shylock's 'trial' at the end of the play is a mockery of justice, with Portia acting as a judge when she has no right to do so. The characters who berated Shylock for dishonesty resort to trickery in order to win. In addition, Shakespeare gives Shylock one of his most eloquent speeches:
<poem>
To bait fish withal; If it will feed nothing else, it will feed my revenge.
He hath disgraced me and hindered me half a million
Laughed at my losses, mocked at my gains,
Scorned my nation, Thwarted my bargains,
And what's his reason? I am a Jew!
Hath not a Jew eyes? Hath not a Jew hands, organs,
dimensions, senses, affections, passions; fed with
the same food, hurt with the same weapons, subject
to the same diseases, healed by the same means,
warmed and cooled by the same winter and summer
as a Christian is? If you prick us, do we not bleed?
If you tickle us, do we not laugh? If you poison us,
do we not die? And if you wrong us, shall we not revenge?
If we are like you in the rest, we will resemble you in that.
If a Jew wrong a Christian, what is his humility?
Revenge. If a Christian wrong a Jew, what should his
sufferance be by Christian example? Why, revenge.
The villainy you teach me, I will execute,
and it shall go hard but I will better the instruction.
(Act III, scene I)</poem>
It is difficult to know whether the sympathetic reading of Shylock is entirely due to changing sensibilities among readers, or whether Shakespeare, a writer who created complex, multi-faceted characters, deliberately intended this reading.
One of the reasons for this interpretation is that Shylock's painful status in Venetian society is emphasised. To some critics, Shylock's celebrated "Hath Not a Jew eyes?" speech (see above) redeems him and even makes him into something of a tragic figure; in the speech, Shylock argues that he is no different from the Christian characters. Detractors note that Shylock ends the speech with a tone of revenge: "if you wrong us, shall we not revenge?" Those who see the speech as sympathetic point out that Shylock says he learned the desire for revenge from the Christian characters: "If a Christian wrong a Jew, what should his sufferance be by Christian example? Why, revenge. The villainy you teach me, I will execute, and it shall go hard but I will better the instruction."
Even if Shakespeare did not intend the play to be read this way, the fact that it retains its power on stage for audiences who may perceive its central conflicts in radically different terms is an illustration of the subtlety of Shakespeare's characterisations. In the trial Shylock represents what Elizabethan Christians believed to be the Jewish desire for "justice", contrasted with their obviously superior Christian value of mercy. The Christians in the courtroom urge Shylock to love his enemies, although they themselves have failed in the past. Harold Bloom explains that, although the play gives merit to both cases, the portraits are not even-handed: "Shylock’s shrewd indictment of Christian hypocrisy [delights us, but]…Shakespeare’s intimations do not alleviate the savagery of his portrait of the Jew…" However, it can rightly be said that
<poem>
Is Shylock content truly?
Even after losing his religion eternally,
As someone bids farewell,
To a departing soul bound for heaven or hell!
It indeed is arguable,
Yet what my heart longs to tell,
Is that Shylock does deserve penalty,
But his religion certainly is not guilty!</poem>
Antonio, Bassanio.
Antonio's unexplained depression — "In sooth I know not why I am so sad" — and utter devotion to Bassanio has led some critics to theorise that he is suffering from unrequited love for Bassanio and is depressed because Bassanio is coming to an age where he will marry a woman. In his plays and poetry Shakespeare often depicted strong male bonds of varying homosociality, which has led some critics to infer that Bassanio returns Antonio's affections despite his obligation to marry:
<poem>ANTONIO: Commend me to your honourable wife:
Tell her the process of Antonio's end,
Say how I lov'd you, speak me fair in death;
And, when the tale is told, bid her be judge
Whether Bassanio had not once a love.
BASSANIO: But life itself, my wife, and all the world
Are not with me esteemed above thy life;
I would lose all, ay, sacrifice them all
Here to this devil, to deliver you. (IV,i)</poem>
In his essay "Brothers and Others", published in "The Dyer's Hand," W. H. Auden describes Antonio as "a man whose emotional life, though his conduct may be chaste, is concentrated upon a member of his own sex." Antonio's feelings for Bassanio are likened to a couplet from Shakespeare's Sonnets: "But since she pricked thee out for women's pleasure,/ Mine be thy love, and my love's use their treasure." Antonio, says Auden, embodies the words on Portia's leaden casket: "Who chooseth me, must give and hazard all he hath." Antonio has taken this potentially fatal turn because he despairs, not only over the loss of Bassanio in marriage, but also because Bassanio cannot requite what Antonio feels for him. Antonio's frustrated devotion is a form of idolatry: the right to live is yielded for the sake of the loved one. There is one other such idolator in the play: Shylock himself. "Shylock, however unintentionally, did, in fact, hazard all for the sake of destroying the enemy he hated; and Antonio, however unthinkingly he signed the bond, hazarded all to secure the happiness of the man he loved." Both Antonio and Shylock, agreeing to put Antonio's life at a forfeit, stand outside the normal bounds of society. There was, states Auden, a traditional "association of sodomy with usury", reaching back at least as far as Dante, with which Shakespeare was likely familiar. (Auden sees the theme of usury in the play as a comment on human relations in a mercantile society.)
Other interpreters of the play regard Auden's conception of Antonio's sexual desire for Bassanio as questionable. Michael Radford, director of the 2004 film version starring Al Pacino, explained that although the film contains a scene where Antonio and Bassanio actually kiss, the friendship between the two is platonic, in line with the prevailing view of male friendship at the time. Jeremy Irons, in an interview, concurs with the director's view and states that he did not "play Antonio as gay". Joseph Fiennes, however, who plays Bassanio, encouraged a homoerotic interpretation and, in fact, surprised Irons with the kiss on set, which was filmed in one take. Fiennes defended his choice, saying "I would never invent something before doing my detective work in the text. If you look at the choice of language ... you'll read very sensuous language. That's the key for me in the relationship. The great thing about Shakespeare and why he's so difficult to pin down is his ambiguity. He's not saying they're gay or they're straight, he's leaving it up to his actors. I feel there has to be a great love between the two characters ... there's great attraction. I don't think they have slept together but that's for the audience to decide."
Performance history.
The earliest performance of which a record has survived was held at the court of King James in the spring of 1605, followed by a second performance a few days later, but there is no record of any further performances in the 17th century. In 1701, George Granville staged a successful adaptation, titled "The Jew of Venice", with Thomas Betterton as Bassanio. This version (which featured a masque) was popular, and was acted for the next forty years. Granville cut the clownish Gobbos in line with neoclassical decorum; he added a jail scene between Shylock and Antonio, and a more extended scene of toasting at a banquet scene. Thomas Doggett was Shylock, playing the role comically, perhaps even farcically. Rowe expressed doubts about this interpretation as early as 1709; Doggett's success in the role meant that later productions would feature the troupe clown as Shylock.
In 1741, Charles Macklin returned to the original text in a very successful production at Drury Lane, paving the way for Edmund Kean seventy years later (see below).
Arthur Sullivan wrote incidental music for the play in 1871.
Shylock on stage.
Jewish actor Jacob Adler and others report that the tradition of playing Shylock sympathetically began in the first half of the 19th century with Edmund Kean, and that previously the role had been played "by a comedian as a repulsive clown or, alternatively, as a monster of unrelieved evil." Kean's Shylock established his reputation as an actor.
From Kean's time forward, all of the actors who have famously played the role, with the exception of Edwin Booth, who played Shylock as a simple villain, have chosen a sympathetic approach to the character; even Booth's father, Junius Brutus Booth, played the role sympathetically. Henry Irving's portrayal of an aristocratic, proud Shylock (first seen at the Lyceum in 1879, with Portia played by Ellen Terry) has been called "the summit of his career". Jacob Adler was the most notable of the early 20th century: Adler played the role in Yiddish-language translation, first in Manhattan's Yiddish Theater District in the Lower East Side, and later on Broadway, where, to great acclaim, he performed the role in Yiddish in an otherwise English-language production.
Kean and Irving presented a Shylock justified in wanting his revenge; Adler's Shylock evolved over the years he played the role, first as a stock Shakespearean villain, then as a man whose better nature was overcome by a desire for revenge, and finally as a man who operated not from revenge but from pride. In a 1902 interview with "Theater" magazine, Adler pointed out that Shylock is a wealthy man, "rich enough to forgo the interest on three thousand ducats" and that Antonio is "far from the chivalrous gentleman he is made to appear. He has insulted the Jew and spat on him, yet he comes with hypocritical politeness to borrow money of him." Shylock's fatal flaw is to depend on the law, but "would he not walk out of that courtroom head erect, the very apotheosis of defiant hatred and scorn?"
Some modern productions take further pains to show the sources of Shylock's thirst for vengeance. For instance, in the 2004 film adaptation directed by Michael Radford and starring Al Pacino as Shylock, the film begins with text and a montage of how Venetian Jews are cruelly abused by bigoted Christians. One of the last shots of the film also brings attention to the fact that, as a convert, Shylock would have been cast out of the Jewish community in Venice, no longer allowed to live in the ghetto. Another interpretation of Shylock and a vision of how "must he be acted" appears at the conclusion of the autobiography of Alexander Granach, a noted Jewish stage and film actor in Weimar Germany (and later in Hollywood and on Broadway).
Adaptations and cultural references.
Film and TV versions.
The Shakespeare play has inspired several films.
Cultural references.
Arnold Wesker's play "The Merchant" tells the same story from Shylock's point of view. In this retelling, Shylock and Antonio are fast friends bound by a mutual love of books and culture and a disdain for the crass anti-Semitism of the Christian community's laws. They make the bond in defiant mockery of the Christian establishment, never anticipating that the bond might become forfeit. When it does, the play argues, Shylock must carry through on the letter of the law or jeopardise the scant legal security of the entire Jewish community. He is, therefore, quite as grateful as Antonio when Portia, as in Shakespeare's play, shows the legal way out. The play received its American premiere on 16 November 1977 at New York's Plymouth Theatre, with Joseph Leon as Shylock and Marian Seldes as Shylock's sister Rivka. This production had a challenging history in previews on the road, culminating (after the first night out of town in Philadelphia on 8 September 1977) with the death of the larger-than-life Broadway star Zero Mostel, who was initially cast as Shylock. The play's author, Arnold Wesker, wrote a book chronicling the out-of-town tribulations that beset the play and Zero's death called "The Birth of Shylock and the Death of Zero Mostel".
David Henry Wilson's play "Shylock's Revenge", which was first performed by The University Players at the Audimax, Hamburg, on 9 June 1989, can be seen as a full-length sequel to Shakespeare's drama.
The title of the film "Seven Pounds" is a reference to the "pound of flesh" from the play.
Edmond Haraucourt, the French playwright and poet, was commissioned in the 1880s by the actor and theatrical director Paul Porel to make a French-verse adaptation of "The Merchant of Venice". His play "Shylock", first performed at the Théâtre de l'Odéon in December 1889, had incidental music by the French composer Gabriel Fauré, later incorporated into an orchestral suite of the same name.
One of the four short stories comprising Alan Isler's "Op Non Cit" is also told from Shylock's point of view. In this story, Antonio was a boy of Jewish origin kidnapped at an early age by priests.
Ralph Vaughan Williams' choral work "Serenade to Music" draws its text from the discussion about music and the music of the spheres in Act V, scene 1.
In both versions of the comic film "To Be or Not to Be" the character "Greenberg", specified as a Jew only in the later version, gives a recitation of the "Hath Not a Jew eyes?" speech to Nazi soldiers.
In "The Pianist", Henryk Szpilman quotes a passage from Shylock's "Hath Not a Jew eyes?" speech to his brother Władysław Szpilman in a Jewish ghetto in Warsaw, Poland, during the Nazi occupation in World War II. Given the questioning of Antisemitism in the speech and also the Nazi use of the play for antisemitic propaganda purposes, the quote is seen as particularly poignant and symbolic.
Steven Spielberg's "Schindler's List" depicts SS Lieutenant Amon Göth quoting Shylock's "Hath Not a Jew eyes?" speech when deciding whether or not to rape his Jewish maid.
The rock musical "Fire Angel" was based on the story of the play, with the scene changed to the Little Italy district of New York. It was performed in Edinburgh in 1974 and in a revised form at Her Majesty's Theatre, London, in 1977.
Christopher Moore combines "The Merchant of Venice" and "Othello" in his 2014 comic novel "The Serpent of Venice", in which he makes Portia (from "The Merchant of Venice") and Desdemona (from "Othello") sisters. All of the characters come from those two plays with the exception of Pocket, the Fool, who comes from Moore's earlier novel based on "King Lear".
Jane Lindskold's book "Changer" contains a scene in which the protagonists consider "using Portia's gambit from "The Merchant of Venice"" to escape from a situation and binding contract analogous to Antonio's.
The online satirical news site "The Onion" satirized the play in its article "'Unconventional Director Sets Shakespeare Play In Time, Place Shakespeare Intended".
The play has been quoted and paraphrased several times in the "Star Trek" Universe:
The David Seltzer screenplay for the 1971 film "Willy Wonka and the Chocolate Factory" contains this line, near the end of the film: spoken by Willy Wonka, as if to himself, when Charlie returns the Everlasting Gobstopper: "So shines a good deed in a weary world"- derived perhaps from Portia's lines in Act V, Scene 1: "That light we see is burning in my hall. How far that little candle throws his beams! So shines a good deed in a naughty world."

</doc>
<doc id="37714" url="http://en.wikipedia.org/wiki?curid=37714" title="Energia">
Energia

Energia (Russian: Энергия, "Energiya", "Energy") was a Soviet rocket that was designed by NPO Energia to serve as a heavy-lift expendable launch system as well as a booster for the Buran spacecraft. Control system main developer enterprise was the NPO "Electropribor". The Energia used four strap-on boosters each powered by a four-chamber RD-170 engine burning kerosene/LOX, and a central core stage with 4 one-chamber RD-0120 (11D122) engines fueled by liquid hydrogen/LOX.
The launch system had two functionally different operational variants: "Energia-Polyus", the initial test configuration, in which the Polyus system was used as a final stage to put the payload into orbit, and "Energia-Buran", in which the Buran spacecraft was the payload and the source of the orbit insertion impulse.
The rocket had the capacity to place about 100 tonnes in Low Earth orbit, up to 20 tonnes to geostationary orbit and up to 32 tonnes to a translunar trajectory.
History.
Development.
Work on the Energia/Buran system began in 1976 after the decision was made to cancel the unsuccessful N1 rocket. The cancelled N1 rocket-based Manned Lunar Launch Facilities and Infrastructure were used for Energia (notably the huge horizontal assembly building), just as NASA reused infrastructure designed for the Saturn V in the Space Shuttle program. Energia also replaced the "Vulkan" concept, which was a design based on the Proton rocket and using the same hypergolic fuels, but much larger and more powerful. The "Vulkan" designation was later given to a variation of the Energia which has eight boosters and multiple stages.
The Energia was designed to launch the Russian "Buran" reusable shuttle, and for that reason was designed to carry its payload mounted on the side of the stack, rather than on the top, as is done with other launch vehicles. After design of the Energia-Buran system, it was also proposed that the booster could be used without the Buran as a heavy-lift cargo launch vehicle; this configuration was originally given the name "Buran-T". This configuration required the addition of an upper stage to perform the final orbital insertion. The first launch of the Energia was in the configuration of a heavy launch vehicle, with the large Polyus military satellite as a payload, however Polyus failed to correctly perform the orbital insertion.
Due to the termination of the Buran program the Energia program was concluded after only two launches, and further the payload on the first launch didn't perform the final boost properly. The legacy of Energia/Buran project manifests itself most visibly in form of the RD-170 family of rocket engines, and the Zenit launcher, with the first stage roughly the same as one of the Energia first-stage boosters.
First launch (Energia-Polyus).
The Energia was first test-launched on 15 May 1987, with the Polyus spacecraft as the payload. A FGB ("Functional Cargo Block") engine section originally built as a cancelled Mir module was incorporated into the upper stage used to inject the payload into orbit, similarly to Buran and the US Space Shuttle performing the final orbital insertion, since the planned "Buran-T" upper stage had not yet progressed beyond the planning stage. The intended orbit was altitude 280 km (170 mi), inclination 64.6°.
The Soviets had originally announced that the launch was a successful sub-orbital test of the new Energia booster with a dummy payload, but some time later it was revealed that the flight had, in fact, been intended to orbit the Polyus, a UKSS (Russian: "Универсальный Комплекс Стенд-Старт", Universal Complex Stand-Start) military payload. The two stages of the Energia launcher functioned as designed, but due to a software error in its attitude control system, Polyus' orbital insertion motor failed to inject the payload into orbit. Instead, the Polyus reentered the atmosphere over the Pacific ocean.
Second launch (Energia-Buran).
The second flight, and the first one where payload successfully reached orbit, was launched on 15 November 1988. This mission launched the unmanned Soviet Shuttle vehicle, Buran. At apogee, the Buran spacecraft made a 66.7 m/s burn to reach a final orbit of 251 km x 263 km.
Discontinuation.
Production of Energia rockets ended with the fall of the Soviet Union and the end of the Buran shuttle project. Ever since, there have been persistent rumors of the renewal of production, but given the current political realities, that is highly unlikely. While the Energia is no longer in production, the Zenit boosters are still in production and in use. The four strap-on liquid-fuel boosters, which burned kerosene and liquid oxygen, were the basis of the Zenit rocket which used the same engines. The engine is the four combustion chamber RD-170. Its derivative, the RD-171, is still used on the Zenit rocket. A half-sized derivative of the engine, the two-chamber RD-180, powers Lockheed Martin's Atlas V rocket, while the single-chamber derivative, the RD-191, has been used to launch the Korean Naro-1 (as a reduced-thrust variant named the RD-151) and the Russian Angara rocket.
Restart.
Restart has been mooted several times, most recently in November 2013.
Variants.
Three major variants were planned after the original configuration, each with vastly different payloads.
Energia M.
The Energia M was the smallest design configuration. The number of Zenit boosters was reduced from four to two, and instead of four RD-0120 engines in the core, it had only one. It was designed to replace the Proton rocket, but lost the 1993 competition to the Angara rocket.
Energia II ("Uragan").
Energia II, named Uragan (Russian: Ураган, "Hurricane"), was a rocket planned to be fully reusable and would have been able to land on a conventional airfield. Unlike the Energia, which was planned to be semi-reusable (like that of the U.S. Space Shuttle), the Uragan design would have allowed the complete recovery of all Buran/Energia elements, like that of the original totally reusable Orbiter/Booster concept of the U.S. Shuttle. The Energia II core as proposed would be capable of re-entering and gliding to a landing, presumably using technology developed for the Buran.
Vulkan-Hercules.
The final unflown configuration was also the largest. With eight Zenit booster rockets and an Energia-M core as the upper stage, the "Vulkan" (which was the same name of another Soviet heavy lift rocket that was cancelled years earlier) or "Hercules" (which is the same name designated to the N-1 rockets) configuration could have launched up to 175 tonnes into orbit.
The development of rocket-carrier "Vulcan" and the refurbishment of the "Energia" launch pad for its launches was in progress in 1990-1993. But later on the work on this project was cancelled due to lack of funds and the collapse of Soviet Union.

</doc>
<doc id="37715" url="http://en.wikipedia.org/wiki?curid=37715" title="Allegro">
Allegro

Allegro may refer to:

</doc>
<doc id="37716" url="http://en.wikipedia.org/wiki?curid=37716" title="Presto">
Presto

Presto may refer to:

</doc>
<doc id="37717" url="http://en.wikipedia.org/wiki?curid=37717" title="Crescendo (disambiguation)">
Crescendo (disambiguation)

Crescendo is a passage of music during which the volume gradually increases.
Crescendo may also refer to:

</doc>
<doc id="37720" url="http://en.wikipedia.org/wiki?curid=37720" title="Staccato">
Staccato

Staccato (Italian for "detached") is a form of musical articulation. In modern notation it signifies a note of shortened duration, separated from the note that may follow by silence. It has been described by theorists and appeared in music since the 18th century.
Notation.
In 20th-century music, a dot placed above or below a note indicates that it should be played staccato, and a wedge is used for the more emphatic staccatissimo. However, before 1850, dots, dashes, and wedges were all likely to have the same meaning, even though some theorists from as early as the 1750s distinguished different degrees of staccato through the use of dots and dashes, with the dash indicating a shorter, sharper note, and the dot a longer, lighter one. A number of signs came to be used in the late 19th and early 20th centuries to discriminate more subtle nuances of staccato. These signs involve various combinations of dots, vertical and horizontal dashes, vertical and horizontal wedges, and the like, but attempts to standardize these signs have not generally been successful. This does not, however, alter the rhythm of the music and the remainder of the time allotted for each staccato note is played as rest. The opposite musical articulation of staccato is legato, signifying long and continuous notes.
The scope of the staccato dot:
In the first measure, the pairs of notes are in the same musical part since they are on a common stem. The staccato applies to both notes of the pairs. In the second measure, the pairs of notes are stemmed separately indicating two different parts, so the staccato applies only to the upper note.
Playing staccato is the opposite of playing legato. A staccato passage for strings is by definition a bowed rather than a pizzicato technique, though pizzicato itself might be thought of as a kind of staccato effect. For example, Leroy Anderson's "Jazz Legato/Jazz Pizzicato". There is an intermediate articulation called either mezzo staccato or non-legato.

</doc>
<doc id="37721" url="http://en.wikipedia.org/wiki?curid=37721" title="Legato">
Legato

In music performance and notation, legato (Italian for "tied together") indicates that musical notes are played or sung smoothly and connected. That is, the player transitions from note to note with no intervening silence. Legato technique is required for slurred performance, but unlike slurring (as that term is interpreted for some instruments), legato does not forbid rearticulation. Standard notation indicates legato either with the word "legato," or by a slur (a curved line) under notes that form one legato group. Legato, like staccato, is a kind of articulation. There is an intermediate articulation called either mezzo staccato or non-legato (sometimes referred to as "portato").
Classical stringed instruments.
In music for classical stringed instruments, legato is an articulation that often refers to notes played with a full bow, and played with the shortest silence, often barely perceptible, between notes. The player achieves this through controlled wrist movements of the bowing hand, often masked or enhanced with vibrato. Such a legato style of playing can also be associated with portamento.
Guitar.
In guitar playing (apart from classical guitar) legato is used interchangeably as a label for both musical articulation and a particular application of technique—playing musical phrases with predominantly hammer-ons or pull-offs instead of picking. Legato "technique" to provide legato "articulation" on electric guitar generally requires playing notes that are close and on the same string, following the first note with others that are played by hammer-ons and pull-offs.
Some guitar virtuosos (notably Allan Holdsworth and Shawn Lane) developed their legato technique to the extent that they could perform extremely complex passages involving any permutation of notes on a string at extreme tempos, and particularly in the case of Holdsworth, tend to eschew pull-offs entirely for what some feel is a detrimental effect on guitar tone as the string is pulled slightly sideways.
The term "hammer-ons from nowhere" is commonly employed when crossing strings and relying solely on fretting hand strength to produce a note.
Many guitar virtuosos are well-versed in the legato technique, as it allows for rapid and "clean" runs. Multiple hammer-ons and pull-offs together are sometimes also referred to colloquially as "rolls," a reference to the fluid sound of the technique. A rapid series of hammer-ons and pull-offs between a single pair of notes is called a trill. 
Legato on guitar is commonly associated with playing more notes within a beat than the stated timing, i.e., playing 5 (a quintuplet) or 7 (a septuplet) notes against a quarter-note instead of the usual even number or triplet. This gives the passage an unusual timing and when played slowly an unusual sound. However, this is less noticeable by ear when played fast, as legato usually is. There is a fine line between legato and two-hand finger tapping, in some cases making the two techniques harder to distinguish by ear. Generally, legato adds a more fluid, smooth sound to a passage.
Synthesizers.
In synthesizers legato is a type of monophonic operation. In contrast to the typical monophonic mode where every new note rearticulates the sound by restarting the envelope generators, in legato mode the envelopes are not re-triggered if the new note is played "legato" (with the previous note still depressed). This causes the initial transient from the attack and decay phases to sound only once for an entire legato sequence of notes. Envelopes reaching the sustain stage remain there until the final note is released.
Vocal music.
In classical singing, legato means a string of sustained vowels with minimal interruption from consonants. It is a key characteristic of the bel canto singing style that prevailed among voice teachers and singers during the 18th century and the first four decades of the 19th century. Usually referred to as "the line", a good, smooth legato is still necessary for successful classical singers. 
In Western Classical vocal music, singers generally use it on any phrase without explicit articulation marks. Usually the most prevalent issue with vocal legato is maintaining the "line" across registers.

</doc>
<doc id="37724" url="http://en.wikipedia.org/wiki?curid=37724" title="Largo">
Largo

Largo may refer to:

</doc>
<doc id="37725" url="http://en.wikipedia.org/wiki?curid=37725" title="Tuning">
Tuning

Tuning can refer to: 

</doc>
<doc id="37726" url="http://en.wikipedia.org/wiki?curid=37726" title="Octave">
Octave

In music, an octave (Latin: "octavus": eighth) or perfect octave is the interval between one musical pitch and another with half or double its frequency. It is defined by ANSI as the unit of frequency level when the base of the logarithm is two. The octave relationship is a natural phenomenon that has been referred to as the "basic miracle of music", the use of which is "common in most musical systems".
The most important musical scales are typically written using eight notes, and the interval between the first and last notes is an octave. For example, the C Major scale is typically written C D E F G A B C, the initial and final C's being an octave apart. Two notes separated by an octave have the same letter name and are of the same pitch class.
Three commonly cited examples of melodies featuring the perfect octave as their opening interval are "Singin' in the Rain", "Somewhere Over the Rainbow", and "Stranger on the Shore".
The interval between the first and second harmonics of the harmonic series is an octave.
The octave has occasionally been referred to as a diapason.
To emphasize that it is one of the perfect intervals (including unison, perfect fourth, and perfect fifth), the octave is designated P8. The octave above or below an indicated note is sometimes abbreviated 8va (= Italian "all'ottava"), 8va bassa (= Italian "all'ottava bassa", sometimes also 8vb), or simply 8 for the octave in the direction indicated by placing this mark above or below the staff.
Theory.
For example, if one note has a frequency of 440 Hz, the note an octave above it is at 880 Hz, and the note an octave below is at 220 Hz. The ratio of frequencies of two notes an octave apart is therefore 2:1. Further octaves of a note occur at 2"n" times the frequency of that note (where "n" is an integer), such as 2, 4, 8, 16, etc. and the reciprocal of that series. For example, 55 Hz and 440 Hz are one and two octaves away from 110 Hz because they are 0.5 (or 2 −1) and 4 (or 22) times the frequency, respectively.
After the unison, the octave is the simplest interval in music. The human ear tends to hear both notes as being essentially "the same", due to closely related harmonics. Notes separated by an octave "ring" together, adding a pleasing sound to music. For this reason, notes an octave apart are given the same note name in the Western system of music notation—the name of a note an octave above A is also A. This is called octave equivalency, the assumption that pitches one or more octaves apart are musically equivalent in many ways, leading to the convention "that scales are uniquely defined by specifying the intervals within an octave". The conceptualization of pitch as having two dimensions, pitch height (absolute frequency) and pitch class (relative position within the octave), inherently include octave circularity. Thus all C♯s, or all 1s (if C = 0), in any octave are part of the same pitch class.
Octave equivalency is a part of most "advanced musical cultures", but is far from universal in "primitive" and early music.
The languages in which the oldest extant written documents on tuning are written, Sumerian and Akkadian, have no known word for "octave". However, it is believed that a set of cuneiform tablets that collectively describe the tuning of a nine-stringed instrument, believed to be a Babylonian lyre, describe tunings for seven of the strings, with indications to tune the remaining two strings an octave from two of the seven tuned strings.
Leon Crickmore recently proposed that "The octave may not have been thought of as a unit in its own right, but rather by analogy like the first day of a new seven-day week".
Monkeys experience octave equivalency, and its biological basis apparently is an octave mapping of neurons in the auditory thalamus of the mammalian brain. Studies have also shown the perception of octave equivalence in rats (Blackwell & Schlosberg, 1943), human infants (Demany & Armand, 1984), and musicians (Allen, 1967) but not starlings (Cynx, 1993), 4-9 year old children (Sergeant, 1983), or nonmusicians (Allen, 1967).
While octaves commonly refer to the perfect octave (P8), the interval of an octave in music theory encompasses chromatic alterations within the pitch class, meaning that G♮ to G♯ (13 semitones higher) is an Augmented octave (A8), and G♮ to G♭ (11 semitones higher) is a diminished octave (d8). The use of such intervals is rare, as there is frequently a preferable enharmonic notation available, but these categories of octaves must be acknowledged in any full understanding of the role and meaning of octaves more generally in music.
Notation.
Octaves are identified with various naming systems. Among the most common are the Scientific, Helmholtz, Organ Pipe, Midi, and Midi Note systems.
In writing, a specific octave is often indicated through the addition of a number after the note letter name. Thus middle C is "C4", because of the note's position as the fourth C key on a standard 88-key piano keyboard, while the C above is "C5", in a system known as scientific pitch notation.
The notation 8va is sometimes seen in sheet music, meaning "play this an octave higher than written" (all' ottava: "at the octave" or "all' 8va"). "8va" stands for "ottava", the Italian word for octave (or "eighth"); the octave above may be specified as "ottava alta" or "ottava sopra"). Sometimes 8va is used to tell the musician to play a passage an octave "lower", though the similar notation 8vb ("ottava bassa" or "ottava sotta") is more common. Similarly, 15ma ("quindicesima") means "play two octaves higher than written" and 15mb ("quindicesima bassa") means "play two octaves lower than written." The abbreviations col 8, coll' 8, and c. 8va stand for "coll'ottava", meaning "play the notes in the passage together with the notes in the notated octaves". Any of these directions can be cancelled with the word "loco", but often a dashed line or bracket indicates the extent of the music affected.
For music-theoretical purposes (not on sheet music), "octave" can be abbreviated as P8 (which is an abbreviation for Perfect Eighth, the interval between 12 semitones or an octave).
First octave.
In music theory, the first octave, also called the contra octave, ranges from C1, or about 32.7 Hz, to C2, about 65.4 Hz, in equal temperament using A440 tuning. This is the lowest complete octave of most pianos (excepting the Bösendorfer Imperial Grand). The lowest notes of instruments such as double bass, electric bass, extended-range bass clarinet, contrabass clarinet, bassoon, contrabassoon, tuba and sousaphone are part of the first octave.
The ability of vocalists to sing competently in the first octave is rare, even for males. A singer who can reach notes in this range is known as a basso profondo, Italian for "deep bass". A Russian bass can also sing in this range, and the fundamental pitches sung by Tibetan monks and the throat singers of Siberia and Mongolia are in this range.

</doc>
<doc id="37727" url="http://en.wikipedia.org/wiki?curid=37727" title="Willow Rosenberg">
Willow Rosenberg

Willow Rosenberg is a fictional character created for the fantasy television series "Buffy the Vampire Slayer" (1997–2003). She was developed by Joss Whedon and portrayed throughout the TV series by Alyson Hannigan.
Willow plays an integral role within the inner circle of friends—called the Scooby Gang—who support Buffy Summers, a teenager gifted with superhuman powers to defeat vampires, demons, and other evil in the fictional town of Sunnydale. The series begins as Buffy, Willow, and their friend Xander are in 10th grade and Willow is a shy and nerdy girl with little confidence. She has inherent magical abilities and begins to study witchcraft; as the series progresses, Willow becomes more sure of herself and her magical powers become significant if inconsistent. Her dependence on magic becomes so consuming that it develops into a dark force that takes her on a redemptive journey in a major story arc when she becomes the sixth season's main villain, threatening to destroy the world in a fit of grief and rage.
The "Buffy" series became extremely popular and earned a devoted fanbase; Willow's intelligence, shy nature, and vulnerability often resounded strongly with viewers in early seasons. Of the core characters, Willow changes the most, becoming a complex portrayal of a woman whose powers force her to seek balance between what is best for the people she loves and what she is capable of doing. Her character stood out as a positive portrayal of a Jewish woman and at the height of her popularity, she fell in love with another woman, a witch named Tara Maclay. They became one of the first lesbian couples on U.S. television and one of the most positive relationships of the series. Willow appears in every "Buffy" episode (making her the only character besides Buffy herself to do so), is featured in three episodes of the spinoff "Angel", an animated series and video game—both of which use Hannigan's voice, and the comic "Buffy the Vampire Slayer Season Eight" (2007–2011), which uses Hannigan's likeness and continues Willow's storyline following the television series.
Character history.
Pilot and casting.
"Buffy the Vampire Slayer" (often simplified as "Buffy") was originally conceived by Joss Whedon for a 1992 feature film. However, in its development Whedon felt it lost some of the quirkiness he considered was the heart of the project, and it was not received as well as he liked. He began to develop for television the concept of a fashion-conscious girl named Buffy, who is imbued with superhuman abilities and attends a high school situated on a portal to hell. Whedon created a group of friends for the main character, including Willow Rosenberg and Xander Harris. A half-hour pilot was filmed starring Riff Regan as Willow, but it was eventually left unaired and network executives requested that Regan be replaced. Willow's character demanded that she be shy and unsure of herself, and the casting department encountered some difficulty finding actors who could portray this effectively and still be likable. After seven auditions, 23-year-old Alyson Hannigan was hired for the role. She was chosen for being able to spin the character's lines with a self-effacing optimism. She later stated in an interview, "I didn't want to do Willow as someone who's feeling sorry for herself. Especially in the first season, she couldn't talk to guys, and nobody liked her. I was like, 'I don't want to play somebody who's down on herself."
In the beginning of the series, Hannigan used her own experiences in high school—which she called "overwhelmingly depressing"—to guide her portrayal of Willow. "My theory on high school was, get in, get out and hopefully I won't get hurt. Basically it was a miserable experience, because you're a walking hormone in this place that is just so cruel. There were times that were OK, but it's not the little myth that high school is the best years of your life. No way." Whedon intended Willow to be realistically introverted, saying "I wanted Willow to have that kind of insanely colorful interior life that truly shy people have. And Alyson has that. She definitely has a loopiness I found creeping into the way Willow talked, which was great. To an extent, all the actors conform to the way I write the character, but it really stands out in Willow's case."
Television series (1997–2003).
Seasons 1–3.
The "Buffy" television series first aired mid-season in March 1997, almost immediately earning positive critical reviews. Willow is presented as a bookish nerd with considerable computer skills, dowdily dressed and easily intimidated by more popular girls in school. She grows faint at the sight of monsters, but quickly forms a friendship with Buffy Summers (Sarah Michelle Gellar) and is revealed to have grown up as friends with Xander (Nicholas Brendon). They are mentored by the school librarian who is also Buffy's Watcher, Rupert Giles (Anthony Stewart Head), who often works closely with Willow in researching the various monsters the group encounters. Joss Whedon found that Hannigan was especially gifted reacting with fear (calling her the "king of pain") and viewers responded strongly when she was placed in danger, needing to be rescued by Buffy. Willow in various predicaments became common in early episodes. However, Willow establishes herself as integral to the group's effectiveness, often willing to break rules by hacking into highly secure computer systems.
In the second season when the characters are in 11th grade, Willow becomes more sure of herself, standing up to the conceited Cordelia Chase (Charisma Carpenter), and approaching Xander, on whom she has had a crush for years, although it is unrequited as Xander is in love with Buffy. Seth Green joined the cast during the second season as Oz, a high school senior who becomes a werewolf, and Willow's primary romantic interest. The show's popularity by early 1998 was evident to the cast members, and Hannigan remarked on her surprise specifically. Willow was noted to be the spirit of the Scooby Gang, and Hannigan attributed Willow's popularity with viewers (she had by May 1998 seven websites devoted to her) to being an underdog who develops confidence and is accepted by Buffy, a strong, popular person in school. Hannigan described her appeal: "Willow is the only reality-based character. She really is what a lot of high-schoolers are like, with that awkwardness and shyness, and all those adolescent feelings."
At the end of the second season, Willow begins to study magic following the murder of the computer teacher and spell caster Jenny Calendar (Robia LaMorte). Willow is able to perform a complicated spell to restore the soul of Angel, a vampire who is also Calendar's murderer and Buffy's boyfriend. During the third season three episodes explore Willow's backstory and foreshadow her development. In "Gingerbread", her home life is made clearer: Sunnydale falls under the spell of a demon who throws the town's adults into a moral panic, and Willow's mother is portrayed as a career-obsessed academic who is unable to communicate with her daughter, eventually trying to burn Willow at the stake for being involved in witchcraft; her father is never featured. In "The Wish" a vengeance demon named Anya (Emma Caulfield) grants Cordelia's wish that Buffy never came to Sunnydale, showing what would happen if it were overrun with vampires. In this alternate reality, Willow is an aggressively bisexual vampire. In a related episode, "Doppelgangland", Willow meets "Vamp Willow", who dresses provocatively and flirts with her.
Seasons 4–6.
Willow chooses to attend college with Buffy in Sunnydale although she is accepted to prestigious schools elsewhere. Her relationships with Buffy and Xander become strained as they try to find their place following high school. Willow becomes much more confident in college, finally finding a place that respects her intellect, while Buffy has difficulty in classes and Xander does not attend school. Willow's relationship with Oz continues until a female werewolf appears on the scene, aggressively pursuing him, and he leaves town to learn how to control the wolf within. She becomes depressed and explores magic more deeply, often with powerful but inconsistent results. She joins the campus Wicca group, meeting Tara Maclay, eventually falling in love with and choosing to be with her even when Oz returns to Sunnydale after apparently getting his lycanthropic tendencies under control.
Each season the Scoobies face a villain they call the Big Bad. In the fifth season, this is a goddess named Glory (Clare Kramer) that Buffy is unable to fight by herself. 
The writers of the series often use elements of fantasy and horror as metaphors for real-life conflicts. The series' use of magic, as noted by religion professor Gregory Stevenson, neither promotes nor denigrates Wiccan ideals and Willow rejects Wiccan colleagues for not practicing the magic she favors. Throughout the series, magic is employed to represent different ideas -— relationships, sexuality, ostracism, power, and particularly for Willow, addiction -— that change between episodes and seasons. The ethical judgment of magic, therefore, lies in the results: performing magic to meet selfish needs or neglecting to appreciate its power often ends disastrously. Using it wisely for altruistic reasons is considered a positive act on the series. 
Through witchcraft, Willow becomes the only member of the group to cause damage to Glory. She reveals that the spells she casts are physically demanding, giving her headaches and nosebleeds. When Glory assaults Tara, making her insane, Willow, in a magical rage that causes her eyes to turn black, finds Glory and battles her. She does not come from the battle unscathed and must be assisted by Buffy, but her power is evident and surprising to her friends. The final episode of the fifth season sees Willow restoring Tara's sanity and crucially weakening Glory in the process. It also features Buffy's death, sacrificing herself to save the world.
Willow and Tara move into the Summers house and raise Buffy's younger sister Dawn (Michelle Trachtenberg). Fearing that Buffy is in hell, Willow suggests at the beginning of the sixth season that she be raised from the dead. In a dark ceremony in which she expels a snake from her mouth, Willow performs the magic necessary to bring Buffy back. She is successful, but Buffy keeps it secret that she believes she was in heaven. 
Willow's powers grow stronger; she uses telepathy which her friends find intrusive, and she begins to cast spells to manipulate Tara. After Wilow fails Tara's challenge to go for one week without performing magic, Tara leaves her, and for two episodes Willow descends into addiction that almost gets Dawn killed. Willow goes for months without any magic, helping Buffy track three geeks called The Trio who grandiosely aspire to be supervillains. 
Immediately following a reconciliation with Tara, Warren (Adam Busch), one of the Trio, shoots Buffy and a stray shot kills Tara right in front of Willow. In an explosion of rage and grief, Willow soaks up all the dark magic text she can, turning her hair and eyes black. In the final episodes of the season Willow becomes exceedingly strong, surviving unharmed when Warren hits her in the back with an axe. She hunts Warren, tortures him by slowly pushing a bullet into his body, then ends by killing him by instantly magically flaying him. Unsatisfied, she attempts to kill the other two members of the Trio and unsuccessful at this, tries to destroy the world, only to be stopped by Xander.
Season 7.
The seventh season starts with Willow in England, unnerved by her power, studying with a coven near Giles' home to harness it. She fears returning to Sunnydale and what she is capable of doing if she loses control again, a fear that dogs her the whole season.
Buffy and the Scoobies face the First Evil, bent on ending the Slayer line and destroying the world. Potential Slayers from around the globe congregate at Buffy's home and she trains them to battle the First Evil. Willow continues to face her grief over Tara's death and, reluctantly, becomes involved with one of the Potentials, Kennedy (Iyari Limon). 
In the final episode of the series, "Chosen", Buffy calls upon Willow to perform the most powerful spell she has ever attempted. With Kennedy nearby, cautioned to kill her if she becomes out of control, Willow infuses every Potential Slayer in the world with the same powers Buffy and Faith have. The spell momentarily turns her hair white and makes her shine -- Kennedy calls her "a goddess" -- and it ensures that Buffy and the Potentials defeat the First Evil. Willow is able to escape with Buffy, Xander, Giles, and Kennedy as Sunnydale is destroyed.
Through the gamut of changes Willow endures in the series, "Buffy" studies scholar Ian Shuttleworth states that Alyson Hannigan's performances are the reason for Willow's popularity: "Hannigan can play on audience heartstrings like a concert harpist... As an actress she is a perfect interpreter in particular of the bare emotional directness which is the specialty of [series writer Marti] Noxon on form."
Comic series (since 2007).
Subsequent to "Buffy"‍ '​s television finale, Dark Horse Comics collaborated with Joss Whedon to produce a canonical comic book continuation of the series, "Buffy the Vampire Slayer Season Eight" (2007–11), written by Whedon and many other writers from the television series. Unfettered by the practical limitations of casting or a television special effects budget, "Season Eight" explores more fantastic storylines, characters, and abilities for Willow. Willow's cover art is done by Jo Chen, and Georges Jeanty and Karl Moline produce character artwork and provide alternative covers. It was followed by two closely interlinked sequels, "Buffy the Vampire Slayer Season Nine" and "Angel & Faith" (both 2012–). Willow features at different times in both series, as well as in her own spin-off miniseries. Jeanty continues to provide Willow's likeness in "Season Nine", while Rebekah Isaacs and Brian Ching are the primary pencillers of "Angel & Faith" and "Willow: Wonderland" respectively. While "Season Nine" and "Angel & Faith" are substantially less fantastical in tone than "Season Eight", Willow's spin-off is high fantasy and focuses on her journey through magical alternate worlds.
Willow appears to Buffy and Xander, who are in charge of thousands of Slayers, a year after the destruction of Sunnydale. Willow reveals a host of new abilities including being able to fly and absorbing others' magic to deconstruct it. The Big Bad of "Season Eight" is a being named Twilight who is bent on destroying magic in the world. A one-shot comic dedicated to Willow's story was released in 2009 titled "Willow: Goddesses and Monsters". It explores the time she took away to discover more about her magical powers, under the tutelage a half-woman half-snake demon named Aluwyn. Willow is still involved with Kennedy through "Season Eight", but becomes intimate with Aluwyn while they are together. She also continues to deal with grief from Tara's death, and struggles with the dark forces of magic that put her in opposition to Buffy. At the conclusion of the season, Buffy destroys an object, a seed, that is the source of the magic in the world, leaving Willow powerless. Whedon divulged that recovering her magical abilities will become Willow's "personal obsession" in a miniseries where she will be the central character.
Identities.
From the inception of Willow's character in the first season, she is presented with contradictions. Bookish, rational, naive, and sometimes absent-minded, she is also shown being open to magic, aggressively boyish, and intensely focused. Willow is malleable, in continuous transition more so than any other "Buffy" character. She is, however, consistently labeled as dependable and reliable by the other characters and thus to the audience, making her appear to be stable. She is unsure of who she is; despite all the tasks she takes on and excels at, for much of the series she has no identity. This is specifically exhibited in the fourth season finale "Restless", an enigmatic pastiche of characters' dream sequences. In Willow's dream, she moves from an intimate moment painting a love poem by Sappho on Tara's bare back, to attending the first day of drama class to learn that she is to be in a play performed immediately for which she does not know the lines or understand. The dream presents poignant anxieties about how she appears to others, not belonging, and the consequences of people finding out her true self. As Willow gives a book report in front of her high school class, she discovers herself wearing the same mousy outfit she wore in the first episode of the show ("Welcome to the Hellmouth") as her friends and classmates shout derisively at her, and Oz and Tara whisper intimately to each other in the audience. She is attacked and strangled by the First Slayer as the class ignores her cries for help.
Long a level-headed character who sacrifices her own desires for those of her friends, she gradually abandons these priorities to be more independent and please herself. She is often shown making choices that allow her to acquire power or knowledge and avoid emotional conflict. The story arc of Willow's growing dependence on magic was noted by Marti Noxon as the representation of "adult crossroads" and Willow's inability and unwillingness to be accountable for her own life. Willow enjoys power she is unable to control. She steals to accomplish her vocational goals and rationalizes her amoral behavior. This also manifests itself in a competitive streak and she accuses others who share their concerns that she uses magic for selfish purposes of being jealous. No longer the conscience of the Scooby Gang, Willow cedes this role to Tara then revels in breaking more rules. After Tara leaves Willow, Willow divulges to Buffy that she does not know who she is and doubts her worth and appeal—specifically to Tara—without magic. Contradicting the characterization of Willow's issues with magic as addiction, "Buffy" essayist Jacqueline Lichtenberg writes "Willow is not addicted to magic. Willow is addicted to the surging hope that this deed or the next or the next will finally assuage her inner pain."
Vamp Willow.
Vamp Willow appears in the third season episodes "The Wish" and "Doppelgangland". She is and aggressive, the opposite of Willow's usual nature; her bad behavior so exaggerated that it does not instill fear into the viewer like other female vampires in the series, but indicates more about Willow's personality. Shocked upon seeing her alter ego in "Doppelgangland", Willow states "That's me as a vampire? I'm so evil and . And I think I'm kinda gay!" Angel is stopped by Buffy in telling the Scoobies that the vampire self carries many of the same attributes as the human self, at which Willow says that is nothing like her. Many Buffy fans saw this as a funny Easter egg when Willow revealed herself to actually be a lesbian in later seasons. As surprised as Willow is with Vamp Willow, she feels bound to her, and does not have the heart to allow Buffy to kill her. Both Willows make the observation that "this world's no fun", before they send Vamp Willow back into the alternate dimension from which she came, whereupon she is staked and dies immediately.
Dark Willow.
A shadow of Dark Willow appears to fight Glory in the fifth season episode "Tough Love", but she does not come into full force until the sixth season in "Villains", "Two to Go", and "Grave". The transition from Willow into Dark Willow, precipitated by Tara's immediate death when she is shot through the heart, was ambiguously received by audiences, many of whom never foresaw Willow's psychic break. It was simultaneously lauded for being an overwhelming depiction of a powerful woman, and derided as representative of a worn cliché that lesbians are amoral and murderous. Dark Willow proved to be exceptionally more powerful than Buffy. She changes visually when she walks into the Magic Box, a store owned by Anya and Giles, telekinetically retrieves dozens of dark magic books from the shelves, and leeches the words from the pages with her fingertips. As the words crawl up her arms and soak into her skin, her eyes and hair become black and her posture "aggressively aware and confident".
Susan Driver writes that it is "crucial to recognize that never before in a teen series has raw fury been so vividly explored through a young queer girl responding to the sudden death of her lover". Dark Willow is preternaturally focused on revenge, relentless and unstoppable. Lights explode when she walks past. She forcefully takes advantage of any opportunity to further her goals. She saves Buffy by removing the bullet from her chest, but later commandeers a tractor trailer, making it slam into Xander's car while he and Buffy are inside protecting Jonathan and Andrew, the other two members of the Trio. She floats, teleports herself at will, and dismantles the local jail where Jonathan and Andrew are held. She is cruelly honest to Dawn and Buffy, and overpowers everyone with whom she comes in contact. When she takes Giles' magic from him, she gains the ability to feel the world's pain, becoming determined to put the world out of its misery. She does not acknowledge her grief, and only Xander can force her to face it when he tells her that he loves her no matter what or who she is, and if she is determined to end the world she must start by killing him. Only then does Willow return, sobbing.
At Salon.com, Stephanie Zacharek writes that Dark Willow is "far from being a cut-out angry lesbian, is more fleshed out, and more terrifyingly alive, than she has ever been before. More than any other character, she has driven the momentum of the past few episodes; she very nearly drove it off a cliff." Several writers state that Willow's transition into Dark Willow is inevitable, grounded in Willow's self-hatred that had been festering from the first season. Both Dark Willow and even Willow herself state that Willow's sacrifices for her friends and lack of assertiveness are her undoing. In "Doppelgangland", Willow (posing as Vampire Willow) says "It's pathetic. She lets everyone walk all over her and gets cranky at her friends for no reason." In "Two to Go", Dark Willow remarks "Let me tell you something about Willow. She's a loser. And she always has been. People picked on Willow... and now Willow's a junkie." Vamp Willow served as an indicator of what Willow is capable of; immediately before she flays Warren in one violent magical flash, she uses the same line Vamp Willow used in the third season: "Bored now."
Following the sixth season, Willow struggles to allow herself to perform magic without the darkness within her taking her over. She is no longer able to abstain from magic as it is such an integral part of her that doing so will kill her. In the instances when she is highly emotional the darkness comes out. Willow must control that part of her and is occasionally unable to do so, giving her a trait similar to Angel, a cursed vampire who fears losing his soul will turn him evil. In a redemptive turn, when Willow turns all the Potentials into Slayers, she glows and her hair turns white, astonishing Kennedy and prompting her to call Willow a goddess.
Relationships.
Willow's earliest and most consistent relationships are with Buffy and Xander, both of whom she refers to as her best friends although they have their conflicts, and Giles as a father figure. Willow takes on the leadership role when Buffy is unavailable, and her growing powers sometimes make her resent being positioned as Buffy's sidekick. Some scholars see Willow as Buffy's sister-figure or the anti-Buffy, similar to Faith, another Slayer whose morals are less strict. In early seasons, Willow's unrequited crush on Xander creates some storylines involving the relationships between Xander, Cordelia, and Oz. Willow is part of a powerful quartet: she represents the spirit, Giles intelligence, Xander heart, and Buffy strength of the Scoobies. Although they often drift apart, they are forced to come together and work in these roles to defeat forces they are unable to fight individually.
Oz.
Willow meets stoic Oz in the second season. Their courtship is slow and patient. Oz is bitten by a werewolf, and just as Willow begins to confront him about why he does not spend time with her, he transforms and attacks her. She must shoot him with a tranquilizer gun several times while he is wild, but her assertiveness in doing so makes her more confident in their relationship. Oz's trials in dealing with a power he cannot control is, according to authors J. Michael Richardson and J. Douglas Rabb, a model for Willow to reference when she encounters her own attraction to evil. When Willow and Oz decide to commit to each other, Willow is enthusiastic that she has a boyfriend, and, as a guitarist in a band, one so cool. Her relationship with Oz endures the high school storylines of exploring her attraction to Xander, which briefly separates them. She worries that she is not as close to Oz as she could be. They stay together through graduation into college, but Oz is drawn to Veruca, another werewolf. He admits an animal attraction to Veruca, which he does not share with Willow. He sleeps with Veruca and leaves shortly after to explore the werewolf part of himself. Willow becomes very depressed and doubts herself. She drinks, her magical abilities are compromised, her spells come out wrong, and she lashes out at her friends when they suggest she get over it ("Something Blue").
Joss Whedon did not intend to write Oz out of the series. Seth Green came to Whedon early in the fourth season to announce that he wished to work on his film career. Whedon admitted he was upset by Green's announcement and that if he had wanted to continue, Oz would have been a part of the story. However, to resolve the relationship between Oz and Willow Whedon says, "we had to scramble. And out of the heavens came Amber Benson."
Tara Maclay.
"Buffy" earned international attention for its unflinching focus on the relationship between Willow and Tara Maclay. Whedon and the writing staff had been considering developing a story arc in which a character explores his or her sexuality as the Scoobies left high school, but no particular effort was made to assign this arc to Willow. In 1999, at the end of the third season, the "Boston Herald" called "Buffy" "the most gay show on network TV this year" despite having no overtly gay characters among the core cast. It simply presented storylines that resembled coming out stories. In the fourth season episode "Hush", Willow meets Tara, and to avoid being killed by a group of ghouls, they join hands to move a large vending machine telekinetically to barricade a door. The scene was, upon completion, noticeably sensual to Whedon, the producers, and network executives, who encouraged Whedon to develop a romantic storyline between Willow and Tara, but at the same time placed barriers on how far it could go and what could be shown. Two episodes later, Hannigan and Amber Benson were informed that their characters would become romantically involved. The actors were not told the end result of the Willow–Oz–Tara storyline, not sure what the eventual trajectory of the relationship would be, until Hannigan said, "Then finally it was, 'Great! It's official. We're in luurrvvve.'"
Whedon made a conscious effort to focus on Willow and Tara's relationship instead of either's identity as a lesbian or the coming out process. When Willow discloses to Buffy what she feels for Tara, she indicates that she has fallen in love with Tara, not that she is a lesbian, and avoids categorizing herself. Some critics regard this as a failure on Willow's part to be strong; Em McAvan interprets this to mean that Willow may be bisexual. Scholar Farah Mendlesohn asserts that Willow's realization that she is in love with Tara allows viewers to re-interpret Willow's relationship with Buffy; in the first three seasons, Willow is often disappointed that she is not a higher priority to Buffy, and even after Willow enters a relationship with Tara, still desires to feel integral to Buffy's cause and the Scooby Gang.
Willow's progression has been noted to be unique in television. Her relationship with Tara coincides with the development of her magical abilities becoming much more profound. By the seventh season, she is the most powerful person in Buffy's circle. Jessica Ford at PopMatters asserts that Willow's sexuality and her magical abilities are connected and represented by her relationships. In her unrequited attraction to Xander, she has no power. With Oz, she has some that gives her the confidence she sorely lacks, but his departure leaves her unsure of herself. Only when she meets Tara do her magical abilities flourish; to Ford, sexuality and magic are both empowering agents in Willow's story arc. David Bianculli in the "New York Daily News" writes that Willow's progression is "unlike anything else I can recall on regular prime-time television: a character evolving naturally over four seasons of stories and arriving at a place of sexual rediscovery".
Not all viewers considered Willow and Tara's relationship a positive development. Some fans loyal to Willow reacted angrily as she chose to be with Tara when Oz made himself available, and they lashed out at Tara and Amber Benson on the fansite message boards. Whedon replied sardonically, "we're going to shift away from this whole lifestyle choice that Willow has made. Just wipe the slate. From now on, Willow will no longer be a Jew. And I think we can all breathe easier." However, he seriously explained his motivation, writing "My show is about emotion. Love is the most powerful, messy, delightful and dangerous emotion... Willow's in love. I think it's cool." Hannigan was also positive about the way the character and her relationship with Tara was written: "It is not about being controversial or making a statement. I think the show is handling it really nicely. It's about two people who care about each other."
Contrasting with some of the more sexual relationships of the other characters, Willow and Tara demonstrate a sentimental, soft, and consistent affection for each other. Some of this was pragmatic: the show was restricted in what it could present to viewers. Willow and Tara did not kiss until the fifth season in an episode that diverted the focus away from the display of affection when Buffy's mother dies in "The Body". Before this, much of their sexuality is represented by allusions to witchcraft; spells doubled for physical affection such as an erotic ritual in "Who Are You?" where Willow and Tara chant and perspire in a circle of light until Willow falls back on a pillow gasping and moaning. Within the "Buffy" universe, magic is portrayed in a mostly female realm. As opposed to it being evil, it is an earth-bound force that is most proficiently harvested by women. The treatment of the lesbian relationship as integral to magic, representative of each other (love is magic, magic is love), earned the series some critical commentary from conservative Christians. To avoid large-scale criticism, scenes had to be shot several different ways because censors would not allow some types of action on screen. In the fourth and fifth seasons, the characters could be shown on a bed, but not under the covers. Hannigan noted the inconsistent standards with the other relationships on the show: "you've got Spike and Harmony just going at it like rabbits, so it's very hypocritical". As a couple, Willow and Tara are treated by the rest of the Scoobies with acceptance and little fanfare. Susan Driver writes that younger viewers especially appreciate that Willow and Tara are able to be affectionate without becoming overly sexual, thus making them objects of fantasy for male enjoyment. Willow and Tara's influence on specifically younger female viewers is, according to Driver, "remarkable".
Academics, however, comment that Willow is a less sexual character than the others in the show. She is displayed as "cuddly" in earlier seasons, often dressing in pink fuzzy sweaters resulting in an innocent tomboyishness. She becomes more feminine in her relationship with Tara, who is already feminine; no issues with gender are present in their union. Their relationship is sanitized and unthreatening to male viewers. When the series moved broadcast networks from the WB to UPN in 2001, some of the restrictions were relaxed. Willow and Tara are shown in some scenes to be "intensely sexual", such as in the sixth season episode "Once More, with Feeling" where it is visually implied that Willow performs cunnilingus on Tara. When Willow and Tara reconcile, they spend part of the episode in "Seeing Red" unclothed in bed, covered by red sheets.
Willow is more demonstrative in the beginning of her relationship with Tara. Where in her relationship with Oz she described herself as belonging to him, Tara states that she belongs to Willow. Willow finds in Tara a place where she can be the focus of Tara's attention, not having to appease or sacrifice as she has in the past. Tara, however, eclipses Willow's role as the moral center of the Scoobies, and as Willow becomes more powerful and less ethical, Tara becomes a maternal figure for the group. Willow acts as a sort of middle child between Xander's immaturity and Buffy's weighty responsibilities. She becomes completely devoted to and enamored of Tara, and then manipulates her to avoid conflict when Tara does not conform to what she wants. Displeased with how Willow abuses her power, especially toward herself, Tara leaves Willow while continuing to counsel Dawn and Buffy. Long after Tara's death, Willow faces the choices she made: in the "Season Eight" episode "Anywhere But Here", Willow tells Buffy that she is responsible for Tara's death. Her ambition to bring back Buffy from the dead inevitably led to Tara getting shot and killed. In the one-shot comic, Willow is offered Tara as a guide for her mystical path to understanding her own powers, but rejects her as being an illusion, too much of a comfort, and not a guide who will force her to grow. She begins a relationship with Kennedy.
Kennedy.
Following protests angry about the death of Tara, Whedon and the writing team made a decision to keep Willow gay. In 2002, he told "The Advocate" about the possibility of Willow having a relationship with a man, "We do that now, and we will be burned alive. And possibly justifiably. We can't have Willow say, 'Oh, cured now, I can go back to cock!' Willow is not going to be straddling that particular fence. She will just be gay." Kennedy is markedly different from Tara. She is younger, outspoken, and aggressively pursues Willow, who hesitates to become involved again. When they first kiss in the episode "The Killer in Me", Willow's realization that she let Tara go reacts with a curse put upon her by another witch named Amy Madison (Elizabeth Anne Allen), turning Willow into Warren, Tara's murderer. The spell is broken when Willow acknowledges her guilt and Kennedy kisses her again. Kennedy expresses that she does not understand the value of magic and assumes it involves tricks, not the all-consuming energy that Willow is capable of. When Willow eventually exhibits what power she has, it briefly frightens Kennedy. Willow worries about becoming sexually intimate with Kennedy, unsure of what may transpire if she loses control of herself.
In season 7 episode 20, "Touched", in which practically all the main cast has sex (two by two) Willow and Kennedy take part in the first lesbian sex scene on primetime television.
In "Season Eight", Kennedy and Willow are still romantically involved, but separated during Willow's self-exploration. Unlike her relationship with Tara, Willow is able to hold a separate identity while with Kennedy. When she realizes her powers have gone at the end of "Season Eight", however, Willow ends her relationship with Kennedy, saying that there is someone else Willow is in love with, who she will never see again.
Kennedy's role split many Buffy fans into two groups. Many viewers hated Kennedy, because they saw her as a way of saying; "Tara's dead, let's move on." and they weren't ready to. After the emotional death of Tara and Willow's reaction (nearly ending all life on Earth) many fans thought that it was ridiculous for Willow to recover and move on so quickly. Kennedy overall, has received much hate, but there is the other side who say that she was exactly what Willow needed to recover and continue a happy life.
Cultural impact.
Willow Rosenberg is undoubtedly the most complexly represented girl in love and lust with other girls to be developed within a mainstream network television series.
Susan Driver in "Queer Girls and Popular Culture"
Willow's religion and sexuality have made her a role model for audiences. Whedon, however, has compared her Jewish identity to her sexuality, stating that they are rarely made a significant focus of the show. Willow at times reminds the other characters of her religion, wondering what her father might think of the crucifixes she must apply to her bedroom wall to keep out vampires, and commenting that Santa Claus misses her house every Christmas because of the "big honkin' menorah". "Buffy" essayist Matthew Pateman criticizes the show for presenting Willow's Jewish identity only when it opposes Christian declarations of holidays and other traditions. "The New York Times", however, named her as a positive example of a depiction of a Jewish woman, who stood out among portrayals of Jews as harsh, unfeminine, and shallow. Producer Gail Berman states that as a Jew, Willow "handles herself just fine, thank you".
In "Queer Girls and Popular Culture", Susan Driver states that television ascribes to viewers what lesbians look and act like, and that realistic portrayals of girls outside the norm of white, upper or middle class, and heterosexual are extremely rare. Realistic depictions of lesbians are so rare that they become strong role models and enable "hope and imagination" for girls limited by the conditions of their immediate surroundings, who may know of no other gay people. The time and space given to Willow to go from being a shy scared girl into a confident woman who falls in love with another woman is, as of 2007, unique in television; it does not occur in one flash or single moment. It is a progression that defies strict definition. Manda Scott in "The Herald" states that Willow's lack of panic or self-doubt when she realizes she is in love with Tara makes her "the best role model a teen could ask for".
When viewers realized that Willow was falling in love with Tara, Whedon remembered that some threatened to boycott the show, complaining "You made Willow a fag", to which he responded, "Bye. We'll miss you "a whole lot."" However, he also said, "For every (negative) post, there's somebody saying, 'You made my life a lot easier because I now have someone I can relate to on screen'." Gay characters had been portrayed before on television, and at the time the popular sitcom "Will & Grace" was on the air. Lesbian-themed HBO special "If These Walls Could Talk 2" won an Emmy. Twenty-three television shows depicted a gay character of some kind in 2000. However, these other characters were mostly desexualized, none were partnered or shown consistently affectionate towards the same person. Willow and Tara's relationship became the first long-term lesbian relationship on U.S. television. "Jane" magazine hailed Willow and Tara as a bold representation of gay relationship, remarking that "they hold hands, slow-dance and lay in bed at night. You won't find that kind of normalcy on "Will and Grace"." Despite Whedon's intentions of not making "Buffy" about overcoming issues, he said Willow's exploration of her sexuality "turned out to be one of the most important things we've done on the show".
Although the show's writers and producers received a minimal negative reaction from Willow choosing Tara over Oz, the response from viewers and critics alike was overwhelming towards Whedon for killing Tara, accusing him of homophobia. Particularly because Tara's death came at a point where Willow and Tara had reconciled and were shown following an apparent sexual encounter, the writers were criticized for representing the consequences of lesbian sex as punishable by death. Series writer and producer Marti Noxon—whose mother fell in love with another woman when Noxon was 13 years old—was unable to read some of the mail the writing team received because it was so upsetting. To her, the pain expressed in viewers' letters was a logical reaction to the lack of realistic lesbian role models on television.
Willow's cultural impact has been noted in several other ways. Patrick Krug, a biologist at California State University, Los Angeles named a sea slug with traits of sexual flexibility "Alderia willowi" partly for his grandmother and partly after Willow's character. Willow was included in AfterEllen.com's Top 50 Lesbian and Bisexual Characters, ranking at No. 7. She was also ranked No. 12 in their Top 50 Favorite Female TV Characters. UGO.com named her one of the best TV nerds. AOL also listed her as the #1 TV witch of all time, and one of the 100 Most Memorable Female TV Characters.

</doc>
<doc id="37729" url="http://en.wikipedia.org/wiki?curid=37729" title="Snowdonia">
Snowdonia

Snowdonia (Welsh: "Eryri") is a region in north Wales and a national park of 823 sqmi in area. It was the first to be designated of the three national parks in Wales, in 1951.
Name and extent.
The English name for the area derives from Snowdon, which is the highest mountain in Wales at 3,560 ft (1,085 m). In Welsh, the area is named "Eryri". One assumption is that the name is derived from "eryr" ("eagle"), but others state that it means quite simply "Highlands", as leading Welsh scholar Sir Ifor Williams proved. In the Middle Ages the title "Prince of Wales and Lord of Snowdonia" ("Tywysog Cymru ac Arglwydd Eryri") was used by Llywelyn ap Gruffudd; his grandfather Llywelyn Fawr used the title "Prince of north Wales and Lord of Snowdonia.
Prior to the designation of the boundaries of the national park, "Snowdonia" was generally used to refer to a smaller area, namely the upland area of northern Gwynedd centred on the Snowdon massif, whereas the national park covers an area more than twice that size extending far to the south into Meirionnydd. This is apparent in books published prior to 1951 such as the classic travelogue "Wild Wales" by George Borrow (1862) and "The Mountains of Snowdonia" by H. Carr & G. Lister (1925). F. J. North, as editor of the book "Snowdonia" (1949), states "When the Committee delineated provisional boundaries, they included areas some distance beyond Snowdonia proper." The traditional Snowdonia thus includes the ranges of Snowdon and its satellites, the Glyderau, the Carneddau and the Moel Siabod group. It does not include the hills to the south of Maentwrog. As "Eryri" (see above), this area has a unique place in Welsh history, tradition and culture.
Snowdonia National Park.
Snowdonia National Park (Welsh: "Parc Cenedlaethol Eryri") was established in 1951 as the third national park in Britain, following the Peak District and the Lake District. It covers 827 sqmi, and has 37 mi of coastline.
The park is governed by the Snowdonia National Park Authority, which is made up of local government and Welsh representatives, and its main offices are at Penrhyndeudraeth. Unlike national parks in other countries, Snowdonia (and other such parks in Britain) are made up of both public and private lands under central planning authority. The makeup of land ownership at Snowdonia is as follows:
More than 26,000 people live within the park, of whom about 62% can speak at least some Welsh. The park attracts over 6 million visitors annually, split almost equally between day and staying visitors, making it the third most visited national park in England and Wales.
Whilst most of the land is either open or mountainous land, there is a significant amount of agricultural activity within the park.
Since the local government re-organisation of 1998, the park lies partly in the county of Gwynedd, and partly in the county borough of Conwy. It is governed by the 18-member Snowdonia National Park Authority; 9 members are appointed by Gwynedd, 3 by Conwy, and the remaining 6 by the National Assembly for Wales to represent the national interest.
Unusually, Snowdonia National Park has a hole in the middle, around the town of Blaenau Ffestiniog, a slate quarrying centre. This was deliberately excluded from the park when it was set up to allow the development of new light industry to replace the decimated slate industry. (There is a similar situation in the Peak District National Park where the boundaries were drawn to exclude large built-up areas and industrial sites from the park with the town of Buxton and the adjacent quarries outside but surrounded on three sides by the park.)
The Snowdonia Society is a registered charity formed in 1967. It is a voluntary group of people with an interest in the area and its protection. Amory Lovins led the successful 1970s opposition to stop Rio Tinto digging up the area for a massive mine.
Mountain ranges.
Snowdonia may be divided into four areas:
Mountain walking.
Many of the hikers in the area concentrate on Snowdon itself. It is regarded as a fine mountain, but can become quite crowded, particularly with the Snowdon Mountain Railway running to the summit.
The other high mountains with their boulder-strewn summits—as well as Tryfan, one of the few mountains in the UK south of Scotland whose ascent needs hands as well as feet—are also very popular. However, there are also some spectacular walks in Snowdonia on the lower mountains, and they tend to be relatively unfrequented. Among hikers' favourites are Y Garn (east of Llanberis) along the ridge to Elidir Fawr; Mynydd Tal-y-Mignedd (west of Snowdon) along the Nantlle Ridge to Mynydd Drws-y-Coed; Moelwyn Mawr (west of Blaenau Ffestiniog); and Pen Llithrig y Wrach north of Capel Curig. Further south are Y Llethr in the Rhinogydd, and Cadair Idris near Dolgellau.
The park has 1479 mi of public footpaths, 164 mi of public bridleways, and 46 mi of other public rights of way. A large part of the park is also covered by Right to Roam laws.
Nature, landscape and the environment.
The park's entire coastline is a Special Area of Conservation, which runs from the Llŷn Peninsula down the mid-Wales coast, the latter containing valuable sand dune systems.
The park's natural forests are of the mixed deciduous type, the commonest tree being the Welsh oak. Birch, ash, mountain-ash and hazel are also common. The park also contains some large (planted) coniferous forested areas such as Gwydir Forest near Betws-y-Coed, although some areas, once harvested, are now increasingly being allowed to regrow naturally.
Northern Snowdonia is the only place in Britain where the Snowdon lily, an arctic–alpine plant, and the rainbow-coloured Snowdon beetle ("Chrysolina cerealis") are found, and the only place in the world where the Snowdonia hawkweed "Hieracium snowdoniense" grows.
A large proportion of the park is today under designation (or under consideration for designation) as Sites of Special Scientific Interest, national nature reserves, Special Areas of Conservation, Special Protection Areas, Biosphere and Ramsar sites.
One of the major problems facing the park in recent years has been the growth of "Rhododendron ponticum". This fast-growing invasive species has a tendency to take over and stifle native species. It can form massive towering growths and has a companion fungus that grows on its roots producing toxins that are poisonous to any local flora and fauna for a seven-year period after the "Rhododendron" infestations have been eradicated. As a result there are a number of desolate landscapes.
Wildlife.
Snowdonia's importance in the conservation of habitat and wildlife in the region reflects in the fact that nearly 20% of its total area is protected by UK and European law. Half of that area was set aside by the government under the European Habitats Directive as a Special Area of Conservation. Rare mammals in the park include otters, polecats, and the feral goat, although the pine marten has not been seen for many years. Rare birds include raven, peregrine, osprey, merlin and the red kite. Another of Snowdonia's famous inhabitants is the Snowdon or rainbow beetle. The park has three RAMSAR Sites: the Dyfi Estuary Biosphere Reserve, Cwm Idwal and Llyn Tegid.
Climate.
Snowdonia is one of the wettest parts of the United Kingdom; Crib Goch in Snowdonia is the wettest spot in the United Kingdom, with an average rainfall of 4473 mm a year over the past 30 years.

</doc>
<doc id="37731" url="http://en.wikipedia.org/wiki?curid=37731" title="Jeff Minter">
Jeff Minter

Jeff 'Yak' Minter (born in Reading, 22 April 1962) is an independent British video game designer and programmer. He is the founder of software house Llamasoft and has created dozens of games during his career. Minter's games are often arcade style shoot 'em ups. They often contain titular or in-game references demonstrating his fondness of ruminants (llamas, sheep, camels, etc.). Many of his programs also feature something of a psychedelic element, as in some of the earliest "light synthesizer" programs including his "Trip-a-Tron".
Minter's works include "Neon" (2004), a non-game music visualisation program that has been built into the Xbox 360 console, and the video games "Space Giraffe" (Xbox Live Arcade, 2007 and PC, 2008), and "Space Invaders Extreme" (Xbox Live Arcade, May 2009).
Game development career.
Pre-commercial career (early years).
Minter had expressed an interest in programming computers from a young age. He wrote the game Deflex for the Commodore PET in 1979. However it would not be until a long illness during secondary school that Minter's talents would develop in any meaningful way. Following a 3-month stint in which Minter was restricted to lying on his back and was confined to his bed between November 1981 and January 1982, boredom led him to take up computer programming in earnest to pass the time.
Upon recovery, Minter teamed up with Richard Jones, a fellow pupil, and together they started writing their own games on their school's Commodore PET. They soon parted ways. Jones went on to commercial projects, some of them in the software market (e.g., "Interceptor Micros").
Commercial 8-bit games.
In 1981 Minter started independently writing and selling video games for the Sinclair ZX80, the first machine he owned. Some were made for software company dk'tronics. These titles were sold as a package but this was not available for very long, as Minter left the company following a royalties dispute. He formed a partnership with his mother, Hazel Minter. Together they developed and commercially produced 20 games for the Sinclair ZX81, Commodore VIC-20, Atari 8-bit computers, ZX Spectrum and Commodore 64. Having been studying physics at the University of East Anglia, success in the programming industry prompted him to drop his studies and take up video game development full-time.
The following year, he founded the software house Llamasoft. His first Llamasoft game was a "Defender" clone for the Commodore VIC-20 called "Andes Attack" (US version: "Aggressor"). In "Andes Attack", little llamas advanced upon and attacked the player instead of the spaceships from "Defender". As a fan of "Defender", Minter would remake it again as "Defender 2000". Using the name 'Salamander Software', Minter released "Gridrunner", published by Quicksilva Ltd. UK – this was written in a week and marked his first commercial success both in the UK and in the US.
Minter went on to develop a number of classic games, all written in assembly language, for the later home computers (such as the Commodore 64, Atari 400/800 and Atari ST) which were marketed mainly by word of mouth and by the occasional magazine advertisement. These games included: "Gridrunner", "Abductor", "Matrix: Gridrunner 2", "Hellgate", "Hover Bovver", "Attack of the Mutant Camels", "Revenge of the Mutant Camels", "Return of the Mutant Camels", "Laser Zone", "Mama Llama", "Metagalactic Llamas Battle at the Edge of Time", "Sheep in Space", "Voidrunner", and "Iridis Alpha".
Post 8-bit work.
In 1989, Minter helped in the production of the Konix Multisystem console.
Minter also worked for Atari and VM Labs. For Atari he produced "Tempest 2000" (1994) on the Jaguar. It was a remake of Dave Theurer's 1981 classic, "Tempest". Minter also produced "Defender 2000" (1995) on the Jaguar, remaking Eugene Jarvis's 1980 classic, "Defender". Minter also produced the "Virtual Light Machine" ("VLM-1") for the Jaguar CD-ROM add-on. For VM Labs, Minter designed related software for the Nuon chip including the creation of the "VLM-2 Light Synth" and the video game, "Tempest 3000".
Minter then wrote games for the Pocket PC platform, some of which also had PC conversions (using a customised Pocket PC emulator). During this time, Minter released three games: "Deflex", "Hover Bovver 2:Grand Theft Flymo" (a reinterpretation of his own 1984 game, "Hover Bovver"), and the PC/Macintosh game "Gridrunner++" (the third title in the "Gridrunner" series).
In 2002, he began work on a music video game for the Nintendo GameCube to be called "Unity". Using the newest version of his "VLM", the "VLM-3" or "Neon", "Unity" was to combine the two main threads of Minter's prior career: light synthesis and classic arcade style shooting. Minter was involved in writing this game for Peter Molyneux's Lionhead Studios throughout 2003; however, the project was cancelled in December 2004. "Neon" has since been reprogrammed and significantly expanded and is used in Xbox 360 media visualisation.
In 2007 Minter released "Space Giraffe", an action video game with similarities to "Tempest". "Space Giraffe" was released for Xbox 360 through Xbox Live Arcade for 400 Microsoft Points, or US$5.
In 2008 it was announced at the Tokyo Game Show that designers at Llamasoft were working on the visualisation aspects of the Xbox 360 version of "Space Invaders", called "Space Invaders Extreme". The game was released in 2008. In December 2008 "Space Giraffe" was released for the PC.
In September 2009 he released "Gridrunner Revolution" for Windows-based PCs as a digital download.
The Minotaur Project.
In 2010, frustrated with the delays surrounding the release of his titles, Minter was keen to return to a style of game development where games could be produced and released quickly. The iOS platform was chosen and Llamasoft announced that a series of games would be produced under the banner "The Minotaur Project". The idea behind the series is that Llamasoft would develop a game in the style of an old piece of hardware but without the constraints of the original hardware.
On 5 January 2011 he released "Minotaur Rescue" for iPhone 3GS, iPhone 4, iPod touch (3rd generation), iPod touch (4th generation), and iPad.
On 2 March 2011 Llamasoft released their second iOS game, . Minotron: 2112 is the remake of the Atari ST / Amiga classic, Llamatron (which is inspired by the coin-op video game ). An iOS version of Deflex was also released although this was not specifically labeled as being part of the Minotaur Project.
On 17 September 2011, Llamasoft released GoatUp, the first platform game they have produced.
On 27 January 2012 "Caverns of Minos" was released followed on 24 March by Gridrunner iOS.
"Super Ox Wars", a shoot-em-up based on Ikaruga was released in July 2012; the final game in the series, "GoatUp 2" was released in March 2013, unique in that it is the only Llamasoft title to feature a level editor. Minter then announced his intention to abandon mobile development due to lack of discoverability, low turnover, and the dominance of free-to-play and video game clones; he ultimately declared that, after accounting for his time, the Minotaur Project made a net loss. Jeff stated on Twitter than "Returning to iOS would be like returning to the scene of a mugging" and "I would advise any dev valuing integrity and sanity to just get the hell out". 
The code framework for the Minotaur Project games enables them to be rebuilt for both Mac and PC versions. Gridrunner was released for the Mac in August 2012.
Return to console games.
In April 2013 it was announced that Llamasoft had signed a deal with Sony Computer Entertainment to create a tube shooter for the "PlayStation Vita" called "TxK". The game would be Llamasoft's fourth tube shooter in two decades and was described as the spiritual successor of 1994's "Tempest 2000" for the "Atari Jaguar". As Minter explained in his development blog the project goals were to create a more traditional, straightforward and accessible tube shooter than "Space Giraffe", to improve on the flaws from "Tempest 2000" and "Tempest 3000", and to evoke the neo-retro aesthetic without being cheesy. TxK was released on Feb 11, 2014, by digital download through PSN.
Personal life.
In online forums and informal game credits pages Minter usually signs as "Yak", which is, in his own words"a pseudonym chosen a long time ago, back in the days when hi-score tables on coin-op machines only held three letters, and I settled on Yak because the yak is a scruffy hairy beast – a lot like me ;-)."
He lives in Wales with his partner Ivan "Giles" Zorzin, four sheep, two goats, two llamas and a dog. Although Minter is synonymous with Llamasoft, Zorzin is also jointly responsible for the recent titles.
Games.
Second Generation games
Third Generation games
Fifth Generation games
Sixth Generation games
Seventh Generation games
"Minotaur Project" series: This series of games pay homage to classic retro platforms. Each game is implemented as if running on a modernised version of the classic platform it represents. Originally developed for the iOS platform the games are being ported to both OS X and Android.
Eighth Generation games

</doc>
<doc id="37732" url="http://en.wikipedia.org/wiki?curid=37732" title="True lover's knot">
True lover's knot

The true lover's knot (or true love knot) is a name which has been used for many distinct knots. The association of knots with the symbolism of love, friendship, and affection dates back to antiquity. Because of this, it is not possible to consider a single knot to be "the" "true love knot".
Naming.
Modern western knotting literature has the name for these related knots deriving from stories or legends in which the knots symbolize the connection between a couple in love. Many examples feature sailors separated from their beloved. Ashley notes that it was once common for sailors' wedding rings, where gold wire was wrought to incorporate the "true lovers" knot such that resultant ring would comprise two tori: each flexible to move about the other; yet nevertheless inseparable.
Variations.
In practical terms, these knots are generally shown as consisting of two interlocked overhand knots made in two parallel ropes or cords. The variations are differentiated by the way in which the overhand knots interweave and in the final arrangement of the knot.
To show if a young couple's love would last, each would take a small limb of a tree and tie a lovers knot. If the knot held and grew for approximately a year, their love would stay true.

</doc>
<doc id="37733" url="http://en.wikipedia.org/wiki?curid=37733" title="Blancmange">
Blancmange

Blancmange ( or , from French "blanc-manger" ]), also known as shape in UK English, is a sweet dessert commonly made with milk or cream and sugar thickened with gelatin, cornstarch or Irish moss (a source of carrageenan), and often flavored with almonds. It is usually set in a mould and served cold. Although traditionally white, blancmanges are frequently given alternative colours. Some similar desserts are Bavarian cream, vanilla pudding (in US usage), panna cotta, the Turkish muhallebi, and haupia.
The historical blancmange originated some time in the Middle Ages and usually consisted of capon or chicken, milk or almond milk, rice and sugar and was considered to be an ideal food for the sick. Tavuk göğsü is a sweet contemporary Turkish pudding made with shredded chicken, similar to the medieval European dish.
History.
The true origin of the blancmange is obscure, but it is believed by some that it was a result of the Arab introduction of rice and almonds in early medieval Europe. However, there is no evidence of the existence of any similar Arab dishes from that period; though the Arabic "mahallabīyah" is similar, its origins are uncertain. Several other names for related or similar dishes existed in Europe, such as the 13th-century Danish "hwit moos" ("white mush"), and the Anglo-Norman "blanc desirree" ("white Syrian dish"); Dutch "calijs" (from Latin "colare", "to strain") was known in English as "cullis" and in French as "coulis", and was based on cooked and then strained poultry. The oldest recipe found so far is from a copy of the oldest extant Danish cookbook, written by Henrik Harpestræng, who died in 1244, which dates it to the early 13th century at the latest. The Danish work may simply be a translation of a German work which is in turn assumed to have been based on a Latin or Romance vernacular manuscript from the 12th century or even earlier.
The "whitedish" (from the original Old French term "blanc mangier") was an upper-class dish common to most of Europe during the Middle Ages and early modern period. It occurs in countless variations from recipe collections from all over Europe and is mentioned in the prologue to Geoffrey Chaucer's "Canterbury Tales" and in an early 15th-century cookbook written by the chefs of Richard II. The basic ingredients were milk or almond milk, sugar and shredded chicken (usually capon) or fish, and often combined with rosewater, rice flour, and mixed into a bland stew. Almond milk and fish were used as substitutes for the other animal products on fast days and Lent. It was also often flavored with spices like saffron or cinnamon and the chicken could be exchanged for various types of fowl, like quail or partridge. Spices were often used in recipes of the later Middle Ages since they were considered highly prestigious. The whitedish was one of the preparations that could be found in recipe collections all over Europe and one of the few truly international dishes of medieval and early modern Europe.
On festive occasions and among the upper classes, whitedishes were often rendered more festive by various colouring agents: the reddish-golden yellow of saffron; green with various herbs; or sandalwood for russet. In 14th-century France, parti-colouring, the use of two bright contrasting colours on the same plate, was especially popular and was described by Guillaume Tirel (also known as Taillevent), one of the primary authors of the later editions of Le Viandier. The brightly coloured whitedishes were one of the most common of the early entremets, edibles that were intended to entertain and delight through a gaudy appearance, as much as through flavour.
In the 17th century, the whitedish evolved into a meatless dessert pudding with cream and eggs and, later, gelatin. In the 19th century, arrowroot and cornflour were added and the dish evolved into the modern blancmange.
Etymology.
The word blancmange derives from Old French "blanc mangier". The name "whitedish" is a modern term used by some historians, though the name historically was either a direct translation from or a calque of the Old French term. Many different local or regional terms were used for the dish in the Middle Ages:
Though it is fairly certain that the etymology is indeed "white dish", medieval sources are not always consistent as to the actual colour of the dish. Food scholar Terence Scully has proposed the alternative etymology of "bland mangier", "bland dish", reflecting its often mild and "dainty" (in this context meaning refined and aristocratic) taste and popularity as a sick dish.

</doc>
<doc id="37735" url="http://en.wikipedia.org/wiki?curid=37735" title="Melody">
Melody

A melody (from Greek μελῳδία, "melōidía", "singing, chanting"), also tune, voice, or line, is a linear succession of musical tones that the listener perceives as a single entity. In its most literal sense, a melody is a combination of pitch and rhythm, while more figuratively, the term can include successions of other musical elements such as tonal color. It may be considered the foreground to the background accompaniment. A line or part need not be a foreground melody.
Melodies often consist of one or more musical phrases or motifs, and are usually repeated throughout a composition in various forms. Melodies may also be described by their melodic motion or the pitches or the intervals between pitches (predominantly conjunct or disjunct or with further restrictions), pitch range, tension and release, continuity and coherence, cadence, and shape.
The true goal of music—its proper enterprise—is melody. All the parts of harmony have as their ultimate purpose only beautiful melody. Therefore, the question of which is the more significant, melody or harmony, is futile. Beyond doubt, the means is subordinate to the end.—Johann Philipp Kirnberger (1771)
Elements.
Given the many and varied elements and styles of melody "many extant explanations [of melody] confine us to specific stylistic models, and they are too exclusive." Paul Narveson claimed in 1984 that more than three-quarters of melodic topics had not been explored thoroughly.
The melodies existing in most European music written before the 20th century, and popular music throughout the 20th century, featured "fixed and easily discernible frequency patterns", recurring "events, often periodic, at all structural levels" and "recurrence of durations and patterns of durations".
Melodies in the 20th century "utilized a greater variety of pitch resources than ha[d] been the custom in any other historical period of Western music." While the diatonic scale was still used, the chromatic scale became "widely employed." Composers also allotted a structural role to "the qualitative dimensions" that previously had been "almost exclusively reserved for pitch and rhythm". Kliewer states, "The essential elements of any melody are duration, pitch, and quality (timbre), texture, and loudness. Though the same melody may be recognizable when played with a wide variety of timbres and dynamics, the latter may still be an "element of linear ordering"
Examples.
Different musical styles use melody in different ways. For example:

</doc>
<doc id="37736" url="http://en.wikipedia.org/wiki?curid=37736" title="Roger Zelazny">
Roger Zelazny

Roger Joseph Zelazny (May 13, 1937 – June 14, 1995) was an American poet and writer of fantasy and science fiction short stories and novels, best known for his The Chronicles of Amber series. He won the Nebula award three times (out of 14 nominations) and the Hugo award six times (also out of 14 nominations), including two Hugos for novels: the serialized novel "...And Call Me Conrad" (1965; subsequently published under the title "This Immortal", 1966) and then the novel "Lord of Light" (1967).
The ostracod "Sclerocypris zelaznyi" was named after him.
Biography.
Roger Joseph Zelazny was born in Euclid, Ohio, the only child of Polish immigrant Joseph Frank Żelazny and Irish-American Josephine Flora Sweet. In high school, he became the editor of the school newspaper and joined the Creative Writing Club. In the fall of 1955, he began attending Western Reserve University and graduated with a B.A. in English in 1959. He was accepted to Columbia University in New York and specialized in Elizabethan and Jacobean drama, graduating with an M.A. in 1962. His M.A. thesis was entitled "Two traditions and Cyril Tourneur: an examination of morality and humor comedy conventions in" The Revenger's Tragedy. Between 1962 and 1969 he worked for the U.S. Social Security Administration in Cleveland, Ohio and then in Baltimore, Maryland spending his evenings writing science fiction. He deliberately progressed from short-shorts to novelettes to novellas and finally to novel-length works by 1965. On May 1, 1969, he quit to become a full-time writer, and thereafter concentrated on writing novels in order to maintain his income. During this period, he was an active and vocal member of the Baltimore Science Fiction Society, whose members included writers Jack Chalker and Joe and Jack Haldeman among others.
Zelazny was married twice, first to Sharon Steberl in 1964 (divorced, no children), and then to Judith Alene Callahan in 1966 (he had also been engaged to folk singer Hedy West for six months in 1961/62). Roger and Judy had two sons, Devin and Trent (an author of crime fiction) and a daughter, Shannon. At the time of his death, Roger and Judy were separated and he was living with author Jane Lindskold.
His first fanzine appearance was part one of the story "Conditional Benefit" ("Thurban 1" #3, 1953) and his first professional publication and sale was the fantasy short story "Mr. Fuller's Revolt" ("Literary Calvalcade", 1954). As a professional writer, his debut works were the simultaneous publication of "Passion Play" ("Amazing", August 1962) and "Horseman!" ("Fantastic", August 1962). "Passion Play" was written and sold first. His first story to attract major attention was "A Rose for Ecclesiastes", published in "The Magazine of Fantasy and Science Fiction", with cover art by Hannes Bok.
Roger Zelazny was also a member of the Swordsmen and Sorcerers' Guild of America (SAGA), a loose-knit group of Heroic Fantasy authors founded in the 1960s, some of whose works were anthologized in Lin Carter's "Flashing Swords!" anthologies.
Raised as a Catholic by his parents, Zelazny later declared himself a lapsed Catholic and remained that way for the rest of his life. "I did have a strong Catholic background, but I am not a Catholic. Somewhere in the past, I believe I answered in the affirmative once for strange and complicated reasons. But I am not a member of any organized religion."
Zelazny died in 1995, aged 58, of kidney failure secondary to colorectal cancer.
Characteristic themes.
In his stories, Roger Zelazny frequently portrayed characters from myth, depicted in the modern world. Zelazny was also apt to include numerous anachronistic present-day elements, such as cigarette-smoking (see below) and references to various drama classics into his fantasy and science-fiction works. His crisp, minimalistic dialogue also seems to be somewhat influenced by the style of wisecracking hardboiled crime authors, such as Raymond Chandler or Dashiell Hammett. The tension between the ancient and the modern, surreal and familiar was what drove most of his work.
A very frequent motif in Zelazny's work is immortality or people who (have) become gods (as well as gods who have turned into people). The mythological traditions his fiction borrowed from include:
Additionally, elements from Norse, Japanese and Irish mythology, Arthurian legend as well as several references to real history appear in his magnum opus, "The Chronicles of Amber".
Aside from working with mythological themes, the most common recurring motif of Zelazny's is the "absent father" (or father-figure). Again, this occurs most notably in the Amber novels: in the first Amber series, the main protagonist Corwin searches for his lost, god-like father Oberon; while in the second series, which focuses on Corwin's son Merlin (not to be confused with the Arthurian Merlin!), it is Corwin himself who is strangely missing. This somewhat Freudian theme runs through almost every Zelazny novel to a smaller or larger degree. "Roadmarks", "Doorways in the Sand", "Changeling", "Madwand", "A Dark Traveling"; the short stories "Dismal Light", "Godson", "The Keys to December"; and the "Alien Speedway" series all feature main characters who are either searching for or have lost their fathers. Zelazny’s father, Joseph, died unexpectedly in 1962 and never knew his son’s successes as a writer; this event may have triggered Zelazny's unconscious and frequent use of the absent father motif.
Two other personal characteristics that influenced his fiction were his expertise in martial arts and his addiction to tobacco. Zelazny became expert with the épée in college, and thus began a lifelong study of several different martial arts, including Karate, Judo, Aikido (which he later taught as well, having gained a black belt), T'ai Chi, Tae Kwon Do, Hapkido, Hsing I, and Pa Kua. In turn, many of his characters ably and knowledgeably use similar skills whilst dispatching their opponents. Zelazny was also a passionate cigarette and pipe smoker (until he quit in the early '80s), so much so, that he made many of his protagonists heavy smokers as well. However, he quit in order to improve his cardiovascular fitness for the martial arts; once he had quit, characters in his later novels and short stories stopped smoking too.
Another characteristic of Zelazny's writing is that many of his protagonists had sufficient familiarity with other languages to be able to quote French, German, Italian or Latin aphorisms when the occasion seemed appropriate (or even inappropriate), although Zelazny himself did not speak any of those languages.
He also often experimented with form in his stories. The novel "Doorways in the Sand" practices a flashback technique in which most chapters open with a scene, typically involving peril, not implied by the end of the previous chapter. Once the scene is established, the narrator backtracks to the events leading up to it, then follows through to the end of the chapter, whereupon the next chapter jumps ahead to another dramatic "non-sequitur".
In "Roadmarks", a novel about a road system that links all possible times, places and histories, the chapters that feature the main protagonist are all titled "One". Other chapters, titled "Two", feature secondary characters, including original characters, pulp heroes, and real historical characters. The "One" storyline is fairly linear, whereas the "Two" storyline jumps around in time and sequence. After finishing the manuscript, Zelazny shuffled the "Two" chapters randomly among the "One" chapters in order to emphasize their non-linear nature relative to the storyline.
"Creatures of Light and Darkness", featuring characters in the personae of Egyptian gods, uses a narrative voice entirely in the present tense; the final chapter is structured as a play, and several chapters take the form of long poems.
Zelazny also tended to write a short fragment, not intended for publication, as a kind of backstory for a major character, as a way of giving that character a life independent of the particular novel being worked on. At least one "fragment" was published, the short story "Dismal Light", originally a backstory for "Isle of the Dead"'s Francis Sandow. Sandow himself figures little in "Dismal Light", the main character being his son, who is delaying his escape from an unstable star system in order to force his distant father to come in and ask him personally. While "Isle of the Dead" has Sandow living a life of irresponsible luxury as an escape from his personal demons, "Dismal Light" anchors his character as one who will face up to his responsibilities, however reluctantly.
Another common stylistic approach in his novels is the use of "mixed genres", whereby elements of each are combined freely and interchangeably. "Jack of Shadows" and "Changeling", for example, revolve around the tensions between the two worlds of magic and technology. "Lord of Light", perhaps one of his most famous works, is written in the classic style of a mythic fantasy, while it is established early in the book that the story itself takes place on a colonized planet.
Many of Zelazny's works explore variations upon the idea that if there exists an infinite number of worlds, then every world that can be imagined must exist, somewhere. Powerful beings in many of his stories have the ability to travel to worlds that possess precisely the characteristics which that being wishes to experience. (Zelazny characters with this ability include Thoth in "Creatures of Light and Darkness", who teleports to these worlds; those with the royal blood of either Amber or Chaos in "The Chronicles of Amber", who "move through shadows" to reach these worlds; the guardian families of "A Dark Traveling", who move between realities using high-tech devices; and Red Dorakeen in "Roadmarks", who reaches these worlds by driving along a magical highway.) Many of these same characters wonder whether they are creating these special places anew, or are merely finding places which already exist (very much like "the problem of universals" in classical metaphysics). Usually each character who ponders this ultimately decides that the question is purely academic and therefore unanswerable.
Awards.
Zelazny won at least 16 awards for particular works of fiction: 6 Hugo Awards, 3 Nebula Awards, 2 Locus Awards, 1 Prix Tour-Apollo Award, 2 Seiun Awards, and 2 Balrog Awards – very often Zelazny's works competed with each other for the same award.
In addition, Zelazny was the Worldcon Guest of Honor at Discon II in Washington, DC in 1974, and won the Inkpot Award for Best Prose Author at Comic-Con International in 1993. "A Rose for Ecclesiastes" was included in "Visions of Mars: First Library on Mars", a DVD taken on board the "Phoenix Mars Lander" in 2008.
Bibliography.
Amber.
The Chronicles of Amber comprise two distinct series of five novels and several short stories.
The first five books describe the adventures of Prince Corwin of Amber:
The second series tells the story of Corwin's son Merlin (Merle), a wizard and computer expert. These volumes are:
Zelazny also wrote seven short stories set in the Amber multiverse. Here they are listed in Zelazny's intended order, with first publication dates.
The latter five of these stories form one tale set after "Prince of Chaos", the last novel, so they are latest in Amber history.
All 10 novels have been published in a single omnibus form as "The Great Book of Amber" and six of the seven short stories were collected in "Manna from Heaven". A sex scene deleted from "The Guns of Avalon" has been published in "Collected Stories", volume 3, while the seven Amber short tales appear in volumes 6.
Zelazny collaborated on a companion book, "The Visual Guide to Castle Amber" (1988), by Zelazny and Neil Randall, illustrated by Todd Cameron Hamilton and James Clouse. The Guide is a reference work providing biographical detail on the Amber characters and a walk-through guide to Castle Amber itself.
John Betancourt has written a series of novels set in the Amber multiverse set several centuries before "Nine Princes in Amber". Betancourt's series tells the story of Corwin's father Oberon, a wizard and shapeshifter. That the Zelazny estate authorized the series has caused some controversy; see The Chronicles of Amber for more details.
An interactive fiction computer game based on "Nine Princes in Amber" was released by Telarium in 1987. The Amber novels also inspired a unique role-playing game, lacking any random element: "Amber Diceless Roleplaying", published by Phage Press.
Posthumous collaborations.
Two books begun by Zelazny were completed by companion and novelist Jane Lindskold after Zelazny's death:
The adventure game "Chronomaster" (developed by DreamForge Intertainment, published by IntraCorp in 1996) was designed by Zelazny and Jane Lindskold (who also finished it after his death).
Anthologies edited by Zelazny.
Zelazny was also a contributor to the Wild Cards shared world anthology series (edited by George R. R. Martin), following the exploits of his character Croyd Crenson, the Sleeper.
Zelazny created the Alien Speedway series of novels (Clypsis by Jeffrey Carver, Pitfall and The Web by Thomas Wylde) which appeared between 1986–87. His own story "Deadboy Donner and the Filstone Cup" appears to have been inspired by the outline that he wrote for Alien Speedway.
Zelazny created and edited a shared world anthology called "Forever After". The frame story uses preludes, written by Roger, to connect the stories. This shared world involved stories by Robert Asprin, David Drake, Jane Lindskold, and Michael A. Stackpole. "Forever After" was published by Baen Books posthumously.
Following Zelazny's death, a tribute anthology entitled "Lord of the Fantastic" was released. This featured stories inspired by Zelazny, and personal recollections by contributors such as Robert Silverberg, Fred Saberhagen, Jennifer Roberson, Walter Jon Williams, Gregory Benford and many others.

</doc>
<doc id="37737" url="http://en.wikipedia.org/wiki?curid=37737" title="The Invisible Man">
The Invisible Man

The Invisible Man is a science fiction novella by H. G. Wells published in 1897. Originally serialized in "Pearson's Weekly" in 1897, it was published as a novel the same year. The Invisible Man of the title is Griffin, a scientist who has devoted himself to research into optics and invents a way to change a body's refractive index to that of air so that it absorbs and reflects no light and thus becomes invisible. He successfully carries out this procedure on himself, but fails in his attempt to reverse the procedure.
While its predecessors, "The Time Machine" and "The Island of Doctor Moreau", were written using first-person narrators, Wells adopts a third-person objective point of view in "The Invisible Man".
Plot summary.
A mysterious man, Griffin, arrives at the local inn of the English village of Iping, West Sussex, during a snowstorm. The stranger wears a long-sleeved, thick coat and gloves; his face is hidden entirely by bandages except for a fake pink nose; and he wears a wide-brimmed hat. He is excessively reclusive, irascible, and unfriendly. He demands to be left alone and spends most of his time in his rooms working with a set of chemicals and laboratory apparatus, only venturing out at night. While Griffin is staying at the inn, hundreds of strange glass bottles (that he calls his luggage) arrive. Many local townspeople believe this to be very strange. He becomes the talk of the village.
Meanwhile, a mysterious burglary occurs in the village. Griffin has run out of money and is trying to find a way to pay for his board and lodging. When his landlady demands that he pay his bill and quit the premises, he reveals part of his invisibility to her in a fit of pique. An attempt to apprehend the stranger is frustrated when he undresses to take advantage of his invisibility, fights off his would-be captors, and flees to the downs.
There Griffin coerces a tramp, Thomas Marvel, into becoming his assistant. With Marvel, he returns to the village to recover three notebooks that contain records of his experiments. When Marvel attempts to betray the Invisible Man to the police, Griffin chases him to the seaside town of Port Burdock, threatening to kill him. Marvel escapes to a local inn and is saved by the people at the inn, but Griffin escapes. Marvel later goes to the police and tells them of this "invisible man," then requests to be locked up in a high-security jail.
Griffin's furious attempt to avenge his betrayal leads to his being shot. He takes shelter in a nearby house that turns out to belong to Dr. Kemp, a former acquaintance from medical school. To Kemp, he reveals his true identity: the Invisible Man is Griffin, a former medical student who left medicine to devote himself to optics. Griffin recounts how he invented chemicals capable of rendering bodies invisible, and, on impulse, performed the procedure on himself.
Griffin tells Kemp of the story of how he became invisible. He explains how he tried the invisibility on a cat, then himself. Griffin burned down the boarding house he was staying in, along with all the equipment he used to turn invisible, to cover his tracks; but he soon realised that he was ill-equipped to survive in the open. He attempted to steal food and clothes from a large department store, and eventually stole some clothing from a theatrical supply shop and headed to Iping to attempt to reverse the invisibility. But now he imagines that he can make Kemp his secret confederate, describing his plan to begin a "Reign of Terror" by using his invisibility to terrorise the nation.
Kemp has already denounced Griffin to the local authorities and is waiting for help to arrive as he listens to this wild proposal. When the authorities arrive at Kemp's house, Griffin fights his way out and the next day leaves a note announcing that Kemp himself will be the first man to be killed in the "Reign of Terror". Kemp, a cool-headed character, tries to organise a plan to use himself as bait to trap the Invisible Man, but a note that he sends is stolen from his servant by Griffin.
Griffin shoots and injures a local policeman who comes to Kemp's aid, then breaks into Kemp's house. Kemp bolts for the town, where the local citizenry come to his aid. Griffin is seized, assaulted, and killed by a mob. The Invisible Man's naked, battered body gradually becomes visible as he dies. A local policeman shouts to have someone cover Griffin's face with a sheet, then the book concludes.
In the final chapter, it is revealed that Marvel has secretly kept Griffin's notes, but that he is completely incapable of understanding them.
Characters.
Griffin.
Griffin is the surname of the story's protagonist. His name is not mentioned until about halfway through the book. Consumed with his greed for power and fame, he is the model of science without humanity. A gifted young student, he becomes interested in the science of refraction. During his experiments he accidentally discovers chemicals (combined with an unspecified kind of radiation) that would make tissue invisible. Obsessed with his discovery, he tries the experiment on himself and becomes invisible. However, he does not discover how to reverse the process, and he slowly discovers that the advantages of being invisible do not outweigh the disadvantages and the problems he faces. Thus begins his downfall as he takes the road to crime for his survival, revealing in the process his lack of conscience, inhumanity and complete selfishness. He progresses from obsession to fanaticism, to insanity, and finally to his fateful end.
Dr. Kemp.
Dr. Kemp is a scientist living in the town of Port Burdock. He is a former acquaintance of Griffin, who knew Kemp to be interested in strange, bizarre aspects of science. Kemp continues to study science as he hopes to be admitted to The Royal Society. His scientific temperament makes him listen to the story Griffin tells him. He does not become hysterical nor does he behave like the locals. Griffin hopes Kemp would support him in his evil schemes and help him live a normal life, but Kemp is too decent to join him. He is repelled by Griffin's brutality and considers him insane and homicidal. He betrays Griffin to the police. He keeps his cool throughout the plot, when the final hunt for Griffin begins. Kemp helps in the final capture and killing of Griffin.
In the 1933 Universal film adaptation, Kemp is given the first name Arthur and is played by William Harrigan. Unlike the novel, Kemp in the film does not survive to the end of the story.
Janny Hall.
Janny Hall is the wife of Mr. Hall and the owner of the Coach and Horses Inn. A very friendly, down-to-earth woman who enjoys socialising with her guests, Mrs. Hall is continually frustrated by the mysterious Griffin's refusal to talk with her, and his repeated temper tantrums, and becomes suspicious of him. She may not be entirely sympathetic, as she vents her own frustrations at her maid Millie.
Mrs. Hall appears in the 1933 film adaptation, where she was played by Una O'Connor.
George Hall.
George Hall is the husband of Mrs. Hall and helps her run the Coach and Horses Inn. He was the first person in Iping to suspect that the mysterious Griffin is invisible: when a dog bites him and tears his glove, Griffin retreats to his room and Hall follows to see if he is all right, only to see Griffin without his glove and handless (or so it appears to Hall).
Mr. Hall appears in the 1933 film adaptation, where his first name is changed to Herbert; he is seriously injured by Griffin. He is portrayed by Forrester Harvey.
Thomas Marvel.
Thomas Marvel is a droll tramp unwittingly recruited to assist the Invisible Man as his first visible partner. He carries the Invisible Man's scientific notebooks and stolen money. Eventually Marvel grows afraid of his unseen partner and flees to Port Burdock, taking both the notebooks and the money with him, where he seeks police protection. Although the Invisible Man is furious and vows revenge, he becomes preoccupied with hiding from the law and retaliating against Dr. Kemp, and Marvel is spared. Marvel eventually uses the stolen money to open his own inn, which he calls the Invisible Man, and prospers. The novel ends with him secretly "marvelling" at Griffin's notes (though not comprehending them). It turns out Marvel kept the notes and only views them when there is nobody around, so nobody can know Griffin's secrets — or that Marvel has them.
Marvel does not appear in the 1933 film adaptation, but does appear in Alan Moore's comics series "The League of Extraordinary Gentlemen".
Col. Adye.
Col. Adye is the chief of police in the town of Port Burdock. He is called upon by Dr. Kemp when the Invisible Man turns up in Kemp's house. Adye saves Kemp from the Invisible Man's first attempt on his life and leads the hunt for the unseen fugitive. He mostly follows Kemp's suggestions in planning the campaign against the Invisible Man. He is eventually shot by the Invisible Man with Kemp's revolver. Upon being shot, Adye is described as falling down and not getting back up. However, he is mentioned in the epilogue as being one of those who had questioned Thomas Marvel about the whereabouts of the Invisible Man's notebooks, and it is never made clear whether this occurred prior to his being shot or if it occurred afterwards and Adye survived.
Dr. Cuss.
Dr. Cuss is a doctor living in the village of Iping. Intrigued by tales of a bandaged stranger staying at the Coach and Horses Inn, Dr. Cuss goes to see him under the pretence of asking for a donation to the nurse's fund. Cuss is scared away after Griffin pinches his nose with an invisible hand. Cuss immediately goes to see the Rev. Bunting, who, not surprisingly, does not believe the doctor's wild story. Later, Cuss and Bunting obtain the Invisible Man's notebooks, but these are subsequently stolen back from them by the invisible Griffin, when he also takes both men's clothes.
J.A. Jaffers.
J.A. Jaffers is a constable in the town of Iping. He is called upon by George Hall and Janny Hall to arrest Griffin after they suspect him of robbing the Reverend Bunting. He quickly overcomes his shock at the discovery that Griffin is invisible,and is determined to arrest him in spite of this. The Invisible Man knocks him unconscious in his flight from Iping.
Jaffers appears in the 1933 film adaptation.
Science.
Russian writer Yakov I. Perelman pointed out in "Physics Can Be Fun" (1913) that from a scientific point of view, a man made invisible by Griffin's method should have been blind, since a human eye works by "absorbing" incoming light, not letting it through completely. Wells seems to show some awareness of this problem in Chapter 20, where the eyes of an otherwise invisible cat retain visible retinas. Nonetheless, this would be insufficient, since the retina would be flooded with light (from all directions) that ordinarily is blocked by the opaque sclera of the eyeball. Also, any image would be badly blurred if the eye had an invisible cornea and lens.
Origins and moral.
As a moral tale, "The Invisible Man" can be seen as a modern version of the "Ring of Gyges" parable by Plato.

</doc>
<doc id="37738" url="http://en.wikipedia.org/wiki?curid=37738" title="Soil">
Soil

Soil is the mixture of minerals, organic matter, gases, liquids, and myriad organisms that together support plant life. Two general classes are "topsoil" and "subsoil". Soil is a natural body that exists as part of the pedosphere and which performs four important functions: it is a medium for plant growth; it is a means of water storage, supply and purification; it is a modifier of the atmosphere of Earth; and it is a habitat for organisms all of which modify the soil.
Soil is considered to be the "skin of the earth" with interfaces between the lithosphere, hydrosphere, atmosphere of Earth, and biosphere. Soil consists of a solid phase (minerals and organic matter) as well as a porous phase that holds gases and water. Accordingly, soils are often treated as a three-state system.
Soil is the end product of the influence of the climate, relief (elevation, orientation, and slope of terrain), organisms, and parent materials (original minerals) interacting over time. Soil continually undergoes development by way of numerous physical, chemical and biological processes, which include weathering with associated erosion.
Most soils have a density between 1 and 2 g/cm3. Little of the soil of planet Earth is older than the Pleistocene and none is older than the Cenozoic, although fossilized soils are preserved from as far back as the Archean.
Soil science has two basic branches of study: edaphology and pedology. Pedology is focused on the formation, description (morphology), and classification of soils in their natural environment, whereas edaphology is concerned with the influence of soils on organisms. In engineering terms, soil is referred to as regolith, or loose rock material that lies above the 'solid geology'. Soil is commonly referred to as "earth" or "dirt"; technically, the term "dirt" should be restricted to displaced soil.
As soil resources serve as a basis for food security, the international community advocates for its sustainable and responsible use through different types of Soil Governance.
Overview.
Soil is a major component of the Earth's ecosystem. The world's ecosystems are impacted in far-reaching ways by the processes carried out in the soil, from ozone depletion and global warming, to rain forest destruction and water pollution. Soil is the largest surficial global carbon reservoir on Earth, and it is potentially one of the most reactive to human disturbance and climate change. As the planet warms, soils will add carbon dioxide to the atmosphere due to its increased biological activity at higher temperatures. Thus, soil carbon losses likely have a large positive feedback response to global warming.
Soil acts as an engineering medium, a habitat for soil organisms, a recycling system for nutrients and organic wastes, a regulator of water quality, a modifier of atmospheric composition, and a medium for plant growth. Since soil has a tremendous range of available niches and habitats, it contains most of the earth's genetic diversity. A gram of soil can contain billions of organisms, belonging to thousands of species. Soil has a mean prokaryotic density of roughly 1013 organisms per cubic meter, whereas the ocean has a mean prokaryotic density of roughly 108 organisms per cubic meter. The carbon content stored in soil is eventually returned to the atmosphere through the process of respiration, which is carried out by heterotrophic organisms that feed upon the carbonaceous material in the soil. Since plant roots need oxygen, ventilation is an important characteristic of soil. This ventilation can be accomplished via networks of soil pores, which also absorb and hold rainwater making it readily available for plant uptake. Since plants require a nearly continuous supply of water, but most regions receive sporadic rainfall, the water-holding capacity of soils is vital for plant survival.
Soils can effectively remove impurities, kill disease agents, and degrade contaminants. Typically, soils maintain a net absorption of oxygen and methane, and undergo a net release of carbon dioxide and nitrous oxide. Soils offer plants physical support, air, water, temperature moderation, nutrients, and protection from toxins. Soils provide readily available nutrients to plants and animals by converting dead organic matter into various nutrient forms.
Soils supply plants with mineral nutrients held in place by the clay and humus content of the soil. For optimum plant growth, the generalized content of soil components by volume should be roughly 50% solids (45% mineral and 5% organic matter), and 50% voids of which half is occupied by water and half by gas. The percent soil mineral and organic content is typically treated as a constant, while the percent soil water and gas content is considered highly variable whereby a rise in one is simultaneously balanced by a reduction in the other. The pore space allows for the infiltration and movement of air and water, both of which are critical for life in soil. Compaction, a common problem with soils, reduces this space, preventing air and water from reaching the plant roots and soil organisms.
Given sufficient time, an undifferientated soil will evolve a soil profile which consists of two or more layers, referred to as soil horizons, that differ in one or more properties such as in their texture, structure, density, porosity, consistency, temperature, color, and reactivity. The horizons differ greatly in thickness and generally lack sharp boundaries. Soil profile development is dependent on the processes that form soils from their parent materials, the type of parent material, and the factors that control soil formation. The biological influences on soil properties are strongest near the surface, while the geochemical influences on soil properties increase with depth. Mature soil profiles in temperate climate regions typically include three basic master horizons: A, B and C. The solum normally includes the A and B horizons. The living component of the soil is largely confined to the solum. In the more hot, humid, climate of the tropics, a soil may have only a single horizon.
The soil texture is determined by the relative proportions of sand, silt, and clay in the soil. The addition of organic matter, water, gases and time causes the soil of a certain texture to develop into a larger soil structure called an aggregate. At that point a soil can be said to be developed, and can be described further in terms of color, porosity, consistency, reaction etc.
Of all the factors influencing the evolution of soil, water is the most powerful due to its involvement in the solution, erosion, transportation, and deposition of the materials of which a soil is composed. The mixture of water and dissolved and suspended materials is called the soil solution. Since soil water is never pure water, but contains hundreds of dissolved organic and inorganic substances, it may be more accurately called the soil solution. Water is central to the solution, precipitation and leaching of minerals from the soil profile. Finally, water affects the type of vegetation that grows in a soil, which in turn affects the development of the soil profile.
The most influential factor in stabilizing soil fertility are the soil colloidal particles, clay and humus, which behave as repositories of nutrients and moisture and so act to buffer the variations of soil solution ions and moisture. The contribution of soil colloids to soil nutrition are out of proportion to their part of the soil. Colloids act to store nutrients that might otherwise be leached from the soil or to release those ions in response to changes of soil pH, and so, to make them available to plants.
The greatest influence on plant nutrient availability is soil pH, which is a measure of the hydrogen ion (acid-forming) soil reactivity, and is in turn a function of the soil materials, precipitation level, and plant root behavior. Soil pH strongly affects the availability of nutrients.
Most nutrients, with the exception of nitrogen, originate from minerals. Some nitrogen originates from rain, but most of the nitrogen available in soils is the result of nitrogen fixation by bacteria. The action of microbes on organic matter and minerals may be to free nutrients for use, sequester them, or cause their loss from the soil by their volatilisation to gases or their leaching from the soil. The nutrients may be stored on soil colloids, and live or dead organic matter, but they may not be accessible to plants due to extremes of pH.
The organic material of the soil has a powerful effect on its development, fertility, and available moisture. Following water and soil colloids, organic material is next in importance to soil's formation and fertility.
History of the study of soil.
Studies concerning soil fertility.
The history of the study of soil is intimately tied to our urgent need to provide food for ourselves and forage for our animals. Throughout history, civilizations have prospered or declined as a function of the availability and productivity of their soils.
The Greek historian Xenophon (450–355 B.C.) is credited with being the first to expound upon the merits of green-manuring crops: "But then whatever weeds are upon the ground, being turned into earth, enrich the soil as much as dung."
Columella's "Husbandry," circa 60 A.D., advocated the use of lime and that clover and alfalfa (green manure) should be turned under, and was used by 15 generations (450 years) under the Roman Empire until its collapse. From the fall of Rome to the French Revolution, knowledge of soil and agriculture was passed on from parent to child and as a result, crop yields were low. During the European Dark Ages, Yahya Ibn_al-'Awwam's handbook, with its emphasis on irrigation, guided the people of North Africa, Spain and the Middle East; a translation of this work was finally carried to the southwest of the United States.
Experiments into what made plants grow first led to the idea that the ash left behind when plant matter was burned was the essential element but overlooked the role of nitrogen, which is not left on the ground after combustion. In about 1635, the Flemish chemist Jan Baptist van Helmont thought he had proved water to be the essential element from his famous five years' experiment with a willow tree grown with only the addition of rainwater. His conclusion came from the fact that the increase in the plant's weight had apparently been produced only by the addition of water, with no reduction in the soil's weight. John Woodward (d. 1728) experimented with various types of water ranging from clean to muddy and found muddy water the best, and so he concluded that earthy matter was the essential element. Others concluded it was humus in the soil that passed some essence to the growing plant. Still others held that the vital growth principal was something passed from dead plants or animals to the new plants. At the start of the 18th century, Jethro Tull demonstrated that it was beneficial to cultivate (stir) the soil, but his opinion that the stirring made the fine parts of soil available for plant absorption was erroneous.
As chemistry developed, it was applied to the investigation of soil fertility. The French chemist Antoine Lavoisier showed in about 1778 that plants and animals must "combust" oxygen internally to live and was able to deduce that most of the 165-pound weight of van Helmont's willow tree derived from air. It was the French agriculturalist Jean-Baptiste Boussingault who by means of experimentation obtained evidence showing that the main sources of carbon, hydrogen and oxygen for plants were the air and water. Justus von Liebig in his book "Organic Chemistry in its Applications to Agriculture and Physiology" (published 1840), asserted that the chemicals in plants must have come from the soil and air and that to maintain soil fertility, the used minerals must be replaced. Liebig nevertheless believed the nitrogen was supplied from the air. The enrichment of soil with guano by the Incas was rediscovered in 1802, by Alexander von Humboldt. This led to its mining and that of Chilean nitrate and to its application to soil in the United States and Europe after 1840.
The work of Liebig was a revolution for agriculture, and so other investigators started experimentation based on it. In England John Bennet Lawes and Joseph Henry Gilbert worked in the Rothamsted Experimental Station, founded by the former, and discovered that plants took nitrogen from the soil, and that salts needed to be in an available state to be absorbed by plants. Their investigations also produced the "superphosphate", consisting in the acid treatment of phosphate rock. This led to the invention and use of salts of potassium (K) and nitrogen (N) as fertilizers. Ammonia generated by the production of coke was recovered and used as fertiliser. Finally, the chemical basis of nutrients delivered to the soil in manure was understood and in the mid-19th century chemical fertilisers were applied. However, the dynamic interaction of soil and its life forms awaited discovery.
In 1856 J. T. Way discovered that ammonia contained in fertilisers was transformed into nitrates, and twenty years later R. W. Warington proved that this transformation was done by living organisms. In 1890 Sergei Winogradsky announced he had found the bacteria responsible for this transformation.
It was known that certain legumes could take up nitrogen from the air and fix it to the soil but it took the development of bacteriology towards the end of the 19th century to lead to an understanding of the role played in nitrogen fixation by bacteria. The symbiosis of bacteria and leguminous roots, and the fixation of nitrogen by the bacteria, were simultaneously discovered by German agronomist Hermann Hellriegel and Dutch microbiologist Martinus Beijerinck.
Crop rotation, mechanisation, chemical and natural fertilisers led to a doubling of wheat yields in Western Europe between 1800 and 1900.
Studies concerning soil formation.
The scientists who studied the soil in connection with agricultural practices had considered it mainly as a static substrate. However, soil is the result of evolution from more ancient geological materials. After studies of the improvement of the soil commenced, others began to study soil genesis and as a result also soil types and classifications.
In 1860, in Mississippi, Eugene W. Hilgard studied the relationship among rock material, climate, and vegetation, and the type of soils that were developed. He realised that the soils were dynamic, and considered soil types classification. Unfortunately his work was not continued. At the same time Vasily Dokuchaev (about 1870) was leading a team of soil scientists in Russia who conducted an extensive survey of soils, finding that similar basic rocks, climate and vegetation types lead to similar soil layering and types, and established the concepts for soil classifications. Due to the language barriers, the work of this team was not communicated to Western Europe until 1914 by a publication in German by K. D. Glinka, a member of the Russian team.
Curtis F. Marbut was influenced by the work of the Russian team, translated Glinka's publication into English, and as he was placed in charge of the U. S. National Cooperative Soil Survey, applied it to a national soil classification system.
Soil-forming processes.
Soil formation, or pedogenesis, is the combined effect of physical, chemical, biological and anthropogenic processes working on soil parent material. Soil is said to be formed when organic matter has accumulated and colloids are washed downward, leaving deposits of clay, humus, iron oxide, carbonate, and gypsum, producing a distinct layer called the B horizon. This is a somewhat arbitrary definition as mixtures of sand, silt, clay and humus will support biological and agricultural activity before that time. These constituents are moved from one level to another by water and animal activity. As a result, layers (horizons) form in the soil profile. The alteration and movement of materials within a soil causes the formation of distinctive soil horizons.
How soil formation proceeds is influenced by at least five classic factors that are intertwined in the evolution of a soil. They are: parent material, climate, topography (relief), organisms, and time. When reordered to climate, relief, organisms, parent material, and time, they form the acronym CROPT.
An example of the development of a soil would begin with the weathering of lava flow bedrock, which would produce the purely mineral-based parent material from which the soil texture forms. Soil development would proceed most rapidly from bare rock of recent flows in a warm climate, under heavy and frequent rainfall. Under such conditions, plants become established very quickly on basaltic lava, even though there is very little organic material. The plants are supported by the porous rock as it is filled with nutrient-bearing water that carries dissolved minerals from the rocks and guano. Crevasses and pockets, local topography of the rocks, would hold fine materials and harbour plant roots. The developing plant roots are associated with mycorrhizal fungi that assist in breaking up the porous lava, and by these means organic matter and a finer mineral soil accumulate with time.
Parent material.
The mineral material from which a soil forms is called parent material. Rock, whether its origin is igneous, sedimentary, or metamorphic, is the source of all soil mineral materials and the origin of all plant nutrients with the exceptions of nitrogen, hydrogen and carbon. As the parent material is chemically and physically weathered, transported, deposited and precipitated, it is transformed into a soil.
Typical soil parent mineral materials are:
Classification of parent material.
Parent materials are classified according to how they came to be deposited. Residual materials are mineral materials that have weathered in place from primary bedrock. Transported materials are those that have been deposited by water, wind, ice or gravity. Cumulose material is organic matter that has grown and accumulates in place.
Residual soils are soils that develop from their underlying parent rocks and have the same general chemistry as those rocks. The soils found on mesas, plateaux, and plains are residual soils. In the United States as little as three percent of the soils are residual.
Most soils derive from transported materials that have been moved many miles by wind, water, ice and gravity.
Cumulose parent material is not moved but originates from deposited organic material. This includes peat and muck soils and results from preservation of plant residues by the low oxygen content of a high water table. While peat may form sterile soils, muck soils may be very fertile.
Weathering of parent material.
The weathering of parent material takes the form of physical weathering (disintegrating), chemical weathering (decomposition) and chemical transformation. Generally, minerals that are formed under the high temperatures and pressures at great depths within the earth's mantle are less resistant to weathering, while minerals formed at low temperature and pressure environment of the surface are more resistant to weathering. Weathering is usually confined to the top few meters of geologic material, because physical, chemical, and biological stresses generally decrease with depth. Physical disintegration begins as rocks that have solidified deep in the earth are exposed to lower pressure near the surface and swell and become unstable. Chemical decomposition is a function of mineral solubility, the rate of which doubles with each 10 °C rise in temperature, but is strongly dependent on water to effect chemical changes. Rocks that will decompose in a few years in tropical climates will remain unaltered for millennia in deserts. Structural changes are the result of hydration, oxidation, and reduction.
Of the above, hydrolysis and carbonation are the most effective.
Saprolite is a particular example of a residual soil formed from the transformation of granite, metamorphic and other types of bedrock into clay minerals. Often called "weathered granite", saprolite is the result of weathering processes that include: hydrolysis, chelation from organic compounds, hydration (the solution of minerals in water with resulting cation and anion pairs) and physical processes that include freezing and thawing. The mineralogical and chemical composition of the primary bedrock material, its physical features, including grain size and degree of consolidation, and the rate and type of weathering transform the parent material into a different mineral. The texture, pH and mineral constituents of saprolite are inherited from its parent material.
Climate.
The principal climatic variables influencing soil formation are effective precipitation (i.e., precipitation minus evapotranspiration) and temperature, both of which affect the rates of chemical, physical, and biological processes. The temperature and moisture both influence the organic matter content of soil through their effects on the balance between plant growth and microbial decomposition. Climate is the dominant factor in soil formation, and soils show the distinctive characteristics of the climate zones in which they form. For every 10 °C rise in temperature, the rates of biochemical reactions more than double. Mineral precipitation and temperature are the primary climatic influences on soil formation. If warm temperatures and abundant water are present in the profile at the same time, the processes of weathering, leaching, and plant growth will be maximized. Humid climates favor the growth of trees. In contrast, grasses are the dominant native vegetation in subhumid and semiarid regions, while shrubs and brush of various kinds dominate in arid areas.
Water is essential for all the major chemical weathering reactions. To be effective in soil formation, water must penetrate the regolith. The seasonal rainfall distribution, evaporative losses, site topography, and soil permeability interact to determine how effectively precipitation can influence soil formation. The greater the depth of water penetration, the greater the depth of weathering of the soil and its development. Surplus water percolating through the soil profile transports soluble and suspended materials from the upper to the lower layers. It may also carry away soluble materials in the surface drainage waters. Thus, percolating water stimulates weathering reactions and helps differentiate soil horizons. Likewise, a deficiency of water is a major factor in determining the characteristics of soils of dry regions. Soluble salts are not leached from these soils, and in some cases they build up to levels that curtail plant growth. Soil profiles in arid and semi-arid regions are also apt to accumulate carbonates and certain types of expansive clays.
The direct influences of climate include:
Climate directly affects the rate of weathering and leaching. Wind moves sand and smaller particles, especially in arid regions where there is little plant cover. The type and amount of precipitation influence soil formation by affecting the movement of ions and particles through the soil, and aid in the development of different soil profiles. Soil profiles are more distinct in wet and cool climates, where organic materials may accumulate, than in wet and warm climates, where organic materials are rapidly consumed. The effectiveness of water in weathering parent rock material depends on seasonal and daily temperature fluctuations. Cycles of freezing and thawing constitute an effective mechanism which breaks up rocks and other consolidated materials.
Climate also indirectly influences soil formation through the effects of vegetation cover and biological activity, which modify the rates of chemical reactions in the soil.
Topography.
The topography, or relief, is characterized by the inclination (slope), elevation, and orientation of the terrain. Topography determines the rate of precipitation or runoff and rate of formation or erosion of the surface soil profile. The topographical setting may either hasten or retard the work of climatic forces.
Steep slopes encourage rapid soil loss by erosion and allow less rainfall to enter the soil before running off and hence, little mineral deposition in lower profiles. In semiarid regions, the lower effective rainfall on steeper slopes also results in less complete vegetative cover, so there is less plant contribution to soil formation. For all of these reasons, steep slopes prevent the formation of soil from getting very far ahead of soil destruction. Therefore, soils on steep terrain tend to have rather shallow, poorly developed profiles in comparison to soils on nearby, more level sites.
In swales and depressions where runoff water tends to concentrate, the regolith is usually more deeply weathered and soil profile development is more advanced. However, in the lowest landscape positions, water may saturate the regolith to such a degree that drainage and aeration are restricted. Here, the weathering of some minerals and the decomposition of organic matter are retarded, while the loss of iron and manganese is accelerated. In such low-lying topography, special profile features characteristic of wetland soils may develop. Depressions allow the accumulation of water, minerals and organic matter and in the extreme, the resulting soils will be saline marshes or peat bogs. Intermediate topography affords the best conditions for the formation of an agriculturally productive soil.
Organisms.
Soil is the most abundant ecosystem on Earth, but the vast majority of organisms in soil are microbes, a great many of which have not been described. There may be a population limit of around one billion cells per gram of soil, but estimates of the number of species vary widely. Estimates range from 50,000 per gram to over a million species per gram of soil. The total number of organisms and species can vary widely according to soil type, location, and depth.
Plants, animals, fungi, bacteria and humans affect soil formation (see soil biomantle and stonelayer). Animals, soil mesofauna and micro-organisms mix soils as they form burrows and pores, allowing moisture and gases to move about. In the same way, plant roots open channels in soils. Plants with deep taproots can penetrate many metres through the different soil layers to bring up nutrients from deeper in the profile. Plants with fibrous roots that spread out near the soil surface have roots that are easily decomposed, adding organic matter. Micro-organisms, including fungi and bacteria, effect chemical exchanges between roots and soil and act as a reserve of nutrients.
Humans impact soil formation by removing vegetation cover with erosion as the result. Their tillage also mixes the different soil layers, restarting the soil formation process as less weathered material is mixed with the more developed upper layers.
Earthworms, ants and termites mix the soil as they burrow, significantly affecting soil formation. Earthworms ingest soil particles and organic residues, enhancing the availability of plant nutrients in the material that passes through their bodies. They aerate and stir the soil and increase the stability of soil aggregates, thereby assuring ready infiltration of water. As they build mounds, some organisms might transport soil materials from one horizon to another.
In general, the mixing activities of animals, sometimes called pedoturbation, tends to undo or counteract the tendency of other soil-forming processes that create distinct horizons. Termites and ants may also retard soil profile development by denuding large areas of soil around their nests, leading to increased loss of soil by erosion. Large animals such as gophers, moles, and prairie dogs bore into the lower soil horizons, bringing materials to the surface. Their tunnels are often open to the surface, encouraging the movement of water and air into the subsurface layers. In localized areas, they enhance mixing of the lower and upper horizons by creating, and later refilling, underground tunnels. Old animal burrows in the lower horizons often become filled with soil material from the overlying A horizon, creating profile features known as crotovinas.
Vegetation impacts soils in numerous ways. It can prevent erosion caused by excessive rain that might result from surface runoff. Plants shade soils, keeping them cooler and slow evaporation of soil moisture, or conversely, by way of transpiration, plants can cause soils to lose moisture. Plants can form new chemicals that can break down minerals and improve the soil structure. The type and amount of vegetation depends on climate, topography, soil characteristics, and biological factors. Soil factors such as density, depth, chemistry, pH, temperature and moisture greatly affect the type of plants that can grow in a given location. Dead plants and fallen leaves and stems begin their decomposition on the surface. There, organisms feed on them and mix the organic material with the upper soil layers; these added organic compounds become part of the soil formation process.
Human activities widely influence soil formation. For example, it is believed that Native Americans regularly set fires to maintain several large areas of prairie grasslands in Indiana and Michigan. In more recent times, human destruction of natural vegetation and subsequent tillage of the soil for crop production has abruptly modified soil formation. Likewise, irrigating an arid region of soil drastically influences the soil-forming factors, as does adding fertilizer and lime to soils of low fertility.
Time.
Time is a factor in the interactions of all the above. While a mixture of sand, silt and clay constitute the texture of a soil and the aggregation of those components produces peds, the development of a soil with a distinct B horizon marks the development of a soil. With time, soils will evolve features that depend on the interplay of the prior listed soil-forming factors. It takes decades to several thousand years for a soil to develop a profile. That time period depends strongly on climate, parent material, relief, and biotic activity. For example, recently deposited material from a flood exhibits no soil development as there has not been enough time for the material to form a structure that further defines soil. The original soil surface is buried, and the formation process must begin anew for this deposit. Over time the soil will develop a profile that depends on the intensities of biota and climate. While a soil can achieve relative stability of its properties for extended periods, the soil life cycle ultimately ends in soil conditions that leave it vulnerable to erosion. Despite the inevitability of soil retrogression and degradation, most soil cycles are long.
Soil-forming factors continue to affect soils during their existence, even on "stable" landscapes that are long-enduring, some for millions of years. Materials are deposited on top or are blown or washed from the surface. With additions, removals and alterations, soils are always subject to new conditions. Whether these are slow or rapid changes depends on climate, topography and biological activity.
Physical properties of soils.
The physical properties of soils, in order of decreasing importance, are texture, structure, density, porosity, consistency, temperature, colour and resistivity. Soil texture is determined by the relative proportion of the three kinds of soil particles, called soil separates: sand, silt, and clay. At the next larger scale, soil structures called peds are created from the soil separates when iron oxides, carbonates, clay, silica and humus, coat particles and cause them to adhere into larger, relatively stable secondary structures. Soil density, particularly bulk density, is a measure of soil compaction. Soil porosity consists of the void part of the soil volume and is occupied by gases or water. Soil consistency is the ability of soil to stick together. Soil temperature and colour are self-defining. Resistivity refers to the resistance to conduction of electric currents and affects the rate of corrosion of metal and concrete structures. These properties may vary through the depth of a soil profile. Most of these properties determine the aeration of the soil and the ability of water to infiltrate and to be held within the soil.
Texture.
 The mineral components of soil are sand, silt and clay, and their relative proportions determine a soil's texture. Properties that are influenced by soil texture, include porosity, permeability, infiltration, shrink-swell rate, water-holding capacity, and susceptibility to erosion. In the illustrated USDA textural classification triangle, the only soil in which neither sand, silt nor clay predominates is called "loam". While even pure sand, silt or clay may be considered a soil, from the perspective of food production a loam soil with a small amount of organic material is considered ideal. The mineral constituents of a loam soil might be 40% sand, 40% silt and the balance 20% clay by weight. Soil texture affects soil behaviour, in particular its retention capacity for nutrients and water.
Sand and silt are the products of physical and chemical weathering of the parent rock; clay, on the other hand, is a product of the precipitation of the dissolved parent rock as a secondary mineral. It is the large surface area to volume ratio (specific surface area) of soil particles and the unbalanced ionic charges within those that determine their role in the cation exchange capacity of soil, and hence its fertility. Sand is least active, followed by silt; clay is the most active. Sand's greatest benefit to soil is that it resists compaction and increases a soil's porosity. Silt is mineralogically like sand but with its higher specific surface area it is more chemically active than sand. But it is the clay content of soil, with its very high specific surface area and generally large number of negative charges, that gives a soil its high retention capacity for water and nutrients. Clay soils also resist wind and water erosion better than silty and sandy soils, as the particles bond tightly to each other.
Sand is the most stable of the mineral components of soil; it consists of rock fragments, primarily quartz particles, ranging in size from 2.0 to in diameter. Silt ranges in size from 0.05 to 0.002 mm (0.002 to 0.00008 in). Clay cannot be resolved by optical microscopes as its particles are 0.002 mm or less in diameter. In medium-textured soils, clay is often washed downward through the soil profile and accumulates in the subsoil.
Soil components larger than 2.0 mm are classed as rock and gravel and are removed before determining the percentages of the remaining components and the texture class of the soil, but are included in the name. For example, a sandy loam soil with 20% gravel would be called gravelly sandy loam.
When the organic component of a soil is substantial, the soil is called organic soil rather than mineral soil. A soil is called organic if:
Structure.
The clumping of the soil textural components of sand, silt and clay causes aggregates to form and the further association of those aggregates into larger units creates soil structures called pedoliths or peds. The adhesion of the soil textural components by organic substances, iron oxides, carbonates, clays, and silica, and the breakage of those aggregates from expansion-contraction, caused by freezing-thawing and wetting-drying cycles, shape soil into distinct geometric forms. The peds evolve into units which may have various shapes, sizes and degrees of development. A soil clod, however, is not a ped but rather a mass of soil that results from mechanical disturbance of the soil. Soil structure affects aeration, water movement, conduction of heat, plant root growth and resistance to erosion. Water, in turn, has its strongest effect on soil structure due to its solution and precipitation of minerals and its effect on plant growth.
Soil structure often gives clues to its texture, organic matter content, biological activity, past soil evolution, human use, and the chemical and mineralogical conditions under which the soil formed. While texture is defined by the mineral component of a soil and is an innate property of the soil that does not change with agricultural activities, soil structure can be improved or destroyed by the choice and timing of farming practices.
Soil structural classes:
At the largest scale, the forces that shape a soil's structure result from swelling and shrinkage that initially tend to act horizontally, causing vertically oriented prismatic peds. Clayey soil, due to its differential drying rate with respect to the surface, will induce horizontal cracks, reducing columns to blocky peds. Roots, rodents, worms, and freezing-thawing cycles further break the peds into a spherical shape.
At a smaller scale, plant roots extend into voids and remove water causing the open spaces to increase, and decrease physical aggregation size. At the same time roots, fungal hyphae and earthworms create microscopic tunnels that break up peds.
At an even smaller scale, soil aggregation continues as bacteria and fungi exude sticky polysaccharides which bind soil into small peds. The addition of the raw organic matter that bacteria and fungi feed upon encourages the formation of this desirable soil structure.
At the lowest scale, the soil chemistry affects the aggregation or dispersal of soil particles. The clay particles contain polyvalent cations which give the faces of clay layers a net negative charge. At the same time the edges of the clay plates have a slight positive charge, thereby allowing the edges to adhere to the faces of other clay particles or to flocculate (form clumps). On the other hand, when monovalent ions such as sodium invade and displace the polyvalent cations, they weaken the positive charges on the edges, while the negative surface charges are relatively strengthened. This leaves a net negative charge on the clay, causing the particles to push apart, and by doing so to prevent the flocculation of clay particles into larger, open assemblages. As a result, the clay disperses and settles into voids between peds, causing those to close. In this way the soil aggregation is destroyed and the soil is made impenetrable to air and water. Such sodic soil tends to form columnar structures near the surface.
Density.
Density is the weight per unit volume of an object. Particle density is equal to the mass of solid particles divided by the volume of solid particles - it is the density of only the mineral particles that make up a soil; i.e., it excludes pore space and organic material. Soil particle density is typically 2.60 to 2.75 grams per cm3 and is usually unchanging for a given soil. Soil particle density is lower for soils with high organic matter content, and is higher for soils with high Fe-oxides content. Soil bulk density is equal to the dry mass of the soil divided by the volume of the soil; i.e., it includes air space and organic materials of the soil volume. A high bulk density is indicative of either soil compaction or high sand content. The bulk density of cultivated loam is about 1.1 to 1.4 g/cm3 (for comparison water is 1.0 g/cm3). Soil bulk density is highly variable for a given soil. A lower bulk density by itself does not indicate suitability for plant growth due to the influence of soil texture and structure. Soil bulk density is inherently always less than the soil particle density.
Porosity.
Pore space is that part of the bulk volume of soil that is not occupied by either mineral or organic matter but is open space occupied by either gases or water. Ideally, the total pore space should be 50% of the soil volume. The gas space is needed to supply oxygen to organisms decomposing organic matter, humus, and plant roots. Pore space also allows the movement and storage of water and dissolved nutrients. This property of soils effectively compartmentalizes the soil pore space such that many organisms are not in direct competition with one another, which may explain not only the large number of species present, but the fact that functionally redundant organisms (organisms with the same ecological niche) can co-exist within the same soil.
There are four categories of pores:
In comparison, root hairs are 8 to 12 µm in diameter. When pore space is less than 30 µm, the forces of attraction that hold water in place are greater than the gravitational force acting to drain the water. At that point, soil becomes water-logged and it cannot breathe. For a growing plant, pore size is of greater importance than total pore space. A medium-textured loam provides the ideal balance of pore sizes. Having large pore spaces that allow rapid gas and water movement is superior to smaller pore space soil that has a greater percentage pore space. Soil texture determines the pore space at the smallest scale, but at a larger scale, soil structure has a strong influence on soil aeration, water infiltration and drainage. Tillage has the short-term benefit of temporarily increasing the number of pores of largest size, but in the end those will be degraded by the destruction of soil aggregation.
Clay soils have smaller pores, but more total pore space than sand.
Consistency.
Consistency is the ability of soil to stick to itself or to other objects (cohesion and adhesion respectively) and its ability to resist deformation and rupture. It is of approximate use in predicting cultivation problems and the engineering of foundations. Consistency is measured at three moisture conditions: air-dry, moist, and wet; In those conditions the consistency quality depend upon the clay content. In the wet state, the two qualities of stickiness and plasticity are assessed. A soil's resistance to fragmentation and crumbling is assessed in the dry state by rubbing the sample. Its resistance to shearing forces is assessed in the moist state by thumb and finger pressure. Finally, a soil's plasticity is measured in the wet state by moulding with the hand. Finally, the cemented consistency depends on cementation by substances other than clay, such as calcium carbonate, silica, oxides and salts; moisture content has little effect on its assessment. The measures of consistency border on subjective as they employ the "feel" of the soil in those states.
The terms used to describe the soil consistency in three moisture states and a last consistency not affected by the amount of moisture are as follows:
Soil consistency is useful in estimating the ability of soil to support buildings and roads. More precise measures of soil strength are often made prior to construction.
Temperature.
Soil temperature depends on the ratio of the energy absorbed to that lost. Soil has a temperature range between -20 to 60 °C. Soil temperature regulates seed germination, plant and root growth and the availability of nutrients. Below 50 cm (20 in), soil temperature seldom changes and can be approximated by adding 1.8 °C (2 °F) to the mean annual air temperature. Soil temperature has important seasonal, monthly and daily variations. Fluctuations in soil temperature are much lower with increasing soil depth. Heavy mulching (a type of soil cover) can slow the warming of soil, and, at the same time, reduce fluctuations in surface temperature.
Most often, agricultural activities must adapt to soil temperatures by:
Otherwise soil temperatures can be raised by drying soils or the use of clear plastic mulches. Organic mulches slow the warming of the soil.
There are various factors that affect soil temperature, such as water content, soil color, and relief (slope, orientation, and elevation), and soil cover (shading and insulation). The color of the ground cover and its insulating properties have a strong influence on soil temperature. Whiter soil tends to have a higher albedo than blacker soil cover, which encourages whiter soils to have cooler soil temperatures. The specific heat of soil is the energy required to raise the temperature of soil by 1 °C. The specific heat of soil increases as water content increases, since the heat capacity of water is greater than that of dry soil. The specific heat of pure water is ~ 1 calorie per gram, the specific heat of dry soil is ~ 0.2 calories per gram and the specific heat of wet soil is ~ 0.2 to 1 calories per gram. Also, tremendous energy (~540 cal/g) is required and dissipated to evaporate water (known as the heat of vaporization). As such, wet soil usually warms more slowly than dry soil - wet surface soil is typically 3 to 6 °C colder than dry surface soil.
Soil heat flux refers to the conduction (or movement) of energy (or heat) in response to a temperature gradient. The heat flux density is the amount of energy that flows through soil per unit area per unit time has both magnitude and direction.
where (including the SI units)
The thermal conductivity, formula_5, is often treated as a constant, though this is not always true. While the thermal conductivity of a material generally varies with temperature, the variation is generally small over a significant range of temperatures for some common materials. In anisotropic materials, the thermal conductivity typically varies with orientation; in this case formula_5 is represented by a second-order tensor. In nonuniform materials, formula_5 varies with spatial location. For soil, thermal conductivity also depends on mineral composition, water content, and bulk density. Compact and wet soils have a higher thermal conductivity than loose and dry soils. For many simple applications, Fourier's law is used in its one-dimensional, x-direction form:
Soil temperature is important for the survival and early growth of newly planted seedlings. Soil temperatures affect the anatomical and morphological character of root systems (Taylor 1983). All physical, chemical, and biological processes in soil and roots are affected not least because of the increased viscosities of water and protoplasm at low temperatures. In general, climates that do not preclude survival and growth of white spruce above ground are sufficiently benign to provide soil temperatures able to maintain white spruce root systems. In some northwestern parts of the range, white spruce occurs on permafrost sites (Gill 1975), and although young unlignified roots of conifers may have little resistance to freezing (Mityga and Lanphear 1971), less than half of the "secondary mature" root system of white spruce was killed by exposure to a temperature of 23.3 °C in multiple year experiment with containerized trees from local nurseries in Massachusetts (Havis 1976).
Optimum temperatures for tree root growth range between 10 °C and 25 °C in general (Lyr and Hoffmann 1967) and for spruce in particular (Chalupa and Fraser 1968, Heninger and White 1974, Ritchie and Dunlap 1980, Binder et al. 1988). In 2-week-old white spruce seedlings that were then grown for 6 weeks in soil at temperatures of 15 °C, 19 °C, 23 °C, 27 °C, and 31 °C; shoot height, shoot dry weight, stem diameter, root penetration, root volume, and root dry weight all reached maxima at 19 °C.
However, whereas strong positive relationships between soil temperature (5 °C to 25 °C) and growth have been found in trembling aspen and balsam poplar (Landhäusser et al. 2001, Tryon and Chapin 1983, Landhäusser et al. 2003), white and other spruce species have shown little or no changes in growth with increasing soil temperature (Turner and Jarvis 1975; Tryon and Chapin 1983; Day et al. 1990; Landhäusser et al. 2001, 2003). Such insensitivity to soil low temperature may be common among a number of western and boreal conifers (Green 2004).
Color.
Soil colour is often the first impression one has when viewing soil. Striking colours and contrasting patterns are especially noticeable. The Red River (Mississippi watershed) carries sediment eroded from extensive reddish soils like Port Silt Loam in Oklahoma. The Yellow River in China carries yellow sediment from eroding loess soils. Mollisols in the Great Plains of North America are darkened and enriched by organic matter. Podsols in boreal forests have highly contrasting layers due to acidity and leaching.
In general, color is determined by the organic matter content, drainage conditions, and degree of oxidation. Soil color, while easily discerned, has little use in predicting soil characteristics. It is of use in distinguishing boundaries within a soil profile, determining the origin of a soil's parent material, as an indication of wetness and waterlogged conditions, and as a qualitative means of measuring organic, salt and carbonate contents of soils. Color is recorded in the Munsell color system as for instance 10YR3/4 "Dusky Red".
Soil color is primarily influenced by soil mineralogy. Many soil colours are due to various iron minerals. The development and distribution of colour in a soil profile result from chemical and biological weathering, especially redox reactions. As the primary minerals in soil parent material weather, the elements combine into new and colourful compounds. Iron forms secondary minerals of a yellow or red colour, organic matter decomposes into black and brown compounds, and manganese, sulfur and nitrogen can form black mineral deposits. These pigments can produce various colour patterns within a soil. Aerobic conditions produce uniform or gradual colour changes, while reducing environments (anaerobic) result in rapid colour flow with complex, mottled patterns and points of colour concentration.
Resistivity.
Soil resistivity is a measure of a soil's ability to retard the conduction of an electric current. The electrical resistivity of soil can affect the rate of galvanic corrosion of metallic structures in contact with the soil. Higher moisture content or increased electrolyte concentration can lower resistivity and increase conductivity, thereby increasing the rate of corrosion. Soil resistivity values typically range from about 2 to 1000 Ω·m, but more extreme values are not unusual.
Soil water.
Water affects soil formation, structure, stability and erosion but is of primary concern with respect to plant growth. Water is essential to plants for four reasons:
In addition, water alters the soil profile by dissolving and re-depositing minerals, often at lower levels, and possibly leaving the soil sterile in the case of extreme rainfall and drainage. In a loam soil, solids constitute half the volume, gas one-quarter of the volume, and water one-quarter of the volume of which only half will be available to most plants.
A flooded field will drain the gravitational water under the influence of gravity until water's adhesive and cohesive forces resist further drainage at which point it is said to have reached field capacity. At that point, plants must apply suction to draw water from a soil. When soil becomes too dry, the available water is used up and the remaining moisture is unavailable water as the plant cannot produce sufficient suction to draw in the water. A plant must produce suction that increases from zero for a flooded field to 1/3 bar at field dry condition (one bar is a little less than one atmosphere pressure). At 15 bar suction, wilting percent, seeds will not germinate, plants begin to wilt and then die. Water moves in soil under the influence of gravity, osmosis and capillarity. When water enters the soil, it displaces air from some of the pores, since air content of a soil is inversely related to its water content.
The rate at which a soil can absorb water depends on the soil and its other conditions. As a plant grows, its roots remove water from the largest pores first. Soon the larger pores hold only air, and the remaining water is found only in the intermediate- and smallest-sized pores. The water in the smallest pores is so strongly held to particle surfaces that plant roots cannot pull it away. Consequently, not all soil water is available to plants. When saturated, the soil may lose nutrients as the water drains. Water moves in a drained field under the influence of pressure where the soil is locally saturated and by capillarity pull to dryer parts of the soil. Most plant water needs are supplied from the suction caused by of evaporation from plant leaves and 10% is supplied by "suction" created by osmotic pressure differences between the plant interior and the soil water. Plant roots must seek out water. Insufficient water will damage the yield of a crop. Most of the available water is used in transpiration to pull nutrients into the plant.
Water retention forces.
Water is retained in a soil when the adhesive force of attraction of water's hydrogen atoms for the oxygen of soil particles and the cohesive forces water's hydrogen feels for other water's oxygen atoms are stronger than the forces that might pull the water from the soil. When a field is flooded, the air in the soil pore space is completely displaced by water. The field will drain under the force of gravity until it reaches what is called field capacity, at which point the smallest pores are filled with water and the largest with water and gases. The total amount of water held when field capacity is reached is a function of the specific surface area of the soil particles. As a result, high clay and high organic soils have higher field capacities. The total force required to pull or push water out of soil is termed suction and usually expressed in units of bars (105 pascal) which is just a little less than one-atmosphere pressure. Alternatively, the terms "tension" or "moisture potential" may be used.
Moisture classification.
The forces with which water is held in soils determine its availability to plants. Forces of adhesion hold water strongly to mineral and humus surfaces and less strongly to itself by cohesive forces. A plant's root may penetrate a very small volume of water that is adhering to soil and be initially able to draw in water that is only lightly held by the cohesive forces. But as the droplet is drawn down, the forces of adhesion of the water for the soil particles make reducing the volume of water increasingly difficult until the plant cannot produce sufficient suction to use the remaining water. The remaining water is considered unavailable. The amount of available water depends upon the soil texture and humus amounts and the type of plant attempting to use the water. Cacti, for example, can produce greater suction than can agricultural crop plants.
The following description applies to a loam soil and agricultural crops. When a field is flooded, it is said to be saturated and all available air space is occupied by water. The suction required to draw water into a plant root is zero. As the field drains under the influence of gravity (drained water is called gravitational water or drain-able water), the suction a plant must produce to use such water increases to 1/3 bar. At that point, the soil is said to have reached field capacity, and plants that use the water must produce increasingly higher suction, finally up to 15 bar. At 15 bar suction, the soil water amount is called wilting percent. At that suction the plant cannot sustain its water needs as water is still being lost from the plant by transpiration; the plant's turgidity is lost, and it wilts. The next level, called air-dry, occurs at 1000 bar suction. Finally the oven dry condition is reached at 10,000 bar suction. All water below wilting percentage is called unavailable water.
Soil moisture content.
When the soil moisture content is optimal for plant growth, the water in the large and intermediate size pores can move about in the soil and be easily used by plants. The amount of water remaining in a soil drained to field capacity and the amount that is available are functions of the soil type. Sandy soil will retain very little water, while clay will hold the maximum amount. The time required to drain a field from flooded condition for a clay loam that begins at 43% water by weight to a field capacity of 21.5% is six days, whereas a sand loam that is flooded to its maximum of 22% water will take two days to reach field capacity of 11.3% water. The available water for the clay loam might be 11.3% whereas for the sand loam it might be only 7.9% by weight.
The above are average values for the soil textures as the percentage of sand, silt and clay vary within the listed soil textures.
Water flow in soils.
Water moves through soil due to the force of gravity, osmosis and capillarity. At zero to one-third bar suction, water is pushed through soil from the point of its application under the force of gravity and the pressure gradient created by the pressure of the water; this is called saturated flow. At higher suction, water movement is pulled by capillarity from wetter toward dryer soil. This is caused by water's adhesion to soil solids, and is called unsaturated flow.
Water infiltration and movement in soil is controlled by six factors:
Water infiltration rates range from 0.25 cm per hour for high clay soils to 2.5 cm per hour for sand and well stabilised and aggregated soil structures. Water flows through the ground unevenly, called "gravity fingers", because of the surface tension between water particles.
Tree roots create paths for rainwater flow through soil by breaking though soil including clay layers: one study showed roots increasing infiltration of water by 153% and another study showed an increase by 27 times.
Flooding temporarily increases soil permeability in river beds, helping to recharge aquifers.
Saturated flow.
Water applied to a soil is pushed by pressure gradients from the point of its application where it is saturated locally, to less saturated areas. Once soil is completely wetted, any more water will move downward, or percolate, carrying with it clay, humus and nutrients, primarily cations, out of the range of plant roots. In order of decreasing solubility, the leached nutrients are:
In the United States percolation water due to rainfall ranges from zero inches just east of the Rocky Mountains to twenty or more inches in the Appalachian Mountains and the north coast of the Gulf of Mexico.
Unsaturated flow.
At suctions less than one-third bar, water moves in all directions via unsaturated flow at a rate that is dependent on the square of the diameter of the water-filled pores. Water is pulled by capillary action due to the adhesion force of water to the soil solids, producing a suction gradient from wet towards drier soil. Doubling the diameter of the pores increases the flow rate by a factor of four. Large pores drained by gravity and not filled with water do not greatly increase the flow rate for unsaturated flow. Water flow is primarily from coarse-textured soil into fine-textured soil and is slowest in fine-textured soils such as clay.
Water uptake by plants.
Of equal importance to the storage and movement of water in soil is the means by which plants acquire it and their nutrients. Ninety percent of water is taken up by plants as passive absorption caused by the pulling force of water evaporating (transpiring) from the long column of water that leads from the plant's roots to its leaves. In addition, the high concentration of salts within plant roots creates an osmotic pressure gradient that pushes soil water into the roots. Osmotic absorption becomes more important during times of low water transpiration caused by lower temperatures (for example at night) or high humidity. It is the process that causes guttation.
Root extension is vital for plant survival. A study of a single winter rye plant grown for four months in one cubic foot of loam soil showed that the plant developed 13,800,000 roots a total of 385 miles in length and 2,550 square feet in surface area and 14 billion hair roots of 6,600 miles total length and 4,320 square feet total area, for a total surface area of 6,870 square feet (83 ft squared). The total surface area of the loam soil was estimated to be 560,000 square feet. In other words the roots were in contact with only 1.2% of the soil. Roots must seek out water as the unsaturated flow of water in soil can move only at a rate of up to 2.5 cm (one inch) per day; as a result they are constantly dying and growing as they seek out high concentrations of soil moisture.
Insufficient soil moisture, to the point of causing wilting, will cause permanent damage and crop yields will suffer. When grain sorghum was exposed to soil suction as low as 13.0 bar during the seed head emergence through bloom and seed set stages of growth, its production was reduced by 34%.
Consumptive use and water efficiency.
Only a small fraction (0.1% to 1%) of the water used by a plant is held within the plant. The majority is ultimately lost via transpiration, while evaporation from the soil surface is also substantial. Transpiration plus evaporative soil moisture loss is called evapotranspiration. Evapotranspiration plus water held in the plant totals to consumptive use, which is nearly identical to evapotranspiration.
The total water used in an agricultural field includes runoff, drainage and consumptive use. The use of loose mulches will reduce evaporative losses for a period after a field is irrigated, but in the end the total evaporative loss will approach that of an uncovered soil. The benefit from mulch is to keep the moisture available during the seedling stage. Water use efficiency is measured by transpiration ratio, which is the ratio of the total water transpired by a plant to the dry weight of the harvested plant. Transpiration ratios for crops range from 300 to 700. For example alfalfa may have a transpiration ratio of 500 and as a result 500 kilograms of water will produce one kilogram of dry alfalfa. 
Soil atmosphere.
The atmosphere of soil is radically different from the atmosphere above. The consumption of oxygen, by microbes and plant roots and their release of carbon dioxide, decrease oxygen and increase carbon dioxide concentration. Atmospheric CO2 concentration is 0.04%, but in the soil pore space it may range from 10 to 100 times that level. At extreme levels CO2 is toxic. In addition, the soil voids are saturated with water vapour. Adequate porosity is necessary, not just to allow the penetration of water, but also to allow gases to diffuse in and out. Movement of gases is by diffusion from high concentrations to lower. Oxygen diffuses in and is consumed and excess levels of carbon dioxide, diffuse out with other gases as well as water. Soil texture and structure strongly affect soil porosity and gas diffusion. It is the total pore space (porosity) of soil not the pore size that determines the rate of diffusion of gases into and out of soil. A Platy soil structure and compacted soils (low porosity) impede gas flow, and a deficiency of oxygen may encourage anaerobic bacteria to reduce nitrate NO3 to the gases N2, N2O, and NO, which are then lost to the atmosphere. Aerated soil is also a net sink of methane CH4 but a net producer of greenhouse gases when soils are depleted of oxygen and subject to elevated temperatures.
Composition of soil particles.
Soil particles can be classified by their chemical composition (mineralogy) as well as their size. The particle size distribution of a soil, its texture, determines many of the properties of that soil, but the mineralogy of those particles can strongly modify those properties. The mineralogy of the finest soil particles, clay, is especially important.
Gravel, sand and silt.
Gravel, sand and silt are the larger soil particles, and their mineralogy is often inherited from the parent material of the soil, but may include products of weathering (such as concretions of calcium carbonate or iron oxide), or residues of plant and animal life (such as silica phytoliths). Quartz is the most common mineral in the sand or silt fraction as it is resistant to chemical weathering; other common minerals are felspars, micas and ferromagnesian minerals such as pyroxenes, amphiboles and olivines.
Mineral colloids; soil clays.
Due to its high specific surface area and its unbalanced negative charges, clay is the most active mineral component of soil. It is a colloidal and most often a crystalline material. In soils, clay is defined in a physical sense as any mineral particle less than 2 µm in effective diameter. Chemically, clay is a range of minerals with certain reactive properties. Clay is also a soil textural class. Many soil minerals, such as gypsum, carbonates, or quartz, are small enough to be classified physically as clay but chemically they do not afford the same utility as do clay minerals.
Clay was once thought to be very small particles of quartz, feldspar, mica, hornblende or augite, but it is now known to be (with the exception of mica-based clays) a precipitate with a mineralogical composition that is dependent on but different from its parent materials and is classed as a secondary mineral. The type of clay that is formed is a function of the parent material and the composition of the minerals in solution. Clay minerals continue to be formed as long as the soil exists. Mica-based clays result from a modification of the primary mica mineral in such a way that it behaves and is classed as a clay. Most clays are crystalline, but some are amorphous. The clays of a soil are a mixture of the various types of clay, but one type predominates.
Most clays are crystalline and most are made up of three or four planes of oxygen held together by planes of aluminium and silicon by way of ionic bonds that together form a single layer of clay. The spatial arrangement of the oxygen atoms determines clay's structure. Half of the weight of clay is oxygen, but on a volume basis oxygen is ninety percent. The layers of clay are sometimes held together through hydrogen bonds or potassium bridges and as a result will swell less in the presence of water. Other clays, such as montmorillonite, have layers that are loosely attached and will swell greatly when water intervenes between the layers.
There are three groups of clays:
Alumino-silica clays.
Alumino-silica clays are characterised by their regular crystalline structure. Oxygen in ionic bonds with silicon forms a tetrahedral coordination (silicon at the center) which in turn forms sheets of silica. Two sheets of silica are bonded together by a plane of aluminium which forms an octahedral coordination, called alumina, with the oxygens of the silica sheet above and that below it. Hydroxyl ions (OH−) sometimes substitute for oxygen. During the clay formation process, Al3+ may substitute for Si4+, and as much as one fourth of the aluminium Al3+ may be substituted by Zn2+, Mg2+ or Fe2+. The substitution of lower-valence cations for higher-valence cations (isomorphic substitution) gives clay a net negative charge that attracts and holds soil cations, some of which are of value for plant growth. Isomorphic substitution occurs during the clay's formation and does not change with time.
Amorphous clays.
Amorphous clays are young, and commonly found in volcanic ash. They are mixtures of alumina and silica which have not formed the ordered crystal shape of alumino-silica clays which time would provide. The majority of their negative charges originates from hydroxyl ions, which can gain or lose a hydrogen ion (H+) in response to soil pH, in such way was as to buffer the soil pH. They may have either a negative charge provided by the attached hydroxyl ion (OH−), which can attract a cation, or lose the hydrogen of the hydroxyl to solution and display a positive charge which can attract anions. As a result they may display either high CEC, in an acid soil solution, or high anion exchange capacity, in a basic soil solution.
Sesquioxide clays.
Sesquioxide clays are a product of heavy rainfall that has leached most of the silica and alumina from alumino-silica clay, leaving the less soluble oxides of iron Fe2O3 and iron hydroxide (Fe(OH)3) and aluminium hydroxides (Al(OH)3). It takes hundreds of thousands of years of leaching to create sesquioxide clays. "Sesqui" is Latin for "one and one-half": there are three parts oxygen to two parts iron or aluminium; hence the ratio is one and one-half. They are hydrated and act as either amorphous or crystalline. They are not sticky and do not swell, and soils high in them behave much like sand and can rapidly pass water. They are able to hold large quantities of phosphates. Sesquioxides have low CEC. Such soils range from yellow to red in colour. Such clays tend to hold phosphorus tightly rendering them unavailable for absorption by plants.
Organic colloids.
Humus is the penultimate state of decomposition of organic matter; while it may linger for a thousand years, on the larger scale of the age of the mineral soil components, it is temporary. It is composed of the very stable lignins (30%) and complex sugars (polyuronides, 30%), proteins (30%), waxes, and fats that are resistant to breakdown by microbes. Its chemical assay is 60% carbon, 5% nitrogen, some oxygen and the remainder hydrogen, sulfur, and phosphorus. On a dry weight basis, the CEC of humus is many times greater than that of clay.
Carbon and terra preta.
In the extreme environment of high temperatures and the leaching caused by the heavy rain of tropical rain forests, the clay and organic colloids are largely destroyed. The heavy rains wash the alumino-silicate clays from the soil leaving only sesquioxide clays of low CEC. The high temperatures and humidity allow bacteria and fungi to virtually dissolve any organic matter on the rain-forest floor overnight and much of the nutrients are volatilized or leached from the soil and lost. However, carbon in the form of charcoal is far more stable than soil colloids and is capable of performing many of the functions of the soil colloids of sub-tropical soils. Soil containing substantial quantities of charcoal, of an anthropogenic origin, is called terra preta. Research into terra preta is still young but is promising. Fallow periods "on the Amazonian Dark Earths can be as short as 6 months, whereas fallow periods on oxisols are usually 8 to 10 years long"
Soil chemistry.
The chemistry of a soil determines its ability to supply available plant nutrients and affects its physical properties and the health of its microbial population. In addition, a soil's chemistry also determines its corrosivity, stability, and ability to absorb pollutants and to filter water. It is the surface chemistry of mineral and organic colloids that determines soil's chemical properties. "A colloid is a small, insoluble, nondiffusible particle larger than a molecule but small enough to remain suspended in a fluid medium without settling. Most soils contain organic colloidal particles called humus as well as the inorganic colloidal particles of clays." The very high specific surface area of colloids and their net charges, gives soil its great ability to hold and release ions. Negatively charged sites on colloids attract and release cations in what is referred to as cation exchange. Cation-exchange capacity (CEC) is the amount of exchangeable cations per unit weight of dry soil and is expressed in terms of milliequivalents of positively charged ions per 100 grams of soil (or centimoles of positive charge per kilogram of soil; cmolc/kg). Similarly, positively charged sites on colloids can attract and release anions in the soil giving the soil anion exchange capacity (AEC).
Cation and anion exchange.
The cation exchange, that takes place between colloids and soil water, buffers (moderates) soil pH, alters soil structure, and purifies percolating water by adsorbing cations of all types, both useful and harmful.
The negative or positive charges on colloid particles make them able to hold cations or anions, respectively, to their surfaces. The charges result from four sources.
Cations held to the negatively charged colloids resist being washed downward by water and out of reach of plants' roots, thereby preserving the fertility of soils in areas of moderate rainfall and low temperatures.
There is a hierarchy in the process of cation exchange on colloids, as they differ in the strength of adsorption by the colloid and hence their ability to replace one another. If present in equal amounts in the soil water solution:
Al3+ replaces H+ replaces Ca2+ replaces Mg2+ replaces K+ same as NH4+ replaces Na+
If one cation is added in large amounts, it may replace the others by the sheer force of its numbers. This is called mass action. This is largely what occurs with the addition of fertiliser.
As the soil solution becomes more acidic (an abundance of H+), the other cations more weakly bound to colloids are pushed into solution and hydrogen ions occupy those sites. A low pH may cause hydrogen of hydroxyl groups to be pulled into solution, leaving charged sites on the colloid available to be occupied by other cations. This ionisation of hydroxyl groups on the surface of soil colloids creates what is described as pH-dependent charges. Unlike permanent charges developed by isomorphous substitution, pH-dependent charges are variable and increase with increasing pH. Freed cations can be made available to plants but are also prone to be leached from the soil, possibly making the soil less fertile. Plants are able to excrete H+ into the soil and by that means, change the pH of the soil near the root and push cations off the colloids, thus making those available to the plant.
Cation exchange capacity (CEC).
Cation exchange capacity should be thought of as the soil's ability to remove cations from the soil water solution and sequester those to be exchanged later as the plant roots release hydrogen ions to the solution. CEC is the amount of exchangeable hydrogen cation (H+) that will combine with 100 grams dry weight of soil and whose measure is one milliequivalents per 100 grams of soil (1 meq/100 g). Hydrogen ions have a single charge and one-thousandth of a gram of hydrogen ions per 100 grams dry soil gives a measure of one milliequivalent of hydrogen ion. Calcium, with an atomic weight 40 times that of hydrogen and with a valence of two, converts to (40/2) x 1 milliequivalent = 20 milliequivalents of hydrogen ion per 100 grams of dry soil or 20 meq/100 g. The modern measure of CEC is expressed as centimoles of positive charge per kilogram (cmol/kg) of oven-dry soil.
Most of the soil's CEC occurs on clay and humus colloids, and the lack of those in hot, humid, wet climates, due to leaching and decomposition respectively, explains the relative sterility of tropical soils. Live plant roots also have some CEC.
Anion exchange capacity (AEC).
Anion exchange capacity should be thought of as the soil's ability to remove anions from the soil water solution and sequester those for later exchange as the plant roots release carbonate anions to the soil water solution. Those colloids which have low CEC tend to have some AEC. Amorphous and sesquioxide clays have the highest AEC, followed by the iron oxides. Levels of AEC are much lower than for CEC. Phosphates tend to be held at anion exchange sites.
Iron and aluminum hydroxide clays are able to exchange their hydroxide anions (OH−) for other anions. The order reflecting the strength of anion adhesion is as follows:
The amount of exchangeable anions is of a magnitude of tenths to a few milliequivalents per 100 g dry soil. As pH rises, there are relatively more hydroxyls, which will displace anions from the colloids and force them into solution and out of storage; hence AEC decreases with increasing pH (alkalinity).
Soil reaction (pH).
Soil reactivity is expressed in terms of pH and is a measure of the acidity or alkalinity of the soil. More precisely, it is a measure of hydrogen ion concentration in an aqueous solution and ranges in values from 0 to 14 (acidic to basic) but practically speaking for soils, pH ranges from 3.5 to 9.5, as pH values beyond those extremes are toxic to life forms.
Soil pH.
At 25 °C an aqueous solution that has a pH of 3.5 has 10−3.5 moles H+ (hydrogen ions) per litre of solution (and also 10−10.5 mole/litre OH−). A pH of 7, defined as neutral, has 10−7 moles hydrogen ions per litre of solution and also 10−7 moles of OH− per litre; since the two concentrations are equal, they are said to neutralise each other. A pH of 9.5 has 10−9.5 moles hydrogen ions per litre of solution (and also 10−2.5 mole per litre OH−). A pH of 3.5 has one million times more hydrogen ions per litre than a solution with pH of 9.5 (9.5 - 3.5 = 6 or 106) and is more acidic.
The effect of pH on a soil is to remove from the soil or to make available certain ions. Soils with high acidity tend to have toxic amounts of aluminium and manganese. Plants which need calcium need moderate alkalinity, but most minerals are more soluble in acid soils. Soil organisms are hindered by high acidity, and most agricultural crops do best with mineral soils of pH 6.5 and organic soils of pH 5.5.
In high rainfall areas, soils tend to acidity as the basic cations are forced off the soil colloids by the mass action of hydrogen ions from the rain as those attach to the colloids. High rainfall rates can then wash the nutrients out, leaving the soil sterile. Once the colloids are saturated with H+, the addition of any more hydrogen ions or aluminum hydroxyl cations drives the pH even lower (more acidic) as the soil has been left with no buffering capacity. In areas of extreme rainfall and high temperatures, the clay and humus may be washed out, further reducing the buffering capacity of the soil. In low rainfall areas, unleached calcium pushes pH to 8.5 and with the addition of exchangeable sodium, soils may reach pH 10. Beyond a pH of 9, plant growth is reduced. High pH results in low micro-nutrient mobility, but water-soluble chelates of those nutrients can supply the deficit. Sodium can be reduced by the addition of gypsum (calcium sulphate) as calcium adheres to clay more tightly than does sodium causing sodium to be pushed into the soil water solution where it can be washed out by an abundance of water.
Base saturation percentage.
There are acid-forming cations (hydrogen and aluminium) and there are base-forming cations. The fraction of the base-forming cations that occupy positions on the soil colloids is called the base saturation percentage. If a soil has a CEC of 20 meq and 5 meq are aluminium and hydrogen cations (acid-forming), the remainder of positions on the colloids (20-5 = 15 meq) are assumed occupied by base-forming cations, so that the percentage base saturation is 15/20 x 100% = 75% (the compliment 25% is assumed acid-forming cations). When the soil pH is 7 (neutral), base saturation is 100 percent and there are no hydrogen ions stored on the colloids. Base saturation is almost in direct proportion to pH (increases with increasing pH). It is of use in calculating the amount of lime needed to neutralise an acid soil. The amount of lime needed to neutralize a soil must take account of the amount of acid forming ions on the colloids not just those in the soil water solution. The addition of enough lime to neutralize the soil water solution will be insufficient to change the pH, as the acid forming cations stored on the soil colloids will tend to restore the original pH condition as they are pushed off those colloids by the calcium of the added lime.
Buffering of soils.
The resistance of soil to changes in pH as a result of the addition of acid or basic material is a measure of the buffering capacity of a soil and increases as the CEC increases. Hence, pure sand has almost no buffering ability, while soils high in colloids have high buffering capacity. Buffering occurs by cation exchange and neutralisation.
The addition of a small amount highly basic aqueous ammonia to a soil will cause the ammonium to displace hydrogen ions from the colloids, and the end product is water and colloidally fixed ammonium, but no permanent change overall in soil pH.
The addition of a small amount of lime, CaCO3, will displace hydrogen ions from the soil colloids, causing the fixation of calcium to colloids and the evolution of CO2 and water, with no permanent change in soil pH.
The addition of carbonic acid (the solution of CO2 in water) will displace calcium from colloids, as hydrogen ions are fixed to the colloids, evolving water and slightly alkaline (temporary increase in pH) highly soluble calcium bicarbonate, which will then precipitate as lime (CaCO3) and water at a lower level in the soil profile, with the result of no permanent change in soil pH.
All of the above are examples of the buffering of soil pH. The general principal is that an increase in a particular cation in the soil water solution will cause that cation to be fixed to colloids (buffered) and a decrease in solution of that cation will cause it to be withdrawn from the colloid and moved into solution (buffered). The degree of buffering is limited by the CEC of the soil; the greater the CEC, the greater the buffering capacity of the soil.
Nutrients.
Sixteen nutrients are essential for plant growth and reproduction. They are carbon, hydrogen, oxygen, nitrogen, phosphorus, potassium, sulfur, calcium, magnesium, iron, boron, manganese, copper, zinc, molybdenum, and chlorine. Nutrients required for plants to complete their life cycle are considered essential nutrients. Nutrients that enhance the growth of plants but are not necessary to complete the plant's life cycle are considered non-essential. With the exception of carbon, hydrogen and oxygen, which are supplied by carbon dioxide and water, the nutrients derive originally from the mineral component of the soil. Although minerals are the origin of those nutrients, the organic component of the soil is the reservoir of the majority of readily available plant nutrients. For the nutrients to be available to plants, they must be in the proper ionic form (with the exception of water and CO2). For example, the application of finely ground minerals, feldspar and apatite, to soil does not provide the necessary amounts of potassium and phosphorus for good plant growth. Nitrogen is the primary limiting nutrient and phosphorus is second to nitrogen as the primary nutrient for plants, animals and microorganisms.
The provision of plant nutrition involves chemical, biological, and physical processes. Nearly all plant nutrients are taken up from the soil water solution in the form of ions, either cations or as anions. In an effort to gain nutrients, plants will release ions to the soil. Bicarbonate (HCO3−) and hydroxyl (OH−) anions released from plant roots enhance the absorption of nutrient anions; similarly, hydrogen cations are released in exchange for cation forms of nutrients. As a result, nutrient ions are pushed into the soil water solution from their sequestration on colloids to become available to plants. Nitrogen, for example, is available in soil organic material but is unusable by plants until it is made available by that material's decomposition by micro-organisms into cation or anion forms. The NH4+ (ammonium) and NO3− (nitrate) forms of nitrogen are stored on the soil colloids until forced off those by the presence of other cations and anions. After that, they will move by physical means to near the plant roots. Generally, plant roots can readily absorb all of the nutrients from the soil solution, provided there is enough oxygen gas in the soil to support root metabolism.
The bulk of most nutrient elements in the soil is held in the form of primary and secondary minerals, and organic matter. The primary minerals (mostly rock dust in the form of silt) hold the nutrients too tightly to be readily available; the nutrients adsorbed onto the colloids clay and humus are moderately available; and the soil solution fraction has ions that are freely available for absorption by plant roots. Gram for gram, the capacity of humus to hold nutrients and water is far greater than that of clay. All in all, small amounts of humus may remarkably increase the soil's capacity to promote plant growth.
Mechanism of nutrient uptake.
All the nutrients with the exception of carbon are taken up by the plant through its roots. To be taken up by a plant, a nutrient element must be in an ionic form (with the exception of water and H3BO3) and must be located at the root surface. Often, parts of a root are in such intimate contact with soil particles that a direct exchange may take place between nutrient ions adsorbed on the surface of the soil colloids and hydrogen ions from the surface of root cell walls. In any case, the supply of nutrients in contact with the root would soon be depleted. There are three basic mechanisms by which the concentration of nutrient ions dissolved in the soil solution are brought into contact with plant roots:
All three mechanisms operate simultaneously, but one mechanism or another may be most important for a particular nutrient. For example, in the case of calcium, which is generally plentiful in the soil solution, mass flow alone can usually bring sufficient amounts to the root surface. However, in the case of phosphorus, diffusion is needed to supplement mass flow because the soil solution is very low in this element in comparison to the amounts needed by plants. For the most part, nutrient ions must travel some distance in the soil solution to reach the root surface. This movement can take place by mass flow, as when dissolved nutrients are carried along with the soil water flowing toward a root that is actively drawing water from the soil. In this type of movement, the nutrient ions are somewhat analogous to leaves floating down a stream. In addition, nutrient ions continually move by diffusion from areas of greater concentration toward the nutrient-depleted areas of lower concentration around the root surface. By this means, plants can continue to take up nutrients even at night, when water is only slowly absorbed into the roots. Finally, root interception comes into play as roots continually grow into new, undepleted soil.
Because nutrient uptake is an active metabolic process, conditions that inhibit root metabolism may also inhibit nutrient uptake. Examples of such conditions include excessive soil water content or soil compaction resulting in poor soil aeration, excessively high or low soil temperatures, and above-ground conditions that result in low translocation of sugars to plant roots. A maize plant will use one quart of water per day at the height of its growing season.
In the above table, phosphorus and potassium nutrients move more by diffusion than they do by mass flow in water solution, as they are rapidly taken up by the roots creating a concentration of almost zero near the roots. The very steep concentration gradient is of greater influence in the movement of those ions than is the movement of those by mass flow. The movement by mass flow requires the transpiration of water from the plant causing water and solution ions to also move toward the roots. Movement by root interception is slowest as the plants must extend their roots. Plants move ions out of their roots in an effort to move nutrients in from the soil. Hydrogen H+ is exchanged for cations, and carbonate (HCO3−) and hydroxide (OH−) anions are exchanged for nutrient anions. Plants derive most of their anion nutrients from decomposing organic matter, which holds 95 percent of the nitrogen, 5 to 60 percent of the phosphorus and 80 percent of the sulfur. As plant roots remove nutrients from the soil water solution, nutrients are added to the soil water as other ions move off of clay and humus, are added from the decomposition of soil minerals, and are released by the decomposition of organic matter. Where crops are produced, the replenishment of nutrients in the soil must be augmented by the addition of fertiliser or organic matter.
Carbon.
Plants obtain their carbon from atmospheric carbon dioxide. A plant's weight is forty-five percent carbon. Elementally, carbon is 50% of plant material. Plant residues have a carbon to nitrogen ratio (C/N) of 50:1. As the soil organic material is digested by arthropods and micro-organisms, the C/N decreases as the carbonaceous material is metabolised and carbon dioxide (CO2) is released as a byproduct which then finds its way out of the soil and into the atmosphere. The nitrogen, and other nutrients however, is sequestered in the bodies of the living matter of those organisms and so it builds up in the soil. Normal CO2 concentration in the atmosphere is 0.03%, which is probably the factor limiting plant growth. In a field of maize on a still day during high light conditions in the growing season, the CO2 concentration drops very low, but under such conditions the crop could use up to 20 times the normal concentration. The respiration of CO2 by soil micro-organisms decomposing soil organic matter contributes an important amount of CO2 to the photosynthesising plants. Within the soil, CO2 concentration is 10 to 100 times that of atmospheric levels but may rise to toxic levels if the soil porosity is low or if diffusion is impeded by flooding.
Nitrogen.
Nitrogen is the most critical element obtained by plants from the soil and is a bottleneck in plant growth. Plants can use the nitrogen as either the ammonium cation (NH4+) or the anion nitrate (NO3−). Nitrogen is seldom missing in the soil, but is often in the form of raw organic material which cannot be used directly. The total nitrogen content depends on the climate, vegetation, topography, age and soil management. Soil nitrogen typically decreases by 0.2 to 0.3% for every temperature increase by 10 °C. Usually, more nitrogen is under grassland than under forest. Humus formation promotes nitrogen immobilization. Cultivation decreases soil nitrogen by exposing soil to more air which the bacteria can use, and no-tillage maintains more nitrogen than tillage.
Some micro-organisms are able to metabolise organic matter and release ammonium in a process called "mineralisation". Others take free ammonium and oxidise it to nitrate. Particular bacteria are capable of metabolising N2 into the form of nitrate in a process called nitrogen fixation. Both ammonium and nitrate can be "immobilized" or essentially lost from the soil by its incorporation into the microbes' living cells, where it is temporarily sequestered in the form of amino acids and protein. Nitrate may also be lost from the soil when bacteria metabolise it to the gases N2 and N2O. The loss of gaseous forms of nitrogen to the atmosphere due to microbial action is called "denitrification". Nitrogen may also be "leached" from the soil if it is in the form of nitrate or lost to the atmosphere as ammonia due to a chemical reaction of ammonium with alkaline soil by way of a process called "volatilisation". Ammonium may also be sequestered in clay by "fixation". A small amount of nitrogen is added to soil by rainfall.
Nitrogen gains.
In the process of mineralisation, microbes feed on organic matter, releasing ammonia (NH3) (which may be reduced to ammonium (NH4+) and other nutrients. As long as the carbon to nitrogen ratio (C/N) in the soil is above 30:1, nitrogen will be in short supply and other bacteria will feed on the ammonium and incorporate its nitrogen into their cells in the immobilization process. In that form the nitrogen is said to be "immobilised". Later, when such bacteria die, they too are "mineralised" and some of the nitrogen is released as ammonium and nitrate. If the C/N is less than 15, ammonia is freed to the soil, where it may be used by bacteria which oxidise it to nitrate (nitrification). Bacteria may on average add 25 lb nitrogen per acre, and in an unfertilised field, this is the most important source of usable nitrogen. In a soil with 5% organic matter perhaps 2 to 5% of that is released to the soil by such decomposition. It occurs fastest in warm, moist, well aerated soil. The mineralisation of 3% of the organic material of a soil that is 4% organic matter overall, would release 120 lb of nitrogen as ammonium per acre.
In nitrogen fixation, rhizobium bacteria convert N2 to nitrate (NO3−). Rhizobia share a symbiotic relationship with host plants, since rhizobia supply the host with nitrogen and the host provides rhizobia with nutrients and a safe environment. It is estimated that such symbiotic bacteria in the root nodules of legumes add 45 to 250 pounds of nitrogen per acre per year, which may be sufficient for the crop. Other, free-living nitrogen-fixing bacteria and blue-green algae live independently in the soil and release nitrate when their dead bodies are converted by way of mineralisation.
Some amount of usable nitrogen is fixed by lightning as nitric oxide (NO) and nitrogen dioxide (NO2−). Nitrogen dioxide is soluble in water to form nitric acid (HNO3) solution of H+ and NO3−. Ammonia, NH3, previously released from the soil or from combustion, may fall with precipitation as nitric acid at a rate of about five pounds nitrogen per acre per year.
Nitrogen sequestration.
When bacteria feed on soluble forms of nitrogen (ammonium and nitrate), they temporarily sequester that nitrogen in their bodies in a process called "immobilisation". At a later time when those bacteria die, their nitrogen may be released as ammonium by the processes of mineralisation.
Protein material is easily broken down, but the rate of its decomposition is slowed by its attachment to the crystalline structure of clay and when trapped between the clay layers. The layers are small enough that bacteria cannot enter. Some organisms can exude extracellular enzymes that can act on the sequestered proteins. However, those enzymes too may be trapped on the clay crystals.
Ammonium fixation occurs when ammonium pushes potassium ions from between the layers of clay such as illite or montmorillonite. Only a small fraction of nitrogen is held this way.
Nitrogen losses.
Usable nitrogen may be lost from soils when it is in the form of nitrate, as it is easily leached. Further losses of nitrogen occur by denitrification, the process whereby soil bacteria convert nitrate (NO3−) to nitrogen gas, N2 or N2O. This occurs when poor soil aeration limits free oxygen, forcing bacteria to use the oxygen in nitrate for their respiratory process. Denitrification increases when oxidisable organic material is available and when soils are warm and slightly acidic. Denitrification may vary throughout a soil as the aeration varies from place to place. Denitrification may cause the loss of 10 to 20 percent of the available nitrates within a day and when conditions are favourable to that process, losses of up to 60 percent of nitrate applied as fertiliser may occur.
"Ammonium volatilisation" occurs when ammonium reacts chemically with an alkaline soil, converting NH4+ to NH3. The application of ammonium fertiliser to such a field can result in volatilisation losses of as much as 30 percent.
Phosphorus.
Phosphorus is the second most critical plant nutrient. The soil mineral apatite is the most common mineral source of phosphorus. While there is on average 1000 lb of phosphorus per acre in the soil, it is generally unavailable in the form of phosphates of low solubility. Total phosphorus is about 0.1 percent by weight of the soil, but only one percent of that is available. Of the part available, more than half comes from the mineralisation of organic matter. Agricultural fields may need to be fertilised to make up for the phosphorus that has been removed in the crop.
When phosphorus does form solubilised ions of H2PO4−, they rapidly form insoluble phosphates of calcium or hydrous oxides of iron and aluminum. Phosphorus is largely immobile in the soil and is not leached but actually builds up in the surface layer if not cropped. The application of soluble fertilisers to soils may result in zinc deficiencies as zinc phosphates form. Conversely, the application of zinc to soils may immobilise phosphorus again as zinc phosphate. Lack of phosphorus may interfere with the normal opening of the plant leaf stomata, resulting in plant temperatures 10 percent higher than normal. Phosphorus is most available when soil pH is 6.5 in mineral soils and 5.5 in organic soils.
Potassium.
The amount of potassium in a soil may be as much as 80,000 lb per acre-foot, of which only 150 lb is available for plant growth. Common mineral sources of potassium are the mica biotite and potassium feldspar, KAlSi3O8. When solubilised, half will be held as exchangeable cations on clay while the other half is in the soil water solution. Potassium fixation often occurs when soils dry and the potassium is bonded between layers of illite clay. Under certain conditions, dependent on the soil texture, intensity of drying, and initial amount of exchangeable potassium, the fixed percentage may be as much as 90 percent within ten minutes. Potassium may be leached from soils low in clay.
Calcium.
Calcium is one percent by weight of soils and is generally available but may be low as it is soluble and can be leached. It is thus low in sandy and heavily leached soil or strongly acidic mineral soil. Calcium is supplied to the plant in the form of exchangeable ions and moderately soluble minerals. Calcium is more available on the soil colloids than is potassium because the common mineral calcite, CaCO3, is more soluble than potassium-bearing minerals.
Magnesium.
Magnesium is central to chlorophyll and aids in the uptake of phosphorus. The minimum amount of magnesium required for plant health is not sufficient for the health of forage animals. A common mineral source of magnesium is the black mica mineral, biotite. Magnesium is generally available in soil, but is missing from some along the Gulf and Atlantic coasts of the United States due to leaching by heavy precipitation.
Sulfur.
Sulfur is essential to the formation of proteins and chlorophyll, and essential to plant vitamin synthesis. Most sulfur is made available to plants, like phosphorus, by its release from decomposing organic matter. Deficiencies may exist in some soils and if cropped, sulfur needs to be added. The application of large quantities of nitrogen to fields that have marginal amounts of sulfur may cause sulfur deficiency in the rapidly growing plants by the plant's growth outpacing the supply of sulfur. A 15-ton crop of onions uses up to 19 lb of sulfur and 4 tons of alfalfa uses 15 lb per acre. Sulfur abundance varies with depth. In a sample of soils in Ohio, United States, the sulfur abundance varied with depths, 0-6 inches, 6-12 inches, 12-18 inches, 18-24 inches in the amounts: 1056, 830, 686, 528 lb per acre respectively.
Micronutrients.
The micronutrients essential for plant life, in their order of importance, include iron, manganese, zinc, copper, boron, chlorine and molybdenum. The term refers to plants' needs, not to their abundance in soil. They are required in very small amounts but are essential to plant health in that most are required parts of some enzyme system which speeds up plants' metabolisms. They are generally available in the mineral component of the soil, but the heavy application of phosphates can cause a deficiency in zinc and iron by the formation of insoluble zinc and iron phosphates. Iron deficiency may also result from excessive amounts of heavy metals or calcium minerals (lime) in the soil. Excess amounts of soluble boron, molybdenum and chloride are toxic.
Non-essential nutrients.
Nutrients which enhance the health but whose deficiency does not stop the life cycle of plants include: cobalt, strontium, vanadium, silicon and nickel. As their importance are evaluated they may be added to the list of essential plant nutrients.
Soil organic matter.
Soil organic matter is made up of organic compounds and includes plant, animal and microbial material, both living and dead. A typical soil has a biomass composition of 70% microorganisms, 22% macrofauna, and 8% roots. The living component of an acre of soil may include 900 lb of earthworms, 2400 lb of fungi, 1500 lb of bacteria, 133 lb of protozoa and 890 lb of arthropods and algae.
A small part of the organic matter consists of the living cells such as bacteria, molds, and actinomycetes that work to break down the dead organic matter. Were it not for the action of these micro-organisms, the entire carbon dioxide part of the atmosphere would be sequestered as organic matter in the soil.
Chemically, organic matter is classed as follows:
Most living things in soils, including plants, insects, bacteria, and fungi, are dependent on organic matter for nutrients and/or energy. Soils have organic compounds in varying degrees of decomposition which rate is dependent on the temperature, soil moisture, and aeration. Bacteria and fungi feed on the raw organic matter, which are fed upon by amoebas, which in turn are fed upon by nematodes and arthropods. Organic matter holds soils open, allowing the infiltration of air and water, and may hold as much as twice its weight in water. Many soils, including desert and rocky-gravel soils, have little or no organic matter. Soils that are all organic matter, such as peat (histosols), are infertile. In its earliest stage of decomposition, the original organic material is often called raw organic matter. The final stage of decomposition is called humus.
In grassland, much of the organic matter added to the soil is from the deep, fibrous, grass root systems. By contrast, tree leaves falling on the forest floor are the principal source of soil organic matter in the forest. Another difference is the frequent occurrence in the grasslands of fires that destroy large amounts of aboveground material but stimulate even greater contributions from roots. Also, the much greater acidity under any forests inhibits the action of certain soil organisms that otherwise would mix much of the surface litter into the mineral soil. As a result, the soils under grasslands generally develop a thicker A horizon with a deeper distribution of organic matter than in comparable soils under forests, which characteristically store most of their organic matter in the forest floor (O horizon) and thin A horizon.
Humus.
Humus refers to organic matter that has been decomposed by soil flora and fauna to the point where it is resistant to further breakdown. Humus usually constitutes only five percent of the soil or less by volume, but it is an essential source of nutrients and adds important textural qualities crucial to soil health and plant growth. Humus also hold bits of undecomposed organic matter which feed arthropods and worms which further improve the soil. The end product, humus, is soluble in water and forms a weak acid that can attack silicate minerals. Humus has a high cation exchange capacity that on a dry weight basis is many times greater than that of clay colloids. It also acts as a buffer, like clay, against changes in pH and soil moisture.
Humic acids and fulvic acids, which begin as raw organic matter, are important constituents of humus. After the death of plants and animals, microbes begin to feed on the residues, resulting finally in the formation of humus. With decomposition, there is a reduction of water-soluble constituents, cellulose and hemicellulose, and nutrients such as nitrogen, phosphorus, and sulfur. As the residues break down, only stable molecules made of aromatic carbon rings, oxygen and hydrogen remain in the form of humin, lignin and lignin complexes collectively called humus. While the structure of humus has few nutrients, it is able to attract and hold cation and anion nutrients by weak bonds that can be released into the soil solution in response to changes in soil pH.
Lignin is resistant to breakdown and accumulates within the soil. It also reacts with amino acids, which further increases its resistance to decomposition, including enzymatic decomposition by microbes. Fats and waxes from plant matter have some resistance to decomposition and persist in soils for a while. Clay soils often have higher organic contents that persist longer than soils without clay as the organic molecules adhere to and are stabilised by the clay. Proteins normally decompose readily, but when bound to clay particles, they become more resistant to decomposition. Clay particles also absorb the enzymes exuded by microbes which would normally break down proteins. The addition of organic matter to clay soils can render that organic matter and any added nutrients inaccessible to plants and microbes for many years. High soil tannin (polyphenol) content can cause nitrogen to be sequestered in proteins or cause nitrogen immobilisation.
Humus formation is a process dependent on the amount of plant material added each year and the type of base soil. Both are affected by climate and the type of organisms present. Soils with humus can vary in nitrogen content but typically have 3 to 6 percent nitrogen. Raw organic matter, as a reserve of nitrogen and phosphorus, is a vital component affecting soil fertility. Humus also absorbs water, and expands and shrinks between dry and wet states, increasing soil porosity. Humus is less stable than the soil's mineral constituents, as it is reduced by microbial decomposition, and over time its concentration diminshes without the addition of new organic matter. However, humus may persist over centuries if not millennia.
Climate and organic matter.
The production, accumulation and degradation of organic matter are greatly dependent on climate. Temperature, soil moisture and topography are the major factors affecting the accumulation of organic matter in soils. Organic matter tends to accumulate under wet or cold conditions where decomposer activity is impeded by low temperature or excess moisture which results in anaerobic conditions. Conversely, excessive rain and high temperatures of tropical climates enables rapid decomposition of organic matter and leaching of plant nutrients; forest ecosystems on these soils rely on efficient recycling of nutrients and plant matter to maintain their productivity. Excessive slope may encourage the erosion of the top layer of soil which holds most of the raw organic material that would otherwise eventually become humus.
Plant residue in soil.
Typical types and percentages of plant residue components
  Cellulose (45%)  Lignin (20%)  Hemicellulose (18%)  Protein (8%)  Sugars and starches (5%)  Fats and waxes (2%)
Cellulose and hemicellulose undergo fast decomposition by fungi and bacteria, with a half-life of 12–18 days in a temperate climate. Brown rot fungi can decompose the cellulose and hemicellulose, leaving the lignin and phenolic compounds behind. Starch, which is an energy storage system for plants, undergoes fast decomposition by bacteria and fungi. Lignin consists of polymers composed of 500 to 600 units with a highly branched, amorphous structure. Lignin undergoes very slow decomposition, mainly by white rot fungi and actinomycetes; its half-life under temperate conditions is about six months.
Soil horizons.
A horizontal layer of the soil, whose physical features, composition and age are distinct from those above and beneath, are referred to as a soil horizon. The naming of a horizon is based on the type of material of which it is composed. Those materials reflect the duration of specific processes of soil formation. They are labelled using a shorthand notation of letters and numbers which describe the horizon in terms of its colour, size, texture, structure, consistency, root quantity, pH, voids, boundary characteristics and presence of nodules or concretions. Few soil profiles have all the major horizons. Some may have only one horizon.
The exposure of parent material to favourable conditions produces mineral soils that are marginally suitable for plant growth. That growth often results in the accumulation of organic residues. The accumulated organic layer called the O horizon produces a more active soil due to the effect of the organisms that live within it. Organisms colonise and break down organic materials, making available nutrients upon which other plants and animals can live. After sufficient time, humus moves downward and is deposited in a distinctive organic surface layer called the A horizon.
Classification.
Soil is classified into categories in order to understand relationships between different soils and to determine the suitability of a soil for a particular use. One of the first classification systems was developed by the Russian scientist Dokuchaev around 1880. It was modified a number of times by American and European researchers, and developed into the system commonly used until the 1960s. It was based on the idea that soils have a particular morphology based on the materials and factors that form them. In the 1960s, a different classification system began to emerge which focused on soil morphology instead of parental materials and soil-forming factors. Since then it has undergone further modifications. The World Reference Base for Soil Resources (WRB) aims to establish an international reference base for soil classification.
Soil classification systems.
Australia.
There are fourteen soil orders at the top level of the Australian Soil Classification. They are: Anthroposols, Organosols, Podosols, Vertosols, Hydrosols, Kurosols, Sodosols, Chromosols, Calcarosols, Ferrosols, Dermosols, Kandosols, Rudosols and Tenosols.
European Union.
The EU's soil taxonomy is based on a new standard soil classification in the World Reference Base for Soil Resources produced by the UN's Food and Agriculture Organization. According to this, the major soils in the European Union are:
USA.
A taxonomy is an arrangement in a systematic manner; the USDA soil taxonomy has six levels of classification. They are, from most general to specific: order, suborder, great group, subgroup, family and series. Soil properties that can be measured quantitatively are used in this classification system — they include: depth, moisture, temperature, texture, structure, cation exchange capacity, base saturation, clay mineralogy, organic matter content and salt content. There are 12 soil orders (the top hierarchical level) in the USDA soil taxonomy. The names of the orders end with the suffix "-sol". The criteria for the different soil orders include properties that reflect major differences in the genesis of soils. The orders are:
<Gallery>
File:Alfisol.jpg|Alfisol
File:Andisol.jpg|Andisol
File:Aridisol.jpg|Aridisol
File:Entisol.jpg|Entisol
File:Gelisol.jpg|Gelisol
File:Histosol.jpg|Histisol
File:Inzeptisol.jpg|Inceptisol
File:Mollisol.jpg|Mollisol
File:Oxisol.jpg|Oxisol
File:Spodosol.jpg|Spodosol
File:Ultisol.jpg|Utisol
File:Vertisol.jpg|Vertisol
</Gallery>
The percentages listed above are for land area free of ice. "Soils of Mountains", which constitute the balance (11.6%), have a mixture of those listed above, or are classified as "Rugged Mountains" which have no soil.
The above soil orders in sequence of increasing degree of development are Entisols, Inceptisols, Aridisols, Mollisols, Alfisols, Spodosols, Ultisols, and Oxisols. Histosols and Vertisols may appear in any of the above at any time during their development.
The soil suborders within an order are differentiated on the basis of soil properties and horizons which depend on soil moisture and temperature. Forty-seven suborders are recognized in the United States.
The soil great group category is a subdivision of a suborder in which the kind and sequence of soil horizons distinguish one soil from another. About 185 great groups are recognized in the United States. Horizons marked by clay, iron, humus and hard pans and soil features such as the expansion-contraction of clays (that produce self-mixing provided by clay), temperature, and marked quantities of various salts are used as distinguishing features.
The great group categories are divided into three kinds of soil subgroups: typic, intergrade and extragrade. A typic subgroup represents the basic or 'typical' concept of the great group to which the described subgroup belongs. An intergrade subgroup describes the properties that suggest how it grades towards (is similar to) soils of other soil great groups, suborders or orders. These properties are not developed or expressed well enough to cause the soil to be included within the great group towards which they grade, but suggest similarities. Extragrade features are aberrant properties which prevent that soil from being included in another soil classification. About 1,000 soil subgroups are defined in the United States.
A soil family category is a group of soils within a subgroup and describes the physical and chemical properties which affect the response of soil to agricultural management and engineering applications. The principal characteristics used to differentiate soil families include texture, mineralogy, pH, permeability, structure, consistency, the locale's precipitation pattern, and soil temperature. For some soils the criteria also specify the percentage of silt, sand and coarse fragments such as gravel, cobbles and rocks. About 4,500 soil families are recognised in the United States.
A family may contain several soil series which describe the physical location using the name of a prominent physical feature such as a river or town near where the soil sample was taken. An example would be Merrimac for the Merrimack River in New Hampshire, USA. More than 14,000 soil series are recognised in the United States. This permits very specific descriptions of soils.
A soil phase of series, originally called 'soil type' describes the soil surface texture, slope, stoniness, saltiness, erosion, and other conditions.
Uses.
Soil is used in agriculture, where it serves as the anchor and primary nutrient base for plants; however, as demonstrated by hydroponics, it is not essential to plant growth if the soil-contained nutrients can be dissolved in a solution. The types of soil and available moisture determine the species of plants that can be cultivated.
Soil material is also a critical component in the mining, construction and landscape development industries. Soil serves as a foundation for most construction projects. The movement of massive volumes of soil can be involved in surface mining, road building and dam construction. Earth sheltering is the architectural practice of using soil for external thermal mass against building walls. Many building materials are soil based.
Soil resources are critical to the environment, as well as to food and fibre production. Soil provides minerals and water to plants. Soil absorbs rainwater and releases it later, thus preventing floods and drought. Soil cleans water as it percolates through it. Soil is the habitat for many organisms: the major part of known and unknown biodiversity is in the soil, in the form of invertebrates (earthworms, woodlice, millipedes, centipedes, snails, slugs, mites, springtails, enchytraeids, nematodes, protists), bacteria, archaea, fungi and algae; and most organisms living above ground have part of them (plants) or spend part of their life cycle (insects) below-ground. Above-ground and below-ground biodiversities are tightly interconnected, making soil protection of paramount importance for any restoration or conservation plan.
The biological component of soil is an extremely important carbon sink since about 57% of the biotic content is carbon. Even on desert crusts, cyanobacteria, lichens and mosses capture and sequester a significant amount of carbon by photosynthesis. Poor farming and grazing methods have degraded soils and released much of this sequestered carbon to the atmosphere. Restoring the world's soils could offset some of the huge increase in greenhouse gases causing global warming, while improving crop yields and reducing water needs.
Waste management often has a soil component. Septic drain fields treat septic tank effluent using aerobic soil processes. Landfills use soil for daily cover. Land application of waste water relies on soil biology to aerobically treat BOD.
Organic soils, especially peat, serve as a significant fuel resource; but wide areas of peat production, such as sphagnum bogs, are now protected because of patrimonial interest.
Geophagy is the practice of eating soil-like substances. Both animals and human cultures occasionally consume soil for medicinal, recreational, or religious purposes. It has been shown that some monkeys consume soil, together with their preferred food (tree foliage and fruits), in order to alleviate tannin toxicity.
Soils filter and purify water and affect its chemistry. Rain water and pooled water from ponds, lakes and rivers percolate through the soil horizons and the upper rock strata, thus becoming groundwater. Pests (viruses) and pollutants, such as persistent organic pollutants (chlorinated pesticides, polychlorinated biphenyls), oils (hydrocarbons), heavy metals (lead, zinc, cadmium), and excess nutrients (nitrates, sulfates, phosphates) are filtered out by the soil. Soil organisms metabolise them or immobilise them in their biomass and necromass, thereby incorporating them into stable humus. The physical integrity of soil is also a prerequisite for avoiding landslides in rugged landscapes.
Degradation.
Land degradation refers to a human-induced or natural process which impairs the capacity of land to function. Soils are the critical component in land degradation when it involves acidification, contamination, desertification, erosion or salination.
While soil acidification is beneficial in the case of alkaline soils, it degrades land when it lowers crop productivity and increases soil vulnerability to contamination and erosion. Soils are often initially acid because their parent materials were acid and initially low in the basic cations (calcium, magnesium, potassium and sodium). Acidification occurs when these elements are leached from the soil profile by rainfall or the by harvesting of forest or agricultural crops. Soil acidification is accelerated by the use of acid-forming nitrogenous fertilizers and by the effects of acid precipitation.
Soil contamination at low levels is often within soil's capacity to treat and assimilate waste material. Soil biota can treat waste by transforming it; soil colloids can adsorb waste material. Many waste treatment processes rely on this treatment capacity. Exceeding treatment capacity can damage soil biota and limit soil function. Derelict soils occur where industrial contamination or other development activity damages the soil to such a degree that the land cannot be used safely or productively. Remediation of derelict soil uses principles of geology, physics, chemistry and biology to degrade, attenuate, isolate or remove soil contaminants to restore soil functions and values. Techniques include leaching, air sparging, chemical amendments, phytoremediation, bioremediation and natural degradation.
Desertification is an environmental process of ecosystem degradation in arid and semi-arid regions, often caused by human activity. It is a common misconception that droughts cause desertification. Droughts are common in arid and semiarid lands. Well-managed lands can recover from drought when the rains return. Soil management tools include maintaining soil nutrient and organic matter levels, reduced tillage and increased cover. These practices help to control erosion and maintain productivity during periods when moisture is available. Continued land abuse during droughts, however, increases land degradation. Increased population and livestock pressure on marginal lands accelerates desertification.
Erosion of soil is caused by water, wind, ice, and movement in response to gravity. More than one kind of erosion can occur simultaneously. Erosion is distinguished from weathering, since erosion also transports eroded soil away from its place of origin (soil in transit may be described as sediment). Erosion is an intrinsic natural process, but in many places it is greatly increased by human activity, especially poor land use practices. These include agricultural activities which leave the soil bare during times of heavy rain or strong winds, overgrazing, deforestation, and improper construction activity. Improved management can limit erosion. Soil conservation techniques which are employed include changes of land use (such as replacing erosion-prone crops with grass or other soil-binding plants), changes to the timing or type of agricultural operations, terrace building, use of erosion-suppressing cover materials (including cover crops and other plants), limiting disturbance during construction, and avoiding construction during erosion-prone periods.
A serious and long-running water erosion problem occurs in China, on the middle reaches of the Yellow River and the upper reaches of the Yangtze River. From the Yellow River, over 1.6 billion tons of sediment flow each year into the ocean. The sediment originates primarily from water erosion (gully erosion) in the Loess Plateau region of northwest China.
Soil piping is a particular form of soil erosion that occurs below the soil surface. It causes levee and dam failure, as well as sink hole formation. Turbulent flow removes soil starting at the mouth of the seep flow and the subsoil erosion advances up-gradient. The term sand boil is used to describe the appearance of the discharging end of an active soil pipe.
Soil salination is the accumulation of free salts to such an extent that it leads to degradation of the agricultural value of soils and vegetation. Consequences include corrosion damage, reduced plant growth, erosion due to loss of plant cover and soil structure, and water quality problems due to sedimentation. Salination occurs due to a combination of natural and human-caused processes. Arid conditions favour salt accumulation. This is especially apparent when soil parent material is saline. Irrigation of arid lands is especially problematic. All irrigation water has some level of salinity. Irrigation, especially when it involves leakage from canals and overirrigation in the field, often raises the underlying water table. Rapid salination occurs when the land surface is within the capillary fringe of saline groundwater. Soil salinity control involves watertable control and flushing with higher levels of applied water in combination with tile drainage or another form of subsurface drainage.
<Gallery>
File:Soil erosion, Southfield - geograph.org.uk - 367917.jpg|Desertification
File:Riparian buffer on Bear Creek in Story County, Iowa.JPG|Erosion control
</Gallery>
Reclamation.
Soils which contain high levels of particular clays, such as smectites, are often very fertile. For example, the smectite-rich clays of Thailand's Central Plains are among the most productive in the world.
Many farmers in tropical areas, however, struggle to retain organic matter in the soils they work. In recent years, for example, productivity has declined in the low-clay soils of northern Thailand. Farmers initially responded by adding organic matter from termite mounds, but this was unsustainable in the long-term. Scientists experimented with adding bentonite, one of the smectite family of clays, to the soil. In field trials, conducted by scientists from the International Water Management Institute in cooperation with Khon Kaen University and local farmers, this had the effect of helping retain water and nutrients. Supplementing the farmer's usual practice with a single application of 200 kg bentonite per rai (6.26 rai = 1 hectare) resulted in an average yield increase of 73%. More work showed that applying bentonite to degraded sandy soils reduced the risk of crop failure during drought years.
In 2008, three years after the initial trials, IWMI scientists conducted a survey among 250 farmers in northeast Thailand, half of whom had applied bentonite to their fields. The average improvement for those using the clay addition was 18% higher than for non-clay users. Using the clay had enabled some farmers to switch to growing vegetables, which need more fertile soil. This helped to increase their income. The researchers estimated that 200 farmers in northeast Thailand and 400 in Cambodia had adopted the use of clays, and that a further 20,000 farmers were introduced to the new technique.
If the soil is too high in clay, adding gypsum, washed river sand and organic matter will balance the composition. Adding organic matter (like ramial chipped wood for instance) to soil which is depleted in nutrients and too high in sand will boost its quality.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="37739" url="http://en.wikipedia.org/wiki?curid=37739" title="The Illustrated Man">
The Illustrated Man

The Illustrated Man is a 1951 book of eighteen science fiction short stories by Ray Bradbury that explores the nature of mankind. A recurring theme throughout the eighteen stories is the conflict of the cold mechanics of technology and the psychology of people. It was nominated for the International Fantasy Award in 1952.
The unrelated stories are tied together by the frame device of "the Illustrated Man", a vagrant former member of a carnival freak show with an extensively tattooed body whom the unnamed narrator meets. The man's tattoos, allegedly created by a time-traveling woman, are animated and each tell a different tale. All but one of the stories had been published previously elsewhere, although Bradbury revised some of the texts for the book's publication.
The book was made into the 1969 film starring Rod Steiger and Claire Bloom, adapted from the stories "The Veldt", "The Long Rain", and "The Last Night of the World".
A number of the stories, including "The Veldt", "The Fox and the Forest" (as "To the Future"), "Marionettes, Inc.", and "Zero Hour" were dramatized for the 1955-57 radio series "X Minus One". "The Veldt", "The Concrete Mixer", "The Long Rain", "Zero Hour", and "Marionettes Inc." were adapted for the TV series "The Ray Bradbury Theater".
Other versions.
The British edition, first published in 1952 by Hart-Davis omits "The Rocket Man", "The Fire Balloons", "The Exiles" and "The Concrete Mixer", and adds "Usher II" from "The Martian Chronicles" and "The Playground".
Editions published by Avon Books in 1997 and William Morrow in 2001 omit "The Fire Balloons" and add "The Illustrated Man" to the end of the book.
Reception.
Boucher and McComas gave "The Illustrated Man" a mixed review, faulting the framing story as "markedly ineffective" and the story selection for seeming "less than wisely chosen". However, they found the better stories "provide a feast [from] the finest traditions in imaginative fiction" and later named it among the year's top books. Villiers Gerson, reviewing the volume for "Astounding Science Fiction", praised it as "a book which demonstrates that its author is one of the most literate and spellbinding writers in science fiction today". In "The New York Times", Gerson also praised the book for its "three-dimensional people with whom it is easy to sympathize, to hate, and to admire".
Adaptations to other media.
1969 film.
A film adaptation of "The Illustrated Man" was released in 1969. It was directed by Jack Smight and starred Rod Steiger, Claire Bloom, and others, including Don Dubbins. The film contains adaptations of "The Veldt", "The Long Rain", "The Last Night of the World" and expands the prologue and epilogue with intermittent scenes and flashbacks of how the illustrations came to be. A short documentary, "Tattooed Steiger", details the process the filmmakers used to cover Steiger's body in mock tattoos and shows actors and filmmakers preparing for the movie.
2008 album.
A musical adaptation by Samuel Otten was released as a musical expression of the stories to go along with the reading.
Influence on "Dark Star", 1974.
Bradbury's "Kaleidoscope" inspired the 1974 science fiction movie "Dark Star", which ends in a similar final scene.
Influence on "To the Dark Side of the Moon", 2010.
A theater adaptation of "Kaleidoscope", with influence from music by Pink Floyd was used to produce "To the Dark Side of the Moon", in reference to the Pink Floyd album by the same name. This adaptation was produced by Stern-Theater, a Swiss-based theater company. The script was written by Daniel Rohr and was first shown at the Theater Rigiblick in Zurich, Switzerland on February 6, 2010. The music includes creative use of a string quartet and a piano.
BBC Radio, 2014.
A radio adaptation was broadcast on BBC Radio 4 on 14 June 2014 as part of the "Dangerous Visions" series adapted by Brian Sibley, directed by Gemma Jenkins and starring Iain Glen as "The Illustrated Man" and Jamie Parker as "The Youth". The stories adapted for this production were "Marionettes, Inc.", "Zero Hour" and "Kaleidoscope".
Film in development.
Director Zack Snyder is attached to direct, at least in part, a film adaptation of three stories from "The Illustrated Man": "The Illustrated Man", "Veldt", and "Concrete Mixer". Screenwriter Alex Tse is writing the screenplay.
"The Whispers" television series.
"The Whispers" is an upcoming American television series based on the short story "Zero Hour".

</doc>
<doc id="37742" url="http://en.wikipedia.org/wiki?curid=37742" title="List of political theorists">
List of political theorists

"This is a list of notable political theorists. See the list of political scientists for those who study politics using the scientific method."
A political theorist is someone who engages in constructing or evaluating political theory, including political philosophy. Theorists may be academics or independent scholars.

</doc>
<doc id="37743" url="http://en.wikipedia.org/wiki?curid=37743" title="Mead">
Mead

Mead (; archaic and dialectal "medd"; from Old English "meodu") is an alcoholic beverage created by fermenting honey with water, sometimes with various fruits, spices, grains, or hops. (Hops act as a preservative and produce a bitter, beer-like flavor.) The alcoholic content of mead may range from about 8% ABV to more than 20%. The defining characteristic of mead is that the majority of the beverage's fermentable sugar is derived from honey. It may be still, carbonated, or naturally sparkling; and it may be dry, semi-sweet, or sweet.
Mead is known from many sources of ancient history throughout Europe, Africa and Asia. "It can be regarded as the ancestor of all fermented drinks," Maguelonne Toussaint-Samat has speculated, "antedating the cultivation of the soil." Hornsey considers archaeological evidence of it ambiguous; however, McGovern and other archaeological chemists consider the presence of beeswax markers and gluconic acid, in the presence of other substances known to ferment, to be reasonably conclusive evidence of the use of honey in ancient fermented beverages.
Claude Lévi-Strauss makes a case for the invention of mead as a marker of the passage "from nature to culture." Mead has played an important role in the beliefs and mythology of some peoples. One such example is the Mead of Poetry, a mead of Norse mythology crafted from the blood of the wise being Kvasir which turns the drinker into a poet or scholar.
The terms "mead" and "honey-wine" are often used synonymously. Honey-wine is differentiated from mead in some cultures. Hungarians hold that while mead is made of honey, water and beer-yeast (barm), honey-wine is watered honey fermented by recrement of grapes (or other fruits).
History.
In Asia, pottery vessels containing chemical signatures of a mixture of honey, rice and other fruits along with organic compounds of fermentation dating from 6500-7000 BC were found in Northern China. In Europe, it is first attested in residual samples found in the characteristic ceramics of the Bell Beaker Culture (c. 2800 – 1800 BC). The earliest archaeological evidence for the European production of mead dates to before 2000 BC.
The earliest surviving description of mead is in the hymns of the "Rigveda", one of the sacred books of the historical Vedic religion and (later) Hinduism dated around 1700–1100 BC. During the Golden Age of Ancient Greece, mead was said to be the preferred drink. Aristotle (384–322 BC) discussed mead in his "Meteorologica" and elsewhere, while Pliny the Elder (AD 23–79) called mead "militites" in his "Naturalis Historia" and differentiated wine sweetened with honey or "honey-wine" from mead. The Spanish-Roman naturalist Columella gave a recipe for mead in "De re rustica", about AD 60.
Take rainwater kept for several years, and mix a sextarius of this water with a [Roman] pound of honey. For a weaker mead, mix a sextarius of water with nine ounces of honey. The whole is exposed to the sun for 40 days, and then left on a shelf near the fire. If you have no rain water, then boil spring water.
There is a poem attributed to the Brythonic-speaking bard Taliesin, who lived around 550 ce, called the "Kanu y med" or "Song of Mead." The legendary drinking, feasting and boasting of warriors in the mead hall is echoed in the mead hall "Din Eidyn" (modern day Edinburgh) as depicted in the poem "Y Gododdin", attributed to the poet Aneirin who would have been a contemporary of Taliesin. In the Old English epic poem "Beowulf", the Danish warriors drank mead. In both Insular Celtic and Germanic cultures mead was the primary heroic drink in poetry.
Later, taxation and regulations governing the ingredients of alcoholic beverages led to commercial mead becoming a more obscure beverage until recently. Some monasteries kept up the old traditions of mead-making as a by-product of beekeeping, especially in areas where grapes could not be grown, a well-known example being at Lindisfarne, where mead continues to be made to this day, albeit not in the monastery itself.
Etymology.
The English word mead derives from the Old English "meodu", from Proto-Germanic "meduz", from Proto-Indo-European "*médʰu" (honey, fermented honey drink). Slavic "med / miod ", which means both "honey" and "mead", (Russian, Czech, Slovak, Serbian, Ukrainian, Bulgarian, Croatian: "med" vs. "medovina", Polish 'miód' pronounce [mju:t] - honey, mead) and Baltic "medus" "honey"/"midus" "mead", also derive from the same Proto-Indo-European root (cf. Welsh medd, Old Irish mid, Sanskrit "madhu", Sogdian [an Old Iranian language]: "muð", Avestan [another Old Iranian language]: "maðu", Classical Persian: مُل "mul", Classical and New Persian: مِی "mey").
Distribution.
Mead was also popular in Eastern Europe and in the Baltic states. In the Polish language mead is called "miód pitny" (), meaning "drinkable honey". In Russian it is called Medovukha "Медовуха", which means the same thing as in Polish.
Since the 19th century, in Russia, mead has remained popular in the drinks medovukha and sbiten long after its decline in the West. Sbiten is often mentioned in the works of 19th-century Russian writers, including Gogol, Dostoevsky and Tolstoy. In Montenegro, "medovina" has been considered a healthy elixir and mentioned often in folk literature.
In Finland, a sweet mead called "sima" (cognate with the root of zymurgy) is still an essential seasonal fermented product connected with the Finnish Vappu (May Day) festival. It is usually spiced by adding both the pulp and rind of a lemon. During secondary fermentation, raisins are added to control the amount of sugars and to act as an indicator of readiness for consumption; they will rise to the top of the bottle when the drink is ready. However, the sugar used in modern practice is typically brown sugar, not honey.
Ethiopian mead is called "tej" (ጠጅ, ]) and is usually home-made. It is flavored with the powdered leaves and bark of "gesho", a hop-like bittering agent which is a species of buckthorn. A sweeter, less-alcoholic version called "berz", aged for a shorter time, is also made. The traditional vessel for drinking "tej" is a rounded vase-shaped container called a "berele".
Mead known as iQhilika is traditionally prepared by the Xhosa of South Africa.
In the USA, mead is enjoying a resurgence, starting with small home meaderies and now with a number of small commercial meaderies. As mead becomes more widely available, it is seeing increased attention and exposure from the news media.
Fermentation process.
The yeast used in mead making is often identical to that used in wine making. Many home mead makers choose to use wine yeasts (particularly those used in the preparation of white wines) to make their meads. The problem with this is that the honey-based must does not have a sufficient quantity of nutrients to produce a wholesome mead. To circumvent the nutrient issue, both commercial and homebrew mead makers add specific quantities of diammonium phosphate, vitamin B1, vitamin B12, vitamin B3, biotin, and other key minerals. These are often added based on a staggered addition schedule in order to achieve a high-quality readily-drinkable mead. In some cases, the mead prepared with a staggered nutrient addition can be consumed the moment it is bottled as opposed to waiting over one year for it to age.
By measuring the specific gravity of the must once before fermentation and throughout the fermentation process by means of a hydrometer or refractometer, mead makers can determine the proportion of alcohol by volume that will appear in the final product. This also serves another purpose. By measuring specific gravity throughout fermentation, a mead maker can quickly troubleshoot a "stuck" batch, the word "stuck" being used to describe a fermentation process that has halted prematurely.
Meads will often ferment well at the same temperatures in which wine is fermented.
After primary fermentation slows down significantly — usually when specific gravity reaches 1.010 — the must is then racked into a second container. This is known as secondary fermentation. Some larger commercial fermenters are designed to allow both primary and secondary fermentation to happen inside of the same vessel. Racking is done for two reasons: it lets the mead sit away from the remains of the yeast cells (trub) that have died during the fermentation process. Second, this lets the mead have time to clear. If the mead maker wishes to backsweeten the product or prevent it from oxidizing, potassium metabisulfite and potassium sorbate are added. After the mead clears, it is bottled and distributed.
Varieties.
Mead can have a wide range of flavors depending on the source of the honey, additives (also known as "adjuncts" or "gruit") including fruit and spices, the yeast employed during fermentation and the aging procedure. Some producers have marketed white wine sweetened and flavored with honey after fermentation as mead, sometimes spelling it "meade." This is closer in style to a Hypocras. Blended varieties of mead may be known by the style represented; for instance, a mead made with cinnamon and apples may be referred to as either a cinnamon cyser or an apple metheglin.
A mead that also contains spices (such as cloves, cinnamon or nutmeg), or herbs (such as meadowsweet, hops, or even lavender or chamomile), is called a metheglin .
A mead that contains fruit (such as raspberry, blackberry or strawberry) is called a melomel, which was also used as a means of food preservation, keeping summer produce for the winter. A mead that is fermented with grape juice is called a pyment.
Mulled mead is a popular drink at Christmas time, where mead is flavored with spices (and sometimes various fruits) and warmed, traditionally by having a hot poker plunged into it.
Some meads retain some measure of the sweetness of the original honey, and some may even be considered as dessert wines. Drier meads are also available, and some producers offer sparkling meads.
There are faux-meads, which are actually wines with honey added after fermentation as a sweetener and flavoring.
Historically, meads were fermented with wild yeasts and bacteria (as noted in the recipe quoted above) residing on the skins of the fruit or within the honey itself. Wild yeasts can produce inconsistent results. Yeast companies have isolated strains of yeast which produce consistently appealing products. Brewers, winemakers and mead makers commonly use them for their fermentations. White Labs, WYeast and Vierka have released yeast strains identified specifically for mead fermentation. These are strains that have been selected because of their characteristic of preserving delicate honey flavors and aromas.
Mead can also be distilled to a brandy or liqueur strength. A version called "honey jack" can be made by partly freezing a quantity of mead and straining the ice out of the liquid (a process known as freeze distillation), in the same way that applejack is made from cider.
In literature.
Mead is featured in many Germanic myths and folktales such as "Beowulf", as well as in other popular works that draw on these myths. Notable examples include books by Tolkien, George R. R. Martin, T. H. White, and Neil Gaiman. It is often featured in books using a historical Germanic setting and in writings about the Viking age. Mead is mentioned many times in Neil Gaiman's 2001 novel, "American Gods"; it is referred to as the drink of the gods. In the Inheritance Cycle series by Christopher Paolini, the protagonist, Eragon, often drinks mead at feasts. It is also referenced in "The Kingkiller Chronicle" novel series by Patrick Rothfuss. The protagonist Kvothe is known to drink metheglin. The non-existent "Greysdale Mead" is also drunk, although it is merely water.

</doc>
<doc id="37744" url="http://en.wikipedia.org/wiki?curid=37744" title="M1 Abrams">
M1 Abrams

The M1 Abrams is an American third-generation main battle tank produced by the United States. It is named after General Creighton Abrams, former Army Chief of Staff and Commander of U.S. military forces in the Vietnam War from 1968 to 1972. Highly mobile, designed for modern armored ground warfare, the M1 is well armed and heavily armored. Notable features include the use of a powerful multifuel turbine engine, the adoption of sophisticated composite armor, and separate ammunition storage in a blow-out compartment for crew safety. Weighing nearly 68 short tons (almost 62 metric tons), it is one of the heaviest main battle tanks in service.
The M1 Abrams entered U.S. service in 1980, replacing the M60 tank. It served for over a decade alongside the improved M60A3, which had entered service in 1978. The M1 remains the principal main battle tank of the United States Army and Marine Corps, and the armies of Egypt, Kuwait, Saudi Arabia, Australia and Iraq.
Three main versions of the M1 Abrams have been deployed, the M1, M1A1, and M1A2, incorporating improved armament, protection and electronics. These improvements and other upgrades to in-service tanks, have allowed this long-serving vehicle to remain in front-line service. In addition, development for the improved M1A3 version has been known since 2009.
History.
The M1 Abrams was developed during the Cold War as a successor to the canceled MBT-70. The M1 Abrams contract went to Chrysler Defense and was the first vehicle to adopt Chobham armor. Adaptations before the Persian Gulf War (Operations Desert Shield and Desert Storm) gave the vehicle better firepower and NBC (Nuclear, Biological and Chemical) protection. Being vastly superior to Iraqi tanks, very few M1 tanks were hit by enemy fire. Upgrades after the war improved the tank's weapons sights and fire control unit. The invasion of Iraq in 2003 destroyed Iraq's military. The subsequent insurgency exposed the tanks' vulnerability to rocket-propelled grenades and mines. These problems were partially rectified with the TUSK modification. The Marine Corps sent a company of M1A1 Abrams to Afghanistan in late 2010.
Development.
The first attempt to replace the aging M60 tank was the MBT-70, developed in partnership with West Germany in the 1960s. The MBT-70 had advanced features such as a height-adjustable air suspension and a very small body with the driver in a turret design that allowed the driver to always face the direction of travel. The MBT-70 ultimately proved to be too heavy, complex, and expensive. As a result of the imminent failure of this project, the U.S. Army introduced the XM803, using some technologies from the MBT-70 but removing some of the more troublesome features. This succeeded only in producing an expensive system with capabilities similar to the M60.
Congress canceled the MBT-70 in November and XM803 December 1971, and redistributed the funds to the new XM815, later renamed the XM1 Abrams after General Creighton Abrams. Prototypes were delivered in 1976 by Chrysler Defense and General Motors armed with the license-built version of the 105 mm Royal Ordnance L7 gun along with a Leopard 2 for comparison. The turbine-powered Chrysler Defense design was selected for development as the M1; Chrysler had significant experience designing turbine-powered land vehicles going back to the 1950s. In March 1982, General Dynamics Land Systems Division (GDLS) purchased Chrysler Defense, after Chrysler built over 1,000 M1s.
A total of 3,273 M1 Abrams were produced 1979–85 and first entered U.S. Army service in 1980. Production at the government-owned, GDLS-operated Lima Army Tank Plant in Lima, Ohio, was joined by vehicles built at the Detroit Arsenal Tank Plant in Warren, Michigan from 1982 to 1996. The M1 was armed with the license-built version of the 105 mm Royal Ordnance L7 gun. An improved model called the M1IP was produced briefly in 1984 and contained small upgrades. The M1IP models were used in the Canadian Army Trophy NATO tank gunnery competition in 1985 and 1987.
About 6,000 M1A1 Abrams were produced from 1986–92 and featured the M256 120 mm smoothbore cannon developed by Rheinmetall AG of Germany for the Leopard 2, improved armor, and a CBRN protection system. Production of M1 and M1A1 tanks totaled some 9,000 tanks at a cost of approximately $4.3 million per unit. By 1999, costs for the tank were upwards of US$ a vehicle.
In 1990, Project on Government Oversight in a report criticized the M1's high costs and low fuel efficiency in comparison with other tanks of similar power and effectiveness such as the Leopard 2. The report was based on data from U.S. Army sources and the Congressional record.
As the Abrams entered service in the 1980s, they operated alongside M60A3 within the United States military, and with other NATO tanks in numerous Cold War exercises. These exercises usually took place in Western Europe, especially West Germany, but also in some other countries, including South Korea. The exercises were aimed at countering Soviet forces. However, by January 1991 the Berlin Wall had fallen and the Abrams was instead deployed in the Middle East.
Gulf War.
The Abrams remained untested in combat until the Persian Gulf War in 1991, during Operation Desert Storm. A total of 1,848 M1A1s were deployed to Saudi Arabia to participate in the liberation of Kuwait. The M1A1 was superior to Iraq's Soviet-era T-55 and T-62 tanks, as well as T-72s imported from the Soviet Union and Poland. The existence of licence-produced T-72 (nicknamed Asad Babil) has been disputed; according to Polish officials none were finished prior to the Iraqi Taji tank plant being destroyed in 1991. The T-72s, like most Soviet export designs, lacked night vision systems and then-modern rangefinders, though they did have some night-fighting tanks with older active infrared systems or floodlights. A total of 23 M1A1s were damaged or destroyed during the war. Of the nine Abrams destroyed, seven were destroyed by friendly fire, and two were purposely destroyed to prevent capture after being damaged. Some others took minor combat damage, with little effect on their operational readiness. Very few M1 tanks were hit by enemy fire, which resulted in no fatalities and only a handful of wounded.
The M1A1 was capable of making kills at ranges in excess of 2500 m. This range was crucial in combat against previous generation tanks of Soviet design in Desert Storm, as the effective range of the main gun in the Soviet/Iraqi tanks was less than 2000 m. This meant Abrams tanks could hit Iraqi tanks before the enemy got in range—a decisive advantage in this kind of combat. In friendly fire incidents, the front armor and fore side turret armor survived direct APFSDS hits from other M1A1s. This was not the case for the side armor of the hull and the rear armor of the turret, as both areas were penetrated on at least two occasions by friendly depleted uranium ammunition during the Battle of Norfolk.
During Operations Desert Shield and Desert Storm some M1IP and M1A1s were modified locally in theater by modification work orders (MWO) with additional rolled homogenous armor plating welded on the turret front. The M1 can be equipped with mine plow and mine roller attachments.
Upgrades.
The M1A2 was a further improvement of the M1A1 with a commander's independent thermal viewer, weapon station, position navigation equipment, and a full set of controls and displays linked by a digital data bus. These upgrades also provided the M1A2 with an improved fire control system. The M1A2 System Enhancement Package (SEP) added digital maps, FBCB2 capabilities, and an improved cooling system to compensate for heat generated by the additional computer systems. The M1A2 SEP also serves as the basis for the M104 Wolverine heavy assault bridge. The M1A2 SEPv2 (version 2) added Common Remotely Operated Weapon Station (CROWS or CROWS II) support, color displays, better interfaces, a new operating system, better front and side armor, and an upgraded transmission for better durability. Further upgrades included depleted uranium armor for all variants, a system overhaul that returns all A1s to like-new condition (M1A1 AIM), a digital enhancement package for the A1 (M1A1D), and a commonality program to standardize parts between the U.S. Army and the Marine Corps (M1A1HC).
Iraq War.
Further combat was seen during 2003 when U.S. forces invaded Iraq and deposed Ba'athist Iraqi leader Saddam Hussein in the Iraq War's Operation Iraqi Freedom. As of March 2005, approximately 80 Abrams tanks were forced out of action by enemy attacks.
The most lopsided achievement of the M1A1s was the destruction of seven T-72s in a point-blank skirmish (less than 50 yd) near Mahmoudiyah, about 18 mi south of Baghdad, with no losses for the American side. In addition to the Abrams's already heavy armament, some crews were also issued M136 AT4 shoulder-fired anti-tank weapons under the assumption that they might have to engage heavy armor in tight urban areas where the main gun could not be brought to bear.
Following lessons learned in Desert Storm, the Abrams and many other U.S. combat vehicles used in the conflict were fitted with Combat Identification Panels to reduce friendly fire incidents. These were fitted on the sides and rear of the turret, with flat panels equipped with a four-cornered 'box' image on either side of the turret front. Some Abrams were also fitted with a secondary storage bin on the back of the existing bustle rack on the rear of the turret (referred to as a bustle rack extension) to enable the crew to carry more supplies and personal belongings.
Several Abrams that were irrecoverable due to loss of mobility or other circumstances were destroyed by friendly forces, usually by other Abrams, to prevent their capture. Some Abrams were disabled by Iraqi infantrymen in ambushes during the invasion. Some troops employed short-range anti-tank rockets and fired at the tracks, rear and top. Other tanks were put out of action by engine fires when flammable fuel stored externally in turret racks was hit by small arms fire and spilled into the engine compartment. A majority of Abrams damaged (post-invasion) were by improvised explosive devices (IEDs). By December 2006, more than 530 Abrams tanks had been shipped back to the U.S. for repair.
Due to the vulnerability of tanks in urban combat, the Tank Urban Survival Kit (or TUSK) is being issued to some M1 Abrams. It adds protection in the rear and side of the tank to improve fighting ability in urban environments.
In May 2008, it was reported that an American M1 tank had also been damaged by an RPG-29, which uses a tandem-charge high explosive anti-tank warhead to penetrate explosive reactive armor (ERA) as well as composite armor behind it, in Iraq. The U.S. considered the RPG-29 threat to American armor high and refused to allow the newly formed Iraqi Army to buy it, fearing that it would fall into the insurgents' hands.
In mid-2014, the Abrams tank saw action in Iraq when the Islamic State launched the June 2014 Northern Iraq offensive. Some Iraqi Army M1A1M tanks were destroyed in fighting against ISIL forces,
War in Afghanistan.
Operating tanks in Afghanistan can be difficult due to the rough terrain, although Canada and Denmark have deployed Leopard 1 and 2 battle tanks that have been specially modified to operate in the relatively flat and arid conditions of south-western Afghanistan. In late 2010, at the request of Regional Command Southwest, the U.S. Marine Corps deployed a small detachment of 14 M1A1 Abrams from Delta Company, 1st Tank Battalion, 1st Marine Division (Forward), to southern Afghanistan in support of operations in Helmand and Kandahar provinces.
Future.
The tracked M8 Armored Gun System was conceived as a possible supplement for the Abrams in U.S. service for low-intensity conflict in the early 1990s. Prototypes were made but the program was canceled. The eight-wheeled M1128 Mobile Gun System was designed to supplement the Abrams in U.S. service for low-intensity conflict. It has been introduced into service and serves with Stryker brigades and Airborne units.
The U.S. Army's Future Combat Systems XM1202 Mounted Combat System was to replace the Abrams in U.S. service and was in development when funding for the program was cut from the DoD's budget.
Engineering Change Proposal 1 is a two-part upgrade process. ECP1A adds space, weight, and entertainment and power improvements and active protection against improvised explosive devices. Nine ECP1A prototypes have been produced as of October 2014. ECP1B, which will begin development in 2015, may include sensor upgrades and the convergence of several tank round capabilities into an multi-purpose round.
The M1A3 Abrams was in the early design period with the U.S. Army in 2009. At that time, the service was seeking a lighter tank version with the same protection as current versions. It aimed to build prototypes by 2014 and begin fielding the first combat-ready M1A3s by 2017. Recent program documents suggest that the U.S. Army plans to start the research and development for the M1A3 in 2020.
The M1A2 SEP TUSK Abrams and a modernized M1 Abrams were included in the Ground Combat Vehicle (GCV) "Analysis of Alternatives" (AOA). Vehicles included in the AOA were determined to be inferior to the planned GCV. The U.S. Army Vice Chief of Staff Gen. Peter Chiarelli commended the M1 Abrams program and recommended a similar approach for the GCV program. The Ground Combat Vehicle family of vehicles was the planned successor to the M1 as well as many other U.S. Army vehicles. However, the Army anticipates that the remaining M1A1 fleet will remain in U.S. service until at least 2021, and the M1A2 to beyond 2050.
Production shutdown.
The U.S. Army planned to end production at the Lima Army Tank Plant from 2013 to 2016 in an effort to save over $1 billion; it would be restarted in 2017 to upgrade existing tanks. General Dynamics Land Systems (GDLS), which operates the factory, opposed the move, arguing that suspension of operations would increase long-term costs and reduce flexibility. Specifically, GDLS estimated that closing the plant would cost $380 million and restarting production would cost $1.3 billion. If passed, a bill in the U.S. Senate from the first session of the 112th Congress would allocate $272 million in funds toward the plant to allow it to continue regular operations through 2013.
By August 2013, Congress had allocated $181 million for buying parts and upgrading Abrams systems to mitigate industrial base risks and sustain development and production capability. Congress and General Dynamics were criticized for redirecting money to keep production lines open and accused of "forcing the Army to buy tanks it didn't need." General Dynamics asserted that a four-year shutdown would cost $1.1–1.6 billion to reopen the line, depending on the length of the shutdown, whether machinery would be kept operating, and whether the plant's components would be completely removed. They contended that the move was to upgrade Army National Guard units to expand a "pure fleet" and maintain production of identified "irreplaceable" subcomponents; a prolonged shutdown could cause their makers to lose their ability to produce them and foreign tank sales were not guaranteed to keep production lines open. Even though money is being spent to protect the industrial base, some feel those strategic choices should not be made by members of Congress, especially those with the facilities in their district. There is still risk of production gaps even with production extended through 2015; with funds awarded before recapitalization is needed, budgetary pressures may push planned new upgrades for the Abrams from 2017 to 2019. In December 2014, Congress again allocated $120 million, against the wishes of the Army, for Abrams upgrades including improving gas mileage by integrating an auxiliary power unit to decrease idle time fuel consumption and upgrading the tank's sights and sensors.
Design.
Countermeasures.
Camouflage.
Earlier U.S. military vehicles, used from World War II through the Vietnam War, used a scheme of dark brownish green known as "olive drab" with large white stars. Prototypes, early production M1 (105 mm gun) and M1-IP models switched to a flat medium green paint scheme. The large white insignia stars have also transitioned to much smaller black markings. Some units painted their M1s with the older Mobility Equipment Research and Design Command (MERDC) 4-color paint scheme but the turn-in requirements for these tanks required repainting them to solid green. Therefore, even though a large number of the base model M1s were camouflaged in the field, few or none exist today.
M1A1s came from the factory with the NATO three color camouflage Black/Med-Green/Dark-Brown Chemical Agent Resistant Coating (CARC) paint jobs. Today M1A1s are given the NATO three color paint job during rebuilds. M1s and M1A1s deployed to Operation Desert Storm were hastily painted desert tan. Some, but not all, of these tanks were re-painted to their "authorized" paint scheme. M1A2s built for Middle Eastern countries were painted in desert tan. Some M1 series tanks are being painted desert tan for service in Iraq and some are not. Replacement parts (roadwheels, armor skirt panels, drive sprockets, etc.) are painted overall green, which can sometimes lead to vehicles with a patchwork of green and desert tan parts.
Australian M1A1s were desert tan when delivered but have undergone a transition to the Australian Army vehicle standard 'Disruptive Pattern Camouflage'; a scheme that consists of black, olive drab and brown.
Concealment.
The turret is fitted with two six-barreled smoke grenade launchers (USMC M1A1s use an eight-barreled version). These can create a thick smoke that blocks both vision and thermal imaging. The engine is also equipped with a smoke generator that is triggered by the driver. When activated, fuel is sprayed into the hot turbine exhaust, creating the thick smoke. However, due to the change from diesel as a primary fuel to the use of JP-8, this system is disabled on most Abrams today because of a slightly elevated risk of fire damage to the engine compartment.
Active protection system.
In addition to the armor, some Abrams are equipped with a Softkill Active protection system, the AN/VLQ-6 Missile Countermeasure Device (MCD) that can impede the function of guidance systems of some semi-active control line-of-sight (SACLOS) wire- and radio guided anti-tank missiles (such as the Russian 9K114 Shturm) and infrared homing missiles. The MCD works by emitting a massive, condensed infrared signal to confuse the infrared homing seeker of an anti-tank guided missile (ATGM). However, the drawback to the system is that the ATGM is not destroyed, it is merely directed away from its intended target, leaving the missile to detonate elsewhere. This device is mounted on the turret roof in front of the loader's hatch, and can lead some people to mistake Abrams fitted with these devices for the M1A2 version, since the Commander's Independent Thermal Viewer on the latter is mounted in the same place, though the MCD is box-shaped and fixed in place as opposed to cylindrical and rotating like the CITV.
Armor.
The Abrams is protected by armor based on the British-designed Chobham armor, a further development of the British 'Burlington' armor. Chobham is a composite armor formed by spacing multiple layers of various alloys of steel, ceramics, plastic composites, and kevlar, giving an estimated maximum (frontal turret) 1320 - of RHAe versus High-explosive anti-tank warhead (and other chemical energy rounds) and 940 - versus kinetic energy penetrators. It may also be fitted with reactive armor over the track skirts if needed (as in the Urban Survival Kit) and slat armor over the rear of the tank and rear fuel cells to protect against ATGMs. Protection against spalling is provided by a Kevlar liner.
Beginning in 1987, M1A1 tanks received improved armor packages that incorporated depleted uranium (DU) components in their armor at the front of the turret and the front of the hull. Armor reinforced in this manner offers significantly increased resistance towards all types of anti-tank weaponry, but at the expense of adding considerable weight to the tank, as depleted uranium is 1.7 times more dense than lead. The first M1A1 tanks to receive this upgrade were tanks stationed in Germany, since they were the first line of defense against the Soviet Union. US-based tank battalions participating in Operation Desert Storm received an emergency program to upgrade their tanks with depleted uranium armor immediately before the onset of the campaign. M1A2 tanks uniformly incorporate depleted uranium armor, and all M1A1 tanks in active service have been upgraded to this standard as well. The added protection from the depleted uranium armor is believed to be equivalent to 24 in of RHA. In the Persian Gulf War, Abrams tanks survived multiple hits at relatively close ranges from Iraqi Lion of Babylon tanks and ATGMs. M829A1 "Silver Bullet" APFSDS rounds from other M1A1 Abrams were unable to penetrate the front and side armor (even at close ranges) in friendly fire incidents as well as an incident in which an Abrams tried to destroy an abandoned Abrams stuck in the mud.
Damage control.
The tank has a halon firefighting system to automatically extinguish fires in the crew compartment. The engine compartment has a firefighting system that is engaged by pulling a T-handle located on the left side of the tank. The crew compartment also contains small hand-held fire extinguishers. Fuel and ammunition are stored in armored compartments with blowout panels to protect the crew from the risk of the tank's own ammunition cooking off if the tank is damaged — the main gun's ammunition is stored in the rear section of the turret, with blast doors that open under power by sliding sideways only to remove a round for firing, then automatically close.
Armament.
Primary.
The main armament of the original model M1 was the M68A1 105 mm rifled tank gun firing a variety of high explosive anti-tank, high explosive, white phosphorus and an anti-personnel (multiple flechette) round. This gun is a license-built version of the British Royal Ordnance L7 gun. However, it proved to be inadequate; a cannon with lethality beyond the 3 km range was needed to combat newer armor technologies. To attain that lethality, projectile diameter needed to be increased.
The main armament of the M1A1 and M1A2 is the M256A1 120 mm smoothbore gun, designed by Rheinmetall AG of Germany, manufactured under license in the U.S. by Watervliet Arsenal, New York. The M256A1 is a variant of the Rheinmetall 120 mm L/44 gun carried on the German Leopard 2 on all variants up to the Leopard 2A5. Leopard 2A6 replaced the L/44 barrel with a longer L/55.
The M256A1 fires a variety of rounds. The M829A2 APFSDS round was developed specifically to address the improved protection of a Russian T-72, T-80U or T-90 main battle tank equipped with Kontakt-5 Explosive Reactive Armor. Later, the M829A3 APFSDS round was introduced to improve its effectiveness against next generation ERA equipped tanks. As a counter to that, the Russian army introduced Relikt, the most modern Russian ERA, which is claimed to be twice as effective as Kontakt-5. Development of the M829 series is continuing with the M829E4 currently in development. The Abrams also fires High-explosive anti-tank warhead shaped charge rounds such as the M830, the latest version of which (M830A1) incorporates a sophisticated multi-mode electronic sensing fuse and more fragmentation which allows it to be used effectively against armored vehicles, personnel, and low-flying aircraft. The Abrams uses a manual loader. The fourth tank crew member on the Abrams also provides additional support for maintenance, observation post/listening post (OP/LP) operations, and other tasks.
The new M1028 120 mm anti-personnel canister cartridge was brought into service early for use in the aftermath of the 2003 invasion of Iraq. It contains 1,098 3/8 in tungsten balls which spread from the muzzle to produce a shotgun effect lethal out to 600 m. The tungsten balls can be used to clear enemy dismounts, break up hasty ambush sites in urban areas, clear defiles, stop infantry attacks and counter-attacks and support friendly infantry assaults by providing covering fire. The canister round is also a highly effective breaching round and can level cinder block walls and knock man-sized holes in reinforced concrete walls for infantry raids at distances up to 75 m. Also in use is the M908 obstacle-reduction round. It is designed to destroy obstacles and barriers. The round is a modified M830A1 with the front fuse replaced by a steel nose to penetrate into the obstacle before detonation.
The Army is developing a new round to replace the M830/M830A1, M1028, and M908. Called the Advanced Multi-Purpose (AMP) round, it will have point detonation, delay, and airburst modes through an ammunition data link and a multi-mode, programmable fuse in a single munition. Having one round that does the job of four would simplify logistics and be able to be used on a variety of targets. The AMP is to be effective against bunkers, infantry, light armor, and obstacles out to 500 meters, and will be able to breach reinforced concrete walls and defeat ATGM teams from 500 to 2,000 meters.
In addition to these, the XM1111 (Mid-Range-Munition Chemical Energy) was also in development. The XM1111 was a guided munition using a dual-mode seeker that combined imaging-infrared and semi-active laser guidance. The MRM-CE was selected over the competing MRM-KE which used a rocket-assisted kinetic energy penetrator. The CE variant was chosen due to its better effects against secondary targets, providing a more versatile weapon. The Army hoped to achieve IOC with the XM1111 by 2013. However, the Mid-Range Munition was cancelled in 2009 along with Future Combat Systems.
Secondary.
The Abrams tank has three machine guns:
Aiming.
The Abrams is equipped with a ballistic fire-control computer that uses user and system-supplied data from a variety of sources, to compute, display, and incorporate the three components of a ballistic solution—lead angle, ammunition type, and range to the target—to accurately fire the tank. These three components are determined using a YAG rod laser rangefinder, crosswind sensor, a pendulum static cant sensor, data concerning performance and flight characteristics of each specific type of round, tank-specific boresight alignment data, ammunition temperature, air temperature, barometric pressure, a muzzle reference system (MRS) that determines and compensates for barrel drop at the muzzle due to gravitational pull and barrel heating due to firing or sunlight, and target speed determined by tracking rate tachometers in the Gunner's or Commander's Controls Handles. All of these factors are computed into a ballistic solution and updated 30 times per second. The updated solution is displayed in the Gunner's or Tank Commander's field of view in the form of a reticle in both day and Thermal modes. The ballistic computer manipulates the turret and a complex arrangement of mirrors so that all one has to do is keep the reticle on the target and fire to achieve a hit. Proper lead and gun tube elevation are applied to the turret by the computer, greatly simplifying the job of the gunner.
The fire-control system uses this data to compute a firing solution for the gunner. The ballistic solution generated ensures a hit percentage greater than 95 percent at nominal ranges. Either the commander or gunner can fire the main gun. Additionally, the Commander's Independent Thermal Viewer (CITV) on the M1A2 can be used to locate targets and pass them on for the gunner to engage while the commander scans for new targets. In the event of a malfunction or damage to the primary sight system, the main and coaxial weapons can be manually aimed using a telescopic scope boresighted to the main gun known as the Gunner's Auxiliary Sight (GAS). The GAS has two interchangeable reticles; one for High-explosive anti-tank warhead and MPAT (MultiPurpose AntiTank) rounds and one for APFSDS and STAFF (Smart Target-Activated Fire and Forget) ammunition. Turret traverse and main gun elevation can be accomplished with manual handles and cranks in the event of a Fire Control System or Hydraulic System failure. The commander's M2HB .50 caliber machine gun on the M1 and M1A1 is aimed by a 3× magnification sight incorporated into the Commander's Weapon Station (CWS), while the M1A2 uses either the machine gun's own iron sights, or a remote aiming system such as the CROWS system when used as part of the TUSK (Tank Urban Survival Kit). The loader's M240 machine gun is aimed either with the built-in iron sights or with a thermal scope mounted on the machine gun.
Mobility.
Tactical.
The M1 Abrams's powertrain comprises a 1500 shp Honeywell AGT 1500 (originally made by Lycoming) multi-fuel gas turbine, and a six speed (four forward, two reverse) Allison X-1100-3B Hydro-Kinetic automatic transmission, giving it a governed top speed of 45 mph on paved roads, and 30 mph cross-country. With the engine governor removed, speeds of around 60 mph are possible on an improved surface; however, damage to the drivetrain (especially to the tracks) and an increased risk of injuries to the crew can occur at speeds above 45 mph. The tank was built around this engine and it is multifuel capable; meaning that it can be powered with diesel, kerosene, any grade of motor gasoline, and jet fuel (such as JP-4 or JP-8). For logistical reasons, JP-8 is the US military's universal fuel powering both aircraft and vehicle fleets. On the other hand, Australian M1A1 AIM SA burn diesel fuel, since the use of JP-8 is less common in the Australian Army.
The gas turbine propulsion system has proven quite reliable in practice and combat, but its high fuel consumption is a serious logistic issue (starting up the turbine alone consumes nearly 10 USgal of fuel). The engine burns more than 1.67 USgal per mile (60 USgal per hour) when traveling cross-country and 10 USgal per hour when idle. The high speed, high temperature jet blast emitted from the rear of M1 Abrams tanks makes it difficult for the infantry to proceed shadowing the tank in urban combat. The turbine is very quiet when compared to diesel engines of similar power output and produces a significantly different sound from a contemporary diesel tank engine, reducing the audible distance of the sound, thus earning the Abrams the nickname "whispering death" during its first REFORGER exercise.
Honeywell was developing another gas turbine engine with General Electric for the XM2001 Crusader program that was to be a replacement for the Abrams's AGT-1500 engine. The new LV100-5 engine was lighter and smaller (43% fewer parts) with rapid acceleration, quieter running, and no visible exhaust. It also featured a 33% reduction in fuel consumption (50% less when idle) and near drop-in replacement. The Abrams-Crusader Common Engine Program was shelved when the Crusader program was canceled, however Phase 2 of Army's PROSE (Partnership for Reduced O&S Costs, Engine) program called for further development of the LV100-5 and replacement of the current AGT-1500 engine.
General Dynamics has been working on a drop-in diesel engine to replace the gas turbine engine. It is smaller than the turbine, 14% cheaper to operate per mile, and has a four-fan cooling system which is to greatly reduce the tank's heat signature. General Dynamics is offering the Tognum America/12V883 diesel engine with new Diehl 570P3 tracks. The engine represents advancements in diesel engine design since the Abrams was first designed, including a common rail fuel injector system where fuel is pressurized and atomized in the cylinder rather than mechanically sprayed. It also has greater torque, an altered nuclear, biological, and chemical protection system that operates independently of the engine, uses less fuel while idle, is quieter, and gives off significantly less heat and pollutants. Incorporating the diesel engine into the Abrams would decrease the operating cost of an armored brigade combat team by 14 percent per mile, increase its operating range from 205 miles to 300+ miles, and use half the amount of fuel on a combat day than the turbine engine. The tracks are a version of the Leopard 2's tracks with different rubber pads and a larger center guide. The improved engine and tracks are not part of an Army upgrade program, but may be included in a near-term engineering change proposal (ECP) phase.
Using a high power density 330 cc Wankel rotary engine modified to use diesel and military grade jet fuel, the Army's TARDEC developed a 220 lb Auxiliary Power Unit designed to fit into the M1 Abrams, replacing an existing battery pack that weighs about 500 lb. The new APU will also be more fuel efficient than the tank's main engine. Testing of the first APUs began in 2009.
Although the M1 tank is not designed to carry riders easily, provisions exist for the Abrams to transport troops in tank desant with the turret stabilization device switched off. A battle equipped infantry squad may ride on the rear of the tank, behind the turret. The soldiers can use ropes and equipment straps to provide handholds and snap links to secure themselves. If and when enemy contact is made, the tank conceals itself allowing the infantry to dismount.
Strategic.
Strategic mobility is the ability of the tanks of an armed force to arrive in a timely, cost effective, and synchronized fashion. The Abrams can be carried by a C-5 Galaxy or a C-17 Globemaster III. The limited capacity (two combat-ready in a C-5, one combat-ready tank in a C-17) caused serious logistical problems when deploying the tanks for the first Persian Gulf War, though there was enough time for 1,848 tanks to be transported by ship.
Marines transport their Marine Air Ground Task Force (MAGTF)-attached Abrams by combat ship. A "Wasp"-class Landing Helicopter Dock (LHD) typically carries a platoon of 4 to 5 tanks attached to the deployed Marine Expeditionary Unit, which are then amphibiously transported to shore by Landing Craft Air Cushion (LCAC) at 1 combat-ready tank per landing craft.
The Abrams is also transportable by truck, namely the M1070 Heavy Equipment Transporter (HET). The HET can operate on highways, secondary roads, and cross-country. The HET accommodates the 4 tank crewmen.
The first instance of the Abrams being airlifted directly into a battlefield occurred in April 2003, when armored elements of the 1st Infantry Division were lifted by C-17s into northern Iraq from Ramstein, Germany to support Task Force Viking.
Variants and upgrades.
Specifications.
Note: All of the above produce a power of 1500 shp.
Tank Urban Survival Kit.
The Tank Urban Survival Kit (TUSK) is a series of improvements to the M1 Abrams intended to improve fighting ability in urban environments. Historically, urban and other close battlefields have been the worst place for tanks to fight. A tank's front armor is much stronger than that on the sides, top, or rear, and, in an urban environment, attacks can come from any direction, and attackers can get close enough to reliably hit weak points in the tank's armor or gain sufficient elevation to hit the top armor.
Armor upgrades include reactive armor on the sides of the tank and slat armor (similar to that on the Stryker) on the rear to protect against rocket-propelled grenades and other shaped charge warheads.
A Transparent Armor Gun Shield and a thermal sight system are added to the loader's top-mounted M240B 7.62 mm machine gun, and a Kongsberg Gruppen Remote Weapon Turret carrying a .50 caliber machine gun (again similar to that used on the Stryker) is in place of the tank commander's original .50 caliber machine gun mount, wherein the commander had to expose himself to fire the weapon manually. An exterior telephone allows supporting infantry to communicate with the tank commander.
The TUSK system is a field-installable kit that allows tanks to be upgraded without needing to be recalled to a maintenance depot. While the reactive armor may not be needed in most situations, in maneuver warfare, items like the rear slat armor, loader's gun shield, infantry phone (which saw use on Marine Corps M1A1s as early as 2003), and Kongsberg Remote Weapons Station for the .50 caliber machine gun will be added to the entire M1A2 fleet over time.
On 29 August 2006, General Dynamics Land Systems received a U.S. Army order for 505 Tank Urban Survivability Kits (TUSK) for Abrams main battle tanks supporting operations in Iraq, under a US$45 million contract. The add-on kit will be provided for M1A1 and M1A2-series tanks to enhance crew survivability in urban environments. The kit ordered by the Army consists of a Loader's Armor Gun Shield (LAGS), a Tank Infantry Phone (TIP), Abrams Reactive Armor Tiles (ARAT), a Remote Thermal Sight (RTS), and a Power Distribution Box (PDB). Deliveries are expected to be complete by April 2009.
Under a separate order, the U.S. Army awarded General Dynamics Armament and Technical Products (GDATP) US$30 million to produce reactive armor kits to equip M1A2s. The total contract value could reach $59 million if all contract options are exercised. The reactive tiles for the M1 will be locally produced at GDATP's Burlington Technology Center. Tiles will be produced at the company's reactive armor facility in Stone County Operations, McHenry, Mississippi. On 8 December 2006, the U.S. Army added Counter Improvised Explosive Device enhancements to the M1A1 and M1A2 TUSK, awarding GDLS U.S. $11.3 million, part of the $59 million package mentioned above. In December, GDLS also received an order, amounting to around 40% of a US$48 million order, for loader's thermal weapon sights being part of the TUSK system improvements for the M1A1 and M1A2 Abrams Tanks.
References.
</dl>

</doc>
<doc id="37745" url="http://en.wikipedia.org/wiki?curid=37745" title="Bell AH-1 Cobra">
Bell AH-1 Cobra

The Bell AH-1 Cobra (company designation: Model 209) is a two-blade, single engine attack helicopter manufactured by Bell Helicopter. It was developed using the engine, transmission and rotor system of the Bell's UH-1 Iroquois. The AH-1 is also referred to as the HueyCobra or Snake.
The AH-1 was the backbone of the United States Army's attack helicopter fleet, but has been replaced by the AH-64 Apache in Army service. Upgraded versions continue to fly with the militaries of several other nations. The AH-1 twin engine versions remain in service with United States Marine Corps (USMC) as the service's primary attack helicopter. Surplus AH-1 helicopters have been converted for fighting forest fires. The United States Forest Service refers to their program as the "Firewatch Cobra". Garlick Helicopters also converts surplus AH-1s for forest firefighting under the name, "FireSnake".
Development.
Background.
Closely related with the development of the Bell AH-1 is the story of the Bell UH-1 Iroquois—predecessor of the modern helicopter, icon of the Vietnam War and one of the most numerous helicopter types built. The UH-1 made the theory of air cavalry practical, as the new tactics called for US forces to be highly mobile across a wide area. Unlike before, they would not stand and fight long battles, and they would not stay and hold positions. Instead, the plan was that the troops carried by fleets of UH-1 "Hueys" would range across the country, to fight the enemy at times and places of their own choice.
It soon became clear that the unarmed troop helicopters were vulnerable against ground fire from Việt Cộng and North Vietnamese troops, particularly as they came down to drop their troops in a landing zone. Without friendly support from artillery or ground forces, the only way to pacify a landing zone was from the air, preferably with an aircraft that could closely escort the transport helicopters, and loiter over the landing zone as the battle progressed. By 1962 a small number of armed UH-1As were used as escorts, armed with multiple machine guns and rocket mounts.
The massive expansion of American military presence in Vietnam opened a new era of war from the air. The linchpin of US Army tactics were the helicopters, and the protection of those helicopters became a vital role.
Iroquois Warrior, Sioux Scout and AAFSS.
Bell had been investigating helicopter gunships since the late 1950s, and had created a mockup of its D-255 helicopter gunship concept, named "Iroquois Warrior". In June 1962, Bell displayed the mockup to Army officials, hoping to solicit funding for further development. The Iroquois Warrior was planned to be a purpose-built attack aircraft based on the UH-1B components with a new, slender airframe and a two-seat, tandem cockpit. It featured a grenade launcher in a ball turret on the nose, a 20 mm belly-mounted gun pod, and stub wings for mounting rockets or SS.10 anti-tank missiles.
The Army was interested and awarded Bell a proof of concept contract in December 1962. Bell modified a Model 47 into the sleek Model 207 Sioux Scout which first flew in July 1963. The Sioux Scout had all the key features of a modern attack helicopter: a tandem cockpit, stub wings for weapons, and a chin-mounted gun turret. After evaluating the Sioux Scout in early 1964, the Army was impressed, but also felt the Sioux Scout was undersized, underpowered, and generally not suited for practical use.
Army's solution to the shortcomings of the Sioux Scout was to launch the Advanced Aerial Fire Support System (AAFSS) competition. The AAFSS requirement gave birth to the Lockheed AH-56 Cheyenne, a heavy attack helicopter with high speed capability. It proved to be too sophisticated, and was canceled after 10 years of development in 1972. The Army sought greater survivability in a conventional attack helicopter.
Model 209.
At the same time, despite the Army's preference for the AAFSS–for which Bell Helicopter was not selected to compete–Bell stuck with their own idea of a smaller and lighter gunship. In January 1965 Bell invested $1 million to proceed with a new design. Mating the proven transmission, the "540" rotor system of the UH-1C augmented by a Stability Control Augmentation System (SCAS), and the T53 turboshaft engine of the UH-1 with the design philosophy of the Sioux Scout, Bell produced the Model 209. Bell's Model 209 largely resembled the "Iroquois Warrior" mockup.
In Vietnam, events were also advancing in favor of the Model 209. Attacks on US forces were increasing, and by the end of June 1965 there were already 50,000 US ground troops in Vietnam. 1965 was also the deadline for AAFSS selection, but the program would become stuck in technical difficulties and political bickering. The U.S. Army needed an interim gunship for Vietnam and it asked five companies to provide a quick solution. Submissions came in for armed variants of the Boeing-Vertol ACH-47A, Kaman HH-2C Tomahawk, Piasecki 16H Pathfinder, Sikorsky S-61, and the Bell 209.
On 3 September 1965 Bell rolled out its Model 209 prototype, and four days later it made its maiden flight, only eight months after the go-ahead. In April 1966, the model won an evaluation against the other rival helicopters. Then the Army signed the first production contract for 110 aircraft. Bell added Cobra to the UH-1's Huey nickname to produce its "HueyCobra" name for the 209. The Army applied the "Cobra" name to its AH-1G designation for the helicopter.
The Bell 209 demonstrator was used for the next six years to test weapons and fit of equipment. It had been modified to the match AH-1 production standard by the early 1970s. The demonstrator was retired to the Patton Museum at Fort Knox, Kentucky and converted to approximately its original appearance.
Into production.
The Bell 209 design was modified for production. The retractable skids were replaced by simpler fixed skids. A new wide-blade rotor was featured. For production, a plexiglass canopy replaced the 209's armored glass canopy which was heavy enough to harm performance. Other changes were incorporated after entering service. The main one of these was moving the tail rotor from the helicopter's left side to the right for improved effectiveness of the rotor.
The U.S. Marine Corps was interested in the Cobra and ordered an improved twin-engined version in 1968 under the designation AH-1J. This would lead to more twin-engine variants. In 1972, the Army sought improved anti-armor capability. Under the Improved Cobra Armament Program (ICAP), trials of eight AH-1s fitted with TOW missiles were conducted in October 1973. After passing qualification tests the following year, Bell was contracted with upgrading 101 AH-1Gs to the TOW-capable AH-1Q configuration. Following AH-1Q operational tests, a more powerful T53 engine and transmission were added from 1976 resulting in the AH-1S version. The AH-1S was upgraded in three steps, culminating with the AH-1F.
Operational history.
United States.
By June 1967, the first AH-1G HueyCobras had been delivered. Originally designated as UH-1H, the "A" for attack designation was soon adopted and when the improved UH-1D became the UH-1H, the HueyCobra became the AH-1G. The AH-1 was initially considered a variant of the H-1 line, resulting in the G series letter.
AH-1 Cobras were in use by the Army during the Tet offensive in 1968 and through to the end of the Vietnam War. Cobras provided fire support for ground forces, escorted transport helicopters and other roles, including aerial rocket artillery (ARA) battalions in the two Airmobile divisions. They also formed "hunter killer" teams by pairing with OH-6A scout helicopters. A team featured one OH-6 flying slow and low to find enemy forces. If the OH-6 drew fire, the Cobra could strike at the then revealed enemy. On 12 September 1968, Capt. Ronald Fogleman was flying an F-100 Super Saber when the aircraft was shot down and he ejected 200 miles north of Bien Hoa. Fogleman became the only pilot to be rescued by holding on to an Army AH-1G's deployed gun-panel door. Bell built 1,116 AH-1Gs for the U.S. Army between 1967 and 1973, and the Cobras chalked up over a million operational hours in Vietnam; the number of Cobras in service peaked at 1,081. Out of nearly 1,110 AH-1s delivered from 1967 to 1973 approximately 300 were lost to combat and accidents during the war. The U.S. Marine Corps used AH-1G Cobras in Vietnam for a short time before acquiring twin-engine AH-1J Cobras.
AH-1 Cobras were deployed for Operation Urgent Fury, the invasion of Grenada in 1983, flying close-support and helicopter escort missions. Army Cobras participated in Operation Just Cause, the U.S. invasion of Panama in 1989.
During Operations Desert Shield and Desert Storm in the Gulf War (1990–91), the Cobras and SuperCobras deployed in a support role. The USMC deployed 91 AH-1W SuperCobras and the US Army 140 AH-1 Cobras; these were operated from forward, dispersed desert bases. Three AH-1s were lost in accidents during fighting and afterward. Cobras destroyed many Iraqi armored vehicles and various targets in the fighting.
Army Cobras provided support for the US humanitarian intervention during Operation Restore Hope in Somalia in 1993. They were also employed during the US invasion of Haiti in 1994. US Cobras were also used in operations later in the 1990s.
The US Army phased out the AH-1 during the 1990s and retired the AH-1 from active service in March 1999, offering them to NATO allies. The Army retired the AH-1 from reserves in September 2001. The retired AH-1s have been passed to other nations and to the USDA Forest Service. The AH-1 continues to be in service with the US military, by the US Marine Corps, which operate the twin-engine AH-1W SuperCobra and AH-1Z Viper.
Israel.
The Israeli Air Force named its Cobras as the "Tzefa" (Hebrew: צפע‎, for Viper). Since the mid-1970s Lebanon has been Israel's most active front; IAF Cobras had been fighting there for more than 20 years.
Cobra helicopters were also used widely by the Israeli Air Force in the 1982 Lebanon War to destroy Syrian armor and fortification. IAF Cobras destroyed dozens of Syrian ground vehicles. The Cobras were also used in major operations against Hezbollah in Operations "Accountability" and "Grapes of Wrath" in southern Lebanon.
Israel retired its fleet of some 33 AH-1 Cobras in late 2013 due to budget cuts. The attack helicopter role was taken up entirely by two squadrons of Israeli AH-64 Apache helicopters, and the fleet of unmanned aerial vehicles took over the role of patrolling combat zones. The Cobra fleet was older than the Apaches and responsible for some fatal crashes, and more expensive to maintain than UAVs and more vulnerable for pilots to MANPADS fired by guerrilla groups.
Japan.
Japan manufactured 89 AH-1S Cobras which were licensed by Fuji Heavy Industries from 1984 to 2000. The type is used by the Japan Ground Self-Defense Force, and are Step 3 models, which are roughly the equivalent to the United States Army's AH-1Fs. The engine is the T53-K-703 turboshaft, which Kawasaki Heavy Industries produced under license.
Pakistan.
Pakistan was supplied with 20 AH-1S gunships by the U.S. between 1984 and 1986, these were later upgraded with the C-NITE thermal imaging package. AH-1s were used as Pakistan's main gunship helicopters against insurgents during the Balochistan conflict. The ongoing War in North-West Pakistan has seen Pakistani AH-1s in action against Taliban and Al Qaeda fighters as well as their tribal allies. The U.S. delivered 12 AH-1Fs to Pakistan in 2007, with 14 more AH-1F Cobras supplied in 2010.
Pakistan has 35 AH-1F helicopters in use. Maintaining these aircraft has been difficult, but possible through commercial channels. Additionally, the U.S. Government has given $750,000 to update a portion of Pakistan Army Aviation's existing AH-1F/S Cobra fleet. Turkey has also supplied spare parts of Cobra helicopters to Pakistan free of cost. Pakistan has repeatedly sought Bell AH-1 SuperCobra attack helicopters from the U.S. to supplement and replace its current AH-1 Cobras. Pakistan has lost 3 aircraft in recent years. Attempts to acquire the AH-1Z Viper or AH-64 Apache from the U.S. have been rejected, so Pakistan turned to buying other foreign attack helicopters to replace its aging AH-1F fleet. Possible candidates included the Turkish TAI T-129, the Chinese CAIC Z-10, and the Russian Mi-35 Hind. In November 2014, Russia approved the sale of Mi-35M helicopters to Pakistan. In April 2015, China delivered to 3 Z-10s to Pakistan. During the same month, the US State Department approved the sale of 15 AH-1Zs to Pakistan along with associated equipment, worth up to $952 million. 
U.S. Forest Service.
In 2003, the U.S. Forest Service acquired 25 retired AH-1Fs from the U.S. Army. These have been designated Bell 209 and are being converted into Firewatch Cobras with infrared and low light sensors and systems for real time fire monitoring. The Florida Division of Forestry has also acquired 3 AH-1Ps from the U.S. Army. These are called Bell 209 "Firesnakes" and are equipped to carry a water/fire retardant system.
Operators.
"For operators of AH-1J, AH-1T, AH-1W, and other AH-1 twin-engine variants, see AH-1 SuperCobra"
former operators.
A small number of former military helicopters are operated by civil organizations for display and demonstration, for example by Red Bull

</doc>
<doc id="37746" url="http://en.wikipedia.org/wiki?curid=37746" title="Boeing AH-64 Apache">
Boeing AH-64 Apache

The Boeing AH-64 Apache is a four-blade, twin-turboshaft attack helicopter with a tailwheel-type landing gear arrangement, and a tandem cockpit for a two-man crew. It features a nose-mounted sensor suite for target acquisition and night vision systems. It is armed with a 30 mm M230 chain gun carried between the main landing gear, under the aircraft's forward fuselage. It has four hardpoints mounted on stub-wing pylons, typically carrying a mixture of AGM-114 Hellfire missiles and Hydra 70 rocket pods. The AH-64 has a large amount of systems redundancy to improve combat survivability.
The Apache originally started as the "Model 77" developed by Hughes Helicopters for the United States Army's Advanced Attack Helicopter program to replace the AH-1 Cobra. The prototype YAH-64 was first flown on 30 September 1975. The U.S. Army selected the YAH-64 over the Bell YAH-63 in 1976, and later approved full production in 1982. After purchasing Hughes Helicopters in 1984, McDonnell Douglas continued AH-64 production and development. The helicopter was introduced to U.S. Army service in April 1986. The first production AH-64D Apache Longbow, an upgraded Apache variant, was delivered to the Army in March 1997. Production has been continued by Boeing Defense, Space & Security; over 2,000 AH-64s have been produced to date.
The U.S. Army is the primary operator of the AH-64; it has also become the primary attack helicopter of multiple nations, including Greece, Japan, Israel, the Netherlands and Singapore; as well as being produced under license in the United Kingdom as the AgustaWestland Apache. U.S. AH-64s have served in conflicts in Panama, the Persian Gulf, Kosovo, Afghanistan, and Iraq. Israel used the Apache in its military conflicts in Lebanon and the Gaza Strip; British and Dutch Apaches have seen deployments in Afghanistan and Iraq.
Development.
Advanced Attack Helicopter.
Following the cancellation of the AH-56 Cheyenne in 1972, in favor of U.S. Air Force and Marine Corps projects like the A-10 Thunderbolt II and Harrier, the United States Army sought an aircraft to fill an anti-armor attack role that would still be under Army command; the 1948 Key West Agreement forbade the Army from owning combat fixed-wing aircraft. The Army wanted an aircraft better than the AH-1 Cobra in firepower, performance and range. It would have the maneuverability for terrain following nap-of-the-earth (NoE) flying. To this end, the U.S. Army issued a Request For Proposals (RFP) for an Advanced Attack Helicopter (AAH) on 15 November 1972. As a sign of the importance of this project, in September 1973 the Army designated its five most important projects, the "Big Five" with AAH included.
Proposals were submitted by Bell, Boeing Vertol/Grumman team, Hughes, Lockheed, and Sikorsky. In July 1973, the U.S. Department of Defense selected finalists Bell and Hughes Aircraft's Toolco Aircraft Division (later Hughes Helicopters). This began the phase 1 of the competition. Each company built prototype helicopters and went through a flight test program. Hughes' "Model 77/YAH-64A" prototype first flew on 30 September 1975, while Bell's Model 409/YAH-63A prototype first flew on 1 October 1975. After evaluating the test results, the Army selected Hughes' YAH-64A over Bell's YAH-63A in 1976. Reasons for selecting the YAH-64A included its more damage tolerant four-blade main rotor and the instability of the YAH-63's tricycle landing gear arrangement.
The AH-64A then entered phase 2 of the AAH program under which three pre-production AH-64s would be built, additionally, the two YAH-64A flight prototypes and the ground test unit were upgraded to the same standard. Weapons and sensor systems were integrated and tested during this time, including the laser-guided AGM-114 Hellfire missile. Development of the Hellfire missile had begun in 1974, originally known by the name of "Helicopter Launched, Fire and Forget Missile" ('Hellfire' being a shortened acronym), for the purpose of arming helicopter platforms with an effective anti-tank missile.
Into production.
In 1981, three pre-production AH-64As were handed over to the U.S. Army for Operational Test II. The Army testing was successful, but afterward it was decided to upgrade to the more powerful T700-GE-701 version of engine, rated at 1,690 shp. The AH-64 was named the "Apache" in late 1981, keeping with the Army's traditional use of American Indian tribal names for its helicopters and it was approved for full-scale production in 1982. In 1983, the first production helicopter was rolled out at Hughes Helicopter's facility at Mesa, Arizona. Hughes Helicopters was purchased by McDonnell Douglas for $470 million in 1984. The helicopter unit later became part of The Boeing Company with the merger of Boeing and McDonnell Douglas in August 1997. In 1986, the incremental or flyaway cost for the AH-64A was $7M and the average unit cost was approximately $13.9M based on total costs.
During the 1980s, McDonnell Douglas studied an AH-64B, featuring an updated cockpit, new fire control system and other upgrades. In 1988, funding was approved for a multi-stage upgrade program to improve sensor and weapon systems. Technological advance led to the program's cancellation in favor of more ambitious changes. In August 1990, development of the AH-64D Apache Longbow was approved by the Defense Acquisition Board. The first AH-64D prototype flew on 15 April 1992, prototype testing ended in April 1995. During testing, six AH-64D helicopters were pitted against a numerically superior group of AH-64A helicopters; the results demonstrated the AH-64D to have a seven times increase in survivability and four times increase in lethality compared to the AH-64A. On 13 October 1995, full-scale production was approved; a $1.9-billion five-year contract was signed in August 1996 to rebuild 232 AH-64As to AH-64D standard. On 17 March 1997, the first production AH-64D first flew, it was delivered on 31 March.
Portions of the Apache are produced by various aerospace firms. AgustaWestland has produced number of components for the Apache, both for the international market and for the British Army's AgustaWestland Apache. Since 2004, Korea Aerospace Industries has been the sole manufacturer of the Apache's fuselage. Fuselage production had previously been performed by Teledyne Ryan Aeronautical; the transfer of fuselage production led to a prolonged legal dispute between Teledyne Ryan and Boeing.
The AH-64D program cost a total of $11bn through 2007. In April 2006, Boeing was awarded a $67.6M fixed-price contract for the remanufacture of several existing U.S. AH-64As to the AH-64D configuration; between May 2009 and July 2011, a further five contracts were issued to remanufacture batches of AH-64As to the upgraded D variant. Since 2008, nations operating the older AH-64A have been urged to undertake modernization programs to become AH-64Ds, as Boeing and the U.S. Army plans to terminate support for the A-variants in the near future.
Design.
Overview.
The AH-64 Apache has a four-blade main rotor and a four-blade tail rotor. The crew sits in tandem, with the pilot sitting behind and above the copilot/gunner. Both crew members are capable of flying the aircraft and performing methods of weapon engagements independently. The AH-64 is powered by two General Electric T700 turboshaft engines with high-mounted exhausts on either side of the fuselage. Various models of engines have been used on the Apache; those in British service use engines from Rolls-Royce instead of General Electric. In 2004, General Electric Aviation began producing more powerful T700-GE-701D engines, rated at 2000 shp for AH-64Ds.
The crew compartment has shielding between the cockpits, such that at least one crew member can survive hits. The compartment and the rotor blades are designed to sustain a hit from 23 mm rounds. The airframe includes some 2500 lb of protection and has a self-sealing fuel system to protect against ballistic projectiles. The aircraft was designed to meet the crashworthiness requirements of MIL-STD-1290, which specifies minimum requirement for crash impact energy attenuation to minimize crew injuries and fatalities. This was achieved through incorporation of increased structural strength, crashworthy landing gear, seats and fuel system.
Avionics and targeting.
One of the revolutionary features of the Apache was its helmet mounted display, the Integrated Helmet and Display Sighting System (IHADSS); among its capabilities, either the pilot or gunner can slave the helicopter's 30 mm automatic M230 Chain Gun to their helmet, making the gun track head movements to point where they look. The M230E1 can be alternatively fixed to a locked forward firing position, or controlled via the Target Acquisition and Designation System (TADS). On more modern AH-64s, the TADS/PNVS has been replaced by Lockheed Martin's Arrowhead (MTADS) targeting system.
U.S. Army engagement training is performed under the Aerial Weapons Scoring System Integration with Longbow Apache Tactical Engagement Simulation System (AWSS-LBA TESS), using live 30 mm and rocket ammunition as well as simulated Hellfire missiles. The Smart Onboard Data Interface Module (SMODIM) transmits Apache data to an AWSS ground station for gunnery evaluation. The AH-64's standard of performance for aerial gunnery is to achieve at least 1 hit for every 30 shots fired at a wheeled vehicle at a range of 800 –.
The AH-64 was designed to perform in front-line environments, and to operate at night or day and during adverse weather conditions. Various sensors and onboard avionics allows the Apache to perform in these conditions; such systems include the Target Acquisition and Designation System, Pilot Night Vision System (TADS/PNVS), passive infrared countermeasures , GPS, and the IHADSS. In August 2012, 24 U.S. Army AH-64Ds were equipped with the Ground Fire Acquisition System (GFAS), which detects and targets ground-based weapons fire sources in all-light conditions and with a 120° Visual field. The GFAS consists of two sensor pods working with the AH-64's other sensors, a thermographic camera precisely locates ground-based threats.
In 2014, it was announced that new targeting and surveillance sensors were under development to provide high-resolution color imagery to crews, replacing older low definition black-and-white imaging systems. In 2014, the U.S Army was adapting its Apaches for increased maritime performance as part of the Pentagon's rebalance to the Pacific. Additional avionics and sensor improvements includes an extended-range radar capable of detecting small ships in littoral environments, software adaptions to handle maritime targets, and adding Link 16 data-links for better communications with friendly assets.
Armaments and configurations.
The AH-64 is adaptable to numerous different roles within its context as Close Combat Attack (CCA), it has a customizable weapons loadout mounted on stub-wings for the role desired. In addition to the 30 mm M230E1 Chain Gun, the Apache carries a range of external stores on its stub-wing pylons, typically a mixture of AGM-114 Hellfire anti-tank missiles, and Hydra 70 general-purpose unguided 70 mm rockets. Since 2005, the Hellfire missile is sometimes outfitted with a thermobaric warhead; designated AGM-114N, it is intended for use against ground forces and urban warfare operations. The use of thermobaric "enhanced blast" weapons such as the AGM-114N has been a point of controversy.
Starting in the 1980s, the Stinger and AIM-9 Sidewinder air-to-air missiles and the AGM-122 Sidearm anti-radiation missile were evaluated for use upon the AH-64. The Stinger was initially selected; the U.S. Army was also considering the Starstreak air-to-air missile. External fuel tanks can also be carried on the stub wings to increase range and mission time. The stub-wing pylons have mounting points for maintenance access; these mountings can be used to secure externally personnel for emergency transportation. Stinger missiles are often used on non-U.S. Apaches as foreign forces did not have as many air superiority aircraft to control the skies. The AH-64E initially lacked the ability to use the Stinger to make room for self-defense equipment, the capability was readded following a South Korean demand.
The AH-64E Apache has the ability to control unmanned aerial vehicles, used by the U.S. Army to perform aerial scouting missions previously performed by the OH-58 Kiowa. Apaches can request to take control of an RQ-7 Shadow or MQ-1C Grey Eagle from ground control stations to safely scout via datalink communications. There are four levels of UAV interoperability (LOI): LOI 1 indirectly receives payload data; LOI 2 receives payload data through direct communication; LOI 3 deploys the UAV's armaments; and LOI 4 takes over flight control. UAVs can search for enemies and, if equipped with a laser designator, target them for the Apache or other friendly aircraft.
Operational history.
United States Army.
The U.S. Army formally accepted its first production AH-64A in January 1984 and training of the first pilots began later that year. The first operational Apache unit, 7th Battalion, 17th Cavalry Brigade, began training on the AH-64A in April 1986 at Fort Hood, Texas. Two operational units with 68 AH-64s first deployed to Europe in September 1987 and took part in large military exercises there. The Apache was first used in combat in 1989, during Operation Just Cause, the invasion of Panama. The AH-64 participated in over 240 hours of combat attacking various targets, mostly at night. General Carl Stiner, the commander of the operation, commented that: "You could fire that Hellfire missile through a window from four miles away at night".
Upon fielding the Apache, capabilities such as using the FLIR for extensive night operations made it clear that it was capable of operating beyond the forward line of own troops (FLOT) that previous attack helicopters were normally restricted to. It was discovered that the Apache was coincidentally fitted with the Have Quick UHF radio system used by the U.S. Air Force, allowing inter-service coordination and joint operations such as the joint air attack teams (JAAT). The Apache have operated extensively with close air support (CAS) aircraft such as the USAF's Fairchild Republic A-10 Thunderbolt II and the USMC's McDonnell Douglas AV-8B Harrier II, often acting as a target designator to conserve the Apache's own munitions.
Nearly half of all U.S. Apaches were deployed to Saudi Arabia following Iraq's invasion of Kuwait. During Operation Desert Storm on 17 January 1991, eight AH-64As guided by four MH-53 Pave Low IIIs destroyed part of Iraq's radar network in the operation's first attack, allowing aircraft to evade detection. The Apaches each carried an asymmetric load of Hydra 70 flechette rockets, Hellfires, and one auxiliary fuel tank. During the 100-hour ground war a total of 277 AH-64s took part, destroying 278 tanks, numerous armored personnel carriers and other Iraqi vehicles. One AH-64 was lost in the war, to an RPG hit at close range, the Apache crashed but the crew survived. To maintain operations, the U.S. Army unofficially grounded all other AH-64s worldwide; Apaches in the theatre flew only one-fifth of the planned flight-hours.
The AH-64 played roles in the Balkans during separate conflicts in Bosnia and Kosovo in the 1990s. During Task Force Hawk, 24 Apaches were deployed to a land base in Albania in 1999 for combat in Kosovo. These required 26,000 tons of equipment to be transported over 550 C-17 flights, at a cost of US$. During these deployments, the AH-64 encountered problems such as deficiencies in training, night vision equipment, fuel tanks, and survivability. On 27 April 1999, an Apache crashed during training in Albania due to a failure with the tail rotor, causing the fleet in the Balkans to be grounded in December 2000.
In 2000, Major General Dick Cody, 101st Airborne's commanding officer, wrote a strongly worded memo to the Chief of Staff about training and equipment failures. No pilots were qualified to fly with night vision goggles, preventing nighttime operations. "The Washington Post" printed a front-page article on the failures, commenting: "The vaunted helicopters came to symbolise everything wrong with the Army as it enters the 21st century: Its inability to move quickly, its resistance to change, its obsession with casualties, its post-Cold War identity crisis". No Apache combat missions took place in Kosovo due to fears of casualties.
U.S. Apaches served in Operation Enduring Freedom in Afghanistan from 2001. The Apache was the only Army platform capable of providing accurate CAS duties for Operation Anaconda, regularly taking fire during the intense early fighting, they were typically repaired quickly. U.S. AH-64Ds typically flew in Afghanistan and Iraq without the Longbow Radar in the absence of armored threats. On 21 December 2009, a pair of U.S. Apaches attacked a British-held base in a friendly fire incident, killing one British soldier. In 2006, Thomas Adams noted that Apaches often fought in small teams with little autonomy to react to threats and opportunities, requiring lengthy dialogue with command structures in an effort to centrally micromanage each unit.
In 2003, the AH-64 participated in the invasion of Iraq during Operation Iraqi Freedom. On 24 March 2003, 31 Apaches were damaged, and one shot down and captured, in an unsuccessful attack on an Iraqi Republican Guard armored brigade near Karbala. Iraqi tank crews had set up a "flak trap" among terrain and effectively employed their guns. Iraqi officials claimed a farmer with a Brno rifle shot down the Apache, but the farmer denied involvement. The helicopter came down intact and both the pilot and co-pilot were captured. The AH-64D was destroyed via air strike the following day.
By the end of U.S. military operations in Iraq in December 2011, several Apache helicopters had been shot down by enemy fire, and others lost in accidents. In 2006, an Apache was downed by a Soviet-made Strela 2 (SA-7) in Iraq, despite the Apache being typically able to avoid such missiles. In 2007, four Apache helicopters were destroyed on the ground by insurgent mortar fire using web-published geotagged photographs taken by soldiers. Several AH-64s were lost to accidents in Afghanistan as of 2012. Most Apaches that took heavy damage were able to continue their missions and return safely.
As of 2011, the U.S. Army Apache fleet had accumulated more than 3 million flight hours since the first prototype flew in 1975. A DOD audit released in May 2011, found that Boeing had significantly overcharged the U.S. Army on multiple occasions, ranging from 33.3 percent to 177,475 percent for routine spare parts in helicopters like the Apache.
On 21 February 2013, the 1st Battalion (Attack), 229th Aviation Regiment at Joint Base Lewis-McChord became the first U.S. Army unit to field the AH-64E Apache Guardian; a total of 24 AH-64E were received by mid-2013. On 27 November 2013, the Apache Guardian achieved initial operating capability (IOC). In March 2014, the 1st-229th Attack Reconnaissance Battalion deployed 24 AH-64Es to Afghanistan in the type' first combat deployment. From March to June 2014, the AH-64E flew 1,700 hours in Afghanistan at what Boeing described as a "higher tempo" than the D-model would be capable of. As of 14 October 2014, AH-64E Apaches had flown almost 9,600 combat hours. From April through September 2014, AH-64E in combat maintained an 88 percent readiness rate.
The Army is implementing a plan to move all Apaches from the Army Reserve and National Guard to the active Army to serve as scout helicopters to replace the OH-58 Kiowa. Using the AH-64 to scout would be less expensive than Kiowa upgrades or purchasing a new scout helicopter. AH-64Es can control unmanned aerial vehicles like the MQ-1C Grey Eagle to perform aerial scouting missions; a 2010 study found the teaming of Apaches and UAVs was the most cost-effective alternative to a new helicopter and would meet 80 percent of reconnaissance requirements, compared to 20 percent with existing OH-58s and 50 percent with upgraded OH-58s. National Guard units, who would lose their attack helicopters, criticized the proposal. In March 2015, the first heavy attack reconnaissance unit was formed, comprising 24 attack Apaches, 24 reconnaissance Apaches, and 12 Shadow UAVs.
In July 2014, the Pentagon announced that Apaches had been dispatched to Baghdad to protect embassy personnel from Islamic State militant attacks. On 4 October 2014, Apaches began performing missions in Operation Inherent Resolve against Islamic State ground forces.
Israel.
The Israeli Air Force (IAF) first received AH-64As in 1990, for a total fleet of 42. There was some controversy over the Air Force's choice to purchase Apaches over upgrading existing AH-1 Cobra attack helicopters. In 2000, Israel was interested in acquiring up to 48 AH-64Ds, but U.S. reluctance to share the software source code complicated the prospect. In April 2005, Boeing delivered the first AH-64D to the IAF. In 2001, the U.S. government was allegedly investigating misuse of the Apache and other US-supplied military equipment against Palestinian leaders and facilities. In 2009, an arranged sale of six AH-64Ds was reportedly blocked by the Obama Administration, pending interagency review, over concerns the helicopters may pose a threat to civilian Palestinians in Gaza. In IAF service, the AH-64A was named as the "Peten" (Hebrew: פתן‎, for Cobra), while the AH-64D was named "Saraph" (שרף, also as "Seraph", Hebrew for venomous/fiery winged serpent).
During the 1990s, Israeli AH-64As frequently attacked Hezbollah outposts in Lebanon. On 13 April 1996, during Operation Grapes of Wrath, an Apache fired two Hellfire missiles at an ambulance in Lebanon, killing six civilians. During the al-Aqsa Intifada in 2000, AH-64s were used to kill senior Hamas figures, such as Ahmed Yassin and Adnan al-Ghoul. On 24 May 2001, a privately owned Lebanese-registered Cessna 152 flew into Israeli airspace, it was intercepted by two AH-64s and shot down by a Hellfire missile, killing the pilot. On 22 March 2004, an Israeli AH-64 used a Hellfire missile to kill Hamas leader Ahmed Yassin, also killing his two bodyguards and nine bystanders. IAF Apaches played a prominent role in the 2006 Lebanon War, launching strikes into Lebanon targeting Hezbollah forces.
There have also been accidents involving the Apache helicopter in Israeli service. During the Lebanon War in 2006, two IAF AH-64A helicopters collided, killing one pilot and critically wounding three. In another incident in the conflict an IAF AH-64D crashed due to a malfunction in the main rotor, killing the two crew. In late 2007, the Israeli Air Force put further purchases and deliveries of AH-64Ds on hold during an investigation upon the aircraft's performance envelope. However, Israeli officials have since praised the Apache for its role in Operation Cast Lead in 2008, against Hamas in Gaza. In recent years, Israeli Apaches have been used to patrol the skies over Gaza; strike operations against insurgents using these helicopters has become a frequent occurrence.
Since recent orders of new AH-64Ds have been blocked, Israel has pursued upgrades to its AH-64A fleet. In June 2010, Israel decided not to upgrade all AH-64As to D configuration, due to funding constraints and lack of U.S. cooperation. In December 2010, the IAF was examining the adoption of a new missile system as a cheaper and lightweight complement to the Hellfire missile, either the American Hydra 70 or the Canadian CRV7. In 2013, Israeli AH-64As had been receiving a comprehensive upgrade of their avionics and electrical systems. The AH-64As are being upgraded to the AH-64Ai configuration, which is near the AH-64D standard.
United Kingdom.
The UK operates a modified version of the Apache Longbow initially called the Westland WAH-64 Apache, and is designated Apache AH1 by the British Army. Westland built 67 WAH-64 Apaches under license from Boeing, following a competition between the Eurocopter Tiger and the Apache for the British Army's new Attack Helicopter in 1995. Important deviations made by AgustaWestland from the U.S. Apache variants include changing to more powerful Rolls-Royce engines, and the addition of a folding blade assembly for use on naval ships.
Netherlands.
The Dutch government initially showed an interest in acquiring Apache helicopters in the late 1980s, where it stated that it may purchase as many as 52. A competition held in 1994 against the Eurocopter Tiger and the Bell AH-1 SuperCobra led to the Royal Netherlands Air Force ordering 30 AH-64D Apaches in 1995. Deliveries began in 1998 and ended in 2002. The RNLAF Apaches are equipped with the Apache Modular Aircraft Survivability Equipment (AMASE) self-protection system to counter infrared (IR) missile threats.
The RNLAF Apaches' first deployment was in 2001 to Djibouti, Africa. They were also deployed alongside U.S. AH-64s in support of NATO peacekeeping forces in Bosnia and Herzegovina. In 2004, six Dutch AH-64s were deployed as part of the Netherlands contribution to Multinational force in Iraq to support the Dutch ground forces. The Apaches performed close combat support and display of force missions, along with providing reconnaissance information to ground forces. In February 2006, the Netherlands contribution to NATO forces in Afghanistan was increased from 600 to 1,400 troops and 6 AH-64s were sent in support.
Shortly after Apaches were deployed to Hamid Karzai International Airport, as part of the Netherlands contribution to ISAF, on 10 April 2004 a pair of Dutch Apaches came under light gunfire close to the Afghan capital. On 17 December 2007, an RNLAF Apache flew into powerlines during a night flying exercise in the Netherlands, forcing an emergency landing and causing a lengthy blackout in the region. On 17 March 2015 a RNLAF Apache crashed during a training mission in Mali. Both pilots died. The ministry of defence opened an investigation into the cause of the crash.
Saudi Arabia.
Following the 1991 Gulf War, during which many U.S. Apaches operated from bases within Saudi territory, Saudi Arabia purchased twelve AH-64As for the Royal Saudi Land Force. It has been speculated that the Saudi purchase had motivated Israel to also procure the Apaches. In August 2006, the Saudi Arabian government began negotiations for Apache upgrades worth up to $400M, possibly remanufacturing their AH-64As to the AH-64D Longbow configuration. In September 2008, the U.S. Government approved the purchase of 12 AH-64Ds requested by Saudi Arabia. In October 2010, Saudi Arabia requested a further 70 AH-64Ds as part of a possible, massive arms deal.
In November 2009, the Royal Saudi Land Force, as part of a military effort against insurgent intrusions of the kingdom's border, started using the Apache in Operation Scorched Earth; this involved launched air strikes against Houthi rebels operating inside neighboring Yemen as well. In January 2010 the rebels claimed to have shot down an Apache; this was denied by the Saudi military. In late January 2010, the leader of the Shiite rebels announced their withdrawal from Saudi territory, this announcement followed a key battle on 12 January when Saudi forces reportedly took control of the border village of Al Jabiri.
Egypt.
In 1995, the Egyptian Air Force placed an order for 36 AH-64A helicopters. These Apaches were delivered with most of the advanced avionics used on the U.S. fleet at that time, with the exception of localized radio equipment. In 2000, Boeing announced an order to remanufacture Egypt's existing Apache fleet to the AH-64D configuration. Notably, the AH-64D upgrade did not include the procurement of the Longbow radar, the supply of which had been refused by the U.S. government. Egypt requested a further 12 AH-64D Block II Apaches through a Foreign Military Sale in 2009.
In August 2012, the Egyptian Armed Forces undertook a large-scale military operation to regain control of the Sinai Peninsula from armed militants. Air cover throughout the operation was provided by the Egyptian Air Force's Apache helicopters; reportedly the Apaches destroyed three vehicles and killed at least 20 militants. Up to five Egyptian Apaches were temporarily stationed in the Sinai following an agreement between Egypt and Israel.
Other users.
The United Arab Emirates purchased 30 AH-64A helicopters in 1991 and 1994, which they are now upgrading to AH-64D specification. In 2005, Kuwait purchased 16 Longbow helicopters.
In September 2003, Greece ordered 12 AH-64D in addition to existing fleet of 20 AH-64A+. By 1995 they had received 20 AH-64As; another 12 AH-64Ds were ordered in 2003. Singapore purchased 20 AH-64D Longbow Apache aircraft in two batches between 1999 and 2001; during October 2010 Apache training was suspended following the forced crash-landing of an Apache.
Japan ordered 50 AH-64Ds, which are being built under license by Fuji Heavy Industries, designated "AH-64DJP". The first helicopter was delivered to the JGSDF in early 2006.
Taiwan (Republic of China) reached an agreement with the U.S. to purchase 30 AH-64D Block III Apaches with weapons, and associated equipment in June 2011. On 5 November 2013, Taiwan received the first 6 AH-64E Apaches. A second batch arrived in December 2013, with all 30 to be delivered by the end of 2014. By early April 2014, 18 had been delivered. On 25 April 2014, a Taiwanese AH-64E crashed into a three-story building during a training flight in bad weather conditions. Power loss was also being considered as a cause. The crash is the first airframe loss of an AH-64E model. An investigation ruled out mechanical failure and concluded human error as responsible, that the pilots descended too fast through clouds at low altitude without checking flight panels to maintain adequate height; the Army responded by stepping up simulator training for pilots. In October 2014, the fifth and final batch of AH-64Es was delivered to Taiwan, completing the order.
Future and possible users.
In 2008, the Indian Air Force (IAF) released a tender for 22 attack helicopters; there were six contending submissions—Sikorsky's UH-60 Black Hawk, the AH-64D, Bell's AH-1 Super Cobra, Eurocopter's Tiger, Mil's Mi-28 and AgustaWestland's A129 Mangusta. In October 2008, Boeing and Bell withdrew. In 2009, the competition was restarted and a new Apache proposal was submitted. In December 2010, India requested the possible sale of 22 AH-64Ds and associated equipment. On 5 October 2012, IAF Chief NAK Browne confirmed the AH-64D Block III's selection. In October 2012, India transferred most armed helicopters from the IAF to the Army Aviation Corps. The IAF sought to maintain control of the 22 proposed Apaches for air combat missions, the Indian Army argued that they would be better used in army operations. In April 2013, the Indian Ministry of Defence (MoD) decided that the IAF would receive the 22 AH-64s as it was an ongoing acquisition. In May 2013, the Indian Army requested 11 AH-64Es; and has a requirement for 39 Apaches. In August 2014, the Indian Ministry of Defence approved the AH-64 procurement, final approval from the Cabinet Committee on Security is required.
In 2009, South Korea showed interest in acquiring Apaches. This move may be related to U.S. plans to withdraw many of its Apaches from South Korea. On 21 September 2012, the U.S. Congress was notified of the possible purchase of 36 AH-64D Block III Apaches, along with associated equipment and armament. The Apache competed against the Bell AH-1Z Viper and the TAI/AgustaWestland T-129; in April 2013, South Korea announced that it is to purchase 36 AH-64Es. The Apaches are to be delivered from 2016 to 2018. On 26 August 2013, the U.S. and Indonesia formalized a $500 million deal for 8 AH-64E Apaches.
Iraq requested the sale of 24 AH-64s in April 2013; In January 2014, a sale, including the helicopters, associated parts, maintenance, and training, was cleared by Congress. However, the proposal was not accepted by the Iraqi government and expired in August 2014. In July 2012, Qatar requested the sale of 24 AH-64D Apache Block III helicopters, with associated equipment, training, and support. The sale was approved on 27 March 2014.
Variants.
AH-64A.
The AH-64A is the original production attack helicopter. The crew sit in tandem in an armored compartment. It is powered by two GE T700 turboshaft engines. The A-model was equipped with the −701 engine version until 1990 when the engines were switched to the more powerful −701C version.
U.S. Army AH-64As are being converted to AH-64Ds. The service's last AH-64A was taken out of service in July 2012 before conversion at Boeing's facility in Mesa, Arizona. On 25 September 2012, Boeing received a $136.8M contract to remanufacture the last 16 AH-64As into the AH-64D Block II version, to be completed by December 2013.
AH-64B.
In 1991 after Operation Desert Storm, the AH-64B was a proposed upgrade to 254 AH-64As. The upgrade would have included new rotor blades, a Global Positioning System (GPS), improved navigation systems and new radios. Congress approved $82M to begin the Apache B upgrade. The B program was canceled in 1992. The radio, navigation, and GPS modifications, were later installed on most A-model Apaches through other upgrades.
AH-64C.
Additional funding from Congress in late 1991 resulted in a program to upgrade AH-64As to an AH-64B+ version. More funding changed the plan to upgrade to AH-64C. The C upgrade would include all changes to be included in the Longbow except for mast-mounted radar and newer −700C engine versions. However, the C designation was dropped after 1993. With AH-64As receiving the newer engine from 1990, the only difference between the C model and the radar-equipped D model was the radar, which could be moved from one aircraft to another; thus the decision was made to simply designate both versions "AH-64D".
AH-64D.
The "AH-64D Apache Longbow", is equipped with a glass cockpit and advanced sensors, the most noticeable of which being the AN/APG-78 Longbow millimeter-wave fire-control radar (FCR) target acquisition system and the Radar Frequency Interferometer (RFI), housed in a dome located above the main rotor. The radome's raised position enables targets detection while the helicopter is behind obstacles (e.g. terrain, trees or buildings). The AN/APG-78 is capable of simultaneously tracking up to 128 targets and engaging up to 16 at once, an attack can be initiated within 30 seconds. A radio modem integrated with the sensor suite allows data to be shared with ground units and other Apaches; allowing them to fire on targets detected by a single helicopter.
The aircraft is powered by a pair of uprated T700-GE-701C engines. The forward fuselage was expanded to accommodate new systems to improve survivability, navigation, and 'tactical internet' communications capabilities. In February 2003, the first Block II Apache was delivered to the U.S. Army, featuring digital communications upgrades. The Japanese Apache AH-64DJP variant is based on the AH-64D; it can be equipped with the AIM-92 Stinger air-to-air missiles for self-defense.
AH-64E.
Formerly known as AH-64D Block III, in 2012, it was redesignated as "AH-64E Guardian" to represent its increased capabilities. The AH-64E features improved digital connectivity, the Joint Tactical Information Distribution System, more powerful T700-GE-701D engines with upgraded face gear transmission to accommodate more power, capability to control Unmanned aerial vehicle (UAVs), full IFR capability, and improved landing gear. New composite rotor blades, which successfully completed testing in 2004, increase cruise speed, climb rate, and payload capacity. Deliveries began in November 2011, full rate production was approved on 24 October 2012. 634 AH-64Ds will be upgraded to AH-64E standard; a production run of 56 new-build AH64Es will start in 2019/20. Changes in production lots 4 through 6 shall include a cognitive decision aiding system, new self-diagnostic abilities, and Link-16 data-links. The updated Longbow radar has an oversea capacity, potentially enabling naval strikes; an AESA radar is under consideration. The E model is to be fit for maritime operations.
AH-64F.
In 2014, Boeing conceptualized an Apache upgrade prior to the introduction of the U.S. Army's anticipated attack version of the Future Vertical Lift aircraft, forecast to replace the Apache by 2040. The conceptual "AH-64F" would have greater speed via a new 3,000 shp turboshaft engine from the improved turbine engine program, retractable landing gear, stub wings to offload lift from the main rotor during cruise, and a tail rotor that can articulate 90 degrees to provide forward thrust; resembling the pusher propeller of the canceled 1970s era Lockheed AH-56 Cheyenne attack helicopter.
Sea Apache.
During the 1980s Naval versions of the AH-64A for the United States Marine Corps and Navy were examined. Multiple concepts were studied with altered landing gear arrangements, improved avionics and weapons. Funding for a naval version was not provided; the Marine Corps continued to use the AH-1. The Canadian Forces Maritime Command also examined a naval Apache. In 2004, British Army AgustaWestland Apaches were deployed upon the Royal Navy's HMS "Ocean", a Landing Platform Helicopter, for suitability testing; there was U.S. interest in the trials. During the 2011 military intervention in Libya, the British Army extensively used Apaches from HMS "Ocean". In 2013, U.S. 36th Combat Aviation Brigade AH-64Ds were tested on a variety of U.S. Navy ships.
Export Apaches.
Several models have been derived from both AH-64A and AH-64D for export. The British-built AgustaWestland Apache (assembled from kits purchased from Boeing) is based on the AH-64D Block I with several different systems, including more powerful engines, folding rotor blades, and other modifications for operation from Royal Navy vessels.
Block modification.
While a major change in design or role will cause the type designator suffix to change, for example from AH-64D to AH-64E the helicopters are also subject to Block modification. Block modification is the combining of equipment changes into blocks of modification work orders, the modifications in the block (sometimes called a block package) are all done to the helicopter at the same time.
References.
</dl>

</doc>
<doc id="37747" url="http://en.wikipedia.org/wiki?curid=37747" title="Maurice Duverger">
Maurice Duverger

Maurice Duverger (5 June 1917 – 16 December 2014) was a French jurist, sociologist and politician. He was born in Angoulême, Charente.
Starting his career as a jurist at the University of Bordeaux, Duverger became more and more involved in political science and in 1948 founded one of the first faculties for political science in Bordeaux, France. An emeritus professor of the Sorbonne and member of the FNSP, he has published many books and articles in newspapers, such as "Corriere della Sera", "la Repubblica", "El País", and especially "Le Monde".
Duverger has studied the evolution of political systems and the institutions that operate in diverse countries, showing a preference for empirical methods of investigation rather than philosophical reasoning.
He devised a theory which became known as Duverger's law, which identifies a correlation between a first-past-the-post election system and the formation of a two-party system.
While analysing the political system of France, he coined the term semi-presidential system.
From 1989 until 1994 he was a member of the Group of the Party of European Socialists in the European Parliament.
In 1981 he was elected a member of the Serbian Academy of Sciences and Arts. He died at the age of 97 on 16 December 2014.
Career.
A member of Doriot's fascist Parti Populaire Français from age 20, Maurice Duverger completed his studies in from the Bordeaux Department of Law in 1942, before lecturing in law at Poitiers in 1942, and Bordeaux in 1943 (where he would, in 1948, found the Institut d'Études Politiques as its first director). He also taught at Vichy France's Institut d'Études Corporatives et Sociales.
In his first publication, "The Constitutions of France" (1944), he explained that the French constitution of 1940 created a "de facto government". However, towards the end of the war, Duverger grew close to the Resistance, and in "Libération" analyzed the legitimacy of the new government of France and devoted himself to social-scientific theory.
After the War, he taught in the faculty of law and economic sciences in Paris, 1955 to 1985, and contributed to "Libération" and "Le Monde". From 1989 to 1994, he sat in the European Parliament as an MEP for the Italian Communist Party.
In 1946 he expanded his theses, with a special interest in the relation between electoral systems and party systems. This interest is at the heart of his most important publication: "The Political Parties" (1951). The work is one of the classics of party research, translated into several languages. That thesis led to Duverger's law, and later he coined the term "semi-presidentialism".
Political parties.
Having as a point of reference their structure, Duverger in his book "Les Partis Politiques" (1951) distinguished parties between elite-based parties and mass-based parties.
Elite-based parties rather prefer the quality of their members over their quantity, their affiliates being people of great influence on local or national scale. They have flexible and disorganized structures, in general are weakly disciplined and lack developed pragmatic content, allowing each of their members to benefit from an enormous freedom of action. Their funding is generally provided by a sponsor, and as their strength comes from their elected representatives, they are typical parties of parliamentarian creation, which depend on the reputation and support of their benefactors.
Mass-based parties possess a secure organization and a strong structure arranged as a pyramid, with superposed hierarchically-arranged levels. Their members identify themselves more with the party's ideology than with its leader, so they have an abstract adhesion. Their decisions are based on the participation of each one of its members, and its founding is granted by their members' payments, a situation that leads them to gain as many adherents as possible.
These parties tend to develop on a par with suffrage and democracy. For instance, elite-based parties execute an often sporadic political labor, focused on elections. However, the disadvantage this implies in relation to their contestant parties (which denote permanent labor and a disciplined and organic structure), impels them to modify their organization to become mass-based parties.
Duverger's Law.
With discovery attributed to Duverger, he observed the effect and recorded it in several papers published in the 1950s and 1960s. In the course of further research, other political scientists began calling the effect a "law" or principle. Duverger's law suggests a nexus or synthesis between a party system and an electoral system: a proportional representation (PR) system creates the electoral conditions necessary to foster party development while a plurality system marginalizes many smaller political parties, resulting in what is known as a two-party system.
In political science, Duverger's law is a principle which asserts that plurality rule elections structured within single-member districts tends to favor a two-party system. This is one of two hypotheses proposed by Duverger, the second stating that "the double ballot majority system and proportional representation tend to multipartism."

</doc>
<doc id="37749" url="http://en.wikipedia.org/wiki?curid=37749" title="Marquis de Condorcet">
Marquis de Condorcet

Marie Jean Antoine Nicolas de Caritat, marquis de Condorcet (]; 17 September 1743 – 28 March 1794), known as Nicolas de Condorcet, was a French philosopher, mathematician, and early political scientist whose "Condorcet method" in voting tally selects the candidate who would beat each of the other candidates in a run-off election. Unlike many of his contemporaries, he advocated a liberal economy, free and equal public education, constitutionalism, and equal rights for women and people of all races. His ideas and writings were said to embody the ideals of the Age of Enlightenment and rationalism, and remain influential to this day. He died a mysterious death in prison after a period of flight from French Revolutionary authorities.
Early years.
Condorcet was born in Ribemont (in present-day Aisne), and descended from the ancient family of Caritat, who took their title from the town of Condorcet in Dauphiné, of which they were long-time residents. Fatherless at a young age, he was raised by his devoutly religious mother. He was educated at the Jesuit College in Reims and at the "Collège de Navarre" in Paris, where he quickly showed his intellectual ability, and gained his first public distinctions in mathematics. When he was sixteen, his analytical abilities gained the praise of Jean le Rond d'Alembert and Alexis Clairaut; soon, Condorcet would study under d'Alembert.
From 1765 to 1774, he focused on science. In 1765, he published his first work on mathematics entitled "Essai sur le calcul intégral", which was well received, launching his career as a mathematician. He would go on to publish more papers, and on 25 February 1769, he was elected to the "Académie royale des Sciences" (French Royal Academy of Sciences).
In 1772, he published another paper on integral calculus. Soon after, he met Jacques Turgot, a French economist, and the two became friends. Turgot was to be an administrator under King Louis XV in 1772, and became Controller-General of Finance under Louis XVI in 1774.
Condorcet worked with Leonhard Euler and Benjamin Franklin. He soon became an honorary member of many foreign academies and philosophic societies including the Royal Swedish Academy of Sciences (1785), Foreign Honorary Member of the American Academy of Arts and Sciences (1792),
and also in Prussia and Russia .
His political ideas, however, many of them in continuity with Turgot's, were criticized heavily in the English-speaking world, most notably by John Adams, who wrote two of his principal works of political philosophy to oppose Turgot and Condorcet's unicameral legislature and radical democracy.
Early political career.
In 1774, Condorcet was appointed Inspector General of the Paris mint by Turgot. From this point on, Condorcet shifted his focus from the purely mathematical to philosophy and political matters. In the following years, he took up the defense of human rights in general, and of women's and Blacks' rights in particular (an abolitionist, he became active in the Society of the Friends of the Blacks in the 1780s). He supported the ideals embodied by the newly formed United States, and proposed projects of political, administrative and economic reforms intended to transform France.
In 1776, Turgot was dismissed as Controller General. Consequently, Condorcet submitted his resignation as Inspector General of the "Monnaie", but the request was refused, and he continued serving in this post until 1791. Condorcet later wrote "Vie de M. Turgot" (1786), a biography which spoke fondly of Turgot and advocated Turgot's economic theories. Condorcet continued to receive prestigious appointments: in 1777, he became Permanent Secretary of the Académie des Sciences, holding the post until the abolition of the Académie in 1793, and in 1782 secretary of the "Académie française".
Condorcet's paradox and the Condorcet method.
In 1785, Condorcet wrote "Essai sur l’application de l’analyse à la probabilité des décisions rendues à la pluralité des voix" ("Essay on the Application of Analysis to the Probability of Majority Decisions"), one of his most important works. This work described several now famous results, including Condorcet's jury theorem, which states that if each member of a voting group is more likely than not to make a correct decision, the probability that the highest vote of the group is the correct decision increases as the number of members of the group increases, and Condorcet's paradox, which shows that majority preferences become intransitive with three or more options – it is possible for a certain electorate to express a preference for A over B, a preference for B over C, and a preference for C over A, all from the same set of ballots.
The paper also outlines a generic Condorcet method, designed to simulate pair-wise elections between all candidates in an election. He disagreed strongly with the alternative method of aggregating preferences put forth by Jean-Charles de Borda (based on summed rankings of alternatives). Condorcet was one of the first to systematically apply mathematics in the social sciences.
Other works.
In 1786, Condorcet worked on ideas for the differential and integral calculus, giving a new treatment of infinitesimals – a work which was never printed. In 1789, he published "Vie de Voltaire (1789)", which agreed with Voltaire in his opposition to the Church. In 1798, Thomas Malthus wrote "An Essay on the Principle of Population" partly in response to Condorcet's views on the "perfectibility of society" as outlined in the "Sketch for a Historical Picture of the Progress of the Human Mind". In 1781, Condorcet wrote a pamphlet, "Reflections on Negro Slavery", in which he denounced slavery.
French Revolution.
Deputy.
Condorcet took a leading role when the French Revolution swept France in 1789, hoping for a rationalist reconstruction of society, and championed many liberal causes. As a result, in 1791 he was elected as a Paris representative in the Assemblée, and then became the secretary of the Assembly. 
In April 1792 Condorcet presented a project for the reformation of the education system, aiming to create a hierarchical system, under the authority of experts, who would work as the guardians of the Enlightenment and who, independent of power, would be the guarantors of public liberties. The project was judged to be contrary to the republican and egalitarian virtues, giving the education of the Nation over to an aristocracy of savants. The institution adopted Condorcet's design for the state education system, and he drafted a proposed Bourbon Constitution for the new France. He advocated women's suffrage for the new government, writing an article for "Journal de la Société de 1789", and by publishing "De l'admission des femmes au droit de cité" in 1790.
There were three competing views on which direction France should go, embodied by three political parties: the moderate royalists or Feuillants, republican Girondins, and the more radical Montagnards, led by Maximilien Robespierre. The Feuillants wished to keep the constitutional monarchy as it was developed by the Assemblée, the latter two favored purging France of its royal past ("Ancien Régime"), each in their own way. Condorcet was quite independent, but still counted many friends in the Girondin party. He presided over the Assembly as the Girondins held the majority, until it was replaced by the National Convention, elected in order to design a new constitution. He led the Constitution Committee which drafted the Girondin constitutional project. The constitution was ordered to be printed, but was not put to a vote. When the Montagnards gained control of the Convention, they wrote their own, the "French Constitution of 1793".
At the time of the Trial of Louis XVI, the Girondins had, however, lost their majority in the Convention. Condorcet, who opposed the death penalty but still supported the trial itself, spoke out against the execution of the King during the public vote at the Convention – he proposed to send the king to the galleys. From that moment on, he was usually considered a Girondin. The Montagnards were becoming more and more influential in the Convention as the King's "betrayal" was confirming their theories. One of them, Marie-Jean Hérault de Séchelles, a member, like Condorcet, of the Constitution's Commission, misrepresented many ideas from Condorcet's draft and presented what was called a "Montagnard Constitution". Condorcet criticized the new work, and as a result, he was branded a traitor. On 3 October 1793, a warrant was issued for Condorcet's arrest.
Arrest and death.
The warrant forced Condorcet into hiding. He hid for five (or eight) months in the house of Mme. Vernet, on Rue Servandoni, in Paris. It was there that he wrote "Esquisse d'un tableau historique des progrès de l'esprit humain" ("Sketch for a Historical Picture of the Progress of the Human Spirit"), which was published posthumously in 1795 and is considered one of the major texts of the Enlightenment and of historical thought. It narrates the history of civilization as one of progress in the sciences, shows the intimate connection between scientific progress and the development of human rights and justice, and outlines the features of a future rational society entirely shaped by scientific knowledge.
On 25 March 1794 Condorcet, convinced he was no longer safe, left his hideout and attempted to flee Paris. Two days later he was arrested in Clamart and imprisoned in Bourg-la-Reine (or, as it was known during the Revolution, "Bourg-l'Égalité", "Equality Borough" rather than "Queen's Borough"). Two days after that, he was found dead in his cell. The most widely accepted theory is that his friend, Pierre Jean George Cabanis, gave him a poison which he eventually used. However, some historians believe that he may have been murdered (perhaps because he was too loved and respected to be executed). Jean-Pierre Brancourt (in his work "L'élite, la mort et la révolution") claims that Condorcet was killed with a mixture of "Datura stramonium" and opium.
Condorcet was symbolically interred in the Panthéon in 1989, in honor of the bicentennial of the French Revolution and Condorcet's role as a central figure in the Enlightenment. However his coffin was empty. Interred in the common cemetery of Bourg-la-Reine, his remains were lost during the nineteenth century.
Family.
In 1786 Condorcet married Sophie de Grouchy, who was more than twenty years his junior. His wife, reckoned one of the most beautiful women of the day, became an accomplished salon hostess as Madame de Condorcet, and also an accomplished translator of Thomas Paine and Adam Smith. She was intelligent and well-educated, fluent in both English and Italian. The marriage was a strong one, and Sophie visited her husband regularly while he remained in hiding. Although she began proceedings for divorce in January 1794, it was at the insistence of Condorcet and Cabanis, who wished to protect their property from expropriation and to provide financially for Sophie and their young daughter, Louise 'Eliza' Alexandrine.
Condorcet was survived by his widow and their four-year-old daughter Eliza. Sophie died in 1822, never having remarried, and having published all her husband's works between 1801 and 1804. Her work was carried on by their daughter Eliza Condorcet-O'Connor, wife of former United Irishman Arthur O'Connor. The Condorcet-O'Connors brought out a revised edition between 1847 and 1849.
The Idea of Progress.
Condorcet's "Sketch for a Historical Picture of the Progress of the Human Spirit" (1795) was perhaps the most influential formulation of the idea of progress ever written. It made the Idea of Progress a central concern of Enlightenment thought. He argued that expanding knowledge in the natural and social sciences would lead to an ever more just world of individual freedom, material affluence, and moral compassion. He argued for three general propositions: that the past revealed an order that could be understood in terms of the progressive development of human capabilities, showing that humanity's "present state, and those through which it has passed, are a necessary constitution of the moral composition of humankind"; that the progress of the natural sciences must be followed by progress in the moral and political sciences "no less certain, no less secure from political revolutions"; that social evils are the result of ignorance and error rather than an inevitable consequence of human nature.
Condorcet's writings were a key contribution to the French Enlightenment, particularly his work on the Idea of Progress. Condorcet believed that through the use of our senses and communication with others, knowledge could be compared and contrasted as a way of analyzing our systems of belief and understanding. None of Condorcet's writings refer to a belief in a religion or a god who intervenes in human affairs. Condorcet instead frequently had written of his faith in humanity itself and its ability to progress with the help of philosophers such as Aristotle. Through this accumulation and sharing of knowledge he believed it was possible for any man to comprehend all the known facts of the natural world. The enlightenment of the natural world spurred the desire for enlightenment of the social and political world. Condorcet believed that there was no definition of the perfect human existence and thus believed that the progression of the human race would inevitably continue throughout the course of our existence. He envisioned man as continually progressing toward a perfectly utopian society. However, he stressed that for this to be a possibility man must unify regardless of race, religion, culture or gender.
Civic duty.
For Condorcet's republicanism the nation needed enlightened citizens and education needed democracy to become truly public. Democracy implied free citizens, and ignorance was the source of servitude. Citizens had to be provided with the necessary knowledge to exercise their freedom and understand the rights and laws that guaranteed their enjoyment. Although education could not eliminate disparities in talent, all citizens, including women, had the right to free education. In opposition to those who relied on revolutionary enthusiasm to form the new citizens, Condorcet maintained that revolution was not made to last and that revolutionary institutions were not intended to prolong the revolutionary experience but to establish political rules and legal mechanisms that would insure future changes without revolution. In a democratic city there would be no Bastille to be seized. Public education would form free and responsible citizens, not revolutionaries.
Evaluation.
Rothschild (2001) argues that Condorcet has been seen since the 1790s as the embodiment of the cold, rational Enlightenment. However she suggests his writings on economic policy, voting, and public instruction indicate different views both of Condorcet and of the Enlightenment. Condorcet was concerned with individual diversity; he was opposed to proto-utilitarian theories; he considered individual independence, which he described as the characteristic liberty of the moderns, to be of central political importance; and he opposed the imposition of universal and eternal principles. His efforts to reconcile the universality of some values with the diversity of individual opinions are of continuing interest. He emphasizes the institutions of civilized or constitutional conflict, recognizes conflicts or inconsistencies within individuals, and sees moral sentiments as the foundation of universal values. His difficulties call into question some familiar distinctions, for example between French, German, and English-Scottish thought, and between the Enlightenment and the counter-Enlightenment. There was substantial continuity between Condorcet's criticism of the economic ideas of the 1760s and the liberal thought of the early 19th century.
The Lycée Condorcet in the rue du Havre, in the 9th arrondissement of Paris is named in his honour.

</doc>
<doc id="37750" url="http://en.wikipedia.org/wiki?curid=37750" title="British North America Acts">
British North America Acts

The British North America Acts 1867–1975 are the original names of a series of Acts at the core of the constitution of Canada. They were enacted by the Parliament of the United Kingdom and the Parliament of Canada. In Canada, some of the Acts were amended or repealed by the Constitution Act, 1982. The rest were renamed in Canada as the "Constitution Acts". In the United Kingdom, those Acts that were passed by the British Parliament remain under their original names. The term "British North America" (BNA) refers to the British colonies in North America.
Constitutional change.
Canada dates its history as a country to the British North America Act, 1867, which came into effect on July 1, 1867. However, Canada was not established as fully independent, since the United Kingdom retained legislative control over Canada and full control over Canadian foreign policy. Canada did not have any foreign embassies until its first one was established in Washington, D.C., in 1931. Until 1949, changes to the British North America Acts could be made only by the British parliament. The British North America (No. 2) Act, 1949, gave the Parliament of Canada the power to make limited constitutional amendments, but full Canadian control over the constitution was not achieved until the passage of the Canada Act 1982. This long delay was in large part due to the inability to agree upon a procedure for making constitutional amendments that was acceptable to all of the provinces, in particular the Province of Quebec.
Because of this, all British North America Acts dated before 1949 were passed by the British Parliament, while some of those dated after 1949 were passed by the Canadian Parliament. When Canada patriated its constitution with the passage of the Canada Act of 1982, the existing British North America Acts were either repealed, or "modernized" and retitled as "Constitution Acts" in Canada.
French-language versions.
The fifteen BNA Acts enacted by the United Kingdom Parliament do not have official French-language versions. Only the English version is official. The five BNA Acts enacted by the Canadian Parliament do have official French-language versions, and the English-language and French-language versions are equally authoritative (as with all legislation enacted by the Canadian Parliament).
The French Constitutional Drafting Committee produced translations of all the British North America Acts, pursuant to section 55 of the Constitution Act, 1982, but these were never enacted by Parliament to make them official.
Individual Acts.
The different Acts of this series are distinguished by appending the year of their enactment. BNA Acts were passed in 1867, 1871, 1886, 1907, 1915, 1916*, 1930, 1940, 1943*, 1946*, 1949, 1949 (No. 2)*, 1951*, 1952*, 1960, 1964, 1965, 1974, 1975 and 1975 (No. 2). Those marked with (*) have since been repealed. Five of the British North America Acts were enacted by the Parliament of Canada; namely those of 1952, 1965, 1974, 1975, and 1975 (No. 2). The other fifteen were enacted by the Imperial Parliament in London.
The first Act, the British North America Act, 1867 created the self-governing (internally) Dominion of Canada. The remaining acts dealt with a variety of topics, though the majority were concerned with modifying the representation in Parliament or in the Senate of Canada as the country enlarged and changed [1886, 1915, 1943, 1946, 1952, 1974, 1975, 1975 (No. 2)], adding the newer Provinces of Manitoba, British Columbia, Saskatchewan, Alberta, and Newfoundland. Other topics include modifying the country's boundaries (1871, 1949), transfer payments (1907), temporary changes due to two world wars (1916, 1943), federal-provincial powers (1930, 1964), power over changes in the constitution [1949 (No. 2)], the creation of new social programs (1951, 1964), and mandatory retirement ages in the Canadian government (1960, 1965)
British North America Act, 1867.
The Act, also known as the BNA Act, comprises a major part of the Constitution of Canada. The Act entails the original creation of a federal dominion and sets the framework for much of the operation of the Government of Canada, including its Federal structure, the House of Commons, the Senate, the justice system, and the taxation system. In 1982, this Act was renamed the "Constitution Act, 1867", with the patriation of the constitution (having originally been enacted by the Parliament of the United Kingdom). Amendments were also made at this time: section 92A was added, giving the Provinces greater control over non-renewable natural resources.
British North America Act, 1871.
This Act gave Canada the power to establish new provinces and territories, and to change provincial boundaries with the affected province's consent. The act recognized the creation of the Province of Manitoba, and also the incorporation of Rupert's Land and the Northwest Territories into Canada. This Act also allowed the Canadian parliament and the legislatures of Ontario and Quebec to redraw the boundaries of the Province of Ontario and the Province of Quebec in order to include parts of these land acquisitions, specifically in northern (Arctic) Canada around Hudson Bay. In 1982, this Act was renamed the "Constitution Act, 1871".
British North America Act, 1886.
This Act gave parliament the authority to allow the Territories of Canada to have representation in the Canadian Senate and Canadian House of Commons. In 1982, this Act was renamed the "Constitution Act, 1886".
British North America Act, 1907.
This Act regulated transfer payments by the Federal government to the smaller provinces to support their legislatures and governments. The funds transferred were set at between C$100,000 and $250,000 depending on the province's population with an extra $100,000 a year for ten years to British Columbia. In 1982, this Act was renamed the "Constitution Act, 1907".
British North America Act, 1915.
This Act expanded the Canadian Senate by giving the Western Canadian provinces 24 Senators, the same number that had been guaranteed to Ontario, Quebec, and the Maritime Provinces. This Act also guaranteed Newfoundland six Senators should that British Domain ever join Confederation – which it did in 1949. Finally, this act amended section 51 of the British North America Act of 1867 to guarantee that no province would have fewer members of the House of Commons than it did senators. In 1982, this Act was renamed the "Constitution Act, 1915".
British North America Act, 1916.
This Act extended the duration of the 12th Canadian Parliament through October 1917, beyond the normal maximum of five years. The extension was carried out due to World War I. This Act was repealed by the Statute Law Revision Act, 1927.
British North America Act, 1930.
This Act gave the newer provinces of British Columbia, Alberta, Manitoba, and Saskatchewan rights over certain natural resources found in Federally-controlled lands. In 1982, this Act was renamed the "Constitution Act, 1930".
British North America Act, 1940.
This Act gave the Federal government jurisdiction over Unemployment Insurance thus allowing such a program to be established on a national level. An earlier attempt to create an Employment and Social Insurance Act during the Great Depression had been ruled to be unconstitutional, since unemployment assistance was judged by the courts to be a provincial responsibility. In 1982, this Act was renamed the "Constitution Act, 1940".
British North America Act, 1943.
This Act delayed redistribution of seats in the Canadian House of Commons until the end of World War II. This Act was repealed in 1982, as being completely outdated and obsolete.
British North America Act, 1946.
This Act adjusted the formula for distributing seats in the Canadian House of Commons among the provinces and territories. This Act was repealed in 1982, as having been superseded.
British North America Act, 1949.
This Act allowed for the entry of Newfoundland into the Federation of Canada as its tenth Province. This Act was renamed the Newfoundland Act when the Canadian Constitution was patriated from the United Kingdom in 1982.
This Act should not be confused with the British North America (No. 2) Act 1949 (see below).
British North America (No. 2) Act, 1949.
 granted Canada limited powers to amend its own constitution. The Parliament of Canada was thereafter allowed to amend the Canadian constitution "in many areas of its own jurisdiction" without first obtaining the consent of the British Parliament. However, the approval of the British Parliament was still needed for wider constitutional changes, such as those involving areas of provincial and Federal responsibilities. Therefore, this Act can at best be considered a "partial patriation" of the Canadian Constitution.
This Act was repealed in 1982 with the full patriation of the Canadian Constitution from the United Kingdom, and with the incorporation of a new, comprehensive procedure for amending the Constitution.
This Act is not to be confused with the British North America Act, 1949 later renamed the Newfoundland Act in 1982 - which confirmed the terms of union between Newfoundland and Canada and which made Newfoundland the tenth province.
British North America Act, 1951.
This Act gave the Federal government the power to pass legislation concerning Old Age Pensions, while also recognizing the rights of provincial legislatures to do so.
While the Canadian Parliament had established an Old Age Pension program in 1927, this was administered by the provinces and jointly funded by them. This Act of the British Parliament allowed the Federal government of Canada to administer and operate its own pension plan and allowed it to pass the "Old Age Security Act". This Act was repealed in 1982, since it had been superseded.
British North America Act, 1952.
This was the first of the British North America Acts to be enacted by the Canadian Parliament (rather than by the British Parliament). That had been made possible under the provisions of the British North America (No. 2) Act, 1949.
This Act changed the number of seats in the House of Commons and it also limited the number of seats that a province could lose due to redistribution based on the national census to 15% of its previous number of seats. This Act also gave the Yukon Territory its own Member of Parliament. This Act was repealed in 1982 as having become obsolete and superseded.
British North America Act, 1960.
This Act instituted a mandatory retirement age of 75 for all superior court judges. In 1982, this Act was renamed the "Constitution Act, 1960".
British North America Act, 1964.
This Act extended the Federal government's jurisdiction over pensions to include those of survivor's benefits and disability benefits while continuing to allow the Provinces to have their own pension programs. This amendment to the BNA Act made the Canada Pension Plan possible. In 1982, this Act was renamed the "Constitution Act, 1964".
British North America Act, 1965.
This was the second of the British North America Acts to be enacted by the Parliament of Canada. This was made possible by the provisions of the British North America (No. 2) Act, 1949.
In 1982, this Act was renamed the Constitution Act, 1965. It was introduced by the government of Prime Minister Lester B. Pearson, and it established a mandatory retirement age of 75 for all members who had been appointed to the Canadian Senate. Those who had been appointed before the passage of this Act were exempted.
British North America Act, 1974.
This was the third of the British North America Acts to be enacted by the Parliament of Canada. This had been made possible by the provisions of the British North America (No. 2) Act, 1949.
This Act changed the rules for the redistribution of seats in the Canadian House of Commons so that Quebec was allocated the fixed number of 75 seats, while other the number of seats allocated to each of the other provinces would always be determined based upon the sizes of their populations in comparison with that of Quebec. However, the Provinces continued to be guaranteed to have at least as many members of the House of Commons as Senators they had in the Senate. In 1982, this Act was renamed the "Constitution Act, 1974".
British North America Act, 1975.
This was the fourth of the British North America Acts to be enacted by the Parliament of Canada. This had been made possible by the provisions of the British North America (No. 2) Act, 1949.
This Act increased the number of representative from the Northwest Territories in the Canadian House of Commons, from one to two members. In 1982, this Act was renamed the "Constitution Act (No. 1), 1975".
British North America Act (No. 2), 1975.
This was the fifth of the British North America Acts to be enacted by the Parliament of Canada.
This Act increased the number of seats in the Canadian Senate from 102 to 104, and it allocated one seat to the Yukon Territory and one to the Northwest Territories. In 1982, this Act was renamed the "Constitution Act (No. 2), 1975".
Canada Act 1982.
This final Act of the British Parliament regarding Canada had a different name, since it renamed all of the unrepealed earlier British North America Acts, amended some of them, and repealed all others, patriated all remaining legislative and constitutional powers to Canada, and included the Constitution Act, 1982 as its schedule. It is the only UK legislation to be enacted in both English and French. It was signed by Elizabeth II and Pierre Trudeau.
External links.
 Texts on Wikisource:

</doc>
<doc id="37751" url="http://en.wikipedia.org/wiki?curid=37751" title="Turtle">
Turtle

Turtles are reptiles of the order Testudines (or Chelonii) characterised by a special bony or cartilaginous shell developed from their ribs and acting as a shield. "Turtle" may refer to the order as a whole (American English) or to fresh-water and sea-dwelling testudines (British English).
The order Testudines includes both extant (living) and extinct species. The earliest known members of this group date from million years ago, making turtles one of the oldest reptile groups and a more ancient group than snakes or crocodilians. Of the 327 known species alive today, some are highly endangered.
Turtles are ectotherms—their internal temperature varies according to the ambient environment, commonly called cold-blooded. However, because of their high metabolic rate, leatherback sea turtles have a body temperature that is noticeably higher than that of the surrounding water.
Turtles are classified as amniotes, along with other reptiles, birds, and mammals. Like other amniotes, turtles breathe air and do not lay eggs underwater, although many species live in or around water.
Turtle, tortoise or terrapin.
The word "chelonian" is popular among veterinarians, scientists, and conservationists working with these animals as a catch-all name for any member of the superorder Chelonia, which includes all turtles living and extinct, as well as their immediate ancestors. "Chelonia" is based on the Greek word χελώνη "chelone" "tortoise", "turtle" (another relevant word is χέλυς "chelys" "tortoise"), also denoting armor or interlocking shields; "testudines" on the other hand, is based on the Latin word "testudo" "tortoise". "Turtle" may either refer to the order as a whole, or to particular turtles which make up a form taxon that is not monophyletic.
The meaning of the word "turtle" differs from region to region. In North America, all chelonians are commonly called turtles, including terrapins and tortoises. In Great Britain, the word "turtle" is used for sea-dwelling species, but not for tortoises.
The term "tortoise" usually refers to any land-dwelling, non-swimming chelonian. Most land-dwelling chelonians are in the Testudinidae family, only one of the 14 extant turtle families.
"Terrapin" is used to describe several species of small, edible, hard-shell turtles, typically those found in brackish waters, and is an Algonquian word for turtle.
Some languages do not have this problem, as all of these are referred to by the same name. For example, in Spanish, the word "tortuga" is used for turtles, tortoises, and terrapins. A sea-dwelling turtle is "tortuga marina", a freshwater species "tortuga de río", and a tortoise "tortuga terrestre".
Anatomy and morphology.
The largest living chelonian is the leatherback sea turtle ("Dermochelys coriacea"), which reaches a shell length of 200 cm and can reach a weight of over 900 kg. Freshwater turtles are generally smaller, but with the largest species, the Asian softshell turtle "Pelochelys cantorii", a few individuals have been reported up to 200 cm. This dwarfs even the better-known alligator snapping turtle, the largest chelonian in North America, which attains a shell length of up to 80 cm and weighs as much as 113.4 kg.
Giant tortoises of the genera "Geochelone", "Meiolania", and others were relatively widely distributed around the world into prehistoric times, and are known to have existed in North and South America, Australia, and Africa. They became extinct at the same time as the appearance of man, and it is assumed humans hunted them for food. The only surviving giant tortoises are on the Seychelles and Galápagos Islands, and can grow to over 130 cm in length, and weigh about 300 kg.
The largest ever chelonian was "Archelon ischyros", a Late Cretaceous sea turtle known to have been up to 4.6 m long.
The smallest turtle is the speckled padloper tortoise of South Africa. It measures no more than 8 cm in length and weighs about 140 g. Two other species of small turtles are the American mud turtles and musk turtles that live in an area that ranges from Canada to South America. The shell length of many species in this group is less than 13 cm in length.
Neck withdrawral.
Turtles are divided into two groups according to how they withdraw their necks into their shells (something the ancestral "Proganochelys" could not do). The Cryptodira withdraw their necks backwards while contracting it under their spine, whereas the Pleurodira contract their necks to the side.
Head.
Most turtles that spend most of their lives on land have their eyes looking down at objects in front of them. Some aquatic turtles, such as snapping turtles and soft-shelled turtles, have eyes closer to the top of the head. These species of turtles can hide from predators in shallow water, where they lie entirely submerged except for their eyes and nostrils. Near their eyes, sea turtles possess glands that produce salty tears that rid their body of excess salt taken in from the water they drink.
Turtles have rigid beaks, and use their jaws to cut and chew food. Instead of having teeth, which they appear to have lost about 150-200 million years ago, the upper and lower jaws of the turtle are covered by horny ridges. Carnivorous turtles usually have knife-sharp ridges for slicing through their prey. Herbivorous turtles have serrated-edged ridges that help them cut through tough plants. They use their tongues to swallow food, but unlike most reptiles, they cannot stick out their tongues to catch food.
Shell.
The upper shell of the turtle is called the carapace. The lower shell that encases the belly is called the plastron. The carapace and plastron are joined together on the turtle's sides by bony structures called bridges. The inner layer of a turtle's shell is made up of about 60 bones that include portions of the backbone and the ribs, meaning the turtle cannot crawl out of its shell. In most turtles, the outer layer of the shell is covered by horny scales called scutes that are part of its outer skin, or epidermis. Scutes are made up of the fibrous protein keratin that also makes up the scales of other reptiles. These scutes overlap the seams between the shell bones and add strength to the shell. Some turtles do not have horny scutes. For example, the leatherback sea turtle and the soft-shelled turtles have shells covered with leathery skin, instead.
The rigid shell means turtles cannot breathe as other reptiles do, by changing the volume of their chest cavities via expansion and contraction of the ribs. Instead, they breathe in two ways. First, they employ buccal pumping, pulling air into their mouths, then pushing it into their lungs via oscillations of the floor of the throat. Secondly, when the abdominal muscles that cover the posterior opening of the shell contract, the internal volume of the shell increases, drawing air into the lungs, allowing these muscles to function in much the same way as the mammalian diaphragm.
The shape of the shell gives helpful clues about how a turtle lives. Most tortoises have a large, dome-shaped shell that makes it difficult for predators to crush the shell between their jaws. One of the few exceptions is the African pancake tortoise, which has a flat, flexible shell that allows it to hide in rock crevices. Most aquatic turtles have flat, streamlined shells which aid in swimming and diving. American snapping turtles and musk turtles have small, cross-shaped plastrons that give them more efficient leg movement for walking along the bottom of ponds and streams.
The color of a turtle's shell may vary. Shells are commonly colored brown, black, or olive green. In some species, shells may have red, orange, yellow, or grey markings, often spots, lines, or irregular blotches. One of the most colorful turtles is the eastern painted turtle, which includes a yellow plastron and a black or olive shell with red markings around the rim.
Tortoises, being land-based, have rather heavy shells. In contrast, aquatic and soft-shelled turtles have lighter shells that help them avoid sinking in water and swim faster with more agility. These lighter shells have large spaces called fontanelles between the shell bones. The shells of leatherback sea turtles are extremely light because they lack scutes and contain many fontanelles.
It has been suggested by Jackson (2002) that the turtle shell can function as pH buffer. To endure through anoxic conditions, such as winter periods trapped beneath ice or within anoxic mud at the bottom of ponds, turtles utilize two general physiological mechanisms. In the case of prolonged periods of anoxia, it has been shown that the turtle shell both releases carbonate buffers and uptakes lactic acid.
Skin and molting.
As mentioned above, the outer layer of the shell is part of the skin; each scute (or plate) on the shell corresponds to a single modified scale. The remainder of the skin is composed of skin with much smaller scales, similar to the skin of other reptiles. Turtles do not molt their skins all at once, as snakes do, but continuously, in small pieces. When turtles are kept in aquaria, small sheets of dead skin can be seen in the water (often appearing to be a thin piece of plastic) having been sloughed off when the animals deliberately rub themselves against a piece of wood or stone. Tortoises also shed skin, but dead skin is allowed to accumulate into thick knobs and plates that provide protection to parts of the body outside the shell.
By counting the rings formed by the stack of smaller, older scutes on top of the larger, newer ones, it is possible to estimate the age of a turtle, if one knows how many scutes are produced in a year. This method is not very accurate, partly because growth rate is not constant, but also because some of the scutes eventually fall away from the shell.
Limbs.
Terrestrial tortoises have short, sturdy feet. Tortoises are famous for moving slowly, in part because of their heavy, cumbersome shells, which restrict stride length.
Amphibious turtles normally have limbs similar to those of tortoises, except the feet are webbed and often have long claws. These turtles swim using all four feet in a way similar to the dog paddle, with the feet on the left and right side of the body alternately providing thrust. Large turtles tend to swim less than smaller ones, and the very big species, such as alligator snapping turtles, hardly swim at all, preferring to walk along the bottom of the river or lake. As well as webbed feet, turtles have very long claws, used to help them clamber onto riverbanks and floating logs upon which they bask. Male turtles tend to have particularly long claws, and these appear to be used to stimulate the female while mating. While most turtles have webbed feet, some, such as the pig-nosed turtle, have true flippers, with the digits being fused into paddles and the claws being relatively small. These species swim in the same way as sea turtles do (see below).
Sea turtles are almost entirely aquatic and have flippers instead of feet. Sea turtles fly through the water, using the up-and-down motion of the front flippers to generate thrust; the back feet are not used for propulsion, but may be used as rudders for steering. Compared with freshwater turtles, sea turtles have very limited mobility on land, and apart from the dash from the nest to the sea as hatchlings, male sea turtles normally never leave the sea. Females must come back onto land to lay eggs. They move very slowly and laboriously, dragging themselves forwards with their flippers.
Behaviour.
Senses.
Turtles are thought to have exceptional night vision due to the unusually large number of rod cells in their retinas. Turtles have color vision with a wealth of cone subtypes with sensitivities ranging from the near ultraviolet (UV A) to red. Some land turtles have very poor pursuit movement abilities, which are normally found only in predators that hunt quick-moving prey, but carnivorous turtles are able to move their heads quickly to snap.
Intelligence.
It has been reported that wood turtles are better than white rats at learning to navigate mazes. Case studies exist of turtles playing. They do however have a very low encephalization quotient (relative brain to body mass), their hard shell enable them to live without fast reflexes and elaborate predator avoidance strategies.
In the laboratory, turtles ("Pseudemys nelsoni") can learn novel operant tasks and have demonstrated a long-term memory of at least 7.5 months.
Ecology and life history.
Although many turtles spend large amounts of their lives underwater, all turtles and tortoises breathe air, and must surface at regular intervals to refill their lungs. They can also spend much or all of their lives on dry land. Aquatic respiration in Australian freshwater turtles is currently being studied. Some species have large cloacal cavities that are lined with many finger-like projections. These projections, called papillae, have a rich blood supply, and increase the surface area of the cloaca. The turtles can take up dissolved oxygen from the water using these papillae, in much the same way that fish use gills to respire.
Like other reptiles, turtles lay eggs which are slightly soft and leathery. The eggs of the largest species are spherical, while the eggs of the rest are elongated. Their albumen is white and contains a different protein from bird eggs, such that it will not coagulate when cooked. Turtle eggs prepared to eat consist mainly of yolk. In some species, temperature determines whether an egg develops into a male or a female: a higher temperature causes a female, a lower temperature causes a male. Large numbers of eggs are deposited in holes dug into mud or sand. They are then covered and left to incubate by themselves. Depending on the species, the eggs will typically take 70–120 days to hatch. When the turtles hatch, they squirm their way to the surface and head toward the water. There are no known species in which the mother cares for her young.
Sea turtles lay their eggs on dry, sandy beaches. Immature sea turtles are not cared for by the adults. Turtles can take many years to reach breeding age, and in many cases breed every few years rather than annually.
Researchers have recently discovered a turtle’s organs do not gradually break down or become less efficient over time, unlike most other animals. It was found that the liver, lungs, and kidneys of a centenarian turtle are virtually indistinguishable from those of its immature counterpart. This has inspired genetic researchers to begin examining the turtle genome for longevity genes.
A group of turtles is known as a bale.
Diet.
A turtle's diet varies greatly depending on the environment in which it lives. Adult turtles typically eat aquatic plants; invertebrates such as insects, snails and worms; and have been reported to occasionally eat dead marine animals. Several small freshwater species are carnivorous, eating small fish and a wide range of aquatic life. However, protein is essential to turtle growth and juvenile turtles are purely carnivorous.
Sea turtles typically feed on jellyfish, sponge and other soft-bodied organisms. Some species of sea turtle with stronger jaws have been observed to eat shellfish while some species, such as the green sea turtle do not eat any meat at all and, instead, have a diet largely made up of algae.
Systematics and evolution.
The first proto-turtles are believed to have existed in the late Triassic Period of the Mesozoic era, about 220 million years ago, and their shell, which has remained a remarkably stable body plan, is thought to have evolved from bony extensions of their backbones and broad ribs that expanded and grew together to form a complete shell that offered protection at every stage of its evolution, even when the bony component of the shell was not complete. This is supported by fossils of the freshwater "Odontochelys semitestacea" or "half-shelled turtle with teeth", from the late Triassic, which have been found near Guangling in southwest China. "Odontochelys" displays a complete bony plastron and an incomplete carapace, similar to an early stage of turtle embryonic development. Prior to this discovery, the earliest-known fossil turtle ancestors, like "Proganochelys", were terrestrial and had a complete shell, offering no clue to the evolution of this remarkable anatomical feature. By the late Jurassic, turtles had radiated widely, and their fossil history becomes easier to read.
Their exact ancestry has been disputed. It was believed they are the only surviving branch of the ancient evolutionary grade Anapsida, which includes groups such as procolophonids, millerettids, protorothyrids, and pareiasaurs. All anapsid skulls lack a temporal opening, while all other extant amniotes have temporal openings (although in mammals the hole has become the zygomatic arch). The millerettids, protorothyrids, and pareiasaurs became extinct in the late Permian period, and the procolophonoids during the Triassic.
However, it was later suggested the anapsid-like turtle skull may be due to reversion rather than to anapsid descent. More recent morphological phylogenetic studies with this in mind placed turtles firmly within diapsids, slightly closer to Squamata than to Archosauria. All molecular studies have strongly upheld the placement of turtles within diapsids; some place turtles within Archosauria, or, more commonly, as a sister group to extant archosaurs, though an analysis conducted by Lyson "et al." (2012) recovered turtles as the sister group of lepidosaurs instead. Reanalysis of prior phylogenies suggests they classified turtles as anapsids both because they assumed this classification (most of them studying what sort of anapsid turtles are) and because they did not sample fossil and extant taxa broadly enough for constructing the cladogram. "Testudines" were suggested to have diverged from other diapsids between 200 and 279 million years ago, though the debate is far from settled. Even the traditional placement of turtles outside Diapsida cannot be ruled out at this point. A combined analysis of morphological and molecular data conducted by Lee (2001) found turtles to be anapsids (though a relationship with archosaurs couldn't be statistically rejected). Similarly, a morphological study conducted by Lyson "et al." (2010) recovered them as anapsids most closely related to "Eunotosaurus". A molecular analysis of 248 nuclear genes from 16 vertebrate taxa suggests that turtles are a sister group to birds and crocodiles (the Archosauria). The date of separation of turtles and birds and crocodiles was estimated to be million years ago. The most recent common ancestor of living turtles, corresponding to the split between Pleurodira and Cryptodira, was estimated to have occurred around million years ago. The oldest definitive crown-group turtle (member of the modern clade Testudines) is the species "Caribemys oxfordiensis" from the late Jurassic period (Oxfordian stage). Through utilizing the first genomic-scale phylogenetic analysis of ultraconserved elements (UCEs) to investigate the placement of turtles within reptiles, Crawford et al. (2012) also suggest that turtles are a sister group to birds and crocodiles (the Archosauria).
The first genome-wide phylogenetic analysis was completed by Wang et al. (2013). Using the draft genomes of "Chelonia mydas" and "Pelodiscus sinensis," the team used the largest turtle data set to date in their analysis and concluded that turtles are likely a sister group of crocodilians and birds (Archosauria). This placement within the diapsids suggests that the turtle lineage lost diapsid skull characteristics as it now possesses an anapsid skull.
The earliest known fully shelled member of the turtle lineage is the late Triassic "Proganochelys". This genus already possessed many advanced turtle traits, and thus probably indicates many millions of years of preceding turtle evolution. It lacked the ability to pull its head into its shell, had a long neck, and had a long, spiked tail ending in a club. While this body form is similar to that of ankylosaurs, it resulted from convergent evolution.
Turtles are divided into two extant suborders: the Cryptodira and the Pleurodira. The Cryptodira is the larger of the two groups and includes all the marine turtles, the terrestrial tortoises, and many of the freshwater turtles. The Pleurodira are sometimes known as the side-necked turtles, a reference to the way they withdraw their heads into their shells. This smaller group consists primarily of various freshwater turtles.
Fossil record.
Turtle fossils of hatchling and nestling size have been documented in the scientific literature. Paleontologists from North Carolina State University have found the fossilized remains of the world's largest turtle in a coal mine in Colombia. The specimen named as "Carbonemys cofrinii" is around 60 million years old and nearly 8 ft long.
On a few rare occasions, paleontologists have succeeded in unearthing large numbers of Jurassic or Cretaceous turtle skeletons accumulated in a single area (the Nemegt Formation in Mongolia, the Turtle Graveyard in North Dakota, or the Black Mountain Turtle Layer in Wyoming). The most spectacular find of this kind to date occurred in 2009 in Shanshan County in Xinjiang, where over a thousand ancient freshwater turtles apparently died after the last water hole in an area dried out during a major drought.
Genomics.
Turtles possess diverse chromosome numbers (2N = 28-66) and a myriad of chromosomal rearrangements have occurred during evolution.
In captivity.
Turtles, particularly small terrestrial and freshwater turtles, are commonly kept as pets. Among the most popular are Russian tortoises, spur-thighed tortoises, and red-eared sliders.
In the United States, due to the ease of contracting salmonellosis through casual contact with turtles, the U.S. Food and Drug Administration (FDA) established a regulation in 1975 to discontinue the sale of turtles under 4 in.
It is illegal in every state in the U.S. for anyone to sell any turtles under 4 in long. Many stores and flea markets still sell small turtles due to a loophole in the FDA regulation which allows turtles under 4 in to be sold for educational purposes.
Some states have other laws and regulations regarding possession of red-eared sliders as pets because they are looked upon as invasive species or pests where they are not native, but have been introduced through the pet trade. As of July 1, 2007, it is illegal in Florida to sell any wild type red-eared slider. Unusual color varieties such as albino and pastel red-eared sliders, which are derived from captive breeding, are still allowed for sale.
As food, traditional medicine, and cosmetics.
The flesh of turtles, "calipash" or "calipee", was, and still is, considered a delicacy in a number of cultures. Turtle soup has been a prized dish in Anglo-American cuisine, and still remains so in some parts of Asia. Gopher tortoise stew was popular with some groups in Florida.
Turtles remain a part of the traditional diet on the island of Grand Cayman, so much so that when wild stocks became depleted, a turtle farm was established specifically to raise sea turtles for their meat. The farm also releases specimens to the wild as part of an effort to repopulate the Caribbean Sea.
Fat from turtles is also used in the Caribbean and in Mexico as a main ingredient in cosmetics, marketed under its Spanish name "crema de tortuga".
Turtle plastrons (the part of the shell that covers a tortoise from the bottom) are widely used in traditional Chinese medicine; according to statistics, Taiwan imports hundreds of tons of plastrons every year. A popular medicinal preparation based on powdered turtle plastron (and a variety of herbs) is the "guilinggao" jelly; these days, though, it is typically made with only herbal ingredients.
Conservation status.
In February 2011, the Tortoise and Freshwater Turtle Specialist Group published a report about the top 25 species of turtles most likely to become extinct, with a further 40 species at very high risk of becoming extinct. This list excludes sea turtles, however both the leatherback and the Kemp's ridley would make the top 25 list. The report is due to be updated in four years time allowing to follow the evolution of the list. Between 48 to 54% of all 328 of their species considered threatened, turtles and tortoises are at a much higher risk of extinction than many other vertebrates. Of the 263 species of freshwater and terrestrial turtles, 117 species are considered Threatened, 73 are either Endangered or Critically Endangered and 1 is Extinct. Of the 58 species belonging to the Testudinidae family, 33 species are Threatened, 18 are either Endangered or Critically Endangered, 1 is Extinct in the wild and 7 species are Extinct. 71% of all tortoise species are either gone or almost gone. Asian species are the most endangered, closely followed by the five endemic species from Madagascar. Turtles face many threats, including habitat destruction, harvesting for consumption, and the pet trade. The high extinction risk for Asian species is primarily due to the long-term unsustainable exploitation of turtles and tortoises for consumption and traditional Chinese medicine, and to a lesser extent for the international pet trade.
Efforts have been made by Chinese entrepreneurs to satisfy increasing demand for turtle meat as gourmet food and traditional medicine with farmed turtles, instead of wild-caught ones; according to a study published in 2007, over a thousand turtle farms operated in China. Turtle farms in Oklahoma and Louisiana raise turtles for export to China as well.
Nonetheless, wild turtles continue to be caught and sent to market in large number (as well as to turtle farms, to be used as breeding stock), resulting in a situation described by conservationists as "the Asian turtle crisis". In the words of the biologist George Amato, "the amount and the volume of captured turtles... vacuumed up entire species from areas in Southeast Asia", even as biologists still did not know how many distinct turtle species live in the region. About 75% of Asia's 90 tortoise and freshwater turtle species are estimated to have become threatened.
Harvesting wild turtles is legal in a number of states in the USA. In one of these states, Florida, just a single seafood company in Fort Lauderdale was reported in 2008 as buying about 5,000 pounds of softshell turtles a week. The harvesters (hunters) are paid about $2 a pound; some manage to catch as many as 30–40 turtles (500 pounds) on a good day. Some of the catch gets to the local restaurants, while most of it is exported to Asia. The Florida Fish and Wildlife Conservation Commission estimated in 2008 that around 3,000 pounds of softshell turtles were exported each week via Tampa International Airport.
Nonetheless, the great majority of turtles exported from the USA are farm raised. According to one estimate by the World Chelonian Trust, about 97% of 31.8 million animals harvested in the U.S. over a three-year period (November 4, 2002 – November 26, 2005) were exported. It has been estimated (presumably, over the same 2002–2005 period) that about 47% of the US turtle exports go to People's Republic of China (predominantly to Hong Kong), another 20% to Taiwan, and 11% to Mexico.
TurtleSAt is a smartphone app that has been developed in Australia in honor of World Turtle Day to help in the conservation of fresh water turtles in Australia. The app will allow the user to identify turtles with a picture guide and the location of turtles using the phones GPS to record sightings and help find hidden turtle nesting grounds. The app has been developed because there has been a high per cent of decline of fresh water turtles in Australia due to foxes, droughts, and urban development. The aim of the app is to reduce the number of foxes and help with targeting feral animal control.
References.
</dl>

</doc>
<doc id="37752" url="http://en.wikipedia.org/wiki?curid=37752" title="Éraic">
Éraic

Éraic (or "eric") was the Irish equivalent of the Welsh galanas and the Anglo-Saxon and Scandic weregild, a form of tribute paid in reparation for murder or other major crimes. The term survived into the sixteenth century as "eiric", by then relating only to compensation for the killing of an Irishman.
In Irish mythology the eraic takes an important place. In the "Oidheadh Chloinne Tuireann", the children of Tuirreann owe an eraic to Lugh. Lug set them a series of seemingly impossible quests as recompense. They achieved them all, but were fatally wounded in completing the last one.

</doc>
