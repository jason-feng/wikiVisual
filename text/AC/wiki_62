<doc id="34119" url="http://en.wikipedia.org/wiki?curid=34119" title="W. G. Grace">
W. G. Grace

William Gilbert "W. G." Grace, , (18 July 1848 – 23 October 1915) was an English amateur cricketer who was important in the development of the sport and is widely considered one of its greatest-ever players. Universally known as "W. G.", he played first-class cricket for a record-equalling 44 seasons, from 1865 to 1908, during which he captained England, Gloucestershire, the Gentlemen, Marylebone Cricket Club (MCC), the United South of England Eleven (USEE) and several other teams. He came from a cricketing family: the appearance in 1880 of W. G. with E. M. Grace, one of his elder brothers, and Fred Grace, his younger brother, was the first time three brothers played together in Test cricket.
Right-handed as both batsman and bowler, Grace dominated the sport during his career. His technical innovations and enormous influence left a lasting legacy. An outstanding all-rounder, he excelled at all the essential skills of batting, bowling and fielding, but it is for his batting that he is most renowned. He is held to have invented modern batsmanship. Usually opening the innings, he was particularly admired for his mastery of all strokes, and his level of expertise was said by contemporary reviewers to be unique. He generally captained the teams he played for at all levels because of his skill and tactical acumen.
Grace qualified as a medical practitioner in 1879. Because of his medical profession, he was nominally an amateur cricketer but he is said to have made more money from his cricketing activities than any professional cricketer. He was an extremely competitive player and, although he was one of the most famous men in England, he was also one of the most controversial on account of his gamesmanship and moneymaking.
He took part in other sports also: he was a champion 440-yard hurdler as a young man and also played football for the Wanderers. In later life, he developed enthusiasm for golf, lawn bowls and curling.
Early years.
Childhood.
W. G. Grace was born in Downend, near Bristol, on 18 July 1848 at his parents' home, Downend House, and was baptised at the local church on 8 August. He was called Gilbert in the family circle, except by his mother who called him Willie, but otherwise he was universally known by his initials W.G. His parents were Henry Mills Grace and Martha ("née" Pocock), who were married in Bristol on Thursday, 3 November 1831 and lived out their lives at Downend, where Henry Grace was the local GP. Downend is near Mangotsfield and, although it is now a suburb of Bristol, it was then "a distinct village surrounded by countryside" and about four miles from Bristol. Henry and Martha Grace had nine children in all: "the same number as Victoria and Albert – and in every respect they were the typical Victorian family". Grace was the eighth child in the family; he had three older brothers, including E.M., and four older sisters. Only Fred, born in 1850, was younger than W.G.
Grace began his "Cricketing Reminiscences" (1899) by answering a question he had frequently been asked: i.e., was he "born a cricketer"? His answer was in the negative because he believed that "cricketers are made by coaching and practice", though he adds that if he was not born a cricketer, he was born "in the atmosphere of cricket". His father and mother were "full of enthusiasm for the game" and it was "a common theme of conversation at home". In 1850, when W.G. was two and Fred was expected, the family moved to a nearby house called "The Chesnuts" which had a sizeable orchard and Henry Grace organised clearance of this to establish a practice pitch that was to become famous throughout the world of cricket. All nine children in the Grace family, including the four daughters, were encouraged to play cricket although the girls, along with the dogs, were required for fielding only. Grace claimed that he first handled a cricket bat at the age of two. It was in the Downend orchard and as members of their local cricket clubs that he and his brothers developed their skills, mainly under the tutelage of his uncle, Alfred Pocock, who was an exceptional coach. Apart from his cricket and his schooling, Grace lived the life of a country boy and roamed freely with the other village boys. One of his regular activities was stone throwing at birds in the fields and he later claimed that this was the source of his eventual skill as an outfielder.
Education.
Grace was "notoriously unscholarly". His first schooling was with a Miss Trotman in Downend village and then with a Mr Curtis of Winterbourne. He subsequently attended a day school called Rudgway House, run by a Mr Malpas, until he was fourteen. One of his schoolmasters, David Barnard, later married Grace's sister Alice. In 1863, Grace was taken seriously ill with pneumonia and his father removed him from Rudgway House. After this illness, Grace grew rapidly to his full height of 6 ft 2 in (1.88 m). He continued his education at home where one of his tutors was the Reverend John Dann, who was the Downend parish church curate; like Mr Barnard before him, Mr Dann became Grace's brother-in-law, marrying Blanche Grace in 1869.
Grace never went to university as his father was intent upon him pursuing a medical career. But Grace was approached by both Oxford University Cricket Club and Cambridge University Cricket Club. In 1866, when he played a match at Oxford, one of the Oxford players, Edmund Carter, tried to interest him in becoming an undergraduate. Then, in 1868, Grace received overtures from Caius College, Cambridge, which had a long medical tradition. Grace said he would have gone to either Oxford or Cambridge if his father had allowed it. Instead, he enrolled at Bristol Medical School in October 1868, when he was 20.
Development as a cricketer.
Henry Grace founded Mangotsfield Cricket Club in 1845 to represent several neighbouring villages including Downend. In 1846, this club merged with the West Gloucestershire Cricket Club whose name was adopted until 1867. It has been said that the Grace family ran the West Gloucestershire "almost as a private club". Henry Grace managed to organise matches against Lansdown Cricket Club in Bath, which was the premier West Country club. West Gloucestershire fared poorly in these games and, sometime in the 1850s, Henry and Alfred Pocock decided to join Lansdown, although they continued to run the West Gloucestershire and this remained their primary club.
Alfred Pocock was especially instrumental in coaching the Grace brothers and spent long hours with them on the practice pitch at Downend. E.M., who was seven years older than W.G., had always played with a full size bat and so developed a tendency, that he never lost, to hit across the line, the bat being too big for him to "play straight". Pocock recognised this problem and determined that W.G. and his youngest brother Fred should not follow suit. He therefore fashioned smaller bats for them, to suit their sizes, and they were taught to play straight and "learn defence, with the left shoulder well forward", before attempting to hit.
Grace recorded in his "Reminiscences" that he saw his first great cricket match in 1854 when he was barely six years old, the occasion being a game between William Clarke's All-England Eleven (the AEE) and twenty-two of West Gloucestershire. He says he himself played for the West Gloucestershire club as early as 1857, when he was nine years old, and had 11 innings in 1859. The earliest match in "CricketArchive" which involved Grace was in 1859, only a few days after his eleventh birthday, when he played for Clifton Cricket Club against the South Wales Cricket Club at Durdham Down, his team winning by 114 runs. Several members of the Grace family, including his elder brother E.M., were involved in the match. Grace batted at number 11 and scored 0 and 0 not out. The first time he made a substantial score was in July 1860 when he scored 51 for West Gloucestershire against Clifton; he wrote that none of his great innings gave him more pleasure. It was through E.M. that the family name first became famous. His mother, Martha, wrote the following in a letter to William Clarke's successor George Parr in 1860 or 1861:
"I am writing to ask you to consider the inclusion of my son, E. M. Grace – a splendid hitter and most excellent catch – in your England XI. I am sure he would play very well and do the team much credit. It may interest you to learn that I have another son, now twelve years of age, who will in time be a much better player than his brother because his back stroke is sounder, and he always plays with a straight bat".
Grace was just short of his thirteenth birthday when, on 5 July 1861, he made his debut for Lansdown and played two matches that month. E.M. had made his debut in 1857, aged sixteen. In August 1862, aged 14, Grace played for West Gloucestershire against a Devonshire team. A year later, following his bout of pneumonia which had left him bed-ridden for several weeks, he scored 52 not out and took 5 wickets against a Somerset XI. Soon afterwards, he was one of four family members who played for Bristol and Didcot XVIII against the All-England Eleven. He bowled well and scored 32 off the bowling of John Jackson, George Tarrant and Cris Tinley. E.M. took ten wickets in the match, which Bristol and Didcot won by an innings, and as a result E.M. was invited to tour Australia a few months later with George Parr's England team.
E.M. did not return from Australia until July 1864 and his absence presented Grace with an opportunity to appear on cricket's greatest stages. He and his elder brother Henry were invited to play for the South Wales Club which had arranged a series of matches in London and Sussex, though Grace wondered humorously how they were qualified to represent South Wales. It was the first time that Grace left the West Country and he made his debut appearances at both The Oval and Lord's.
Cricket career (1864 to 1914).
First-class career summary.
The details of Grace's statistical first-class career are controversial but "CricketArchive" recognises 1865 to 1908 as its span and lists 29 teams, the England national team and 28 domestic teams, represented by Grace in first-class matches. Most of these were "ad hoc" or guest appearances. In minor cricket, Grace represented upwards of forty teams. Besides playing for England in Test cricket (1880–99), the key teams in Grace's first-class career were the Gentlemen (1865–1906), All-England "aka" England (i.e., non-international; 1865–99), Marylebone Cricket Club (MCC; 1869–1904), Gloucestershire (1870–99), the United South of England Eleven (USEE; 1870–76) and London County (1900–04). Apart from the London County venture in his later years, Grace had firmly committed himself to all of these by the end of the 1870 season when he was 22.
Cricket in the 1860s underwent a revolution with the legalisation of overarm bowling in June 1864 and Grace himself said it was "no exaggeration to say that, between 1860 and 1870, English cricket passed through its most critical period" with the game in transition and "it was quite a revolutionary period so far as its rules were concerned". Grace was still 15 when the 1864 season began and had turned 20 when the 1868 season ended and he began his medical career by enrolling at Bristol Medical School on 7 October 1868. In the interim, specifically in 1866, he became widely recognised as the finest cricketer in England. Just after his eighteenth birthday in July 1866, Grace confirmed his potential with an innings of 224 not out for All-England against Surrey at The Oval. It was his maiden first-class century and, according to Harry Altham, he was "thenceforward the biggest name in cricket and the main spectator attraction with the successes (coming) thick and fast". In 1868, Grace scored two centuries in a match, only the second time in cricket history that this is known to have been done, following William Lambert in 1817. Summarising the 1868 season, Simon Rae wrote that Grace was "now indisputably the cricketer of the age, the Champion".
In 1869, Grace was made a member of MCC and scored four centuries in July, including an innings of 180 at The Oval which was achieved during the highest wicket partnership involving Grace in his entire career; he shared 283 runs for the first wicket with Bransby Cooper. Later in the month, Grace scored 122 out of 173 in difficult batting conditions during the North v. South match at Bramall Lane, famously prompting the laconic Tom Emmett to call him a "nonsuch" (i.e., a "nonpareil") and declare: "He ought to be made to play with a littler bat".
Grace had another outstanding season in 1870, during which Gloucestershire acquired first-class status, and Derek Birley records that, "scorning the puny modern fashion of moustaches", he grew the enormous black beard that made him so recognisable. In addition, his "ample girth" had developed for he weighed 15 stone (95 kg) in his early twenties. Grace was a non-smoker but he enjoyed good food and wine; many years later, when discussing the overheads incurred during Lord Sheffield's profitless tour of Australia in 1891–92, Arthur Shrewsbury commented: "I told you what wine would be drunk by the amateurs; Grace himself would drink enough to swim a ship."
According to Harry Altham, 1871 was Grace's "annus mirabilis", except that he produced another outstanding year in 1895. In all first-class matches in 1871, a total of 17 centuries were scored and Grace accounted for 10 of them, including the first century in a first-class match at Trent Bridge. He averaged 78.25 and the next best average by a batsman playing more than a single innings was 39.57, barely more than half his figure. His aggregate for the season was 2,739 runs and this was the first time that anyone had scored 2,000 first-class runs in a season; Harry Jupp was next best with 1,068. Grace produced his season's highlight in the South v North match at The Oval when he made his highest career score to date of 268, having been dismissed by Jem Shaw for nought in the first innings. It was to no avail as the match was drawn. But the occasion produced a memorable and oft-quoted comment by Jem Shaw who ruefully said: "I puts the ball where I likes and he puts it where he likes".
Grace had numerous nicknames during his career including "The Doctor", after he achieved his medical qualification, and "The Old Man", as he reached the veteran stage. He was most auspiciously nicknamed "The Champion". He was first acclaimed as "the Champion Cricketer" by "Lillywhite's Companion" in recognition of his exploits in 1871. However, Grace's great year was marred by the death of his father in December.
Grace and his younger brother Fred still lived with their mother at Downend. Their father had left just enough to maintain the family home but the onus was now on the brothers to increase their earnings from cricket to pay for their medical studies (Fred started his in the autumn of 1872). They achieved this through their involvement as match organisers of the United South of England Eleven which played six matches in the 1872 season including games in Edinburgh and Glasgow, Grace's first visit to Scotland. 1872 was a wet summer and Grace ended his season in early August so that he could join the tour of North America.
Grace became the first batsman to score a century before lunch in a first-class match when he made 134 for Gentlemen of the South "versus" Players of the South at The Oval in 1873. In the same season, he became the first player ever to complete the "double" of 1,000 runs and 100 wickets in a season. He went on to do the double eight times in all:
1873 was the year that some semblance of organisation was brought into county cricket with the introduction of a residence qualification. This was aimed principally at England's outstanding bowler James Southerton who had been playing for both Surrey and Sussex, having been born in one county and living in the other. Southerton chose to play for his county of residence, Surrey, from then on but remained the country's top bowler. The counties agreed on residence but not on a means of deciding a County Championship and so the title, known as "Champion County", remained an unofficial award until 1889. Grace's Gloucestershire had a very strong claim to this unofficial title in 1873 but consensus was that they shared it with Nottinghamshire. These two did not play each other and both were unbeaten in six matches, but Nottinghamshire won five and Gloucestershire won four.
Having toured Australia in the winter of 1873–74, Grace arrived in England on 18 May 1874 and was quickly back into domestic cricket. The 1874 season was very successful for him as he completed a second successive double. Gloucestershire again had a strong claim to the Champion County title although some sources have awarded it to Derbyshire and Grace himself said that it should have gone to Yorkshire. Another good season followed in 1875 when he again completed the double with 1,498 runs and 191 wickets. This was his most successful season as a bowler.
One of the most outstanding phases of Grace's career occurred in the 1876 season, beginning with his career highest score of 344 for Marylebone Cricket Club (MCC) v Kent at the St Lawrence Ground, Canterbury, in August. Two days after his innings at Canterbury, he made 177 for Gloucestershire v Nottinghamshire; and two days after that 318 not out for Gloucestershire v Yorkshire, these two innings against counties with exceptionally strong bowling attacks. Thus, in three consecutive innings Grace scored 839 runs and was only out twice. His innings of 344 was the first triple century scored in first-class cricket and broke the record for the highest individual score in all classes of cricket, previously held by William Ward who scored 278 in 1820. Ward's record had stood for 56 years and, within a week, Grace bettered it twice. In 1877, Gloucestershire won the unofficial championship for the third and (to date) final time, largely thanks to another outstanding season by Grace who scored 1,474 runs and took 179 wickets.
There was speculation that Grace intended to retire before the 1878 season to concentrate on his medical career, but he decided to continue playing cricket and may have been influenced by the arrival of the first Australian team to tour England in May. At Lord's on 27 May, the Australians took part in one of the most famous matches of all time when they defeated a strong MCC team, including Grace, by nine wickets in a single day's play. News of the match "spread like wildfire and created a sensation in London and throughout England". The satirical magazine "Punch" responded to it by publishing a parody of Byron's poem "The Destruction of Sennacherib" including a wry commentary on Grace's contribution:
"The Australians came down like a wolf on the fold",
"The Mary'bone Cracks for a trifle were bowled";
"Our Grace before dinner was very soon done",
"And Grace after dinner did not get a run".
There was bad feeling between Grace and some of the 1878 Australians, especially their manager John Conway; this came to a head on 20 June in a row over the services of Grace's friend Billy Midwinter, an Australian who had played for Gloucestershire in 1877. Midwinter was already in England before the main Australian party arrived and had joined them for their first match in May. On 20 June, Midwinter was at Lord's where he was due to play for the Australians against Middlesex. On the same day, the Gloucestershire team was at The Oval to play Surrey but arrived a man short. As a result, a group of Gloucestershire players led by W. G. and E. M. Grace went to Lord's and persuaded Midwinter to accompany them back to The Oval to make up their numbers. They were pursued by three of the Australians who caught them at The Oval gates where a furious altercation ensued in front of bystanders. At one point, Grace called the Australians "a damned lot of sneaks" (he later apologised). In the end, Grace got his way and Midwinter stayed with Gloucestershire for the rest of the season, although he did not play for the county against the Australians. Afterwards, the row was patched up and Gloucestershire invited the Australians to play the county team, minus Midwinter, at Clifton College. The Australians took a measure of revenge and won easily by 10 wickets, with Fred Spofforth taking 12 wickets and making the top score. It was Gloucestershire's first ever home defeat. The events at The Oval had a postscript during the following winter when W. G. and E. M. were called to account by the Gloucestershire membership because of the expenses they had claimed from Surrey for that match, and which Surrey had refused to authorise.
Despite his troubles in 1878, it was another good season for Grace on the field as he completed a sixth successive double. He made 24 first-class appearances in the season, scoring 1,151 runs, with a highest score of 116, at an average of 28.77 with 1 century and 5 half-centuries. In the field, he held 42 catches and took 152 wickets with a best analysis of 8/23. His bowling average was 14.50; he had 5 wickets in an innings 12 times and 10 wickets in a match 6 times.
Grace missed a large part of the 1879 season because he was doing the final practical for his medical qualification and, for the first time since 1869, he did not complete 1,000 runs, though he did take 105 wickets. Having qualified as a doctor in November 1879, he had to give priority to his new practice in Bristol for the next five years. As a result, his cricket sometimes had to be set aside. He had other troubles including a serious bout of mumps in 1882. He never topped the seasonal batting averages in the 1880s and from 1879 to 1882, he did not complete 1,000 runs in the season.
Grace was badly upset by the death of his brother Fred in 1880, soon after all three brothers played for England against Australia in what is retrospectively recognised as the inaugural Test match in England. Fred's death has been seen as a major factor in the subsequent decline of the Gloucestershire team. Grace made only 13 appearances in 1881. In 1882, he was in the England team that lost the famous "Ashes Match" at The Oval.
In 1883, Grace's medical priorities caused him to miss a Gentlemen v Players match for the first time since 1867. Injury problems restricted his appearances in 1884.
Grace achieved his career-best bowling analysis of 10/49 when playing for MCC against Oxford University at The Parks in 1886; and he scored 104 in his only innings to complete a rare "match double". 1886 was the last time he took 100 wickets in a season.
In 1888, Grace scored two centuries in one match v Yorkshire (148 and 153) and labelled this "my champion match". He had reduced his bowling somewhat in the last few seasons and he became an occasional bowler only from 1889. Injury problems, particularly a bad knee, took their toll in the early 1890s and Grace had his worst season in 1891 when he scored no centuries and could only average 19.76. Despite this, few doubted that he should lead the England team on its 1891–92 tour of Australia. Australia, led by Jack Blackham, won the three-match series 2–1.
Following his injury problems and loss of form in 1890 and 1891, Grace rallied somewhat during the next three seasons and reached 1,000 runs each time.
Against all expectation, Grace produced in 1895 a season that has been called his "Indian Summer". He completed his hundredth century playing for Gloucestershire against Somerset in May. Charles Townsend, his batting partner when he reached the milestone, said that as he approached his hundred: "This was the one and only time I ever saw him flustered..." Eventually Sammy Woods bowled a full toss which Grace drove for four to reach his century. He then went on to score 1,000 runs in the month, the first time this had ever been done, with scores of 13, 103, 18, 25, 288, 52, 257, 73 not out, 18 and 169 totalling 1,016 runs between 9 and 30 May. His aggregate for the whole season was 2,346 at an average of 51.00 with nine centuries. He was aged forty-six at the start of the season. Following his "Indian Summer", Grace was the sole recipient of the Wisden Cricketers of the Year award for 1896, the first of only three times that "Wisden" has restricted the award to a single player, there being normally five recipients.
By the time of his fiftieth birthday in July 1898, Grace had developed a somewhat corpulent figure and had lost his former agility, which meant he was no longer a capable fielder. He remained a very good batsman and at need a useful slow bowler, but he was clearly entering the twilight of his career and was now generally referred to as "The Old Man". As a special occasion, the MCC committee arranged the 1898 Gentlemen v Players match to coincide with his fiftieth birthday and he celebrated the event by scoring 43 and 31 not out, though handicapped by lameness and an injured hand. He terminated his association with both England and Gloucestershire in 1899 and relocated to South London where he joined the new London County club.
With the demise in 1904 of London County as a first-class team, the number of Grace's appearances dwindled over the next four seasons until he called it a day in 1908. His final appearance for the Gentlemen versus the Players was in July 1906 at The Oval. Grace made his final first-class appearance on 20–22 April 1908 for the Gentlemen of England v Surrey at The Oval, where, opening the innings, he scored 15 and 25.
Gentlemen v Players.
In 1864, having scored 5 and 38 for the South Wales club in his first match at The Oval, Grace was outstanding in the next match and scored 170 and 56 not out against the Gentlemen of Sussex at the Royal Brunswick Ground in Hove. His innings of 170 was his first-ever century in a serious match. The third match, against Marylebone Cricket Club (MCC) was Grace's debut at Lord's and he was joined by E.M. who had just disembarked from his voyage. Grace scored 50 in the first innings only three days after his sixteenth birthday.
His name now well known in cricketing circles, Grace played for Gentlemen of the South v Players of the South in June 1865 when he was still only 16 but already 6 ft 2 in (1.88 m) tall and weighing 11 st (70 kg). This match is regarded by "CricketArchive" as his first-class debut. He bowled extremely well and had match figures of 13 for 84. It was this performance that earned him his first selection for the prestigious Gentlemen v Players fixture.
During this period, before the start of Test cricket in 1877, Gentlemen v Players was the most prestigious fixture in which a player could take part. This is apart from North v South which was technically a fixture of higher quality given that the amateur Gentlemen were usually (until Grace took a hand) outclassed by the professional Players. Grace represented the Gentlemen in their matches against the Players from 1865 to 1906. It was he who enabled the amateurs to meet the paid professionals on level terms and to defeat them more often than not. His ability to master fast bowling was the key factor. Before Grace's debut in the fixture, the Gentlemen had lost 19 consecutive games; of the next 39 games they won 27 and lost only 4. In consecutive innings against the Players from 1871 to 1873, Grace scored 217, 77 and 112, 117, 163, 158 and 70. In his whole career, he scored a record 15 centuries in the fixture.
Grace's 1865 debut in the fixture did not turn the tide as the Players won at The Oval by 118 runs. He played quite well and took seven wickets in the match but could only score 23 and 12 not out. In the second 1865 match, this time at Lord's, the Gentlemen finally ended their losing streak and won by 8 wickets, but it was E. M. Grace, not W.G., who was the key factor with 11 wickets in the match. Even so, Grace made his mark by scoring 34 out of 77–2 in the second innings to steer the Gentlemen to victory.
In 1870, Grace scored 215 for the Gentlemen which was the first double century achieved in the Gentlemen v Players fixture.
Grace last played at Lord's for the Gentlemen in 1899 though he continued to represent the team at other venues until 1906.
Marylebone Cricket Club (MCC).
Grace became a member of Marylebone Cricket Club (MCC) in 1869 after being proposed by the treasurer, Thomas Burgoyne, and seconded by the secretary, Robert Allan Fitzgerald. Given an ongoing rift in the sport during the 1860s between the northern professionals and Surrey, MCC feared the loss of its authority should Grace "throw in his lot with the professionals" so it was considered vital for them and their interests to get him onside. As it happens, the dispute was nearly over but it has been said that "MCC regained its authority over the game by hanging onto W.G.'s shirt-tails". Grace wore MCC colours for the rest of his career, playing for them on an irregular basis until 1904, and their red and yellow hooped cap became as synonymous with him as his large black beard. He played for MCC on an expenses only basis but any hopes that the premier club had of keeping him firmly within the amateur ranks would soon be disappointed for his services were much in demand.
Grace, a medical student at the time, was first on the scene when George Summers received the blow on the head that caused his death four days later. This was in the MCC v Nottinghamshire match at Lord's in June 1870. Grace was fielding nearby when Summers was struck and took his pulse. Summers recovered consciousness and Grace advised him to leave the field. Summers did not go to hospital but it transpired later that his skull had been fractured. The Lord's pitch had a poor reputation for being rough, uneven and unpredictable all through the 19th century and many players including Grace considered it dangerous.
Gloucestershire.
It is generally understood that Gloucestershire County Cricket Club was formally constituted in 1870, having developed from Dr Henry Grace's West Gloucestershire club. Gloucestershire acquired first-class status when its team played against Surrey at Durdham Down near Bristol on 2, 3 & 4 June 1870. With Grace and his brothers E.M. and Fred playing, Gloucestershire won that game by 51 runs and quickly became one of the best teams in England. The club was unanimously rated Champion County in 1876 and 1877 as well as sharing the unofficial title in 1873 and staking a claim for it in 1874. Surrey and Gloucestershire played a return match at The Oval in July 1870 and Gloucestershire won this by an innings and 129 runs. Grace scored 143, sharing a second wicket partnership with Frank Townsend (89) of 234. The Grace family "ran the show" at Gloucestershire and E.M. was chosen as secretary which, as Birley points out, "put him in charge of expenses, a source of scandal that was to surface before the end of the decade". W.G., though aged only 21, was from the start the team captain and Birley puts this down to his "commercial drawing power".
In 1878, Gloucestershire made its first visit to Old Trafford Cricket Ground in July to play Lancashire and this was the match immortalised by Francis Thompson in his idyllic poem "At Lord's". In a match against Surrey at Clifton, the ball lodged in Grace's shirt after he had played it and he seized the opportunity to complete several runs before the fielders forced him to stop. He disingenuously claimed that he would have been out handled the ball if he had removed it and, following a discussion, it was agreed that three runs should be awarded.
In the 1880s, Gloucestershire declined following its heady success in the 1870s. One of the reasons was the early death of W.G.'s younger brother Fred from pneumonia in 1880, there being a view that "the county was never quite the same without him". Apart from W.G. himself, the only players of Fred Grace's calibre at this time were the leading professionals. Unlike the south-east and northern counties, Gloucestershire had neither the large home gates nor the necessary funds that could have secured the services of good quality professionals. This was at a time when a new generation of professionals was appearing with the likes of Billy Gunn, Maurice Read and Arthur Shrewsbury. As a result, Gloucestershire fell away in county competition and could no longer match Nottinghamshire, Surrey and Lancashire who had the strongest sides in the 1880s.
Grace had received an invitation from the Crystal Palace Company in London to help them form the London County Cricket Club. Grace accepted the offer and became the club's secretary, manager and captain with an annual salary of £600. As a result, he severed his connection with Gloucestershire during the 1899 season.
United South of England Eleven (USEE).
The United South of England Eleven (USEE) had been formed by Edgar Willsher in 1865 but the heyday of the travelling teams was over and their organisers were desperate to feature new attractions. Grace had played for the USEE previously and he formally joined the club in 1870 as its match organiser, for which he received payment, but he played for expenses only.
Overseas tours.
Grace made three overseas tours during his career. The first was to the United States and Canada with RA Fitzgerald's team in August and September 1872. The expenses of this tour were paid by the Montreal Club who had written to Fitzgerald the previous winter and invited him to form a team. Grace and his all-amateur colleagues made "short work of the weak teams" they faced. The team included two other future England captains in A.N. Hornby, who became a rival of Grace in future years; and the Honourable George Harris, the future Lord Harris, who became a very close friend and a most useful ally. The team met in Liverpool on 8 August and sailed on the "SS Sarmatian", docking at Quebec on 17 August. Simon Rae recounts that the bond between Grace and Harris was forged by their mutual sea-sickness. Matches were played in Montreal, Ottawa, Toronto, London, New York, Philadelphia and Boston. The team sailed back from Quebec on 27 September and arrived at Liverpool on 8 October. The tour was "a high point of (Grace's) early years" and he "retained fond memories of it" for the rest of his life, calling it "a prolonged and happy picnic" in his ghost-written "Reminiscences".
Grace visited Australia in 1873–74 as captain of "W. G. Grace's XI". On the morning of the team's departure from Southampton, Grace responded to well-wishers by saying that his team "had a duty to perform to maintain the honour of English cricket, and to uphold the high character of English cricketers". But both his and the team's performance fell well short of this goal. The tour was not a success and the only positive outcome was the fact of the tour having taken place, ten years after the previous one, as it "gave Australian cricket a much needed fillip". Most of the problems lay with Grace himself and his "overbearing personality" which quickly exhausted all personal goodwill towards him. There was also bad feeling within the team itself because Grace, who normally got on well with professional players, enforced the class divide throughout the tour. In terms of results, the team fared reasonably well following a poor start in which they were beaten by both Victoria and New South Wales. They played 15 matches in all but none are recognised as first-class.
Despite his injury problems in 1891, few doubted that Grace should captain England in Australia the following winter when he led Lord Sheffield's team to Australia in 1891–92. Australia, led by Jack Blackham, won the three-match series 2–1.
Test career.
Although the early matches were recognised retrospectively, Test cricket began in 1877 when Grace was already 28 and he made his debut in 1880, scoring England's first-ever Test century against Australia. He played for England in 22 Tests through the 1880s and 1890s, all of them against Australia, and was an automatic selection for England at home, but his only Test-playing tour of Australia was that of 1891–92.
Grace's most significant Test was England v Australia in 1882 at The Oval. Thanks to Spofforth who took 14 wickets in the match, Australia won by 7 runs and the legend of The Ashes was born immediately afterwards. Grace scored only 4 and 32 but he has been held responsible for "firing up" Spofforth. This came about through a typical piece of gamesmanship by Grace when he effected an unsporting, albeit legal, run out of Sammy Jones.
The highest Test wicket partnership involving Grace was at The Oval in 1886 when he and William Scotton scored 170 for the first wicket against Australia. Grace's own score was also 170 and was the highest in his Test career.
An oft-repeated story about Grace is that, in 1896, the Australian pace bowler Ernie Jones bowled a short-pitched delivery so close to his face that it appeared to go through the famous beard which made him so instantly recognisable. Grace reportedly reacted by demanding of Australian captain Harry Trott: "Here, what's all this?" Trott said to Jones: "Steady, Jonah". To which Jones laconically replied: "Sorry, doctor, she slipped". There are multiple variations of the story and, although some sources have recorded that the incident happened in a Test match, there is little doubt that the game in question was the tour opener at Sheffield Park. This is separately confirmed by C.B. Fry and Stanley Jackson who were both playing in the match, Jackson batting with Grace at the time.
Grace captained England in the First Test of the 1899 series against Australia at Trent Bridge, when he was 51. By this time his bulk had made him a liability in the field and, afterwards, realising his limitations all too clearly, he decided to stand down and surrendered both his place and the captaincy to Archie MacLaren. It is evident that Grace "plotted" his own omission from the England team by asking C.B. Fry, another selector who had arrived late for their meeting, if he thought that MacLaren should play in the Second Test. Fry answered: "Yes, I do." "That settles it", said Grace, and he promptly retired from international cricket. Explaining his decision later, Grace ruefully admitted of his diminished fielding skills that "the ground was getting a bit too far away".
London County.
Having ended his international career in 1899, Grace then began the last phase of his overall first-class career when he joined the new London County Cricket Club, based at Crystal Palace Park, which played first-class matches between 1900 and 1904. Grace's presence initially attracted other leading players into the team, including C. B. Fry, Ranjitsinhji and Johnny Douglas, but the increased importance of the County Championship, combined with Grace's inevitable decline in form and the lack of a competitive element in London's matches, led to reduced attendances and consequently the club lost money. Nevertheless, Grace remained an attraction and could still produce good performances. As late as 1902, though aged 54 by the end of the season, he scored 1,187 runs in first-class cricket, with two centuries, at an average of 37.09. London's final first-class matches were played in 1904 and the enterprise folded in 1908.
Later years.
Despite his age and bulk, Grace continued to play minor cricket for several years after his retirement from the first-class version. His penultimate match, and the last in which he batted, was for Eltham Cricket Club at Grove Park on 25 July 1914, a week after his 66th birthday. He contributed an undefeated 69 to a total of 155–6 declared, having begun his innings when they were 31–4. Grove Park made 99–8 in reply. The last match of any kind that Grace played in, though he neither batted nor bowled, was for Eltham v Northbrook on 8 August, a few days after the outbreak of the First World War.
On 26 August, in response to news of casualties at the Battle of Mons, Grace wrote a letter to "The Sportsman" in which he called for the immediate closure of the county cricket season and for all first-class cricketers to set an example and serve their country. It was published next day but did not, as is often supposed, bring an immediate end to the cricket season as one further round of County Championship matches was played.
Grace was reportedly distressed by the war and was known to shake his fist and shout at the German Zeppelins floating over his home in South London. When H. D. G. Leveson-Gower remonstrated that he had not allowed fast bowlers to unsettle him, Grace retorted: "I could see those beggars; I can't see these".
W. G. Grace died at Mottingham on 23 October 1915, aged 67, after suffering a heart attack. His death "shook the nation almost as much as Winston Churchill's fifty years later". He is buried in the family grave at Beckenham Crematorium and Cemetery, Kent.
Style and technique.
Grace's approach to cricket.
Grace himself had much to say about how to play cricket in his two books "Cricket" (1891) and "Reminiscences" (1899), which were both ghost-written. His fundamental opinion was that cricketers are "not born" but must be nurtured to develop their skills through coaching and practice; in his own case, he had achieved his skill through constant practice as a boy at home under the tutelage of his uncle Alfred Pocock.
Although the work ethic was of prime importance in his development, Grace insisted that cricket must also be enjoyable and freely admitted that his family all played in a way that was "noisy and boisterous" with much "chaff" (i.e., a Victorian term for teasing). W.G. and E.M. in particular were noted throughout their careers for being noisy and boisterous on the field. They were extremely competitive and always playing to win. Sometimes this went to extremes (e.g., on one occasion at school, E.M. was so upset about a decision going against him that he went home and took the stumps with him) and developed into the gamesmanship for which E.M. and W.G. were always controversial.
We in Australia did not take kindly to W.G.. For so big a man, he is surprisingly tenacious on very small points. We thought him too apt to wrangle in the spirit of a duo-decimo lawyer over small points of the game.
"Report in an Australian local newspaper, 1874"
It was because of gamesmanship and insistence on his rights, as he saw them, that Grace never enjoyed good relations with Australians in general, though he had personal friends like Billy Midwinter and Billy Murdoch. In 1874, an Australian newspaper wrote: "We in Australia did not take kindly to W.G.. For so big a man, he is surprisingly tenacious on very small points. We thought him too apt to wrangle in the spirit of a duo-decimo lawyer over small points of the game."
But he was just the same in England and even his long-term friend Lord Harris agreed that "his gamesmanship added to the fund of stories about him". The point was that Grace "approached cricket as if he were fighting a small war" and he was "out to win at all costs". The Australians understood this twenty years later when Joe Darling, touring England for the first time in 1896, said: "We were all told not to trust the Old Man as he was out to win every time and was a great bluffer".
Batting.
""W.G." was a very correct batsman. His left shoulder pointed to the bowler. He held his bat straight and brought it straight through to the ball. His beard hung right over the ball as he stroked it – the ball, I mean, not his beard. He was the most powerful straight-driver I have ever seen. When he drove at a ball I was mighty glad I was behind the stumps." 
With regard to Grace's batsmanship, C.L.R. James held that the best analysis of his style and technique was written by another top-class batsman K.S. Ranjitsinhji in his "Jubilee Book of Cricket" (co-written with C.B. Fry). Ranjitsinhji wrote that, by his extraordinary skills, Grace "revolutionised cricket and developed most of the techniques of modern batting" and was "the bible of batsmanship". Before him, batsmen would play either forward or back and make a speciality of a certain stroke. Grace "made utility the criterion of style" and incorporated both forward and back play into his repertoire of strokes, favouring only that which was appropriate to the ball being delivered at the moment. In an oft-quoted phrase, Ranjitsinhji said of Grace that "he turned the old one-stringed instrument (i.e., the cricket bat) into a many-chorded lyre" and that "the theory of modern batting is in all essentials the result of W.G.'s thinking and working on the game".
Ranjitsinhji summarised Grace's importance to the development of cricket by writing: "I hold him to be not only the finest player born or unborn, but the maker of modern batting". Cricket writer and broadcaster John Arlott, writing in 1975, supported this view by holding that Grace "created modern cricket".
But Grace's extraordinary skill had already been recognised very early in his career, especially by the professional bowlers. A very prescient comment was made by the laconic Yorkshire and England fast bowler Tom Emmett who, after playing against Grace for the first time in 1869, called him a "nonsuch" (without equal) who "ought to be made to play with a littler bat".
H.S. Altham pointed out that for most of Grace's career, he played on pitches that "the modern schoolboy would consider unfit for a house match" and on grounds without boundaries where every hit including those "into the country" had to be run in full. Rowland Bowen records that 1895, the year of Grace's "Indian Summer", was the season in which marl was first used as a binding agent in the composition of English pitches, its benefit being to ensure "good lasting wickets".
It was through Alfred Pocock's perseverance that Grace had learned to play straight and to develop a sound defence so that he would stop or leave the good deliveries and score off the poor ones. This contrasted him with E.M. who was "always a hitter" and whose basic defence was not as sound. However, as Grace's skills developed, he became a very powerful hitter himself with a full range of shots and, at his best, would score runs freely. Despite being an all-rounder, Grace was also an opening batsman.
Bowling.
As a bowler, Grace belonged to what Altham calls the "high, home and easy school of a much earlier day". Using a roundarm action, Grace was adept at varying both his pace and the arc of his slower deliveries which worked in from the leg side of the pitch. The chief feature of his bowling was the excellent length which he consistently maintained. He originally bowled at a consistently fast medium pace but in the 1870s he increasingly adopted his slower style which utilised a leg break. He called his leg break a "leg-tweeker" but he put very little break on the ball, just enough to bring it across from the batsman's legs to the wicket and he invariably posted a fielder in a strategic position on the square leg boundary, a trap which brought occasional success. He was unusual in persisting with his roundarm action throughout his career, when almost all other bowlers adopted the new overarm style.
Fielding.
In his prime, Grace was noted for his outstanding fielding and was a very strong thrower of the ball; he was once credited with throwing the cricket ball 122 yards during an athletics event at Eastbourne. He attributed this skill to his country-bred childhood in which stone throwing at crows was a daily exercise. In later life, Grace commented upon a decline in English fielding standards and blamed it on "the falling numbers of country-bred boys who strengthen their arms by throwing stones at birds in the fields".
Much of Grace's success as a bowler was due to his magnificent fielding to his own bowling; as soon as he had delivered the ball he covered so much ground to the left that he made himself into an extra mid-off and he took some extraordinary catches in this way.
In his early career, Grace generally fielded at long-leg or cover-point; later he was usually at point (see Fielding positions in cricket). In his prime, he was a fine thrower, a fast runner and a safe catcher.
Grace's amateur status.
The expenses enquiry at Gloucestershire took place in January 1879. W.G. and E.M. were forced to answer charges that they had claimed "exorbitant expenses", one of the few times that their money-making activity was seriously challenged. The claim had been submitted to Surrey regarding the controversial 1878 match in which Billy Midwinter was brought in as a late replacement, but Surrey refused to pay it and this provoked the enquiry. The Graces managed to survive "a protracted and stormy meeting" with E.M. retaining his key post as club secretary, although he was forced to liaise in future with a new finance committee and abide by stricter rules.
The incident highlighted an ongoing issue about the nominal amateur status of the Grace brothers. The amateur was, by definition, not a professional and the dictum of the amateur-dominated Marylebone Cricket Club was that "a gentleman ought not to make any profit from playing cricket". Like all amateur players, they claimed expenses for travel and accommodation to and from cricket matches, but there is plenty of evidence that the Graces made even more money by playing than their basic expenses would allow and W.G. in particular "made more than any professional". However, in his later years he had to pay for a "locum tenens" to run his medical practice while he was playing cricket and he had a reputation for treating his poorer patients without charging a fee. He was paid a salary for his roles as secretary and manager of the London County club. He was the recipient of two national testimonials. The first was presented to him by Lord Fitzhardinge at Lord's on 22 July 1879 in the form of a marble clock, two bronze ornaments and a cheque for £1,458. The second, collected by MCC, the county of Gloucestershire, the "Daily Telegraph" and "The Sportsman", amounted to £9,703 and was presented to him in 1896 in appreciation of his "Indian Summer" season of 1895.
Whatever criticisms may be made of Grace for making money for himself out of cricket, he was "punctilious in his aid when (professional players) were the beneficiaries". For example, when Alfred Shaw's benefit match in 1879 was ruined by rain, Grace insisted on donating to Shaw the proceeds of another match that had been arranged to support Grace's own testimonial fund. After the same thing happened to Edgar Willsher's benefit match, Grace took a select team to play Kent a few days later, the proceeds all going to Willsher. On another occasion, he altered the date of a Gloucestershire match so that he could travel to Sheffield and take part in a Yorkshire player's benefit match, knowing full well the impact that his appearance would have on the gate. As John Arlott recorded, "it was no uncommon sight to see outside a cricket ground":
"CRICKET MATCHAdmission 6dIf W. G. Grace playsAdmission 1/–"
Grace and his brother Fred faced financial difficulty after their father died in December 1871 as they were still living with their mother who had been left just enough to retain the family home. As medical students, they faced considerable outlay in addition to their living expenses and it became imperative for them to make what they could out of cricket, especially the United South of England Eleven. Grace as its match organiser had to find gaps in the first-class fixture list and then pull together a team to visit a location where a suitable profit could be made. It has been estimated that the standard fee paid to the USEE was £100 for a three-day match with £5 each going to the nine professionals in the team and the other £45 to W.G. and Fred: a sizeable amount in 1872 when £100 was perhaps the equivalent of £3,000-plus at the end of the 20th century. Otherwise, Grace played for expenses but these were loaded as, for example, he is known to have claimed £15 per appearance for Gloucestershire and £20 for representing the Gentlemen. Although the money he was paid is "small beer" compared with 21st-century sports stars, there is no doubt he had a comfortable living out of cricket and made far more money than any contemporary professional. To put it in context, a domestic servant earned less than £50 a year.
Grace's first-class career statistics.
According to the statistical record used by "CricketArchive", Grace's final first-class appearance in 1908 was his 870th and concluded a first-class career that had lasted 44 seasons from 1865 to 1908, equalling the record for the longest career span held by John Sherman, who played from 1809 to 1852. But according to an older version of Grace's career record, published by "Wisden" in 1916, Grace played in 878 first-class matches over the same span.
Grace himself regarded the South Wales matches in 1864 as first-class fixtures and refers to them in his "Cricketing Reminiscences" as "really big" games. He was supported in his view by "Lillywhite's Guide to Cricketers" (1865 edition) which included his innings at Hove in a list called "Scores of 100 or more made since 1850 in first-class matches". Grace's score was one of only six that exceeded 150. Despite Grace's own views on the matter, his "first-class career record" was effectively confirmed by F.S. Ashley-Cooper who produced a list of season-by-season figures to supplement Grace's obituary in the 1916 edition of "Wisden Cricketers' Almanack". These figures came to be known as Grace's "traditional" career record and granted him 126 first-class centuries, a total beaten by Jack Hobbs in 1925; it was not until Roy Webber's researches in the 1950s that Ashley-Cooper's list was challenged.
Following further research by the Association of Cricket Statisticians and Historians (ACS) in the 1970s and 1980s, an "amended" career record was published which reduced Grace's total of centuries to 124. This was challenged, for historical reasons, by "Wisden" in 1983 and the current situation re this controversy is that both sides generally accept each other's views. For example, Rae points out that the statisticians are right to criticise Victorian compilers for "including minor matches to enable Grace to reach certain milestones"; but he also respects the view of Grace's contemporaries that "any match in which he played was elevated in status by his very presence".
Other sports.
Grace was an outstanding athlete as a young man and won the 440 yards hurdling title at the National Olympian Games at Crystal Palace in August 1866. In addition to running, he was an excellent thrower as evidenced when he threw a cricket ball 122 yards during an athletics event at Eastbourne.
Grace played football for the Wanderers on several occasions although he did not feature in any of their FA Cup-winning teams.
In later life, after his family moved to Mottingham, Kent, he became very interested in lawn bowls. He founded the English Bowling Association in 1903 and became its first president. He helped found an international competition with Scotland, Ireland and Wales, captaining England from the inaugural international at Crystal Palace in 1903 until 1908. He was also keen on curling. His interest in golf brought him into intimate contact with one of his biographers Bernard Darwin, who said that Grace played golf "with a mixture of keen seriousness and cheerful noisiness". He could drive straight and sometimes putt well but, for reasons that Darwin could not understand, "he never could play an iron shot well".
Personal life and medical career.
Importance of family.
Despite living in London for many years, Grace never lost his Gloucestershire accent. His entire life, including his cricket and medical careers, is inseparable from his close-knit family background which was strongly influenced by his father Henry Grace, who set great store by qualifications and was determined to succeed. He passed this attitude on to each of his five sons. Therefore, like his father and his brothers, Grace chose a professional career in medicine, though because of his cricketing commitments he did not complete his qualification as a doctor until 1879 when he was 31 years old.
Grace's married life and summary of his medical career.
Grace was married on 9 October 1873 to Agnes Nicholls Day (1853–1930), who was the daughter of his first cousin William Day. Two weeks later, they began their honeymoon by taking ship to Australia for Grace's 1873–74 tour. They returned from the tour in May 1874 with Agnes six months pregnant. Their eldest son William Gilbert junior (1874–1905) was born on 6 July. Grace had to catch up with his studies at Bristol Medical School and he and his wife and son lived at Downend until February 1875 with his mother, brother Fred and sister Fanny.
The Graces moved to London in February 1875 when W. G. was assigned to St Bartholomew's Hospital and lived at Earl's Court, about five miles from the City. Their second son Henry Edgar (1876–1937) was born in London in July 1876. A ward in the Queen Elizabeth II Wing at St. Bartholomew's Hospital still bears the name "W. G. Grace Ward", caring for patients recovering from cardiothoracic surgery. In the autumn of 1877, the family moved back to Gloucestershire where they lived with Grace's elder brother Henry, who was a general practitioner. Grace's studies had reached a crucial point with a theoretical backlog to catch up followed by his final practical session. Agnes became pregnant again at this time and their third child Bessie (1878–98) was born in May 1878.
Following the 1878 season, Grace was assigned to Westminster Hospital Medical School for his final year of medical practice and this curtailed his cricket for a time as he did not play in the 1879 season until June. The family moved back to London and lived at Acton. But the upheaval was worthwhile because, in November 1879, Grace finally received his diploma from the University of Edinburgh, having qualified as a Licentiate of the Royal College of Physicians (LRCP) and became a Member of the Royal College of Surgeons (MRCS). After qualifying he worked both in his own practice at Thrissle Lodge, 61 Stapleton Road in Easton, a largely poor district of Bristol, employing two locums during the cricket season. He was the local Public Vaccinator and had additional duties as the Medical Officer to the Barton Regis Union, which involved tending patients in the workhouse.
There are many testimonies from his patients that he was a good doctor, for example: "Poor families knew that they did not need to worry about calling him in, as the bills would never arrive". The family lived at four different addresses close to the practice over the next twenty years and their fourth and last child Charles Butler (1882–1938) was born.
After leaving Gloucestershire in 1900, the Graces lived in Mottingham, a south-east London suburb, not far from the Crystal Palace where he played for London County, or from Eltham where he played club cricket in his sixties. A blue plaque marks their residence, 'Fairmount', in Mottingham Lane.
Personal tragedies.
Grace endured a number of tragedies in his life beginning with the death of his father in December 1871. He was badly upset by the early death of his younger brother Fred in 1880, only two weeks after he, W. G. and E. M. had all played in a Test for England against Australia. In July 1884, Grace's rival A. N. Hornby stopped play in a Lancashire v Gloucestershire match at Old Trafford so that E. M. and W. G. could return home on receipt of a cable reporting the death of Mrs Martha Grace at the age of 72. The greatest tragedy of Grace's life was the loss of his daughter Bessie in 1898, aged only 20, from typhoid. She had been his favourite child. Then, in February 1905, his eldest son W. G. junior died of appendicitis at the age of 30.
Legacy.
MCC decided to commemorate Grace's life and career with a "Memorial Biography", published in 1919. Its preface begins with this passage:"Never was such a band of cricketers gathered for any tour as has assembled to do honour to the greatest of all players in the present Memorial Biography. That such a volume should go forth under the auspices of the Committee of MCC is in itself unique in the history of the game, and that such an array of cricketers, critics and enthusiasts should pay tribute to its finest exponent has no parallel in any other branch of sport. In itself this presents a noble monument of what W. G. Grace was, a testimony to his prowess and to his personality".
In 1923, the W. G. Grace Memorial Gates were erected at the St John's Wood Road entrance to Lord's. They were designed by Sir Herbert Baker and the opening ceremony was performed by Sir Stanley Jackson, who had suggested the inclusion of the words "The Great Cricketer" in the dedication. On 12 September 2009, Grace was posthumously inducted into the ICC Cricket Hall of Fame at Lord's. Two of his direct descendants attended the ceremony: Dominic, his great-great-grandson; and George, Dominic's son.
According to Mark Bonham-Carter, H. H. Asquith's grandson, Grace would have been one of the people to be appointed a peer had Asquith's plan to flood the House of Lords with Liberal peers come to fruition. British commemorative postage stamps issued on 16 May 1973 for the County Cricket Centenary featured three sketches of W. G. Grace by Harry Furniss. The values were threepence (then first-class post); seven pence halfpenny; and ninepence. Grace's fame has endured and his large beard in particular remains familiar; for example, "Monty Python and the Holy Grail" uses his image as "the face of God" during the sequence in which God sends the knights out on their quest for the grail.
In many of the tributes paid to Grace, he was referred to as "The Great Cricketer". H S Altham, for one, described him as "the greatest of all cricketers". John Arlott summarised him as "timeless" and "the greatest (cricketer) of them all". The anti-establishment writer C. L. R. James, in his classic work "Beyond a Boundary", included a section "W.G.: Pre-Eminent Victorian", containing four chapters and covering some sixty pages. He declared Grace "the best-known Englishman of his time" and aligned him with Thomas Arnold and Thomas Hughes as "the three most eminent Victorians". James wrote of cricket as "the game he (Grace) transformed into a national institution". Simon Rae also commented upon Grace's eminence in Victorian England by saying that his public recognition was equalled only by Queen Victoria herself and William Ewart Gladstone.
The inaugural edition of "Playfair Cricket Annual" in 1948 coincided with the centenary of Grace's birth and carried a tribute which spoke of Grace as "King in his own domain" and his "Olympian personality". "Playfair" went on to say how Grace had "pulverised fast bowling on chancy pitches" and had then "astonished the world" by his deeds during the 1895 "Indian Summer". In the foreword of the same edition, C. B. Fry insisted that Grace would not have started the 1948 season with any notion of being beaten by that season's Australian touring team, for "he was sanguine" and would have put everything he could muster into the task of beating them with no acceptance of defeat "till after it happened". As mentioned in "Playfair", both MCC and Gloucestershire arranged special matches on Grace's birthday to commemorate his centenary.
In the 1963 edition of "Wisden Cricketers' Almanack", Grace was selected by Neville Cardus as one the Six Giants of the Wisden Century. This was a special commemorative selection requested by "Wisden" for its 100th edition. The other five players chosen were Sydney Barnes, Don Bradman, Jack Hobbs, Tom Richardson and Victor Trumper.
Derek Birley, who devoted whole passages of his book to criticism of Grace's gamesmanship and moneymaking, wrote that the "bleakness (of the war) was exemplified in November ("sic") 1915 by the death of Grace, which seemed depressingly emblematic of the end of an era". Rowland Bowen wrote that "many of Grace's achievements would be rated extremely good by our standards" but "by the standards of his day they were "phenomenal": nothing like them had ever been done before". David Frith summed up Grace's legacy to cricket by writing that "his influence lasted long after his final appearance in first-class cricket in 1908 and his death in 1915". "For decades", wrote Frith, "Grace had been arguably the most famous man in England", easily recognisable because of "his beard and his bulk", and revered because of "his batsmanship". Even though his records have been overtaken, "his pre-eminence has not" and he remains "the most famous cricketer of them all", the one who "elevated the game in public esteem".
He is buried at Beckenham Cemetery in Elmers End Rd, Beckenham, Kent. A Public House named after Dr. Grace was built next to the cemetery.
Footnote.
• a)^ As described in Grace's first-class career statistics, there are different versions of Grace's first-class career totals as a result of disagreement among cricket statisticians re the status of some matches he played in. Note that this is a statistical issue only and has little, if any, bearing on the historical aspects of Grace's career. In the infobox, the "traditional" first-class figures from "Wisden 1916" (as reproduced by Rae, pp. 495–496), are given first and the "amended" figures from "CricketArchive" follow in parentheses. There is no dispute about Grace's Test career record and those statistics are universally recognised. See Variations in first-class cricket statistics for more information.
</dl>
Bibliography.
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Grace
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Grace
 |{{
 #if: 1891
 |, 1891{{
 #if:
}}{{
 #if: 
 #ifeq: | 1891
 |{{
 #if: 
 #if: Grace
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Grace |&rft.aulast={{urlencode:Grace}}{{
 }}{{
 #if: Grace |&rft.au={{urlencode:Grace}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Cricket
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = 
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = J. W. Arrowsmith. Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
</dl>
Further reading.
</dl>

</doc>
<doc id="34121" url="http://en.wikipedia.org/wiki?curid=34121" title="World Tourism Organization">
World Tourism Organization

The United Nations World Tourism Organization (UNWTO) is the United Nations agency responsible for the promotion of responsible, sustainable and universally accessible tourism. It is the leading international organization in the field of tourism, which promotes tourism as a driver of economic growth, inclusive development and environmental sustainability and offers leadership and support to the sector in advancing knowledge and tourism policies worldwide. It encourages the implementation of the Global Code of Ethics for Tourism to maximize the contribution of tourism to socio-economic development, while minimizing its possible negative impacts, and is committed to promoting tourism as an instrument in achieving the United Nations Millennium Development Goals (MDGs), geared towards reducing poverty and fostering sustainable development.
UNWTO generates market knowledge, promotes competitive and sustainable tourism policies and instruments, fosters tourism education and training, and works to make tourism an effective tool for development through technical assistance projects in over 100 countries around the world.
UNWTO’s membership includes 156 countries, 6 territories and over 400 affiliate members representing the private sector, educational institutions, tourism associations and local tourism authorities. Its headquarters are located in Madrid.
Organizational aims.
The objectives of the UNWTO are to promote and develop sustainable tourism so as to contribute to economic development, international understanding, peace, prosperity and universal respect for, and observance of, human rights and fundamental freedoms for all, without distinction as to race, sex, language or religion. In pursuing these aims, UNWTO pays particular attention to the interests of developing countries in the field of tourism.
History.
The origin of UNWTO stems back to 1925 when the International Congress of Official Tourist Traffic Associations (ICOTT) was formed at The Hague. Some articles from early volumes of the Annals of Tourism Research, claim that the UNWTO originated from the International Union of Official Tourist Publicity Organizations (IUOTPO), although the UNWTO states that the ICOTT became the International Union of Official Tourist Publicity Organizations first in 1934.
Following the end of the Second World War and with international travel numbers increasing, the IUOTPO restructured itself into the International Union of Official Travel Organizations (IUOTO). A technical, non-governmental organization, the IUOTO was made up of a combination of national tourist organizations, industry and consumer groups. The goals and objectives of the IUOTO were to not only promote tourism in general but also to extract the best out of tourism as an international trade component and as an economic development strategy for developing nations.
Towards the end of the 1960s, the IUOTO realized the need for further transformation to enhance its role on an international level. The 20th IUOTO general assembly in Tokyo, 1967, declared the need for the creation of an intergovernmental body with the necessary abilities to function on an international level in cooperation with other international agencies, in particular the United Nations. Throughout the existence of the IUOTO, close ties had been established between the organization and the United Nations (UN) and initial suggestions had the IUOTO becoming part of the UN. However, following the circulation of a draft convention, consensus held that any resultant intergovernmental organization should be closely linked to the UN but preserve its "complete administrative and financial autonomy".
It was on the recommendations of the UN that the formation of the new intergovernmental tourism organization was based. Resolution 2529 of the XXIVth UN general assembly stated:
In 1970, the IUOTO general assembly voted in favor of forming the World Tourism Organization (WTO). Based on statutes of the IUOTO, and after ratification by the prescribed 51 states, the WTO came into operation on November 1, 1974.
Most recently, at the fifteenth general assembly in 2003, the WTO general council and the UN agreed to establish the WTO as a specialized agency of the UN. The significance of this collaboration, WTO Secretary-General Mr. Francesco Frangialli claimed, would lie in "the increased visibility it gives the WTO, and the recognition that will be accorded to [it].Tourism will be considered on an equal footing with other major activities of human society".
Members.
s of 2013[ [update]], the membership of the UNWTO included 156 states, six associate members (Flemish Community (1997), Puerto Rico (2002), Aruba (1987), Hong Kong (1999), Macau (1981), Madeira (1995)), and two observers (Holy See (1979), Palestine (1999)). Seventeen state members have withdrawn from the organization for different periods in the past: Australia, Bahamas, Bahrain, Belgium, Canada, Costa Rica, El Salvador, Grenada, Honduras, Kuwait, Malaysia, Myanmar, Panama, Philippines, Qatar, Thailand and Puerto Rico (as an associate member). Most of them have rejoined. The Netherland Antilles was an associate member before its dissolution.
Former members are: Belgium (until 1997), Canada (until 2012), Grenada (until 1997) and Latvia (2005-2012) 
Non-members are: Antigua and Barbuda, Barbados, Belgium, Belize, Comoros, Denmark, Dominica, Estonia, Finland, Grenada, Guyana, Iceland, Ireland, Kiribati, Latvia, Liechtenstein, Luxembourg, Marshall Islands, Micronesia, Nauru, New Zealand, Palau, Saint Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Samoa, Singapore, Solomon Islands, Somalia, South Sudan, Suriname, Sweden, Tonga, Tuvalu, United Arab Emirates, United Kingdom, United States.
Additionally there are some 400 affiliate members, representing the private sector, educational institutions, tourism associations and local tourism authorities, non-governmental entities with specialised interests in tourism, and commercial and non-commercial bodies and associations with activities related to the aims of UNWTO or falling within its competence.
Structure.
General Assembly.
The General Assembly is the principal gathering of the World Tourism Organization. It meets every two years to approve the budget and programme of work and to debate topics of vital importance to the tourism sector. Every four years it elects a Secretary-General. The General Assembly is composed of full members and associate members. Affiliate members and representatives of other international organizations participate as observers.
The World Committee on Tourism Ethics is a subsidiary organ of the General Assembly.
Executive Council.
The Executive Council is UNWTO's governing board, responsible for ensuring that the Organization carries out its work and adheres to its budget. It meets at least twice a year and is composed of members elected by the General Assembly in a ratio of one for every five full members. As host country of UNWTO's headquarters, Spain has a permanent seat on the Executive Council. Representatives of the associate members and affiliate members participate in Executive Council meetings as observers.
Committees.
Specialized committees of UNWTO members advise on management and programme content. These include: the Programme Committee, the Committee on Budget and Finance, the Committee on Statistics and the Tourism Satellite Account, the Committee on Market and Competitiveness, the Sustainable Development of Tourism Committee, the World Committee on Tourism Ethics, the Committee on Poverty Reducction and the Committee for the Review of applications for affiliate membership.
Secretariat.
The Secretariat is led by Secretary-General Taleb Rifai of Jordan, who supervises about 110 full-time staff at UNWTO's Madrid headquarters. These officials are responsible for implementing UNWTO's programme of work and serving the needs of members. The affiliate members are supported by a full-time Executive Director at the Madrid headquarters. The Secretariat also includes a regional support office for Asia-Pacific in Osaka, Japan, financed by the Japanese Government. The official languages of UNWTO are Arabic, English, French, Chinese, Russian and Spanish.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="34122" url="http://en.wikipedia.org/wiki?curid=34122" title="Wacław Sierpiński">
Wacław Sierpiński

Wacław Franciszek Sierpiński (]) (March 14, 1882 – October 21, 1969) was a Polish mathematician. He was known for outstanding contributions to set theory (research on the axiom of choice and the continuum hypothesis), number theory, theory of functions and topology. He published over 700 papers and 50 books.
Three well-known fractals are named after him (the Sierpinski triangle, the Sierpinski carpet and the Sierpinski curve), as are Sierpinski numbers and the associated Sierpiński problem.
Education.
Sierpiński enrolled in the Department of Mathematics and Physics at the University of Warsaw in 1899 and graduated four years later. In 1903, while still at the University of Warsaw, the Department of Mathematics and Physics offered a prize for the best essay from a student on Voronoy's contribution to number theory. Sierpiński was awarded a gold medal for his essay, thus laying the foundation for his first major mathematical contribution. Unwilling for his work to be published in Russian, he withheld it until 1907, when it was published in Samuel Dickstein's mathematical magazine 'Prace Matematyczno-Fizyczne' (Polish: 'The Works of Mathematics and Physics').
After his graduation in 1904, Sierpiński worked as a school teacher of mathematics and physics in Warsaw. However, when the school closed because of a strike, Sierpiński decided to go to Kraków to pursue a doctorate. At the Jagiellonian University in Kraków he attended lectures by Stanisław Zaremba on mathematics. He also studied astronomy and philosophy. He received his doctorate and was appointed to the University of Lwów in 1908.
Contributions to mathematics.
In 1907 Sierpiński first became interested in set theory when he came across a theorem which stated that points in the plane could be specified with a single coordinate. He wrote to Tadeusz Banachiewicz (then at Göttingen), asking how such a result was possible. He received the one-word reply 'Cantor'. Sierpiński began to study set theory and, in 1909, he gave the first ever lecture course devoted entirely to the subject.
Sierpiński maintained an incredible output of research papers and books. During the years 1908 to 1914, when he taught at the University of Lwów, he published three books in addition to many research papers. These books were "The Theory of Irrational Numbers" (1910), "Outline of Set Theory" (1912), and "The Theory of Numbers" (1912). 
When World War I began in 1914, Sierpiński and his family were in Russia. To avoid the persecution that was common for Polish foreigners, Sierpiński spent the rest of the war years in Moscow working with Nikolai Luzin. Together they began the study of analytic sets. In 1916, Sierpiński gave the first example of an absolutely normal number.
When World War I ended in 1918, Sierpiński returned to Lwów. However shortly after taking up his appointment again in Lwów he was offered a post at the University of Warsaw, which he accepted. In 1919 he was promoted to a professor. He spent the rest of his life in Warsaw. 
During the Polish–Soviet War (1919–1921), Sierpiński helped break Soviet Russian ciphers for the Polish General Staff's cryptological agency.
In 1920, Sierpiński, together with Zygmunt Janiszewski and his former student Stefan Mazurkiewicz, founded an influential mathematical journal Fundamenta Mathematica. Sierpiński edited the journal, which specialized in papers on set theory. 
During this period, Sierpiński worked predominantly on set theory, but also on point set topology and functions of a real variable. In set theory he made contributions on the axiom of choice and on the continuum hypothesis. He proved that Zermelo–Fraenkel set theory together with the Generalized continuum hypothesis imply the Axiom of choice. He also worked on what is now known as the Sierpinski curve. Sierpiński continued to collaborate with Luzin on investigations of analytic and projective sets. His work on functions of a real variable includes results on functional series, differentiability of functions and Baire's classification. 
Sierpiński retired in 1960 as professor at the University of Warsaw, but continued until 1967 to give a seminar on the Theory of Numbers at the Polish Academy of Sciences. He also continued editorial work as editor-in-chief of "Acta Arithmetica", and as an editorial-board member of "Rendiconti del Circolo Matematico di Palermo", "Composito Matematica", and "Zentralblatt für Mathematik".
Sierpiński is interred at the Powązki Cemetery in Warsaw, Poland.
Honors received.
Honorary Degrees: Lwów (1929), St. Marks of Lima (1930), Amsterdam (1931), Tarta (1931), Sofia (1939), Prague (1947), Wrocław (1947), Lucknow (1949), and Moscow (1967). 
For high involvement with the development of mathematics in Poland, Sierpiński was honored with election to the Polish Academy of Learning in 1921 and that same year was made dean of the faculty at the University of Warsaw. In 1928, he became vice-chairman of the Warsaw Scientific Society, and that same year was elected chairman of the Polish Mathematical Society.
He was elected to the Geographic Society of Lima (1931), the Royal Scientific Society of Liège (1934), the Bulgarian Academy of Sciences (1936), the National Academy of Lima (1939), the Royal Society of Sciences of Naples (1939), the Accademia dei Lincei of Rome (1947), the Germany Academy of Sciences (1950), the United States National Academy of Sciences (1959), the Paris Academy (1960), the Royal Dutch Academy (1961), the Academy of Science of Brussels (1961), the London Mathematical Society (1964), the Romanian Academy (1965) and the Papal Academy of Sciences (1967). 
In 1949 Sierpiński was awarded Poland's Scientific Prize, first degree.
Publications.
Sierpiński authored 724 papers and 50 books (two of which, "Introduction to General Topology" (1934) and "General Topology" (1952) have been translated into English by Canadian mathematician Cecilia Krieger).

</doc>
<doc id="34126" url="http://en.wikipedia.org/wiki?curid=34126" title="William Golding">
William Golding

Sir William Gerald Golding CBE (19 September 1911 – 19 June 1993) was an English novelist, playwright, and poet. Best known for his novel "Lord of the Flies", he won a Nobel Prize in Literature, and was also awarded the Booker Prize for literature in 1980 for his novel "Rites of Passage", the first book in what became his sea trilogy, "To the Ends of the Earth".
Golding was knighted by Elizabeth II in 1988. He was a fellow of the Royal Society of Literature. In 2008, "The Times" ranked Golding third on their list of "The 50 greatest British writers since 1945".
Biography.
Early life.
William Golding was born in his grandmother's house, 47 Mountwise, Newquay, Cornwall, and he spent many childhood holidays there. He grew up in Marlborough, Wiltshire, where his father (Alec Golding) was a science master at Marlborough Grammar School (1905 to retirement). Alec Golding was a socialist who advocated science-inspired rationalism, and the young Golding and his elder brother Joseph attended the school where his father taught. His mother, Mildred (Curnoe), kept house at 29, The Green, Marlborough, and was a campaigner for female suffrage. In 1930 Golding went to Brasenose College, Oxford, where he read Natural Sciences for two years before transferring to English Literature.
Golding took his B.A. degree with Second Class Honours in the summer of 1934, and later that year a book of his "Poems" was published by Macmillan & Co, with the help of his Oxford friend, the anthroposophist Adam Bittleston.
He was a schoolmaster teaching Philosophy and English in 1939, then just English from 1945 to 1962 at Bishop Wordsworth's School, Salisbury, Wiltshire.
Marriage and family.
Golding married Ann Brookfield, an analytic chemist,(p161) on 30 September 1939 and they had two children, Judith and David.
War service.
During World War II, Golding joined the Royal Navy in 1940. He fought (on board a destroyer) and was briefly involved in the pursuit and sinking of the German battleship "Bismarck". He also participated in the invasion of Normandy on D-Day, commanding a landing ship that fired salvoes of rockets onto the beaches, and was in action at Walcheren at which 23 out of 24 assault craft were sunk.
Death.
In 1985, Golding and his wife moved to Tullimaar House at Perranarworthal, near Truro, Cornwall. He died of heart failure eight years later, on 19 June 1993. He was buried in the village churchyard at Bowerchalke, South Wiltshire (near the Hampshire and Dorset county boundaries). He left the draft of a novel, "The Double Tongue", set in ancient Delphi, which was published posthumously. His son David continues to live at Tullimaar House.
Career.
Writing success.
In September 1953, after many rejections from other publishers, Golding sent a manuscript to Faber & Faber and was initially rejected by their reader. His book however was championed by Charles Monteith, a new editor at the firm. Monteith asked for some changes to the text and the novel was published in September 1954 as "Lord of the Flies".
After moving in 1958 from Salisbury to nearby Bowerchalke, he met his fellow villager and walking companion James Lovelock. The two discussed Lovelock's hypothesis that the living matter of the planet Earth functions like a single organism, and Golding suggested naming this hypothesis after Gaia, the goddess of the earth in Greek mythology. His publishing success made it possible for Golding to resign his teaching post at Bishop Wordsworth's School in 1961, and he spent that academic year in the United States as writer-in-residence at Hollins College, near Roanoke, Virginia.
Golding won the James Tait Black Memorial Prize in 1979, and the Booker Prize in 1980. In 1983 he was awarded the Nobel Prize for Literature, and was according to the "Oxford Dictionary of National Biography" "an unexpected and even contentious choice". In 1988 Golding was appointed as a Knight Bachelor. In September 1993, only a few months after his sudden death, the First International William Golding Conference was held in France, where Golding's presence had been promised and eagerly anticipated.
Fiction.
His first novel, "Lord of the Flies" (1954; film, 1963 and 1990; play, adapted by Nigel Williams, 1995), describes a group of boys stranded on a tropical island reverting to savagery. "The Inheritors" (1955) shows "new people" (generally identified with "Homo sapiens sapiens"), triumphing over a gentler race (generally identified with Neanderthals) by deceit and violence. His 1956 novel "Pincher Martin" records the delusions experienced by a drowning sailor in his last moments. "Free Fall" (1959) explores the issue of free choice as a prisoner held in solitary confinement in a German POW camp during World War Two looks back over his life. "The Spire" (1964) follows the building (and near collapse) of a huge spire onto a medieval cathedral (generally assumed to be Salisbury Cathedral); the spire symbolizing both spiritual aspiration and worldly vanity. In his 1967 novel "The Pyramid" three separate stories in a shared setting (a small English town in the 1920s) are linked by a narrator, and "The Scorpion God" (1971) consists of three novellas, the first set in a prehistoric African hunter-gatherer band ('Clonk, Clonk'), the second in an ancient Egyptian court ('The Scorpion God') and the third in the court of a Roman emperor ('Envoy Extraordinary'). The last of these reworks his 1958 play "The Brass Butterfly". His later novels include "Darkness Visible" (1979), which is about a terrorist group, a paedophile teacher, and a mysterious angel-like figure who survives a fire in The Blitz, "The Paper Men" (1984) which is about the conflict between a writer and his biographer, and a sea trilogy "To the Ends of the Earth", which includes the "Rites of Passage" (1980), "Close Quarters" (1987), and "Fire Down Below" (1989), the first book of which (originally intended as a stand-alone novel) won the Booker Prize.

</doc>
<doc id="34127" url="http://en.wikipedia.org/wiki?curid=34127" title="White Zombie (band)">
White Zombie (band)

White Zombie was an American heavy metal band that formed in 1985. Based in New York City, White Zombie was originally a noise rock band. White Zombie is better-known for its later heavy metal-oriented sound. The group officially disbanded in 1998. In 2000, White Zombie was included on VH1's 100 Greatest Artists of Hard Rock, ranking at No. 56.
History.
Early years.
White Zombie was co-founded by writer, vocalist and graphic artist Rob Zombie, after coming up with the band idea in 1985 while attending Parsons School of Design in his junior year. Zombie's girlfriend at the time, Sean Yseult, was the other co-founder. She had been playing the Farfisa keyboard in the band LIFE with Ivan de Prume, but the band soon broke up. Ena Kostabi owned a recording studio, which he would rent out to different bands. When he met Yseult, she asked if he could teach her to play bass. They then recruited Peter Landau to play drums and began to write and record songs. White Zombie's first release, "Gods on Voodoo Moon", was an EP and was recorded on October 18, 1985. It was released under the band's own label Silent Explosion, under which they would release most of their early work. Only 300 copies were pressed, of which only 100 were sold; the band members still retain possession of the remaining 200.
In 1986, Zombie hired Tim Jeffs, his Parsons School of Design roommate, to play guitar to replace Ena Kostabi, and Yseult brought in De Prume from their days in the band LIFE as the replacement for Landau. It was at this time the band started touring, making their live performance debut at CBGB on April 28, 1986. White Zombie released their second EP, "Pig Heaven", that year. The release contained two songs, "Pig Heaven" and "Slaughter the Grey". The EP was recorded at 6/8 Studios on Houston St and Bleecker St in NoHo in New York City. Other songs that were recorded during the session but never released were titled "Follow Wild", "Rain Insane", "Paradise Fireball" and "Red River Flow". After touring for a year in the band, Tim Jeffs left and was replaced by Tom Guay, often known as Tom Five. The band released a second pressing of "Pig Heaven" with different cover art, but retained the same recording with Jeffs on guitar. Only 500 copies of each pressing were released on vinyl.
In 1987, the band released their third EP, "Psycho-Head Blowout". Later that year, the band released their first full-length album, "Soul-Crusher", which was their first release to feature sound clips from movies in the songs, a trademark that would continue for the remainder of the band's lifespan. John Ricci replaced Tom Guay shortly after the release of "Soul-Crusher".
In 1988, the band signed to Caroline Records, permanently discontinuing their old indie label. Their second album, "Make Them Die Slowly", was released in February 1989. The album was a musical shift for White Zombie. While their previous releases had been strictly punk-influenced noise rock, "Make Them Die Slowly" had more of a heavy metal sound. This is also the first album crediting "Rob Zombie" instead of his previous stage name, "Rob 'Dirt' Straker".
Ricci's carpal tunnel syndrome severely affected his ability to play guitar, forcing him to leave the band when "Make Them Die Slowly" was finished. Jay Yuenger, or "J", replaced him before the album's release, affecting their future sound. One of the most obvious examples of this direction is the difference between the songs "Disaster Blaster" on "Make Them Die Slowly" and the re-worked version, "Disaster Blaster II", on the "God of Thunder" EP.
Major label years.
After searching for a record label and being turned down multiple times, the band turned towards RCA Records. However, Zombie opted for a recording contract with Geffen Records. Michael Alago, a representative of Geffen, became interested after hearing "God of Thunder" and watched one of their shows at Pyramid Club and liked them, mostly for their song "Soul-Crusher". The band produced a demo with the help of J. G. Thirlwell of Foetus and were signed to Geffen.
On March 17, 1992, White Zombie released ', the album which launched them into mainstream recognition. White Zombie began a two-and-a-half-year-long tour for the album soon after its release, during which the band gained a large cult following. During the tour, Ivan de Prume left the band to pursue a successful career as a producer/engineer as well as drummer/percussionist and opened his own studio, Burningsound. He was replaced by Phil Buerstatte. The music video for the song "Thunder Kiss '65" went into heavy rotation on MTV in 1993. The popular TV show "Beavis and Butt-head" began featuring their music videos, boosting the band's popularity. By the end of 1993, the album had been certified gold by the RIAA. By the time the tour ended in December 1994, Zombie and Yseult had broken up, and "La Sexorcisto" had gone platinum. Due to artistic differences, Buerstatte was let go, and John Tempesta, who had previously worked with Exodus and Testament, was hired to record White Zombie's second major label album. In 1995, ' was released, featuring the hit single "More Human than Human". In 1996, an album of remixes was released under the title "Supersexy Swingin' Sounds". After making one last song for the 1996 film "Beavis and Butt-head Do America", titled "Ratfinks, Suicide Tanks and Cannibal Girls", White Zombie broke up in 1998.
After disbanding.
After the breakup of White Zombie, Sean Yseult joined the surf rock band The Famous Monsters, and started playing bass for horror-themed New Orleans-based band, Rock City Morgue. She also briefly played bass for The Cramps.
Tempesta continued his musical relationship with Zombie, drumming for him on his first two solo albums, "Hellbilly Deluxe" and "The Sinister Urge". He is no longer with Zombie, and has gone on to play for Scum of the Earth with his brother, Powerman 5000 guitarist Mike Tempesta, and ex-Zombie guitarist Mike Riggs. Tempesta has toured with Testament (as shown on Testament's DVD, "Live In London"). On February 14, 2006, he was hired as the new drummer for The Cult, before which, he played with Helmet.
J. produced records for Fu Manchu and New York-based Puny Human.
In July 2006, original members Tom Five and de Prume reunited to perform with de Prume's band, Healer, a middle eastern infused metal band, for several concerts in Southern California for The Vans Warped Tour. De Prume continues to write and record music with Healer, as well as recording, producing and engineering for special projects in his studio, Burningsound. His drums and percussion work can also be heard on Sony's "Ghost Rider" score. In 2009, de Prume began hosting the weekly radio show, "Metalopolis". His studio guests have included Rob Halford, Dave Mustaine, Max Cavalera, Vinnie Paul and Tom Araya. De Prume is also a member of the band KREEP, and has completed a West Coast tour in spring 2010, and is planning an East Coast tour in fall 2010.
In November 2008, Geffen/UME released "Let Sleeping Corpses Lie", a boxed set which includes sixty four tracks featuring every White Zombie album and EP (except the remix albums), all remastered. The package also contained nine music videos (including their breakthrough Grammy-nominated hit "Thunder Kiss '65"), and ten live performances. In an interview to promote the release of "Let Sleeping Corpses Lie", Zombie made it clear that a reunion with his White Zombie band mates was unlikely, saying, "I don't want fans to think it's the beginning of anything."
In December 2010 Yseult released "I'm in the Band", a book containing tour diaries and photos as well as detailing her eleven years spent as a member of White Zombie.
In June 2011, in an interview with "Metal Hammer" magazine, Rob Zombie was asked why White Zombie split up, in which he replied: "It had run its course. Success is a big thing that you can never plan for, because it affects everybody differently. I don't want to blame myself or anyone else in the band — it's just that the band didn't work anymore. Rather than continuing on and making shitty records and having it all fall apart, I thought: 'Let's just end it on a high point'".
In May 2013, former drummer Phil Buerstatte died.

</doc>
<doc id="34128" url="http://en.wikipedia.org/wiki?curid=34128" title="Wilhelm Wundt">
Wilhelm Wundt

Wilhelm Maximilian Wundt (16 August 1832 – 31 August 1920) was a German physician, physiologist, philosopher, and professor, known today as one of the founding figures of modern psychology. Wundt, who noted psychology as a science apart from biology and philosophy, was the first person to ever call himself a Psychologist. He is widely regarded as the "father of experimental psychology". In 1879, Wundt founded the first formal laboratory for psychological research at the University of Leipzig. This marked psychology as an independent field of study.
By creating this laboratory he was able to explore the nature of religious beliefs,
identify mental disorders and abnormal behavior, and find damaged parts of the brain. In doing so, he was able to establish psychology as a separate science from other topics. He also formed the first academic journal for psychological research, Philosophische Studien, in the year 1883.
Biography.
Wundt was born at Neckarau, Baden (now part of Mannheim) on 16 August 1832, the fourth child to parents Maximilian Wundt (a Lutheran minister), and his wife Marie Frederike, née Arnold (1797-1868). Wundt's paternal grandfather was Friedrich Peter Wundt (1742-1805), Professor of Geography and pastor in Wieblingen. When Wundt was about four years of age, his family moved to Heidelsheim, then a small medieval town in Baden-Württemberg.
Wundt studied from 1851 to 1856 at the University of Tübingen, at the University of Heidelberg, and at the University of Berlin. After graduating in medicine from Heidelberg (1856), Wundt studied briefly with Johannes Peter Müller, before joining the University's staff, becoming an assistant to the physicist and physiologist Hermann von Helmholtz in 1858. There he wrote "Contributions to the Theory of Sense Perception" (1858–62). In 1865, he wrote a textbook about human physiology. However, his main interest was not in physiology but in the medical field of pathological anatomy. In 1867 he became a professor in acquainting medical students with the exact physical needs for medical investigation. In 1874, he became a professor of "Inductive Philosophy" in Zurich.
In 1867, near Heidelberg, Wundt met Sophie Mau (1844-1912). She was the eldest daughter of the Kiel theology professor Heinrich August Mau and his wife Louise, née von Rumohr, and a sister of the archaeologist August Mau. They married on 14 August 1872 in Kiel. The couple had three children: Eleanor (*1876-1957 ), Lily (1880-1884), and Max Wundt (1879-1963), who became a philosopher.
During Wundt's time at the University of Heidelberg he offered the first course ever taught in scientific psychology, all the while stressing the use of experimental methods drawn from the natural sciences, emphasizing the physiological relationship of the human brain and the mind. His background in physiology would have a great effect on his approach to the new science of psychology. His lectures on psychology were published as "Lectures on the Mind of Humans and Animals" in 1863-1864. He was promoted to Assistant Professor of Physiology at Heidelberg in 1864. Weber (1795–1878) and Fechner (1801–1887), who worked at Leipzig, inspired Wundt's interest in psychology.
Wundt applied himself to writing a work that came to be one of the most important in the history of psychology, "Principles of Physiological Psychology" in 1874. This was the first textbook that was written pertaining to the field of psychology. Wundt claimed that the book was "an attempt to mark out [psychology] as a new domain of science". The "Principles" utilized a system of psychology that sought to investigate the immediate experiences of consciousness, including feelings, emotions, volitions and ideas, mainly explored through Wundt's system of "internal perception", or the self-examination of conscious experience by objective observation of one's consciousness.
In 1875, Wundt moved to Leipzig. In 1879, at the University of Leipzig, Wundt opened the first laboratory ever to be exclusively devoted to psychological studies, and this event marked the official birth of psychology as an independent field of study. The new lab was full of graduate students carrying out research on topics assigned by Wundt, and it soon attracted young scholars from all over the world who were eager to learn about the new science that Wundt had developed.
Wundt's work and influence on modern psychology.
Wundt believed that scientific psychology should focus on analyzing consciousness, a person's subjective experience of the world and mind. Parts of Wundt's system were developed and championed by his one-time student, Titchener, who described his system as Structuralism, or the analysis of the basic elements that constitute the mind. This approach involved breaking consciousness down into elemental sensations and feelings. Wundt believed that scientific psychology should focus on consciousness and therefore centralizes on structuralism. Wundt analyzes the constituents of the mind by using a method called introspection, which involves the subjective observation of one's own experience. This became the reason why structuralism gradually faded out, based on the unreliability of this method. Several of Wundt's works, including "Principles of Physiological Psychology", are considered fundamentally important texts in the fields of physiology and psychology. Though widely recognized as important in the birth and growth of psychology, his influence on psychology today is a subject of continuing debate among experts. Wundt also influenced in the field of psycholinguistics. For example, the influential Leonard Bloomfield based his linguistics textbook, published in 1914, on Wundtian psychology. Wundt hypothesized that the mental sentence, or "inner psychological construction", determines the unfolding sentence, and should therefore be regarded as a unit of speech.
In 1886, in his "Logik", Wundt formulated the famous expression "heterogony of ends" ("Heterogonie der Zwecke").
Several of Wundt's students became eminent psychologists in their own right, including two who became philosophers (Ljubomir Nedić and Branislav Petronijević). They include: the Germans Oswald Külpe (a professor at the University of Würzburg), Ottmar Dittrich (who continued Wundt's work in psycholinguistics by heading the group on phonetics and psychology of language at the University of Leipzig); the Americans James McKeen Cattell (the first professor of psychology in the United States), G. Stanley Hall (the father of the child psychology movement and adolescent developmental theorist, head of Clark University), Charles Hubbard Judd (Director of the School of Education at the University of Chicago), Hugo Münsterberg, Walter Dill Scott (who contributed to the development of industrial psychology and taught at Harvard University), Edward Bradford Titchener, Lightner Witmer (founder of the first psychological clinic in his country); the Englishman Charles Spearman (who developed the two-factor theory of intelligence and several important statistical analyses - "see Factor analysis", "Spearman's rank correlation coefficient"); the Romanian Constantin Rădulescu-Motru (Personalist philosopher and head of the Philosophy department at the University of Bucharest).
The University of Leipzig assigned Wundt a lab in 1876 to store equipment he had brought from Zurich. Located in the Konvikt building, many of Wundt's demonstrations took place in this laboratory due to the inconvenience of transporting his equipment between the lab and his classroom. Wundt collected many pieces of equipment such as tachistoscopes, chronoscopes, pendulums, electrical devices, timers, and sensory mapping devices and was known to assign an instrument to various graduate students with the assignment of developing uses for future research in experimentation.
In 1879 Wundt began conducting experiments that were not part of his course work, and he claimed that these independent experiments solidified his lab's legitimacy as a formal laboratory of psychology, though the University did not officially recognize the building as part of the campus until 1883. Wundt faced much opposition in regards to his colleague's rejections of psychology as a legitimate science and their questions concerning the nature of introspection. Despite this opposition, the laboratory grew and encompassing a total of eleven rooms, the Psychological Institute, as it became known, eventually moved to a new building that Wundt had designed specifically for psychological research.
Wundt's laboratory students called their approach "Ganzheitspsychologie" ("holistic psychology") following Wundt's death. Much of Wundt's work was derided mid-century in the United States because of a lack of adequate translations, misrepresentations by certain students, and behaviorism's polemic with the structuralist program. Titchener, a two-year resident of Wundt's lab and one of Wundt's most vocal advocates in the United States, is responsible for several English translations and mistranslations of Wundt's works that supported his own views and approach, which he termed "structuralism" and claimed was wholly consistent with Wundt's position.
Titchener's focus on internal structures of mind was rejected by behaviorists following the ideas of B. F. Skinner; the latter dominated psychological studies in the mid-1900s. Part of this rejection included Wundt, whose work was eclipsed during this period. In later decades, his actual positions and techniques have seen reconsideration and reassessment by major psychologists.
An optical illusion described by him is called the "Wundt illusion"
Wundt tried to provide objective measurements of conscious processes by using reaction time techniques similar to those first developed by Helmholtz. His fasting research participants, focusing only on the response they were to make, could respond automatically to the tone because they didn't have to engage in the additional step of interpretation. This type of experimentation broke new ground by showing that psychologists could use scientific techniques to disentangle even subtle conscious processes. [2]
Like many of his contemporaries, Wundt accepted a developmental conception of mind. But developmental in the idealist sense of unfolding reason, such that the highest intelligence is a logical product of more primitive manifestations.
Publications.
Wundt was extremely prolific in publications, of which this is a selection only.
Notes and references.
</dl>
Further reading.
—

</doc>
<doc id="34129" url="http://en.wikipedia.org/wiki?curid=34129" title="Weapon (biology)">
Weapon (biology)

Weapons are traits that are used by males to fight one another off for access to mates. A mate is won in battle either by a male chasing off a fellow competitor or killing it off, usually leaving the victor as the only option for the female to reproduce with. However, because stronger organisms, whether mentally or physically, are usually favored in combat, this also leads to the evolution of stronger organisms in species that use combat as a way to secure mates. Examples of weapons include the antlers bucks use to fight one another off when competing for females.

</doc>
<doc id="34130" url="http://en.wikipedia.org/wiki?curid=34130" title="WarGames">
WarGames

WarGames is a 1983 American Cold War science-fiction film written by Lawrence Lasker and Walter F. Parkes and directed by John Badham. The film stars Matthew Broderick, Dabney Coleman, John Wood, and Ally Sheedy.
The film follows David Lightman (Broderick), a young hacker who unwittingly accesses WOPR (War Operation Plan Response), a United States military supercomputer programmed to predict possible outcomes of nuclear war. Lightman gets WOPR to run a nuclear war simulation, originally believing it to be a computer game. The simulation causes a national nuclear missile scare and nearly starts World War III.
The film was a box office success, costing US$12 million, and grossing $79,567,667 after five months in the United States and Canada. The film was nominated for three Academy Awards. A sequel, "", was released direct to DVD on July 29, 2008.
Plot.
During a surprise drill of a nuclear attack, many United States Air Force Strategic Missile Wing missileers prove unwilling to turn a required key to launch a missile strike. Such refusals convince John McKittrick (Dabney Coleman) and other systems engineers at NORAD that command of missile silos must be maintained through automation, without human intervention. Control is given to a NORAD supercomputer, WOPR (War Operation Plan Response), programmed to continuously run military simulations and learn over time.
David Lightman (Matthew Broderick) is a bright but unmotivated Seattle high school student and hacker. After receiving a failing grade in school, he uses his IMSAI 8080 microcomputer to hack into the district's computer system. He then changes his grade and does the same for his friend and classmate Jennifer Mack (Ally Sheedy). Later, while dialing every number in Sunnyvale, California to find a set of forthcoming computer games, a computer that does not identify itself intrigues David. On the computer he finds a list of games, starting with general strategy games like chess, checkers, backgammon, and poker and then progressing to titles like "Theaterwide Biotoxic and Chemical Warfare" and "Global Thermonuclear War", but cannot proceed further. Two of his hacker friends explain the concept of a backdoor password and suggest tracking down the Falken referenced in "Falken's Maze", the first game listed. David discovers that Stephen Falken is an early artificial intelligence researcher, and guesses correctly that his dead son's name "Joshua" is the backdoor password.
David does not know that the Sunnyvale phone number connects to WOPR, or "Joshua", at Cheyenne Mountain Complex. He starts a game of Global Thermonuclear War, playing as the Soviet Union. The computer starts a simulation that briefly convinces the military personnel at NORAD that actual Soviet nuclear missiles are inbound. While they defuse the situation, Joshua nonetheless continues the simulation to trigger the scenario and win the game. It continuously feeds false data such as Soviet bomber incursions and submarine deployments to the humans at NORAD, pushing them into raising the DEFCON level and toward a retaliation that will start World War III. David learns the true nature of his actions from a news broadcast, and the FBI arrests him and takes him to NORAD. He realizes that Joshua is behind the NORAD alerts but fails to convince McKittrick and faces imprisonment. David escapes NORAD by joining a tourist group and, with Jennifer's help, travels to the Oregon island where the widowed Falken (John Wood) now lives. David and Jennifer find that Falken has become despondent and believes that nuclear war is inevitable. The teenagers convince Falken that he should return to NORAD to stop Joshua.
The computer stages a massive Soviet first strike with hundreds of missiles, submarines, and bombers. Believing the attack to be genuine, NORAD prepares to retaliate. Falken, David, and Jennifer convince military officials to cancel the second strike and ride out the non-existent attack. Joshua tries to launch the missiles itself, however, using a brute force attack to obtain the launch code. Without humans in the silos as a safeguard, the computer will trigger a mass launch. All attempts to log in and order Joshua to cancel the countdown fail, and all weapons will launch if the computer is disabled. Instead, Falken and David direct the computer to play tic-tac-toe against itself. This results in a long string of draws, forcing the computer to learn the concept of futility. Joshua obtains the missile code but before launching, it cycles through all the nuclear war scenarios it has devised, finding they too all result in stalemates. Having discovered the concept of Mutually Assured Destruction ("WINNER: NONE"), the computer concludes that nuclear warfare is "a strange game" in which "the only winning move is not to play." Joshua then offers to play "a nice game of chess", and relinquishes control of NORAD and the missiles.
Production.
Development.
Development on "WarGames" began in 1979, when writers Walter F. Parkes and Lawrence Lasker developed an idea for a script called "The Genius", about "a dying scientist and the only person in the world who understands him – a rebellious kid who's too smart for his own good." Lasker was inspired by a television special presented by Peter Ustinov on several geniuses including Stephen Hawking. Lasker said "I found the predicament Hawking was in fascinating – that he might one day figure out the unified field theory and not be able to tell anyone, because of his progressive ALS. So there was this idea that he'd need a successor. And who would that be? Maybe this kid, a juvenile delinquent whose problem was that nobody realized he was too smart for his environment." The concept of computers and hacking as part of the film was not yet present.
"The Genius" began its transformation into "WarGames" when Parkes and Lasker met Peter Schwartz from the Stanford Research Institute. "There was a new subculture of extremely bright kids developing into what would become known as hackers," said Schwartz. Schwartz made the connection between youth, computers, gaming, and the military. Parkes and Lasker came up with several different military-themed plotlines prior to the final story. One version of the script had an early version of WOPR named "Uncle Ollie", or OLI (Omnipresent Laser Interceptor), a space-based defensive laser run by an intelligent program, but this idea was discarded because it was too speculative. Director John Badham coined the name "WOPR", feeling that the name of NORAD's SIOP (Single Integrated Operational Plan) was "boring, and told you nothing". The name "WOPR" played off of the Whopper hamburger, and a general sense of something going "whop".
David Lightman was modeled on David Scott Lewis, a hacking enthusiast Parkes and Lasker met. Falken was inspired by Stephen Hawking with the appearance of John Lennon, who was interested in the role. General Beringer was based on James V. Hartinger, the then-commander-in-chief of NORAD who Parkes and Lasker met while visiting the base, and who, like Beringer, favored keeping humans in the decision loop.
The WOPR computer as seen in the film was a prop created in Culver City, California, by members of the International Alliance of Theatrical and Stage Employees Local 44. It was designed by production designer (credited as visual consultant) Geoffrey Kirkland based on some pictures he had of early tabulating machines, and metal furniture, consoles, and cabinets used particularly in the U.S. military in the 1940s and 50s. They were adapted in drawings and concepts by art director Angelo Graham. WOPR was operated by a crewmember sitting inside the computer, entering commands into an Apple II at the director's instruction. The prop was broken up for scrap after production was completed. A replica was built for a 2006 AT&T commercial.
Filming.
Martin Brest was originally hired as director but was fired after 12 days of shooting because of a disagreement with the producers, and replaced with John Badham. Several of the scenes shot by Brest remain in the final film. Badham said that "[Brest had] taken a somewhat dark approach to the story and the way it was shot. It was like [Broderick and Sheedy] were doing some Nazi undercover thing. So it was my job to make it seem like they were having fun, and that it was exciting." According to Badham, Broderick and Sheedy were "stiff as boards" when they came onto the sound stage, having both Brest's dark vision and the idea that they would soon be fired. Badham did 12–14 takes of the first shot to loosen the actors up. At one point, Badham decided to have a race with the two actors around the sound stage with the one who came last having to sing a song to the crew. Badham lost and sang "The Happy Wanderer", the silliest song he could think of.
Tom Mankiewicz says he wrote some additional scenes during shooting which were used.
Release.
"WarGames" did well at the North American box office, earning $79,567,667, the fifth-highest of 1983. The film was screened out of competition at the 1983 Cannes Film Festival. President Reagan, a family friend of Lasker, watched the film and discussed the plot with members of Congress.
Reception.
Critical response.
The film received critical acclaim. Film review aggregator Rotten Tomatoes reported that 92% of sampled critics gave the film positive reviews and that it got a rating average of 7.5 out of 10. Film critic Roger Ebert gave the film four out of four stars, calling it "an amazingly entertaining thriller" and "one of the best films so far this year", with a "wonderful" ending. "Softline" praised the film as being "completely original"; unlike other computer-related films like "Tron" that "could (and do) exist in substantially the same form with some other plot", "WarGames" "could not exist if the microcomputer did not exist ... It takes the micro and telecommunications as a given—part of the middle-class American landscape". The magazine praised the film as "Very funny, excruciatingly suspenseful, and endlessly inventive, this movie is right on the mark; authentic even when highly improbable". "Computer Gaming World" stated that ""Wargames" is plausible enough to intrigue and terrifying enough to excite ... [it] makes one think, as well as feel, all the way", raised several moral questions about technology and society, and recommended the film to "Computer hobbyists of all kinds".
Accolades.
"WarGames" was nominated for three Academy Awards — Best Cinematography (William A. Fraker), Sound (Michael J. Kohut, Carlos Delarios, Aaron Rochin, Willie D. Burton), and Writing, Screenplay Written Directly for the Screen (Lawrence Lasker, Walter F. Parkes). The company that provided the large screens used to display the tactical situations seen in the NORAD set employed a new design that was super-bright enabling the displays to be filmed live. (The set was more visually impressive than the actual NORAD facilities at the time.) No post-production work was needed. For this, the company was awarded an Academy Scientific and Technical Award.
Influence.
Bulletin Board System operators reported an unusual rise in activity in 1984, which at least one sysop attributed to "WarGames" introducing viewers to modems. The scenes showing Lightman's computer dialing every number in Sunnyvale led to the term "war dialing" (earlier known as "demon dialing"), a technique of using a modem to scan a list of telephone numbers to search for unknown computers, and indirectly to the newer term "wardriving".
Video games.
A video game, "WarGames" was released for the ColecoVision in 1983 and ported to the Atari 8-bit family and Commodore 64 in 1984. It played similarly to the NORAD side of the "Global Thermonuclear War" game, where the United States had to be defended from a Soviet strike by placing bases and weapons at strategic points. "", a real-time strategy game that was only loosely related to the film was released for the PlayStation and PC in 1998. A tile-matching video game, "WarGames: WOPR", was released for iOS and Android devices in 2012.
A game inspired by the film, called "Computer War" from Thorn EMI, in which the player must track and shoot down ICBMs as well as crack a computer code, was released for the Atari 8-bit family, TI-99/4A and Commodore VIC-20. The film also inspired the Introversion game "DEFCON" (2006).
Soundtrack.
The film's music was composed and conducted by Arthur B. Rubinstein. A soundtrack album including songs (recorded for but not used in the film) and dialogue excerpts was released by Polydor. Intrada Records issued an expanded release in 2008 with the complete score, without the dialogue.
The folk rock supergroup Crosby, Stills & Nash were tapped at one point to write a title song for the film, but at the last minute it was scrapped from the project. The band released the song anyway, with a video made of footage from the movie airing on MTV. It was available on their now out-of-print album Allies.
Sequel and possible remake.
In November 2006, pre-production began on a sequel, titled "". It was directed by Stuart Gillard, and starred Matt Lanter as a hacker named Will Farmer facing off with a government supercomputer called RIPLEY. MGM released the sequel directly to DVD on July 29, 2008 along with the 25th Anniversary Edition DVD of "WarGames". To promote the sequel, the film returned to selected theaters as a one-night-only twenty-fifth anniversary event on July 24, 2008.
There have been various rumours of reboots. It was reported in February 2009 that Leonardo DiCaprio was looking to produce one, and in 2011 MGM Studios were said to be planning a reboot with Seth Gordon signed on to direct, although no writers or cast were yet on board.

</doc>
<doc id="34131" url="http://en.wikipedia.org/wiki?curid=34131" title="Wilhelm Ostwald">
Wilhelm Ostwald

Friedrich Wilhelm Ostwald (Latvian: "Vilhelms Ostvalds"; 2 September 1853 – 4 April 1932) was a Baltic German chemist. He received the Nobel Prize in Chemistry in 1909 for his work on catalysis, chemical equilibria and reaction velocities. Ostwald, Jacobus Henricus van 't Hoff, and Svante Arrhenius are usually credited with being the modern founders of the field of physical chemistry.
Early life and education.
Ostwald was born ethnically Baltic German in Riga, to master-cooper Gottfried Wilhelm Ostwald (1824–1903) and Elisabeth Leuckel (1824–1903). He was the middle of two brothers, Eugen (1851–1932) and Gottfried (1855–1918). Ostwald graduated from the University of Tartu, Estonia, in 1875, received his Ph.D. there in 1878 under the guidance of Carl Schmidt, and taught at Co-Arc from 1875 to 1881 and at Riga Polytechnicum from 1881 to 1887.
Career and research.
Ostwald is usually credited with inventing the Ostwald process (patent 1902), used in the manufacture of nitric acid, although the basic chemistry had been patented some 64 years earlier by Kuhlmann, when it was probably of only academic interest due to the lack of a significant source of ammonia. That may have still been the state of affairs in 1902, although things were due to change dramatically in the second half of the decade as a result of Haber and Bosch's work on their nitrogen fixing process (completed by 1911 or 1913). The date 1908 (six years after the patent) is often given for the invention of the Ostwald process, and it may be that these developments motivated him to do additional work to commercialize the process in that time-frame. Alternatively, six years might simply have been the bureaucratic interval between filing the patent and the time it was granted.
The combination of these two breakthroughs soon led to more economical and larger-scale production of fertilizers and explosives, of which Germany was to find itself in desperate need during World War I. Ostwald also did significant work on dilution theory leading to his discovery of the law of dilution which is named after him. Ostwald's rule concerns the behaviour of polymorphs. The word mole, according to Gorin, was introduced into chemistry around 1900 by Ostwald. Ostwald defined one mole as the molecular weight of a substance in mass grams. The concept was linked to the ideal gas, according to Ostwald. Ironically, Ostwald's development of the mole concept was directly related to his philosophical opposition to the atomic theory, against which he (along with Ernst Mach) was one of the last holdouts. He explained in a conversation with Arnold Sommerfeld that he was converted by Jean Perrin's experiments on Brownian Motion.
In 1906 Ostwald was elected a member of the International Committee on Atomic Weights. As a consequence of World War I this membership ended in 1917 and was not resumed after the war. The 1917 Annual report of the committee ended with the unusual note: "Because of the European war the Committee has had much difficulty in the way of correspondence. The German member, Professor Ostwald, has not been heard from in connection with this report. Possibly the censorship of letters, either in Germany or en route, has led to a miscarriage".
In addition to his work in chemistry, Wilhelm Ostwald was very productive in an extremely broad range of fields. His published work, which includes numerous philosophical writings, contains about forty thousand pages. Ostwald was also engaged in the peace movement of Berta von Suttner.
Among his other interests, Ostwald was a passionate amateur painter who made his own pigments, and who developed a strong interest in color theory in the later decades of his life. He wrote several publications in the field, such as his "Malerbriefe" ("Letters to a Painter," 1904) and "Die Farbenfibel" ("The Color Primer," 1916). His work in color theory was influenced by that of Albert Henry Munsell, and in turn influenced Paul Klee and members of De Stijl, including Piet Mondrian. He was also interested in the international language movement, first learning Esperanto, then later supporting Ido. Ostwald donated half the proceddings of his 1909 Nobel prize to the Ido movement, funding the Ido magazine "Progreso" which he had proposed in 1908.
Ostwald adopted the philosophy of Monism as advanced by Ernst Haeckel and became President of the Monistic Alliance in 1911. He used the Alliance's forum to promote Social Darwinism, eugenics and euthanasia. Ostwald's Monism influenced Carl G. Jung's identification of psychological types.
He was one of the directors of the Die Brücke institute in München. The institute was sponsored, significantly, from Ostwald's Nobel Prize money.
Personal life.
On 24 April 1880 Ostwald married Helene von Reyher (1854 – 1946), with whom he had five children: 
In 1887, he moved to Leipzig where he worked for the rest of his life. Arthur Noyes was one of his students, as was Willis Rodney Whitney. On his religious views, Ostwald was an atheist. Ostwald died in a hospital in Leipzig on 4 April 1932, and was buried at his house in Großbothen, near Leipzig and then in the Great Cemetery of Riga.
In fiction.
He appears as a character in Joseph Skibell's 2010 novel, A Curable Romantic.

</doc>
<doc id="34134" url="http://en.wikipedia.org/wiki?curid=34134" title="Wendell Willkie">
Wendell Willkie

Wendell Lewis Willkie (; February 18, 1892 – October 8, 1944) was a corporate lawyer in the United States and a dark horse who became the Republican Party nominee for president in 1940. A member of the liberal wing of the party, he crusaded against those domestic policies of the New Deal that he thought were inefficient and anti-business. Willkie, an internationalist, needed the votes of the large isolationist element, so he waffled on the bitterly debated issue of America's role in World War II, losing support from both sides. His opponent, incumbent President Franklin D. Roosevelt, won the 1940 election with 55% of the popular vote and 85% of the electoral vote.
Afterward, Roosevelt found Willkie to be compatible politically with his plans and brought him aboard as an informal ambassador-at-large. Willkie criss-crossed the globe and brought home a vision of "One World" freed from imperialism and colonialism. Following his journeys, Willkie wrote "One World"; a bestselling account of his travels and meetings with the Allied heads of state, as well as ordinary citizens and soldiers in regions such as Russia and Iran. His liberalism lost him supporters in the Republican Party and he dropped out of the 1944 race, then several months later died of a heart attack.
Early life.
Education and early career.
Willkie was born and raised in Elwood, Indiana, the son of Herman Willkie, a German immigrant from the Province of Saxony, whose family name originally was "Willcke", and his wife Henrietta (Trisch), whose parents were German. Both of his parents were lawyers in Elwood, his mother being one of the first women admitted to the bar in Indiana. He was named Lewis Wendell Willkie, but among his friends and family he was called by his middle name, Wendell.
Willkie graduated from Elwood High School, and in 1913 earned a BA from Indiana University, where he belonged to Beta Theta Pi fraternity. He taught history for a year at a high school in Coffeyville, Kansas, then entered the Indiana University School of Law, receiving his LLB in 1916.
The following year, when the U.S. entered World War I, Willkie enlisted in the Army. An Army clerk accidentally transposed his first and middle names, and Willkie did not correct it, thereafter calling himself Wendell Lewis Willkie. He received a commission as a First Lieutenant and trained to be an artillery officer. However, he arrived in France just as the war ended. Since he was a lawyer, he was assigned to the American headquarters in Paris to assist in military trials.
After his discharge, Willkie worked as a corporate lawyer for the Firestone Tire and Rubber Company in Akron, Ohio. He became active in the Akron Democratic Party, and was a delegate to the 1924 Democratic National Convention. In 1919 Willkie married Edith Wilk (no relation), a librarian from Rushville, Indiana. They had one son, Philip.
Business and politics.
In 1929, Willkie became a legal counsel for the New York-based Commonwealth & Southern Corporation, which provided electrical power to customers in eleven states. Four years later, he became the company's president. Willkie was a delegate to the 1932 Democratic National Convention. He initially backed former Secretary of War Newton D. Baker for the presidential nomination, but when Franklin D. Roosevelt was chosen, Willkie supported him and contributed money to his campaign.
Fights TVA.
In 1933, President Roosevelt proposed legislation creating the Tennessee Valley Authority (TVA), a government agency with far-reaching influence that promised to bring flood control and cheap electricity to the impoverished Tennessee Valley. However, the TVA would compete with existing private power companies in the area, including Commonwealth & Southern. This caused Willkie to become an active critic of the TVA, as well as other New Deal agencies that directly competed with private corporations. Willkie argued that government-controlled organizations such as the TVA had unfair advantages, since they did not have to be profitable and could thus charge cheaper rates than private corporations. This idea was not new to Willkie; in 1930 he had said publicly that it would be unconstitutional for the federal government to enter the utility business.
In April 1933, Willkie testified against the TVA legislation before the Military Affairs Committee in the House of Representatives. He said the TVA's supplanting of Commonwealth & Southern could threaten $400 million in investors' equity, thereby convincing the House to limit the TVA's ability to build transmission lines that competed with those of existing private companies.
However, Roosevelt persuaded the Senate to remove the restrictions and the resulting law gave the TVA extremely broad powers. The TVA could borrow unlimited funds at low interest rates, and Willkie's Commonwealth & Southern was unable to compete. In 1939, Commonwealth & Southern was forced to sell its property in the Tennessee Valley to the TVA for $78.6 million. Willkie formally switched political parties that year and began making speeches opposing the New Deal. Willkie did not condemn all New Deal programs. He supported New Deal programs that dealt with problems he felt could not be solved better by private enterprise, including Social Security, the Wagner Labor Relations Act, and the Securities and Exchange Commission. He maintained that since the government had unfair advantages over private businesses, it should avoid competing directly against them. On January 6, 1938 Willkie made a highly publicized appearance on the popular "Town Hall" nationwide radio program, where he debated the merits of the private-enterprise system with Robert H. Jackson. Jackson was Roosevelt's Solicitor General and a possible 1940 Democratic presidential candidate. Most listeners felt that Willkie won the debate, and many liberal Republicans began to view him as a possible presidential candidate.
1940 presidential election.
Republican nomination.
The 1940 presidential campaign was conducted against the backdrop of World War II. Although the United States was still neutral, the nation - and especially the Republican Party - was deeply divided between isolationists, who felt the nation should avoid any steps that could lead America into the war, and interventionists, who felt that America's survival depended upon helping the Allies defeat Nazi Germany. The three leading candidates for the 1940 Republican nomination were all isolationists to varying degrees: Senators Robert A. Taft of Ohio, Arthur Vandenberg of Michigan, and Thomas E. Dewey, the "gangbusting" District Attorney from New York. These three men had campaigned vigorously, but only 300 of the 1,000 convention delegates were pledged to a candidate before the convention. This left an opening for a "dark horse" candidate to emerge.
Willkie seemed an unlikely candidate as he was a former Democrat and Wall Street industrialist who had never before run for public office. He had backing from some major media magnates: Ogden Reid of the "New York Herald Tribune", Roy W. Howard of the Scripps-Howard newspaper chain, and John Cowles and Gardner Cowles, publishers of the "Minneapolis Star" and "Tribune", the "Des Moines Register", and "Look" magazine. Willkie's supporters established a national grassroots network, but his support was thin. A May 8 Gallup poll showed Dewey at 67% support among Republicans, followed by Vandenberg and Taft, with Willkie at a mere 3%.
Willkie tried to appeal to the powerful isolationist wing of the Republican Party by saying: "no man has the right to use the great powers of the Presidency to lead the people, indirectly, into war." However, Willkie's greatest support came from the party's internationalist wing, which wanted the US to provide all the aid possible to the Allies (especially Britain), short of a formal declaration of war. Willkie consistently spoke of the need to aid Britain against Germany; this contrasted with his main rivals Taft, Dewey, and Vandenberg, who were isolationists.
While Taft stressed that America needed to prevent the New Deal from using the international crisis to extend socialism and dictatorship at home, the German blitzkrieg that quickly defeated France shook public opinion. Sympathy for the embattled British was mounting. In mid-June, little over one week before the convention opened, Gallup reported that Willkie had surged to second place with 17%, and that Dewey was slipping. Willkie stumped the country, seeking the support of liberal and East Coast Republicans worried by German victories.
Republican convention.
As the convention opened in Philadelphia on June 24, Gallup reported that in a poll taken a few days earlier, Willkie had moved up to 29%, Dewey had slipped 5% to 47%, and Taft, Vandenberg, and former President Hoover trailed at 8%, 8%, and 6% respectively. With the surrender of France to Germany on June 22, 1940, and the belief that Britain was under imminent threat of a Nazi invasion, the convention opened in an atmosphere of great excitement and national stress; this is believed to have boosted Willkie's chances even further.
Hundreds of thousands of telegrams urging support for Willkie poured in, many from "Willkie Clubs" that had sprung up across the country. Millions more citizens signed petitions circulating throughout the country. At the convention, Governor Harold Stassen of Minnesota, the keynote speaker, announced for Willkie and became his official floor manager. Hundreds of vocal Willkie supporters packed the upper galleries of the convention hall. Willkie's amateur status and fresh face appealed to delegates as well as voters. The delegates were selected not by primaries but by party organizations in each state, and as political veterans, they had a keen sense of how fast public opinion was changing. This change was also reflected in a later poll taken by Gallup but not reported till after the convention: Willkie had pulled ahead among Republican voters by 44% to only 29% for the collapsing Dewey.
Dewey led the first ballot, but was far short of a majority; Taft was second, and Willkie was a surprisingly strong third. On the second and third ballots Dewey's support dwindled, as his delegates went to either Taft or Willkie, with most favoring Willkie. Meanwhile, Willkie's supporters in the galleries chanted "We Want Willkie" over and over. On the fourth ballot Willkie surged into first place, with Taft close behind; other candidates began to drop out in favor of the two frontrunners. As the delegates belonging to "favorite son" candidates were released by their original candidates, Willkie steadily gained more of them than Taft. Finally, on the sixth ballot, Willkie received a majority of the ballots cast and won the nomination. His victory is still considered by most political historians to be one of the most dramatic moments in the history of American presidential conventions.
Willkie left the selection of the candidate for Vice President to convention chairman Joseph W. Martin Jr., who suggested Senate Minority Leader Charles L. McNary of Oregon. Despite the fact that McNary had spearheaded a "Stop Willkie" campaign late in the balloting, Willkie selected McNary, who was nominated by acclamation. Willkie asked Martin to take on the task of Republican National Committee chairman, a post that Martin held simultaneously with his House leadership role from 1940–1942. Martin found the party without adequate finances after Willkie's defeat and unable to raise needed funds for the 1942 congressional elections.
Convention chairman Joe Martin went to Elwood, Indiana, to inform Willkie officially of the nomination, as was then the custom. In giving his acceptance speech, Willkie used a full text of the speech which was typewritten with double spacing in ordinary pica type, whereas experienced politicians used triple space in large letters as notes for giving speeches. Martin writes in his memoirs, "As I feared, Willkie had difficulty reading the speech from the small type. His performance was flat. Then the crowning blunder came at the end of the speech when the Willkie clubs, without my knowledge, piped in an appeal for funds to the tremendous radio audience. If ever such an appeal was out of place, it was in a high-minded notification ceremony...
General election.
Willkie centered his presidential campaign on three major themes: the alleged inefficiency and corruption of Roosevelt's New Deal programs; Roosevelt's attempt to win an unprecedented third term as President; and the government's alleged lack of military preparedness. Willkie claimed that he would keep most of FDR's New Deal welfare and regulatory programs, but that he would make them more efficient and effective, and that he would work more closely with business leaders to end the Great Depression. Roosevelt's attempt to break the "two-term" tradition established by George Washington was also a focus of Willkie's criticism; the Republican candidate accused Roosevelt of thinking himself indispensable and wanting to institute "one-man rule." He said FDR had "weakened rather than strengthened democracy throughout the world." FDR's attempt to break the "two-term" tradition had also earned criticism from some conservative Democrats (such as John Nance Garner), and Willkie hoped to win their support.
Willkie relied heavily on radio to broadcast his message to the people. Joe Martin writes that he could "hardly find enough money to buy him all the time he wanted on the networks."
However, these first two themes did not catch the public's attention, and as Willkie's support sagged, he turned to criticism of Roosevelt's lack of preparedness in military matters. However, during the campaign, Roosevelt preempted the military issue by expanding military contracts and instituting a military draft. Although Willkie had initially supported the draft, he waffled and reversed his stance when polls showed that opposition to entering another world war was a popular issue for the Republicans. Willkie then began to claim that Roosevelt was secretly planning to take the U.S. into the European war against Germany. With this claim, his campaign attracted isolationists and managed to regain some of its momentum.
Late in the campaign, the Republicans obtained letters written by Henry A. Wallace, the Democratic vice presidential nominee, to controversial Russian mystic Nicholas Roerich, who had invented an eclectic religion based on Tibetan Buddhism. Wallace addressed Roerich as "Dear Guru", and signed his own name as "G" for Galahad — a name Roerich assigned Wallace in his religion — and showed his complete adherence to Roerich's doctrines. Democratic leaders feared that if the letters were published, Wallace's exotic religious beliefs would alienate many voters. Republicans did plan to publish the Wallace letters, but the Democrats threatened to release information about Willkie's rumored extramarital affair with writer Irita Van Doren, resulting in a stalemate.
Eleanor Roosevelt's biographer and very close personal friend Joseph Lash wrote "The anti-Roosevelt underground campaign in 1940 was venomous, and (Democratic National Chairman) Flynn accused the Republicans of conducting the 'most vicious, most shameful campaign since the time of Lincoln.' Much of the abuse centered on Eleanor and the Roosevelt family." However, the abuse went both ways, as historian William Manchester noted: "above all, he [Willkie] should never have been subjected to the accusation of Henry Wallace, FDR's new vice-presidential candidate, that Willkie was the Nazis' choice."
The Election.
Willkie received 22.3 million votes (more than any previous Republican candidate), but was outpolled by Roosevelt with 27.3 million, losing the contest with 54.7% to 44.8% in the popular vote. Roosevelt won the electoral vote to 449 to 82. Willkie carried ten states: Maine, Vermont, Michigan, Indiana, Iowa, North Dakota, South Dakota, Nebraska, Kansas, and Colorado. However, Willkie did draw 5.8 million votes more than Alf Landon, the 1936 Republican candidate, and he ran strong in the rural Midwest, taking 57% of the farm vote. Roosevelt, meanwhile, carried every city in the nation with a population of more than 400,000, except for Cincinnati. Willkie was the only major-party nominee for President who never held major elected or appointive office or high military rank.
Post-election life.
After the election, Willkie became a fervent internationalist and an unlikely ally of Roosevelt. To the chagrin of many Republicans, Willkie spoke out for controversial Roosevelt initiatives such as Lend-Lease, and campaigned against isolationism. In 1941, Willkie joined with Eleanor Roosevelt to found Freedom House. On July 23, 1941, he urged unlimited aid to Britain. As Roosevelt's personal representative, he traveled to Britain and the Middle East in late 1941, and to the Soviet Union and China in 1942.
In 1943, Willkie published "One World", a book for popular audiences in which he recounted his world travels on the Gulliver and urged that America accept some form of "world government" after the war. "One World" was a best-seller that marked his transformation into a major spokesman for internationalism and made him a controversial figure within the Roosevelt administration and among his Republican colleagues, but it helped move public opinion from isolationism to internationalism. Its publication also extended Willkie's contacts with the world of literary critics and film executives.
Law Practice.
In April 1941, Willkie joined the law firm of Miller, Boston, and Owen in New York City, and shortly thereafter the firm changed its name to Willkie, Owen, Otis, Farr, and Gallagher. It is now Willkie Farr & Gallagher LLP.
Civil rights activist.
Willkie spoke often of the need to extend equal rights and privileges to African Americans and addressed a convention of the National Association for the Advancement of Colored People (NAACP) in 1942, one of the most prominent politicians to do so up to that time. When a violent race riot broke out in Detroit on June 20, 1943, Willkie went on national radio to criticize Republicans and Democrats for ignoring "the Negro question." He said, "The desire to deprive some of our citizens of their rights — economic, civic or political — has the same basic motivation as actuates the Fascist mind when it seeks to dominate whole peoples and nations. It is essential that we eliminate it at home as well as abroad." During this time, Willkie also worked with Walter White, executive secretary of the NAACP, to try to convince Hollywood to change its portrayal of blacks in the movies.
1944 Republican primaries.
In the 1944 presidential election, Willkie again sought the Republican nomination, choosing his wife's hometown, Rushville, Indiana, as his campaign headquarters. However, his progressive and internationalist views gained little support because of the rightward shift of the party and Republican rank-and-file resentment over Willkie's close collaboration with Roosevelt.
Having won a narrow victory in the New Hampshire primary, Willkie seemed at first a strong candidate in Wisconsin as well. However, a January 1944 poll in Wisconsin suddenly showed Dewey, the favorite of party regulars, leading Willkie by a two-to-one margin. "The New York Times" hailed the Willkie candidacy: "Win, lose or draw next Tuesday, Willkie will have made a campaign that reflects the sincerity of his convictions and the high quality of his leadership."
Willkie finished a distant fourth in Wisconsin, behind Dewey, General Douglas MacArthur, and Harold Stassen. Willkie received only 4.6 percent of the primary ballots. Following this decisive loss, Willkie withdrew from the race.
In remarks in Omaha, Nebraska, Willkie said:
It is obvious now that I cannot be nominated. I therefore am asking my friends to desist from any activity toward that end and not to present my name at the convention. I earnestly hope that the Republican convention will nominate a candidate and write a platform that really represents the views which I have advocated and which I believe are shared by millions of Americans. I shall continue to work for these principles and policies for which I have fought during the last five years.
By the time of his sudden death in October 1944, Wilkie had not endorsed either Dewey or Roosevelt, but Wilkie had approached Roosevelt with the possibility of forming a new party with support from liberals in both the Republican Party and the Democratic Party. Though Wilkie began working with the Liberal Party of New York to launch a new national party, Wilkie's death ended that effort.
Death.
In October 1944, Willkie was on a Pennsylvania Railroad train traveling from Indianapolis to New York City when he was stricken with a major heart attack somewhere in Ohio. Other passengers implored him to get off the train at Pittsburgh and go to a hospital there to seek treatment. Willkie, who had a history of cardiovascular issues prior to this sudden attack, chose to proceed on to his destination as he preferred to be treated by his own physician in New York and decided to wait until he got there to seek treatment for his worsening condition. He arrived safely at Pennsylvania Station in New York on October 6, 1944, but suffered a coronary thrombosis two days later and died in Lenox Hill Hospital, aged 52. Willkie's running mate, Senator McNary, died in February 1944 at the age of 69 from terminal brain cancer, marking the first time a major party's complete ticket died during the presidential term in which they would have served if elected.
Though he had been in ill health for a month prior to his passing, Willkie appeared a picture of robust health and was the dominant figure among internationalists within the Republican Party. At the time of his death, both Franklin Roosevelt and Thomas Dewey had been hoping for Willkie's support, which may have been worth several million votes from the undecided ranks.
In her "My Day" column for October 12, 1944, Eleanor Roosevelt eulogized Willkie as a "man of courage... [whose] outspoken opinions on race relations were among his great contributions to the thinking of the world. ... Americans tend to forget the names of the men who lost their bid for the presidency. Willkie proved the exception to this rule."
Wendell Willkie is interred at East Hill Cemetery in Rushville, Indiana. In his honor, the Bar of the Summit County Courthouse erected a brass bas relief which is prominently displayed in its main hall.
Legacies.
Willkie's name was prominently mentioned by keynote speaker and Democratic Senator Zell Miller at the 2004 Republican National Convention. Miller praised Willkie as a politician who embodied a non-partisan spirit of co-operation during wartime and praised his support of President Roosevelt's creation of a military draft. Miller spoke of Willkie saying, "Shortly before Willkie died, he told a friend, that if he could write his own epitaph and had to choose between 'here lies a president' or 'here lies one who contributed to saving freedom,' he would prefer the latter." Miller compared John Kerry negatively and blasted the senator for being critical of President George W. Bush's foreign policy by claiming Willkie refused to criticize FDR on foreign policy during a time of war.
"State of the Union", a 1945 play by Howard Lindsay and Russel Crouse about a fictional Republican presidential candidate, was reputedly inspired by Willkie's dalliance with alleged mistress Irita Bradford Van Doren. (The play was made into a movie in 1948.)
The experimental biography, One Life, by the contemporary American poet Muriel Rukeyser, explores Willkie's career as a public figure and his relations with F.D.R, Churchill, and Chiang Kai-Shek as well as anonymous members of the working class and poor of the First World War and the Great Depression. Rukeyser calls this biography both a "story and a song" and sees Willkie as a significant contributor to the American imagination.
Willkie is also featured as a character in Philip Roth's counterfactual history novel, "The Plot Against America," in which he opposes not FDR but Charles Lindbergh in the 1940 presidential election.
A large dormitory complex at Indiana University Bloomington is named after Willkie and for several decades was home to the Willkie Co-op, an experimental housing cooperative operated independent of university oversight by students.
In the Bugs Bunny animated cartoon "Falling Hare", Bugs is pestered by a gremlin while trying to fly a World War II bomber. When he realizes what the gremlin is, he timidly asks, "Could that have been a [whispering] gremlin?" In a German accent, the gremlin replies, shouting in Bugs's ear, "It ain't Vendell Villkie!" At the 1940 Republican National Convention, the head of one Midwest state delegation announced "two votes for Villkie" in a Scandinavian accent. Broadcast on national radio as it had been, "It ain't Vendell Vilkie" was briefly in vogue as a standard American rejoinder.
In an alternate history novel by S. M. Stirling, "Marching Through Georgia", Roosevelt retires after two terms and Willkie succeeds him as President. The short story 'Trips' by Robert Silverberg repeats the scenario.
The Liberty ship "SS Wendell L. Willkie" was laid down November 8, 1944, just one month after Willkie's death; it was commissioned December 9, 1944, and served with the United States Maritime Commission until it was scrapped in 1970.
Willkie was honored by the United States Postal Service with a 75¢ Great Americans series postage stamp.
Publications.
Willkie was the author of two books:
and a published collection of his speeches and writings:

</doc>
<doc id="34137" url="http://en.wikipedia.org/wiki?curid=34137" title="XFL">
XFL

XFL, LLC was a single entity professional American football league operated as the XFL, founded by World Wrestling Federation owner Vince McMahon. It was intended to be a major professional sports league complement to the offseason of the National Football League, but was unable to find an audience and ceased operation after its debut season in 2001. The XFL was widely ridiculed; McMahon conceded that the league was a "colossal failure".
Founding.
Created as a 50–50 joint venture between NBCUniversal and WWF-owned subsidiary WWE Properties International, Inc. under the company name "XFL, LLC", the XFL was created as a "single-entity league", meaning that the teams were not individually owned and operated franchises (as in the NFL), but that the league was operated as a single business unit. Vince McMahon's original plan was to purchase the Canadian Football League (after the CFL initially approached him about purchasing the Toronto Argonauts), while NBC was moving ahead at the time with Time Warner to create a football league of their own.
The concept of the league was first announced by league commissioner Tyler Schueck on February 3, 2000. The XFL was originally conceived to build on the success of the NFL and professional wrestling. It combined the scoring system of the NFL with the kayfabe and stunts of the WWE. It was hyped as "real" football without penalties for roughness and with fewer rules in general. The loud games featured players and coaches with microphones and cameras in the huddle and in the locker rooms. Stadiums featured trash-talking public address announcers and scantily-clad cheerleaders. Instead of a pre-game coin toss, XFL officials put the ball on the ground and let a player from each team scramble for it to determine who received the kickoff option (the was dubbed "The Human Coin Toss" by commentators), which led to the first XFL injury.
The XFL chose unusual names for its franchises, most of which either referenced images of uncontrolled insanity (Maniax, Rage, Xtreme, Demons) or criminal activity (Enforcers [a reference to mob enforcers], Hitmen, Outlaws, and the Birmingham Blast). After outrage from Birmingham residents who noted that Birmingham had a history of notorious "blasts," including the 16th Street Baptist Church bombing in 1963 and Eric Rudolph's 1998 bombing of a local abortion clinic, the XFL changed the name of the Birmingham team to the more benign "Birmingham Thunderbolts" (later shortened to "Bolts").
The XFL had impressive television coverage for an upstart league, with three games televised each week on NBC, UPN, and TNN.
Contrary to popular belief, the "X" in XFL did not stand for "extreme", as in "eXtreme Football League". When the league was first organized in 1999, it was originally supposed to stand for "Xtreme Football League"; however, there was already a league in formation at the same time with that name, and so promoters wanted to make sure that everyone knew that the "X" did not actually stand for anything (though McMahon would comment that "if the NFL stood for the 'No Fun League', the XFL will stand for the 'extra fun league'"). The other Xtreme Football League, which was also organized in 1999, merged with the Arena Football League's AF2 before ever fielding its first game.
Draft.
The only main draft for the league took place over a three-day period from October 28, 2000 to October 30, 2000. A total of 475 players were selected initially, with 65 additional players then selected in a supplemental draft on December 29, 2000.
2001 season.
The XFL's opening game took place on February 3, 2001, one year after the concept of the league was announced, and immediately following the NFL's Super Bowl. The first game was between the New York/New Jersey Hitmen and the Las Vegas Outlaws at Sam Boyd Stadium in Whitney, Nevada. The game ended with a 19–0 victory for the Outlaws, and was watched on NBC by an estimated 14 million viewers. During the telecast, NBC switched over to the game between the Orlando Rage and the Chicago Enforcers, which was a closer contest than the blowout taking place in Las Vegas. The opening night drew a 9.5 Nielsen rating.
Although the XFL began with better-than-expected TV ratings (the opening-week games actually delivered ratings double those of what NBC had promised advertisers and the Saturday broadcast had more viewers than the NFL Pro Bowl) and fair publicity, the audience declined sharply after the first week of the season, going from a 9.5 rating to a 4.6 in just one week, and the media attacked the league for what was perceived as a poor quality of play. A further problem was that the XFL itself was the brainchild of Vince McMahon, a man who was ridiculed by mainstream sports journalists due to the stigma attached to professional wrestling as being "fake"; many journalists even jokingly speculated whether any of the league's games were rigged, although nothing of this sort was ever seriously investigated.
Even longtime NBC sportscaster Bob Costas joined in the mocking of the league. In an appearance on "Late Night with Conan O'Brien" in February 2001, after the league's second week of play, Costas joked: "It has to be at least a decade since I first mused out loud, 'Why doesn't somebody combine mediocre high school football with a tawdry strip club?' Finally, somebody takes my idea and runs with it." He also said about the sharp drop in the television ratings in that second week: "I have to put the right spin on this because I'm also on NBC—apparently, it went through the toilet."
Teams.
Eastern Division
Western Division
XFL rule changes.
Despite boasts by WWF promoters of a "rules-light" game and universally negative reviews from the mainstream sports media early on, the XFL played a brand of 11-man outdoor football that was recognizable, aside from the opening game sprint to determine possession and some other changes, some modified during the season.
Grass stadiums.
All XFL teams had to play in outdoor stadiums with grass surfaces. No artificial turf fields or stadiums with domed or retractable roofs were allowed. In addition, every XFL field was designed identically, with no individual team branding on the field. Each end zone and 50-yard line was decorated with the XFL logo. In the league's two northernmost markets, Chicago and New York/New Jersey (the latter of which played in Giants Stadium during a brief window in which the stadium's usual artificial turf had been replaced by natural grass), the combination of the all-grass requirement, midwinter playing season and the fact that the XFL followed shortly after the NFL had used both fields for a full season caused significant damage to the playing fields; at Chicago's Soldier Field, the wear and tear on the field was such that by midseason, the midfield logo of the Enforcers' cross-league rivals the Chicago Bears was clearly visible amid a stretch of dirt and dead grass. Giants Stadium would have its artificial turf restored in 2003; Soldier Field was renovated extensively in 2002 but remained a grass field.
Opening scramble.
Replacing the coin toss at the beginning of each game was an event in which one player from each team fought to recover a football 20 yards away in order to determine possession. Both players lined up side-by-side on one of the 30-yard lines, with the ball being placed at the 50-yard line. At the whistle, the two players would run toward the ball and attempt to gain possession; whichever player gained possession first was allowed to choose possession (as if he had won a coin toss in other leagues). The XFL's first injury infamously resulted from the opening scramble; Orlando free safety Hassan Shamsid-Deen suffered a separated shoulder prior to the Rage's 33–29 season-opening win over the Chicago Enforcers at Florida Citrus Bowl Stadium on February 3. He ended up missing the remainder of the campaign.
No PAT (point after touchdown) kicks.
After touchdowns there were no extra point kicks, due to the XFL's perception that an extra point kick was a "guaranteed point." To earn a point after a touchdown, teams ran a single offensive down from the two-yard line (functionally identical to the NFL/NCAA/CFL two-point conversion), but for just a single point. By the playoffs, two-point and three-point conversions had been added to the rules. Teams could opt for the bonus points by playing the conversion farther back from the goal line.
This rule, as originally implemented, was similar to the WFL's "Action Point," and was identical to a 1968 "Pressure Point" experiment by the NFL and American Football League, used only in preseason interleague games that year.
Overtime.
Ties were resolved in similar fashion to the NCAA and present-day CFL game, with at least one possession by each team, starting from the opponent's 20-yard line. There were differences: there were no first downs – teams had to score within four downs, and the team that had possession first in overtime could not attempt a field goal until fourth down. If that team managed to score a touchdown in fewer than four downs, the second team would only have that same number of downs to match or beat the result. If the score was still tied after one overtime period, the team that played second on offense in the first OT would start on offense in the second OT.
Bump and run.
The XFL allowed full bump and run coverage early in the season. Defensive backs were allowed to hit wide receivers any time before the quarterback released the ball, as long as the hit came from the front or the side (similar to the NCAA). In an effort to increase offensive production, bump and run was restricted to the first five yards from the line of scrimmage (similar to NFL) following the fourth week of the season.
Forward motion.
Unlike the NFL, but like the World Football League and Arena Football League before it, the XFL allowed one offensive player to move toward the line of scrimmage once he was outside the tackles.
Halo rule / live punts.
The heavily-hyped "no fair catch" rule was paired with a five-yard zone excluding players of the kicking team around potential returners before the ball touched them or the ground, similar to rules in Canadian football, rugby union, and contemporary NCAA rules (where the term "halo" was applied, though the XFL called it instead the "danger zone"). But instead of making punt returns more exciting, it often had the opposite effect, since the XFL players' inexperience with the rule caused a high number of game-delaying penalties.
The fair catch had previously been abolished from Canadian football, NCAA rules (but only for the 1950 season), and rugby league.
Another difference was that after touching ground 25 yards or more beyond the line of scrimmage, punts could be recovered and advanced by all players of the kicking team. This led to more quick kicks being taken on third-down-and-long situations in the one season of the small league than had been seen in the NFL over several preceding decades of longer seasons. This XFL rule was similar to a rule that had been in effect in American football in the 1910s and part of the 1920s.
XFL penalized 10 yards from the succeeding spot for punts going out of bounds, even if they first touched the ground (but not a player of the receiving team). The changes practically eliminated the coffin corner kicking style, in which a good punter could pin an opposing offense deep in its own territory by precisely kicking a ball out of bounds a few yards from the end zone.
For the initial weeks of the season, the XFL forbade all players on the kicking team from going downfield before a kick was made from scrimmage on that down, similarly to a rule the NFL considered in 1974. For the rest of the season the XFL modified it to allow one player closest to each sideline downfield ahead of the kick, the same modification the NFL adopted to their change just before their 1974 exhibition games started.
The purpose of these provisions was to keep play going after the ball was punted, encouraging the kicking team to make the ball playable and the receiving team to run it back.
Play clock.
The XFL used a 35-second play clock, five seconds shorter than the contemporary NFL play clock of 40 seconds, in an effort to speed up the game.
Roster and salaries.
The XFL limited each team to an unusually low 38 players, as opposed to 53 on NFL teams and 80 or more on unlimited college rosters. This was similar to the CFL, which had a comparable 40-man roster limit in 2001. This resulted, most commonly, in each team only carrying two quarterbacks and one kicker who doubled as the punter.
The XFL paid standardized player salaries. Quarterbacks earned US$5,000 per week, kickers earned $3,500, and all other uniformed players earned $4,500 per week, though a few players got around these restrictions (Los Angeles Xtreme players Noel Prefontaine, the league's lone punting specialist, and Matt Malloy, a wide receiver) by having themselves listed as backup quarterbacks. Players on a winning team received a bonus of $2,500 for the week, $7,500 for winning a playoff game. The team that won the championship game split $1,000,000 (roughly $25,000 per player). Players did not receive any fringe benefits, and had to pay for their own health insurance.
Broadcast overview.
Sky cam.
Although the XFL was not the first football league to feature the "sky cam", which enables TV viewers to see behind the offensive unit, it helped to popularize its unique capabilities. For the first several weeks, the league used the sky cam and on-field cameramen extensively, giving the television broadcasts a perspective similar to video games such as the "Madden" series.
After the XFL's failure, the use of aerial blimps, the sky cam was adopted by the NFL's broadcasters; the device has subsequently come into use on all major networks. (It is not as widely used in most NFL broadcasts as it was in the XFL, except on "NBC Sunday Night Football".)
Broadcast schedule.
At the beginning of the season, NBC showed a feature game at 8 p.m. Eastern Time on Saturday nights, also taping a second game. The second game, in some weeks, would air in the visiting team's home market and be put on the air nationally if the feature game was a blowout (as was the case in week one) or encountered technical difficulties (as was the case in week two). Two games were shown each Sunday: one at 4 p.m. Eastern on TNN (now Spike TV) and another at 7 p.m. Eastern on UPN (which has since merged with The WB to form The CW).
In a notable departure from the NFL, in which any references to sports betting, including point spreads, are strictly prohibited on league broadcasts, XFL announcers were free to discuss point spreads during the game and did so frequently.
The XFL also had a fairly extensive local radio presence, often using nationally recognized disc jockeys. The morning radio duo of Rick and Bubba, for instance, was the radio broadcast team for the Birmingham Thunderbolts, while Opie and Anthony had covered pregame for NBC. Super Dave Osborne was a sideline reporter for Los Angeles Xtreme broadcasts on KLSX; WMVP carried Chicago Enforcers games.
In the third week of the season, the games were sped up through changes in the playing rules, and broadcasts were subjected to increased time constraints. The reason was the reaction of Lorne Michaels, creator and executive producer of "Saturday Night Live", to the length of the Los Angeles Xtreme versus Chicago Enforcers game that went into double overtime. This caused the start of "Saturday Night Live" to be pushed back from 11:30 p.m. Eastern Time to 12:15 a.m. Sunday morning. This angered Michaels, who expected high ratings with Jennifer Lopez as the show's host. For the rest of the season, the XFL cut off coverage at 11:00 Eastern Time, regardless of whether or not the game was over.
In the face of declining ratings, the XFL announced prior to week 6's game between the Orlando Rage and the Las Vegas Outlaws that they would be entering the Rage's cheerleaders' locker room during halftime. The heavily promoted event was, in fact, a stunt: instead of showing an entry into the room, viewers instead saw a sketch in which the cameraman knocked himself unconscious by running into the locker room door, followed by a "dream sequence" with only slightly suggestive content. Vince McMahon appeared at the beginning and the end of the sketch, berating the cameraman for his failure.
Media reception.
The XFL aimed to attract two distinct audiences: wrestling fans and football fans. The XFL also tried to attract fans from other areas of entertainment (e.g., movies).
Many football fans distrusted the league because of its relationship to pro wrestling. They had a hard time accepting that a close, come-from-behind win or a controversial ending had not been scripted in advance, although there was no evidence to support this (it did not help that the league's opening-night telecast began with a high-octane pep talk by WWE wrestler The Rock and with Vince McMahon addressing the stadium crowd during the pre-game ceremony with the bombast typical of his "Mr. McMahon" character on WWE telecasts).[]
The league was panned by critics as boring football with a tawdry broadcast style, although the broadcasts on TNN and to a lesser extent UPN and the Matt Vasgersian–helmed NBC coverage were considered comparatively professional. Longtime WWE play-by-play man Jim Ross got the bulk of the criticism for his play-by-play calls of XFL games despite his 30+ years of experience in calling wrestling matches as well as calling play-by-play for the NFL's Atlanta Falcons in the early 1990s.
Scoring was so scarce that bookmakers could not set the over-under total low enough. Gamblers who took the under, often in the mid 30s, would win consistently; they could even parlay the under for all four games in a weekend and win on a regular basis. Towards the end of the season, bookies needed to make the totals in the upper 20s, highly unusual in pro football gambling circles. The league was forced to change rules during the season to afford receivers more protection, but the mid-season rule changes did little to bolster league credibility.
In 2000, before the XFL's launch, the league aired a series of cheerleader commercials on NBC, featuring adult models such as Pennelope Jimenez, Karen McDougal, and Rachel Sterling. The most famous one featured them as some of the cheerleaders taking a shower in the locker room. Using camera angles and strategically placed objects, the commercial gave viewers the illusion that the cheerleaders were nude in the shower. The commercials caused controversy and were deemed too risqué by the media, and they were quickly withdrawn before the debut of the league.
End of season and failure.
The WWE and NBC each lost a reported $35 million. On April 21, 2001, the season concluded as the Los Angeles Xtreme defeated the San Francisco Demons 38–6 in the XFL Championship Game (which was originally given the Zen-like moniker "The Big Game at the End of the Season", but was later dubbed the Million Dollar Game, after the amount of money awarded to the winning team).
Though paid attendance at games remained respectable, if unimpressive (overall attendance was only 10% below what the league's goal had been at the start of the season), the XFL ceased operations after just one season due to low TV ratings. Facing stiff competition from the NCAA Basketball Tournament, the NBC telecast of the Chicago/NY-NJ game on March 31 received a 1.5 rating, at that time the lowest ever for any major network primetime weekend first-run sports television broadcast in the United States.
Despite initially agreeing to broadcast XFL games for two years and owning half of the league, NBC announced it would not broadcast a second XFL season, admitting failure in its attempt at airing replacement pro football. WWE Chairman Vince McMahon initially announced that the XFL would continue, as it still had UPN and TNN as broadcast outlets. In fact, expansion teams were being explored for cities such as Washington, D.C. and Detroit. However, in order to continue broadcasting XFL games, UPN demanded that "WWE SmackDown!" broadcasts be cut from two hours to one and a half hours. McMahon found these terms unacceptable and he announced the XFL's closure on May 10, 2001. McMahon's chief adviser, a perplexed Nathan Livian, was quoted as saying "the situation is, indeed, very bad".
One reason for the failure of the league to catch on, despite its financial solvency and massive visibility, was the lack of respect for the league in the sports media. XFL games were rarely treated as sports contests, but rather more like WWE-like sensationalized events. With few NFL-quality players, save Tommy Maddox, the league's MVP, and with little thoughtful analysis or even consideration by sports columnists, the XFL never gained the necessary recognition to be regarded as a viable league. The fact that the league was co-owned by NBC made ESPN (which was part of the same corporation as ABC) and Fox Sports Net (owned by Fox TV) disinclined to report on the XFL, though Time Warner properties such as "Sports Illustrated", as well as the Associated Press, devoted coverage to the league ("Sports Illustrated" even featured the XFL on the cover of its February 12, 2001, edition, albeit with the description of it being "sleazy gimmicks and low-rent football"). Many local TV newscasts and newspapers (even in XFL cities) did not report league scores or show highlights. This led to many football fans treating the XFL as a joke, rather than competition to the NFL. Other problems included the scantily-clad cheerleaders, trash-talking announcers, and the lack of penalties for roughness.
The XFL ranked No. 3 on "TV Guide"‍ '​s list of the TV Guide's worst TV shows of all time in July 2002, as well as No. 2 on ESPN's list of biggest flops in sports, behind Ryan Leaf. In 2010, TV Guide Network also listed the show at No. 21 on their list of "25 Biggest TV Blunders".
Many stories recapping the history of the XFL show photos of the crash of its promotional blimp, portraying it retrospectively as an ill-omen for the league. The incident occurred a month before the opening game, when its pilot and a student pilot with him, lost control of the airship and were forced to evacuate. The ground crew were unable to secure the vehicle and the "unattended blimp then floated five miles north over the Oakland Estuary, at one point reaching 1,600 feet, until its gondola caught on a sailboat mast in the Central Basin marina. It draped over the roof of the Oyster Reef restaurant -- next to where the boat was moored -- and a nearby power line." While the pilot was hospitalized no other major injuries were reported. The blimp needed $2.5 million in repairs, the sailboat and restaurant had only minor damages. Also before the season started, a fictional XFL game appeared in the Schwarzenegger movie "The 6th Day" set in 2015.
Legacy.
Despite its unimpressive showing among the TV audience, the XFL finished the entire schedule without a franchise folding.
The league popularized "in-game" interviews: Today, National Hockey League players are interviewed between commercial breaks and Major League Baseball has managers and coaches being interviewed. The National Basketball Association also often features in-game interviews with coaches on games televised on ESPN and TNT following the 1st quarter of certain games.
NBC continued airing professional league football beyond the demise of the XFL, starting with the Arena Football League television coverage from 2003 to 2006. In 2006, NBC returned to coverage of NFL games with "NBC Sunday Night Football". The occasional use of the "sky-cam" and sideline interviews are the only features common to both the NFL and XFL coverage.
XFL team names and logos sometimes appear in movies and television where professional football needs to be dramatized, as licensing for NFL logos may be cost prohibitive (such as in the Arnold Schwarzenegger starring sci-fi film The 6th Day).
The United Football League later placed all four of its inaugural franchises in former XFL markets and stadiums. However, the UFL drew far fewer fans than the XFL average: For example, the XFL's San Francisco Demons drew an average of 35,000 fans, while the UFL's California Redwoods drew an average of 6,000, despite both playing in the same ballpark. Three of the four charter teams, including the Redwoods, moved to other markets by the time of the UFL's third season.
Notable players.
Notable players included league MVP and Los Angeles quarterback Tommy Maddox, who signed with the Pittsburgh Steelers after the XFL folded (Maddox later became the starting quarterback for the Steelers in 2002 and led them to that year's playoffs, as well as continuing to start for them into 2004). Los Angeles used the first pick in the XFL draft to select a former NFL quarterback, Scott Milanovich. Milanovich lost the starting quarterback job to Maddox, who was placed on the Xtreme as one of a handful of players put on each team due to geographic distance between the player's college and the team's hometown. Another of the better-known players was Las Vegas running back Rod Smart, who first gained popularity because the name on the back of his jersey read "He Hate Me." Smart, who was only picked 357th in the draft, later went on to play for the Philadelphia Eagles, Carolina Panthers, and the Oakland Raiders. His Panther teammate Jake Delhomme named his newborn horse "She Hate Me" as a reference to him. Smart played in Super Bowl XXXVIII becoming one of seven XFL players to play in a Super Bowl. Receiver Yo Murphy also achieved this as a member of the St. Louis Rams in Super Bowl XXXVI). Tommy Maddox played for a Super Bowl team (with the Pittsburgh Steelers) in Super Bowl XL in Detroit, (although Maddox, by then a third-string quarterback, did not play in the game, which turned out to be his last appearance in uniform before retiring). Lastly, Las Vegas Outlaws DB Kelly Herndon played in Super Bowl XL with the Seattle Seahawks in 2005, where he is remembered for intercepting a pass and returning it a then-record 76 yards. Although he did not play for an NFL team after the XFL's lone season, former Las Vegas Outlaw offensive guard Isaac Davis also had a notable NFL career, playing in 58 games over a six-year career. Davis started for the San Diego Chargers in Super Bowl XXIX.
Current status.
XFL games are now part of the WWE Video Library. Comcast, the current owners of NBCUniversal, would also presumably co-own distribution rights to XFL games along with WWE.
In September 2012, WWE attempted to file a new XFL trademark for use in wrestling and football which was previously filed in 2009 under XFL LLC. The application is still pending since WWE have not put together a "Statement of Use" for the trademark. WWE could consider abandoning the old application and file the new one under WWE Inc. As of 2014, the trademark status is "response after non-final action" meaning it likely remains active.

</doc>
<doc id="34138" url="http://en.wikipedia.org/wiki?curid=34138" title="XML">
XML

Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format which is both human-readable and machine-readable. It is defined by the W3C's XML 1.0 Specification and by several other related specifications, all of which are free open standards.
The design goals of XML emphasize simplicity, generality and usability across the Internet. It is a textual data format with strong support via Unicode for different human languages. Although the design of XML focuses on documents, it is widely used for the representation of arbitrary data structures such as those used in web services.
Several schema systems exist to aid in the definition of XML-based languages, while many application programming interfaces (APIs) have been developed to aid the processing of XML data.
Applications of XML.
s of 2009[ [update]], hundreds of document formats using XML syntax have been developed, including RSS, Atom, SOAP, and XHTML. XML-based formats have become the default for many office-productivity tools, including Microsoft Office (Office Open XML), OpenOffice.org and LibreOffice (OpenDocument), and Apple's iWork. XML has also been employed as the base language for communication protocols, such as XMPP. Applications for the Microsoft .NET Framework use XML files for configuration. Apple has an implementation of a registry based on XML.
XML has come into common use for the interchange of data over the Internet. IETF RFC 7303 gives rules for the construction of Internet Media Types for use when sending XML. It also defines the media types "application/xml" and "text/xml", which say only that the data is in XML, and nothing about its semantics. The use of "text/xml" has been criticized as a potential source of encoding problems and it has been suggested that it should be deprecated.
RFC 7303 also recommends that XML-based languages be given media types ending in "+xml"; for example "image/svg+xml" for SVG.
Further guidelines for the use of XML in a networked context may be found in RFC 3470, also known as IETF BCP 70, a document covering many aspects of designing and deploying an XML-based language.
Key terminology.
The material in this section is based on the XML Specification. This is not an exhaustive list of all the constructs that appear in XML; it provides an introduction to the key constructs most often encountered in day-to-day use.
Characters and escaping.
XML documents consist entirely of characters from the Unicode repertoire. Except for a small number of specifically excluded control characters, any character defined by Unicode may appear within the content of an XML document.
XML includes facilities for identifying the "encoding" of the Unicode characters that make up the document, and for expressing characters that, for one reason or another, cannot be used directly.
Valid characters.
Unicode code points in the following ranges are valid in XML 1.0 documents:
XML 1.1 extends the set of allowed characters to include all the above, plus the remaining characters in the range U+0001–U+001F. At the same time, however, it restricts the use of C0 and C1 control characters other than U+0009, U+000A, U+000D, and U+0085 by requiring them to be written in escaped form (for example U+0001 must be written as &#x01; or its equivalent). In the case of C1 characters, this restriction is a backwards incompatibility; it was introduced to allow common encoding errors to be detected.
The code point U+0000 is the only character that is not permitted in any XML 1.0 or 1.1 document.
Encoding detection.
The Unicode character set can be encoded into bytes for storage or transmission in a variety of different ways, called "encodings". Unicode itself defines encodings that cover the entire repertoire; well-known ones include UTF-8 and UTF-16. There are many other text encodings that predate Unicode, such as ASCII and ISO/IEC 8859; their character repertoires in almost every case are subsets of the Unicode character set.
XML allows the use of any of the Unicode-defined encodings, and any other encodings whose characters also appear in Unicode. XML also provides a mechanism whereby an XML processor can reliably, without any prior knowledge, determine which encoding is being used. Encodings other than UTF-8 and UTF-16 will not necessarily be recognized by every XML parser.
Escaping.
XML provides "escape" facilities for including characters which are problematic to include directly. For example:
There are five predefined entities:
All permitted Unicode characters may be represented with a "numeric character reference". Consider the Chinese character "中", whose numeric code in Unicode is hexadecimal 4E2D, or decimal 20,013. A user whose keyboard offers no method for entering this character could still insert it in an XML document encoded either as codice_23 or codice_24. Similarly, the string "codice_25" could be encoded for inclusion in an XML document as "codice_26".
"codice_27" is not permitted, however, because the null character is one of the control characters excluded from XML, even when using a numeric character reference. An alternative encoding mechanism such as Base64 is needed to represent such characters.
Comments.
Comments may appear anywhere in a document outside other markup. Comments cannot appear before the XML declaration. Comments start with "codice_28" and end with "codice_29". For compatibility with SGML, the string "codice_30" (double-hyphen) is not allowed inside comments; this means comments cannot be nested. The ampersand has no special significance within comments, so entity and character references are not recognized as such, and there is no way to represent characters outside the character set of the document encoding.
An example of a valid comment:
"codice_31"
International use.
XML 1.0 (Fifth Edition) and XML 1.1 support the direct use of almost any Unicode character in element names, attributes, comments, character data, and processing instructions (other than the ones that have special symbolic meaning in XML itself, such as the less-than sign, "<"). The following is a well-formed XML document including Chinese, Armenian and Cyrillic characters:
Well-formedness and error-handling.
The XML specification defines an XML document as a well-formed text – meaning that it satisfies a list of syntax rules provided in the specification. Some key points in the fairly lengthy list include:
The definition of an "XML document" excludes texts that contain violations of well-formedness rules; they are simply not XML. An XML processor that encounters such a violation is required to report such errors and to cease normal processing. This policy, occasionally referred to as "draconian error handling," stands in notable contrast to the behavior of programs that process HTML, which are designed to produce a reasonable result even in the presence of severe markup errors. XML's policy in this area has been criticized as a violation of Postel's law ("Be conservative in what you send; be liberal in what you accept").
The XML specification defines a valid XML document as a well-formed XML document which also conforms to the rules of a Document Type Definition (DTD).
Schemas and validation.
In addition to being well-formed, an XML document may be "valid". This means that it contains a reference to a Document Type Definition (DTD), and that its elements and attributes are declared in that DTD and follow the grammatical rules for them that the DTD specifies.
XML processors are classified as "validating" or "non-validating" depending on whether or not they check XML documents for validity. A processor that discovers a validity error must be able to report it, but may continue normal processing.
A DTD is an example of a "schema" or "grammar". Since the initial publication of XML 1.0, there has been substantial work in the area of schema languages for XML. Such schema languages typically constrain the set of elements that may be used in a document, which attributes may be applied to them, the order in which they may appear, and the allowable parent/child relationships.
Document Type Definition.
The oldest schema language for XML is the Document Type Definition (DTD), inherited from SGML.
DTDs have the following benefits:
DTDs have the following limitations:
Two peculiar features that distinguish DTDs from other schema types are the syntactic support for embedding a DTD within XML documents and for defining "entities", which are arbitrary fragments of text and/or markup that the XML processor inserts in the DTD itself and in the XML document wherever they are referenced, like character escapes.
DTD technology is still used in many applications because of its ubiquity.
XML Schema.
A newer schema language, described by the W3C as the successor of DTDs, is XML Schema, often referred to by the initialism for XML Schema instances, XSD (XML Schema Definition). XSDs are far more powerful than DTDs in describing XML languages. They use a rich datatyping system and allow for more detailed constraints on an XML document's logical structure. XSDs also use an XML-based format, which makes it possible to use ordinary XML tools to help process them.
xs:schema element that defines a schema:
RELAX NG.
RELAX NG was initially specified by OASIS and is now also an ISO/IEC International Standard (as part of DSDL). RELAX NG schemas may be written in either an XML based syntax or a more compact non-XML syntax; the two syntaxes are isomorphic and James Clark's conversion tool - ", can convert between them without loss of information. RELAX NG has a simpler definition and validation framework than XML Schema, making it easier to use and implement. It also has the ability to use datatype framework plug-ins; a RELAX NG schema author, for example, can require values in an XML document to conform to definitions in XML Schema Datatypes.
Schematron.
Schematron is a language for making assertions about the presence or absence of patterns in an XML document. It typically uses XPath expressions.
ISO DSDL and other schema languages.
The ISO DSDL (Document Schema Description Languages) standard brings together a comprehensive set of small schema languages, each targeted at specific problems. DSDL includes RELAX NG full and compact syntax, Schematron assertion language, and languages for defining datatypes, character repertoire constraints, renaming and entity expansion, and namespace-based routing of document fragments to different validators. DSDL schema languages do not have the vendor support of XML Schemas yet, and are to some extent a grassroots reaction of industrial publishers to the lack of utility of XML Schemas for publishing.
Some schema languages not only describe the structure of a particular XML format but also offer limited facilities to influence processing of individual XML files that conform to this format. DTDs and XSDs both have this ability; they can for instance provide the infoset augmentation facility and attribute defaults. RELAX NG and Schematron intentionally do not provide these.
Related specifications.
A cluster of specifications closely related to XML have been developed, starting soon after the initial publication of XML 1.0. It is frequently the case that the term "XML" is used to refer to XML together with one or more of these other technologies which have come to be seen as part of the XML core.
Some other specifications conceived as part of the "XML Core" have failed to find wide adoption, including XInclude, XLink, and XPointer.
Programming interfaces.
The design goals of XML include, "It shall be easy to write programs which process XML documents." Despite this, the XML specification contains almost no information about how programmers might go about doing such processing. The XML Infoset specification provides a vocabulary to refer to the constructs within an XML document, but also does not provide any guidance on how to access this information. A variety of APIs for accessing XML have been developed and used, and some have been standardized.
Existing APIs for XML processing tend to fall into these categories:
Stream-oriented facilities require less memory and, for certain tasks which are based on a linear traversal of an XML document, are faster and simpler than other alternatives. Tree-traversal and data-binding APIs typically require the use of much more memory, but are often found more convenient for use by programmers; some include declarative retrieval of document components via the use of XPath expressions.
XSLT is designed for declarative description of XML document transformations, and has been widely implemented both in server-side packages and Web browsers. XQuery overlaps XSLT in its functionality, but is designed more for searching of large XML databases.
Simple API for XML.
Simple API for XML (SAX) is a lexical, event-driven interface in which a document is read serially and its contents are reported as callbacks to various methods on a handler object of the user's design. SAX is fast and efficient to implement, but difficult to use for extracting information at random from the XML, since it tends to burden the application author with keeping track of what part of the document is being processed. It is better suited to situations in which certain types of information are always handled the same way, no matter where they occur in the document.
Pull parsing.
Pull parsing treats the document as a series of items which are read in sequence using the Iterator design pattern. This allows for writing of recursive-descent parsers in which the structure of the code performing the parsing mirrors the structure of the XML being parsed, and intermediate parsed results can be used and accessed as local variables within the methods performing the parsing, or passed down (as method parameters) into lower-level methods, or returned (as method return values) to higher-level methods. Examples of pull parsers include StAX in the Java programming language, XMLPullParser in Smalltalk, XMLReader in PHP, ElementTree.iterparse in Python, System.Xml.XmlReader in the .NET Framework, and the DOM traversal API (NodeIterator and TreeWalker).
A pull parser creates an iterator that sequentially visits the various elements, attributes, and data in an XML document. Code which uses this iterator can test the current item (to tell, for example, whether it is a start or end element, or text), and inspect its attributes (local name, namespace, values of XML attributes, value of text, etc.), and can also move the iterator to the next item. The code can thus extract information from the document as it traverses it. The recursive-descent approach tends to lend itself to keeping data as typed local variables in the code doing the parsing, while SAX, for instance, typically requires a parser to manually maintain intermediate data within a stack of elements which are parent elements of the element being parsed. Pull-parsing code can be more straightforward to understand and maintain than SAX parsing code.
Document Object Model.
The Document Object Model (DOM) is an interface-oriented application programming interface that allows for navigation of the entire document as if it were a tree of node objects representing the document's contents. A DOM document can be created by a parser, or can be generated manually by users (with limitations). Data types in DOM nodes are abstract; implementations provide their own programming language-specific bindings. DOM implementations tend to be memory intensive, as they generally require the entire document to be loaded into memory and constructed as a tree of objects before access is allowed.
Data binding.
Another form of XML processing API is XML data binding, where XML data are made available as a hierarchy of custom, strongly typed classes, in contrast to the generic objects created by a Document Object Model parser. This approach simplifies code development, and in many cases allows problems to be identified at compile time rather than run-time. Example data binding systems include the Java Architecture for XML Binding (JAXB) and XML Serialization in .NET.
XML as data type.
XML has appeared as a first-class data type in other languages. The ECMAScript for XML (E4X) extension to the ECMAScript/JavaScript language explicitly defines two specific objects (XML and XMLList) for JavaScript, which support XML document nodes and XML node lists as distinct objects and use a dot-notation specifying parent-child relationships. E4X is supported by the Mozilla 2.5+ browsers (though now deprecated) and Adobe Actionscript, but has not been adopted more universally. Similar notations are used in Microsoft's LINQ implementation for Microsoft .NET 3.5 and above, and in Scala (which uses the Java VM). The open-source xmlsh application, which provides a Linux-like shell with special features for XML manipulation, similarly treats XML as a data type, using the <[ ]> notation. The Resource Description Framework defines a data type codice_39 to hold wrapped, canonical XML.
History.
XML is an application profile of SGML (ISO 8879).
The versatility of SGML for dynamic information display was understood by early digital media publishers in the late 1980s prior to the rise of the Internet. By the mid-1990s some practitioners of SGML had gained experience with the then-new World Wide Web, and believed that SGML offered solutions to some of the problems the Web was likely to face as it grew. Dan Connolly added SGML to the list of W3C's activities when he joined the staff in 1995; work began in mid-1996 when Sun Microsystems engineer Jon Bosak developed a charter and recruited collaborators. Bosak was well connected in the small community of people who had experience both in SGML and the Web.
XML was compiled by a working group of eleven members, supported by a (roughly) 150-member Interest Group. Technical debate took place on the Interest Group mailing list and issues were resolved by consensus or, when that failed, majority vote of the Working Group. A record of design decisions and their rationales was compiled by Michael Sperberg-McQueen on December 4, 1997. James Clark served as Technical Lead of the Working Group, notably contributing the empty-element "<empty />" syntax and the name "XML". Other names that had been put forward for consideration included "MAGMA" (Minimal Architecture for Generalized Markup Applications), "SLIM" (Structured Language for Internet Markup) and "MGML" (Minimal Generalized Markup Language). The co-editors of the specification were originally Tim Bray and Michael Sperberg-McQueen. Halfway through the project Bray accepted a consulting engagement with Netscape, provoking vociferous protests from Microsoft. Bray was temporarily asked to resign the editorship. This led to intense dispute in the Working Group, eventually solved by the appointment of Microsoft's Jean Paoli as a third co-editor.
The XML Working Group never met face-to-face; the design was accomplished using a combination of email and weekly teleconferences. The major design decisions were reached in a short burst of intense work between August and November 1996, when the first Working Draft of an XML specification was published. Further design work continued through 1997, and XML 1.0 became a W3C Recommendation on February 10, 1998.
Sources.
XML is a profile of an ISO standard SGML, and most of XML comes from SGML unchanged. From SGML comes the separation of logical and physical structures (elements and entities), the availability of grammar-based validation (DTDs), the separation of data and metadata (elements and attributes), mixed content, the separation of processing from representation (processing instructions), and the default angle-bracket syntax. Removed were the SGML declaration (XML has a fixed delimiter set and adopts Unicode as the document character set).
Other sources of technology for XML were the Text Encoding Initiative (TEI), which defined a profile of SGML for use as a "transfer syntax"; and HTML, in which elements were synchronous with their resource, document character sets were separate from resource encoding, the xml:lang attribute was invented, and (like HTTP) metadata accompanied the resource rather than being needed at the declaration of a link. The Extended Reference Concrete Syntax (ERCS) project of the SPREAD (Standardization Project Regarding East Asian Documents) project of the ISO-related China/Japan/Korea Document Processing expert group was the basis of XML 1.0's naming rules; SPREAD also introduced hexadecimal numeric character references and the concept of references to make available all Unicode characters. To support ERCS, XML and HTML better, the SGML standard IS 8879 was revised in 1996 and 1998 with WebSGML Adaptations. The XML header followed that of ISO HyTime.
Ideas that developed during discussion which were novel in XML included the algorithm for encoding detection and the encoding header, the processing instruction target, the xml:space attribute, and the new close delimiter for empty-element tags. The notion of well-formedness as opposed to validity (which enables parsing without a schema) was first formalized in XML, although it had been implemented successfully in the Electronic Book Technology "Dynatext" software; the software from the University of Waterloo New Oxford English Dictionary Project; the RISP LISP SGML text processor at Uniscope, Tokyo; the US Army Missile Command IADS hypertext system; Mentor Graphics Context; Interleaf and Xerox Publishing System.
Versions.
There are two current versions of XML. The first ("XML 1.0") was initially defined in 1998. It has undergone minor revisions since then, without being given a new version number, and is currently in its fifth edition, as published on November 26, 2008. It is widely implemented and still recommended for general use.
The second ("XML 1.1") was initially published on February 4, 2004, the same day as XML 1.0 Third Edition, and is currently in its second edition, as published on August 16, 2006. It contains features (some contentious) that are intended to make XML easier to use in certain cases. The main changes are to enable the use of line-ending characters used on EBCDIC platforms, and the use of scripts and characters absent from Unicode 3.2. XML 1.1 is not very widely implemented and is recommended for use only by those who need its unique features.
Prior to its fifth edition release, XML 1.0 differed from XML 1.1 in having stricter requirements for characters available for use in element and attribute names and unique identifiers: in the first four editions of XML 1.0 the characters were exclusively enumerated using a specific version of the Unicode standard (Unicode 2.0 to Unicode 3.2.) The fifth edition substitutes the mechanism of XML 1.1, which is more future-proof but reduces redundancy. The approach taken in the fifth edition of XML 1.0 and in all editions of XML 1.1 is that only certain characters are forbidden in names, and everything else is allowed, in order to accommodate the use of suitable name characters in future versions of Unicode. In the fifth edition, XML names may contain characters in the Balinese, Cham, or Phoenician scripts among many others which have been added to Unicode since Unicode 3.2.
Almost any Unicode code point can be used in the character data and attribute values of an XML 1.0 or 1.1 document, even if the character corresponding to the code point is not defined in the current version of Unicode. In character data and attribute values, XML 1.1 allows the use of more control characters than XML 1.0, but, for "robustness", most of the control characters introduced in XML 1.1 must be expressed as numeric character references (and #x7F through #x9F, which had been allowed in XML 1.0, are in XML 1.1 even required to be expressed as numeric character references). Among the supported control characters in XML 1.1 are two line break codes that must be treated as whitespace. Whitespace characters are the only control codes that can be written directly.
There has been discussion of an XML 2.0, although no organization has announced plans for work on such a project. XML-SW (SW for skunkworks), written by one of the original developers of XML, contains some proposals for what an XML 2.0 might look like: elimination of DTDs from syntax, integration of namespaces, XML Base and XML Information Set ("infoset") into the base standard.
The World Wide Web Consortium also has an XML Binary Characterization Working Group doing preliminary research into use cases and properties for a binary encoding of the XML infoset. The working group is not chartered to produce any official standards. Since XML is by definition text-based, ITU-T and ISO are using the name "Fast Infoset" for their own binary infoset to avoid confusion (see ITU-T Rec. X.891 | ISO/IEC 24824-1).
Criticism.
XML and its extensions have regularly been criticized for verbosity and complexity. Mapping the basic tree model of XML to type systems of programming languages or databases can be difficult, especially when XML is used for exchanging highly structured data between applications, which was not its primary design goal. Other criticisms attempt to refute the claim that XML is a self-describing language (though the XML specification itself makes no such claim). JSON, YAML, and S-Expressions are frequently proposed as alternatives (see Comparison of data serialization formats); which focus on representing highly structured data rather than documents, which may contain both highly structured and relatively unstructured content.

</doc>
<doc id="34139" url="http://en.wikipedia.org/wiki?curid=34139" title="Xenon">
Xenon

Xenon is a chemical element with symbol Xe and atomic number 54. It is a colorless, dense, odorless noble gas, that occurs in the Earth's atmosphere in trace amounts. Although generally unreactive, xenon can undergo a few chemical reactions such as the formation of xenon hexafluoroplatinate, the first noble gas compound to be synthesized.
Naturally occurring xenon consists of eight stable isotopes. There are also over 40 unstable isotopes that undergo radioactive decay. The isotope ratios of xenon are an important tool for studying the early history of the Solar System. Radioactive xenon-135 is produced from iodine-135 as a result of nuclear fission, and it acts as the most significant neutron absorber in nuclear reactors.
Xenon is used in flash lamps and arc lamps, and as a general anesthetic. The first excimer laser design used a xenon dimer molecule (Xe2) as its lasing medium, and the earliest laser designs used xenon flash lamps as pumps. Xenon is also being used to search for hypothetical weakly interacting massive particles and as the propellant for ion thrusters in spacecraft.
History.
Xenon was discovered in England by the Scottish chemist William Ramsay and English chemist Morris Travers on July 12, 1898, shortly after their discovery of the elements krypton and neon. They found xenon in the residue left over from evaporating components of liquid air. Ramsay suggested the name "xenon" for this gas from the Greek word "ξένον" [xenon], neuter singular form of "ξένος" [xenos], meaning 'foreign(er)', 'strange(r)', or 'guest'. In 1902, Ramsay estimated the proportion of xenon in the Earth's atmosphere as one part in 20 million.
During the 1930s, American engineer Harold Edgerton began exploring strobe light technology for high speed photography. This led him to the invention of the xenon flash lamp, in which light is generated by sending a brief electrical current through a tube filled with xenon gas. In 1934, Edgerton was able to generate flashes as brief as one microsecond with this method.
In 1939, American physician Albert R. Behnke Jr. began exploring the causes of "drunkenness" in deep-sea divers. He tested the effects of varying the breathing mixtures on his subjects, and discovered that this caused the divers to perceive a change in depth. From his results, he deduced that xenon gas could serve as an anesthetic. Although Russian toxicologist Nikolay V. Lazarev apparently studied xenon anesthesia in 1941, the first published report confirming xenon anesthesia was in 1946 by American medical researcher John H. Lawrence, who experimented on mice. Xenon was first used as a surgical anesthetic in 1951 by American anesthesiologist Stuart C. Cullen, who successfully operated on two patients.
Xenon and the other noble gases were for a long time considered to be completely chemically inert and not able to form compounds. However, while teaching at the University of British Columbia, Neil Bartlett discovered that the gas platinum hexafluoride (PtF6) was a powerful oxidizing agent that could oxidize oxygen gas (O2) to form dioxygenyl hexafluoroplatinate (O2+[PtF6]−). Since O2 and xenon have almost the same first ionization potential, Bartlett realized that platinum hexafluoride might also be able to oxidize xenon. On March 23, 1962, he mixed the two gases and produced the first known compound of a noble gas, xenon hexafluoroplatinate. Bartlett thought its composition to be Xe+[PtF6]−, although later work has revealed that it was probably a mixture of various xenon-containing salts. Since then, many other xenon compounds have been discovered, along with some compounds of the noble gases argon, krypton, and radon, including argon fluorohydride (HArF), krypton difluoride (KrF2), and radon fluoride. By 1971, more than 80 xenon compounds were known.
In November 1999 a team of IBM scientists demonstrated a technology capable of manipulating individual atoms. The program, called IBM in atoms, used a scanning tunneling microscope to arrange 35 individual xenon atoms on a substrate of chilled crystal of nickel to spell out the three letter company acronym. It was the first time atoms had been precisely positioned on a flat surface.
Characteristics.
Xenon has atomic number 54; that is, its nucleus contains 54 protons. At standard temperature and pressure, pure xenon gas has a density of 5.761 kg/m3, about 4.5 times the surface density of the Earth's atmosphere, 1.217 kg/m3. As a liquid, xenon has a density of up to 3.100 g/mL, with the density maximum occurring at the triple point. Under the same conditions, the density of solid xenon, 3.640 g/cm3, is higher than the average density of granite, 2.75 g/cm3. Using gigapascals of pressure, xenon has been forced into a metallic phase.
Solid xenon changes from face-centered cubic (fcc) to hexagonal close packed (hcp) crystal phase under pressure and begins to turn metallic at about 140 GPa, with no noticeable volume change in the hcp phase. It is completely metallic at 155 GPa. When metalized, xenon looks sky blue because it absorbs red light and transmits other visible frequencies. Such behavior is unusual for a metal and is explained by the relatively small widths of the electron bands in metallic xenon.
Xenon is a member of the zero-valence elements that are called noble or inert gases. It is inert to most common chemical reactions (such as combustion, for example) because the outer valence shell contains eight electrons. This produces a stable, minimum energy configuration in which the outer electrons are tightly bound.
In a gas-filled tube, xenon emits a blue or lavenderish glow when the gas is excited by electrical discharge. Xenon emits a band of emission lines that span the visual spectrum,
but the most intense lines occur in the region of blue light, which produces the coloration.
Occurrence and production.
Xenon is a trace gas in Earth's atmosphere, occurring at 87±1 parts per billion (nL/L), or approximately 1 part per 11.5 million, and is also found as a component in gases emitted from some mineral springs.
Xenon is obtained commercially as a by-product of the separation of air into oxygen and nitrogen. After this separation, generally performed by fractional distillation in a double-column plant, the liquid oxygen produced will contain small quantities of krypton and xenon. By additional fractional distillation steps, the liquid oxygen may be enriched to contain 0.1–0.2% of a krypton/xenon mixture, which is extracted either via absorption onto silica gel or by distillation. Finally, the krypton/xenon mixture may be separated into krypton and xenon via distillation. Worldwide production of xenon in 1998 was estimated at 5,000–7,000 m3. Because of its low abundance, xenon is much more expensive than the lighter noble gases—approximate prices for the purchase of small quantities in Europe in 1999 were 10 €/L for xenon, 1 €/L for krypton, and 0.20 €/L for neon; the much more plentiful argon costs less than a cent per liter.
Within the Solar System, the nucleon fraction of xenon is 1.56 × 10−8, for an abundance of approximately one part in 630 thousand of the total mass. Xenon is relatively rare in the Sun's atmosphere, on Earth, and in asteroids and comets. The planet Jupiter has an unusually high abundance of xenon in its atmosphere; about 2.6 times as much as the Sun. This high abundance remains unexplained and may have been caused by an early and rapid buildup of planetesimals—small, subplanetary bodies—before the presolar disk began to heat up. (Otherwise, xenon would not have been trapped in the planetesimal ices.) The problem of the low terrestrial xenon may potentially be explained by covalent bonding of xenon to oxygen within quartz, hence reducing the outgassing of xenon into the atmosphere.
Unlike the lower mass noble gases, the normal stellar nucleosynthesis process inside a star does not form xenon. Elements more massive than iron-56 have a net energy cost to produce through fusion, so there is no energy gain for a star when creating xenon. Instead, xenon is formed during supernova explosions, by the slow neutron capture process (s-process) of red giant stars that have exhausted the hydrogen at their cores and entered the asymptotic giant branch, in classical nova explosions and from the radioactive decay of elements such as iodine, uranium and plutonium.
Isotopes and isotopic studies.
Naturally occurring xenon is made of eight stable isotopes, the most of any element with the exception of tin, which has ten. Xenon and tin are the only elements to have more than seven stable isotopes. The isotopes 124Xe and 134Xe are predicted to undergo double beta decay, but this has never been observed so they are considered to be stable.
Besides these stable forms, there are over 40 unstable isotopes that have been studied. The longest lived of these isotopes is 136Xe, which has been observed to undergo double beta decay with a half-life of 2.11 x 1021yr. 129Xe is produced by beta decay of 129I, which has a half-life of 16 million years, while 131mXe, 133Xe, 133mXe, and 135Xe are some of the fission products of both 235U and 239Pu, and therefore used as indicators of nuclear explosions.
Nuclei of two of the stable isotopes of xenon, 129Xe and 131Xe, have non-zero intrinsic angular momenta (nuclear spins, suitable for nuclear magnetic resonance). The nuclear spins can be aligned beyond ordinary polarization levels by means of circularly polarized light and rubidium vapor. The resulting spin polarization of xenon nuclei can surpass 50% of its maximum possible value, greatly exceeding the thermal equilibrium value dictated by paramagnetic statistics (typically 0.001% of the maximum value at room temperature, even in the strongest magnets). Such non-equilibrium alignment of spins is a temporary condition, and is called "hyperpolarization". The process of hyperpolarizing the xenon is called "optical pumping" (although the process is different from pumping a laser).
Because a 129Xe nucleus has a spin of 1/2, and therefore a zero electric quadrupole moment, the 129Xe nucleus does not experience any quadrupolar interactions during collisions with other atoms, and thus its hyperpolarization can be maintained for long periods of time even after the laser beam has been turned off and the alkali vapor removed by condensation on a room-temperature surface. Spin polarization of 129Xe can persist from several seconds for xenon atoms dissolved in blood to several hours in the gas phase and several days in deeply frozen solid xenon. In contrast, 131Xe has a nuclear spin value of 3⁄2 and a nonzero quadrupole moment, and has t1 relaxation times in the millisecond and second ranges.
Some radioactive isotopes of xenon, for example, 133Xe and 135Xe, are produced by neutron irradiation of fissionable material within nuclear reactors. 135Xe is of considerable significance in the operation of nuclear fission reactors. 135Xe has a huge cross section for thermal neutrons, 2.6×106 barns, so it acts as a neutron absorber or "poison" that can slow or stop the chain reaction after a period of operation. This was discovered in the earliest nuclear reactors built by the American Manhattan Project for plutonium production. Fortunately the designers had made provisions in the design to increase the reactor's reactivity (the number of neutrons per fission that go on to fission other atoms of nuclear fuel).
135Xe reactor poisoning played a major role in the Chernobyl disaster. A shutdown or decrease of power of a reactor can result in buildup of 135Xe and getting the reactor into the iodine pit.
Under adverse conditions, relatively high concentrations of radioactive xenon isotopes may be found emanating from nuclear reactors due to the release of fission products from cracked fuel rods, or fissioning of uranium in cooling water.
Because xenon is a tracer for two parent isotopes, xenon isotope ratios in meteorites are a powerful tool for studying the formation of the solar system. The iodine-xenon method of dating gives the time elapsed between nucleosynthesis and the condensation of a solid object from the solar nebula. In 1960, physicist John H. Reynolds discovered that certain meteorites contained an isotopic anomaly in the form of an overabundance of xenon-129. He inferred that this was a decay product of radioactive iodine-129. This isotope is produced slowly by cosmic ray spallation and nuclear fission, but is produced in quantity only in supernova explosions. As the half-life of 129I is comparatively short on a cosmological time scale, only 16 million years, this demonstrated that only a short time had passed between the supernova and the time the meteorites had solidified and trapped the 129I. These two events (supernova and solidification of gas cloud) were inferred to have happened during the early history of the Solar System, as the 129I isotope was likely generated before the Solar System was formed, but not long before, and seeded the solar gas cloud with isotopes from a second source. This supernova source may also have caused collapse of the solar gas cloud.
In a similar way, xenon isotopic ratios such as 129Xe/130Xe and 136Xe/130Xe are also a powerful tool for understanding planetary differentiation and early outgassing. For example, The atmosphere of Mars shows a xenon abundance similar to that of Earth:
0.08 parts per million, however Mars shows a higher proportion of 129Xe than the Earth or the Sun. As this isotope is generated by radioactive decay, the result may indicate that Mars lost most of its primordial atmosphere, possibly within the first 100 million years after the planet was formed. In another example, excess 129Xe found in carbon dioxide well gases from New Mexico was believed to be from the decay of mantle-derived gases soon after Earth's formation.
Compounds.
See also: .
After Neil Bartlett's discovery in 1962 that xenon can form chemical compounds, a large number of xenon compounds have been discovered and described. Almost all known xenon compounds contain the electronegative atoms fluorine or oxygen.
Halides.
Three fluorides are known: XeF2, XeF4, and XeF6. XeF is theorized to be unstable. The fluorides are the starting point for the synthesis of almost all xenon compounds.
The solid, crystalline difluoride XeF2 is formed when a mixture of fluorine and xenon gases is exposed to ultraviolet light. Ordinary daylight is sufficient. Long-term heating of XeF2 at high temperatures under an NiF2 catalyst yields XeF6. Pyrolysis of XeF6 in the presence of NaF yields high-purity XeF4.
The xenon fluorides behave as both fluoride acceptors and fluoride donors, forming salts that contain such cations as XeF+ and XeF3+, and anions such as XeF5-, XeF7-, and XeF82-. The green, paramagnetic Xe2+ is formed by the reduction of XeF2 by xenon gas.
XeF2 is also able to form coordination complexes with transition metal ions. Over 30 such complexes have been synthesized and characterized.
Whereas the xenon fluorides are well-characterized, the other halides are not known, the only exception being the dichloride, XeCl2. Xenon dichloride is reported to be an endothermic, colorless, crystalline compound that decomposes into the elements at 80 °C, formed by the high-frequency irradiation of a mixture of xenon, fluorine, and silicon or carbon tetrachloride. However, doubt has been raised as to whether XeCl2 is a real compound and not merely a van der Waals molecule consisting of weakly bound Xe atoms and Cl2 molecules. Theoretical calculations indicate that the linear molecule XeCl2 is less stable than the van der Waals complex.
Oxides and oxohalides.
Three oxides of xenon are known: xenon trioxide (XeO3) and xenon tetroxide (XeO4), both of which are dangerously explosive and powerful oxidizing agents, and xenon dioxide (XeO2), which was reported in 2011 with a coordination number of four. XeO2 forms when xenon tetrafluoride is poured over ice. Its crystal structure may allow it to replace silicon in silicate minerals. The XeOO+ cation has been identified by infrared spectroscopy in solid argon.
Xenon does not react with oxygen directly; the trioxide is formed by the hydrolysis of XeF6:
XeO3 is weakly acidic, dissolving in alkali to form unstable "xenate" salts containing the HXeO4− anion. These unstable salts easily disproportionate into xenon gas and "perxenate" salts, containing the XeO64− anion.
Barium perxenate, when treated with concentrated sulfuric acid, yields gaseous xenon tetroxide:
To prevent decomposition, the xenon tetroxide thus formed is quickly cooled to form a pale-yellow solid. It explodes above −35.9 °C into xenon and oxygen gas.
A number of xenon oxyfluorides are known, including XeOF2, XeOF4, XeO2F2, and XeO3F2. XeOF2 is formed by the reaction of OF2 with xenon gas at low temperatures. It may also be obtained by the partial hydrolysis of XeF4. It disproportionates at −20 °C into XeF2 and XeO2F2. XeOF4 is formed by the partial hydrolysis of XeF6, or the reaction of XeF6 with sodium perxenate, Na4XeO6. The latter reaction also produces a small amount of XeO3F2. XeOF4 reacts with CsF to form the XeOF5− anion, while XeOF3 reacts with the alkali metal fluorides KF, RbF and CsF to form the XeOF4− anion.
Other compounds.
Recently, there has been an interest in xenon compounds where xenon is directly bonded to a less electronegative element than fluorine or oxygen, particularly carbon. Electron-withdrawing groups, such as groups with fluorine substitution, are necessary to stabilize these compounds. Numerous such compounds have been characterized, including:
Other compounds containing xenon bonded to a less electronegative element include F–Xe–N(SO2F)2 and F–Xe–BF2. The latter is synthesized from dioxygenyl tetrafluoroborate, O2BF4, at −100 °C.
An unusual ion containing xenon is the tetraxenonogold(II) cation, AuXe42+, which contains Xe–Au bonds. This ion occurs in the compound AuXe4(Sb2F11)2, and is remarkable in having direct chemical bonds between two notoriously unreactive atoms, xenon and gold, with xenon acting as a transition metal ligand.
The compound Xe2Sb2F11 contains a Xe–Xe bond, the longest element-element bond known (308.71 pm = 3.0871 Å).
In 1995, M. Räsänen and co-workers, scientists at the University of Helsinki in Finland, announced the preparation of xenon dihydride (HXeH), and later xenon hydride-hydroxide (HXeOH), hydroxenoacetylene (HXeCCH), and other Xe-containing molecules. In 2008, Khriachtchev "et al." reported the preparation of HXeOXeH by the photolysis of water within a cryogenic xenon matrix. Deuterated molecules, HXeOD and DXeOH, have also been produced.
Clathrates and excimers.
In addition to compounds where xenon forms a chemical bond, xenon can form clathrates—substances where xenon atoms are trapped by the crystalline lattice of another compound. An example is xenon hydrate (Xe•5.75 H2O), where xenon atoms occupy vacancies in a lattice of water molecules. This clathrate has a melting point of 24 °C. The deuterated version of this hydrate has also been produced. Such clathrate hydrates can occur naturally under conditions of high pressure,
such as in Lake Vostok underneath the Antarctic ice sheet. Clathrate formation can be used to fractionally distill xenon, argon and krypton.
Xenon can also form endohedral fullerene compounds, where a xenon atom is trapped inside a fullerene molecule. The xenon atom trapped in the fullerene can be monitored via 129Xe nuclear magnetic resonance (NMR) spectroscopy. Using this technique, chemical reactions on the fullerene molecule can be analyzed, due to the sensitivity of the chemical shift of the xenon atom to its environment. However, the xenon atom also has an electronic influence on the reactivity of the fullerene.
While xenon atoms are at their ground energy state, they repel each other and will not form a bond. When xenon atoms becomes energized, however, they can form an excimer (excited dimer) until the electrons return to the ground state. This entity is formed because the xenon atom tends to fill its outermost electronic shell, and can briefly do this by adding an electron from a neighboring xenon atom. The typical lifetime of a xenon excimer is 1–5 ns, and the decay releases photons with wavelengths of about 150 and 173 nm. Xenon can also form excimers with other elements, such as the halogens bromine, chlorine and fluorine.
Applications.
Although xenon is rare and relatively expensive to extract from the Earth's atmosphere, it has a number of applications.
Illumination and optics.
Gas-discharge lamps.
Xenon is used in light-emitting devices called xenon flash lamps, which are used in photographic flashes and stroboscopic lamps; to excite the active medium in lasers which then generate coherent light; and, occasionally, in bactericidal lamps. The first solid-state laser, invented in 1960, was pumped by a xenon flash lamp, and lasers used to power inertial confinement fusion are also pumped by xenon flash lamps.
Continuous, short-arc, high pressure xenon arc lamps have a color temperature closely approximating noon sunlight and are used in solar simulators. That is, the chromaticity of these lamps closely approximates a heated black body radiator that has a temperature close to that observed from the Sun. After they were first introduced during the 1940s, these lamps began replacing the shorter-lived carbon arc lamps in movie projectors. They are employed in typical 35mm, IMAX and the new digital projectors film projection systems, automotive HID headlights, high-end "tactical" flashlights and other specialized uses. These arc lamps are an excellent source of short wavelength ultraviolet radiation and they have intense emissions in the near infrared, which is used in some night vision systems.
The individual cells in a plasma display use a mixture of xenon and neon that is converted into a plasma using electrodes. The interaction of this plasma with the electrodes generates ultraviolet photons, which then excite the phosphor coating on the front of the display.
Xenon is used as a "starter gas" in high pressure sodium lamps. It has the lowest thermal conductivity and lowest ionization potential of all the non-radioactive noble gases. As a noble gas, it does not interfere with the chemical reactions occurring in the operating lamp. The low thermal conductivity minimizes thermal losses in the lamp while in the operating state, and the low ionization potential causes the breakdown voltage of the gas to be relatively low in the cold state, which allows the lamp to be more easily started.
Lasers.
In 1962, a group of researchers at Bell Laboratories discovered laser action in xenon, and later found that the laser gain was improved by adding helium to the lasing medium. The first excimer laser used a xenon dimer (Xe2) energized by a beam of electrons to produce stimulated emission at an ultraviolet wavelength of 176 nm.
Xenon chloride and xenon fluoride have also been used in excimer (or, more accurately, exciplex) lasers. The xenon chloride excimer laser has been employed, for example, in certain dermatological uses.
Medical.
Anesthesia.
Xenon has been used as a general anesthetic. Although it is expensive, anesthesia machines that can deliver xenon are about to appear on the European market, because advances in recovery and recycling of xenon have made it economically viable.
Xenon interacts with many different receptors and ion channels and like many theoretically multi-modal inhalation anesthetics these interactions are likely complementary. Xenon is a high-affinity glycine-site NMDA receptor antagonist. However, xenon distinguishes itself from other clinically used NMDA receptor antagonists in its lack of neurotoxicity and its ability to inhibit the neurotoxicity of ketamine and nitrous oxide. Unlike ketamine and nitrous oxide, xenon does not stimulate a dopamine efflux from the nucleus accumbens. Like nitrous oxide and cyclopropane, xenon activates the two-pore domain potassium channel TREK-1. A related channel TASK-3 also implicated in inhalational anesthetic actions is insensitive to xenon. Xenon inhibits nicotinic acetylcholine α4β2 receptors which contribute to spinally mediated analgesia. Xenon is an effective inhibitor of plasma membrane Ca2+ ATPase. Xenon inhibits Ca2+ ATPase by binding to a hydrophobic pore within the enzyme and preventing the enzyme from assuming active conformations.
Xenon is a competitive inhibitor of the serotonin 5-HT3 receptor. While neither anesthetic nor antinociceptive this activity reduces anesthesia-emergent nausea and vomiting.
Xenon has a minimum alveolar concentration (MAC) of 72% at age 40, making it 44% more potent than N2O as an anesthetic. Thus it can be used in concentrations with oxygen that have a lower risk of hypoxia. Unlike nitrous oxide (N2O), xenon is not a greenhouse gas and so it is also viewed as environmentally friendly. Xenon vented into the atmosphere is being returned to its original source, so no environmental impact is likely.
Neuroprotectant.
Xenon induces robust cardioprotection and neuroprotection through a variety of mechanisms of action. Through its influence on Ca2+, K+, KATP\HIF and NMDA antagonism xenon is neuroprotective when administered before, during and after ischemic insults. Xenon is a high affinity antagonist at the NMDA receptor glycine site. Xenon is cardioprotective in ischemia-reperfusion conditions by inducing pharmacologic non-ischemic preconditioning. Xenon is cardioprotective by activating PKC-epsilon & downstream p38-MAPK. Xenon mimics neuronal ischemic preconditioning by activating ATP sensitive potassium channels. Xenon allosterically reduces ATP mediated channel activation inhibition independently of the sulfonylurea receptor1 subunit, increasing KATP open-channel time and frequency.
Xenon upregulates hypoxia inducible factor 1 alpha (HIF1a).
Xenon gas was added as an ingredient of the ventilation mix for a newborn baby at St. Michael's Hospital, Bristol, England, whose life chances were otherwise very compromised, and was successful, leading to the authorisation of clinical trials for similar cases. The treatment is done simultaneously with cooling the body temperature to 33.5 °C.
Doping.
Inhaling a xenon/oxygen mixture activates production of the transcription factor HIF-1-alpha, which leads to increased production of erythropoietin. The latter hormone is known to increase red blood cell production and athletes' performance. Xenon inhalation has been used for this purpose in Russia since at least 2004. On August 31 2014 the World Anti Doping Agency (WADA) added Xenon (and Argon) to the list of prohibited substances and methods, although at this time there is no reliable test for abuse.
Imaging.
Gamma emission from the radioisotope 133Xe of xenon can be used to image the heart, lungs, and brain, for example, by means of single photon emission computed tomography. 133Xe has also been used to measure blood flow.
Xenon, particularly hyperpolarized 129Xe, is a useful contrast agent for magnetic resonance imaging (MRI). In the gas phase, it can be used to image empty space such as cavities in a porous sample or alveoli in lungs. Hyperpolarization renders 129Xe much more detectable via magnetic resonance imaging and has been used for studies of the lungs and other tissues. It can be used, for example, to trace the flow of gases within the lungs. Because xenon is soluble in water and also in hydrophobic solvents, it can be used to image various soft living tissues.
Xenon with its high nuclear mass is a useful contrast medium for x-ray photography. For this purpose it is supplemented by Krypton and used at concentrations below 35% as otherwise it would act as a narcotic.
NMR spectroscopy.
Because of the xenon atom's large, flexible outer electron shell, the NMR spectrum changes in response to surrounding conditions, and can therefore be used as a probe to measure the chemical circumstances around it. For instance xenon dissolved in water, in hydrophobic solvent, and xenon associated with certain proteins can be distinguished by NMR.
Hyperpolarized xenon can be used by surface chemists. Normally, it is difficult to characterize surfaces using NMR, because signals from the surface of a sample will be overwhelmed by signals from the far-more-numerous atomic nuclei in the bulk. However, nuclear spins on solid surfaces can be selectively polarized, by transferring spin polarization to them from hyperpolarized xenon gas. This makes the surface signals strong enough to measure, and distinguishes them from bulk signals.
Other.
In nuclear energy applications, xenon is used in bubble chambers, probes, and in other areas where a high molecular weight and inert nature is desirable. A by-product of nuclear weapon testing is the release of radioactive xenon-133 and xenon-135. The detection of these isotopes is used to monitor compliance with nuclear
test ban treaties, as well as
to confirm nuclear test explosions by states such as North Korea.
Liquid xenon is being used in calorimeters for measurements of gamma rays as well as a medium for detecting hypothetical weakly interacting massive particles, or WIMPs. When a WIMP collides with a xenon nucleus, it is predicted to impart enough energy to cause ionization and scintillation. Liquid xenon is useful for this type of experiment due to its high density which makes dark matter interaction more likely and permits a quiet detector due to self-shielding.
Xenon is the preferred propellant for ion propulsion of spacecraft because of its low ionization potential per atomic weight, and its ability to be stored as a liquid at near room temperature (under high pressure) yet be easily converted back into a gas to feed the engine. The inert nature of xenon makes it environmentally friendly and less corrosive to an ion engine than other fuels such as mercury or caesium. Xenon was first used for satellite ion engines during the 1970s. It was later employed as a propellant for JPL's Deep Space 1 probe, Europe's SMART-1 spacecraft and for the three ion propulsion engines on NASA's Dawn Spacecraft.
Chemically, the perxenate compounds are used as oxidizing agents in analytical chemistry. Xenon difluoride is used as an etchant for silicon, particularly in the production of microelectromechanical systems (MEMS). The anticancer drug 5-fluorouracil can be produced by reacting xenon difluoride with uracil. Xenon is also used in protein crystallography. Applied at pressures from 0.5 to 5 MPa (5 to 50 atm) to a protein crystal, xenon atoms bind in predominantly hydrophobic cavities, often creating a high-quality, isomorphous, heavy-atom derivative, which can be used for solving the phase problem.
Precautions.
Many oxygen-containing xenon compounds are toxic due to their strong oxidative properties, and explosive due to their tendency to break down into elemental xenon plus diatomic oxygen (O2), which contains much stronger chemical bonds than the xenon compounds.
Xenon gas can be safely kept in normal sealed glass or metal containers at standard temperature and pressure. However, it readily dissolves in most plastics and rubber, and will gradually escape from a container sealed with such materials. Xenon is non-toxic, although it does dissolve in blood and belongs to a select group of substances that penetrate the blood–brain barrier, causing mild to full surgical anesthesia when inhaled in high concentrations with oxygen.
At 169 m/s, the speed of sound in xenon gas is slower than that in air due to the slower average speed of the heavy xenon atoms compared to nitrogen and oxygen molecules. Hence, xenon lowers the rate of vibration in the vocal tract when exhaled. This produces a characteristic lowered voice timbre, an effect opposite to the high-timbred voice caused by inhalation of helium. Like helium, xenon does not satisfy the body's need for oxygen. Xenon is both a simple asphyxiant and an anesthetic more powerful than nitrous oxide; consequently, many universities no longer allow the voice stunt as a general chemistry demonstration. As xenon is expensive, the gas sulfur hexafluoride, which is similar to xenon in molecular weight (146 versus 131), is generally used in this stunt, and is an asphyxiant without being anesthetic.
It is possible to safely breathe dense gases such as xenon or sulfur hexafluoride when they are in a mixture of at least 20% oxygen. Xenon at 80% concentration along with 20% oxygen rapidly produces the unconsciousness of general anesthesia (and has been used for this, as discussed above). Breathing mixes gases of different densities very effectively and rapidly so that heavier gases are purged along with the oxygen, and do not accumulate at the bottom of the lungs. There is, however, a danger associated with any heavy gas in large quantities: it may sit invisibly in a container, and if a person enters a container filled with an odorless, colorless gas, they may find themselves breathing it unknowingly. Xenon is rarely used in large enough quantities for this to be a concern, though the potential for danger exists any time a tank or container of xenon is kept in an unventilated space.

</doc>
<doc id="34141" url="http://en.wikipedia.org/wiki?curid=34141" title="Xenophobia">
Xenophobia

Xenophobia is the unreasoned fear of that which is perceived to be foreign or strange. Xenophobia can manifest itself in many ways involving the relations and perceptions of an ingroup towards an outgroup, including a fear of losing identity, suspicion of its activities, aggression, and desire to eliminate its presence to secure a presumed purity. Xenophobia can also be exhibited in the form of an "uncritical exaltation of another culture" in which a culture is ascribed "an unreal, stereotyped and exotic quality". Vienna Declaration and Programme of Action urges all governments to take immediate measures and to develop strong policies to prevent and combat all forms and manifestations of racism, xenophobia or related intolerance, where necessary by enactment of appropriate legislation including penal measure.
Definitions.
Dictionary definitions of "xenophobia" include: "deep-rooted, irrational hatred towards foreigners" (Oxford English Dictionary; OED), and "unreasonable fear or hatred of the unfamiliar" (Webster's). The word comes from the Greek words ξένος ("xenos"), meaning "strange", "foreigner", and φόβος ("phobos"), meaning "fear".
Two forms.
The first is a population group present within a society that is not considered part of that society. Often they are recent immigrants, but xenophobia may be directed against a group which has been present for centuries, or became part of this society through conquest and territorial expansion. This form of xenophobia can elicit or facilitate hostile and violent reactions, such as mass expulsion of immigrants, pogroms or in other cases, genocide.
The second form of xenophobia is primarily cultural, and the objects of the phobia are cultural elements which are considered alien. All cultures are subject to external influences, but cultural xenophobia is often narrowly directed, for instance, at foreign loan words in a national language. It rarely leads to aggression against individual persons, but can result in political campaigns for cultural or linguistic purification. In addition, entirely xenophobic societies tend not to be open to interactions from anything "outside" themselves, resulting in isolationism that can further increase xenophobia.
Causes.
The following are ways one would develop a general and more often a specific type of xenophobia:

</doc>
<doc id="34142" url="http://en.wikipedia.org/wiki?curid=34142" title="X">
X

X (named "ex" , plural "exes") is the twenty-fourth letter in the ISO basic Latin alphabet. In Roman numerals, it represents 10.
History.
In Ancient Greek, 'Χ' and 'Ψ' were among several variants of the same letter, used originally for /kʰ/ and later, in western areas such as Arcadia, as a simplification of the digraph 'ΧΣ' for /ks/. In the end, more conservative eastern forms became the standard of Classical Greek, and thus 'Χ' "(Chi)" stands for /kʰ/ (later /x/). However, the Etruscans had taken over 'Χ' from western Greek, and it therefore stands for /ks/ in Etruscan and Latin.
The letter 'Χ' ~ 'Ψ' for /kʰ/ was a Greek addition to the alphabet, placed after the Semitic letters along with "phi" 'Φ' for /pʰ/. (The variant 'Ψ' later replaced the digraph 'ΦΣ' for /ps/; "omega" was a later addition)..
Use in English.
In English orthography, "x" is typically pronounced as the voiceless consonant cluster when it follows the stressed vowel (e.g. "ox"), and the voiced consonant when it precedes the stressed vowel (e.g. "exam"). It is pronounced when it also precedes a silent "h" and an accented vowel (e.g. "exhaust"). Before "i" or "u", it can be pronounced or (e.g. "sexual" and "luxury"); these result from earlier and . It also makes the sound in words ending in "-xion" (typically used only in British-based spellings of the language; American spellings tend to use "-ction"). When "x" ends a word, it is always (e.g. "ax"), except in loan words such as "faux" (see French, below).
There are very few English words that start with "x" (the least amount of any letter). When "x" does start a word, it is usually pronounced (e.g. "xylophone", "xenophobia", and "xanthan"); in rare recent loanwords or foreign proper names, it can also be pronounced (e.g. the obsolete Vietnamese monetary unit "xu") or (e.g. Chinese names starting with Xi like Xiaomi or Xinjiang). Many of the words that start with "x" are either standardized trademarks ("Xerox") or acronyms ("XC"). In abbreviations, it can represent "trans-" (e.g. "XMIT" for transmit, "XFER" for transfer), "cross-" (e.g. "X-ing" for crossing, "XREF" for cross-reference), "Christ-" as shorthand for the labarum (e.g. "Xmas" for Christmas, "Xian" for Christian), the "crys-" in crystal ("XTAL"), or various words starting with "ex-" (e.g. "XL" for extra large, "XOR" for exclusive-or). It does not begin any words in Basic English (but it occurs in words beginning with other letters).
It is the third least common letter in English (after "Q" and "Z"), with a frequency of about 0.15% in words.
Use in other languages.
In the International Phonetic Alphabet, [x] represents a voiceless velar fricative.
In Latin, 'x' stood for [ks]. In some languages, as a result of assorted phonetic changes, handwriting adaptations or simply spelling convention, 'x' has other pronunciations:
Additionally, in languages for which the Latin alphabet has been adapted only recently, 'x' has been used for various sounds, in some cases inspired by European usage, but in others, for consonants uncommon in Europe. For these no Latin letter stands out as an obvious choice, and since most of the various European pronunciations of 'x' can be written by other means, the letter becomes available for more unusual sounds.
Metalinguistic usage.
In mathematics, 'x' is commonly used as the name for an independent variable or unknown value. The modern tradition of using 'x' to represent an unknown was started by René Descartes in "La Géométrie" (1637).
It may also be used to signify the multiplication operation when a more appropriate glyph is unavailable. In mathematical typesetting, 'x' meaning an algebraic variable is normally in italic type (formula_1), partly to avoid confusion with the multiplication symbol. In fonts containing both 'x' (the letter) and '×' (the multiplication sign), the two glyphs are dissimilar.
Computing codes.
In the C programming language, 'x' preceded by zero (0x or 0X) is used to denote hexadecimal literal values.

</doc>
<doc id="34145" url="http://en.wikipedia.org/wiki?curid=34145" title="XTC">
XTC

XTC were a new wave rock band from Swindon, England, led by songwriters Andy Partridge and Colin Moulding and active between 1976 and 2005. The band enjoyed some chart success, including the UK and Canadian hits "Making Plans for Nigel" (1979) and "Senses Working Overtime" (1982).
XTC were a performing and touring band up until 1982. For the remaining twenty-three years of XTC's existence they were a studio-based project involving session players around a nucleus of Partridge, Moulding and Dave Gregory. 
History.
Early days: 1972–1976.
First coming together in 1972, Colin Moulding (bass & vocals) and Terry Chambers (drums) asked Andy Partridge (guitars & vocals) to join their new band and went through many band names (including The Helium Kidz and Star Park) over the next five years. As the Helium Kidz, they were featured in a small "NME" article as an up-and-coming band from Swindon. Drawing influence from the New York Dolls, particularly the "Jetboy" single, and the emerging New York punk scene, they played glam rock with homemade costumes and slowly built up a following. Keyboard player Barry Andrews joined in 1976, and the band finally settled on a name: XTC.
Touring years: 1977–1982.
In 1977, XTC were signed by Virgin Records. They recorded the "3D - EP" that summer, and followed it up with their debut LP "White Music" in January 1978. These and future XTC releases would find Andy Partridge writing and singing about two-thirds of the material, while Colin Moulding would write and sing approximately one-third. ("White Music" also featured a cover of Bob Dylan's "All Along The Watchtower", sung by Partridge.) "White Music" received favourable reviews and entered the British top 40, but lead single "Statue of Liberty" was banned by the BBC because of its supposedly
"lewd" reference to the famous statue ("in my fantasy I sail beneath your skirt"). The group also picked up a cult following in Australia thanks to the support of the Sydney rock radio station 2JJ (now Triple-J) and the nationally broadcast weekly music TV show "Countdown", which screened all of the band's early videos (beginning with their first Australian single release - "This Is Pop"); thanks to this interest, the group made two well-received tours there in 1979 and 1980. Their second album "Go 2", released later in 1978, featured a typewriter-text cover (designed by Hipgnosis) and early pressings were accompanied by a bonus disc "Go +", a collection of dub mixes of songs from the album.
Following the release of "Go 2", in January 1979 Barry Andrews left the group (joining Robert Fripp's League of Gentlemen and subsequently co-founding Shriekback). XTC initially sought a new keyboard player - Thomas Dolby was among those considered - but Dave Gregory, guitarist and long-time friend of Partridge's, was eventually selected as Andrews' replacement. Gregory's 1960s-influenced guitar style steered the band on a path towards a more traditional rock sound; he would also contribute occasional keyboards (and later, string arrangements).
Coinciding with Gregory's arrival, XTC scored their first charting single in the UK with "Life Begins at the Hop", which was also the first XTC single penned by Colin Moulding. Their third album "Drums and Wires" contained the band's first major hit single "Making Plans for Nigel" (another Moulding composition), which caused a minor controversy because of its lyrical reference to British Steel. "Drums and Wires" also marked their first sessions at London's Townhouse Studios. The studio was at the time much sought after for its highly reverberant "live" drum room, and it was greatly favoured by their producer Steve Lillywhite and his engineer Hugh Padgham, who were at that time also creating influential recordings with Peter Gabriel and Genesis. The Lillywhite-Padgham connection also led to Dave Gregory contributing to Gabriel's third solo album.
During this period, Partridge released an LP of dub in 1980 under the name 'Mr Partridge'. The album, "Take Away/The Lure of Salvage", featured dub reconstructions of music from the preceding XTC albums. Later the same year Moulding and Chambers released the "Too Many Cooks In The Kitchen" single under the name "The Colonel". In March 1980 XTC released a non-album single, the reggae-styled "Wait 'Til Your Boat Goes Down", but it failed to chart. Hoping to crack the American market, they undertook a gruelling US-Canada tour which included numerous support spots with The Police. The band opened three shows for The Cars at Madison Square Garden and the Nassau Coliseum between their own headline gigs at smaller area venues.
Their fourth LP "Black Sea" (Sept. 1980) featured the singles "Sgt. Rock (Is Going to Help Me)" and "Generals and Majors", both of which made the UK Top 40, with the album reaching No. 1 in Australia. In the film clip of 'Generals and Majors' (directed by Russell Mulcahy), Virgin Records founder and chair Richard Branson has a cameo role as one of the 'majors'.
The last major hit of XTC's touring phase was "Senses Working Overtime". This was the first single from their double album "English Settlement" (February 1982) and their first top 10 hit in the UK.
Partridge's breakdown and XTC's withdrawal from touring (1982).
In early 1982, while at the peak of their popularity, XTC embarked on a major tour. This was abruptly cut short when Partridge suffered a mental breakdown on stage during one of the first concerts of the tour in Paris on 18 March 1982.
On 2 April 1982, a Friday night, XTC were scheduled to play at the Hollywood Palladium in Los Angeles, with opening act Jools Holland, but the packed club was told that the show would not take place due to the "illness" of one of the band members (later revealed as Andy Partridge's ongoing fight with stage fright in Chris Twomey's book "XTC: Chalkhills and Children"). The following day, XTC played one last concert at the California Theatre in San Diego but then never played another tour date. (XTC would perform several acoustic sets for radio only in 1989.)
Andy Partridge's breakdown, which manifested itself as uncontrollable stage fright, was reportedly precipitated by his wife throwing away his supply of Valium. According to the band's biography, Valium was prescribed to him as a teenager, but he was never taken off the drug and became dependent on it. Concerned about her husband's dependence, Partridge's wife threw his tablets away — without seeking medical advice — just before the Paris concert. Partridge particularly needed Valium to cope with the grinding monotony of concert touring, which he had always disliked but endured for the good of the band. In addition to "memory loss and limb seizures", the sudden withdrawal of medication brought on anxiety attacks of such severity that he was soon forced to withdraw from performing permanently. The European and British dates were cancelled and after completing only one show in San Diego the whole US leg was also abandoned. After this XTC became exclusively a studio band (apart from occasional live-to-air performances from radio stations, and a handful of TV appearances).
Studio years: 1982–1998.
Adapting to their new studio-based existence, XTC recorded the album "Mummer". Released in 1983, it took the group's music away from the more performance-friendly new wave rock of their earlier years in favour of a consciously pastoral direction (and songtitles such as "Love on a Farmboy's Wages").
Terry Chambers left the band during the "Mummer" sessions (his last recording was on the track "Toys"). Chambers had always preferred touring over working in the confines of a studio, and was uncomfortable with the band's desire to experiment with new rhythmic possibilities such as drum machines and found percussion. However, the main reason for his departure was a desire to be with his Australian girlfriend; they subsequently married, and Chambers migrated to Australia and settled in Newcastle, New South Wales. There, Chambers joined the band Dragon from 1983 to 1985, drumming on their 1984 album "Body and the Beat" and associated hit single "Rain" (#2 AUS, #88 US). He has since withdrawn from the music scene. Rather than finding a replacement, XTC used a series of session drummers over the years, including Peter Phipps, Prairie Prince of The Tubes, Dave Mattacks of Fairport Convention, Pat Mastelotto (of Mr. Mister, and later of King Crimson), Chuck Sabo, and in their "Dukes of Stratosphear" incarnation, Dave Gregory's brother Ian (credited as "E.I.E.I. Owen").
XTC's next album, 1984's "The Big Express" marked a return to the harsher and more abrasive sounds of their early albums, but the combination of the group's 'no touring' status and the growing disenchantment of their label made it their poorest selling LP to date. The album was nonetheless a personal high point for Partridge, who ranks songs such as "The Everyday Story of Smalltown" and "Train Running Low on Soul Coal" amongst his best work.
Later in 1984, the members of XTC created their alter-ego, "Dukes of Stratosphear" (a suggested band name that the group had considered when they first formed). With this project, they reunited with original producer John Leckie to record a series of affectionate parodies that indulged their love of classic 1960s psychedelic music. The first Dukes release was the EP "25 O'Clock", issued on April Fools' Day 1985.
In 1986, the band travelled to Todd Rundgren's rural studio in Woodstock, New York to record "Skylarking". Although the pairing of XTC and Rundgren was highly anticipated by fans, the sessions were less than enjoyable for the band. Rundgren had been hired to trim the band's studio excesses and return them to commercial success. Prior to the recording sessions, Rundgren listened through demos of the songs, chose 15 for the record and worked out a sequence for the album. Being accustomed to creative independence in the studio, Partridge resisted Rundgren's decision-making role as producer. Rundgren and Partridge clashed frequently during the recording of "Skylarking" and when it was finished Partridge said that he was not at all happy with the resulting product. Partridge has since softened his view, describing the album as "a summer's day baked into one cake." Nevertheless, it was praised highly by both fans and critics alike.
"Skylarking" spawned the controversial track "Dear God", which was originally issued as the B-side of the album's first single, "Grass". Interest in the song saw the US album re-pressed with "Dear God" included and the new version of the LP sold 250,000 copies in the USA, reviving the band's commercial fortunes and earning critical accolades. "Dear God" replaced "Mermaid Smiled" on the American version of the album and the latter track was finally reinstated for the remastered reissue of "Skylarking" CD in 2000.
Temporarily returning to work as Dukes of Stratosphear, XTC released the LP "Psonic Psunspot" in 1987. Although it was a full-length album, it was not intended to be the follow-up to "Skylarking". The tracks from this album and the "25 O'Clock" EP were combined for the CD "Chips from the Chocolate Fireball", which also came out in 1987.
The band released their official follow-up to "Skylarking" in 1989. This album, "Oranges & Lemons", produced by Paul Fox, was their biggest seller yet, with the videos for "The Mayor of Simpleton" and "King for a Day" getting heavy airplay on MTV and other international music TV programmes. Sonically lush and tightly produced, the album continued along the psychedelic influence of "Skylarking" while drawing from the energetic pop sound of their earlier work. Like its predecessor, it was also well-received critically.
It was during this period that Partridge began a relationship with an American fan, Erica Wexler, daughter of writer Norman Wexler. Although signs of the failing of Partridge's first marriage were evident as far back as "English Settlement" (notably on the album's closing track, "Snowman"), it was some time before the still-married Partridge felt comfortable with Wexler's advances and his mixed feelings about the situation were chronicled in the song "Another Satellite". The relationship finally came to fruition after Partridge's first wife Marianne left him.
XTC's 1992 album "Nonsuch" (named after Henry VIII's fabled palace), united them with UK producer Gus Dudgeon, known for his 1970s work with Elton John and drummer Dave Mattacks (Fairport Convention). The album featured the US and UK hit tunes "Dear Madam Barnum" and "The Ballad of Peter Pumpkinhead", the latter bringing the band perhaps its greatest success after the early 1980s. (The video for the song drew intriguing parallels between the deaths of Jesus Christ and John F. Kennedy.) Despite the LP's success, soon after its release a contractual dispute with their label, Virgin Records, saw XTC go "on strike" from 1992 through 1998, which finally resulted in the termination of their contract. They released no new material during this time (aside from the track "The Good Things" on the tribute CD "A Testimonial Dinner", credited to Terry and the Lovemen), although Virgin did issue two compilations - the US-only greatest hits collection "Upsy Daisy Assortment", and the 2-CD set 'Best Of' collection "", which featured remastered versions of their singles, including many tracks not previously issued on CD.
Management and contractual problems had dogged the band throughout their career, and around the time of the recording of "Nonsuch" they had to make a legal settlement with their former manager. Although most fans assume (and the lyrics of "I Bought Myself a Liarbird" from "The Big Express" imply) that there was some financial impropriety involved, the terms of the settlement imposed a "gag" on the band and have prevented them from speaking publicly about the matter.
By now, XTC's relationship with their label had almost totally broken down; the final straw was Virgin's scuttling of their 1992 single "Wrapped in Grey". Vinyl 7" singles, CD singles and a few cassette singles were pressed but the vast majority were recalled and destroyed by the label, who unilaterally decided it had no prospect of charting: the few copies that made it into circulation are now highly prized collector's items. The band asked that Virgin either allow them to re-negotiate their contract or release them from it, but the label stalled for years until finally agreeing to release them after a change of management at the company.
Independent years: 1998–2005.
After leaving Virgin, Partridge had the band's accounts audited and it was discovered that the company had withheld substantial royalty payments from them. The settlement of the accounts provided the group with much-needed cash flow, allowing Partridge and Moulding to install fully equipped studios and work comfortably at home.
Though able to record the majority of their work themselves, they also used major commercial studios (including Abbey Road Studios in London) for some sessions. Finally released from Virgin, they formed their own label, Idea Records, and embarked on the recording of the ambitious "Apple Venus" project, a collection of the best material written during the band's dispute with Virgin. The band's initial plan had been to record a double album, featuring one disc of acoustic and orchestral songs and one of electric songs. Financial constraints forced the band to abandon the double album plan and finish and release the first volume (released 1999) before completing the second (2000).
During the recording sessions for "Apple Venus Volume 1", Dave Gregory left the band after 20 years' service. Ostensibly, this was due to "musical differences"—Gregory was unhappy with the plan to record an album whose arrangements relied largely upon orchestral instruments and keyboards rather than guitars.
In the end, Gregory was credited as a session musician rather than as a band member on the finished album, as he left before it was completed. Partridge later claimed in a press interview that he and Colin were going to sack Gregory anyway because of his sullen attitude during the recordings, and that they had waited for him for six years to write the orchestral arrangements, and had finally told him that they would not let him stop the project.
The band's next record, "Wasp Star (Apple Venus Volume 2)" was the guitar-heavy collection Gregory would have preferred. Partridge and Moulding then released instrumental and demo versions of the two Apple Venus albums. In October 2005, the two original albums and the demo versions of the albums were reissued together in the four-CD "Apple Box" collection.
Having left Virgin, relations between XTC and their former label improved and Andy Partridge released a series of albums of demos of his songs (mainly from the Virgin years) under the title of "Fuzzy Warbles" beginning in 2002, on a new label imprint APE. Colin Moulding declined to contribute his demos to the series. The Fuzzy Warbles series eventually included eight volumes, which were collected in a boxed set (designed to look like a stamp collector's album) that also included a bonus CD of demos called "Hinges."
A four-CD compilation—"Coat of Many Cupboards"—spanning the band's time with Virgin was also released in 2002. Timed to coincide with the release of remastered CDs of their back catalogue, the set included remastered album and single tracks along with voluminous demos, live tracks, unreleased songs, and alternate versions, culminating in the Partridge and Moulding recording of "Didn't Hurt A Bit", built from the studio reference recording of Moulding's composition (with drums and percussion intact, played by Dave Mattacks), taped during the Nonsuch sessions.
Gregory reunited with Partridge and Moulding when the three got back together for a charity reunion of their Dukes of Stratosphear alter-egos in 2003. Though Gregory would not rejoin XTC, he was once again an official member of the Dukes, who recorded and issued the track "Open a Can (Of Human Beans)" that year for a charity project. In late 2006 Partridge revealed that he and Gregory had rekindled their friendship.
Break-up and recent activity: 2005–present.
The 2005 inclusion in "Apple Box" of the first new XTC tracks in five years ("Spiral", written by Partridge and "Say It", by Moulding), offered hope that the band might continue. These songs were available to purchasers of the box set in digital format only, with the use of a special download code. A follow-up internet-only single, Moulding's "Where Did The Ordinary People Go?", was issued in December.
However, in November 2006, Partridge told several interviewers that Moulding no longer had any interest in writing, performing or even listening to music. Partridge has said he would not continue XTC without Moulding, and that therefore he has been forced to regard XTC "in the past tense," with no likelihood of a new project unless Moulding should have a change of heart. In an interview on a Todd Rundgren fansite in February 2008, Partridge revealed that Moulding had moved and changed his phone number, effectively ending all contact between the two and reducing their correspondence to emails exchanged via their manager in order to discuss the division of the band's assets. Partridge also said he and Gregory — their differences now resolved — had considered working together again.
On 30 July 2008, Partridge summed up the status of the band on the news website "Swindon Advertiser", in his "Ask Andy" column:
Yes I believe my musical partnership with Colin Moulding has come to an end. For reasons too personal and varied to go into here, but we had a good run as they say and produced some real good work. No, I won't be working with him in the future.
In a December 2008 internet radio interview on RundgrenRadio.com, Moulding resurfaced to confirm his recent disillusionment with music, but revealed that he was thinking of working on solo material. His given reasons for the break-up were financial discord, disagreement over the extent of the Fuzzy Warbles project, and a "change in mindset" on Partridge's part. However, he also stated that he and Partridge were once again communicating directly by email.
Reissue programme.
Newly remastered re-issues of several XTC albums have been released or are in the works. Included are re-worked previously unreleased tracks with contributions by Moulding. The first of these releases, expanded versions of "25 O'Clock" and "Psonic Psunspot", have been released by Partridge's APE House record label. These re-issues were to begin in 2010, with expanded CD and vinyl editions of "English Settlement", "Skylarking", and "Oranges & Lemons" planned to make up the first wave. In the end, however, a new vinyl version of "Skylarking" (remastered to fix technical issues that limited the breadth of the stereo mix) was the only one of these three titles issued.
In 2009 Partridge's Ape House label reissued the Dukes of Stratosphear recordings as a limited-edition boxed set which included heavyweight vinyl pressings of the original EP and LP in gatefold sleeves, a 500-piece jigsaw puzzle, a T-shirt and the single, "Tin Toy Clockwork Train". Other XTC side projects include a "Viz" promotional single as "Johnny Japes and his Jesticles" (with John Otway on vocals), a Christmas-themed single as "The Three Wise Men" and a guest appearance on their own tribute album "Testimonial Dinner" as "Terry and the Lovemen" (named after a rejected album title for "Black Sea").
In 2010, Andy Partridge announced that a follow-up to 'Rag And Bone Buffet' entitled 'Bric-a-Brac Breakfast' was in the pipeline and he asked XTC fans via his own APE Blog which tracks should be considered for inclusion on this new compilation. As of 2014, however, this collection has not yet appeared, but a new re-release campaign was announced that would involve their entire catalogue being mixed in 5.1 surround sound and released in expanded editions beginning with their 1992 album "Nonsuch."
Remixer Steven Wilson has prepared new stereo mix and a 5.1 Surround Sound mix of "Drums and Wires" for release late in 2014. Bonus material includes rare demos and rehearsal tapes. The liner notes will be by Partridge, Moulding and Gregory.
Timeline.
Following the band's cessation of touring and the departure of Terry Chambers in November 1982, the band continued with a variety of session drummers on studio recordings.

</doc>
<doc id="34147" url="http://en.wikipedia.org/wiki?curid=34147" title="X Window System">
X Window System

The X Window System (X11, X, and sometimes informally X-Windows) is a windowing system for bitmap displays, common on UNIX-like computer operating systems.
X provides the basic framework for a GUI environment: drawing and moving windows on the display device and interacting with a mouse and keyboard. X does not mandate the user interface — this is handled by individual programs. As such, the visual styling of X-based environments varies greatly; different programs may present radically different interfaces.
X originated at the Massachusetts Institute of Technology (MIT) in 1984. The protocol version has been X11 since September 1987. The X.Org Foundation leads the X project, with the current reference implementation, X.Org Server, available as free and open source software under the MIT License and similar permissive licenses.
Purpose and abilities.
X is an architecture-independent system for remote graphical user interfaces and input device capabilities. Each person using a networked terminal has the ability to interact with the display with any type of user input device.
In its standard distribution it is a complete, albeit simple, display and interface solution which delivers a standard toolkit and protocol stack for building graphical user interfaces on most Unix-like operating systems and OpenVMS, and has been ported to many other contemporary general purpose operating systems.
X provides the basic framework, or primitives, for building such GUI environments: drawing and moving windows on the display and interacting with a mouse, keyboard or touchscreen. X does not mandate the user interface; individual client programs handle this. Programs may use X's graphical abilities with no user interface. As such, the visual styling of X-based environments varies greatly; different programs may present radically different interfaces.
Unlike most earlier display protocols, X was specifically designed to be used over network connections rather than on an integral or attached display device. X features network transparency: the machine where an application program (the "client" application) runs can differ from the user's local machine (the display "server"). X's network protocol is based on X command primitives. This approach allows both 2D and 3D operations to be fully accelerated on the remote X server.
X provides no native support for audio; several projects exist to fill this niche, some also providing transparent network support.
Software architecture.
X uses a client–server model: an X server communicates with various "client" programs. The server accepts requests for graphical output (windows) and sends back user input (from keyboard, mouse, or touchscreen). The server may function as:
This client–server terminology—the user's terminal being the server and the applications being the clients—often confuses new X users, because the terms appear reversed. But X takes the perspective of the application, rather than that of the end-user: X provides display and I/O services to applications, so it is a server; applications use these services, thus they are clients.
The communication protocol between server and client operates network-transparently: the client and server may run on the same machine or on different ones, possibly with different architectures and operating systems. A client and server can even communicate securely over the Internet by tunneling the connection over an encrypted network session.
An X client itself may emulate an X server by providing display services to other clients. This is known as "X nesting". Open-source clients such as Xnest and Xephyr support such X nesting.
To use an X client application on a remote machine, the user may do the following:
The remote X client application will then make a connection to the user's local X server, providing display and input to the user.
Alternatively, the local machine may run a small program that connects to the remote machine and starts the client application.
Practical examples of remote clients include:
Principles.
In 1984, Bob Scheifler and Jim Gettys set out the early principles of X:
The first principle was modified during the design of X11 to: "Do not add new functionality unless you know of some real application that will require it."
X has largely kept to these principles. The sample implementation is developed with a view to extension and improvement of the implementation, while remaining compatible with the original 1987 protocol.
User interfaces.
X primarily defines protocol and graphics primitives - it deliberately contains no specification for application user-interface design, such as button, menu, or window title-bar styles. Instead, application software – such as window managers, GUI widget toolkits and desktop environments, or application-specific graphical user interfaces – define and provide such details. As a result, there is no "typical" X interface and several different desktop environments have become popular among users.
A window manager controls the placement and appearance of application windows. This may result in desktop interfaces reminiscent of those of Microsoft Windows or of the Apple Macintosh (examples include GNOME 2, KDE, Xfce) or have radically different controls (such as a tiling window manager, like wmii or Ratpoison). Some interfaces such as Sugar or Chrome OS eschew the desktop metaphor altogether, simplifying their interfaces for specialized applications. Window managers range in sophistication and complexity from the bare-bones ("e.g.", twm, the basic window manager supplied with X, or evilwm, an extremely light window-manager) to the more comprehensive desktop environments such as Enlightenment and even to application-specific window-managers for vertical markets such as point-of-sale.
Many users use X with a desktop environment, which, aside from the window manager, includes various applications using a consistent user-interface. Popular desktop environments include GNOME, KDE Software Compilation and Xfce. The UNIX98 standard environment is the Common Desktop Environment (CDE). The freedesktop.org initiative addresses interoperability between desktops and the components needed for a competitive X desktop.
Implementations.
The X.Org implementation is the canonical implementation of X. Owing to liberal licensing, a number of variations, both free and open source and proprietary, have appeared. Commercial Unix vendors have tended to take the reference implementation and adapt it for their hardware, usually customizing it and adding proprietary extensions.
Up to 2004, XFree86 provided the most common X variant on free Unix-like systems. XFree86 started as a port of X for 386-compatible PCs and, by the end of the 1990s, had become the greatest source of technical innovation in X and the "de facto" standard of X development. Since 2004, however, the X.Org Server, a fork of XFree86, has become predominant.
While it is common to associate X with Unix, X servers also exist natively within other graphical environments. Hewlett-Packard's OpenVMS operating system includes a version of X with Common Desktop Environment (CDE), known as DECwindows, as its standard desktop environment. Apple originally ported X to OS X in the form of X11.app, but that has been deprecated in favor of the XQuartz implementation. Third-party servers under Apple's older operating systems in the 1990s, System 7, and Mac OS 8 and 9, included Apple's MacX and White Pine Software's eXodus.
Microsoft Windows is not shipped with support for X, but many third-party implementations exist, as free and open source software such as Cygwin/X, and proprietary products such as Exceed, MKS X/Server, Reflection X, X-Win32 and Xming.
There are also Java implementations of X servers. WeirdX runs on any platform supporting Swing 1.1, and will run as an applet within most browsers. The is an open source Java implementation that runs on Android devices.
When an operating system with a native windowing system hosts X in addition, the X system can either use its own normal desktop in a separate host window or it can run "rootless", meaning the X desktop is hidden and the host windowing environment manages the geometry and appearance of the hosted X windows within the host screen.
X terminals.
An "X terminal" is a thin client that only runs an X server. This architecture became popular for building inexpensive terminal parks for many users to simultaneously use the same large computer server to execute application programs as clients of each user's X terminal. This use is very much aligned with the original intention of the MIT project.
X terminals explore the network (the local broadcast domain) using the X Display Manager Control Protocol to generate a list of available hosts that are allowed as clients. One of the client hosts should run an X display manager.
A limitation of X terminals and most thin clients is that they are not capable of any input or output other than the keyboard, mouse, and display. All relevant data is assumed to exist solely on the remote server, and the X terminal user has no methods available to save or load data from a local peripheral device.
Dedicated (hardware) X terminals have fallen out of use; a PC or modern thin client with an X server typically provides the same functionality at the same, or lower, cost.
Limitations and criticism.
"The Unix-Haters Handbook" (1994) devoted a full chapter to the problems of X. "Why X Is Not Our Ideal Window System" (1990) by Gajewska, Manasse and McCormack detailed problems in the protocol with recommendations for improvement.
User interface issues.
The lack of design guidelines in X has resulted in several vastly different interfaces, and in applications that have not always worked well together. The Inter-Client Communication Conventions Manual (ICCCM), a specification for client interoperability, has a reputation of being difficult to implement correctly. Further standards efforts such as Motif and CDE did not alleviate problems. This has frustrated users and programmers. Graphics programmers now generally address consistency of application look and feel and communication by coding to a specific desktop environment or to a specific widget toolkit, which also avoids having to deal directly with the ICCCM.
X also lacks native support for user-defined stored procedures on the X server, in the manner of NeWS — there is no Turing-complete scripting facility. Various desktop environments may thus offer their own (usually mutually incompatible) facilities.
Computer accessibility related issues.
Systems built upon X may have accessibility issues that make utilization of a computer difficult for disabled users, including right click, double click, middle click, mouse-over, and focus stealing. Some X11 clients deal with accessibility issues better than others, so persons with accessibility problems are not locked out of using X11. However there is no accessibility standard or accessibility guidelines for X11. Within the X11 standards process there is no working group on accessibility, however, accessibility needs are being addressed by software projects to provide these features on top of X.
The Orca project adds accessibility support to the X Window System, including implementing an API (AT-SPI). This is coupled with Gnome's ATK to allow for accessibility features to be implemented in X programs using the Gnome/GTK APIs. KDE provides a different set of accessibility software, including a text-to-speech converter and a screen magnifier. The other major desktops (LXDE, Xfce and Enlightenment) attempt to be compatible with ATK.
Network.
An X client cannot generally be detached from one server and reattached to another unless its code specifically provides for it (emacs is one of the few common programs with this ability). As such, moving an entire session from one X server to another is generally not possible. However, approaches like Virtual Network Computing (VNC), NX and Xpra allow a virtual session to be reached from different X servers (in a manner similar to GNU Screen in relation to terminals), and other applications and toolkits provide related facilities.
Workarounds like x11vnc ("VNC :0 viewers"), Xpra's shadow mode and NX's nxagent shadow mode also exist to make the current X-server screen available. This ability allows the user interface (mouse, keyboard, monitor) of a running application to be switched from one location to another without stopping and restarting the application.
Network traffic between an X server and remote X clients is not encrypted by default. An attacker with a packet sniffer can intercept it, making it possible to view anything displayed to or sent from the user's screen. The most common way to encrypt X traffic is to establish a Secure Shell (SSH) tunnel for communication.
Like all thin clients, when using X across a network, bandwidth limitations can impede the use of bitmap-intensive applications that require rapidly updating large portions of the screen with low latency, such as 3D animation or photo editing. Even a relatively small uncompressed 640x480x24bit 30fps video stream can easily outstrip the bandwidth of a 100Mbit network for a single client. In contrast, modern versions of X generally have extensions such as MESA allowing local display of a local program's graphics to be optimized to bypass the network model and directly control the video card, for use of full-screen video, rendered 3D applications, and other such applications.
Client–server separation.
X's design requires the clients and server to operate separately, and device independence and the separation of client and server incur overhead. Most of the overhead comes from network round-trip delay time between client and server (latency) rather than from the protocol itself: the best solutions to performance issues depend on efficient application design. A common criticism of X is that its network features result in excessive complexity and decreased performance if only used locally.
Modern X implementations use Unix domain sockets for efficient connections on the same host. Additionally shared memory (via the MIT-SHM extension) can be employed for faster client–server communication. However, the programmer must still explicitly activate and use the shared memory extension. It is also necessary to provide fallback paths in order to stay compatible with older implementations, and in order to communicate with non-local X servers.
Competitors.
Some people have attempted writing alternatives to and replacements for X. Historical alternatives include Sun's NeWS, which failed in the market, and NeXT's Display PostScript, both PostScript-based systems supporting user-definable display-side procedures, which X lacked. Current alternatives include:
Additional ways to achieve a functional form of the 'network transparency' feature of X, via network transmissibility of graphical services, include:
History.
Predecessors.
Several bitmap display systems preceded X. From Xerox came the Alto (1973) and the Star (1981). From Apollo Computer came Display Manager (1981). From Apple came the Lisa (1983) and the Macintosh (1984). The Unix world had the Andrew Project (1982) and Rob Pike's Blit terminal (1982).
Carnegie Mellon University produced a remote-access application called Alto Terminal, that displayed overlapping windows on the Xerox Alto, and made remote hosts (typically DEC VAX systems running Unix) responsible for handling window-exposure events and refreshing window contents as necessary.
X derives its name as a successor to a pre-1983 window system called W (the letter preceding X in the English alphabet). W ran under the V operating system. W used a network protocol supporting terminal and graphics windows, the server maintaining display lists.
Origin and early development.
 The email in which X was introduced to the Project Athena community at MIT in June 1984
The original idea of X emerged at MIT in 1984 as a collaboration between Jim Gettys (of Project Athena) and Bob Scheifler (of the MIT Laboratory for Computer Science). Scheifler needed a usable display environment for debugging the Argus system. Project Athena (a joint project between Digital Equipment Corporation (DEC), MIT and IBM to provide easy access to computing resources for all students) needed a platform-independent graphics system to link together its heterogeneous multiple-vendor systems; the window system then under development in Carnegie Mellon University's Andrew Project did not make licenses available, and no alternatives existed.
The project solved this by creating a protocol that could both run local applications and call on remote resources. In mid-1983 an initial port of W to Unix ran at one-fifth of its speed under V; in May 1984, Scheifler replaced the synchronous protocol of W with an asynchronous protocol and the display lists with immediate mode graphics to make X version 1. X became the first windowing system environment to offer true hardware independence and vendor independence.
Scheifler, Gettys and Ron Newman set to work and X progressed rapidly. They released Version 6 in January 1985. DEC, then preparing to release its first Ultrix workstation, judged X the only windowing system likely to become available in time. DEC engineers ported X6 to DEC's QVSS display on MicroVAX.
In the second quarter of 1985, X acquired color support to function in the DEC VAXstation-II/GPX, forming what became version 9.
A group at Brown University ported version 9 to the IBM RT/PC, but problems with reading unaligned data on the RT forced an incompatible protocol change, leading to version 10 in late 1985. By 1986, outside organizations had begun asking for X. X10R2 was released in January 1986, then X10R3 in February 1986. Although MIT had licensed X6 to some outside groups for a fee, it decided at this time to license X10R3 and future versions under what became known as the MIT License, intending to popularize X further and, in return, hoping that many more applications would become available. X10R3 became the first version to achieve wide deployment, with both DEC and Hewlett-Packard releasing products based on it. Other groups ported X10 to Apollo and to Sun workstations and even to the IBM PC/AT. Demonstrations of the first commercial application for X (a mechanical computer-aided engineering system from Cognition Inc. that ran on VAXes and remotely displayed on PCs running an X server ported by Jim Fulton and Jan Hardenbergh) took place at the Autofact trade show at that time. The last version of X10, X10R4, appeared in December 1986.
Attempts were made to enable X servers as real-time collaboration devices, much as Virtual Network Computing (VNC) would later allow a desktop to be shared. One such early effort was Philip J. Gust's SharedX tool.
Although X10 offered interesting and powerful functionality, it had become obvious that the X protocol could use a more hardware-neutral redesign before it became too widely deployed, but MIT alone would not have the resources available for such a complete redesign. As it happened, DEC's Western Software Laboratory found itself between projects with an experienced team. Smokey Wallace of DEC WSL and Jim Gettys proposed that DEC WSL build X11 and make it freely available under the same terms as X9 and X10. This process started in May 1986, with the protocol finalized in August. Alpha testing of the software started in February 1987, beta-testing in May; the release of X11 finally occurred on 15 September 1987.
The X11 protocol design, led by Scheifler, was extensively discussed on open mailing lists on the nascent Internet that were bridged to USENET newsgroups. Gettys moved to California to help lead the X11 development work at WSL from DEC's Systems Research Center, where Phil Karlton and Susan Angebrandt led the X11 sample server design and implementation. X therefore represents one of the first very large-scale distributed free and open source software projects.
The MIT X Consortium and the X Consortium, Inc..
In 1987, with the success of X11 becoming apparent, MIT wished to relinquish the stewardship of X, but at a June 1987 meeting with nine vendors, the vendors told MIT that they believed in the need for a neutral party to keep X from fragmenting in the marketplace. In January 1988, the "MIT X Consortium" formed as a non-profit vendor group, with Scheifler as director, to direct the future development of X in a neutral atmosphere inclusive of commercial and educational interests.
Jim Fulton joined in January 1988 and Keith Packard in March 1988 as senior developers, with Jim focusing on Xlib, fonts, window managers, and utilities; and Keith re-implementing the server. Donna Converse, Chris D. Peterson, and Stephen Gildea joined later that year, focusing on toolkits and widget sets, working closely with Ralph Swick of MIT Project Athena. The MIT X Consortium produced several significant revisions to X11, the first (Release 2 – X11R2) in February 1988. Jay Hersh joined the staff in January 1991 to work on the PEX and X113D functionality. He was followed soon after by Ralph Mor (who also worked on PEX) and Dave Sternlicht. In 1993, as the MIT X Consortium prepared to depart from MIT, the staff were joined by R. Gary Cutbill, Kaleb Keithley, and David Wiggins.
In 1993, the X Consortium, Inc. (a non-profit corporation) formed as the successor to the MIT X Consortium. It released X11R6 on 16 May 1994. In 1995 it took on the development of the Motif toolkit and of the Common Desktop Environment for Unix systems. The X Consortium dissolved at the end of 1996, producing a final revision, X11R6.3, and a legacy of increasing commercial influence in the development.
The Open Group.
In January 1997, the X Consortium passed stewardship of X to The Open Group, a vendor group formed in early 1996 by the merger of the Open Software Foundation and X/Open.
The Open Group released X11R6.4 in early 1998. Controversially, X11R6.4 departed from the traditional liberal licensing terms, as the Open Group sought to assure funding for the development of X. The new terms would have prevented its adoption by many projects (such as XFree86) and even by some commercial vendors. After XFree86 seemed poised to fork, the Open Group relicensed X11R6.4 under the traditional license in September 1998. The Open Group's last release came as X11R6.4 patch 3.
X.Org and XFree86.
XFree86 originated in 1992 from the X386 server for IBM PC compatibles included with X11R5 in 1991, written by Thomas Roell and Mark W. Snitily and donated to the MIT X Consortium by Snitily Graphics Consulting Services (SGCS). XFree86 evolved over time from just one port of X to the leading and most popular implementation and the "de facto" standard of X's development.
In May 1999, the Open Group formed X.Org. X.Org supervised the release of versions X11R6.5.1 onward. X development at this time had become moribund; most technical innovation since the X Consortium had dissolved had taken place in the XFree86 project. In 1999, the XFree86 team joined X.Org as an honorary (non-paying) member, encouraged by various hardware companies interested in using XFree86 with Linux and in its status as the most popular version of X.
By 2003, while the popularity of Linux (and hence the installed base of X) surged, X.Org remained inactive, and active development took place largely within XFree86. However, considerable dissent developed within XFree86. The XFree86 project suffered from a perception of a far too cathedral-like development model; developers could not get CVS commit access and vendors had to maintain extensive patch sets. In March 2003, the XFree86 organization expelled Keith Packard, who had joined XFree86 after the end of the original MIT X Consortium, with considerable ill feeling.
X.Org and XFree86 began discussing a reorganisation suited to properly nurturing the development of X. Jim Gettys had been pushing strongly for an open development model since at least 2000. Gettys, Packard and several others began discussing in detail the requirements for the effective governance of X with open development.
Finally, in an echo of the X11R6.4 licensing dispute, XFree86 released version 4.4 in February 2004 under a more restrictive license which many projects relying on X found unacceptable. The added clause to the license was based on the original BSD license's advertising clause, which was viewed by the Free Software Foundation and Debian as incompatible with the GNU General Public License. Other groups saw it as against the spirit of the original X. Theo de Raadt of OpenBSD, for instance, threatened to fork XFree86 citing license concerns. The license issue, combined with the difficulties in getting changes in, left many feeling the time was ripe for a fork.
The X.Org Foundation.
In early 2004, various people from X.Org and freedesktop.org formed the X.Org Foundation, and the Open Group gave it control of the codice_1 domain name. This marked a radical change in the governance of X. Whereas the stewards of X since 1988 (including the prior X.Org) had been vendor organizations, the Foundation was led by software developers and used community development based on the bazaar model, which relies on outside involvement. Membership was opened to individuals, with corporate membership being in the form of sponsorship. Several major corporations such as Hewlett-Packard currently support the X.Org Foundation.
The Foundation takes an oversight role over X development: technical decisions are made on their merits by achieving rough consensus among community members. Technical decisions are not made by the board of directors; in this sense, it is strongly modelled on the technically non-interventionist GNOME Foundation. The Foundation employs no developers.
The Foundation released X11R6.7, the X.Org Server, in April 2004, based on XFree86 4.4RC2 with X11R6.6 changes merged. Gettys and Packard had taken the last version of XFree86 under the old license and, by making a point of an open development model and retaining GPL compatibility, brought many of the old XFree86 developers on board.
X11R6.8 came out in September 2004. It added significant new features, including preliminary support for translucent windows and other sophisticated visual effects, screen magnifiers and thumbnailers, and facilities to integrate with 3D immersive display systems such as Sun's Project Looking Glass and the Croquet project. External applications called "compositing window managers" provide policy for the visual appearance.
On 21 December 2005, X.Org released X11R6.9, the monolithic source tree for legacy users, and X11R7.0, the same source code separated into independent modules, each maintainable in separate projects. The Foundation released X11R7.1 on 22 May 2006, about four months after 7.0, with considerable feature improvements.
XFree86 development continued for a few more years, 4.8.0 being released on 15 December 2008.
Future directions.
The X.Org Foundation and freedesktop.org managed the main line of X development and they intend to provide more access to ubiquitous 3D hardware features. For sufficiently capable combinations of hardware and operating systems, X.Org plans to access the video hardware only via the Direct Rendering Infrastructure (DRI), using the 3D hardware. The DRI first appeared in XFree86 version 4.0 and became standard in X11R6.7 and later, and this work is ongoing.
Nomenclature.
The proper names for the system are listed in the manual page as X; X Window System; X Version 11; X Window System, Version 11; or X11.
The term "X-Windows" (in the manner of the subsequently released "Microsoft Windows") is not officially endorsed — with X Consortium release manager Matt Landau stating in 1993, "There is no such thing as 'X Windows' or 'X Window', despite the repeated misuse of the forms by the trade rags" — though it has been in common informal use since early in the history of X and has been used deliberately for provocative effect, for example in the "Unix-Haters Handbook".
Key terms.
The X window system has nuanced usage of a number of terms when compared to common usage, particularly "display" and "screen", a subset of which is given here for convenience:
The term "display" should not be confused with the more specialized jargon "Zaphod display". The latter is a rare configuration allowing multiple users of a single computer to each have an independent set of display, mouse, and keyboard, as though they were using separate computers, but at a lower per-seat cost.
References.
</dl>

</doc>
<doc id="34150" url="http://en.wikipedia.org/wiki?curid=34150" title="Xena">
Xena

Xena is a fictional character from Robert Tapert's ' franchise. She first appeared in the 1995–1999 television series ', before going on to appear in "Xena: Warrior Princess" TV show and of the same name. The Warrior Princess has also appeared in the spin-off animated movie "", as well as numerous non-canon expanded universe material, such as and . Xena was played by New Zealand actress Lucy Lawless, who commonly wore a tight leather skirted outfit overlaid with metal armor.
Xena is the protagonist of the story, and the series depicts her on a quest to redeem herself for her dark past by using her formidable fighting skills to help people. Xena was raised as the daughter of Cyrene and Atrius in Amphipolis, though the episode "The Furies" raised the possibility that Ares might be Xena's biological father, but it is never pursued further. She had two brothers, the younger of who is dead; she visits his grave to speak with him in "Sins of the Past." In "Hercules: The Legendary Journeys," during her two first episodes, Xena was a villain, but in the third episode she appears in, she joins Hercules to defeat Darphus, who had taken her army. Aware that the character of Xena had been very successful with the public in the three "Hercules: The Legendary Journeys" episodes, the producers of the series decided to create a spin-off series based on her adventures. Later in "Xena: Warrior Princess" she is joined by Gabrielle, a small town bard. Together they go up against ruthless warlords and Gods in the ancient mythological world.
The character Gabrielle, introduced in the first episode, becomes Xena's greatest ally and best friend; her initial naïveté helps to balance Xena and assists her in recognizing and pursuing the "greater good."
Creation and production.
Xena was developed in 1995 by John Schulian as a secondary character for "", although Lawless had already appeared as the character Lyla on the episode "As Darkness Falls", on 20 February, 1995. Xena was originally conceived to die at the end of the third episode, "Unchained Heart", but when the studio decided they wanted to do a spin-off from "Hercules", the producer Robert Tapert said that Xena was the best choice, since she was largely well received by television critics and fans and had a full story to be explored. The studio wanted to do something about "Jason and the Argonauts", but Tapert said that show would have too much of the same feel as Hercules.
The original choice to play Xena was the British actress Vanessa Angel, but she fell ill and was unable to make it to the set. Ultimately the role was given to Lawless as she was already a resident of New Zealand. Lawless had several mishaps playing the character due to the stunts (some of which she performed herself), such as getting cut by swords, being struck in the head, and horse-related incidents. In 1996, while rehearsing a sketch for "The Tonight Show with Jay Leno," she broke her hip when she was thrown clear from her horse. As a result, several episodes of Season 2 had to be edited to accommodate her recovery, and some of them were changed so Lawless could have a very slight appearance, and the crew created some brand new episodes.
Bruce Campbell, Rose McIver, Hudson Leick, and Ted Raimi also portrayed Xena in various episodes of the series as a result of "body-swap" plotlines.
Appearances and development.
Origins on Hercules.
Xena originally appears as a villain in the "Hercules" episode ""; about ten years into her career of pillaging and marauding, Xena meets Hercules. Initially, she sets out to kill him. In "", her army turns against her, believing that she has become weak after she stops her lieutenant, Darphus, from killing a child in a sacked village. Xena runs a gauntlet, and survives, becoming the only person ever to survive the gauntlet. She then fights Hercules, in the hope that she will regain her army if she can bring back his head. Xena seems to be getting the upper hand until Hercules' cousin intervenes, making no real difference himself but inadvertently giving Hercules his sword, which allows him to fight Xena on equal ground and defeat her. However, Hercules refuses to kill Xena, telling her, "Killing isn't the only way of proving you're a warrior." Touched and inspired by Hercules' integrity, and by the fact that he too suffered the loss of blood kin as she did and yet chooses to fight in honor of them, she decides to join him and defeat her old army. In "Unchained Heart", Hercules tells Xena that there is goodness in her heart, and the two of them share a brief romantic relationship, before Xena decides to leave and start making amends for her past.
Fictional character history.
Initial turn to evil.
Several years prior to the series pilot, "Sins of the Past", Xena commits numerous horrible deeds from terrorism to piracy and murder and at one point becomes known as the "Destroyer of Nations." Her journey down the path of evil arguably begins when her beloved brother is killed during an attack by the warlord Cortese. Xena vows revenge and she becomes estranged from her mother as a result. Sometime later, she acts as the captain of a pirate ship, doing everything from raiding other ships to ransoming hostages. It is during one ransom attempt that she encounters the young, handsome and brash Roman nobleman named Julius Caesar. Caesar is an experienced warrior and military commander with grand ambitions. He and Xena have a passionate love affair and plan to join forces. Caesar, however, betrays Xena and has her beaten and her legs broken and then strung up on a beach to die of exposure—that is, until she is saved by an Egyptian slave girl named M'Lila. M'Lila had originally stowed away on Xena's ship and subsequently befriends her and teaches Xena her first pressure points. After saving Xena, M'Lila takes her to a healer who treats her injuries. While the healer is treating Xena, Roman soldiers burst in and try to kill Xena but M'Lila shields Xena and takes a fatal shot from a crossbow and dies in Xena's arms. This event drives Xena to the side of evil completely and despite her injuries manages to kill the soldiers but warns the last one before he dies: "Tell Hades to prepare himself; a new Xena is born tonight."
First steps towards redemption.
Afterward, Xena becomes the leader of an army and aligns herself with Borias whom she effectively seduces away from his family and the two join forces. The two become lovers and after a time, Xena becomes pregnant with her son Solan. It is during her pregnancy that a significant event happens. Xena travels with her Army to China where she hopes to build an alliance with the powerful Lao clan to facilitate her activities there. Subsequent events that involve Borias betraying Xena lead to Xena running for her life and being hunted. While on the run, Xena finds her way into Lao Ma's estate and she is protected and sheltered by the powerful noblewoman. Lao Ma cares for Xena as she never had been before by treating her as a friend who is only interested is helping her become a better person. Under her friend's guidance, she learns to put aside a great deal of her hatred and pain. Additionally, Lao Ma heals Xena's crippled legs and teaches her more about pressure points. Lao Ma gives Xena the metaphorical title "Warrior Princess," intending that she be a major catalyst for change in the land. In the end, Lao Ma's efforts come to nothing, at least in the short term. In the long run, however, Lao Ma's teachings are instrumental in shaping the good person she was to become.
Borias and Xena reconcile and renew their alliance, only to break it a final time and to split their forces between them, with Xena proving the stronger of the two. Borias is killed in the forthcoming battle, and Xena gives the newborn Solan to the Centaurs to raise so that he will be kept safe and protected.
Encounter with Hercules and subsequent reform.
Xena continues her life as a warlord for many years until she has a life-changing encounter with Hercules wherein she turns her back on the path of evil. She turns against her troops to protect a baby whose family would not pay the ransom she demanded. Her troops were going to kill Xena for becoming weak in their eyes. After these events, Xena travels with Hercules for a short time and the two share a brief romantic relationship. While their romance does not last long, the two form a special friendship. Each comes to respect the other's abilities and judgement. In a series 1 episode, each acknowledged the positive impact the other had on the world. In that instalment, Xena said, "The world needs Hercules." To that, Hercules responded, "The world needs Xena, too." As the years progress, Xena and Hercules come to each other's aid at different times as well as acting as a source of comfort to the other. However, after first meeting Hercules, Xena finds the way to redemption to be more painful than she anticipated.
The meeting with Gabrielle.
Haunted by her past transgressions, she is about to give up on her life as a warrior completely. In the pilot episode, she strips off her armor and weapons and buries them in the dirt. She sees a group of village girls being attacked by a band of warriors. In the group is Gabrielle. Xena saves the young women and Gabrielle is left in awe of the Warrior Princess's abilities. Gabrielle follows Xena in a quest to persuade Xena to let her be her traveling companion. During the pilot, Xena returns to her home town, Amphipolis, where she eventually reconciles with her mother, Cyrene. She also visits the grave of her brother Lyceus to 'speak' with him. When Xena privately confides with Lyceus that it is difficult to be alone, Gabrielle—who is silently standing in the doorway of the crypt—tells her, "You're not alone." Soon, Xena agrees to allow Gabrielle to travel with her. Over time, Gabrielle becomes Xena's dearest friend.
Subsequent travels and hardships.
Gabrielle and Xena become best friends, soulmates and indeed constant companions over the many adventures that follow. Each of the women learns from the other; Gabrielle becomes a hardened warrior, and Xena develops a softer and more loving personality to balance her warrior's heart. Xena's subsequent life is marred by many tragedies. Her son Solan, who never came to know her as his mother, is killed by Hope, Gabrielle's demonic child, (with the help of Callisto); and Xena nearly loses Gabrielle more than once.
The instances where Xena and Gabrielle almost part ways tend to result from the outside manipulations of others. The most serious of these, is, of course, the death of Xena's son at the hands of Gabrielle's demonic child, Hope. After this, Gabrielle, consumed with grief journeys to stay with the Amazons. Xena, in turn, locates her and tries to take Gabrielle's life by throwing her over a cliff while she is in a weakened state. Xena fails in doing this and, subsequently, both women reconcile with the help of the spirit of Xena's son Solan. Specifically, Solan creates the land of Illusia wherein through music both women expresses their grief and anger; not so much with each other, but with the traumas they have each endured. It is here that Xena confesses that she did, indeed, kill Ming Tien and she admits to Solan that she is his mother and sings to him asking forgiveness. After this, they travel together again.
Enemies.
Soon after the start of her journeys with Gabrielle, Xena runs into Ares, who has evidently known her since her warlord days and he tries to seduce her into joining him as his Warrior Queen, efforts that she repeatedly thwarts. She also encounters a formidable warrior woman named Callisto, whose family was killed by Xena years ago.
The path to redemption continues.
Marcus, a warrior, close friend and lover from her warlord days, whom she persuades to follow her in choosing good, is killed while doing his first good deed. Later, he is allowed to briefly return to the world of the living to help thwart a vicious killer who has escaped from the underworld. He and Xena spend a night together before Marcus has to return to the other side. Several years after her first meeting with Lao Ma, a messenger is sent by Lao Ma to ask Xena to travel to China to aid in stopping a great evil from taking hold. She sets out without delay to help her dear friend but insists that she must deal with this alone and that Gabrielle stay behind. In spite of her best efforts, she is too late to save her mentor and friend Lao Ma from being tortured to death by her own son, the emperor Ming T'ien and is crushed with the loss. Finally, she and Gabrielle are crucified by the Romans on the Ides of March by Caesar, previously an ally and former lover of Xena's with whom she had planned to take over known civilization until he betrayed her. Caeser, himself, is betrayed and killed by Brutus. They are later revived by a mystic named Eli with the spiritual aid of Callisto, who by that time had become an angel after being killed by Xena. This event would have long-lasting effects for all involved.
Eve/Livia.
The event mentioned above leads to the birth of Xena's daughter, . Essentially speaking, Eve is the reincarnated Callisto. Unfortunately, mother and daughter would have little time together as the gods were bent on destroying the child to save themselves as she is prophesied to bring about the Twilight of the Olympian gods and the birth of Christianity. In order to save her child as well as herself and Gabrielle; they fake their deaths, but their plan goes awry when Ares buries them in an ice cave where they sleep for 25 years.
During that time, Eve is adopted by the Roman nobleman Octavius who provides for her every need and make certain that she receives the best of everything. She grows up to become Livia, the Champion of Rome, and a ruthless persecutor of Eli's followers. Eve's ruthless behavior may be due to the influence of Callisto's soul, but this is unclear, particularly since Callisto was purged of all the evil within her when she became an angel. After her return, Xena is able to turn Livia to repentance, and Livia takes back the name Eve and becomes the Messenger of Eli. After Eve's cleansing by baptism, Xena is granted the power to kill gods as long as her daughter lives. In a final confrontation, the Twilight comes to pass when Xena kills most of the gods to save her daughter, with the help of God and Archangel Michael, and is herself saved by Ares when he gives up his immortality to heal the badly injured and dying Eve and Gabrielle, with Xena later helping him regain his godhood.
Final redemption and death.
Xena's quest for redemption ends when she sacrifices herself to kill the Japanese demon Yodoshi, and decides to stay dead so the souls of the 40,000 she (accidentally) killed years ago could be released into a state of peace. However, her spirit is seen with Gabrielle in a ship shortly afterwards.
Legacy.
According to the darsham, Naiyima, this is only one of many lives Xena will live throughout the ages. One such life is that of Arminestra, an Indian holy mother who leads a movement that preaches peace and yet another is a woman named Melinda, who, during World War II, uncovers the tomb of Ares and is possessed by the spirit of Xena to stop the God of War. In many of those lives, she will walk a path together with her soulmate Gabrielle furthering the cause of good against evil.
Skills and abilities.
Xena has many skills that she acquired during her extensive travels to many parts of the ancient world over a period of many years. In particular, she has shown remarkable skill and prowess in hand-to-hand combat, displaying numerous acrobatic tricks and the ability to disable and/or otherwise kill multiple opponents at one time. She is also skilled in the use of pressure points—being able to cripple or even kill someone if she triggers the appropriate pressure point. Xena has an extensive knowledge of first aid and herbal remedies that rivals that of any professional healer.
Xena's signature weapon is the chakram, a razor-edged throwing weapon which she often uses for ranged combat. Xena can skillfully deflect the chakram off the surfaces it strikes, allowing her to hit multiple targets in one throw. She is usually able to deflect the chakram back towards her, allowing her to catch it. Besides being a formidable weapon, the chakram has other uses such as distracting enemies or quickly cutting distant targets such as ropes. Along with her sword and chakram, she has also shown great proficiency with other weapons such as batons, daggers, and whips. On three occasions, she used telekinesis and energy projection thanks to Lao Ma's teachings; she also knows the rudiments of most other forms of magic. Xena also once possessed the power to kill gods through her daughter, Eve. Throughout the series, Xena often utilized a signature war cry, "Alalaes." Her cry was an alternate writing for "Alale" (or "Alala"), who in Greek mythology was the female personification of the war cry.
Xena is a formidable tactician and strategic thinker. She has the ability to analyze her enemies's tactics and effectively formulate a response. In responding to her enemies's attacks, she shows a great deal of creativity and ingenuity; at times, she has worked with little or no resources and limited time. Xena is well versed in military tactics such as forming a defensive perimeter, building defensive fortifications, organizing and leading troops, and cutting an enemy's supply lines. She also repeatedly demonstrates a talent for disguises, infiltration, and codes.
In other media.
Xena has appeared in all of the series spin-offs, usually as the lead character. The animated movie "" marks the first appearance of Xena outside of the television series. She also appears in the comics series "," originally released by Topp and Dark Horse Comics, and in 2007, Dynamite Entertainment acquired the rights to the book upon its discovery that the show still had many fans. This resulted in Dynamite Entertainment's spin-off comic book series "Xena: Contest of the Pantheons" and "Dark Xena." This last takes place after the T.V. Series ended.
Xena is a playable character in the videogames "," and a selectable character in "." In 1999, Lucy Lawless also appeared in the animated television show "The Simpsons" dressed as her Xena character, during the Treehouse of Horror X.
Reception and legacy.
Lesbian subtext and debates.
"Xena" has enjoyed a particular cult status in the lesbian community. Some of the lesbian fanbase see Xena and Gabrielle as a couple and have embraced them as role models and lesbian icons. A group called The Marching Xenas participated in many gay and lesbian pride parades.
A subject of much interest and debate among viewers is the question of whether Xena and Gabrielle are lovers. The issue is left deliberately ambiguous by the writers during most of the show. Jokes, innuendo, and other subtle evidence of a romantic relationship between Xena and Gabrielle is referred to as "lesbian subtext" or simply "subtext" by fans. The issue of the true nature of the Xena/Gabrielle relationship caused intense shipping debates in the fandom, which turned especially impassioned due to spillover from real-life debates about same-sex sexuality and gay rights.
Many fans felt that the sexual nature of Xena's and Gabrielle's relationship was cemented by an interview given by Lucy Lawless to "Lesbian News" magazine in 2003. Lawless stated that after the series finale—in which Gabrielle revives Xena with a mouth-to-mouth water transfer and filmed to look like a full kiss—she had come to believe that Xena's and Gabrielle's relationship was "definitely gay... there was always a 'well, she might be or she might not be' but when there was that drip of water passing between their lips in the very final scene, that cemented it for me. Now it wasn't just that Xena was bisexual and kinda liked her gal pal and they kind of fooled around sometimes, it was 'Nope, they're married, man'."
The "Xena" fandom also popularized the term Altfic (from "alternative fiction") to refer to same-sex romantic fan fiction. Many fans felt the term slash fiction carried the connotation of being about male/male couples only and was not a good description for romantic fan fiction about Xena and Gabrielle.
She was ranked No.3 in AfterEllen.com's Top 50 Favorite Female TV Characters.
Popular culture.
"Xena: Warrior Princess" has been referred to as a pop cultural phenomenon and feminist and lesbian icon. The television series, which employed pop culture references as a frequent humorous device, has itself become a frequent pop culture reference in video games, comics and television shows, and has been frequently parodied and spoofed.
"Xena" has been credited by many, including "Buffy the Vampire Slayer" creator Joss Whedon, with blazing the trail for a new generation of female action heroes such as Buffy, Max of "Dark Angel", Sydney Bristow of "Alias", and Beatrix Kiddo a.k.a. the Bride in Quentin Tarantino's "Kill Bill". The director Quentin Tarantino is also a fan of Xena. It is interesting to note that after serving as Lucy Lawless' stunt double on "Xena", stunt woman Zoë E. Bell was recruited to be Uma Thurman's stunt double in Tarantino's "Kill Bill". By helping to pave the way for female action heroes in television and film, "Xena" also strengthened the stunt "woman" profession.
David Eick, one of the co-developers of the Xena series, was also the executive producer of "Battlestar Galactica", which also features strong female characters, and Lucy Lawless in a recurring role.
In 2005, the team that discovered the dwarf planet 2003 UB313 nicknamed it 'Xena' in honor of the TV character. On 1 October, 2005, the team announced that 2003 UB313 had a moon, which they had nicknamed "Gabrielle". The objects were officially named Eris and Dysnomia by the International Astronomical Union on 13 September, 2006. Although the official names have legitimate roots in Greek mythology, "Dysnomia" is also a synonym to the word "anomia", which means "lawlessness" in Greek, perpetuating the link with Lucy Lawless.
In 2006, Lucy Lawless donated her personal Xena costume to the Museum of American History. In an interview the same year with "Smithsonian" magazine, she was asked the question "Was the Warrior Princess outfit comfortable?" and she responded:
Not at first, because they would put boning in the corset. It would cover up those little floating ribs that are so important for breathing, so I'd feel like I was having panic attacks. But it just became a second skin after a while. It was very functional, once I got over the modesty factor. I admit to being a little bit embarrassed the first couple weeks because I'd never worn anything so short.—Lucy Lawless, "Smithsonian", November 2006, page 44
In 2004, Xena was listed in Bravo's "100 Greatest TV Characters".

</doc>
<doc id="34151" url="http://en.wikipedia.org/wiki?curid=34151" title="X-ray crystallography">
X-ray crystallography

X-ray crystallography is a tool used for identifying the atomic and molecular structure of a crystal, in which the crystalline atoms cause a beam of incident X-rays to diffract into many specific directions. By measuring the angles and intensities of these diffracted beams, a crystallographer can produce a three-dimensional picture of the density of electrons within the crystal. From this electron density, the mean positions of the atoms in the crystal can be determined, as well as their chemical bonds, their disorder and various other information.
Since many materials can form crystals—such as salts, metals, minerals, semiconductors, as well as various inorganic, organic and biological molecules—X-ray crystallography has been fundamental in the development of many scientific fields. In its first decades of use, this method determined the size of atoms, the lengths and types of chemical bonds, and the atomic-scale differences among various materials, especially minerals and alloys. The method also revealed the structure and function of many biological molecules, including vitamins, drugs, proteins and nucleic acids such as DNA. X-ray crystallography is still the chief method for characterizing the atomic structure of new materials and in discerning materials that appear similar by other experiments. X-ray crystal structures can also account for unusual electronic or elastic properties of a material, shed light on chemical interactions and processes, or serve as the basis for designing pharmaceuticals against diseases.
In a single-crystal X-ray diffraction measurement, a crystal is mounted on a goniometer. The goniometer is used to position the crystal at selected orientations. The crystal is bombarded with a finely focused monochromatic beam of X-rays, producing a diffraction pattern of regularly spaced spots known as "reflections". The two-dimensional images taken at different rotations are converted into a three-dimensional model of the density of electrons within the crystal using the mathematical method of Fourier transforms, combined with chemical data known for the sample. Poor resolution (fuzziness) or even errors may result if the crystals are too small, or not uniform enough in their internal makeup.
X-ray crystallography is related to several other methods for determining atomic structures. Similar diffraction patterns can be produced by scattering electrons or neutrons, which are likewise interpreted by Fourier transformation. If single crystals of sufficient size cannot be obtained, various other X-ray methods can be applied to obtain less detailed information; such methods include fiber diffraction, powder diffraction and (if the sample is not crystallized) small-angle X-ray scattering (SAXS).
If the material under investigation is only available in the form of nanocrystalline powders or suffers from poor crystallinity, the methods of electron crystallography can be applied for determining the atomic structure.
For all above mentioned X-ray diffraction methods, the scattering is elastic; the scattered X-rays have the same wavelength as the incoming X-ray. By contrast, "inelastic" X-ray scattering methods are useful in studying excitations of the sample, rather than the distribution of its atoms.
History.
Early scientific history of crystals and X-rays.
Crystals have long been admired for their regularity and symmetry, but they were not investigated scientifically until the 17th century. Johannes Kepler hypothesized in his work "Strena seu de Nive Sexangula" (A New Year's Gift of Hexagonal Snow) (1611) that the hexagonal symmetry of snowflake crystals was due to a regular packing of spherical water particles.
Crystal symmetry was first investigated experimentally by Danish scientist Nicolas Steno (1669), who showed that the angles between the faces are the same in every exemplar of a particular type of crystal, and by René Just Haüy (1784), who discovered that every face of a crystal can be described by simple stacking patterns of blocks of the same shape and size. Hence, William Hallowes Miller in 1839 was able to give each face a unique label of three small integers, the Miller indices which are still used today for identifying crystal faces. Haüy's study led to the correct idea that crystals are a regular three-dimensional array (a Bravais lattice) of atoms and molecules; a single unit cell is repeated indefinitely along three principal directions that are not necessarily perpendicular. In the 19th century, a complete catalog of the possible symmetries of a crystal was worked out by Johan Hessel, Auguste Bravais, Evgraf Fedorov, Arthur Schönflies and (belatedly) William Barlow. From the available data and physical reasoning, Barlow proposed several crystal structures in the 1880s that were validated later by X-ray crystallography; however, the available data were too scarce in the 1880s to accept his models as conclusive.
X-rays were discovered by Wilhelm Conrad Röntgen in 1895, just as the studies of crystal symmetry were being concluded. Physicists were initially uncertain of the nature of X-rays, although it was soon suspected (correctly) that they were waves of electromagnetic radiation, in other words, another form of light. At that time, the wave model of light—specifically, the Maxwell theory of electromagnetic radiation—was well accepted among scientists, and experiments by Charles Glover Barkla showed that X-rays exhibited phenomena associated with electromagnetic waves, including transverse polarization and spectral lines akin to those observed in the visible wavelengths. Single-slit experiments in the laboratory of Arnold Sommerfeld suggested the wavelength of X-rays was about 1 angstrom. However, X-rays are composed of photons, and thus are not only waves of electromagnetic radiation but also exhibit particle-like properties. The photon concept was introduced by Albert Einstein in 1905, but it was not broadly accepted until 1922, when Arthur Compton confirmed it by the scattering of X-rays from electrons. Therefore, these particle-like properties of X-rays, such as their ionization of gases, caused William Henry Bragg to argue in 1907 that X-rays were "not" electromagnetic radiation. Nevertheless, Bragg's view was not broadly accepted and the observation of X-ray diffraction by Max von Laue in 1912 confirmed for most scientists that X-rays were a form of electromagnetic radiation.
X-ray analysis of crystals.
Crystals are regular arrays of atoms, and X-rays can be considered waves of electromagnetic radiation. Atoms scatter X-ray waves, primarily through the atoms' electrons. Just as an ocean wave striking a lighthouse produces secondary circular waves emanating from the lighthouse, so an X-ray striking an electron produces secondary spherical waves emanating from the electron. This phenomenon is known as elastic scattering, and the electron (or lighthouse) is known as the "scatterer". A regular array of scatterers produces a regular array of spherical waves. Although these waves cancel one another out in most directions through destructive interference, they add constructively in a few specific directions, determined by Bragg's law:
Here "d" is the spacing between diffracting planes, formula_2 is the incident angle, "n" is any integer, and λ is the wavelength of the beam. These specific directions appear as spots on the diffraction pattern called "reflections". Thus, X-ray diffraction results from an electromagnetic wave (the X-ray) impinging on a regular array of scatterers (the repeating arrangement of atoms within the crystal).
X-rays are used to produce the diffraction pattern because their wavelength λ is typically the same order of magnitude (1–100 angstroms) as the spacing "d" between planes in the crystal. In principle, any wave impinging on a regular array of scatterers produces diffraction, as predicted first by Francesco Maria Grimaldi in 1665. To produce significant diffraction, the spacing between the scatterers and the wavelength of the impinging wave should be similar in size. For illustration, the diffraction of sunlight through a bird's feather was first reported by James Gregory in the later 17th century. The first artificial diffraction gratings for visible light were constructed by David Rittenhouse in 1787, and Joseph von Fraunhofer in 1821. However, visible light has too long a wavelength (typically, 5500 angstroms) to observe diffraction from crystals. Prior to the first X-ray diffraction experiments, the spacings between lattice planes in a crystal were not known with certainty.
The idea that crystals could be used as a diffraction grating for X-rays arose in 1912 in a conversation between Paul Peter Ewald and Max von Laue in the English Garden in Munich. Ewald had proposed a resonator model of crystals for his thesis, but this model could not be validated using visible light, since the wavelength was much larger than the spacing between the resonators. Von Laue realized that electromagnetic radiation of a shorter wavelength was needed to observe such small spacings, and suggested that X-rays might have a wavelength comparable to the unit-cell spacing in crystals. Von Laue worked with two technicians, Walter Friedrich and his assistant Paul Knipping, to shine a beam of X-rays through a copper sulfate crystal and record its diffraction on a photographic plate. After being developed, the plate showed a large number of well-defined spots arranged in a pattern of intersecting circles around the spot produced by the central beam. Von Laue developed a law that connects the scattering angles and the size and orientation of the unit-cell spacings in the crystal, for which he was awarded the Nobel Prize in Physics in 1914.
Scattering.
As described in the mathematical derivation below, the X-ray scattering is determined by the density of electrons within the crystal. Since the energy of an X-ray is much greater than that of a valence electron, the scattering may be modeled as Thomson scattering, the interaction of an electromagnetic ray with a free electron. This model is generally adopted to describe the polarization of the scattered radiation.
The intensity of Thomson scattering for one particle with mass "m" and charge "q" is:
Hence the atomic nuclei, which are much heavier than an electron, contribute negligibly to the scattered X-rays.
Development from 1912 to 1920.
After Von Laue's pioneering research, the field developed rapidly, most notably by physicists William Lawrence Bragg and his father William Henry Bragg. In 1912–1913, the younger Bragg developed Bragg's law, which connects the observed scattering with reflections from evenly spaced planes within the crystal. The Braggs, father and son, shared the 1915 Nobel Prize in Physics for their work in crystallography. The earliest structures were generally simple and marked by one-dimensional symmetry. However, as computational and experimental methods improved over the next decades, it became feasible to deduce reliable atomic positions for more complicated two- and three-dimensional arrangements of atoms in the unit-cell.
The potential of X-ray crystallography for determining the structure of molecules and minerals—then only known vaguely from chemical and hydrodynamic experiments—was realized immediately. The earliest structures were simple inorganic crystals and minerals, but even these revealed fundamental laws of physics and chemistry. The first atomic-resolution structure to be "solved" (i.e., determined) in 1914 was that of table salt. The distribution of electrons in the table-salt structure showed that crystals are not necessarily composed of covalently bonded molecules, and proved the existence of ionic compounds. The structure of diamond was solved in the same year, proving the tetrahedral arrangement of its chemical bonds and showing that the length of C–C single bond was 1.52 angstroms. Other early structures included copper, calcium fluoride (CaF2, also known as "fluorite"), calcite (CaCO3) and pyrite (FeS2) in 1914; spinel (MgAl2O4) in 1915; the rutile and anatase forms of titanium dioxide (TiO2) in 1916; pyrochroite Mn(OH)2 and, by extension, brucite Mg(OH)2 in 1919;. Also in 1919 sodium nitrate (NaNO3) and caesium dichloroiodide (CsICl2) were determined by Ralph Walter Graystone Wyckoff, and the wurtzite (hexagonal ZnS) structure became known in 1920.
The structure of graphite was solved in 1916 by the related method of powder diffraction, which was developed by Peter Debye and Paul Scherrer and, independently, by Albert Hull in 1917. The structure of graphite was determined from single-crystal diffraction in 1924 by two groups independently. Hull also used the powder method to determine the structures of various metals, such as iron and magnesium.
Cultural and aesthetic importance of X-ray crystallography.
In what has been called his scientific autobiography, "The Development of X-ray Analysis", Sir William Lawrence Bragg mentioned that he believed the field of crystallography was particularly welcoming to women because the techno-aesthetics of the molecular structures resembled textiles and household objects. Bragg was known to compare crystal formation to "curtains, wallpapers, mosaics, and roses."
In 1951, the Festival Pattern Group at the Festival of Britain hosted a collaborative group of textile manufacturers and experienced crystallographers to design lace and prints based on the X-ray crystallography of insulin, china clay, and hemoglobin. One of the leading scientists of the project was Dr. Helen Megaw (1907–2002), the Assistant Director of Research at the Cavendish Laboratory in Cambridge at the time. Megaw is credited as one of the central figures who took inspiration from crystal diagrams and saw their potential in design. In 2008, the Wellcome Collection in London curated an exhibition on the Festival Pattern Group called "From Atom to Patterns."
Contributions to chemistry and material science.
X-ray crystallography has led to a better understanding of chemical bonds and non-covalent interactions. The initial studies revealed the typical radii of atoms, and confirmed many theoretical models of chemical bonding, such as the tetrahedral bonding of carbon in the diamond structure, the octahedral bonding of metals observed in ammonium hexachloroplatinate (IV), and the resonance observed in the planar carbonate group and in aromatic molecules. Kathleen Lonsdale's 1928 structure of hexamethylbenzene established the hexagonal symmetry of benzene and showed a clear difference in bond length between the aliphatic C–C bonds and aromatic C–C bonds; this finding led to the idea of resonance between chemical bonds, which had profound consequences for the development of chemistry. Her conclusions were anticipated by William Henry Bragg, who published models of naphthalene and anthracene in 1921 based on other molecules, an early form of molecular replacement.
Also in the 1920s, Victor Moritz Goldschmidt and later Linus Pauling developed rules for eliminating chemically unlikely structures and for determining the relative sizes of atoms. These rules led to the structure of brookite (1928) and an understanding of the relative stability of the rutile, brookite and anatase forms of titanium dioxide.
The distance between two bonded atoms is a sensitive measure of the bond strength and its bond order; thus, X-ray crystallographic studies have led to the discovery of even more exotic types of bonding in inorganic chemistry, such as metal-metal double bonds, metal-metal quadruple bonds, and three-center, two-electron bonds. X-ray crystallography—or, strictly speaking, an inelastic Compton scattering experiment—has also provided evidence for the partly covalent character of hydrogen bonds. In the field of organometallic chemistry, the X-ray structure of ferrocene initiated scientific studies of sandwich compounds, while that of Zeise's salt stimulated research into "back bonding" and metal-pi complexes. Finally, X-ray crystallography had a pioneering role in the development of supramolecular chemistry, particularly in clarifying the structures of the crown ethers and the principles of host-guest chemistry.
In material sciences, many complicated inorganic and organometallic systems have been analyzed using single-crystal methods, such as fullerenes, metalloporphyrins, and other complicated compounds. Single-crystal diffraction is also used in the pharmaceutical industry, due to recent problems with polymorphs. The major factors affecting the quality of single-crystal structures are the crystal's size and regularity; recrystallization is a commonly used technique to improve these factors in small-molecule crystals. The Cambridge Structural Database contains over 500,000 structures; over 99% of these structures were determined by X-ray diffraction.
Mineralogy and metallurgy.
Since the 1920s, X-ray diffraction has been the principal method for determining the arrangement of atoms in minerals and metals. The application of X-ray crystallography to mineralogy began with the structure of garnet, which was determined in 1924 by Menzer. A systematic X-ray crystallographic study of the silicates was undertaken in the 1920s. This study showed that, as the Si/O ratio is altered, the silicate crystals exhibit significant changes in their atomic arrangements. Machatschki extended these insights to minerals in which aluminium substitutes for the silicon atoms of the silicates. The first application of X-ray crystallography to metallurgy likewise occurred in the mid-1920s. Most notably, Linus Pauling's structure of the alloy Mg2Sn led to his theory of the stability and structure of complex ionic crystals.
On October 17, 2012, the Curiosity rover on the planet Mars at "Rocknest" performed the first X-ray diffraction analysis of Martian soil. The results from the rover's CheMin analyzer revealed the presence of several minerals, including feldspar, pyroxenes and olivine, and suggested that the Martian soil in the sample was similar to the "weathered basaltic soils" of Hawaiian volcanoes.
Early organic and small biological molecules.
The first structure of an organic compound, hexamethylenetetramine, was solved in 1923. This was followed by several studies of long-chain fatty acids, which are an important component of biological membranes. In the 1930s, the structures of much larger molecules with two-dimensional complexity began to be solved. A significant advance was the structure of phthalocyanine, a large planar molecule that is closely related to porphyrin molecules important in biology, such as heme, corrin and chlorophyll.
X-ray crystallography of biological molecules took off with Dorothy Crowfoot Hodgkin, who solved the structures of cholesterol (1937), penicillin (1946) and vitamin B12 (1956), for which she was awarded the Nobel Prize in Chemistry in 1964. In 1969, she succeeded in solving the structure of insulin, on which she worked for over thirty years.
Biological macromolecular crystallography.
Crystal structures of proteins (which are irregular and hundreds of times larger than cholesterol) began to be solved in the late 1950s, beginning with the structure of sperm whale myoglobin by Sir John Cowdery Kendrew, for which he shared the Nobel Prize in Chemistry with Max Perutz in 1962. Since that success, over 86817 X-ray crystal structures of proteins, nucleic acids and other biological molecules have been determined. For comparison, the nearest competing method in terms of structures analyzed is nuclear magnetic resonance (NMR) spectroscopy, which has resolved 9561 chemical structures. Moreover, crystallography can solve structures of arbitrarily large molecules, whereas solution-state NMR is restricted to relatively small ones (less than 70 kDa). X-ray crystallography is now used routinely by scientists to determine how a pharmaceutical drug interacts with its protein target and what changes might improve it. However, intrinsic membrane proteins remain challenging to crystallize because they require detergents or other means to solubilize them in isolation, and such detergents often interfere with crystallization. Such membrane proteins are a large component of the genome and include many proteins of great physiological importance, such as ion channels and receptors. Helium cryogenics are used to prevent radiation damage in protein crystals.
Relationship to other scattering techniques.
Elastic vs. inelastic scattering.
X-ray crystallography is a form of elastic scattering; the outgoing X-rays have the same energy, and thus same wavelength, as the incoming X-rays, only with altered direction. By contrast, "inelastic scattering" occurs when energy is transferred from the incoming X-ray to the crystal, e.g., by exciting an inner-shell electron to a higher energy level. Such inelastic scattering reduces the energy (or increases the wavelength) of the outgoing beam. Inelastic scattering is useful for probing such excitations of matter, but not in determining the distribution of scatterers within the matter, which is the goal of X-ray crystallography.
X-rays range in wavelength from 10 to 0.01 nanometers; a typical wavelength used for crystallography is 1 Å (0.1 nm), which is on the scale of covalent chemical bonds and the radius of a single atom. Longer-wavelength photons (such as ultraviolet radiation) would not have sufficient resolution to determine the atomic positions. At the other extreme, shorter-wavelength photons such as gamma rays are difficult to produce in large numbers, difficult to focus, and interact too strongly with matter, producing particle-antiparticle pairs. Therefore, X-rays are the "sweetspot" for wavelength when determining atomic-resolution structures from the scattering of electromagnetic radiation.
Other X-ray techniques.
Other forms of elastic X-ray scattering include powder diffraction, SAXS and several types of X-ray fiber diffraction, which was used by Rosalind Franklin in determining the double-helix structure of DNA. In general, single-crystal X-ray diffraction offers more structural information than these other techniques; however, it requires a sufficiently large and regular crystal, which is not always available.
These scattering methods generally use "monochromatic" X-rays, which are restricted to a single wavelength with minor deviations. A broad spectrum of X-rays (that is, a blend of X-rays with different wavelengths) can also be used to carry out X-ray diffraction, a technique known as the Laue method. This is the method used in the original discovery of X-ray diffraction. Laue scattering provides much structural information with only a short exposure to the X-ray beam, and is therefore used in structural studies of very rapid events (Time resolved crystallography). However, it is not as well-suited as monochromatic scattering for determining the full atomic structure of a crystal and therefore works better with crystals with relatively simple atomic arrangements.
The Laue back reflection mode records X-rays scattered backwards from a broad spectrum source. This is useful if the sample is too thick for X-rays to transmit through it. The diffracting planes in the crystal are determined by knowing that the normal to the diffracting plane bisects the angle between the incident beam and the diffracted beam. A Greninger chart can be used to interpret the back reflection Laue photograph.
Electron and neutron diffraction.
Other particles, such as electrons and neutrons, may be used to produce a diffraction pattern. Although electron, neutron, and X-ray scattering are based on different physical processes, the resulting diffraction patterns are analyzed using the same coherent diffraction imaging techniques.
As derived below, the electron density within the crystal and the diffraction patterns are related by a simple mathematical method, the Fourier transform, which allows the density to be calculated relatively easily from the patterns. However, this works only if the scattering is "weak", i.e., if the scattered beams are much less intense than the incoming beam. Weakly scattered beams pass through the remainder of the crystal without undergoing a second scattering event. Such re-scattered waves are called "secondary scattering" and hinder the analysis. Any sufficiently thick crystal will produce secondary scattering, but since X-rays interact relatively weakly with the electrons, this is generally not a significant concern. By contrast, electron beams may produce strong secondary scattering even for relatively thin crystals (>100 nm). Since this thickness corresponds to the diameter of many viruses, a promising direction is the electron diffraction of isolated macromolecular assemblies, such as viral capsids and molecular machines, which may be carried out with a cryo-electron microscope. Moreover the strong interaction of electrons with matter (about 1000 times stronger than for X-rays) allows determination of the atomic structure of extremely small volumes. The field of applications for electron crystallography ranges from bio molecules like membrane proteins over organic thin films to the complex structures of (nanocrystalline) intermetallic compounds and zeolites.
Neutron diffraction is an excellent method for structure determination, although it has been difficult to obtain intense, monochromatic beams of neutrons in sufficient quantities. Traditionally, nuclear reactors have been used, although the new Spallation Neutron Source holds much promise in the near future. Being uncharged, neutrons scatter much more readily from the atomic nuclei rather than from the electrons. Therefore, neutron scattering is very useful for observing the positions of light atoms with few electrons, especially hydrogen, which is essentially invisible in the X-ray diffraction. Neutron scattering also has the remarkable property that the solvent can be made invisible by adjusting the ratio of normal water, H2O, and heavy water, D2O.
Methods.
Overview of single-crystal X-ray diffraction.
The oldest and most precise method of X-ray crystallography is "single-crystal X-ray diffraction", in which a beam of X-rays strikes a single crystal, producing scattered beams. When they land on a piece of film or other detector, these beams make a "diffraction pattern" of spots; the strengths and angles of these beams are recorded as the crystal is gradually rotated. Each spot is called a "reflection", since it corresponds to the reflection of the X-rays from one set of evenly spaced planes within the crystal. For single crystals of sufficient purity and regularity, X-ray diffraction data can determine the mean chemical bond lengths and angles to within a few thousandths of an angstrom and to within a few tenths of a degree, respectively. The atoms in a crystal are not static, but oscillate about their mean positions, usually by less than a few tenths of an angstrom. X-ray crystallography allows measuring the size of these oscillations.
Procedure.
The technique of single-crystal X-ray crystallography has three basic steps. The first—and often most difficult—step is to obtain an adequate crystal of the material under study. The crystal should be sufficiently large (typically larger than 0.1 mm in all dimensions), pure in composition and regular in structure, with no significant internal imperfections such as cracks or twinning.
In the second step, the crystal is placed in an intense beam of X-rays, usually of a single wavelength ("monochromatic X-rays"), producing the regular pattern of reflections. As the crystal is gradually rotated, previous reflections disappear and new ones appear; the intensity of every spot is recorded at every orientation of the crystal. Multiple data sets may have to be collected, with each set covering slightly more than half a full rotation of the crystal and typically containing tens of thousands of reflections.
In the third step, these data are combined computationally with complementary chemical information to produce and refine a model of the arrangement of atoms within the crystal. The final, refined model of the atomic arrangement—now called a "crystal structure"—is usually stored in a public database.
Limitations.
As the crystal's repeating unit, its unit cell, becomes larger and more complex, the atomic-level picture provided by X-ray crystallography becomes less well-resolved (more "fuzzy") for a given number of observed reflections. Two limiting cases of X-ray crystallography—"small-molecule" and "macromolecular" crystallography—are often discerned. "Small-molecule crystallography" typically involves crystals with fewer than 100 atoms in their asymmetric unit; such crystal structures are usually so well resolved that the atoms can be discerned as isolated "blobs" of electron density. By contrast, "macromolecular crystallography" often involves tens of thousands of atoms in the unit cell. Such crystal structures are generally less well-resolved (more "smeared out"); the atoms and chemical bonds appear as tubes of electron density, rather than as isolated atoms. In general, small molecules are also easier to crystallize than macromolecules; however, X-ray crystallography has proven possible even for viruses with hundreds of thousands of atoms. Though normally x-ray crystallography can only be performed if the sample is in crystal form, new research has been done into sampling non-crystalline forms of samples.
Crystallization.
Although crystallography can be used to characterize the disorder in an impure or irregular crystal, crystallography generally requires a pure crystal of high regularity to solve the structure of a complicated arrangement of atoms. Pure, regular crystals can sometimes be obtained from natural or synthetic materials, such as samples of metals, minerals or other macroscopic materials. The regularity of such crystals can sometimes be improved with macromolecular crystal annealing and other methods. However, in many cases, obtaining a diffraction-quality crystal is the chief barrier to solving its atomic-resolution structure.
Small-molecule and macromolecular crystallography differ in the range of possible techniques used to produce diffraction-quality crystals. Small molecules generally have few degrees of conformational freedom, and may be crystallized by a wide range of methods, such as chemical vapor deposition and recrystallization. By contrast, macromolecules generally have many degrees of freedom and their crystallization must be carried out to maintain a stable structure. For example, proteins and larger RNA molecules cannot be crystallized if their tertiary structure has been unfolded; therefore, the range of crystallization conditions is restricted to solution conditions in which such molecules remain folded.
 Protein crystals are almost always grown in solution. The most common approach is to lower the solubility of its component molecules very gradually; if this is done too quickly, the molecules will precipitate from solution, forming a useless dust or amorphous gel on the bottom of the container. Crystal growth in solution is characterized by two steps: "nucleation" of a microscopic crystallite (possibly having only 100 molecules), followed by "growth" of that crystallite, ideally to a diffraction-quality crystal. The solution conditions that favor the first step (nucleation) are not always the same conditions that favor the second step (subsequent growth). The crystallographer's goal is to identify solution conditions that favor the development of a single, large crystal, since larger crystals offer improved resolution of the molecule. Consequently, the solution conditions should "disfavor" the first step (nucleation) but "favor" the second (growth), so that only one large crystal forms per droplet. If nucleation is favored too much, a shower of small crystallites will form in the droplet, rather than one large crystal; if favored too little, no crystal will form whatsoever.
It is extremely difficult to predict good conditions for nucleation or growth of well-ordered crystals. In practice, favorable conditions are identified by "screening"; a very large batch of the molecules is prepared, and a wide variety of crystallization solutions are tested. Hundreds, even thousands, of solution conditions are generally tried before finding the successful one. The various conditions can use one or more physical mechanisms to lower the solubility of the molecule; for example, some may change the pH, some contain salts of the Hofmeister series or chemicals that lower the dielectric constant of the solution, and still others contain large polymers such as polyethylene glycol that drive the molecule out of solution by entropic effects. It is also common to try several temperatures for encouraging crystallization, or to gradually lower the temperature so that the solution becomes supersaturated. These methods require large amounts of the target molecule, as they use high concentration of the molecule(s) to be crystallized. Due to the difficulty in obtaining such large quantities (milligrams) of crystallization-grade protein, robots have been developed that are capable of accurately dispensing crystallization trial drops that are in the order of 100 nanoliters in volume. This means that 10-fold less protein is used per experiment when compared to crystallization trials set up by hand (in the order of 1 microliter).
Several factors are known to inhibit or mar crystallization. The growing crystals are generally held at a constant temperature and protected from shocks or vibrations that might disturb their crystallization. Impurities in the molecules or in the crystallization solutions are often inimical to crystallization. Conformational flexibility in the molecule also tends to make crystallization less likely, due to entropy. Ironically, molecules that tend to self-assemble into regular helices are often unwilling to assemble into crystals . Crystals can be marred by twinning, which can occur when a unit cell can pack equally favorably in multiple orientations; although recent advances in computational methods may allow solving the structure of some twinned crystals. Having failed to crystallize a target molecule, a crystallographer may try again with a slightly modified version of the molecule; even small changes in molecular properties can lead to large differences in crystallization behavior.
Data collection.
Mounting the crystal.
The crystal is mounted for measurements so that it may be held in the X-ray beam and rotated. There are several methods of mounting. In the past, crystals were loaded into glass capillaries with the crystallization solution (the mother liquor). Nowadays, crystals of small molecules are typically attached with oil or glue to a glass fiber or a loop, which is made of nylon or plastic and attached to a solid rod. Protein crystals are scooped up by a loop, then flash-frozen with liquid nitrogen. This freezing reduces the radiation damage of the X-rays, as well as the noise in the Bragg peaks due to thermal motion (the Debye-Waller effect). However, untreated protein crystals often crack if flash-frozen; therefore, they are generally pre-soaked in a cryoprotectant solution before freezing. Unfortunately, this pre-soak may itself cause the crystal to crack, ruining it for crystallography. Generally, successful cryo-conditions are identified by trial and error.
The capillary or loop is mounted on a goniometer, which allows it to be positioned accurately within the X-ray beam and rotated. Since both the crystal and the beam are often very small, the crystal must be centered within the beam to within ~25 micrometers accuracy, which is aided by a camera focused on the crystal. The most common type of goniometer is the "kappa goniometer", which offers three angles of rotation: the ω angle, which rotates about an axis perpendicular to the beam; the κ angle, about an axis at ~50° to the ω axis; and, finally, the φ angle about the loop/capillary axis. When the κ angle is zero, the ω and φ axes are aligned. The κ rotation allows for convenient mounting of the crystal, since the arm in which the crystal is mounted may be swung out towards the crystallographer. The oscillations carried out during data collection (mentioned below) involve the ω axis only. An older type of goniometer is the four-circle goniometer, and its relatives such as the six-circle goniometer.
X-ray Sources.
Rotating Anode.
Small scale can be done on a local X-ray tube source, typically coupled with an image plate detector. These have the advantage of being (relatively) inexpensive and easy to maintain, and allow for quick screening and collection of samples. However, the wavelength light produced is limited by anode material, typically copper. Further, intensity is limited by the power applied and cooling capacity available to avoid melting the anode. In such systems, electrons are boiled off of a cathode and accelerated through a strong electric potential of ~50 kV; having reached a high speed, the electrons collide with a metal plate, emitting "bremsstrahlung" and some strong spectral lines corresponding to the excitation of inner-shell electrons of the metal. The most common metal used is copper, which can be kept cool easily, due to its high thermal conductivity, and which produces strong Kα and Kβ lines. The Kβ line is sometimes suppressed with a thin (~10 µm) nickel foil. The simplest and cheapest variety of sealed X-ray tube has a stationary anode (the Crookes tube) and run with ~2 kW of electron beam power. The more expensive variety has a rotating-anode type source that run with ~14 kW of e-beam power.
X-rays are generally filtered (by use of X-Ray Filters) to a single wavelength (made monochromatic) and collimated to a single direction before they are allowed to strike the crystal. The filtering not only simplifies the data analysis, but also removes radiation that degrades the crystal without contributing useful information. Collimation is done either with a collimator (basically, a long tube) or with a clever arrangement of gently curved mirrors. Mirror systems are preferred for small crystals (under 0.3 mm) or with large unit cells (over 150 Å)
Synchrotron Radiation.
Synchrotron radiation are some of the brightest lights on earth. It is the single most powerful tool available to X-ray crystallographers. It is made of X-ray beams generated in large machines called synchrotrons. These machines accelerate electrically charged particles, often electrons, to nearly the speed of light and confine them in a (roughly) circular loop using magnetic fields.
Synchrotrons are generally national facilities, each with several dedicated beamlines where data is collected without interruption. Synchrotrons were originally designed for use by high-energy physicists studying subatomic particles and cosmic phenomena. The largest component of each synchrotron is its electron storage ring. This ring is actually not a perfect circle, but a many-sided polygon. At each corner of the polygon, or sector, precisely aligned magnets bend the electron stream. As the electrons’ path is bent, they emit bursts of energy in the form of X-rays.
Using synchrotron radiation frequently has specific requirements for X-ray crystallography. The intense ionizing radiation can cause radiation damage to samples, particularly macromolecular crystals. Cryo crystallography protects the sample from radiation damage, by freezing the crystal at liquid nitrogen temperatures (~100 K). However, synchrotron radiation frequently has the advantage of user selectable wavelengths, allowing for anomalous scattering experiments which maximizes anomalous signal. This is critical in experiments such as SAD and MAD.
Free Electron Laser.
Recently, free electron lasers have been developed for use in X-ray crystallography. These are the brightest X-ray sources currently available; with the X-rays coming in femtosecond bursts. The intensity of the source is such that atomic resolution diffraction patterns can be resolved for crystals otherwise too small for collection. However, the intense light source also destroys the sample, requiring multiple crystals to be shot. As each crystal is randomly oriented in the beam, hundreds of thousands of individual diffraction images must be collected in order to get a complete data-set. This method, serial femtosecond crystallography, has been used in solving the structure of a number of protein crystal structures, sometimes noting differences with equivalent structures collected from synchrotron sources.
Recording the reflections.
When a crystal is mounted and exposed to an intense beam of X-rays, it scatters the X-rays into a pattern of spots or "reflections" that can be observed on a screen behind the crystal. A similar pattern may be seen by shining a laser pointer at a compact disc. The relative intensities of these spots provide the information to determine the arrangement of molecules within the crystal in atomic detail. The intensities of these reflections may be recorded with photographic film, an area detector or with a charge-coupled device (CCD) image sensor. The peaks at small angles correspond to low-resolution data, whereas those at high angles represent high-resolution data; thus, an upper limit on the eventual resolution of the structure can be determined from the first few images. Some measures of diffraction quality can be determined at this point, such as the mosaicity of the crystal and its overall disorder, as observed in the peak widths. Some pathologies of the crystal that would render it unfit for solving the structure can also be diagnosed quickly at this point.
One image of spots is insufficient to reconstruct the whole crystal; it represents only a small slice of the full Fourier transform. To collect all the necessary information, the crystal must be rotated step-by-step through 180°, with an image recorded at every step; actually, slightly more than 180° is required to cover reciprocal space, due to the curvature of the Ewald sphere. However, if the crystal has a higher symmetry, a smaller angular range such as 90° or 45° may be recorded. The rotation axis should be changed at least once, to avoid developing a "blind spot" in reciprocal space close to the rotation axis. It is customary to rock the crystal slightly (by 0.5–2°) to catch a broader region of reciprocal space.
Multiple data sets may be necessary for certain phasing methods. For example, MAD phasing requires that the scattering be recorded at least three (and usually four, for redundancy) wavelengths of the incoming X-ray radiation. A single crystal may degrade too much during the collection of one data set, owing to radiation damage; in such cases, data sets on multiple crystals must be taken.
Data analysis.
Crystal symmetry, unit cell, and image scaling.
The recorded series of two-dimensional diffraction patterns, each corresponding to a different crystal orientation, is converted into a three-dimensional model of the electron density; the conversion uses the mathematical technique of Fourier transforms, which is explained below. Each spot corresponds to a different type of variation in the electron density; the crystallographer must determine "which" variation corresponds to "which" spot ("indexing"), the relative strengths of the spots in different images ("merging and scaling") and how the variations should be combined to yield the total electron density ("phasing").
Data processing begins with "indexing" the reflections. This means identifying the dimensions of the unit cell and which image peak corresponds to which position in reciprocal space. A byproduct of indexing is to determine the symmetry of the crystal, i.e., its "space group". Some space groups can be eliminated from the beginning. For example, reflection symmetries cannot be observed in chiral molecules; thus, only 65 space groups of 230 possible are allowed for protein molecules which are almost always chiral. Indexing is generally accomplished using an "autoindexing" routine. Having assigned symmetry, the data is then "integrated". This converts the hundreds of images containing the thousands of reflections into a single file, consisting of (at the very least) records of the Miller index of each reflection, and an intensity for each reflection (at this state the file often also includes error estimates and measures of partiality (what part of a given reflection was recorded on that image)).
A full data set may consist of hundreds of separate images taken at different orientations of the crystal. The first step is to merge and scale these various images, that is, to identify which peaks appear in two or more images ("merging") and to scale the relative images so that they have a consistent intensity scale. Optimizing the intensity scale is critical because the relative intensity of the peaks is the key information from which the structure is determined. The repetitive technique of crystallographic data collection and the often high symmetry of crystalline materials cause the diffractometer to record many symmetry-equivalent reflections multiple times. This allows calculating the symmetry-related R-factor, a reliability index based upon how similar are the measured intensities of symmetry-equivalent reflections, thus assessing the quality of the data.
Initial phasing.
The data collected from a diffraction experiment is a reciprocal space representation of the crystal lattice. The position of each diffraction 'spot' is governed by the size and shape of the unit cell, and the inherent symmetry within the crystal. The intensity of each diffraction 'spot' is recorded, and this intensity is proportional to the square of the "structure factor" amplitude. The structure factor is a complex number containing information relating to both the amplitude and phase of a wave. In order to obtain an interpretable "electron density map", both amplitude and phase must be known (an electron density map allows a crystallographer to build a starting model of the molecule). The phase cannot be directly recorded during a diffraction experiment: this is known as the phase problem. Initial phase estimates can be obtained in a variety of ways:
Model building and phase refinement.
Having obtained initial phases, an initial model can be built. This model can be used to refine the phases, leading to an improved model, and so on. Given a model of some atomic positions, these positions and their respective Debye-Waller factors (or B-factors, accounting for the thermal motion of the atom) can be refined to fit the observed diffraction data, ideally yielding a better set of phases. A new model can then be fit to the new electron density map and a further round of refinement is carried out. This continues until the correlation between the diffraction data and the model is maximized. The agreement is measured by an "R"-factor defined as
where "F" is the structure factor. A similar quality criterion is "R"free, which is calculated from a subset (~10%) of reflections that were not included in the structure refinement. Both "R" factors depend on the resolution of the data. As a rule of thumb, "R"free should be approximately the resolution in angstroms divided by 10; thus, a data-set with 2 Å resolution should yield a final "R"free ~ 0.2. Chemical bonding features such as stereochemistry, hydrogen bonding and distribution of bond lengths and angles are complementary measures of the model quality. Phase bias is a serious problem in such iterative model building. "Omit maps" are a common technique used to check for this.
It may not be possible to observe every atom of the crystallized molecule – it must be remembered that the resulting electron density is an average of all the molecules within the crystal. In some cases, there is too much residual disorder in those atoms, and the resulting electron density for atoms existing in many conformations is smeared to such an extent that it is no longer detectable in the electron density map. Weakly scattering atoms such as hydrogen are routinely invisible. It is also possible for a single atom to appear multiple times in an electron density map, e.g., if a protein sidechain has multiple (<4) allowed conformations. In still other cases, the crystallographer may detect that the covalent structure deduced for the molecule was incorrect, or changed. For example, proteins may be cleaved or undergo post-translational modifications that were not detected prior to the crystallization.
Deposition of the structure.
Once the model of a molecule's structure has been finalized, it is often deposited in a crystallographic database such as the Cambridge Structural Database (for small molecules), the Inorganic Crystal Structure Database (ICSD) (for inorganic compounds) or the Protein Data Bank (for protein structures). Many structures obtained in private commercial ventures to crystallize medicinally relevant proteins are not deposited in public crystallographic databases.
Diffraction theory.
The main goal of X-ray crystallography is to determine the density of electrons "f"(r) throughout the crystal, where r represents the three-dimensional position vector within the crystal. To do this, X-ray scattering is used to collect data about its Fourier transform "F"(q), which is inverted mathematically to obtain the density defined in real space, using the formula
where the integral is taken over all values of q. The three-dimensional real vector q represents a point in reciprocal space, that is, to a particular oscillation in the electron density as one moves in the direction in which q points. The length of q corresponds to 2formula_6 divided by the wavelength of the oscillation. The corresponding formula for a Fourier transform will be used below
where the integral is summed over all possible values of the position vector r within the crystal.
The Fourier transform "F"(q) is generally a complex number, and therefore has a magnitude |"F"(q)| and a phase "φ"(q) related by the equation
The intensities of the reflections observed in X-ray diffraction give us the magnitudes |"F"(q)| but not the phases "φ"(q). To obtain the phases, full sets of reflections are collected with known alterations to the scattering, either by modulating the wavelength past a certain absorption edge or by adding strongly scattering (i.e., electron-dense) metal atoms such as mercury. Combining the magnitudes and phases yields the full Fourier transform "F"(q), which may be inverted to obtain the electron density "f"(r).
Crystals are often idealized as being "perfectly" periodic. In that ideal case, the atoms are positioned on a perfect lattice, the electron density is perfectly periodic, and the Fourier transform "F"(q) is zero except when q belongs to the reciprocal lattice (the so-called "Bragg peaks"). In reality, however, crystals are not perfectly periodic; atoms vibrate about their mean position, and there may be disorder of various types, such as mosaicity, dislocations, various point defects, and heterogeneity in the conformation of crystallized molecules. Therefore, the Bragg peaks have a finite width and there may be significant "diffuse scattering", a continuum of scattered X-rays that fall between the Bragg peaks.
Intuitive understanding by Bragg's law.
An intuitive understanding of X-ray diffraction can be obtained from the Bragg model of diffraction. In this model, a given reflection is associated with a set of evenly spaced sheets running through the crystal, usually passing through the centers of the atoms of the crystal lattice. The orientation of a particular set of sheets is identified by its three Miller indices ("h", "k", "l"), and let their spacing be noted by "d". William Lawrence Bragg proposed a model in which the incoming X-rays are scattered specularly (mirror-like) from each plane; from that assumption, X-rays scattered from adjacent planes will combine constructively (constructive interference) when the angle θ between the plane and the X-ray results in a path-length difference that is an integer multiple "n" of the X-ray wavelength λ.
A reflection is said to be "indexed" when its Miller indices (or, more correctly, its reciprocal lattice vector components) have been identified from the known wavelength and the scattering angle 2θ. Such indexing gives the unit-cell parameters, the lengths and angles of the unit-cell, as well as its space group. Since Bragg's law does not interpret the relative intensities of the reflections, however, it is generally inadequate to solve for the arrangement of atoms within the unit-cell; for that, a Fourier transform method must be carried out.
Scattering as a Fourier transform.
The incoming X-ray beam has a polarization and should be represented as a vector wave; however, for simplicity, let it be represented here as a scalar wave. We also ignore the complication of the time dependence of the wave and just concentrate on the wave's spatial dependence. Plane waves can be represented by a wave vector kin, and so the strength of the incoming wave at time "t=0" is given by
At position r within the sample, let there be a density of scatterers "f"(r); these scatterers should produce a scattered spherical wave of amplitude proportional to the local amplitude of the incoming wave times the number of scatterers in a small volume "dV" about r
where "S" is the proportionality constant.
Let's consider the fraction of scattered waves that leave with an outgoing wave-vector of kout and strike the screen at rscreen. Since no energy is lost (elastic, not inelastic scattering), the wavelengths are the same as are the magnitudes of the wave-vectors |kin|=|kout|. From the time that the photon is scattered at r until it is absorbed at rscreen, the photon undergoes a change in phase
The net radiation arriving at rscreen is the sum of all the scattered waves throughout the crystal
which may be written as a Fourier transform
where q = kout – kin. The measured intensity of the reflection will be square of this amplitude
Friedel and Bijvoet mates.
For every reflection corresponding to a point q in the reciprocal space, there is another reflection of the same intensity at the opposite point -q. This opposite reflection is known as the "Friedel mate" of the original reflection. This symmetry results from the mathematical fact that the density of electrons "f"(r) at a position r is always a real number. As noted above, "f"(r) is the inverse transform of its Fourier transform "F"(q); however, such an inverse transform is a complex number in general. To ensure that "f"(r) is real, the Fourier transform "F"(q) must be such that the Friedel mates "F"(−q) and "F"(q) are complex conjugates of one another. Thus, "F"(−q) has the same magnitude as "F"(q) but they have the opposite phase, i.e., "φ"(q) = −"φ"(q)
The equality of their magnitudes ensures that the Friedel mates have the same intensity |"F"|2. This symmetry allows one to measure the full Fourier transform from only half the reciprocal space, e.g., by rotating the crystal slightly more than 180° instead of a full 360° revolution. In crystals with significant symmetry, even more reflections may have the same intensity (Bijvoet mates); in such cases, even less of the reciprocal space may need to be measured. In favorable cases of high symmetry, sometimes only 90° or even only 45° of data are required to completely explore the reciprocal space.
The Friedel-mate constraint can be derived from the definition of the inverse Fourier transform
Since Euler's formula states that ei"x" = cos("x") + i sin("x"), the inverse Fourier transform can be separated into a sum of a purely real part and a purely imaginary part
The function "f"(r) is real if and only if the second integral "I"sin is zero for all values of r. In turn, this is true if and only if the above constraint is satisfied
since "I"sin = −"I"sin implies that "I"sin=0.
Ewald's sphere.
Each X-ray diffraction image represents only a slice, a spherical slice of reciprocal space, as may be seen by the Ewald sphere construction. Both kout and kin have the same length, due to the elastic scattering, since the wavelength has not changed. Therefore, they may be represented as two radial vectors in a sphere in reciprocal space, which shows the values of q that are sampled in a given diffraction image. Since there is a slight spread in the incoming wavelengths of the incoming X-ray beam, the values of|"F"(q)|can be measured only for q vectors located between the two spheres corresponding to those radii. Therefore, to obtain a full set of Fourier transform data, it is necessary to rotate the crystal through slightly more than 180°, or sometimes less if sufficient symmetry is present. A full 360° rotation is not needed because of a symmetry intrinsic to the Fourier transforms of real functions (such as the electron density), but "slightly more" than 180° is needed to cover all of reciprocal space within a given resolution because of the curvature of the Ewald sphere. In practice, the crystal is rocked by a small amount (0.25-1°) to incorporate reflections near the boundaries of the spherical Ewald shells.
Patterson function.
A well-known result of Fourier transforms is the autocorrelation theorem, which states that the autocorrelation "c"(r) of a function "f"(r)
has a Fourier transform "C"(q) that is the squared magnitude of "F"(q)
Therefore, the autocorrelation function "c"(r) of the electron density (also known as the "Patterson function") can be computed directly from the reflection intensities, without computing the phases. In principle, this could be used to determine the crystal structure directly; however, it is difficult to realize in practice. The autocorrelation function corresponds to the distribution of vectors between atoms in the crystal; thus, a crystal of "N" atoms in its unit cell may have "N(N-1)" peaks in its Patterson function. Given the inevitable errors in measuring the intensities, and the mathematical difficulties of reconstructing atomic positions from the interatomic vectors, this technique is rarely used to solve structures, except for the simplest crystals.
Advantages of a crystal.
In principle, an atomic structure could be determined from applying X-ray scattering to non-crystalline samples, even to a single molecule. However, crystals offer a much stronger signal due to their periodicity. A crystalline sample is by definition periodic; a crystal is composed of many unit cells repeated indefinitely in three independent directions. Such periodic systems have a Fourier transform that is concentrated at periodically repeating points in reciprocal space known as "Bragg peaks"; the Bragg peaks correspond to the reflection spots observed in the diffraction image. Since the amplitude at these reflections grows linearly with the number "N" of scatterers, the observed "intensity" of these spots should grow quadratically, like "N"2. In other words, using a crystal concentrates the weak scattering of the individual unit cells into a much more powerful, coherent reflection that can be observed above the noise. This is an example of constructive interference.
In a liquid, powder or amorphous sample, molecules within that sample are in random orientations. Such samples have a continuous Fourier spectrum that uniformly spreads its amplitude thereby reducing the measured signal intensity, as is observed in SAXS. More importantly, the orientational information is lost. Although theoretically possible, it is experimentally difficult to obtain atomic-resolution structures of complicated, asymmetric molecules from such rotationally averaged data. An intermediate case is fiber diffraction in which the subunits are arranged periodically in at least one dimension.

</doc>
<doc id="34153" url="http://en.wikipedia.org/wiki?curid=34153" title="DAX">
DAX

The DAX ("Deutscher Aktienindex" (German stock index)) is a blue chip stock market index consisting of the 30 major German companies trading on the Frankfurt Stock Exchange. Prices are taken from the electronic Xetra trading system. According to Deutsche Börse, the operator of Xetra, DAX measures the performance of the Prime Standard’s 30 largest German companies in terms of order book volume and market capitalization. It is the equivalent of the FT 30 and the Dow Jones Industrial Average, and because of its small selection it does not necessarily represent the vitality of the economy as whole.
The L-DAX Index is an indicator of the German benchmark DAX index's performance after the Xetra electronic-trading system closes based on the floor trading at the Frankfurt Stock Exchange. The L-DAX Index basis is the "floor" trade ("Parketthandel") at the Frankfurt stock exchange; it is computed daily between 09:00 and 17:45 Hours CET. The L/E-DAX index (Late/Early DAX) is calculated from 17:45 to 20:00 CET and from 08:00 to 09:00 CET. The Eurex, a European electronic futures and options exchange based in Zürich, Switzerland with a subsidiary in Frankfurt, Germany, offers options (ODAX) and Futures (FDAX) on the DAX from 08:00 to 22:00 CET.
The Base date for the DAX is 30 December 1987 and it was started from a base value of 1,000. The Xetra system calculates the index after every 1 second since 1 January 2006.
Versions.
The DAX has two versions, called performance index and price index, depending on whether dividends are counted. The performance index is the more commonly quoted, however the price index is more similar to commonly quoted indexes in other countries.
Price history.
On March 16, 2015, the performance index first closed above 12,000. On April 10, 2015, the price index first closed above its closing high from 2000.
Record values.
 Intraday high
 10 April 2015
 12,390.75
Components.
A list of the current DAX companies, as of the quarterly review effective on 24 September 2012.
Former components of DAX.
Following table lists the former components of DAX and the ones replaced them.

</doc>
<doc id="34154" url="http://en.wikipedia.org/wiki?curid=34154" title="PARC (company)">
PARC (company)

PARC (Palo Alto Research Center Incorporated), formerly Xerox PARC, is a research and development company in Palo Alto, California, with a distinguished reputation for its contributions to information technology and hardware systems.
Founded in 1970 as a division of Xerox Corporation, PARC has been responsible for such developments as laser printing, Ethernet, the modern personal computer, graphical user interface (GUI) and desktop paradigm, object-oriented programming, ubiquitous computing, amorphous silicon (a-Si) applications, and advancing very-large-scale-integration (VLSI) for semiconductors.
Xerox formed Palo Alto Research Center Incorporated as a wholly owned subsidiary in 2002.
History.
In 1969, Chief Scientist at Xerox Jack Goldman approached George Pake, a physicist specializing in nuclear magnetic resonance and provost of Washington University in St. Louis, about starting a second research center for the company.
Pake selected Palo Alto, California, as the site of what was to become known as PARC. While the 3,000 mile buffer between it and Xerox headquarters in Rochester, New York afforded scientists at the new lab great freedom to undertake their work, the distance also served as an impediment in persuading management of the promise of some of their greatest achievements.
PARC's West Coast location proved to be advantageous in the mid-1970s, when the lab was able to hire many employees of the nearby SRI Augmentation Research Center as that facility's funding from DARPA, NASA, and the U.S. Air Force began to diminish. Being situated on Stanford Research Park land leased from Stanford University
allowed Stanford graduate students to be involved in PARC research projects, and PARC scientists to collaborate with academic seminars and projects.
Much of PARC's early success in the computer field was under the leadership of its Computer Science Laboratory manager Bob Taylor, who guided the lab as associate manager from 1970 to 1977 and as manager from 1977 to 1983.
PARC today.
After three decades as a division of Xerox, PARC was transformed in 2002 into an independent, wholly owned subsidiary company dedicated to developing and maturing advances in science and business concepts with the support of commercial partners and clients.
Xerox remains the company's largest customer (50%), but PARC has numerous other corporate and venture clients in different fields of use than Xerox including: VMware, Fujitsu, Dai Nippon Printing (DNP), Samsung, NEC, SolFocus, Powerset, Thin Film Electronics ASA and many more.
PARC currently conducts research into "clean technology", user interface design, sensemaking, ubiquitous computing and context-aware systems, large-area electronics, digital manufacturing, and model-based control and optimization in embedded, intelligent systems.
Accomplishments.
Xerox PARC has been the inventor and incubator of many elements of modern computing in the contemporary office work place:
The Alto.
Most of these developments were included in the Alto, which added the now familiar SRI-developed mouse, unifying into a single model most aspects of now-standard personal computer use. The integration of Ethernet prompted the development of the PARC Universal Packet architecture, much like today's Internet.
The GUI.
Xerox has been heavily criticized (particularly by business historians) for failing to properly commercialize and profitably exploit PARC's innovations. A favorite example is the GUI, initially developed at PARC for the Alto and then commercialized as the Xerox Star by the Xerox Systems Development Department. Although very significant in terms of its influence on future system design, it is deemed a failure because it only sold approximately 25,000 units. A small group from PARC led by David Liddle and Charles Irby formed Metaphor Computer Systems. They extended the Star desktop concept into an animated graphic and communicating office-automation model and sold the company to IBM.
Distinguished researchers.
Among PARC's distinguished researchers were three Turing Award winners: Butler W. Lampson (1992), Alan Kay (2003), and Charles P. Thacker (2009). The ACM Software System Award recognized the Alto system in 1984, Smalltalk in 1987, InterLisp in 1992, and Remote Procedure Call in 1994. Lampson, Kay, Bob Taylor, and Charles P. Thacker received the National Academy of Engineering's prestigious Charles Stark Draper Prize in 2004 for their work on the Alto.
Legacy.
PARC's developments in information technology served for a long time as standards for much of the computing industry. Many advances were not equalled or surpassed for two decades, enormous timespans in the fast-paced high-tech world.
While there is some truth that Xerox management failed to see the potential of many of PARC's inventions, this was mostly centered to the computing research, a relatively small part of PARC's operations. A number of GUI engineers left to join Apple Computer. Technologies pioneered by its materials scientists such as LCD, optical disc innovations, and laser printing were actively and successfully introduced by Xerox to the business and consumer marketplaces.
Work at PARC since the early 1980s includes advances in ubiquitous computing, aspect-oriented programming, and IPv6.

</doc>
<doc id="34155" url="http://en.wikipedia.org/wiki?curid=34155" title="Xenophon">
Xenophon

Xenophon (; Greek: Ξενοφῶν ], "Xenophōn"; c. 430 – 354 BC), son of Gryllus, of the deme Erchia of Athens, also known as Xenophon of Athens, was a Greek historian, soldier, mercenary, and student of Socrates. While not referred to as a philosopher by his contemporaries, his status as such is now a topic of debate. He is known for writing about the history of his own times, the late 5th and early 4th centuries BC, especially for his account of the final years of the Peloponnesian War. His "Hellenica", which recounts these times, is considered to be the continuation of Thucydides’ "History of the Peloponnesian War". His youthful participation in the failed campaign of Cyrus the Younger to claim the Persian throne inspired him to write his most famous work, "Anabasis".
Despite his birth-association with Athens, Xenophon affiliated himself with Sparta for most of his life. His pro-oligarchic views, service under Spartan generals in the Persian campaign and beyond, as well as his friendship with King Agesilaus II endeared Xenophon to the Spartans, and them to him. A number of his writings display his pro-Spartan bias and admiration, especially "Agesilaus" and "Constitution of Sparta".
Other than Plato, Xenophon is the foremost authority on Socrates, having learned under the great philosopher while a young man. He greatly admired his teacher, and well after Socrates’ death in 399 Xenophon wrote several Socratic dialogues, including an "Apology" concerning the events of his trial and death.
Xenophon’s works cover a wide range of genres and are written in very uncomplicated Attic Greek. Xenophon’s works are among the first that many students of Ancient Greek translate on account of the straightforward and succinct nature of his prose. This sentiment was apparent even in ancient times, as Diogenes Laertius states in his "Lives of Eminent Philosophers" (2.6) that Xenophon was sometimes known as the "Attic Muse" for the sweetness of his diction.
Life.
Early years.
Little is known about Xenophon other than what he wrote about himself. Xenophon was born around 430 BC near the city of Athens to a wealthy equestrian family. The years of his youth are not well attested before 401 BC. It was in this year that Xenophon was convinced by his Boeotian friend Proxenus ("Anabasis" 3.1.9) to participate in the expedition led by Cyrus the Younger against his older brother, King Artaxerxes II of Persia.
"Anabasis".
Expedition with Cyrus.
Written years after these events, Xenophon's book "Anabasis" (Greek: ἀνάβασις, literally "going up") is his record of the entire expedition of Cyrus against the Persians and the Greek mercenaries’ journey home. Xenophon writes that he had asked the veteran Socrates for advice on whether to go with Cyrus, and that Socrates referred him to the divinely inspired Delphic oracle. Xenophon's query to the oracle, however, was not whether or not to accept Cyrus' invitation, but "to which of the gods he must pray and do sacrifice, so that he might best accomplish his intended journey and return in safety, with good fortune". The oracle answered his question and told him to which gods to pray and sacrifice. When Xenophon returned to Athens and told Socrates of the oracle's advice, Socrates chastised him for asking so disingenuous a question ("Anabasis" 3.1.5–7).
Under the pretext of fighting Tissaphernes, the Persian satrap of Ionia, Cyrus assembled a massive army composed of native Persian soldiers, but also a large number of Greeks. Prior to waging war against Artaxerxes, Cyrus proposed that the enemy was the Pisidians, and so the Greeks were unaware that they were to battle against the larger army of King Artaxerxes II ("Anabasis" 1.1.8–11). At Tarsus the soldiers became aware of Cyrus's plans to depose the king, and as a result, refused to continue ("Anabasis" 1.3.1). However, Clearchus, a Spartan general, convinced the Greeks to continue with the expedition. The army of Cyrus met the army of Artaxerxes II in the Battle of Cunaxa. Despite effective fighting by the Greeks, Cyrus was killed in the battle ("Anabasis" 1.8.27–1.9.1). Shortly thereafter, Clearchus was invited to a peace conference, where, alongside four other generals and many captains, he was betrayed and executed ("Anabasis" 2.5.31–32).
Return.
The mercenaries, known as the Ten Thousand, found themselves without leadership far from the sea, deep in hostile territory near the heart of Mesopotamia. They elected new leaders, including Xenophon himself, and fought their way north along the Tigris through hostile Persians and Medes to Trapezus on the coast of the Black Sea ("Anabasis" 4.8.22). They then made their way westward back to Greece via Chrysopolis ("Anabasis" 6.3.16). Once there, they helped Seuthes II make himself king of Thrace, before being recruited into the army of the Spartan general Thibron. The Spartans were at war with Tissaphernes and Pharnabazus, Persian satraps in Anatolia, probably on account of the aforementioned treacherous slaughter of their general Clearchus. Xenophon’s military activity with these Spartans marks the final episodes of the "Anabasis" (Books 6–7).
Exile and death.
Upon his return to Greece proper, Xenophon continued to associate with the Spartans, even so far as to fight under the Spartan king Agesilaus II against his native Athens at Coronea in 394 BC. On account of this he was exiled from Athens. However, there may have been contributory causes, such as his support for Socrates, as well as the fact that he had taken service with the Persians. The Spartans gave him property at Scillus, near Olympia in Elis, where he likely composed the Anabasis. However, because his son Gryllus fought and died for Athens at the Battle of Mantinea while Xenophon was still alive, Xenophon's banishment may have been revoked. Nevertheless, after the Battle of Leuktra in 371 and the end of Spartan hegemony, Xenophon moved to Corinth or Athens where he died. He died around 355, but the exact date is uncertain; historians know only that he survived his patron Agesilaus II, for whom he wrote an encomium which shared the Spartan king’s name.
Xenophon's politics.
Xenophon has long been associated with the opposition of democracy. Although Xenophon seems to prefer oligarchy, or at least the aristocracy, especially in light of his associations with Sparta, none of his works explicitly attack democracy, unless his account of democratic proceedings in the Anabasis be interpreted as anti-democracy when deliberations are intimidated by cries of "pelt" if a speaker says something others disagree with. Some scholars go so far as to say his views aligned with those of the democracy in his time. However, certain works of Xenophon, in particular the Cyropaedia, appear to display his pro-oligarchic politics. This historical-fiction serves as a forum for Xenophon to subtly display his political inclinations.
"Cyropaedia".
Relations between Medes and Persians in the "Cyropaedia".
It is generally recognized that the purpose of Xenophon in writing the "Cyropaedia" was to present his political and moral philosophy. To this end, he chose a historical figure, Cyrus, and endowed him with the qualities that Xenophon thought should be possessed by an ideal ruler. The question may be asked whether it was not just the figure of Cyrus, but also significant historical events in his life, that formed the framework for Xenophon’s portrait. The contemporary consensus answers this in the negative, choosing to follow instead the outline of Cyrus’s career as given in the "Histories" of Herodotus. But Steven Hirsch writes, “Yet there are occasions when it can be confirmed from Oriental evidence that Xenophon is correct where Herodotus is wrong or lacks information. A case in point involves the ancestry of Cyrus.” Herodotus contradicts Xenophon at several other points, most notably in the matter of Cyrus’s relationship with the Median Kingdom. Herodotus says that Cyrus led a rebellion against his maternal grandfather, Astyages king of Media, and defeated him, thereafter (improbably) keeping Astyages in his court for the remainder of his life ("Histories" 1.130). The Medes were thus “reduced to subjection” (1.130) and became “slaves” (1.129) to the Persians 20 years before the capture of Babylon in 539 B.C.
The "Cyropaedia" relates instead that Astyages died and was succeeded by his son Cyaxares II, the maternal uncle of Cyrus (1.5.2). In the initial campaign against the Lydians, Babylonians and their allies, the Medians were led by Cyaxares and the Persians by Cyrus, who was crown prince of the Persians, since his father was still alive (4.5.17). Xenophon relates that at this time the Medes were the strongest of the kingdoms that opposed the Babylonians (1.5.2). There is an echo of this statement, verifying Xenophon and contradicting Herodotus, in the Harran Stele, a document from the court of Nabonidus. In the entry for year 14 or 15 of his reign (542-540 B.C.), Nabonidus speaks of his enemies as the kings of Egypt, the Medes, and the Arabs. There is no mention of the Persians,
although according to Herodotus and the current consensus the Medians had been made “slaves” of the Persians several years previously. It does not seem that Nabonidus would be completely misled about who his enemies were, or who was really in control over the Medes and Persians just one to three years before his kingdom fell to their armies.
Other archaeological evidence supporting Xenophon’s picture of a confederation of Medes and Persians, rather than a subjugation of the Medes by the Persians, comes from the bas-reliefs in the stairway at Persepolis. These show no distinction in official rank or status between the Persian and Median nobility. Although Olmstead followed the consensus view that Cyrus subjugated the Medes, he nevertheless wrote, “Medes were honored equally with Persians; they were employed in high office and were chosen to lead Persian armies.” A more extensive list of considerations related to the credibility of the "Cyropaedia’s" picture of the relationship between the Medes and Persians is found on the "Cyropaedia" page.
Both Herodotus (1.123,214) and Xenophon (1.5.1,2,4, 8.5.20) present Cyrus as about 40 years old when his forces captured Babylon. In the Nabonidus Chronicle, there is mention of the death of the wife of the king (name not given) within a month after the capture of Babylon. It has been conjectured that this was Cyrus’s first wife, which lends credibility to the "Cyropaedia’s" statement (8.5.19) that Cyaxares II gave his daughter in marriage to Cyrus soon (but not immediately) after the fall of the city, with the kingdom of Media as her dowry. When Cyaxares died about two years later the Median kingdom passed peaceably to Cyrus, so that this would be the true beginning of the Medo-Persian Empire under just one monarch.
Persians as centaurs.
The "Cyropaedia" as a whole lavishes a great deal of praise on the first Persian emperor Cyrus the Great on account of his virtue and leadership quality, and it was through his greatness that the Persian Empire held together. Thus this book is normally read as a positive treatise about Cyrus. However, following the lead of Leo Strauss, David Johnson suggests that there is a subtle but strong layer to the book in which Xenophon conveys criticism of not only the Persians but the Spartans and Athenians as well.
In section 4.3 of the "Cyropaedia" Cyrus makes clear his desire to institute cavalry. He even goes so far to say that he desires that no Persian "" (“noble and good man” literally, or simply “noble”) ever be seen on foot but always on a horse, so much so that the Persians may actually seem to be centaurs (4.3.22–23). Centaurs were often thought of as creatures of ill repute, which makes even Cyrus’ own advisors wary of the label. His minister Chrysantas admires the centaurs for their dual nature, but also warns that the dual nature does not allow centaurs to fully enjoy or act as either one of their aspects in full (4.3.19–20).
In labeling Persians as centaurs through the mouth of Cyrus, Xenophon plays upon the popular post-Persian-war propagandistic paradigm of using mythological imagery to represent the Greco-Persian conflict. Examples of this include the wedding of the Lapiths, giantomachy, Trojan War, and Amazonomachy on the Parthenon frieze. Johnson reads even more deeply into the centaur label. He believes that the unstable dichotomy of man and horse found in a centaur is indicative of the unstable and unnatural alliance of Persian and Mede formulated by Cyrus. The Persian hardiness and austerity is combined with the luxuriousness of the Medes, two qualities that cannot coexist. He cites the regression of the Persians directly after the death of Cyrus as a result of this instability, a union made possible only through the impeccable character of Cyrus. In a further analysis of the centaur model, Cyrus is likened to a centaur such as Chiron, a noble example from an ignoble race. Thus this entire paradigm seems to be a jab at the Persians and an indication of Xenophon’s general distaste for the Persians.
Against empire/monarchy.
The strength of Cyrus in holding the empire together is praiseworthy according to Xenophon. However, the empire began to decline upon the death of Cyrus. By this example Xenophon sought to show that empires lacked stability and could only be maintained by a person of remarkable prowess, such as Cyrus. Cyrus is idealized greatly in the narrative. Xenophon displays Cyrus as a cold, passionless man. This is not to say that he was not a good ruler, but he is depicted as surreal and not subject to the foibles of other men. By showing that only someone who is almost beyond human could conduct such an enterprise as empire, Xenophon indirectly censures imperial design. Thus he also reflects on the state of his own reality in an even more indirect fashion, using the example of the Persians to decry the attempts at empire made by Athens and Sparta. Although partially graced with hindsight, having written the "Cyropaedia" after the downfall of Athens in the Peloponnesian War, this work criticizes the Greek attempts at empire and “monarchy,” dooming them to failure.
Against democracy.
Another passage that Johnson cites as criticism of monarchy and empire concerns the devaluation of the "homotimoi". The manner in which this occurs seems also to be a subtle yet poignant jab at democracy. Homotimoi were highly and thoroughly educated and thus became the core of the soldiery as heavy infantry. As the name "homotimoi" (“equal,” or “same honors” i.e. “peers”) suggests, their small band (1000 when Cyrus fought the Assyrians) shared equally in the spoils of war. However, in the face of overwhelming numbers in a campaign against the Assyrians, Cyrus armed the commoners with similar arms instead of their normal light ranged armament ("Cyropaedia" 2.1.9). Argument ensued as to how the spoils would now be split, and Cyrus enforced a meritocracy. Many "homotimoi" found this unfair because their military training was no better than the commoners, only their education, and hand-to-hand combat was less a matter of skill than strength and bravery. As Johnson asserts, this passage decries imperial meritocracy and corruption, for the "homotimoi" now had to sychophantize to the emperor for positions and honors; from this point they were referred to as "entimoi", no longer of the “same honors” but having to be “in” to get the honor. On the other hand, the passage seems to be critical of democracy, or at least sympathetic to aristocrats within democracy, for the "homotimoi" (aristocracy/oligarchs) are devalued upon the empowerment of the commoners ("demos"). Although empire emerges in this case, this is also a sequence of events associated with democracy. Through his dual critique of empire and democracy, Xenophon subtly relates his support of oligarchy.
"Constitution of the Spartans".
The Spartans wrote nothing about themselves, or if they did it is lost. Therefore what we know about them comes exclusively from outsiders, such as Xenophon. Xenophon’s affinity for the Spartans is clear in the "", as well as his penchant for oligarchy. The opening line reads:
“It occurred to me one day that Sparta, though among the most thinly populated of states, was evidently the most powerful and most celebrated city in Greece; and I fell to wondering how this could have happened. But when I considered the institutions of the Spartans, I wondered no longer.”
Xenophon goes on to describe in detail the main aspects of the Lacedaemonian state, handing to us the most comprehensive extant analysis of the institutions of Sparta.
Old Oligarch.
A short treatise on the "Constitution of Athens" exists that was once thought to be by Xenophon, but which was probably written when Xenophon was about five years old. The author, often called in English the "Old Oligarch" or Pseudo-Xenophon, detests the democracy of Athens and the poorer classes, but he argues that the Periclean institutions are well designed for their deplorable purposes. Although the real Xenophon seems to prefer oligarchy over democracy, none of his works so ardently decry democracy as does the Constitution of the Athenians. However, this treatise makes evident that anti-democratic sentiments were extant in Athens in the late 5th century B.C. and were only increased after its shortcomings were exploited and made apparent during the Peloponnesian War.
Socratic works and dialogues.
Xenophon’s variegated corpus includes a significant selection of Socratic dialogues. His completely preserved Socratic writings, along with the dialogues of Plato, are the only surviving representatives of the genre of "Sokratikoi logoi" (Socratic dialogues). These works include his "Apology, Memorabilia, Symposium," and "Oeconomicus". The "Symposium" outlines the character of Socrates as he and his companions discuss what attribute they take pride in. In "Oeconomicus" Socrates explains how to manage the household well. Both the "Apology" and "Memorabilia" serve to defend Socrates’ character and teachings. The former is set during the trial of Socrates, essentially defending Socrates’ loss and death, while the latter as a general defense of Socrates, explaining his moral principles and that he was not a corrupter of the youth.
Relationship with Socrates.
Xenophon was a student of Socrates, and their personal relationship is evident through a direct conversation between the two in Xenophon’s "Anabasis". His admiration for his teacher is clear in writings such as "Symposium", "Apology", and "Memorabilia". Xenophon was off on his Persian campaign when Socrates died, so he was not present for the trial of his old master. Nevertheless, much of his Socratic writing, especially "Apology", concerns that very trial and the defense Socrates put forward.
In his Lives of Eminent Philosophers, the Greek biographer Diogenes Laertius reports how Xenophon came to be associated with Socrates. “They say that Socrates met him in a narrow lane, and put his stick across it and prevented him from passing by, asking him where all kinds of necessary things were sold. And when he had answered him, he asked him again where men were made good and virtuous. And as he did not know, he said, ‘Follow me, then, and learn.’ And from this time forth, Xenophon became a follower of Socrates.”
Socrates: Xenophon vs. Plato.
Both Plato and Xenophon wrote an "Apology" concerning the death of Socrates. The two writers seem more concerned about answering questions that arose after the trial than about the actual charges. In particular, Xenophon and Plato are concerned with the failures of Socrates to defend himself. The Socrates that Xenophon portrayed was different from Plato’s in multiple respects. Xenophon asserts that Socrates dealt with his prosecution in an exceedingly arrogant manner, or at least was perceived to have spoken arrogantly. Conversely, while not omitting it completely, Plato worked to temper that arrogance in his own "Apology". Xenophon framed Socrates’ defense, which both men admit was not prepared at all, not as failure to effectively argue his side, but as striving for death even in the light of unconvincing charges. As Danzig interprets it, convincing the jury to condemn him even on unconvincing charges would be a rhetorical challenge worthy of the great persuader. Xenophon uses this interpretation as justification for Socrates’ arrogant stance and conventional failure. By contrast, Plato does not go so far as to claim that Socrates actually desired death, but seems to argue that Socrates was attempting to demonstrate a higher moral standard and teach a lesson, although his defense failed by conventional standards. This places Socrates in a higher moral position than his prosecutors, a typical Platonic example of absolving “Socrates from blame in every conceivable way.”
Historical reality.
Although Xenophon claims to have been present at the "Symposium", this is impossible as he was only a young boy at the date which he proposes it occurred. And again, Xenophon was not present at the trial of Socrates, having been on campaign in Anatolia and Persia. Thus he puts into the latter’s mouth what he would have thought him to say. It seems that Xenophon wrote his "Apology" and "Memorabilia" as defenses of his former teacher, not to explain Socrates' relationship to the actual charges incurred.
Modern reception.
Xenophon's standing as a political philosopher has been defended in recent times by Leo Strauss, who devoted a considerable part of his philosophic analysis to the works of Xenophon, returning to the high judgment of Xenophon as a thinker expressed by Shaftesbury, Winckelmann, Machiavelli and John Adams.
Xenophon’s lessons on leadership have been reconsidered for their modern-day value. Jennifer O’Flannery holds that "discussions of leadership and civic virtue should include the work of Xenophon...on public education for public service." The "Cyropaedia", in outlining Cyrus as an ideal leader having mastered the qualities of “education, equality, consensus, justice and service to state,” is the work that she suggests be used as a guide or example for those striving to be leaders (see Mirrors for Princes). The linking of moral code and education is an especially pertinent quality subscribed to Cyrus that O’Flannery believes is in line with modern perceptions of leadership.
List of works.
Xenophon’s entire corpus is extant. The following list of his works exhibits the extensive breadth of genres in which Xenophon wrote.
Short treatises.
These works were probably written by Xenophon when he was living in Scillus. His days were likely spent in relative leisure here, and he wrote these treatises about the sorts of activities he spent time on.

</doc>
<doc id="34159" url="http://en.wikipedia.org/wiki?curid=34159" title="XSL">
XSL

In computing, the term Extensible Stylesheet Language (XSL) is used to refer to a family of 
languages used to transform and render XML documents.
Historically, the XSL Working Group in W3C produced a draft specification under the name XSL, which eventually split into three parts:
As a result, the term XSL is now used with a number of different meanings:
This article is concerned with the various usages of the term XSL: for details of the various languages embraced by the term, see the relevant article.
History.
XSL began as an attempt to bring the functionality of DSSSL, particularly in the area of print and high-end typesetting, to XML.
In response to a submission from Arbortext, Inso, and Microsoft, a W3C working group on "XSL" started operating in December 1997, with Sharon Adler and Steve Zilles as co-chairs, with James Clark acting as editor (and unofficially as chief designer), and Chris Lilley as the W3C staff contact. The group released a first public Working Draft on 18 August 1998. XSLT and XPath became W3C Recommendations on 16 November 1999 and XSL-FO reached Recommendation status on 15 October 2001.
The XSL family.
XSL Transformations.
XSL Transformations (XSLT) currently[ [update]] has many implementations available. Several web browsers, including Internet Explorer (using the MSXML engine), Opera (native engine) and Safari, all support transformation of XML to HTML (or other languages) through XSLT. Other notable implementations include Saxon and Xalan.
Support in Firefox, Mozilla, and Netscape (all using the TransforMiiX engine) is incomplete. Support of disable-output-escaping does not work which is why HTML Fragments are not rendered properly. This bug is known since 2001 https://bugzilla.mozilla.org/show_bug.cgi?id=98168 .
XSL Formatting Objects.
Support for XSL Formatting Objects is available in a number of products:
These products support output in a number of file formats, to varying degrees:
XPath.
XML Path Language (XPath), itself part of the XSL family, functions within XSLT as a means of navigating an XML document.
Another W3C project, XQuery, aims to provide similar capabilities for querying XML documents using XPath.

</doc>
<doc id="34160" url="http://en.wikipedia.org/wiki?curid=34160" title="Xingu River">
Xingu River

The Xingu River (Portuguese: "Rio Xingu", ], ) is a 1640 km river in north Brazil. It is a southeast tributary of the Amazon River.
Description and history.
The first Indian Park in Brazil was created in the river basin by the Brazilian government in the early 1960s. This park marks the first indigenous territory recognized by the Brazilian government and it was the world's largest indigenous reserve on the date of its creation. Currently, fourteen tribes live on the reserve surviving with natural resources and extracting from the river most of what they need for food and water.
The Brazilian government is building the Belo Monte Dam, which will be the world's third-largest hydroelectric dam, on the Lower Xingu. Construction of this dam is under legal challenge by environment and indigenous groups, who assert the dam would have negative environmental and social impacts along with reducing the flow by up to 80% along a 100 km stretch known as the "Big Bend" (Volta Grande). More than 450 fish species have been documented in the Xingu River Basin and it is estimated that the total is around 600 fish species, including many endemics. In the last 5 years alone, 21 new fish species have been described from the river. Many species are seriously threatened by the dam, including at least 26 fish species that are entirely restricted to the lower Xingu.
In the Upper Xingu region was a highly self-organized pre-Columbian anthropogenic landscape, including deposits of fertile agricultural terra preta, black soil in Portuguese, with a network of roads and polities each of which covered about 250 square kilometers.
Near the source of Xingu River is Culuene River, a 600 km tributary.

</doc>
<doc id="34163" url="http://en.wikipedia.org/wiki?curid=34163" title="Xe">
Xe

 
 
 
Xe or XE may refer to:

</doc>
<doc id="34164" url="http://en.wikipedia.org/wiki?curid=34164" title="Xerox">
Xerox

Xerox Corporation is an American multinational document management corporation that produces and sells a range of color and black-and-white printers, multifunction systems, photocopiers, digital production printing presses, and related consulting services and supplies. Xerox is headquartered in Norwalk, Connecticut (moved from Stamford, Connecticut in October 2007), though its largest population of employees is based around Rochester, New York, the area in which the company was founded. On September 28, 2009, Xerox announced the intended acquisition of Affiliated Computer Services for $6.4 billion. The deal closed on February 8, 2010. As a large developed company, it is consistently placed in the list of Fortune 500 companies.
Researchers at Xerox and its Palo Alto Research Center invented several important elements of personal computing, such as the desktop metaphor GUI, the computer mouse and desktop computing. These features were frowned upon by the then board of directors, who ordered the Xerox engineers to share them with Apple technicians. The features were taken on by Apple and, later, Microsoft. Partly thanks to these features, these two firms would then go on to duopolize the personal computing world.
History.
Xerox was founded in 1906 in Rochester as The Haloid Photographic Company, which originally manufactured photographic paper and equipment.
In 1938 Chester Carlson, a physicist working independently, invented a process for printing images using an electrically charged drum and dry powder "toner".
Joseph C. Wilson, credited as the "founder of Xerox", took over Haloid from his father. He saw the promise of Carlson's invention and, in 1946, signed an agreement to develop it as a commercial product. Wilson remained as President/CEO of Xerox until 1967 and served as Chairman until his death in 1971.
Looking for a term to differentiate its new system, Haloid coined the term Xerography from two Greek roots meaning "dry writing".
Haloid subsequently changed its name to Haloid Xerox in 1958 and then Xerox Corporation in 1961.
Before releasing the 914, Xerox tested the market by introducing a developed version of the prototype hand-operated equipment known as the Flat-plate 1385. The 1385 was not actually a viable copier because of its speed of operation. As a consequence, it was sold as a platemaker to the offset lithography market, perhaps most notably as a platemaker for the Addressograph-Multigraph Multilith 1250 and related sheet-fed offset printing presses. It was little more than a high quality, commercially available plate camera mounted as a horizontal rostrum camera, complete with photo-flood lighting and timer. The glass film/plate had been replaced with a selenium-coated aluminum plate. Clever electrics turned this into a quick developing and reusable substitute for film. A skilled user could produce fast, paper and metal printing plates of a higher quality than almost any other method. Having started as a supplier to the offset lithography duplicating industry, Xerox now set its sights on capturing some of offset's market share.
The 1385 was followed by the first automatic xerographic printer, the Copyflo, in 1955. The Copyflo was a large microfilm printer which could produce positive prints on roll paper from any type of microfilm negative. Following the Copyflo, the process was scaled down to produce the 1824 microfilm printer. At about half the size and weight, this still sizable machine printed onto hand-fed, cut-sheet paper which was pulled through the process by one of two gripper bars. A scaled-down version of this gripper feed system was to become the basis for the 813 desktop copier.
The Xerox 914.
The company came to prominence in 1959 with the introduction of the Xerox 914, "the most successful single product of all time." The 914, the first plain paper photocopier was developed by Carlson and John H. Dessauer; it was so popular that by the end of 1961 Xerox had almost $60 million in revenue. Revenues leaped to over $500 million by 1965.
1960s.
The company expanded substantially throughout the 1960s, making millionaires of some long-suffering investors who had nursed the company through the slow research and development phase of the product. In 1960, a xerography research facility called the Wilson Center for Research and Technology was opened in Webster, New York. In 1961, the company changed its name to Xerox Corporation. Xerox common stock (XRX) was listed on the New York Stock Exchange in 1961 and on the Chicago Stock Exchange in 1990.
In 1963 Xerox introduced the Xerox 813, the first desktop plain-paper copier, realizing Carlson's vision of a copier that could fit on anyone's office desk. Ten years later in 1973, a basic, analogue, color copier, based on the 914, followed. The 914 itself was gradually sped up to become the 420 and 720. The 813 was similarly developed into the 330 and 660 products and, eventually, also the 740 desktop microfiche printer.
Xerox's first foray into duplicating, as distinct from copying, was with the Xerox 2400, introduced in 1966. "2400" denoted the number of prints produced in an hour. Although still some way short of offset speeds, this machine introduced the industry's first Automatic Document Feeder, Slitter/Perforator, and Collator (sorter). This product was soon sped up by fifty percent to become the Xerox 3600 Duplicator.
Meanwhile, a small lab team was borrowing 914 copiers and modifying them. The lab was working on a project called the "Long Distance Xerography" (LDX) project. The aim was to be able to connect two copiers together via the public telephone network, such that a document scanned on one machine would be copied out on the other. The LDX system was introduced in 1964. Many years later this work came to fruition in the Xerox Telecopiers, seminal to today's fax machines. The fax operation in today's multifunction copiers is true to Carlson's original vision for these devices.
C. Peter McColough, a longtime executive of Haloid and Xerox took over as CEO from Joseph Wilson in 1968.
In 1968 the company consolidated its headquarters at "Xerox Square" in downtown Rochester with its iconic 30-story Xerox Tower. In 2007 the headquarters was moved to Stamford, Connecticut, but most of the office staff remained in Rochester. In 2009 Xerox decided to sell the property, and the sale was completed in 2013, with Xerox continuing to lease space for the remaining approximately 1400 employees.
Xerox embarked on a series of acquisitions. University Microfilms was purchased in 1962, Electro-Optical Systems in 1963, and R.R. Bowker in 1967. In 1969, Xerox acquired Scientific Data Systems (SDS). It renamed the division "Xerox Data Systems" (XDS) and produced the Sigma line and its successor the XDS 5xx series of mainframe computers in the 1960s and 1970s. XDS was sold to Honeywell in 1975.
1970s.
Archie McCardell was named president of the company in 1971. During his tenure, Xerox introduced the Xerox 6500, its first color copier. During McCardell's reign at Xerox, the company announced record revenues, earnings and profits in 1973, 1974, and 1975. John Carrol became a backer, later spreading the company throughout North America.
In the mid-1970s, Xerox introduced the "Xerox 9200 Duplicating System". Originally designed to be sold to print shops, to increase their productivity, it was twice a fast as the 3600 duplicator at two impressions per second (7200 per hour). It was followed by the 9400, which did auto-duplexing, and then by the 9500, which was which added variable zoom reduction and electronic lightness/darkness control.
In a 1975 Super Bowl commercial for the 9200, Xerox debuted an advertising campaign featuring "Brother Dominic", a monk who used the 9200 system to save decades of manual copying. Dominic, portrayed by Jack Eagle, became the face of Xerox into the 1980s.
Following these years of record profits, in 1975, Xerox resolved an anti-trust suit with the United States Federal Trade Commission (FTC), which at the time was under the direction of Frederic M. Scherer. The Xerox consent decree resulted in the forced licensing of the company's entire patent portfolio, mainly to Japanese competitors. Within four years of the consent decree, Xerox's share of the U.S. copier market dropped from nearly 100% to less than 14%.
In 1979, Xerox purchased Western Union as the basis for its proposed "Xerox Telecommunications Network" (XTEN) for local-loop communications. However, after three years, in 1982, the company decided the idea was a mistake and sold its assets to MCI at a loss.
1980s.
David T. Kearns, a Xerox executive since 1971, took over as CEO in 1982. The company was revived in the 1980s and 1990s, through improvement in quality design and realignment of its product line. Attempting to expand beyond copiers, in 1981 Xerox introduced a line of electronic memory typewriters, the "Memorywriter", which gained 20% market share, mostly at the expense of IBM.
In 1983 Xerox bought Crum & Forster, an insurance company, and formed Xerox Financial Services (XFS) in 1984.
In 1985 Xerox sold all of its publishing subsidiaries including University Microfilms and R.R. Bowker.
1990s.
In 1990 Paul Allaire, a Xerox executive since 1966, succeeded David Kearns, who had reached mandatory retirement age. Allaire disentangled Xerox from the financial services industry.
Development of digital photocopiers in the 1990s and a revamp of the entire product range again gave Xerox a technical lead over its competitors. In 1990, Xerox released the DocuTech Production Publisher Model 135, ushering in print-on-demand. Digital photocopiers were essentially high-end laser printers with integrated scanners. Soon, additional features such as network printing and faxing were added to many models, known as Multi Function Machines, or just MFMs, which were able to be attached to computer networks. Xerox worked to turn its product into a service, providing a complete document service to companies including supply, maintenance, configuration, and user support.
To reinforce this image, in 1994 the company introduced a corporate signature, "The Document Company", above its main logo and introduced a red digital X. The digital X symbolized the transition of documents between the paper and digital worlds.
In the mid-1990s LA County Superior Court turned to Xerox for help in replacing nearly 500 aging copiers throughout LA County, but Xerox refused to consider leasing. The County instead went to Konica. Xerox was shut out of the County for the next two years.
In April 1999 Allaire was succeeded by Richard Thoman, who had been brought in from IBM in 1997 as president. The first "outsider" to head Xerox Thoman became a victim of internal politics, and he was forced to resign in 2000.
2000s.
After Thoman's resignation Allaire again resumed the position of CEO and served until the appointment of Anne M. Mulcahy, another long-term Xerox executive. Xerox's turnaround was largely led by Mulcahy, who was appointed president in May 2000, CEO in August 2001 and chairman in January 2002. She launched an aggressive turnaround plan that returned Xerox to full-year profitability by the end of 2002, along with decreasing debt, increasing cash, and continuing to invest in research and development.
In 2000, Xerox acquired Tektronix color printing and imaging division in Wilsonville, Oregon, for US$925 million. This led to the current Xerox Phaser line of products as well as Xerox solid ink printing technology.
In September 2004, Xerox celebrated the 45th anniversary of the Xerox 914. More than 200,000 units were made around the world between 1959 and 1976, the year production of the 914 was stopped. Today, the 914 is part of American history as an artifact in the Smithsonian Institution.
In November 2006, Xerox completed the acquisition of XMPie. XMPie, the leading provider of software for cross-media, variable data one-to-one marketing, offers solutions to help businesses create and manage highly-effective direct marketing and cross-media campaigns.
In October 2008, Xerox Canada Ltd. was named one of Greater Toronto's Top Employers by Mediacorp Canada Inc., which was announced by the Toronto Star newspaper.
On May 21, 2009, it was announced that Ursula Burns would succeed Anne Mulcahy as CEO of Xerox. On July 1, 2009, Burns became the first African American woman to head a company the size of Xerox.
On September 28, 2009, Xerox announced the intended acquisition of Affiliated Computer Services, a services and outsourcing company, for $6.4 Billion. The acquisition was completed in February 2010. Xerox said it paid 4.935 Xerox shares and $18.60 cash for each share of ACS, totaling $6.4 billion, or $63.11 a share for the company.
2010s.
In May 2011, Xerox acquired NewField IT for an undisclosed sum. NewField IT developed the Asset DB toolset which is widely used across the managed print services (MPS) market along with MPS market-leading consulting and software services delivering a large impact for this relatively small acquisition.
In December 2013, Xerox sold their Wilsonville, Oregon solid ink product design, engineering and chemistry group and related assets previously acquired from Tektronix to 3D Systems for $32.5 million in cash.
In December 2014, Xerox sold the IT Outsourcing business it had acquired in 2009 from Affiliated Computer Services to Atos for . This move was taken due to the relatively slow growth of this business relative to some other Xerox units.
Digital printing.
The laser printer was invented in 1969 by Xerox researcher Gary Starkweather by modifying a Xerox 7000 copier. Xerox management was afraid the product version of Starkweather's invention, which became the 9700, would negatively impact their copier business so the innovation sat in limbo until IBM launched the 3800 laser printer in 1976.
The first commercial non-impact printer was the Xerox 1200, introduced in 1973, based on the 3600 copier. It had an optical character generator designed by optical engineer Phil Chen.
In 1977, following IBM's laser printer introduction, the Xerox 9700 was introduced. Laser printing eventually became a multi-billion-dollar business for Xerox.
In the late 1970s Xerox introduced the "Xerox 350 color slide system" This product allowed the customer to create digital word and graphic 35mm slides. Many of the concepts used in today's "Photo Shop" programs were pioneered with this technology.
In 1980, Xerox announced the forward looking 5700 laser printing system, a much smaller version of their 9700, but with revolutionary touch screen capabilities and multiple media input (word processing disks, IBM magcards, etc.) and printer 'finishing' options. This product was allegedly never intended to make the commercial markets due to its development cost, but rather to show the innovation of Xerox. It did take off with many customers, but was soon replaced with its still smaller and lower cost 2700 Distributed Electronic Printer offering in 1982.
Palo Alto Research Center.
In 1970, under company president C. Peter McColough, Xerox opened the Xerox Palo Alto Research Center, known as Xerox PARC. The facility developed many modern computing technologies such as the graphical user interface (GUI), laser printing, WYSIWYG text editors and Ethernet. From these inventions, Xerox PARC created the Xerox Alto in 1973, a small minicomputer similar to a modern workstation or personal computer. This machine can be considered the first true Personal Computer, given its versatile combination of a cathode-ray-type screen, mouse-type pointing device, and a QWERTY-type alphanumeric keyboard. But the Alto was never commercially sold, as Xerox itself could not see the sales potential of it. It was, however, installed in Xerox's own offices, worldwide and those of the US Government and military, who could see the potential. Within these sites the individual workstations were connected together by Xerox's own unique LAN, The Ethernet. Data was sent around this system of heavy, yellow, low loss coaxial cable using the packet data system. In addition, PARC also developed one of the earliest internetworking protocol suites, the PARC Universal Packet (PUP).
In 1979, Steve Jobs made a deal with Xerox's venture capital division: He would let them invest $1 million in exchange for a look at the technology they were working on. Jobs and the others saw the commercial potential of the WIMP (Window, Icon, Menu, and Pointing device) system and redirected development of the Apple Lisa to incorporate these technologies. Jobs is quoted as saying, "They just had no idea what they had." In 1980, Jobs invited several key PARC researchers to join his company so that they could fully develop and implement their ideas.
In 1981, Xerox released a system similar to the Alto, the Xerox 8010 Star. It was the first commercial system to incorporate technologies that have subsequently become commonplace in personal computers, such as a bitmapped display, window-based GUI, mouse, Ethernet networking, file servers, print servers and e-mail. The Xerox 6085 Star, despite its technological breakthroughs, did not sell well due to its high price, costing $16,000 per unit. A typical Xerox Star-based office, complete with network and printers, would have cost $100,000.
In the mid-1980s, Apple considered buying Xerox; however, a deal was never reached. Apple instead bought rights to the Alto GUI and adapted it into to a more affordable personal computer, aimed towards the business and education markets. The Apple Macintosh was released in 1984, and was the first personal computer to popularize the GUI and mouse amongst the public.
In 2002 PARC was spun off into an independent wholly owned subsidiary of Xerox.
Xerox Partner Programs.
Xerox offers numerous partnership programs such as, being an Authorized Sales Agent, North American Reseller Sales (NARS), Xerox Business Innovation Partnership Program, and Xerox Premier Partners Global Network. One can also create their own agency, such as Paper Trail Solutions, in North Carolina and Documaxx, in Texas.
Products and services.
Xerox today manufactures and sells a wide variety of office and production equipment including LCD Monitors, photo copiers, Xerox Phaser printers, multifunction printers, large-volume digital printers as well as workflow software under the brand strategy of FreeFlow. The impact of Xerox FreeFlow products on the graphic arts market and the print industry in general has grown exponentially since May 2006, largely as a result of the Xerox presence at IPEX 2006. Xerox also sells scanners and digital presses. On May 29, 2008, Xerox launched the Xerox iGen4 Press.
Xerox sells both color and black-and-white printers under the Xerox Phaser and ColorQube brand, with the color consumer model starting at US$299; the most expensive color model costs US$6,799.
Multifunction office color and black-and-white products are sold under the ColorQube, Phaser, and WorkCentre brands.
Xerox also produces fax machines, professional printers, black and white copiers, and several other products.
In addition, Xerox produces many printing and office supplies such as paper in many forms, and solid ink that takes advantage of 2400 FinePoint technology; and markets software such as Xerox DocuShare, Xerox MarketPort and FlowPort, offers consulting services, ECM Digital Repository Services and printing outsourcing. s of 2014[ [update]], the head of the Xerox services business was Robert Zapfel.
Corporate structure.
Although Xerox is a global brand, it maintains a joint venture, Fuji Xerox, with Japanese photographic firm Fuji Photo Film Co. to develop, produce and sell in the Asia-Pacific region. Fuji Photo Film Co. is currently the majority stakeholder, with 75% of the shareholding.
Xerox India, formerly Modi Xerox, is Xerox's Indian subsidiary derived from a joint venture formed between Dr. Bhupendra Kumar Modi and Rank Xerox in 1983. Xerox obtained a majority stake in 1999 and aims to buy out the remaining shareholders.
NewField IT is a wholly owned subsidiary of Xerox that implements and supports third party software for MPS providers.
Xerox now sponsors the Factory Ducati Team in the World Superbike Championship, under the name of the "Xerox Ducati".
Rank Xerox.
European operations, Rank Xerox, later extended to Asia and Africa, has been fully owned by Xerox Corporation since 1997. The Rank Xerox name was discontinued following the buyout, and the Rank Xerox Research Centre was renamed to the Xerox Research Centre Europe.
Accounting irregularities.
On May 31, 2001, Xerox Corporation announced that its auditors, KPMG LLP, had certified Xerox's financial statements for the three years ended December 31, 2000. And the financials included some restatements. On March 31, 2002, Xerox restated its financials which reflected the reallocation of equipment sales revenue of more than $2 billion. On April 11, 2002, the U.S. Securities and Exchange Commission filed a complaint against Xerox. The complaint alleged Xerox deceived the public between 1997 and 2000 by employing several "accounting maneuvers," the most significant of which was a change in which Xerox recorded revenue from copy machine leases – recognizing a "sale" when a lease contract was signed, instead of recognizing revenue over the entire length of the contract. At issue was when the revenue was recognized, not the validity of the revenue. Xerox's restatement only changed what year the revenue was recognized. On December 20, 2002, Xerox Corporation reported that it had discovered an error in the calculation of its non-cash interest expense related to a debt instrument and associated interest rate swap agreements, resulted in after-tax understatement of interest expense of approximately $5 million to $6 million or less than 1 cent per share in each of the four quarters of 2001 and for the first three quarters of 2002.
In response to the SEC's complaint, Xerox Corporation neither admitted nor denied wrongdoing. It agreed to pay a $10 million penalty and to restate its financial results for the years 1997 through 2000. On June 5, 2003, six Xerox senior executives accused of securities fraud settled their issues with the SEC and neither admitted nor denied wrongdoing. They agreed to pay $22 million in penalties, disgorgement, and interest. The company received approval to settle the securities lawsuit in 2008.
On January 29, 2003, the SEC filed a complaint against Xerox's auditors, KPMG, alleging four partners in the "Big Five" accounting firm permitted Xerox to "cook the books" to fill a $3 billion "gap" in revenue and $1.4 billion "gap" in pre-tax earnings. In April 2005 KPMG settled with the SEC by paying a US$22.48 million fine. Meanwhile, Xerox paid a civil penalty of $10 million. As part of the settlement KPMG neither admits nor denies wrongdoings.
During settlement with the Securities and Exchange Commission, Xerox began to revamp itself once more. As a symbol of this transformation, the relative size of the word "Xerox" was increased in proportion to "The Document Company" on the corporate signature and the latter was dropped altogether in September-2004, along with the digital X. However, the digital X and "The Document Company" were still used by Fuji Xerox until April-2008.
Character substitution bug.
In 2013, German computer scientist David Kriesel discovered an error in a Xerox WorkCentre 7535 copier. The device would substitute number digits in scanned documents, even when OCR was turned off. For instance, a cost table in a scanned document had an entry of 85.40, instead of the original sum of 65.40. After unsuccessfully trying to resolve this issue with Xerox's customer support, he publicised his findings on his blog. Providing examples pages that lead to the bug occurrence, it was confirmed that this bug was reproducible on a variety of Xerox WorkCentre and other high-end Xerox copiers.
The source of the error was a bug in the JBIG2 implementation, which is an image compression standard that makes use of pattern matching to encode identical characters only once. While this provides a high level of compression, it is susceptible to errors in identifying similar characters.
A possible workaround was published by Kriesel, which involved setting the image quality from "normal" to "higher" or "high". Shortly afterwards it was found that the same fix had been suggested in the printer manual, which mentioned the occurrence of character substitutions in "normal mode", indicating that Xerox was aware of the software error. In Xerox's initial response to a growing interest by the media, the error was described as occurring rarely and only when factory settings had been changed. After Kriesel provided evidence that the error was also occurring in the highest image quality mode, Xerox corrected its statement and released a software patch to eliminate the problem. Despite the problem being present in some instances also in higher quality mode, Xerox advises users that they can use this mode as an alternative to applying the patch.
Trademark.
The word "xerox" is used as a synonym for "photocopy" (both as a noun and a verb) in many areas; for example,""I xeroxed the document and placed it on your desk." or "Please make a xeroxed copy of the articles and hand them out a week before the exam"". Though both are common, the company does not condone such uses of its trademark, and is particularly concerned about the ongoing use of Xerox as a verb as this places the trademark in danger of being declared a generic word by the courts. The company is engaged in an ongoing advertising and media campaign to convince the public that Xerox should not be used as a verb.
To this end, the company has written to publications that have used Xerox as a verb, and has also purchased print advertisements declaring that "you cannot 'xerox' a document, but you can copy it on a Xerox Brand copying machine". Xerox Corporation continues to protect its trademark in most if not all trademark categories. Despite their efforts, many dictionaries continue to include the use of "xerox" as a verb, including the "Oxford English Dictionary".

</doc>
<doc id="34167" url="http://en.wikipedia.org/wiki?curid=34167" title="Xyzzy (computing)">
Xyzzy (computing)

Zzyzx
Xyzzy is a magic word from the "Colossal Cave Adventure" computer game.
In computing, the word is sometimes used as a metasyntactic variable or as a video game cheat code, the canonical "magic word". In mathematics, the word is used as a mnemonic for the cross product.
Origin.
Modern usage is primarily from one of the earliest computer games, "Colossal Cave Adventure", in which the idea is to explore an underground cave with many rooms, collecting the treasures found there. By typing "xyzzy" at the appropriate time, the player could move instantly between two otherwise distant points. As "Colossal Cave Adventure" was both the first adventure game and the first interactive fiction, hundreds of later interactive fiction games included responses to the command "xyzzy" in tribute.
The origin of the word has been the subject of debate. Rick Adams pointed out that the mnemonic "XYZZY" has long been taught by math teachers to remember the process for performing cross products (as a mnemonic that lists the order of subscripts to be multiplied first). Crowther, author of "Colossal Cave Adventure", states that he was unaware of the mnemonic, and that he "made it up from whole cloth" when writing the game.
Uses.
Xyzzy has been implemented as an undocumented no-op command on several operating systems; in Data General's AOS, for example, it would typically respond "Nothing happens", just as the game did if the magic was invoked at the wrong spot or before a player had performed the action that enabled the word. The 32-bit version, AOS/VS, would respond "Twice as much happens". On several computer systems from Sun Microsystems, the command "xyzzy" is used to enter the interactive shell of the u-boot bootloader. Early versions of Zenith Z-DOS (a re-branded variant of MS-DOS 1.25) had the command "xyzzy" which took a parameter of "on" or "off". Xyzzy by itself would print the status of the last "xyzzy on" or "xyzzy off" command.
The popular "Minesweeper" game under older versions of Microsoft Windows had a cheat mode triggered by entering the command codice_1, then pressing the key sequence shift and then enter, which turned a single pixel in the top-left corner of the entire screen into a small black or white dot depending on whether or not the mouse pointer is over a mine. This easter egg was present in all Windows versions through Windows XP Service Pack 3, but under Windows 95, 98 and NT 4.0 the pixel was visible only if the standard Explorer desktop was not running. The easter egg does not exist in versions after Windows XP SP3.
Within the low-traffic Usenet newsgroup alt.xyzzy, the word is used for test messages, to which other readers (if there are any) customarily respond, "Nothing happens" as a note that the test message was successfully received. In the Internet Relay Chat client mIRC and Pidgin, entering the undocumented command "/xyzzy" will display the response "Nothing happens". The string "xyzzy" is also used internally by mIRC as the hard-coded master encryption key that is used to decrypt over 20 sensitive strings from within the mirc.exe program file.
A "deluxe chatting program" for DIGITAL's VAX/VMS written by David Bolen in 1987 and distributed via BITNET took the name xyzzy. It enabled users on the same system or on linked DECnet nodes to communicate via text in real time. There was a compatible program with the same name for IBM's VM/CMS.
xYzZY is used as the default boundary marker by the Perl HTTP::Message module for multipart MIME messages, and was used in Apple's AtEase for workgroups as the default administrator password in the 1990s.
In the game Zork, typing xyzzy and pressing enter produces the response: A hollow voice says "fool." The command commonly produces a humorous response in other Infocom games and text adventures, leading to its usage in the title of the interactive fiction competition, the XYZZY Awards.
When booting a Cr-48 from developer mode, when the screen displays the "sad laptop" image, pressing xyzzy produces a joke BSOD screen.
Gmail lists XYZZY as a capability when connected via IMAP before logging in. It takes no arguments, and responds with "OK Nothing happens."
In Dungeons and Dragons Online, Xy'zzy is the nigh-invulnerable raid boss in the Hound of Xoriat adventure.
In the PC version of the popular Electronic Arts game Road Rash, the cheat mode is enabled by typing the key string "xyzzy" in the middle of the race.
In Primordia, one is able to get a bonus short scene featuring a shout-out to 'CCA' as a form of non-playable text-adventure, which is accessible by typing 'xyzzy' in Memorious's data-kiosk.
The Hewlett Packard HP3458A 8½ digit multimeter recognizes XYZZY as a command via HP-IB and responds "I see no cave here."
The Hewlett Packard 9836A computer with HPL 2.0 programming language has XYZZY built into the HPL language itself with the result of "I see no cave here." when used. All devices using HPIB (Hewlett Packard Interface Bus) are equipped with the same HPL programming language.
The "Cards Against Humanity" clone game "Pretend You're Xyzzy" has an obvious reference to the term in its title.
Andrew Sega released an album under the name XYZZY.

</doc>
<doc id="34168" url="http://en.wikipedia.org/wiki?curid=34168" title="Xenogears">
Xenogears

Xenogears (ゼノギアス, Zenogiasu) is a science fiction role-playing video game developed and published by Squaresoft (now Square Enix) for Sony's PlayStation. It was released on February 11, 1998 in Japan and on October 20, 1998 in North America. The game was never released in PAL territories. It was re-released by Squaresoft as a Greatest Hits title in 2003, and on the PlayStation Network on June 25, 2008 in Japan and on February 22, 2011 in North America.
"Xenogears" follows protagonist Fei Fong Wong and several others as they journey to uncover the truth behind mysterious, cabalistic entities operating in their world. The principles and philosophies of Friedrich Nietzsche, Sigmund Freud and Carl Jung influence the plot, character design, and world of "Xenogears". Additionally, the symbols, theological concepts, and devotional practices of several world religions are represented in fictionalized forms in the game. Major psychological themes are the nature of identity and human memory, particularly as these relate to the phenomenon of dissociative identity disorder. The relationship between humanity and machines is central to the game's plot, as indicated by the presence of giant robots dubbed "gears," which almost each playable character can control.
"Xenogears" was generally well received by critics, with a 91% rating on Game Rankings and a score of 83 out of 100 at Metacritic. Reviews particularly praised the storyline with multiple subplots, the gameplay, the characters, the themes (including allusions to Jungian psychology and Gnostic spirituality), and the generally epic scope of the narrative. It was voted the 16th best video game of all time by readers of "Famitsu" in 2006. "Xenogears" has shipped 1.19 million copies worldwide as of March 31, 2003.
Gameplay.
"Xenogears" combines traditional role-playing video game structures such as Square's signature Active Time Battle system with new features particular to the game's martial-arts combat style. It features two slightly different battle systems: in the first the user controls human characters in turn-based combat manipulated through the sequencing of learned combos. The second, making use of "gears," introduces different sets of statistics and abilities for each character. "Xenogears" features both traditional anime and pre-rendered CGI movie clips by Production I.G to illustrate important plot points.
The player advances the protagonist and his companions through a fully three-dimensional fictional world. There is an overworld map with visitable cities, geographical sites, and other important locations spread out across several continents. A couple of locations encountered throughout the game exist not on the original world map, but in the sky. At first, the party only travels on foot, but is eventually permitted to make use of a variety of vehicles, including their gears and the "sand submarine" Yggdrasil.
Battle system.
Battle in "Xenogears" is a variant of the Active Time Battle system found in games such as "Chrono Trigger" and the "Final Fantasy" series. Most enemy encounters in "Xenogears" are random. When a battle begins, there is a transition to a separate screen with a combat interface. Player-characters use a combination of martial arts moves, "Ether" (magical) attacks, and special "Deathblow" combinations which are learned through the repetition of specific proportions of strong, moderate, and weak hits. All offensive actions use Action Points (AP), costing either three points, two points, or one point, corresponding to the intensity of the attack. Each character can initially use only three AP per turn, but at higher levels, they can eventually use up to seven AP per turn. At a certain point in the game, characters can begin using "Elemental Deathblows," which, as the name implies, attach elemental attributes to physical combos. In addition to being used for attacks, AP may be saved and allocated to Attack Points for combo attacks during later turns. A total of 28 AP may be accumulated for combo attacks.
Characters can also use a variety of magical abilities for both offense and ally-support. These abilities are limited by the number of Ether Points (EP) that are available to a character, which must be replenished using items during exploration (non-combat) sequences. For most characters, these abilities are attributed to "Ether," a mysterious power to which (presumably) all humans have access. Some characters' magical abilities are referred to by different names, implying differences in their origins. For example, Fei's magic is called "Chi" and Citan's is called "Arcane". While fighting in gears, human Ether abilities are amplified, though some change or become unavailable during this type of combat.
Gear battle.
In addition to small-scale, hand-to-hand combat, the characters sometimes fight from within their respective giant robots, called gears. In gear combat, the limiting factor of AP is replaced by fuel, with each attack consuming an amount corresponding to its power. For these battles, "deathblows" may only be executed after first building up the "Attack Level"—an abstract concept represented by a number in the bottom-left of the gear combat interface—through the execution of simple strong, moderate, or weak attacks. One deathblow is allowed per point on the Attack Level gauge. There are three levels for normal gear deathblows and, beyond the third level, an "infinite" level with its own set of deathblows. To reach Infinity Mode, a character has to stay at attack level 3 while performing any other action. With each turn, there is a chance that Infinity Mode will be reached. Having a duration of three turns, "Infinity Mode" allows fuel to be recharged in much larger quantities and, while in this mode, gears have access to "Infinity" attacks. This mode is actually referred to as "Hyper Mode" in-game through a little-known text read-out found in one of the bonus dungeons at the end of the game.
Gears can regain fuel with a "Charge" command. The gears can also activate "Boosters" which enable them to act faster at a cost of extra fuel per turn. The "Special Option" command allows for gear HP restoration abilities and special, fuel-consuming attacks. When a gear has no fuel left, it can no longer execute attacks, use special options, or use boosters. They can, however, Charge to regain fuel and use Ether abilities. Gear fuel, parts, and upgrades may be purchased in shops or from certain individual vendors.
Plot.
Setting.
"Xenogears" initially takes place on Ignas, the largest continent of the "Xenogears" world, and the site of a centuries-long war between the nations of Aveh and Kislev. A church-like organization known as the Ethos has excavated gears, ostensibly for the preservation of the world's culture. Although Kislev originally had the upper hand in the war, a mysterious army known as Gebler appeared and began to provide assistance to Aveh. With Gebler's help, the Aveh military not only recovered its losses, but began making its way into Kislev's territory. As the story unfolds, the setting broadens to encompass the entire world and the two floating countries, Shevat and Solaris. Solaris, ruled by Emperor Cain and the Gazel Ministry, commands the Gebler army and the Ethos and secretly uses both to dominate the land-dwellers. Shevat has been the only country to evade the control of Solaris.
Much of "Xenogears" plot and backstory is detailed in the Japanese-only book "Xenogears Perfect Works." This book, produced by the now defunct DigiCube, details the history of the "Xenogears" universe from the discovery of the Zohar to the start of the game. According to the "Perfect Works" schematic (as well as the game's end credits), "Xenogears" is the fifth episode in a series of six.
Characters.
"Xenogears"‍ '​ nine playable characters hail from different areas of the game's world. The game begins on Ignas, a continent with two countries, Aveh and Kislev. Fei and Citan at first appear to be from this land, although it is later learned that they originate from the capital cities Aphel Aura and Etrenank of the floating countries of Shevat and Solaris, respectively. Fei is the story's protagonist, and has initially lost his memories of his past. Citan is a man whose knowledge of the world and technology often aids in the party's quest. Bart, a desert pirate, is also from Ignas and is the rightful heir to the throne of Aveh. Rico, a demi-human with incredible strength, lives in a Kislev prison, spending his days as a gear-battling champion. Solaris, a hidden city of advanced technology, is home to several characters in the game. Billy, a pious worker for the Ethos religious group, was originally from Solaris. Elly, a beautiful Gebler officer of Solaris, is destined to be near Fei and falls in love with him by the end of the game. Maria and Chu-Chu are both from Shevat, the floating city and the only place resisting Solaris' domination. Emeralda is a humanoid being constructed by an ancient civilization from a colony of nanomachines, and was retrieved from the ruins of the ancient civilization Zeboim. Significant non-playable characters include Krelian and Miang, both leaders of Solaris who seek to revive Deus, a mechanical weapon that fell to earth thousands of years ago. They serve as the game's main antagonists. Grahf, a mysterious man with immense power, serves as a major antagonist ; he follows Fei and his group and often fights them, though his goals remain a mystery until very late in the game. As being "the Contact", "the Anti-type" and "the Complement", Fei, Elly, and Miang have been reincarnated several times throughout the game's history.
Story.
"Xenogears" centers around the protagonist Fei Fong Wong, an adopted young male in the village, Lahan, brought by a mysterious "masked man" three years ago. The events surrounding Fei's arrival at the village cause him to have retrograde amnesia. During an attack on Lahan from Gebler, Fei pilots an empty gear and fights the enemy, accidentally destroying the village. As a result, Fei and Citan, the village's doctor, decide to leave with the abandoned gear to get it away from the village. Fei meets Elly, a Gebler officer, and Grahf, who claims to know about Fei's past. Eventually, Fei and Citan are picked up by Bart, a desert pirate and heir to the throne of Aveh. Fei again loses control of himself inside his gear while Bart and Citan are attacked by an unknown red gear. Fei wakes up in a Kislev prison and meets Wiseman, a mysterious masked man, who originally brought Fei to Lahan. Fei is able to escape with the help of his friends, but he and Elly are separated from the rest of the party and accidentally shot down by Bart. 
They are rescued by the Thames, a movable floating city. After learning Elly's whereabouts, Gebler attacks Thames to kidnap Elly and Miang, a Gebler officer, unsuccessfully brainwashes her. Ramsus, who holds a vendetta against Fei, attacks Thames, searching for him. Afterward, Billy, an Ethos worker onboard Thames, allows Fei to use the Ethos' advanced medical technology. Bishop Stone, Ethos' leader, reveals to the party Ethos's true purpose of controlling the land dwellers, or "Lambs", for Solaris. The group follows Stone to Zeboim, an excavation site. They discover a young girl composed of nanomachines, which is what Krelian, a Solarian leader, seeks. Stone takes the girl while the group fights Id, the mysterious red gear's pilot, who wants the girl, but is stopped by Wiseman. The group returns and finds Fei awake and standing at his gear with a case of anterograde amnesia. Fei and his friends decide to ally themselves with the floating city of Shevat, the only remaining city capable of resisting Solaris. When entering Solaris, they encounter Emeralda, the nanomachine colony. She attacks at first, but recognizes Fei, referring to him as "Kim", much to Fei's confusion. In Solaris, Fei learns that Citan has been working for Emperor Cain and that Solaris has been producing food and medicine out of recycled humans in the Soylent System facility. The party also learns that the Gazel Ministry seeks to revive Deus and achieve eternal life, while Krelian seeks to possess Elly. Back at Shevat, Citan informs his friends that Id is actually Fei's split personality. 
The Gazel Ministry uses the Gaetia Key, an artifact that manipulates the DNA of massive amounts of humans around the world, turning them into mutants called Wels in order to collect flesh to reconstruct a god called Deus that crash-landed on the planet ten thousand years ago. During this time, Elly and Fei become romantically involved with each other. They learn that they are the reincarnations of Sophia and Lacan. Lacan was a painter while Sophia was the Holy Mother of Nisan around the time of the war between Shevat and Solaris five-hundred years earlier. Lacan blamed himself for Sophia's death during the war and, with the help of Miang, became Grahf and sought to destroy the world. Although defeated, he and Miang have transmigrated their minds into other humans since. Krelian and Miang dispose of the Emperor and the Gazel Ministry because they are no longer necessary and kidnap Elly, the "Mother", who must be sacrificed in order to revive Deus. Miang is killed by an enraged Ramsus as he realizes he has been used, and Elly turns into Miang, becoming absorbed by Deus. Fei, as Id, attempts to make contact with the Zohar. Wiseman, who reveals himself to be Fei's father, stops him, giving peace to Fei's other personalities. Fei's gear transforms into the Xenogears and Grahf appears, revealing that he had been inside Fei's father's body. At this time, Fei makes contact with the Wave Existence—an extra-dimensional being who is trapped inside Deus and is the source of power for all gears—and learns that he must destroy Deus to free humanity. Grahf, who tries to merge with Fei, is defeated.
Fei discovers that he is a descendant of Abel, a young boy who was a passenger on board the Eldridge, a spaceship that was being used to transport Deus, the core of an interplanetary invasion system created by a federation of spacefaring humans, one that was deemed far too dangerous for use and was therefore dismantled and moved. Deus, however, had become self-aware and took over the Eldridge. Amidst the confusion, Abel was separated from his mother and accidentally made contact with the Wave Existence through the Zohar, Deus' power source. It gave him the power to one day destroy Deus and the Zohar in order to free itself. The Wave Existence also sensed Abel's longing for his mother and used the biological computer Kadomony to create a woman for a companion. When Deus gained full control over the Eldridge, the captain decided to initiate the self-destruct sequence in an attempt to destroy it. Both Deus and the Zohar survived the explosion and landed on a nearby planet along with Abel, under the protection of the Wave Existence. He was the sole survivor, but was soon united with the woman that the Wave Existence had created for him as a companion, Elly. Abel and Elly, at first, led a happy life, but Deus had also created Miang, Cain, and the Gazel Ministry to begin a human civilization on the planet, one which would be under their control to one day be turned into Wels and be absorbed into Deus to recover its strength. When the now-adult Abel and Elly discovered this, they openly challenged Cain and the Gazel Ministry, but lost. However, through the power of the Wave Existence, they are able to be reincarnated in later eras to combat Deus. One of these incarnations lived during an ancient technologically advanced era in Zeboim, where Abel's incarnation went by the name Kim and created Emeralda. 
Fei sets out to destroy Deus and free the Wave Existence and Elly. In Merkaba, the party defeats Deus, but they realize that the energy released from the Wave Existence's shift will destroy the planet. Elly, inside Deus, tries to move it away from the planet and Fei, in his Xenogears, follows to save her, but both disappear in the rift. Krelian confronts them, telling Fei he only sought to end the pain and suffering that comes with human existence by reverting everything back to when it all began, when all was one, to ascend to the realm of God. Fei rejects Krelian's ideology with his love for Elly, but Krelian challenges Fei, telling him to prove this love that could make him independent of God, and calls forth Urobolus, a gigantic serpent-like incarnation of Miang. Xenogears appears and Fei uses it to defeat Urobolus. Krelian releases Elly and reveals to Fei that he had planned to become one with God along with Elly. During her time with Krelian, Elly had seen inside his heart and realized it was full of sadness and despair for all the atrocities he had committed. Despite everything, Elly says that Krelian truly loved people more than anyone else. Because no one will forgive his sins, he declines Fei's offer to return and ascends to a higher plain of existence along with the Wave Existence, telling Fei and Elly that he envies them. Fei and Elly then return to their planet along with Xenogears and reunite with the rest of the party.
Development.
"Xenogears" was produced by Hiromichi Tanaka, who previously worked on the SNES game "Secret of Mana". The scenario of the game was written by director Tetsuya Takahashi and by Kaori Tanaka. Yasuyuki Honne served as art director, while Kunihiko Tanaka was responsible for the character designs. Tetsuo Mizuno, Tomoyuki Takechi, and "Final Fantasy" creator Hironobu Sakaguchi were executive producers for "Xenogears". Koichi Mashimo, an animation director and his studio Bee Train, was in charge of the anime cut scenes. "Xenogears" started out as an early concept conceived by Tetsuya Takahashi and Kaori Tanaka for the Square game "Final Fantasy VII". Their superior in the company deemed it "too dark and complicated for a fantasy", but Takahashi was allowed to develop it as a separate project. It is the fifth part of a six-part story detailed in "Xenogears Perfect Works"; at the end of the game's credits, "Episode V" appears on screen. The story of "Xenogears" is influenced by the ideas of Freud, Jung, and Nietzsche, and they are referenced numerous times within the game's narrative.
Due to a combination of the second disc content being almost entirely composed of single boss battles surrounded by character narration and a large number of unused assets and fragments that can be found included in the code on the second disc, there has long been speculation the game was rushed at the end of production. If this happened or why has never been confirmed by anyone involved in the game's development. While the game is considered 'finished', signs of rushed development are found throughout both discs, and several story threads were left incomplete.
Square had announced that "Xenogears" may not have come out in the United States due to "sensitive religious issues". However, Square soon after reversed this and, with a joint partnership with Electronic Arts, released the game in October 1998. The English translation of "Xenogears" was the first instance in which an English localization team worked directly with Square developers. It also was the first major project of Square translator Richard Honeywood. According to Honeywood, translating the game was a particularly difficult task due to it containing numerous scientific concepts and philosophies.
Square Enix released "Xenogears" on the Japanese PlayStation Network on June 25, 2008 and in North America on February 22, 2011.
Audio.
The music in "Xenogears" was composed by Yasunori Mitsuda, composer of the SNES title "Chrono Trigger". The "Xenogears Original Soundtrack" was released on two discs and published by DigiCube in Japan. The score contains 41 instrumental tracks, in addition to a choral track and two songs. According to Mitsuda, the music of "Xenogears" belongs to the traditional music genre. Though he first described it as stemming from "a world of [his] own imagining" rather than any specific country, he has also claimed a strong Irish or Celtic music influence. There are two vocal tracks included on the OST, and both are sung by Joanne Hogg. One of the tracks, "Stars of Tears", did not appear in the final version of the game. It was originally intended to play in a cut scene at the start of the game along with the main staff credits. The scene, however, was removed for pacing issues, as it would have made the combined opening movie and introduction scenes last roughly ten minutes. The other, "Small Two of Pieces ~Screeching Shards~", was the first ending theme with sung lyrics to ever appear in a game developed by Square.
An arranged soundtrack of "Xenogears" also composed and arranged by Mitsuda was released as "Creid". For "Creid", he expanded on the theme from the original album of having Celtic influences in "easy-to-listen-to" pop tracks to create an album of arranged "Xenogears" music with a more prominent Celtic style. The album contains a mixture of vocal and instrumental tracks, and combines Japanese and Celtic music together in its pieces. The album features five vocal tracks and five instrumental tracks. The main lyricist, Junko Kudo, wrote the lyrics to four of the five vocal tracks, while Mitsuda wrote the lyrics to the titular track "Creid", which were then translated from Japanese to Gaelic for the recording. Celtic singer Joanne Hogg did not reprise her role in "Creid". Instead, Tetsuko Honma sang the four tracks written by Kudo, while Eimear Quinn sang "Creid".
In October 2010, Mitsuda announced that he planned to work on "", a second arranged album of music from the game, in an orchestral style. He took suggestions from fans as to which tracks to include.
Merchandise.
There have been several Japanese books and comics published concerning the "Xenogears" franchise. "Xenogears God Slaying Story", a series by Masatoshi Kusakabe, was published by Shueisha in 1998. DigiCube published both "Xenogears Perfect Works" and a memorial album named "Thousands of Daggers", which contains the entire script to the game in Japanese, along with screenshots. Two manga books, "Xenogears Comic Anthology" and "Xenogears 4koma Comic", were released by Movic. Movic also released wallscrolls, notebooks, pins, keychains, stickers, and postcards depicting the "Xenogears" cast.
Reception.
"Xenogears" was a commercial success in both Japan and North America. As of March 31, 2003, the game had shipped 1.19 million copies worldwide, with 910,000 of those copies being shipped in Japan and 280,000 abroad. As a result of these sales, it was re-released as a Greatest Hits title in December 2003. In Japanese gaming magazine "Famitsu", "Xenogears" was voted the 16th best video game of all time by its readers in a poll held in 2006. On a similar poll at GameFAQs, users of the website voted "Xenogears" the 32nd "Best Game Ever" in 2005. It was placed in the same position in IGN's "Top 100 Games - Readers Choice" feature in 2006, and as number 28 in 2008.
Critical response.
"Xenogears" was met with critical acclaim. Allgame pointed out in a positive light that the character battles are "unlike most role-playing games from this company". GameSpot wrote that the story becomes "a little preachy at times", but went on to say that the religious and existential themes "enhance the story and [our] understanding of the game's deep characterizations". "Edge" commented that although it is "considered by some to be a multimillion-yen, convoluted science-fiction vanity project, "Xenogears" nevertheless remains one of the most keenly eulogized PlayStation RPGs." The magazine also noted that it was Takahashi's "most challenging and pure work" and that the "Xenosaga" series never quite matched up to "Xenogears".
The game was criticized for having too many cut scenes, especially on the second disc, where the use of the world map is restricted for an extended period and the amount of cut scenes increases. IGN, however, stated that despite all the cut scenes and the confusing plot, "immersion is a key factor in "Xenogears" and the questions you may have about the storyline are all answered at some point in the game." "Edge" criticized its "flawed" script and "muddied" translation. Years after the game's release, Electronic Gaming Monthly called the game's plot "one of the wackiest game plotlines ever", saying that it "actually makes sense" if the player ignores all of the sideplots. However, Game Informer and Next Generation Magazine agreed that the plot was one of the game's highlights, the former making the claim that it draws from "Star Wars", "Star Blazers", the Old Testament, and many other Square games, making it "a game every RPG fanatic must play."
Reviewers largely praised "Xenogears"' gameplay. "Next Generation" praised Square's Active Time Battle gauge and said that inclusion of the AP meter and combo attacks "is not only refreshing in a turn-based RPG, but gives players a higher level of interaction during battle." IGN claimed that "the most impressive feature in combat is the ability to use massive "Gears" or mechs", noting that Square's attention to programming these battles is made evident by how "visually satisfying" they are. IGN praised the game's exploration, saying that the ability to jump and climb "adds even more depth to exploration of different environments and distances Xenogears from being too straightforward of a traditional RPG", the only complaint being that the rotating camera is sometimes "clumsy".
However, the game's audio received a more mixed reception. GameSpot noted that many of the games' tracks "include voice or chanting and all are appropriately uppity or low with the game's mood", but complained that there were too many areas with silence or ambience. "Xenogears" was the first Square game to feature voice overs and anime cut scenes. These aspects were criticized by reviewers, like Game Revolution, who stated that they were poorly synched and too sparse, respectively.
Legacy.
Shortly after "Xenogears" was released, there was speculation of a sequel being released, although this never occurred. While "Xenogears" has never had an official sequel or prequel, there was wide speculation that Namco and Monolith Soft's "Xenosaga" was a prequel when it was first announced. Tetsuya Takahashi was the director and writer for both "Xenogears" and "Xenosaga" and has noted that "with our relation between Square, I think it is difficult for us to say it is a direct sequel or prequel". Approximately twenty members of the "Xenosaga" development staff had previously worked on "Xenogears".
On the connection between "Xenogears" and "Xenosaga", Takahashi has stated:It's probably more suitable to say that it follows the direction and style of "Xenogears". [...] Now that we are under a different company, we figured we should start everything from scratch all over again. Though there are familiar faces that serve as important characters in "Xenosaga", others are more like self-parodies, so we don't really want "Xenogears" fans to overreact. Like movies, sometimes you have the director of the movie or friend of the leading actor appearing as cameos, so it's similar to that.
Several members of the "Xenogears" staff came together in 2008 to work on "Sands of Destruction", a role-playing game for the Nintendo DS, published by Sega. These staff members include Masato Kato, Kunihiko Tanaka, and Yasunori Mitsuda.

</doc>
<doc id="34175" url="http://en.wikipedia.org/wiki?curid=34175" title="Aveh">
Aveh

Aveh may refer to:

</doc>
<doc id="34185" url="http://en.wikipedia.org/wiki?curid=34185" title="Kislev">
Kislev

Kislev (Hebrew: כִּסְלֵו, "Kislev" "Kislēw"; also "Chislev" is the third month of the civil year and the ninth month of the ecclesiastical year on the Hebrew calendar.
In a regular ("kesidran") year Kislev has 30 days, but because of the Rosh Hashanah postponement rules, in some years it can lose a day to make the year a "short" ("chaser") year. Kislev is an autumn month which occurs in November–December on the Gregorian calendar and is sometimes known as the month of dreams. 
The name of the month may be taken from Akkadian "kislimu", which means "inspissated, thickened" due to plentiful rains. But the name may also derive from the Hebrew root K-S-L as in the words "kesel, kisla" (hope, positiveness) or "ksil" (Orion, a constellation that shines especially in this month) - because of the expectation and hope for rains.
Holidays in Kislev.
 25 Kislev—2 Tevet - Hanukkah – ends 3 Tevet if Kislev is short
Kislev in Jewish history.
15 Kislev - (162 BC) - The Greeks set up the "Abomination of Desolation" in the Temple
20 Kislev - (457 BC) - Ezra's address
25 Kislev - (167 BC) The Greeks make pagan sacrifices in the Temple
25 Kislev - (164 BC) - The Hanukkah miracle
27 Kislev - (2105 BC) - Flood rains cease

</doc>
<doc id="34190" url="http://en.wikipedia.org/wiki?curid=34190" title="XFree86">
XFree86

XFree86 was an implementation of the X Window System. It was originally written for Unix-like operating systems on IBM PC compatibles and was available for many other operating systems and platforms. It is free and open source software under the XFree86 License version 1.1. It was developed by the XFree86 Project, Inc. The lead developer was David Dawes. The last released version was 4.8.0, released December 2008. The last XFree86 CVS commit was made on May 18, 2009; the project was confirmed dormant in December 2011.
For most of the 1990s and early 2000s, the project was the source of most innovation in X and was the "de facto" steward of X development. Until early 2004, it was almost universal on Linux and the BSDs.
In February 2004, with version 4.4.0, The XFree86 Project adopted a license change that the Free Software Foundation considered GPL incompatible. Most open source operating systems using XFree86 found this unacceptable and moved to a fork from before the license change. The first fork was the abortive Xouvert, but X.Org Server soon became dominant. Most XFree86 developers also moved to X.Org.
Usage.
While XFree86 was used in most distributions before its license change with version 4.4.0, it has mostly been replaced by its fork X.org and is used rarely nowadays. The last remaining operating system distribution to use it is NetBSD, which still ships some platforms with 4.5.0 by default (though Xorg can be installed from pkgsrc).
Architecture.
The XFree86 server communicates with the host operating system's kernel to drive input and output devices, with the exception of graphics cards. These are generally managed directly by XFree86, so it includes its own drivers for all graphic cards a user might have. Some cards are supported by vendors themselves via binary-only drivers.
Since version 4.0, XFree86 has supported certain accelerated 3D graphics cards via the GLX and DRI extensions. Also in the version 4.0, XFree86 moved to a new driver model, from one X server binary per driver to a unique X server capable of loading several drivers at a time.
Because the server usually needs low level access to graphics hardware, on many configurations it needs to run as the superuser, or a user with UID 0. However, on some systems and configurations it is possible to run the server as a normal user.
It is also possible to use XFree86 in a framebuffer device, which in turn uses a kernel graphics card driver.
On a typical POSIX-system, the directory /etc/X11 includes the configuration files. The basic configuration file is /etc/X11/XF86Config (or XF86Config-4) that includes variables about the screen (monitor), keyboard and graphics card. The program "xf86config" is often used, although "xf86cfg" also comes with the XFree86 server and is certainly friendlier. Many Linux distributions used to include a configuration tool that was easier to use (such as Debian's debconf) or autodetected most (if not all) settings (Red Hat Linux and Fedora's "Anaconda", SuSE's "YaST" and Mandrake Linux used to choose this path).
History.
Early history and naming.
The project began in 1992 when David Wexelblat, Glenn Lai, David Dawes and Jim Tsillas joined forces addressing bugs in the source code of the X386 X display server (written by Thomas Roell), as contributed to X11R5. This version was initially called X386 1.2E. As newer versions of the (originally freeware) X386 were being sold under a proprietary software license by SGCS (of which Roell was a partner), confusion existed between the projects. After discussion, the project was renamed X"Free"86, as a pun (compare X-three-eighty-six to X-free-eighty-six). Roell has continued to sell proprietary X servers, most recently under the name "Accelerated-X".
Rise with Linux.
As Linux grew in popularity, XFree86 rose with it, as the main X project with drivers for PC video cards.
By the late 1990s, official X development was moribund. Most technical advancement was happening in the XFree86 project. In 1999, XFree86 was sponsored onto X.Org (the official industry consortium) by various hardware companies interested in its use with Linux and its status as the most popular version of X.
2002: growing dissent within the project.
By 2002, while Linux's popularity, and hence the installed base of X, surged, X.Org was all but inactive; active development was largely carried out by XFree86. However, there was considerable dissent within XFree86.
XFree86 used to have a "Core Team" which was made up of experienced developers, selected by other Core Team members for their merits. Only the members of this Core Team were allowed to commit to CVS. This was perceived as far too cathedral-like in its development model: developers were unable to get commit rights quickly and vendors ended up maintaining extensive patches.
A key event was Keith Packard losing his commit rights. Hours before the feature freeze window for XFree86 4.3.0 started, he committed the XFIXES extension, without prior discussion or without review within the Core Team. The Core Team decided to remove Keith's commit access, but without removing him from the Core Team itself, and the XFIXES extension was backed out 6 weeks later.
2003: The fork and the disbanding of the Core Team.
In March, the Core Team claimed that Keith Packard had been trying to fork the XFree86 project by working inside the project while trying to attract core developers to a new X Server project of his own making. Packard denied this had been his aim, but some emails were provided as evidence otherwise. Keith Packard was subsequently expelled from the Core Team.
A short time later, Keith Packard created xwin.org, which mainly served as a meeting point for cultivating the XFree86 fork. The rest of the year, many of the developers that were still active at XFree86 went over to the project that was being set up at the freedesktop.org and X.org domains.
By the end of the year, due to dwindling active membership and limited remaining development capacity, the XFree86 Core Team voted to disband itself.
2004: Licensing controversy.
Versions of XFree86 up to and including some release candidates for 4.4.0 were under the MIT License, a permissive, non-copyleft free software license. In February 2004, XFree86 4.4 was released with a change to the XFree86 license, by adding a credit clause, similar to that in the original BSD license, but broader in scope. The newer terms are referred to as the XFree86 License 1.1.
Many projects relying on XFree86 found the new license unacceptable, and the Free Software Foundation considers it incompatible with the version 2 of the GNU General Public License, though compatible with version 3. The XFree86 Project states that the license is "as GPL compatible as any and all previous versions were", but does not mention which version or versions of the GPL this is valid for.
Some projects made releases (notably OpenBSD 3.5 and 3.6, and Debian 3.1 "Sarge") based on XFree86 version 4.4 RC2, the last version under the old license. Most operating systems incorporating XFree86 (including later versions of OpenBSD and Debian) migrated to the X.Org Server.
The last code commit was in 2009; the project was confirmed dormant in 2011.
Forks of XFree86.
Xwin.
Shortly after he was expelled from the XFree86 Core Team, Keith Packard started setting up xwin.org. While this was claimed to be the fork of XFree86, Keith Packard later refined this to "a forum for community participation in X". Xwin saw a lot of activity in the first two months after the announcements, but most of the activity was happening behind the scenes, and Keith moved his own development to freedesktop.org.
Xouvert.
Xouvert was later also hailed as the first XFree86 fork in August 2003. Even though releases were announced for October 2003 and April 2004, no releases were made. The last status change was made in March 2004 and it was communicated that there were delays in setting up a revision control system.
X.Org.
The X.Org Server became the official reference implementation of X11. The first version, X11R6.7.0, was forked from XFree86 version 4.4 RC2 to avoid the XFree86 license changes, with X11R6.6 changes merged in. Version X11R6.8 added many new extensions, drivers and fixes. It is hosted by and works closely with corporate-sponsored freedesktop.org.
Most of the open-source Unix-like operating systems have adopted the X.Org Server in place of XFree86, and most of the XFree86 developers have moved to X.Org.
References.
</dl>

</doc>
<doc id="34191" url="http://en.wikipedia.org/wiki?curid=34191" title="X (American band)">
X (American band)

X is an American punk rock band, formed in Los Angeles in 1977. Established among the first wave of American punk, the original members are vocalist Exene Cervenka, vocalist/bassist John Doe, guitarist Billy Zoom, and drummer DJ Bonebrake. The band released seven studio albums from 1980 to 1993. After a period of inactivity during the mid to late 1990s, X reunited in the early 2000s, and currently tours.
X achieved limited mainstream success but influenced various genres of music, including punk rock and folk rock. In 2003, X's first two studio albums, "Los Angeles" and "Wild Gift", were ranked by Rolling Stone magazine as being among the 500 greatest albums of all time. "Los Angeles" was ranked 91st on Pitchfork's Top 100 Albums of the 1980s. The band received an Official Certificate of Recognition from the City of Los Angeles in acknowledgment of its contribution to Los Angeles music and culture.
History.
1977–1979: Formation and Dangerhouse era.
X was founded by bassist/singer John Doe and guitarist Billy Zoom. Doe brought his poetry-writing girlfriend Exene Cervenka to band practices, and she eventually joined the band as a vocalist. Drummer DJ Bonebrake was the last of the original members to join after leaving local group The Eyes.
X's first record deal was with independent label Dangerhouse, for which the band produced a sole single, "Adult Books" / "We're Desperate" (1978). A Dangerhouse session version of "Los Angeles" was also featured on a 1979 Dangerhouse 12" EP compilation called "Yes L.A." (a play on the now-famous no wave compilation "No New York"), a picture disc that featured other early-punk-era LA bands like the Weirdos and Black Randy.
1980–1981: "Los Angeles" and "Wild Gift".
As the band became the flag bearer for the local scene, a larger independent label, Slash Records, signed the band to issue its first LP. The result was their first LP release, "Los Angeles" (1980) (produced by The Doors' keyboard player, Ray Manzarek). It was a minor hit and was well received by the underground press and mainstream media. Much of X's early material had a rockabilly edge. Doe and Cervenka co-wrote most of the group's songs, and their slightly off-kilter harmony vocals remain perhaps the group's most distinctive element. Their lyrics tended to be straight-out poetry; comparisons to Charles Bukowski and Raymond Chandler were made from the start.
Their follow-up effort, 1981's "Wild Gift", broadened the band's profile when it was named "Record of the Year" by "Rolling Stone", "The Los Angeles Times", "The New York Times", and "Village Voice". "Wild Gift", like their debut album, was released on Slash records, and was similar in musical style, although "Wild Gift" featured shorter, faster songs; arguably their most stereotypically punk-sounding record.
1982–1984: Elektra era and The Knitters.
X then signed to Elektra in 1982 to release "Under the Big Black Sun", which marked a slight departure from their trademark sound. While still fast and loud, the album's country leanings were evolving and its raw punk sound was channeling raw guitar power chords. The album was heavily influenced by the death of Exene Cervenka's elder sister Mirielle (Mary) in an automobile accident in 1980. Three songs on the album, "Riding With Mary", "Come Back to Me", and the title track all directly relate to the tragedy. A fourth, a high-speed version of Al Dubin and Joe Burke's "Dancing With Tears in My Eyes", was, years later, indirectly attributed to Exene Cervenka's mournful state of mind. The stark black-and-white cover art and title were also a reflection of the somber mood of the band during this time. She has said it is her favorite X album 
"You know, my favorite record is Under the Big Black Sun, so everything else is kind of . . . 
I'm saying if I had to sit down in a room and put on an X record—which I don't generally do—I have recently listened to some X records but I generally don't listen to myself—the record I would pick to listen to would be "Under the Big Black Sun."
1983 saw the release of the "More Fun in the New World" album. X slightly redefined their sound with this release, making it somewhat more polished, eclectic and radio-ready than in previous albums. With the sound moving away from punk rock, the band's rockabilly influence became even more noticeable, along with some new elements: funk on the track "True Love Pt. II" and Woody Guthrie-influenced folk protest songs like "The New World" and "I Must Not Think Bad Thoughts." The record received critical praise from "Rolling Stone" and "Playboy", who had long been stalwart supporters and fans of X and their sound.
A side project of some of the band members was "Poor Little Critter on the Road" in 1985, under the name The Knitters: X minus Zoom, plus Dave Alvin (of The Blasters) on guitar and Johnny Ray Bartel (of The Red Devils) on double bass. The Knitters were devoted to folk and country music; their take on Merle Haggard's "Silver Wings" "may be the definitive version."
1985–1987: Commercial era and departure of Zoom.
Despite the overwhelmingly positive critical reception for their first four albums, the band was frustrated by its lack of wider mainstream success. Billy Zoom had also stated that he would leave the band unless its next album was more successful. The band decided to change producers in search of a more accessible sound. Their fifth record, "Ain't Love Grand!", was produced by pop-metal producer Michael Wagener. It featured a drastic change in sound, especially in the polished and layered production, while the band's punk roots were little in evidence, replaced by a countrified version of hard rock. The change in production was intended to bring the band more chart success, but although it got somewhat more mainstream radio play than their earlier releases, it did not represent a commercial breakthrough. Zoom left the group shortly thereafter in 1986, the same year in which the feature-length documentary film, "X: The Unheard Music", was released.
Zoom was initially replaced by ex-Blasters guitarist Dave Alvin on guitar. The band then added a fifth member, guitarist Tony Gilkyson, formerly of the band Lone Justice. By the time the band released its sixth album, "See How We Are", Alvin had already left the band, although he plays on the record along with Gilkyson. Like "Ain't Love Grand", the album's sound was fairly far removed from the band's punk origins, yet featured a punchy, energetic, hard-rocking roots rock sound that in many ways represented a more natural progression from their earlier sound than the previous record had. After touring for the album, X released a live record of the tour entitled "Live at the Whisky a Go-Go", and then went on an extended hiatus.
Back in 1984, X had released a cover version of "Wild Thing" as a non-LP single. In 1989, the song was re-released as the lead single from the soundtrack to the hit film "Major League". It later became a staple at sporting events, particularly baseball games, and was used by Japanese professional wrestler Atsushi Onita after he founded Frontier Martial-Arts Wrestling in 1989.
1993–1995: First reunion, "Hey Zeus!" and "Unclogged".
X regrouped in the early 1990s to record their seventh studio album, "Hey Zeus!". The album marked somewhat of a retreat from the increasingly roots-rock direction that the band's past few records had gone in, instead featuring an eclectic alternative-rock sound that fit in well with the then-current musical climate. Despite this, it failed to become a hit, although two of its songs, "Country at War" and "New Life" peaked at numbers 15 and 26 on the Billboard Modern Rock charts, respectively. The band followed it with an acoustic live album "Unclogged" in 1995. In 1994, they contributed a cover of the Richard Thompson song, "Shoot Out the Lights" to a Thompson tribute album called "Beat the Retreat", which featured David Hidalgo of Los Lobos on electric guitar. On the same album, Doe sang harmony and played bass and Bonebrake played drums on Bob Mould's cover of "Turning of the Tide", and Bonebrake played drums on the title track, which was performed by the British folk artist June Tabor.
1997–2004: Hiatus and second reunion.
In 1997, X released a compilation called "", which focused heavily on the early years with Billy Zoom and included a number of previously unreleased versions of songs that had appeared on their previous albums. At the same time, they also announced that they were disbanding. However, they did a farewell tour to promote the compilation in 1998, with Zoom returning on guitar. The original lineup also returned to the studio for the final time, with Ray Manzarek reprising his role as producer, to record a cover of The Doors' "The Crystal Ship" for the for "The X-Files: Fight the Future". Although the band has not released any new studio material since then, they continue to perform live with Zoom on guitar.
"X: The Unheard Music" was released on DVD in 2005, as was the concert DVD "X – Live in Los Angeles", which commemorates the 25th anniversary of the band's landmark debut album, "Los Angeles."
2005–2007: Reunion of the Knitters.
In 2005, Doe, Cervenka and Bonebrake reunited with Dave Alvin and Johnny Ray Bartel to release a second Knitters album, 20 years after the first, titled "The Modern Sound of the Knitters". In summer 2006, X toured North America on the "As the World Burns" tour with the Rollins Band and Riverboat Gamblers. In the spring of 2008, the band embarked on their "13X31" tour with Skybombers and the Detroit Cobras, with all original members. "13X31" is a reference to their 31st anniversary.
2008–present: Recent activities.
X appeared at the 2008 SXSW Festival. Footage of their performance is viewable on Crackle. X appeared at the Coachella Valley Music and Arts Festival on April 19, 2009 and at the All Tomorrow's Parties festival in Minehead, England from May 15–17, 2009. They were invited to perform at the latter by the festival's curators, The Breeders.
In June 2009, the band publicly announced that Exene had been diagnosed with multiple sclerosis. However, she told the "Orange County Register" in 2011 that the doctor who originally diagnosed the disease believes he misdiagnosed her. Exene stated that "I’ve had so many doctors tell me I have MS, then some say I don’t ... I don’t even care anymore.”
In June 2010, X played a free show at the North by Northeast festival in Toronto, Canada, and on June 18, 2011 the band headlined the third annual Johnny Cash Music Festival in Ventura, California.
X performed at The Voodoo Experience 2011, held at City Park in New Orleans, Louisiana, on October 28–30, 2011. The band also opened for Pearl Jam on their 2011 South and Central American tour in November and their European tour in June and July 2012.
On September 2, 2012, X performed at the Made in America festival in Philadelphia, PA.
Solo material.
Over the years, both Doe and Cervenka have released solo albums, with Doe having a stronger emphasis on roots music in his solo work. While Cervenka's solo albums have also been in a more folk or country vein, she has also fronted punk bands like Auntie Christ and The Original Sinners. She also has done tours featuring her poetry, sometimes along with either Lydia Lunch or Henry Rollins. Since 1986, Doe has also maintained a busy second career as an actor, appearing in such films as Oliver Stone's "Salvador", Allison Anders' "Border Radio" and "Sugar Town", the Jerry Lee Lewis biopic "Great Balls of Fire", Miguel Arteta's "The Good Girl", Craig Mazin's "The Specials", Paul Thomas Anderson's "Boogie Nights", and the independent feature "Roadside Prophets", in which he starred with Beastie Boy Adam Horovitz. He was a regular cast member of the television series "Roswell" on WB Television Network and UPN, and made a memorable appearance as an aging rock star on "Law & Order".

</doc>
<doc id="34193" url="http://en.wikipedia.org/wiki?curid=34193" title="XP">
XP

XP may refer to:

</doc>
<doc id="34194" url="http://en.wikipedia.org/wiki?curid=34194" title="Xenarthra">
Xenarthra

The superorder Xenarthra is a group of placental mammals (infraclass Eutheria), extant today only in the Americas and represented by anteaters, tree sloths, and armadillos. The origins of the order can be traced as far back as the Paleocene, as early as 59 million years ago in South America. Xenarthrans developed and diversified extensively in South America during its long period of isolation. They invaded the Antilles by the early Miocene and, starting about 9 Mya, they spread to Central and North America as part of the Great American Interchange. Nearly all of the formerly abundant megafaunal xenarthrans, such as ground sloths, glyptodonts, and pampatheres, became extinct at the end of the Pleistocene.
Xenarthrans share several characteristics not present in other placental mammals. The name Xenarthra, which means "strange joints", was chosen because their vertebral joints have extra articulations and are unlike those of any other mammals — a character referred to as "xenarthry" — and ischiosacral fusion. The males have internal testicles, which are located between the bladder and the rectum. Also, xenarthrans have the lowest metabolic rates among the therians.
Evolutionary relationships.
Xenarthrans were previously classified alongside the pangolins and aardvarks in the order Edentata (meaning toothless, because the members do not have front incisor teeth and lack, or have poorly developed, molars). Subsequently, Edentata was found to be a polyphyletic grouping whose New World and Old World taxa are unrelated, and it was split up to reflect their true phylogeny. Aardvarks and pangolins are now placed in individual orders, and the new order Xenarthra was erected to group the remaining families (which are all related). The name "Xenarthra" means "strange joints", and was chosen because their vertebral joints have extra articulations and are unlike those of any other mammals. Because they lack characteristics believed to be present in the common ancestor of other known eutherian mammals, some weak morphological evidence suggests Xenarthra is outside Epitheria, the group that contains all other eutherians known today. Some even place xenarthrans outside of placentals, in the separate group Paratheria.
The morphology of xenarthrans generally suggests the anteaters and sloths are more closely related to each other than either is to the armadillos; this is upheld by molecular studies. Since its conception, Xenarthra has increasingly come to be considered to be of a higher rank than 'order'; some authorities consider it to be a cohort, while others consider it to be a superorder. Whatever the rank, Xenarthra is now generally considered to be divided into two orders: Cingulata, which contains the armadillos; and Pilosa, which contains the Vermilingua (anteaters) and Folivora (sloths; previously known as Tardigrada or Phyllophaga).
Xenarthra may be most closely related to either Afrotheria (in the group Atlantogenata), or Epitheria (comprising Afrotheria and Boreoeutheria). In other words, it may be nested within Eutheria or it may be the basal extant group. A comprehensive phylogeny by Goloboff et al. includes xenarthrans as a sister clade of Euarchontoglires within Boreoeutheria (Laurasiatheria+Euarchontoglires).
Classification.
XENARTHRA

</doc>
<doc id="34195" url="http://en.wikipedia.org/wiki?curid=34195" title="XyWrite">
XyWrite

XyWrite is a word processor for DOS and Windows modeled on the mainframe-based ATEX typesetting system. Popular with writers and editors for its speed and degree of customization, XyWrite was in its heyday the house word processor in many editorial offices, including the "New York Times" from 1989 to 1993. XyWrite was developed by David Erickson and marketed by XyQuest from 1982 through 1992, after which it was acquired by The Technology Group. The final version for DOS was 4.18 (1993); for Windows, 4.13.
History and current usage.
XyQuest was founded in June 1982 by former ATEX employees Dave Erickson and John Hild. Its most successful product was XyWrite III Plus, which attracted a devoted following among professional writers.
The turning point for XyWrite came in the form of a disastrous near-partnership with IBM, which was seeking a modern replacement for its venerable DisplayWrite word processor. Working under an agreement signed in June 1990, XyQuest devoted nearly all of its development resources to revising Erickson's XyWrite IV to IBM's specifications, including IBM Common User Access-style menus, mouse support and a graphical user interface. Envisioned as a marriage between XyQuest technology and IBM marketing, the product was to be called Signature.
But on the eve of Signature's release, IBM announced a strategic decision to withdraw completely from the desktop software market, shocking XyQuest and leaving Signature in limbo. When a prospective new alliance with Lotus did not materialize, XyQuest had no alternative but to resticker the ready-to-ship Signature packages as XyWrite 4.0 and attempt to carry on.
However, the changes IBM had insisted on were a liability where the III Plus user base was concerned. Some key reviews (such as in "The Wall Street Journal") were harsh, and there were complaints that 4.0 was buggy and slow. Moreover, in the years since the last major XyWrite release, WordPerfect had cemented its hold on the DOS word processor market. Already financially strained by the long development cycle for Signature, by the end of 1992 XyQuest was bleeding money. The sale to The Technology Group ensued.
While there were a few maintenance releases of 4.0 after the acquisition, The Technology Group's major commitment was to developing XyWrite for Windows. But XyWrite remained a niche product, unable to compete for the business user against Word for Windows, WordPerfect for Windows, and Ami Pro, despite added versatility and customization potential. The Technology Group was dissolved in 2003.
Several versions of XyWrite for DOS and Windows were also localized for use in European countries. For example, the programs were offered in Germany under the name "euroscript" by North American Software GmbH.
A descendant of XyWrite called Nota Bene (word processor) is still being actively developed. Nota Bene, which runs on the XyWrite engine, is popular among academics. Nota Bene for Windows is now in version 10.
Thanks in large part to the work of users of XyWrite, the program is still very usable with Windows (or MS-DOS, and thus Linux). Even on Pentium and similar hardware, it remains noticeably faster than MS Word or OpenOffice.org. Despite these advantages in speed, XyWrite does not have as many features as Word or OpenOffice.org. For example, XyWrite is unaware of Windows ANSI or Unicode character sets and Nota Bene does not support languages (such as Chinese) that require double-byte characters.
Reception.
"BYTE" in 1984 stated "the XyQuest people have done an admirable job porting the editing part of the Atex system" to the IBM PC. While criticizing the documentation, it called XyWrite "extremely fast, powerful, compact, and flexible".

</doc>
<doc id="34197" url="http://en.wikipedia.org/wiki?curid=34197" title="X-ray">
X-ray

X-radiation (composed of X-rays) is a form of electromagnetic radiation. Most X-rays have a wavelength ranging from 0.01 to 10 nanometers, corresponding to frequencies in the range 30 petahertz to 30 exahertz (3×1016 Hz to 3×1019 Hz) and energies in the range 100 eV to 100 keV. X-ray wavelengths are shorter than those of UV rays and typically longer than those of gamma rays. In many languages, X-radiation is referred to with terms meaning Röntgen radiation, after Wilhelm Röntgen, who is usually credited as its discoverer, and who had named it "X-radiation" to signify an unknown type of radiation. Spelling of "X-ray(s)" in the English language includes the variants "x-ray(s)", "xray(s)" and "X ray(s)".
X-rays with photon energies above 5–10 keV (below 0.2–0.1 nm wavelength) are called "hard X-rays", while those with lower energy are called "soft X-rays". Due to their penetrating ability, hard X-rays are widely used to image the inside of objects, e.g., in medical radiography and airport security. As a result, the term "X-ray" is metonymically used to refer to a radiographic image produced using this method, in addition to the method itself. Since the wavelengths of hard X-rays are similar to the size of atoms they are also useful for determining crystal structures by X-ray crystallography. By contrast, soft X-rays are easily absorbed in air and the attenuation length of 600 eV (~2 nm) X-rays in water is less than 1 micrometer.
There is no universal consensus for a definition distinguishing between X-rays and gamma rays. One common practice is to distinguish between the two types of radiation based on their source: X-rays are emitted by electrons, while gamma rays are emitted by the atomic nucleus. This definition has several problems; other processes also can generate these high energy photons, or sometimes the method of generation is not known. One common alternative is to distinguish X- and gamma radiation on the basis of wavelength (or equivalently, frequency or photon energy), with radiation shorter than some arbitrary wavelength, such as 10−11 m (0.1 Å), defined as gamma radiation.
This criterion assigns a photon to an unambiguous category, but is only possible if wavelength is known. (Some measurement techniques do not distinguish between detected wavelengths.) However, these two definitions often coincide since the electromagnetic radiation emitted by X-ray tubes generally has a longer wavelength and lower photon energy than the radiation emitted by radioactive nuclei.
Occasionally, one term or the other is used in specific contexts due to historical precedent, based on measurement (detection) technique, or based on their intended use rather than their wavelength or source.
Thus, gamma-rays generated for medical and industrial uses, for example radiotherapy, in the ranges of 6–20 MeV, can in this context also be referred to as X-rays.
Properties.
X-ray photons carry enough energy to ionize atoms and disrupt molecular bonds. This makes it a type of ionizing radiation, and therefore harmful to living tissue. A very high radiation dose over a short amount of time causes radiation sickness, while lower doses can give an increased risk of radiation-induced cancer. In medical imaging this increased cancer risk is generally greatly outweighed by the benefits of the examination. The ionizing capability of X-rays can be utilized in cancer treatment to kill malignant cells using radiation therapy. It is also used for material characterization using X-ray spectroscopy.
Hard X-rays can traverse relatively thick objects without being much absorbed or scattered. For this reason, X-rays are widely used to image the inside of visually opaque objects. The most often seen applications are in medical radiography and airport security scanners, but similar techniques are also important in industry (e.g. industrial radiography and industrial CT scanning) and research (e.g. small animal CT). The penetration depth varies with several orders of magnitude over the X-ray spectrum. This allows the photon energy to be adjusted for the application so as to give sufficient transmission through the object and at the same time good contrast in the image.
X-rays have much shorter wavelength than visible light, which makes it possible to probe structures much smaller than what can be seen using a normal microscope. This can be used in X-ray microscopy to acquire high resolution images, but also in X-ray crystallography to determine the positions of atoms in crystals.
Interaction with matter.
X-rays interact with matter in three main ways, through photoabsorption, Compton scattering, and Rayleigh scattering. The strength of these interactions depend on the energy of the X-rays and the elemental composition of the material, but not much on chemical properties since the X-ray photon energy is much higher than chemical binding energies. Photoabsorption or photoelectric absorption is the dominant interaction mechanism in the soft X-ray regime and for the lower hard X-ray energies. At higher energies, Compton scattering dominates.
Photoelectric absorption.
The probability of a photoelectric absorption per unit mass is approximately proportional to "Z"3/"E"3, where "Z" is the atomic number and "E" is the energy of the incident photon. This rule is not valid close to inner shell electron binding energies where there are abrupt changes in interaction probability, so called absorption edges. However, the general trend of high absorption coefficients and thus short penetration depths for low photon energies and high atomic numbers is very strong. For soft tissue photoabsorption dominates up to about 26 keV photon energy where Compton scattering takes over. For higher atomic number substances this limit is higher. The high amount of calcium ("Z"=20) in bones together with their high density is what makes them show up so clearly on medical radiographs.
A photoabsorbed photon transfers all its energy to the electron with which it interacts, thus ionizing the atom to which the electron was bound and producing a photoelectron that is likely to ionize more atoms in its path. An outer electron will fill the vacant electron position and the produce either a characteristic photon or an Auger electron. These effects can be used for elemental detection through X-ray spectroscopy or Auger electron spectroscopy.
Compton scattering.
Compton scattering is the predominant interaction between X-rays and soft tissue in medical imaging. Compton scattering is an inelastic scattering of the X-ray photon by an outer shell electron. Part of the energy of the photon is transferred to the scattering electron, thereby ionizing the atom and increasing the wavelength of the X-ray. The scattered photon can go in any direction, but a direction similar to the original direction is a bit more likely, especially for high-energy X-rays. The probability for different scattering angles are described by the Klein–Nishina formula. The transferred energy can be directly obtained from the scattering angle from the conservation of energy and momentum.
Rayleigh scattering.
Rayleigh scattering is the dominant elastic scattering mechanism in the X-ray regime. The inelastic forward scattering is what gives rise to the refractive index, which for X-rays is only slightly below 1.
Production.
Whenever charged particles (electrons or ions) of sufficient energy hit a material, x-rays are produced.
Production by electrons.
X-rays can be generated by an X-ray tube, a vacuum tube that uses a high voltage to accelerate the electrons released by a hot cathode to a high velocity. The high velocity electrons collide with a metal target, the anode, creating the X-rays. In medical X-ray tubes the target is usually tungsten or a more crack-resistant alloy of rhenium (5%) and tungsten (95%), but sometimes molybdenum for more specialized applications, such as when softer X-rays are needed as in mammography. In crystallography, a copper target is most common, with cobalt often being used when fluorescence from iron content in the sample might otherwise present a problem.
The maximum energy of the produced X-ray photon is limited by the energy of the incident electron, which is equal to the voltage on the tube times the electron charge, so an 80 kV tube cannot create X-rays with an energy greater than 80 keV. When the electrons hit the target, X-rays are created by two different atomic processes:
So the resulting output of a tube consists of a continuous bremsstrahlung spectrum falling off to zero at the tube voltage, plus several spikes at the characteristic lines. The voltages used in diagnostic X-ray tubes range from roughly 20 to 150 kV and thus the highest energies of the X-ray photons range from roughly 20 to 150 keV.
Both of these X-ray production processes are inefficient, with a production efficiency of only about one percent, and hence, to produce a usable flux of X-rays, most of the electric power consumed by the tube is released as waste heat. The X-ray tube must be designed to dissipate this excess heat.
Short nanosecond bursts of X-rays peaking at 15-keV in energy may be reliably produced by peeling pressure-sensitive adhesive tape from its backing in a moderate vacuum. This is likely to be the result of recombination of electrical charges produced by triboelectric charging. The intensity of X-ray triboluminescence is sufficient for it to be used as a source for X-ray imaging. Using sources considerably more advanced than sticky tape, at least one startup firm is exploiting tribocharging in the development of highly portable, ultra-miniaturized X-ray devices.
A specialized source of X-rays which is becoming widely used in research is synchrotron radiation, which is generated by particle accelerators. Its unique features are X-ray outputs many orders of magnitude greater than those of X-ray tubes, wide X-ray spectra, excellent collimation, and linear polarization.
Production by fast positive ions.
X-rays can also be produced by fast protons or other positive ions. The Proton-induced X-ray emission or Particle-induced X-ray emission is widely used as an analytical procedure. For high energies, the production cross section is proportional to "Z12Z2−4", where "Z1" refers to the atomic number of the ion, "Z2" to that of the target atom.
An overview of these cross sections is given in the same reference.
Detectors.
X-ray detectors vary in shape and function depending on their purpose. Imaging detectors such as those used for radiography were originally based on photographic plates and later photographic film but are now mostly replaced by various digital detector types such as image plates or flat panel detectors. For radiation protection direct exposure hazard is often evaluated using ionization chambers, while dosimeters are used to measure the radiation dose a person has been exposed to. X-ray spectra can be measured either by energy dispersive or wavelength dispersive spectrometers.
Medical uses.
Since Röntgen's discovery that X-rays can identify bone structures, X-rays have been used for medical imaging. The first medical use was less than a month after his paper on the subject. Up until 2010, 5 billion medical imaging studies have been conducted worldwide. Radiation exposure from medical imaging in 2006 made up about 50% of total ionizing radiation exposure in the United States.
Radiographs.
A radiograph is an X-ray image obtained by placing a part of the patient in front of an X-ray detector and then illuminating it with a short X-ray pulse. Bones contain much calcium, which due to its relatively high atomic number absorbs x-rays efficiently. This reduces the amount of X-rays reaching the detector in the shadow of the bones, making them clearly visible on the radiograph. The lungs and trapped gas also show up clearly because of lower absorption compared to tissue, while differences between tissue types are harder to see.
Radiographs are useful in the detection of pathology of the skeletal system as well as for detecting some disease processes in soft tissue. Some notable examples are the very common chest X-ray, which can be used to identify lung diseases such as pneumonia, lung cancer or pulmonary edema, and the abdominal x-ray, which can detect bowel (or intestinal) obstruction, free air (from visceral perforations) and free fluid (in ascites). X-rays may also be used to detect pathology such as gallstones (which are rarely radiopaque) or kidney stones which are often (but not always) visible. Traditional plain X-rays are less useful in the imaging of soft tissues such as the brain or muscle.
Dental radiography is commonly used in the diagnoses of common oral problems, such as cavities.
In medical diagnostic applications, the low energy (soft) X-rays are unwanted, since they are totally absorbed by the body, increasing the radiation dose without contributing to the image. Hence, a thin metal sheet, often of aluminium, called an X-ray filter, is usually placed over the window of the X-ray tube, absorbing the low energy part in the spectrum. This is called "hardening" the beam since it shifts the center of the spectrum towards higher energy (or harder) x-rays.
To generate an image of the cardiovascular system, including the arteries and veins (angiography) an initial image is taken of the anatomical region of interest. A second image is then taken of the same region after an iodinated contrast agent has been injected into the blood vessels within this area. These two images are then digitally subtracted, leaving an image of only the iodinated contrast outlining the blood vessels. The radiologist or surgeon then compares the image obtained to normal anatomical images to determine if there is any damage or blockage of the vessel.
Computed tomography.
Computed tomography (CT scanning) is a medical imaging modality where tomographic images or slices of specific areas of the body are obtained from a large series of two-dimensional X-ray images taken in different directions. These cross-sectional images can be combined into a three-dimensional image of the inside of the body and used for diagnostic and therapeutic purposes in various medical disciplines.
Fluoroscopy.
Fluoroscopy is an imaging technique commonly used by physicians or radiation therapists to obtain real-time moving images of the internal structures of a patient through the use of a fluoroscope. In its simplest form, a fluoroscope consists of an X-ray source and fluorescent screen between which a patient is placed. However, modern fluoroscopes couple the screen to an X-ray image intensifier and CCD video camera allowing the images to be recorded and played on a monitor. This method may use a contrast material. Examples include cardiac catheterization (to examine for coronary artery blockages) and barium swallow (to examine for esophageal disorders).
Radiotherapy.
The use of X-rays as a treatment is known as radiation therapy and is largely used for the management (including palliation) of cancer; it requires higher radiation doses than those received for imaging alone. X-rays beams are used for treating skin cancers using lower energy x-ray beams while higher energy beams are used for treating cancers within the body such as brain, lung, prostate and breast.
Adverse effects.
Diagnostic X-rays (primarily from CT scans due to the large dose used) increase the risk of developmental problems and cancer in those exposed. X rays are classified as a carcinogen by both the World Health Organization's International Agency for Research on Cancer and the U.S. government. It is estimated that 0.4% of current cancers in the United States are due to computed tomography (CT scans) performed in the past and that this may increase to as high as 1.5-2% with 2007 rates of CT usage.
Experimental and epidemiological data currently do not support the proposition that there is a threshold dose of radiation below which there is no increased risk of cancer. However, this is under increasing doubt. It is estimated that the additional radiation will increase a person's cumulative risk of getting cancer by age 75 by 0.6–1.8%. The amount of absorbed radiation depends upon the type of X-ray test and the body part involved. CT and fluoroscopy entail higher doses of radiation than do plain X-rays.
To place the increased risk in perspective, a plain chest X-ray will expose a person to the same amount from background radiation that we are exposed to (depending upon location) every day over 10 days, while exposure from a dental X-ray is approximately equivalent to 1 day of environmental background radiation. Each such X-ray would add less than 1 per 1,000,000 to the lifetime cancer risk. An abdominal or chest CT would be the equivalent to 2–3 years of background radiation to the whole body, or 4–5 years to the abdomen or chest, increasing the lifetime cancer risk between 1 per 1,000 to 1 per 10,000. This is compared to the roughly 40% chance of a US citizen developing cancer during their lifetime. For instance, the effective dose to the torso from a CT scan of the chest is about 5 mSv, and the absorbed dose is about 14 mGy. A head CT scan (1.5mSv, 64mGy) that is performed once with and once without contrast agent, would be equivalent to 40 years of background radiation to the head. Accurate estimation of effective doses due to CT is difficult with the estimation uncertainty range of about ±19% to ±32% for adult head scans depending upon the method used.
The risk of radiation is greater to unborn babies, so in pregnant patients, the benefits of the investigation (X-ray) should be balanced with the potential hazards to the unborn fetus. In the US, there are an estimated 62 million CT scans performed annually, including more than 4 million on children. Avoiding unnecessary X-rays (especially CT scans) will reduce radiation dose and any associated cancer risk.
Medical X-rays are a significant source of man-made radiation exposure. In 1987, they accounted for 58% of exposure from man-made sources in the United States. Since man-made sources accounted for only 18% of the total radiation exposure, most of which came from natural sources (82%), medical X-rays only accounted for 10% of "total" American radiation exposure; medical procedures as a whole (including nuclear medicine) accounted for 14% of total radiation exposure. By 2006, however, medical procedures in the United States were contributing much more ionizing radiation than was the case in the early 1980s. In 2006, medical exposure constituted nearly half of the total radiation exposure of the U.S. population from all sources. The increase is traceable to the growth in the use of medical imaging procedures, in particular computed tomography (CT), and to the growth in the use of nuclear medicine.
Dosage due to dental X-rays varies significantly depending on the procedure and the technology (film or digital). Depending on the procedure and the technology, a single dental X-ray of a human results in an exposure of 0.5 to 4 mrem. A full mouth series may therefore result in an exposure of up to 6 (digital) to 18 (film) mrem, for a yearly average of up to 40 mrem.
Other uses.
Other notable uses of X-rays include
History.
Discovery.
German physicist Wilhelm Röntgen is usually credited as the discoverer of X-rays in 1895, because he was the first to systematically study them, though he is not the first to have observed their effects. He is also the one who gave them the name "X-rays" (signifying an unknown quantity) though many others referred to these as "Röntgen rays" (and the associated X-ray radiograms as, "Röntgenograms") for several decades after their discovery and even to this day in some languages, including Röntgen's native German.
X-rays were found emanating from Crookes tubes, experimental discharge tubes invented around 1875, by scientists investigating the cathode rays, that is energetic electron beams, that were first created in the tubes. Crookes tubes created free electrons by ionization of the residual air in the tube by a high DC voltage of anywhere between a few kilovolts and 100 kV. This voltage accelerated the electrons coming from the cathode to a high enough velocity that they created X-rays when they struck the anode or the glass wall of the tube. Many of the early Crookes tubes undoubtedly radiated X-rays, because early researchers noticed effects that were attributable to them, as detailed below. Wilhelm Röntgen was the first to systematically study them, in 1895.
Early research.
Both William Crookes (in the 1880s) and German physicist Johann Hittorf, a co-inventor and early researcher of the Crookes tube, found that photographic plates placed near the tube became unaccountably fogged or flawed by shadows. Neither found the cause nor investigated this effect.
In 1877 Ukrainian-born Ivan Pulyui, a lecturer in experimental physics at the University of Vienna, constructed various designs of vacuum discharge tube to investigate their properties. He continued his investigations when appointed professor at the Prague Polytechnic and in 1886 he found that sealed photographic plates became dark when exposed to the emanations from the tubes. Early in 1896, just a few weeks after Röntgen published his first X-ray photograph, Pulyui published high-quality X-ray images in journals in Paris and London. Although Pulyui had studied with Röntgen at the University of Strasbourg in the years 1873–75, his biographer Gaida (1997) asserts that his subsequent research was conducted independently.
X-rays were generated and detected by Fernando Sanford (1854–1948), the foundation Professor of Physics at Stanford University, in 1891. From 1886 to 1888 he had studied in the Hermann Helmholtz laboratory in Berlin, where he became familiar with the cathode rays generated in vacuum tubes when a voltage was applied across separate electrodes, as previously studied by Heinrich Hertz and Philipp Lenard. His letter of January 6, 1893 (describing his discovery as "electric photography") to The Physical Review was duly published and an article entitled "Without Lens or Light, Photographs Taken With Plate and Object in Darkness" appeared in the San Francisco Examiner.
Starting in 1888, Philipp Lenard, a student of Heinrich Hertz, conducted experiments to see whether cathode rays could pass out of the Crookes tube into the air. He built a Crookes tube (later called a "Lenard tube") with a "window" in the end made of thin aluminum, facing the cathode so the cathode rays would strike it. He found that something came through, that would expose photographic plates and cause fluorescence. He measured the penetrating power of these rays through various materials. It has been suggested that at least some of these "Lenard rays" were actually X-rays.
Hermann von Helmholtz formulated mathematical equations for X-rays. He postulated a dispersion theory before Röntgen made his discovery and announcement. It was formed on the basis of the electromagnetic theory of light. However, he did not work with actual X-rays.
In 1894 Nikola Tesla noticed damaged film in his lab that seemed to be associated with Crookes tube experiments and began investigating this "radiant energy of "invisible" kinds". After Röntgen identified the x-ray Tesla began making X-ray images of his own using high voltages and tubes of his own design, as well as Crookes tubes.
Wilhelm Röntgen.
On November 8, 1895, German physics professor Wilhelm Röntgen stumbled on X-rays while experimenting with Lenard and Crookes tubes and began studying them. He wrote an initial report "On a new kind of ray: A preliminary communication" and on December 28, 1895 submitted it to the Würzburg's Physical-Medical Society journal. This was the first paper written on X-rays. Röntgen referred to the radiation as "X", to indicate that it was an unknown type of radiation. The name stuck, although (over Röntgen's great objections) many of his colleagues suggested calling them Röntgen rays. They are still referred to as such in many languages, including German, Danish, Polish, Swedish, Finnish, Estonian, Russian, Japanese, Dutch, and Norwegian. Röntgen received the first Nobel Prize in Physics for his discovery.
There are conflicting accounts of his discovery because Röntgen had his lab notes burned after his death, but this is a likely reconstruction by his biographers: Röntgen was investigating cathode rays using a fluorescent screen painted with barium platinocyanide and a Crookes tube which he had wrapped in black cardboard so the visible light from the tube would not interfere. He noticed a faint green glow from the screen, about 1 meter away. Röntgen realized some invisible rays coming from the tube were passing through the cardboard to make the screen glow. He found they could also pass through books and papers on his desk. Röntgen threw himself into investigating these unknown rays systematically. Two months after his initial discovery, he published his paper.
Röntgen discovered its medical use when he made a picture of his wife's hand on a photographic plate formed due to X-rays. The photograph of his wife's hand was the first photograph of a human body part using X-rays. When she saw the picture, she said "I have seen my death."
Advances in radiology.
In 1895, Thomas Edison investigated materials' ability to fluoresce when exposed to X-rays, and found that calcium tungstate was the most effective substance. Around March 1896, the fluoroscope he developed became the standard for medical X-ray examinations. Nevertheless, Edison dropped X-ray research around 1903, even before the death of Clarence Madison Dally, one of his glassblowers. Dally had a habit of testing X-ray tubes on his hands, and acquired a cancer in them so tenacious that both arms were amputated in a futile attempt to save his life.
In 1901, U.S. President William McKinley was shot twice in an assassination attempt. While one bullet only grazed his sternum, another had lodged somewhere deep inside his abdomen and could not be found. "A worried McKinley aide sent word to inventor Thomas Edison to rush an X-ray machine to Buffalo to find the stray bullet. It arrived but wasn't used." While the shooting itself had not been lethal, "gangrene had developed along the path of the bullet, and McKinley died of septic shock due to bacterial infection" six days later.
The first use of X-rays under clinical conditions was by John Hall-Edwards in Birmingham, England on 11 January 1896, when he radiographed a needle stuck in the hand of an associate. On 14 February 1896 Hall-Edwards was also the first to use X-rays in a surgical operation. In early 1896, several weeks after Röntgen's discovery, Ivan Romanovich Tarkhanov irradiated frogs and insects with X-rays, concluding that the rays "not only photograph, but also affect the living function".
The first medical X-ray made in the United States was obtained using a discharge tube of Pulyui's design. In January 1896, on reading of Röntgen's discovery, Frank Austin of Dartmouth College tested all of the discharge tubes in the physics laboratory and found that only the Pulyui tube produced X-rays. This was a result of Pulyui's inclusion of an oblique "target" of mica, used for holding samples of fluorescent material, within the tube. On 3 February 1896 Gilman Frost, professor of medicine at the college, and his brother Edwin Frost, professor of physics, exposed the wrist of Eddie McCarthy, whom Gilman had treated some weeks earlier for a fracture, to the X-rays and collected the resulting image of the broken bone on gelatin photographic plates obtained from Howard Langill, a local photographer also interested in Röntgen's work.
Dangers.
With the widespread experimentation with x‑rays after their discovery in 1895 by scientists, physicians, and inventors came many stories of burns, hair loss and worse in technical journals of the time. In February 1896 Professor John Daniel and Dr. William Lofland Dudley of Vanderbilt University reported hair loss after Dr. Dudley was X-rayed. In August 1896 Dr. H/D. Hawks, a graduate of Columbia College, suffered severe hand and chest burns in an x-ray demonstration. It was reported in "Electrical Review" and led to many other reports of problems associated with x-rays being sent in to the publication. Many experimenters including Elihu Thomson at Edison's lab, William J. Morton, and Nikola Tesla also reported burns. Elihu Thomson deliberately exposed a finger to an x-ray tube over a period of time and suffered pain, swelling, and blistering. Other effects were sometime blamed for the damage including ultraviolet rays and (according to Tesla) ozone. Many physicians claimed there were no effects from x-ray exposure at all.
20th century and beyond.
The many applications of X-rays immediately generated enormous interest. Workshops began making specialized versions of Crookes tubes for generating X-rays and these first generation cold cathode or Crookes X-ray tubes were used until about 1920.
Crookes tubes were unreliable. They had to contain a small quantity of gas (invariably air) as a current will not flow in such a tube if they are fully evacuated. However, as time passed the X-rays caused the glass to absorb the gas, causing the tube to generate "harder" X-rays until it soon stopped operating. Larger and more frequently used tubes were provided with devices for restoring the air, known as "softeners". These often took the form of a small side tube which contained a small piece of mica: a mineral that traps relatively large quantities of air within its structure. A small electrical heater heated the mica and this caused it to release a small amount of air, thus restoring the tube's efficiency. However, the mica had a limited life, and the restoration process was consequently difficult to control.
In 1904, John Ambrose Fleming invented the thermionic diode, the first kind of a vacuum tube. This used a hot cathode that caused an electric current to flow in a vacuum. This idea was quickly applied to X-ray tubes, and hence heated-cathode X-ray tubes, called "Coolidge tubes", completely replaced the troublesome cold cathode tubes by about 1920.
In about 1906, the physicist Charles Barkla discovered that X-rays could be scattered by gases, and that each element had a characteristic X-ray. He won the 1917 Nobel Prize in Physics for this discovery.
In 1912, Max von Laue, Paul Knipping, and Walter Friedrich first observed the diffraction of X-rays by crystals. This discovery, along with the early work of Paul Peter Ewald, William Henry Bragg, and William Lawrence Bragg, gave birth to the field of X-ray crystallography.
The Coolidge X-ray tube was invented during the following year by William D. Coolidge. It made possible the continuous emissions of X-rays. X-ray tubes similar to this are still in use in 2012.
The use of X-rays for medical purposes (which developed into the field of radiation therapy) was pioneered by Major John Hall-Edwards in Birmingham, England. Then in 1908, he had to have his left arm amputated because of the spread of X-ray dermatitis on his arm.
The X-ray microscope was developed during the 1950s.
The Chandra X-ray Observatory, launched on July 23, 1999, has been allowing the exploration of the very violent processes in the universe which produce X-rays. Unlike visible light, which gives a relatively stable view of the universe, the X-ray universe is unstable. It features stars being torn apart by black holes, galactic collisions, and novae or neutron stars that build up layers of plasma that then explode into space.
An X-ray laser device was proposed as part of the Reagan Administration's Strategic Defense Initiative in the 1980s, but the only test of the device (a sort of laser "blaster", or death ray, powered by a thermonuclear explosion) gave inconclusive results. For technical and political reasons, the overall project (including the X-ray laser) was de-funded (though was later revived by the second Bush Administration as National Missile Defense using different technologies).
Phase-contrast X-ray imaging refers to a variety of techniques that use phase information of a coherent x-ray beam to image soft tissues. It has become an important method for visualizing cellular and histological structures in a wide range of biological and medical studies. There are several technologies being used for x-ray phase-contrast imaging, all utilizing different principles to convert phase variations in the x-rays emerging from an object into intensity variations. These include propagation-based phase contrast, talbot interferometry, refraction-enhanced imaging, and x-ray interferometry. These methods provide higher contrast compared to normal absorption-contrast x-ray imaging, making it possible to see smaller details. A disadvantage is that these methods require more sophisticated equipment, such as synchrotron or microfocus x-ray sources, x-ray optics and high resolution x-ray detectors.
Visibility.
While generally considered invisible to the human eye, in special circumstances X-rays can be visible. Brandes, in an experiment a short time after Röntgen's landmark 1895 paper, reported after dark adaptation and placing his eye close to an X-ray tube, seeing a faint "blue-gray" glow which seemed to originate within the eye itself. Upon hearing this, Röntgen reviewed his record books and found he too had seen the effect. When placing an X-ray tube on the opposite side of a wooden door Röntgen had noted the same blue glow, seeming to emanate from the eye itself, but thought his observations to be spurious because he only saw the effect when he used one type of tube. Later he realized that the tube which had created the effect was the only one powerful enough to make the glow plainly visible and the experiment was thereafter readily repeatable. The knowledge that X-rays are actually faintly visible to the dark-adapted naked eye has largely been forgotten today; this is probably due to the desire not to repeat what would now be seen as a recklessly dangerous and potentially harmful experiment with ionizing radiation. It is not known what exact mechanism in the eye produces the visibility: it could be due to conventional detection (excitation of rhodopsin molecules in the retina), direct excitation of retinal nerve cells, or secondary detection via, for instance, X-ray induction of phosphorescence in the eyeball with conventional retinal detection of the secondarily produced visible light.
Though X-rays are otherwise invisible it is possible to see the ionization of the air molecules if the intensity of the X-ray beam is high enough. The beamline from the wiggler at the at ESRF is one example of such high intensity.
Units of measure and exposure.
The measure of X-rays ionizing ability is called the exposure:
However, the effect of ionizing radiation on matter (especially living tissue) is more closely related to the amount of energy deposited into them rather than the charge generated. This measure of energy absorbed is called the absorbed dose:
The equivalent dose is the measure of the biological effect of radiation on human tissue. For X-rays it is equal to the absorbed dose.

</doc>
<doc id="34198" url="http://en.wikipedia.org/wiki?curid=34198" title="X86">
X86

x86 is a family of backward compatible instruction set architectures based on the Intel 8086 CPU and its Intel 8088 variant. The 8086 was introduced in 1978 as a fully 16-bit extension of Intel's 8-bit based 8080 microprocessor, with memory segmentation as a solution for addressing more memory than can be covered by a plain 16-bit address. The term "x86" came into being because the names of several successors to the Intel's 8086 processor ended in "86", including 80186, 80286, 80386 and 80486 processors.
Many additions and extensions have been added to the x86 instruction set over the years, almost consistently with full backward compatibility. The architecture has been implemented in processors from Intel, Cyrix, AMD, VIA and many other companies; there are also open implementations, such as the Zet SoC platform.
The term is not synonymous with IBM PC compatibility as this implies a multitude of other computer hardware; embedded systems as well as general-purpose computers used x86 chips before the PC-compatible market started, some of them before the IBM PC itself.
Overview.
In the 1980s and early 1990s when the 8088 and 80286 were still in common use, the term x86 usually represented any 8086 compatible CPU. Today, however, x86 usually implies a binary compatibility also with the 32-bit instruction set of the 80386. This is due to the fact that this instruction set has become something of a lowest common denominator for many modern operating systems and probably also because the term became common "after" the introduction of the 80386 in 1985.
A few years after the introduction of the 8086 and 8088, Intel added some complexity to its naming scheme and terminology as the "iAPX" of the ambitious but ill-fated Intel iAPX 432 processor was tried on the more successful 8086 family of chips, applied as a kind of system-level prefix. An 8086 "system", including coprocessors such as 8087 and/or 8089, as well as simpler Intel-specific system chips, was thereby described as an iAPX 86 "system". There were also terms "iRMX" (for operating systems), "iSBC" (for single-board computers), and "iSBX" (for multimodule boards based on the 8086-architecture) – all together under the heading "Microsystem 80". However, this naming scheme was quite temporary, lasting for a few years during the early 1980s.
Although the 8086 was primarily developed for embedded systems and small multi-user or single-user computers, largely as a response to the successful 8080-compatible Zilog Z80, the x86 line soon grew in features and processing power. Today, x86 is ubiquitous in both stationary and portable personal computers, and is also used in midrange computers, workstations, servers and most new supercomputer clusters of TOP500 list. A large amount of software, including operating systems (OSs) such as DOS, Windows, Linux, BSD, Solaris and Mac OS X, functions with x86-based hardware.
Modern x86 is relatively uncommon in embedded systems, however, and small low power applications (using tiny batteries) as well as low-cost microprocessor markets, such as home appliances and toys, lack any significant x86 presence. Simple 8-bit and 16-bit based architectures are common here, although the x86-compatible VIA C7, VIA Nano, AMD's Geode, Athlon Neo and Intel Atom are examples of 32- and 64-bit designs used in some "relatively" low power and low cost segments.
There have been several attempts, including by Intel itself, to end the market dominance of the "inelegant" x86 architecture designed directly from the first simple 8-bit microprocessors. Examples of this are the iAPX 432 (a project originally named the "Intel 8800"), the Intel 960, Intel 860 and the Intel/Hewlett-Packard Itanium architecture. However, the continuous refinement of x86 microarchitectures, circuitry and semiconductor manufacturing would make it hard to replace x86 in many segments. AMD's 64-bit extension of x86 (which Intel eventually responded to with a compatible design) and the scalability of x86 chips such as the eight-core Intel Xeon and 12-core AMD Opteron is underlining x86 as an example of how continuous refinement of established industry standards can resist the competition from completely new architectures.
Chronology.
The table below lists brands of common consumer targeted processors implementing the x86 instruction set, grouped by generations that emphasize important events of x86 history. Note: CPU generations are not strict - each generation is characterized by significantly improved or commercially successful processor microarchitecture designs.
History.
Background.
The x86 architecture was first used for the Intel 8086 central processing unit (CPU) released during 1978, a fully 16-bit design based on the earlier 8-bit based 8008 and 8080. Although not binary compatible, it was designed to allow assembly language programs written for these processors (as well as the contemporary 8085) to be mechanically translated into equivalent 8086 assembly. This made the new processor a tempting software migration route for many customers.
However, the 16-bit external data bus of the 8086 implied fairly significant hardware redesign, as well as other complications and expenses. To address this obstacle, Intel introduced the almost identical 8088, basically an 8086 with an 8-bit external databus that permitted simpler printed circuit boards and demanded fewer (1-bit wide) DRAM chips; it was also more easily interfaced to already established (i.e. low-cost) 8-bit system and peripheral chips. Among other, non-technical factors, this contributed to IBM's decision to design a personal computer based on the 8088, despite the presence of 16-bit microprocessors from Motorola, Zilog, National Semiconductor and others, as well as several established 8-bit processors that were also considered. Largely as a result of IBM's position and historical reputation as a strong and dominant computer company, the resulting IBM PC subsequently became preferred to Z80-based CP/M systems, Apple IIs, and other popular computers as the de facto standard for personal computers, thus enabling the 8088 and its successors to dominate this large part of the microprocessor market.
iAPX 432 and the 80286.
Another factor was that the advanced but non-compatible 32-bit Intel 8800 (alias iAPX 432) failed in the market around the time the original IBM-PC was initiated; the new and fast 80286 actually contributed to the disappointment in the performance of the semi-contemporary 8800 during early 1982. (The 80186, initiated simultaneously with the 80286, was intended for embedded systems, and would therefore have had a large market anyway.) The market failure of the 32-bit 8800 was a significant impetus for Intel to continue to develop more advanced 8086-compatible processors instead, such as the 80386 (a 32-bit extension of the well performing 80286).
Other manufacturers.
At various times, companies such as IBM, NEC, AMD, TI, STM, Fujitsu, OKI, Siemens, Cyrix, Intersil, C&T, NexGen, UMC, and DM&P started to design or manufacture x86 processors (CPUs) intended for personal computers as well as embedded systems. Such x86 implementations are seldom simple copies but often employ different internal microarchitectures as well as different solutions at the electronic and physical levels. Quite naturally, early compatible microprocessors were 16-bit, while 32-bit designs were developed much later. For the personal computer market, real quantities started to appear around 1990 with i386 and i486 compatible processors, often named similarly to Intel's original chips. Other companies, which designed or manufactured x86 or x87 processors, include ITT Corporation, National Semiconductor, ULSI System Technology, and Weitek.
Following the fully pipelined i486, Intel introduced the Pentium brand name (which, unlike numbers, could be trademarked) for their new set of superscalar x86 designs; with the x86 naming scheme now legally cleared, other x86 vendors had to choose different names for their x86-compatible products, and initially some chose to continue with variations of the numbering scheme: IBM partnered with Cyrix to produce the 5x86 and then the very efficient 6x86 (M1) and 6x86MX (MII) lines of Cyrix designs, which were the first x86 microprocessors implementing register renaming to enable speculative execution. AMD meanwhile designed and manufactured the advanced but delayed 5k86 (K5), which, "internally", was closely based on AMD's earlier 29K RISC design; similar to NexGen's Nx586, it used a strategy such that dedicated pipeline stages decode x86 instructions into uniform and easily handled micro-operations, a method that has remained the basis for most x86 designs to this day.
Some early versions of these microprocessors had heat dissipation problems. The 6x86 was also affected by a few minor compatibility problems, the Nx586 lacked a floating point unit (FPU) and (the then crucial) pin-compatibility, while the K5 had somewhat disappointing performance when it was (eventually) introduced. Customer ignorance of alternatives to the Pentium series further contributed to these designs being comparatively unsuccessful, despite the fact that the K5 had very good Pentium compatibility and the 6x86 was significantly faster than the Pentium on integer code. AMD later managed to establish itself as a serious contender with the K6 set of processors, which gave way to the very successful Athlon and Opteron. There were also other contenders, such as Centaur Technology (formerly IDT), Rise Technology, and Transmeta. VIA Technologies' energy efficient C3 and C7 processors, which were designed by the Centaur company, have been sold for many years. Centaur's newest design, the VIA Nano, is their first processor with superscalar and speculative execution. It was, perhaps interestingly, introduced at about the same time as Intel's first "in-order" processor since the P5 Pentium, the Intel Atom.
Extensions of word size.
The instruction set architecture has twice been extended to a larger word size. In 1985, Intel released the 32-bit 80386 (later known as i386) which gradually replaced the earlier 16-bit chips in computers (although typically not in embedded systems) during the following years; this extended programming model was originally referred to as "the i386 architecture" (like its first implementation) but Intel later dubbed it IA-32 when introducing its (unrelated) IA-64 architecture.
In 1999-2003, AMD extended this 32-bit architecture to 64 bits and referred to it as x86-64 in early documents and later as AMD64. Intel soon adopted AMD's architectural extensions under the name IA-32e, later using the name EM64T and finally using Intel 64. Microsoft and Sun Microsystems also use term "x64", while many Linux distributions also use the "amd64" term. Microsoft Windows, for example, designates its 32-bit versions as "x86" and 64-bit versions as "x64", while installation files of 64-bit Windows versions are required to be placed into a directory called "AMD64".
Overview.
Basic properties of the architecture.
The x86 architecture is a variable instruction length, primarily "CISC" design with emphasis on backward compatibility. The instruction set is not typical CISC, however, but basically an extended version of the simple eight-bit 8008 and 8080 architectures. Byte-addressing is enabled and words are stored in memory with little-endian byte order. Memory access to unaligned addresses is allowed for all valid word sizes. The largest native size for integer "arithmetic" and memory addresses (or offsets) is 16, 32 or 64 bits depending on architecture generation (newer processors include direct support for smaller integers as well). Multiple scalar values can be handled simultaneously via the SIMD unit present in later generations, as described below. Immediate addressing offsets and immediate data may be expressed as 8-bit quantities for the frequently occurring cases or contexts where a -128..127 range is enough. Typical instructions are therefore 2 or 3 bytes in length (although some are much longer, and some are single-byte).
To further conserve encoding space, most registers are expressed in opcodes using three or four bits, the latter via an opcode prefix in 64-bit mode, while at most one operand to an instruction can be a memory location. However, this memory operand may also be the "destination" (or a combined source "and" destination), while the other operand, the "source", can be either "register" or "immediate". Among other factors, this contributes to a code size that rivals eight-bit machines and enables efficient use of instruction cache memory. The relatively small number of general registers (also inherited from its 8-bit ancestors) has made register-relative addressing (using small immediate offsets) an important method of accessing operands, especially on the stack. Much work has therefore been invested in making such accesses as fast as register accesses, i.e. a one cycle instruction throughput, in most circumstances where the accessed data is available in the top-level cache.
Floating point and SIMD.
A dedicated floating point processor with 80-bit internal registers, the 8087, was developed for the original 8086. This microprocessor subsequently developed into the extended 80387, and later processors incorporated a backward compatible version of this functionality on the same microprocessor as the main processor. In addition to this, modern x86 designs also contain a SIMD-unit (see SSE below) where instructions can work in parallel on (one or two) 128-bit words, each containing 2 or 4 floating point numbers (each 64 or 32 bits wide respectively), or alternatively, 2, 4, 8 or 16 integers (each 64, 32, 16 or 8 bits wide respectively).
The presence of wide SIMD registers means that existing x86 processors can load or store up to 128 bits of memory data in a single instruction and also perform bitwise operations (although not integer arithmetic) on full 128-bits quantities in parallel. Intel's Sandy Bridge processors added the AVX (Advanced Vector Extensions) instructions. widening the SIMD registers to 256 bits. Knights Corner, the architecture used by Intel on their Xeon Phi co-processors, uses 512-bit wide SIMD registers.
Current implementations.
During execution, current x86 processors employ a few extra decoding steps to split most instructions into smaller pieces called micro-operations. These are then handed to a control unit that buffers and schedules them in compliance with x86-semantics so that they can be executed, partly in parallel, by one of several (more or less specialized) execution units. These modern x86 designs are thus superscalar, and also capable of out of order and speculative execution (via register renaming), which means they may execute multiple (partial or complete) x86 instructions simultaneously, and not necessarily in the same order as given in the instruction stream.
When introduced, in the mid-1990s, this method was sometimes referred to as a "RISC core" or as "RISC translation", partly for marketing reasons, but also because these micro-operations share some properties with certain types of RISC instructions. However, "traditional" microcode (used since the 1950s) also inherently shares many of the same properties; the new method differs mainly in that the translation to micro-operations now occurs asynchronously. Not having to synchronize the execution units with the decode steps opens up possibilities for more analysis of the (buffered) code stream, and therefore permits detection of operations that can be performed in parallel, simultaneously feeding more than one execution unit.
The latest processors also do the opposite when appropriate; they combine certain x86 sequences (such as a compare followed by a conditional jump) into a more complex micro-op which fits the execution model better and thus can be executed faster or with less machine resources involved.
Another way to try to improve performance is to cache the decoded micro-operations, so the processor can directly access the decoded micro-operations from a special cache, instead of decoding them again. Intel followed this approach with the Execution Trace Cache feature in their NetBurst Microarchitecture (for Pentium 4 processors) and later in the Decoded Stream Buffer (for Core-branded processors since Sandy Bridge).
Transmeta used a completely different method in their x86 compatible CPUs. They used just-in-time translation to convert x86 instructions to the CPU's native VLIW instruction set. Transmeta argued that their approach allows for more power efficient designs since the CPU can forgo the complicated decode step of more traditional x86 implementations.
Segmentation.
Minicomputers during the late 1970s were running up against the 16-bit 64-KB address limit, as memory had become cheaper. Some minicomputers like the PDP-11 used complex bank-switching schemes, or, in the case of Digital's VAX, redesigned much more expensive processors which could directly handle 32-bit addressing and data. The original 8086, developed from the simple 8080 microprocessor and primarily aiming at very small and inexpensive computers and other specialized devices, instead adopted simple segment registers which increased the memory address width by only 4 bits. By multiplying a 64-KB address by 16, the 20-bit address could address a total of one megabyte (1,048,576 bytes) which was quite a large amount for a small computer at the time. The concept of segment registers was not new to many mainframes which used segment registers to swap quickly to different tasks. In practice, on the x86 it was (is) a much-criticized implementation which greatly complicated many common programming tasks and compilers. However, the architecture soon allowed linear 32-bit addressing (starting with the 80386 in late 1985) but major actors (such as Microsoft) took several years to convert their 16-bit based systems. The 80386 (and 80486) was therefore largely used as a fast (but still 16-bit based) 8086 for many years.
Data and code could be managed within "near" 16-bit segments within 64 KB portions of the total 1 MB address space, or a compiler could operate in a "far" mode using 32-bit codice_1 pairs reaching (only) 1 MB. While that would also prove to be quite limiting by the mid-1980s, it was working for the emerging PC market, and made it very simple to translate software from the older 8008, 8080, 8085, and Z80 to the newer processor. During 1985, the 16-bit segment addressing model was effectively factored out by the introduction of 32-bit offset registers, in the 386 design.
In real mode, segmentation is achieved by shifting the segment address left by 4 bits and adding an offset in order to receive a final 20-bit address. For example, if DS is A000h and SI is 5677h, DS:SI will point at the absolute address DS × 10h + SI = A5677h. Thus the total address space in real mode is 220 bytes, or 1 MB, quite an impressive figure for 1978. All memory addresses consist of both a segment and offset; every type of access (code, data, or stack) has a default segment register associated with it (for data the register is usually DS, for code it is CS, and for stack it is SS). For data accesses, the segment register can be explicitly specified (using a segment override prefix) to use any of the four segment registers.
In this scheme, two different segment/offset pairs can point at a single absolute location. Thus, if DS is A111h and SI is 4567h, DS:SI will point at the same A5677h as above. This scheme makes it impossible to use more than four segments at once. CS and SS are vital for the correct functioning of the program, so that only DS and ES can be used to point to data segments outside the program (or, more precisely, outside the currently executing segment of the program) or the stack.
In protected mode, a segment register no longer contains the physical address of the beginning of a segment, but contain a "selector" that points to a system-level structure called a "segment descriptor". A segment descriptor contains the physical address of the beginning of the segment, the length of the segment, and access permissions to that segment. The offset is checked against the length of the segment, with offsets referring to locations outside the segment causing an exception. Offsets referring to locations inside the segment are combined with the physical address of the beginning of the segment to get the physical address corresponding to that offset.
The segmented nature can make programming and compiler design difficult because the use of near and far pointers affects performance.
Addressing modes.
Addressing modes for 16-bit x86 processors can be summarized by this formula:
Addressing modes for 32-bit address size on 32-bit or 64-bit x86 processors can be summarized by this formula:
Addressing modes for 64-bit code on 64-bit x86 processors can be summarized by this formula:
Instruction relative addressing in 64-bit code (RIP + displacement, where RIP is the instruction pointer register) simplifies the implementation of position-independent code (as used in shared libraries in some operating systems).
The 8086 had 64 KB of 8-bit (or alternatively 32 K-word of 16-bit) I/O space, and a 64 KB (one segment) stack in memory supported by computer hardware. Only words (2 bytes) can be pushed to the stack. The stack grows downwards (toward numerically lower addresses), its bottom being pointed by SS:SP. There are 256 interrupts, which can be invoked by both hardware and software. The interrupts can cascade, using the stack to store the return address.
x86 registers.
"For a description of the general notion of a CPU register, see Processor register."
16-bit.
The original Intel 8086 and 8088 have fourteen 16-bit registers. Four of them (AX, BX, CX, DX) are general-purpose registers (GPRs), although each may have an additional purpose; for example, only CX can be used as a counter with the "loop" instruction. Each can be accessed as two separate bytes (thus BX's high byte can be accessed as BH and low byte as BL). Two pointer registers have special roles: SP (stack pointer) points to the "top" of the stack, and BP (base pointer) is often used to point at some other place in the stack, typically above the local variables (see frame pointer). The registers SI, DI, BX and BP are address registers, and may also be used for array indexing.
Four segment registers (CS, DS, SS and ES) are used to form a memory address. The FLAGS register contains flags such as carry flag, overflow flag and zero flag. Finally, the instruction pointer (IP) points to the next instruction that will be fetched from memory and then executed; this register cannot be directly accessed (read or written) by a program.
The Intel 80186 and 80188 are essentially an upgraded 8086 or 8088 CPU, respectively, with on-chip peripherals added, and they have the same CPU registers as the 8086 and 8088 (in addition to interface registers for the peripherals).
The 8086, 8088, 80186, and 80188 can use an optional floating-point coprocessor, the 8087. The 8087 appears to the programmer as part of the CPU and adds eight 80-bit wide registers, st(0) to st(7), each of which can hold numeric data in one of seven formats: 32-, 64-, or 80-bit floating point, 16-, 32-, or 64-bit (binary) integer, and 80-bit packed decimal integer.
In the Intel 80286, to support protected mode, three special registers hold descriptor table addresses (GDTR, LDTR, IDTR), and a fourth task register (TR) is used for task switching. The 80287 is the floating-point coprocessor for the 80286 and has the same registers as the 8087 with the same data formats.
32-bit.
With the advent of the 32-bit 80386 processor, the 16-bit general-purpose registers, base registers, index registers, instruction pointer, and FLAGS register, but not the segment registers, were expanded to 32 bits. This is represented by prefixing an "E" (for "extended") to the register names in x86 assembly language. Thus, the AX register corresponds to the lowest 16 bits of the new 32-bit EAX register, SI corresponds to the lowest 16 bits of ESI, and so on. The general-purpose registers, base registers, and index registers can all be used as the base in addressing modes, and all of those registers except for the stack pointer can be used as the index in addressing modes.
Two new segment registers (FS and GS) were added. With a greater number of registers, instructions and operands, the machine code format was expanded. To provide backward compatibility, segments with executable code can be marked as containing either 16-bit or 32-bit instructions. Special prefixes allow inclusion of 32-bit instructions in a 16-bit segment or vice versa.
The 80386 had an optional floating-point coprocessor, the 80387; it had eight 80-bit wide registers: st(0) to st(7), like the 8087 and 80287. (The 80386 could also use an 80287 coprocessor.) With the 80486 and all subsequent x86 models, the floating-point processing unit (FPU) was integrated on-chip.
With the Pentium MMX, eight 64-bit MMX integer registers were added (MMX0 to MMX7, which share lower bits with the 80-bit-wide FPU stack). With the Pentium III, a 32-bit Streaming SIMD Extensions (SSE) control/status register (MXCSR) and eight 128-bit SSE floating point registers (XMM0 to XMM7) were added.
64-bit.
Starting with the AMD Opteron processor, the x86 architecture extended the 32-bit registers into 64-bit registers in a way similar to how the 16 to 32-bit extension took place. An R-prefix identifies the 64-bit registers (RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, RFLAGS, RIP), and eight additional 64-bit general registers (R8-R15) were also introduced in the creation of x86-64. However, these extensions are only usable in 64-bit mode, which is one of the two modes only available in long mode. The addressing modes were not dramatically changed from 32-bit mode, except that addressing was extended to 64 bits, virtual addresses are now sign extended to 64 bits (in order to disallow mode bits in virtual addresses), and other selector details were dramatically reduced. In addition, an addressing mode was added to allow memory references relative to RIP (the instruction pointer), to ease the implementation of position-independent code, used in shared libraries in some operating systems.
128-bit.
SIMD registers XMM0–XMM15.
256-bit.
SIMD registers YMM0–YMM15.
512-bit.
SIMD registers ZMM0–ZMM31.
Miscellaneous/special purpose.
x86 processors that have a protected mode, i.e. the 80286 and later processors, also have three descriptor registers (GDTR, LDTR, IDTR) and a task register (TR).
32-bit x86 processors (starting with the 80386) also include various special/miscellaneous registers such as control registers (CR0 through 4, CR8 for 64-bit only), debug registers (DR0 through 3, plus 6 and 7), test registers (TR3 through 7; 80486 only), and model-specific registers (MSRs, appearing with the Pentium).
Purpose.
Although the main registers (with the exception of the instruction pointer) are "general-purpose" in the 32-bit and 64-bit versions of the instruction set and can be used for anything, it was originally envisioned that they be used for the following purposes:
Segment registers:
No particular purposes were envisioned for the other 8 registers available only in 64-bit mode.
Some instructions compile and execute more efficiently when using these registers for their designed purpose. For example, using AL as an accumulator and adding an immediate byte value to it produces the efficient "add to AL" opcode of 04h, whilst using the BL register produces the generic and longer "add to register" opcode of 80C3h. Another example is double precision division and multiplication that works specifically with the AX and DX registers.
Modern compilers benefited from the introduction of the "sib" byte ("scale-index-base byte") that allows registers to be treated uniformly (minicomputer-like). However, using the sib byte universally is inoptimal, as it produces longer encodings than only using it selectively when necessary. (The main benefit of the sib byte is the orthogonality and more powerful addressing modes it provides, which make it possible to save instructions and the use of registers for address calculations such as scaling an index.) Some special instructions lost priority in the hardware design and became slower than equivalent small code sequences. A notable example is the LODSW instruction.
Structure.
Note: The ?PL registers are only available in 64-bit mode.
Note: The ?IL registers are only available in 64-bit mode.
Operating modes.
Real mode.
Real Address mode, commonly called Real mode, is an operating mode of 8086 and later x86-compatible CPUs. Real mode is characterized by a 20-bit segmented memory address space (meaning that only 1 MiB of memory can be addressed—actually, slightly more), direct software access to peripheral hardware, and no concept of memory protection or multitasking at the hardware level. All x86 CPUs in the 80286 series and later start up in real mode at power-on; 80186 CPUs and earlier had only one operational mode, which is equivalent to real mode in later chips. (On the IBM PC platform, direct software access to the IBM BIOS routines is available only in real mode, since BIOS is written for real mode. However, this is not a characteristic of the x86 CPU but of the IBM BIOS design.)
In order to use more than 64 KB of memory, the segment registers must be used. This created great complications for compiler implementors who introduced odd pointer modes such as "near", "far" and "huge" to leverage the implicit nature of segmented architecture to different degrees, with some pointers containing 16-bit offsets within implied segments and other pointers containing segment addresses and offsets within segments. It is technically possible to use up to 256 KB of memory for code and data, with up to 64 KB for code, by setting all four segment registers once and then only using 16-bit offsets (optionally with default-segment override prefixes) to address memory, but this puts substantial
restrictions on the way data can be addressed and memory operands can be combined, and it violates the architectural intent of the Intel designers, which is for separate data items (e.g. arrays, structures, code units) to be contained in separate segments and addressed by their own segment addresses, in new programs that are not ported from earlier 8-bit processors with 16-bit address spaces.
Protected mode.
In addition to real mode, the Intel 80286 supports protected mode, expanding addressable physical memory to 16 MB and addressable virtual memory to 1 GB, and providing protected memory, which prevents programs from corrupting one another. This is done by using the segment registers only for storing an index into a descriptor table that is stored in memory. There are two such tables, the Global Descriptor Table (GDT) and the Local Descriptor Table (LDT), each holding up to 8192 segment descriptors, each segment giving access to 64 KB of memory. In the 80286, a segment descriptor provides a 24-bit base address, and this base address is added to a 16-bit offset to create an absolute address. The base address from the table fulfills the same role that the literal value of the segment register fulfills in real mode; the segment registers have been converted from direct registers to indirect registers. Each segment can be assigned one of four ring levels used for hardware-based computer security. Each segment descriptor also contains a segment limit field which specifies the maximum offset that may be used with the segment. Because offsets are 16 bits, segments are still limited to 64 KB each in 80286 protected mode.
Each time a segment register is loaded in protected mode, the 80286 must read a 6-byte segment descriptor from memory into an a set of hidden internal registers. Therefore, loading segment registers is much slower in protected mode than in real mode, and changing segments very frequently is to be avoided. Actual memory operations using protected mode segments are not slowed much because the 80286 and later have hardware to check the offset against the segment limit in parallel with instruction execution.
The Intel 80386 extended offsets and also the segment limit field in each segment descriptor to 32 bits, enabling a segment to span the entire memory space. It also introduced support in protected mode for paging, a mechanism making it possible to use paged virtual memory (with 4 KB page size). Paging allows the CPU to map any page of the virtual memory space to any page of the physical memory space. To do this, it uses additional mapping tables in memory called page tables. Protected mode on the 80386 can operate with paging either enabled or disabled; the segmentation mechanism is always active and generates virtual addresses that are then mapped by the paging mechanism if it is enabled. The segmentation mechanism can also be effectively disabled by setting all segments to have a base address of 0 and size limit equal to the whole address space; this also requires a minimally-sized segment descriptor table of only four descriptors (since the FS and GS segments need not be used).
Paging is used extensively by modern multitasking operating systems. Linux, 386BSD and Windows NT were developed for the 386 because it was the first Intel architecture CPU to support paging and 32-bit segment offsets. The 386 architecture became the basis of all further development in the x86 series.
x86 processors that support protected mode boot into real mode for backward compatibility with the older 8086 class of processors. Upon power-on (a.k.a. booting), the processor initializes in real mode, and then begins executing instructions. Operating system boot code, which might be stored in ROM, may place the processor into the protected mode to enable paging and other features. The instruction set in protected mode is backward compatible with the one used in real mode.
Virtual 8086 mode.
There is also a sub-mode of operation in 32-bit protected mode (a.k.a. 80386 protected mode) called "virtual 8086 mode", also known as "V86 mode". This is basically a special hybrid operating mode that allows real mode programs and operating systems to run while under the control of a protected mode supervisor operating system. This allows for a great deal of flexibility in running both protected mode programs and real mode programs simultaneously. This mode is exclusively available for the 32-bit version of protected mode; it does not exist in the 16-bit version of protected mode, or in long mode.
Long mode.
In the mid 1990s, it was obvious that the 32-bit address space of the x86 architecture was limiting its performance in applications requiring large data sets. A 32-bit address space would allow the processor to directly address only 4 GB of data, a size surpassed by applications such as video processing and database engines. Using 64-bit addresses, it is possible to directly address 16 EiB of data, although most 64-bit architectures do not support access to the full 64-bit address space; for example, AMD64 supports only 48 bits from a 64-bit address, split into four paging levels.
In 1999, AMD published a (nearly) complete specification for a 64-bit extension of the x86 architecture which they called "x86-64" with claimed intentions to produce. That design is currently used in almost all x86 processors, with some exceptions intended for embedded systems.
Mass-produced "x86-64" chips for the general market were available four years later, in 2003, after the time was spent for working prototypes to be tested and refined; about the same time, the initial name "x86-64" was changed to "AMD64". The success of the AMD64 line of processors coupled with lukewarm reception of the IA-64 architecture forced Intel to release its own implementation of the AMD64 instruction set. Intel had previously implemented support for AMD64 but opted not to enable it in hopes that AMD would not bring AMD64 to market before Itanium's new IA-64 instruction set was widely adopted. It branded its implementation of AMD64 as "EM64T", and later re-branded it "Intel 64".
In its literature and product version names, Microsoft and Sun refer to AMD64/Intel 64 collectively as "x64" in the Windows and Solaris operating systems respectively. Linux distributions refer to it either as "x86-64", its variant "x86_64", or "amd64". BSD systems use "amd64" while Mac OS X uses "x86_64".
Long mode is mostly an extension of the 32-bit instruction set, but unlike the 16–to–32-bit transition, many instructions were dropped in the 64-bit mode. This does not affect actual binary backward compatibility (which would execute legacy code in other modes that retain support for those instructions), but it changes the way assembler and compilers for new code have to work.
This was the first time that a "major" extension of the x86 architecture was initiated and originated by a manufacturer other than Intel. It was also the first time that Intel accepted technology of this nature from an outside source.
Extensions.
Floating point unit.
Early x86 processors could be extended with floating-point hardware in the form of a series of floating point numerical co-processors with names like 8087, 80287 and 80387, abbreviated x87. This was also known as the NPX ("Numeric Processor eXtension"), an apt name since the coprocessors, while used mainly for floating-point calculations, also performed integer operations on both binary and decimal formats. With very few exceptions, the 80486 and subsequent x86 processors then integrated this x87 functionality on chip which made the x87 instructions a de facto integral part of the x86 instruction set.
Each x87 register, known as ST(0) through ST(7), is 80 bits wide and stores numbers in the IEEE floating-point standard double extended precision format. These registers are organized as a stack with ST(0) as the top. This was done in order to conserve opcode space, and the registers are therefore randomly accessible only for either operand in a register-to-register instruction; ST0 must always be one of the two operands, either the source or the destination, regardless of whether the other operand is ST(x) or a memory operand. However, random access to the stack registers can be obtained through an instruction which exchanges any specified ST(x) with ST(0).
The operations include arithmetic and transcendental functions, including trigonometric and exponential functions, as well as instructions that load common constants (such as 0; 1; e, the base of the natural logarithm; log2(10); and log10(2)) into one of the stack registers. While the integer capability is often overlooked, the x87 can operate on larger integers with a single instruction than the 8086, 80286, 80386, or any x86 CPU without to 64-bit extensions can, and repeated integer calculations even on small values (e.g. 16-bit) can be accelerated by executing integer instructions on the x86 CPU and the x87 in parallel. (The x86 CPU keeps running while the x87 coprocessor calculates, and the x87 sets a signal to the x86 when it is finished or interrupts the x86 if it needs attention because of an error.)
MMX.
MMX is a SIMD instruction set designed by Intel and introduced in 1997 for the Pentium MMX microprocessor. The MMX instruction set was developed from a similar concept first used on the Intel i860. It is supported on most subsequent IA-32 processors by Intel and other vendors. MMX is typically used for video processing (in multimedia applications, for instance).
MMX added 8 new "registers" to the architecture, known as MM0 through MM7 (henceforth referred to as "MMn"). In reality, these new "registers" were just aliases for the existing x87 FPU stack registers. Hence, anything that was done to the floating point stack would also affect the MMX registers. Unlike the FP stack, these MMn registers were fixed, not relative, and therefore they were randomly accessible. The instruction set did not adopt the stack-like semantics so that existing operating systems could still correctly save and restore the register state when multitasking without modifications.
Each of the MMn registers are 64-bit integers. However, one of the main concepts of the MMX instruction set is the concept of "packed data types", which means instead of using the whole register for a single 64-bit integer (quadword), one may use it to contain two 32-bit integers (doubleword), four 16-bit integers (word) or eight 8-bit integers (byte). Given that the MMX's 64-bit MMn registers are aliased to the FPU stack and each of the floating point registers are 80 bits wide, the upper 16 bits of the floating point registers are unused in MMX. These bits are set to all ones by any MMX instruction, which correspond to the floating point representation of NaNs or infinities.
3DNow!
In 1997 AMD introduced 3DNow!. The introduction of this technology coincided with the rise of 3D entertainment applications and was designed to improve the CPU's vector processing performance of graphic-intensive applications. 3D video game developers and 3D graphics hardware vendors use 3DNow! to enhance their performance on AMD's K6 and Athlon series of processors.
3DNow! was designed to be the natural evolution of MMX from integers to floating point. As such, it uses exactly the same register naming convention as MMX, that is MM0 through MM7. The only difference is that instead of packing integers into these registers, two single precision floating point numbers are packed into each register. The advantage of aliasing the FPU registers is that the same instruction and data structures used to save the state of the FPU registers can also be used to save 3DNow! register states. Thus no special modifications are required to be made to operating systems which would otherwise not know about them.
SSE.
In 1999, Intel introduced the Streaming SIMD Extensions (SSE) instruction set, following in 2000 with SSE2. The first addition allowed offloading of basic floating-point operations from the x87 stack and the second made MMX almost obsolete and allowed the instructions to be realistically targeted by conventional compilers. Introduced in 2004 along with the "Prescott" revision of the Pentium 4 processor, SSE3 added specific memory and thread-handling instructions to boost the performance of Intel's HyperThreading technology. AMD licensed the SSE3 instruction set and implemented most of the SSE3 instructions for its revision E and later Athlon 64 processors. The Athlon 64 does not support HyperThreading and lacks those SSE3 instructions used only for HyperThreading.
SSE discarded all legacy connections to the FPU stack. This also meant that this instruction set discarded all legacy connections to previous generations of SIMD instruction sets like MMX. But it freed the designers up, allowing them to use larger registers, not limited by the size of the FPU registers. The designers created eight 128-bit registers, named XMM0 through XMM7. ("Note": in AMD64, the number of SSE XMM registers has been increased from 8 to 16.) However, the downside was that operating systems had to have an awareness of this new set of instructions in order to be able to save their register states. So Intel created a slightly modified version of Protected mode, called Enhanced mode which enables the usage of SSE instructions, whereas they stay disabled in regular Protected mode. An OS that is aware of SSE will activate Enhanced mode, whereas an unaware OS will only enter into traditional Protected mode.
SSE is a SIMD instruction set that works only on floating point values, like 3DNow!. However, unlike 3DNow! it severs all legacy connection to the FPU stack. Because it has larger registers than 3DNow!, SSE can pack twice the number of single precision floats into its registers. The original SSE was limited to only single-precision numbers, like 3DNow!. The SSE2 introduced the capability to pack double precision numbers too, which 3DNow! had no possibility of doing since a double precision number is 64-bit in size which would be the full size of a single 3DNow! MMn register. At 128 bits, the SSE XMMn registers could pack two double precision floats into one register. Thus SSE2 is much more suitable for scientific calculations than either SSE1 or 3DNow!, which were limited to only single precision. SSE3 does not introduce any additional registers.
Physical Address Extension (PAE).
Physical Address Extension or PAE was first added in the Intel Pentium Pro, to allow an additional 4 bits of physical addressing in 32-bit protected mode. The size of memory in Protected mode is usually limited to 4 GB. Through tricks in the processor's page and segment memory management systems, x86 operating systems may be able to access more than 32-bits of address space, even without the switchover to the 64-bit paradigm. This mode does not change the length of segment offsets or linear addresses; those are still only 32 bits.
x86-64.
By the 2000s it had become obvious that 32-bit x86 processors' limitations in memory addressing were an obstacle to their utilization in high-performance computing clusters and powerful desktop workstations. The aged 32-bit x86 was competing with much more advanced 64-bit RISC architectures which could address much more memory. Intel and the whole x86 ecosystem needed 64-bit memory addressing if x86 was to survive the 64-bit computing era, as workstation and desktop software applications were soon to start hitting the limitations present in 32-bit memory addressing. However, Intel felt that it was the right time to make a bold step and use the transition to 64-bit desktop computers for a transition away from the x86 architecture in general, an experiment which ultimately failed.
In 2001, Intel attempted to introduce a non-x86 64-bit architecture named IA-64 in its Itanium processor, initially aiming for the high-performance computing market, hoping that it would eventually replace the 32-bit x86. While IA-64 was incompatible with x86, the Itanium processor did provide emulation capabilities for translating x86 instructions into IA-64, but this affected the performance of x86 programs so badly that it was rarely, if ever, actually useful to the users: programmers should rewrite x86 programs for the IA-64 architecture or their performance on Itanium would be orders of magnitude worse than on a true x86 processor. The market rejected the Itanium processor since it broke backward compatibility and preferred to continue using x86 chips, and very few programs were rewritten for IA-64.
AMD decided to take another path toward 64-bit memory addressing, making sure backward compatibility would not suffer. In April 2003, AMD released the first x86 processor with 64-bit physical memory address registers, capable of addressing much more than 4 GB of memory using the new x86-64 extension (also known as AMD64 or x64) which introduced the long mode. The 64-bit extensions to the x86 architecture were enabled only in long mode, therefore 32-bit and 16-bit applications could simply continue using an AMD64 processor in protected or other modes, without even the slightest sacrifice of performance and with full compatibility back to the original instructions of the 16-bit Intel 8086.(p13–14) The market responded positively, adopting the 64-bit AMD processors for both high-performance applications and business or home computers.
Seeing the market rejecting the incompatible Itanium processor and Microsoft supporting AMD64, Intel had to respond and introduced its own x86-64 processor in July 2004. As a result, the Itanium processor with its IA-64 instruction set is rarely used today and x86, through its x86-64 incarnation, is still the dominant CPU architecture in non-embedded computers.
x86-64 also introduced the NX bit, which offers some protection against security bugs caused by buffer overruns.
As a result of AMD's 64-bit contribution to the x86 lineage and its subsequent acceptance by Intel, the 64-bit RISC architectures ceased to be a threat to the x86 ecosystem and almost disappeared from the workstation market. x86-64 began to be utilized in powerful supercomputers (in its AMD Opteron and Intel Xeon incarnations), a market which was previously the natural habitat for 64-bit RISC designs (such as the IBM POWER microprocessors or SPARC processors). The great leap toward 64-bit computing and the maintenance of backward compatibility with 32-bit and 16-bit software enabled the x86 architecture to become an extremely flexible platform today, with x86 chips being utilized from small low-power systems (for example, Intel Quark and Intel Atom) to fast gaming desktop computers (for example, Intel Core i7 and AMD FX), and even dominate large supercomputing clusters, effectively leaving only the ARM 32-bit and 64-bit RISC architecture as a competitor in the smartphone and tablet market.
Virtualization.
Prior to 2005 x86 architecture processors were unable to meet the Popek and Goldberg requirements - a specification for virtualization created in 1974 by Gerald J. Popek and Robert P. Goldberg. However both commercial and open source x86 virtualization hypervisor products were developed using software-based virtualization. Commercial systems included VMware ESX, VMware Workstation, Parallels, Microsoft Hyper-V Server, and Microsoft Virtual PC; while open source systems included QEMU/KQEMU, VirtualBox, and Xen.
The introduction of the AMD-V and Intel VT-x instruction sets in 2005 allowed x86 processors to meet the Popek and Goldberg virtualization requirements.
Further reading.
</dl>

</doc>
<doc id="34199" url="http://en.wikipedia.org/wiki?curid=34199" title="Xiangqi">
Xiangqi

Xiangqi (Chinese: 象棋,  "Xiàngqí"), also called Chinese chess, is a strategy board game for two players. It is one of the most popular board games in China, and is in the same family as Western (or international) chess, chaturanga, shogi, Indian chess and janggi. Besides China and areas with significant ethnic Chinese communities, xiangqi ("cờ tướng") is also a popular pastime in Vietnam.
The game represents a battle between two armies, with the object of capturing the enemy's general (king). Distinctive features of xiangqi include the cannon ("pao"), which must jump to capture; a rule prohibiting the generals from facing each other directly; areas on the board called the "river" and "palace", which restrict the movement of some pieces (but enhance that of others); and placement of the pieces on the intersections of the board lines, rather than within the squares.
Board.
Xiangqi is played on a board nine lines wide and ten lines long. As in the game Go ("Wéiqí" 圍棋), the pieces are placed on the intersections, which are known as "points". The vertical lines are known as "files", and the horizontal lines are known as "ranks".
Centered at the first to third and eighth to tenth ranks of the board are two zones, each three points by three points, demarcated by two diagonal lines connecting opposite corners and intersecting at the center point. Each of these areas is known as 宮  , a "palace" or "fortress".
Dividing the two opposing sides, between the fifth and sixth ranks, is 河 "hé", the "river". The river is often marked with the phrases 楚河  , meaning "Chu River", and 漢界 (in Traditional Chinese),  , meaning "Han border", a reference to the Chu-Han War. Although the river provides a visual division between the two sides, only two pieces are affected by its presence: soldier pieces have an enhanced move after crossing the river, and elephant pieces cannot cross it. The starting points of the soldiers and cannons are usually, but not always, marked with small crosses.
Rules.
The pieces start in the position shown in the diagram above. Which player moves first has varied throughout history and from one part of China to another. Different xiangqi books advise either that the black or red side moves first. Some books refer to the two sides as north and south; which direction corresponds to which color also varies from source to source. Generally, Red moves first in most modern tournaments.
Each player in turn moves one piece from the point it occupies to another point. Pieces are generally not permitted to move through a point occupied by another piece. A piece can be moved onto a point occupied by an enemy piece, in which case the enemy piece is captured and removed from the board. A player cannot capture one of his own pieces. Pieces are never promoted (converted into other pieces), although the soldier is able to move sideways after it crosses the river. Almost all pieces capture using their normal moves, while the cannon has a special capture move described below.
The game ends when one player captures the other's general. When the general is in danger of being captured by the enemy player on his next move, the enemy player has "delivered a check" (, abbreviated ( )), and the general is "in check". A check should be announced. If the general's player can make no move to prevent the general's capture, the situation is called "checkmate" (). Unlike chess, in which a stalemate is a draw, in xiangqi, a player with no legal moves left loses.
In xiangqi, a player—often with material or positional disadvantage—may attempt to check or chase pieces in a way such that the moves fall in a cycle, forcing the opponent to draw the game. The following special rules are used to make it harder to draw the game by endless checking and chasing, regardless of whether the positions of the pieces are repeated or not:
Different sets of rules set different limits on what is considered perpetual. For example, club xiangqi rules allow a player to check or chase six consecutive times using one piece, twelve times using two pieces, and eighteen times using three pieces before considering the action perpetual.
The above rules to prevent perpetual checking and chasing, while popular, are not the only ones; there are numerous end game situations.
Pieces.
The two players' pieces are usually colored red and black. Pieces are flat circular disks labeled or engraved with a Chinese character identifying the piece type, and in a color indicating which player has ownership. The black pieces are marked with somewhat different characters from the corresponding red pieces.
In mainland China, most sets still use traditional Chinese characters (as opposed to simplified Chinese characters). Modern pieces are usually plastic, though some sets are wooden, and more expensive sets may use jade. In more ancient times, many sets were simple unpainted woodcarvings; thus, to distinguish between pieces of the two sides, most corresponding pieces used characters that were similar but varied slightly. This practice may have originated in situations where there was only one material available to make the pieces from and no coloring material available to distinguish the opposing armies. The oldest xiangqi piece found to date is a 俥 (chariot) piece. It is kept in the Henan Provincial Museum.
General.
Generals are labelled with the Chinese character 將 (trad.) / 将 (simp.)   ("general") on the black side and 帥 (trad.) / 帅 (simp.)   ("marshal") on the red side.
The general starts the game at the midpoint of the back edge, within the palace. The general may move and capture one point orthogonally. The two generals may not face each other in the same file with no intervening pieces.
If that happens, the 飛將 ("flying general") move may be executed, in which one general may cross the board to capture the enemy general. In practice, this rule is only used to enforce checkmate. The general may not leave the palace except when executing the flying general move.
The Indian name "king" for this piece was changed to "general" because China's rulers objected to their royal titles being given to game pieces.
Advisor.
Advisors (also known as guards or ministers, and less commonly as assistants, mandarins, or warriors) are labelled 士   ("scholar", "gentleman", "officer") for Black and 仕   ("scholar", "official") for Red. Rarely, sets use the character 士 for both colors.
The advisors start on either side of the general. They move and capture one point diagonally and may not leave the palace, which confines them to five points on the board. The advisor is probably derived from the mantri in chaturanga, like the queen in Western chess.
Elephant.
Elephants are labeled 象 "xiàng" ("elephant") for Black and 相 "xiàng" ("minister") for Red. They are located next to the advisors. These pieces move and capture exactly two points diagonally and may not jump over intervening pieces; the move is described as being like the character 田 "Tián" ("field"). If an elephant cannot move due to a diagonally adjacent piece, it is known as "blocking the elephant's eye" (塞象眼).
Elephants may not cross the river, and serve as defensive pieces. Because an elephant's movement is restricted to just seven board positions, it can be easily trapped or threatened. The two elephants are often used to defend each other.
The Chinese characters for "minister" and "elephant" are homophones in Mandarin ( ) and both have alternative meanings as "appearance" or "image". However, both are referred to as elephants in the game.
Horse.
Horses are labelled 馬   for Black and 傌   for Red in sets marked with Traditional Chinese characters and 马 "mǎ" for both Black and Red in sets marked with Simplified Chinese characters. Some traditional sets use 馬 for both colors. Horses begin the game next to the elephants, on their outside flanks. A horse moves and captures one point orthogonally and then one point diagonally away from its former position, a move which is traditionally described as being like the character 日 "Rì". The horse does not jump as the knight does in Western chess, and can be blocked by a piece located one point horizontally or vertically adjacent to it. Blocking a horse is called "hobbling the horse's leg" (蹩馬腿). The diagram on the left illustrates the horse's movement.
Since horses can be blocked, it is sometimes possible to trap the opponent's horse. It is possible for one player's horse to have an asymmetric attack advantage if an opponent's horse is blocked, as seen in the diagram on the right.
Chariot.
Chariots are labelled 車 for Black and 俥 for Red in sets marked with Traditional Chinese characters and 车 for both Black and Red in sets marked with Simplified Chinese characters. Some traditional sets use 車 for both colors. In the context of Chinese Chess, all of these characters are pronounced as  , (instead of the common pronunciation "chē"). The chariot moves and captures any distance orthogonally, but may not jump over intervening pieces. The chariots begin the game on the points at the corners of the board. The chariot is often considered to be the strongest piece in the game due to its freedom of movement and lack of restrictions.
The chariot is sometimes known as the rook by English-speaking players, since it is like the rook in Western chess. Chinese players (and others) often call this piece a car, since that is one modern meaning of the character 車.
Cannon.
Cannons are labelled 砲   ("catapult") for Black and "pào" ("cannon") for Red. The names are homophones, though sometimes 炮 is used for both Red and Black. The 石 "shí" radical of 砲 means "stone", and the 火 "huǒ" radical of 炮 means "fire". Both colors' pieces are normally referred to as cannons in English. The black piece is sometimes labelled .
Each player has two cannons, which start on the row behind the soldiers, two points in front of the horses. Cannons move like chariots, any distance orthogonally without jumping, but can only capture by jumping a single piece, friend or foe, along the path of attack. The piece over which the cannon jumps is called the 炮臺 (trad.) / 炮台 (simp.) "pào tái" ("cannon platform") or "screen". Any number of unoccupied spaces, including none, may exist between the cannon, screen, and the piece to be captured. Cannons can be exchanged for horses immediately from their starting positions.
Soldier.
Each side has five soldiers, labelled 卒   ("pawn" or "private") for Black and 兵   ("soldier") for Red. Soldiers begin the game located on every other point one row back from the edge of the river. They move and capture by advancing one point. Once they have crossed the river, they may also move and capture one point horizontally. Soldiers cannot move backward, and therefore cannot retreat; after advancing to the last rank of the board, however, a soldier may still move sideways at the enemy's edge. The soldier is sometimes called the "pawn" by English-speaking players, due to the pieces' similarities.
Approximate relative values of the pieces.
These approximate values do not take into account the position of the piece in question (except the soldier in a general sense), the positions of other pieces on the board, or the number of pieces remaining.
Notation.
There are several types of notation used to record xiangqi games. In each case the moves are numbered and written with the same general pattern.
It is clearer but not required to write each move pair on a separate line.
System 1.
The book "The Chess of China" describes a move notation method in which the ranks of the board are numbered 1 to 10 from closest to farthest away, followed by a digit 1 to 9 for files from right to left. Both values are relative to the moving player. Moves are then indicated as follows:
codice_1
Thus, the most common opening in the game would be written as:
System 2.
A notation system partially described in "A Manual of Chinese Chess" and used by several computer software implementations describes moves in relative terms as follows:
codice_2
The file numbers are counted from each player's right to each player's left.
In case there are two identical pieces in one file, symbols + (front) and – (rear) are used instead of former file number.
Direction of movement is indicated via an operator symbol. A plus sign is used to indicate forward movement. A minus sign is used to indicate backwards movement. A dot or period or equal sign is used to indicate horizontal or lateral movement. For a piece that moves diagonally (such as the horse or elephant), the plus or minus sign is used rather than the period.
Thus, the most common opening in the game would be written as:
System 3.
This system is unofficial and principally used by Western players. It is similar to algebraic notation for Western chess. Letters are used for files and numbers for ranks. File "a" is on Red's left and rank "1" is nearest to Red. A point's designation does not depend on which player moves; for both sides "a1" is the lowest left point from Red's side.
codice_3
Pieces are abbreviated as in notation system 2, except that no letter is used for the soldier.
Former position is only indicated if necessary to distinguish between two identical pieces that could have made the move. If they share the same file, indicate which rank moves; if they share the same rank, indicate which file moves. If they share neither rank nor file, then the file is indicated.
Capture is indicated by "x". No symbol is used to indicate a non-capturing move.
Check is indicated by "+", double check by "++", triple check by "+++", and quadruple check by "++++". Checkmate is indicated by "#".
For analysis purposes, bad moves are indicated by "?" and good moves by "!". These can be combined if the analysis is uncertain ("!?" might be either but is probably good; "?!" is probably bad) or repeated for emphasis ("??" is a disaster).
Thus, the most common opening in the game would be written as:
An example of a brief game ("the early checkmate") is:
Gameplay.
Because of the size of the board and the low number of long-range pieces, there is a tendency for the battle to focus on a particular area of the board.
Tactics.
Xiangqi involves several tactics common to games in the chess family. Some common ones are briefly discussed here.
Usually, soldiers do not support each other, because from the initial position it takes a minimum of five moves of a soldier to allow mutual protection between two of them.
The chariots, as the most valuable pieces, are not normally lined up together, as it risks losing one chariot to an enemy's inferior piece. Depending on the situation, it may be advantageous to position a chariot at one of the corners on the enemy's side of the board, where it is difficult to dislodge and able to threaten the enemy general.
It is common to use cannons independently to control particular ranks and files. Using a cannon to control the middle file is often considered vital strategy, because it locks pieces such as the advisors and elephants in certain positions to prevent a check. The two files adjacent to the middle file are also considered important and horses and chariots can be used to push for checkmate there. Two cannons on the same file is also a powerful formation, as the rear cannon can threaten the general, but moving a piece in front of the cannons to block will fail, because the front cannon can then attack the general.
A common defensive configuration is to leave the general at its starting position, deploy one advisor and one elephant on the two points directly in front of the general, and to leave the other advisor and elephant in their starting positions, to the side of the general. In this setup, the advisor-elephant pairs support each other, and the general is immune from attacks by cannons. Losing any of the pieces makes the general vulnerable to cannon, and the setup may need to be abandoned. The defender may move advisors or elephants away from the general, or even sacrifice them intentionally, to ward off attack by a cannon.
Openings.
Since the left and right flanks of the starting setup are symmetrical, it is customary to make the first move on the right flank. Starting on the left flank is considered needlessly confusing.
The most common opening is to move the cannon to the central column, an opening known as 當頭炮 (trad.) / 当头炮 (simp.) "dāng tóu pào" ("appropriate start cannon"). The most common reply is to advance the horse on the same flank. Together, this move-and-response is known by the rhyme 當頭炮，馬來跳 (trad.) / 当头炮，马来跳 (simp.)  . The notation for this is "1. 炮 (32)–35, 馬 (18)–37", "1. C2.5 H8+7", or "1. Che3 Hg8" (diagram at right).
The most common second move is 出車 (trad.) / 出车 (simp.) "chū jū" ("chariot sortie"), in which the first player moves a chariot forward one space. The most common reply is to move the right advisor diagonally, 上士 "shàng shì".
This prevents a series of events that leads to the first player quickly checkmating the second.
Less common first moves include moving an elephant to the central column, advancing the soldier on the third or seventh file, moving a horse forward, and moving either cannon behind the second soldier from the left or right.
General advice for the opening includes rapid development of at least one chariot, as it is the most powerful piece with a long attack range. There is a saying that only a poor player does not move a chariot in the first three moves. Another possible start is to develop one horse to the edge of the board to avoid being blocked by one's own unmovable soldiers. Usually, at least one horse should be moved to the middle.
History.
The commonly accepted theory, developed by Harold James Ruthven Murray, author of "A History of Chess", is that games from the chess family originated in India. From there, they spread to the rest of the world, and one offshoot evolved into modern xiangqi in China, possibly influenced by other games already played there.
References to a game called "xiangqi" date back to the Warring States period; according to the first century BC text "Shuo yuan" (說苑), it was one of Lord Mengchang of Qi's interests. Emperor Wu of Northern Zhou wrote a book in AD 569 called "Xiang Jing". It is believed to have described the rules of an astronomically themed game called xiangqi or xiangxi (象戲). The word "xiàngqí" 象棋 is usually translated as "elephant game" or "figure game", because the Chinese character 象 means "elephant" and "figure"; it originated as a stylized drawing of an elephant, and was used to write a word meaning "figure", likely because the two words were pronounced the same. But the name can also mean "constellation game", and sometimes the xiàngqí board's "river" is called the "heavenly river", which may mean the Milky Way.
For these reasons, Murray theorized that "in China [chess] took over the board and name of a game called 象棋 in the sense of 'Astronomical Game', which represented the apparent movements of naked-eye-visible astronomical objects in the night sky, and that the earliest Chinese references to 象棋 meant the Astronomical Game and not Chinese chess". Previous games called xiàngqí may have been based on the movements of sky objects. However, the connection between 象 and astronomy is marginal, and arose from constellations being called "figures" in astronomical contexts where other meanings of "figure" were less likely; this usage may have led some ancient Chinese authors to theorize that the game 象棋 started as a simulation of astronomy.
To support his argument, Murray quoted an old Chinese source that says that in the older xiangqi (which modern xiangqi may have taken some of its rules from) the game pieces could be shuffled, which does not happen in the modern chess-style xiangqi. Murray also wrote that in ancient China there was more than one game called xiangqi.
An alternative hypothesis to Murray's is that xiangqi was patterned after the array of troops in the Warring States era. David H. Li, for example, argues that the game was developed by Han Xin in the winter of 204 BC-203 BC to prepare for an upcoming battle. His theories have been questioned by other chess researchers, however. The earliest description of the game's rules appears in the story "Cén Shùn" (岑順) in the collection "Xuanguai lu" (玄怪錄), written in the middle part of the Tang dynasty.
With the economic and cultural development during the Qing Dynasty, xiangqi entered a new stage. Many different schools of circles and players came into prominence. With the popularization of xiangqi, many books and manuals on the techniques of playing the game were published. They played an important role in popularizing xiangqi and improving the techniques of play in modern times. A Western-style "Encyclopedia of Chinese Chess Openings" was written in 2004.
Modern play.
Tournaments and leagues.
Although xiangqi has its origin in Asia, there are xiangqi leagues and clubs all over the world. Each European nation generally has its own governing league; for example, in Britain, xiangqi is regulated by the United Kingdom Chinese Chess Association. Asian countries also have nationwide leagues, such as the Malaysia Chinese Chess Association.
In addition, there are several international federations and tournaments. The Chinese Xiangqi Association hosts several tournaments every year, including the Yin Li and Ram Cup Tournaments. Other organizations include the Asian Xiangqi Federation and a World Xiangqi Federation, which hosts tournaments and competitions bi-annually, with most limited to players from member nations.
Rankings.
The Asian Xiangqi Federation (AXF) and its corresponding member associations rank players in a format similar to the Elo rating system of chess. According to the XiangQi DataBase, the top-ranking female and male players in China, as of June 2012, were Tang Dan and Jiang Chuan, with ratings of 2529 and 2667, respectively. Other strong players include Zhao GuanFang (female), Xu Yinchuan (male), Lu Qin (male), and Wang LinNa (female).
The Asian Xiangqi Federation also bestows the title of grandmaster to select individuals around the world who have excelled at xiangqi or made special contributions to the game. There are no specific criteria for becoming a grandmaster and the list of grandmasters was fewer than a hundred people in September 1996. The titles of grandmaster is bestowed by bodies such as the AXF and the Chinese Xiangqi Association (CXA).
Computers.
The game-tree complexity of xiangqi is approximately 10150; in 2004 it was projected that a human top player will be defeated before 2010. Xiangqi is one of the more popular competitions at the annual Computer Olympiad.
Computer programs for playing xiangqi show the same development trend as has occurred for international chess: they are usually console applications (called engines) which communicate their moves in text form through some standard protocol. For displaying the board graphically, they then rely on a separate Graphical User Interface (GUI). Through such standardization, many different engines can be used through the same GUI, which can also be used for automated play of different engines against each other. Popular protocols are UCI (Universal Chess Interface), UCCI (Universal Chinese Chess Interface), Qianhong (QH) protocol, and WinBoard/XBoard (WB) protocol (the latter two named after the GUIs that implemented them). There now exist many dozens of xiangqi engines supporting one or more of these protocols, including some commercial engines.
Variations.
Using a standard xiangqi board and pieces.
Blitz Chess Each player only has around 5–10 minutes each, depending on the exact rules.
Supply Chess Similar to the Western chess variant Bughouse Chess, this variant features the ability to re-deploy captured pieces, similar to a rule in shogi. Four players play as two-person teams in two side-by-side games. One teammate plays Black and other plays Red. Any piece obtained by capturing the opponent's piece is given to the teammate for use in the other game. These pieces can be deployed by the teammate to give him an advantage over the other player, so long as the piece starts on the player's own side of the board and does not cause the opponent to be in check.
Formation One player's pieces are jumbled up, then placed randomly on one side of the river, except for the generals and advisors, which must be at their usual positions, and the elephants, which must start at two of the seven points they can normally reach. The other player's pieces are set up to mirror the first's. All other rules are the same.
Banqi This variation is more well known in Hong Kong than in mainland China. It uses the xiangqi pieces and board, but does not follow any of its rules, bearing more of a resemblance to the western game Stratego as well as the Chinese game Luzhanqi.
Using a special board and/or pieces.
There are many versions of three-player xiangqi, or "san xiangqui", all played on special boards.
San Guo Qi "Game of the Three Kingdoms" is played on a special hexagonal board with three xiangqi armies (red, blue, and green) vying for dominance. A Y-shaped river divides the board into three gem-shaped territories, each containing the grid found on one side of a xiangqi board, but distorted to make the game playable by three people. Each player has eighteen pieces: the sixteen of regular xiangqi, plus two new ones that stand on the same rank as the cannons. The new pieces have different names depending on their side: "huo" ("fire") for Red, "qi" ("flag") for Blue, and "feng" ("wind") for Green. They move two spaces orthogonally, then one space diagonally. The generals each bear the name of a historical Chinese kingdom—Shu for Red, Wei for Blue, and Wu for Green—from China's Three Kingdoms period. It is likely that San Guo Qi first appeared under the Southern Song Dynasty (960–1279).
San You Qi "Three Friends Chess" was invented by Zheng Jinde from Shexian in the Anhui province during the reign of the Kangxi Emperor of Qing Dynasty (1661–1722). It is played on a Y-shaped board with a full army of xiangqi pieces set up at the end of each of the board's three wide radii. In the center of the board sits a triangular zone with certain features, such as ocean, mountain, or city walls, each of which is impassable by certain pieces. Two of an army's five soldiers are replaced by new pieces called "huo" ("fire") pieces, which move one space diagonally forward. Two "qi" ("flag") pieces are positioned on the front corners of the palace; they move two spaces forward inside their own camp, and then one space in any direction inside an enemy camp.
Sanrenqi "Three Men Chess" is a riverless, commercial variant played on a cross-shaped board with some special rules, including a fourth, neutral country called "Han." Han has three Chariots, one Cannon, and one General named "Emperor Xian of Han", but these pieces do not move and do not belong to any of the players until a certain point in the game when two players team up against the third player. At that point the third player gets to also control Han.
Si Guo Qi "Four Kingdoms Chess" is also played on a riverless, cross-shaped board, but with four players. Because there are no rivers, elephants may move about the board freely.
Further reading.
</dl>

</doc>
<doc id="34203" url="http://en.wikipedia.org/wiki?curid=34203" title="XFS">
XFS

XFS is a high-performance 64-bit journaling file system created by Silicon Graphics, Inc (SGI) in 1993. It was the default file system in the SGI's IRIX operating system starting with its version 5.3; the file system was ported to the Linux kernel in 2001. s of 2014[ [update]], XFS is supported by most Linux distributions, some of which use it as the default file system.
XFS excels in the execution of parallel input/output (I/O) operations due to its design, which is based on allocation groups (a type of subdivision of the physical volumes in which XFS is used- also shortened to "AGs"). Because of this, XFS enables extreme scalability of I/O threads, file system bandwidth, and size of files and of the file system itself when spanning multiple physical storage devices.
XFS ensures the consistency of data by employing metadata journaling and supporting write barriers. Space allocation is performed via extents with data structures stored in B+ trees, improving the overall performance of the file system, especially when handling large files. Delayed allocation assists in the prevention of file system fragmentation; online defragmentation is also supported. A feature unique to XFS is the pre-allocation of I/O bandwidth at a pre-determined rate, which is suitable for many real-time applications; however, this feature was supported only on IRIX, and only with specialized hardware.
A notable XFS user, NASA Advanced Supercomputing Division, takes advantage of these capabilities deploying two 300+ terabyte XFS filesystems on two SGI Altix archival storage servers, each of which is directly attached to multiple Fibre Channel disk arrays.
History.
Silicon Graphics began development of XFS in 1993, including it into IRIX for the first time in its version 5.3 in 1994. The file system was released under the GNU General Public License (GPL) in May 2000 and was ported to Linux by a team led by Steve Lord at SGI, while first support by a Linux distribution came in 2001. This support gradually became available in almost all Linux distributions.
Linux kernel's support for XFS was originally available through patches from SGI. It was merged into the Linux kernel mainline for the 2.6 series, and separately merged in February 2004 into the 2.4 series in version 2.4.25, making XFS almost universally available on Linux systems.
Gentoo Linux was the first Linux distribution to introduce an option for XFS to be used as the default filesystem in mid-2002.
Installation programs for the Arch, Debian, Fedora, openSUSE, Kate OS, Mandriva, Slackware, Ubuntu, VectorLinux and Zenwalk Linux distributions all offer XFS as a choice of filesystem, but few of these let the user create XFS for the /boot filesystems due to deficiencies and unpredictable behavior in GRUB, generally the default bootloader.
FreeBSD added read-only support for XFS in December 2005 and in June 2006 introduced experimental write support; however this was supposed to be used only as an aid in migration from Linux, not as a "main" file system. Support for XFS was removed in FreeBSD 10.
In 2009, version 5.4 of 64-bit Red Hat Enterprise Linux (RHEL) Linux distribution contained the necessary kernel support for the creation and usage of XFS file systems, but did not contain the corresponding command-line tools. The tools available from CentOS could be used for that purpose, and they were also provided to RHEL customers on request. RHEL 6.0, released in 2010, includes XFS support for a fee as part of Red Hat's "scalable file system add-on". Oracle Linux 6, which was released in 2011, also includes an option for using XFS.
RHEL 7.0, released in June 2014, uses XFS as the default file system, including support for using XFS for the /boot partition.
Features.
Capacity.
XFS is a 64-bit file system. It supports a maximum file system size of 8 exbibytes minus one byte (263-1 bytes), but this limitation can be decreased by limitations imposed by the host operating system. 32-bit Linux systems limit the size of both the file and file system to 16 tebibytes.
Journaling.
In modern computing, journaling is a capability which ensures consistency of data in the file system, despite any power outages or system crash that may occur. XFS provides journaling for file system metadata, where file system updates are first written to a serial journal before the actual disk blocks are updated. The journal is a circular buffer of disk blocks that is not read in normal file system operation.
The XFS journal is limited to a maximum size of both 64 KB blocks and 128 MB, with the minimum size dependent upon a calculation of the file system block size and directory block size. Placing the journal on an external device larger than the maximum journal size will simply leave the extra space unused by the journal. It can be stored within the data section of the file system (as an internal log), or on a separate device to minimize disk contention.
In XFS, the journal contains "logical" entries that describe, in a humanly understandable way, what operations are being performed (as opposed to a "physical" journal that stores a copy of the blocks modified during each operation). Journal updates are performed asynchronously to avoid a decrease in performance speed.
In the event of a system crash, file system operations which occurred immediately prior to the crash can be reapplied and completed as recorded in the journal, which is how data stored in XFS file systems remain consistent. Recovery is performed automatically the first time the file system is mounted after the crash. The speed of recovery is independent of the size of the file system, instead depending on the amount of file system operations to be reapplied.
Allocation groups.
XFS file systems are internally partitioned into "allocation groups", which are equally sized linear regions within the file system. Files and directories can span allocation groups. Each allocation group manages its own inodes and free space separately, providing scalability and parallelism — multiple threads and processes can perform I/O operations on the same file system simultaneously.
This architecture helps to optimize parallel I/O performance on systems with multiple processors and/or cores, as metadata updates can also be parallelized. The internal partitioning provided by allocation groups can be especially beneficial when the file system spans multiple physical devices, allowing for optimal usage of throughput of the underlying storage components.
Striped allocation.
If an XFS file system is to be created on a striped RAID array, a "stripe unit" can be specified when the file system is created. This maximizes throughput by ensuring that data allocations, inode allocations and the internal log (the journal) are aligned with the stripe unit.
Extent based allocation.
Blocks used in files stored on XFS file systems are managed with variable length extents where one extent describes one or more contiguous blocks. This can shorten the list of blocks considerably, compared to file systems that list all blocks used by a file individually.
Also, many file systems manage space allocation with one or more block oriented bitmaps — in XFS, these structures are replaced with an extent oriented structure consisting of a pair of B+ trees for each file system allocation group. One of the B+ trees is indexed by the length of the free extents, while the other is indexed by the starting block of the free extents. This dual indexing scheme allows for the highly efficient location of free extents for file system operations.
Variable block sizes.
The file system block size represents the minimum allocation unit. XFS allows file systems to be created with block sizes ranging between 512 bytes and 64 KB, allowing the file system to be tuned for the expected degree of usage. When many small files are expected, a small block size would typically maximize capacity, but for a system dealing mainly with large files, a larger block size can provide a performance efficiency advantage.
Delayed allocation.
XFS makes use of lazy evaluation techniques for file allocation. When a file is written to the buffer cache, rather than allocating extents for the data, XFS simply reserves the appropriate number of file system blocks for the data held in memory. The actual block allocation occurs only when the data is finally flushed to disk. This improves the chance that the file will be written in a contiguous group of blocks, reducing fragmentation problems and increasing performance.
Sparse files.
XFS provides a 64-bit sparse address space for each file, which allows both for very large file sizes, and for "holes" within files in which no disk space is allocated. As the file system uses an extent map for each file, the file allocation map size is kept small. Where the size of the allocation map is too large for it to be stored within the inode, the map is moved into a B+ tree which allows for rapid access to data anywhere in the 64-bit address space provided for the file.
Extended attributes.
XFS provides multiple data streams for files; this is made possible by its implementation of extended attributes. These allow the storage of a number of name/value pairs attached to a file. Names are null-terminated printable character strings which are up to 256 bytes in length, while their associated values can contain up to 64 KB of binary data.
They are further subdivided into two namespaces: codice_1 and codice_2. Extended attributes stored in the root namespace can be modified only by the superuser, while attributes in the user namespace can be modified by any user with permission to write to the file.
Extended attributes can be attached to any kind of XFS inode, including symbolic links, device nodes, directories, etc. The codice_3 utility can be used to manipulate extended attributes from the command line, and the codice_4 and codice_5 utilities are aware of extended attributes, and will back up and restore their contents. Most other backup systems do not support working with extended attributes.
Direct I/O.
For applications requiring high throughput to disk, XFS provides a direct I/O implementation that allows non-cached I/O operations to be applied directly to the userspace. Data is transferred between the buffer of the application and the disk using DMA, which allows access to the full I/O bandwidth of the underlying disk devices.
Guaranteed-rate I/O.
The XFS guaranteed-rate I/O system provides an API that allows applications to reserve bandwidth to the filesystem. XFS dynamically calculates the performance available from the underlying storage devices, and will reserve bandwidth sufficient to meet the requested performance for a specified time. This is a feature unique to the XFS file system. Guaranteed rates can be "hard" or "soft", representing a trade off between reliability and performance; however, XFS will only allow "hard" guarantees if the underlying storage subsystem supports it. This facility is used mostly for real-time applications, such as video streaming.
Guaranteed-rate I/O was only supported under IRIX, and required special hardware for that purpose.
DMAPI.
XFS implemented the DMAPI interface to support Hierarchical Storage Management in IRIX. As of October 2010, the Linux implementation of XFS supported the required on-disk metadata for DMAPI implementation, but the kernel support was reportedly not usable. For some time, SGI hosted a kernel tree which included the DMAPI hooks, but this support has not been adequately maintained, although kernel developers have stated an intention to bring this support up to date.
Snapshots.
XFS does not provide direct support for snapshots, as it expects the snapshot process to be implemented by the volume manager. Taking a snapshot of an XFS filesystem involves temporarily halting I/O to the filesystem using the codice_6 utility, having the volume manager perform the actual snapshot, and then resuming I/O to continue with normal operations. The snapshot can then be mounted read-only for backup purposes.
Releases of XFS in IRIX incorporated an integrated volume manager called XLV. This volume manager has not been ported to Linux, and XFS works with standard LVM in Linux systems instead.
In recent Linux kernels, the codice_6 functionality is implemented in the VFS layer, and is executed automatically when the Volume Manager's snapshot functionality is invoked. This was once a valuable advantage as the ext3 file system could not be suspended and the volume manager was unable to create a consistent "hot" snapshot to back up a heavily busy database. Fortunately this is no longer the case. Since Linux 2.6.29, the file systems ext3, ext4, GFS2 and JFS have the freeze feature as well.
Online defragmentation.
Although the extent-based nature of XFS and the delayed allocation strategy it uses significantly improves the file system's resistance to fragmentation problems, XFS provides a filesystem defragmentation utility (codice_8, short for XFS filesystem reorganizer) that can defragment the files on a mounted and active XFS filesystem.
Online resizing.
XFS provides the codice_9 utility to perform online resizing of XFS file systems. XFS filesystems can be grown so long as there is remaining unallocated space on the device holding the filesystem. This feature is typically used in conjunction with volume management, as otherwise the partition holding the filesystem will need enlarging separately. XFS partitions cannot (as of August 2010) be shrunk in place, although several possible workarounds have been discussed.
Native backup/restore utilities.
XFS provides the codice_4 and codice_5 utilities to aid in the backup of data stored in XFS file systems. The codice_4 utility backs up an XFS filesystem in inode order, and in contrast to traditional UNIX file systems which must be unmounted before dumping to guarantee a consistent dump image, XFS file systems can be dumped while the file system is in use. This is not the same as a snapshot, since files are not frozen during the dump.
XFS dumps and restores are also resumable, and can be interrupted without difficulty. The multi-threaded operation of codice_4 provides high performance of backup operations by splitting the dump into multiple streams, which can be sent to different dump destinations. The multi stream capabilities have not been fully ported to Linux yet, however.
Atomic disk quotas.
Quotas for XFS filesystems are turned on when initially mounted; this fixes a race window that is present with most other filesystems that first require to be mounted and where no quotas are enforced until quotaon(8) is called.
Performance considerations.
Write barriers.
XFS filesystems mount with "write barriers" enabled by default. This feature will cause the write back cache of the underlying storage device to be flushed at appropriate times, particularly on write operations to the XFS log. This feature is intended to assure filesystem consistency, and its implementation is device specific — not all underlying hardware will support cache flush requests.
When an XFS filesystem is used on a logical device provided by a hardware RAID controller with battery backed cache, this feature can slow performance significantly, as the filesystem code is not aware that the cache is nonvolatile, and if the controller honors the flush requests, data will be written to the disk more often than is necessary. To avoid this problem, areas wherein the data in the device cache is protected from power failure or other host problems, the filesystem can be mounted with the "nobarrier" option.
Journal placement.
By default, XFS filesystems are created with an "internal" log, which places the filesystem journal on the same block device as the filesystem data. Filesystem writes are preceded by metadata updates to the journal, which can be a cause of disk contention. Under most workloads, the level of contention caused is too low to impact performance, but random-write heavy workloads, such as those seen on busy database servers, can suffer from less than optimal performance as a result of this I/O contention. An additional factor which can increase the severity of this problem is that writes to the journal are committed synchronously — they must complete successfully before the associated write operation can begin.
Where optimum filesystem performance is required, XFS provides the option of placing the log on a separate physical device, with its own I/O path. This requires little physical space, and if a low-latency path can be provided for synchronous writes, it can greatly improve performance in the operation of the filesystem. The required performance characteristics make this a suitable candidate for the use of a solid-state drive (SSD) device, or a RAID system with write-back cache, though the latter can reduce data safety in the event of power interruptions. The use of an external log requires the filesystem to be mounted with the codice_14 option, indicating a suitable journal device.

</doc>
<doc id="34204" url="http://en.wikipedia.org/wiki?curid=34204" title="XEmacs">
XEmacs

XEmacs is a graphical- and console-based text editor which runs on almost any Unix-like operating system as well as Microsoft Windows. XEmacs is a fork, based on a version of GNU Emacs from the late 1980s. Any user can download, use, and modify XEmacs as free software available under the GNU General Public License version 2 or any later version.
History.
Between 1987 and 1993 significant delays occurred in bringing out a new version of GNU Emacs (presumed to be version 19).
In the late 1980s, Richard P. Gabriel's Lucid Inc. faced a requirement to ship Emacs to support the Energize C++ IDE. So Lucid recruited a team to improve and extend the code,
with the intention that their new version, released in 1991, would form the basis of GNU Emacs version 19. However, they did not have time to wait for their changes to be accepted by the Free Software Foundation (FSF).
Lucid continued developing and maintaining their version of Emacs, while the FSF released version 19 of GNU Emacs a year later, while merging some of the code and adapting some other parts.
When Lucid went out of business in 1994, other developers picked up the code.
Companies such as Sun Microsystems wanted to carry on shipping Lucid Emacs, however, using the trademark had become legally ambiguous because no one knew who would eventually control the trademark "Lucid". Accordingly the "X" in XEmacs represents a compromise among the parties involved in developing XEmacs.
The "X" in XEmacs is thus not related to the X Window System. XEmacs has always supported text-based terminals and windowing systems other than X11. Installers can compile both XEmacs and GNU Emacs with and without X support. For a period of time XEmacs even had some terminal-specific features, such as coloring, that GNU Emacs lacked.
The software community generally refers to GNU Emacs, XEmacs (and a number of other similar editors) collectively or individually as "emacsen" (by analogy with boxen) or as "emacs", since they both take their inspiration from the original TECO Emacs.
Features.
XEmacs text-editing features commands to manipulate words and paragraphs (deleting them, moving them, moving through them, and so forth), syntax highlighting for making source code easier to read, and "keyboard macros" for performing arbitrary batches of editing commands defined by the user.
XEmacs has comprehensive online help, as well as five manuals available from the XEmacs website. XEmacs supports many human languages as well as editing-modes for many programming and markup-languages. XEmacs runs on many operating systems including Unix/Linux, BSDs and Mac OS X. Running on Mac OS requires X11; while development has started[ [update]] on a native Carbon version. Two versions of XEmacs for the Microsoft Windows environment exist: a native installer and a Cygwin package.
Users can reconfigure almost all of the functionality in the editor by using the Emacs Lisp language. Changes to the Lisp code do not require the user to restart or recompile the editor. Programmers have made available many pre-written Lisp extensions.
Many packages exist to extend and supplement the capabilities of XEmacs. Users can either download them piecemeal through XEmacs' package manager or apply them in bulk using the xemacs-sumo package or "sumo tarballs". Since XEmacs 21.1 functionality has been moved out of XEmacs core and made available separately as packages. This allows users to exclude packages they have no need for. XEmacs has had a package manager for over a decade before GNU Emacs developed one, but XEmacs must be restarted before new packages are loaded.
Development.
From the project's beginnings, the developers of XEmacs aimed to have a frequent release-cycle: currently[ [update]] 2 to 3 releases appear per year, which is a slowdown from earlier years.
They also aimed for more openness to experimentation, and XEmacs often offers new features before other emacsen—pioneering (for example) inline images, variable fonts and terminal coloring. Over the years, the developers have extensively rewritten the code in order to improve consistency and to follow modern programming conventions stressing data abstraction. XEmacs has a packaging system for independently maintained Lisp packages. The latest[ [update]] version has GTK+ support
and a native Carbon port for Mac OS X.
XEmacs has always had a very open development-environment, including anonymous CVS, later Mercurial access and publicly accessible development mailing-lists. XEmacs comes with a 500+ page internals manual (Wing, et al., 2004).
The XEmacs project has a policy of maintaining compatibility with the GNU Emacs API. For example, it provides a compatibility-layer implementing overlays via the native extent functionality. "[T]he XEmacs developers strive to keep their code compatible with GNU Emacs, especially on the Lisp level."
Support for Unicode has become a problem for XEmacs. As of 2005, the released version depends on the unmaintained package called Mule-UCS to support Unicode, while the development branch of XEmacs has had robust native support for external Unicode encodings since May 2002, but the internal Mule character sets lack completeness, and development seems stalled as of September 2005.
XEmacs development features three branches: stable, gamma, and beta,
with beta getting new features first, but potentially having less testing, stability and security. The developers released version 20.0 on 9 February 1997, and version 21.0 on 12 July 1998. As of January 2009, the stable branch had reached version 21.4.22 and the beta branch version 21.5.28. No gamma releases exist as of 2007[ [update]]. With the release of XEmacs 21.4.0, version numbers follow a scheme whereby an odd second number signals a development-version, and an even second number indicates a stable release.
XEmacs and GNU Emacs.
Several of XEmacs's principal developers have published accounts of the split between XEmacs and GNU Emacs, for example, Stephen Turnbull's summary of the arguments from both sides. One of the main disagreements involves different views of copyright assignment. The FSF sees copyright assignment to the FSF as necessary to allow it to defend the code against GPL violations,
while the XEmacs developers have argued that the lack of copyright assignment has allowed major companies to get involved, as sometimes companies can license their code but due to a cautious attitude concerning fiduciary duties to shareholders, companies may have trouble in getting permission to assign away code completely. The Free Software Foundation holds copyright of much of the XEmacs code because of prior copyright assignment during merge attempts and cross-development. Whether a piece of new XEmacs code enters GNU Emacs often depends on the willingness of that individual contributor to assign the code to the FSF. New features in either editor usually show up in the other sooner or later. Furthermore, many developers contribute to both projects; in particular, many major packages, such as Gnus and Dired, undergo development to work with both.
XEmacs development has slowed, with the most recent stable version 21.4.22 released in January 2009. XEmacs has incorporated much code from GNU Emacs in recent versions while GNU Emacs has implemented many formerly XEmacs-only features. This has led some users to proclaim XEmacs' death, advocating that its developers contribute to GNU Emacs instead.

</doc>
<doc id="34210" url="http://en.wikipedia.org/wiki?curid=34210" title="XXX">
XXX

XXX may refer to:
A mark indicating "extra strong".
Various contexts, but especially:
Communication.
A warning or danger signal, or symbol for doubtful/unknown

</doc>
<doc id="34211" url="http://en.wikipedia.org/wiki?curid=34211" title="XSLT">
XSLT

XSLT (Extensible Stylesheet Language Transformations) is a language for transforming XML documents into other XML documents, or other formats such as HTML for web pages, plain text or into XSL Formatting Objects, which may subsequently be converted to other formats, such as PDF PostScript and PNG.
The original document is not changed; rather, a new document is created based on the content of an existing one. Typically, input documents are XML files, but anything from which the processor can build an XQuery and XPath Data Model can be used, for example relational database tables, or geographical information systems.
XSLT is a Turing-complete language, meaning it can specify any computation that can be performed by a computer.
History.
XSLT is influenced by functional languages, and by text-based pattern matching languages like SNOBOL and awk. Its most direct predecessor is DSSSL, which did for SGML what XSLT does for XML.
Design and processing model.
The XSLT processor takes one or more XML source documents, plus one or more XSLT stylesheets, and processes them to produce an output document. In contrast to widely-implemented imperative programming languages like C, XSLT is declarative. This makes a given XSLT program more resilient to change to the input it is likely to receive, useful in a language used for information processing applications. The basic processing paradigm is pattern matching. Rather than listing an imperative sequence of actions to perform in a stateful environment, template rules only define how to handle a node matching a particular XPath-like pattern, if the processor should happen to encounter one, and the contents of the templates effectively comprise functional expressions that directly represent their evaluated form: the result tree, which is the basis of the processor's output.
The processor follows a fixed algorithm. First, assuming a stylesheet has already been read and prepared, the processor builds a source tree from the input XML document. It then processes the source tree's root node, finds the best-matching template for that node in the stylesheet, and evaluates the template's contents. Instructions in each template generally direct the processor to either create nodes in the result tree, or to process more nodes in the source tree in the same way as the root node. Output derives from the result tree.
Processor implementations.
Performance.
Most early XSLT processors were interpreters. More recently, code generation is increasingly common, using portable intermediate languages (such as Java bytecode or .NET Common Intermediate Language) as the target. However, even the interpretive products generally offer separate analysis and execution phases, allowing an optimized expression tree to be created in memory and reused to perform multiple transformations. This gives substantial performance benefits in online publishing applications, where the same transformation is applied many times per second to different source documents. This separation is reflected in the design of XSLT processing APIs (such as JAXP).
Early XSLT processors had very few optimizations. Stylesheet documents were read into Document Object Models and the processor would act on them directly. XPath engines were also not optimized. Increasingly, however, XSLT processors use optimization techniques found in functional programming languages and database query languages, such as static rewriting of an expression tree (e.g., to move calculations out of loops), and lazy pipelined evaluation to reduce the memory footprint of intermediate results (and allow "early exit" when the processor can evaluate an expression such as codice_2 without a complete evaluation of all subexpressions). Many processors also use tree representations that are significantly more efficient (in both space and time) than general-purpose DOM implementations.
In June 2014, Debbie Lockett and Michael Kay introduced an open-source benchmarking framework for XSLT processors called XT-Speedo.
XSLT and XPath.
XSLT uses XPath to identify subsets of the source document tree and perform calculations. XPath also provides a range of functions, which XSLT itself further augments.
XSLT 1.0 uses XPath 1.0. XSLT 2.0 uses XPath 2.0. And XSLT 3.0 uses XPath 3.0. In the case of 1.0 and 2.0, the specifications were published on the same date. With 3.0, however, they were no longer synchronized; XPath 3.0 became a Recommendation in April 2014, while XSLT 3.0 was still work in progress.
XSLT and XQuery compared.
XSLT functionalities overlap with those of XQuery, which was initially conceived as a query language for large collections of XML documents.
The XSLT 2.0 and XQuery 1.0 standards were developed by separate working groups within W3C, working together to ensure a common approach where appropriate. They share the same data model, type system, and function library, and both include XPath 2.0 as a sublanguage.
The two languages, however, are rooted in different traditions and serve the needs of different communities. XSLT was primarily conceived as a stylesheet language whose primary goal was to render XML for the human reader on screen, on the web (as web template language), or on paper. XQuery was primarily conceived as a database query language in the tradition of SQL.
Because the two languages originate in different communities, XSLT is stronger in its handling
of narrative documents with more flexible structure, while XQuery is stronger in its data handling, for example when performing relational joins.
XSLT media types.
The codice_3 element can optionally take the attribute codice_4, which allows one to set the media type (or MIME type) for the resulting output, for example: codice_5. The XSLT 1.0 recommendation recommends the more general attribute types codice_6 and codice_7 since for a long time there was no registered media type for XSLT. During this time codice_8 became the de facto standard. In XSLT 1.0 it was not specified how the codice_4 values should be used.
With the release of the XSLT 2.0, the W3C recommended the registration of the MIME media type codice_10 and it was later registered with the Internet Assigned Numbers Authority
Pre-1.0 working drafts of XSLT used codice_8 in their embedding examples, and this type was implemented and continues to be promoted by Microsoft in Internet Explorer and MSXML. It is also widely recognized in the codice_12 processing instruction by other browsers. In practice, therefore, users wanting to control transformation in the browser using this processing instruction are obliged to use this unregistered media type.
XSLT examples.
For grouping problems, see XSLT/Muenchian grouping. Below a sample of incoming XML document
Example 1 (transforming XML to XML).
This XSLT stylesheet provides templates to transform the XML document:
Its evaluation results in a new XML document, having another structure:
Example 2 (transforming XML to XHTML).
Processing the following example XSLT file
with the XML input file shown above results in the following XHTML (whitespace has been adjusted here for clarity):
This XHTML generates the output below when rendered in a web browser.
In order for a web browser to be able automatically to apply an XSL transformation to an XML document on display, an XML stylesheet processing instruction can be inserted into XML. So, for example, if the stylesheet in Example 2 above were available as "example2.xsl", the following instruction could be added to the original incoming XML:
In this example, codice_8 is technically incorrect according to the W3C specifications, but it is the only media type that is widely supported across browsers as of 2009.

</doc>
<doc id="34214" url="http://en.wikipedia.org/wiki?curid=34214" title="XMMS">
XMMS

X Multimedia System (XMMS) is an audio player for Unix-like systems released under a free software license.
History.
XMMS was originally written as "X11Amp" by Peter and Mikael Alm in November 1997. The player was made to resemble Winamp, which was first released in May that year. As such, XMMS has supported Winamp 2 "classic" skins since its release. Though the original release was made under a license that did not provide any access to the program's source code, it is now released under the GNU General Public License.
On June 10, 1999, 4Front Technologies decided to sponsor X11Amp development and the project was renamed to "XMMS" - the name being an acronym for "X MultiMedia System". Most XMMS users take this to mean "X11 MultiMedia System" or "X Window System MultiMedia System"; the official interpretation of the "X" is "Cross-platform".
Forks.
XMMS has continued to use GTK+ 1.x toolkit, despite a major revision of GTK (2.x) being available for several years, and the current version being GTK3. The primary reason for this reluctance to upgrade is that many XMMS plugins (written by third parties) are dependent on the older version of GTK+ to properly function, "e.g.", "about" boxes and configuration dialogs. Many software developers also consider the XMMS codebase to be poorly designed and difficult to maintain. These factors led to various forks and related projects:
Features.
XMMS currently supports the following audio and video file formats:
Skins.
XMMS has a default skin provided, but it is also possible to use any classic skins to enhance the graphic attractiveness of the player. (see attached image)
Coverviewer.
xmms-coverviewer is an XMMS plugin which allows XMMS to display album art and further enhance the graphical interface of the player. (see attached image)

</doc>
<doc id="34215" url="http://en.wikipedia.org/wiki?curid=34215" title="X-Ray Spex">
X-Ray Spex

X-Ray Spex were an English punk band from London that formed in 1976.
During their first incarnation (1976–79), X-Ray Spex were “deliberate underachievers” and only managed to release five singles and one album. Nevertheless, their first single, "Oh Bondage Up Yours!", is now acknowledged as a classic punk rock single and the album, "Germfree Adolescents", is widely acclaimed as a classic album of the punk rock genre.
Career.
Initially, the band featured singer Poly Styrene (born Marianne Joan Elliott-Said) on vocals, Jak Airport (Jack Stafford) on guitars, Paul Dean on bass, Paul 'B. P.' Hurding on drums, and Lora Logic (born Susan Whitby) on saxophone. This latter instrument was an atypical addition to the standard punk instrumental line-up, and became one of the group's most distinctive features. Lora played on only one of the band's records. As she was only fifteen, playing saxophone was a hobby and she left the band to complete her education.
X-Ray Spex's other distinctive musical element was Poly Styrene's voice, which has been variously described as "effervescently discordant" and "powerful enough to drill holes through sheet metal". As Mari Elliot, Poly had released a reggae single for GTO Records in 1976, "Silly Billy", which had not charted. Born in 1957 in Bromley, Kent, of both Somali and British parentage, Poly Styrene became the group's public face, and remains one of the most memorable front-women to emerge from the punk movement. Unorthodox in appearance, she wore thick braces on her teeth and once stated that "I said that I wasn't a sex symbol and that if anybody tried to make me one I'd shave my head tomorrow". She later actually did at Johnny Rotten's flat prior to a concert at Victoria Park. Mark Paytress recounts in the liner notes for the 2002 compilation, "The Anthology", that Jah Wobble, Rotten's longtime friend and bassist for his post-punk venture PiL, once described Styrene as a "strange girl who often talked of hallucinating. She freaked John out." Rotten, known more for his outspoken dislikes and disdain than for praise and admiration, recently said of X-Ray Spex in a retrospective punk documentary, "Them, they came out with a sound and attitude and a whole energy—it was just not relating to anything around it—"superb"."
Styrene was inspired to form a band by seeing the Sex Pistols in Hastings and, through their live performances, she and X-Ray Spex became one of the most talked about acts on the infant punk scene. The band played twice at the punk club The Roxy during its first 100 days. In March, the band played with The Drones and Chelsea. In April, they shared the bill with the Buzzcocks, Wire, and Johnny Moped. Their first Roxy gig was only their second live appearance. It was recorded and their anthem "Oh Bondage Up Yours!" was included on the influential "Live at the Roxy WC2" album. The publicity from this gig led to a "near residency", particularly on Sunday nights, at 'The Man in the Moon' pub, Kings Road, Chelsea, and record label interest.
In late September 1977, a studio recording of "Oh Bondage Up Yours!" was released as a single. Today, the 45 is regarded as their most enduring artefact, both as a piece of music and as a sort of proto-grrrl catchphrase. Opening with the spoken/screamed line, "Some people think little girls should be seen and not heard but I think, oh bondage, up yours!", the song could be interpreted as a premonition of the riot grrrl movement a good 15 years later, although Styrene herself insists it was more intended as an anti-consumerist/anti-capitalist jingle, and was not exclusively feminist in nature.
In late 1977, Lora Logic was replaced on saxophone, first temporarily by John Glyn (who later joined Wreckless Eric's band), and then permanently by Rudi Thompson (also known as Steve Rudi).
In November 1978, the band released their debut album. With the exception of "Identity", which was partially based on Styrene seeing a girl slash her wrists in a club toilet, the rest of "Germfree Adolescents" dealt with the anti consumerist theme. Indeed, The Guardian newspaper described the album as containing "unrivalled anti-consumerism anthems".
X-Ray Spex played at 'Front Row Festival', a three-week event at the Hope and Anchor, Islington in late November and early December 1977. This resulted in the band's inclusion, alongside the likes of Wilko Johnson, 999, The Only Ones, the Saints, The Stranglers, and XTC, on a double album of recordings from the festival. Then, in February 1978, before the release of their second single, X-Ray Spex recorded the first of two sessions for John Peel at BBC Radio 1. Their profile was further enhanced by playing a fortnight's residency at New York's CBGB's, even though the album "Germ Free Adolescents" was not released in America until 1992.
On 30 April, the band appeared at the Rock Against Racism gig at Victoria Park, Bow, Tower Hamlets. Also on the bill were Steel Pulse, The Clash, The Ruts, Sham 69, Generation X and Tom Robinson Band. Later in the year, to promote the album, X-Ray Spex embarked on their first, and only, full UK tour. Exhausted by touring, Poly Styrene left the band in mid 1979, though she is seen performing with the band in the 1980 film, "D.O.A.". She released a solo album, "Translucence", before joining the Hare Krishna movement (as did Logic, who left the band aged 16 in 1977 to form a new group called Essential Logic).
Without Styrene, the group lost its momentum and split up. Hurding and Airport went on to form Classix Nouveaux, while Paul Dean and Rudi Thompson went on to form Agent Orange with Anthony "Tex" Doughty, who later become a founding member of Transvision Vamp.
The first incarnation of X-Ray Spex existed from mid-1976 to 1979, during which time they released five singles—"Oh Bondage Up Yours!", "Identity", "The Day the World Turned Day-Glo", "Germfree Adolescents", and "Highly Inflammable"—and one album, "Germfree Adolescents". One retrospective review described the singles as “not only riveting examples of high-energy punk, but contained provocative, thoughtful lyrics berating the urban synthetic fashions of the 70s and urging individual expression”.
The same reviewer in "The Virgin Encyclopedia of Popular Music" sums up the band's 1970s contribution as “one of the most inventive, original and genuinely exciting groups to emerge during the punk era”.
Reformation.
In 1991 X-Ray Spex reformed for a surprise sell-out gig at the Brixton Academy where Poly appeared in a blue foam dress with an army helmet (to her regret). The group reformed again in 1995 with a line-up of Styrene, Dean and Logic to release a new album "Conscious Consumer". Although heralded as the first in a trilogy, the album was not a commercial success. Styrene later explained that touring and promotional work suffered an abrupt end when she was run over by a fire engine in central London, suffering a fractured pelvis. The following year X-Ray Spex played at the 20th Anniversary of Punk Festival in Blackpool minus Poly Styrene, overcoming her last-minute decision to withdraw by recruiting a replacement female singer named 'Poly Filla'. The band subsequently disbanded, but later releases include a compilation of the group's early records, a live album, and an anthology of all the aforementioned.
Jak Airport later worked for the BBC's Corporate and Public Relations department under his real name, Jack Stafford; he died on 13 August 2004 of cancer.
On 28 April 2008, Poly Styrene gave a performance of "Oh Bondage Up Yours!" in front of more than 10,000 people at the Love Music Hate Racism free concert in Victoria Park, East London
, working as Concrete Jungle Productions, together with Poly Styrene, produced the live show at Camden Roundhouse in 2008.
The band including original bass player Paul Dean, played what was described as a raucous comeback gig and in front of an audience of 3,000 full at The Roundhouse in London on 6 September 2008. The gig consisted of "Germfree Adolescents" in its entirety, with the exception of "Plastic Bag". A DVD and CD of the Roundhouse performance was released in November 2009 on the Year Zero Label by Future Noise Music.
Poly Styrene died of spinal and breast cancer on 25 April 2011.
Discography.
Appearances on various artist compilations (selective).
Listing of those various artist compilation albums mentioned in the text of the main article:

</doc>
<doc id="34217" url="http://en.wikipedia.org/wiki?curid=34217" title="X-Factor (comics)">
X-Factor (comics)

X-Factor is an American comic book series published by Marvel Comics. It is a spin-off from the popular X-Men franchise, featuring characters from X-Men stories. The series has been relaunched several times with different team rosters, most recently in X-Factor v. 3 as X-Factor Investigations.
"X-Factor" launched in 1986, featuring an eponymous team composed of the five original X-Men. In 1991, the founding members were incorporated back into the regular "X-Men" series, and "X-Factor" relaunched as a U.S. government-sponsored team incorporating many secondary characters from the X-Men mythos. The series was canceled in 1998.
In 2002 a four-part "X-Factor" mini-series detailed an investigation by the Mutant Civil Rights Task Force into an alleged conspiracy by hate-groups to commit murder against mutants. The series was written by Jeff Jensen with artwork by Arthur Ranson.
In 2005 a new "X-Factor" series was launched, following the mutant detective agency X-Factor Investigations. Written by Peter David, the series drew acclaim from Ain't It Cool News, as well as controversy for establishing a homosexual romantic relationship between Rictor and Shatterstar, a move criticized by Shatterstar's co-creator, Rob Liefeld. The series also won a 2011 GLAAD Media Award for Outstanding Comic Book. The series ended in 2013.
In 2014 a new series written by David, "All-New X-Factor" was launched featuring a new corporate-sponsored X-Factor team.
Publication history.
Volume 1 (1986–1998).
Original team (1986-1991).
"X-Factor" launched in 1986 featuring an eponymous team composed of the five original X-Men that debuted in "X-Men" #1 (1963):
The founding of "X-Factor" hinged upon the reunion of the original X-Men, an event complicated by the extensive histories of the characters following the initiation of a new team of X-Men in 1975.
In the 1970s and early 1980s, Angel, Beast, and Iceman wandered through various superhero teams. By 1985, all three were members of the Defenders, whose monthly series was shortly canceled, which freed the trio.
A more difficult task was the return of Cyclops and Jean Grey. In 1980, Jean Grey was killed during the seminal "Dark Phoenix Saga", and was not originally conceived in the team's female role, with fellow mutant Dazzler as the front-runner for that part. However, writer Kurt Busiek suggested a way to add Jean Grey to the roster that became one of the most significant cases of retconning in comic book history: Jean Grey had never actually been the Phoenix. Instead, the Phoenix entity copied Grey's identity and form, keeping her safe in a cocoon-like structure beneath Jamaica Bay. Busiek related the idea to Roger Stern, who related it to John Byrne. Byrne wrote and illustrated "Fantastic Four" #286 (1985), incorporating Busiek's idea.
In order to join the team, Cyclops walked out on his new wife Madelyne Pryor, an Alaskan pilot who bore a strange resemblance to Grey, and their infant son, Nathan Christopher. These events, along with the resurrection of Grey in general, were highly controversial with fans.
The original X-Men disassociate with the current team because Professor X had placed their old nemesis, Magneto, as its leader. The five original members set up a business advertised as mutant-hunters for hire, headquartered in the TriBeCa neighborhood of downtown New York City, posing as "normal" (non-superpowered) humans to their clients. The mutants that X-Factor capture are secretly trained to control their powers and reintegrated into society. Through their "mutant hunting" they recruit a group of young wards:
Eventually, the team decides that the "mutant hunter" ruse did more harm than good by inflaming hatred, and blames it on X-Factor's original business manager, Cameron Hodge, who is revealed as a mutant-hating mastermind.
Bob Layton and Jackson Guice wrote and illustrated, respectively, the first few issues of "X-Factor". They soon turned over creative duties to Louise Simonson (writer) and Walt Simonson (artist). Despite their relationship as husband-and-wife, both the Simonsons have said they did not approach work with each other any differently than any other collaboration; in particular, though Walt occasionally contributed ideas, he did not co-plot the series with his wife. In "X-Factor" #6 (1986), Louise introduced Apocalypse, who would appear in multiple issues and become X-Factor's nemesis.
Louise Simonson placed the series in line with the darker tone of most of the X-Men franchise; after a year on "X-Factor", she remarked that "in real life all of my friends should be happy, but in comic books all of my characters should be miserable." In "X-Factor" #10, the Marauders, a group of mutant mercenaries, severely injure Angel's wings, which are later amputated. When an interviewer commented on the brutality of this turn of events, Walt Simonson replied, "Hey, that's nothing compared to what happens to him eventually." Despondent, Angel attempts suicide by detonating his airliner mid-flight, but Apocalypse rescues him and transforms him into Death, one of his Four Horsemen, giving him metal wings and blue skin. Angel escaped Apocalypse's control, but these physical changes remain. He is renamed Archangel and becomes a much darker character, eventually rejoining the team in issue #36. Angel's replacement on X-Factor, Caliban, turns to Apocalypse for more power in issue #24, with Apocalypse leaving X-Factor his ship in return.
In the 1989 crossover "Inferno", Madelyne Pryor is revealed to be a clone of Jean Grey created by the mutant geneticist Mister Sinister. Manipulated by demons and tormented by Scott's rejection of her, Madelyne kills herself in a suicide attack on X-Factor.
Wanting to do stories with more focus on X-Factor's teenage wards, Louise Simonson successfully petitioned editor Bob Harras for permission to do a miniseries featuring them. Following the miniseries, titled "X-Terminators", the characters left "X-Factor" and were moved to "New Mutants".
In the last major storyline of the first "X-Factor" series, published in early 1991, Apocalypse kidnaps Nathan Summers, sensing that he would grow up to be a powerful mutant and possible threat. X-Factor rescue Nathan from Apocalypse's lunar base, but find him infected with a "techno-organic" virus that cannot be treated. A clan of rebels from the future, known as the Askani, send a representative to the present time to bring Nathan 2,000 years into the future to be treated. Fully grown, he returns to the 20th century as the antihero, Cable.
X-Factor, the X-Men, and several minor characters team up to fight the telepathic Shadow King in another crossover event, "The Muir Island Saga". Afterward, the original members of X-Factor rejoin the X-Men and several characters from various X-Men-related series become founding members of a new X-Factor.
Government team (1991-1998).
Rather than end the series, Marvel hired writer Peter David and illustrator Larry Stroman to recreate X-Factor with new members, all of whom were already allies of the X-Men, and three of whom were involved in the "Muir Island Saga". The new X-Factor worked for the Pentagon, replacing Freedom Force as the government's salaried mutant team. Their relationship with their benefactors was often strained and complicated. The new X-Factor, debuting in issue #71, included:
The lineup was selected by the "X-Factor" editorial staff. Legion was to be a member as well, but was dropped because it was felt the character was not suited to be a team player. David was instead given the option to use Quicksilver, which he has said was a pleasant surprise.
Commenting on his approach to the series, David said that his priority was to tell stories which developed the individual characters of the team, remarking "I feel there's nothing unique to the book if you come up with a generic plot and just plug in these characters."
David left in 1993. The series continued under writer J. M. DeMatteis and artist Jan Duursema, but struggled to distinguish itself among other X-books. Shortly after David's tenure on the book ended, Forge, a former government weapons contractor whose mutant powers were his brilliant engineering skills, was added to the group; first replacing Cooper as their liaison after she had been compromised by one of Magneto's Acolytes, and later as an active member. Cooper later becomes an active member as well, her marksmanship and athletic skills compensating for her lack of superhuman powers.
In a 1995 story, Multiple Man apparently dies of the Legacy Virus, a deadly illness that attacks mutant genes, which is later revealed to have only killed one of his duplicates. Strong Guy is put into suspended animation after suffering a heart attack caused by the stress his extra mass put on his body. Wolfsbane, cured of her artificial love for Alex, transfers to the European mutant team Excalibur. Havok leaves to infiltrate a mutant terrorist ring.
Writer John Francis Moore and illustrator Jeff Matsuda introduced a new X-Factor line-up, consisting of Forge as the team's new leader, Polaris, Cooper, and several new recruits:
Afterward, writer Howard Mackie injected more political and espionage elements into the series, a trend that culminated in the team's secession from government sponsorship. Multiple Man and Strong Guy appear again at the same time. Despite Forge managing to fix Strong Guy's problems, he does not rejoin the team. The popularity of "X-Factor" continued to dwindle and Mystique and Sabretooth, two popular X-Men villains, failed to draw in more readers. Wild Child mutates out of control, Mystique hunts down Sabretooth (who had kidnapped young Tyler Trevor Chase), and Forge breaks ties with X-Factor.
In 1997, Marvel attempted yet another revival. After various stories focusing on individual characters, a new team was gathered consisting of Havok, Multiple Man, Polaris, Shard, and other members of the X.S.E., Fixx, and Greystone, that are brought to the 20th century (their teammate Archer, who also came back in time, turns down an offer to join). However, this version of the team disbands in the same issue in which they debut. In that issue, #149 (1998), Greystone builds a time machine meant to take him and his compatriots back to the future. However, the device explodes, killing Greystone and Havok. Afterward, X-Factor disbands.
The time machine's explosion transports Havok to a parallel world, populated by twisted versions of Marvel characters. He explores this strange world in the series "Mutant X", which lasted from 1998 until 2001. Although Marvel planned to revive "X-Factor" as an ongoing title after "Mutant X" ended, this did not happen for another 4 years.
Volume 2 (2002 miniseries).
A four-issue "X-Factor" limited series was launched in 2002. This series focused on the government's new Mutant Civil Rights Task Force, which consisted of humans who investigated anti-mutant hate crimes and inadvertently discovered an anti-mutant conspiracy within their own ranks. This series focused heavily on the "mutants as a metaphor for minorities" aspects of the X-Men concept.
Volume 3 (2005–2013).
X-Factor Investigations is a detective agency run by Jamie Madrox, formerly known as Multiple Man. The name is taken from the government-sponsored group the three founders previously served on. The initial staff consists of Madrox's best friend and special enforcer, Guido Carosella (Strong Guy), and former teammate Rahne Sinclair (Wolfsbane). Following the events of the "House of M" storyline, Madrox's new-found wealth from winning a "Who Wants to Be a Millionaire?"-style game show allows him to recruit several of his former colleagues from the Paris branch of the now defunct X-Corporation. New members include M (Monet), a powerless Rictor, Siryn, and Layla Miller, who inserts herself into the group to keep them from discovering the truth behind the "Decimation" storyline.
Peter David put a noir spin on the mutant series and dealt with Jamie Madrox as the central character. The new series spun off of the "House of M" and "Decimation" storylines and opens with a suicide attempt by Rictor, who has lost his powers. The series deals with the group's attempt to unravel the truth behind the "Decimation" and its aftermath, fighting with Singularity Investigations, and dealing with Madrox's powers and their consequences.
During the "Messiah Complex" storyline, Jamie and Layla travel to a dystopian future in which mutants are persecuted and imprisoned. Jamie escapes and returns to the early 21st century, but Layla is still trapped. Rahne fears (because of a glimpse she has had of the future) that she, while in her wolf shape, will murder Jamie and Layla. To prevent this, she quits the team and joins X-Force. Rictor also quits. Jamie travels to the future with the help of an aged Layla Miller and helps a rebellion led by a cyborg Scott Summers and his daughter Ruby, while the rest of the team is in the present. After battling Arcade, who captured Rictor (who then rejoins), the team is joined by the real Longshot and Darwin and meets one of Jamie's duplicates, who calls himself Cortex.
Writer Peter David's decision to explicitly establish male characters Shatterstar and Rictor entering a romantic relationship in "X-Factor" #45 (August 2009), confirming clues that had been established in "X-Force" years earlier, drew criticism from Shatterstar's co-creator, Rob Liefeld, though Editor-in-Chief Joe Quesada supported David's story. David would eventually be nominated for and win a 2011 GLAAD Media Award for Outstanding Comic Book for this second run on the title.
In December 2009, the series adopted a cumulative numbering with issue #200, with 149 issues of the first volume plus 50 issues of the third volume constituting the previous 199 issues.
The series ended with issue #262 in September 2013.
"All-New X-Factor".
The next incarnation of the series was "All-New X-Factor", written by Peter David and illustrated by 
Carmine Di Giandomenico. This version was announced as a part of the All-New Marvel NOW! initiative at the New York Comic Con in October 2013, and debuted in January 2014. The opening storyline, which continues events from issue #260 of the previous series, and depicts the corporation "Serval Industries" forming a new corporate-sponsored version of the team, which includes Polaris, Quicksilver, Gambit, Danger, Cypher and Warlock.
Other versions.
In "Ultimate War", X-Factor is a U.S. operated prison camp for mutants in Cuba, which appears to have been named after Camp X-Ray in Guantanamo Bay.
In other media.
X-Factor appeared in the "X-Men" episode "Cold Comfort". Its lineup consisted of Forge, Polaris, Multiple Man, Strong Guy, Quicksilver, Havok, and Wolfsbane. Iceman broke into their facility to find his girlfriend Polaris and ran afoul of the X-Men. When it came to a battle against the X-Factor, Forge said it was to test them. In "Family Ties," Quicksilver was again seen as a member of X-Factor and in "The Phalanx Covenant Part 1 & 2" Quicksilver, Forge and Polaris appear as members of X-Factor.

</doc>
<doc id="34218" url="http://en.wikipedia.org/wiki?curid=34218" title="X-Men">
X-Men

The X-Men are a fictional team of superheroes appearing in American comic books published by Marvel Comics. Created by writer Stan Lee and artist/co-writer Jack Kirby, the characters first appeared in "The X-Men" #1 (September 1963). They are among Marvel Comics' most popular and lucrative intellectual properties, appearing in numerous books, television shows, films, and video games.
The X-Men are mutants, a subspecies of humans who are born with superhuman abilities. The X-Men fight for peace and equality between normal humans and mutants in a world where antimutant bigotry is fierce and widespread. They are led by Charles Xavier, also known as Professor X, a powerful mutant telepath who can control and read minds. Their archenemy is traditionally Magneto, a powerful mutant with the ability to generate and control magnetic fields. Professor X and Magneto have opposing views and philosophies regarding the relationship between mutants and humans. While Professor X works towards peace and understanding between mutants and humans, Magneto views humans as a threat and believes in taking an aggressive approach against them.
Professor X is the founder of Xavier's School for Gifted Youngsters at a location commonly called the X-Mansion, which recruits mutants from around the world. Located in Westchester County, New York, the X-Mansion is the home and training site of the X-Men. The founding five members of the X-Men who appear in "The X-Men" #1 (September 1963) are Angel (Archangel), Beast, Cyclops, Iceman, and Marvel Girl (Jean Grey); Professor X and Magneto also make their first appearances in "The X-Men" #1. Since then, dozens of mutants have held membership as X-Men, with notable members such as Colossus, Psylocke, Gambit, Kitty Pryde, Nightcrawler, Rogue, Storm, and Wolverine, among others.
Publication history.
In 1963, with the success of Spider-Man in "Amazing Fantasy", as well as the Hulk, Thor, Iron Man, and the Fantastic Four, co-creator Stan Lee wanted to create another group of superheroes without coming up with new origins for how they got their powers. In 2004, Stan Lee recalled:
In a 1987 interview, Jack Kirby said, "The X-Men, I did the natural thing there. What would you do with mutants who were just plain boys and girls and certainly not dangerous? You school them. You develop their skills. So I gave them a teacher, Professor X. Of course, it was the natural thing to do, instead of disorienting or alienating people who were different from us, I made the X-Men part of the human race, which they were. Possibly, radiation, if it is beneficial, may create mutants that’ll save us instead of doing us harm. I felt that if we train the mutants our way, they’ll help us - and not only help us, but achieve a measure of growth in their own sense. And so, we could all live together."
Lee devised the series title after Marvel publisher Martin Goodman turned down the initial name, "The Mutants," stating that readers would not know what a "mutant" was. Within the Marvel Universe, the X-Men are widely regarded to have been named after Professor Xavier himself. Xavier however claims that the name "X-Men" was never chosen to be a self-tribute. The name is also linked to the "X-Gene," an unknown gene that causes the mutant evolution. The original explanation for the name, as provided by Xavier in "The X-Men" #1 (1963), is that mutants "possess an extra power... one which ordinary humans do not!! That is why I call my students... X-Men, for EX-tra power!" 
1960s.
Early "X-Men" issues introduced the original team composed of Cyclops, Marvel Girl, Beast, Angel, and Iceman, along with their archenemy Magneto and his Brotherhood of Evil Mutants featuring Mastermind, Quicksilver, Scarlet Witch, and Toad. The comic focused on a common human theme of good versus evil and later included storylines and themes about prejudice and racism, all of which have persisted throughout the series in one form or another. The evil side in the fight was shown in human form and under some sympathetic beginnings via Magneto, a character who was later revealed to have survived Nazi concentration camps only to pursue a hatred for normal humanity. His key followers, Quicksilver and the Scarlet Witch, were Romani. Only one new member of the X-Men was added, Mimic/Calvin Rankin, but soon left due to his temporary loss of power.
The title lagged in sales behind Marvel's other comic franchises. In 1969, writer Roy Thomas and illustrator Neal Adams rejuvenated the comic book and gave regular roles to two recently introduced characters: Havok/Alex Summers (who had been introduced by Roy Thomas before Adams began work on the comic) and Lorna Dane, later called Polaris (created by Arnold Drake and Jim Steranko). However, these later "X-Men" issues failed to attract sales and Marvel stopped producing new stories with issue #66, later reprinting a number of the older comics as issues #67–93.
1970s.
In "Giant-Size X-Men" #1 (1975), writer Len Wein and artist Dave Cockrum introduced a new team that then starred in a revival of "The X-Men", beginning with issue #94. This new team, however, differed greatly from the original. Unlike in the early issues of the original series, the new team was not made up of teenagers and they also had a more diverse background. Each was from a different country with varying cultural and philosophical beliefs, and all were already well-versed in using their mutant powers, several being experienced in combat. The "all-new, all-different X-Men" were led by Cyclops, from the original team, and consisted of the newly created Colossus (from the Soviet Union), Nightcrawler (from West Germany), Storm (from Kenya), and Thunderbird (a Native American from the Apache nation). In addition to the newly created members were three previously introduced characters: Banshee (from Ireland), Sunfire (from Japan), and Wolverine (from Canada). Wolverine eventually became the breakout character on the team and, in terms of comic sales and appearances, the most popular X-Men character. A revamped Jean Grey soon rejoined the X-Men as the popular "Phoenix". Angel, Beast, Havok, and Polaris also made significant guest appearances.
The revived series was illustrated by Cockrum, and later by John Byrne, and written by Chris Claremont. Claremont became the series' longest-running contributor. The run met with critical acclaim and produced such early storylines as the death of Thunderbird, the return of the Sentinels and the emergence of Phoenix, the saga of the Starjammers and the fight for control of the M'Kraan Crystal, the resurrection of Garokk the Petrified Man, the introduction of Alpha Flight and the Proteus saga. Other characters introduced during this time include Amanda Sefton, Multiple Man, Mystique, and Moira MacTaggert, with her genetic research facility on Muir Island.
1980s.
The 1980s began with the comic's best-known story arc, the Dark Phoenix Saga, which saw Phoenix manipulated by the illusionist Mastermind and becoming corrupted with an overwhelming lust for power and destruction as the evil Dark Phoenix. Other important storylines included "Days of Future Past," the saga of Deathbird and the Brood, the discovery of the Morlocks, the invasion of the Dire Wraiths and "The Trial of Magneto," as well as "," the partial inspiration for the 2003 movie "X2: X-Men United."
By the early 1980s, "X-Men" was Marvel's top-selling comic title. Its sales were such that distributors and retailers began using an "X-Men index", rating each comic book publication by how many orders it garnered compared to that month's issue of "X-Men". The growing popularity of "Uncanny X-Men" and the rise of comic book specialty stores led to the introduction of a number of ongoing spin-off series nicknamed "X-Books." The first of these was "The New Mutants", soon followed by "Alpha Flight", "X-Factor", "Excalibur", and a solo "Wolverine" title. When Claremont conceived a story arc, the "Mutant Massacre", which was too long to run in the monthly "X-Men", editor Louise Simonson decided to have it overlap into several X-Books. The story was a major financial success, and when the later "Fall of the Mutants" was similarly successful, the marketing department declared that the X-Men lineup would hold such crossovers annually.
Throughout the decade, "Uncanny X-Men" was written solely by Chris Claremont, and illustrated for long runs by John Byrne, Dave Cockrum, Paul Smith, John Romita, Jr., and Marc Silvestri. Additions to the X-Men during this time were Kitty Pryde/Shadowcat, Dazzler, Forge, Longshot, Psylocke, Rogue, Rachel Summers/Phoenix, and Jubilee. In a controversial move, Professor X relocated to outer space to be with Lilandra, Majestrix of the Shi'ar Empire, in 1986. Magneto then joined the X-Men in Xavier's place and became the director of the New Mutants. This period also included the emergence of the Hellfire Club, the arrival of the mysterious Madelyne Pryor, and the villains Apocalypse, Mister Sinister, Mojo, and Sabretooth.
1990s.
In 1991, Marvel revised the entire lineup of X-Books, centered on the launch of a second X-Men series, simply titled "". With the return of Xavier and the original X-Men to the team, the roster was split into two strike forces: Cyclops' "Blue Team" (chronicled in "X-Men") and Storm's "Gold Team" (in "Uncanny X-Men").
Its first issues were written by longstanding X-Men writer Chris Claremont and drawn and co-plotted by Jim Lee. Retailers pre-ordered over 8.1 million copies of issue #1, generating and selling nearly $7 million (though retailers probably sold closer to 3 million copies ), making it the best-selling comic book of all-time, according to Guinness Book of World Records, which presented honors to Claremont at the 2010 San Diego Comic-Con.
Another new X-book released at the time was "X-Force", featuring the characters from "The New Mutants", led by Cable; it was written by Rob Liefeld and Fabian Nicieza. Internal friction soon split the X-books' creative teams. In a controversial move, X-Men editor Bob Harras sided with Lee (and "Uncanny X-Men" artist Whilce Portacio) over Claremont in a dispute over plotting. Claremont left after only three issues of "X-Men", ending his 16-year run as "X-Men" writer. Marvel replaced Claremont briefly with John Byrne, who scripted both books for a few issues. Byrne was then replaced by Nicieza and Scott Lobdell, who would take over the majority of writing duties for the X-Men until Lee's own departure months later when he and several other popular artists (including former X-title artists Liefeld, Portacio, and Marc Silvestri) would leave Marvel to form Image Comics. Jim Lee's X-Men designs would be the basis for much of the "X-Men" animated series and action figure line as well as several Capcom video games.
The 1990s saw an even greater number of X-books with numerous ongoing series and miniseries running concurrently. X-book crossovers continued to run annually, with "" in 1990, "The Muir Island Saga" in 1991, "X-Cutioner's Song" in 1992, "Fatal Attractions" in 1993, "Phalanx Covenant" in 1994, "Legion Quest"/"Age of Apocalypse" in 1995, "Onslaught" in 1996, and "" in 1997. Though the frequent crossovers were criticized by fans as well as editorial and creative staff for being artificially regular, disruptive to the direction of the individual series, and having far less lasting impact than promised, they continued to be financially successful.
There were many new popular additions to the X-Men in the 1990s, including Gambit, Cable, and Bishop. Gambit became one of the most popular X-Men, rivaling even Wolverine in size of fanbase after his debut in "Uncanny X-Men" #266 (Aug. 1990). Many of the later additions to the team came and went, such as Joseph, Maggott, Marrow, Cecilia Reyes, and a new Thunderbird. Xavier's New Mutants grew up and became "X-Force", and the next generation of students began with "Generation X", featuring Jubilee and other teenage mutants led and schooled by Banshee and former villainess Emma Frost at her Massachusetts Academy. In 1998, "Excalibur" and "X-Factor" ended and the latter was replaced with "Mutant X", starring Havok stranded in a parallel universe. Marvel launched a number of solo series, including "Deadpool", "Cable", "Bishop", "X-Man", and "Gambit", but few of the series would survive the decade.
2000s.
In 2000, Claremont returned to Marvel and was put back on the primary X-Men titles during the "Revolution" event. He was later removed from the two flagship titles in 2001 and created his spin-off series, "X-Treme X-Men". "X-Men" had its title changed to "New X-Men" and writer Grant Morrison took over. The book is often referred to as the Morrison-era, due to the drastic changes he made, beginning with "E Is For Extinction," where a new villain, Cassandra Nova, destroys Genosha, killing sixteen million mutants. Morrison also brought reformed ex-villain Emma Frost into the primary X-Men team, and opened the doors of the school by having Xavier "out" himself to the public about being a mutant. The bright spandex costumes that had become iconic over the previous decades were replaced by black leather street clothes reminiscent of the uniforms of the "X-Men" films. Morrison also introduced Xorn, who would figure prominently in the climax of his run. "Ultimate X-Men" set in Marvel's revised imprint was also launched. While Chuck Austen began his controversial run on "Uncanny X-Men".
Several short-lived spin-offs and miniseries started featuring several X-Men in solo series, such as Emma Frost, Gambit, Mystique, Nightcrawler, and Rogue. Another series, "Exiles," started at the same time and concluded in December 2007 which led to "New Exiles" in January 2008 written by Claremont. Cable and Deadpool's books were merged into one book, "Cable & Deadpool". Following Morrison's departure, a third core X-Men title, "Astonishing X-Men" was launched which was written by Joss Whedon. "New X-Men: Academy X" was also launched focusing on the lives of the new young mutants at the Institute. This period included the resurrections of Colossus and Psylocke, a new death for Jean Grey, who later returned temporarily in the ", as well as Emma Frost becoming the new headmistress of the Institute. The Institute formerly ran as a school, until the depowering of 98% of the mutant population served as a safe haven to mutants who are still powered.
In 2007, the " crossover saw the destruction of the Xavier Institute and the disbanding of the X-Men. It spun the new volumes of "X-Force," following the team led by Wolverine, and "Cable," following Cable's attempts at protecting Hope Summers. "X-Men" was renamed into "X-Men: Legacy" which focused on Professor X, Rogue and Gambit. Under Cyclops' leadership, the X-Men later reformed in "Uncanny X-Men" #500, with their new base located in San Francisco. "Uncanny X-Men" returned to its roots as the flagship title for the X-Franchise and served as the umbrella under which the various X-Books co-exist. In 2009, "Messiah War" written by Craig Kyle and Chris Yost served as the second part in the trilogy that began with "Messiah Complex" was released. "Utopia" written by Matt Fraction, was a crossover of Dark Avengers and Uncanny X-Men that served as a part of the Dark Reign storyline. A new "New Mutants" volume written by Zeb Wells, which featured the more prominent members of the original team reunited was launched. Magneto joined the X-Men during the Nation X storyline to the dismay of other members of the X-Men, such as Beast, who left the team. Magneto began to work with Namor to transform Utopia into a homeland for both mutants and Atlanteans. After the conclusion of "Utopia", Rogue became the main character of "X-Men: Legacy".
Notable additions to the X-Men have been Emma Frost, Husk, Northstar, Armor, Pixie and Warpath. While former villains such as Juggernaut, Lady Mastermind, Mystique, and Sabretooth became members of the X-Men. Other notable story arcs of this decade are "E Is For Extinction" (2001), "Planet X," "Here Comes Tomorrow," "Gifted" (2004), "House of M" (2005), " (2005–2006), " (2007), " (2008), " (2008–2009), "X-Infernus," and "Necrosha" (2009). The X-Men were also involved in the "Secret Invasion" storyline.
2010s.
In 2010, "" continued the plot threads on "Messiah Complex" and "House of M", while in 2012, "Avengers vs. X-Men" served as a closure to story lines such as "House of M" and "Decimation". It also ended with the death of Professor X and reappearance of new mutants. The aftermath of the "" (2011) led to the fallout between Wolverine and Cyclops. Featured in a new series titled "Wolverine and the X-Men", Wolverine rebuilt the original X-Mansion and named it as Jean Grey School for Higher Learning.
As part of the Marvel NOW! relaunch in 2012, many of the X-Men titles were canceled and relaunched, including "X-Force", "X-Factor", "X-Men: Legacy", "X-Men", and "Uncanny X-Men". The relaunched "Uncanny X-Men" features Cyclops, his team, and the new mutants, taking up residency in the Weapon X facility, which they have rebuilt into a school and named as the New Charles Xavier School for Mutants. New flagship titles such as "Amazing X-Men", "Uncanny Avengers" and "All New X-Men" were launched. "Uncanny Avengers" featured a team of Avengers and X-Men members while "All-New X-Men" featured the original five X-Men members being brought to the present day. In 2013, for the 50th anniversary of the X-Men franchise, "Battle of the Atom" was published which involved members of both X-Men schools try to decide what to do about the time-displaced original X-Men.
Notable additions to the X-Men have been X-23, Hope Summers, X-Man and Blink. Other notable story arcs of this decade are "Curse of the Mutants" (2010-2011), "Age of X", "" (2011) and "AXIS" (2014).
World of the X-Men.
The X-Men exist in the Marvel Universe along with other characters featured in Marvel Comics series. They often meet characters from other series, and the global nature of the mutant concept means the scale of stories can be highly varied. The X-Men's enemies range from mutant thieves to galactic threats.
Historically, the X-Men have been based in the Xavier Institute, near Salem Center, in north-east Westchester County, New York, and are often portrayed as a family. The X-Mansion is often depicted with three floors and two underground levels. To the outside world, it acted as a higher learning institute until the 2000s, when Xavier was publicly exposed as a mutant at which point it became a known mutant boarding school. Xavier funds a corporation aimed at reaching mutants worldwide, though it ceased to exist following the "Decimation." The X-Men benefit from advanced technology such as Xavier tracking down mutants with a device called Cerebro which amplifies his powers; the X-Men train within the Danger Room, first depicted as a room full of weapons and booby traps, now as generating holographic simulations; and the X-Men travel in their Blackbird jet.
Fictional places.
The X-Men introduced several fictional locations which are regarded as important within the shared universe in which Marvel Comics characters exist:
Reflecting social issues.
The conflict between mutants and normal humans is often compared to real-world conflicts experienced by minority groups in America such as African Americans, Jews, various religious (or "non-religious") groups, Communists, the LGBT community, etc. It has been remarked that attitudes towards mutants do not make sense in the context of the Marvel Universe, since non-mutants with similar powers are rarely regarded with fear; "X-Men" editor Ann Nocenti remarked that "I think that's literary, really - because there is no difference between Colossus and the Torch. If a guy comes into my office in flames, or a guy comes into my office and turns to steel, I'm going to have the same reaction. It doesn't really matter that I know their origins. [...] as a book, "The X-Men" has always represented something different - their powers arrive at puberty, making them analogous to the changes you go through at adolescence - whether they're special, or out of control, or setting you apart - the misfit identity theme." Also on an individual level, a number of X-Men serve a metaphorical function as their powers illustrate points about the nature of the outsider.
"The X-Men are hated, feared and despised collectively by humanity for no other reason than that they are mutants. So what we have here, intended or not, is a book that is about racism, bigotry and prejudice."
—"Uncanny X-Men" writer Chris Claremont, 1981 
Cultural impact.
The insecurity and anxieties in Marvel's early 1960s comic books such as "The Fantastic Four," "The Amazing Spider-Man," "The Incredible Hulk," and "X-Men" ushered in a new type of superhero, very different from the certain and all-powerful superheroes before them, and changed the public's perception of superheroes.

</doc>
<doc id="34220" url="http://en.wikipedia.org/wiki?curid=34220" title="X rating">
X rating

In some countries, X or XXX is or has been a motion picture rating reserved for the most explicit films. Films rated X are intended only for viewing by adults, usually legally defined as people over the age of 18 or 21.
Australia.
The Australian Classification Board (ACB), a government institution, issues ratings for all movies and television shows sold or aired. Material showing explicit, non-simulated sex that is pornographic in nature is rated X18+.
People under 18 may not buy, rent, exhibit or view these films. The exhibition or sale of these films to people under the age of 18 years is a criminal offence carrying a maximum fine of $5,500.
Films classified as X18+ are banned from being sold or rented in most Australian states. They are legally available to be sold in the Australian Capital Territory and the Northern Territory. 
Importing X18+ material from these territories to any of the Australian states is legal, as the constitution forbids any restrictions on trade between the states and territories. 
The X18+ rating does not exist for video or computer games.
France.
Films may be shown in theaters in France only after classification by an administrative commission of the ministry of Culture. In 1975, the X classification (officially: "pornographic or violence-inciting movies") was created for pornographic movies, or movies with successions of scenes of graphic violence. The commission has some leeway in classification, it may for instance take into account the artistic qualities of a movie not to count it pornographic.
Movies with an X rating may only be shown in specific theaters (which hardly exist nowadays in France); they bear special taxes and tax rates, including a 33% tax on revenue.
In 2000, some conservative associations sued the government for granting the movie "Baise-moi", which contained graphic, realistic scenes of sex and violence, a non-X classification. The "Conseil d'État" at litigation ruled that the movie should have been rated X. The decision was highly controversial, and some suggested changing the law under which it was rated 18.
United Kingdom.
The original X certificate, replacing the H certificate, was issued between 1951 and 1982 by the British Board of Film Censors in the United Kingdom. It was introduced as a result of the Wheare Report on film censorship. From 1951 to 1970, it meant "Suitable for those aged 16 and over," and from 1970 to 1982 it was redefined as meaning "Suitable for those aged 18 and over". The X certificate was replaced in November 1982 by the 18 certificate.
Sometimes the rating of a film has changed significantly over time. For example the French film "Jules and Jim" received an X rating in 1962 that was changed to a PG rating in 1991. In some early cases, films politically motivated received an X rating. "The Battleship Potemkin" was rejected for "inflammatory subtitles and Bolshevik propaganda" in 1926, rated X in 1954, and finally rated PG in 1987.
United States.
In the United States, the X rating was applied to a film that contained content judged unsuitable for children, such as extreme violence, strongly implied sex, and graphic language. When the MPAA film rating system began in the US on November 1, 1968, the X rating was given to a film by the MPAA if submitted to it or, due to its non-trademarked status, it could be self-applied to a film by a distributor that knew beforehand that its film contained content unsuitable for minors. From the late 1960s to about the mid-1980s, many mainstream films were released with an X rating such as "Midnight Cowboy", "Last of the Mobile Hot Shots", "Beyond the Valley of the Dolls", "A Clockwork Orange", "Fritz the Cat", "Last Tango in Paris" and "The Evil Dead". (Films that achieved critical and commercial success were later re-rated R after minor cuts, including "Midnight Cowboy" and "A Clockwork Orange.") The threat of an X rating also encouraged filmmakers to re-edit their films to achieve an R rating. Certain films, such as "Cruising" (1980), received an R rating that some theatre owners felt should have been an X ("Cruising" was withdrawn from distribution after it was clear that required cuts to obtain the R rating had not been made). 
Because the X rating was not trademarked, anybody could apply it to their films, including pornographers, as many began to do in the 1970s. As pornography began to become chic and more legally tolerated, pornographers placed an X rating on their films to emphasize the adult content. Some even started using multiple X's (i.e. XX, XXX, etc.) to give the impression that their film contained more graphic sexual content than the simple X rating. In some cases, the X ratings were applied by reviewers or film scholars, e.g. William Rotsler, who wrote "The XXX-rating means hard-core, the XX-rating is for simulation, and an X-rating is for comparatively cool films." Nothing beyond the simple X rating has ever been officially recognized by the MPAA. Because of the heavy use of the X rating by pornographers, it became associated largely with pornographic films, so that non-pornographic films given an X rating would have fewer theaters willing to book them and fewer venues for advertising. Moreover, many newspapers refused to advertise X rated films. This led to a number of films being released unrated sometimes with a warning that the film contained content for adults only. In response, the MPAA eventually agreed in 1990 to a new NC-17 rating that would be trademarked, and could only be applied by the MPAA itself. By trademarking the rating, the MPAA committed to defending a NC-17 film charged with violating obscenity laws.

</doc>
<doc id="34223" url="http://en.wikipedia.org/wiki?curid=34223" title="Southern platyfish">
Southern platyfish

The southern platyfish, common platy, moonfish or mickey mouse platy ("Xiphophorus maculatus") is a species of freshwater fish in family Poecilidae of order Cyprinodontiformes. A live-bearer, it is closely related to the green swordtail ("X. helleri") and can interbreed with it. It is native to an area of North and Central America stretching from Veracruz, Mexico, to northern Belize.
The southern platyfish grows to a maximum overall length of 6.0 cm. Sexual dimorphism is slight, the male’s caudal fin being more pointed. The anal fin of the male fish has evolved into a gonopodium, a stick-shaped organ used for reproduction. The female southern platyfish's anal fin is fan shaped. Wild varieties are drab in coloration, lacking the distinctive dark lateral line common to many "Xiphophorus" species.
"X. maculatus" prefers slow-moving waters of canals, ditches, and warm springs. Omnivorous, its diet includes both plants and small crustaceans, insects, and annelid worms.
Breeders have developed a multitude of color varieties (e.g. orange, red, yellow, red/black, and black/white) which are common aquarium fish for hobbyists.
The southern platyfish is commonly known simply as the platy (pl. platys or platies), from the fish’s original generic name, "Platypoecilus."
Nonindigenous occurrences.
This species has been recorded from: Orange County, California, near Westminster; near a fish farm in Conejos County and the South Platte drainage, Colorado; several counties in Florida; Hawaii; an unnamed tributary to Big Branch Bayou in Lacombe, Louisiana; Beaverhead Rock Pond (Madison County), Montana; Clark County, Nevada; and Texas. It has also been collected in the Loiza drainage near Loiza Reservoir, Quebrada Honda, and Rio Abajo Forest Station north of Utuado in Puerto Rico.
The southern platyfish has been released probably due to fish farm or aquarium releases. Specimens in Louisiana were collected near a tropical fish farm. Southern platies, and other introduced poeciliids, have been implicated in the decline of native damselflies on Oahu, Hawaii. Often the distributions of the damselflies and introduced fishes were found to be mutually exclusive, probably resulting from competition for limited insect food.
In the aquarium.
Platies are easy to keep and well suited to a community aquarium. They prefer water with a 7.0–8.0 pH, a water hardness of 9.0–19.0 dGH, and a temperature range of 18 –.
In captivity, they reach maturity in three to four months, and breed readily, the females giving birth to about 20–40 young at a time.
The fish commonly sold in pet shops is not a pure strain of "X. maculatus", but is a hybrid between "X. hellerii" and "X. maculatus". In general, if the male has a sword-shaped tail, they are called swordtails. Otherwise, they are labeled platy. Color and fin shape vary wildly in the aquarium trade.
A common statement in the trade is that it is harder to stop them breeding than to make them do so, with ‘surprise’ fry appearing in community tanks regularly.
Genetics.
The genome of Xiphophorus maculatus was sequenced in 2013.

</doc>
<doc id="34225" url="http://en.wikipedia.org/wiki?curid=34225" title="Yahoo (Gulliver's Travels)">
Yahoo (Gulliver's Travels)

A Yahoo is a legendary being in the novel "Gulliver's Travels" (1726) by Jonathan Swift. 
Swift describes them as being filthy and with unpleasant habits, resembling human beings far too closely for the liking of protagonist Lemuel Gulliver, who finds the calm and rational society of intelligent horses, the Houyhnhnms, greatly preferable. The Yahoos are primitive creatures obsessed with "pretty stones" they find by digging in mud, thus representing the distasteful materialism and ignorant elitism Swift encountered in Britain. Hence the term "yahoo" has come to mean "a crude, brutish or obscenely coarse person".
American frontiersman Daniel Boone, who often used terms from "Gulliver's Travels", claimed that he killed a hairy giant that he called a Yahoo.
Yahoos were referred to in a letter sent by serial killer David Berkowitz to New York City police while committing the "Son of Sam" murders in 1976.

</doc>
<doc id="34226" url="http://en.wikipedia.org/wiki?curid=34226" title="Yuri Gagarin">
Yuri Gagarin

Yuri Alekseyevich Gagarin (Russian: Ю́рий Алексе́евич Гага́рин; ]; 9 March 1934 – 27 March 1968) was a Russian Soviet pilot and cosmonaut. He was the first human to journey into outer space, when his Vostok spacecraft completed an orbit of the Earth on 12 April 1961.
Gagarin became an international celebrity, and was awarded many medals and titles, including Hero of the Soviet Union, the nation's highest honour. Vostok 1 marked his only spaceflight, but he served as backup crew to the Soyuz 1 mission (which ended in a fatal crash). Gagarin later became deputy training director of the Cosmonaut Training Centre outside Moscow, which was later named after him. Gagarin died in 1968 when the MiG-15 training jet he was piloting crashed.
Early life and education.
Yuri Gagarin was born in the village of Klushino, near Gzhatsk (renamed Gagarin in 1968 after his death), on 9 March 1934. His parents worked on a collective farm: Alexey Ivanovich Gagarin as a carpenter and bricklayer, and Anna Timofeyevna Gagarina as a milkmaid. Yuri was the third of four children: older brother Valentin, older sister Zoya, and younger brother Boris.
Like millions of people in the Soviet Union, the Gagarin family suffered during Nazi occupation in World War II. Klushino was occupied in November 1941 during the German advance on Moscow, and an officer took over the Gagarin residence. The family was allowed to build a mud hut, approximately 3 by inside, on the land behind their house, where they spent a year and nine months until the end of the occupation. His two older siblings were deported by the Germans to Poland for slave labour in 1943, and did not return until after the war in 1945. In 1946, the family moved to Gzhatsk, where Gagarin continued his secondary education.
Another version of Gagarin's biography suggests that his family fled east to the Ural Mountains before the German army reached Gzhatsk in 1941, and they returned only when the war ended.
At the age of 16 in 1950, Gagarin entered into an apprenticeship as a foundryman at the Lyubertsy Steel Plant near Moscow, and also enrolled at a local "young workers" school for seventh grade evening classes. After graduating in 1951 from both the seventh grade and the vocational school (with honours in moldmaking and foundry-work), he was selected for further training at the Saratov Industrial Technical School, where he studied tractors. While in Saratov, Gagarin volunteered for weekend training as a Soviet air cadet at a local flying club, where he learned to fly — at first in a biplane and later in a Yak-18 trainer. He also earned extra money as a part-time dock laborer on the Volga River.
Career in the Soviet Air Force.
After graduating from the technical school in 1955, the Soviet Army drafted Gagarin. On a recommendation, Gagarin was sent to the First Chkalov Air Force Pilot's School in Orenburg, and soloed in a MiG-15 in 1957. While there he met Valentina Ivanovna Goryacheva, a medical technician graduate of the Orenburg Medical School. They were married on 7 November 1957, the same day Gagarin graduated from Orenburg.
Post-graduation, he was assigned to the Luostari airbase in Murmansk Oblast, close to the Norwegian border, where terrible weather made flying risky. He became a Lieutenant in the Soviet Air Forces on 5 November 1957; on 6 November 1959 he received the rank of Senior Lieutenant.
Career in the Soviet space program.
Selection and training.
In 1960, after much searching and a selection process, Yuri Gagarin was chosen with 19 other pilots for the Soviet space program. Gagarin was further selected for an elite training group known as the Sochi Six, from which the first cosmonauts of the Vostok programme would be chosen. Gagarin and other prospective candidates were subjected to experiments designed to test physical and psychological endurance; he also underwent training for the upcoming flight. Out of the twenty selected, the eventual choices for the first launch were Gagarin and Gherman Titov due to their performance during training sessions as well as their physical characteristics — space was limited in the small Vostok cockpit, and both men were rather short. Gagarin was 1.57 m tall.
In August 1960, when Gagarin was one of 20 possible candidates, an Air Force doctor evaluated his personality as follows:
Modest; embarrasses when his humor gets a little too racy; high degree of intellectual development evident in Yuriy; fantastic memory; distinguishes himself from his colleagues by his sharp and far-ranging sense of attention to his surroundings; a well-developed imagination; quick reactions; persevering, prepares himself painstakingly for his activities and training exercises, handles celestial mechanics and mathematical formulae with ease as well as excels in higher mathematics; does not feel constrained when he has to defend his point of view if he considers himself right; appears that he understands life better than a lot of his friends.—Soviet Air Force doctor
Gagarin was also a favoured candidate by his peers. When the 20 candidates were asked to anonymously vote for which other candidate they would like to see as the first to fly, all but three chose Gagarin. One of these candidates, Yevgeny Khrunov, believed that Gagarin was very focused, and was demanding of himself and others when necessary.
Gagarin kept physically fit throughout his life, and was a keen sportsman. Cosmonaut Valery Bykovsky wrote:
Service in the Air Force made us strong, both physically and morally. All of us cosmonauts took up sports and PT seriously when we served in the Air Force. I know that Yuri Gagarin was fond of ice hockey. He liked to play goal keeper... I don't think I am wrong when I say that sports became a fixture in the life of the cosmonauts.
In addition to being a keen ice hockey player, Gagarin was also a basketball fan, and coached the Saratov Industrial Technical School team, as well as being a referee.
Vostok 1.
On 12 April 1961, the Vostok 3KA-3 (Vostok 1) spacecraft with Gagarin aboard was launched from Baikonur Cosmodrome. Gagarin thus became both the first human to travel into space, and the first to orbit the earth. His call sign was "Kedr" (Russian: Кедр, Siberian pine or Cedar).
The radio communication between the launch control room and Gagarin included the following dialogue at the moment of rocket launch:
Korolev: "Preliminary stage... intermediate... main... lift off! We wish you a good flight. Everything is all right."
Gagarin: "Поехали!" ("Poyekhali!" - "Let's go!").
Gagarin's informal "poyekhali!" became a historical phrase in the Eastern Bloc, used to refer to the beginning of the Space Age in human history.
In his post-flight report, Gagarin recalled his experience of spaceflight, having been the first human in space:The feeling of weightlessness was somewhat unfamiliar compared with Earth conditions. Here, you feel as if you were hanging in a horizontal position in straps. You feel as if you are suspended.
Following the flight, Gagarin told the Soviet leader Nikita Khrushchev that during reentry he had whistled the tune "The Motherland Hears, The Motherland Knows" (Russian: "Родина слышит, Родина знает"). The first two lines of the song are: "The Motherland hears, the Motherland knows/Where her son flies in the sky". This patriotic song was written by Dmitri Shostakovich in 1951 (opus 86), with words by Yevgeniy Dolmatovsky.
Some sources have claimed that Gagarin commented during the flight, "I don't see any God up here." However, no such words appear in the verbatim record of his conversations with Earth-based stations during the spaceflight. In a 2006 interview, Gagarin's friend Colonel Valentin Petrov stated that the cosmonaut never said such words, and that the quote originated from Nikita Khrushchev's speech at the plenum of the Central Committee of the CPSU about the state's anti-religion campaign, saying "Gagarin flew into space, but didn't see any god there." Petrov also said that Gagarin had been baptised into the Orthodox Church as a child, and a 2011 "Foma" magazine article quoted the rector of the Orthodox church in Star City saying, "Gagarin baptized his elder daughter Yelena shortly before his space flight; and his family used to celebrate Christmas and Easter and keep icons in the house."
After Vostok 1.
Gagarin's flight was a triumph for the Soviet space program. The announcement on the Soviet radio was made by Yuri Levitan, the same speaker, who announced all major events in the Great Patriotic War. Gagarin became a national hero of the Soviet Union and Eastern Bloc, and a worldwide celebrity. Newspapers around the globe published his biography and details of his flight. Moscow and other cities in the USSR held mass demonstrations, the scale of which was second only to World War II Victory Parades. Gagarin was escorted in a long motorcade of high-ranking officials through the streets of Moscow to the Kremlin where, in a lavish ceremony, he was awarded the title of Hero of the Soviet Union, by Nikita Khrushchev.
Later on, Gagarin toured widely abroad. He visited Italy, Germany, Canada, Brazil, Japan, Egypt and Finland to promote the Soviet Union's accomplishment of putting the first human in space. He visited the United Kingdom three months after the Vostok 1 mission, going to London and Manchester.
The sudden rise to fame took its toll on Gagarin. While acquaintances say Gagarin had been a "sensible drinker", his touring schedule placed him in social situations where he was always expected to drink. Gagarin was also reportedly caught by his wife in a room with another woman, a nurse named Anna who had aided him after a boating incident earlier in the day, at a Black Sea resort in September 1961. He attempted to escape by leaving through a window and jumping off her second floor balcony, hitting his face on a kerbstone and leaving a permanent scar above his left eyebrow.
In 1962, he began serving as a deputy to the Soviet of the Union, and was elected to the Central Committee of the Young Communist League. He later returned to Star City, the cosmonaut facility, where he spent seven years working on designs for a reusable spacecraft. He became a lieutenant colonel of the Soviet Air Forces on 12 June 1962, and received the rank of colonel on 6 November 1963. Soviet officials tried to keep him away from any flights, being worried of losing their hero in an accident. Gagarin was backup pilot for his friend Vladimir Komarov in the Soyuz 1 flight, which was launched despite Gagarin's protests that additional safety precautions were necessary. When Komarov's flight ended in a fatal crash, Gagarin was permanently banned from training for and participating in further spaceflights.
On 20 December 1963 Gagarin had become deputy training director of the Star City cosmonaut training base. Two years later he was re-elected as a deputy to the SSSU, but this time to the Soviet of Nationalities. Next year he began to re-qualify as a fighter pilot. On 17 February 1968 he defended his aerospace engineering thesis on the subject of spaceplane aerodynamic configuration with flying colors.
Death.
On 27 March 1968, while on a routine training flight from Chkalovsky Air Base, he and flight instructor Vladimir Seryogin died in a MiG-15UTI crash near the town of Kirzhach. The bodies of Gagarin and Seryogin were cremated and the ashes were buried in the walls of the Kremlin on Red Square.
Gagarin was survived by his wife Valentina, and daughters Yelena and Galina. Yelena Yurievna Gagarina, Yuri's elder daughter, is an art historian who has worked as the director-general of the Moscow Kremlin Museums since 2001. His younger daughter, Galina Yurievna Gagarina, is department chair and a professor of economics at Plekhanov Russian University of Economics in Moscow.
Cause of jet crash.
The cause of the crash that killed Gagarin is not entirely certain, and has been subject to speculation about conspiracy theories over the ensuing decades.
Soviet documents declassified in March 2003 showed that the KGB had conducted their own investigation of the accident, in addition to one government and two military investigations. The KGB's report dismissed various conspiracy theories, instead indicating that the actions of airbase personnel contributed to the crash. The report states that an air traffic controller provided Gagarin with outdated weather information, and that by the time of his flight, conditions had deteriorated significantly. Ground crew also left external fuel tanks attached to the aircraft. Gagarin's planned flight activities needed clear weather and no outboard tanks. The investigation concluded that Gagarin's aircraft entered a spin, either due to a bird strike or because of a sudden move to avoid another aircraft. Because of the out-of-date weather report, the crew believed their altitude to be higher than it actually was, and could not react properly to bring the MiG-15 out of its spin.
Another theory, advanced by the original crash investigator in 2005, hypothesizes that a cabin air vent was accidentally left open by the crew or the previous pilot, leading to oxygen deprivation and leaving the crew incapable of controlling the aircraft. A similar theory, published in "Air & Space" magazine, is that the crew detected the open vent and followed procedure by executing a rapid dive to a lower altitude. This dive caused them to lose consciousness and crash.
On 12 April 2007, the Kremlin vetoed a new investigation into the death of Gagarin. Government officials said that they saw no reason to begin a new investigation.
In April 2011, documents from a 1968 commission set up by the Central Committee of the Communist Party to investigate the accident were declassified. Those documents revealed that the commission's original conclusion was that Gagarin or Seryogin had maneuvered sharply either to avoid a weather balloon, leading the jet into a "super-critical flight regime and to its stalling in complex meteorological conditions," or to avoid "entry into the upper limit of the first layer of cloud cover".
In his 2004 book "Two Sides of the Moon", Alexey Leonov, who was part of a State Commission established to investigate the death in 1968, recounts that he was flying a helicopter in the same area that day when he heard "two loud booms in the distance." Corroborating other theories, his conclusion is that a Sukhoi jet (which he identifies as a Su-15 'Flagon') was flying below its minimum allowed altitude, and "without realizing it because of the terrible weather conditions, he passed within 10 or 20 meters of Yuri and Seregin's plane while breaking the sound barrier." The resulting turbulence would have sent the MiG into an uncontrolled spin. Leonov believes the first boom he heard was that of the jet breaking the sound barrier, and the second was Gagarin's plane crashing. In a June 2013 interview with Russian television network RT, Leonov said that a declassified report on the incident revealed the presence of a second, "unauthorized" Su-15 flying in the area. Leonov states that this aircraft had descended to 450 m and that, while running afterburners, "the aircraft reduced its echelon at a distance of 10–15 meters in the clouds, passing close to Gagarin, turning his plane and thus sending it into a tailspin – a deep spiral, to be precise – at a speed of 750 kilometers per hour." As a condition of being allowed to discuss the report, however, Leonov was required to not disclose the name of the other pilot, who was reported to be 80 years old (as of 2013) and in poor health.
Legacy and tributes.
Legacy.
Aside from his short stature at 1.57 m, one of Gagarin's most notable traits was his smile. Many commented on how Gagarin's smile gained the attention of crowds on the frequent tours he did in the months after the Vostok 1 mission success.
Gagarin also garnered a reputation as an adept public figure. When he visited Manchester in the United Kingdom, it was pouring rain. However, Gagarin insisted that the car hood remain back so that the cheering crowds could catch a glimpse of him. Gagarin stated, "If all these people have turned out to welcome me and can stand in the rain, so can I." Gagarin refused an umbrella and remained standing in his open-top Bentley so that the cheering crowds could still see him.
Sergei Korolev, one of the masterminds behind the early years of the Soviet space program, later said that Gagarin possessed a smile "that lit up the Cold War".
Tributes.
Since 1962, 12 April has been celebrated in the USSR and later in Russia and other post-Soviet states as the Cosmonautics Day. In 2011 it was declared the International Day of Human Space Flight by the United Nations. Since 2001, Yuri's Night, an international celebration is held every 12 April to commemorate milestones in space exploration.
The Cosmonaut Training Center in Star City was named after Gagarin in 1969.
The launch pad at Baikonur Cosmodrome from which Sputnik 1 and Vostok 1 were launched, is now known as Gagarin's Start.
A cycle of Soviet patriotic songs "The Constellation Gagarin" (Russian: Созвездье Гагарина, "Sozvezdie Gagarina") was written by Alexandra Pakhmutova and Nikolai Dobronravov in 1970-1971. The most famous of these songs referred to Gagarin's "poekhali!": "He said "let's go!" He waved his hand".
Gagarin was honored by the American space program during Apollo 11 when astronauts Neil Armstrong and Buzz Aldrin left a memorial satchel containing medals commemorating Gagarin and fellow cosmonaut Vladimir Komarov on the surface of the Moon. On 2 August 1971, Apollo 15 astronauts David Scott and James Irwin left the Fallen Astronaut on the surface of the Moon as a memorial to all the American astronauts and Soviet cosmonauts who died in the Space Race, with Yuri Gagarin listed among 14 others.
A Soviet tracking ship "Kosmonaut Yuri Gagarin" was built in 1971.
Gagarin Raion in the Sevastopol city (Ukraine) was named after him during the Soviet Union.
There were two commemorative coins issued in the Soviet Union to honour the 20th and 30th anniversaries of his flight: 1 ruble coin (1981, copper-nickel) and 3 ruble coin (1991, silver). In 2001, to commemorate the 40th anniversary of Gagarin's flight, a series of four coins bearing his likeness was issued in Russia: 2 ruble coin (copper-nickel), 3 ruble coin (silver), 10 ruble coin (brass-copper, nickel), and 100 ruble coin (silver). In 2011, Russia issued a 1,000 ruble coin (gold) and 3 ruble coin (silver) to mark the 50th anniversary of his flight.
In 2008, the Kontinental Hockey League named their championship trophy the Gagarin Cup.
In a 2010 Space Foundation survey, Gagarin was ranked as the #6 most popular space hero, tied with Star Trek's fictional Capt. James T. Kirk.
In January 2011, Armenian airline Armavia named their first Sukhoi Superjet 100 in Gagarin's honour.
On 14 July 2011, a statue of Yuri Gagarin was unveiled at the Admiralty Arch end of The Mall in London, opposite the permanent sculpture of . It is a copy of the statue outside Gagarin's former school in Lyubertsy. In 2013, the London statue was moved to a permanent location outside the Royal Observatory in Greenwich, and was publicly unveiled on 7 March 2013.
On 15 October 2012, a statue of Gagarin was unveiled at the site of NASA's original spaceflight headquarters on South Wayside Drive in Houston, Texas.
50th anniversary.
The 50th anniversary of Gagarin's journey into space was marked in 2011 by tributes around the world. A film titled "First Orbit" was shot from the International Space Station, combining the original flight audio with footage of the route taken by Gagarin. The Russian, American, and Italian Expedition 27 crew aboard the ISS sent a special video message to wish the people of the world a "Happy Yuri's Night", wearing shirts with an image of Gagarin.
Swiss-based German watchmaker Bernhard Lederer created a limited edition of 50 Gagarin Tourbillons to commemorate the 50th anniversary of Yuri Gagarin's flight.
The launch of Soyuz TMA-21 on 4 April 2011 was devoted to the 50th anniversary of the first manned space mission.
Honours and awards.
and others.
Yuri Gagarin was elected an honorary citizen of the following cities:
He was also awarded the golden keys to the gates of the cities of Cairo and Alexandria (Egypt).

</doc>
<doc id="34230" url="http://en.wikipedia.org/wiki?curid=34230" title="Yukon">
Yukon

Yukon (also commonly called the Yukon) is the westernmost and smallest of Canada's three federal territories. Whitehorse is the territorial capital and Yukon's only city.
The territory was split from the Northwest Territories in 1898. The federal government's "Yukon Act", which received royal assent on March 27, 2002, confirmed "Yukon" as the standard, though "Yukon Territory" remains the more popular usage. Though officially bilingual (English and French), the Yukon Government also recognizes First Nations languages.
At 5959 m, Yukon's Mount Logan, in Kluane National Park and Reserve, is the highest mountain in Canada and the second-highest on the North American continent (after Mount McKinley in the U.S. state of Alaska). The territory's climate is Arctic in the north (north of Old Crow), subarctic in the central region, between north of Whitehorse and Pie Town, and has a humid continental climate in the far south, south of Whitehorse and in areas close to the British Columbia border. Several rivers run through Yukon, some being the Stewart River, Peel River, and the Yukon River, after which the territory was named.
History.
Long before the arrival of Europeans, central and southern Yukon was populated by First Nations people, and the area escaped glaciation. The volcanic eruption of Mount Churchill in approximately 800 AD in the U.S. state of Alaska blanketed southern Yukon with a layer of ash which can still be seen along the Klondike Highway and forms part of the oral tradition of First Nations peoples in Yukon and further south.
Coastal and inland First Nations had extensive trading networks. European incursions into the area only began early in the 19th century with the fur trade, followed by missionaries and the Western Union Telegraph Expedition. By the 1870s and 1880s gold miners began to arrive. This drove a population increase that justified the establishment of a police force, just in time for the start of the Klondike Gold Rush in 1897. The increased population coming with the gold rush led to the separation of the Yukon district from the Northwest Territories and the formation of the separate Yukon Territory in 1898.
Sites of archeological significance in Yukon hold some of the earliest evidence of the presence of human occupation in North America. The sites safeguard the history of the first people and the earliest First Nations of the Yukon.
Geography.
The territory is the approximate shape of a right triangle, bordering the U.S. state of Alaska to the west for 1,210 km (752 mi) mostly along longitude 141° W, the Northwest Territories to the east and British Columbia to the south. Its northern coast is on the Beaufort Sea. Its ragged eastern boundary mostly follows the divide between the Yukon Basin and the Mackenzie River drainage basin to the east in the Mackenzie mountains.
Most of the territory is in the watershed of its namesake, the Yukon River. The southern Yukon is dotted with a large number of large, long and narrow glacier-fed alpine lakes, most of which flow into the Yukon River system. The larger lakes include Teslin Lake, Atlin Lake, Tagish Lake, Marsh Lake, Lake Laberge, Kusawa Lake and Kluane Lake. Bennett Lake on the Klondike Gold Rush trail is a lake flowing into Nares Lake, with the greater part of its area within Yukon.
Canada's highest point, Mount Logan (5959 m), is in the territory's southwest. Mount Logan and a large part of the Yukon's southwest are in Kluane National Park and Reserve, a UNESCO World Heritage Site. Other national parks include Ivvavik National Park and Vuntut National Park in the north.
Other watersheds include the Mackenzie River, the Peel Watershed and the Alsek–Tatshenshini, and a number of rivers flowing directly into the Beaufort Sea. The two main Yukon rivers flowing into the Mackenzie in the Northwest Territories are the Liard River in the southeast and the Peel River and its tributaries in the northeast.
Notable widespread tree species within Yukon are the Black Spruce and White Spruce. Many trees are stunted because of the short growing season and severe climate.
The capital, Whitehorse, is also the largest city, with about two-thirds of the population; the second largest is Dawson City (pop. 1,327), which was the capital until 1952.
Climate.
While the average winter temperature in the Yukon is mild by Canadian arctic standards, no other place in North America gets as cold as the Yukon during extreme cold snaps. The temperature has dropped down to -60 C three times, 1947, 1954, and 1968. The most extreme cold snap occurred in February 1947 when the abandoned town of Snag dropped down to -63.0 C.
Unlike most of Canada where the most extreme heat waves occur in July, August, and even September, The Yukon's extreme heat tends to occur in June and even May. The Yukon has recorded 36 C three times. The first time was in June 1969 when Mayo recorded a temperature of 36.1 C. 14 years later this record was almost beaten when Forty Mile recorded 36 C in May 1983. The old record was finally broken 21 years later in June 2004 when the Mayo Road weather station, located just northwest of Whitehorse, recorded a temperature of 36.5 C.
Demographics.
In the 2011 Census, Yukon had a population of 33,897 living in 14,117 of its 16,259 total dwellings, an 11.6% change from its 2006 population of 30,372. With a land area of 474712.64 km2, it had a population density of in 2011.
Ethnicity.
The 2006 Canadian census examined Canadians' ethnicity and ancestry (beyond grandparents). Out of a Yukon population of 30,195, only 13,045 (43%) responded with a single answer, 57% of respondents selected multiple ethnicity making a 'simple' assessment of the ethnic portrait impossible. From the total answers (118,035) 13% are of "aboriginal", "North American Indian", or "Métis" origin. This percentage might be a little higher if the 'Canadian' origin includes both First Nations people and European descendents. The categories for other origins are confounding ('European' vs 'Western European' vs 'French' vs 'Scottish', etc.) and therefore a further breakdown is not realistic. According to the Statistics Canada 2006 Community Profiles page, Yukoners of "aboriginal identity population" (including all persons with treaty status or band registry) represent 25% of the population.
Language.
The most commonly reported mother tongue among the 33,145 single responses to the 2011 Canadian census was English at 28,065 (%). The second-most common was 1,455 (%) for French. Among 510 multiple respondents, 140 of them (%) reported a mother tongue of both English and French, while 335 (%) reported English and a 'non-official language' and 20 (%) reported French and a 'non-official language'.
The Language Act of Yukon "recognises the significance" of aboriginal languages in Yukon; however, only English and French are available for laws, court proceedings, and legislative assembly proceedings.
Religion.
The largest denominations by number of adherents according to the 2001 census were the Roman Catholic Church with 5,975 (22 percent); the Anglican Church of Canada with 3,795 (13 percent); and the United Church of Canada with 2,105 (7 percent). 37.4% of residents claimed no religion.
Economy.
Yukon's historical major industry was mining (lead, zinc, silver, gold, asbestos and copper). The government acquired the land from the Hudson's Bay Company in 1870 and split it from the Northwest Territories in 1898 to fill the need for local government created by the population influx of the gold rush.
Thousands of these prospectors flooded the territory, creating a colourful period recorded by authors such as Robert W. Service and Jack London. The memory of this period and the early days of the Royal Canadian Mounted Police, as well as the territory's scenic wonders and outdoor recreation opportunities, makes tourism the second most important industry.
Manufacturing, including furniture, clothing, and handicrafts, follows in importance, along with hydroelectricity. The traditional industries of trapping and fishing have declined. Today, the government sector is by far the biggest employer in the territory, directly employing approximately 5,000 out of a labour force of 12,500.
Tourism.
Yukon's tourism motto is "Larger than life". Yukon's major appeal is its nearly pristine nature. Tourism relies heavily on this, and there are many organized outfitters and guides available to hunters and anglers and nature lovers of all sorts. Sports enthusiasts can paddle lakes and rivers with canoes and kayaks, ride or walk trails, ski or snowboard in an organized setting or access the backcountry by air or snowmobile, climb the highest peaks in Canada or take a family hike up smaller mountains, or try ice climbing and dog sledding.
Yukon also has a wide array of cultural and sporting events and infrastructures that attract artists, participants and tourists from all parts of the world; Yukon International Storytelling Festival, Frostbite Music Festival, Dawson Music Festival, Yukon Quest, Sourdough Rendezvous, the Yukon Beringia Interpretive Centre, Northern Lights Centre, Klondike Gold Rush memorials and activities, "Takhini Hot Springs", and the Whitehorse fish ladder.
There are many opportunities to experience pre-colonial lifestyles by learning about Yukon's First Nations. Wildlife and nature observation is exceptional and a wide variety of large mammals, birds, and fish are easily accessible, whether or not within Yukon's many territorial parks (Herschel Island Qikiqtaruk Territorial Park, Tombstone Territorial Park, Fishing Branch Ni'iinlii'njik Park, Coal River Springs Territorial Park) and national parks (Kluane National Park and Reserve, Vuntut National Park, Ivvavik National Park) and reserves, or nearby Liard River Hot Springs Provincial Park in British Columbia.
The latitude enables the view of aurora borealis in Yukon.
Arts and culture.
Although English is the main language used in the territory, as evidenced by the census, the Government of Yukon recognizes several aboriginal languages as part of the cultural heritage of the territory: the Tlingit, and the less common Tahltan, as well as seven Athapaskan languages, Upper Tanana, Gwitchin, Hän, Northern Tutchone, Southern Tutchone, Kaska and Tagish, some of which are rare. As noted above, the "aboriginal identity population" makes up a relatively small part of the total population, accounting for about 25 percent. Notwithstanding, the aboriginal culture is strongly reflected in such areas as winter sports, as in the Yukon Quest sled dog race. The modern comic-book character Yukon Jack depicts a heroic aboriginal persona. By far the strongest cultural and tourism aspect of Yukon, however, is the legacy of the Klondike Gold Rush (1897 - 1899), which inspired such contemporary writers at the time as Robert W. Service, Jack London and Jules Verne and which continues to inspire films and games from Mae West's "Klondike Annie" to The Yukon Trail ("see" Cultural legacy of the Klondike Gold Rush). Notable residents have included Leslie Nielsen, Erik Nielsen and Pierre Berton.
Government.
In the 19th century, Yukon was a segment of North-Western Territory that was administered by the Hudson's Bay Company, and then of the Northwest Territories administered by the federal Canadian government. It only obtained a recognizable local government in 1895 when it became a separate district of the Northwest Territories. In 1898, it was made a separate territory with its own commissioner and an appointed Territorial Council.
Prior to 1979, the territory was administered by the commissioner who was appointed by the federal Minister of Indian Affairs and Northern Development. The commissioner had a role in appointing the territory's "Executive Council", served as chair, and had a day-to-day role in governing the territory. The elected "Territorial Council" had a purely advisory role. In 1979, a significant degree of power was devolved from the commissioner and the federal government to the territorial legislature which, in that year, adopted a party system of responsible government. This change was accomplished through a letter from Jake Epp, the Minister of Indian Affairs and Northern Development, rather than through formal legislation.
In preparation for responsible government, political parties were organized and ran candidates to the Yukon Legislative Assembly for the first time in 1978. The Progressive Conservatives won these elections and formed the first party government of Yukon in January 1979. The Yukon New Democratic Party (NDP) formed the government from 1985 to 1992 under Tony Penikett and again from 1996 under Piers McDonald until being defeated in 2000. The conservatives returned to power in 1992 under John Ostashek after having renamed themselves the Yukon Party. The Liberal government of Pat Duncan was defeated in elections in November 2002, with Dennis Fentie of the Yukon Party forming the government as Premier.
The "Yukon Act", passed on April 1, 2003, formalized the powers of the Yukon government and devolved additional powers to the territorial government (e.g., control over land and natural resources). As of 2003, other than criminal prosecutions, the Yukon government has much of the same powers as provincial governments, and the other two territories are looking to obtaining the same powers. Today the role of commissioner is analogous to that of a provincial lieutenant governor; however, unlike lieutenant-governors, commissioners are not formal representatives of the Queen but are employees of the federal government.
Although there has been discussion in the past about Yukon becoming Canada's 11th province, it is generally felt that its population base is too sparse for this to occur at present.
At the federal level, the territory is represented in the Parliament of Canada by a single Member of Parliament and one senator. Members of Parliament from Canadian territories are full and equal voting representatives and residents of the territory enjoy the same rights as other Canadian citizens. One Yukon Member of Parliament, Erik Nielsen, was the Deputy Prime Minister under the government of Brian Mulroney, while another, Audrey McLaughlin, was the leader of the federal New Democratic Party from 1989 to 1995.
Federal representation.
In the Canadian House of Commons, Yukon is represented by Ryan Leef of the Conservative Party. Leef was first elected to the House of Commons in 2011. Previous Members of Parliament include Larry Bagnell (Liberal Party, 2000–2011), Louise Hardy (New Democratic Party (NDP), 1997–2000), Audrey McLaughlin (NDP, 1987–1997), Erik Nielsen (Progressive Conservative Party, 1957–1987), James Aubrey Simmons (Liberal, 1949–1957).
Yukon is allocated one Senate of Canada seat and has been represented by three Senators since the position was created in 1975. The Senate position is held by Daniel Lang, who was appointed on December 22, 2008. It was previously filled by Ione Christensen, of the Liberal Party. Appointed to the Senate in 1999 by Prime Minister Jean Chrétien, Christensen resigned in December 2006 to help her ailing husband. From 1975 to 1999, Paul Lucier (Liberal) served as Senator for Yukon. Lucier was appointed by Prime Minister Pierre Trudeau.
Infrastructure.
Before modern forms of transportation, the rivers and mountain passes were the main transportation routes for the coastal Tlingit people trading with the Athabascans of which the Chilkoot Pass and Dalton Trail, as well as the first Europeans.
From the Gold Rush until the 1950s, riverboats plied the Yukon River, mostly between Whitehorse and Dawson City, with some making their way further to Alaska and over to the Bering Sea, and other tributaries of Yukon River such as the Stewart River. Most of the riverboats were owned by the British-Yukon Navigation Company, an arm of the White Pass and Yukon Route, which also operated a narrow gauge railway between Skagway, Alaska, and Whitehorse. The railway ceased operation in the 1980s with the first closure of the Faro mine. It is now run during the summer months for the tourism season, with operations as far as Carcross.
Today, major land routes include the Alaska Highway, the Klondike Highway (between Skagway and Dawson City), the Haines Highway (between Haines, Alaska, and Haines Junction), and the Dempster Highway (linking Inuvik, Northwest Territories to the Klondike Highway), all paved except for the Dempster. Other highways with less traffic include the "Robert Campbell Highway" linking Carmacks (on the Klondike Highway) to Watson Lake (Alaska Highway) via Faro and Ross River, and the "Silver Trail" linking the old silver mining communities of Mayo, Elsa and Keno City to the Klondike Highway at the Stewart River bridge. Air travel is the only way to reach the far north community of Old Crow.
Whitehorse International Airport serves as the air transport infrastructure hub, with direct flights to Vancouver, Calgary, Edmonton, Fairbanks, and Frankfurt (summer months). Every Yukon community is served by an airport. The communities of Dawson City, Old Crow, and Inuvik, have regular passenger service through Air North. Air charter businesses exist primarily to serve the tourism and mining exploration industries.
Further reading.
</dl>

</doc>
<doc id="34238" url="http://en.wikipedia.org/wiki?curid=34238" title="Yunus Emre">
Yunus Emre

Yunus Emre (]) (1240?–1320?) was a Turkish poet and Sufi mystic. He has exercised immense influence on Turkish literature, from his own day until the present. Because Yunus Emre is, after Ahmet Yesevi and Sultan Walad, one of the first known poets to have composed works in the spoken Turkish of his own age and region rather than in Persian or Arabic, his diction remains very close to the popular speech of his contemporaries in Central and Western Anatolia. This is also the language of a number of anonymous folk-poets, folk-songs, fairy tales, riddles ("tekerlemeler"), and proverbs. 
Like the Oghuz "Book of Dede Korkut", an older and anonymous Central Asian epic, the Turkish folklore that inspired Yunus Emre in his occasional use of "tekerlemeler" as a poetic device had been handed down orally to him and his contemporaries. This strictly oral tradition continued for a long while.
Following the Mongolian invasion of Anatolia facilitated by the Sultanate of Rûm's defeat at the 1243 Battle of Köse Dağ, Islamic mystic literature thrived in Anatolia, and Yunus Emre became one of its most distinguished poets. Poems of Sultan Yunus Emre — despite being fairly simple on the surface — evidence his skill in describing quite abstruse mystical concepts in a clear way. He remains a popular figure in a number of countries, stretching from Azerbaijan to the Balkans, with seven different and widely dispersed localities disputing the privilege of having his tomb within their boundaries.
His poems, written in the tradition of Anatolian folk poetry, mainly concern divine love as well as human destiny:
Yunus Emre's portrait is depicted on the reverse of the Turkish 200 lira banknote issued in 2009.

</doc>
<doc id="34240" url="http://en.wikipedia.org/wiki?curid=34240" title="Ytterbium">
Ytterbium

Ytterbium is a chemical element with symbol Yb and atomic number 70. It is the fourteenth and penultimate element in the lanthanide series, which is the basis of the relative stability of the +2 oxidation state. However, like the other lanthanides, the most common oxidation state is +3, seen in its oxide, halides and other compounds. In aqueous solution, like compounds of other late lanthanides, soluble ytterbium compounds form complexes with nine water molecules. Because of its closed-shell electron configuration, its density and melting and boiling points differ from those of the other lanthanides.
In 1878, the Swiss chemist Jean Charles Galissard de Marignac separated in the rare earth "erbia" another independent component, which he called "ytterbia", for Ytterby, the village in Sweden near where he found the new component of erbium. He suspected that ytterbia was a compound of a new element that he called "ytterbium" (in total, four elements were named after the village, the others being yttrium, terbium and erbium). In 1907, the new earth "lutecia" was separated from ytterbia, from which the element "lutecium" (now lutetium) was extracted by Georges Urbain, Carl Auer von Welsbach, and Charles James. After some discussion, Marignac's name "ytterbium" was retained. A relatively pure sample of the metal was obtained only in 1953. At present, ytterbium is mainly used as a dopant of stainless steel or active laser media, and less often as a gamma ray source.
Natural ytterbium is a mixture of seven stable isotopes, which altogether are present at concentrations of 3 parts per million. This element is mined in China, the United States, Brazil, and India in form of the minerals monazite, euxenite, and xenotime. The ytterbium concentration is low, because the element is found among many other rare earth elements; moreover, it is among the least abundant ones. Once extracted and prepared, ytterbium is somewhat hazardous as an eye and skin irritant. The metal is a fire and explosion hazard.
Characteristics.
Physical properties.
Ytterbium is a soft, malleable and ductile chemical element that displays a bright silvery luster when in its pure form. It is a rare earth element, and it is readily attacked and dissolved by the strong mineral acids. It reacts slowly with cold water and it oxidizes slowly in air.
Ytterbium has three allotropes labeled by the Greek letters alpha, beta and gamma; their transformation temperatures are −13 °C and 795 °C, although the exact transformation temperature depends on the pressure and stress. The beta allotrope exists at room temperature, and it has a face-centered cubic crystal structure. The high-temperature gamma allotrope has a body-centered cubic crystalline structure. The alpha allotrope has a hexagonal crystalline structure and is stable at low temperatures. Normally, the beta allotrope has a metallic electrical conductivity, but it becomes a semiconductor when exposed to a pressure of about 16,000 atmospheres (1.6 GPa). Its electrical resistivity increases ten times upon compression to 39,000 atmospheres (3.9 GPa), but then drops to about 10% of its room-temperature resistivity at about 40,000 atm (4.0 GPa).
In contrast with the other rare-earth metals, which usually have antiferromagnetic and/or ferromagnetic properties at low temperatures, ytterbium is paramagnetic at temperatures above 1.0 kelvin. However, the alpha allotrope is diamagnetic. With a melting point of 824 °C and a boiling point of 1196 °C, ytterbium has the smallest liquid range of all the metals.
Contrary to most other lanthanides, which have a close-packed hexagonal lattice, ytterbium crystallizes in the face-centered cubic
structure. As a result, its density (6.973 g/cm3) is significantly lower than, e.g., those of the neighboring elements thulium (9.32 g/cm3) and lutetium (9.841 g/cm3). The melting and boiling points of ytterbium are also significantly lower than those of thulium and lutetium. These properties stem from the closed-shell electron configuration of ytterbium ([Xe] 4f14 6s2), which causes only the two 6s electrons to be available for metallic bonding (in contrast to the other lanthanides where three electrons are available).
Chemical properties.
Ytterbium metal tarnishes slowly in air. Finely dispersed ytterbium readily oxidizes in air and under oxygen. Mixtures of powdered ytterbium with polytetrafluoroethylene or hexachloroethane burn with a luminous emerald-green flame. Ytterbium reacts with hydrogen to form various non-stoichiometric hydrides. Ytterbium dissolves slowly in water, but quickly in acids, liberating hydrogen gas.
Ytterbium is quite electropositive, and it reacts slowly with cold water and quite quickly with hot water to form ytterbium(III) hydroxide:
Ytterbium reacts with all the halogens:
The ytterbium(III) ion absorbs light in the near infrared range of wavelengths, but not in visible light, so the mineral ytterbia, Yb2O3, is white in color and the salts of ytterbium are also colorless. Ytterbium dissolves readily in dilute sulfuric acid to form solutions that contain the colorless Yb(III) ions, which exist as nonahydrate complexes:
Yb(II) vs. Yb(III).
Although usually trivalent, ytterbium readily forms divalent compounds. This behavior is unusual to most lanthanides, which almost exclusively form compounds with an oxidation state of +3. The +2 state has a valence electron configuration of 4"f"14 because the fully filled "f"-shell gives more stability. The yellow-green ytterbium(II) ion is a very strong reducing agent and decomposes water, releasing hydrogen gas, and thus only the colorless ytterbium(III) ion occurs in aqueous solution. Samarium and thulium also behave this way in the +2 state, but europium(II) is stable in aqueous solution. Ytterbium metal behaves similarly to europium metal and the alkaline earth metals, dissolving in ammonia to form blue electride salts.
Isotopes.
Natural ytterbium is composed of seven stable isotopes: 168Yb, 170Yb, 171Yb, 172Yb, 173Yb, 174Yb, and 176Yb, with 174Yb being the most abundant isotope, at 31.8% of the natural abundance). 27 radioisotopes have been observed, with the most stable ones being 169Yb with a half-life of 32.0 days, 175Yb with a half-life of 4.18 days, and 166Yb with a half-life of 56.7 hours. All of its remaining radioactive isotopes have half-lives that are less than two hours and most of these have half-lives are less than 20 minutes. Ytterbium also has 12 meta states, with the most stable being 169mYb (t1/2 46 seconds).
The isotopes of ytterbium range in atomic weight from 147.9674 atomic mass unit (u) for 148Yb to 180.9562 u for 181Yb. The primary decay mode of ytterbium isotopes lighter than the most abundant stable isotope, 174Yb, is electron capture, and the primary decay mode for those heavier than 174Yb is beta decay. The primary decay products of ytterbium isotopes lighter than 174Yb are thulium isotopes, and the primary decay products of ytterbium isotopes with heavier than 174Yb are lutetium isotopes.
Occurrence.
Ytterbium is found with other rare earth elements in several rare minerals. It is most often recovered commercially from monazite sand (0.03% ytterbium). The element is also found in euxenite and xenotime. The main mining areas are China, the United States, Brazil, India, Sri Lanka, and Australia; and reserves of ytterbium are estimated as one million tonnes. Ytterbium is normally difficult to separate from other rare earths, but ion-exchange and solvent extraction techniques developed in the mid- to late 20th century have simplified separation. Known compounds of ytterbium are rare and have not yet been well characterized. The abundance of ytterbium in the Earth's crust is about 3 mg/kg.
As an even-numbered lanthanide, in accordance with the Oddo-Harkins rule, ytterbium is significantly more abundant than its immediate neighbors, thulium and lutetium, which occur in the same concentrate at levels of about 0.5% each. The world production of ytterbium is only about 50 tonnes per year, reflecting the fact that ytterbium has few commercial applications. Microscopic traces of ytterbium are used as a dopant in the , a solid-state laser in which ytterbium is the element that undergoes stimulated emission of electromagnetic radiation.
Production.
It is somewhat difficult to separate ytterbium from other lanthanides due to its similar properties. As a result, the process is somewhat long. First, minerals such as monazite or xenotime are dissolved into various acids, such as sulfuric acid. Ytterbium can then be separated from other lanthanides by ion exchange, as can other lanthanides. The solution is then applied to a resin, which different lanthanides bond to in different matters. This is then dissolved using complexing agents, and due to the different types of bonding exhibited by the different lanthanides, it is possible to isolate the compounds.
Ytterbium is separated from other rare earths either by ion exchange or by reduction with sodium amalgam. In the latter method, a buffered acidic solution of trivalent rare earths is treated with molten sodium-mercury alloy, which reduces and dissolves Yb3+. The alloy is treated with hydrochloric acid. The metal is extracted from the solution as oxalate and converted to oxide by heating. The oxide is reduced to metal by heating with lanthanum, aluminium, cerium or zirconium in high vacuum. The metal is purified by sublimation and collected over a condensed plate.
Compounds.
The chemical behavior of ytterbium is similar to that of the rest of the lanthanides. Most ytterbium compounds are found in the +3 oxidation state and its salts in this oxidation state are nearly colorless. Like europium, samarium, and thulium, the trihalides of ytterbium can be reduced by hydrogen, zinc dust, or by the addition of metallic ytterbium to the dihalides. The +2 oxidation state only occurs in solid compounds and reacts in some ways similarly to the alkaline earth metal compounds; for example, ytterbium(II) oxide (YbO) shows the same structure as calcium oxide (CaO).
Halides.
Ytterbium forms both dihalides and trihalides with the halogens fluorine, chlorine, bromine, and iodine. The dihalides are susceptible to oxidation to the trihalides at room temperature and disproportionate to the trihalides and metallic ytterbium at high temperature:
Some ytterbium halides are used as reagents in organic synthesis. For example, ytterbium(III) chloride (YbCl3) is a Lewis acid and can be used as a catalyst in the Aldol and Diels–Alder reactions. Ytterbium(II) iodide (YbI2) may be used, like samarium(II) iodide, as a reducing agent for coupling reactions. Ytterbium(III) fluoride (YbF3) is used as an inert and non-toxic tooth filling as it continuously releases fluoride ions, which are good for dental health, and is also a good X-ray contrast agent.
Oxides.
Ytterbium reacts with oxygen to form ytterbium(III) oxide (Yb2O3), which crystallizes in the "rare-earth C-type sesquioxide" structure which is related to the fluorite structure with one quarter of the anions removed, leading to ytterbium atoms in two different six coordinate (non-octahedral) environments. Ytterbium(III) oxide can be reduced to ytterbium(II) oxide (YbO) with elemental ytterbium, which crystallizes in the same structure as sodium chloride.
History.
Ytterbium was discovered by the Swiss chemist Jean Charles Galissard de Marignac in the year 1878. While examining samples of gadolinite, Marignac found a new component in the earth then known as erbia, and he named it ytterbia, for Ytterby, the Swedish village near where he found the new component of erbium. Marignac suspected that ytterbia was a compound of a new element that he called "ytterbium".
In 1907, the French chemist Georges Urbain separated Marignac's ytterbia into two components: neoytterbia and lutecia. Neoytterbia would later become known as the element ytterbium, and lutecia would later be known as the element lutetium. The Austrian chemist Carl Auer von Welsbach independently isolated these elements from ytterbia at about the same time, but he called them aldebaranium and cassiopeium; the American chemist Charles James also independently isolated these elements at about the same time. Urbain and Welsbach accused each other of publishing results based on the other party. The Commission on Atomic Mass, consisting of Frank Wigglesworth Clarke, Wilhelm Ostwald, and Georges Urbain, which was then responsible for the attribution of new element names, settled the dispute in 1909 by granting priority to Urbain and adopting his names as official ones, based on the fact that the separation of lutetium from Marignac's ytterbium was first described by Urbain; after Urbain's names were recognized, neoytterbium was reverted to ytterbium.
The chemical and physical properties of ytterbium could not be determined with any precision until 1953, when the first nearly pure ytterbium metal was produced by using ion-exchange processes. The price of ytterbium was relatively stable between 1953 and 1998 at about US$1,000/kg.
Applications.
Source of gamma rays.
The 169Yb isotope (with a half-life of 32 days), which is created along with the short-lived 175Yb isotope (half-life 4.2 days) by neutron activation during the irradiation of ytterbium in nuclear reactors, has been used as a radiation source in portable X-ray machines. Like X-rays, the gamma rays emitted by the source pass through soft tissues of the body, but are blocked by bones and other dense materials. Thus, small 169Yb samples (which emit gamma rays) act like tiny X-ray machines useful for radiography of small objects. Experiments show that radiographs taken with a 169Yb source are roughly equivalent to those taken with X-rays having energies between 250 and 350 keV. 169Yb is also used in nuclear medicine.
World's most stable atomic clock.
Ytterbium clocks hold the record for stability with ticks stable to within less than two parts in 1 quintillion (). The clocks developed at the National Institute of Standards and Technology (NIST) rely on about 10,000 rare-earth atoms cooled to 10 microkelvin (10 millionths of a degree above absolute zero) and trapped in an optical lattice—a series of pancake-shaped wells made of laser light. Another laser that "ticks" 518 trillion times per second provokes a transition between two energy levels in the atoms. The large number of atoms is key to the clocks' high stability.
Doping of stainless steel.
Ytterbium can also be used as a dopant to help improve the grain refinement, strength, and other mechanical properties of stainless steel. Some ytterbium alloys have rarely been used in dentistry.
Ytterbium as dopant of active media.
The ytterbium +3 ion is used as a doping material in active laser media, specifically in solid state lasers and double clad fiber lasers. Ytterbium lasers are highly efficient, have long lifetimes and can generate short pulses; ytterbium can also easily be incorporated into the material used to make the laser. Ytterbium lasers commonly radiate in the 1.06–1.12 µm band
being optically pumped at wavelength 900 nm–1 µm, dependently on the host and application.
The small quantum defect makes ytterbium a prospective dopant for efficient lasers and power scaling.
The kinetic of excitations in ytterbium-doped materials is simple and can be described within the concept of effective cross-sections; for most ytterbium-doped laser materials (as for many other optically pumped gain media), the McCumber relation holds, although the application to the ytterbium-doped composite materials was under discussion.
Usually, low concentrations of ytterbium are used. At high concentrations, the ytterbium-doped materials show photodarkening
(glass fibers) or even a switch to broadband emission (crystals and ceramics) instead of efficient laser action.
This effect may be related with not only overheating, but also with conditions of charge compensation at high concentrations of ytterbium ions.
Much progress has been made in the power scaling Lasers and Amplifiers produced with ytterbium (Yb) doped optical fibers. Power levels have increased from the 1 kW regimes due to the advancements in components as well as the Yb doped fibers themselves. Fabrication of Low NA, Large Mode Area (LMA) fibers enable achievement of near perfect beam qualities (M2<1.1) at power levels of 1.5 kW to greater than 2 kW at ~1064 nm in a broadband configuration. Ytterbium doped LMA fibers also have the advantages of a larger mode field diameter (MFD) which negates the impacts of nonlinear effects such as stimulated Brillion scattering (SBS) and stimulated Raman scattering (SRS), which limit the achievement of higher power levels, and provides a distinct advantage over single mode Yb doped fibers.
In order to achieve even higher power levels in Yb based fiber systems all factors of the fiber must be considered. These can only be achieved via optimization of all the Yb fiber parameters, ranging from the core background losses to the geometrical properties, in order to reduce the splice losses within the cavity. Power scaling also requires optimization of matching passive fibers within the optical cavity. The optimization of the Yb doped glass itself through host glass modification of various dopants also plays a large part in reducing the background loss of the glass, improvements in slope efficiency of the fiber and improved photodarkening performance. All of which contribute to increased power levels in 1 µm systems.
Others.
Ytterbium metal increases its electrical resistivity when subjected to high stresses. This property is used in stress gauges to monitor ground deformations from earthquakes and explosions.
Light waves vibrate faster than microwaves, and therefore optical clocks can be more precise than caesium atomic clocks. The Physikalisch-Technische Bundesanstalt (PTB) is working on several such optical clocks. The model with one single ytterbium ion caught in an ion trap is highly accurate. The optical clock based on it is exact to 17 digits after the decimal point.
A pair of experimental atomic clocks based on ytterbium atoms at the National Institute of Standards and Technology (NIST) has set a new record for stability. NIST physicists report in the Aug. 22, 2013 issue of Science Express that the ytterbium clocks' ticks are stable to within less than two parts in 1 quintillion (1 followed by 18 zeros), roughly 10 times better than the previous best published results for other atomic clocks. The clocks would be accurate within a second for a period comparable to the age of the universe.
Currently, ytterbium is being investigated as a possible replacement for magnesium in high density pyrotechnic payloads for kinematic infrared decoy flares. As ytterbium(III) oxide has a significantly higher emissivity in the infrared range than magnesium oxide, a higher radiant intensity is obtained with ytterbium-based payloads in comparison to those commonly based on magnesium/Teflon/Viton (MTV).
Precautions.
Although ytterbium is fairly stable chemically, it is stored in airtight containers and in an inert atmosphere such as a nitrogen-filled dry box to protect the metal from air and moisture. All compounds of ytterbium are treated as highly toxic, although initial studies appear to indicate that the danger is minimal. Ytterbium compounds are, however, known to cause irritation to the human skin and eyes, and some might be teratogenic. Metallic ytterbium dust can spontaneously combust, and the resulting fumes are hazardous. Ytterbium fires cannot be extinguished using water, and only dry chemical class D fire extinguishers can extinguish the fires.

</doc>
<doc id="34241" url="http://en.wikipedia.org/wiki?curid=34241" title="Ytterby">
Ytterby

Ytterby quarry (]) is a village on the Swedish island of Resarö, in Vaxholm Municipality in the Stockholm archipelago.
The name of the village means "outer village".
Chemical discoveries.
At a quarry and mine near the village, the rare earth mineral yttria was discovered and named after the village. This crude mineral eventually proved to be the source of four new elements that were named after the mineral ore and the village. These elements are yttrium (Y), erbium (Er), terbium (Tb), and ytterbium (Yb) and were first described in 1794, 1842, 1842, and 1878, respectively. In 1989 the ASM International society installed a plaque at the former entrance to the mine, commemorating the mine as a historical landmark.
In addition, three other lanthanides, holmium (Ho, named after Stockholm), thulium (Tm, named after Thule, a mythic analog of Scandinavia), and gadolinium (Gd, after the chemist Johan Gadolin) can trace their discovery to the same quarry.

</doc>
<doc id="34242" url="http://en.wikipedia.org/wiki?curid=34242" title="Yard">
Yard

The yard (abbreviation: yd) is an English unit of length standardized as exactly 0.9144 meters by international agreement in 1959.
In both the British imperial and US customary systems of measurement, the yard comprises 3 feet or 36 inches. In both systems, a metal yardstick originally formed the physical standard from which all other units of length were officially derived. In the 19th and 20th centuries, increasingly powerful microscopes and scientific measurement detected variation in these prototype yards which became significant as technology improved. In 1959, the United States, United Kingdom, Australia, New Zealand, and South Africa agreed to adopt the Canadian compromise value of 0.9144 meters per yard.
The term yard is also sometimes used for translating related lengths in other systems.
Name.
The name derives from the Old English "gerd", "gyrd", &c., which was used for branches, staves, and measuring rods. It is first attested in the late-7th century laws of Ine of Wessex, where the "yard of land" mentioned is the yardland, an old English unit of tax assessment equal to ¼ hide. Around the same time, the Lindisfarne Gospel's account of the messengers from John the Baptist in the Book of Matthew used it for a branch swayed by the wind. In addition to the yardland, Old and Middle English both used their forms of "yard" to denote the surveying lengths of 15 or 16 1⁄2 ft used in computing acres, a distance now usually known as the "rod".
A unit of three English feet is attested in a statute of c. 1300 (see below) but there it is called an ell (Latin: "ulna",  "arm"), a separate and usually longer unit of around 45 inches. The use of the word "yard" (Middle English: "ȝerd" or "ȝerde") to describe this length is first attested in Langland's poem on Piers Plowman. The usage seems to derive from the prototype standard rods held by the king and his magistrates (see below).
The word "yard" is a homonym of "yard" in the sense of an enclosed area of land. This second meaning of "yard" has an etymology related to the verb "to gird" and is probably not related.
History.
Origin.
The origin of the measure is uncertain. Both the Romans and the Welsh used multiples of a shorter foot, but 2½ Roman feet was a "step" ("gradus") and 3 Welsh feet was a "pace" ("cam"). The Proto-Germanic cubit or arm's-length has been reconstructed as *"alinâ", which developed into the Old English "ęln", Middle English "elne", and modern ell of 1¼ yd. This has led some to derive the yard of three English feet from pacing; others from the ell or cubit; others from Henry I's arm standard (see below). Based on the etymology of the other "yard", others suggest it originally derived from the girth of a person's waist, while others believe it originated as a cubic measure.
The earliest record of a prototype measure is the statute II Edgar Cap. 8 (AD 959  963), which survives in several variant manuscripts. In it, Edgar the Peaceful directed the Witenagemot at Andover that "the measure held at Winchester" should be observed throughout his realm. (Some manuscripts read "at London and at Winchester".) The statutes of William I similarly refer to and uphold the standard measures of his predecessors without naming them.
William of Malmesbury's "Deeds of the Kings of England" records that during the reign of Henry I "the measure of his arm was applied to correct the false ell of the traders and enjoined on all throughout England." The folktale that the length was bounded by the king's nose was added some centuries later. Watson dismisses William's account as "childish" but William was among the most conscientious and trustworthy medieval historians, the French "king's foot" was supposed to have derived from Charlemagne, and the English kings subsequently repeatedly intervened to impose shorter units with the aim of increasing tax revenue.
The earliest surviving definition of this form of the ell appears in the Act on the Composition of Yards and Perches, one of the statutes of uncertain date tentatively dated to the reign of Edward I or II c. 1300. Its wording varies in surviving accounts. One reads:
It is ordained that 3 grains of barley dry and round do make an inch, 12 inches make 1 foot, 3 feet make 1 yard, 5 yards and a half make a perch, and 40 perches in length and 4 in breadth make an acre.
The Liber Horn states:
And be it remembered that the iron yard of our Lord the King containeth 3 feet and no more, and a foot ought to contain 12 inches by the right measure of this yard measured, to wit, the 36th part of this yard rightly measured maketh 1 inch neither more nor less and 5 yards and a half make a perch that is 16 feet and a half measured by the aforesaid yard of our Lord the King.
In some early books, this act was appended to another statute of uncertain date titled the Statute for the Measuring of Land. The act was not repealed until the Weights and Measures Act of 1824.
Yard and inch.
In a law of 1439 (18 Henry VI. Cap. 16.) the sale of cloth by the "yard and handful" was abolished, and the "yard and inch" instituted.
There shall be but one Measure of Cloth through the Realm by the Yard and the Inch, and not by the Yard and Handful, according to the London Measure.
According to Connor, cloth merchants had previously sold cloth by the yard and handful to evade high taxes on cloth (the extra handful being essentially a black-market transaction). Enforcement efforts resulted in cloth merchants switching over to the yard and inch, at which point the government gave up and made the yard and inch official. In 1552, the yard and inch for cloth measurement was again sanctioned in law (5 & 6 Edward VI Cap. 6. "An Act for the true making of Woolen Cloth.")
And once in legislation of 1557-8 (4 & 5 Philip and Mary Cap. 5. "An act touching the making of woolen clothes." par. IX.)
As recently as 1593 we find the same principle mentioned once again (35 Elizabeth. Cap. 10. "An act for the reformation of sundry abuses in clothes, called Devonshire kerjies or dozens, according to a proclamation of the thirty-fourth year of the reign of our sovereign lady the Queen that now is." par. III.)
Physical standards.
One of the oldest yard-rods in existence is the clothyard of the Worshipful Company of Merchant Taylors. It consists of a hexagonal iron rod inch in diameter and inch short of a yard, encased within a silver rod bearing the hallmark 1445. In the early 15th century, the Merchant Taylors Company was authorized to "make search" at the opening of the annual St. Bartholemew's Day Cloth Fair. In the mid-18th century Graham compared the standard yard of the Royal Society to other existing standards. These were a "long-disused" standard made in 1490 during the reign of Henry VII, and a brass yard and a brass ell from 1588 in the time of Queen Elizabeth and still in use at the time, held at the Exchequer; a brass yard and a brass ell at the Guildhall; and a brass yard presented to the Clock-Makers' Company by the Exchequer in 1671. The Exchequer yard was taken as "true"; the variation was found to be + to - of an inch, and an additional graduation for the Exchequer yard was made on the Royal Society's standard. In 1758 the legislature required the construction of a standard yard, which was made from the Royal Society's standard and was deposited with the clerk of the House of Commons; it was divided into feet, one of the feet into inches, and one of the inches into tenths. A copy of it, but with upright cheeks between which other measuring rods could be placed, was made for the Exchequer for commercial use.
19th-century Britain.
Following Royal Society investigations by John Playfair, Hyde Wollaston and John Warner in 1814 a committee of parliament proposed defining the standard yard based upon the length of a seconds pendulum. This idea was examined but not approved. The Weights and Measures Act of 1824 (5° George IV. Cap. 74.) "An Act for ascertaining and establishing Uniformity of Weights and Measures" stipulates that:
From and after the First Day of "May" One thousand eight hundred and twenty five the Straight Line or Distance between the Centres of the Two Points in the Gold Studs of the Straight Brass Rod now in the Custody of the Clerk of the House of Commons whereon the Words and Figures "Standard Yard 1760" are engraved shall be and the same is hereby declared to be the original and genuine Standard of that Measure of Length or lineal Extension called a Yard; and that the same Straight Line or Distance between the Centres of the said Two Points in the said Gold Studs in the said Brass Rod the Brass being at the Temperature of Sixty two Degrees by "Fahrenheit"'s Thermometer shall be and is hereby denominated the Imperial Standard Yard and shall be and is hereby declared to be the Unit or only Standard Measure of Extension, wherefrom or whereby all other Measures of Extension whatsoever, whether the same be lineal, superficial or solid, shall be derived, computed and ascertained; and that all Measures of Length shall be taken in Parts or Multiples, or certain Proportions of the said Standard Yard; and that One third Part of the said Standard Yard shall be a Foot, and the Twelfth Part of such Foot shall be an Inch; and that the Pole or Perch in Length shall contain Five such Yards and a Half, the Furlong Two hundred and twenty such Yards, and the Mile One thousand seven hundred and sixty such Yards.
In 1834, the primary Imperial yard standard was partially destroyed in a fire known as the Burning of Parliament. In 1838, a commission was formed to reconstruct the lost standards, including the troy pound, which had also been destroyed. In 1845, a new yard standard was constructed based on two previously existing standards known as A1 and A2, both of which had been made for the Ordnance Survey, and R.S. 46, the yard of the Royal Astronomical Society. All three had been compared to the Imperial standard before the fire. The new standard was made of Baily's metal No. 4 consisting of 16 parts copper, 2 1⁄2 parts tin, and 1 part zinc. It was 38 inches long and 1 inch square. The Weights and Measures Act of 1855 granted official recognition to the new standards. Between 1845 and 1855 forty yard standards were constructed, one of which was selected as the new Imperial standard. Four others, known as Parliamentary Copies, were distributed to The Royal Mint, The Royal Society of London, The Royal Observatory at Greenwich, and the New Palace at Westminster, commonly called the Houses of Parliament. The other 35 yard standards were distributed to the cities of London, Edinburgh, and Dublin, as well the United States and other countries (although only the first five had official status). The imperial standard received by the United States is known as "Bronze Yard No. 11"
The Weights and Measures Act 1878 confirmed the status of the existing yard standard, mandated regular intercomparisons between the several yard standards, and authorized the construction of one additional Parliamentary Copy (made in 1879 and known as Parliamentary Copy VI).
Definition of the yard in terms of the meter.
The yard is equal to 3 feet or 36 inches. Under an agreement in 1959 between Australia, Canada, New Zealand, South Africa, the United Kingdom and the United States, the yard (known as the "international yard" in the United States) was legally defined to be exactly 0.9144 meters.
Subsequent measurements revealed that the yard standard and its copies were shrinking at the rate of one part per million every twenty years due to the gradual release of strain incurred during the fabrication process.
The international prototype meter, on the other hand, was comparatively stable. A measurement made in 1895 determined the length of the meter at inches relative to the imperial standard yard. The Weights and Measures (Metric) Act of 1897 in conjunction with Order in Council 411 (1898) made this relationship official. After 1898, the de facto legal definition of the yard came to be accepted as 36⁄ of a meter.
In 1959, the USA, UK, Canada, Australia, New Zealand, and South Africa agreed to adopt the international yard of exactly 0.9144 meters. In the UK, the provisions of the treaty were ratified by the Weights and Measures Act of 1963. The Imperial Standard Yard of 1855 was renamed the United Kingdom Primary Standard Yard and retained its official status as the national prototype yard.
Schedule 2, Part I of The Weights and Measures Act of 1985 defines the yard as 0.9144 meters, and the meter as the distance light travels in ⁄ of a second. It then goes on to state:
Current use.
The yard is used as the standard unit of field-length measurement in American, Canadian and Association football, cricket pitch dimensions, and in some countries, golf fairway measurements.
There are corresponding units of area and volume: the square yard and cubic yard respectively. These are sometimes referred to simply as "yards" when no ambiguity is possible, for example an American or Canadian concrete mixer may be marked with a capacity of "11 yards" or "1.5 yards", where cubic yards are obviously referred to.
Yards are also used on road signs for shorter distances in the United Kingdom.
Textiles and fat quarters.
The yard, subdivided into eighths, is used for the purchase of fabrics in the United States and was previously used elsewhere. The term "fat quarter" is used for a piece of fabric which is half a yard in length cut from a roll and then cut again along the width so that it is only half the width of the roll, thus the same area as a piece of one quarter yard cut from the full width of the roll; these pieces are popular for patchwork and quilting. The term "fat eighth" is also used, for a piece of one quarter yard from half the roll width, the same area as one eighth cut from the roll.
Equivalences.
For purposes of measuring cloth, the early yard was divided by the binary method into two, four, eight and sixteen parts. The two most common divisions were the fourth and sixteenth parts. The quarter of a yard was known as the "quarter" without further qualification, while the sixteenth of a yard was called a nail. The eighth of a yard was sometimes called a finger, but was more commonly referred to simply as an eighth of a yard, while the half-yard was called "half a yard".
Other units related to the yard, but not specific to cloth measurement: two yards are a fathom, a quarter of a yard (when not referring to cloth) is a span.

</doc>
<doc id="34243" url="http://en.wikipedia.org/wiki?curid=34243" title="Y">
Y

Y (named "wye" , plural "wyes") is the twenty-fifth letter in the ISO basic Latin alphabet (next to last letter) and represents either a vowel or a consonant in English.
Name.
In Latin, Y was named "I graeca". This was pronounced as "E grecka", since the classical Greek sound /y/, similar to modern German "ü" or French "u", was not a native sound for Latin speakers, and the letter was initially only used to spell foreign words. In Romance languages, this history has led to the standard modern name of the letter: In Galician "i grego", in Catalan "i grega", in French and Romanian "i grec" - all meaning "Greek I". The names "igrek" in Polish and "i gờ-rét" in Vietnamese are both phonetic borrowings of the French name. In Dutch, both "Griekse ij" and "i-grec" are used. In Spanish, Y is also called "i griega", however, in the twentieth century, the shorter name "ye" was proposed and was officially recognized as its name in 2010 by the Real Academia Española, although its original name is still accepted. The original Greek name "upsilon" has also been adapted into several modern languages; in German, for example, it is called "Ypsilon", and in Italian the name is "ípsilon" or "ípsilo". In Portuguese, both names are used ("ípsilon" and "i grego").
Old English borrowed Latin Y to write the native Old English sound /y/ (previously written with the rune yr ᚣ). The name of the letter may be related to 'ui' (or 'vi') in various medieval languages; in Middle English it was 'wi' /wiː/, which through the Great Vowel Shift became the Modern English 'wy' /waɪ/.
History.
Semitic, Phoenician, Greek and Latin.
The oldest direct ancestor of English letter Y was the Semitic letter "waw", from which also come F, U, V, and W. See F for details. The Greek and Latin alphabets developed from the Phoenician form of this early alphabet. In Modern English, there is also some historical influence from the old English letter "yogh" (Ȝȝ), which developed from Semitic gimel, as shown below.
Vowel.
Y first appeared as the Greek letter "upsilon". The Romans borrowed a small form of upsilon as the single letter V, representing both the vowel sound /u/ and the consonant /w/. (In modern ways of writing Latin, V is typically written as U, for a vowel, or V for the consonant.) However, this first loaning of upsilon into Latin is not the source of Modern English Y.
The usage of the capital form of upsilon, 'Y' as opposed to U, V, or W, dates back to the Latin of the first century BC, when upsilon was introduced a second time, this time with its "foot" to distinguish it. It was used to transcribe loanwords from the prestigious Attic dialect of Greek, which had the non-Latin sound /y/, as found in modern French "cru" (raw), or German "grün" (green). Because it was not a native sound of Latin, it was usually pronounced /u/ or /i/. The latter pronunciation was the most common in the Classical period and was used by most people except Greek educated ones.
The letter was also used for other languages with a /y/ sound. Some words of Italic origin were re-spelled with a 'y': Latin "silva" ('forest') was commonly spelled "sylva", in analogy with the Greek cognate and synonym "ὕλη".
The Roman Emperor Claudius proposed introducing a new letter into the Latin alphabet to transcribe the so-called "sonus medius" (a short vowel before labial consonants), which in inscriptions was sometimes used for Greek upsilon instead.
In Old English there was a native /y/ sound, and so both Latin U and Y were adapted for use. By the time of Middle English, /y/ had lost its roundedness and became identical to I (/iː/ and /ɪ/). Therefore, many words that originally had I were spelled with Y, and vice versa. (Some dialects, however, retained the sound /y/ and spelled it U, following French usage.)
Likewise, Modern English vocalic Y is pronounced identically to the letter I. But Modern English uses it in only certain places, unlike Middle and early Modern English. It has three uses: for upsilon in Greek loan-words ("system": Greek σύστημα), at the end of a word ("rye, city"; compare "cities", where S is final), and before vowel endings ("dy-ing", "justify-ing").
Consonant.
As a consonant in English, Y is normally a palatal approximant, /j/ (year", German Jahr"). This is possibly influenced by the Middle English letter "yogh" (Ȝȝ), which represented /j/. (Yogh's other sound, /ɣ/, came to be written "gh" in Middle English, and although the sound is no longer pronounced in standard modern English silent "gh" is common in many words where this sound was once present, such as "through" and "caught", and in some cases an /f/ sound has resulted in modern English, as in "rough" or "trough".)
Orthographic confusion with the letter thorn.
When printing was introduced to Great Britain, Caxton and other English printers used Y in place of Þ (thorn: Modern English "th"), which did not exist in continental typefaces. From this convention comes the spelling of "the" as "ye" in the mock archaism "Ye Olde Shoppe". But in spite of the spelling, pronunciation was the same as for modern "the" (stressed /ðiː/, unstressed /ðə/). "Ye" (/jiː/) is purely a modern spelling pronunciation.
Usage.
English.
The letter Y was originally established as a vowel. In the standard English alphabet, the letter Y is traditionally regarded as a consonant, but a survey of almost any English text will show that Y more commonly functions as a vowel.
As [j]:
As [i]:
As [ɪ]:
As [ai]:
Other:
In English morphology, "-y" is an adjectival suffix.
Other Germanic languages.
Y has the sound values /y/ or /ʏ/ in the Scandinavian languages and in German. It can never be a consonant (except for loanwords), but can in German appear in diphthongs, as in the name "Meyer", where it serves as a variant of ⟨i⟩. In Norwegian it forms part of the diphthong ⟨øy⟩, which in Swedish is spelled ⟨öj⟩ and ⟨øj⟩ (formerly ⟨øi⟩) in Danish.
In Dutch, Y appears only in loanwords and names and usually represents /i/. It may sometimes be left out of the Dutch alphabet and replaced with the ligature "IJ". In addition, the Y is occasionally used instead of an IJ, albeit very rarely. In the Afrikaans language, a descendant of Dutch, Y denotes the diphthong [ɛi], which may derive from the IJ ligature.
The Icelandic writing system uses y for /ɪ/ and ý for /i/. In Faroese, Y is always pronounced /i/. In both languages, it can also form part of diphthongs such as ⟨ey⟩ (in both languages) and ⟨oy⟩ (Faroese only).
French.
In French orthography y is identical to i in pronunciation. It is pronounced as [i] when a vowel (as in the words "cycle", "y") and as [j] as a consonant (as in "yeux", "voyez"). It alternates orthographically with i in the conjugations of some verbs, indicating a [j] sound.
In French Y can have a diaresis ("tréma") as in Moÿ-de-l'Aisne.
Spanish.
In the Spanish language, Y was used as a word-initial form of I that was more visible. (German has used J in a similar way.) Hence "el yugo y las flechas" was a symbol sharing the initials of Isabella I of Castille ("Ysabel") and Ferdinand II of Aragon. This spelling was reformed by the Royal Spanish Academy and currently is only found in proper names spelled archaically, such as Ybarra or CYII, the symbol of the Canal de Isabel II.
Appearing alone as a word, the letter Y is a grammatical conjunction with the meaning "and" in Spanish and is pronounced /i/.
In Spanish family names, "y" can separate the father's surname from the mother's surname as in "Santiago Ramón y Cajal"; another example is "Maturin y Domanova", from the Aubrey-Maturin series. Catalan names use "i" for this. As a consonant y represents [ʝ] in Spanish. When coming before the sound /i/, the conjunction Y is replaced with E: "español e inglés". This is to avoid pronouncing /i/ twice.
The letter Y is called "i/y griega", literally meaning "Greek I", after the Greek letter ypsilon, or "ye".
Portuguese.
In Portuguese, Y (called "ípsilon" in Brazil, both "ípsilon" or "i grego" in Portugal) was, together with K and W, recently re-introduced as the 25th letter, and 19th consonant, of the Portuguese alphabet, in consequence of the Portuguese Language Orthographic Agreement of 1990.
It is mostly used in loanwords from English, Japanese, Spanish, Russian and Hebrew. Loanwords in general, primarily gallicisms in both varieties, are more common in Brazilian Portuguese than in European Portuguese. It was always common for Brazilians to stylize Tupi-influenced names of their children with the letter (which is present in most romanizations of Old Tupi) e.g. Guaracy, Jandyra, Mayara – though placenames and loanwords derived from Indigenous origins had the letter substituted for ⟨i⟩ over time e.g. Nictheroy became Niterói.
To a minor degree (often stigmatized as a signal of the lower classes) it is also true for common Western/Christian in Brazil, together with those of immigrant communities, although the practice is not possible in Portugal where names are required to follow official spelling conventions (see more at Portuguese name).
Usual pronunciations are /i/, [j], [ɪ] and /ɨ/ (the two latter ones are inexistent in European and Brazilian Portuguese varieties respectively, being both substituted by /i/ in other dialects). The letters ⟨i⟩ and ⟨y⟩ are regarded as phonemically not dissimilar, though the first corresponds to a vowel and the latter to a consonant, and both can correspond to a semivowel depending on its place in a word.
Other languages.
Italian, too, has Y ("ipsilon") in a small number of loanwords.
In Polish and Guaraní, it represents the vowel [ɨ].
In Welsh it is pronounced [ə] non-final syllables, and /ɨ/ or [i] (depending on the accent) in final syllables.
In Finnish and Albanian, Y is always pronounced [y].
In Estonian, Y is unofficially used as a subtenant for Ü. It is pronounced the same as in Finnish.
In Lithuanian Y is the 15th letter and is a vowel. It is called "the long i" and is pronounced /iː/ like in English "see".
When used as a vowel in Vietnamese, the letter "y" represents the sound /i/; when it is a monophthong, it is functionally equivalent to the Vietnamese letter "i". Thus, "Mỹ Lai" does not rhyme but "mỳ Lee" does. There have been efforts to replace all such uses with "i" altogether, but they have been largely unsuccessful. As a consonant, it represents the palatal approximant. The capital letter "Y" is also used in Vietnamese as a given name.
In Aymara, Turkish, Quechua and the romanization of Japanese, Y is always a palatal consonant, denoting [j], as in English.
In Malagasy, the letter "y" represents the final variation of /ɨ/.
In Turkmen, Y represents [ɯ].
In Japan, Ⓨ is a symbol used for resale price maintenance.
International Phonetic Alphabet.
In the , [y] corresponds to the close front rounded vowel, and the slightly different character [ʏ] corresponds to the near-close near-front rounded vowel.
It is indicative of the rarity of front rounded vowels that [y] is the rarest sound represented in the IPA by a letter of the Latin alphabet, being cross-linguistically less than half as frequent as [q] or [c] and only about a quarter as frequent as [x].
The IPA symbol [j] ("jod") represents the sound of the English letter ⟨y⟩ in the word "yes".

</doc>
<doc id="34244" url="http://en.wikipedia.org/wiki?curid=34244" title="Yugoslavia">
Yugoslavia

Yugoslavia (Serbo-Croatian, Macedonian, Slovene: "Jugoslavija", Југославија), once spelled and called "Jugoslavia", was a country in Southeast Europe during most of the 20th century. It came into existence after World War I in 1918 under the name of Kingdom of Serbs, Croats and Slovenes by the merger of the provisional State of Slovenes, Croats and Serbs (itself formed from territories of the former Austro-Hungarian Empire) with the formerly independent Kingdom of Serbia and Kingdom of Montenegro. The Serbian royal House of Karađorđević became the Yugoslav royal dynasty. Yugoslavia gained international recognition on 13 July 1922 at the Conference of Ambassadors in Paris. The country was named after the South Slavic peoples and constituted their first union, following centuries in which the territories had been part of the Ottoman Empire and Austria-Hungary.
Renamed Kingdom of Yugoslavia on 3 October 1929, it was invaded by the Axis powers on 6 April 1941. In 1943, a Democratic Federal Yugoslavia was proclaimed by the Partisan resistance. In 1944, the king recognised it as the legitimate government, but in November 1945 the monarchy was abolished. Yugoslavia was renamed the Federal People's Republic of Yugoslavia in 1946, when a communist government was established. It acquired the territories of Istria, Rijeka, and Zadar from Italy. Partisan leader Josip Broz Tito ruled the country as president until his death in 1980. In 1963, the country was renamed again to the Socialist Federal Republic of Yugoslavia (SFRY).
The constituent six Socialist Republics that made up the country were Socialist Republic of Bosnia and Herzegovina, SR Croatia, SR Macedonia, SR Montenegro, SR Slovenia, and SR Serbia. Serbia contained two Socialist Autonomous Provinces, Vojvodina and Kosovo, which after 1974 were largely equal to the other members of the federation. After an economic and political crisis in the 1980s and the rise of nationalism, Yugoslavia broke up along its republics' borders, at first into five countries, leading to the Yugoslav Wars.
After the breakup, the republics of Serbia and Montenegro formed a reduced federation, the Federal Republic of Yugoslavia (FRY), which aspired to the status of sole legal successor to the SFRY, but those claims were opposed by the other former republics. Eventually, Serbia and Montenegro accepted the opinion of the Badinter Arbitration Committee about shared succession. Serbia and Montenegro themselves broke up in 2006 and became independent states, while Kosovo proclaimed independence in 2008.
Background.
The concept of "Yugoslavia", as a single state for all South Slavic peoples, emerged in the late 17th century and gained prominence through the Illyrian Movement of the 19th century. The name was created by the combination of the Slavic words "jug" (south) and "slaveni" (Slavs). Yugoslavia was the result of the Corfu Declaration, as a project of the Serbian Parliament in exile and the Serbian royal Karađorđević dynasty, who became the Yugoslav royal dynasty.
Kingdom of Yugoslavia.
The country was formed in 1918 immediately after World War I as the Kingdom of Serbs, Croats and Slovenes by union of the State of Slovenes, Croats and Serbs and the Kingdom of Serbia. It was commonly referred to at the time as the "Versailles state". Later, the government renamed the country leading to the first official use of "Yugoslavia" in 1929.
King Alexander.
On 20 June 1928 Serb deputy Puniša Račić shot at five members of the opposition Croatian Peasant Party in the National Assembly resulting in the death of two deputies on the spot and that of leader Stjepan Radić a few weeks later. On 6 January 1929 King Alexander I suspended the constitution, banned national political parties, assumed executive power and renamed the country Yugoslavia. He hoped to curb separatist tendencies and mitigate nationalist passions. He imposed a new constitution and relinquished his dictatorship in 1931. However, Alexander's policies later encountered opposition from other European powers stemming from developments in Italy and Germany, where Fascists and Nazis rose to power, and the Soviet Union, where Joseph Stalin became absolute ruler. None of these three regimes favored the policy pursued by Alexander I. In fact, Italy and Germany wanted to revise the international treaties signed after World War I, and the Soviets were determined to regain their positions in Europe and pursue a more active international policy.
Alexander attempted to create a centralised Yugoslavia. He decided to abolish Yugoslavia's historic regions, and new internal boundaries were drawn for provinces or banovinas. The banovinas were named after rivers. Many politicians were jailed or kept under police surveillance. The effect of Alexander's dictatorship was to further alienate the non-Serbs from the idea of unity. During his reign the flags of Yugoslav nations were banned. Communist ideas were banned also.
The king was assassinated in Marseille during an official visit to France in 1934 by Vlado Chernozemski, an experienced marksman from Ivan Mihailov's Internal Macedonian Revolutionary Organization with the cooperation of the Ustaše, a Croatian fascist revolutionary organisation. Alexander was succeeded by his eleven-year-old son Peter II and a regency council headed by his cousin, Prince Paul.
1934–1941.
The international political scene in the late 1930s was marked by growing intolerance between the principal figures, by the aggressive attitude of the totalitarian regimes and by the certainty that the order set up after World War I was losing its strongholds and its sponsors were losing their strength. Supported and pressured by Fascist Italy and Nazi Germany, Croatian leader Vladko Maček and his party managed the creation of the Banovina of Croatia (Autonomous Region with significant internal self-government) in 1939. The agreement specified that Croatia was to remain part of Yugoslavia, but it was hurriedly building an independent political identity in international relations. The entire kingdom was to be federalised but World War II stopped the fulfillment of those plans.
Prince Paul submitted to the fascist pressure and signed the Tripartite Pact in Vienna on 25 March 1941, hoping to still keep Yugoslavia out of the war. But this was at the expense of popular support for Paul's regency. Senior military officers were also opposed to the treaty and launched a coup d'état when the king returned on 27 March. Army General Dušan Simović seized power, arrested the Vienna delegation, exiled Paul, and ended the regency, giving 17-year-old King Peter full powers. Hitler then decided to attack Yugoslavia on 6 April 1941, followed immediately by an invasion of Greece where Mussolini had previously been repelled.
World War II.
At 5:12 am on 6 April 1941, German, Italian and Hungarian forces invaded Yugoslavia. The German Air Force ("Luftwaffe") bombed Belgrade and other major Yugoslav cities. On 17 April, representatives of Yugoslavia's various regions signed an armistice with Germany in Belgrade, ending 11 days of resistance against the invading German Army ("Wehrmacht Heer"). More than 300,000 Yugoslav officers and soldiers were taken prisoner.
The Axis Powers occupied Yugoslavia and split it up. The Independent State of Croatia was established as a Nazi satellite state, ruled by the fascist militia known as the Ustaše that came into existence in 1929, but was relatively limited in its activities until 1941. German troops occupied Bosnia and Herzegovina as well as part of Serbia and Slovenia, while other parts of the country were occupied by Bulgaria, Hungary, and Italy. From 1941–45, the Croatian Ustaše regime murdered around 500,000 people, 250,000 were expelled, and another 200,000 were forced to convert to Catholicism; the victims were predominantly Serbians but included 37,000 Jews.
From the start, the Yugoslav resistance forces consisted of two factions: the communist-led Yugoslav Partisans and the royalist Chetniks, with the former receiving Allied recognition only at the Tehran conference (1943). The heavily pro-Serbian Chetniks were led by Draža Mihajlović, while the pan-Yugoslav oriented Partisans were led by Josip Broz Tito.
The Partisans initiated a guerrilla campaign that developed into the largest resistance army in occupied Western and Central Europe. The Chetniks were initially supported by the exiled royal government and the Allies, but they soon focused increasingly on combating the Partisans rather than the occupying Axis forces. By the end of the war, the Chetnik movement transformed into a collaborationist Serb nationalist militia completely dependent on Axis supplies. The highly mobile Partisans, however, carried on their guerrilla warfare with great success. Most notable of the victories against the occupying forces were the battles of Neretva and Sutjeska.
On 25 November 1942, the Anti-Fascist Council of National Liberation of Yugoslavia was convened in Bihać, modern day Bosnia and Herzegovina. The council reconvened on 29 November 1943, in Jajce, also in Bosnia and Herzegovina, and established the basis for post-war organisation of the country, establishing a federation (this date was celebrated as Republic Day after the war).
The Yugoslav Partisans were able to expel the Axis from Serbia in 1944 and the rest of Yugoslavia in 1945. The Red Army provided limited assistance with the liberation of Belgrade and withdrew after the war was over. In May 1945, the Partisans met with Allied forces outside former Yugoslav borders, after also taking over Trieste and parts of the southern Austrian provinces of Styria and Carinthia. However, the Partisans withdrew from Trieste in June of the same year under heavy pressure from Stalin, who did not want a confrontation with the other Allies.
Western attempts to reunite the Partisans, who denied the supremacy of the old government of the Kingdom of Yugoslavia, and the émigrés loyal to the king led to the Tito-Šubašić Agreement in June 1944; however, Marshal Josip Broz Tito was in control and was determined to lead an independent communist state, starting as a prime minister. He had the support of Moscow and London and led by far the strongest partisan force with 800,000 men.
The official Yugoslav post-war estimate of victims in Yugoslavia during World War II is 1,704,000. Subsequent data gathering in the 1980s by historians Vladimir Žerjavić and Bogoljub Kočović showed that the actual number of dead was about 1 million.
SFR Yugoslavia.
On 11 November 1945 elections were held with only the Communist-led National Front appearing on the ballot, securing all 354 seats. On 29 November, while still in exile, King Peter II was deposed by Yugoslavia's Constituent Assembly, and the Federal People's Republic of Yugoslavia was declared. However, he refused to abdicate. Marshal Tito was now in full control, and all opposition elements were eliminated.
On 31 January 1946, the new constitution of Socialist Federal Republic of Yugoslavia, modeled after the Soviet Union, established six republics, an autonomous province, and an autonomous district that were part of SR Serbia. The federal capital was Belgrade. The policy focused on a strong central government under the control of the Communist Party, and on recognition of the multiple nationalities.
Tito's regional goal was to expand south and take control of Albania and parts of Greece. In 1947, negotiations between Yugoslavia and Bulgaria led to the Bled agreement, which proposed to form a close relationship between the two Communist countries, and enable Yugoslavia to start a civil war in Greece and use Albania and Bulgaria as bases. Stalin vetoed this agreement and it was never realised. The break between Belgrade and Moscow was now imminent.
Yugoslavia solved the national issue of nations and nationalities (national minorities) in a way that all nations and nationalities had the same rights. The flags of the republics used versions of the red flag or Slavic tricolor, with a red star in the centre or in the canton.
The 1948 Yugoslavia-Soviet split.
The country distanced itself from the Soviets in 1948 (cf. Cominform and Informbiro) and started to build its own way to socialism under the strong political leadership of Josip Broz Tito. The country criticised both Eastern Bloc and NATO nations and, together with other countries, started the Non-Aligned Movement in 1961, which remained the official affiliation of the country until it dissolved.
In 1974, the two provinces of Vojvodina and Kosovo-Metohija (for the latter had by then been upgraded to the status of a province), as well as the republics of Bosnia and Herzegovina and Montenegro, were granted greater autonomy to the point that Albanian and Hungarian became nationally recognised minority languages, and the Serbo-Croat of Bosnia and Montenegro altered to a form based on the speech of the local people and not on the standards of Zagreb and Belgrade. In Slovenia the recognized minorities were Hungarians and Italians.
Vojvodina and Kosovo-Metohija formed a part of the Republic of Serbia but those provinces also formed part of the federation, which led to the unique situation that Central Serbia did not have its own assembly but a joint assembly with its provinces represented in it.
Demographics.
Yugoslavia had always been a home to a very diverse population, not only in terms of national affiliation, but also religious affiliation. Of the many religions, Islam, Roman Catholicism, Judaism and Protestantism, as well as various Eastern Orthodox faiths, composed the religions of Yugoslavia, comprising over 40 in all. The religious demographics of Yugoslavia changed dramatically since World War II. A census taken in 1921 and later in 1948 show that 99% of the population appeared to be deeply involved with their religion and practices. With postwar government programs of modernisation and urbanisation, the percentage of religious believers took a dramatic plunge. Connections between religious belief and nationality posed a serious threat to the post-war Communist government's policies on national unity and state structure.
After the rise of communism, a survey taken in 1964 showed that just over 70% of the total population of Yugoslavia considered themselves to be religious believers. The places of highest religious concentration were that of Kosovo with 91% and Bosnia and Herzegovina with 83.8%. The places of lowest religious concentration were Slovenia 65.4%, Serbia with 63.7% and Croatia with 63.6%. Religious differences between Orthodox Serbs, Catholic Croats, Muslim Bosniaks and Albanians alongside the rise of nationalism contributed to the collapse of Yugoslavia in 1991.
Government.
On 7 April 1963, the nation changed its official name to Socialist Federal Republic of Yugoslavia and Josip Broz Tito was named President for life. In the SFRY, each republic and province had its own constitution, supreme court, parliament, president and prime minister. At the top of the Yugoslav government were the President (Tito), the federal Prime Minister, and the federal Parliament (a collective Presidency was formed after Tito's death in 1980). Also important were the Communist Party general secretaries for each republic and province, and the general secretary of Central Committee of the Communist Party.
Tito was the most powerful person in the country, followed by republican and provincial premiers and presidents, and Communist Party presidents. Slobodan Penezić Krcun, Tito's chief of secret police in Serbia, fell victim to a dubious traffic incident after he started to complain about Tito's politics. Minister of the interior Aleksandar Ranković lost all of his titles and rights after a major disagreement with Tito regarding state politics. Some influential ministers in government, such as Edvard Kardelj or Stane Dolanc, were more important than the Prime Minister.
First cracks in the tightly governed system surfaced when students of the University of Belgrade and several other cities joined the worldwide protests of 1968. President Josip Broz Tito gradually stopped the protests by giving in to some of the students' demands and saying that "students are right" during a televised speech. But in the following years, he dealt with the leaders of the protests by sacking them from university and Communist party posts.
A more severe sign of disobedience was so-called Croatian Spring of 1970–1971, when students in Zagreb organised demonstrations for greater civil liberties and greater Croatian autonomy, followed by mass manifestations across Croatia. The regime stifled the public protest and incarcerated the leaders, but many key Croatian representatives in the Party silently supported this cause, lobbying within the Party ranks for a reorganisation of the country. As a result, new Constitution was ratified in 1974, which gave more rights to the individual republics in Yugoslavia and provinces in Serbia.
Ethnic tensions and economic crisis.
The Yugoslav federation was constructed against a double background: an inter-war Yugoslavia which had been dominated by the Serbian ruling class; and a war-time division of the country, as Fascist Italy and Nazi Germany split the country apart and endorsed an extreme Croatian nationalist faction called the Ustaše. A small faction of Bosniak nationalists joined the Axis forces and attacked Serbs while extreme Serb nationalists engaged in attacks on Bosniaks and Croats.
Yugoslav Partisans took over the country at the end of the war and banned nationalism from being publicly promoted. Overall relative peace was retained under Tito's rule, though nationalist protests did occur, but these were usually repressed and nationalist leaders were arrested and some were executed by Yugoslav officials. However one protest in Croatia in the 1970s, called the "Croatian Spring" was backed by large numbers of Croats who claimed that Yugoslavia remained a Serb hegemony and demanded that Serbia's powers be reduced.
Tito, whose home republic was Croatia, was concerned over the stability of the country and responded in a manner to appease both Croats and Serbs, he ordered the arrest of the Croat protestors, while at the same time conceding to some of their demands. In 1974, Serbia's influence in the country was significantly reduced as autonomous provinces were created in ethnic Albanian-majority populated Kosovo and the mixed-populated Vojvodina.
These autonomous provinces held the same voting power as the republics but unlike the republics, they could not legally separate from Yugoslavia. This concession satisfied Croatia and Slovenia, but in Serbia and in the new autonomous province of Kosovo, reaction was different. Serbs saw the new constitution as conceding to Croat and ethnic Albanian nationalists. Ethnic Albanians in Kosovo saw the creation of an autonomous province as not being enough, and demanded that Kosovo become a constituent republic with the right to separate from Yugoslavia. This created tensions within the Communist leadership, particularly among Communist Serb officials who resented the 1974 constitution as weakening Serbia's influence and jeopardising the unity of the country by allowing the republics the right to separate.
An economic crisis erupted in the 1970s which was the product of disastrous errors by Yugoslav governments, such as borrowing vast amounts of Western capital in order to fund growth through exports . Western economies then entered recession, blocked Yugoslav exports and created a huge debt problem. The Yugoslav government then accepted the IMF loan.
In 1989, according to official sources, 248 firms were declared bankrupt or were liquidated and 89,400 workers were laid off. During the first nine months of 1990 directly following the adoption of the IMF programme, another 889 enterprises with a combined work-force of 525,000 workers suffered the same fate. In other words, in less than two years "the trigger mechanism" (under the Financial Operations Act) had led to the lay off of more than 600,000 workers out of a total industrial workforce of the order of 2.7 million. An additional 20% of the work force, or half a million people, were not paid wages during the early months of 1990 as enterprises sought to avoid bankruptcy. The largest concentrations of bankrupt firms and lay-offs were in Serbia, Bosnia and Herzegovina, Macedonia and Kosovo. Real earnings were in a free fall and social programmes had collapsed; creating within the population an atmosphere of social despair and hopelessness. This was a critical turning point in the events to follow.
Breakup.
Though the 1974 Constitution reduced the power of the federal government, Tito's authority substituted for this weakness until his death in 1980.
After Tito's death on 4 May 1980, ethnic tensions grew in Yugoslavia. The legacy of the Constitution of 1974 was used to throw the system of decision-making into a state of paralysis, made all the more hopeless as the conflict of interests had become irreconcilable. The Albanian majority in Kosovo demanded the status of a republic in the 1981 protests in Kosovo while Serbian authorities suppressed this sentiment and proceeded to reduce the province's autonomy.
In 1986, the Serbian Academy of Sciences and Arts drafted a memorandum addressing some burning issues concerning position of Serbs as the most numerous people in Yugoslavia. The largest Yugoslav republic in territory and population, Serbia's influence over the regions of Kosovo and Vojvodina was reduced by the 1974 Constitution. Because its two autonomous provinces had de facto prerogatives of full-fledged republics, Serbia found that its hands were tied, for the republican government was restricted in making and carrying out decisions that would apply to the provinces. Since the provinces had a vote in the Federal Presidency Council (an eight-member council composed of representatives from the six republics and the two autonomous provinces), they sometimes even entered into coalition with other republics, thus outvoting Serbia. Serbia's political impotence made it possible for others to exert pressure on the 2 million Serbs (20% of the total Serbian population) living outside Serbia.
Serbian communist leader Slobodan Milošević sought to restore pre-1974 Serbian sovereignty. Other republics, especially Slovenia and Croatia, denounced this move as a revival of greater Serbian hegemonism. Through a series of moves known as the "anti-bureaucratic revolution", Milošević succeeded in reducing the autonomy of Vojvodina and of Kosovo and Metohija, but both entities retained a vote in the Yugoslav Presidency Council. The very instrument that reduced Serbian influence before was now used to increase it: in the eight-member Council, Serbia could now count on four votes at a minimum – Serbia proper, then-loyal Montenegro, Vojvodina, and Kosovo.
As a result of these events, the ethnic Albanian miners in Kosovo organised the 1989 Kosovo miners' strike, which dovetailed into ethnic conflict between the Albanians and the non-Albanians in the province. At around 80% of the , ethnic-Albanians were the majority. The number of Slavs in Kosovo (mainly Serbs) was quickly declining for several reasons, among them the ever increasing ethnic tensions and subsequent emigration from the area. By 1999 the Slavs formed as little as 10% of the total population in Kosovo.
Meanwhile Slovenia, under the presidency of Milan Kučan, and Croatia supported the Albanian miners and their struggle for formal recognition. Initial strikes turned into widespread demonstrations demanding a Kosovan republic. This angered Serbia's leadership which proceeded to use police force, and later even the Federal Army was sent to the province by the order of the Serbia-held majority in the Yugoslav Presidency Council.
In January 1990, the extraordinary 14th Congress of the League of Communists of Yugoslavia was convened. For most of the time, the Slovenian and Serbian delegations were arguing over the future of the League of Communists and Yugoslavia. The Serbian delegation, led by Milošević, insisted on a policy of "one person, one vote", which would empower the plurality population, the Serbs. In turn, the Slovenes, supported by Croats, sought to reform Yugoslavia by devolving even more power to republics, but were voted down. As a result, the Slovenian and Croatian delegations left the Congress and the all-Yugoslav Communist party was dissolved.
The constitutional crisis that inevitably followed resulted in a rise of nationalism in all republics: Slovenia and Croatia voiced demands for looser ties within the Federation.
Following the fall of communism in the rest of Eastern Europe, each of the republics held multi-party elections in 1990. Slovenia and Croatia held the elections in April since their communist parties chose to cede power peacefully. Other Yugoslav republics – especially Serbia – were more or less dissatisfied with the democratisation in two of the republics and proposed different sanctions (e.g. Serbian "customs tax" for Slovenian products) against the two, but as the year progressed, other republics' communist parties saw the inevitability of the democratisation process and in December as the last member of the federation – Serbia held parliamentary elections which confirmed former communists' rule in this republic.
The unresolved issues however remained. In particular, Slovenia and Croatia elected governments oriented towards greater autonomy of the republics (under Milan Kučan and Franjo Tuđman, respectively), since it became clear that Serbian domination attempts and increasingly different levels of democratic standards were becoming increasingly incompatible. Serbia and Montenegro elected candidates who favoured Yugoslav unity.
The Croat quest for independence led to large Serb communities within Croatia rebelling and trying to secede from the Croat republic. Serbs in Croatia would not accept a status of a national minority in a sovereign Croatia, since they would be demoted from the status of a constituent nation of the entirety of Yugoslavia.
Yugoslav Wars.
The war broke out when the new regimes tried to replace Yugoslav civilian and military forces with secessionist forces. When, in August 1990, Croatia attempted to replace police in the Serb populated Croat Krajina by force, the population first looked for refuge in the Yugoslavian Army barracks, while the army remained passive. The civilians then organised armed resistance. These armed conflicts between the Croatian armed forces ("police") and civilians mark the beginning of the Yugoslav war that inflamed the region. Similarly, the attempt to replace Yugoslav frontier police by Slovenian police forces provoked regional armed conflicts which finished with a minimal number of victims.
A similar attempt in Bosnia and Herzegovina led to a war that lasted more than three years (see below). The results of all these conflicts are almost complete emigration of the Serbs from all three regions, massive displacement of the populations in Bosnia and Herzegovina, and establishment of the three new independent states. The separation of Macedonia was peaceful, although the Yugoslav Army occupied the peak of the Straža mountain on the Macedonian soil.
Serbian uprisings in Croatia began in August 1990 by blocking roads leading from the Dalmatian coast towards the interior almost a year before Croatian leadership made any move towards independence. These uprisings were more or less discretely backed up by the Serb-dominated federal army (JNA). The Serbs in Croatia proclaimed "Serb autonomous areas", later united into the Republic of Serb Krajina. The federal army tried to disarm the territorial defence forces of Slovenia (republics had their local defence forces similar to the Home Guard) in 1990 but was not completely successful. Still, Slovenia began to covertly import arms to replenish its armed forces.
Croatia also embarked upon the illegal import of arms, (following the disarmament of the republics' armed forces by the federal army) mainly from Hungary, and were under constant surveillance which produced a video of a secret meeting between the Croatian Defence minister Martin Špegelj and the two men, filmed by the Yugoslav counter-intelligence ("KOS, Kontra-obavještajna služba"). Špegelj announced that they were at war with the army and gave instructions about arms smuggling as well as methods of dealing with the Yugoslav Army's officers stationed in Croatian cities. Serbia and JNA used this discovery of Croatian rearmament for propaganda purposes.
Guns were also fired from army bases through Croatia. Elsewhere, tensions were running high.
In the same month, the Army leaders met with the Presidency of Yugoslavia in an attempt to get them to declare a state of emergency which would allow for the army to take control of the country. The army was seen as an arm of the Serbian government by that time so the consequence feared by the other republics was to be total Serbian domination of the union. The representatives of Serbia, Montenegro, Kosovo, and Vojvodina voted for the decision, while all other republics, Croatia, Slovenia, Macedonia and Bosnia and Herzegovina, voted against. The tie delayed an escalation of conflicts, but not for long.
Following the first multi-party election results, in the autumn of 1990, the republics of Slovenia and Croatia proposed transforming Yugoslavia into a loose confederation of six republics. By this proposal, republics would have right to self-determination. However Milošević rejected all such proposals, arguing that like Slovenes and Croats, the Serbs (having in mind Croatian Serbs) should also have a right to self-determination.
On 9 March 1991, demonstrations were held against Slobodan Milošević in Belgrade, but the police and the military were deployed in the streets to restore order, killing two people. In late March 1991, the Plitvice Lakes incident was one of the first sparks of open war in Croatia. The Yugoslav People's Army (JNA), whose superior officers were mainly of Serbian ethnicity, maintained an impression of being neutral, but as time went on, they got more and more involved in state politics.
On 25 June 1991, Slovenia and Croatia became the first republics to declare independence from Yugoslavia. The federal customs officers in Slovenia on the border crossings with Italy, Austria, and Hungary mainly just changed uniforms since most of them were local Slovenes. The following day (26 June), the Federal Executive Council specifically ordered the army to take control of the "internationally recognised borders", leading to the Ten-Day War.
The Yugoslav People's Army forces, based in barracks in Slovenia and Croatia, attempted to carry out the task within the next 48 hours. However, because of misinformation given to the Yugoslav Army conscripts that the Federation was under attack by foreign forces and the fact that the majority of them did not wish to engage in a war on the ground where they served their conscription, the Slovene territorial defence forces retook most of the posts within several days with only minimal loss of life on both sides.
There was a suspected incident of a war crime, as the Austrian ORF TV network showed footage of three Yugoslav Army soldiers surrendering to the territorial defence force, before gunfire was heard and the troops were seen falling down. However, none were killed in the incident. There were however numerous cases of destruction of civilian property and civilian life by the Yugoslav People's Army, including houses and a church. A civilian airport, along with a hangar and aircraft inside the hangar, was bombarded; truck drivers on the road from Ljubljana to Zagreb and Austrian journalists at the Ljubljana Airport were killed.
A ceasefire was eventually agreed upon. According to the Brioni Agreement, recognised by representatives of all republics, the international community pressured Slovenia and Croatia to place a three-month moratorium on their independence.
During these three months, the Yugoslav Army completed its pull-out from Slovenia, but in Croatia, a bloody war broke out in the autumn of 1991. Ethnic Serbs, who had created their own state Republic of Serbian Krajina in heavily Serb-populated regions resisted the police forces of the Republic of Croatia who were trying to bring that breakaway region back under Croatian jurisdiction. In some strategic places, the Yugoslav Army acted as a buffer zone; in most others it was protecting or aiding Serbs with resources and even manpower in their confrontation with the new Croatian army and their police force.
In September 1991, the Republic of Macedonia also declared independence, becoming the only former republic to gain sovereignty without resistance from the Belgrade-based Yugoslav authorities. 500 U.S. soldiers were then deployed under the U.N. banner to monitor Macedonia's northern borders with the Republic of Serbia. Macedonia's first president, Kiro Gligorov, maintained good relations with Belgrade and the other breakaway republics and there have to date been no problems between Macedonian and Serbian border police even though small pockets of Kosovo and the Preševo valley complete the northern reaches of the historical region known as Macedonia (Prohor Pčinjski part), which would otherwise create a border dispute if ever Macedonian nationalism should resurface ("see VMRO"). This was despite the fact that the Yugoslav Army refused to abandon its military infrastructure on the top of the Straža Mountain up to the year 2000.
As a result of the conflict, the United Nations Security Council unanimously adopted UN Security Council Resolution 721 on 27 November 1991, which paved the way to the establishment of peacekeeping operations in Yugoslavia.
In Bosnia and Herzegovina in November 1991, the Bosnian Serbs held a referendum which resulted in an overwhelming vote in favour of forming a Serbian republic within the borders of Bosnia and Herzegovina and staying in a common state with Serbia and Montenegro. On 9 January 1992, the self-proclaimed Bosnian Serb assembly proclaimed a separate "Republic of the Serb people of Bosnia and Herzegovina". The referendum and creation of SARs were proclaimed unconstitutional by the government of Bosnia and Herzegovina and declared illegal and invalid. However, in February–March 1992, the government held a national referendum on Bosnian independence from Yugoslavia. That referendum was in turn declared contrary to the BiH and the Federal constitution by the federal Constitutional Court in Belgrade and the newly established Bosnian Serb government.
The referendum was largely boycotted by the Bosnian Serbs. The Federal court in Belgrade did not decide on the matter of the referendum of the Bosnian Serbs. The turnout was somewhere between 64–67% and 98% of the voters voted for independence. It was not clear what the two-thirds majority requirement actually meant and whether it was satisfied. The republic's government declared its independence on 5 April, and the Serbs immediately declared the independence of "Republika Srpska". The war in Bosnia followed shortly thereafter.
Timeline.
Various dates are considered the end of the Socialist Federal Republic of Yugoslavia:
New states.
The successor states to the former Yugoslavia are the following:
Succession, 1992–2003.
As the Yugoslav Wars raged through Croatia and Bosnia, the republics of Serbia and Montenegro, which remained relatively untouched by the war, formed a rump state known as the Federal Republic of Yugoslavia (FRY) in 1992. The Federal Republic of Yugoslavia aspired to be a sole legal successor to the Socialist Federal Republic of Yugoslavia, but those claims were opposed by the other former republics. The United Nations also denied its request to automatically continue the membership of the former state. Eventually, after the overthrow of Slobodan Milošević from power as president of the federation in 2000, the country dropped those aspirations, accepted the opinion of the Badinter Arbitration Committee about shared succession, and reapplied for and gained UN membership on 2 November 2000. (From 1992 to 2000, some countries, including the United States, had referred to the FRY as "Serbia and Montenegro".) In April 2001, the five successor states extant at the time drafted an Agreement on Succession Issues, signing the agreement in June 2001. Marking an important transition in its history, the Federal Republic of Yugoslavia was officially renamed Serbia and Montenegro in 2003.
Succession, 2006–present.
In June 2006, Montenegro became an independent nation after the results of a May 2006 referendum, therefore rendering Serbia and Montenegro no longer existent. After Montenegro's independence, Serbia became the legal successor of Serbia and Montenegro, while Montenegro re-applied for membership in international organisations. In February 2008, the Republic of Kosovo declared independence from Serbia, leading to an ongoing dispute on whether Kosovo is a legally recognised state. However, numerous countries, including the United States and various members of the European Union, have recognised Kosovo as an independent nation.
Yugosphere.
In 2009, "The Economist" coined the term "Yugosphere" to describe the present-day physical areas that formed Yugoslavia, as well as its culture and influence.
The similarity of the languages and the long history of common life have left many ties among the peoples of the new states, even though the individual state policies of the new states favour differentiation, particularly in language. The Serbo-Croatian language is linguistically a single language, with several literary and spoken variants since the language of the government was imposed where other languages dominated (Slovenia, Macedonia). Now, separate sociolinguistic standards exist for the Bosnian, Croatian, Montenegrin and Serbian languages.
Remembrance of the time of the joint state and its perceived positive attributes is referred to as "Yugonostalgia".
Many aspects of Yugonostalgia refer to the socialist system and the sense of social security it provided. There are still people from the former Yugoslavia who self-identify as Yugoslavs; this identifier is commonly seen in demographics relating to ethnicity in today's independent states.

</doc>
<doc id="34245" url="http://en.wikipedia.org/wiki?curid=34245" title="History of Yemen">
History of Yemen

Yemen is one of the oldest centers of civilization in the Near East. Its relatively fertile land and adequate rainfall in a moister climate helped sustain a stable population, a feature recognized by the ancient Greek geographer Ptolemy, who described Yemen as "Eudaimon Arabia" (better known in its Latin translation, "Arabia Felix") meaning "fortunate Arabia" or "Happy Arabia".
Some scholars believe that Yemen remains the only region in the world that is exclusively Semitic, meaning that Yemen historically did not have any non–Semitic-speaking people. Yemeni Semites derived their Musnad script by the 12th to 8th centuries BCE, which explains why most historians date all of the ancient Yemeni kingdoms to the 12th to 8th centuries BCE.
Between the 12th century BCE and the 6th century CE, it was dominated by six successive civilizations which rivaled each other, or were allied with each other and controlled the lucrative spice trade: Ma'in, Qataban, Hadhramaut, Awsan, Saba and Himyar. Islam arrived in 630 CE, and Yemen became part of the Muslim realm.
Ancient history.
With its long sea border between early civilizations, Yemen has long existed at a crossroads of cultures with a strategic location in terms of trade on the west of the Arabian Peninsula. Large settlements for their era existed in the mountains of northern Yemen as early as 5000 BC. Little is known about ancient Yemen and how exactly it transitioned from nascent Bronze Age civilizations to more trade-focussed caravan kingdoms. This may be due to social or official discouragement of research into pre-Islamic civilizations in Arabia.
The Sabaean Kingdom came into existence from at least the eleventh century BC. There were four major kingdoms or tribal confederations in South Arabia: Saba, Hadramout, Qataban and Ma'in. Saba is believed to be biblical Sheba and was the most prominent federation. The Sabaean rulers adopted the title Mukarrib generally thought to mean "unifier", or a "priest-king". The role of the Mukarrib was to bring the various tribes under the kingdom and preside over them all. The Sabaens built the Great Dam of Marib around 940 BC. The dam was built to withstand the seasonal flash floods surging down the valley.
Between 700 and 680 BC, the Kingdom of Awsan dominated Aden and its surroundings. Sabaean Mukarrib Karib'il Watar I changed his ruling title to that of a king, and conquered the entire realm of Awsan, expanding Sabaean rule and territory to include much of South Arabia. Lack of water in the Arabian Peninsula prevented the Sabaeans from unifying the entire peninsula. Instead, they established various colonies to control trade routes. Evidence of Sabaean influence is found in northern Ethiopia, where the South Arabian alphabet religion and pantheon, and the South Arabian style of art and architecture were introduced. The Sabaean created a sense of identity through their religion. They worshipped El-Maqah and believed themselves to be his children. For centuries, the Sabaeans controlled outbound trade across the Bab-el-Mandeb, a strait separating the Arabian Peninsula from the Horn of Africa and the Red Sea from the Indian Ocean.
By the 3rd century BC, Qataban, Hadramout and Ma'in became independent from Saba and established themselves in the Yemeni arena. Minaean rule stretched as far as Dedan, with their capital at Baraqish. The Sabaeans regained their control over Ma'in after the collapse of Qataban in 50 BCE. By the time of the Roman expedition to Arabia Felix in 25 BC, the Sabaeans were once again the dominating power in Southern Arabia. Aelius Gallus was ordered to lead a military campaign to establish Roman dominance over the Sabaeans. The Romans had a vague and contradictory geographical knowledge about Arabia Felix or Yemen. The Roman army of ten thousand men was annihilated before Marib. Strabo's close relationship with Aelius Gallus led him to attempt to justify his friend's defeat in his writings. It took the Romans six months to reach Marib and sixty days to return to Egypt. The Romans blamed their Nabataean guide and executed him for treachery. No direct mention in Sabaean inscriptions of the Roman expedition has yet been found.
After the Roman expedition – perhaps earlier – the country fell into chaos and two clans, namely Hamdan and Himyar, claimed kingship, assuming the title "King of Sheba and Dhu Raydan". Dhu Raydan (i.e. Himyarites) allied themselves with Aksum in Ethiopia against the Sabaeans. The chief of Bakil and king of "Saba and Dhu Raydan", El-sharah Yahdub, launched successful campaigns against the Himyarites and "Habashat" (i.e. Aksum), El-sharah took proud of his campaigns and added the title "Yahdub" to his name, which means "suppressor"; he used to kill his enemies by cutting them to pieces. Sana'a came into prominence during his reign as he built the Ghumdan Palace to be his place of residence.
The Himyarite annexed Sana'a from Hamdan in around 100 AD. Hashdi tribesmen rebelled against them, however, and regained Sana'a in around 180 AD. It was not until 275 AD that Shammar Yahri'sh conquered Hadramout and Najran and Tihama, thus unifying Yemen and consolidating Himyarite rule. The Himyarites rejected polytheism and adhered to a consensual form of monotheism called Rahmanism. In 354 AD, Roman Emperor Constantius II sent an embassy headed by Theophilos the Indian to convert the Himyarites to Christianity. According to Philostorgius, the mission was resisted by local Jews. Several inscriptions have been found in Hebrew and Sabaean praising the ruling house in Jewish terms for "helping and empowering the People of Israel".
According to Islamic traditions, King As'ad The Perfect mounted a military expedition to support the Jews of Yathrib. Abu Karib As'ad, as known from the inscriptions, led a military campaign to central Arabia or Najd to support the vassal Kingdom of Kindah against the Lakhmids. However, no direct reference to Judaism or Yathrib was discovered from his lengthy reign. Abu Kariba died in 445 AD having reigned for almost 50 years. By 515 AD, Himyar became increasingly divided along religious lines and a bitter conflict between different factions paved the way for an Aksumite intervention. The last Himyarite king Ma'adikarib Ya'fur was supported by Aksum against his Jewish rivals. Ma'adikarib was Christian and launched a campaign against the Lakhmids in Southern Iraq, with the support of other Arab allies of Byzantium. The Lakhmids were a Bulwark of Persia, which was intolerant to a proselytizing religion like Christianity.
After the death of Ma'adikarib Ya'fur in around 521 AD, a Himyarite Jewish warlord named Yousef Asar Yathar rose to power. His honorary title "Yathar" means "to avenge". Yemenite Christians, aided by Aksum and Byzantium, systematically persecuted Jews and burned down several synagogues across the land. Yousef avenged his people with great cruelty. He marched toward the port city of Mocha killing 14,000 and capturing 11,000. Then he settled a camp in Bab-el-Mandeb to prevent aid flowing from Aksum. At the same time, Yousef sent an army under the command of another Jewish warlord, Sharahil Yaqbul, to Najran. Sharahil had reinforcements from the Bedouins of the Kindah and Madh'hij tribes, eventually wiping out the Christian community in Najran. Yousef or Dhu Nuwas (The one with sidelocks) as known in Arabic literature, believed that Christians in Yemen were a fifth column. Christian sources portray Dhu Nuwas (Yousef Asar) as a Jewish zealot, while Islamic traditions say that he threw 20,000 Christians into pits filled with flaming oil. This history, however, is shrouded in legend. Dhu Nuwas left two inscriptions, neither of them making any reference to fiery pits. Byzantium had to act or lose all credibility as protector of eastern Christianity. It is reported that Byzantium Emperor Justin I sent a letter to the Aksumite King Kaleb, pressuring him to "attack the abominable Hebrew". A tripartite military alliance of Byzantine, Aksumite and Arab Christians successfully defeated Yousef around 525–527 AD and a client Christian king was installed on the Himyarite throne.
Esimiphaios was a local Christian lord, mentioned in an inscription celebrating the burning of an ancient Sabaean palace in Marib to build a church on its ruins. Three new churches were built in Najran alone. Many tribes did not recognize Esimiphaios's authority. Esimiphaios was displaced in 531 by a warrior named Abraha, who refused to leave Yemen and declared himself an independent king of Himyar. Emperor Justinian I sent an embassy to Yemen. He wanted the officially "Christian" Himyarites to use their influence on the tribes in inner Arabia to launch military operations against Persia. Justinian I bestowed the "dignity of king" upon the Arab sheikhs of Kindah and Ghassan in central and north Arabia. From early on, Roman and Byzantine policy was to develop close links with the powers of the coast of the Red Sea. They were successful in converting Aksum and influencing their culture. The results with regard to Yemen were rather disappointing.
A Kendite prince called "Yazid bin Kabshat" rebelled against Abraha and his Arab Christian allies. A truce was reached once The Great Dam of Marib had suffered a breach. Abraha died around 555–565; no reliable sources regarding his death are available. The Sasanid empire annexed Aden around 570 AD. Under their rule, most of Yemen enjoyed great autonomy except for Aden and Sana'a. This era marked the collapse of ancient South Arabian civilization, since the greater part of the country was under several independent clans until the arrival of Islam in 630 AD.
Middle Ages.
Advent of Islam and the three Dynasties.
Mohammed sent his cousin Ali to Sana'a and its surroundings around 630 AD. At the time, Yemen was the most advanced region in Arabia. The Banu Hamdan confederation were among the first to accept Islam. Mohammed sent Muadh ibn Jabal as well to Al-Janad in present day Taiz, and dispatched letters to various tribal leaders. The reason behind this was the division among the tribes and the absence of a strong central authority in Yemen during the days of the prophet. Major tribes, including Himyar, sent delegations to Medina during the "Year of delegations" around 630–631 AD. Several Yemenis accepted Islam before the year 630, such as Ammar ibn Yasir, Al-Ala'a Al-Hadrami, Miqdad ibn Aswad, Abu Musa Ashaari and Sharhabeel ibn Hasana. A man named 'Abhala ibn Ka'ab Al-Ansi expelled the remaining Persians and claimed to be a prophet of Rahman. He was assassinated by a Yemeni of Persian origin called Fayruz al-Daylami. Christians, who were mainly staying in Najran along with Jews, agreed to pay Jizya, although some Jews converted to Islam, such as Wahb ibn Munabbih and Ka'ab al-Ahbar.
The country was stable during the Rashidun Caliphate. Yemeni tribes played a pivotal role in the Islamic conquests of Egypt, Iraq, Persia the Levant, Anatolia, North Africa, Sicily and Andalusia. Yemeni tribes that settled in Syria, contributed significantly to the solidification of Umayyad rule, especially during the reign of Marwan I. Powerful Yemenite tribes like Kindah were on his side during the Battle of Marj Rahit. Several emirates led by people of Yemeni descent were established in North Africa and Andalusia. Effective control over entire Yemen was not achieved by the Umayyad Caliphate. Imam Abdullah ibn Yahya Al-Kindi was elected in 745 AD to lead the Ibāḍī movement in Hadramawt and Oman. He expelled the Umayyad governor from Sana'a and captured Mecca and Medina in 746 AD. Al-Kindi, known by his nickname "Talib al-Haq" (Seeker of truth), established the first Ibadi state in the history of Islam but was killed in Taif around 749 AD.
Muhammad ibn Abdullah ibn Ziyad founded the Ziyadid dynasty in Tihama around 818 AD; the state stretched from Haly (In present day Saudi Arabia) to Aden. They nominally recognized the Abbasid Caliphate but were in fact ruling independently from their capital in Zabid. The history of this dynasty is obscure; they never exercised control over the highlands and Hadramawt, and did not control more than a coastal strip of the Yemen (Tihama) bordering the Red Sea. A Himyarite clan called the Yufirids established their rule over the highlands from Saada to Taiz, while Hadramawt was an Ibadi stronghold and rejected all allegiance to the Abbasids in Baghdad. By virtue of its location, the Ziyadid dynasty of Zabid developed a special relationship with Abyssinia. The chief of the Dahlak islands exported slaves as well as amber and leopard hides to the then ruler of Yemen.
The first Zaidi imam, Yahya ibn al-Husayn, arrived to Yemen in 893 AD. He was the founder of the Zaidi imamate in 897. He was a religious cleric and judge who was invited to come to Saada from Medina to arbitrate tribal disputes. Imam Yahya persuaded local tribesmen to follow his teachings. The sect slowly spread across the highlands, as the tribes of Hashid and Bakil, later known as "the twin wings of the imamate", accepted his authority. Yahya established his influence in Saada and Najran; he also tried to capture Sana'a from the Yufirids in 901 AD but failed miserably. In 904, the Qarmatians invaded Sana'a. The Yufirid emir As'ad ibn Ibrahim retreated to Al-Jawf, and between 904 and 913, Sana'a was conquered no less than 20 times by Qarmatians and Yufirids. As'ad ibn Ibrahim regained Sana'a in 915. The country was in turmoil as Sana'a became a battlefield for the three dynasties as well as independent tribes.
The Yufirid emir Abdullah ibn Qahtan attacked and burned Zabid in 989, severely weakening the Ziyadid dynasty. The Ziyadid monarchs lost effective power after 989, or even earlier than that. Meanwhile, a succession of slaves held power in Zabid and continued to govern in the name of their masters eventually establishing their own dynasty around 1022 or 1050 according to different sources. Although they were recognized by the Abbasid Caliphate in Baghdad, they ruled no more than Zabid and four districts to its north. The rise of the Ismaili Shia Sulayhid dynasty in the Yemeni highlands reduced their history to a series of intrigues.
Sulayhid Dynasty.
The Sulayhid dynasty was founded in the northern highlands around 1040. At the time, Yemen was ruled by different local dynasties.
In 1060, Ali ibn Mohammed Al-Sulayhi conquered Zabid and killed its ruler Al-Najah, founder of the Najahid dynasty, whose sons were forced to flee to Dahlak. Hadramawt fell into Sulayhid hands after their capture of Aden in 1162. By 1063, Ali had subjugated Greater Yemen. He then marched toward Hejaz and occupied Makkah. Ali was married to Asma bint Shihab, who governed Yemen with her husband. The Khutba during Friday prayers was proclaimed in her husband's and her name. No other Arab woman had this honor since the advent of Islam.
Ali al-Sulayhi was killed by Najah's sons on his way to Mecca in 1084. His son Ahmad al-Mukarram led an army to Zabid and killed 8,000 of its inhabitants. He later installed the Zurayids to govern Aden. Ahmad al-Mukarram, who had been afflicted with facial paralysis resulting from war injuries, retired in 1087 and handed over power to his wife Arwa al-Sulayhi. Queen Arwa moved the seat of the Sulayhid dynasty from Sana'a to Jibla, a small town in central Yemen near Ibb. Jibla was strategically near the Sulayhid dynasty source of wealth, the agricultural central highlands. It was also within easy reach of the southern portion of the country, especially Aden. She sent Ismaili missionaries to India where a significant Ismaili community was formed that exists to this day. Queen Arwa continued to rule securely until her death in 1138.
Arwa al-Sulayhi is still remembered as a great and much loved sovereign, as attested in Yemeni historiography, literature, and popular lore, where she is referred to as " Balqis al-sughra ", that is "the junior queen of Sheba". Although the Sulayhids were Ismaili, they never tried to impose their beliefs on the public. Shortly after queen Arwa's death, the country was split between five competing petty dynasties along religious lines. The Ayyubid dynasty overthrew the Fatimid caliphate in Egypt. A few years after their rise to power, Saladin dispatched his brother Turan Shah to conquer Yemen in 1174.
Ayyubid conquest.
Turan Shah conquered Zabid from the Mahdids in May 1174, then marched toward Aden in June and captured it from the Zurayids. The Hamdanid sultans of Sana'a resisted the Ayyubid in 1175 and it was not until 1189 that the Ayyubids managed to definitely secure Sana'a. The Ayyubid rule was stable in southern and central Yemen where they succeeded in eliminating the mini-states of that region, while Ismaili and Zaidi tribesmen continued to hold out in a number of fortresses. The Ayyubids failed to capture the Zaydis stronghold in northern Yemen. In 1191, Zaydis of Shibam Kawkaban rebelled and killed 700 Ayyubid soldiers. Imam Abdullah bin Hamza proclaimed the imamate in 1197 and fought al-Mu'izz Ismail, the Ayyubid Sultan of Yemen. Imam Abdullah was defeated at first but was able to conquer Sana'a and Dhamar in 1198 al-Mu'izz Ismail was assassinated in 1202 Abdullah bin Hamza carried on the struggle against the Ayyubid until his death in 1217. After his demise, the Zaidi community was split between two rival imams. The Zaydis were dispersed and a truce was signed with the Ayyubid in 1219. The Ayyubid army was defeated in Dhamar in 1226. Ayyubid Sultan Mas'ud Yusuf left for Mecca in 1228 never to return. Other sources suggest that he was forced to leave for Egypt instead in 1123.
Rasulid Dynasty.
The Rasulid Dynasty was established in 1229 by Umar ibn Rasul. Umar ibn Rasul was appointed deputy governor by the Ayyubids in 1223. When the last Ayyubid ruler left Yemen in 1229, Umar stayed in the country as caretaker. He subsequently declared himself an independent king by assuming the title " al-Malik Al-Mansur " (the king assisted by Allah). Umar established the Rasulid dynasty on a firm foundation and expanded its territory to include the area from Dhofar to Mecca Umar first established himself at Zabid, then moved into the mountainous interior, taking the important highland centre Sana'a. However, the Rasulid capitals were Zabid and Ta'izz. He was assassinated by his nephew in 1249. Omar's son Yousef defeated the faction led by his father assassins and crushed several counter-attacks by the Zaydi imams who still held on in the northern highland. It was mainly because of the victories which he scored over his rivals that he assumed the honorific title " al-Muzaffar " (the victorious). After the fall of Baghdad to the Mongols in 1258, al-Muzaffar Yusuf I appropriated the title of caliph. He chose the city of Ta'izz to became the political capital of the kingdom because of its strategic location and proximity to Aden. al-Muzaffar Yusuf I died in 1296 having reigned for 47 years. When the news of his death reached the Zaydi imam Al-Mutawakkil al-Mutahhar bin Yahya he commented by saying: "The greatest king of Yemen, the Muawiyah of the time, has died. His pens used to break our lances and swords to pieces"
The Rasulid state nurtured Yemen's commercial links with India and the Far East. They profited greatly by the Red Sea transit trade via Aden and Zabid. The economy also boomed due to the agricultural development programs instituted by the kings who promoted massive cultivation of palms. It was during this period that coffee became a lucrative cash crop in Yemen. The Rasulid kings enjoyed the support of the population of Tihama and southern Yemen while they had to buy the loyalty of Yemen's restive northern highland tribes. The Rasulid sultans built numerous Madrasas in order to solidify the Shafi'i school of thought which is still the dominant school of jurisprudence amongst Yemenis today. Under their rule, Ta'izz and Zabid became major international centers of Islamic learning. The Kings themselves were learned men in their own right who not only had important libraries but who also wrote treatises on a wide array of subjects, ranging from astrology and medicine to agriculture and genealogy.
The dynasty is regarded as the greatest native Yemeni state since the fall of pre-Islamic Himyarite Kingdom. They were, of course, of Turkic descent but claimed an ancient Yemenite origin to justify their rule. The Rasulids were not the first dynasty to create a fictitious genealogy for political purposes, nor were they doing anything out of the ordinary in the tribal context of Arabia. By claiming descent from a solid Yemenite tribe, the Rasulid brought Yemen to a vital sense of unity in an otherwise chaotic regional milieu. They had a difficult relationship with the Mamluks of Egypt because the latter considered them a vassal state. Their competition centered over the Hejaz and the right to provide kiswa of the Ka'aba in Mecca. The dynasty became increasingly threatened by disgruntled family members over the problem of succession, combined by periodic tribal revolts, as they were locked in a war of attrition with the Zaydi imams in the northern highlands. During the last twelve years of Rasulid rule, the country was torn between several contenders for the kingdom. The weakening of the Rasulids provided an opportunity for the Banu Taher clan to take over and establish themselves as the new rulers of Yemen in 1454 AD.
Tahiride Dynasty.
The Tahirids were a local clan based in Rada'a. While they were not as impressive as their predecessors, they were still keen builders. They built schools, mosques and irrigation channels as well as water cisterns and bridges in Zabid and Aden, Rada'a, and Juban. Their best-known monument is the Amiriya Madrasa in Rada' which was built in 1504. The Tahiride were too weak either to contain the Zaydi Imams or to defend themselves against foreign attacks. The Mamluks of Egypt tried to attach Yemen to Egypt and the Portuguese, led by Afonso de Albuquerque, occupied Socotra and made an unsuccessful attack on Aden in 1513. The Portuguese posed an immediate threat to the Indian ocean trade; the Mamluks of Egypt therefore sent an army under the command of Hussein Al-Kurdi to fight the intruders. The Mamluk sultan of Egypt sailed to Zabid in 1515 and began diplomatic talks with Tahiride Sultan 'Amir bin Abdulwahab for money that would be needed for "jihad" against the Portuguese. Instead of confronting the Portuguese, the Mamluks, who were running out of food and water, landed their fleet on the Yemen coastline and started to harass Tihama villagers for what they needed. Realizing how rich the Tahiride realm was, they decided to conquer it. The Mamluk army with the support of forces loyal to Zaydi Imam Al-Mutawakkil Yahya Sharaf ad-Din conquered the entire realm of the Tahiride but failed to capture Aden in 1517. The Mamluk victory turned out to be short-lived. The Ottoman Empire conquered Egypt, hanging the last Mamluk Sultan in Cairo. It was not until 1538 that the Ottomans decided to conquer Yemen. The Zaydi Highland tribes emerged as national heroes by offering a stiff, vigorous resistance to the Turkish occupation.
Modern history.
The Zaydis and Ottomans.
The Ottomans had two fundamental interests to safeguard in Yemen: The Islamic holy cities of Mecca and Medina and the trade route with India in spices and textiles, both of which were threatened and the latter virtually eclipsed by the arrival of the Portuguese in the Indian Ocean and the Red Sea in the early part of the 16th century. Hadım Suleiman Pasha, The Ottoman governor of Egypt, was ordered to command a fleet of 90 ships to conquer Yemen. The country was in a state of incessant anarchy and discord as Hadım Suleiman Pasha described it by saying:"Yemen is a land with no lord, an empty province. It would be not only possible but easy to capture, and should it be captured, it would be master of the lands of India and send every year a great amount of gold and jewels to Constantinople."
Imam al-Mutawakkil Yahya Sharaf ad-Din ruled over the northern highlands including Sana'a while Aden was held by the last Tahiride Sultan 'Amir ibn Dauod. Hadım Suleiman Pasha stormed Aden in 1538, killing its ruler and extended Ottoman's authority to include Zabid in 1539 and eventually Tihama in its entirety. Zabid became the administrative headquarters of Yemen Eyalet. The Ottoman governors did not exercise much control over the highlands, they held sway mainly in the southern coastal region, particularly around Zabid, Mocha and Aden. Out of 80,000 soldiers sent to Yemen from Egypt between 1539 – 1547, only 7,000 survived. The Ottoman accountant-general in Egypt remarks:"We have seen no foundry like Yemen for our soldiers. Each time we have sent an expeditionary force there, it has melted away like salt dissolved in water."
The Ottoman sent yet another expeditionary force to Zabid in 1547 while Imam al-Mutawakkil Yahya Sharaf ad-Din was ruling the highlands independently. Imam al-Mutawakkil Yahya chose his son Ali to succeed him, a decision that infuriated his other son al-Mutahhar ibn Yahya. Al-Mutahhar was lame and therefore not qualified for the Imamate. He urged Oais Pasha, the Ottoman colonial governor in Zabid, to attack his father. Indeed Ottoman troops supported by tribal forces loyal to Imam al-Mutahhar stormed Ta'izz and marched north toward Sana'a in August 1547. The Turks officially made Imam al-Mutahhar a Sanjak-bey with authority over 'Amran. Imam al-Mutahhar assassinated the Ottoman colonial governor and recaptured Sana'a but the Ottomans led by Özdemir Pasha, forced al-Mutahhar to retreat to his fortress in Thula. Özdemir Pasha effectively put Yemen under Ottoman rule between 1552 and 1560, he garrisoned the main cities. built new fortresses and rendered secure the main routes. Özdemir died in Sana'a in 1561 to be succeeded by Mahmud Pasha.
Mahmud Pasha was described by other Ottoman officials as corrupt and unscrupulous governor, he used his authority to take over a number of castles some of which belonged to the former Rasulid Kings. Mahmud Pasha killed a Sunni scholar from Ibb. The Ottoman historian claimed that this incident was celebrated by the Zaydi Shia community in the northern highlands. Disregarding the delicate balance of power in Yemen by acting tactlessly, he alienated different groups within Yemeni society, causing them to forget their rivalries and unite against the Turks. Mahmud Pasha was displaced by Ridvan Pasha in 1564. By 1565, Yemen was split into two provinces: the highlands under the command of Ridvan Pasha and Tihama under Murad Pasha. Imam al-Mutahhar launched a propaganda campaign in which he claimed contact with prophet Mohammed in a dream advising him to wage "jihad" against the Ottomans. Al-Mutahhar led the tribes to capture Sana'a from Ridvan Pasha in 1567. When Murad tried to relieve Sana'a, highland tribesmen ambushed his unit and slaughtered everyone of them. Over 80 battles were fought, the last decisive encounter took place in Dhamar around 1568 in which Murad Pasha was beheaded and had his head sent to al-Mutahhar in Sana'a. By 1568, only Zabid remained under the possession of the Turks.
Lala Kara Mustafa Pasha, the Ottoman governor of Syria, was ordered by Selim II to suppress the Yemeni rebels, the Turkish army in Egypt was reluctant to go to Yemen however. Mustafa Pasha sent a letter with two Turkish shawishes hoping to persuade al-Mutahhar to give an apology and say that he did not promote any act of aggression against the Ottoman army, and claim that the " ignorant Arabians " according to the Turks, acted on their own. Imam al-Mutahhar refused the Ottoman offer. Mustafa Pasha sent an expeditionary force under the command of Uthman Pasha, the expeditionary force was defeated with great casualties. Sultan Selim II was infuriated by Mustafa's hesitation to go Yemen, he executed a number of sanjak-beys in Egypt and ordered Sinan Pasha to lead the entire Turkish army in Egypt to reconquer Yemen. Sinan Pasha was a prominent Ottoman General of Albanian origin. He reconquered Aden, Ta'izz, Ibb and besieged Shibam Kawkaban in 1770 for 7 months, the siege was lifted once a truce was reached. Imam al-Mutahhar was pushed back but could not be entirely overcome. After al-Mutahhar's demise in 1572, the Zaydi community was not united under an imam; the Turks took advantage of their disparity and conquered Sana'a, Sa'dah and Najran in 1583. Imam al-Nasir Hassan was arrested in 1585 and exiled to Constantinople, thereby putting an end to the Yemeni rebellion.
The Zaydi tribesmen in the northern highlands, particularly those of Hashid and Bakil, were a constant irritant to Turkish rule in Arabia. Justifying their presence in Yemen as a triumph for Islam, the Ottomans accused the Zaydis of being infidels. Hassan Pasha was appointed governor of Yemen, which enjoyed a period of relative peace from 1585 to 1597. Pupils of al-Mansur al-Qasim suggested that he claim the immamate and fight the Turks. He declined at first but was infuriated by the promotion of the Hanafi school of jurisprudence at the expense of Zaydi Islam. He proclaimed the Imamate in September 1597, which was the same year the Ottoman authorities inaugurated al-Bakiriyya Mosque. By 1608, Imam al-Mansur (the victorious) regained control over the highlands and signed a 10 year truce with the Ottomans. When Imam al-Mansur al-Qasim died in 1620 his son Al-Mu'ayyad Muhammad succeeded him and confirmed the truce with the Ottomans. In 1627, the Ottomans lost Aden and Lahej. 'Abdin Pasha was ordered to suppress the rebels but failed and had to retreat to Mocha. After Al-Mu'ayyad Muhammad expelled the Ottomans from Sana'a in 1628, only Zabid and Mocha remained under Ottoman possession. Al-Mu'ayyad Muhammad captured Zabid in 1634 and allowed the Ottomans to leave Mocha peacefully. The reasons behind Al-Mu'ayyad Muhammad's success were the tribes' possession of firearms and the fact that they were unified behind him.
In 1632, Al-Mu'ayyad Muhammad sent an expeditionary force of 1000 men to conquer Mecca. The army entered the city in triumph and killed its governor. The Ottomans were not ready to lose Mecca after Yemen, so they sent an army from Egypt to fight the Yemenites. Seeing that the Turkish army was too numerous to overcome, the Yemeni army retreated to a valley outside Mecca. Ottoman troops attacked the Yemenis by hiding at the wells that supplied them with water. This plan proceeded successfully, causing the Yemenis over 200 casualties, most from thirst. The tribesmen eventually surrendered and returned to Yemen. Al-Mu'ayyad Muhammad died in 1644. He was succeeded by Al-Mutawakkil Isma'il, another son of al-Mansur al-Qasim, who conquered Yemen in its entirety, from Asir in the north to Dhofar in the east. During his reign and that of his successor, Al-Mahdi Ahmad (1676–1681),the Imamate implemented some of the harshest discriminatory laws (Ar. "ghiyar") against the Jews of Yemen, which culminated in the expulsion of all Jews (Exile of Mawza) to a hot and arid region in the Tihama coastal plain. The " Qasimid "state was the strongest Zaydi state to ever exist.
During that period, Yemen was the sole Coffee producer in the world. The country established diplomatic relations with the Safavid dynasty of Persia, the Ottomans of Hejaz, the Mughal Empire in India and Ethiopia. The Fasilides of Ethiopia sent three diplomatic missions to Yemen, but the relations did not develop into a political alliance as Fasilides had hoped, due to the rise of powerful feudalists in the country. In the first half of the 18th century, the Europeans broke Yemen's monopoly on coffee by smuggling out coffee trees and cultivating them in their own colonies in the East Indies, East Africa, the West Indies and Latin America. The imammate did not follow a cohesive mechanism for succession, and family quarrels and tribal insubordination led to the political decline of the Qasimi dynasty in the 18th century. In 1728 or 1731 the chief representative of Lahej declared himself an independent Sultan in defiance of the Qasimid Dynasty and conquered Aden thus establishing the Sultanate of Lahej. The rising power of the fervently Islamist Wahhabi movement on the Arabian Peninsula cost the Zaidi state its coastal possessions after 1803. The imam was able to regain them temporarily in 1818, but new intervention by the Ottoman viceroy of Egypt in 1833 again wrested the coast from the ruler in Sana'a. After 1835 the imamate changed hands with great frequency and some imams were assassinated. After 1849 the Zaidi polity descended into chaos that lasted for decades.
Great Britain and the Nine Regions.
The British were looking for a coal depot to service their steamers en route to India. It took 700 tons of coal for a round-trip from Suez to Bombay. East India Company officials decided on Aden. The British Empire tried to reach an agreement with the Zaydi imam of Sana'a permitting them a foothold in Mocha; and when unable to secure their position, they extracted a similar agreement from the Sultan of Lahej, enabling them to consolidate a position in Aden. An incident played into British hands when, while passing Aden for trading purposes, one of their sailing ships sank and Arab tribesmen boarded it and plundered its contents. The British India government dispatched a warship under the command of Captain Stafford Bettesworth Haines to demand compensation.
Haines bombarded Aden from his warship in January 1839. The ruler of Lahej, who was in Aden at the time, ordered his guards to defend the port, but they failed in the face of overwhelming military and naval power. The British managed to occupy Aden and agreed to compensate the sultan with an annual payment of 6000 riyals. The British evicted the Sultan of Lahej from Aden and forced him to accept their "protection". In November 1839, 5000 tribesmen tried to retake the town but were repulsed and 200 were killed. The British realized that Aden's prosperity depended on their relations with the neighboring tribes, which required that they rest on a firm and satisfactory basis.
The British government concluded "protection and friendship" treaties with nine tribes surrounding Aden, whereas they would remain independent from British interference in their affairs as long as they do not conclude treaties with foreigners (non-Arab colonial powers). Aden was declared a free zone in 1850. With emigrants from India, East Africa and Southeast Asia, Aden grew into a "world city". in 1850, only 980 Arabs were registered as original inhabitants of the city. The English presence in Aden put them at odds with the Ottomans. The Turks asserted to the British that they held sovereignty over the whole of Arabia, including Yemen as successor of Mohammed and the chief of the universal Caliphate.
Ottoman Return.
The Ottomans were concerned about the British expansion from India to the Red Sea and Arabia. They returned to the Tihama in 1849 after an absence of two centuries. Rivalries and disturbances continued among the Zaydi imams, between them and their deputies, with the ulema, with the heads of tribes, as well as with those who belonged to other sects. Some citizens of Sana'a were desperate to return law and order to Yemen and asked the Ottoman Pasha in Tihama to pacify the country. Yemeni merchants knew that the return of the Ottomans would improve their trade, for the Ottomans would become their customers. An Ottoman expedition force tried to capture Sana'a but was defeated and had to evacuate the highlands. The opening of the Suez Canal in 1869 strengthened the Ottomans' decision to remain in Yemen. In 1872, military forces were dispatched from Constantinople and moved beyond the Ottoman stronghold in the lowlands (Tihama) to conquer Sana'a. By 1873 the Ottomans succeeded in conquering the northern highlands. Sana'a became the administrative capital of Yemen Vilayet.
The Ottomans learned from their previous experience and worked on the disempowerment of local lords in the highland regions. They even attempted to secularize the Yemeni society; Yemenite Jews came to perceive themselves in Yemeni nationalist terms. The Ottomans appeased the tribes by forgiving their rebellious chiefs and appointing them to administrative posts. They introduced a series of reforms to enhance the country's economic welfare. On the other hand, corruption was widespread in the Ottoman administration in Yemen. This stemmed from the fact that only the worst of the officials were appointed because those who could avoid serving in Yemen did so. The Ottomans had reasserted control over the highlands for temporary duration. The so-called "Tanzimat" reforms were considered heretic by the Zaydi tribes. In 1876, the Hashid and Bakil tribes rebelled against the Ottomans, the Turks had to appease them with gifts to end the uprising.
The tribal chiefs were difficult to appease and an endless cycle of violence curbed the Ottoman efforts to pacify the land. Ahmed Izzet Pasha proposed that the Ottoman army should evacuate the highlands and confined itself to Tihama and not to be unnecessarily burdened with continuing military operation against the Zaydi tribes. The hit-and-run tactics of the northern highlands tribesmen wore out the Ottoman military. They resented the Turkish Tanzimat and defied all attempts to impose a central government upon them. The northern tribes united under the leadership of the House of Hamidaddin in 1890. Imam Yahya Hamidaddin led a rebellion against the Turks in 1904, the rebels disrupted the Ottoman ability to govern. The revolts between 1904 and 1911 were especially damaging to the Ottomans, costing them as much as 10,000 soldier and 500,000 pound per year. The Ottomans signed a treaty with imam Yahya Hamidaddin in 1911. Under the treaty, imam Yahya was recognized as an autonomous leader of the Zaydi northern highlands. The Ottomans continued to rule Shafi'i areas in the mid-south until their departure in 1918.
Idrisid Emirate And Mutawakkilite Kingdom of Yemen.
 
Imam Yahya hamid ed-Din al-Mutawakkil was ruling the northern highlands independently from 1911. After the Ottoman departure in 1918 he sought to recapture the lands of his Qasimid ancestors. He dreamed of Greater Yemen stretching from Asir to Dhofar. These schemes brought him into conflict with the de facto rulers in the territories claimed, namely the Idrsids, Ibn Saud and the British government in Aden. The Zaydi imam did not recognize the Anglo-Ottoman border agreement of 1905 on the grounds that it was made between two foreign powers occupying Yemen. The border treaty effectively divided Yemen into "north" and "south." In 1915 the British signed a treaty with the Idrsids guaranteeing their security and independence if they would fight against the Turks. In 1919, Imam Yahya hamid ed-Din moved southward to " liberate " the nine British protectorates. The British responded by moving quickly towards Tihama and occupying al-Hudaydah. Then they handed it over to their Idrisi allies. Imam Yahya attacked the southern protectorates again in 1922. The British bombed Yahya's tribal forces using aircraft to which the tribes had no effective counter.
In 1925, Imam Yahya captured al-Hudaydah from the Idrsids. He continued to follow and attack the Idrsids until Asir fell under the control of the Imam's forces, forcing the Idrisi to request an agreement that would enable them to administer the region in the name of the Imam. Imam Yahya refused the offer on the grounds that the Idrisis were of a Moroccan decent. According to Imam Yahya, the Idrisis, along with the British, were nothing but recent intruders and ought to be driven out of Yemen permanently. In 1927, when Imam Yahya's forces were 50 kilometers away from Aden, Ta'izz and Ibb were bombed by the British for five days, and the Imam had to pull back. Small Bedouin forces mainly from the Madh'hij confederation of Marib, attacked Shabwah but were bombed by the British and had to retreat.
The Italian Empire was the first to recognize Imam Yahya as the "King of Yemen" in 1926. This created a great deal of anxiety for the British, who interpreted it as recognition of Imam Yahya's claim to sovereignty over Greater Yemen which included the Aden protectorate and Asir. The idrisis turned to Ibn Saud seeking his protection from Yahya hamid ed-Din. In 1932, however, the Idrisis broke their accord with Ibn Saud and went back to Imam Yahya seeking help against Ibn Saud himself, who had begun liquidating their authority and expressed his desire to annex those territories into his own Saudi domain. Imam Yahya demanded the return of all Idrisi dominion. That same year, a group of Hejazi liberals fled to Yemen and plotted to expel Ibn Saud from the former Hashemite Kingdom of Hejaz which was conquered by the Saudis seven years earlier. Ibn Saud appealed to Britain for aid. The British government sent arms and aeroplanes . The British were anxious that Ibn Saud's financial difficulties may encourage the Italian Empire to bail him out. Ibn Saud suppressed the Asiri rebellion in 1933, after which the Idrsids fled to Sana'a. Negotiations between the Imam Yahya Hamid ed-Din and Ibn Saud proved fruitless. After a military confrontation, Ibn Saud announced a ceasefire in May 1934. Imam Yahya agreed to release Saudi hostages and the surrender of the Idrisis to Saudi custody. Imam Yahya ceded the three provinces of Najran, Asir and Jazan for 20 years. and signed another treaty with the British government in 1934. The Imam recognized the British sovereignty over Aden protectorate for 40 years. Yahya submitted to the Saudi and British demands out of fear for Hudaydah. According to Bernard Reich, Professor of Political Science and International Affairs at George Washington University, Yahya could have done better by reorganizing the Zaydi tribes of the northern highlands as his ancestors did against the Turks and British intruders and turn the lands they captured into another graveyard.
Although the imamate lost Asir, it was able to put down rebel tribes in the north using Iraq-trained Yemani troops. With the country, now established within clearly defined territory, finally pacified, the urban nationalists began to assert themselves. These nationalists had long practiced non-Zaidi traditions (especially Shafi'i), and were centered in the coastal province of Tahama, the city of Ta'izz and the British-occupied Aden. Many had been students in Cairo and had acquired connections with the Muslim Brotherhood and Algerian nationalists. Muslim Brotherhood operatives in Yemen aligned themselves with the urban opposition and supported Zaidi prince Abdullah bin Ahmad al-Wazir, who joined those actively seeking to overthrow Imam Yahya. On February 17, 1948 the opposition revolted in Sana'a and killed Imam Yahya. Crown prince Ahmad was able to rally northern tribes and retake the capital, quelling the revolt after a brief siege on March 12, 1948.
Imam Ahmad reversed the isolationist policies of his father and opened Yemen's economy and society to the outside world. It went as the theocratic and largely medieval Imamate which became the first Arab state to accept Soviet aid. Beginning in 1955 Yemen entered into various treaties of friendship and from 1957 began receiving large amounts of Soviet arms as well as Soviet and Chinese military advisers. When the imam went abroad owing to illness, crown prince Muhammad al-Badr led a pro-Soviet party and communist activity increased. When the Imam returned in 1959, brutal repression ensued and communists were expelled.
In April 1956 Yemen joined a defensive pact with Syria and Egypt, and in February 1958 it federated with the United Arab Repulic. The latter move was conceived as a defensive measure against republican agitation, which urban nationalists still engaged in from British-occupied Aden. So long as Yemen was federated with the UAR, republicans would be deprived any assistance from Egyptian President Nasser. Although the federation only lasted for three years, crown prince al-Badr continued to portray himself as an Arab patriot, often railing against "reactionary Arab monarchs."
Two states.
Arab nationalism made an impact in some circles who opposed the lack of modernization efforts in the Mutawakkilite monarchy. This became apparent when Imam Ahmad bin Yahya died in 1962. He was succeeded by his son, but army officers attempted to seize power, sparking the North Yemen Civil War. The Hamidaddin royalists were supported by Saudi Arabia, Britain, and Jordan (mostly with weapons and financial aid, but also with small military forces), whilst the republicans were backed by Egypt. Egypt provided the republicans with weapons and financial assistance but also sent a large military force to participate in the fighting. Israel covertly supplied weapons to the royalists in order to keep the Egyptian military busy in Yemen and make Nasser less likely to initiate a conflict in Sinai.
After six years of civil war, the republicans were victorious (February 1968) and formed the Yemen Arab Republic.
The revolution in the north coincided with the Aden Emergency, which hastened the end of British rule in the south. On 30 November 1967, the state of South Yemen was formed, comprising Aden and the former Protectorate of South Arabia. This socialist state was later officially known as the People's Democratic Republic of Yemen and a programme of nationalisation was begun.
Relations between the two Yemeni states fluctuated between peaceful and hostile. The South was supported by the Eastern bloc. The North, however, wasn't able to get the same connections. In 1972, the two states fought a war. The war was resolved with a ceasefire and negotiations brokered by the Arab League, where it was declared that unification would eventually occur. In 1978, Ali Abdallah Saleh was named as president of the Yemen Arab Republic.
After the war, the North complained about the South's help from foreign countries. This included Saudi Arabia.
1979 – Fresh fighting between YAR and PDRY. Renewed efforts to unite the two states.
1986 – Thousands die in south in political rivalry. President Ali Nasser Muhammad flees the country and is later sentenced to death for treason. New government formed.
1990 May – "Unified Republic of Yemen proclaimed, with Saleh as president."
Unification.
In 1990, the two governments reached a full agreement on the joint governing of Yemen, and the countries were merged on 22 May 1990 with Saleh as President. The President of South Yemen, Ali Salim al-Beidh, became Vice-President. A unified parliament was formed and a unity constitution was agreed upon. In the 1993 parliamentary election, the first held after unification, the General People's Congress won 122 of 301 seats.:309
After the invasion of Kuwait crisis in 1990, Yemen's President opposed military intervention from non-Arab states. As a member of the United Nations Security Council for 1990 and 1991, Yemen abstained on a number of UNSC resolutions concerning Iraq and Kuwait and voted against the "use of force resolution". The vote outraged the U.S. Saudi Arabia expelled 800,000 Yemenis in 1990 and 1991 to punish Yemen for its opposition to the war.
Following food riots in major towns in 1992, a new coalition government made up of the ruling parties from both the former Yemeni states was formed in 1993. However, Vice-President al-Beidh withdrew to Aden in August 1993 and said he would not return to the government until his grievances were addressed. These included northern violence against his Yemeni Socialist Party, as well as the economic marginalization of the south. Negotiations to end the political deadlock dragged on into 1994. The government of Prime Minister Haydar Abu Bakr Al-Attas became ineffective due to political infighting
An accord between northern and southern leaders was signed in Amman, Jordan on 20 February 1994, but this could not stop the civil war. During these tensions, both the northern and southern armies (which had never integrated) gathered on their respective frontiers. The May – July 1994 civil war in Yemen resulted in the defeat of the southern armed forces and the flight into exile of many Yemeni Socialist Party leaders and other southern secessionists. Saudi Arabia actively aided the south during the 1994 civil war.
Saleh became Yemen's first directly elected president in the 1999 presidential election, winning 96.2% of the vote.:310 The only other candidate, Najeeb Qahtan Al-Sha'abi, was the son of Qahtan Muhammad al-Shaabi, a former President of South Yemen. Though a member of Saleh's General People's Congress (GPC) party, Najeeb ran as an independent.
In October 2000, seventeen U.S. personnel died after a suicide attack on the U.S. naval vessel "USS Cole" in Aden which was subsequently blamed on al-Qaeda. After the September 11 attacks on the United States, President Saleh assured U.S. President George W. Bush that Yemen was a partner in his War on Terror. In 2001, there was violence surrounding a referendum which apparently supported extending Saleh's rule and powers.
The Shia insurgency in Yemen began in June 2004 when dissident cleric Hussein Badreddin al-Houthi, head of the Zaidi Shia sect, launched an uprising against the Yemeni government. The Yemeni government alleged that the Houthis were seeking to overthrow it and to implement Shī'a religious law. The rebels counter that they are "defending their community against discrimination" and government aggression.
In 2005, at least 36 people were killed in clashes across the country between police and protesters over rising fuel prices.
In the 2006 presidential election, held on 20 September, Saleh won with 77.2% of the vote. His main rival, Faisal bin Shamlan, received 21.8%. Saleh was sworn in for another term on 27 September.
A suicide bomber killed eight Spanish tourists and two Yemenis in the province of Marib in July 2007. There was a series of bomb attacks on police, official, diplomatic, foreign business and tourism targets in 2008. Car bombings outside the U.S. embassy in Sana'a killed 18 people, including six of the assailants in September 2008. In 2008, an opposition rally in Sana'a demanding electoral reform was met with police gunfire.
Al Qaeda.
In January 2009, the Saudi and Yemeni al-Qaeda branches merged to form Al-Qaeda in the Arabian Peninsula (AQAP). Al Qaeda in the Arabian Peninsula is based in Yemen, and many of its members were Saudi nationals who had been released from Guantanamo Bay. Saleh released 176 al-Qaeda suspects on condition of good behaviour, but terrorist activities continued.
The Yemeni army launched a fresh offensive against the Shia insurgents in 2009, assisted by Saudi forces. Tens of thousands of people were displaced by the fighting. A new ceasefire was agreed upon in February 2010. However, by the end of the year, Yemen claimed that 3,000 soldiers had been killed in renewed fighting. The Shia rebels accused Saudi Arabia of providing support to salafi groups to suppress Zaidism in Yemen. Saleh's government used Al-Qaeda in its wars against the insurgent Houthis clan.
Some news reports have suggested that, on orders from U.S. President Barack Obama, U.S. warplanes fired cruise missiles at what officials in Washington claimed were Al Qaeda training camps in the provinces of Sana'a and Abyan on 17 December 2009. Instead of hitting Al-Qaeda operatives, it hit a village killing 55 civilians. Officials in Yemen said that the attacks claimed the lives of more than 60 civilians, 28 of them children. Another airstrike was carried out on 24 December.
The U.S. launched a series of drone attacks in Yemen to curb a perceived growing terror threat due to political chaos in Yemen. Since December 2009, U.S. strikes in Yemen have been carried out by the U.S. military with intelligence support from CIA. The drone strikes are protested by human-rights groups who say they kill innocent civilians and that the U.S. military and CIA drone strikes lack sufficient congressional oversight, including the choice of human targets suspected of being threats to America. Controversy over U.S. policy for drone attacks mushroomed after a September 2011 drone strike in Yemen killed Anwar al-Awlaki and Samir Khan, both U.S. citizens. Another drone strike in October 2011 killed Anwar's teenage son, Abdulrahman al-Awlaki.
In 2010 the Obama administration policy allowed targeting of people whose names are not known. The U.S. government increased military aid to $140 million in 2010. U.S. drone strikes continued after the ousting of President Saleh.
Government instability 2011-present.
The Yemeni Crisis began with the 2011–12 revolution against President Ali Abdullah Saleh, who had led Yemen for more than two decades. After Saleh left office in early 2012 as part of a mediated agreement between the Yemeni government and opposition groups, the government led by Saleh's former vice president, Abd Rabbuh Mansur Hadi, struggled to unite the fractious political landscape of the country and fend off threats both from Al Qaeda in the Arabian Peninsula and Houthi militants that had been waging a protracted insurgency in the north for years. In 2014, Houthi fighters swept into the capital of Sana'a and forced Hadi to negotiate a "unity government" with other political factions. The rebels continued to apply pressure on the weakened government until, after his presidential palace and private residence came under attack from the militant group, Hadi resigned along with his ministers in January 2015. The following month, the Houthis declared themselves in control of the government, dissolving Parliament and installing an interim Revolutionary Committee led by Mohammed Ali al-Houthi, a cousin of Houthi leader Abdul-Malik al-Houthi. However, Hadi escaped to Aden, where he declared he remains Yemen's legitimate president, proclaimed the country's temporary capital, and called on loyal government officials and members of the military to rally to him.
2011 revolution.
The 2011 Yemeni revolution followed other Arab Spring mass protests in early 2011. The uprising was initially against unemployment, economic conditions, and corruption, as well as against the government's proposals to modify the constitution of Yemen so that Saleh's son could inherit the presidency.
In March 2011, police snipers opened fire on the pro-democracy camp in Sana'a, killing more than 50 people. In May, dozens were killed in clashes between troops and tribal fighters in Sana'a. By this point, Saleh began to lose international support. In October 2011, Yemeni human rights activist Tawakul Karman won the Nobel Peace Prize and the UN Security Council condemned the violence and called for a transfer of power. On 23 November 2011, Saleh flew to Riyadh, in neighbouring Saudi Arabia, to sign the Gulf Co-operation Council plan for political transition, which he had previously spurned. Upon signing the document, he agreed to legally transfer the office and powers of the presidency to his deputy, Vice President Abd Rabbuh Mansur Hadi.
Hadi took office for a two-year term upon winning the uncontested presidential elections in February 2012, in which he was the only candidate standing. A unity government – including a prime minister from the opposition – was formed. Al-Hadi will oversee the drafting of a new constitution, followed by parliamentary and presidential elections in 2014. 
2012.
Saleh returned in February 2012. In the face of objections from thousands of street protesters, parliament granted him full immunity from prosecution. Saleh's son, General Ahmed Ali Abdullah Saleh continues to exercise a strong hold on sections of the military and security forces.
AQAP claimed responsibility for the February 2012 suicide attack on the presidential palace which killed 26 Republican Guards on the day that President Hadi was sworn in. AQAP was also behind the suicide bombing which killed 96 soldiers in Sana'a three months later. In September 2012, a car bomb attack in Sana'a killed 11 people, a day after a local al-Qaeda leader Said al-Shihri was reported killed in the south.
By 2012, there has been a "small contingent of U.S. special-operations troops" – in addition to CIA and "unofficially acknowledged" U.S. military presence – in response to increasing terror attacks by AQAP on Yemeni citizens. Many analysts have pointed out the former Yemeni government role in cultivating terrorist activity in the country. Following the election of new president Abd Rabbuh Mansur Hadi, the Yemeni military was able push Ansar al-Sharia back and recapture the Shabwah Governorate.

</doc>
<doc id="34246" url="http://en.wikipedia.org/wiki?curid=34246" title="Geography of Yemen">
Geography of Yemen

Yemen is located in Southwest Asia at the southern tip of the Arabian Peninsula between Oman and Saudi Arabia. It is situated at the entrance to the Bab-el-Mandeb Strait, which links the Red Sea to the Indian Ocean (via the Gulf of Aden) and is one of the most active and strategic shipping lanes in the world. Yemen has an area of 527970 km2, including the islands of Perim at the southern end of the Red Sea and Socotra at the entrance to the Gulf of Aden. Yemen's land boundaries total 1746 km. Yemen borders Saudi Arabia to the north (1458 km) and Oman to the northeast (288 km).
Topography.
Yemen occupies the southern end of the Arabian Plate.
The country's mountainous interior is surrounded by narrow coastal plains to the west, south, and east and by upland desert to the north along the border with Saudi Arabia. The Tihamah is a nearly 419 km long, semidesert coastal plain that runs along the Red Sea and is part of the Arabian Peninsula coastal fog desert ecoregion.
The interior mountains have elevations ranging from a few hundred meters to the country’s highest point, Jabal an Nabi Shuayb, which is 3666 m above sea level. The mountains are young, jagged peaks that are known to rise from an elevation of a few hundred meters to well over 3,000. The mountains can be separated into a western and central highland. The western highlands have peaks reaching around 3,000 meters, with relatively fertile soil and sufficient and plentiful rainfall. The central highlands is more like a plateau of about 2,000–3,200 meters, with rolling hills, small knolls, and some very prominent peaks, but is still relatively more elevated. Less rainfall can be seen in this region, but the summer months give enough to sustain crops.
The highland regions are interspersed with wadis, or river valleys, that are dry in the winter months. (Yemen has no permanent rivers.) Most notable is the Wadi Hadhramaut in eastern Yemen, the upper portions of which contain alluvial soil and floodwaters and the lower portion of which is barren and largely uninhabited. Both the eastern plateau region and the desert in the north are hot and dry with little vegetation.
In the northeastern Empty Quarter, sands highlight the region, being the largest expanse of sand in the world. It receives little to no rain for extensive periods of time. Little vegetation grows here either.
The central highlands are drier than the western highlands because of rain-shadow influences, but still receives sufficient rain in wet years for extensive cropping. Its diurnal temperature variations are among the highest in the world: ranges from 30 °C in the day to 0 °C at night are normal. Water storage allows for irrigation and the growing of wheat and barley while the western highlands are famous for sorghum, coffee, and some tropical fruits like bananas and mangos.
Elevation.
Yemen is a continuously elevated country, with only the coastal plains being the lowest-lying areas. The range of elevation is from sea level to 3666 m. Jagged peaks and plateaus cover most of Yemen, and the average elevation in the country is about 2000 m. Among the countries in the Arab world, it is the one with the second highest high point, being the 3666 m high Jabal an Nabi Shu'ayb, after Morocco's 4167 m high Jbel Toubkal. The Yemenis used the elevation of their homeland to stay isolated for thousands of years with foreign trade conducted only when the Yemenis wished to go to the coastal areas.
Climate.
Temperatures are generally very high in Yemen, particularly in the coastal regions. Rainfall is limited, with variations based on elevation. The highlands enjoy a temperate, rainy summer with an average high temperature of 21 °C and a cool, moderately dry winter with temperatures occasionally dipping below 0 °C. The climate of the Tihamah (western coastal plain) is tropical; temperatures occasionally exceed 54 °C, and the humidity ranges from 50 to 70 percent. Rainfall, which comes in irregular heavy torrents, averages 130 mm annually. In Aden the average temperature is 25 °C in January and 32 °C in June, but with highs often exceeding 37 °C. Average annual rainfall is 127 mm. The highest mountainous areas of southern Yemen receive from 520 to of rain a year. Some areas of the western highlands, most notably Ibb and Ta'izz, receive from about 1000 – of rain each year. The capital, Sana'a, receives around 300 mm a year, it is not uncommon for the northern and eastern sections of the country to receive no rain for five years or more. The Wadi Hadhramaut in the eastern part of Yemen is arid and hot, and the humidity ranges from 35 percent in June to 64 percent in January. Yemen is dry in the east and humid in the west.
Coastline and maritime claims.
Yemen has 1906 km of coastline along the Arabian Sea, the Gulf of Aden, and the Red Sea. Yemen claims a territorial sea of 12 nmi, a contiguous zone of 24 nmi, an exclusive economic zone of 200 nmi, and a continental shelf of 200 nmi or to the edge of the continental margin.
Natural resources.
Yemen's principal natural resources are oil and natural gas as well as agriculturally productive land in the west. Other natural resources include fish and seafood, rock salt, marble, and minor deposits of coal, gold, lead, nickel, and copper.
Land use.
Only 2.2 percent of Yemen is considered to be arable land, and less than 0.6 percent of the land is planted with permanent crops. About 6801 km2 of the land is irrigated. According to the United Nations, Yemen has 19550 km2 of forest and other wooded land, which constitutes almost 4 percent of total land area.
Environmental factors.
Yemen is subject to sandstorms and dust storms, resulting in soil erosion and crop damage. The country has very limited natural freshwater and consequently inadequate supplies of potable water. Desertification (land degradation caused by aridity) and overgrazing are also problems. It is a party to international Biodiversity, Climate Change, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Nuclear Test Ban, Ozone Layer Protection agreements.
Disputed territory.
A long-standing dispute between Saudi Arabia and Yemen was resolved in June 2000 with the signing of the Treaty of Jeddah. This agreement provides coordinates for use in delineating the land and maritime border, including the section in the eastern desert region of Yemen that potentially contains significant amounts of oil. Friction between the two countries in recent years over security of the borders appears to have been alleviated by the establishment of joint border patrols. Following years of dispute between Yemen and Eritrea over ownership of the Hanish Islands and fishing rights in the Red Sea, in 1999 an international arbitration panel awarded sovereignty of the islands to Yemen. Relations between the two countries remain strained, and Yemen continues to protest Eritrean fishing in the disputed territory.

</doc>
<doc id="34247" url="http://en.wikipedia.org/wiki?curid=34247" title="Demographics of Yemen">
Demographics of Yemen

This article is about the demographic features of the population of Yemen, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.
Population.
The population of Yemen was about 24 million according to June 2011 estimates, with 46% of the population being under 15 years old and 2.7% above 65 years. In 1950, it was 4.3 million. By 2050, the population is estimated to increase to about 60 million.
Yemenis are mainly of Arab origin. When the former states of North and South Yemen were established, most resident minority groups departed. Yemen is still a largely tribal society. In the northern, mountainous parts of the country, there are some 400 Zaidi tribes. There are also hereditary caste groups in urban areas such as Al-Akhdam.
According to the USCRI, Yemen hosted a population of refugees and asylum seekers numbering approximately 124,600 in 2007. Refugees and asylum seekers living in Yemen were predominantly from Iraq, Somalia, Ethiopia, and Syria.
Vital statistics.
In 2007 the birthrate and death rate were estimated to be 42.7 per 1,000 and 8.1 per 1,000, respectively (CIA est.). The infant mortality rate was almost 58 deaths per 1,000 live births. The rate was estimated to be higher for males than for females—more than 62 male deaths per 1,000 live births, as compared with about 53 female deaths per 1,000 live births. Despite an increase of 14 years in the last decade, life expectancy at birth in Yemen has remained low compared with other developing countries—60.6 years for males and 64.5 years for females, or 62.5 years overall. The country’s fertility rate was almost 6.5 children per woman in 2007 free.
Fertility and births.
Total Fertility Rate (TFR) and Crude Birth Rate (CBR):
Ethnic groups.
Predominantly Arab; but also Afro-Arab, South Asians, and Europeans.
Languages.
Arabic is the official language; English is also used in official and business circles. In the Mahra area (the extreme east), several non-Arabic languages (including Mehri) are spoken. When the former states of north and south Yemen were established, most resident minority groups departed.
Religions.
Religion in Yemen consists primarily of two principal Islamic religious groups: 53% of the Muslim population is Sunni and over 45% is Shia, according to the UNHCR. Other put the numbers of Shias at 30%. Sunnis primarily adhere to the Shafi'i school, and there are also significant followers of the Maliki and Hanbali schools. Shias are primarily Zaidi and also have significant minorities of Twelver and Ismaili Shias.
Zaidis are generally found in the north and northwest and Shafi'is in the south and southeast. There are also approximately 3,000 Christians and 400 Jews.
Literacy.
According to composite data compiled by the World Bank, the adult literacy rate for Yemen in 2005 was 35 percent for females and 73 percent for males. The overall literacy rate for the population age 15 and older was 54 percent. By comparison, low-income countries in the aggregate average an adult literacy rate of almost 62 percent.
In 2006 only 75 percent of Yemen’s school-age population was enrolled in primary school; enrollment was even lower for the female population—only 65 percent. In that same year, only 37 percent of the school-age population was enrolled in secondary school, including only 26 percent of eligible females.
Diaspora.
The Yemeni diaspora is largely concentrated in the United Kingdom, where between 70,000 and 80,000 Yemenis live. Over 20,000 Yemenis reside in the United States, and an additional 2,812 live in Italy. Other Yemenis also reside in Saudi Arabia, the United Arab Emirates, Qatar and Bahrain, as well as Indonesia, Malaysia, Brunei, and the former USSR. A smaller number of modern-day Pakistanis are of Yemeni descent, their original ancestors having left Yemen for the Indian subcontinent and Southeast Asia over four centuries ago. 350,000 Yemenite Jews live in Israel.
Demographic statistics from the CIA World Factbook.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population.
Source: CIA Factbooks 2000–2010.
18.78
18.3
Age structure.
estimates for 2010:
HIV/AIDS – deaths.
N/A

</doc>
<doc id="34248" url="http://en.wikipedia.org/wiki?curid=34248" title="Politics of Yemen">
Politics of Yemen

Politics of Yemen is in an uncertain state due to a 2014–15 coup d'état. An armed group known as the Houthis or Ansar Allah seized control of the Yemeni government and announced it would dissolve parliament, as well as install a "presidential council", "transitional national council", and "supreme revolutionary council" to govern the country for an interim period. However, the deposed president, Abd Rabbuh Mansur Hadi, has declared he is still in office and is working to establish a rival government in Aden.
Prior to the coup, Yemen's politics nominally took place in a framework of a presidential representative democratic republic, where the President of Yemen was the head of state, while the Prime Minister of Yemen (who is appointed by the President) was the head of government. Although it was notionally a multi-party system, in reality it was completely dominated by one party, the General People's Congress, and has been since unification. Executive power was exercised by the government. Legislative power was vested in both the government and parliament. The Judiciary was theoretically independent but in reality it was prone to interference from the executive branch.
Yemen was a republic with a bicameral legislature. Under the constitution, an elected president, an elected 301-seat House of Representatives, and an appointed 111-member Shura Council share power. The president is head of state, and the prime minister is head of government. The constitution provides that the president be elected by popular vote from at least two candidates endorsed by Parliament; the prime minister is appointed by the president. The presidential term of office is 7 years, and the parliamentary term of elected office is 6 years. Suffrage is universal over 18.
Political background.
For hundreds of years Yemen was ruled by imams who had absolute powers on the political process in the country. The imams of Yemen and later the Kings of Yemen were religiously consecrated leaders belonging to the Zaidiyyah branch of Shia Islam. They established a blend of religious and secular rule in parts of Yemen from 897. Their imamate endured under varying circumstances until the republican revolution in 1962. Zaidiyyah theology differed from Ismailis or Twelver Shi'ites by stressing the presence of an active and visible imam as leader. This came to an end with the assassination of Imam Yehia. His son, Imam Badr succeeded him but the political situation deteriorated with the beginning of the North Yemen Civil War in 1962 with the overthrow of Imam Badr and the setting of a new, Republican regime.
While in the North, during the civil war, the pro-monarch and pro-republican forces fought for power, the South of Yemen was under British control. During the 1960s, the British sought to incorporate all of the Aden Protectorate territories into the Federation. On 18 January 1963, the Colony of Aden was incorporated against the wishes of much of the city's populace as the State of Aden and the Federation was renamed the Federation of South Arabia. Several more states subsequently joined the Federation and the remaining states that declined to join, mainly in Hadhramaut, formed the Protectorate of South Arabia. In 1963 fighting between Egyptian forces and British-led Saudi-financed guerrillas in the Yemen Arab Republic spread to South Arabia with the formation of the National Liberation Front (NLF), who hoped to force the British out of South Arabia. Hostilities started with a grenade attack by the NLF against the British High Commissioner on 10 December 1963, killing one person and injuring fifty, and a state of emergency was declared, becoming known as the Aden Emergency. In 1964, the new British government under Harold Wilson announced their intention to hand over power to the Federation of South Arabia in 1968, but that the British military would remain. In 1964, there were around 280 guerrilla attacks and over 500 in 1965. In 1966 the British Government announced that all British forces would be withdrawn at independence. In response, the security situation deteriorated with the creation of the socialist Front for the Liberation of Occupied South Yemen (FLOSY) which started to attack the NLF in a bid for power, as well as attacking the British. With the British being defeated and driven from Aden by the end of November 1967, earlier than had been planned by British Prime Minister Harold Wilson and without an agreement on the succeeding governance. Their enemies, the NLF, managed to seize power, with Aden itself under NLF control. The Royal Marines, who had been the first British troops to occupy Aden in 1839, were the last to leave. The Federation of South Arabia collapsed and Southern Yemen became independent as the People's Republic of South Yemen.
Following this Yemen suffered from a highly fractured political landscape, which is the legacy of the regime of President Ali Abd Allah Saleh, who came to power in 1978 and formally resigned his office in February 2012.
Reunification.
The Republic of Yemen (ROY) was declared on 22 May 1990 with Saleh becoming President and al-Baidh Vice President. For the first time in centuries, much of Greater Yemen was politically united. A 30-month transitional period for completing the unification of the two political and economic systems was set. A presidential council was jointly elected by the 26-member YAR advisory council and the 17-member PDRY presidium. The presidential council appointed a Prime Minister, who formed a Cabinet. There was also a 301-seat provisional unified parliament, consisting of 159 members from the north, 111 members from the south, and 31 independent members appointed by the chairman of the council.
A unity constitution was agreed upon in May 1990 and ratified by the populace in May 1991. It affirmed Yemen's commitment to free elections, a multiparty political system, the right to own private property, equality under the law, and respect of basic human rights. Parliamentary elections were held on 27 April 1993. International groups assisted in the organization of the elections and observed actual balloting. The resulting Parliament included 143 GPC, 69 YSP, 63 Islaah (Yemeni grouping for reform, a party composed of various tribal and religious groups), six Baathis, three Nasserists, two Al Haq, and 15 independents. The head of Islaah, Paramount Hashid Sheik Abdallah Bin Husayn Al-Ahmar, is the speaker of Parliament.
In late 1991 through early 1992, deteriorating economic conditions led to significant domestic unrest, including several riots. Legislative elections were nonetheless held in early 1993, and in May the two former ruling parties, the GPC and the YSP, merged to create a single political party with an overall majority in the new House of Representatives. In August Vice President al Baydh exiled himself voluntarily to Aden, and the country’s general security situation deteriorated as political rivals settled scores and tribal elements took advantage of the widespread unrest. In January 1994, representatives of the main political parties signed a document of pledge and accord in Amman, Jordan, that was designed to resolve the ongoing crisis. Despite this, clashes intensified until civil war broke out in early May 1994.
Yemeni uprising.
The 2011 Yemeni protests followed the initial stages of the Arab Spring and began simultaneously with the Egyptian Revolution. The protests were initially against unemployment, economic conditions and corruption, as well as against the government's proposals to modify the constitution of Yemen. The protestors' demands then escalated to calls for President Ali Abdullah Saleh to resign.
The situation however quickly deteriorated into a widescale uprising, with various insurgency campaigns consolidating into an armed tribal struggles, both between the armed opposition and terror groups vs. the government and among themselves. Eventually Saudi-brokered agreement on Saleh's resignation and 2012 Presidential election saw the installation of Abd Rabbuh Mansur Hadi as an interim President. Hadi has been presiding over political reform and national reconciliation and was supposed to serve only two years in the post. On November 2013 U.N. envoy Jamal Benomar told The Associated Press Hadi will remain president after February 2014 because the transition is not likely to be completed earlier due to "obstruction" from former regime loyalists.
Houthi insurgency.
In northern Yemen, where a large Shi’a Zaydi population lives, Saleh's regime has for decades alienated this community through discriminatory religious and political policies. Saleh, with the help of some elements in Saudi Arabia, had promoted strongly anti-Zaydi groups of Salafi Muslims in this region. Feeling beleaguered and marginalized, the Zaydis organized themselves politically in the early 2000s under the aegis of a family of religious scholars called the Houthis. They began by criticizing Saleh’s pro-U.S. policies, which led to armed confrontation and a series of wars with the Yemeni army. This ultimately dragged the Saudi Arabian military into the fray, leading to considerable property destruction and a large refugee problem. In 2011, as Saleh's power waned in the provinces as a result of the uprising against him, the Houthis took control over large areas of the north, but still remain outside the political framework of government.
Executive branch.
Under the Constitution, the President is elected by direct, popular vote for a seven-year term. The vice-president, prime minister and deputy prime ministers are appointed by the President. The Council of Ministers is appointed by the President on the advice of the prime minister.
Legislative branch.
The Assembly of Representatives ("Majlis al-Nuwaab") has 301 members, elected for a six-year term in single-seat constituencies. In May 1997, the president created a Consultative Council, sometimes referred to as the upper house of Parliament; its 59 members are all appointed by the president. The president of the Consultative Council was Abdul Aziz Abdul Ghani prior to his death in August 2011.
Political parties and elections.
In April 2003 parliamentary elections, the General People's Congress (GPC) maintained an absolute majority. International observers described the elections as "another significant step forward on Yemen’s path toward democracy; however, sustained and forceful efforts must be undertaken to remedy critical flaws in the country’s election and political processes." There were some problems with underage voting, confiscation of ballot boxes, voter intimidation, and election-related violence; moreover, the political opposition in Yemen has little access to the media, since most outlets are owned or otherwise controlled by the government.
The 2006 elections were described in positive wording, and the elections were monitored by a number of international observers. The EU's Election Observation Mission to Yemen has published this final report on the elections: Yemeni media reported on the 22.01.2007 that the opposition coalition JMP has set up a Shadow government "to play an effective role in the political, economic and social life". The ruling party GPC called upon the opposition to "acquaint themselves with constitutional systems before starting to talk every now and then about...rosy dreams and illusions".
Judicial branch.
The constitution calls for an independent judiciary. The former northern and southern legal codes have been unified. The legal system includes separate commercial courts and a Supreme Court based in Sanaá. The Quran is the basis for all laws, and no law may contradict it. Indeed many court cases are debated by the religious basis of the laws i.e. by interpretations of the Quran. For this reason, many judges are religious scholars as well as legal authorities.
Administrative divisions.
Yemen is divided into 20 governorates ("muhafazat", singular - "muhafazah") and the capital city of Sana'a. The governorates are Abyan, 'Adan, Amran, Al Asimah, Al Bayda', Al Dhale'e, Al Hudaydah, Al Jawf, Al Mahrah, Al Mahwit, Dhamar, Hadhramawt, Hajjah, Ibb, Lahij, Ma'rib, Raymah, Sa'dah, Shabwah ('Ataq) and Ta'izz.
Provincial and local government.
Formal government authority is centralized in the capital city of Sanaa. Yemen’s Local Authority Law decentralized authority by establishing locally elected district and governorate councils (last elected in September 2006), formerly headed by government-appointed governors. After the September 2006 local and governorate council elections, President Salih announced various measures that would enable future governors and directors of the councils to be directly elected. In May 2008, governors were elected for the first time. However, because the ruling party, the General People’s Congress (GPC), continues to dominate the local and governorate councils, the May 2008 elections retained this party’s executive authority over the governorates. In rural Yemen, direct state control is weak, with tribal confederations acting as autonomous sub-states.

</doc>
<doc id="34249" url="http://en.wikipedia.org/wiki?curid=34249" title="Economy of Yemen">
Economy of Yemen

At the time of unification, South Yemen and North Yemen had vastly different but equally struggling underdeveloped economic systems. Since unification, the economy has been forced to sustain the consequences of Yemen's support for Iraq during the 1990–91 Persian Gulf War: Saudi Arabia expelled almost 1 million Yemeni workers, and both Saudi Arabia and Kuwait significantly reduced economic aid to Yemen. The 1994 civil war further drained Yemen's economy. As a consequence, for the past 10 years Yemen has relied heavily on aid from multilateral agencies to sustain its economy. In return, it has pledged to implement significant economic reforms. In 1997 the International Monetary Fund (IMF) approved two programs to increase Yemen's credit significantly: the enhanced structural adjustment facility (now known as the poverty reduction and growth facility, or PRGF) and the extended funding facility (EFF). In the ensuing years, Yemen's government attempted to implement recommended reforms—reducing the civil service payroll, eliminating diesel and other subsidies, lowering defense spending, introducing a general sales tax, and privatizing state-run industries. However, limited progress led the IMF to suspend funding between 1999 and 2001.
In late 2005, the World Bank, which had extended Yemen a four-year US$2.3 billion economic support package in October 2002 together with other bilateral and multilateral lenders, announced that as a consequence of Yemen's failure to implement significant reforms it would reduce financial aid by one-third over the period July 2005 through July 2008. A key component of the US$2.3 billion package—US$300 million in concessional financing—has been withheld pending renewal of Yemen's PRGF with the IMF, which is currently under negotiation. However, in May 2006 the World Bank adopted an assistance strategy for Yemen under which it will provide approximately US$400 million in International Development Association (IDA) credits over the period FY 2006 to FY 2009. In November 2006, at a meeting of Yemen's development partners, a total of US$4.7 billion in grants and concessional loans was pledged for the period 2007–10. At present, despite possessing significant oil and gas resources and a considerable amount of agriculturally productive land, Yemen remains one of the poorest of the world's low-income countries; more than 45 percent of the population lives in poverty. The influx of an average 1,000 Somali refugees per month into Yemen looking for work is an added drain on the economy, which already must cope with a 20 to 40 percent rate of unemployment. Yemen remains under significant pressure to implement economic reforms or face the loss of badly needed international financial support.
At unification, both the Yemen Arab Republic and the People's Democratic Republic of Yemen were struggling underdeveloped economies. In the north, disruptions of civil war (1962–1970) and frequent periods of drought had dealt severe blows to a previously prosperous agricultural sector. Coffee production, formerly the north's main export and principal form of foreign exchange, declined as the cultivation of khat increased. Low domestic industrial output and a lack of raw materials made the YAR dependent on a wide variety of imports.
Macro-economic trend.
This is a chart of trend of gross domestic product of Yemen (since reunification) at market prices by the International Monetary Fund with figures in millions of Yemeni Rials.
For purchasing power parity comparisons, the US Dollar is exchanged at 150.11 Yemeni Rials only. Mean wages were $1.06 per manhour in 2009.
Remittances from Yemenis working abroad and foreign aid paid for perennial trade deficits. Substantial Yemeni communities exist in many countries of the world, including Yemen's immediate neighbors on the Arabian Peninsula, Indonesia, India, East Africa, the United Kingdom, and the United States. Beginning in the mid-1950s, the Soviet Union and People's Republic of China provided large-scale assistance to the YAR. This aid included funding of substantial construction projects, scholarships, and considerable military assistance.
Integration issues.
In the south, pre-independence economic activity was overwhelmingly concentrated in the port city of Aden. The seaborne transit trade, which the port relied upon, collapsed with the closure of the Suez Canal and Britain's withdrawal from Aden in 1967. Only extensive Soviet aid, remittances from south Yemenis working abroad, and revenues from the Aden refinery (built in the 1950s) kept the PDRY's centrally planned Marxist economy afloat. With the dissolution of the Soviet Union and a cessation of Soviet aid, the south's economy basically collapsed.
Since unification, the government has worked to integrate two relatively disparate economic systems. However, severe shocks, including the return in 1990 of approximately 850,000 Yemenis from the Persian Gulf states, a subsequent major reduction of aid flows, and internal political disputes culminating in the 1994 civil war, hampered economic growth.
Industries.
Agriculture and fishing.
Agriculture is the mainstay of Yemen's economy, generating more than 20 percent of gross domestic product (GDP) since 1990 (20.4 percent in 2005 according to the Central Bank of Yemen) and employing more than half (54.2 percent in 2003) of the working population. However, a U.S. government estimate suggests that the sector accounted for only 13.5 percent of GDP in 2005. Numerous environmental problems hamper growth in this sector—soil erosion, sand dune encroachment, and deforestation—but the greatest problem by far is the scarcity of water. As a result of low levels of rainfall, agriculture in Yemen relies heavily on the extraction of groundwater, a resource that is being depleted. Yemen's water tables are falling by approximately two meters a year, and it is estimated that Sanaa's groundwater supplies could be exhausted by 2008. The use of irrigation has made fruit and vegetables Yemen's primary cash crops. With the rise in the output of irrigated crops, the production of traditional rain-fed crops such as cereals has declined. According to the Central Bank of Yemen, in 2005 the production of khat, a mildly narcotic and heavily cultivated plant that produces natural stimulants when its leaves are chewed, rose 6.7 percent and accounted for 5.8 percent of GDP; its usage in Yemen is widespread. According to the World Bank and other economists, cultivation of this plant plays a dominant role in Yemen's agricultural economy, constituting 10 percent of GDP and employing an estimated 150,000 persons while consuming an estimated 30 percent of irrigation water and displacing land areas that could otherwise be used for exportable coffee, fruits, and vegetables.
Although Yemen's extensive territorial waters and marine resources have the potential to produce 840,000 tons of fish each year, the fishing industry is relatively underdeveloped and consists largely of individual fishermen in small boats. In recent years, the government has lifted restrictions on fish exports, and production has reached one-quarter of capacity, yielding revenues valued at US$260 million in 2005. Fish and fish products constitute only 1.7 percent of Yemen's GDP but are the second largest export. In December 2005, the World Bank approved a US$25 million credit for a Fisheries Management and Conservation Project to be launched in all coastal governorates along the Red Sea and the Gulf of Aden. This project is expected to improve fish landing and auction facilities, provide ice plants for fish preservation, and enable Yemen's Ministry of Fisheries to undertake more effective research, resource management planning, and regulatory activities.
Oil and gas.
Yemen is a small oil producer and does not belong to the Organization of the Petroleum Exporting Countries (OPEC). Unlike many regional oil producers, Yemen relies heavily on foreign oil companies that have production-sharing agreements with the government. Income from oil production constitutes 70 to 75 percent of government revenue and about 90 percent of exports. Yemen contains proven crude oil reserves of more than 4 Goilbbl, although these reserves are not expected to last more than 9 years, and output from the country's older fields is falling, a concern since oil provides around 90% of the country's exports. The World Bank predicts that Yemen's oil and gas revenues will plummet during 2009 and 2010, and fall to zero by 2017 as supplies run out, and UK's Royal Institute for International Affairs warns that instability there could expand a zone of lawlessness from northern Kenya to Saudi Arabia, while describing Yemen's democracy as "fragile" and pointing to armed conflicts with Islamists pand tribal insurgents. Thus western and other diplomats and leaders are concerned to preserve Yemen's stability and to avert adverse outcomes. According to statistics published by the Energy Information Administration, crude oil output averaged 413300 oilbbl/d in 2005, a reduction from 423700 oilbbl/d in 2004. For the first eight months of 2006, crude oil output was flat, averaging 412500 oilbbl/d.
Following a minor discovery in 1982 in the south, an American company found an oil basin near Ma'rib in 1984. A total of 27,000 m³ (170,000 barrels) of oil per day were produced there in 1995. A small oil refinery began operations near Ma'rib in 1986. A Soviet discovery in the southern governorate of Shabwah has proven only marginally successful even when taken over by a different group. A Western consortium began exporting oil from Masila in the Hadhramaut in 1993, and production there reached 67,000 m³ (420,000 barrels) per day in 1999. More than a dozen other companies have been unsuccessful in finding commercial quantities of oil. There are new finds in the Jannah (formerly known as the Joint Oil Exploration Area) and east Shabwah blocks. Yemen's oil exports in 1995 earned about US$1 billion.
Marib oil contains associated natural gas. In September 1995, the Yemeni Government signed an agreement that designated Total of France to be the lead company for a project for the export of liquefied natural gas (LNG). In 1997, Yemen Gas Company joined with various privately held companies to establish Yemen LNG (YLNG). In August 2005 the government gave final approval to three LNG supply agreements, enabling YLNG to award a US$2 billion contract to an international consortium to build the country's first liquefaction plant at Balhat on the Arabian Sea coast. The project is a $3.7 billion investment over 25 years, producing approximately 6.7 million tons of LNG annually, with shipments likely to go to the United States and South Korea. Production of LNG began in October 2009. The Yemen government expects the LNG project to add US$350 million to its budget and enable it to develop a petrochemicals industry.
Industry and manufacturing.
The U.S. government estimates that Yemen's industrial sector constitutes 47.2 percent of gross domestic product. Together with services, construction, and commerce, industry accounts for less than 25 percent of the labor force. The largest contributor to the manufacturing sector's output is oil refining, which generates roughly 40 percent of total revenue. The remainder of this sector consists of the production of consumer goods and construction materials. Manufacturing constituted approximately 9.5 percent of Yemen's gross domestic product in 2005. In 2000 Yemen had almost 34,000 industrial establishments with a total of slightly fewer than 115,000 workers; the majority of the establishments were small businesses (one to four employees). Almost half of all industrial establishments are involved in processing food products and beverages; the production of flour and cooking oil has increased in recent years. Approximately 10 percent of the establishments are classified as manufacturing mixed metal products such as water-storage tanks, doors, and windows.
Services and tourism.
Economists have reported that Yemen's services sector constituted 51.7 percent of gross domestic product (GDP) in 2002 and 52.2 percent of GDP in 2003. The U.S. government estimates that the services sector accounted for 39.7 percent of gross domestic product in 2004 and 39.3 percent in 2005.
Yemen's tourism industry is hampered by limited infrastructure as well as serious security concerns. The country's hotels and restaurants are below international standards, and air and road transportation is largely inadequate. Kidnappings of foreign tourists remain a threat, especially outside the main cities, and, coupled with terrorist bombings at the Port of Aden in 2000 and 2002, present a significant deterrent to tourism. As recently as September 2006, tribesmen in the Shabwa province, east of Sanaa, kidnapped four French tourists on their way to Aden. They were freed two weeks later. In October 2006, the U.S. Department of State reiterated previous warnings to U.S. citizens, strongly urging them to consider carefully the risks of traveling to Yemen. Britain's Foreign Office has issued a similar advisory. Recent statistics for tourist arrivals in Yemen are not available, but in 2004 the number rose to 274,000 from 155,000 in 2003.
Labor.
According to the U.S. government, the agriculture and herding sector employs the majority of Yemen's working population (54.2 percent in 2003). Industry, together with services, construction, and commerce, accounts for less than 25 percent of the labor force.
According to the World Bank, Yemen's civil service is characterized by a large, poorly paid work force and inadequate salary differential between high and low skilled jobs to attract and retain qualified workers. In 2004 the government increased civil service salaries by 20 to 40 percent in order to alleviate the impact of anticipated economic reforms that were never implemented. The result was a 20 percent rise in wage costs; civil service wages constituted 7 percent of gross domestic product in 2004. The 2005 budget reduced economic subsidies but in exchange required the government to make various concessions, including increasing civil service wages another 10 to 15 percent by 2007 as part of a national wage strategy.
The economic assistance package the International Monetary Fund (IMF) pledged to Yemen is contingent on the implementation of civil service reform, which the government has resisted because of the country's estimated 20 to 40 percent unemployment rate. In 2004 the government claimed to have reduced the civil service labor force through retirements and layoffs, but it appears that the large salary increases have lessened the impact of any reforms. The IMF has stated that civil service salaries as a component of gross domestic product should be reduced 1 to 2 percent, a level that can only be achieved with continued reductions in the size of the civil service. It is unclear whether the national wage strategy, which may succeed in streamlining the system and removing irregularities, will in fact be able to reduce employment costs.
Currency, exchange rate, and inflation.
Yemen's currency is the Yemeni riyal (YR), which was floated on the open market in July 1996. Periodic intervention by the Central Bank of Yemen has enabled the riyal to gradually depreciate approximately 4 percent per year since 1999. Its valued averaged YR191.5 per US$1 in 2005, and has averaged YR197.5 in 2006. In late November 2006, the exchange rate was about YR198 per US$1.
During the years immediately following unification (1990–96), Yemen experienced a very high average rate of inflation—40 percent. Economic reforms brought this rate down to only 5.4 percent in 1997, but high oil prices and cuts in the fuel subsidy in recent years have had a negative impact on the inflation rate, which has generally been on the rise despite some fluctuations. In 2004 efforts by the Central Bank of Yemen to tighten the money supply were offset by a weakening US$, to which the Yemeni riyal is linked in a managed float, and by rising global commodity prices, resulting in an inflation rate of 12.5 percent. In July 2005, the government succumbed to public opposition and lowered the new general sales tax from 10 to 5 percent. This tax, coupled with reductions in government fuel subsidies and higher import prices, is expected to result in an estimated inflation rate of 15 percent in 2006, up from 11.8 percent in 2005.
Banking and finance.
According to economists, Yemen's financial services sector is underdeveloped and dominated by the banking system. Yemen has no public stock exchange. The banking system consists of the Central Bank of Yemen, 15 commercial banks (nine private domestic banks, four of which are Islamic banks; four private foreign banks; and two state-owned banks), and two specialized state-owned development banks. The Central Bank of Yemen controls monetary policy and oversees the transfer of currencies abroad. It is the lender of last resort, exercises supervisory authority over commercial banks, and serves as a banker to the government. Since end 2005 and up to the end of 2010, Tadhamon International Islamic Bank has maintained the top spot between all banks in Yemen (Commercial and Islamic) in terms of total assets, capital and trade business. The largest commercial bank, the Credit and Agricultural Cooperative Bank, which is state-owned, and the Yemen Bank for Reconstruction and Development, which is majority state-owned, are currently being restructured with the goal of eventual privatization. Because of fiscal difficulties in both banks, in 2004 Yemen's government adopted a plan to merge them; the new publicly owned Development Bank will have a minimum capital of US$50 million. Till end April 2011 this step has yet to materialize.
The large volume of non-performing loans, low capitalization, and weak enforcement of regulatory standards hamper Yemen's banking sector as a whole. Numerous banks are technically insolvent. Because many debtors are in default, Yemen's banks limit their lending activities to a select group of consumers and businesses; as a result, the entire banking system holds less than 60 percent of the money supply. The bulk of the economy operates with cash. Legislation adopted in 2000 gave the Central Bank the authority to enforce tougher lending requirements, and in mid-2005 the Central Bank promulgated several new capital requirements for commercial banks aimed at curtailing currency speculation and protecting deposits.
Energy.
Yemen's state-owned Public Electricity Corporation (PEC) operates an estimated 80 percent of the country's electricity generating capacity (810–900 megawatts) as well as the national power grid. Over the past 10 years, the government has considered various means of alleviating the country's significant electricity shortage, including restructuring the PCE, integrating the power sector through small-scale privatization of power stations, creating independent power projects (IPPs), and introducing gas-generated power plants to free up oil supplies for export. However, because of inadequate infrastructure, large-scale IPPs and privatization proposals have failed to materialize, although several smaller-scale projects in Al Mukalla and Aden have been completed, and contracts have been signed for future projects. In 2004 Yemen's diesel-run power plants generated 4.1 billion kilowatt-hours of electricity, a level of production that is insufficient to maintain a consistent supply of electricity. Although demand for electricity increased 20 percent between 2000 and 2004, it is estimated that only 40 percent of the total population has access to electricity from the national power grid, and supply is intermittent. To meet this demand, the government plans to increase the country's power generating capacity to 1,400 megawatts by 2002.
Government budget.
In 1995, in order to comply with conditions stipulated by the International Monetary Fund (IMF), Yemen began an economic reform program, one component of which is fiscal policy reform aimed at reducing deficits and expanding the revenue base. However, the government has failed to significantly reduce its primary expenditure—subsidies, especially the fuel subsidy. In January 2005, Yemen's parliament narrowly adopted a 2005 budget that forecast a reduced budget deficit of about 3 percent of gross domestic product (GDP). The budget was predicated on the adoption of a reform package that included a broad-based, 10 percent general sales tax (GST) and a 75 percent reduction in the fuel subsidy. Strong public opposition to these reforms led the government in July 2005 to defer the 10 percent GST for 18 months, adopting instead a hybrid 5 percent GST, and to modify the fuel subsidy reduction. Nonetheless, the cost of subsidies, primarily for fuel, rose dramatically (almost 90 percent) in 2005, accounting for the largest share (almost 25 percent) of total government expenditures and approximately 9 percent of GDP. These costs, coupled with a 24 percent increase in civil service wages and salaries and a 42 percent increase in defense spending, resulted in a government budget deficit of US$350.8 million, or more than 2 percent of GDP, in 2005. The government has budgeted a sharp (41 percent) rise in overall spending for 2006, which economists estimate will result in a fiscal deficit of US$800 million, or 4.2 percent of GDP.
Foreign economic relations.
History and overview.
During the 1990–91 Persian Gulf War, Yemen supported Iraq in its invasion of Kuwait, thereby alienating Saudi Arabia and Kuwait, which both had provided critical financial assistance to Yemen. In addition to withdrawing this aid, Saudi Arabia expelled almost 1 million Yemeni workers. The resultant fall in expatriate remittances had a disastrous impact on Yemen's governmental budget. The civil war of 1994 further drained the economy, and in 1995 Yemen sought the aid of multilateral agencies. In 1996 the International Monetary Fund (IMF) granted Yemen a US$190 million stand-by credit facility, and the following year it approved two funding facilities that increased the country's credit by approximately US$500 million. The funding was contingent on Yemen's adoption of stringent economic reforms, a requirement that the country had limited success in fulfilling. As a result, the IMF suspended lending to Yemen from late 1999 until February 2001. The extension of the two funding facilities, particularly the poverty reduction and growth facility (PRGF), through October 2001 was again contingent on Yemen's commitment to economic reform. Because of Yemen's failure to comply sufficiently with the terms imposed by the IMF, since 2002 the IMF has withheld US$300 million in concessional financing. Discussions over the renewal of the PRGF are ongoing. In 2000 Kuwait and Saudi Arabia resumed financial aid to Yemen.
In October 2002, bilateral and multilateral lenders led by the World Bank agreed to give Yemen a four-year economic support package worth US$2.3 billion, 20 percent in grants and 80 percent in concessional loans. This funding is almost eight times the amount of financial support Yemen received under the IMF's PRGF. However, in December 2005 the World Bank announced that because of the government's continued inability to effect significant economic reforms and stem corruption, funding would be reduced by more than one-third, from US$420 million to US$240 million for the period July 2005 – July 2008. In May 2006, the World Bank adopted a new Country Assistance Strategy (CAS) for Yemen for the period FY 2006 to FY 2009, providing a blueprint for fostering the country's fiscal and human development improvement. The bank pledged to contribute approximately US$400 million in International Development Association (IDA) credits over the CAS time frame. At present, Yemen owes approximately US$264 million to Japan, one of its largest donors. In December 2005, the Japanese government pledged to write off US$17 million of the debt. That same month, Germany pledged to increase its annual aid to Yemen to US$83.6 million over the next two years; funding will go primarily to education and water improvement projects. In November 2006, the United Kingdom announced that aid to Yemen would increase 400 percent, to US$222 million through 2011.
Yemen is a member of the Arab Fund for Economic and Social Development, which since 1974 has contributed to the financing of economic and social development in Arab states and countries through loans and guarantees. In March 2004, the Arab League provided US$136 million to Yemen to finance infrastructure improvements. At a mid-November 2006 meeting in London, a group of bilateral and multilateral donors pledged US$4.7 billion over four years (2007–10) to fund economic development in Yemen. The goal of the meeting, which was jointly chaired by the World Bank and the government of Yemen, was to provide sufficient economic aid to Yemen to enable it to qualify for future Gulf Cooperation Council (GCC) membership. More than 55 percent of the aid, which is primarily in the form of grants, will come from the GCC. Yemen was granted observer status at the World Trade Organization (WTO) in 1999, and its application for full membership was under negotiation as of December 2006.
Foreign trade.
Imports totaled an estimated US$4.7 billion in 2005 and are projected to increase to US$5 billion in 2006 and to US$5.4 billion in 2007. Yemen is a net importer of all major categories of products except fuels. Principal imports are machinery and transport equipment, food and livestock, and processed materials. According to the United Nations, Yemen imports more than 75 percent of its main dietary staple—wheat. The principal source of Yemen's imports in 2005 was the United Arab Emirates (13.4 percent of total imports); the bulk of these imports are actually re-exports from the United States and Kuwait. Yemen received 10.6 percent of its total imports from Saudi Arabia and 9 percent from China.
In 2005 Yemen's exports totaled US$6.4 billion. Exports are expected to increase to reach a record US$8.6 billion in 2006 as a result of strong oil revenues. Petroleum is Yemen's main export, accounting for 92 percent of total exports in 2004 and 87 percent in 2005. Yemen's non-oil exports are primarily agricultural products, mainly fish and fish products, vegetables, and fruit. In 2005 Asia was the most important market for Yemen's exports, primarily China (37.3 percent of total exports), Thailand, and Japan. Chile was also a primary export market (19.6 percent of total exports).
Yemen's import and export values have increased and decreased dramatically in the past 10 years owing to shifts in global oil prices. As a result, the country's trade balance has fluctuated significantly from a deficit of almost US$800 million in 1998 to a surplus of US$1 billion in 2000. Rising oil prices resulted in a surplus of US$817 million in 2004 and a surplus of US$1.7 billion in 2005.
In recent years, Yemen has reported increasing non-merchandise deficits. These deficits have, however, been offset by record export earnings, which have resulted in large enough trade surpluses to keep the current account in surplus—US$175.7 million in 2003, US$524.6 million in 2004, and US$633.1 million (about 4 percent of gross domestic product) in 2005.
External debt.
In 1990 the newly unified Republic of Yemen inherited an unsustainable debt burden amounting to roughly 106 percent of gross domestic product. Debt rescheduling by the Paris Club creditor countries in the 1990s coupled with assistance from the World Bank's International Development Agency resulted in a drop in Yemen's debt stock to US$5.4 billion (an estimated 39 percent of gross domestic product) by year-end 2004. According to the Central Bank of Yemen, Yemen's debt stock was US$5.2 billion (an estimated 33 percent of gross domestic product) by year-end 2005. According to the U.S. government, Yemen's reserves of foreign exchange and gold were US$6.1 billion in 2005.
Foreign investment.
Yemen does not have a stock exchange, therefore limiting inward portfolio investment. Portfolio investment abroad is also very limited, with the result that portfolio flows are largely unrecorded by authorities. In the early 1990s, net direct investment was at its peak as foreign investors tapped Yemeni oil reserves, but since 1995 net direct investment flows have been negative because cost recovery for foreign oil companies has exceeded new direct investment. A five-year US$3 billion liquid natural gas (LNG) construction project involving a consortium of foreign companies is planned following government approval in August 2005. Such a project raises the prospect of increased foreign investment in the future as LNG facilities are built.

</doc>
<doc id="34252" url="http://en.wikipedia.org/wiki?curid=34252" title="Military of Yemen">
Military of Yemen

The armed forces of Yemen include the Yemen Army (includes Republican Guard), Navy (includes Marines), 1st Armored Division, Yemeni Air Force (Al Quwwat al Jawwiya al Yamaniya, which includes the Air Defense Force) (2008). A major reorganization of the armed forces continues. The unified air forces and air defenses are now under one command. The navy has concentration in Aden. Total armed forces manning numbers about 401,000 active personnel, including conscripts. The Yemen Arab Republic and The People's Democratic Republic of Yemen joined to form the Republic of Yemen on 22 May 1990.
The supreme commander of the armed forces is Field Marshal Abd Rabbuh Mansur Al-Hadi, the President of the Republic of Yemen.
The number of military personnel in Yemen is relatively high; in sum, Yemen has the second largest military force on the Arabian Peninsula after Saudi Arabia. In 2012, total active troops were estimated as follows: army, 66,700; navy, 7,000; and air force, 5,000. In September 2007, the government announced the reinstatement of compulsory military service. Yemen’s defense budget, which in 2006 represented approximately 40 percent of the total government budget, is expected to remain high for the near term, as the military draft takes effect and internal security threats continue to escalate. By 2012 Yemen now has 401,000 active personnel.
Yemen used child soldiers between 2001 and 2004. Child soldiers were also used by organized forces and tribal militia as of 2011.
History.
North Yemen Civil War.
The North Yemen Civil War began in 1962 and ended in 1970. It took place between the North Yemen republican forces and the Mutawakkilite Kingdom of Yemen. The Royalists received support from Saudi Arabia and Jordan while the Republicans received support from Egypt and the Soviet Union. the Royalists used local tribesmen. The Republicans also used about 55,000 Egyptian troops.
The Royalists were commanded by Muhammad al-Badr of the Mutawakkilite Kingdom of Yemen.
The Republican commanders were Gamal Abdul Nasser and Abdul Hakim Amer from Egypt and Abdullah as-Sallal from the North Yemen republic. During the conflict over 50,000 of Egypt's troops were tied down in Yemen, which proved to be a disadvantage to Egypt during the Six-day war in 1967. The war concluded when the Republican forces won, and this resulted in transformation of the Mutawakkilite Kingdom of Yemen into North Yemen. Over 100,000 died on both sides during the conflict.
Chemical Warfare during North Yemen Civil War.
The first attack took place on June 8, 1963 against Kawma, a village of about 100 inhabitants in northern Yemen, killing about seven people and damaging the eyes and lungs of twenty-five others. This incident is considered to have been experimental, and the bombs were described as "home-made, amateurish and relatively ineffective". The Egyptian authorities suggested that the reported incidents were probably caused by napalm, not gas. The Israeli Foreign Minister, Golda Meir, suggested in an interview that Nasser would not hesitate to use gas against Israel as well.
There were no reports of gas during 1964, and only a few were reported in 1965. The reports grew more frequent in late 1966. On December 11, 1966, fifteen gas bombs killed two people and injured thirty-five. On January 5, 1967, the biggest gas attack came against the village of Kitaf, causing 270 casualties, including 140 fatalities. The target may have been Prince Hassan bin Yahya, who had installed his headquarters nearby. The Egyptian government denied using poison gas, and alleged that Britain and the US were using the reports as psychological warfare against Egypt. On February 12, 1967, it said it would welcome a UN investigation. On March 1, U Thant said he was "powerless" to deal with the matter.
On May 10, the twin villages of Gahar and Gadafa in Wadi Hirran, where Prince Mohamed bin Mohsin was in command, were gas bombed, killing at least seventy-five. The Red Cross was alerted and on June 2, it issued a statement in Geneva expressing concern. The Institute of Forensic Medicine at the University of Berne made a statement, based on a Red Cross report, that the gas was likely to have been halogenous derivatives - phosgene, mustard gas, lewisite, chloride or cyanogen bromide.
The gas attacks stopped for three weeks after the Six-Day War of June, but resumed on July, against all parts of royalist Yemen. Casualty estimates vary, and an assumption, considered conservative, is that the mustard and phosgene-filled aerial bombs caused approximately 1,500 fatalities and 1,500 injuries.
1994 Civil War.
During the 1994 civil war in Yemen almost all of the actual fighting in the 1994 civil war occurred in the southern part of the country despite air and missile attacks against cities and major installations in the north. Southerners sought support from neighboring states and received billions of dollars of equipment and financial assistance, mostly from Saudi Arabia, which felt threatened during Gulf War in 1991 when Yemen supported Saddam Hussien. The United States repeatedly called for a cease-fire and a return to the negotiating table. Various attempts, including by a UN special envoy, were unsuccessful to effect a cease-fire.
Southern leaders declared secession and the establishment of the Democratic Republic of Yemen (DRY) on 21 May 1994, but the DRY was not recognized by the international community. Ali Nasir Muhammad supporters greatly assisted military operations against the secessionists and Aden was captured on 7 July 1994.[1] Other resistance quickly collapsed and thousands of southern leaders and military went into exile.[1]
2011 Yemeni Uprising.
In March 2011, a month after the beginning of an uprising against President Salehs rule, Maj. Gen. Ali Mohsen al-Ahmar, the commander of the 1st Armoured Division, defected to the side of the protesters taking hundreds of troops and several tanks to protect protesting citizens. Rival tanks of the 1st Armoured Division and the Republican Guard faced off against each other in San'na.
The Yemeni Army's 119th Brigade, which had defected to the opposition, launched a joint operation with 31st and 201st Brigades which were still loyal to Saleh and retook the city of Zanjibar on 10 September from Islamist militants who were exploiting the chaos in the country to expand their influence. The offensive relieved besieged army units in the process.
On 17 September, at least one rebel soldier was killed in clashes with loyalists in San'na near the city's central square, trying to protect the protest camp there from security forces.
Anti government tribesmen overran a loyalist army base north of San'na on 20 September, capturing 30 soldiers.
Organization.
Yemen’s military is divided into an army, navy, air force, and border guard.
The army is organized into eight armored brigades, 16 infantry brigades, six mechanized brigades, two airborne commando brigades, one surface-to-surface missile brigade, three artillery brigades, one central guard force, one Special Forces brigade, and six air defense brigades, which consist of four antiaircraft artillery battalions and one surface-to-air missile battalion.
"A military takeover could only realistically be launched by one of the five Area Commanders. Having himself come to power by coup, Saleh has been extremely careful to select Commanders whose loyalty is ensured by tribal bonds. Members of Saleh's Sanhan tribe control all military districts and most high security posts, with the commanders enjoying blood and/or close ties to Saleh. The Commanders report directly to the President, outside the normal channels of the Ministry of Defense and without constitutional mandate. They are the final authority in nearly every aspect of regional governance. In practice, they behave like tribal sheikhs and super-governors, parceling out new schools, water projects, and money. Despite periodic efforts to integrate military units, the Commanders recruit largely from regional tribes."
As of September 2005, "Brigadier General Ali Mohsen al-Ahmar, Commander of the Northeastern region, is the most powerful of these military elites. The commander of the Eastern Area is BG Mohammed Ali Mohsen. The Eastern Area includes the governorates of Hadramawt and al-Mahra. Ali Faraj is commander for the Central Area, which includes Al-Jawf, Maarib, al-Bayda, and Shabwa, while the Southern Commander, controlling the Aden, Taiz, Lahaj, al-Dhala and Abyan, is Abd al-Aziz al-Thabet. Finally, BG Awadh bin Fareed commands the Central Area, including the capital Sanaa. With the exception of Ali Mohsen, all of these commands are subject to periodic change or shuffle."
The air force includes an air defense force. Yemen recently placed an order for TOR air defence systems, which will be far more advanced than the current air defense systems in place. The TOR order has been completed. The Yemeni Army has a total strength of 137,900 troops.
In 2001, Yemen’s National Defense Council abolished the existing two-year compulsory military service, relying instead on volunteers to fill posts in the military and security forces. In 2007, the Yemeni government announced that it would reinstate the draft to counter unemployment; approximately 70,000 new recruits were expected to join the military.
Defense budget.
Yemen’s defense spending has historically been one of the government’s three largest expenditures and is expected to remain high as a result of the reinstatement of conscription and security threats posed by terrorism and tribal conflict. The defense budget increased from US$540 million in 2001 to an estimated US$2 billion–US$2.1 billion in 2006, to which it is probably $3.5 billion by 2012. According to the U.S. government, the 2006 budget represents about 6 percent of gross domestic product.
Paramilitary forces.
Yemen’s paramilitary force has about 71,000 troops. Approximately 50,000 constitute the Central Security Organization of the Ministry of Interior; they are equipped with a range of infantry weapons and armored personnel carriers. An additional 20,000 are forces of armed tribal levies. Yemen is building up a small coast guard under the Ministry of Interior, training naval military technicians for posts in Aden and Al Mukalla.
The coast guard currently has 1,200 personnel.
Navy.
Yemen's navy was created in 1990 when North and South Yemen united. The navy’s major bases are located in Aden and Al Hudaydah; there are also bases in Al Mukalla, Perim Island, and Socotra that maintain naval support equipment. Yemen's navy uses +2,000 officers and seamen to support their main bases at Aden and Hodeida. A naval fortress is in construction at Hodeida. 
Yemen early on had problems with trying to keep drugs from entering Yemen by sea. In 2006, Yemen purchased ten patrol boats based on the Australian Bay class, which were very effective at stopping smugglers from entering Yemen.
In the Hanish Islands conflict, Yemen prepared its navy for an assault on the Hanish islands and on Eritrea. Eritrea accidentally destroyed a Russian ship thinking it was a Yemeni ship. The invasion however never happened since Eritrea made agreements with Yemen which involved Eritrea taking over the islands. Yemen however, later took over Zukur-Hanish archipelago island which created further tensions with the Eritrean government but it didn't lead to another war.
Naval Equipment.
Corvette
Missile Boat
Patrol Craft
Utility Craft
Landing Ships
Minesweeper/hunter

</doc>
<doc id="34253" url="http://en.wikipedia.org/wiki?curid=34253" title="Foreign relations of Yemen">
Foreign relations of Yemen

The foreign relations of Yemen are the relationships and policies that Yemen maintains with other countries. It is a member of the United Nations, the Arab League, and the Organisation of Islamic Cooperation. Yemen participates in the nonaligned movement. The Republic of Yemen accepted responsibility for all treaties and debts of its predecessors, the YAR and the PDRY. Additionally, Yemen has acceded to the Nuclear Non-Proliferation Treaty and has stressed the need to render the Middle East region free of nuclear and other weapons of mass destruction.
History.
North Yemen.
The geography and ruling Imams of North Yemen kept the country isolated from foreign influence before 1962. During the 1920s, the government of Yemen forged relations with the Italian government under Mussolini, which lead to the conclusion of an Italian-Yemeni friendship treaty on September 2, 1926. This gave the Sana'a government diplomatic support vis-a-vis the Saudi government, which had aggressive designs on Yemeni territory. The country's relations with Saudi Arabia were defined by the Treaty of Taif in 1934 which delineated the northernmost part of the border between the two kingdoms and set the framework for commerce and other interactions. The Taif Agreement has been renewed periodically in 20-year increments, and its validity was reaffirmed in 1995. Relations with the British colonial authorities in Aden and the south were usually tense.
The Soviet and Communist Chinese Aid Missions established in 1958 and 1959 were the first important non-Muslim presence in North Yemen. Following the September 1962 revolution, the Yemen Arab Republic became closely allied with and heavily dependent upon Egypt. Saudi Arabia aided the royalists in their attempt to defeat the republicans and did not recognize the Yemen Arab Republic until 1970. Subsequently, Saudi Arabia provided Yemen substantial budgetary and project support. At the same time, Saudi Arabia maintained direct contact with Yemeni tribes, which sometimes strained its official relations with the Yemeni government. Hundreds of thousands of Yemenis found employment in Saudi Arabia during the late 1970s and 1980s.
Saleh's foreign policy as the leader of North Yemen was characterized by the principles of "positive neutrality" and Arab unity. Under Saleh, Yemen cultivated close ties with Saudi Arabia and other pro-West states in the region. He also purchased military equipment from the United States and expanded economic relations with the West. At the same time, Saleh also tried to maintain friendly relations with the then-Soviet Union (which broke apart in 1991). In October 1984, he renewed the treaty of Friendship and Cooperation that was originally signed in 1964 by San'a and Moscow.
In February 1989, North Yemen joined Iraq, Jordan, and Egypt informing the Arab Cooperation Council (ACC), an organization created partly in response to the founding of the Gulf Cooperation Council, and intended to foster closer economic cooperation and integration among its members. After unification, the Republic of Yemen was accepted as a member of the ACC in place of its YAR predecessor. In the wake of the Persian Gulf crisis, the ACC has remained inactive.
South Yemen.
British authorities left South Yemen in November 1967 in the wake of an intense terrorist campaign. The People's Democratic Republic of Yemen, the successor to British colonial rule, had diplomatic relations with many nations, but its major links were with the Soviet Union and other Communist countries. Relations between it and the conservative Arab states of the Arabian Peninsula were strained. There were military clashes with Saudi Arabia in 1969 and 1973, and the PDRY provided active support for the Dhofar Rebellion against the Sultanate of Oman. The PDRY was the only Arab state to vote against admitting new Arab states from the Persian Gulf area to the United Nations and the Arab League. The PDRY provided sanctuary and material support to various international terrorist groups.
Unified Yemen.
The Persian Gulf crisis dramatically affected Yemen's foreign relations. As a member of the UN Security Council (UNSC) for 1990 and 1991, Yemen abstained on a number of UNSC resolutions concerning Iraq and Kuwait and voted against the "use of force resolution". Western and Persian Gulf Arab states reacted by curtailing or canceling aid programs and diplomatic contacts. At least 850,000 Yemenis returned from Saudi Arabia and the Persian Gulf.
After the liberation of Kuwait, Yemen continued to maintain high-level contacts with Iraq. This hampered its efforts to rejoin the Arab mainstream and to mend fences with its immediate neighbors. In 1993, Yemen launched an unsuccessful diplomatic offensive to restore relations with its Persian Gulf neighbors. Some of its aggrieved neighbors actively aided the south during the 1994 civil war. Since the end of that conflict, tangible progress has been made on the diplomatic front in restoring normal relations with Yemen's neighbors. The Omani-Yemeni border has been officially demarcated. In the summer of 2000, Yemen and Saudi Arabia signed an International Border Treaty settling a 50-year-old dispute over the location of the border between the two countries. Yemen settled its dispute with Eritrea over the Hanish Islands in 1998.
By country.
Bangladesh.
It was here that a person named Shah Jalal spread Islam and introduced the religion to the people of Bangladesh back in 1303.
Djibouti.
Relations between Yemen and Djibouti are good, and cooperation takes place on many levels. A causeway between the two countries has been proposed.
Eritrea.
In 1995, there was a conflict between Yemen and Eritrea over the Hanish islands. Eritrea has half, while Yemen has half.
Holy See.
The Holy See and Yemen established diplomatic relations in 1998.
India.
India has an embassy in Sana'a, while Yemen has an embassy in New Delhi.
Iran.
Following the first two decades of the Islamic Revolution, ties between Tehran and Sana'a were never strong, but in recent years the two countries have attempted to settle their differences. One sign of this came on December 2, 2003, when the Yemeni foreign ministry announced that "Yemen welcomes Iran's request to participate in the Arab League as an observer member."
However, relations have also been tense in recent years, particularly for the alleged Iranian support to Houthi rebels in Yemen, as part of the Shia insurgency in Yemen.
Israel.
Yemen does not have diplomatic relations with Israel and relations between the two countries are very tense. People with an Israeli passport or any passport with an Israeli stamp cannot enter Yemen, and Yemen is defined as an enemy state by Israeli law.
Malaysia.
Malaysia has an embassy in Sana'a, and Yemen has an embassy in Kuala Lumpur.
Oman.
Oman and Yemen are generally enjoying good relations. The two countries share a border. Both Oman and Yemen were part of the Persian Empire, and later of Umayyad and Abbasid Caliphates. Yemen has an embassy in Muscat. Oman is represented in Yemen through its embassy in San'a.
Pakistan.
Pakistan has an embassy in Sana'a. Many Pakistani worked in Yemen.
Saudi Arabia.
Although similar in dialect, ethnicity and religion, diplomatic relations between the two countries have been hostile owing to various political and border disputes.
Singapore.
Singapore and Yemen generally have solid, good relations. The governments of Yemen and Singapore are in support of the War on Terror and Singapore is also one of Yemen's biggest trading partners outside the Gulf States
Somalia.
Although relations between the modern-day territories of Somalia and Yemen stretch back to antiquity, the two countries formally established diplomatic ties on December 18, 1960. Both nations are also members of the Arab League.
Following the outbreak of the civil war in Somalia in the 1990s, the Yemeni authorities maintained relations with Somalia's newly established Transitional National Government and its successor the Transitional Federal Government. The subsequent establishment of the Federal Government of Somalia in August 2012 was also welcomed by the Yemeni authorities, who re-affirmed Yemen's continued support for Somalia's government, its territorial integrity and sovereignty.
Additionally, Somalia maintains an embassy in Yemen, with the diplomatic mission led by Ambassador Ismail Qassim Naji. Yemen also has an embassy in Mogadishu.
United Kingdom.
The United Kingdom have one consulate and embassy based in Sana'a. 
United States.
Traditionally, Yemen's relations with the United States have been tepid, as the lack of strong military-to-military ties, commercial relations, and support of Yemeni President Ali Abdullah Saleh has hindered the development of strong bilateral ties. During the early years of the George W. Bush administration, relations improved under the rubric of the war on terror, though Yemen's lax policy toward wanted terrorists has stalled additional American support.
International organization membership.
Yemen is a member of the United Nations (UN) and the following UN affiliates and specialized agencies:
Yemen is also a member of the following organizations:
Yemen was granted observer status at the World Trade Organization (WTO) in 1999 and in 2002 and 2003 submitted necessary documentation for full membership. The WTO working party on Yemen met in 2004 and twice thereafter to discuss Yemen's accession; negotiations are expected to take several years.
Relations with the Gulf Cooperation Council.
Yemen desires to join the 24-year-old Gulf Cooperation Council (GCC), a sub-regional organization which groups Saudi Arabia, Kuwait, Bahrain, Qatar, the United Arab Emirates, and Oman in an economic and security alliance. GCC members have traditionally opposed accession of additional states. Currently, Yemen has partial observer status on some GCC committees, and observers believe that full membership is unlikely. Others assert that it is in the GCC's interest to assist Yemen and prevent it from becoming a failed state, lest its instability spread to neighboring Gulf countries. This has helped Yemen greatly. In November 2006, an international donors' conference was convened in London to raise funds for Yemen's development. Yemen received pledges totaling $4.7 billion, which are to be disbursed over four years (2007–2010) and represent over 85% of the government's estimated external financing needs. Much of these pledges came from Yemen's wealthy Arab neighbors.
The impediments to full GCC membership are steep. Reportedly, Kuwait, still bitter over Yemen's support for Saddam Hussein during the first Gulf War, has blocked further discussion of membership. Meanwhile, Yemen needs to export thousands of its workers each year to the Gulf in order to alleviate economic burdens at home. Foreign remittances are, aside from oil exports, Yemen's primary source of hard currency.
Arab–Israeli conflict.
Yemen has usually followed mainstream Arab positions on Arab–Israel issues, and its geographic distance from the conflict and lack of political clout make it a minor player in the peace process. Yemen has not established any bilateral mechanism for diplomatic or commercial contacts with Israel. The Yemeni Jewish community (300 members) continues to dwindle, as many of its members emigrated to Israel decades ago. On December 11, 2008, Moshe Nahari, a Jewish teacher, was murdered in a market in Raidah, home to one of the last Jewish communities in Yemen. After the attack, President Saleh pledged to relocate Yemeni Jews to the capital.
Yemen supports the Arab Peace Initiative, which calls for Israel's full withdrawal from all occupied territories and the establishment of a Palestinian state in the West Bank and Gaza Strip in exchange for full normalization of relations with all Arab states in the region. In the spring of 2008, President Saleh attempted to broker a reconciliation agreement between the competing Palestinian factions Hamas and Fatah. During a March meeting in Sana'a, Palestinian representatives from both groups signed a declaration (the Sana'a Declaration) calling for the creation of a national unity government, but the talks fell apart over the issue of Hamas's role in a unified Palestinian Authority.
Major international treaties.
Yemen is a signatory to various international agreements on agricultural commodities, commerce, defense, economic and technical cooperation, finance, and postal matters. Yemen is a Non-Annex I country under the United Nations Framework Convention on Climate Change. Yemen is not a signatory to the Kyoto Protocol but has acceded to it, which has the same legal effect as ratification. Yemen is a signatory to the Nuclear Non-Proliferation Treaty, is a party to the Biological Weapons Convention, and has signed and ratified the Chemical Weapons Convention. Yemen is also a party to environmental conventions on Biodiversity, Desertification, Environmental Modification, Hazardous Wastes, Law of the Sea, and Ozone Layer Protection.
2010 embassy closures.
In late December 2009, the U.S. Embassy asked Americans in Yemen to keep watch for any suspicious terrorist activity following a terrorist incident on board a flight to the US that was linked to Yemen. On January 3, 2010, following intelligence and threats from al-Qaeda, the U.S. embassy in Sana'a was closed. A statement issued on the embassy's website said: "The US Embassy in Sana'a is closed today, in response to ongoing threats by Al-Qaeda in the Arabian Peninsula (AQAP) to attack American interests in Yemen". Al Jazeera reported that the closure of the embassy can mean only that "they believe al-Qaeda threat is very serious". No reopening date was given.
On the same day, the United Kingdom withdrew their presence in the country for similar purposes. The following day, France closed its embassy. Although the French Embassy was closed, staff remained inside. The French foreign ministry issued a statement saying, "Our ambassador decided on January 3 not to authorise any public access to the diplomatic mission until further notice." At the Italian Embassy, only those with prior appointments were allowed to enter. Ambassador Mario Boffo noted, though, that "if things remain as they are, then tomorrow or the day after we will return to normality." The embassy of the Czech Republic closed the visa and consular departments "amid fears of terrorist attacks." Japan, Spain and Germany also made changes to their security arrangements and embassy accessibility. In addition to extra security at embassies, Yemen increased security at Sana'a International Airport.
According to the BBC, Yemeni media say the embassy closures come after "six trucks full of weapons and explosives entered the capital, and the security forces lost track of the vehicles." Trucks driven by militants, previously under security surveillance, had entered Sana'a and lost the surveillance at that point.
The French, UK, and US embassies later reopened the following day.
2015 embassy closures.
Following the 2014–15 Yemeni coup d'état, many nations closed their embassies. France, United Kingdom, and United States closed their embassies on 11 February 2015, Germany, Italy, and Saudi Arabia closed their embassies on 13 February, Spain, Turkey, and United Arab Emirates closed their embassies on 14 February, Japan closed its embassy on 16 February, and Egypt closed its embassy on 23 February.

</doc>
<doc id="34254" url="http://en.wikipedia.org/wiki?curid=34254" title="Yellow fever">
Yellow fever

Yellow fever, known historically as yellow jack, yellow plague, or bronze john, is an acute viral disease. In most cases, symptoms include fever, chills, loss of appetite, nausea, muscle pains particularly in the back, and headaches. Symptoms typically improve within five days. In some people within a day of improving, the fever comes back, abdominal pain occurs, and liver damage begins causing yellow skin. If this occurs, the risk of bleeding and kidney problems is also increased.
The disease is caused by the yellow fever virus and is spread by the bite of the female mosquito. It infects only humans, other primates, and several species of mosquitoes. In cities, it is spread primarily by mosquitoes of the "Aedes aegypti" species. The virus is an RNA virus of the genus "Flavivirus". The disease may be difficult to tell apart from other illnesses, especially in the early stages. To confirm a suspected case, blood sample testing with polymerase chain reaction is required.
A safe and effective vaccine against yellow fever exists and some countries require vaccinations for travelers. Other efforts to prevent infection include reducing the population of the transmitting mosquito. In areas where yellow fever is common and vaccination is uncommon, early diagnosis of cases and immunization of large parts of the population is important to prevent outbreaks. Once infected, management is symptomatic with no specific measures effective against the virus. In those with severe disease, death occurs in about half of people without treatment.
Yellow fever causes 200,000 infections and 30,000 deaths every year, with nearly 90% of these occurring in Africa. Nearly a billion people live in an area of the world where the disease is common. It is common in tropical areas of South America and Africa, but not in Asia. Since the 1980s, the number of cases of yellow fever has been increasing. This is believed to be due to fewer people being immune, more people living in cities, people moving frequently, and changing climate. The disease originated in Africa, where it spread to South America through the slave trade in the 17th century. Since the 17th century, several major outbreaks of the disease have occurred in the Americas, Africa, and Europe. In the 18th and 19th centuries, yellow fever was seen as one of the most dangerous infectious diseases. The yellow fever virus was the first human virus discovered.
Signs and symptoms.
Yellow fever begins after an incubation period of three to six days. Most cases only cause a mild infection with fever, headache, chills, back pain, fatigue, loss of appetite, muscle pain, nausea, and vomiting. In these cases, the infection lasts only three to four days.
In 15 percent of cases, however, people enter a second, toxic phase of the disease with recurring fever, this time accompanied by jaundice due to liver damage, as well as abdominal pain. Bleeding in the mouth, the eyes, and the gastrointestinal tract will cause vomit containing blood, hence the Spanish name for yellow fever, "vomito negro" ("black vomit"). The toxic phase is fatal in about 20% of cases, making the overall fatality rate for the disease 3%. In severe epidemics, the mortality may exceed 50%.
Surviving the infection provides lifelong immunity, and normally there is no permanent organ damage.
Cause.
Yellow fever is caused by the yellow fever virus, a 40- to 50-nm-wide enveloped RNA virus, the type species and namesake of the family Flaviviridae. It was the first illness shown to be transmissible by filtered human serum and transmitted by mosquitoes, by Walter Reed around 1900. The positive-sense, single-stranded RNA is around 11,000 nucleotides long and has a single open reading frame encoding a polyprotein. Host proteases cut this polyprotein into three structural (C, prM, E) and seven nonstructural proteins (NS1, NS2A, NS2B, NS3, NS4A, NS4B, NS5); the enumeration corresponds to the arrangement of the protein coding genes in the genome. Yellow fever belongs to the group of hemorrhagic fevers.
The viruses infect, amongst others, monocytes, macrophages, and dendritic cells. They attach to the cell surface via specific receptors and are taken up by an endosomal vesicle. Inside the endosome, the decreased pH induces the fusion of the endosomal membrane with the virus envelope. The capsid enters the cytosol, decays, and releases the genome. Receptor binding, as well as membrane fusion, are catalyzed by the protein E, which changes its conformation at low pH, causing a rearrangement of the 90 homodimers to 60 homotrimers.
After entering the host cell, the viral genome is replicated in the rough endoplasmic reticulum (ER) and in the so-called vesicle packets. At first, an immature form of the virus particle is produced inside the ER, whose M-protein is not yet cleaved to its mature form and is therefore denoted as prM (precursor M) and forms a complex with protein E. The immature particles are processed in the Golgi apparatus by the host protein furin, which cleaves prM to M. This releases E from the complex which can now take its place in the mature, infectious virion.
Transmission.
Yellow fever virus is mainly transmitted through the bite of the yellow fever mosquito "Aedes aegypti", but other mosquitoes such as the tiger mosquito ("Aedes albopictus") can also serve as a vector for this virus. Like other Arboviruses which are transmitted by mosquitoes, the yellow fever virus is taken up by a female mosquito when it ingests the blood of an infected human or other primate. Viruses reach the stomach of the mosquito, and if the virus concentration is high enough, the virions can infect epithelial cells and replicate there. From there, they reach the haemocoel (the blood system of mosquitoes) and from there the salivary glands. When the mosquito next sucks blood, it injects its saliva into the wound, and the virus reaches the bloodstream of the bitten person. Transovarial and transstadial transmission of the yellow fever virus within "A. aegypti", that is, the transmission from a female mosquito to her eggs and then larvae, are indicated. This infection of vectors without a previous blood meal seems to play a role in single, sudden breakouts of the disease.
Three epidemiologically different infectious cycles occur, in which the virus is transmitted from mosquitoes to humans or other primates. In the "urban cycle", only the yellow fever mosquito "A. aegypti" is involved. It is well adapted to urban areas and can also transmit other diseases, including dengue fever and chikungunya. The urban cycle is responsible for the major outbreaks of yellow fever that occur in Africa. Except in an outbreak in 1999 in Bolivia, this urban cycle no longer exists in South America.
Besides the urban cycle, both in Africa and South America, a sylvatic cycle (forest cycle or jungle cycle) is present, where "Aedes africanus" (in Africa) or mosquitoes of the genus "Haemagogus" and "Sabethes" (in South America) serve as vectors. In the jungle, the mosquitoes infect mainly non-human primates; the disease is mostly asymptomatic in African primates. In South America, the sylvatic cycle is currently the only way humans can infect each other, which explains the low incidence of yellow fever cases on the continent. People who become infected in the jungle can carry the virus to urban areas, where "A. aegypti" acts as a vector. Because of this sylvatic cycle, the yellow fever cannot be eradicated.
In Africa, a third infectious cycle known as "savannah cycle" or intermediate cycle, occurs between the jungle and urban cycles. Different mosquitoes of the genus "Aedes" are involved. In recent years, this has been the most common form of transmission of yellow fever in Africa.
Pathogenesis.
After transmission from a mosquito, the viruses replicate in the lymph nodes and infect dendritic cells in particular. From there, they reach the liver and infect hepatocytes (probably indirectly via Kupffer cells), which leads to eosinophilic degradation of these cells and to the release of cytokines. Necrotic masses known as Councilman bodies appear in the cytoplasm of hepatocytes.
Fatality may occur when cytokine storm, shock, and multiple organ failure follow.
Diagnosis.
Yellow fever is a clinical diagnosis, which often relies on the whereabouts of the diseased person during the incubation time. Mild courses of the disease can only be confirmed virologically. Since mild courses of yellow fever can also contribute significantly to regional outbreaks, every suspected case of yellow fever (involving symptoms of fever, pain, nausea and vomiting six to 10 days after leaving the affected area) is treated seriously.
If yellow fever is suspected, the virus cannot be confirmed until six to 10 days after the illness. A direct confirmation can be obtained by reverse transcription polymerase chain reaction where the genome of the virus is amplified. Another direct approach is the isolation of the virus and its growth in cell culture using blood plasma; this can take one to four weeks.
Serologically, an enzyme linked immunosorbent assay during the acute phase of the disease using specific IgM against yellow fever or an increase in specific IgG-titer (compared to an earlier sample) can confirm yellow fever. Together with clinical symptoms, the detection of IgM or a fourfold increase in IgG-titer is considered sufficient indication for yellow fever. Since these tests can cross-react with other flaviviruses, like dengue virus, these indirect methods cannot conclusively prove yellow fever infection.
Liver biopsy can verify inflammation and necrosis of hepatocytes and detect viral antigens. Because of the bleeding tendency of yellow fever patients, a biopsy is only advisable "post mortem" to confirm the cause of death.
In a differential diagnosis, infections with yellow fever must be distinguished from other feverish illnesses like malaria. Other viral hemorrhagic fevers, such as Ebola virus, Lassa virus, Marburg virus, and Junin virus, must be excluded as cause.
Prevention.
Personal prevention of yellow fever includes vaccination, as well as avoidance of mosquito bites in areas where yellow fever is endemic. Institutional measures for prevention of yellow fever include vaccination programmes and measures of controlling mosquitoes. Programmes for distribution of mosquito nets for use in homes are providing reductions in cases of both malaria and yellow fever.
Vaccination.
Vaccination is recommended for those traveling to affected areas, because non-native people tend to suffer more severe illness when infected. Protection begins by the 10th day after vaccine administration in 95% of people, and lasts for at least 10 years. About 81% of people are still immune after 30 years. The attenuated live vaccine stem 17D was developed in 1937 by Max Theiler. The World Health Organization (WHO) recommends routine vaccinations for people living in affected areas between the ninth and 12th month after birth. Up to one in four people experience fever, aches, and local soreness and redness at the site of injection.
In rare cases (less than one in 200,000 to 300,000), the vaccination can cause yellow fever vaccine-associated viscerotropic disease, which is fatal in 60% of cases. It is probably due to the genetic morphology of the immune system. Another possible side effect is an infection of the nervous system, which occurs in one in 200,000 to 300,000 cases, causing yellow fever vaccine-associated neurotropic disease, which can lead to meningoencephalitis and is fatal in less than 5% of cases.
In 2009, the largest mass vaccination against yellow fever began in West Africa, specifically Benin, Liberia, and Sierra Leone. When it is completed in 2015, more than 12 million people will have been vaccinated against the disease. According to the WHO, the mass vaccination cannot eliminate yellow fever because of the vast number of infected mosquitoes in urban areas of the target countries, but it will significantly reduce the number of people infected. The WHO plans to continue the vaccination campaign in another five African countries — the Central African Republic, Ghana, Guinea, Côte d'Ivoire, and Nigeria — and stated that about 160 million people in the continent could be at risk unless the organization acquires additional funding to support widespread vaccinations.
In 2013, the WHO stated, "a single dose of vaccination is sufficient to confer life-long immunity against yellow fever disease."
Compulsory vaccination.
Some countries in Asia are theoretically in danger of yellow fever epidemics (mosquitoes with the capability to transmit yellow fever and susceptible monkeys are present), although the disease does not yet occur there. To prevent introduction of the virus, some countries demand previous vaccination of foreign visitors if they have passed through yellow fever areas. Vaccination has to be proven in a vaccination certificate which is valid 10 days after the vaccination and lasts for 10 years. A list of the countries that require yellow fever vaccination is published by the WHO. If the vaccination cannot be conducted for some reasons, dispensation may be possible. In this case, an exemption certificate issued by a WHO-approved vaccination center is required. Although 32 of 44 countries where yellow fever occurs endemically do have vaccination programmes, in many of these countries, less than 50% of their population is vaccinated.
Vector control.
Control of the yellow fever mosquito "A. aegypti" is of major importance, especially because the same mosquito can also transmit dengue fever and chikungunya disease. "A. aegypti" breeds preferentially in water, for example in installations by inhabitants of areas with precarious drinking water supply, or in domestic waste; especially tires, cans, and plastic bottles. These conditions are common in urban areas in developing countries.
Two main strategies are employed to reduce mosquito populations. One approach is to kill the developing larvae. Measures are taken to reduce the water accumulations in which the larva develops. Larvicides are used, as well as larvae-eating fish and copepods, which reduce the number of larvae. For many years, copepods of the genus "Mesocyclops" have been used in Vietnam for preventing dengue fever. It eradicated the mosquito vector in several areas. Similar efforts may be effective against yellow fever. Pyriproxyfen is recommended as a chemical larvicide, mainly because it is safe for humans and effective even in small doses.
The second strategy is to reduce populations of the adult yellow fever mosquito. Lethal ovitraps can reduce "Aedes" populations, but with a decreased amount of pesticide because it targets the mosquitoes directly. Curtains and lids of water tanks can be sprayed with insecticides, but application inside houses is not recommended by the WHO. Insecticide-treated mosquito nets are effective, just as they are against the "Anopheles" mosquito that carries malaria.
Treatment.
As for other flavivirus infections, no cure is known for yellow fever. Hospitalization is advisable and intensive care may be necessary because of rapid deterioration in some cases. Different methods for acute treatment of the disease have been shown to not be very successful; passive immunisation after emergence of symptoms is probably without effect. Ribavirin and other antiviral drugs, as well as treatment with interferons, do not have a positive effect in patients.
A symptomatic treatment includes rehydration and pain relief with drugs such as paracetamol (acetaminophen in the United States). Acetylsalicylic acid (aspirin) should not be given because of its anticoagulant effect, which can be devastating in the case of internal bleeding that can occur with yellow fever.
Epidemiology.
Yellow fever is common in tropical and subtropical areas of South America and Africa. Though the main vector ("A. aegypti") also occurs in tropical and subtropical regions of Asia, the Pacific and Australia, yellow fever does not occur in these parts of the globe.
Proposed explanations include the idea that the strains of the mosquito in the East are less able to transmit the yellow fever virus, that immunity is present in the populations because of other diseases caused by related viruses (for example, dengue), and that the disease was never introduced because the shipping trade was insufficient, but none are considered satisfactory. Another proposal is the absence of a slave trade to Asia on the scale of that to the Americas. The trans-Atlantic slave trade was probably the means of introduction into the Western hemisphere from Africa.
Worldwide, about 600 million people live in endemic areas. The WHO estimates 200,000 cases of disease and 30,000 deaths a year occur; the number of officially reported cases is far lower. An estimated 90% of the infections occur on the African continent. In 2008, the largest number of recorded cases were in Togo.
Phylogenetic analysis identified seven genotypes of yellow fever viruses, and they are assumed to be differently adapted to humans and to the vector "A. aegypti". Five genotypes (Angola, Central/East Africa, East Africa, West Africa I, and West Africa II) occur only in Africa. West Africa genotype I is found in Nigeria and the surrounding areas. This appears to be especially virulent or infectious, as this type is often associated with major outbreaks. The three genotypes in East and Central Africa occur in areas where outbreaks are rare. Two recent outbreaks in Kenya (1992–1993) and Sudan (2003 and 2005) involved the East African genotype, which had remained unknown until these outbreaks occurred.
In South America, two genotypes have been identified (South American genotypes I and II). Based on phylogenetic analysis these two genotypes appear to have originated in West Africa and were first introduced into Brazil. The date of introduction into South America appears to be 1822 (95% confidence interval 1701 to 1911). The historical record shows an outbreak of yellow fever occurred in Recife, Brazil, between 1685 and 1690. The disease seems to have disappeared, with the next outbreak occurring in 1849. It was likely introduced with the importation of slaves through the slave trade from Africa. Genotype I has been divided into five subclades, A through E.
History.
The evolutionary origins of yellow fever most likely lie in Africa, with transmission of the disease from primates to human beings.
The virus is thought to have originated in East or Central Africa and spread from there to West Africa. As it was endemic in Africa, the natives had developed some immunity to it. When an outbreak of yellow fever would occur in an African village where colonists resided, most Europeans died, while the native population usually suffered nonlethal symptoms resembling influenza. This phenomenon, in which certain populations develop immunity to yellow fever due to prolonged exposure in their childhood, is known as acquired immunity. The virus, as well as the vector "A. aegypti," were probably transferred to North and South America with the importation of slaves from Africa, part of the Columbian Exchange following European exploration and colonization.
The first definitive outbreak of yellow fever in the New World was in 1647 on the island of Barbados. An outbreak was recorded by Spanish colonists in 1648 in the Yucatán, where the indigenous Mayan people called the illness "xekik" ("blood vomit"). In 1685, Brazil suffered its first epidemic, in Recife. The first mention of the disease by the name "yellow fever" occurred in 1744.
Although yellow fever is most prevalent in tropical-like climates, the northern United States were not exempted from the fever. The first outbreak in English-speaking North America occurred in New York in 1668, and a serious one afflicted Philadelphia in 1793. English colonists in Philadelphia and the French in the Mississippi River Valley recorded major outbreaks in 1669, as well as those occurring later in the 18th and 19th centuries. The southern city of New Orleans was plagued with major epidemics during the 19th century, most notably in 1833 and 1853. At least 25 major outbreaks took place in the Americas during the 18th and 19th centuries, including particularly serious ones in Cartagena in 1741, Cuba in 1762 and 1900, Santo Domingo in 1803, and Memphis in 1878. Major outbreaks have also occurred in southern Europe. Gibraltar lost many to outbreaks in 1804, in 1814, and again in 1828. Barcelona suffered the loss of several thousand citizens during an outbreak in 1821. Urban epidemics continued in the United States until 1905, with the last outbreak affecting New Orleans.
Due to yellow fever, in Colonial times and during the Napoleonic Wars, the West Indies were known as a particularly dangerous posting for soldiers. Both English and French forces posted there were decimated by the "yellow jack." Wanting to regain control of the lucrative sugar trade in Saint-Domingue, and with an eye on regaining France's New World empire, Napoleon sent an army under the command of his brother-in-law to Saint-Domingue to seize control after a slave revolt. The historian J. R. McNeill asserts that yellow fever accounted for about 35,000 to 45,000 casualties of these forces during the fighting. Only one-third of the French troops survived for withdrawal and return to France. Napoleon gave up on the island, and in 1804 Haiti proclaimed its independence as the second republic in the Western Hemisphere.
The yellow fever epidemic of 1793 in Philadelphia, which was then the capital of the United States, resulted in the deaths of several thousand people, more than 9% of the population. The national government fled the city, including President George Washington. Additional yellow fever epidemics struck Philadelphia, Baltimore, and New York in the 18th and 19th centuries, and traveled along steamboat routes from New Orleans. They caused some 100,000–150,000 deaths in total.
In 1853, Cloutierville, Louisiana had a late summer outbreak of yellow fever that quickly killed 68 of the 91 inhabitants. A local doctor concluded that the infectious agents (mosquitos) arrived in a package from New Orleans. In 1858, St. Matthew's German Evangelical Lutheran Church in Charleston, South Carolina, suffered 308 yellow fever deaths, reducing the congregation by half. In 1873, Shreveport, Louisiana, lost almost a quarter of its population to yellow fever. In 1878, about 20,000 people died in a widespread epidemic in the Mississippi River Valley. That year, Memphis had an unusually large amount of rain, which led to an increase in the mosquito population. The result was a huge epidemic of yellow fever. The steamship "John D. Porter" took people fleeing Memphis northward in hopes of escaping the disease, but passengers were not allowed to disembark due to concerns of spreading yellow fever. The ship roamed the Mississippi River for the next two months before unloading her passengers. The last major U.S. outbreak was in 1905 in New Orleans.
Ezekiel Stone Wiggins, known as the Ottawa Prophet, proposed that the cause of a yellow fever epidemic in Jacksonville, Florida, in 1888, was astronomical.
The planets were in the same line as the sun and earth and this produced, besides Cyclones, Earthquakes, etc., a denser atmosphere holding more carbon and creating microbes. Mars had an uncommonly dense atmosphere, but its inhabitants were probably protected from the fever by their newly discovered canals, which were perhaps made to absorb carbon and prevent the disease.
Carlos Finlay, a Cuban doctor and scientist, first proposed in 1881 that yellow fever might be transmitted by mosquitoes rather than direct human contact. Since the losses from yellow fever in the Spanish–American War in the 1890s were extremely high, Army doctors began research experiments with a team led by Walter Reed, composed of doctors James Carroll, Aristides Agramonte, and Jesse William Lazear. They successfully proved Finlay's ″mosquito hypothesis″. Yellow fever was the first virus shown to be transmitted by mosquitoes. The physician William Gorgas applied these insights and eradicated yellow fever from Havana. He also campaigned against yellow fever during the construction of the Panama Canal, after a previous effort on the part of the French failed (in part due to mortality from the high incidence of yellow fever and malaria, which decimated the workers).
Although Dr. Reed has received much of the credit in United States history books for "beating" yellow fever, he had fully credited Dr. Finlay with the discovery of the yellow fever vector, and how it might be controlled. Dr. Reed often cited Finlay's papers in his own articles, and also gave him credit for the discovery in his personal correspondence. The acceptance of Finlay's work was one of the most important and far-reaching effects of the Walter Reed Commission of 1900. Applying methods first suggested by Finlay, the United States government and Army eradicated yellow fever in Cuba and later in Panama, allowing completion of the Panama Canal. While Dr. Reed built on the research of Carlos Finlay, historian François Delaporte notes that yellow fever research was a contentious issue. Scientists, including Finlay and Reed, became successful by building on the work of less prominent scientists, without always giving them the credit they were due. Dr. Reed's research was essential in the fight against yellow fever. He should also receive full credit for his use of the first type of medical consent form during his experiments in Cuba, an attempt to ensure that participants knew they were taking a risk by being part of testing.
During 1920–1923, the Rockefeller Foundation’s International Health Board (IHB) undertook an expensive and successful yellow fever eradication campaign in Mexico. The IHB gained the respect of Mexico’s federal government because of the success. The eradication of yellow fever strengthened the relationship between the US and Mexico, which had not been very good in the past. The eradication of yellow fever was also a major step toward better global health.
In 1927, scientists isolated the yellow fever virus in West Africa. Following this, two vaccines were developed in the 1930s. The vaccine 17D was developed by the South African microbiologist Max Theiler at the Rockefeller Institute in New York City. This vaccine was widely used by the U.S. Army during World War II. Following the work of Ernest Goodpasture, Theiler used chicken eggs to culture the virus and won a Nobel Prize in 1951 for this achievement. A French team developed the French neurotropic vaccine (FNV), which was extracted from mouse brain tissue. Since this vaccine was associated with a higher incidence of encephalitis, FNV was not recommended after 1961. 17D is still in use and more than 400 million doses have been distributed. Little research has been done to develop new vaccines. Some researchers worry that the 60-year-old technology for vaccine production may be too slow to stop a major new yellow fever epidemic. Newer vaccines, based on vero cells, are in development and should replace 17D at some point.
Using vector control and strict vaccination programs, the urban cycle of yellow fever was nearly eradicated from South America. Since 1943, only a single urban outbreak in Santa Cruz de la Sierra, Bolivia, has occurred. But, since the 1980s, the number of yellow fever cases has been increasing again, and "A. aegypti" has returned to the urban centers of South America. This is partly due to limitations on available insecticides, as well as habitat dislocations caused by climate change. It is also because the vector control program was abandoned. Although no new urban cycle has yet been established, scientists believe this could happen again at any point. An outbreak in Paraguay in 2008 was thought to be urban in nature, but this ultimately proved not to be the case.
In Africa, virus eradication programs have mostly relied upon vaccination. These programs have largely been unsuccessful because they were unable to break the sylvatic cycle involving wild primates. With few countries establishing regular vaccination programs, measures to fight yellow fever have been neglected, making the future spread of the virus more likely.
Research.
In the hamster model of yellow fever, early administration of the antiviral ribavirin is an effective early treatment of many pathological features of the disease. Ribavirin treatment during the first five days after virus infection improved survival rates, reduced tissue damage in the liver and spleen, prevented hepatocellular steatosis, and normalised levels of alanine aminotransferase, a liver damage marker. The mechanism of action of ribavirin in reducing liver pathology in yellow fever virus infection may be similar to its activity in treatment of hepatitis C, a related virus. Because ribavirin had failed to improve survival in a virulent rhesus model of yellow fever infection, it had been previously discounted as a possible therapy.
In the past, yellow fever has been researched by several countries as a potential biological weapon.
Further reading.
</dl>

</doc>
<doc id="34257" url="http://en.wikipedia.org/wiki?curid=34257" title="Yahweh">
Yahweh

Yahweh (, or often in English; Hebrew: יהוה‎), was the national god of the Kingdom of Israel and the Kingdom of Judah, and appears to have been unique to those two kingdoms. His origins are debated but there is widespread acceptance that he did not originate with Israel. His name may have begun as an epithet of El, head of the Bronze Age Canaanite pantheon, but the earliest plausible references to it place him among the nomads of the southern Transjordan.
In the oldest biblical literature Yahweh is a typical ancient Near Eastern "divine warrior" who leads the heavenly army against Israel's enemies. He became the main god of the northern Kingdom of Israel and patron of its royal dynasty. Over time, Yahwism became increasingly intolerant of rivals, and the royal court and temple promoted Yahweh as the god of the entire cosmos, possessing all the positive qualities previously attributed to the other gods and goddesses. With the work of Second Isaiah (the theoretical author of the second part of the Book of Isaiah) towards the end of the Babylonian exile (6th century BC), the very existence of foreign gods was denied, and Yahweh was proclaimed as the creator of the cosmos and the true god of all the world.
Origins.
Two theories have been proposed to explain the origin of Yahweh, the first that his name was a title for El, the head of the Canaanite pantheon ("el dū yahwī ṣaba’ôt", "El who creates the hosts", meaning the heavenly army accompanying El as he marched beside the earthly armies of Israel), the second that El and Yahweh were originally separate gods who merged gradually. Support for the first hypothesis comes from the fact that Yahweh and El share many features, while evidence for the second includes, among many other points, the fact that although El and Yahweh have much in common they also have many differences, notably that while El's home was in the north, Yahweh's is always described as being in the south. Further support for the southern hypothesis comes from Egyptian inscriptions that mention a "land of the Shasu Yahu", the Shasu being nomads from the region of Midian and Edom and Yahu (or more accurately, YHW) a place name; there is considerable acceptance among scholars that YHW refers to the name Yahweh. 
If Yahweh originated in regions south of Israel, the question that arises is how he made his way to the north. A widely accepted hypothesis (called the Kenite hypothesis, after one of the groups involved) is that traders brought Yahweh to Israel along the caravan routes between Egypt and Canaan. The strength of this hypothesis is the way it ties together various points of data, such as the absence of Yahweh from Canaan, his links with Edom and Midian in the biblical stories, and the Kenite or Midianite ties of Moses.
Yahweh and the gods of Canaan.
Scholars agree that the Israelite community arose peacefully and internally in the highlands of Canaan–in the words of archaeologist William Dever, "most of those who came to call themselves Israelites … were or had been indigenous Canaanites"– and that Israelite religion accordingly emerged gradually from a Canaanite milieu. 
El, not Yahweh, was the original "God of Israel"–the word "Israel" is based on the name El rather than Yahweh. He was the chief of the Canaanite gods, described as "the kind, the compassionate," "the creator of creatures". He lived in a tent on a mountain from whose base originated all the fresh waters of the world, from where he presided over the Assembly of the Gods with the goddess Asherah as his consort. The pair made up the top tier of the Canaanite pantheon; the second tier was made up of their children, the "seventy sons of Athirat" (another name of Asherah). Prominent in this group was Baal, with his home on Mount Zaphon; he gradually became the dominant deity, so that El became the executive power and Baal the military power in the cosmos. Baal's sphere was the thunderstorm with its life-giving rains, so that he was also a fertility god, although not quite "the" fertility god. The third tier was made up of comparatively minor craftsman and trader deities, and the fourth and final tier of divine messengers and the like. Yahweh, the southern warrior-god, joined the pantheon headed by El and in time he and El were identified, with El's name becoming a generic term for "god". Each member of the divine council had a human nation under his care, and a textual variant of Deuteronomy 32:8–9 describes the sons of El, including Yahweh, each receiving his own people:
Yahwism in Israel (Samaria) and Judah, c.930–580 BCE.
Yahweh as national god (God of Israel).
Israel emerges into the historical record in the last decades of the 13th century BCE, at the very end of the Late Bronze Age, as the Cannanite city-state system was ending. By the 9th century BCE a new system of nation-states was forming (Israel, Judah, Moab, Ammon and others), marked by, among other things, the emergence of national gods. What distinguished Israel from other emerging Iron Age Canaanite societies was its elevation of Yahweh as the national god, rather than, for example, Chemosh, the god of Moab, or Moloch, the god of the Ammonites.
According to the Hebrew Bible Israel began in the 10th century as a united kingdom ruled by David and his son Solomon before splitting into the two separate states of Judah and Israel. Since the 1980s scholars have reassessed this picture and now believe that a significant northern kingdom emerged only in the 9th century BCE, while Judah emerged as a state only in the 8th.
Israel was as one of a number of regional kingdoms which crystallised along the trade route between Egypt and Mesopotamia at the close of the Bronze Age, all of which seem to have adopted a national god. The gods came to represent their nations, and stood more or less equal to each other–Chemosh, for example, represented Moab just as Yahweh represented Israel. The idea that the worship of Yahweh as national god played a key role in the formation of the monarchic state remains common among scholars, but the evidence is in fact slender—for example, none of the patriarchs, tribes, or early kings has a name based on Yahweh. We do not know what god the earliest kings worshiped, but from the mid-9th century the court cult in Israel (meaning the northern kingdom) was definitely linked to Yahweh, and same applied to Judah from the time of king Jehoshaphat, a close ally of the king of Israel.
It was in Samaria that Yahweh had the title "God of Israel"–no "God of Judah" is mentioned anywhere in the Bible– and the name "Israel" appears to have taken on an ideological role in Judah after the fall of Samaria to the Assyrians in c.720 BCE, with Judah cast as the "true" Israel.
The emergence of the monarchic state involved the concentration of power through kingship. The king used national religion to exert his authority, and as head of the state was also the head of the national religion and God's viceroy on Earth.
Worship (temples, sacrifice, etc).
The Hebrew Bible gives the impression that the temple in Jerusalem was the most important or even sole temple of Yahweh, but this was not the case. The earliest known Israelite place of worship is a 12th-century open-air altar in the hills of Samaria featuring a bronze bull reminiscent of Canaanite Bull El. The archaeological remains of further temples have been found at Dan on Israel's northern border, at Arad in the Negev, and at Beersheba (both in the territory of Judah), and the evidence of the Biblical texts indicates that Shiloh, Bethel, Gilgal, Mizpah, Ramah and Dan were major sites for festivals, sacrifices, making of vows, private rituals and the adjudication of legal disputes.
The centre of Yahweh's worship lay in three great annual festivals, all coinciding with major events in rural life: Passover with the birthing of lambs, Shavuot with the cereal harvest, and Sukkot with the fruit harvest. These probably pre-dated the arrival of the Yahweh religion, but became linked to the invented national history of Israel: Passover to the exodus from Egypt, Shavuot to the law-giving at Sinai, and Sukkot to the wilderness wanderings. In the reworked religious calendar the festivals celebrated Yahweh's salvation of Israel and Israel's status as his holy people, although the earlier agricultural meaning was not entirely lost.
There was also an annual ceremony–probably at the New Year–during which Yahweh was enthroned in the Temple. 
Yahweh's worship presumably involved sacrifice, but many scholars have concluded that the rituals detailed in Leviticus 1-16, with their stress on purity and atonement, were introduced only after the Babylonian exile, and that in reality any head of a family was able to offer sacrifice as occasion demanded. (A number of scholars have also drawn the conclusion that infant sacrifice, whether to the underworld deity Molech or to Yahweh himself, was a part of Israelite/Judahite religion until the reforms of King Josiah in the late 7th century BCE). Sacrifice was presumably complemented by the singing or recital of psalms on occasions varying from royal and public to communal and personal, but again the details are scant. Prayer played little role in official worship.
Relationship to other gods and goddesses.
The Hebrew Bible provides evidence that many gods other than Yahweh were worshiped in Israel and Judah–for example, when King Josiah reformed Jerusalem's religious practice in the late 7th century, places of worship for other gods around Jerusalem had to be destroyed, priests had to be stopped from burning incense to Baal and the sun and moon and the "host of heaven," and Yahweh's own temple had to be purged of Baal, Asherah, the Host of Heaven, the chariots of the sun, and more.
Yahweh and El merged at religious centres such as Shechem, Shiloh and Jerusalem, and the priesthood of Yahweh inherited the religious lore of El. Yahweh appropriated many of the older supreme god's titles such as El Shaddai (El of the Mountains) and El Elyon (El Almighty), but Yahwism did not absorb the bull cult associated with El, and the rejection of the golden calf of Aaron and the bulls of Jeroboam was fundamental to the Israelite self-understanding as expressed in the biblical scriptures.
Yahweh's appearances as a storm god owe much to Canaanite depictions of Baal. Baal and Yahweh coexisted in the early period of Israel's history, but from the 9th century they were considered irreconcilable, probably as a result of the attempts of King Ahab and Jezebel, his Phoenician queen, to elevate him in the northern kingdom.
Goddesses worshiped in Israel and Judah included Asherah, Astarte, and a deity called the Queen of Heaven, who was probably a fusion of Astarte and the Mesopotamian goddess Ishtar. Evidence increasingly suggests Asherah, formerly the wife of El, was worshiped as Yahweh's consort, and various biblical passages indicate that her statues were kept in his temples in Jerusalem, Bethel, and Samaria. Yahweh may also have appropriated Anat, the wife of Baal, as his consort, as Anat-Yahu ("Anat of Yahu," i.e., Yahweh) is mentioned in 5th century records from the Jewish colony at Elephantine in Egypt.
There is evidence also of the worship of further gods and goddesses from the Canaanite pantheon, such as the "Queen of Heaven" mentioned in Jeremiah who might be Astarte (also known as Ishtar, Both the archaeological evidence and the biblical texts document tensions between groups comfortable with the worship of Yahweh alongside local deities such as Asherah and Baal and those insistent on worship of Yahweh alone during the monarchical period (1 Kings 18, Jeremiah 2) The Deuteronomistic source gives evidence of a strong monotheistic party during the reign of king Josiah during the late 7th century BCE, but the strength and prevalence of earlier monotheistic worship of Yahweh is widely debated based on interpretations of how much of the Deuteronomistic history is accurately based on earlier sources, and how much Deuteronomistic redactors have re-worked that history to bolster their own theological views. The archaeological record documents widespread polytheism in and around Israel during the period of the monarchy.
Traditional scholarship distinguished "orthodox Yahwism"–the worship of Yahweh alone by the elite–from heterodox popular and family religion, but there was in fact no authority deciding what was orthodox and what was not, and Yahweh was probably only one among many objects of veneration. Orthodox or "normative" Yahwism did not exist in either Israel or Judah for most of the monarchical period.
Yahweh and the rise of monotheism.
Scholars agree that Israelite monotheism was the culmination of a unique set of historical circumstances. Pre-exilic Israel, like its neighbours, was polytheistic; the worship of Yahweh alone began at the earliest with Elijah in the 9th century BCE, but more likely with the prophet Hosea in the 8th; even then it remained the concern of a small opposition party, with the brief exception of a period of royal support under King Josiah, before gaining the ascendancy in the exilic and early post-exilic period.
The process by which this came about might be described as follows: In the early tribal period each tribe would have had its own patron god; the emergence of the state led to the promotion of Yahweh as the "God of Israel," supreme over the other gods; gradually further concepts emerged, including that of the divine covenant between Yahweh and the state, while Yahweh absorbed all the positive traits of the other gods and goddesses; finally, in the national crisis of the exile, the very existence of other gods was denied.
Closely linked with Israelite monotheism is the concept of aniconism, the idea that idols are useless inanimate objects. Since the late 1980s there has been a major shift in the scholarly consensus on when and how this tradition arose in Israel.
Everything in the moral realm was understood in relation to Yahweh as a manifestation of holiness. Divine law protected family relationships and the welfare of the weaker members of society; purity of conduct, dress, food, etc. were regulated. Religious leadership resided in priests who were associated with sanctuaries, and also in prophets, who were bearers of divine oracles. In the political sphere the king was understood as the appointee and agent of Yahweh.
The fifth century Elephantine papyri were written by a group of Egyptian Jews living at Elephantine near the Nubian border, and witness a religion that has been described as "nearly identical to Iron Age II Judahite religion". The papyri describe these Jews as worshiping Anat-Yahu (or AnatYahu), either the wife of Yahweh or as a hypostatized aspect of the god. "Even in exile and beyond, the veneration of a female deity endured."

</doc>
