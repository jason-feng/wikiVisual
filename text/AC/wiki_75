<doc id="37753" url="http://en.wikipedia.org/wiki?curid=37753" title="Isis">
Isis

Isis (; Ancient Greek: Ἶσις ]; original Egyptian pronunciation more likely "Aset" or "Iset") is a goddess from the polytheistic pantheon of Egypt. She was first worshiped in Ancient Egyptian religion, and later her worship spread throughout the Roman empire and the greater Greco-Roman world. Isis is still widely worshiped by many pagans today in diverse religious contexts; including a number of distinct pagan religions, the modern Goddess movement, and interfaith organizations such as the Fellowship of Isis.
Isis was worshipped as the ideal mother and wife as well as the patroness of nature and magic. She was the friend of slaves, sinners, artisans and the downtrodden, but she also listened to the prayers of the wealthy, maidens, aristocrats and rulers. Isis is often depicted as the mother of Horus, the falcon-headed deity associated with king and kingship (although in some traditions Horus's mother was Hathor). Isis is also known as protector of the dead and goddess of children.
The name Isis means "Throne". Her headdress is a throne. As the personification of the throne, she was an important representation of the pharaoh's power. The pharaoh was depicted as her child, who sat on the throne she provided. Her cult was popular throughout Egypt, but her most important temples were at Behbeit El-Hagar in the Nile delta, and, beginning in the reign with Nectanebo I (380–362 BCE), on the island of Philae in Upper Egypt.
In the typical form of her myth, Isis was the first daughter of Geb, god of the Earth, and Nut, goddess of the Sky, and she was born on the fourth intercalary day. She married her brother, Osiris, and she conceived Horus with him. Isis was instrumental in the resurrection of Osiris when he was murdered by Set. Using her magical skills, she restored his body to life after having gathered the body parts that had been strewn about the earth by Set.
This myth became very important during the Greco-Roman period. For example it was believed that the Nile River flooded every year because of the tears of sorrow which Isis wept for Osiris. Osiris's death and rebirth was relived each year through rituals. The worship of Isis eventually spread throughout the Greco-Roman world, continuing until the suppression of paganism in the Christian era. The popular motif of Isis suckling her son Horus, however, lived on in a Christianized context as the popular image of Mary suckling her infant son Jesus from the fifth century onward.
Etymology.
The Greek name version of Isis is surprisingly close to her original, Egyptian name spelling (namely "Aset"). Isis' name was originally written with the signs of a throne seat (Gardiner sign "Q1", pronounced "as" or "is"), a bread loaf (Gardiner sign "X1", pronounced "t" or "tj") and with an unpronounced determinative of a sitting woman. A second version of the original was also written with the throne seat and the bread loaf, but ended with an egg symbol (Gardiner sign "H8") which was normally read "set", but here it was used as a determinative to promote the correct reading. The grammar, spelling and used signs of Isis' name never changed during time in any way, making it easy to recognize her any time.
However, the symbolic and metaphoric meaning of Isis' name remains unclear. The throne seat sign in her name might point to a functional role as a goddess of kingship, as the maternal protector of the ruling king. Thus, her name could mean "she of the kings' throne". But all other Egyptian deities have names that point to clear cosmological or nature elemental roles ("Râ" = the sun; "Ma'at" = justice and world order), thus the name of Isis shouldn't be connected to the king himself. The throne seat symbol might alternatively point to a meaning as "throne-mother of the gods", making her the highest and most powerful goddess before all other gods. This in turn would supply a very old existence of Isis, long before her first mentioning during the late Old Kingdom, but this hypothesis remains unproven. A third possible meaning might be hidden in the egg-symbol, that was also used in Isis' name. The egg-symbol always represented motherhood, implying a maternal role of Isis. Her name could mean "mother goddess", pointing to her later, mythological role as the mother of Horus. But this remains problematic, too: the initial mother-goddess of Horus was Hathor, not Isis.
Principal features of the cult.
Origins.
Most Egyptian deities were first worshipped by very local cults, and they retained those local centres of worship even as their popularity spread, so that most major cities and towns in Egypt were known as the home of a particular deity. However, the origins of the cult of Isis are very uncertain. In fact, Egyptologists such as Maria Münster and Jan Assmann point to the lack of archaeological evidences for a goddess 'Isis' before the time of the late Old Kingdom of Egypt.
The first secure references to Isis date back to the 5th dynasty, when her name appears in the sun temple of king Niuserre and on the statue of a priest named "Pepi-Ankh", who worshipped at the very beginning of 6th dynasty and bore the title "high priest of Isis and Hathor".
Also, according to Veronica Ions book "Egyptian Mythology" from 1981 on page 56, "Isis (or Eset) was also originally an independent and popular deity whose
followers were established in pre- dynastic times in the northern Delta, at
Sebennytos."
Classical Egyptian period.
During the Old Kingdom period, Isis was represented as the wife or assistant to the deceased pharaoh. Thus she had a funerary association, her name appearing over eighty times in the pharaoh's funereal texts (the Pyramid Texts). This association with the pharaoh's wife is consistent with the role of Isis as the spouse of Horus, the god associated with the pharaoh as his protector, and then later as the deification of the pharaoh himself.
But in addition, Isis was also represented as the mother of the "four sons of Horus", the four deities who protected the canopic jars containing the pharaoh's internal organs. More specifically, Isis was viewed as the protector of the liver-jar-deity, Imsety. By the Middle Kingdom period, as the funeral texts began to be used by members of Egyptian society other than the royal family, the role of Isis as protector also grew, to include the protection of nobles and even commoners.
By the New Kingdom period, in many places, Isis was more prominent than her spouse. She was seen as the mother of the pharaoh, and was often depicted breastfeeding the pharaoh. It is theorized that this displacement happened through the merging of cults from the various cult centers as Egyptian religion became more standardized. When the cult of Ra rose to prominence, with its cult center at Heliopolis, Ra was identified with the similar deity, Horus. But Hathor had been paired with Ra in some regions, as the mother of the god. Since Isis was paired with Horus, and Horus was identified with Ra, Isis began to be merged with Hathor as "Isis-Hathor". By merging with Hathor, Isis became the mother of Horus, as well as his wife. Eventually the mother role displaced the role of spouse. Thus, the role of spouse to Isis was open and in the Heliopolis pantheon, Isis became the wife of Osiris and the mother of Horus/Ra. This reconciliation of themes led to the evolution of the myth of Isis and Osiris.
Temples and priesthood.
In Egypt, Isis would have received the same sort of rituals as other Egyptian Deities, including daily offerings. She was served by both priests and priestesses throughout the history of her cult. By the Greco-Roman era, many of her priests and priestesses had a reputation for wisdom and healing, and were said to have other special powers, including dream interpretation and the ability to control the weather, which they did by braiding or not combing their hair. The latter was believed because the Egyptians considered knots to have magical powers.
The cult of Isis and Osiris continued up until the 6th century CE on the island of Philae in Upper Nile. The Theodosian decree (about 380 CE) banning all pagan religions was not enforced there until the time of Justinian. This toleration was due to an old treaty made between the Blemyes-Nobadae and the emperor Diocletian. Every year they visited Elephantine and at certain intervals took the image of Isis up river to the land of the Blemyes for oracular purposes before returning it. Justinian sent Narses to destroy the sanctuaries, with the priests being arrested and the divine images taken to Constantinople. Philae was the last of the ancient Egyptian temples to be closed.
Iconography.
Associations.
Due to the association between knots and magical power, a symbol of Isis was the "tiet" or "tyet" (meaning "welfare"/"life"), also called the "Knot of Isis", "Buckle of Isis", or the "Blood of Isis", which is shown to the right. In many respects the "tyet" resembles an ankh, except that its arms point downward, and when used as such, seems to represent the idea of eternal life or resurrection. The meaning of "Blood of Isis" is more obscure, but the "tyet" often was used as a funerary amulet made of red wood, stone, or glass, so this may simply have been a description of the appearance of the materials used.
The star Sopdet (Sirius) is associated with Isis. The appearance of the star signified the advent of a new year and Isis was likewise considered the goddess of rebirth and reincarnation, and as a protector of the dead. The Book of the Dead outlines a particular ritual that would protect the dead, enabling travel anywhere in the underworld, and most of the titles Isis holds signify her as the goddess of protection of the dead.
Depictions.
In art, originally Isis was pictured as a woman wearing a long sheath dress and crowned with the hieroglyphic sign for a "throne". Sometimes she is depicted as holding a lotus, or, as a sycamore tree. One pharaoh, Thutmose III, is depicted in his tomb as nursing from a sycamore tree that has a breast.
After she assimilated many of the roles of Hathor, Isis's headdress was replaced with that of Hathor: the horns of a cow on her head, with the solar disk between them, and often with her original throne symbol atop the solar disk. Sometimes she also is represented as a cow, or with a cow's head. She is often depicted with her young child, Horus (the pharaoh), with a crown, and a vulture. Occasionally she is represented as a kite flying above the body of Osiris or with the dead Osiris she works her magic to bring him back to life.
Most often Isis is seen holding an ankh (the sign for "life") and a simple lotus staff, but in late images she is sometimes seen with the sacred sistrum rattle and the fertility-bearing "menat" necklace, items usually associated with Hathor. In "The Book of Coming Forth By Day" Isis is depicted standing on the prow of the Solar Barque with her arms outstretched.
Mythology.
Sister-wife to Osiris.
During the Old Kingdom period, the pantheons of individual Egyptian cities varied by region. During the 5th dynasty, Isis entered the pantheon of the city of Heliopolis. She was represented as a daughter of Nut and Geb, and sister to Osiris, Nephthys, and Set. The two sisters, Isis and Nephthys, often were depicted on coffins, with wings outstretched, as protectors against evil. As a funerary deity, she was associated with Osiris, lord of the underworld, and was considered his wife.
A later myth, when the cult of Osiris gained more authority, tells the story of Anubis, the god of the underworld. The tale describes how Nephthys was denied a child by Set and disguised herself as her twin, Isis, to seduce him. The plot succeeded, resulting in the birth of Anubis.
In fear of Set's retribution, Nephthys persuaded Isis to adopt Anubis, so that Set would not find out and kill the child. The tale describes both why Anubis is seen as an underworld deity (he becomes the adopted son of Osiris), and why he could not inherit Osiris's position (as he was not actually the son of Osiris but of his brother Set), neatly preserving Osiris's position as lord of the underworld.
The most extensive account of the Isis-Osiris story known today is Plutarch's Greek description written in the 1st century CE, usually known under its Latin title "De Iside et Osiride".
In that version, Set held a banquet for Osiris in which he brought in a beautiful box and said that whoever could fit in the box perfectly would get to keep it. Set had measured Osiris in his sleep and made sure that he was the only one who could fit the box. Several tried to see whether they fit. Once it was Osiris's turn to see if he could fit in the box, Set closed the lid on him so that the box was now a coffin for Osiris. Set flung the box in the Nile so that it would drift far away. Isis went looking for the box so that Osiris could have a proper burial. She found the box in a tree in Byblos, a city along the Phoenician coast, and brought it back to Egypt, hiding it in a swamp. But Set went hunting that night and found the box. Enraged, Set chopped Osiris's body into fourteen pieces and scattered them all over Egypt to ensure that Isis could never find Osiris again for a proper burial.
Isis and her sister Nephthys went looking for these pieces, but could only find thirteen of the fourteen. Fish had swallowed the last piece, his phallus. With Thoth's help she created a golden phallus, and attached it to Osiris’s body. She then transformed into a kite, and with the aid of Thoth’s magic conceived Horus the Younger. The number of pieces is described on temple walls variously as fourteen and sixteen, and occasionally forty-two, one for each nome or district.
Mother/Sister of Horus.
Yet another set of late myths detail the adventures of Isis after the birth of Osiris's posthumous son, Horus. Isis was said to have given birth to Horus at Khemmis, thought to be located on the Nile Delta. Many dangers faced Horus after birth, and Isis fled with the newborn to escape the wrath of Set, the murderer of her husband. In one instance, Isis heals Horus from a lethal scorpion sting; she also performs other miracles in relation to the "cippi", or the plaques of Horus. Isis protected and raised Horus until he was old enough to face Set, and subsequently become the pharaoh of Egypt. In some stories. Isis is referred to as Horus' sister.
Magic.
It was said that Isis tricked Ra into telling her his "secret name" by causing a snake to bite him, the antidote to whose venom only Isis possessed. Knowing his secret name thus gave her power over him. The use of secret names became central in many late Egyptian magic spells. By the late Egyptian historical period, after the occupations by the Greeks and the Romans, Isis became the most important and most powerful deity of the Egyptian pantheon because of her magical skills. Magic is central to the entire mythology of Isis, arguably more so than any other Egyptian deity.
Isis had a central role in Egyptian magic spells and ritual, especially those of protection and healing. In many spells her powers are merged with those of her son Horus. His power accompanies hers whenever she is invoked. In Egyptian history the image of a wounded Horus became a standard feature of Isis's healing spells, which typically invoked the curative powers of Isis' milk.
Greco-Roman world.
"Interpretatio graeca".
Using the comparative methodology known as "interpretatio graeca", the Greek historian Herodotus (5th century BCE) described Isis by comparison with the Greek goddess Demeter, whose mysteries at Eleusis offered initiates guidance in the afterlife and a vision of rebirth. Herodotus says that Isis was the only goddess worshiped by all Egyptians alike.
After the conquest of Egypt by Alexander the Great and the Hellenization of the Egyptian culture initiated by Ptolemy I Soter, Isis became known as "Queen of Heaven". Other Mediterranean goddesses, such as Demeter, Astarte, and Aphrodite, became identified with Isis, as did the Arabian goddess Al-‘Uzzá through a similarity of name, since etymology was thought to reveal the essential or primordial nature of the thing named. An alabaster statue of Isis from the 3rd century BCE, found in Ohrid, in the Republic of Macedonia, is depicted on the obverse of the Macedonian 10 denar banknote, issued in 1996.
Isis in the Roman Empire.
Tacitus writes that after the assassination of Julius Caesar, a temple in honour of Isis had been decreed, but was suspended by Augustus as part of his program to restore traditional Roman religion. The emperor Caligula, however, was open to Eastern religions, and the "Navigium Isidis", a procession in honor of Isis, was established in Rome during his reign. According to the Jewish historian Josephus, Caligula donned female garb and took part in the mysteries he instituted. Vespasian, along with Titus, practised incubation in the Roman Iseum. Domitian built another Iseum along with a Serapeum. In a relief on the Arch of Trajan in Rome, the emperor appears before Isis and Horus, presenting them with votive offerings of wine. Hadrian decorated his villa at Tibur with Isiac scenes. Galerius regarded Isis as his protector.
The religion of Isis thus spread throughout the Roman Empire during the formative centuries of Christianity. Wall paintings and objects reveal her pervasive presence at Pompeii, preserved by the eruption of Vesuvius in 79 CE. In Rome, temples were built and obelisks erected in her honour. In Greece, the cult of Isis was introduced to traditional centres of worship in Delos, Delphi, Eleusis and Athens, as well as in northern Greece. Harbours of Isis were to be found on the Arabian Sea and the Black Sea. Inscriptions show followers in Gaul, Spain, Pannonia, Germany, Arabia, Asia Minor, Portugal and many shrines even in Britain. Tacitus interprets a goddess among the Germanic Suebi as a form of Isis whose symbol "(signum)" was a ship. Bruce Lincoln regards the identity of this Germanic goddess as "elusive."
The Greek antiquarian Plutarch wrote a treatise on "Isis and Osiris", a major source for Imperial theology concerning Isis. Plutarch describes Isis as "a goddess exceptionally wise and a lover of wisdom, to whom, as her name at least seems to indicate, knowledge and understanding are in the highest degree appropriate... ." The statue of Athena in Sais was identified with Isis, and according to Plutarch was inscribed "I am all that has been, and is, and shall be, and my robe no mortal has yet uncovered." At Sais, however, the patron goddess of the ancient cult was Neith, many of whose traits had begun to be attributed to Isis during the Greek occupation.
The Roman writer Apuleius recorded aspects of the cult of Isis in the 2nd century CE, including the "Navigium Isidis," in his novel "The Golden Ass". The protagonist Lucius prays to Isis as "Regina Caeli", "Queen of Heaven":
You see me here, Lucius, in answer to your prayer. I am nature, the universal Mother, mistress of all the elements, primordial child of time, sovereign of all things spiritual, queen of the dead, queen of the ocean, queen also of the immortals, the single manifestation of all gods and goddesses that are, my nod governs the shining heights of Heavens, the wholesome sea breezes. Though I am worshipped in many aspects, known by countless names ... the Egyptians who excel in ancient learning and worship call me by my true name...Queen Isis.
According to Apuleius, these other names include manifestations of the goddess as Ceres, "the original nurturing parent"; Heavenly Venus "(Venus Caelestis)"; the "sister of Phoebus", that is, Diana or Artemis as she is worshipped at Ephesus; or Proserpina (Greek Persephone) as the triple goddess of the underworld. From the middle Imperial period, the title "Caelestis", "Heavenly" or "Celestial", is attached to several goddesses embodying aspects of a single, supreme Heavenly Goddess. The "Dea Caelestis" was identified with the constellation Virgo (the Virgin), who holds the divine balance of justice.
Greco-Roman temples.
On the Greek island of Delos a Doric Temple of Isis was built on a high over-looking hill at the beginning of the Roman period to venerate the familiar trinity of Isis, the Alexandrian Serapis and Harpocrates. The creation of this temple is significant as Delos is particularly known as the birthplace of the Greek gods Artemis and Apollo who had temples of their own on the island long before the temple to Isis was built.
In the Roman Empire, a well-preserved example was discovered in Pompeii. The only sanctuary of Isis "(fanum Isidis") identified with certainty in Roman Britain is located in Londinium (present-day London).
Late antiquity.
The cult of Isis was part of the syncretic tendencies of religion in the Greco-Roman world of late antiquity. The names Isidoros and Isidora in Greek mean "gift of Isis" (similar to "Theodoros", "God's gift").
The sacred image of Isis with the Horus Child in Rome often became a model for the Christian Mary carrying her child Jesus and many of the epithets of the Egyptian Mother of God came to be used for her.

</doc>
<doc id="37754" url="http://en.wikipedia.org/wiki?curid=37754" title="Mountain">
Mountain

A mountain is a large landform that stretches above the surrounding land in a limited area, usually in the form of a peak. A mountain is generally steeper than a hill. Mountains are formed through tectonic forces or volcanism. These forces can locally raise the surface of the earth. Mountains erode slowly through the action of rivers, weather conditions, and glaciers. A few mountains are isolated summits, but most occur in huge mountain ranges.
High elevations on mountains produce colder climates than at sea level. These colder climates strongly affect the ecosystems of mountains: different elevations have different plants and animals. Because of the less hospitable terrain and climate, mountains tend to be used less for agriculture and more for resource extraction and recreation, such as mountain climbing.
The highest mountain on Earth is Mount Everest in the Himalayas of Asia, whose summit is 8850 m above mean sea level. The highest known mountain on any planet in the Solar System is Olympus Mons on Mars at 21171 m.
Definition.
There is no universally accepted definition of a mountain. Elevation, volume, relief, steepness, spacing and continuity have been used as criteria for defining a mountain. In the Oxford English Dictionary a mountain is defined as "a natural elevation of the earth surface rising more or less abruptly from the surrounding level and attaining an altitude which, relatively to the adjacent elevation, is impressive or notable."
Whether a landform is called a mountain may depend on local usage. The highest point in San Francisco, California, is called Mount Davidson, notwithstanding its height of 300 m, which makes it twenty feet short of the minimum for a mountain by American designations. Similarly, Mount Scott outside Lawton, Oklahoma is only 251 m from its base to its highest point. Whittow's "Dictionary of Physical Geography" states "Some authorities regard eminences above 600 m (2,000 ft) as mountains, those below being referred to as hills."
In the United Kingdom and the Irish Republic, a mountain is usually defined as any summit at least 2,000 feet (or 610 metres) high, whilst the official United Kingdom government's definition of a mountain, for the purposes of access, is a summit of 600 metres or higher. In addition, some definitions also include a topographical prominence requirement, typically 100 or. For a while, the US defined a mountain as being 1,000 ft or taller. Any similar landform lower than this height was considered a hill. However, today, the United States Geological Survey (USGS) concludes that these terms do not have technical definitions in the US.
The UN Environmental Programme's definition of "mountainous environment" includes any of the following:
Using these definitions, mountains cover 33% of Eurasia, 19% of South America, 24% of North America, and 14% of Africa. As a whole, 24% of the Earth's land mass is mountainous.
Geology.
There are three main types of mountains: volcanic, fold, and block. All three types are formed from plate tectonics: when portions of the Earth's crust move, crumple, and dive. Compressional forces, isostatic uplift and intrusion of igneous matter forces surface rock upward, creating a landform higher than the surrounding features. The height of the feature makes it either a hill or, if higher and steeper, a mountain. Major mountains tend to occur in long linear arcs, indicating tectonic plate boundaries and activity.
Volcanoes.
Volcanoes are formed when a plate is pushed below another plate, or at a mid-ocean ridge or hotspot. At a depth of around 100 km, melting occurs in rock above the slab (due to the addition of water), and forms magma that reaches the surface. When the magma reaches the surface, it often builds a volcanic mountain, such as a shield volcano or a stratovolcano. Examples of volcanoes include Mount Fuji in Japan and Mount Pinatubo in the Philippines. The magma does not have to reach the surface in order to create a mountain: magma that solidifies below ground can still form dome mountains, such as Navajo Mountain in the United States.
Fold mountains.
Fold mountains occur when two plates collide: shortening occurs along thrust faults and the crust is overthickened. Since the less dense continental crust "floats" on the denser mantle rocks beneath, the weight of any crustal material forced upward to form hills, plateaus or mountains must be balanced by the buoyancy force of a much greater volume forced downward into the mantle. Thus the continental crust is normally much thicker under mountains, compared to lower lying areas. Rock can fold either symmetrically or asymmetrically. The upfolds are anticlines and the downfolds are synclines: in asymmetric folding there may also be recumbent and overturned folds. The Jura Mountains are an example of fold mountains.
Block mountains.
Block mountains are caused by faults in the crust: a seam where rocks can move past each other. When rocks on one side of a fault rise relative to the other, it can form a mountain. The uplifted blocks are block mountains or horsts. The intervening dropped blocks are termed graben: these can be small or form extensive rift valley systems. This form of landscape can be seen in East Africa, the Vosges, the Basin and Range province of Western North America and the Rhine valley. These areas often occur when the regional stress is extensional and the crust is thinned.
Erosion.
During and following uplift, mountains are subjected to the agents of erosion (water, wind, ice, and gravity) which gradually wear the uplifted area down. Erosion causes the surface of mountains to be younger than the rocks that form the mountains themselves. Glacial processes produce characteristic landforms, such as pyramidal peaks, knife-edge arêtes, and bowl-shaped cirques that can contain lakes. Plateau mountains, such as the Catskills, are formed from the erosion of an uplifted plateau.
Climate.
Climate on mountains become colder at high elevations, due to the way that the sun heats the surface of the Earth. The sun warms the ground directly, while the greenhouse effect acts as a blanket, reflecting heat back towards the Earth that would otherwise be lost to space. The greenhouse effect thus keeps the air at low elevations warm. As elevation increases, there is less greenhouse effect, so the ambient temperature goes down.
The rate at which the temperature drops with elevation, called the environmental lapse rate, is not constant (it can fluctuate throughout the day or seasonally and also regionally), but a typical lapse rate is 5.5°C per 1,000 m (3.57°F per 1,000 ft). Therefore, moving up 100 meters on a mountain is roughly equivalent to moving 80 kilometers (45 miles or 0.75° of latitude) towards the nearest pole. This relationship is only approximate, however, since local factors such as proximity to oceans (such as the Arctic Ocean) can drastically modify the climate. As the altitude increases, the main form of precipitation becomes snow and the winds increase.
The effect of the climate on the ecology at an elevation can be largely captured through a combination of amount of precipitation, and the biotemperature, as described by Leslie Holdridge in 1947. Biotemperature is the mean temperature; all temperatures below 0 C are considered to be 0 °C. When the temperature is below 0 °C, plants are dormant, so the exact temperature is unimportant. The peaks of mountains with permanent snow can have a biotemperature below 1.5 C.
Ecology.
The colder climate on mountains affects the plants and animals residing on mountains. A particular set of plants and animals tend to be adapted to a relatively narrow range of climate. Thus, ecosystems tend to lie along elevation bands of roughly constant climate. This is called altitudinal zonation.
In regions with dry climates, the tendency of mountains to have higher precipitation as well as lower temperatures also provides for varying conditions, which enhances zonation.
Some plants and animals found in altitudinal zones tend to become isolated since the conditions above and below a particular zone will be inhospitable and thus constrain their movements or dispersal. These isolated ecological systems are known as sky islands.
Altitudinal zones tend to follow a typical pattern. At the highest elevations, trees cannot grow, and whatever life may be present will be of the alpine type, resembling tundra. Just below the tree line, one may find subalpine forests of needleleaf trees, which can withstand cold, dry conditions. Below that, montane forests grow. In the temperate portions of the earth, those forests tend to be needleleaf trees, while in the tropics, they can be broadleaf trees growing in a rain forest.
In society.
Mountains are generally less preferable for human habitation than lowlands, because of harsh weather and little level ground suitable for agriculture. While 7% of the land area of Earth is above 2500 m, only 140 million people live above that altitude and only 20-30 million people above 3000 m elevation. The decreasing atmospheric pressure with increasing elevation means that less oxygen is available for breathing, and there is less protection against solar radiation (UV). Due to decreasing oxygen, the highest known permanent habitation in the world is at 5100 m, while the highest known permanently tolerable altitude is at 5950 m. Above 8000 m elevation, there is not enough oxygen to support human life. This is known as the "death zone". The summits of Mount Everest and K2 are in the death zone.
About half of mountain dwellers live in the Andes, Central Asia, and Africa. Traditional mountain societies rely on agriculture, with higher risk of crop failure than at lower elevations. Minerals often occur in mountains, with mining being an important component of the economics of some montane societies. More recently, tourism supports mountain communities, with some intensive development around attractions such as national parks or ski resorts. About 80% of mountain people live below the poverty line.
Most of the world's rivers are fed from mountain sources, with snow acting as a storage mechanism for downstream users. More than half of humanity depends on mountains for water.
Mountaineering, mountain climbing, or alpinism is the sport, hobby or profession of hiking, skiing, and climbing mountains. While mountaineering began as attempts to reach the highest point of unclimbed big mountains it has branched into specializations that address different aspects of the mountain and consists of three areas: rock-craft, snow-craft and skiing, depending on whether the route chosen is over rock, snow or ice. All require experience, athletic ability, and technical knowledge to maintain safety.
Superlatives.
Heights of mountains are typically measured above sea level. Using this metric, Mount Everest is the highest mountain on Earth, at 8848 m. There are at least 100 mountains with heights of over 7200 m above sea level, all of which are located in central and southern Asia. The highest mountains above sea level are generally not the highest above the surrounding terrain. There is no precise definition of surrounding base, but Mount McKinley, Mount Kilimanjaro and Nanga Parbat are possible candidates for the tallest mountain on land by this measure. The bases of mountain islands are below sea level, and given this consideration Mauna Kea (4207 m above sea level) is the world's tallest mountain and volcano, rising about 10203 m from the Pacific Ocean floor.
The highest mountains are not generally the most voluminous. Mauna Loa (4169 m) is the largest mountain on Earth in terms of base area (about 2000 sqmi) and volume (about 18000 mi3). Mount Kilimanjaro is the largest non-shield volcano in terms of both base area (245 sqmi) and volume (1150 mi3). Mount Logan is the largest non-volcanic mountain in base area (120 sqmi).
The highest mountains above sea level are also not those with peaks farthest from the centre of the Earth, because the figure of the Earth is not spherical. Sea level closer to the equator is several miles farther from the centre of the Earth. The summit of Chimborazo, Ecuador's tallest mountain, is usually considered to be the farthest point from the Earth's centre, although the southern summit of Peru's tallest mountain, Huascarán, is another contender. Both have elevations above sea level more than 2 km less than that of Everest.
References.
</dl>

</doc>
<doc id="37755" url="http://en.wikipedia.org/wiki?curid=37755" title="List of mountains">
List of mountains

This is a list of mountains around the world.
Eight-thousanders.
The 14 "eight-thousanders," 8,000 meters or higher above sea level, all in the Himalayas:
Seven Summits.
The highest mountains of each continent (the Seven Summits):
Seven Second Summits.
The second highest mountains of each continent (the Seven Second Summits), which in virtually every case are more difficult to climb than the highest peaks of each continent:
Seven Third Summits.
The third highest mountains of each continent (the Seven Third Summits):
Volcanic Seven Summits.
The highest volcanoes of each continent (the Volcanic Seven Summits):
Summits farthest from Earth's center.
Mount Everest is the point with the highest elevation above sea level on Earth, but it is not the summit that is farthest from Earth's center. Because of the equatorial bulge, the summit of Mount Chimborazo in Ecuador is the point on Earth that is farthest from the center of Earth, and is 2168 m farther from Earth's center than the summit of Everest.
By continent or area.
Asia.
Great Himalayas.
The rankings are derived from the list of highest mountains, which ranks mountains separated by 500 m of prominence. See talk page.
Iran.
Zagros Mountains
Southeast Asia.
National Record
Region
Additional
Europe.
Balkans.
"See also": List of mountains in Albania, List of mountains in Kosovo, List of mountains in Greece, Greek names of mountains, List of mountains in Bulgaria, List of mountains in the Republic of Macedonia.
Crimean Mountains.
The Crimea's highest peak is the Roman-Kosh (Ukrainian and Russian: Роман-Кош, Crimean Tatar: Roman Qoş) on the Babugan Yayla at 1,545 metres (5,069 ft). Other important peaks over 1,200 metres include:
Denmark.
Note that this list only considers Denmark as a country, Danish territories (Faroe Islands and Greenland) are not considered. Also note that the listing only considers natural formations
"Source: Kort & Matrikelstyrelsen, Faktoider.nu."
Norway.
Norway has 300 peaks above 2000 m.
"Source: nfo2000m.no."
Norway's highest mountains by Fylke
Sweden.
Sweden has 12 peaks above 2000 meters in height.
Sweden, Highest elevation per historical province:
North America.
Canada.
Notables
United States.
A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z

</doc>
<doc id="37756" url="http://en.wikipedia.org/wiki?curid=37756" title="Delhi">
Delhi

Delhi (, ] Dilli), officially the National Capital Territory of Delhi, is the Capital territory of India. It has a population of about 11 million and a metropolitan population of about 16.3 million, making it the second most populous city and second most populous urban agglomeration in India. Such is the nature of urban expansion in Delhi that its growth has expanded beyond the NCT to incorporate towns in neighbouring states and at its largest extent can count a population of about 25 million residents as of 2014.
The NCT and its urban region have been given the special status of National Capital Region (NCR) under the Constitution of India's 69th amendment act of 1991. The NCR includes the neighbouring cities of Gurgaon, Noida, Ghaziabad, Faridabad, Neharpar (Greater Faridabad), Greater Noida, Bahadurgarh, Sonepat, Panipat, Karnal, Rohtak, Bhiwani, Rewari, Baghpat, Meerut, Alwar, Bharatpur and other nearby towns. A union territory, the political administration of the NCT of Delhi today more closely resembles that of a state of India, with its own legislature, high court and an executive council of ministers headed by a Chief Minister. New Delhi is jointly administered by the federal government of India and the local government of Delhi, and is the capital of the NCT of Delhi.
Delhi has been continuously inhabited since the 6th century BC. Through most of its history, Delhi has served as a capital of various kingdoms and empires. It has been captured, ransacked and rebuilt several times, particularly during the medieval period, and modern Delhi is a cluster of a number of cities spread across the metropolitan region.
Toponymy and idioms.
There are a number of legends associated with the origin of the name "Delhi". One is that it is derived from "Dhillu" or "Dilu", a king who built a city at this location in 50 BC and named it after himself. Another legend holds that the name of the city is based on the Hindi/Prakrit word "dhili" ("loose") and that it was used by the Tomaras to refer to the city because the Iron Pillar of Delhi had a weak foundation and had to be moved. The coins in circulation in the region under the Tomaras were called "dehliwal". According to the Bhavishya Purana, King Prithiviraja,of Indraprastha built a new fort in the modern-day Purana Qila area for the convenience of all four castes in his kingdom. He ordered the construction of a gateway to the fort and later named the fort "dehali". Some historians believe that the name is derived from "Dilli", a corruption of "dehleez" or "dehali"—both terms meaning 'threshold' or 'gateway'—and symbolic of the city as a gateway to the Gangetic Plain. Another theory suggests that the city's original name was Dhillika.
The people of Delhi are referred to as "Delhiites" or "Dilliwalas". The city is referenced in various idioms of the Northern Indo-Aryan languages. Examples include:
History.
The area around Delhi was probably inhabited before the second millennium BC, and there is evidence of continuous inhabitation since at least the 6th century BC. The city is believed to be the site of Indraprastha, the legendary capital of the Pandavas in the Indian epic Mahabharata. According to this epic this land was initially a huge mass of forests called 'Kandavaprastha' which was burnt down to build the city of Indraprastha. The earliest architectural relics date back to the Maurya period (c. 300 BC); in 1966, an inscription of the Mauryan Emperor Ashoka (273–235 BC) was discovered near Srinivaspuri. Remains of eight major cities have been discovered in Delhi. The first five cities were in the southern part of present-day Delhi. Anang Pal of the Tomara dynasty founded the city of Lal Kot in AD 736. The Chauhans conquered Lal Kot in 1180 and renamed it Qila Rai Pithora.
The king Prithviraj Chauhan was defeated in 1192 by Muhammad Ghori, a Tajik invader from Afghanistan, who made a concerted effort to conquer northern India. By 1200, native Hindu resistance had begun to crumble, the dominance of foreign Turkic Muslim dynasties in India was to last for the next five centuries. On the death of Muhammad in 1206, the Turkic slave-general, Qutb-ud-din Aibak, broke away from the Ghurid Dynasty and became the first Sultan of Delhi. He began construction of the Qutb Minar and Quwwat-al-Islam (might of Islam) mosque, the earliest extant mosque in India. Qutb-ud-din faced widespread Hindu rebellions and it was his successor, Iltutmish (1211–36), who consolidated the Turkic conquest of northern India.
For the next three hundred years, Delhi was ruled by a succession of Turkic and an Afghan, Lodhi dynasty. They built a number of forts and townships that are part of the seven cities of Delhi. Delhi was a major centre of Sufism during this period. The Mamluk Sultanate (Delhi) was overthrown in 1290 by the Khilji dynasty (1290–1320). Under the second Khilji ruler, Ala-ud-din Khilji, the Delhi sultanate extended its control south of the Narmada River in the Deccan. The Delhi sultanate reached its greatest extent during the reign of Muhammad bin Tughluq (1325–1351). In an attempt to bring the whole of the Deccan under control, he moved his capital to Daulatabad, Maharashtra in central India, but by moving away from Delhi he lost control of the north and was forced to return to Delhi to restore order. The southern provinces then broke away. In the years following the reign of Firoz Shah Tughlaq (1351–1388), the Delhi sultanate rapidly began to lose its hold over its northern provinces. Delhi was captured and sacked by Timur Lenk in 1398. Near Delhi, Timur massacred 100,000 captives. Delhi's decline continued under the Sayyid dynasty (1414–1451), until the sultanate was reduced to Delhi and its hinterland. Under the Afghan Lodhi dynasty (1451–1526), the Delhi sultanate recovered control of the Punjab and the Gangetic plain to once again achieve domination over northern India. However, the recovery was short-lived and in 1526 the sultanate was destroyed by Babur, founder of the Mughal dynasty.
In 1526, Babur, a descendant of Genghis Khan and Timur, from the Fergana Valley in modern-day Uzbekistan, invaded India, defeated the last Lodhi sultan in the First Battle of Panipat and founded the Mughal Empire that ruled from Delhi and Agra. The Mughal dynasty ruled Delhi for more than three centuries, with a sixteen-year hiatus during the reign of Sher Shah Suri, from 1540 to 1556. In 1553, the Hindu king, Hemu Vikramaditya acceded to the throne of Delhi by defeating forces of Mughal Emperor Humayun at Agra and Delhi. However, the Mughals re-established their rule after Akbar's army defeated Hemu during the Second Battle of Panipat in 1556. Shah Jahan built the seventh city of Delhi that bears his name "Shahjahanabad", which served as the capital of the Mughal Empire from 1638 and is today known as the "Old City" or "Old Delhi".
After the death of Aurangzeb in 1707, the Mughal Empire's influence declined rapidly as the Hindu Maratha Empire rose to prominence. In 1737, Maratha forces sacked Delhi following their victory against the Mughals in the First Battle of Delhi. In 1739, the Mughal Empire lost the huge Battle of Karnal in less than three hours against the numerically outnumbered but military superior Persian army led by Nader Shah of Persia during his invasion after which he completely sacked and looted Delhi, the Mughal capital, carrying away immense wealth including the Peacock Throne, the Daria-i-Noor, and Koh-i-Noor. The Mughals, severely further weakened, would never overcome this crushing defeat and humiliation which would also let the way open for more invaders to come, including eventually the British. Nader eventually agreed to leave the city and India after forcing the Mughal emperor Muhammad Shah I to beg him for mercy and granting him the keys of the city and the royal treasury. A treaty signed in 1752 made Marathas the protectors of the Mughal throne in Delhi. 
In 1757, the Afghan ruler, Ahmad Shah Durrani, sacked Delhi. He returned to Afghanistan leaving a Mughal puppet ruler in nominal control. The Marathas again occupied Delhi in 1758, and were in control before their defeat in 1761 at the third battle of Panipat, and the city was captured again by Ahmad Shah. However, in 1771, the Marathas established a protectorate over Delhi when the Maratha ruler, Mahadji Shinde, recaptured Delhi and the Mughal Emperor Shah Alam II was installed as a puppet ruler in 1772. In 1783, Sikhs under Baghel Singh captured Delhi and Red Fort, however due to treaty Sikhs withdraw from Red Fort and agreed to restore Shah Alam as the emperor.In 1803, during the Second Anglo-Maratha War, the forces of British East India Company defeated the Maratha forces in the Battle of Delhi. During the Indian Rebellion of 1857, Delhi fell to the forces of East India Company after a bloody fight known as the Siege of Delhi. The city came under the direct control of the British Government in 1858. It was made a district province of the Punjab. In 1911, it was announced that the capital of British held territories in India was to be transferred from Calcutta to Delhi. The name "New Delhi" was given in 1927, and the new capital was inaugurated on 13 February 1931. New Delhi, also known as "Lutyens' Delhi", was officially declared as the capital of the Union of India after the country gained independence on 15 August 1947.
During the partition of India, thousands of Hindu and Sikh refugees, mainly from West Punjab fled to Delhi, while many Muslim residents of the city migrated to Pakistan. Migration to Delhi from the rest of India continues (as of 2013), contributing more to the rise of Delhi's population than the birth rate, which is declining.
The Constitution (Sixty-ninth Amendment) Act, 1991 declared the Union Territory of Delhi to be formally known as the National Capital Territory of Delhi. The Act gave Delhi its own legislative assembly along Civil lines, though with limited powers. In December 2001, the Parliament of India building in New Delhi was attacked by armed militants, killing six security personnel. India suspected Pakistan-based militant groups were behind the attack, which caused a major diplomatic crisis between the two countries. There were further terrorist attacks in Delhi in October 2005 and September 2008, resulting in a total of 103 deaths.
Ecology.
Delhi is located at , and lies in Northern India. It borders the Indian states of Haryana on the north, west and south and Uttar Pradesh (UP) to the east. During the British Raj, Delhi was part of the province of Punjab and is still historically and culturally connected to the Punjab region. Two prominent features of the geography of Delhi are the Yamuna flood plains and the Delhi ridge. The Yamuna river was the historical boundary between Punjab and UP, and its flood plains provide fertile alluvial soil suitable for agriculture but are prone to recurrent floods. The Yamuna, a sacred river in Hinduism, is the only major river flowing through Delhi. The Hindon River separates Ghaziabad from the eastern part of Delhi. The Delhi ridge originates from the Aravalli Range in the south and encircles the west, north-east and north-west parts of the city. It reaches a height of 318 m and is a dominant feature of the region.
The National Capital Territory of Delhi covers an area of 1484 km2, of which 783 km2 is designated rural, and 700 km2 urban therefore making it the largest city in terms of area in the country. It has a length of 51.9 km and a width of 48.48 km.
Delhi is included in India's seismic zone-IV, indicating its vulnerability to major earthquakes, but earthquakes have not been common in recent history.
Climate.
Delhi features an atypical version of the humid subtropical climate (Köppen "Cwa"). The warm season lasts from 9 April to 8 July with an average daily high temperature above 36 °C. The hottest day of the year is 22 May, with an average high of 38 °C and low of 25 °C. The cold season lasts from 11 December to 11 February with an average daily high temperature below 18 °C. The coldest day of the year is 4 January, with an average low of 2 °C and high of 15 °C. In early March, the wind direction changes from north-westerly to south-westerly. From April to October the weather is hot. The monsoon arrives at the end of June, along with an increase in humidity. The brief, mild winter starts in late November, peaks in January and heavy fog often occurs.
Temperatures in Delhi usually range from 5 to, with the lowest and highest temperatures ever recorded being -6.7 and respectively. The annual mean temperature is 25 °C; monthly mean temperatures range from 13 to. The highest temperature recorded in July was 45 °C in 1931. The average annual rainfall is approximately 714 mm, most of which falls during the monsoon in July and August. The average date of the advent of monsoon winds in Delhi is 29 June.
Air pollution.
Delhi is the most polluted city in the world and according to one estimate, air pollution causes the death of about 10,500 people in Delhi every year. During 2013-14, peak levels of fine particulate matter (PM) in Delhi increased by about 44%, primarily due to high vehicular and industrial emissions, construction work and crop burning in adjoining states. Delhi has the highest level of the airborne particulate matter, PM2.5 considered most harmful to health, with 153 micrograms. Rising air pollution level has significantly increased lung-related ailments (especially asthma and lung cancer) among Delhi's children and women. The dense smog in Delhi during winter season results in major air and rail traffic disruptions every year. According to Indian meteorologists, the average maximum temperature in Delhi during winters has declined notably since 1998 due to rising air pollution.
Environmentalists have criticised the Delhi government for not doing enough to curb air pollution and to inform people about air quality issues. Most of Delhi's residents are unaware of alarming levels of air pollution in the city and the health risks associated with it; however, as of 2015, awareness, particularly among the foreign diplomatic community and high-income Indians, was noticeably increasing. Since the mid-1990s, Delhi has undertaken some measures to curb air pollution – Delhi has the third highest quantity of trees among Indian cities and the Delhi Transport Corporation operates the world's largest fleet of environmentally friendly compressed natural gas (CNG) buses. In 1996, the Centre for Science and Environment (CSE) started a public interest litigation in the Supreme Court of India that ordered the conversion of Delhi's fleet of buses and taxis to run on compressed natural gas (CNG) and banned the use of leaded petrol in 1998. In 2003, Delhi won the United States Department of Energy's first 'Clean Cities International Partner of the Year' award for its "bold efforts to curb air pollution and support alternative fuel initiatives". The Delhi Metro has also been credited for significantly reducing air pollutants in the city.
However, according several authors, most of these gains have been lost, especially due to stubble burning, a rise in the market share of diesel cars and a considerable decline in bus ridership. According to CSE and System of Air Quality Weather Forecasting and Research (SAFAR), burning of agricultural waste in nearby Punjab, Haryana and Uttar Pradesh regions results in severe intensification of smog over Delhi. The state government of Uttar Pradesh is considering imposing a ban on crop burning to reduce pollution in Delhi NCR and an environmental panel has appealed to India's Supreme Court to impose a 30% cess on diesel cars.
The Circles of Sustainability assessment of Delhi gives a marginally more favourable impression of the ecological sustainability of the city only because it is based on a more comprehensive series of measures than only air pollution. Part of the reason that the city remains assessed at basic sustainability is because of the low resource-use and carbon emissions of its poorer neighbourhoods.
Civic administration.
As of July 2007, the National Capital Territory of Delhi comprises nine districts, 27 tehsils, 59 census towns, 300 villages, and three statutory towns, the Municipal Corporation of Delhi (MCD) – 1397.3 km2, the New Delhi Municipal Council (NDMC) – 42.7 km2 and the Delhi Cantonment Board (DCB) – 43 km2). On 16 July 2012, the Delhi Government decided to increase the number of districts from nine to 11.
The Delhi metropolitan area lies within the National Capital Territory of Delhi (NCT), which has five local municipal corporations; , , , NDMC and DCB. The former MCD was divided into three smaller Municipal Corporations – North Delhi, South Delhi and East Delhi. According to the 2011 census, MCD is among the largest municipal bodies in the world, providing civic services to about 11 million people.
Delhi (civic administration) was ranked 5th out of 21 Cities for best governance & administrative practices in India in 2014. It scored 3.6 on 10 compared to the national average of 3.3.
Delhi houses the Supreme Court of India, and the regional Delhi High Court, along with the Small Causes Court for civil cases; the Magistrate Court and the Sessions Court for criminal cases, has jurisdiction over Delhi. The city is administratively divided into eleven police-zones, which are subdivided into 95 local police stations.
Government and politics.
The National Capital Territory of Delhi has its own Legislative Assembly, Lieutenant Governor, council of ministers and Chief Minister. Members of the legislative assembly are directly elected from territorial constituencies in the NCT. The legislative assembly was abolished in 1956, after which direct federal control was implemented until it was re-established in 1993. The Municipal Corporation of Delhi (MCD) handles civic administration for the city as part of the Panchayati Raj Act. The Government of India and the Government of National Capital Territory of Delhi jointly administer New Delhi, where both bodies are located. The Parliament of India, the Rashtrapati Bhavan (Presidential Palace), Cabinet Secretariat and the Supreme Court of India are located in the municipal district of New Delhi. There are 70 assembly constituencies and seven Lok Sabha (Indian parliament's lower house) constituencies in Delhi.
The Indian National Congress (Congress) formed all the governments in Delhi until the 1990s, when the Bharatiya Janata Party (BJP), led by Madan Lal Khurana, came to power. In 1998, the Congress returned to power under the leadership of Sheila Dikshit, who was subsequently re-elected for 3 consecutive terms. But in 2013, the Congress was ousted from power, with the newly formed Aam Aadmi Party (AAP) led by Arvind Kejriwal forming the government with outside support from the Congress. However, that government was short-lived, collapsing only after 49 days. Delhi was then under President's rule till February, 2015. On February 10, 2015, the Aam Aadmi Party returned to power after a landslide victory, winning 67 out of the 70 seats in Delhi Legislative Assembly.
Economy.
Delhi is the largest commercial centre in northern India; it has an estimated net State Domestic Product (FY 2010) of ₹1595 billion () in nominal terms and ~₹6800 billion () in PPP terms. As of 2013, the per capita income of Delhi was Rs. 230000, highest in India. GSDP in Delhi at the current prices for 2012-13 is estimated at Rs 3.88 trillion (short scale) against Rs 3.11 trillion (short scale) in 2011-12.
As per the Economic survey of Delhi (2005–2006), the tertiary sector contributes 70.95% of Delhi's gross SDP followed by secondary and primary sectors, with 25.20% and 3.85% contributions respectively. Delhi's workforce constitutes 32.82% of the population, and increased by 52.52% between 1991 and 2001. Delhi's unemployment rate decreased from 12.57% in 1999–2000 to 4.63% in 2003. In December 2004, 636,000 people were registered with various employment exchange programs in Delhi.
In 2001 the total workforce in national and state governments and the quasi-government sector was 620,000, and the private sector employed 219,000. Key service industries are information technology, telecommunications, hotels, banking, media and tourism. Construction, power, health and community services, and real estate are also important to the city's economy. Delhi has one of India's largest and fastest growing retail industries. Manufacturing also grew considerably as consumer goods companies established manufacturing units and headquarters in the city. Delhi's large consumer market and the availability of skilled labour has attracted foreign investment. In 2001, the manufacturing sector employed 1,440,000 workers and the city had 129,000 industrial units.
Utility services.
Delhi's municipal water supply is managed by the Delhi Jal Board (DJB). As of 2005–06, it supplied 650 million gallons per day (MGD), whereas the estimated consumption requirement is 963 MGD. The shortfall is met by private and public tube wells and hand pumps. At 240 MGD, the Bhakra storage is DJB's largest water source, followed by the Yamuna and Ganges rivers. Delhi's groundwater level is falling and its population density is increasing, so residents often encounter acute water shortage. In Delhi, daily domestic solid waste production is 8000 tonnes which is dumped at three landfill locations by MCD. The daily domestic waste water production is 470 MGD and industrial waste water is 70 MGD. A large portion of the sewage flows untreated into the Yamuna river.
The city's electricity consumption is about 1,265 kWh per capita, but actual demand is higher. In Delhi power distribution is managed by Tata Power Distribution and BSES Rajdhani since 2002. The Delhi Fire Service runs 43 fire stations that attend about 15,000 fire and rescue calls per year. The state-owned Mahanagar Telephone Nigam Limited (MTNL) and private enterprises Vodafone, Airtel, Idea cellular, Reliance Infocomm, Aircel and Tata Docomo provide telephone and cell phone service to the city. Cellular coverage is available in GSM, CDMA, 3G and 4G.
Transport.
Air.
Indira Gandhi International Airport, situated to the southwest of Delhi, is the main gateway for the city's domestic and international civilian air traffic. In 2012-13, the airport was used by more than 35 million passengers, making it one of the busiest airports in South Asia. Terminal 3, which cost ₹96.8 billion () to construct between 2007 and 2010, handles an additional 37 million passengers annually.
The "Delhi Flying Club", established in 1928 with two de Havilland Moth aircraft named "Delhi" and "Roshanara", was based at "Safdarjung Airport" which started operations in 1929, when it was the Delhi's only airport and the second in India. The airport functioned until 2001, however in January 2002 the government closed the airport for flying activities because of security concerns following the New York attacks in September 2001. Since then, the club only carries out aircraft maintenance courses, and is used for helicopter rides to Indira Gandhi International Airport for VIP including the president and the prime minister.
A second airport open for commercial flights has been suggested, by expansion of Meerut Airport or construction of a new airport in Greater Noida.
Road.
Delhi has the highest road density of 2103 km/100 sq. km in India.
Buses are the most popular means of road transport catering to about 60% of Delhi's total demand. Delhi has one of India's largest bus transport systems. Buses are operated by the state-owned Delhi Transport Corporation (DTC), which owns largest fleet of Compressed Natural Gas (CNG)-fueled buses in the world. Personal vehicles especially cars also form a major chunk of vehicles plying on Delhi roads. Delhi has the highest number of registered cars compared to any other metropolitan city in India. Taxis, Auto Rickshaws and Cycle Rickshaws also ply on Delhi roads in large numbers.
Important Roads in Delhi
Some roads and expressways serve as important pillars of Delhi's road infrastructure:
National Highways Passing Through Delhi
Delhi is connected by Road to various parts of the country through several National highways:
Railway.
Delhi is a major junction in the Indian railway network and is the headquarters of the Northern Railway. The five main railway stations are New Delhi railway station, Old Delhi, Nizamuddin Railway Station, Anand Vihar Railway Terminal and Sarai Rohilla. The Delhi Metro, a mass rapid transit system built and operated by Delhi Metro Rail Corporation (DMRC), serves many parts of Delhi and the neighbouring cities Gurgaon, Noida and Ghaziabad. As of August 2011, the metro consists of six operational lines with a total length of 189 km and 146 stations, and several other lines are under construction. The Phase-I was built at a cost of US$2.3 billion and the Phase-II was expected to cost an additional ₹216 billion (). Phase-II has a total length of 128 km and was completed by 2010. Delhi Metro completed 10 years of operation on 25 December 2012. It carries millions of passengers every day. In addition to the Delhi Metro, a suburban railway, the Delhi Suburban Railway exists.
Metro.
The Delhi Metro is a rapid transit system serving Delhi, Gurgaon, Faridabad, Noida, and Ghaziabad in the National Capital Region of India. Delhi Metro is the world's 13th largest metro system in terms of length. Delhi Metro was India's first modern public transportation system, which has revolutionised travel by providing a fast, reliable, safe, and comfortable means of transport. The network consists of six lines with a total length of 189.63 km with 142 stations, of which 35 are underground, five are at-grade, and the remainder are elevated. All stations have escalators, elevators, and tactile tiles to guide the visually impaired from station entrances to trains. It has a combination of elevated, at-grade, and underground lines, and uses both broad gauge and standard gauge rolling stock. Four types of rolling stock are used: Mitsubishi-ROTEM Broad gauge, Bombardier MOVIA, Mitsubishi-ROTEM Standard gauge, and CAF Beasain Standard gauge. The Phase-I of Delhi Metro was built at a cost of US$2.3 billion and the Phase-II was expected to cost an additional ₹216 billion (). Phase-II has a total length of 128 km and was completed by 2010. Delhi Metro completed 10 years of operation on 25 December 2012. It carries millions of passengers every day. In addition to the Delhi Metro, a suburban railway, the Delhi Suburban Railway exists.
Delhi Metro is being built and operated by the Delhi Metro Rail Corporation Limited (DMRC), a state-owned company with equal equity participation from Government of India and Government of National Capital Territory of Delhi. However, the organisation is under administrative control of Ministry of Urban Development, Government of India. Besides construction and operation of Delhi metro, DMRC is also involved in the planning and implementation of metro rail, monorail and high-speed rail projects in India and providing consultancy services to other metro projects in the country as well as abroad. The Delhi Metro project was spearheaded by Padma Vibhushan E. Sreedharan, the Managing Director of DMRC and popularly known as the "Metro Man" of India. He famously resigned from DMRC, taking moral responsibility for a metro bridge collapse which took five lives. Sreedharan was awarded with the prestigious Legion of Honour by the French Government for his contribution to Delhi Metro.
Regional Rapid Transit System (RRTS).
The 08 RRTS Corridors have been proposed by National Capital Region Planning Board (NCRPB) to facilitate the people travelling from nearby cities in NCR to Delhi. The three main corridors in first phase are as follows which are expected to become operational before 2019:
Remaining five corridors are also approved by National Capital Region Planning Board but are planned in the second phase.
To make the project operational NCRPB has formed a separate body named as "National Capital Region Transport Corporation" on the lines of DMRC to independently formalise and monitor its progress.
Roads of 2006 and 2007.
As of 2007, private vehicles account for 30% of the total demand for transport. Delhi has 1922.32 km of road length per 100 km2, one of the highest road densities in India. It is connected to other parts of India by five National Highways: NH 1, 2, 8, 10 and 24. The city's road network is maintained by MCD, NDMC, Delhi Cantonment Board, Public Works Department (PWD) and Delhi Development Authority. The Delhi-Gurgaon Expressway connects Delhi with Gurgaon and the international airport. connects Delhi with the neighbouring industrial town of Faridabad. The DND Flyway and Noida-Greater Noida Expressway connect Delhi with the suburbs of Noida and Greater Noida. Delhi's rapid rate of economic development and population growth has resulted in an increasing demand for transport, creating excessive pressure on the city's transport infrastructure. As of 2008, the number of vehicles in the metropolitan region, Delhi NCR, is 11.2 million (11.2 million). In 2008, there were 85 cars in Delhi for every 1,000 of its residents.
To meet the transport demand, the State and Union government constructed a mass rapid transit system, including the Delhi Metro. In 1998, the Supreme Court of India ordered that all public transport vehicles in Delhi must be fuelled by compressed natural gas (CNG). Buses are the most popular means of public transport, catering for about 60% of the total demand. The state-owned Delhi Transport Corporation (DTC) is a major bus service provider which operates the world's largest fleet of CNG-fuelled buses. Delhi Bus Rapid Transit System runs between Ambedkar Nagar and Delhi Gate.
Demographics.
According to the 2011 census of India, the population of Delhi is 16,753,235. The corresponding population density was 11,297 persons per km2, with a sex ratio of 866 women per 1000 men, and a literacy rate of 86.34%. In 2004, the birth rate, death rate and infant mortality rate per 1000 population were 20.03, 5.59 and 13.08, respectively. In 2001, the population of Delhi increased by 285,000 as a result of migration and by 215,000 as a result of natural population growth – this made Delhi one of the fastest growing cities in the world. By 2015, Delhi is expected to be the third-largest conurbation in the world after Tokyo and Mumbai. Dwarka Sub City, Asia's largest planned residential area, is located within the National Capital Territory of Delhi.
Hinduism is Delhi's predominant religious faith, with approximately 81% of Delhi's population, followed by Islam(9.9%), Sikhism(5%), Jainism(1.1%), and others(1.2%). Other minority religions include Buddhism, Zoroastrianism, Christianity, Baha'ism and Judaism. Punjabi & Hindi are the most widely spoken languages in Delhi. English is the principal written language of the city and the most commonly used language for the official purposes. In addition to Hindi and English, Punjabi with Gurmukhī alphabets and Urdu also have official language status in Delhi.
According a 1999–2000 estimate, the total number of people living below the poverty line, defined as living on US$11 or less per month, in Delhi was 1,149,000, or 8.23% of the total population, compared to 27.5% of India as a whole. 52% of Delhi residents who live in slums without basic services like water, electricity, sanitation, sewage system or proper housing. In 2005, Delhi accounted for the highest percentage (16.2%) of the crimes reported in 35 Indian cities with populations of one million or more. The city has the highest rate of kidnapping and abduction cases with 9.3%; the national rate is 2.2%. Delhi accounts for 15.4% of crime against women in Indian cities.
Findings from surveys conducted by the Centre for the Study of Developing Societies (CSDS) in Delhi estimate an average of 40% of the voters in Delhi belong to the upper castes. About 12% are Brahmins, 7% are Punjabi Khatris, 7% are Rajputs, 6% belong to the Vaishya (Bania) and Jain communities and 8% are from other upper castes.Jat community, roughly 5% of Delhi's population and located mostly in the rural parts of outer Delhi. OBC communities such as the Gujjars, Yadavs and the lower OBCs together form about 18% of Delhi's population. The Dalit communities 17% of Delhi's population.
Culture.
Delhi's culture has been influenced by its lengthy history and historic association as the capital of India. This is exemplified by many significant monuments in the city. Delhi is also identified as the location of Indraprastha, the ancient capital of the Pandavas. The Archaeological Survey of India recognises 1200 heritage buildings and 175 monuments as national heritage sites. In the Old City, the Mughals and the Turkic rulers constructed several architecturally significant buildings, such as the Jama Masjid – India's largest mosque and the Red Fort. Three World Heritage Sites – the Red Fort, Qutab Minar and Humayun's Tomb – are located in Delhi. Other monuments include the India Gate, the Jantar Mantar – an 18th-century astronomical observatory – and the Purana Qila – a 16th-century fortress. The Laxminarayan temple, Akshardham temple, the Bahá'í Lotus temple and the ISKCON temple are examples of modern architecture. Raj Ghat and associated memorials houses memorials of Mahatma Gandhi and other notable personalities. New Delhi houses several government buildings and official residences reminiscent of British colonial architecture, including the Rashtrapati Bhavan, the Secretariat, Rajpath, the Parliament of India and Vijay Chowk. Safdarjung's Tomb is an example of the Mughal gardens style. Some regal "havelis" (palatial residences) are in the Old City.
Lotus Temple, is a Bahá'í House of Worship completed in 1986. Notable for its flowerlike shape, it serves as the Mother Temple of the Indian subcontinent and has become a prominent attraction in the city. The Lotus Temple has won numerous architectural awards and been featured in hundreds of newspaper and magazine articles. Like all other Bahá'í Houses of Worship, is open to all regardless of religion, or any other distinction, as emphasised in Bahá'í texts. The Bahá'í laws emphasise that the spirit of the House of Worship be that it is a gathering place where people of all religions may worship God without denominational restrictions. The Bahá'í laws also stipulate that only the holy scriptures of the Bahá'í Faith and other religions can be read or chanted inside in any language; while readings and prayers can be set to music by choirs, no musical instruments can be played inside. Furthermore no sermons can be delivered, and there can be no ritualistic ceremonies practised.
Chandni Chowk, a 17th-century market, is one of the most popular shopping areas in Delhi for jewellery and "Zari" saris. Delhi's arts and crafts include, "Zardozi"  – an embroidery done with gold thread – and "Meenakari" – the art of enamelling.
Festivals.
Delhi's association and geographic proximity to the capital, New Delhi, has amplified the importance of national events and holidays like Republic Day, Independence Day (15 August) and "Gandhi Jayanti". On Independence Day, the Prime Minister addresses the nation from the Red Fort. Most Delhiites celebrate the day by flying kites, which are considered a symbol of freedom. The Republic Day Parade is a large cultural and military parade showcasing India's cultural diversity and military strength. Over the centuries, Delhi has become known for its composite culture, and a festival that symbolises this is the "Phool Walon Ki Sair", which takes place in September. Flowers and "pankhe" – fans embroidered with flowers – are offered to the shrine of 13th century Sufi saint Khwaja Bakhtiyar Kaki and the Yogmaya temple, both situated in Mehrauli.
Religious festivals include "Diwali" (the festival of lights), "Mahavir Jayanti", Guru Nanak's Birthday, "Raksha Bandhan", "Durga Puja", "Holi", "Lohri", "Chauth", "Krishna Janmastami", "Maha Shivratri", Eid ul-Fitr, "Moharram" and "Buddha Jayanti". The Qutub Festival is a cultural event during which performances of musicians and dancers from all over India are showcased at night, with the Qutub Minar as a backdrop. Other events such as Kite Flying Festival, International Mango Festival and "Vasant Panchami" (the Spring Festival) are held every year in Delhi. The Auto Expo, Asia's largest auto show, is held in Delhi biennially. The World Book Fair, held biannually at the Pragati Maidan, is the second largest exhibition of books in the world. Delhi is often regarded as the "Book Capital" of India because of high readership.
Cuisine.
As India's national capital and centuries old Mughal capital, Delhi influenced the food habits of its residents and is where Mughlai cuisine originated. Along with Indian cuisine, a variety of international cuisines are popular among the residents. The dearth of food habits among the city's residents created a unique style of cooking which became popular throughout the world, with dishes such as "Kebab", "biryani", "tandoori". The city's classic dishes include Butter chicken, "Aloo Chaat", "chaat", "dahi vada", "kachori", "chole bhature", Chole kulche, "jalebi" and "lassi".:40–50, 189–196
The fast living habits of Delhi's people has motivated the growth of street food outlets.:41 A trend of dining at local "dhabas" is popular among the residents. High profile restaurants have gained popularity in recent years, among the popular restaurants are the Karim Hotel, the Punjab Grill and Bukhara. The "Gali Paranthe Wali" (the street of fried bread) is a street in Chandni Chowk particularly for food eateries since the 1870s. Almost the entire street is occupied by fast food stalls or street vendors. It has nearly become a tradition that almost every prime minister of India has visited the street to eat "paratha" at least once. Other Indian cuisines are also available in this area even though the street specializes in north Indian food .:40–50
Education.
Private schools in Delhi – which use either English or Hindi as the language of instruction – are affiliated to one of three administering bodies, the "Council for the Indian School Certificate Examinations" (CISCE), the "Central Board for Secondary Education" (NCERT (CBSE)) or the "National Institute of Open Schooling" (NIOS). In 2004–05, approximately 15.29 lakh (1.529 million) students were enrolled in primary schools, 8.22 lakh (0.822 million) in middle schools and 6.69 lakh (0.669 million) in secondary schools across Delhi. Female students represented 49% of the total enrolment. The same year, the Delhi government spent between 1.58% and 1.95% of its gross state domestic product on education.
Schools and higher educational institutions in Delhi are administered either by the Directorate of Education, the NCT government or private organisations. In 2006, Delhi had 165 colleges, five medical colleges and eight engineering colleges, seven major universities and nine deemed universities. Indraprastha Institute of Information Technology, Delhi Technological University, Guru Gobind Singh Indraprastha University and National Law University are the only state universities, Indira Gandhi National Open University is for distance education and the rest are central universities.
As of 2008, about 16% of all Delhi residents possessed at least a college graduate degree.
Media.
As the capital of India, Delhi is the focus of political reportage, including regular television broadcasts of Parliament sessions. Many national media agencies, including the state-owned Press Trust of India, Media Trust of India and Doordarshan, is based in the city. Television programming includes two free terrestrial television channels offered by Doordarshan, and several Hindi, English and regional-language cable channels offered by multi system operators. Satellite television has yet to gain a large quantity of subscribers in the city.
Print journalism remains a popular news medium in Delhi. The city's Hindi newspapers include "Navbharat Times", "Hindustan Dainik", "Punjab Kesari", "Pavitra Bharat", "Dainik Jagran", "Dainik Bhaskar" and "Dainik Desbandhu". Amongst the English language newspapers, "The Hindustan Times", with a daily circulation of over a million copies, is the single largest daily. Other major English newspapers include "Times of India", "The Hindu", "Indian Express", "Business Standard", "The Pioneer" and "The Asian Age'Top Story (Daily). Regional language newspapers include the Malayalam daily "Malayala Manorama" and the Tamil dailies "Dinamalar" and "Dinakaran".
Radio is a less popular mass medium in Delhi, although FM radio has gained popularity since the inauguration of several new stations in 2006.
A number of state-owned and private radio stations broadcast from Delhi.
Sports.
Delhi has hosted many major international sporting events, including the first and also the ninth Asian Games, the 2010 Hockey World Cup, the 2010 Commonwealth Games and the 2011 Cricket World Cup. Delhi lost bidding for the 2014 Asian Games, and considered making a bid for the 2020 Summer Olympics. However, sports minister Manohar Singh Gill later stated that funding infrastructure would come before a 2020 bid. There are indications of a possible 2028 bid.
The 2010 Commonwealth Games, which ran from 3 to 14 October 2010, was one of the largest sports event held in India. The opening ceremony of the 2010 Commonwealth Games was held at the Jawaharlal Nehru Stadium, the main stadium of the event, in New Delhi at 7:00 pm Indian Standard Time on 3 October 2010. The ceremony featured over 8,000 performers and lasted for two and a half hours. It is estimated that ₹3.5 billion () were spent to produce the ceremony. Events took place at 12 competition venues. 20 training venues were used in the Games, including seven venues within Delhi University. The rugby stadium in Delhi University North Campus hosted rugby games for Commonwealth Games. The mess left behind after the Commonwealth Games prompted Prime Minister Manmohan Singh to replace Sports and Youth Affairs minister Manohar Singh Gill with Ajay Maken in 19 January 2011 Cabinet reshuffle.
Cricket and football are the most popular sports in Delhi. There are several cricket grounds, or "maidans", located across the city. The Feroz Shah Kotla Ground (known commonly as the "Kotla") is one of the oldest cricket grounds in India and is a venue for international cricket matches. It is the home ground of the Delhi cricket team, which represents the city in the Ranji Trophy, the premier Indian domestic first-class cricket championship. The Delhi cricket team has produced several world-class international cricketers such as Virender Sehwag, Gautam Gambhir, Virat Kohli, Madan Lal, Chetan Chauhan and Bishan Singh Bedi to name a few. The Railways and Services cricket teams in the Ranji Trophy also play their home matches in Delhi, in the Karnail Singh Stadium and the Harbax Singh Stadium respectively. The city is also home to the Indian Premier League team Delhi Daredevils, who play their home matches at the Kotla, and was the home to the Delhi Giants team (previously Delhi Jets) of the now defunct Indian Cricket League.
Ambedkar Stadium, a football stadium in Delhi which holds 21,000 people, was the venue for the Indian football team's World Cup qualifier against UAE on 28 July 2012. Delhi hosted the Nehru Cup in 2007 and 2009, in both of which India defeated Syria 1–0. In the Elite Football League of India, Delhi's first professional American football franchise, the Delhi Defenders played its first season in Pune. Buddh International Circuit in Greater Noida, a suburb of Delhi, hosts the annual Formula 1 Indian Grand Prix. The Indira Gandhi Arena is also in Delhi.
Delhi is a member of the Asian Network of Major Cities 21.
World Heritage status.
In February 2014, Government of India approved Delhi's bid for World Heritage City status. The historical city of Shahjahanabad and Lutyens' Bungalow Zone in New Delhi have been cited in the bid. A team from UNESCO is scheduled to visit Delhi in September, 2014 to validate its claims. Indian National Trust for Art and Cultural Heritage (INTACH) has acted as the nodal agency for the bid.
The announcement of accepted cities will be made in June, 2015.

</doc>
<doc id="37757" url="http://en.wikipedia.org/wiki?curid=37757" title="Vindolanda">
Vindolanda

Vindolanda was a Roman auxiliary fort ("castrum") just south of Hadrian's Wall in northern England. Located near the modern village of Bardon Mill, it guarded the Stanegate, the Roman road from the River Tyne to the Solway Firth. It is noted for the Vindolanda tablets, among the most important finds of military and private correspondence (written on wooden tablets) found anywhere in the Roman Empire.
Early accounts.
The first post-Roman record of the ruins at Vindolanda was made by the antiquarian William Camden, in his "Britannia" (1586). Occasional travellers reached the site over the next two hundred years, and the accounts they left are useful because they predate much of the stone-stealing that has damaged the site. The military bath-house was still partly roofed when Christopher Hunter visited the site in 1702. In about 1715 an excise officer named John Warburton found an altar there, which he removed. In 1814 the first real archaeological work was begun, by the Rev. Anthony Hedley. Hedley died in 1835, before writing up his discoveries. Little more was done for a long time, although in 1914 a workman found another altar at the site, set up by the civilians living at the fort in honour of the Divine House and Vulcan. Several names for the site are used in the early records, including Chesters on Caudley, Little Chesters, the Bower, and Chesterholm; the altar found in 1914 confirmed that the true Roman name for the site was "Vindolanda", which had been in dispute as one early source referred to it as "Vindolana".
Garrison.
The garrison were auxiliary infantry or cavalry units, not components of Roman legions. From the early third century AD onwards, this was the Fourth Cohort of Gauls. It had been presumed that this title was by this time purely nominal, with auxiliary troops being recruited locally, but an inscription found in a recent season of excavations suggests that native Gauls were still to be found in the regiment and that they liked to distinguish themselves from British soldiers. The inscription reads:
A free translation of this is "The troops from Gaul dedicate this statue to the goddess Gallia with the full support of the British-born troops".
Fort and village.
Early wooden forts.
The earliest Roman forts at Vindolanda were built of wood and turf. The remains are now buried as much as 4 metres deep in the anoxic waterlogged soil. There are 5 timber forts, built (and demolished) one after the other. The first, a small fort was probably built by the 1st Cohort of Tungrians about AD 85. By about AD 95 this was replaced by a larger wooden fort built by the 9th Cohort of Batavians, a mixed infantry-cavalry unit of about 1000 men. That fort was repaired in about AD 100 under the command of the Roman prefect Flavius Cerialis.
When the 9th Cohort of Batavians left in AD 105, their fort was demolished. The 1st Cohort of Tungrians came back to Vindolanda, built a larger wooden fort, and remained here until Hadrian's Wall was built around AD 122, when they moved, most likely to Vercovicium (Housesteads).
Stone forts, stone huts.
Soon after Hadrian's Wall was built, most of its men were moved north to the Antonine Wall. To cope with the death of soldiers, a stone fort was built at Vindolanda, possibly for the 2nd Cohort of Nervians.
From AD 208 to 211, there was a major rebellion against Rome in Britain, and the Emperor Septimius Severus led an army to Britain to cope with it personally. The old stone fort was demolished, and replaced by an unconventional set of army buildings on the west, and an unusual array of many round stone huts where the old fort had been: some of these circular huts are visible by the north and the southwest walls of the final stone fort. The Roman army may have built these to accommodate families of British farmers in this unsettled period.
Septimius Severus died at York in AD 211; his sons paid off the rebels and left for Rome. The stone buildings were demolished, and a large new stone fort was built where the huts had been, for the 4th Cohort of Gauls.
Vicus.
A "vicus", a self-governing village, developed to the west of the fort. The "vicus" contains several rows of buildings, each containing several one-room chambers. Most are not connected to the existing drainage system. The one that does was perhaps a butchery where, for health reasons, an efficient drain would have been important. A stone altar found in 1914 (and exhibited in the museum) proves that the settlement was officially a "vicus", and that it was named Vindolanda.
To the south of the fort is a large Roman bath.The Roman baths were used by many.
The later stone fort, and the adjoining village, remained in use until about AD 285, when it was largely abandoned for some reason.
4th century forts.
About AD 300 the fort was again rebuilt, but the "vicus" was not reoccupied, so most likely the area remained too unsafe for life outside the defended walls of the fort.
In about 370 AD the fort was roughly repaired, perhaps by irregular soldiers. There is no evidence for the traditional view that Roman occupation ended suddenly in AD 410; it may have declined slowly.
Excavation.
In the 1930s, the house at Chesterholm where the museum is now located was purchased by archaeologist Eric Birley, who was interested in excavating the site. The excavations have been continued by his sons, Robin and Anthony, and his grandson, Andrew Birley, into the present day. They are undertaken each summer, and some of the archaeological deposits reach depths of six meters. The anoxic conditions at these depths have preserved thousands of artefacts, such as wooden writing tablets, that normally disintegrate in the ground, thus providing an opportunity to gain a fuller understanding of Roman life – military and otherwise – on the northern frontier. 
In 2010, the remains of what is thought to be a girl between the ages of 8 and 10 years old, with her hands tied, were uncovered in a shallow pit in what was the barrack room. She is believed to have been murdered about 1,800 years ago.
Along with ongoing excavations (in season) and excavated remains, a full size replica of a section of Hadrian's Wall in both stone and timber can be seen on the site.
Site museum.
The Vindolanda site museum, also known as Chesterholm Museum, conserves and displays finds from the site. The museum is set in gardens, which include full-sized reconstructions of a Roman temple, a Roman shop, Roman house and Northumbrian croft, all with audio presentations. Exhibits include Roman boots, shoes, armour, jewellery and coins, infra-red photographs of the writing tablets and, from 2011, a small selection of the tablets themselves, on loan from the British Museum. 2011 saw the reopening of the museum at Vindolanda, and also the Roman Army Museum at Carvoran, refurbished with a grant from the Heritage Lottery Fund.
A spectacular find in 2006 was the richly detailed bronze and silver brooch (fibula) modelled with the figure of Mars, on which Quintus Sollonius, a Gaul to judge by his name, had carefully punched his name before he lost it in the early second century; nothing comparably fine has been recovered along the Wall.
Vindolanda Trust.
In 1970, the Vindolanda Trust, a registered charity, was founded to administer the site and its museum, and in 1997, the Trust took over the running of the Roman Army Museum at Carvoran, another Hadrian's Wall fort, which it had acquired in 1972.

</doc>
<doc id="37760" url="http://en.wikipedia.org/wiki?curid=37760" title="Plzeň">
Plzeň

 
Plzeň or Pilsen (]; German: "Pilsen") is a city in western Bohemia in the Czech Republic. About 90 km west of Prague, it is the fourth most populous city in the Czech Republic.
The city is known worldwide for Pilsner beer, created by Bavarian brewer Josef Groll here in 1842.
History.
Plzeň was first mentioned as a castle in 976, as the scene of a battle between Duke Boleslaus II the Pious of Bohemia and Emperor Otto II. It became a town in 1295 when King Wenceslaus II granted Plzeň its civic charter as a "Royal City" and established a new town site, some 10 km away from the original settlement, which is the current town of Starý Plzenec. It quickly became an important town on trade routes leading to Nuremberg and Regensburg; in the 14th century, it was the third-largest town in Bohemia after Prague and Kutná Hora. During the Hussite Wars, it was the centre of Catholic resistance to the Hussites: Prokop the Great unsuccessfully besieged it three times, and it joined the league of Catholic nobles against King George of Podebrady. In 1468, the town acquired a printing press; the Trojan Chronicle ("Kronika trojánská" in Czech), the first book published in Bohemia, was printed on it.
Emperor Rudolf II made Plzeň his seat from 1599–1600. During the Thirty Years' War the town was taken by Mansfeld in 1618 after the Siege of Plzeň and it was not recaptured by Imperial troops until 1621. Wallenstein made it his winter quarters in 1633. The town was unsuccessfully besieged by the Swedes in 1637 and 1648. The town and region have been staunchly Catholic despite the Hussite Wars.
From the end of the 17th century, the architecture of Plzeň has been influenced by the Baroque style. The city centre has been under cultural heritage preservation since 1989.
In the second half of the 19th century Plzeň, already an important trade centre for Bohemia, near the Bavarian/German border, began to industrialise rapidly. In 1869 Emil Škoda started up the Škoda Works, which became the most important and influential engineering company in the country and a crucial supplier of arms to the Austro-Hungarian Army. By 1917 the Škoda Works employed over 30,000 workers. After 1898 the second largest employer was the National Railways train workshop, with about 2,000 employees: this was the largest rail repair shop in all Austria-Hungary. Between 1861 and 1877, the Plzeň railway junction was completed and in 1899 the first tram line started in the city. This burst of industry had two important effects: the growth of the local Czech (Slavic) population and of the urban poor. After 1868 first Czech mayor of the city was elected.
Following Czechoslovak independence from Austria-Hungary in 1918 the German-speaking minority in the countryside bordering the city of Plzeň hoped to be united with Austria and were unhappy at being included in Czechoslovakia. Many allied themselves to the Nazi cause after 1933, in the hope that Adolf Hitler might be able to unite them with their German-speaking neighbours.
Following the Munich Agreement in 1938, Plzeň became literally a frontier town, after the creation of the Sudetenland moved the Third Reich borders to the city's outer limits. During the Nazi occupation from 1939 to 1945 the Škoda Works in Pilsen was forced to provide armaments for the Wehrmacht, and Czech contributions, particularly in the field of tanks, were noted.
Between 17 and 26 January 1942, over 2,000 Jewish inhabitants, most of Plzeň's Jewish population, were deported by the Nazis to the Theresienstadt concentration camp.
The German-speaking population was forcibly expelled from the city and indeed all of Czechoslovakia after the end of the war in 1945, according to the provisions of the Potsdam agreement. All of their property was confiscated.
On 6 May 1945, near the end of World War II, Plzeň was liberated from Nazi Germany by the 16th Armored Division of General Patton's 3rd Army. Also participating in the liberation of the city were elements of the 97th and 2nd Infantry Divisions. Other Third Army units liberated major portions of Western Bohemia. The rest of Czechoslovakia was liberated from German control by the Soviet Red Army. Elements of the 3rd Army, as well as units from the 1st Army, remained in Plzeň until late November 1945, assisting the Czechs with rebuilding. After seizing power in 1948, the Communists undertook a systematic campaign to suppress all acknowledgement of the U.S. Army's role in liberating the city and Western Bohemia. This continued until 1989 when the Communists were removed from power. Since 1990, the city of Plzeň has organised an annual Liberation Festival, taking place in May, which has already become a local tradition, and has been attended by many American and Allied veterans.
After the Communist takeover of February 1948, the totalitarian, Soviet-oriented Czechoslovak government launched a currency reform in 1953. This decision caused a wave of discontent, including the Plzeň uprising. On 1 June 1953 over 20,000 people, mainly workers at the Škoda Works, began demonstrating against the communist regime. Demonstrators forced their way into the town hall and threw Communist symbols, furniture and other objects out of the windows. The demonstration was violently suppressed by Communist officials. In retaliation the regime immediately destroyed the statue of Thomas Garrigue Masaryk.
The next year, a West German homing pigeon was lost near the Czechoslovak border. It returned two days later, bearing a strong anti-Communist message, signed "Unbowed Pilsen." The bird was named Leaping Lena, and taken to the United States as a celebrity Cold War hero.
Pilsner beer.
The officials of Plzeň founded a city-owned brewery in 1839, "Bürger Brauerei" (Citizens' Brewery – now Plzeňský Prazdroj), and recruited Bavarian brewer Josef Groll (1813–1887) who produced the first batch of modern Pilsner beer on 5 October 1842. The combination of pale colour from the new malts, Pilsen's remarkably soft water, Saaz noble hops from nearby Žatec ("Saaz" in German) and Bavarian-style lagering produced a clear, golden beer which was regarded as a sensation.
Improving transport meant that this new beer was soon available throughout Central Europe and "Pilsner Brauart"-style brewing was widely imitated. In 1859, “Pilsner Bier” was registered as a brand name at the Chamber of Commerce and Trade in Plzeň. In 1898, the Pilsner Urquell trade mark was created to put emphasis on it being the original brewery.
Education and economy.
Plzeň is a centre of academic, business, and cultural life for the western part of the Czech Republic. The University of West Bohemia in Plzeň is well known for its School of Law, School of Mechanical Engineering and School of Applied Science in particular.
Since the late 1990s the city has experienced high growth in foreign investment. In 2007, Israeli mall developer Plaza Centers opened the Pilsen Plaza, a 20,000 m2 shopping mall and entertainment centre featuring a multiplex cinema from Cinema City Czech Republic.
Plzeň produces about two-thirds of the Plzeň Region GDP, even though it contains only 29.8% of its population. Based on these figures, the city of Plzeň has a total GDP of approximately $7.2 billion, and a per capita GDP of $44,000. While part of this is explained by commuters to the city, it is one of the most prosperous cities in the Czech Republic.
The Škoda company, established in Plzeň in 1859, has been an important element of Austro-Hungarian, Czechoslovak and Czech engineering, and one of the biggest European arms factories. During the Communist era (1948–1989) the company's production had been directed to the needs of the Eastern Bloc. Disarray in the era after the Velvet Revolution, and unsuccessful efforts to gain new Western markets, resulted in sales problems and debts. After a huge restructuring process the company now has just two principal subsidiaries: Škoda Transportation (locomotives, underground trains and trams, which have been sold to Portland, Oregon; Tacoma; Seattle and Sardinia) and Škoda Power (turbines) now owned by the UK company.
Many foreign companies now have manufacturing bases in Plzeň, including Daikin and Panasonic. There has been much discussion of redeveloping those large areas of the Škoda plant which the company no longer uses.
Plzeň also has the biggest distillery (Stock) in the Czech Republic.
Sport.
Local hockey club HC Škoda Plzeň and the football club FC Viktoria Plzeň are among the most successful in the Czech Republic. Viktoria Plzeň has played in the UEFA Champions League and UEFA Europa League.
Dioceses.
Since 31 May 1993 Plzeň has been the seat of the Catholic Diocese of Plzeň. The first and incumbent Bishop is František Radkovský. The diocese covers almost the entire territory of Plzeň region with a total of 818,700 inhabitants. The Diocese office is in St. Bartholomew's Cathedral on Republic Square in Plzeň. The diocese is divided into 10 vicariates with a total of 72 parishes.
Tourism.
The most prominent sights of Plzeň are the Gothic St. Bartholomew's Cathedral, founded in the late 13th century, whose tower, at 102 m, is the highest in the Czech Republic, the Renaissance Town Hall, and the Moorish Revival Great Synagogue, the second largest synagogue in Europe, after the Dohány Street Synagogue in Budapest. There is also a 20 km historic underground tunnel/cellar network, among the longest in Central Europe. Part of this network is open to the public for tours of about 750 m in length and up to a depth of 12 m.
Built in 1532, the former water tower was integrated into the city's fortification system at Prague Gate. Another storey was added in 1822 in French Imperial style. The Gothic portal (dating from the 1500s) was added in 1912, coming from another house that had been demolished. Above the portal there is a commemorative plaque dedicated to Dr Josef Skoda (a professor at the Vienna University), who was born next door on 10 December 1805.
Plzeň is also well known for the Pilsner Urquell (since 1842) and Gambrinus (since 1869) breweries, currently owned by South African Breweries. A popular tourist attraction is the Plzeňský Prazdroj brewery tour where visitors can discover the history of beer. The pilsener style of beer was developed in Plzeň in the 19th century.
Plzeň has been selected to be a European Capital Of Culture in 2015, along with Mons, Belgium.
Transport.
The Plzeň metropolitan area is largely served by a network of trams, trolleybuses and buses operated by the . Like other continental European cities, tickets bought from vending machines or small shops are valid for any transportation run by the city of Plzeň. For residents of the city, a Plzeň Card can be purchased and through a system of "topping up" be used on any public transport with no limitations, as long as it is paid up and valid.
The most importance transport link in the city is the D5 highway connecting Prague and Nuremberg. Plzeň is an important centre of Czech railway transport, with the crossing of five main railway lines:
A public domestic and private international airport is located 11 km south-west from Plzeň, at the nearby village of Líně.
Geography and climate.
Plzeň has a cool and temperate Oceanic climate (Cfb). Plzeň has low rainfall (604 mm year average) evenly spread over the year. Precipitation occurs on average every second day, and the number of days with thunderstorms is 19. It receives on average 1700 hours of sunshine though winters have longer periods without sunshine. Terrain features and a relatively low altitude (290 – 390 metres) give some shelter from strong winds. Winters are chilly but milder than some adjacent areas. Snow cover is erratic and lasts on average for 51 days. Though an average year has 113 days with minimum temperature below zero, the temperature falls below -15 °C on 5 days. The record low temperatures is around -20 °C. Winters are often murky with frequent long-standing haze. Spring is short, and in April to June there is blooming vegetation. Summer lasts from the end of May until the first third of September. During that period Plzeň has changeable weather which can be warm to hot. Temperatures are always above 5 degrees Celsius with nights between 8 to and days between 16 to. Days are up to 16 hours long.
Plzeň can be hot, especially during heat waves originating in the southern Mediterranean. The number of hot days above 30 °C is steadily growing, with 5 months (late April – early September) of possible 30+ °C days. If hot weather does occur, it is often changes after a few weeks into cold and rainy weather with incoming Atlantic-based fronts. Nights can be unpleasantly cold even in summer, with high level of humidity. Winter frosts frequently occur from the second half of November to the end of March. February is the driest month with 32 mm of precipitation, and July the wettest with 80 mm. The only natural hazards are occasional fast changes of weather with negative consequences, e.g. floodings.
Extreme values for years 2011 & 2012: 
An extremely cold day of 2011 had -7.6 °C on average (23 February, -0.7 to and extremely hot day 25.2 °C on average (24 August, 19.5 to. The year 2012 had the coldest day on 12 February with minimum plummeting to -22.1 °C and maximum around -3.7 °C with average -14.9 °C. The hottest day of 2012 occurred on 21 August with daily maximum temperature 33.9 °C and minimum staying on 19.4 °C with all day average on 25.5 °C. Absolute minimum and maximum for both years were -22.1 °C (February 2012) and 37.4 °C during August 2012.
Number of rainy/snowy days for 2011: 78; number of days with frost: 76; number of days with minimal temperatures below -10 °C: 12; number of days with average temperature below zero: 35; number of days with daily average temperature higher than 10 °C: 188; number of days with daily average higher than 20 °C: 32. 
Total amount of precipitation for year 2011: 529.1 mm; average year humidity value: 80.8%. Maximal temperature: 33.3 °C; minimal temperature -14.8 °C.
Average 2011 temperature: 9.7 °C; average speed of wind: 4.7 km/h, mainly from SSE.
Number of days with frost was 96 during year 2012; 18 days had minima below -10 °C and 165 days with an average temperature on or above 10.0 °C. Number of days with maxima on or above 20.0 °C was 42.
Twin cities.
Plzeň is twinned with the following cities:
 Santo André, Brazil
 Limoges, France
 Liège, Belgium

</doc>
<doc id="37762" url="http://en.wikipedia.org/wiki?curid=37762" title="Tamar of Georgia">
Tamar of Georgia

 
Tamar the Great (Georgian: თამარი) ( 1160 – 18 January 1213) reigned as Queen of Georgia from 1184 to 1213, presiding over the apex of the Georgian Golden Age. A member of the Bagrationi dynasty, her position as the first woman to rule Georgia in her own right was emphasized by the title "mep'e" ("king"), commonly afforded to Tamar in the medieval Georgian sources.
Tamar was proclaimed heir and co-ruler by her reigning father George III in 1178, but she faced significant opposition from the aristocracy upon her ascension to full ruling powers after George's death. Tamar was successful in neutralizing this opposition and embarked on an energetic foreign policy aided by the decline of the hostile Seljuq Turks. Relying on a powerful military élite, Tamar was able to build on the successes of her predecessors to consolidate an empire which dominated the Caucasus until its collapse under the Mongol attacks within two decades after Tamar's death.
Tamar was married twice, her first union being, from 1185 to 1187, to the Rus' prince Yuri, whom she divorced and expelled from the country, defeating his subsequent attempts at coup. For her second consort Tamar chose, in 1191, the Alan prince David Soslan, by whom she had two children, George and Rusudan, the two successive monarchs on the throne of Georgia.
Tamar's association with the period of political and military successes and cultural achievements, combined with her role as a female ruler, has led to her idealization and romantization in Georgian arts and historical memory. She remains an important symbol in Georgian popular culture and has been canonized by the Georgian Orthodox Church as the Holy Righteous King Tamar (Georgian: წმიდა კეთილმსახური მეფე თამარი), with her feast day commemorated on 14 May (O.S. 1 May).
Early life and ascent to the throne.
Tamar was born in c. 1160 to George III, King of Georgia, and his consort Burdukhan, a daughter of the king of Alania. While it is possible that Tamar had a younger sister, Rusudan, she is only mentioned once in all contemporary accounts of Tamar's reign. The name Tamar is of Hebrew origin and, like other biblical names, was favored by the Georgian Bagrationi dynasty because of their claim to be descended from David, the second king of Israel.
Tamar's youth coincided with a major upheaval in Georgia; in 1177, her father, George III, was confronted by a rebellious faction of nobles. The rebels intended to dethrone George in favor of the king's fraternal nephew, Demna, who was considered by many to be a legitimate royal heir of his murdered father, David V. Demna's cause was little but a pretext for the nobles, led by the pretender's father-in-law, the amirspasalar ("constable") Ivane Orbeli, to weaken the crown. George III was able to crush the revolt and embarked on a campaign of crackdown on the defiant aristocratic clans; Ivane Orbeli was put to death and the surviving members of his family were driven out of Georgia. Prince Demna, castrated and blinded on his uncle's order, did not survive the mutilation and soon died in prison. Once the rebellion was suppressed and the pretender eliminated, George went ahead to co-opt Tamar into government with him and crowned her as co-ruler in 1178. By doing so, the king attempted to preempt any dispute after his death and legitimize his line on the throne of Georgia. At the same time, he raised men from the gentry and unranked classes to keep the dynastic aristocracy away from the center of power.
Early reign and the first marriage.
For six years, Tamar was a co-ruler with her father upon whose death, in 1184, Tamar continued as the sole monarch and was crowned a second time at the Gelati cathedral near Kutaisi, western Georgia. She inherited a relatively strong kingdom, but the centrifugal tendencies fostered by the great nobles were far from being quelled. There was a considerable opposition to Tamar's succession; this was sparked by a reaction against the repressive policies of her father and encouraged by the new sovereign's other perceived weakness, her sex. As Georgia had never previously had a female ruler, a part of the aristocracy questioned Tamar's legitimacy, while others tried to exploit her youth and supposed weakness to assert greater autonomy for themselves. The energetic involvement of Tamar's influential aunt Rusudan and the Georgian catholicos Michael IV Mirianisdze was crucial for legitimizing Tamar's succession to the throne. However, the young queen was forced into making significant concessions to the aristocracy. She had to reward the catholicos Michael's support by making him a chancellor, thus placing him at the top of both the clerical and secular hierarchies.
Tamar was also pressured into dismissing her father's appointees, among them the constable Qubasar (ყუბასარი), a Georgianized Kipchak of ignoble birth, who had helped George III in his crackdown on the defiant nobility. One of the few untitled servitors of George III to escape this fate was the treasurer Qutlu Arslan who now led a group of nobles and wealthy citizens in a struggle to limit the royal authority by creating a new council, "karavi", whose members would alone deliberate and decide policy. This attempt at "feudal constitutionalism" was rendered abortive when Tamar had Qutlu Arslan arrested and his supporters were inveigled into submission. Yet, Tamar’s first moves to reduce the power of the aristocratic élite were unsuccessful. She failed in her attempt to use a church synod to dismiss the catholicos Michael, and the noble council, "darbazi", asserted the right to approve royal decrees. Even the queen’s first husband, the Rus' prince Yuri, was forced on her by the nobles.
Pursuant to dynastic imperatives and the ethos of the time, the nobles required Tamar to marry in order to have a leader for the army and to provide an heir to the throne. Their choice fell on Yuri, son of the murdered prince Andrei I Bogolyubsky of Vladimir-Suzdal, who then lived as a refugee among the Kipchaks of the North Caucasus. The choice was approved by Tamar’s aunt Rusudan and the prince was brought to Georgia to marry the queen in 1185. Yuri proved to be an able soldier, but a difficult person and he soon ran afoul of his wife. The strained spousal relations paralleled a factional struggle at the royal court in which Tamar was becoming more and more assertive of her rights as a queen regnant. The turning point in Tamar's fortunes came with the death of the powerful catholicos Michael whom the queen replaced, as a chancellor, with her supporter, Anton Gnolistavisdze. Tamar gradually expanded her own powerbase and elevated her loyal nobles to high positions at the court, most notably the Kurdish family, known in Georgia as the Mkhargrdzeli.
Second marriage.
In 1187, Tamar persuaded the noble council to approve her divorce with Yuri who was accused of addiction to drunkenness and "sodomy", and sent off to Constantinople. Assisted by several Georgian aristocrats anxious to check Tamar’s growing power, Yuri made two attempts at coup, but failed and went off to obscurity after 1191. The queen chose her second husband herself. He was David Soslan, an Alan prince, to whom the 18th-century Georgian scholar Prince Vakhushti ascribes descent from the early 11th-century Georgian king George I. David, a capable military commander, became Tamar's major supporter and was instrumental in defeating the rebellious nobles rallied behind Yuri.
Tamar and David had two children. In 1192 or 1194, the queen gave birth to a son, George-Lasha, the future king George IV. The daughter, Rusudan, was born 1195 and would succeed her brother as a sovereign of Georgia.
David Soslan's status of a king consort, as well as his presence in art, on charters, and on coins, was dictated by the necessity of male aspects of kingship, but he remained a subordinate ruler who shared throne with and derived his power from Tamar. Tamar continued to be styled as "mep’et’a mep’e" – "king of kings". In Georgian, a language with no grammatical genders, "mep'e" ("king") does not necessarily imply a masculine connotation and can be rendered as a "sovereign". The female equivalent of "mep'e" is "dedop'ali" ("queen"), which was applied to queens consort or the king's closest, senior female relatives. Tamar is occasionally called "dedop'ali" in the Georgian chronicles and on some charters. Thus, the title of "mep'e" might have been applied to Tamar to mark out her unique position among women.
Foreign policy and military campaigns.
Muslim neighbors.
Once Tamar succeeded in consolidating her power and found a reliable support in David Soslan, the Mkhargrdzeli, Toreli, and other noble families, she revived the expansionist foreign policy of her predecessors. Repeated occasions of dynastic strife in Georgia combined with the efforts of regional successors of the Great Seljuq Empire, such as the Ildenizid atabegs of Azerbaijan, Shirvanshahs, and the Ahlatshahs, had slowed down the dynamic of the Georgians achieved during the reigns of Tamar's great-grandfather, David IV, and her father, George III. However, the Georgians became again active under Tamar, more prominently in the second decade of her rule.
Early in the 1190s, the Georgian government began to interfere in the affairs of the Ildenizids and of the Shirvanshahs, aiding rivaling local princes and reducing Shirvan to a tributary state. The Ildenizid atabeg Abu Bakr attempted to stem the Georgian advance, but suffered a defeat at the hands of David Soslan at Shamkir and lost his capital to a Georgian protégé in 1195. Although Abu Bakr was able to resume his reign a year later, the Ildenizids were only barely able to contain further Georgian forays.
In 1199, Tamar's armies led by two Christianised Kurdish generals, Zak'are and Ivane Mkhargrdzeli, dislodged the Shaddadid dynasty from Ani, the erstwhile capital of the Armenian kingdom, and received it from the queen as their fief. From their base at Ani, the brothers surged ahead into the central Armenian lands, reclaiming one after another fortress and district from local Muslim dynasts: Bjni was taken in 1201 and Dvin fell in 1203.
Alarmed by the Georgian successes, Süleymanshah II, the resurgent Seljuqid sultan of Rûm, rallied his vassal emirs and marched against Georgia, but his camp was attacked and destroyed by David Soslan at the battle of Basian in 1203 or 1204. The chronicler of Tamar describes how the army was assembled at the rock-hewn town of Vardzia before marching on to Basian and how the queen addressed the troops from the balcony of the church.
The Mkhargrdzeli captured Kars on behalf of the Georgian crown in 1206, but were repelled from the walls of Akhlat in 1209. This brought the struggle for the Armenian lands to a stall, leaving the Lake Van region in a relatively secure possession of its new masters – the Ayyubids of Damascus. In 1209, the brothers Mkhargrdzeli laid waste to Ardabil – according to the Georgian and Armenian annals – as a revenge for the local Muslim ruler's attack on Ani and his massacre of the city’s Christian population. In a great final burst, the brothers led an army marshaled throughout Tamar's possessions and vassal territories in a march, through Nakhchivan and Julfa, to Marand, Tabriz, and Qazvin in northwest Iran, pillaging several settlements on their way.
Trebizond and the Middle East.
Among the remarkable events of Tamar's reign was the foundation of the empire of Trebizond on the Black Sea in 1204. This state was established by Alexios Megas Komnenos and his brother, David, in the northeastern – Pontic – provinces of the crumbling Byzantine Empire with the aid of Georgian troops. Alexios and David, Tamar's relatives, were fugitive Byzantine princes raised at the Georgian court. According to Tamar's historian, the aim of the Georgian expedition to Trebizond was to punish the Byzantine emperor Alexios IV Angelos for his confiscation of a shipment of money from the Georgian queen to the monasteries of Antioch and Mount Athos. However, Tamar's Pontic endeavor can better be explained by her desire to take advantage of the Western European Fourth Crusade against Constantinople to set up a friendly state in Georgia's immediate southwestern neighborhood, as well as by the dynastic solidarity to the dispossessed Komnenoi.
Tamar sought to make use of the weakness of the Byzantine Empire and the crusaders' defeat at the hands of the Ayyubid sultan Saladin in order to gain Georgia's position on the international stage and to assume the traditional role of the Byzantine crown as a protector of the Christians of the Middle East. Georgian Christian missionaries were active in the North Caucasus and the expatriate monastic communities were scattered throughout the eastern Mediterranean. Tamar's chronicle praises her universal protection of Christianity and her support of churches and monasteries from Egypt to Bulgaria and Cyprus.
The Georgian court was primarily concerned with the protection of the Georgian monastic centers in the Holy Land. By the 12th century, eight Georgian monasteries were listed in Jerusalem. Saladin's biographer Bahā' ad-Dīn ibn Šaddād reports that, after the Ayyubid conquest of Jerusalem in 1187, Tamar sent envoys to the sultan to request that the confiscated possessions of the Georgian monasteries in Jerusalem be returned. Saladin's response is not recorded, but the queen's efforts seem to have been successful: Jacques de Vitry, who attained to the bishopric of Acre shortly after Tamar's death, gives further evidence of the Georgians’ presence in Jerusalem. He writes that the Georgians were – in contrast to the other Christian pilgrims – allowed a free passage into the city, with their banners unfurled. Ibn Šaddād furthermore claims that Tamar outbid the Byzantine emperor in her efforts to obtain the relics of the True Cross, offering 200,000 gold pieces to Saladin who had taken the relics as booty at the battle of Hattin – to no avail, however.
Golden age.
Feudal monarchy.
Georgia's political and cultural exploits of Tamar's epoch were rooted in a long and complex past. Tamar owed her accomplishments most immediately to the reforms of her great-grandfather David IV (r. 1089–1125) and, more remotely, to the unifying efforts of David III and Bagrat III who became architects of a political unity of Georgian kingdoms and principalities in the opening decade of the 11th century. Tamar was able to build upon their successes. 
By the last years of Tamar's reign, the Georgian state had reached the zenith of its power and prestige in the Middle Ages. Tamar's realm stretched from the Greater Caucasus crest in the north to Erzurum in the south, and from the Zygii in the northwest to the vicinities of Ganja in the southeast, forming a pan-Caucasian empire, with the loyal Zachariad regime in northern and central Armenia, Shirvan as a vassal and Trebizond as an ally. A contemporary Georgian historian extols Tamar as the master of the lands "from the Sea of Pontus [that is, the Black Sea] to the Sea of Gurgan [the Caspian Sea], from Speri to Derbend, and all the Hither and the Thither Caucasus up to Khazaria and Scythia."
The royal title was correspondingly aggrandized. It now reflected not only Tamar's sway over the traditional subdivisions of the Georgian realm, but also included new components, emphasizing the Georgian crown's hegemony over the neighboring lands. Thus, on the coins and charters issued in her name, Tamar is identified as:
The queen never achieved autocratic powers and the noble council continued to function. However, Tamar's own prestige and the expansion of "patronq'moba" – a Georgian version of feudalism – kept the more powerful dynastic princes from fragmenting the kingdom. This was a classical period in the history of Georgian feudalism. Attempts at transplanting feudal practices in the areas where they had previously been almost unknown did not pass without resistance. Thus, there was a revolt among the mountaineers of Pkhovi and Dido on Georgia's northeastern frontier in 1212, which was put down by Ivane Mkhargrdzeli after three months of heavy fighting.
With flourishing commercial centers now under Georgia's control, industry and commerce brought new wealth to the country and the court. Tribute extracted from the neighbors and war booty added to the royal treasury, giving rise to the saying that "the peasants were like nobles, the nobles like princes, and the princes like kings."
Culture.
With this prosperity came an outburst of the distinct Georgian culture, emerging from the amalgam of Christian and secular, western and eastern. Despite this, the Georgians continued to identify with the Byzantine West, rather than Islamic east, with the Georgian monarchy seeking to underscore its association with Christianity and present its position as God-given. It was in that period that the canon of Georgian Orthodox architecture was redesigned and a series of large-scale domed cathedrals were built. The Byzantine-derived expression of royal power was modified in various ways to bolster Tamar's unprecedented position as a woman ruling in her own right. The five extant monumental church portraits of the queen are clearly modeled on the Byzantine imagery, but also highlight specifically Georgian themes and Persian-type ideals of female beauty. Despite Georgia's Byzantine-leaning culture, the country's intimate trade connection with the Middle East is evidenced on contemporary Georgian coinage, whose legends were composed in Georgian and Arabic. A series of coins minted c. 1200 in the name of Queen Tamar depicted a local variant of the Byzantine obverse and an Arabic inscription on the reverse proclaiming Tamar as the "Champion of the Messiah".
The contemporary Georgian chronicles enshrined Christian morality and patristic literature continued to flourish, but it had, by that time, lost its earlier dominant position to secular literature, which was highly original, even though it developed in close contact with the neighboring cultures. The trend culminated in Shota Rustaveli's epic poem "The Knight in the Panther's Skin" ("Vepkhistq'aosani"), which celebrates the ideals of an "Age of Chivalry" and is revered in Georgia as the greatest achievement of native literature.
Death and burial.
Tamar outlived her consort, David Soslan, and died of a "devastating disease" not far from her capital Tbilisi, having previously crowned her son, George-Lasha, coregent. Tamar's historian relates that the queen suddenly fell ill when discussing the state affairs with her ministers at the Nacharmagevi castle near the town of Gori. She was transported to Tbilisi and then to the nearby castle of Agarani where Tamar died and was mourned by her subjects. Her remains were transferred to the cathedral of Mtskheta and then to the Gelati monastery, a family burial ground of the Georgian royal dynasty. The prevalent scholarly opinion is that Tamar died in 1213, although there are some vague indications that she might have died earlier, in 1207 or 1210.
In later times, a number of legends emerged about Tamar's place of burial. One of them has it that Tamar was buried in a secret niche at the Gelati monastery so as to prevent the grave from being profaned by her enemies. Another version suggests that Tamar's remains were reburied in a remote location, possibly in the Holy Land. The French knight Guillaume de Bois in his letter, dating from the early 13th century, written in Palestine and addressed to the bishop of Besançon, claimed that he had heard that the king of the Georgians was heading towards Jerusalem with a huge army and had already conquered many cities of the Saracens. He was carrying, the report said, the remains of his mother, the "powerful queen Tamar" ("regina potentissima Thamar"), who had been unable to make a pilgrimage to the Holy Land in her lifetime and had bequeathed her body to be buried near the Holy Sepulchre.
In the 20th century, the quest for Tamar's grave became a subject of scholarly research as well as a focus of a broader public interest. The Georgian writer Grigol Robakidze wrote in his 1918 essay on Tamar: "Thus far, nobody knows where Tamar's grave is. She belongs to everyone and to no one: her grave is in the heart of the Georgian. And in the Georgians' perception, this is not a grave, but a beautiful vase in which an unfading flower, the great Tamar, flourishes." An orthodox academic view still places Tamar's grave at Gelati, but a series of archaeological studies, beginning with Taqaishvili in 1920, has failed to locate it at the monastery.
Legacy and popular culture.
Medieval.
Over the centuries, Queen Tamar has emerged as a dominant figure in the Georgian historical pantheon. The construction of her reign as a "Golden age" began in the reign itself and Tamar became the focus of the era. Several medieval Georgian poets, including Shota Rustaveli, claimed Tamar as the inspiration for their works. A legend has it that Rustaveli was even consumed with love for the queen and ended his days in a monastery. A dramatic scene from Rustaveli's poem where the seasoned king Rostevan crowns his daughter Tinatin is an allegory to George III's co-option of Tamar. Rustaveli comments on this: "A lion cub is just as good, be it female or male".
The queen became a subject of several contemporary panegyrics, such as Chakhrukhadze's "Tamariani" and Ioane Shavteli's "Abdul-Mesia". She was eulogized in the chroniclers, most notably in the two accounts centered on her reign – "The Life of Tamar, Queen of Queens" and "The Histories and Eulogies of the Sovereigns" – which became the primary sources of Tamar's sanctification in the Georgian literature. The chroniclers exalt her as a "protector of the widowed" and "the thrice blessed", and place a particular emphasis on Tamar's virtues as a woman: beauty, humility, love of mercy, fidelity, and purity. Although Tamar was canonized by the Georgian church much later, she was even named as a saint in her lifetime in a bilingual Greco-Georgian colophon attached to the manuscript of the Vani Gospels.
The idealization of Tamar was further accentuated by the events that took place under her immediate successors; within two decades of Tamar's death, the Khwarezmian and Mongol invasions brought the Georgian ascendancy to an abrupt end. Later periods of national revival were too ephemeral to match the achievements of Tamar's reign. All of these contributed to the cult of Tamar which blurred the distinction between the idealized queen and the real personality.
In popular memory, Tamar's image has acquired a legendary and romantic façade. A diverse set of folk songs, poems and tales illustrate her as an ideal ruler, a holy woman onto whom certain attributes of pagan deities and Christian saints were sometimes projected. For example, in an old Ossetian legend, Queen Tamar conceives her son of a sunbeam which shines through the window. Another myth, from the Georgian mountains, equates Tamar with the pagan deity of weather, Pirimze, who controls winter. Similarly, in the highland district of Pshavi, Tamar's image fused with a pagan goddess of healing and female fertility.
While Tamar occasionally accompanied her army and is described as planning some campaigns, she was never directly involved in the fighting. Yet, the memory of the military victories of her reign contributed to Tamar's other popular image, that of a model warrior-queen. It also echoed in the "Tale of Queen Dinara", a popular 16th-century Russian story about a fictional Georgian queen fighting against the Persians. Tsar of All the Russias Ivan the Terrible before the seizure of Kazan encouraged his army by the examples of Tamar's battles by describing her as:
Modern.
Much of the modern perception of Queen Tamar was shaped under the influence of 19th-century Romanticism and growing nationalism among Georgian intellectuals of that time. In the Russian and Western literatures of the 19th century, the image of Queen Tamar reflected the European conceptions of the Orient – of which Georgia was perceived as a part – and the position and characteristics of women in it. The Tyrolean writer Jakob Philipp Fallmerayer described Tamar as a "Caucasian Semiramis". Fascinated by the "exotic" Caucasus, the Russian poet Mikhail Lermontov wrote the romantic poem "Tamara" (Russian: Тамара; 1841) in which he utilized the old Georgian legend about a siren-like mountainous princess whom the poet gave the name of Queen Tamar. Although Lermontov's depiction of the Georgian queen as a destructive seductress had no apparent historical background, it has been influential enough to raise the issue of Tamar's sexuality, a question that was given some prominence by the 19th-century European authors. Knut Hamsun's 1903 play "Dronning Tamara" ("Queen Tamara") was less successful; the theatre critics saw in it "a modern woman dressed in a medieval costume" and read the play as "a commentary on the new woman of the 1890s." Russian conductor Mily Balakirev composed a symphony naming it as "Tamara".
In Georgian literature, Tamar was also romanticized, but very differently from the Russian and Western European view. The Georgian romanticists followed a medieval tradition in Tamar's portrayal as a gentle, saintly woman who ruled a country permanently at war. This sentiment was further inspired by the rediscovery of a contemporary, 13th-century wall painting of Tamar in the then-ruined Betania monastery, which was uncovered and restored by Prince Grigory Gagarin in the 1840s. The fresco became a source of numerous engravings circulating in Georgia at that time and inspired the poet Grigol Orbeliani to dedicate a romantic poem to it. Furthermore, the Georgian literati, reacting to the Russian rule in Georgia and the suppression of national institutions, contrasted Tamar's era to their contemporary situation, lamenting the irretrievably lost past in their writings. Hence, Tamar became a personification of the heyday of Georgia, a perception that has persisted down to the present time.
Tamar's marriage to the Rus prince Yuri has become a subject of two resonant prose works in modern Georgia. Shalva Dadiani's play, originally entitled "The Unfortunate Russian" (უბედური რუსი; 1916–1926), was attacked by the Soviet critics for distorting the "centuries-long friendship of the Russian and Georgian peoples." Under the Communist Party pressure, Dadiani had to revise both the title and the plot to bring it into line of the official ideology. In 2002, a satyrical short-story "The First Russian" (პირველი რუსი) penned by the young Georgian writer Lasha Bughadze and focused on a frustrated wedding night of Tamar and Yuri outraged many conservatives and triggered a nationwide controversy, including heated discussions in the media, the Parliament of Georgia and the Patriarchate of the Georgian Orthodox Church.
Genealogy.
The chart below shows the abbreviated genealogy of Tamar and her family, tracing it from Tamar's grandfather to her grandchildren.

</doc>
<doc id="37764" url="http://en.wikipedia.org/wiki?curid=37764" title="Hippopotamus">
Hippopotamus

The common hippopotamus ("Hippopotamus amphibius"), or hippo, is a large, mostly herbivorous mammal in sub-Saharan Africa, and one of only two extant species in the family Hippopotamidae, the other being the pygmy hippopotamus ("Choeropsis liberiensis" or "Hexaprotodon liberiensis"). The name comes from the ancient Greek for "river horse" (ἱπποπόταμος). After the elephant and rhinoceros, the common hippopotamus is the third-largest type of land mammal and the heaviest extant artiodactyl. Despite their physical resemblance to pigs and other terrestrial even-toed ungulates, their closest living relatives are cetaceans (whales, porpoises, etc.) from which they diverged about million years ago. The common ancestor of whales and hippos split from other even-toed ungulates around million years ago. The earliest known hippopotamus fossils, belonging to the genus "Kenyapotamus" in Africa, date to around million years ago.
Common hippos are recognizable by their barrel-shaped torsos, wide-opening mouths revealing large canine tusks, nearly hairless bodies, columnar-like legs and large size; adults average 1500 kg and 1300 kg for males and females respectively. Despite its stocky shape and short legs, it is capable of running 30 km/h over short distances. The hippopotamus is a highly aggressive and unpredictable animal and is ranked among the most dangerous animals in Africa. Nevertheless, they are still threatened by habitat loss and poaching for their meat and ivory canine teeth.
The common hippopotamus is semiaquatic, inhabiting rivers, lakes and mangrove swamps, where territorial bulls preside over a stretch of river and groups of five to 30 females and young. During the day, they remain cool by staying in the water or mud; reproduction and childbirth both occur in water. They emerge at dusk to graze on grasses. While hippopotamuses rest near each other in the water, grazing is a solitary activity and hippos are not territorial on land.
Etymology.
The word "hippopotamus" is derived from the ancient Greek ἱπποπόταμος, "hippopotamos", from ἵππος, "hippos", "horse", and ποταμός, "potamos", "river", meaning "horse of the river". In English, the plural is hippopotamuses, but "hippopotami" is also used; "hippos" can be used as a short plural. Hippopotamuses are gregarious, living in groups of up to 30 animals. A group is called a pod, herd, dale, or bloat.
In Africa, the hippo is known by various names, including "seekoei" (Afrikaans), "mvuvu" (Venda), "kubu" (Lozi) and "mvubu" (Xhosa, Siswati and Zulu) in the south; "kiboko" (Swahili), e"nsherre" (Nkore), "tomondo" (Turu), "nvubu" (Luganda), "ifuru" (Luhya), "emiria" (Ateso), "magawit" (Sebei), "kibei" (Kalenjin) and "olmakau" (Maasai) in the African Great Lakes region;:256 and ጉማርረ/"gumarre" (Amharic) and "jeer" (Somali) in the Horn of Africa.
Taxonomy and origins.
Classification.
The hippopotamus is the type genus of the family Hippopotamidae. The pygmy hippopotamus belongs to a different genus in Hippopotamidae, either "Choeropsis" or "Hexaprotodon." Hippopotamidae are sometimes known as hippopotamids. Sometimes, the subfamily Hippopotaminae is used. Further, some taxonomists group hippopotamuses and anthracotheres in the superfamily Anthracotheroidea.:39 Hippopotamidae are classified along with other even-toed ungulates in the order Artiodactyla. Other artiodactyls include camels, cattle, deer and pigs, although hippopotamuses are not closely related to these groups.
Five subspecies of hippos have been described based on morphological differences in their skulls and geographical differences::3
The suggested subspecies were never widely used or validated by field biologists; the described morphological differences were small enough that they could have resulted from simple variation in nonrepresentative samples.:2 Genetic analyses have tested the existence of three of these putative subspecies. A study examining mitochondrial DNA from skin biopsies taken from 13 sampling locations, considered genetic diversity and structure among hippo populations across the continent. The authors found low, but significant, genetic differentiation among "H. a. amphibius", "H. a. capensis", and "H. a. kiboko". Neither "H. a. tschadensis" nor "H. a. constrictus" has been tested.
Evolution.
Until 1909, naturalists grouped hippos with pigs, based on molar patterns. Several lines of evidence, first from blood proteins, then from molecular systematics and DNA
 and the fossil record, show that their closest living relatives are cetaceans – whales, dolphins and porpoises. The common ancestor of hippos and whales branched off from Ruminantia and the rest of the even-toed ungulates; the cetacean and hippo lineages split soon afterwards.
The most recent theory of the origins of Hippopotamidae suggests that hippos and whales shared a common semiaquatic ancestor that branched off from other artiodactyls around million years ago. This hypothesized ancestral group likely split into two branches around million years ago. One branch would evolve into cetaceans, possibly beginning about million years ago, with the protowhale "Pakicetus" and other early whale ancestors collectively known as Archaeoceti, which eventually underwent aquatic adaptation into the completely aquatic cetaceans. The other branch became the anthracotheres, a large family of four-legged beasts, the earliest of which in the late Eocene would have resembled skinny hippopotamuses with comparatively small and narrow heads. All branches of the anthracotheres, except that which evolved into Hippopotamidae, became extinct during the Pliocene without leaving any descendants.
A rough evolutionary lineage can be traced from Eocene and Oligocene species: "Anthracotherium" and "Elomeryx" to the Miocene species "Merycopotamus" and "Libycosaurus" and the very latest anthracotheres in the Pliocene. "Merycopotamus", "Libycosaurus" and all hippopotamids can be considered to form a clade, with "Libycosaurus" being more closely related to hippos. Their common ancestor would have lived in the Miocene, about million years ago. Hippopotamids are therefore deeply nested within the family Anthracotheriidae. The Hippopotamidae are believed to have evolved in Africa; the oldest known hippopotamid is the genus "Kenyapotamus", which lived in Africa from 16 to million years ago. While hippopotamid species spread across Asia and Europe, no hippopotamuses have ever been discovered in the Americas, although various anthracothere genera emigrated into North America during the early Oligocene. From 7.5 to million years ago, an ancestor to the modern hippopotamus, "Archaeopotamus", lived in Africa and the Middle East.
While the fossil record of hippos is still poorly understood, the two modern genera, "Hippopotamus" and "Choeropsis" (sometimes "Hexaprotodon"), may have diverged as far back as million years ago. Taxonomists disagree whether or not the modern pygmy hippopotamus is a member of "Hexaprotodon" – an apparently paraphyletic genus, also embracing many extinct Asian hippopotamuses, that is more closely related to "Hippopotamus" – or of "Choeropsis", an older and basal genus.
Extinct species.
Three species of Malagasy hippopotamus became extinct during the Holocene on Madagascar, one of them within the past 1,000 years. The Malagasy hippos were smaller than the modern hippopotamus, likely through the process of insular dwarfism. Fossil evidence indicates many Malagasy hippos were hunted by humans, a likely factor in their eventual extinction. Isolated members of Malagasy hippopotamus may have survived in remote pockets; in 1976, villagers described a living animal called the "kilopilopitsofy", which may have been a Malagasy hippopotamus.
Two species of hippopotamus, the European hippopotamus ("H. antiquus") and "H. gorgops", ranged throughout continental Europe and the British Isles. Both species became extinct before the last glaciation. Ancestors of European hippos found their way to many islands of the Mediterranean during the Pleistocene. The Pleistocene also saw a number of dwarf species evolve on several Mediterranean islands, including Crete ("H. creutzburgi"), Cyprus ("H. minor"), Malta ("H. melitensis"), and Sicily ("H. pentlandi"). Of these, the Cyprus dwarf hippopotamus, survived until the end of the Pleistocene or early Holocene. Evidence from an archaeological site, Aetokremnos, continues to cause debate on whether or not the species was encountered, and was driven to extinction, by man.
Description.
Hippopotamuses are among the largest living land mammals being only smaller than elephants and some rhinoceroses. Head-and-body length is from 2.8 to, a tail of about 35 to and shoulder height averages about 1.4 to. Mean adult weight is around 1500 kg and 1300 kg for males and females respectively, very large males can reach 2000 kg and an exceptional male weighting almost 2700 kg has been reported. Male hippos appear to continue growing throughout their lives while females reach maximum weight at around age 25.
Different from all other large land mammals, hippos are of semiaquatic habits, spending the day in lakes and rivers.:3 The eyes, ears, and nostrils of hippos are placed high on the roof of their skulls. This allows these organs to remain above the surface while the rest of the body submerges.:259 Their barrel-shaped bodies have graviportal skeletal structures,:8 adapted to carrying their enormous weight, and their specific gravity allows them to sink and move along the bottom of a river. Hippopotamuses have small legs (relative to other megafauna) because the water in which they live reduces the weight burden. Though they are bulky animals, hippopotamuses can gallop at 30 km/h on land but normally trot. They are incapable of jumping but do climb up steep banks. Despite being semiaquatic and having webbed feet, an adult hippo is not a particularly good swimmer nor can it float. It is rarely found in deep water; when it is, the animal moves by porpoise-like leaps from the bottom.:3 The testes of the males descend only partially and a scrotum is not present. In addition, the penis retracts into the body when not erect. The genitals of the female are unusual in that the vagina is ridged and two large diverticula protrude from the vulval vestibule. The function of these is unknown.:28–29
The hippo's jaw is powered by a large masseter and a well-developed digastric; the latter loops up behind the former to the hyoid.:259 The jaw hinge is located far back enough to allow the animal to open its mouth at almost 180°.:17 On the National Geographic Channel television program, "Dangerous Encounters with Brady Barr", Dr. Brady Barr measured the bite force of an adult female hippo at 8100 newtons; Barr also attempted to measure the bite pressure of an adult male hippo, but had to abandon the attempt due to the male's aggressiveness. Hippopotamus teeth sharpen themselves as they grind together. The lower canines and lower incisors are enlarged, especially in males, and grow continuously. The incisors can reach 40 cm, while the canines reach up to 50 cm. The canines and incisors are used for combat and play no role in feeding. Hippos rely on their broad horny lips to grasp and pull grasses which are then ground by the molars.:259, 263 The hippo is considered to be a pseudoruminant; it has a complex three- or four-chambered stomach but does not "chew cud".:22
Unlike most other semiaquatic animals, the hippopotamus has very little hair.:260 The skin is 15 cm thick, providing it great protection against conspecifics and predators. By contrast, its subcutaneous fat layer is thin.:3 The animals' upper parts are purplish-gray to blue-black, while the under parts and areas around the eyes and ears can be brownish-pink.:260 Their skin secretes a natural sunscreen substance which is red-colored. The secretion is sometimes referred to as "blood sweat", but is neither blood nor sweat. This secretion is initially colorless and turns red-orange within minutes, eventually becoming brown. Two distinct pigments have been identified in the secretions, one red (hipposudoric acid) and one orange (norhipposudoric acid). The two pigments are highly acidic compounds. Both pigments inhibit the growth of disease-causing bacteria; as well, the light absorption of both pigments peaks in the ultraviolet range, creating a sunscreen effect. All hippos, even those with different diets, secrete the pigments, so it does not appear that food is the source of the pigments. Instead, the animals may synthesize the pigments from precursors such as the amino acid tyrosine. Nevertheless, this natural sunscreen cannot prevent the animal's skin from cracking if it stays out of water too long.
A hippo's lifespan is typically 40–50 years.:277 Donna the Hippo was the oldest living hippo in captivity. She lived at the Mesker Park Zoo in Evansville, Indiana in the US until her death in 2012 at the age of 61. The oldest hippo ever recorded was called Tanga; she lived in Munich, Germany, and died in 1995 at the age of 61.
Distribution.
"Hippopotamus amphibius" was widespread in North Africa and Europe during the Eemian and late Pleistocene until about 30,000 years ago. Archaeological evidence exists of its presence in the Levant, dating to less than 3,000 years ago. The species was common in Egypt's Nile region during antiquity, but has since been extirpated. Pliny the Elder writes that, in his time, the best location in Egypt for capturing this animal was in the Saite nome; the animal could still be found along the Damietta branch after the Arab Conquest in 639. Hippos are still found in the rivers and lakes of the northern Democratic Republic of the Congo, Uganda, Tanzania and Kenya, north through to Ethiopia, Somalia and Sudan, west to Gambia, and south to South Africa. They inhabit both savanna and forest areas.
Conservation status.
Genetic evidence suggests that common hippos in Africa experienced a marked population expansion during or after the Pleistocene epoch, attributed to an increase in water bodies at the end of the era. These findings have important conservation implications as hippo populations across the continent are currently threatened by loss of access to fresh water. Hippos are also subject to unregulated hunting and poaching. In May 2006, the hippopotamus was identified as a vulnerable species on the IUCN Red List drawn up by the World Conservation Union (IUCN), with an estimated population of between 125,000 and 150,000 hippos, a decline of between 7% and 20% since the IUCN's 1996 study. Zambia (40,000) and Tanzania (20,000–30,000) possess the largest populations.
The hippo population declined most dramatically in the Democratic Republic of the Congo. The population in Virunga National Park had dropped to 800 or 900 from around 29,000 in the mid-1970s. The decline is attributed to the disruptions caused by the Second Congo War. The poachers are believed to be Mai-Mai rebels, poorly paid Congolese soldiers, and local militia groups. Reasons for poaching include the belief that hippos are harmful to society, as well as financial gain. The sale of hippo meat is illegal, but black-market sales are difficult for Virunga National Park officers to track. Hippo meat is considered a delicacy in some areas of central Africa and the teeth have become a valued substitute for elephant ivory.
Invasive potential.
In the late 1980s, Pablo Escobar kept four hippos in a private menagerie at his residence in Hacienda Nápoles, 100 km east of Medellín, Colombia, after buying them in New Orleans. They were deemed too difficult to seize and move after Escobar's death, and hence left on the untended estate. By 2007, the animals had multiplied to 16 and had taken to roaming the area for food in the nearby Magdalena River. In 2009, two adults and one calf escaped the herd and, after attacking humans and killing cattle, one of the adults (called "Pepe") was killed by hunters under authorization of the local authorities. As of early 2014, 40 hippos have been reported to exist in Puerto Triunfo, Antioquia from the original four belonging to Escobar. The National Geographic Channel produced a documentary about them titled "Cocaine Hippos".
Behavior.
With the exception of eating, most of hippopotamuses' lives – from childbirth, fighting with other hippos, to reproduction – occurs in the water. Hippos leave the water at dusk and travel inland, sometimes up to 10 km, to graze on short grasses, their main source of food. They spend four to five hours grazing and can consume 68 kg of grass each night. Like almost any herbivore, they consume other plants if presented with them, but their diet in nature consists almost entirely of grass, with only minimal consumption of aquatic plants. Hippos are born with sterile intestines, and require bacteria obtained from their mothers' feces to digest vegetation. Hippos have (rarely) been filmed eating carrion, usually close to the water. There are other reports of meat-eating, and even cannibalism and predation. The stomach anatomy of a hippo is not suited to carnivory, and meat-eating is likely caused by aberrant behavior or nutritional stress.:84
Hippo defecation creates allochthonous deposits of organic matter along the river beds. These deposits have an unclear ecological function. Because of their size and their habit of taking the same paths to feed, hippos can have a significant impact on the land across which they walk, both by keeping the land clear of vegetation and depressing the ground. Over prolonged periods, hippos can divert the paths of swamps and channels.
Adult hippos move at speeds up to 8 km/h in water; typically resurfacing to breathe every three to five minutes. The young have to breathe every two to three minutes.:4 The process of surfacing and breathing is automatic. A hippo sleeping underwater rises and breathes without waking. A hippo closes its nostrils when it submerges into the water. As with fish and turtles on a coral reef, hippos occasionally visit cleaning stations and signal, by opening their mouths wide, their readiness for being cleaned of parasites by certain species of fishes. This is an example of mutualism in which the hippo benefits from the cleaning, while the fish receive food.
Social life.
Studying the interaction of male and female hippopotamuses has long been complicated because hippos are not sexually dimorphic; thus females and young males are almost indistinguishable in the field. Although hippos lie close to each other, they do not seem to form social bonds except between mothers and daughters, and they are not social animals. The reason they huddle close together is unknown.:49
Hippopotamuses are territorial only in water, where a bull presides over a small stretch of river, on average 250 m in length, and containing 10 females. The largest pods can contain over 100 hippos.:50 Other bachelors are allowed in a bull's stretch, as long as they behave submissively toward the bull. The territories of hippos exist to establish mating rights. Within the pods, the hippos tend to segregate by gender. Bachelors lounge near other bachelors, females with other females, and the bull on his own. When hippos emerge from the water to graze, they do so individually.:4
Hippopotamuses appear to communicate vocally, through grunts and bellows, and they may practice echolocation, but the purpose of these vocalizations is currently unknown. Hippos have the unique ability to hold their heads partially above the water and send out a cry that travels through both water and air; individuals respond above and under water.
Reproduction.
Female hippos reach sexual maturity at five to six years of age and have a gestation period of eight months. A study of endocrine systems revealed that female hippopotamuses may begin puberty as early as three or four years of age. Males reach maturity at around 7.5 yr. A study of hippopotamus reproductive behavior in Uganda showed that peak conceptions occurred during the end of the wet season in the summer, and peak births occurred toward the beginning of the wet season in late winter. This is because of the female's estrous cycle; as with most large mammals, male hippopotamus spermatozoa is active year round. Studies of hippos in Zambia and South Africa also showed evidence of births occurring at the start of the wet season.:60–61 After becoming pregnant, a female hippopotamus will typically not begin ovulation again for 17 months.
Mating occurs in the water, with the female submerged for most of the encounter,:63 her head emerging periodically to draw breath. Baby hippos are born underwater at a weight between 25 and and an average length of around 127 cm, and must swim to the surface to take their first breaths. A mother typically gives birth to only one calf, although twins also occur. The young often rest on their mothers' backs when the water is too deep for them, and they swim under water to suckle. They suckle on land when the mother leaves the water. Weaning starts between six and eight months after birth, and most calves are fully weaned after a year.:64 Like many other large mammals, hippos are described as K-strategists, in this case typically producing just one large, well-developed infant every couple of years (rather than many small, poorly developed young several times per year as is common among small mammals such as rodents).
Aggression.
Hippopotamuses are aggressive animals. Hippos that attack other animals are often either territorial bulls or females protecting their calves. Hippopotamus coexist with a variety of formidable predators. Nile crocodiles, lions and spotted hyenas are known to prey on young hippos.:273:118 However, due to their aggression and size, adult hippopotamus are not usually preyed upon by other animals. Cases where large lion prides or cooperating groups of Nile crocodiles have successfully preyed on adult hippopotamus have been reported; however, this predation is exceptionally rare. Crocodiles are frequent targets of hippo aggression, probably because they often inhabit the same riparian habitats; crocodiles may be either aggressively displaced or killed by hippopotamuses. Hippos are also very aggressive towards humans, whom they sometimes attack whether in boats or on land, commonly with no apparent provocation, and are widely considered to be one of the most dangerous large animals in Africa.
Hippos mark their territory by defecation. While depositing the faeces, hippos spin their tails to distribute their excrement over a greater area. "Yawning" serves as a threat display. When fighting, male hippos use their incisors to block each other's attacks and their large canines to inflict injuries.:260 When hippos become over-populated or a habitat is reduced, bulls sometimes attempt infantacide, but this behavior is not common under normal conditions. Incidents of hippo cannibalism have been documented, but this is believed to be the behavior of distressed or sick hippos.:82–83
Hippos and humans.
The earliest evidence of human interaction with hippos comes from butchery cut marks on hippo bones at Bouri Formation dated around 160,000 years ago. Later rock paintings and engravings showing hippos being hunted have been found in the mountains of the central Sahara dated 4,000–5,000 years ago near Djanet in the Tassili n'Ajjer Mountains.:1 The ancient Egyptians recognized the hippo as a ferocious denizen of the Nile.
The hippopotamus was also known to the Greeks and Romans. The Greek historian Herodotus described the hippopotamus in "The Histories" (written "circa" 440 BC) and the Roman naturalist Pliny the Elder wrote about the hippopotamus in his encyclopedia "Naturalis Historia" (written "circa" 77 AD).
Zulu warriors preferred to be as brave as a hippopotamus, since even lions were not considered to match its courage. "In 1888, Captain Baden-Powell was part of a column searching for the Zulu chief Dinuzulu, who was leading the Usutu people in revolt against the British colonists. The column was joined by John Dunn, a white Zulu chief, who led an "impi" (army) of 2,000 Zulu warriors to join the British." 
The words of the Zulu anthem sounded like this:
""Een-gonyama Gonyama! Invooboo! Yah-bo! Yah-bo! Invooboo!"
"John Dunn was at the head of his "impi". [Baden Powell] asked him to translate the Zulu anthem his men had been singing. Dunn laughed and replied: 'He is a lion. Yes, he is better than a lion – he is a hippopotamus.'"
In the U.S., Representative Robert F. Broussard of Louisiana introduced the "American Hippo bill" in 1910 to authorize the importation and release of hippopotamus into the bayous of Louisiana. Broussard argued that the hippopotamus would eat the invasive water hyacinth that was clogging the rivers and also produce meat to help solve the American meat crisis. The chief collaborators and proponents of Broussard's bill were Major Frederick Russell Burnham and Captain Fritz Duquesne Former President Theodore Roosevelt backed the plan, as did the U.S. Department of Agriculture, "The Washington Post", and "The New York Times" which praised the taste of hippopotamus as "lake cow bacon". The "American Hippo Bill" fell just short of being passed.
Attacks on humans.
The hippopotamus is considered very aggressive and has frequently been reported as charging and attacking boats. Small boats can be capsized by hippos and passengers can be injured or killed by the animals or drown. In one case in Niger, a boat was capsized by a hippo and 13 people were killed. As hippopotamuses will often engage in raiding nearby crops if the opportunity arises, humans may also come in conflict with them on these occasions, with potential for fatalities on both sides.
Hippos in zoos.
Hippopotamuses have long been popular zoo animals. The first zoo hippo in modern history was Obaysch, which arrived at the London Zoo on May 25, 1850, where he attracted up to 10,000 visitors a day and inspired a popular song, the "Hippopotamus Polka". Hippos have remained popular zoo animals since Obaysch, and generally breed well in captivity. Their birth rates are lower than in the wild, but this is attributed to zoos not wanting to breed as many hippos as possible, since hippos are large and relatively expensive animals to maintain.:129
Like many zoo animals, hippos were traditionally displayed in concrete exhibits. In the case of hippos, they usually had a pool of water and patch of grass. In the 1980s, zoo designers increasingly designed exhibits that reflected the animals' native habitats. One of these, the Toledo Zoo Hippoquarium, features a 360,000 gallon pool for hippos. In 1987, researchers were able to record for the first time an underwater birth as in the wild at the Toledo Zoo. The exhibit was so popular, the hippos became the logo of the Toledo Zoo.
Cultural depictions.
A red hippo represented the Ancient Egyptian god Set; the thigh is the "phallic leg of Set" symbolic of virility. Set's consort Tawaret was also seen as part hippo and was a goddess of protection in pregnancy and childbirth, because ancient Egyptians recognized the protective nature of a female hippopotamus toward her young. The Ijo people wore masks of aquatic animals like the hippo when practicing their water spirit cults. The Behemoth from the Book of Job, 40:15–24 is thought to be based on a hippo.
Hippos have been the subjects of various African folktales. According to a San story; when the Creator assigned each animal its place in nature, the hippos wanted to live in the water, but were refused out of fear that they might eat all the fish. After begging and pleading, the hippos were finally allowed to live in the water on the conditions that they would eat grass instead of fish and would fling their dung so that it can be inspected for fish bones. In a Ndebele tale, the hippo originally had long, beautiful hair, but was set on fire by a jealous hare and had to jump into a nearby pool. The hippo lost most of his hair and was too embarrassed to leave the water.
Ever since Obaysch inspired the "Hippopotamus Polka", hippos have been popular animals in Western culture for their rotund appearance that many consider comical. Stories of hippos such as Huberta, which became a celebrity in South Africa in the 1930s for trekking across the country; or the tale of Owen and Mzee, a hippo and tortoise which developed an intimate bond; have amused people who have bought hippo books, merchandise, and many stuffed hippo toys. Hippos were mentioned in the novelty Christmas song "I Want a Hippopotamus for Christmas" that became a hit for child star Gayla Peevey in 1953. They also feature in the songs "The Hippopotamus" and "Hippo Encore" by Flanders and Swann, with the famous refrain "Mud, Mud, Glorious Mud". They even inspired a popular board game, Hungry Hungry Hippos.
Hippos have also been popular cartoon characters, where their rotund frames are used for humorous effect. The Disney film "Fantasia" featured a ballerina hippopotamus dancing to the opera "La Gioconda". Other cartoon hippos have included Hanna-Barbera's Peter Potamus, the book and TV series "George and Martha", Flavio and Marita on the "Animaniacs", Pat of the French duo "Pat et Stanley", "The Backyardigan's" Tasha, The Moomins, and Gloria and Moto-Moto from the "Madagascar" franchise.
The hippopotamus characters "Happy Hippos" were created in 1987 by the French designer André Roche to be hidden in the "Kinder Surprise egg" of the Italian chocolate company Ferrero SpA. The Nintendo Company published Game Boy adventures of them in 2001 and 2007. In the game of chess, the hippopotamus lends its name to the Hippopotamus Defense, an opening system, which is generally considered weak. "The River Horse" is a popular outdoor sculpture at George Washington University in Washington, D.C.

</doc>
<doc id="37765" url="http://en.wikipedia.org/wiki?curid=37765" title="University of California, Los Angeles">
University of California, Los Angeles

The University of California, Los Angeles (UCLA) is a public research university located in the Westwood neighborhood of Los Angeles, California, United States. It became the University of California Southern Branch in 1919, making it the second-oldest undergraduate campus of the ten-campus system after the original University of California campus in Berkeley (1873). It offers 337 undergraduate and graduate degree programs in a wide range of disciplines. With an approximate enrollment of 30,000 undergraduate and 12,000 graduate students, UCLA has the highest enrollment of any university in California and is the most applied to university in the United States with over 112,000 applications for fall 2015.
The university is organized into five undergraduate colleges, seven professional schools, and four professional health science schools. The undergraduate colleges are the College of Letters and Science; Henry Samueli School of Engineering and Applied Science (HSSEAS); School of the Arts and Architecture; School of Theater, Film, and Television; and School of Nursing. Fifteen Nobel laureates, one Fields Medalist, and three Turing Award winners have been faculty, researchers, or alumni. Among the current faculty members, 55 have been elected to the National Academy of Sciences, 28 to the National Academy of Engineering, 39 to the Institute of Medicine, and 124 to the American Academy of Arts and Sciences. The university was elected to the Association of American Universities in 1974.
UCLA student-athletes compete as the Bruins in the Pacific-12 Conference. The Bruins have won 125 national championships, including 112 NCAA team championships. UCLA student-athletes have won 250 Olympic medals: 125 gold, 65 silver and 60 bronze. The Bruins have competed in every Olympics since 1920 with one exception (1924), and have won a gold medal in every Olympics that the United States has participated in since 1932.
History.
In March 1881, after heavy lobbying by Los Angeles residents, the California State Legislature authorized the creation of a southern branch of the California State Normal School (which later became San Jose State University) in downtown Los Angeles to train teachers for the growing population of Southern California. The State Normal School at Los Angeles opened on August 29, 1882, on what is now the site of the Central Library of the Los Angeles Public Library system. The new facility included an elementary school where teachers-in-training could practice their teaching technique on children. That elementary school is related to the present day version, UCLA Lab School. In 1887, the school became known as the Los Angeles State Normal School.
In 1914, the school moved to a new campus on Vermont Avenue (now the site of Los Angeles City College) in East Hollywood. In 1917, UC Regent Edward Augustus Dickson, the only regent representing the Southland at the time, and Ernest Carroll Moore, Director of the Normal School, began working together to lobby the State Legislature to enable the school to become the second University of California campus, after UC Berkeley. They met resistance from UC Berkeley alumni, Northern California members of the state legislature, and Benjamin Ide Wheeler, President of the University of California from 1899 to 1919, who were all vigorously opposed to the idea of a southern campus. However, David Prescott Barrows, the new President of the University of California, did not share Wheeler's objections. On May 23, 1919, the Southern Californians' efforts were rewarded when Governor William D. Stephens signed Assembly Bill 626 into law, which merged the Los Angeles Normal School with the University of California as the Southern Branch of the University of California. The same legislation added its general undergraduate program, the College of Letters and Science. The Southern Branch campus opened on September 15 of that year, offering two-year undergraduate programs to 250 Letters and Science students and 1,250 students in the Teachers College, under Moore's continued direction.
Under University of California President William Wallace Campbell, enrollment at the Southern Branch expanded so rapidly that by the mid-1920s the institution was outgrowing the 25 acre Vermont Avenue location. The Regents conducted a search for a new location and announced their selection of the so-called "Beverly Site"—just west of Beverly Hills—on March 21, 1925 edging out the panoramic hills of the still-empty Palos Verdes Peninsula. After the athletic teams entered the Pacific Coast conference in 1926, the Southern Branch student council adopted the nickname "Bruins", a name offered by the student council at UC Berkeley. In 1927, the Regents renamed the Southern Branch the "University of California at Los Angeles" (the word "at" was officially replaced by a comma in 1958, in line with other UC campuses). In the same year, the state broke ground in Westwood on land sold for $1 million, less than one-third its value, by real estate developers Edwin and Harold Janss, for whom the Janss Steps are named.
The original four buildings were the College Library (now Powell Library), Royce Hall, the Physics-Biology Building (now the Humanities Building), and the Chemistry Building (now Haines Hall), arrayed around a quadrangular courtyard on the 400 acre (1.6 km²) campus. The first undergraduate classes on the new campus were held in 1929 with 5,500 students. In 1933, after further lobbying by alumni, faculty, administration and community leaders, UCLA was permitted to award the master's degree, and in 1936, the doctorate, against continued resistance from UC Berkeley.
A timeline of the history can be found on its website, as well as a published book.
Maturity as a university.
For the first 32 years of its existence, UCLA was treated as an off-site department of UC. As such, its presiding officer was called a "provost," and reported to the main campus in Berkeley. In 1951, UCLA was formally elevated to co-equal status with UC Berkeley, and its presiding officer was granted the title of chancellor. Raymond B. Allen was the first chief executive with that title. The appointment of Franklin David Murphy to the position of Chancellor in 1960 helped to spark an era of tremendous growth of facilities and faculty honors. By the end of the decade, UCLA had achieved distinction in a wide range of subjects. This era also secured UCLA's position as a proper university in its own right and not simply a branch of the UC system. This change is exemplified by an incident involving Chancellor Murphy, which was described by him later on:
I picked up the telephone and called in from somewhere, and the phone operator said, "University of California." And I said, "Is this Berkeley?" She said, "No." I said, "Well, who have I gotten to?" "UCLA." I said, "Why didn't you say UCLA?" "Oh," she said, "we're instructed to say University of California." So the next morning I went to the office and wrote a memo; I said, "Will you please instruct the operators, as of noon today, when they answer the phone to say, 'UCLA.'" And they said, "You know they won't like it at Berkeley." And I said, "Well, let's just see. There are a few things maybe we can do around here without getting their permission."
In 2006, the university completed Campaign UCLA, which collected over $3.05 billion and is the second most successful fundraising campaign among public universities. In 2008, UCLA raised over $456 million, ranking the institution among the top 10 universities in the United States in total fundraising for the year.
On January 26, 2011, Meyer and Renee Luskin donated $100 million to UCLA. On February 14, 2011, UCLA received a $200 million donation gift by The Lincy Foundation in order to establish The Dream Fund, which is "a community-based fund devoted to the support of medical research and academic programs at UCLA".
In 2014, the university launched the Centennial Campaign for UCLA, which is intended to raise $4.2 billion by 2019.
Campus.
When UCLA opened its new campus in 1929, it had four buildings: Royce Hall and Haines Hall on the north, and Powell Library and Kinsey Hall (now the Humanities Building) on the south. The Janss Steps were the original 87-step entrance to the university that lead directly to the quad of these four buildings. Today, the campus includes 163 buildings across 419 acres (1.7 km²) in the western part of Los Angeles, north of the Westwood shopping district and just south of Sunset Boulevard. In terms of acreage, it is the second smallest of the ten UC campuses. The campus is close but not adjacent to the 405 San Diego Freeway.
The campus is located in the residential area of Westwood and bordered by Bel-Air to the north, Beverly Hills to the east, and Brentwood to the west. The campus is informally divided into North Campus and South Campus, which are both on the eastern half of the university's land. North Campus is the original campus core; its buildings are more old-fashioned in appearance and clad in imported Italian brick. North Campus is home to the arts, humanities, social sciences, law, and business programs and is centered around ficus and sycamore-lined Dickson Court, also known as the "Sunken Garden". South Campus is home to the physical sciences, life sciences, engineering, mathematical sciences, health-related fields, and the UCLA Medical Center. The campus includes sculpture gardens, fountains, museums, and a mix of architectural styles.
Ackerman Union, the John Wooden Center, the Arthur Ashe Health and Wellness Center, the Student Activities Center, Kerckhoff Hall, the J.D. Morgan Center, the James West Alumni Center, and Pauley Pavilion stand at the center of the campus, bordering Wilson Plaza. The campus is bisected by Bruin Walk, a heavily traveled pathway from the residential hill to the main campus. At the intersection of Bruin Walk and Westwood Plaza is Bruin Plaza, featuring an outdoor performing arts stage and a bronze statue of the Bruin bear.
Architecture.
The first campus buildings were designed by the local firm Allison & Allison. The Romanesque Revival style of these first four structures remained the predominant building style on campus until the 1950s, when architect Welton Becket was hired to supervise the expansion of the campus over the next two decades. Becket greatly streamlined the
general appearance of the campus, adding several rows of minimalist, slab–shaped brick buildings to the southern half of the campus, the largest of these being the UCLA Medical Center. Architects such as A. Quincy Jones, William Pereira and Paul Williams designed many subsequent structures on the campus during the mid-20th century. More recent additions include buildings designed by architects I.M. Pei, Venturi, Scott Brown and Associates, Richard Meier, Cesar Pelli, and Rafael Vinoly. In order to accommodate UCLA's rapidly growing student population, multiple construction and renovation projects are in progress, including expansions of the life sciences and engineering research complexes. This continuous construction gives UCLA the on-campus nickname of "Under Construction Like Always".
The tallest building on campus is named after African-American alumnus Ralph Bunche, who received the 1950 Nobel Peace Prize for negotiating an armistice agreement between the Jews and Arabs in Israel. The entrance of Bunche Hall features a bust of him overlooking the Franklin D. Murphy Sculpture Garden. He was the first individual of non-European background and the first UCLA alumnus to be honored with the Prize.
The Hannah Carter Japanese Garden is located a mile north of campus, in the community of Bel Air. The garden was designed by landscape architect Nagao Sakurai of Tokyo and garden designer Kazuo Nakamura of Kyoto in 1959. After the garden was damaged by heavy rains in 1969, UCLA Professor of Art and Campus Architect Koichi Kawana took on the task of its reconstruction.
Filming.
With a location near Hollywood, UCLA has attracted filming for decades. Much of the 1985 film "Gotcha!" was shot at UCLA, as well as John Singleton's "Higher Learning" (1995). "Legally Blonde" (2001), "Old School" (2003), "The Nutty Professor" (1995), "Erin Brockovich" (2000), "How High" (2001), "National Lampoon's Van Wilder" (2002), "American Pie 2" (2001), and "Bring It On Again" (2004) were all mainly shot at the university campus or locale. In January 2009, the Bollywood movie "My Name is Khan" was shot at UCLA. UCLA is also often cast as Stanford, in tv shows such as "The Mindy Project" and "Chuck". Some of the exterior shots of the fictional UC Sunnydale in "Buffy the Vampire Slayer", and ABC Family original series "Greek" were also filmed at UCLA. In response to the major demand for filming, UCLA instated a policy on filming and professional photography at the campus.
"UCLA is located in Los Angeles, the same place as the American motion picture industry", said UCLA visiting professor of film and television Jonathan Kuntz. "So we're convenient for (almost) all of the movie companies, TV production companies, commercial companies and so on. We're right where the action is."
Transportation and parking.
The campus maintains 24,000 parking spaces and operates an award-winning sustainable transportation program. Elements of the sustainable transportation program include vanpools, a campus shuttle system called BruinBus, discounted carpool permits, and subsidized transit passes. One of the pass programs includes BruinGo!, which allows students and staff members to purchase discounted one-way or quarterly passes to ride Santa Monica's Big Blue Bus and the Culver CityBus.
2014 flooding.
On July 29, 2014, a nearly century-old water main burst on the section of Sunset Boulevard immediately above campus, sending approximately twenty million gallons of water flooding below. The nearly four hour rush of water caused damage to buildings and athletic facilities, including Pauley Pavilion and the Wooden Center. In addition, several parking structures were partially inundated, trapping nearly 740 cars.
UCLA offered emergency assistance in the form of interest-free loans to students and staff whose cars were damaged by the flood. Loans of up to $5,000 are available to victims, and are to be repaid in the span of two years through payroll deduction.
Academics.
Healthcare.
The David Geffen School of Medicine, School of Nursing, School of Dentistry and Fielding School of Public Health constitute the professional schools of health science.
The UCLA Health System operates the Ronald Reagan UCLA Medical Center, a hospital in Santa Monica and twelve primary care clinics throughout Los Angeles County. In addition, the UCLA David Geffen School of Medicine uses two Los Angeles County public hospitals as teaching hospitals—Harbor-UCLA Medical Center and Olive View-UCLA Medical Center—as well as the largest private nonprofit hospital on the west coast, Cedars-Sinai Medical Center. The Greater Los Angeles VA Medical Center is also a major teaching and training site for the university.
In 1981, the UCLA Medical Center made history when Assistant Professor Michael Gottlieb first diagnosed an unknown affliction later to be called AIDS. UCLA medical researchers also pioneered the use of positron emission tomography (PET) scanning to study brain function. Professor of Pharmacology Louis Ignarro was one of the recipients of the 1998 Nobel Prize in Physiology or Medicine for discovering the signaling cascade of nitric oxide, one of the most important molecules in cardiopulmonary physiology.
The "U.S. News & World Report" Best Hospitals ranking for 2014-2015 ranks UCLA Medical Center #5 and "Best in the West" in the United States. UCLA Medical Center ranked in the top 20 in 15 of the 16 medical specialty areas examined.
Rankings.
Global.
The "Times Higher Education World University Rankings" for 2014–2015 ranks UCLA 12th for academics and 13th for reputation. In 2014, UCLA was ranked 37th in the "QS World University Rankings", 12th in the world (10th in North America) by the "Academic Ranking of World Universities (ARWU)" and 23rd in the world (13th in North America) in "Financial Times"' Global MBA Rankings. In 2013, "Business Insider" ranked UCLA as having the most driven students in the world. In 2014, the Center for World University Rankings (CWUR) ranked the university 15th in the world based on quality of education, alumni employment, quality of faculty, publications, influence, citations, broad impact, and patents. s of March 2015[ [update]], "U.S. News & World Report" ranked UCLA #8 in their "Best Global University Rankings". In 2014, "Business Insider" ranked UCLA #5 in the world for the number of alumni working at Google (behind Stanford, UC Berkeley, Carnegie Mellon and MIT).
National.
The 2015 "U.S. News & World Report" Best Colleges report ranked UCLA second among public universities (tied with the University of Virginia) and 23rd among national universities. "The Washington Monthly" ranked UCLA fifth among national universities in 2014, with criteria based on research, community service, and social mobility. "Money Magazine" ranked UCLA 31st in the country out of the nearly 1500 schools it evaluated for its 2014 Best Colleges ranking. In 2014, "The Daily Beast"'s Best Colleges report ranked UCLA 10th in the country. In 2014 "Kiplinger" ranked UCLA the 5th best-value public university in the nation, and 1st in California. The 2013 "Top American Research Universities" report by the Center for Measuring University Performance ranks UCLA #11 in power, #12 in resources, faculty, and education, #14 in resources and education and #9 in education. The 2014 "Princeton Review" College Hopes & Worries Survey ranked UCLA as the #7 "Dream College" among college applicants. The National Science Foundation ranked UCLA 10th in the nation for research and development expenditures in 2013, spending $967 million. The university is one of the Public Ivies, a public university considered to provide an education comparable to those of the Ivy League.
s of March 2015[ [update]], the "U.S. News & World Report" Best Colleges report ranked UCLA #11 among national universities for campus ethnic diversity, #1 among national universities for economic diversity among the top 25 ranked schools, #22 among national universities for high school counselor rankings, and tied for #3 among national universities for freshman retention rate. In 2014, the Institute of International Education ranked UCLA #6 in the country for having the most international students (behind NYU, USC, the University of Illinois, Columbia and Purdue). In 2014, "Business Insider" ranked UCLA #8 among the Smartest Public Colleges in America based on the average of the 25th and 75th percentiles of the combined SAT Math and Verbal scores of enrolled undergraduates.
Graduate school.
s of March 2015[ [update]], the "U.S. News & World Report" Best Graduate Schools report ranked the Graduate School of Education and Information Studies (GSEIS) at #13, the Anderson School of Management at #15, the David Geffen School of Medicine at #7 for Primary Care and #13 for Research, the School of Law at #16, the Henry Samueli School of Engineering and Applied Science (HSSEAS) at #14, and the School of Nursing #19. The QS Global 200 MBA Rankings report for 2015 ranks the Anderson School of Management #9 among North American business schools. The 2014 "Economist" ranking of Full-time MBA programs ranks the Anderson School of Management #13 in the world. The 2014 "Financial Times" ranking of MBA programs ranks the Anderson School #26 in the world. The 2014 "Bloomberg Businessweek" ranking of Full-time MBA programs ranks the Anderson School of Management #11 in the United States. The 2014 "Business Insider" ranking of the world's best business schools ranks the Anderson School of Management #20 in the world.
Departmental.
Departmental rankings in the national top ten according to the 2015 "U.S. News & World Report" Best Graduate Schools report include Clinical Psychology (#1), Psychology (#2), Fine Arts (#4), Mathematics (#7), History (#9), Sociology (#9), English (#10), Political Science (#10), and Public Health (#10). Among engineering departments, the Computer Science department is ranked #13.
Departmental rankings in the global top ten according to the 2015 "U.S. News & World Report" Best Global Universities report include Chemistry (#5), Clinical Medicine (#7), Mathematics (#4), Neuroscience and Behavior (#6), Psychiatry/Psychology (#4) and Social Sciences and Public Health (#7).
Departmental rankings in the global top ten according to the "Academic Ranking of World Universities" (ARWU) for 2014 include Mathematics (#9), Computer Science (#9) and Chemistry (#10).
Departmental rankings in the global top ten according to the "QS World University Rankings" for 2014 include Modern Languages (#9), Linguistics (#2), English Language & Literature (#10), Medicine (#5), Psychology (#6), Mathematics (#8), Earth & Marine Sciences (#10), Chemistry (#10), Geography (#6), Statistics & Operational Research (#8), and Sociology (#2).
Academic field.
Academic field rankings in the global top ten according to the "Academic Ranking of World Universities" for 2014 include Natural Sciences and Mathematics (#9) and Clinical Medicine and Pharmacy (#9).
Academic field rankings in the global top ten according to the "Times Higher Education World University Rankings" for 2014-2015 include Arts & Humanities (#10), Clinical, Pre-clinical and Health (#9), Engineering and Technology (#9), Physical Sciences (#9), and Social Sciences (#9).
Library system.
UCLA's library system has over nine million books and 70,000 serials spread over twelve libraries and eleven other archives, reading rooms, and research centers. It is the United States' 12th largest library in number of volumes.
The first library, University Library (presently Powell Library), was founded in 1884. In 1910, Elizabeth Fargo became the university's first librarian. Lawrence Powell became librarian in 1944, and began a series of system overhauls and modifications, and in 1959, he was named Dean of the School of Library Service. More libraries were added as previous ones filled. Page Ackerman became University Librarian in 1973, and was the nation's first female librarian of a system as large as UCLA's. She oversaw the first coordinations between other UC schools, and formed a new administrative network that is still in use today. Since her retirement, the system has seen steady growth and improvement under various Librarians. The present University Librarian is Virginia Steel, who took office on July 15, 2013.
Medical school admissions.
According to the Association of American Medical Colleges (AAMC), UCLA supplies the most undergraduate applicants to U.S. medical schools among all American universities. In 2014, UCLA supplied 919 medical school applicants, ahead of the University of Michigan with 825 medical school applicants, followed by UC Berkeley with 769 medical school applicants.
Among first-time medical school applicants who received their Bachelor's degree from UCLA in 2013, 53% were admitted to at least one U.S. medical school.
Admissions.
Undergraduate.
Freshman statistics
UCLA is rated "Most Selective" by "U.S. News & World Report." It received 92,681 freshman applications for Fall 2015, the highest number of any four-year university in the United States. As of Fall 2014, UCLA is the second-most selective UC campus, with an admittance rate of 18.6%, and the most selective UC campus for California residents, with an admittance rate of 16.9% for California residents.
Approximately 3,200 transfer students entered UCLA in Fall 2014, with 92.3% from the California Community Colleges System. Over the past 15 years over 45,000 transfer students have entered UCLA. One-third of baccalaureate degrees are awarded to students who entered UCLA as transfer students. One of the major debates is over the decreased admission of African-Americans, especially since the passage of Proposition 209 in 1996, prohibiting racial or sexual discrimination at public institutions. In response to this issue, UCLA shifted to a more holistic admissions process starting Fall 2007.
Admitted freshman applicants for Fall 2014 had an average weighted GPA of 4.39 (3.89 unweighted), a combined SAT Reasoning Test score in the interquartile range of 1940 - 2240 (with an interquartile range of 620 - 740 for Critical Reading, an interquartile range of 650 - 770 for Mathematics, and an interquartile range of 640 - 760 for Writing) and an average ACT Composite score in the interquartile range of 28 - 34.
Graduate.
For Fall 2014, the David Geffen School of Medicine admitted 3.2% of its applicants, making it the #9 most selective U.S. medical school. For Fall 2014, the School of Law admitted 27.9% of applicants, with a median undergraduate GPA of 3.79 and median Law School Admission Test (LSAT) score of 167 for the incoming class of 2017. For Fall 2014, the Anderson School of Management admitted 18% of applicants with an average Graduate Management Admission Test (GMAT) score of 714 for the class of 2016.
The average Dental Admissions Test (DAT) scores for admitted students in the School of Dentistry for the class of 2017 were 22 in both the academic and perceptual ability sections. The Graduate School of Nursing currently has an acceptance rate of 3.9%.
Crime.
In 2012, "Business Insider" rated UCLA the most dangerous college campus in the US with 921 property crimes, and 49 violent crimes (recorded in 2011). UCLA's director of media relations responded stating crime reports are taken both on and off campus, including the multiple UCLA medical centers and clinics in Los Angeles County, suggesting data might be inflated. Other media outlets, such as the Los Angeles Times, LAist, and LA Weekly disputed the ranking.
Economic impact.
The university has a significant impact in the Los Angeles economy. It is the fifth largest employer in the county (after Los Angeles County, the Los Angeles Unified School District, the federal government and the City of Los Angeles) and the seventh largest in the region.
Trademarks and licensing.
The UCLA trademark "is the exclusive property of the Regents of the University of California", but it is managed, protected, and licensed through UCLA Trademarks and Licensing, a division of the Associated Students UCLA. As such, the ASUCLA also has a share in the profits.
Due to UCLA's academic and athletic prestige, as well as the name being associated with popular images of Southern California lifestyle, apparel with UCLA logos and insignia sells not just in the United States, but as an overseas clothing and accessories brand. High demand for UCLA apparel has inspired the licensing of its trademark to UCLA brand stores throughout Europe, the Middle East and Asia. Since 1980, 15 UCLA stores have opened in South Korea, and 49 are currently open in China. The newest store was opened in Kuwait. There are also stores in Mexico, Singapore, India and Europe. UCLA makes $400,000 in royalties every year through its international licensing program.
Athletics.
The school's sports teams are called the Bruins, with colors True Blue and gold. The Bruins participate in NCAA Division I-A as part of the Pacific-12 Conference. Two notable sports facilities serve as home venues for UCLA sports. The Bruin men's football team plays home games at the Rose Bowl in Pasadena; the team won a national title in 1954. The basketball and volleyball teams, and the women's gymnastics team play at Pauley Pavilion on campus. The school also sponsors cross country, soccer, women's rowing, golf, tennis, water polo, track and field, and women's softball.
The mascots are Joe and Josephine Bruin, and the fight songs are "Sons of Westwood" and "Mighty Bruins". The alma mater is "Hail to the Hills of Westwood".
When Henry "Red" Sanders came to UCLA to coach football in 1949, the uniforms were redesigned. Sanders added a gold loop on the shoulders—the UCLA Stripe. The navy blue was changed to a lighter shade of blue. Sanders figured that the baby blue would look better on the field and in film. He dubbed the uniform "Powder Keg Blue", a powder blue with an explosive kick. This would also differentiate UCLA from all other UC teams, whose official colors are blue and gold.
UCLA is competitive in all major Division I-A sports and has won 125 national championships, including 112 NCAA championships, more than any other university. Most recently, UCLA's women's soccer team defeated Florida State to win its first NCAA National Championship along with women's tennis who defeated North Carolina to win its second NCAA National title ever. UCLA's softball program is also outstanding. Women's softball won their NCAA-leading 11th National Championship, on June 8, 2010. The women's water polo team is also dominant, with a record 7 NCAA championships. Notably, the team helped UCLA become the first school to win 100 NCAA championships overall when they won their fifth on May 13, 2007. The men's water polo team helped UCLA become the first school to win 112 NCAA championships overall when they defeated University of Southern California (USC) on December 7, 2014 and UCLA men's water polo team won their record 9 NCAA championships. Among these championships, some of the more notable victories are in men's basketball. Under legendary coach John Wooden, UCLA men's basketball teams won 10 NCAA championships, including a record seven consecutive, in 1964, 1965, 1967-1973, and 1975, and an 11th was added under then-coach Jim Harrick in 1995 (through 2008, the most consecutive by any other team is two). From 1971 to 1974, UCLA men's basketball won an unprecedented 88 consecutive games.
UCLA has also shown dominance in men's volleyball, with 19 national championships. All 19 teams were led by former coach Al Scates, which ties him with John McDonnell of the University of Arkansas as NCAA leader for national championships in a single sport.
Former UCLA basketball player and current Portland Trail Blazers player Earl Watson commented, "Eleven national championships, the best coach (Wooden) to coach the game says a lot. I take offense to those who act like UCLA is just another school compared with Duke. Duke is a great school in the east, but UCLA is worldwide."
UCLA has the most NCAA team championships with 112, followed by Stanford University with 106, then USC with 100.
UCLA is one of only five universities (the University of Michigan, Stanford University, Ohio State, and the University of California at Berkeley being the others) to have won national championships in all three major men's sports (baseball, basketball, and football). 
USC rivalry.
UCLA shares a traditional sports rivalry with the nearby University of Southern California. Under legendary coach John Wooden, UCLA became a dominating power in men's basketball, and has won 11 NCAA championships, against USC's zero. In football, UCLA has one national champion team and 16 conference titles, compared to USC's 11 national championships and 37 conference championships. In 2014, UCLA's football team beat USC for the third consecutive game in a 38-20 victory at the Rose Bowl.
The schools share a rivalry in many other sports. In men's volleyball, UCLA won 19 NCAA Men's Volleyball Championships against USC's four. UCLA also dominates the all-time series vs. USC in men's volleyball (86–34). In women's volleyball UCLA leads the all-time series against USC as well and has won eight national champions to USC's six. In soccer, UCLA leads USC in the all-time series 13–3–0, yet USC no longer competes in men's NCAA Division I soccer. The Crosstown Gauntlet is the name given to the official competition between the two schools in 18 varsity sports where UCLA has won the annual award three times and USC has won the award on eight occasions. This rivalry even extends to the Olympic Games, where UCLA athletes have won 250 medals over a short span of 50 years while USC athletes have won 287 that took nearly 100 years to accomplish.
The origin is unclear, but the rivalry most likely started when football Hall of Fame coach Red Sanders led UCLA to dominance in the 1950s. USC, having won four national championships prior to UCLA's first and only title in 1954 diverted some attention from then-rival University of Notre Dame, and the new cross-town rivalry began.
Student life.
The campus' location in Los Angeles makes excursions to local museums, theaters, or other entertainment venues relatively convenient. UCLA offers classical orchestras, intramural sports, and over 800 student organizations. UCLA is also home to more than 68 national and local Greek-letter organizations, which collectively constitute the largest membership-based and multi-faceted community on campus. Fraternity and sorority members represent 15% of the student population. Phrateres, a non-exclusive social-service club for women was founded here in 1924 by the Dean of Women, Helen Matthewson Laughlin. The Student Alumni Association (SAA) branch of the UCLA Alumni Association conducts UCLA's oldest and greatest traditions, such as Blue and Gold Week, Senior Send-off, Spring Sing, and Dinners for 12 Strangers. UCLA also operates the UCLA Marina Aquatic Center in Marina del Rey, where students and staff participate in dinghy sailing, surfing, windsurfing, rowing, and kayaking.
UCLA is often regarded as the pioneer in the West Coast collegiate contemporary a cappella tradition with its first group, Awaken A Cappella, founded in 1992. The all-male group on campus, Bruin Harmony, has enjoyed a successful career since its inception in 2006, portraying a collegiate a cappella group in "The Social Network" (2010), while the ScatterTones finished in second-place in the International Championship of Collegiate A Cappella in 2011–2013. Other a cappella groups on campus include Signature, Random Voices, Medleys, YOUTHphonics, Deviant Voices, Awechords and Cadenza. YOUTHphonics is UCLA's only nonprofit service-oriented a cappella group focused on youth.
There are also a variety of cultural organizations on campus, such as Nikkei Student Union (NSU), Japanese Student Association (JSA), Association of Chinese Americans (ACA), Chinese Students and Scholars Association (CSSA), Chinese Music Ensemble (CME), Chinese Cultural Dance Club (CCDC), Taiwanese American Union (TAU), Taiwanese Student Association (TSA), Hong Kong Student Society (HKSS), Hanoolim Korean Cultural Awareness Group, Samahang Pilipino, Vietnamese Student Union (VSU), and Thai Smakom, each with its focuses on sharing culture and history. Many of these organizations have an annual "culture night" consisting of drama and dance which raises awareness of culture and history to the campus and community.
UCLA operates on a quarter calendar. 
Traditions.
UCLA's official charity is UniCamp, founded in 1934. It is a week-long summer camp for under-served children from the greater Los Angeles area, with UCLA volunteer counselors. Student volunteers attend two hour training sessions once a week during spring quarter to prepare them for their week at camp. UniCamp runs for seven weeks throughout the summer at Camp River Glen in the San Bernardino National Forest. Because UniCamp is a non-profit organization, student volunteers from UCLA also fundraise money throughout the year to allow these children to attend summer camp.
UCLA begins the fall quarter with True Bruin Welcome to introduce new students to clubs and activities. The week includes the Day of Service for all freshmen, the Enormous Activities Fair, the Sports Fair, and other events. At the end of move-in and the beginning of True Bruin Welcome, UCLA holds Bruin Bash. Hosted by the USAC Campus Events Commission and USAC Cultural Affairs Commission, Bruin Bash includes a concert, dance, and movie. Past performers include Thrice and Common (2005), Xzibit and Rooney (2006), T.I. (2007), The Cool Kids, Estelle, Hellogoodbye (2008), LMFAO and Clipse (2009), Ying Yang Twins, Travis McCoy and The Cataracs (2010). Bruin Bash was created as a replacement for Black Sunday, a large-scale day of partying including all fraternities, in North Westwood Village, where the majority of off-campus students reside adjacent to campus.
Dance Marathon is an annual event organized by the Pediatric AIDS Coalition, previously held in Ackerman Grand Ballroom and since 2014 Pauley Pavilion, where thousands of students raise a minimum of $250 and dance for 26 hours to support the Elizabeth Glaser Pediatric AIDS Foundation, Project Kindle, and the UCLA AIDS Institute. Dancers are not allowed to sit (except to use the restroom) during the marathon, literally taking a stand against pediatric AIDS, and symbolizing the suffering of affected children around the world. In 2013, Dance Marathon at UCLA raised a record-breaking $475,422.57. Since 2002, the Marathon has raised over $3.5 million.
UCLA students also participate in "Midnight Yell" during Finals Week, where every midnight, students yell as loudly as possible for a few minutes, taking a short break from studying and releasing some stress.
The quarterly Undie Run takes place during the Wednesday evening of Finals Week, when students run through the campus in their underwear or in skimpy costumes. The run began in Fall of 2001 when a student, Eric Whitehead, wearing what he described as "really short shorts" walked around singing and playing a guitar to protest the police restrictions on the Midnight Yell. With the increasing safety hazards and Police and Administration involvement, a student committee changed the route to a run through campus to Shapiro Fountain, which now culminates with students dancing in the fountain. In 2007, the route was changed again to begin at Strathmore Avenue instead of Landfair Avenue. The Undie Run concept has since spread to other college campuses around the United States, including the University of Texas at Austin, Arizona State University, and Syracuse University.
The Alumni Association sponsors several events, usually large extravaganzas involving huge amounts of coordination, such as the 69-year old Spring Sing, organized by the Student Alumni Association (SAA). UCLA's oldest tradition, Spring Sing is an annual gala of student talent, which is held at either Pauley Pavilion or the outdoor Los Angeles Tennis Center. The committee bestows the George and Ira Gershwin Lifetime Achievement Award each year to a major contributor to the music industry. Past recipients have included Stevie Wonder, Frank Sinatra, Ella Fitzgerald, James Taylor, Ray Charles, Natalie Cole, Quincy Jones, Lionel Richie, and in 2009, Julie Andrews. The Dinner for 12 Strangers, a common tradition among universities, is a gathering of students, alumni, administration and faculty to network around different interests. The week before the USC rivalry football game, there is a "Beat 'SC Bonfire and Rally".
Crowd at JazzReggae Festival 2010 at UCLA.
The USAC Cultural Affairs Commission hosts the JazzReggae Festival, a two-day concert on Memorial Day weekend that attracts more than 20,000 attendees. The JazzReggae Festival is the largest, entirely student produced and run event of its kind on the West Coast.
Sigma Eta Pi and Bruin Entrepreneurs organize an annual hackathon called LA Hacks, a weekend-long programming competition where students from around the nation come to build technology products. LA Hacks established itself as the largest hackathon in the nation when over 1500 students participated in April 11–13, 2014. LA Hacks also holds the record for the most funds raised via corporate sponsorships with $250,000 raised. Some of the tech world's most prominent people have given talks and judged projects at LA Hacks, including Evan Spiegel (Founder and CEO of Snapchat), Alexis Ohanian (Co-Founder of Reddit), Baiju Bhatt (Co-Founder of Robinhood), Sam Altman (President of Y Combinator), Chris De Wolfe (Founder of Myspace), and Tomer Kagan (Co-Founder and CEO of Quixey).
Student government.
The Associated Students UCLA (ASUCLA) is the official entity encompassing student government and student-led enterprises at UCLA. ASUCLA has four major components: the Undergraduate Students Association, the Graduate Students Association, Student Media, and services & enterprises. However, in common practice, the term ASUCLA is often more narrowly used to refer to the services and enterprises component. This includes the Student Store, Bookstore, Food Services, Student Union, etc. These commercial enterprises serving the UCLA campus community generate approximately $90 million in annual revenues, making it financially the largest student government operation in the world. As a nonprofit corporation, the financial goal of ASUCLA is to provide quality services and programs to the campus community at reasonable prices. ASUCLA is governed by a student-majority Board of Directors. The Undergraduate Students Association and Graduate Students Association each appoint three members plus one alternate. In addition to the student members, there are representatives appointed by the administration, the academic senate, and the alumni association. The "services and enterprises" portion of ASUCLA is run by a professional executive director who oversees some 300 staff and 2,000 student employees.
The Graduate Students Association is the governing body for approximately 13,000 graduate and professional students at UCLA.
"USAC" is an acronym for Undergraduate Students Association Council, the governing body of the Undergraduate Students Association (USA) whose membership comprises every UCLA undergraduate student. The student body currently has two major political slates, Bruins United and Let's Act.
USAC's fourteen student officers and commissioners are elected by members of the Undergraduate Students Association at an annual election held during Spring Quarter. In addition to its fourteen elected members, USAC includes appointed representatives of the Administration, the Alumni, and the Faculty, as well as two ex-officio members, the ASUCLA Executive Director and a student Finance Committee Chairperson who is appointed by the USA President and approved by USAC. All members of USAC may participate fully in Council deliberations, but only the elected officers, minus the USAC President may vote.
The fourteen elected positions include: USAC President, Internal Vice President, External Vice President, General Representative (3), Academic Affairs Commissioner, Cultural Affairs Commissioner, Facilities Commissioner, Campus Events Commissioner, Student Welfare Commissioner, Community Service Commissioner, Transfer Student Representative and Financial Supports Commissioner.
The USAC President appoints more than seventy undergraduates to administrative committees and the Academic Affairs Commissioner Appoints approximately 25 undergraduates to Academic Senate Committees. Students have an opportunity to serve on the ASUCLA Board of Directors and the Communications Board, as well as on other significant committees, having input into the decision making process at a high level.
USAC's programs offers additional services to the campus and surrounding communities. For example, each year approximately 40,000 students, faculty and staff attend programs of the Campus Events Commission, including a low-cost film program, a speakers program which presents leading figures from a wide range of disciplines, and performances by dozens of entertainers. Two to three thousand UCLA undergraduates participate annually in the more than twenty voluntary outreach programs run by the Community Service Commission. A large corps of undergraduate volunteers also participate in programs run by the Student Welfare Commission, such as AIDS Awareness, Substance Abuse Awareness, Blood Drives and CPR/First Aid Training.
Media publications.
Student Media UCLA is the home of UCLA's student-run media, including the campus newspaper, magazines, and radio and television stations. Most student media publications distributed on-campus are governed by the ASUCLA Communications Board.
The "Daily Bruin" is UCLA's most prominent student publication. Founded in 1919 under the name "Cub Californian", it has since then developed into Los Angeles' third-most circulated newspaper. It has won over 20 national awards in the last five years, and is regularly commended for layout and content. In 2006, the Society of Professional Journalists awarded it Best All-Around Daily Newspaper in the national Mark of Excellence Awards. The newspaper has not been without scrutiny and controversy, and in 1954, the administration attempted to intervene with the previous policy of electing editors by a student council.
UCLA Student Media also publishes seven news magazines, each established to serve a special-interest community on campus: "Al-Talib", "Fem", "Ha'Am", "La Gente de Aztlan", "Nommo", "Pacific Ties", and "Outwrite", a school yearbook, "BruinLife", the student-run radio station, UCLAradio.com, formerly known as KLA, and the online campus review-site "Bruinwalk.com".
Student groups such as The Forum for Energy Economics and Development also publish yearly journals focused on energy technologies and industries. There are also numerous graduate student-run journals at UCLA, such as "Carte Italiane", "Issues in Applied Linguistics", and "Mediascape". Many of these publications are available through open access. The School of Law publishes the UCLA Law Review which is currently ranked seventh among American law schools.
Housing.
UCLA provides housing to over 10,000 undergraduate and 2,900 graduate students.
Most undergraduate students are housed in 14 complexes on the western side of campus, referred to by students as "The Hill". Students can live in halls, plazas, suites, or university apartments, which vary in pricing and privacy. Housing plans also offer students access to dining facilities, which have been ranked by the "Princeton Review" as some of the best in the United States. Dining halls are located in De Neve, Rieber, Covel, and Hedrick Halls. In winter 2012, a dining hall called The Feast at Rieber opened to students. The newest dining hall (as of Winter Quarter 2014) is Bruin Plate, located in the Carnesale Commons (commonly referred to as Sproul Plaza). Residential cafes include Bruin Cafe, Rendezvous, and Cafe 1919 which formerly housed a cafe known as Puzzles. UCLA currently offers three years guaranteed housing to its incoming freshmen, and one year to incoming transfer students. There are four type of housing available for students: residential halls, deluxe residential halls, residential plazas, and residential suites. Available on the hill are study rooms, basketball courts, tennis courts, and Sunset Recreational Center which includes three swimming pools.
Graduate students are housed in one of five apartment complexes. One, Weyburn Terrace, is located just southwest of the campus in Westwood Village. The other four are roughly five miles south of UCLA in Palms and Mar Vista. They too vary in pricing and privacy.
According to the "Daily Bruin", 1,525 beds, 10 faculty in-residence apartments and a 750-seat dining hall will be built on the Northwest Housing Infill Project on the Hill by 2013. The buildings are tentatively titled De Neve Gardenia Way, De Neve Holly Ridge, Sproul Cove, and Sproul Landing.
Students who are involved in Greek life have the option to also live in Greek housing while at UCLA. Sorority houses are located east of campus on Hilgard Avenue, and fraternity houses are located west of campus throughout Westwood Village. A student usually lives with 50+ students in Greek housing.
Hospitality.
Hospitality constituents of the university include departments not directly related to student life or administration. The Hospitality department manages the UCLA Guest House, a full-service, on-campus hotel. The 61-room Guest House services those visiting the university for campus-related activities. The department also manages the UCLA Conference Center, a 40 acre (0.2 km²) conference center in the San Bernardino Mountains near Lake Arrowhead. Hospitality also operates UCLA Catering a vending operation, and summer conference center located on the Westwood campus.
Chabad House.
The UCLA Chabad House is a community center for Jewish students operated by the Orthodox Jewish Chabad movement. Established in 1969, it was the first Chabad House at a university. In 1980, three students died in a fire in the original building of the UCLA Chabad House. The present building was erected in their memory. The building, completed in 1984, was the first of many Chabad houses worldwide designed as architectural reproductions of the residence of the Lubavitcher Rebbe, Rabbi Menachem Mendel Schneerson at 770 Eastern Parkway in Brooklyn, New York.
Faculty and alumni.
Fifteen Nobel laureates are associated with UCLA: eight professors and seven alumni.
Two other faculty members winning the Nobel Prize were Bertrand Russell and Al Gore, who each had a short stay at UCLA.
The alumni Nobel laureates include Richard Heck, Chemistry, 2010; Elinor Ostrom, Economic Sciences, 2009; and Randy Schekman, Physiology or Medicine, 2013. Fifty-two UCLA professors have been awarded Guggenheim Fellowships, and eleven are MacArthur Foundation Fellows. Mathematics professor Terence Tao was awarded the 2006 Fields Medal.
Geography professor Jared Diamond won the 1998 Pulitzer Prize for his book "Guns, Germs, and Steel". Two UCLA history professors have each won 2008 Pulitzer Prizes for general nonfiction and history. Saul Friedländer, professor of history and noted scholar of the Nazi Holocaust, won the prize for general nonfiction for his 2006 book, "The Years of Extermination: Nazi Germany and the Jews, 1939–1945", and Professor Emeritus Daniel Walker Howe won for his 2007 book, "What Hath God Wrought: The Transformation of America, 1815–1848".
A number of UCLA alumni are notable politicians. In the U.S. House of Representatives, Henry Waxman ('61, '64) represented California's 30th congressional district and was Chairman of the House Energy and Commerce Committee. U.S. Representative Judy Chu ('74) represents California's 32nd congressional district and became the first Chinese American woman elected to the U.S. Congress in 2009. Kirsten Gillibrand ('91) is U.S. Senator from the State of New York and former U.S. Representative for New York's 20th congressional district. UCLA boasts two Mayors of Los Angeles: Tom Bradley (1937-1940), the city's only African-American mayor, and Antonio Villaraigosa ('77), who served as mayor from 2005 to 2013. Nao Takasugi was the mayor of Oxnard, California and the first Asian-American California assemblyman.
Laurence Fink (BA '74, MBA '76) is chairman and CEO of the world's largest money-management firm BlackRock.
Bill Gross (MBA '71) co-founded Pacific Investment Management (PIMCO).
Michael Morhaime (BA '90), Allen Adham (BA '90) and Frank Pearce (BA '90) are the founders of Blizzard Entertainment, one of the world's largest video game developers. Tom Anderson is a co-founder of the social networking website Myspace. Ben Horowitz (MS '90) is a co-founder of the Silicon Valley venture capital firm Andreessen Horowitz. Computer scientist Vint Cerf ('70, '72) is Vice President and Chief Internet Evangelist at Google and the person most widely considered the "father of the Internet." Henry Samueli ('75) is co-founder of Broadcom Corporation and owner of the Anaheim Ducks. Susan Wojcicki (MBA '98) is the CEO of YouTube.
Venture capitalist, author and futurist Donald Prell (BA '48) founder of Datamation magazine.
UCLA alumni have also achieved prominence in the arts and entertainment. Composer John Williams is laureate conductor at the Boston Pops Orchestra and Academy Award-winning composer of the "Star Wars" film score. Martin Sherwin (’71) was awarded the Pulitzer Prize for "American Prometheus: The Triumph and Tragedy of J. Robert Oppenheimer". Actors Ben Stiller, Tim Robbins, James Franco, George Takei, Mayim Bialik, Sean Astin, Holland Roden and Milo Ventimiglia are also UCLA alumni. Popular music artists Sara Bareilles, The Doors, Linkin Park, and Maroon 5 all attended UCLA. Giada De Laurentiis is a program host at Food Network and former chef at Spago. Greg Graffin, lead singer of punk rock band Bad Religion, earned a master's degree in Geology at UCLA, and used to teach a course on evolution there. Carol Burnett was the winner of the Mark Twain Prize for American Humor in 2013 (also winner of Emmys, a Peabody and a Presidential Medal of Freedom in 2005). Francis Ford Coppola ('67) was the director of the gangster film trilogy "The Godfather" and the Vietnam War film "Apocalypse Now".
Meb Keflezighi ('98) is the winner of the 2014 Boston Marathon.
UCLA also boasts an excellent military background, with hundreds of alumni serving their nation. Carlton Skinner was a U.S. Navy Commander who racially integrated the service at the end of World War II on the USS Sea Cloud. He was also the first civilian governor of Guam. Francis B. Wai is, to date, the only Chinese-American and the first Asian-American to be awarded the Congressional Medal of Honor for his actions in World War II. UCLA also lost an alumnus in early 2007 when Second Lieutenant Mark Daily was killed in Mosul, Iraq after his HMMWV was hit by an IED. Lieutenant Daily's service is marked by a plaque located on the northern face of the Student Activities Center (SAC), where the ROTC halls are currently located.
H.R. Haldeman (’48) and John Ehrlichman (’48) are among the most infamous alumni because of their activities during the 1972 Watergate Scandal.
UCLA's faculty and alumni have won a number of awards including:
UCLA Medal.
The highest honor given by UCLA to individuals for "extraordinary accomplishment" is the UCLA Medal, which was established in 1979. More than 140 have received the award, including:

</doc>
<doc id="37767" url="http://en.wikipedia.org/wiki?curid=37767" title="Patch collecting">
Patch collecting

Patch collecting or badge collecting (also, scutelliphily, from Latin "scutellus" meaning "little shield", and Greek "phileein" meaning "to love") is the hobby of collecting souvenir patches or badges. 
Souvenir patches.
Souvenir patches are usually shield-shaped, and generally contain a coat of arms, a map or a miniature view. The patches can be made of any material, but are usually woven or embroidered fabric, though they can also be made from paper or, increasingly, plastic.
Other types of collectible patches include police or service patches, space mission patches, Scout patches, fashion patches, political and sports stickers, walking stick labels, car window pennants, and pin badges. Collecting metal badges or pins, either military or civil, is known as faleristics.
History.
Badges have been collected since ancient times. Greek and Roman pilgrims to pagan shrines made collections of miniature images of gods and goddesses or their emblems, and Christian pilgrims later did the same. Usually medieval Christian pilgrim badges were metal pin badges - most famously the shell symbol showing the wearer had been to the shrine of St. James at Santiago de Compostela in Spain. These were stuck in hats or into clothing and hard
working pilgrims could assemble quite a collection, as mentioned by Chaucer in his 'Canterbury Tales'.
The growth in the 19th century of travel for ordinary people saw a huge increase in the souvenir industry, as these new secular pilgrims - like their medieval counterparts - wanted to bring back reminders of their holidays/vacations and sightseeing, ranging from china plates to postcards. 
The production of stick-on souvenir badges seems to have started in mainland Europe during the early 20th-century, probably in Germany shortly after the First World War when hiking became popular, and people began sewing badges of resort towns onto their backpacks and jackets. In the U.S., the development of the National parks system and the growing popularity of vacationing saw a similar development of patch collecting.
After the Second World War, American GIs occupying Germany sent badges back to their loved ones, showing where they were stationed. These badges became known as "sweetheart patches". They were also imported to Britain by Sampson Souvenirs Ltd., which also began producing badges of British tourist spots, and went on to become (and still is) the largest British manufacturer of souvenir badges. The biggest American manufacturer is Voyager Emblems of Sanborn, New York.
They are a good way of showing off places visited if worn on clothing, or stored in albums they can bring back memories of holidays/vacations or day trips.
Law enforcement patch collecting.
"See Police patch collecting"
Another patch collecting specialty is police agencies such as sheriff, police, highway patrol, marshal, constable, park rangers, law enforcement explorer scouts, or other law enforcement related personnel. Emblems worn on uniforms have been exchanged between officials as a sign of cooperation for decades, and displays of patches are found in police stations. The publishing of reference books on law enforcement insignia over the past decade has made law enforcement patch collecting a popular way to preserve law enforcement history.
Fire department patch collecting.
Similar to police patches, fire department patches are also traded amongst fire agencies and some sold to the general public. Station patches are available amongst large fire departments in North America. Some station patches are worn by fire fighters, but mostly not on official uniforms. The patch design is sometimes found on fire vehicles.

</doc>
<doc id="37770" url="http://en.wikipedia.org/wiki?curid=37770" title="Seville">
Seville

Seville (, Spanish: "Sevilla" ], ]) is the capital and largest city of the autonomous community of Andalusia and the province of Seville, Spain. It is situated on the plain of the River Guadalquivir. The inhabitants of the city are known as "sevillanos" (feminine form: "sevillanas") or "hispalenses", after the Roman name of the city, "Hispalis". Seville has a municipal population of about 703,000 as of 2011, and a metropolitan population of about 1.5 million, making it the fourth-largest city in Spain and the 30th most populous municipality in the European Union. Its Old Town, the third largest in Europe with an area of 4 km², contains three UNESCO World Heritage Sites: the Alcázar palace complex, the Cathedral and the General Archive of the Indies. The Seville harbour, located about 80 km from the Atlantic Ocean, is the only river port in Spain. Seville is also the hottest major metropolitan area in Europe, with summer average high temperatures of above 35 °C.
Seville was founded as the Roman city of "Hispalis", and was known as "Ishbiliya" (Arabic:إشبيلية) after the Muslim conquest in 712. During the Muslim rule in Spain, Seville came under the jurisdiction of the Caliphate of Córdoba before becoming the independent Taifa of Seville; later it was ruled by the Muslim Almoravids and the Almohads until finally being incorporated into the Christian Kingdom of Castile under Ferdinand III in 1248. After the discovery of the Americas, Seville became one of the economic centres of the Spanish Empire as its port monopolised the trans-oceanic trade and the Casa de Contratación (House of Trade) wielded its power, opening a Golden Age of arts and literature. In 1519, Ferdinand Magellan departed from Seville for the first circumnavigation of the Earth. Coinciding with the Baroque period of European history, the 17th century in Seville represented the most brilliant flowering of the city's culture; then began a gradual economic and demographic decline as silting in the Guadalquivir forced the trade monopoly to relocate to the nearby port of Cádiz.
The 20th century in Seville saw the horrors of the Spanish Civil War, decisive cultural milestones such as the Ibero-American Exposition of 1929 and Expo '92, and the city's election as the capital of the Autonomous Community of Andalusia.
Name.
Etymology.
"Spal" is the oldest known name for Seville. It appears to have originated during the Phoenician colonisation of the Tartessian culture in south-western Iberia and, according to Manuel Pellicer Catalán, meant "lowland" in the Phoenician language (similar to the Hebrew Shfela). During Roman rule, the name was Latinised as "Hispalis". After the Moorish invasion, this name was adapted into Arabic as "Ishbiliyya" (Arabic أشبيليّة, from Greek Σεβίλλη, "Sebílle"); since "p" does not exist in Arabic, it was replaced by "b", the Latin place-name suffix "-is" was substituted for its direct Arabic equivalent "-iyya", and stressed "a" /æ/ turned into "i" /i/, due to the phonetic phenomenon called imela.
Motto.
"NO8DO" is the official motto of Seville. It is popularly believed to be a rebus signifying the Spanish "No me ha dejado", meaning "It [Seville] has not abandoned me", with the eight in the middle representing a "madeja", or skein of wool. Legend states that the title was given by King Alfonso X, who was resident in the city's Alcazar and supported by the citizens when his son, later Sancho IV of Castille, tried to usurp him from the throne. The emblem is present on the municipal flag and features on city property such as manhole covers, and Christopher Columbus's tomb in the Cathedral.
History.
Seville is approximately 2,200 years old. The passage of the various civilisations instrumental in its growth has left the city with a distinct personality, and a large and well-preserved historical centre.
Early periods.
The mythological founder of the city is Hercules (Heracles), commonly identified with the Phoenician god Melqart, who the myth says sailed through the Strait of Gibraltar to the Atlantic, and founded trading posts at the current sites of Cádiz and of Seville.
The city was known from Roman times as "Hispalis". Important archaeological remains also exist in the nearby towns of Santiponce (Italica) and Carmona.
Existing Roman features in Seville include the remnants of an aqueduct, a temple in "Mármoles" Street, the columns of La Alameda de Hércules, the remains exposed "in situ" in the underground Antiquarium of the Metropol Parasol building and the remains in the Patio de Banderas square near of the Seville Cathedral. The walls surrounding the city were originally built during the rule of Julius Caesar, but their current course and design were the result of Moorish reconstructions.
Following Roman rule, there were successive conquests of the Roman province of "Hispania Baetica" by the Vandals, the Suebi and the Visigoths during the 5th and 6th centuries.
Moorish era.
Seville was taken by the Moors, Muslims from North of Africa, during the conquest of Hispalis in 712. It was the capital for the kings of the Umayyad Caliphate, the Almoravid dynasty first and after the Almohad dynasty (from Arabic الموحدون al-Muwahhidun, i.e., "the monotheists" or "the Unitarians"), from the 8th to 13th centuries.
The Moorish urban influences continued and are present in contemporary Seville, for instance in the custom of decorating with herbaje and small fountains the courtyards of the houses. However, most buildings of the Moorish aesthetic actually belong to the Mudéjar style of Islamic art, developed under Christian rule and inspired by the Arabic style. Original Moorish buildings are the "Patio del Yeso" in the Alcázar, the city walls, and the main section of the Giralda, bell tower of the Seville Cathedral.
Castilian rule.
In 1247, the Christian King Ferdinand III of Castile and Leon began the conquest of Andalusia. After conquering Jaén and Córdoba, he seized the villages surrounding the city, Carmona Lora del Rio and Alcalá del Rio, and kept a standing army in the vicinity, the siege lasting for fifteen months. The decisive action took place in May 1248 when Ramon Bonifaz sailed up the Guadalquivir and severed the Triana bridge that made the provisioning of the city from the farms of the Aljarafe possible. The city surrendered on 23 November 1248.
The city's development continued after the Castilian conquest in 1248. Public buildings constructed including churches, many of which were built in the "Mudéjar" style, and the Seville Cathedral, built during the 15th century with Gothic architecture. The Moors' Palace became the Castilian royal residence, and during Pedro I's rule it was replaced by the Alcázar (the upper levels are still used by the Royal Family as the official Seville residence).
1391 Pogroms.
In 1391, Archdeacon Ferrant Martinez closed all the synagogues in Seville, converting them to churches, as in the case of Santa María la Blanca, and also appropriated the Jewish quarter's land and shops (sited in modern-day 'Barrio Santa Cruz'). Thousands were killed during the pogrom, while others were forced to convert. The Plaza de San Francisco was the site of the 'autos de fé'. At first, the activity of the Inquisition was limited to the dioceses of Seville and Cordoba, where Alonso de Hojeda had detected converso activity. The first Auto de Fé took place in Seville on 6 February 1481, when six people were burned alive. Alonso de Hojeda himself gave the sermon. The Inquisition then grew rapidly. By 1492, tribunals existed in eight Castilian cities: Ávila, Córdoba, Jaén, Medina del Campo, Segovia, Sigüenza, Toledo and Valladolid; and by the Alhambra decree all Jews were forced to convert to Catholicism or ejected from Spain.
The Golden Age.
Following the 1492 Christopher Columbus expedition to the New World (from the port of Palos de la Frontera), the results from his claiming territory and trade for the Crown of Castile (incipient Spain) in the West Indies began to profit the city, as all goods imported from the New World had to pass through the Casa de Contratacion before being distributed throughout the rest of Spain. A 'golden age of development' commenced in Seville, due to its being the only port awarded the royal monopoly for trade with the growing Spanish colonies in the Americas and the influx of riches from them. Since only sailing ships leaving from and returning to the inland port of Seville could engage in trade with the Spanish Americas, merchants from Europe and other trade centres needed to go to Seville to acquire New World trade goods. The city's population grew to nearly a million people.
In the late 16th century the monopoly was broken, with the port of Cádiz also authorised as a port of trade. The Great Plague of Seville in 1649 reduced the population by almost half, and it would not recover until the early 19th century. By the 18th century its international importance was in decline. After the silting up of the harbour by the Guadalquivir (river), upriver shipping ceased and the city went into relative economic decline.
The writer Miguel de Cervantes lived primarily in Seville between 1596 and 1600. Because of financial problems, Cervantes worked as a purveyor for the Spanish Armada, and later as a tax collector. In 1597, discrepancies in his accounts of the three years previous landed him in the Royal Prison of Seville for a short time.
"Rinconete y Cortadillo", a popular comedy among his works, features two young vagabonds who come to Seville, attracted by the riches and disorder that the 16th-century commerce with the Americas had brought to that metropolis.
18th century.
During the 18th century Charles III of Spain promoted Seville's industries. Construction of the "Real Fábrica de Tabacos" (Royal Tobacco Factory) began in 1728, with additions to it over the next 30 years. It was the second largest building in Spain, after the royal residence El Escorial. Since the 1950s it has been the seat of the rectorate of the University of Seville, together with the Schools of Law, Philology, Geography and History.
Many operas have been set in the city, including those by such composers as Beethoven "(Fidelio)", Mozart "(The Marriage of Figaro and Don Giovanni)", Rossini (The Barber of Seville) and Bizet "(Carmen)".
Seville became the dean of the Spanish provincial press in 1758 with the publication of its first newspaper, the "Hebdomario útil de Seville", the first to be printed in Spain outside Madrid.
19th and 20th centuries.
Between 1825 and 1833, Melchor Cano acted as chief architect in Seville; most of the urban planning policy and architectural modifications of the city were made by him and his collaborator Jose Manuel Arjona y Cuba.
Industrial architecture surviving today from the first half of the 19th century includes the ceramics factory installed in the Carthusian monastery at La Cartuja in 1841 by the Pickman family, and now home to the El Centro Andaluz de Arte Contemporáneo (CAAC), which manages the collections of the Museo de Arte Contemporáneo de Sevilla. It also houses the rectory of the UNIA.
In the years that Queen Isabel II ruled directly, about 1843–1868, the Sevillian bourgeoisie invested in a construction boom unmatched in the city's history. The Isabel II bridge, better known as the Triana bridge, dates from this period; street lighting was expanded in the municipality and most of the streets were paved during this time as well.
By the second half of the 19th century Seville began an expansion supported by railway construction and the demolition of part of its ancient walls, allowing the urban space of the city to grow eastward and southward. The "Sevillana de Electricidad" Company was created in 1894 to provide electric power throughout the municipality, and in 1901 the "Plaza de Armas" railway station was inaugurated. The Museum of Fine Arts "(Museo de Bellas Artes de Sevilla)" opened in 1904.
In 1929 the city hosted the Ibero-American Exposition, which accelerated the southern expansion of the city and created new public spaces such as the Plaza de España and the Maria Luisa Park. Not long before the opening, the Spanish government began a modernisation of the city in order to prepare for the expected crowds by erecting new hotels and widening the mediaeval streets to allow for the movement of automobiles.
Seville fell very quickly at the beginning of the Spanish Civil War in 1936. General Queipo de Llano carried out a coup within the city, quickly capturing the city centre. Radio Seville opposed the uprising and called for the peasants to come to the city for arms, while workers' groups established barricades. De Llano then moved to capture Radio Seville, which he used to broadcast propaganda on behalf of the Franquist forces. After the initial takeover of the city, resistance continued among residents of the working-class neighbourhoods for some time, until a series of fierce reprisals took place.
Under Francisco Franco's rule Spain was officially neutral in World War II, and like the rest of the country, Seville remained largely economically and culturally isolated from the outside world. In 1953 the shipyard of Seville was opened, eventually employing more than 2,000 workers in the 1970s. Before the existence of wetlands regulation in the Guadalquivir basin, Seville suffered regular heavy flooding; perhaps worst of all were the floods that occurred in November 1961 when the river Tamarguillo overflowed as a result of a prodigious downpour of rain, and Seville was consequently declared a disaster zone. 
Trade unionism in Seville began during the 1960s with the underground organisational activities of the Workers' Commissions or Comisiones Obreras (CCOO), in factories such as Hytasa, the Astilleros shipyards, Hispano Aviación, etc. Several of the movement's leaders were imprisoned in November 1973. On 3 April 1979 Spain held its first democratic municipal elections after the end of Franco's dictatorship; councillors representing four different political parties were elected in Seville. On 5 November 1982, Pope John Paul II arrived in Seville to officiate at a Mass before more than half a million people at the fairgrounds. He visited the city again 13 June 1993, for the International Eucharistic Congress.
In 1992, coinciding with the fifth centenary of the Discovery of the Americas, the Universal Exposition was held for six months in Seville, on the occasion of which the local communications network infrastructure was greatly improved: the SE-30 ring road around the city was completed and new highways were constructed; the new Santa Justa train station had opened in 1991, while the Spanish High Speed Rail system, the "Alta Velocidad Española" (AVE), began to operate between Madrid-Seville. The Seville Airport, "(Aeropuerto de Sevilla)", was expanded with a new terminal building designed by the architect Rafael Moneo, and various other improvements were made. The monumental "Puente del Alamillo" (Alamillo Bridge) over the Guadalquivir, designed by the architect Santiago Calatrava, was built to allow access to the island of La Cartuja, site of the massive exposition. Some of the installations remaining at the site after the exposition were converted into the Scientific and Technological Park Cartuja 93.
21st century.
In 2004 the Metropol Parasol project was launched to revitalise the Plaza de la Encarnación, for years used as a car park and seen as a dead spot between more popular tourist destinations in the city. The Metropol Parasol was completed in March, 2011.
"Metropol Parasol", locally also known as "Las Setas" by the German architect Jürgen Mayer
Geography.
Topography.
Seville has an area of 140 km2, according to the National Topographic Map "(Mapa Topográfico Nacional)" series from the "Instituto Geográfico Nacional – Centro Nacional de Información Geográfica", the country's civilian survey organisation (pages 984, 985 and 1002). The city is situated in the fertile valley of the Guadalquivir River. The average height above sea level is 7 m. Most of the city is on the east side of the river, while Triana, La Cartuja and Los Remedios are on the west side. The Aljarafe region lies further west, and is considered part of the metropolitan area. The city has boundaries on the north with La Rinconada, La Algaba and Santiponce; on the east with Alcalá de Guadaira; on the south with Dos Hermanas and Gelves and on the west with San Juan de Aznalfarache, Tomares and Camas.
Climate.
Seville has a subtropical Mediterranean climate (Köppen climate classification "Csa"). Like most Mediterranean climates, Seville has a drier summer and wet winter. The annual average temperature is 25 C during the day and 13 C at night.
After the city of Córdoba (also in Andalusia), Seville has the hottest summer in continental Europe among all cities with a population over 100,000 people, with average daily highs in July of 36.0 C. Average minimum temperatures in July are 20.3 C and every year the temperature exceeds 40 C on several occasions. The coldest temperature extreme of -5.5 C was registered by the weather station at Seville Airport on 12 February 1956. A historical record high (disputed) of 50.0 C was recorded on 4 August 1881, according to the NOAA Satellite and Information Service. There is a non-accredited record by the National Institute of Meteorology of 47.2 C on 1 August during the 2003 heat wave, according to a weather station (83910 LEZL) located in the southern part of Seville Airport, near the abandoned military zone. This temperature would be one of the highest ever recorded in Spain and Europe after the European record of 48.0 °C recorded in Athens on 10 July 1977 and the 47.4 °C (117.4 °F) of Amareleja, Portugal on 1 August 2003.
Government.
Seville is the capital of the autonomous community of Andalusia. The historical edifice of the Palace of San Telmo is now the seat of the presidency of the Andalusian Autonomous Government. The administrative headquarters are in Torre Triana, in La Cartuja. The Hospital de las Cinco Llagas (literally, "Hospital of the Five Holy Wounds") is the current seat of the Parliament of Andalusia. Since 2012 the government of the autonomous community has been a coalition between the leftist Spanish Socialist Workers' Party or "Partido Socialista Obrero Español" (PSOE) and the United Left, or "Izquierda Unida" (IU); its president is Jose Antonio Griñán Martínez. Elections to the autonomous community are held every four years.
Status.
Seville is the capital of the Autonomous Community of Andalusía, according to Article 4 of the Statute of Autonomy of Andalucía of 2007, and is the capital of the Province of Seville as well.
The Common Council of Seville has 33 councillors and a mayor, with elections every four years. Since 2011, the government of the city has been by the conservative People's Party or "Partido Popular" (PP), and Juan Ignacio Zoido Álvarez has been mayor. The City Hall is on the Plaza Nueva, in the "El Arenal" neighbourhood. The administration of the City is decentralized into 11 districts.
Districts and neighbourhoods.
Seville has 11 districts, further divided into 108 neighbourhoods.
Main sights.
The Alcázar, the Cathedral, and the "Archivo General de Indias" (General Archive of the Indies) are UNESCO World Heritage Sites.
Landmarks.
The Cathedral of St. Mary was built from 1401–1519 after the "Reconquista" on the former site of the city's mosque. It is among the largest of all medieval and Gothic cathedrals, in terms of both area and volume. The interior is the longest nave in Spain, and is lavishly decorated, with a large quantity of gold evident. La Giralda is a tower attached to the Cathedral that dates back to the twelfth century. It was originally built as part of a mosque when the Moors ruled in Spain and was later added onto by the Christians. Tourists today can climb the tower by walking up a series of ramps that were previously used by officials who rode their horses to the top of the tower. La Giralda gets its name from the weathervane attached to the very top of it, as "gira" means "turning one" in the Spanish language.
The "Alcázar" facing the cathedral was developed from a previous Moorish Palace. Construction was started in 1181 and continued for over 500 years, mainly in the Mudéjar style, but also in the Renaissance style.
The "Torre del Oro" was built as a watchtower and defensive barrier on the river. A chain was strung through the water from the base of the tower to prevent boats from traveling into the river port.
The City Hall was built in the 16th century in high Plateresque style by master architect Diego de Riaño. The façade to Plaza Nueva was built in the 19th century in Neoclassical style.
The Palace of San Telmo, formerly the University of Sailors, and later the Seminary, is now the seat for the Andalusian Autonomous Government. It is one of the most emblematic buildings of baroque architecture, mainly to its world-renowned churrigueresque principal façade and the impressive chapel.
The Royal Tobacco Factory is housed on the original site of the first tobacco factory in Europe, a vast 18th century building in Baroque style and the purported inspiration for the opera "Carmen".
The "Metropol Parasol", in La Encarnación square, is the world's largest wooden structure. A monumental umbrella-like building designed by the German architect Jürgen Mayer, finished in 2011. This modern architecture structure houses the central market and an underground archaeological complex. The terrace roof is a city viewpoint.
The General Archive of the Indies, is the repository of extremely valuable archival documents illustrating the history of the Spanish Empire in the Americas and the Philippines. The building itself, an unusually serene and Italianate example of Spanish Renaissance architecture, was designed by Juan de Herrera.
The "Plaza de España", in Maria Luisa Park ("Parque de Maria Luisa"), was built by the architect Aníbal González for the 1929 Exposición Ibero-Americana. It is an outstanding example of Regionalist Revival Architecture, a bizarre and loftily conceived mixture of diverse historic styles, such as Art Deco and lavishly ornamented with typical glazed tiles.
The neighbourhood of "Triana", situated on the west bank of the Guadalquivir River, played an important role in the history of the city and constitutes by itself a folk, monumental and cultural center.
On the other hand, "La Macarena" neighbourhood is located on the northern side of the city centre. It contains some important monuments and religious buildings, such as the Museum and Catholic Church of "La Macarena" or the "Hospital de las Cinco Llagas".
Plaza de España, panoramic view.
Museums.
The most important art collection of Seville is the Museum of Fine Arts of Seville. It was established in 1835 in the former Convent of "La Merced". It holds many masterworks by Murillo, Pacheco, Zurbarán, Valdés Leal, and others masters of the Baroque Sevillian School, containing also Flemish paintings of the 15th and 16th centuries.
Other museums in Seville are:
Parks and gardens.
The Alcázar Gardens
Culture.
Festivals.
The "Semana Santa" (Holy Week) and the "Feria de Sevilla" (Seville Fair), also known as "Feria de Abril" (April Fair), are the two most well-known of Seville's festivals. Seville is internationally renowned for the solemn but decorative processions during Holy Week and the colourful and lively fair held two weeks after. During the Feria, families, businesses and organisations set up "casetas" (marquees) in which they spend the week dancing, drinking, and socialising. Traditionally, women wear elaborate flamenco dresses and men dress in their best suits. The marquees are set up on a permanent fairground in the district of Los Remedios, in which each street is named after a famous bullfighter.
Gastronomy.
The "tapas" scene is one of the main cultural attractions of the city: people go from one bar to another, enjoying small dishes called tapas (literally "lids" or "covers" in Spanish, referring to their probable origin as snacks served on small plates used to cover drinks).
Local specialities include fried and grilled seafood (including squid, "choco" (cuttlefish), swordfish, marinated dogfish, and "ortiguillas"), grilled and stewed meat, spinach with chickpeas, "Jamón ibérico", lamb kidneys in sherry sauce, snails, "caldo de puchero", and "gazpacho". A sandwich known as a "serranito" is the typical and popular version of fast food.
Typical desserts from Seville include "pestiños", a honey-coated sweet fritter; "torrijas", fried slices of bread with honey; "roscos fritos", deep-fried sugar-coated ring doughnuts; "magdalenas" or fairy cakes; "yemas de San Leandro", which provide the city's convents with a source of revenue; and "tortas de aceite", a thin sugar-coated cake made with olive oil. "Polvorones" and "mantecados" are traditional Christmas products, whereas "pestiños" and "torrijas" are typically consumed during the Holy Week.
Bitter Seville oranges grow on trees lining the city streets. Formerly, large quantities were collected and exported to Britain to be used in marmalade. Today the fruit is used predominantly as compost locally, rather than as a foodstuff. According to legend, the Arabs brought the bitter orange to Seville from East Asia via Iraq around the 10th century to beautify and perfume their patios and gardens, as well as to provide shade. The flowers of the tree are a source of neroli oil, commonly used in perfumery and in skin lotions for massage.
Music.
Seville had a vibrant rock music scene in the 1970s and 1980s with bands like Triana, Alameda and Smash, who fused Andalusia's traditional flamenco music with British-style progressive rock. The punk rock group Reincidentes and indie band Sr Chinarro, as well as singer Kiko Veneno, rose to prominence in the early 1990s. The city's music scene now features rap acts such as SFDK, Mala Rodríguez, Dareysteel, Tote King, Dogma Crew, and Jesuly. Seville's diverse music scene is reflected in the variety of its club-centred nightlife.
The city is also home to many theatres and performance spaces where classical music is performed, including Teatro Lope de Vega, Teatro La Maestranza, Teatro Central, the Real Alcazar Gardens and the Sala Joaquín Turina.
Despite its name, the sevillana dance, commonly presented as flamenco, is not thought to be of Sevillan origin. However, the folksongs called "sevillanas" are authentically Sevillan, as is the four-part dance performed with them. Seville, and most significantly, the western district of Triana, was a major centre of the development of flamenco.
Economy.
Seville is the most populated city in southern Spain, and has the largest GDP (Gross Domestic Product) of any in Andalusia, accounting for one quarter of its total GDP. All municipalities in the metropolitan area depend directly or indirectly on Seville's economy, while agriculture dominates the economy of the smaller villages, with some industrial activity localised in industrial parks. The "Diputacion de Sevilla" (Deputation of Seville), with provincial headquarters in the Antiguo Cuartel de Caballería (Old Cavalry Barracks) on Avenida Menendez Pelayo, provides public services to distant villages that they can not provide themselves. The University of Seville and the University Pablo de Olavide are important centres of learning in western Andalusia as they offer a wide range of academic courses; consequently the city has a large number of students from Huelva and Cádiz.
The economic activity of Seville cannot be detached from the geographical and urban context of the city; the capital of Andalusia is the centre of a growing metropolitan area. Aside from traditional neighbourhoods such as Santa Cruz, Triana and others, those further away from the centre, such as Nervión, Sevilla Este, and El Porvenir have seen recent economic growth. Until the economic crisis of 2007, this urban area saw significant population growth and the development of new industrial and commercial parks.
During this period, availability of infrastructure in the city contributed to the growth of an economy dominated by the service sector, but in which industry still holds a considerable place.
Infrastructure.
The 1990s saw massive growth in investment in infrastructure in Seville, largely due to its hosting of the Universal Exposition of Seville in 1992. This economic development of the city and its urban area is supported by good transportation links to other Spanish cities, including a high-speed AVE railway connection to Madrid, and a new international airport.
Seville has the only inland port in Spain, located 80 km from the mouth of the Guadalquivir River. This harbour complex offers access to the Atlantic and the Mediterranean, and allows trade in goods between the south of Spain (Andalusia, Extremadura) and Europe, the Middle East and North Africa. The port has undergone reorganisation. Annual tonnage rose to 5.3 million tonnes of goods in 2006.
Cartuja 93 is a research and development park. employing 15,000 persons. The Cajasol Tower skyscraper is under construction in the park for the Spanish bank Cajasol's headquarters and offices. The tower was started in March 2008 and is expected to be finished in early 2013. With a height of 180.5 metres (592 feet) and 40 floors, it will be the tallest building in Andalusia.
Seville has conference facilities, including the Congress Palace. Its "Parque Tecnológico y Aeronáutico Aerópolis" (Technological and Aeronautical Park) is focussed on the aircraft industry. Outside of Seville are nine PS20 solar power towers which use the city's sunny weather to provide most of it with clean and renewable energy.
Research and development.
The "Consejo Superior de Investigaciones Científicas en Sevilla" (CSIC) is based in the former Pavilion of Peru in the Maria Luisa Park. In April 2008 the city council of Seville provided a grant to renovate the building to create the "Casa de la Ciencia" (Science Center) to encourage popular interest in science.
The internationally recognised company "Neocodex" has its headquarters in Seville; it maintains the first and largest DNA bank in Spain and has made significant contributions to scientific research in genetics. Seville is also considered an important technological and research centre for renewable energy and the aeronautics industry.
The output of the research centres in Sevillan universities working in tandem with city government, and the numerous local technology companies, have made Seville a leader among Spanish cities in technological research and development. The "Parque Científico Tecnológico Cartuja 93" is a nexus of private and public investment in various fields of research.
Principal fields of innovation and research are: telecommunications, new technologies, biotechnology (with applications in local agricultural practices), environment and renewable energy.
Transportation.
Bus.
Seville is served by the TUSSAM bus network which runs buses throughout the city. The communicates by bus with all the satellite towns of Seville.
Two bus stations serve transportation between surrounding areas and other cities: "Plaza de Armas" Station, with destinations north and west, and "Prado de San Sebastián" Station, covering routes to the south and east. "Plaza de Armas" station has direct bus lines to many Spanish cities and with Lisbon, in Portugal.
Metro.
The Seville metro ("Metro de Sevilla" in Spanish) is a light metro network serving the city of Seville and its metropolitan area. The system is totally independent of any other rail or street traffic. All stations were built with platform screen doors.
It was the sixth Metro system to be built in Spain, after those in Madrid, Barcelona, Valencia, Bilbao and Palma de Mallorca. Currently, it is the fifth biggest Metro company in Spain by number of passengers carried (more than 12,000,000 in 2009).
Tram.
MetroCentro is a surface tramway serving the centre of the city. It began operating in October 2007.
The service has just five stops: Plaza Nueva, Archivo de Indias, Puerta de Jerez, Prado de San Sebastián and San Bernardo, all as part of "Phase I" of the project. It is expected to be extended to Santa Justa AVE station, including four new stops: San Francisco Javier, Eduardo Dato, Luis de Morales and Santa Justa. This extension was postponed although the City Council had made expanding the metro lines a priority. 
Train.
The Santa Justa Train Station is served by the AVE high-speed rail system, and is operated by the Spanish formerly state-owned rail company Renfe. A five-line commuter rail service ("Cercanías") joins the city with the Metropolitan area. Seville is on the , a net created with Seville next to 17 major cities of Spain with high-speed rail.
Bicycle.
The Sevici community bicycle programme has integrated bicycles into the public transport network. Bicycles are available for hire around the city at low cost and green bicycle lanes can be seen on most major streets. The number of people using bicycles as a mean of transport in Seville has increased substantially in recent years, multiplying tenfold from 2006 to 2011. As of 2013, an estimated 8.9 percent of all mechanized trips in the city (and 5.6 percent of all trips including those on foot) are made by bicycle.
The city council signed a contract with the multinational corporation JCDecaux, an outdoor advertising company. The public bicycle rental system is financed by a local advertising operator in return for the city signing over a 10-year licence to exploit city-wide billboards. The overall scheme is called Cyclocity by JCDecaux, but each city's system is branded under an individual name.
Airport.
San Pablo Airport is the main airport for Seville and is Andalusia’s second busiest airport, after Malaga. The airport handled 4,051,392 passengers and just under 5,000 tonnes of cargo in 2009. It has one terminal and one runway.
It is one of many bases for the Spanish low cost carrier Vueling, and from November 2010 Ryanair will base two aircraft at the airport.
Port.
Seville is the only commercial river port of Spain, and the only inland city in the country where cruise ships can arrive in the historical centre. On 21 August 2012, the Muelle de las Delicias, controlled by the Port Authority of Seville, hosted the cruise ship Azamara Journey for two days, the largest ship ever to visit the town. This vessel belongs to the shipping company Royal Caribbean and can accommodate up to 700 passengers.
Roads.
Seville has one ring road, the SE-30, which connects with the dual carriageway of the south, the A-4, that directly communicates the city with Cádiz, Cordoba and Madrid. Also there is another dual carriageway, the A-92, linking the city with Estepa, Antequera, Granada, Guadix and Almeria. The A-49 links Seville with Huelva and the Algarve in the south of Portugal.
Education.
Seville is home to three public universities: the University of Seville, founded in 1505, originally was a tobacco factory and the one in which Carmen worked in the opera Carmen, the Pablo de Olavide University, founded in 1997 and the International University of Andalusia, founded in 1994.
Additionally, there is the School of Hispanic American Studies, founded in 1942, the Menéndez Pelayo International University, based in Santander, which operates branch campuses in Seville.
Sport.
Seville is the hometown of two rival association football teams: Sevilla Fútbol Club and Real Betis Balompié, Sevilla playing in the Liga BBVA with Betis recently relegated to the Liga Adelante in the 2013/14 season. Both teams have only won the league once each: Betis in 1935 and Sevilla in 1946. Only Sevilla has won European competitions, winning consecutive UEFA Cup finals in 2006 and 2007 and the UEFA Europa League in 2014. Sevilla's stadium, the Ramón Sánchez Pizjuán, was a venue during the 1982 FIFA World Cup and four years later hosted the 1986 European Cup Final. Seville's Olympic Stadium on the Isla de La Cartuja was the venue for the 2003 UEFA Cup Final.
Seville housed the tennis Davis Cup final in 2004 and 2011, and the 7th Athletics World Championships. The city unsuccessfully bid for the 2004 and 2008 Summer Olympics, for which the 60,000-seat Estadio de La Cartuja was designed to stage. Seville has one important basketball club, the CB Sevilla, that plays in ACB League. Seville's Guadalquivir river is one of only three FISA approved international training centres for rowing (sport) and the only one in Spain; the 2002 World Rowing Championships and the 2013 European Rowing Championships were held there.
Twin towns and sister cities.
Seville is twinned with the following cities:
Titles.
Seville has been given titles by Spanish monarchs and heads of state throughout its history.

</doc>
<doc id="37773" url="http://en.wikipedia.org/wiki?curid=37773" title="M. R. James">
M. R. James

Montague Rhodes James OM, MA, FBA (1 August 1862 – 12 June 1936), who used the publication name M. R. James, was an English author, medievalist scholar and provost of King's College, Cambridge (1905–18), and of Eton College (1918–36). 
Though James's work as a medievalist is still highly regarded, he is best remembered for his ghost stories, which are regarded as among the best in the genre. James redefined the ghost story for the new century by abandoning many of the formal Gothic clichés of his predecessors and using more realistic contemporary settings. However, James's protagonists and plots tend to reflect his own antiquarian interests. Accordingly, he is known as the originator of the "antiquarian ghost story".
Early influences.
James was born in Goodnestone Parsonage, near Dover in Kent, England, although his parents had associations with Aldeburgh in Suffolk. His father was Herbert James, an Evangelical Anglican clergyman, and his mother, Mary Emily ("née" Horton), was the daughter of a naval officer. He had two older brothers, Sydney and Herbert (nicknamed "Ber"), and an older sister, Grace. Sydney James later became Archdeacon of Dudley. From the age of three (1865) until 1909 James's home, if not always his residence, was at the Rectory in Great Livermere, Suffolk. This had previously been the childhood home of another eminent Suffolk antiquary, "Honest Tom" Martin (1696–1771) "of Palgrave." Several of James's ghost stories are set in Suffolk, including "'Oh, Whistle, and I'll Come to You, My Lad'" (Felixstowe), "A Warning to the Curious" (Aldeburgh), "Rats" and "A Vignette" (Great Livermere). In September 1873 he arrived as a boarder at Temple Grove School, one of the leading boys' preparatory schools of the day. He lived for many years, first as an undergraduate, then as a don and provost, at King's College, Cambridge, where he was also a member of the Pitt Club. The university provides settings for several of his tales. Apart from medieval subjects, James studied the classics and appeared very successfully in a staging of Aristophanes' play "The Birds", with music by Hubert Parry. His ability as an actor was also apparent when he read his new ghost stories to friends at Christmas time.
Scholarly works.
James is best known for his ghost stories, but his work as a medievalist scholar was prodigious and remains highly respected in scholarly circles. Indeed, the success of his stories was founded on his antiquarian talents and knowledge. His discovery of a manuscript fragment led to excavations in the ruins of the abbey at Bury St Edmunds, West Suffolk, in 1902, in which the graves of several twelfth-century abbots described by Jocelyn de Brakelond (a contemporary chronicler) were rediscovered, having been lost since the Dissolution. His 1917 edition of the Latin "Lives" of Saint Aethelberht, king and martyr ("English Historical Review" 32), remains authoritative.
He catalogued many of the manuscript libraries of the Cambridge colleges. Among his other scholarly works, he wrote "The Apocalypse in Art", which placed illuminated Apocalypse manuscripts into families. He also translated the New Testament Apocrypha and contributed to the "Encyclopaedia Biblica" (1903). His ability to wear his learning lightly is apparent in his "Suffolk and Norfolk" (Dent, 1930), in which a great deal of knowledge is presented in a popular and accessible form, and in "Abbeys" (Great Western Railway, 1925).
James also achieved a great deal during his directorship of the Fitzwilliam Museum in Cambridge (1893–1908). He managed to secure a large number of important paintings and manuscripts, including notable portraits by Titian.
James was Provost of Eton College from 1918 to 1936. He died in 1936 and was buried in Eton town cemetery.
Ghost stories.
James's ghost stories were published in a series of collections: "Ghost Stories of an Antiquary" (1904), "More Ghost Stories of an Antiquary" (1911), "A Thin Ghost and Others" (1919), and "A Warning to the Curious and Other Ghost Stories" (1925). The first hardback collected edition appeared in 1931. Many of the tales were written as Christmas Eve entertainments and read aloud to friends. This idea was used by the BBC in 2000 when they filmed Christopher Lee reading James's stories in a candle-lit room in King's College.
James perfected a method of story-telling which has since become known as Jamesian. The classic Jamesian tale usually includes the following elements:
According to James, the story must "put the reader into the position of saying to himself, 'If I'm not very careful, something of this kind may happen to me!'" He also perfected the technique of narrating supernatural events through implication and suggestion, letting his reader fill in the blanks, and focusing on the mundane details of his settings and characters in order to throw the horrific and bizarre elements into greater relief. He summed up his approach in his foreword to the anthology "Ghosts and Marvels": "Two ingredients most valuable in the concocting of a ghost story are, to me, the atmosphere and the nicely managed crescendo. ... Let us, then, be introduced to the actors in a placid way; let us see them going about their ordinary business, undisturbed by forebodings, pleased with their surroundings; and into this calm environment let the ominous thing put out its head, unobtrusively at first, and then more insistently, until it holds the stage."
He also noted: "Another requisite, in my opinion, is that the ghost should be malevolent or odious: amiable and helpful apparitions are all very well in fairy tales or in local legends, but I have no use for them in a fictitious ghost story."
Despite his suggestion (in the essay "Stories I Have Tried to Write") that writers employ reticence in their work, many of James's tales depict scenes and images of savage and often disturbing violence. For example, in "Lost Hearts", pubescent children are taken in by a sinister dabbler in the occult who cuts their hearts from their still-living bodies. In a 1929 essay, James stated:
Reticence may be an elderly doctrine to preach, yet from the artistic point of view, I am sure it is a sound one. Reticence conduces to effect, blatancy ruins it, and there is much blatancy in a lot of recent stories. They drag in sex too, which is a fatal mistake; sex is tiresome enough in the novels; in a ghost story, or as the backbone of a ghost story, I have no patience with it. At the same time don't let us be mild and drab. Malevolence and terror, the glare of evil faces, 'the stony grin of unearthly malice', pursuing forms in darkness, and 'long-drawn, distant screams', are all in place, and so is a modicum of blood, shed with deliberation and carefully husbanded; the weltering and wallowing that I too often encounter merely recall the methods of M G Lewis.
Although not overtly sexual, plots of this nature have been perceived as unintentional metaphors of the Freudian variety. James's biographer Michael Cox wrote in "M. R. James: An Informal Portrait" (1983), "One need not be a professional psychoanalyst to see the ghost stories as some release from feelings held in check." Reviewing this biography ("Daily Telegraph", 1983), the novelist and diarist Anthony Powell, who attended Eton under James's tutelage, commented that "I myself have heard it suggested that James's (of course platonic) love affairs were in fact fascinating to watch." Powell was referring to James's relationships with his pupils, not his peers.
Other critics have seen complex psychological undercurrents in James's work. His authorial revulsion from tactile contact with other people has been noted by Julia Briggs in "Night Visitors: The Rise and Fall of the English Ghost Story" (1977). As Nigel Kneale said in the introduction to the Folio Society edition of "Ghost Stories of M. R. James", "In an age where every man is his own psychologist, M. R. James looks like rich and promising material. ... There must have been times when it was hard to be Monty James." Or, to put it another way, "Although James conjures up strange beasts and supernatural manifestations, the shock effect of his stories is usually strongest when he is dealing in physical mutilation and abnormality, generally sketched in with the lightest of pens."
In addition to writing his own stories, James championed the works of Sheridan Le Fanu, whom he viewed as "absolutely in the first rank as a writer of ghost stories", editing and supplying introductions to "Madame Crowl's Ghost" (1923) and "Uncle Silas" (1926).
James's statements about his actual beliefs about ghosts were ambiguous. He wrote, "I answer that I am prepared to consider evidence and accept it if it satisfies me."
Reception and influence.
H. P. Lovecraft was an admirer of James's work, extolling the stories as the peak of the ghost story form in his essay "Supernatural Horror in Literature" (1927). Another renowned fan of James in the horror and fantasy genre was Clark Ashton Smith, who wrote an essay on him. Michael Sadleir described M. R. James as "the best ghost-story writer England has ever produced". Marjorie Bowen also admired James's work, referring to his ghost stories as "the supreme art of M. R. James". Mary Butts, another admirer of James, wrote the first critical essay on his work, "The Art of Montagu James", in the February 1934 issue of the "London Mercury". Manly Wade Wellman esteemed James' fiction. In "The Great Railway Bazaar", Paul Theroux refers to "The Mezzotint" as "the most frightening story I know". In his list "The 13 Most Terrifying Horror Stories", T. E. D. Klein placed James's "Casting the Runes" at number one. E. F. Bleiler has stated that James is "in the opinion of many, the foremost modern writer of supernatural fiction", and he described "More Ghost Stories of an Antiquary" as containing "first-rate stories". Ruth Rendell has also expressed admiration for James's work, stating, "There are some authors one wished one had never read in order to have the joy of reading them for the first time. For me, M. R. James is one of these." David Langford has described James as the author of "the 20th century's most influential canon of ghost stories".
Sir John Betjeman, in an introduction to Peter Haining's book about James, shows how influenced he was by James's work:
In the year 1920 I was a new boy at the Dragon school, Oxford, then called Lynam's, of which the headmaster was C. C. Lynam, known as 'the Skipper'. He dressed and looked like an old Sea Salt, and in his gruff voice would tell us stories by firelight in the boys' room of an evening with all the lights out and his back to the fire. I remember he told the stories as having happened to himself. ... they were the best stories I ever heard, and gave me an interest in old churches, and country houses, and Scandinavia that not even the mighty Hans Christian Andersen eclipsed.
Betjeman later discovered the stories were all based on those of M. R. James.
H. Russell Wakefield's supernatural fiction was strongly influenced by the work of James. A large number of British writers deliberately wrote ghost stories in the Jamesian style; these writers, sometimes described as the "James Gang", include A. N. L. Munby, E. G. Swain, "Ingulphus" (pseudonym of Sir Arthur Gray, 1852–1940), Amyas Northcote and R. H. Malden, although some commentators consider their stories to be inferior to those of James himself. Although most of the early Jamesian writers were male, there were several notable female writers of such fiction, including Eleanor Scott (pseudonym of Helen M Leys, 1892–1965) in the stories of her book "Randall's Round" (1929) and D. K. Broster in the collection "Couching at the Door: Strange and Macabre Tales" (1942). L. T. C. Rolt also modelled his ghost stories on James's work but, unlike other Jamesian writers, set them in industrial locations, such as mines and railways.
The stories of M. R. James continue to influence many of today's great supernatural writers, including Stephen King (who discusses James in the 1981 non-fiction book "Danse Macabre") and Ramsey Campbell, who edited "Meddling with Ghosts: Stories in the Tradition of M. R. James" and wrote the short story "The Guide" in tribute. The author John Bellairs paid homage to James by incorporating plot elements borrowed from James's ghost stories into several of his own juvenile mysteries. Several of Jonathan Aycliffe's novels, including "Whispers in the Dark" and "The Matrix" are influenced by James's work. Aycliffe/MacEoin studied for his PhD in Persian Studies at King' College. This makes three KC authors of ghost stories (James, Munby and Aycliffe).
Works inspired by James.
The composer Kaikhosru Shapurji Sorabji wrote two pieces for piano with a link to James: "Quaere reliqua hujus materiei inter secretiora" (1940), inspired by "Count Magnus", and "St. Bertrand de Comminges: "He was laughing in the tower"" (1941), inspired by "Canon Alberic's Scrap-Book".
H. Russell Wakefield's story "He Cometh and He Passeth By!" (1928) is a homage to James's "Casting the Runes".
W. F. Harvey's ghost story "The Ankardyne Pew" (1928) is also a homage to James's work, which Harvey admired.
H. F. Heard's novel "The Black Fox" is an occult thriller inspired by "The Stalls of Barchester Cathedral".
Kingsley Amis' novel "The Green Man" is partly a homage to James's ghost stories.
Between 1976 and 1992, Sheila Hodgson authored and produced for BBC Radio 4 a series of plays which portrayed M. R. James as the diarist of a series of fictional ghost stories, mainly inspired by fragments referred to in his essay "Stories I Have Tried to Write". These consisted of "Whisper in the Ear" (October 1976), "Turn, Turn, Turn" (March 1977), "The Backward Glance" (22 September 1977), "Here Am I, Where Are You?" (29 December 1977), "Echoes from the Abbey" (21 November 1984), "The Lodestone" (19 April 1989), and "The Boat Hook" (15 April 1992). David March appeared as James in all but the final two, which starred Michael Williams. Raidió Teilifís Éireann also broadcast "The Fellow Travellers", with Aiden Grennell as James, on 20 February 1994. All the stories later appeared in Hodgson's collection "The Fellow Travellers and Other Ghost Stories" (Ash-Tree Press, 1998).
On Christmas Day 1987, "The Teeth of Abbot Thomas", an MRJ parody by Stephen Sheridan, was broadcast on Radio 4. It starred Alfred Marks (as Abbot Thomas), Robert Bathurst, Denise Coffey, Jonathan Adams and Bill Wallis.
The novelist James Hynes wrote an updated version of "Casting the Runes" in his 1997 story collection "Publish and Perish".
In 2003, Radio 4 broadcast "The House at World's End" by Stephen Sheridan. A pastiche of James's work, it contained numerous echoes of his stories while offering a fictional account of how he became interested in the supernatural. James was played by John Rowe, with Jonathan Keeble playing James's younger self.
In 2008 the English experimental neofolk duo The Triple Tree, featuring Tony Wakeford and Andrew King from Sol Invictus, released the album "Ghosts" on which all but three songs were based upon the stories of James. One of the songs, "Three Crowns" (based on the short story "A Warning to the Curious"), also appeared on the compilation album "John Barleycorn Reborn" (2007).
In February 2012, the UK psychedelic band The Future Kings of England released their 4th album, "Who Is This Who Is Coming", based on James's "Oh, Whistle, and I’ll Come to You, My Lad". An instrumental work, it evokes the story from beginning to end, with the tracks seguing into one another to form a continuous piece of music.
On 23 February 2012 the Royal Mail released a stamp featuring James as part its "Britons of Distinction" series.
In August 2013, The Fan Museum in London announced a performance, on 25 and 26 October 2013, of "The Laws of Shadows" a new play by Adrian Drew about M. R. James. The play is set in James's rooms at Cambridge University and deals with his relationships with his colleague E. F. Benson and the young artist James McBryde.
Adaptations.
Television.
There have been numerous television adaptations of James's stories. The very first TV adaptation was American—a 1951 version of "The Tractate Middoth" in the "Lights Out" series, called "The Lost Will of Dr Rant" and featuring Leslie Nielsen. It is available on several DVDs, including an Alpha Video release alongside Gore Vidal's "Climax!" adaptation of "Doctor Jekyll and Mister Hyde", starring Michael Rennie.
The majority of television adaptations of James's works have been made in Britain. The best-known adaptations include "Whistle and I'll Come to You" (1968, directed by Jonathan Miller) and "A Warning to the Curious" (1972; directed by Lawrence Gordon Clark), starring Michael Hordern and Peter Vaughan respectively. The latter was part of an annual BBC series titled "A Ghost Story for Christmas", which would ultimately produce five dramatizations of James's stories: "The Stalls of Barchester" (1971), "A Warning to the Curious" (1972), "Lost Hearts" (1973), "The Treasure of Abbot Thomas" (1974) and "The Ash-tree" (1975).
Although ITV produced four black-and-white adaptations of James's ghost stories between 1966 and 1968, no surviving copies are known to exist. However, a short preview trailer featuring several scenes from the 1968 adaptation of "Casting the Runes" survived and has been shown at cult film festivals. It is also available on Network DVD's "Mystery and Imagination" DVD set. "Casting the Runes" was again adapted for television in 1979 as an episode of the "ITV Playhouse" series with Lawrence Gordon Clark directing and starring Jan Francis as the lead protagonist (a man in previous adaptations). It has been released by Network DVD which also includes a 20-minute adaptation of "Mr Humphreys and His Inheritance" (made in 1976 by Yorkshire Television as part of the "Music Scene" ITV Schools programme) and "A Pleasant Terror", a 1995 ITV documentary about James.
In 1980, the BBC produced a series, aimed at older children, of readings of classic horror stories read by various actors entitled "Spine Chillers". This included readings of James's stories "The Mezzotint", "The Diary of Mr Poynter" and "A School Story", all read by Michael Bryant. In December 1986, BBC2 broadcast partially dramatized readings by the actor Robert Powell of "The Mezzotint", "The Ash-Tree", "Wailing Well", "Oh, Whistle, and I'll Come to You, My Lad" and "The Rose Garden". In a similar vein, the BBC also produced a short series ("M. R. James' Ghost Stories for Christmas") of further readings in 2000, which featured Christopher Lee as James, who (in character) read 30-minute adaptations of "The Stalls of Barchester Cathedral", "The Ash-tree", "Number 13" and "A Warning to the Curious".
The 1970s "Ghost Story for Christmas" tradition was briefly revived in December 2005, when BBC Four broadcast a new version of James's story "A View from a Hill", with "Number 13" following in December 2006. These were broadly faithful to the originals and were quite well received. A new version of "Whistle and I'll Come to You", starring John Hurt, was broadcast by BBC Two on Christmas Eve 2010.
Ten of the BBC productions made between 1968 and 2010 (including three episodes of the Christopher Lee readings series) were released on DVD in October 2011 as a five-disc boxed set in Australia by Shock DVD, as "The Complete Ghost Stories of M.R. James". A boxed set of the BBC's "Ghost Stories For Christmas" productions, including all of the M.R. James adaptations, was released in Britain in 2012, and an expanded six-disc set (including Robert Powell's series of readings from 1986, and readings from the BBC's 1980 "Spine Chillers" series for children) was released in 2013.
A new adaptation of "The Tractate Middoth", the directorial debut of Mark Gatiss, was broadcast on BBC Two on 25 December 2013. Gatiss also presented a new documentary, entitled "M. R. James: Ghost Writer", which was screened directly afterwards.
Radio and audio.
On 19 November 1947, the thirteenth episode of the CBS radio series "Escape" was an adaptation of "Casting the Runes".
On 12 January 1974, the CBS Radio Mystery Theater, hosted by E. G. Marshall, presented the episode "This will Kill You", which was an updated, loose adaptation of "Casting the Runes".
In January 1981, BBC Radio 4 broadcast an Afternoon Play called "The Hex", written by Gregory Evans and loosely based on "Casting the Runes", starring Conrad Phillips and Kim Hartman. The play was subsequently transmitted, in translation, in several other countries.
In 1997–1998 Radio 4 broadcast "The Late Book: Ghost Stories", a series of 15-minute readings of M. R. James stories, abridged and produced by Paul Kent and narrated by Benjamin Whitrow (repeated on BBC 7, December 2003–January 2004, September–October 2004, February 2007, October–November 2011). The stories were "Canon Alberic's Scrap-Book", "Lost Hearts", "A School Story", "The Haunted Dolls' House" and "Rats".
In the 1980s, a series of four double audio cassettes was released by Argo Records, featuring nineteen unabridged James stories narrated by Michael Hordern. The tapes were titled "Ghost Stories" (1982), "More Ghost Stories" (1984), "A Warning to the Curious" (1985) and "No. 13 and Other Ghost Stories" (1988). ISIS Audio Books also released two collections of unabridged James stories, this time narrated by Nigel Lambert. These tapes were titled "A Warning to the Curious and Other Tales" (four audio cassettes, six stories, March 1992) and "Ghost Stories of an Antiquary" (three audio cassettes, eight stories, December 1992).
In Spring 2007 UK-based Craftsman Audio Books released the first complete set of audio recordings of James's stories on CD, spread across two volumes and read by David Collings. The ghost story author Reggie Oliver acted as consultant on the project.
April 2007 also saw the release of "Tales of the Supernatural", Volume One, an audiobook presentation by , featuring the James stories "Lost Hearts" read by Geoffrey Bayldon, "Rats" and "Number 13" by Ian Fairbairn, with Gareth David-Lloyd reading "Casting the Runes" and "There Was a Man Dwelt by a Churchyard". Volume Two was to follow in the summer.
Over the 2007 Christmas period Radio 4 revived the tradition of James's ghost stories for the festive period with a series of adaptations of his most popular tales. Each lasted around 15 minutes and was introduced by Derek Jacobi as James himself. Due to the short running times the tales were fairly rushed, with much of the stories condensed or removed. Stories adapted included "Oh, Whistle, and I'll Come to You, My Lad", "Number 13" and "Lost Hearts".
As of 2010 the audiobooks site LibriVox offers a set of audio readings (available as free downloads) under the collective heading "Ghost Stories of an Antiquary".
Film.
The only notable film version of James's work to date has been the 1957 British adaptation of "Casting the Runes" by Jacques Tourneur, titled "Night of the Demon" (known as "Curse of the Demon" in the US), starring Dana Andrews, Peggy Cummins and Niall MacGinnis. Another, looser adaptation of "Casting the Runes" borrowing elements from the earlier film is Sam Raimi's 2009 film, "Drag Me to Hell". "The Brides of Dracula" (Terence Fisher, 1960) appears to quote the padlocked coffin scene from "Count Magnus", while Michele Soavi's 1989 film "La Chiesa" ("The Church")—which features a script co-authored by Dario Argento—borrows the motif of the "stone with seven eyes", as well as a few other important details, from "The Treasure of Abbot Thomas". A new film adaptation of "Casting The Runes" was announced in 2013 by director Joe Dante, which is a modernised reimagining of the story with James's characters of Dunning now portrayed as a celebrity blogger and Karswell as a successful motivational speaker and self-help guru with connections to the occult. Actor Simon Pegg was attached to star, though the film has yet to go into production.
Stage.
The first stage version of "Casting the Runes" was performed at the Carriageworks Theatre in Leeds, England, on 9–10 June 2006 by the Pandemonium Theatre Company.
In 2006–2007, Nunkie Theatre Company toured "A Pleasing Terror" round the UK and Ireland. This one-man show was an atmospheric retelling of two of James's tales, "Canon Alberic's Scrap-Book" and "The Mezzotint". In October 2007, a sequel, "Oh, Whistle...", comprising "Oh, Whistle, and I'll Come to You, My Lad" and "The Ash-tree", began to tour the UK. A third James performance, "A Warning to the Curious", comprising the eponymous story and "Lost Hearts", began touring the UK in October 2009. Although Nunkie's Robert Lloyd Parry said in 2009 that the last would probably be his final M. R. James tour, he continued to tour the three aforementioned productions in subsequent years; and in 2012 he announced a fourth production, "Count Magnus" (consisting of "Count Magnus" and "Number 13"), to premiere on 28 September of that year.
In the summer of 2011, the Crusade Theatre Company toured a new stage adaptation of "Oh, Whistle, and I'll Come to You, My Lad" in England.

</doc>
<doc id="37774" url="http://en.wikipedia.org/wiki?curid=37774" title="Fallopia japonica">
Fallopia japonica

Fallopia japonica, commonly known as Japanese knotweed, is a large, herbaceous perennial plant of the family Polygonaceae, native to Eastern Asia in Japan, China and Korea. In North America and Europe the species is very successful and has been classified as an invasive species in several countries. Japanese knotweed has hollow stems with distinct raised nodes that give it the appearance of bamboo, though it is not closely related. While stems may reach a maximum height of 3–4 m each growing season, it is typical to see much smaller plants in places where they sprout through cracks in the pavement or are repeatedly cut down. The leaves are broad oval with a truncated base, 7–14 cm long and 5–12 cm broad, with an entire margin. The flowers are small, cream or white, produced in erect racemes 6–15 cm long in late summer and early autumn.
Closely related species include giant knotweed ("Fallopia sachalinensis", syn. "Polygonum sachalinense") and Russian vine ("Fallopia baldschuanica", syn. "Polygonum aubertii", "Polygonum baldschuanicum").
Other English names for Japanese knotweed include fleeceflower, Himalayan fleece vine, monkeyweed, monkey fungus, Hancock's curse, elephant ears, pea shooters, donkey rhubarb (although it is not a rhubarb), sally rhubarb, Japanese bamboo, American bamboo, and Mexican bamboo (though it is not a bamboo). In Chinese medicine, it is known as "Huzhang" (), which translates to "tiger stick." There are also regional names, and it is sometimes confused with sorrel. In Japanese, the name is "itadori" (虎杖, イタドリ).
 
Invasive species.
It is listed by the World Conservation Union as one of the world's worst invasive species.
The invasive root system and strong growth can damage concrete foundations, buildings, flood defences, roads, paving, retaining walls and architectural sites. It can also reduce the capacity of channels in flood defences to carry water.
It is a frequent colonizer of temperate riparian ecosystems, roadsides and waste places. It forms thick, dense colonies that completely crowd out any other herbaceous species and is now considered one of the worst invasive exotics in parts of the eastern United States. The success of the species has been partially attributed to its tolerance of a very wide range of soil types, pH and salinity. Its rhizomes can survive temperatures of -35 °C and can extend 7 m horizontally and 3 m deep, making removal by excavation extremely difficult.
The plant is also resilient to cutting, vigorously resprouting from the roots. The most effective method of control is by herbicide application close to the flowering stage in late summer or autumn. In some cases it is possible to eradicate Japanese knotweed in one growing season using only herbicides. Trials in the Queen Charlotte Islands (Haida Gwaii) of British Columbia using sea water sprayed on the foliage have demonstrated promising results, which may prove to be a viable option for eradication where concerns over herbicide application are too great.
Two biological pest control agents that show promise in the control of the plant are the psyllid "Aphalara itadori" and a leaf spot fungus from genus "Mycosphaerella".
It is classed as an unwanted organism in New Zealand and is established in some parts of the country.
In the UK, Japanese knotweed is established in the wild in many parts of the country and creates problems due to the impact on biodiversity, flooding management and damage to property. It is an offence under section 14(2) of the Wildlife and Countryside Act 1981 to "plant or otherwise cause to grow in the wild" any plant listed in Schedule nine, Part II to the Act, which includes Japanese knotweed. It is also classed as "controlled waste" in Britain under part 2 of the Environmental Protection Act 1990. This requires disposal at licensed landfill sites. The species is expensive to remove; Defra's Review of Non-native Species Policy states that a national eradication programme would be prohibitively expensive at £1.56 billion.
The decision was taken on 9 March 2010 in the UK to release into the wild a Japanese psyllid insect, "Aphalara itadori". Its diet is highly specific to Japanese knotweed and shows good potential for its control.
In Scotland, the Wildlife and Natural Environment (Scotland) Act 2011 came into force in July 2012 that superseded the Wildlife and Countryside Act 1981. This act states that is an offence to spread intentionally or unintentionally Japanese knotweed (or other non-native invasive species).
The weed can be found in 39 of the 50 United States and in six provinces in Canada. It is listed as an invasive weed in Maine, Ohio, Vermont, Virginia, West Virginia, New York, Alaska, Pennsylvania, Michigan, Oregon and Washington state, and Colorado .
Uses.
Japanese knotweed flowers are valued by some beekeepers as an important source of nectar for honeybees, at a time of year when little else is flowering. Japanese knotweed yields a monofloral honey, usually called "bamboo honey" by northeastern U.S. beekeepers, like a mild-flavored version of buckwheat honey (a related plant also in the Polygonaceae).
The young stems are edible as a spring vegetable, with a flavor similar to extremely sour rhubarb. In some locations, semi-cultivating Japanese knotweed for food has been used as a means of controlling knotweed populations that invade sensitive wetland areas and drive out the native vegetation. It is eaten in Japan as "sansai" or wild foraged vegetable.
Similarly to rhubarb, knotweed contains oxalic acid, which when eaten may aggravate conditions such as rheumatism, arthritis, gout, kidney stones or hyperacidity.
Both Japanese knotweed and giant knotweed are important concentrated sources of resveratrol and its glucoside piceid, replacing grape byproducts. Many large supplement sources of resveratrol now use Japanese knotweed and use its scientific name in the supplement labels. The plant is useful because of its year-round growth and robustness in different climates.
Control.
Japanese knotweed has a large underground network of roots (rhizomes). To eradicate the plant the roots need to be killed. All above-ground portions of the plant need to be controlled repeatedly for several years in order to weaken and kill the entire patch. Picking the right herbicide is essential, as it must travel through the plant and into the root system below. Glyphosate is the best active ingredient in herbicide for use on Japanese knotweed as it is ’systemic’; it penetrates through the whole plant and travels to the roots.
Digging up the rhizomes is a common solution where the land is to be developed, as this is quicker than the use of herbicides, but safe disposal of the plant material without spreading it is difficult; knotweed is classed as controlled waste in the UK, and disposal is regulated by law. Digging up the roots is also very labor-intensive and not always efficient. The roots can go to up to 10 feet (3 meters) deep, and leaving only a few inches of root behind will result in the plant quickly growing back.
Covering the affected patch of ground with a non-translucent material can be an effective follow-up strategy. However, the trimmed stems of the plant can be razor sharp and are able to pierce through most materials. Covering with non-flexible materials such as concrete slabs has to be done meticulously and without leaving even the smallest splits. The slightest opening can be enough for the plant to grow back.
More ecologically-friendly means are being tested as an alternative to chemical treatments. Soil steam sterilization involves injecting steam into contaminated soil in order to kill subterranean plant parts. Research has also been carried out on "Mycosphaerella" leafspot fungus, which devastates knotweed in its native Japan. This research has been relatively slow due to the complex life cycle of the fungus.
Research has been carried out by not-for-profit inter-governmental organisation CABI in the UK. Following earlier studies imported Japanese knotweed psyllid insects ("Aphalara itadori"), whose only food source is Japanese knotweed, were released at a number of sites in Britain in a study running from 1 April 2010 to 31 March 2014. In 2012, results suggested that establishment and population growth were likely, after the insects overwintered successfully.
Anecdotal reports of effective control describe the use of goats to eat the plant parts above ground followed by the use of pigs to root out and eat the underground parts of the plant. 
Controversy.
In the United Kingdom, Japanese knotweed has received a lot of attention in the press as a result of very restrictive lending policies by banks and other mortgage companies. Several lenders have refused mortgage applications on the basis of the plant being discovered in the garden or neighbouring garden. The Royal Institution of Chartered Surveyors published a report in 2012 in response to lenders refusing to lend "despite [knotweed] being treatable and rarely causing severe damage to the property." 
There is a real lack of information and understanding of what Japanese knotweed is and the actual damage it can cause. Without actual advice and guidance, surveyors have been unsure of how to assess the risk of Japanese knotweed, which can result in inconsistent reporting of the plant in mortgage valuations. RICS hopes that this advice will provide the industry with the tools it needs to measure the risk effectively, and provide banks with the information they require to identify who and how much to lend to at a time when it is essential to keep the housing market moving.—Philip Santo, RICS Residential Professional Group
In response to this guidance, several lenders have relaxed their criteria in relation to discovery of the plant. As recently as 2012, the policy at the Woolwich (part of Barclays plc) was "if Japanese knotweed is found on or near the property then a case will be declined due to the invasive nature of the plant." Their criteria have since been relaxed to a category-based system depending on whether the plant is discovered on a neighbouring property (categories 1 and 2) or the property itself (categories 3 and 4) incorporating proximity to the property curtilage and the main buildings. Even in a worst-case scenario (category 4), where the plant is "within 7 metres of the main building, habitable spaces, conservatory and/or garage and any permanent outbuilding, either within the curtilage of the property or on neighbouring land; and/or is causing serious damage to permanent outbuildings, associated structures, drains, paths, boundary walls and fences" Woolwich lending criteria now specify that this property may be acceptable if "remedial treatment by a Property Care Association (PCA) registered firm has been satisfactorily completed. Treatment must be covered by a minimum 10-year insurance-backed guarantee, which is property specific and transferable to subsequent owners and any mortgagee in possession." Santander have relaxed their attitude in a similar fashion.
Property Care Association chief executive Steve Hodgson, whose trade body has set up a task force to deal with the issue, said: "Japanese knotweed is not 'house cancer' and could be dealt with in the same way qualified contractors dealt with faulty wiring or damp."
Japan.
The plant is known as "itadori" (イタドリ, 虎杖). The kanji expression is from the Chinese meaning "tiger staff", but as to the Japanese appellation, one straightforward interpretation is that it comes from "remove pain" (alluding to its painkilling use), though there are other etymological explanations offered.
It grows widely throughout Japan and is foraged as a wild edible vegetable (sansai), though not in sufficient quantities to be included in statistics. They are called by such regional names as: "tonkiba" (Yamagata), "itazuiko" (Nagano, Mie), "itazura" (Gifu, Toyama, Nara, Wakayama, Kagawa), "gonpachi" (Shizuoka, Nara, Mie, Wakayama), "sashi" (Akita, Yamagata), "jajappo" (Shimane, Tottori, Okayama), "sukanpo" (many areas).
Young leaves and shoots, which look like asparagus, are used. They are extremely sour; the fibrous outer skin must be peeled, soaked in water for half a day raw or after parboiling, before being cooked.
Places in Shikoku such as central parts of Kagawa Prefecture pickle the peeled young shoots by weighting them down in salt mixed with 10% nigari (magnesium chloride). Kochi also rub these cleaned shoots with coarse salt-nigari blend. It is said (though no authority is cited) that the magnesium of the "nigari" binds with the oxalic acid thus mitigating its hazard.
A novel use for a related species known as "oh-itadori" ("Polygonum sachalinense") in Hokkaido is feeding it to larvae of sea urchins in aquaculture.

</doc>
<doc id="37776" url="http://en.wikipedia.org/wiki?curid=37776" title="Lyonesse">
Lyonesse

Lyonesse is a country in Arthurian legend, particularly in the story of Tristan and Iseult. Said to border Cornwall, it is most notable as the home of the hero Tristan, whose father was king. In later traditions Lyonesse is said to have sunk beneath the waves some time after the Tristan stories take place, making it similar to Ys and other lost lands in medieval Celtic tales, and perhaps connecting it with the Isles of Scilly.
Lyonesse in Arthurian legend.
In medieval Arthurian legend, there are no references to the sinking of Lyonesse, for the simple reason that the name originally referred to a still-existing place. Lyonesse is an English alteration of French "Léoneis" or "Léonois" (earlier "Loönois"), a development of "Lodonesia", the Latin name for Lothian in Scotland. Continental writers of Arthurian romances were often puzzled by the internal geography of Great Britain; thus it is that the author French "Prose Tristan" appears to place Léonois contiguous, by land, to Cornwall. In English adaptations of the French tales, Léonois, now "Lyonesse", becomes a kingdom wholly distinct from Lothian, and closely associated with the Cornish region, though its exact geographical location remained unspecified. The name was not attached to Cornish legends of lost coastal lands until the reign of Elizabeth I of England, however. However, the legendary lost land between Land's End and Scilly has a distinct Cornish name: "Lethowsow". This derives from the Cornish name for the Seven Stones reef, on the reputed site of the lost land's capital and the site of the notorious wreck of the "Torrey Canyon". The name translates into English as "the milky ones", from the constant white water surrounding the reef.
Alfred, Lord Tennyson's Arthurian epic "Idylls of the King", describes Lyonesse as the site of the final battle between Arthur and Mordred. One passage in particular references legends of Lyonesse as a land fated to sink beneath the ocean:
<poem>Then rose the King and moved his host by night
And ever pushed Sir Mordred, league by league,
Back to the sunset bound of Lyonesse—
A land of old upheaven from the abyss
By fire, to sink into the abyss again;
Where fragments of forgotten peoples dwelt,
And the long mountains ended in a coast
Of ever-shifting sand, and far away
The phantom circle of a moaning sea.</poem>
Deriving from a false etymology of Lyonesse, the 'City of Lions' was said in some later traditions to be the capital of the legendary kingdom, situated on what is today the Seven Stones reef, some eighteen miles west of Land's End and eight miles north-east of the Isles of Scilly.
Analogues in Celtic mythology.
The legend of a sunken kingdom appears in both Cornish and Breton mythology. In Christian times it came to be viewed as a sort of Cornish Sodom and Gomorrah, an example of divine wrath provoked by unvirtuous living, although the parallels were limited in that Lyonesse remained in Cornish thought very much a mystical and mythical land, comparable to the role of Tir na nÓg in Irish mythology.
There is a Breton parallel in the tale of the Cité d'Ys, similarly drowned as a result of its debauchery with a single virtuous survivor escaping on a horse, in this case King Gradlon. The Welsh equivalent to Lyonesse and Ker Ys is Cantre'r Gwaelod, a legendary drowned kingdom in Cardigan Bay.
It is often suggested that the tale of Lyonesse represents an extraordinary survival of folk memory of the flooding of the Isles of Scilly and Mount's Bay near Penzance. For example, the Cornish name of St Michael's Mount is "Karrek Loos y'n Koos" - literally, "the grey rock in the wood". Cornish people around Penzance still get occasional glimpses at extreme low water of a sunken forest in Mount's Bay, where petrified tree stumps become visible. The importance of the maintenance of this memory can be seen in that it came to be associated with the legendary British hero Arthur, although the date of its inundation is actually c.2500 BC.
Lyonesse in modern English literature.
Walter de la Mare's "Sunk Lyonesse" (1922) evokes it as a lost world:
<poem>In sea-cold Lyonesse,
When the Sabbath eve shafts down
On the roofs, walls, belfries
Of the foundered town,
The Nereids pluck their lyres
Where the green translucency beats,
And with motionless eyes at gaze
Make ministrely in the streets./ 
And the ocean water stirs
In salt-worn casement and porch
Plies the blunt-nosed fish
With fire in his skull for torch.
And the ringing wires resound;
And the unearthly lovely weep,
In lament of the music they make
In the sullen courts of sleep:
Whose marble flowers bloom for aye:
And—lapped by the moon-guiled tide—
Mock their carver with heart of stone,
Caged in his stone-ribbed side.</poem>
Lyonesse has been used as a setting for many modern fantasy stories, including:
Other uses of Lyonesse.
The name "Lyonesse" has often been applied to transport subjects:
Lyonesse is also the name of one of the three school houses at Cape Cornwall School.

</doc>
<doc id="37777" url="http://en.wikipedia.org/wiki?curid=37777" title="Dragon Book">
Dragon Book

The Dragon Book may refer to:

</doc>
<doc id="37778" url="http://en.wikipedia.org/wiki?curid=37778" title="Tajiks">
Tajiks

Tajik (Persian: تاجيک‎: "Tājīk" , Tajik: Тоҷик) is a general designation for a wide range of Persian-speaking people of Iranian origin, with traditional homelands in present-day Tajikistan, Afghanistan and Uzbekistan. 
As a self-designation, the term "Tajik", which earlier on had been more or less pejorative, has become acceptable only during the last several decades, particularly as a result of Soviet administration in Central Asia. Alternative names for the Tajiks are Fārsī (Persian), Fārsīwān (Persian-speaker), and Dīhgān (cf. Tajik: Деҳқон, "Dehqon", literally "farmer or settled villager", in a wider sense "settled" in contrast to "nomadic" and also described as a class of land-owning magnates during the Sassanid and early Islamic period).
Not all Tajiks speak a variety of modern Persian. They may speak any one of the extant Iranian languages. For example, the Tajiks of China speak Eastern Iranian languages and are distinct from more western Tajiks.
History.
The Tajiks are an Iranian people, speaking a variety of Persian, concentrated in the Oxus Basin, the Farḡāna valley (Tajikistan and parts of Uzbekistan) and on both banks of the upper Oxus, i.e., the Pamir Mountains (Mountain Badaḵšān, in Tajikistan) and northeastern Afghanistan (Badaḵšān).
According to Richard Nelson Frye, a leading historian of Iranian and Central Asian history, the Persian migration to Central Asia may be considered the beginning of the modern Tajik nation, and ethnic Persians, along with some elements of East-Iranian Bactrians and Sogdians, as the main ancestors of modern Tajiks. In later works, Frye expands on the complexity of the historical origins of the Tajiks. In a 1996 publication, Frye explains that many "factors must be taken into account in explaining the evolution of the peoples whose remnants are the Tajiks in Central Asia" and that "the peoples of Central Asia, whether Iranian or Turkic speaking, have one culture, one religion, one set of social values and traditions with only language separating them."
The geographical division between the eastern and western Iranians is often considered historically and currently to be the desert Dasht-e Kavir, situated in the center of the Iranian plateau.
Name.
According to "Encyclopaedia Iranica":
According to the "Encyclopaedia of Islam", however, the oldest known usage of the word "Tajik" as a reference to Persians in Persian literature can be found in the writings of the Persian poet Jalal ad-Din Rumi. The 15th century Turkic-speaking poet Mīr Alī Šer Navā'ī also used "Tajik" as a reference to Persians.
An example for the usage of the word "Tajik" in Persian literature is, for example, the writing of Sa'adi:شایَد کِه بَه پادشاه بگویند<br>ترک تو بریخت خون تاجیک<br><br>"Šāyad ki ba pādšāh bigōyand"<br>"Turk-i tu birēxt xūn-i Tāǰīk"<br><br>"It's appropriate to tell the King,"<br>"Your Turk shed the blood of Tajik"
Location.
The Tajiks are the principal ethnic group in most of Tajikistan, as well as in northern and western Afghanistan, though there are more Tajiks in Afghanistan than in Tajikistan. Tajiks are a substantial minority in Uzbekistan, as well as in overseas communities. Historically, the ancestors of the Tajiks lived in a larger territory in Central Asia than now.
Afghanistan.
According to the World Factbook, Tajiks make up about 27% of the population in Afghanistan, but the Encyclopædia Britannica explains that they constitute about one-fifth of the population. They are predominant in four of the largest cities in Afghanistan (Kabul, Mazar-e Sharif, Herat, and Ghazni) and make up the largest ethnic group in the northern and western provinces of Balkh, Takhar, Badakhshan, Samangan, Parwan, Panjshir, Kapisa, Baghlan, Ghor, Badghis and Herat.
In Afghanistan, the Tajiks do not organize themselves by tribes and refer to themselves by the region, province, city, town, or village that they are from; such as "Badakhshi", "Baghlani", "Mazari", "Panjsheri", "Kabuli", "Herati", "Kohistani" etc. Although in the past, some non-Pashto speaking tribes were identified as Tajik, for example the Furmuli.
Tajikistan.
Tajiks comprise around 79.9% of the population of Tajikistan. This number includes speakers of the Pamiri languages, including Wakhi and Shughni, and the Yaghnobi people who in the past were considered by the government of the Soviet Union nationalities separate from the Tajiks. In the 1926 and 1937 Soviet censuses, the Yaghnobis and Pamiri language speakers were counted as separate nationalities. After 1937, these groups were required to register as Tajiks.
Uzbekistan.
In Uzbekistan, the Tajiks are the largest part of the population of the ancient cities of Bukhara and Samarkand, and are found in large numbers in the Surxondaryo Province in the south and along Uzbekistan's eastern border with Tajikistan. According to official statistics (2000), Surxondaryo Province accounts for 24.4% of all Tajiks in Uzbekistan, with another 34.3% in Samarqand and Bukhara provinces.
Official statistics in Uzbekistan state that the Tajik community comprises 5% of the nation's total population. However, these numbers do not include ethnic Tajiks who, for a variety of reasons, choose to identify themselves as Uzbeks in population census forms. During the Soviet "Uzbekization" supervised by Sharof Rashidov, the head of the Uzbek Communist Party, Tajiks had to choose either stay in Uzbekistan and get registered as Uzbek in their passports or leave the republic for Tajikistan, which is mountainous and less agricultural. It is only in the last population census (1989) that the nationality could be reported not according to the passport, but freely declared on the basis of the respondent's ethnic self-identification. This had the effect of increasing the Tajik population in Uzbekistan from 3.9% in 1979 to 4.7% in 1989. Expert estimates suggest that Tajiks may make up 35% of Uzbekistan's population.
Kazakhstan.
According to the 1999 population census, there were 26,000 Tajiks in Kazakhstan (0.17% of the total population), about the same number as in the 1989 census.
Kyrgyzstan.
According to official statistics, there were about 47,500 Tajiks in Kyrgyzstan in 2007 (0.9% of the total population), up from 42,600 in the 1999 census and 33,500 in the 1989 census.
Turkmenistan.
According to the , there were 3,149 Tajiks in Turkmenistan, or less than 0.1% of the total population of 3.5 million at that time. The first population census of independent Turkmenistan conducted in 1995 showed 3,103 Tajiks in a population of 4.4 million (0.07%), most of them (1,922) concentrated in the eastern provinces of Lebap and Mary adjoining the borders with Afghanistan and Uzbekistan.
Russia.
The population of Tajiks in Russia is about 200,303 according to the 2010 census, up from 38,000 in the last Soviet census of 1989. Most Tajiks came to Russia after the dissolution of the Soviet Union.
Pakistan.
There are an estimated 220,000 Tajiks in Pakistan, mainly refugees from Afghanistan and Tajikistan. Their number was higher in the 1990s, but in the last decade many have left Pakistan and returned to their native countries. Some Tajiks are also living in Hunza, Ishkoman and along the border of Afghanistan and Pakistan called "Broghil".
Physical characteristics.
On the whole, Tajiks are a genetically diverse population, displaying a wide range of phenotypes. Around 10% of Tajiks are said to have blond hair, more prevalent in the Zarafshan and Pamir region, where they are known as Pamiri people. Some ethnic Tajiks, particularly those from Tajikistan, show clear Mongoloid admixture possibly originating from their Kyrgyz and Uzbek neighbors.
Culture.
Language.
The language of the Tajiks is an eastern dialect of Persian, called Dari (derived from "Darbārī", "[of/from the] royal courts", in the sense of "courtly language"), or also Parsi-e Darbari. In Tajikistan, where Cyrillic script is used, it is called the Tajiki language. Historically, it was considered the local dialect of Persian spoken by the Tajik/Persian ethnic group in Central Asia, from where it spread westward only to drive the Arabic language out as the mother tongue of ethnic Persians. In Afghanistan, unlike in Tajikistan, Tajiks continue to use the Perso-Arabic script, as well as in Iran. However, when the Soviet Union introduced the Latin script in 1928, and later the Cyrillic script, the Persian dialect of Tajikistan came to be considered a separate (Persian) language. Since the 19th century, Tajiki has been strongly influenced by the Russian language and has incorporated many Russian language loan words. It has also adopted fewer Arabic loan words than Iranian Persian, while retaining vocabulary that has fallen out of use in the latter language. In Tajikistan, in ordinary speech, also known as “zaboni kucha” (lit. "street language", as opposed to “zaboni adabi”, lit. "literary language", which is used in schools, media etc.), many urban Tajiks prefer to use Russian loanwords instead of their literary Persian analogs.
The dialects of the Persians of Iran and of the Tajiks of central Asia have a common origin. This is underscored by the Tajiks' claim to such famous writers as Rudaki, Ferdowsi, Anwari, Rumi, other famous Persian poets. Russian is widely used in government and business in Tajikistan as well. Since Tajikistan gained independence, there has been a public debate about whether Tajiki should revert to the Perso-Arabic script.
Religion.
Various scholars have recorded the Zoroastrian, Buddhist, and Aryan pre-Islamic heritage of the Tajik people. Early temples for fire worship have been found in Balkh and Bactria and excavations in present day Tajikistan and Uzbekistan show remnants of Zoroastrian fire temples.
Today, however, the great majority of Tajiks follow Sunni Islam, although small Twelver and Ismaili Shia minorities also exist in scattered pockets. Areas with large numbers of Shias include Herat, Bamyan, Badakhshan provinces in Afghanistan, the Gorno-Badakhshan Autonomous Province in Tajikistan, and Tashkurgan Tajik Autonomous County in China. Some of the famous Islamic scholars were from East-Iranian regions lying in Afghanistan and Tajikistan today and therefore can arguably be viewed as Tajiks. They include Abu Hanifa, Imam Bukhari, Tirmidhi, Abu Dawood, Abu Mansur Maturidi, and many others. Since the Tajiks generally follow Islamic belief patterns. Belief in the supernatural, outside of formal Islam, falls into several categories: curative customs, fortune-telling, and ascription of bad fortune to the power of fate or of evil beings called jinn.
According to a 2009 U.S. State Department release, the population of Tajikistan is 98% Muslim, (approximately 85% Sunni and 5% Shia). In Afghanistan, the great number of Tajiks adhere to Sunni Islam. The smaller number of Tajiks who may follow Twelver Shia Islam are locally called Farsiwan. The community of Bukharian Jews in Central Asia speak a dialect of Persian. The Bukharian Jewish community in Uzbekistan is the largest remaining community of Central Asian Jews and resides primarily in Bukhara and Samarkand, while the Bukharaian Jews of Tajikistan live in Dushanbe and number only a few hundred. From the 1970s to the 1990s the majority of these Tajik-speaking Jews emigrated to the United States and to Israel in accordance with Aliyah.
Tajikistan marked 2009 as the year to commemorate the Tajik Sunni Muslim jurist Abu Hanifa, whose ancestry hailed from Parwan Province of Afghanistan, as the nation hosted an international symposium that drew scientific and religious leaders. The construction of one of the largest mosques in the world, funded by Qatar, was announced in October 2009. The mosque is planned to be built in Dushanbe and construction is said to be completed by 2014.
Recent developments.
Cultural revival.
The collapse of the Soviet Union and the civil war in Afghanistan both gave rise to a resurgence in Tajik nationalism across the region. Tajikistan in particular has been a focal point for this movement, and the government there has made a conscious effort to revive the legacy of the Samanid empire, the first Tajik-dominated state in the region after the Arab advance. For instance, the President of Tajikistan, Emomalii Rahmon, dropped the Russian suffix "-ov" from his surname and directed others to adopt Tajik names when registering births. According to a government announcement in October 2009, approximately 4,000 Tajik nationals have dropped "ov" and "ev" from their surnames since the start of the year.
In an interview to Iranian news media in May 2008, Tajikistan's deputy culture minister said that Tajikistan would study the issue of switching its Tajik alphabet from Cyrillic to the Persian script used in Iran and Afghanistan when the government feels that "the Tajik people became familiar with the Persian alphabet". More recently, the Islamic Renaissance Party of Tajikistan seeks to have the nation's language referred to as "Tajiki-Farsi" rather than "Tajik." The proposal has drawn criticism from Russian media since the bill seeks to remove the Russian language as the mode of interethnic communication. In 1989, the original name of the language (Farsi) was added to its official name in brackets. However, Rahmon's government renamed the language to simply 'Tajiki' in 1994. According to an Islamic Renaissance Party official, the Tajiks had referred to their language as "Farsi" before Sovietization. On October 2009, Tajikistan adopted the law that removes Russian as the "language for interethnic communication."

</doc>
<doc id="37779" url="http://en.wikipedia.org/wiki?curid=37779" title="Luge">
Luge

A luge is a small one- or two-person sled on which one sleds supine (face up) and feet-first. Steering is done by flexing the sled's runners with the calf of each leg or exerting opposite shoulder pressure to the seat. Racing sleds weigh 21–25 kilograms (46–55 lb) for singles and 25–30 kilograms (55–66 lb) for doubles. Luge is also the name of an Olympic sport. Lugers can reach speeds of 140 km per hour (87 mph). Manuel Pfister of Austria, reached a top speed of 154 km per hour (95.69 mph) on the track in Whistler, Canada prior to the 2010 Vancouver Winter Olympics.
Lugers compete against a timer and on artificial tracks are timed to a thousandth of a second, making luge one of the most precisely timed sports in the world. The first recorded use of the term "luge" is 1905, from the Savoy/Swiss dialect of French "luge" meaning "small coasting sled", and is possibly from a Gaulish word with the same root as English sled.
History.
The practical use of sleds is ancient and widespread. The first recorded sled races took place in Norway sometime during the 15th century. The sport of luge, like the skeleton and the bobsleigh, originated in the health-spa town of St Moritz, Switzerland, in the mid-to-late 19th century, through the endeavours of hotel entrepreneur Caspar Badrutt. Badrutt successfully sold the idea of winter resorting, as well as rooms with food, drink, and activities. His more adventurous English guests began adapting delivery boys' sleds for recreation, which led to collisions with pedestrians as they sped down the lanes and alleys of the village.
The first organized meeting of the sport took place in 1883 in Switzerland. 
In 1913, the Internationale Schlittensportverband or International Sled Sports Federation was founded in Dresden, Germany. This body governed the sport until 1935, when it was incorporated in the Fédération Internationale de Bobsleigh et de Tobogganing (FIBT, International Bobsleigh and Tobogganing Federation). After it had been decided that luge would replace the sport of skeleton at the Olympic Games, the first World Championships in the sport were held in 1955 in Oslo (Norway). In 1957, the Fédération Internationale de Luge de Course (FIL, International Luge Federation) was founded. Luge events were first included in the Olympic Winter Games in 1964.
Americans were slow to adopt the sport of luge. The first luge run in North America was built at Lolo Hot Springs, Montana in 1965. Although the United States competed in every Olympic luge event from 1964 through 1976, it was not until 1979 that the United States Luge Association was founded. The first artificial American track was completed in that year for use in the 1980 XIII Winter Olympic Games at Lake Placid, New York.
Since that time the United States luge program has greatly improved. A second artificial track was constructed near Park City, Utah for the 2002 XIX Olympic Winter Games at Salt Lake City.
Artificial tracks.
Artificial luge tracks have specially-designed and -constructed banked curves plus walled-in straights. Most tracks are artificially refrigerated, but artificial tracks without artificial cooling also exist (for example, in St. Moritz). Tracks tend to be very smooth.
The athletes ride in a flat, aerodynamic position on the sled, keeping their heads low to minimize air resistance. They steer the sled mainly with their calves by applying pressure on the runners—right calf to turn left, left calf to turn right. It takes a precise mix of shifting body weight, applying pressure with calves and rolling the shoulders. There are also handles for minor adjustments. A successful luger maintains complete concentration and relaxation on the sled while traveling at high speeds. Most lugers "visualize" the course in their minds before sliding. Fastest times result from following the perfect "line" down the track. Any slight error, such as a brush of the wall, costs time. Track conditions are also important. Softer ice tends to slow speeds, while harder ice tends to lead to faster times. Lugers race at speeds averaging 120–145 km/h (75–90 mph) around high banked curves while experiencing a centripetal acceleration of up to 5g. Men's Singles have their start locations near where the bobsled and skeleton competitors start at most tracks, while both the Doubles and Women's Singles competition have their starthouse located further down the track. Artificial track luge is the fastest and most agile sledding sport.
Natural track luge.
Natural tracks are adapted from existing mountain roads and paths. Artificially banked curves are not permitted. The track's surface should be horizontal. They are naturally iced. Tracks can get rough from the braking and steering action. Athletes use a steering rein and drag their hands and use their legs in order to drive around the tight flat corners. Braking is often required in front of curves and is accomplished by the use of spikes built on the bottom of the shoes.
Most of the tracks are situated in Austria and Italy, with others in Germany, Poland, Russia, Slovenia, Canada, and the United States. The Upper Peninsula Luge Club in Negaunee, Michigan, is home to one of only five lighted natural track luge runs in the world, and the only natural track in the United States. The over 800 meter (half-mile) track features 29 curves along its 88 m vertical drop. The club hosts international luge events and offers luge instruction to the public during the winter months.
World championships have been held since 1979 while European championships have been held since 1970.
Events.
There are four luge disciplines. 
These are further broken into several age classes - multiple youth and junior classes that cover the range of age 7–20, and general class (ages 21 and older). Older competitors may enjoy the sport in masters (age 30–50), and senior masters (age 51+) classes. 
In a team relay competition one man, one woman and a doubles pair form a team. A touchpad at the bottom of the run is touched by a competitor signaling a teammate at the top of the run to start.
Rules and procedures for races are very precise:
Training.
The sport of luge requires an athlete to balance mental and physical fitness. To become an elite luger, a competitor must begin training at an early age and spend decades honing their skills. Physically, a luger must have strong neck, upper body, abdominal, and thigh muscles. Strength training is essential to withstand the extreme G-forces of tight turns at high speeds. Since lugers have very little protection other than a visor and helmet, they must be able to endure the physical pounding administered by the track when mistakes are made. Mentally a luger must maintain total focus as they steer their sled through more than a kilometer of curves and straights at high speed. Dozens of subtle movements and weight shifts are required to find the perfect line down the track. Consistency is essential for success. Sled maintenance is also an important element for success. Serious lugers spend hours meticulously sanding their "steels," and making other important adjustments and repairs to their sleds. No luger can possibly achieve elite status without working closely with an experienced coaching staff, implementing suggestions and fine tuning technique. Other lugers will often give tips that can improve a slider's ability to find the "sweet spot" on the track. Though luge is a winter sport, it requires daily, year-round training.
Risks.
As with many extreme sports, luging has risks. Though most injuries involve bumps, bruises, broken bones and concussions, fatalities do occasionally occur. Georgian luger Nodar Kumaritashvili suffered a fatal crash during his final practice run for the 2010 Winter Olympics in Whistler, British Columbia, Canada. Hours later, the International Luge Federation concluded that the accident was caused by a steering error and not a track error; nevertheless, changes to the track were made before the re-opening. Kumaritashvili was the fourth athlete to die while in preparation for a Winter Olympics competition, following speed skier Nicolas Bochatay, 27, who died while preparing for the Albertville 1992 games, British luger Kazimierz Kay-Skrzypeski and skier Ross Milne, 19, who both died in the run-up to the Innsbruck 1964 games.
Governing body.
The sport of luge is governed by the FIL, Fédération International de Luge de Course. The FIL is located in Berchtesgaden, Germany and includes 53 member nations. It is traditionally dominated by German representatives, however.
The following persons have been president of the FIL:
Olympic Medal table.
Men's singles.
Current Olympic champion: 01 !   (GER) 02 !   (RUS) 03 !   (ITA)
Doubles.
Current Olympic champion: 01 !   (GER) 02 !   (AUT) 03 !   (LAT)
Women's singles.
Current Olympic champion: 01 !   (GER) 02 !   (GER) 03 !   (USA)
Team relay.
Current Olympic champion: 01 !   (GER) 02 !   (RUS) 03 !   (LAT)

</doc>
<doc id="37780" url="http://en.wikipedia.org/wiki?curid=37780" title="Anglo-Saxons">
Anglo-Saxons

The Anglo-Saxons were a people who inhabited Great Britain from the 5th century. They included people from Germanic tribes who migrated to the island from continental Europe, and their descendants; as well as indigenous British groups who adopted some aspects of Anglo-Saxon culture and language. The Anglo-Saxon period denotes the period of British history between about 450 and 1066, after their initial settlement, and up until the Norman conquest.
The Anglo-Saxon period includes the creation of an English nation, with many of the aspects that survive today including regional government of shires and hundreds; the re-establishment of Christianity; a flowering in literature and language; and the establishment of charters and law. The term "Anglo-Saxon" is also popularly used for the language, in scholarly use more usually called Old English, that was spoken and written by the Anglo-Saxons in England and eastern Scotland between at least the mid-5th century and the mid-12th century.
The history of the Anglo-Saxons is the history of a cultural identity, and how this developed from divergent groups, grew with the adoption of Christianity, was used in the establishment of various kingdoms, and, in the face of a threat from Danish settlers, re-established itself as one identity until after the Norman Conquest. The outward appearance of Anglo-Saxon culture can be seen in the material culture of buildings, dress styles, illuminated texts and grave goods. Behind the symbolic nature of these cultural emblems there are strong elements of tribal and lordship ties, and an elite that became kings who developed "burhs", and saw themselves and their people in Biblical terms. Above all, as Helena Hamerow has observed, "local and extended kin groups remained...the essential unit of production throughout the Anglo-Saxon period". The effects persist even in the 21st century as according to a study published in March 2015, the genetic make up of British populations today shows traces of the political units in the early Anglo-Saxon period.
Use of the term "Anglo-Saxon" assumes that the words "Angles", "Saxons" or "Anglo-Saxon" have the same meaning in all the sources. Assigning ethnic labels such as "Anglo-Saxon" is fraught with difficulties, and the term itself only began to be used in the 8th century to distinguish "Germanic" groups in Britain from those on the continent. Catherine Hills summarised the views of many modern scholars that attitudes towards Anglo-Saxon and hence the interpretation of their culture and history has been "more contingent on contemporary political and religious theology as on any kind of evidence."
Ethnonym.
The Old English ethnonym "Angul-Seaxan" comes from the Latin, "Angli-Saxones" and became the name of the peoples Bede calls Anglorum and Gildas calls Saxones. Anglo-Saxon is a term that was rarely used by Anglo-Saxons themselves; it is not an endonym. Alternatives names would have been "ængli", "Seaxe", or more probably a local or tribal name such as "Mierce", "Cantie", "Gewisse", "Westseaxe", or "Norþanhymbre". Also, the use of Anglo-Saxon disguises the extent to which people thought of themselves as Anglo-Scandinavian after the Viking age or the conquest of 1016, or Anglo-Norman after the Norman conquest.
The earliest historical references from outside Britain refer to piratical Germanic raiders, 'Saxones' who attacked the shore of Britain and Gaul in the 3rd century AD. Procopius states that Britain was settled by three races: the Angiloi, Frisones, and Britons. The term "Angli Saxones" seems to have first been used in continental writing of the 8th century; Paul the Deacon, uses it to distinguish the English Saxons from the continental Saxons ("Ealdseaxe", literally, 'old Saxons'). The name therefore seemed to mean "English" Saxons.
The Christian church seems to have used the word Angli; for example in the story of Pope Gregory I and his remark, "Non Angli sed angeli" (not English but angels). the terms "ænglisc" ('the language') and "Angelcynn" ('the people') were also used by West Saxon King Alfred to refer to the people and in doing so he was following established practice. The first use of the Anglo-Saxon amongst the insular sources are in the titles for Athelstan: "Angelsaxonum Denorumque gloriosissimus rex" (most glorious king of the Anglo-Saxons and of the Danes) and "rex Angulsexna and Norþhymbra imperator paganorum gubernator Brittanorumque propugnator" (king of the Anglo-Saxons and emperor of the Northumbrians, governor of the pagans, and defender of the Britons). Interesting at other times he uses the term "rex Anglorum" (king of the English), which presumably meant both Anglo-Saxons and Danes. The term "Engla cyningc" (King of the English) is used by Æthelred and it is only with King Cnut in 1021 that land not the people are referred to; "ealles Englalandes cyningc" (King of all England). These titles provide a sense that the Anglo-Saxons were a Christian people with a king anointed by God.
The indigenous Common Brittonic speakers, referred to Anglo-Saxons as "Saxones" or possibly "Saeson" (the word "Saeson" is the modern Welsh word for 'English people'); the equivalent word in Scottish Gaelic is "Sasannach" and in the Irish language, "Sasanach". Catherine Hills suggests that it is no accident, "that the English call themselves by the name sanctified by the Church, as that of a people chosen by God, whereas their enemies use the name originally applied to piratical raiders".
Early Anglo-Saxon history (410-660).
The early Anglo-Saxon period covers the history of medieval Britain that starts from the end of Roman rule. It is a period widely known in European history as the Migration Period, also the "Völkerwanderung" ("migration of peoples" in German), and was a period of intensified human migration in Europe from about 400 to 800. The migrants were Germanic tribes such as the Goths, Vandals, Angles, Saxons, Lombards, Suebi, Frisii and Franks; they were later pushed westwards by the Huns, Avars, Slavs, Bulgars and Alans.
By the year 400, southern Britain – that is Britain below Hadrian's Wall – was a peripheral part of the Roman Empire in the west, occasionally lost to rebellion or invasion, but until then always eventually recovered. Eventually around 410, Britain slipped beyond direct imperial control into a phase which has generally been termed "sub-Roman".
Migration (c.410-c.560).
The traditional narrative of this period is one of decline and fall, invasion and migration, however Heinke Härke states: 
"It is now widely accepted that the Anglo-Saxons were not just transplanted Germanic invaders and settlers from the Continent, but the outcome of insular interactions and changes.
Writing c.540 Gildas mentions that, sometime in the 5th century, a council of leaders in Britain agreed that some land in the east of southern Britain would be given to the Saxons on the basis of a treaty, a "foedus", by which the Saxons would defend the Britons against attacks from the Picts and Scoti in exchange for food supplies. The most contemporaneous textual evidence is the Chronica Gallica of 452 which records for the year 441: "The British provinces, which to this time had suffered various defeats and misfortunes, are reduced to Saxon rule." This is an earlier date for the than the date of 451 for the "coming of the Saxons" used by Bede in his "Historia ecclesiastica gentis Anglorum", written around 731.
Gildas recounts how a war broke out between the Saxons and the local population - Higham calls it the "War of the Saxon Federates" - which ended shortly after the siege at 'Mons Badonicus'. The Saxons go back to "their eastern home". Gildas calls the peace a "grievous divorce with the barbarians". The price of peace, Nick Higham argues, is a better treaty for the Saxons, giving them the ability to receive tribute from people across the lowlands of Britain. The archaeological evidence agrees with this earlier timescale. In particular, the work of Catherine Hills and Sam Lucy on the evidence of Spong Hill has moved the chronology for the settlement earlier than 450, with a significant number of items now in phases before Bede's date.
This vision of the Anglo-Saxons exercising extensive political and military power at an early date remains contested. The most developed vision of a continuation in sub-Roman Britain, with control over its own political and military destiny for well over a century, is that of Kenneth Dark, who suggests that the sub-Roman elite survived in culture, politics and military power up to c. 570. However Nick Higham seems to agree with Bede who identified three phases of settlement: an exploration phase, when mercenaries came to protect the resident population; a migration phase, which was substantial as implied by the statement that "Anglus" was deserted; and an establishment phase, in which Anglo-Saxons started to control areas, implied in Bede's statement about the origins of the tribes.
There remains variant views over how many migrants came to Britain in this period. Heinke Härke suggest that the figure is around 100,000," based on the molecular evidence, whereas archaeologists such as Christine Hills and Richard Hodges suggest the number is nearer 20,000. By around 500 the Anglo-Saxon migrants were established in southern and eastern Britain. What happened to the indigenous Brittonic people is also subject to question. Heinrich Harke and Richard Coates point out that they are invisible archaeologically and linguistically. However taking a fairly high Anglo-Saxon figure (200,000) and a low Brythonic one (800,000), Brythonic people are likely to have outnumbered Anglo-Saxons by at least four to one. The interpretation of such figures is that while "culturally, the later Anglo-Saxons and English did emerge as remarkably un-British, . . . their genetic, biological make-up is none the less likely to have been substantially, indeed predominantly, British". The process of Anglo-Saxonisation is described by two processes. One is similar to culture changes observed in Russia, North Africa and parts of the Islamic world; where a powerful minority culture becomes, over a rather short period, adopted by a settled majority. The second process is explained through incentives, Nick Higham has provided this summary:
"As Bede later implied, language was a key indicator of ethnicity in early England. In circumstances where freedom at law, acceptance with the kindred, access to patronage, and the use and possession of weapons were all exclusive to those who could claim Germanic descent, then speaking Old English without Latin or Brittonic inflection had considerable value."
By the middle of the 6th century some Brythonic people in the lowlands of Britain had moved across the sea to form Brittany, some had moved west, but the majority were abandoning their past language and culture and adopting the new culture of the Anglo-Saxons. As they adopted language and culture so the barriers that existed between peoples, who had lived parallel lives, started to break down. The archaeological evidence shows a lot of continuity in the system of landscape and local governance, which was inherited from the indigenous community, and there is evidence for a fusion of culture in this early period., 
One of the elements is the Brythonic names that appear in the lists of Anglo-Saxon elite. The Wessex royal line was traditionally founded by a man named Cerdic, an undoubtedly Celtic name ultimately derived from Caratacus. This may indicate that Cerdic was a native Briton, and that his dynasty became anglicised over time. A number of Cerdic's alleged descendants also possessed Celtic names, including the 'Bretwalda' Ceawlin. The last occurrence of a British name in this dynasty being that of King Caedwalla, who died as late as 689.
Development of an Anglo-Saxon society (560–610).
In the last half of the 6th century four structures were having a bearing on the development of society, they were: the position and freedoms of the "ceorl", the smaller tribal areas coalescing into larger kingdoms, the elite developing from warriors to kings, and Irish monasticism developing under Finnian (who had consulted Gildas) and his pupil Columba.
The Anglo-Saxons farms of this period are often falsely supposed to be "peasant farms". However, a "ceorl", who was the lowest ranking freeman in early Anglo-Saxon society, was not a peasant but an arms-owning male with the support of a kindred, access to law and the "wergild"; situated at the apex of an extended household working at least one hide of land. The farmer had freedom and rights over lands, with provision of a rent or duty to an overlord who provided only slight lordly input. Most of this land was common outfield arable land (of an outfield-infield system) that provided the ability to build kinship and group cultural ties.
The Tribal Hidage lists thirty-five peoples, or tribes, with assessments in hides, which may have originally been defined as the area of land sufficient to maintain one family. The assessments in the "Hidage" reflect the relative size of the provinces. Although varying in size, all thirty-five peoples of the Tribal Hidage were of the same status, in that they were areas which were ruled by their own elite family (or royal houses), and so were assessed independently for payment of tribute. By the end of the sixth century larger kingdoms were based on the south or east coasts. They include the provinces of the Jutes of Hampshire and Wight, the South Saxons, Kent, the East Saxons, East Angles, Lindsey and (north of the Humber) Deira and Bernicia. Several of these kingdoms may have had as their initial focus a territory based on a former Roman "civitas".
By the end of the sixth century the leaders of these communities were styling themselves kings, though it should not be assumed that all of them were Germanic in origin. The Bretwalda concept is taken as evidence for a presence of a number of early Anglo-Saxon elite families. What Bede seems to imply in his "Bretwalda" is the ability to extract tribute, overawe and/or protect the small regions, which may well have been relatively short-lived in any one instance. Ostensibly "Anglo-Saxon" dynasties variously replaced one another in this role in a discontinuous but influential and potent roll call of warrior elites. Importantly, whatever their origin or whenever they flourished, they established their claim to lordship through their links to extended kin ties. As Helen Peake jokingly points out "they all just happened to be related back to Woden".
The process from warrior to "cyning" - Old English for king - is described in Beowulf:
Conversion to Christianity (590-660).
In 565, Columba, an monk from Ireland, who studied at the monastic school of Moville under St. Finnian, arrived in Iona as a self-imposed exile. The influence of the monastery of Iona would grow into what Peter Brown has called an "unusually extensive spiritual empire" which "stretched from western Scotland deep to the southwest into the heart of Ireland and, to the southeast, it reached down throughout northern Britain, through the influence of its sister monastery Lindisfarne."
In June 597 Columba died, as a quirk of history at the same time Augustine landed on the Isle of Thanet and proceeded to King Æthelberht's main town of Canterbury. He had been the prior of a monastery in Rome when Pope Gregory the Great chose him in 595 to lead the Gregorian mission, to Britain to Christianise the Kingdom of Kent from their native Anglo-Saxon paganism. Kent was probably chosen because Æthelberht had married a Christian princess, Bertha, daughter of Charibert I the King of Paris, who was expected to exert some influence over her husband. Æthelberht was converted to Christianity, churches were established, and wider-scale conversion to Christianity began in the kingdom. Æthelberht's law for Kent, the earliest written code in any Germanic language, instituted a complex system of fines. Kent was rich, with strong trade ties to the continent, and Æthelberht may have instituted royal control over trade. For the first time following the Anglo-Saxon invasion, coins began circulating in Kent during his reign.
In 635 Aidan, an Irish monk from Iona chose the Isle of Lindisfarne to establish a monastery and close to King Oswald's main fortress of Bamburgh. He had been at the monastery in Iona when Oswald asked to be sent a mission to Christianise the Kingdom of Northumbria from their native Anglo-Saxon paganism. Oswald had probably chosen Iona because after his father had been killed he had fled into south-west Scotland and had encountered Christianity, and had returned determined to make Northumbria Christian. Aidan achieved great success in spreading the Christian faith, and since Aidan could not speak English and Oswald had learned Irish during his exile, Oswald acted as Aidan's interpreter when the latter was preaching. Later, Northumberland's patron saint, Saint Cuthbert, was an abbot of the monastery, and then Bishop of Lindisfarne. An anonymous life of Cuthbert written at Lindisfarne is the oldest extant piece of English historical writing. and in his memory a gospel (known as the St Cuthbert Gospel) was placed in his coffin. The decorated leather bookbinding is the oldest intact European binding.
In 664, the Synod of Whitby was convened and established Roman practice (in style of tonsure and dates of Easter) as the norm in Northumbria, and thus "brought the Northumbrian church into the mainstream of Roman culture." The episcopal seat of Northumbria was transferred from Lindisfarne to York. Wilfrid, chief advocate for the Roman position, later became Bishop of Northumbria, while Colmán and the Ionan supporters, who did not change their practices, withdrew to Iona.
Middle Anglo-Saxon history (660-899).
By 660 the political map of Lowland Britain had developed with smaller territories coalescing into kingdoms, from this time larger kingdoms started dominating the smaller kingdoms. The development of kingdoms, with a particular king being recognised as an overlord, developed out of an early loose structure that, Higham believes, is linked back to the original "feodus". The traditional name for this period is the Heptarchy, which has not been used by scholars since the early 20th century as it gives the impression of a single political structure and does not afford the "opportunity to treat the history of any one kingdom as a whole". Simon Keynes suggests that the 8th and 9th century was period of economic and social flourishing which created stability both below the Thames and above the Humber. Many areas flourished and their influence was felt across the continent, however in between the Humber and Thames, one political entity grew in influence and power and to the East these developments in Britain attracted attention.
Mercian supremacy (626-821).
Middle-lowland Britain was known as the place of the "Mierce", the border or frontier folk, in Latin Mercia. Mercia was a diverse area of tribal groups, as shown by the Tribal Hidage; the peoples were a mixture of Brythonic speaking peoples and "Anglo-Saxon" pioneers and their early leaders had Brythonic names, such as Penda. Although Penda does not appear in Bede's list of great overlords it would appear from what Bede says elsewhere that he was dominant over the southern kingdoms. At the time of the battle of the river Winwæd, thirty "duces regii" (royal generals) fought on his behalf. Although there are many gaps in the evidence, it is clear that the seventh-century Mercian kings were formidable rulers who were able to exercise a wide-ranging overlordship from their Midland base.
Mercian military success was the basis of their power; it succeeded not only 106 kings and kingdoms by winning set-piece battles, but by ruthlessly ravaging any area foolish enough to withhold tribute. There are a number of casual references scattered throughout the Bede's history to this aspect of Mercian military policy. Penda is found ravaging Northumbria as far north as Bamburgh and only a miraculous intervention from Aidan prevents the complete destruction of the settlement. In 676 Æthelred conducted a similar ravaging in Kent and caused such damage in the Rochester diocese that two successive bishops gave up their position because of lack of funds. In these accounts there is a rare glimpse of the realities of early Anglo-Saxon overlordship and how a widespread overlordship could be established in a relatively short period. By the middle of the 8th century, other kingdoms of southern Britain were also affected by Mercian expansionism. The East Saxons seem to have lost control of London, Middlesex and Hertfordshire to Æthelbald, although the East Saxon homelands do not seem to have been affected, and the East Saxon dynasty continued into the ninth century. The Mercian influence and reputation reached its peak when, in the late 8th century, the most powerful European ruler of the age, the Frankish king Charlemagne, recognised the Mercian King Offa's power and accordingly treated him with respect, even if this could have been just flattery.
Learning and monasticism (660-793).
Michael Drout calls this period the "Golden Age", when learning flourishes with a renaissance in classical knowledge. The growth and popularity of monasticism was not an entirely internal development, with influence from the continent shaping Anglo-Saxon monastic life. In 669 Theodore, a Greek-speaking monk originally from Tarsus in Asia Minor, arrived in Britain to become the eighth Archbishop of Canterbury. He was joined the following year by his colleague Hadrian, a Latin-speaking African by origin and former abbot of a monastery in Campania (near Naples). One of their first tasks at Canterbury was the establishment of a school; and according to Bede (writing some sixty years later), they soon "attracted a crowd of students into whose minds they daily poured the streams of wholesome learning". As evidence of their teaching, Bede reports that some of their students, who survived to his own day were as fluent in Greek and Latin as in their native language. Bede does not mention Aldhelm in this connection; but we know from a letter addressed by Aldhelm to Hadrian that he too must be numbered among their students.
Aldhelm wrote in elaborate and grandiloquent and very difficult Latin, which became the dominant style for centuries. Michael Drout states "Aldhelm wrote Latin hexameters better than anyone before in England (and possibly better than anyone since, or at least up until Milton). His work showed that scholars in England, at the very edge of Europe, could be as learned and sophisticated as any writers in Europe." During this period, the wealth and power of the monasteries increased in wealth as elite families, possibly without power, turned to monastic life.
Anglo-Saxon monasticism developed the unusual institution of the "double monastery", a house of monks and a house of nuns, living next to each other, sharing a church but never mixing, and living separate lives of celibacy. These double monasteries were presided over by abbesses, some of the most powerful and influential women in Europe. Double monasteries which were built on strategic sites near rivers and coasts, accumulated immense wealth and power over multiple generations (their inheritances were not divided) and became centers of art and learning.
While Aldhelm was doing his work in Malmesbury, far from him, up in the North of England, Bede was writing a large quantity of books, gaining a reputation in Europe and showing that the English could write history and theology, and do astronomical computation (for the dates of Easter, among other things).
West Saxon hegemony and the Anglo-Scandinavian Wars (793-878).
The 9th century saw the rise of Wessex, from the foundations laid by King Egbert in the first quarter of the century to the achievements of King Alfred the Great in its closing decades. The outlines of the story are told in the "Anglo-Saxon Chronicle", though the annals represent a West Saxon point of view. On the day of Egbert's succession to the kingdom of Wessex, in 802, a Mercian ealdorman from the province of the "Hwicce" had crossed the border at Kempsford, with the intention of mounting a raid into northern Wiltshire; the Mercian force was met by the local ealdorman, "and the people of Wiltshire had the victory". In 829 Egbert went on, the chronicler reports, to conquer "the kingdom of the Mercians and everything south of the Humber". It was at this point that the chronicler chose to attach Egbert's name to Bede's list of seven overlords, adding that "he was the eighth king who was Bretwalda". Simon Keynes suggests Egbert's foundation of a 'bipartite' kingdom is crucial as it stretched across southern England, and the created a working alliance between the West Saxon dynasty and the rulers of the Mercians. In 860 the eastern and western parts of the southern kingdom were united by agreement between the surviving sons of King Æthelwulf, though the union was not maintained without some opposition from within the dynasty; and in the late 870s King Alfred gained the submission of the Mercians under their ruler Æthelred, who in other circumstances might have been styled a king, but who under the Alfredian regime was regarded as the 'ealdorman' of his people.
The wealth of the monasteries and the success of Anglo-Saxon society attracted the attention of people from continental Europe, mostly Danes and Norwegians. Due to the plundering raids that followed, the raiders attracted the name Viking - from the Old Norse "víkingr" meaning an expedition - which soon became used for the raiding activity or piracy reported in western Europe. In 793, Lindisfarne was raided and while this was not the first raid of its type it was the most prominent. A year later Jarrow, the monastery where Bede wrote, was attacked; in 795 Iona; and in 804 the nunnery at Lyminge Kent was granted refuge inside the walls of Canterbury. Sometime around 800, a Reeve from Portland in Wessex was killed when he mistook some raiders for ordinary traders.
Viking raids continued until in 850, then the Chronicle says: "The heathen for the first time remained over the winter". The fleet does not appear to have stayed long in England, but it started a trend which others subsequently followed. In particular, the army which arrived in 865 remained over many winters, and part of it later settled what became known as the Danelaw. This was the "Great Army", a term used by the Chronicle in England and by Adrevald of Fleury on the Continent. The invaders were able not only to exploit the feuds between and within the various kingdoms, but to appoint puppet kings, Ceolwulf in Mercia in 873, 'a foolish king's thane' (ASC), and perhaps others in Northumbria in 867 and East Anglia in 870. The third phase was an era of settlement, however the 'Great Army' went wherever it could find the richest pickings, crossing the Channel when faced with resolute opposition, as in England in 878, or with famine, as on the Continent in 892. By this stage the Vikings were assuming ever increasing importance as catalysts of social and political change. They constituted the common enemy, making the English the more conscious of a national identity which overrode deeper distinctions; they could be perceived as an instrument of divine punishment for the people's sins, raising awareness of a collective Christian identity; and by 'conquering' the kingdoms of the East Angles, the Northumbrians and the Mercians they created a vacuum in the leadership of the English people.
Danish settlement continued, settling in Mercia in 877, and East Anglia in 879—80 and 896. The rest of the army meanwhile continued to harry and plunder on both sides of the Channel, with new recruits evidently arriving to swell its ranks, for it clearly continued to be a formidable fighting force. At first, Alfred responded by the offer of repeated tribute payments. However, after a decisive victory at Edington in 878, Alfred offered vigorous opposition. He established a chain of fortresses across the south of England, reorganised the army, "so that always half its men were at home, and half out on service, except for those men who were to garrison the burhs" (A.SC s.a. 893), and in 896 ordered a new type of craft to be built which could oppose the Viking longships in shallow coastal waters. When the Vikings returned from the Continent in 892, they found they could no longer roam the country at will, for wherever they went they were opposed by a local army. After four years, the Scandinavians therefore split up, some to settle in Northumbria and East Anglia, the remainder to try their luck again on the Continent.
King Alfred and the rebuilding (878-899).
More important to Alfred than his military and political victories were, his religion, his love of learning, and his spread of writing throughout England. Simon Keynes suggests Alfred's work laid the foundations for what really makes England unique in all of medieval Europe from around 800 until 1066. What is also unique is that we can discover some of this in Alfred's own words:
Thinking about how learning and culture had fallen since the last century he wrote:
"...So completely had wisdom fallen off in England that there were very few on this side of the Humber who could understand their rituals in English, or indeed could translate a letter from Latin into English; and I believe that there were not many beyond the Humber. There were so few of them that I indeed cannot think of a single one south of the Thames when I became king."(Preface: "Gregory the Great's Pastoral Care")
Alfred knew that literature and learning, both in English and in Latin, were very important, but the state of learning was not good when Alfred came to the throne. Alfred saw kingship as a priestly office, a shepherd for his people. One book that was particularly valuable to him was Gregory the Great's "Cura Pastoralis"(Pastoral Care). This is a priest's guide on how to care for people. Alfred took this book as his own guide on how to be a good king to his people; hence, a good king to Alfred increases literacy. Alfred translated this book himself and explains in the preface:
"...When I had learned it I translated it into English, just as I had understood it, and as I could most meaningfully render it. And I will send one to each bishopric in my kingdom, and in each will be an æstel worth fifty mancuses. And I command in God's name that no man may take the æstel from the book nor the book from the church. It is unknown how long there may be such learned bishops as, thanks to God, are nearly everywhere."(Preface: "Gregory the Great's Pastoral Care")
What is presumed to be one of these "æstel" (the word only appears in this one text) is the gold, rock crystal and enamel Alfred Jewel, discovered in 1693, which is assumed to have been fitted with a small rod and used as a pointer when reading. Alfred provided functional patronage, linked to a social programme of vernacular literacy in England, which was unprecedented.
"Therefore it seems better to me, if it seems so to you, that we also translate certain books ...and bring it about ...if we have the peace, that all the youth of free men who now are in England, those who have the means that they may apply themselves to it, be set to learning, while they may not be set to any other use, until the time when they can well read English writings."(Preface: "Gregory the Great's Pastoral Care")
This set in train a growth in charters, law, theology and learning. Alfred thus laid the foundation for the great accomplishments of the tenth century and did much to make the vernacular was more important than Latin in Anglo-Saxon culture.
"I desired to live worthily as long as I lived, and to leave after my life, to the men who should come after me, the memory of me in good works."(Preface: "The Consolation of Philosophy by Boethius")
Late Anglo-Saxon history (899-1066).
A framework for the momentous events of the 10th and 11th centuries are provided by the "Anglo-Saxon Chronicle". However charters, law-codes and coins supply detailed information on various aspects of royal government, and the surviving works of Anglo-Latin and vernacular literature, as well as the numerous manuscripts written in the 10th century, testify in their different ways to the vitality of ecclesiastical culture. Yet as Simon Keynes suggests "it does not follow that the 10th century is better understood than more sparsely documented periods".
Reform and formation of England (899-978).
During the course of the 10th century, the West Saxon kings extended their power first over Mercia, then into the southern Danelaw, and finally over Northumbria, thereby imposing a semblance of political unity on peoples, who nonetheless would remain conscious of their respective customs and their separate pasts. The prestige, and indeed the pretensions, of the monarchy increased, the institutions of government strengthened, and kings and their agents sought in various ways to establish social order. This process started with Edward the Elder - who with his sister, Æthelflæd, Lady of the Mercians, initially, charters reveal, encouraged people to purchase estates from the Danes, thereby to reassert some degree of English influence in territory which had fallen under Danish control. David Dumville suggests that Edward may have extended this policy by rewarding his supporters with grants of land in the territories newly conquered from the Danes, and that any charters issued in respect of such grants have not survive. When Athelflæd died, Mercia was absorbed by Wessex. From that point on there was no contest for the throne, so the house of Wessex became the ruling house of England.
Edward the Elder was succeeded by his son Æthelstan, who Simon Keynes calls the "towering figure in the landscape of the tenth century". His victory over a coalition of his enemies - Constantine, King of the Scots, Eógan of Strathclyde, and Olaf Guthfrithson, King of Dublin - at the battle of Brunanburh, celebrated by a famous poem in the Anglo-Saxon Chronicle, opened the way for him to be hailed as the first king of England. Æthelstan's legislation shows how the king drove his officials to do their respective duties. He was uncompromising in his insistence on respect for the law. However this legislation also reveals the persistent difficulties which confronted the king and his councillors in bringing a troublesome people under some form of control. His claim to be "king of the English" was by no means widely recognised. The situation was complex: the Hiberno-Norse rulers of Dublin still coveted their interests in the Danish kingdom of York; terms had to be made with the Scots, who had the capacity not merely to interfere in Northumbrian affairs, but also to block a line of communication between Dublin and York; and the inhabitants of northern Northumbria were considered a law unto themselves. It was only after twenty years of crucial developments following Æthelstan's death in 939, that a unified kingdom of England began to assume its familiar shape. However, the major political problem for Edmund and Eadred, who succeeded Æthelstan, remained the difficulty of subjugating the north. In 959 Edgar is said to have "succeeded to the kingdom both in Wessex and in Mercia and in Northumbria, and he was then 16 years old" (ASC, version 'B', 'C'), and is called "the Peacemaker". By the early 970s, after a decade of Edgar's 'peace', it may have seemed that the kingdom of England was indeed made whole. In his formal address to the gathering at Winchester the king urged his bishops, abbots and abbesses "to be of one mind as regards monastic usage . . . lest differing ways of observing the customs of one Rule and one country should bring their holy conversation into disrepute".
Athelstan's court had been an intellectual incubator. In that court were two young men named Dunstan and Æthelwold who were made priests, supposedly at the insistence of Athelstan, right at the end of his reign in 939. Between 970 and 973 a council was held, under the aegis of Edgar, where a set of rules were devised that would be applicable throughout England. This put all the monks and nuns in England under one set of detailed customs for the first time. In 973, Edgar received a special second, 'imperial coronation' at Bath, and from this point England was ruled by Edgar under the strong influence of Dunstan, Athelwold, and Oswald, the Bishop of Worcester.
Athelred and the return of the Scandinavians (978-1016).
The reign of King Æthelred the Unready witnessed the resumption of Viking raids on England, putting the country and its leadership under strains as severe as they were long sustained. Raids began on a relatively small scale in the 980s, but became far more serious in the 990s, and brought the people to their knees in 1009-12, when a large part of the country was devastated by the army of Thorkell the Tall. It remained for Swein Forkbeard, king of Denmark, to conquer the kingdom of England in 1013–14, and (after Æthelred's restoration) for his son Cnut to achieve the same in 1015–16. The tale of these years incorporated in the "Anglo-Saxon Chronicle" must be read in its own right, and set beside other material which reflects in one way or another on the conduct of government and warfare during Æthelred's reign. It is this evidence which the basis for Simon Keynes's view that the king lacked the strength, judgement and resolve to give adequate leadership to his people in a time of grave national crisis; who soon found out that he could rely on little but the treachery of his military commanders; and who throughout his reign tasted nothing but the ignominy of defeat. The raids exposed tensions and weaknesses which went deep into the fabric of the late Anglo-Saxon state; and it is apparent that events proceeded against a background more complex than the chronicler probably knew. It seems, for example, that the death of Bishop Æthelwold in 984 had precipitated further reaction against certain ecclesiastical interests; that by 993 the king had come to regret the error of his ways, leading to a period when the internal affairs of the kingdom appear to have prospered.
The increasingly difficult times brought on by the Viking attacks are reflected in both Ælfric's and Wulfstan's works, but most notably in Wulfstan's fierce rhetoric in the "Sermo Lupi ad Anglos", dated to 1014. Malcolm Godden suggests that ordinary people saw the return of the Vikings, as the imminent "expectation of the apocalypse", and this was given voice in Ælfric and Wulfstan writings, which is similar to that of Gildas and Bede. Raids were signs of God punishing his people, Ælfric refers to people adopting the customs of the Danish and exhorts people not to abandon the native customs on behalf of the Danish ones, and then requests a 'brother Edward', to try to put an end to a 'shameful habit' of drinking and eating in the outhouse, which some of the countrywomen practiced at beer parties.
In April 1016 Æthelred died of illness, leaving his son and successor Edmund Ironside to defend the country. The final struggles were complicated by internal dissension, and especially by the treacherous acts of Ealdorman Eadric of Mercia, who opportunistically changed sides to Cnut's party. After the defeat of the English in the battle of Assandun in October 1016, Edmund and Cnut agreed to divide the kingdom so that Edmund would rule Wessex and Cnut Mercia, but Edmund died soon after his defeat in November 1016, making it possible for Cnut to seize power over all England.
Conquest England: Danes and Normans (1016-1066).
In the 11th century, there were two conquests and some Anglo-Saxon people would live through both: one in the aftermath of the conquest of Cnut in 1016; the second after that of William of Normandy in 1066. The consequences of each conquest can only be assessed with hindsight. In 1016, no-one was to know that whatever cultural ramifications were felt then, they would be subsumed half a century later; and in 1066 there was nothing to predict that the effects of William's conquest would be any greater or more lasting than those of Cnut's.
In this period and beyond the Ango-Saxon culture is changing. Politically and chronologically, the texts of this period are not 'Anglo-Saxon'; linguistically, those written in English (as opposed to Latin or French, the other official written languages of the period) are moving away from the late West Saxon standard that is called 'Old English'. Yet neither are they 'Middle English'; moreover, as Treharne explains, for around three quarters of this period, "there is barely any 'original' writing in English at all". These factors have led to a gap in scholarship implying a discontinuity either side of the Norman Conquest, however this assumption is being challenged.
At first sight, there would seem little to debate. Cnut appears to have adopted wholeheartedly the traditional role of Anglo-Saxon kingship. However an examination of the laws, homilies, wills, and charters dating from this period suggests that as a result of widespread aristocratic death and the fact that Cnut did not systematically introduce a new landholding class, major and permanent alterations occurred in the Saxon social and political structures. Eric John has remarked that for Cnut "the simple difficulty of exercising so wide and so unstable an empire made it necessary to practice a delegation of authority against every tradition of English kingship". The disappearance of the aristocratic families which had traditionally played an active role in the governance of the realm, coupled with Cnut's choice of thegnly advisors, put an end to the balanced relationship between monarchy and aristocracy so carefully forged by the West Saxon Kings.
Edward became king in 1042, and given his upbringing might have been considered a Norman by those who lived across the English Channel. Following Cnut's reforms, excessive power was concentrated in the hands of the rival houses of Leofric of Mercia and Godwine of Wessex. Problems also came for Edward from the resentment caused by the king's introduction of Norman friends. A crisis arose in 1051 when Godwine defied the king's order to punish the men of Dover, who had resisted an attempt by Eustace of Boulogne to quarter his men on them by force. The support of Earl Leofric and Earl Siward enabled Edward to secure the outlawry of Godwine and his sons; and William of Normandy paid Edward a visit during which Edward may have promised William succession to the English throne, although this Norman claim may have been mere propaganda. Godwine and his sons came back the following year with a strong force, and the magnates were not prepared to engage them in civil war but forced the king to make terms. Some unpopular Normans were driven out, including Archbishop Robert, whose archbishopric was given to Stigand; this act supplied an excuse for the Papal support of William's cause.
The fall of England and the Norman Conquest is a multi-generational, multi-family succession problem caused in great part by Athelred's incompetence. By the time William from Normandy, sensing an opportunity, landed his invading force in 1066, the elite of Anglo-Saxon England had changed, although much of the culture and society had stayed the same.
"Ða com Wyllelm eorl of Normandige into Pefnesea on Sancte Michæles mæsseæfen, sona þæs hi fere wæron, worhton castel æt Hæstingaport. Þis wearð þa Harolde cynge gecydd, he gaderade þa mycelne here, com him togenes æt þære haran apuldran, Wyllelm him com ongean on unwær, ær þis folc gefylced wære. Ac se kyng þeah him swiðe heardlice wið feaht mid þam mannum þe him gelæstan woldon, þær wearð micel wæl geslægen on ægðre healfe. Ðær wearð ofslægen Harold kyng, Leofwine eorl his broðor, Gyrð eorl his broðor, fela godra manna, þa Frencyscan ahton wælstowe geweald."
Then came William, the Earl of Normandy, into Pevensey on the evening of St.Michael's mass, and soon as his men were ready, they built a fortress at Hasting's port.This was told to King Harold, and he gathered then a great army and come towards them at the Hoary Apple Tree, and William came upon him unawares before his folk were ready. But the king nevertheless withstood him very strongly with fighting with those men who would follow him, and there was a great slaughter on either side. Then Harald the King was slain, and Leofwine the Earl, his brother, and Gyrth, and many good men, and the Frenchmen held the place of slaughter.
After the Norman Conquest.
Following the conquest, the Anglo-Saxon nobility were either exiled or joined the ranks of the peasantry. It has been estimated that only about 8 per cent of the land was under Anglo-Saxon control by 1087. Many Anglo-Saxon nobles fled to Scotland, Ireland, and Scandinavia. The Byzantine Empire became a popular destination for many Anglo-Saxon soldiers, as the Byzantines were in need of mercenaries. The Anglo-Saxons became the predominant element in the elite Varangian Guard, hitherto a largely North Germanic unit, from which the emperor's bodyguard was drawn and continued to serve the empire until the early 15th century. However, the population of England at home remained largely Anglo-Saxon; for them, little changed immediately except that their Anglo-Saxon lord was replaced by a Norman lord.
The chronicler Orderic Vitalis (1075 – c. 1142), himself the product of an Anglo-Norman marriage, wrote: "And so the English groaned aloud for their lost liberty and plotted ceaselessly to find some way of shaking off a yoke that was so intolerable and unaccustomed". The inhabitants of the North and Scotland never warmed to the Normans following the Harrying of the North (1069-1070), where William, according to the Anglo Saxon Chronicle utterly "ravaged and laid waste that shire".
Many Anglo-Saxon people needed to learn Norman French to communicate with their rulers, but it is clear that among themselves they kept speaking Old English, which meant that England was in an interesting tri-lingual situation: Anglo-Saxon for the common people, Latin for the Church, and Norman French for the administrators, the nobility, and the law courts. In this time, and due to the cultural shock of the Conquest, Anglo-Saxon began to change very rapidly, and by 1200 or so, it was no longer Anglo-Saxon English, but what scholars call early Middle English. But this language had deep roots in Anglo-Saxon, which was being spoken a lot later than 1066. Research in the early twentieth century, and still continuing today, has shown that a form of Anglo-Saxon was still being spoken, and not merely among uneducated peasants, into the thirteenth century in the West Midlands. This was J.R.R. Tolkien's major scholarly discovery when he studied a group of texts written in early Middle English called the Katherine Group, because they include the Life of St. Katherine (also, the Life of St. Margaret, the Life and the Passion of St. Juliana, Ancrene Wisse, and Hali Meithhad—these last two teaching how to be a good anchoress and arguing for the goodness of virginity). Tolkien noticed that a subtle distinction preserved in these texts indicated that Old English had continued to be spoken far longer than anyone had supposed. In Old English there is a distinction between two different kinds of verbs.
The Anglo-Saxons had always been defined very closely to the language, now this language gradually changed, and although some people (like the famous scribe known as the Tremulous Hand of Worcester) could read Old English in the thirteenth century. Soon afterwards, it became impossible for people to read Old English, and the texts became useless. The precious Exeter Book, for example, seems to have been used to press gold leaf and at one point had a pot of fish-based glue sitting on top of it, for Michael Drout this symbolises the end of the Anglo-Saxons.
Life and society.
The larger narrative, seen in the history of Anglo-Saxon England, is the continued mixing and integration of various disparate elements into one Anglo-Saxon people. The outcome of this mixing and integration was a continuous re-interpretation by the Anglo-Saxons of their society and worldview, which Heinreich Härke calls a "complex and ethnically mixed society".
Kingship and kingdoms.
Anglo-Saxon kingship had its origins in war-leadership. Anglo-Saxon leaders, some of whom may well have had forefathers who had been brought to Britain to provide military protection for the Romano-British, were able to seize the initiative and to establish kingdoms for themselves and their successors. Anglo-Saxon leaders, unable to tax and coerce followers instead extracted surplus by raiding and collecting food renders and 'prestige goods'. The later sixth century saw the end of a 'prestige goods' economy, as evidenced by the decline of accompanied burial, and the appearance of the first princely graves and high-status settlements. These centres of trade and production reflect the increased socio-political stratification and wider territorial authority which allowed seventh-century elites to extract and redistribute surpluses with far greater effectiveness than their sixth-century predecessors would have found possible. Anglo-Saxon society, in short, looked very different in 600 than it did a hundred years earlier.
By 600, the establishment of the first Anglo-Saxon 'emporia' was in prospect. There seem to have been over thirty of such units, many of which were certainly controlled by kings, in the parts of Britain which the Anglo-Saxons controlled. Bede's use of the term "imperium" has been seen as significant in defining the status and powers of the bretwaldas, in fact it is a word Bede used regularly as an alternative to "regnum"; scholars believe this just meant the collection of tribute. Oswiu's extension of overlordship over the Picts and Scots is expressed in terms of making them tributary. Military overlordship could bring great short-term success and wealth, but the system had its disadvantages. Many of the overlords enjoyed their powers for a relatively short period. Foundations had to be carefully laid to turn a tribute-paying under-kingdom into a permanent acquisition, such as Bernician absorption of Deira. The smaller kingdoms did not disappear without trace once they were incorporated into larger polities; on the contrary their territorial integrity was preserved when they became ealdormanries or, depending on size, parts of ealdormanries within their new kingdoms. An obvious example of this tendency for later boundaries to preserve earlier arrangements is Sussex; the county boundary is essentially the same as that of the West Saxon shire and the Anglo-Saxon kingdom. The Witan, also called Witenagemot, was the council of kings; its essential duty was to advise the king on all matters on which he chose to ask its opinion. It attested his grants of land to churches or laymen, consented to his issue of new laws or new statements of ancient custom, and helped him deal with rebels and persons suspected of disaffection.
By 800 only five Anglo-Saxon kingdoms are definitely known to have been still in existence, and a number of British kingdoms in the west of the country had disappeared as well. The major kingdoms had grown through absorbing smaller principalities and the means through which they did it and the character their kingdoms acquired as a result are one of the major themes of the Middle Saxon period. Beowulf, for all its heroic content, clearly makes the point that economic and military success were intimately linked. A 'good' king was a generous king who through his wealth won the support which would ensure his supremacy over other kingdoms. King Alfred's digressions in his translation of Boethius' Consolation of Philosophy, provided these observations about the resources which every king needed:
"In the case of the king, the resources and tools with which to rule are that he have his land fully manned: he must have praying men, fighting men and working men. You know also that without these tools no king may make his ability known. Another aspect of his resources is that he must have the means of support for his tools, the three classes of men. These, then, are their means of support: land to live on, gifts, weapons, food, ale, clothing and whatever else is necessary for each of the three classes of men."
This is the first written appearance of the division of society into the 'three orders'; the 'working men' provided the raw materials to support the other two classes. The advent of Christianity saw the introduction of new concepts of land tenure. The role of churchmen was analogous with that of the warriors waging heavenly warfare. However what Alfred was alluding to was that in order for a king to fulfil his responsibilities towards his people, particularly those concerned with defence, he had the right to make considerable exactions from the landowners and people of his kingdom. The need to endow the church resulted in the permanent alienation of stocks of land which had previously only been granted out on a temporary basis and introduced the concept of a new type of hereditary land which could be freely alienated and was free of any family claims.
Probably no one living in the eighth century would have predicted that the great Mercian empire would be destroyed and that the West Saxons with their poor track record for feuds and infighting within the royal house would emerge as the dominant kingdom in the ninth century. The nobility under the influence of Alfred became involved with developing the cultural life of their kingdom. As the kingdom became one they brought the monastic and spiritual life of the kingdom under one rule and stricter control. However the Anglo-Saxons believed in 'luck' as a random element in the affairs of man and so would probably have agreed that there is a limit to the extent one can understand why one kingdom failed while another succeeded. They also believed in 'destiny' and interpreted the fate of the kingdom of England with Biblical and Carolingian ideology, with parallels, between the Israelites, the great European empires and the Anglo-Saxons. Danish and Norman conquests were just the manner in which God punished his sinful people and the fate of great empires.
Religion and the church.
The first of King Alfred's three-fold Anglo-Saxon society are praying men; people who work at prayer. Although the Christianity dominates the religious history of the Anglo-Saxons, life in the 5th/6th centuries was dominated by 'pagan' religious beliefs with a Scando-Germanic heritage.
Early Anglo-Saxon society attached great significance to the horse; a horse may have been an acquaintance of the god Wodan, and/or they may have been (according to Tacitus) confidants of the gods. Horses were closely associated with gods, especially Odin and Freyr. Horses played a central role in funerary practices as well as in other rituals. Horses were prominent symbols of fertility, and there were many horse fertility cults. The rituals associated with these include horse fights, burials, consumption of horse meat, and horse sacrifice. Hengist and Horsa, the mythical ancestors of the Anglo-Saxons, were associated with horses, and references to horses are found throughout Anglo-Saxon literature. Actual horse burials in England are relatively rare and "may point to influence from the continent". A well-known Anglo-Saxon horse burial (from the sixth/seventh century) is Mound 17 at Sutton Hoo, a few yards from the more famous ship burial in Mound 1. A sixth-century grave near Lakenheath, Suffolk, yielded the body of a man next to that of a "complete horse in harness, with a bucket of food by its head." Pagan Anglo-Saxons worshipped at a variety of different sites across their landscape, some of which were apparently specially built temples and others that were natural geographical features such as sacred trees, hilltops or wells. According to place name evidence, these sites of worship were known alternately as either "hearg" or as "wēoh". Almost no poem from before the Norman Conquest, no matter how Christian its theme, is not steeped in pagan symbolism and their integration into the new faith goes beyond the literary sources. Thus, as Lethbridge reminds us, "to say, 'this is a monument erected in Christian times and therefore the symbolism on it must be Christian,' is an unrealistic approach. The rites of the older faith, now regarded as superstition, are practised all over the country today. It did not mean that people were not Christian; but that they could see a lot of sense in the old beliefs also"
Bede's story of Cædmon, the cowherd who became the 'Father of English Poetry' represents the real heart of the conversion of the Anglo-Saxons from paganism to Christianity. Bede wrote, "[t]here was in the Monastery of this Abbess (Streonæshalch - now known as Whitby Abbey) a certain brother particularly remarkable for the Grace of God, who was wont to make religious verses, so that whatever was interpreted to him out of scripture, he soon after put the same into poetical expressions of much sweetness and humility in Old English, which was his native language. By his verse the minds of many were often excited to despise the world, and to aspire to heaven." The story of Cædmon illustrates the blending of Christian and Germanic, Latin and oral tradition, monasteries and double monasteries, pre-existing customs and new learning, popular and elite, that characterizes the Conversion period of Anglo-Saxon history and culture. Cædmon does not destroy or ignore traditional Anglo-Saxon poetry. Instead, he converts it into something that helps the Church. Anglo-Saxon England finds ways to synthesize the religion of the Church with the existing "northern" customs and practices. Thus the conversion of the Anglo-Saxons was not just their switching from one practice to another, but making something new out of their old inheritance and their new belief and learning.
Monasticism, and not just the church, was at the centre of Anglo Saxon Christian life. Western monasticism, as a whole, had been evolving since the time of the desert fathers, but, in the seventh century, monasticism in England confronted a dilemma that brought to question the truest representation of the Christian faith. The two monastic traditions were the Celtic and the Roman, and a decision was made to adopt the Roman tradition. "Monasteria" seem to describe all religious congregations other than those of the Bishop.
In the 10th century, Dunstan brought Athelwold to Glastonbury, where the two of them set up a monastery on Benedictine lines. For a number of years this was the only monastery in England that strictly followed the Benedictine Rule and observed complete monastic discipline. What Mechthild Gretsch calls an "Aldhelm Seminar" developed at Glastonbury, and the effects of this seminar on the curriculum of learning and study in Anglo-Saxon England were enormous. Royal power was put behind the reforming impulses of Dunstan and Athelwold, helping them to enforce their reform ideas. This happened first at the Old Minster in Winchester, before the reformers built new foundations and refoundations at Thorney, Peterborough, and Ely, among other places. Benedictine Monasticism spread throughout England, these became centers of learning again, run by people trained in Glastonbury, with one rule, the works of Aldhelm at the center of their curricula but also influenced by the vernacular efforts of Alfred. From this mixture sprung a great flowering of literary production.
Fighting and warfare.
The second element of Alfred's society is fighting men. The subject of war and the Anglo-Saxons is a curiously neglected one, however, it is an important element of the Anglo-Saxon society.
Firstly, the mustering of armies. For both offensive and defensive war, and whether armies consisted essentially of household bands, as seems to have been characteristic of the earlier period, or were recruited on a territorial basis, soldiers had to be summoned. The mustering of an army, annually at times, occupied an important place in Frankish history, both military and constitutional. The English kingdoms appear to have known no institution similar to this. The earliest reference is Bede's account of the overthrow of the Northumbrian ^Ethelfrith by Redwald overlord of the southern English. Redwald raised a large army, presumably from among the kings who accepted his overlordship, and 'not giving him time to summon and assemble his whole army, Redwald met him with a much greater force and slew him on the Mercian border on the east bank of the river Idle'. There is a more detailed account of raising an army in 878, when the Danes made a surprise attack on Alfred at Chippenham after Twelfth Night. Alfred retreated to Athelney 'after Easter' and then seven weeks after Easter mustered an army at "Egbert's stone". It is not difficult to imagine that Alfred sent out word to the ealdormen of Somerset, Wiltshire and Hampshire, and to the reeves, to call his men to arms. This may explain the delay, and it is probably no more than coincidence that the army mustered at the beginning of May, a time when there would have been sufficient grass for the horses. There is also information about the mustering of fleets in the eleventh Century. From 992 to 1066 fleets were assembled at London, or returned to the city at the end of their service, on several occasions. Where they took up Station depended on the quarter from which a threat was expected: Sandwich if invasion was expected from the north, or the Isle of Wight if it was from Normandy.
Once they left home these armies and fleets had to be supplied, not only with food and clothing for the men but also forage for the horses which gave them mobility and were fitting to their Station. Yet if armies of the seventh and eighth centuries were accompanied by servants and a supply train of lesser free men, Alfred found these arrangements insufficient to defeat the Vikings. One of his reforms, if he was responsible for them, was to divide his military resources into three. One part manned the burhs and found the permanent garrisons which would make it impossible for the Danes to overrun Wessex, although they would also take to the field when extra soldiers were needed. The remaining two would take it in turns to serve. They were allocated a fixed term of Service and brought the necessary provisions with them. This arrangement did not always function perfectly. On one occasion a division on Service went home in the middle of blockading a Danish army on Thorney Island, its provisions consumed and its term expired, before the king came to relieve them. This method of division and rotation remained in force right up to 1066. In 917, when armies from Wessex and Mercia were in the field from early April until November, one division went home and another took over. Again, in 1052 when Edward's fleet was waiting at Sandwich to intercept Godwine's return, the ships returned to London to take on new earls and crews. The importance of supply, vital to military success, was appreciated even if it was taken for granted and features only incidentally in the sources.
Military training and strategy are two important matters on which the sources are more than usually silent. There are no references in literature or laws to men training, and so it is necessary to fall back on inference. For the noble warrior, his childhood was of first importance in learning both individual military skills and the teamwork essential for success in battle. Perhaps the games the youthful Cuthbert played ('wrestling, jumping, running, and every other exercise') had some military significance. Turning to strategy, of the period before Alfred the evidence gives the Impression that Anglo-Saxon armies fought battles frequently. If this is not solely due to the deficiencies of the sources, it would make England a special case. Battle was risky and best avoided unless all the factors were on your side. But if you were in a position so advantageous that you were willing to take the chance, it is likely that your enemy would be in such a weak position that he would avoid battle and pay tribute. Unless, of course, he was Bede's Oswald and trusted in God. Anyway, battle put the princes' lives at risk, as is demonstrated by the Northumbrian and Mercian overlordships brought to an end by a defeat in the field. Gillingham has shown how few pitched battles successful Charlemagne and Richard I chose to fight.
A defensive strategy becomes more apparent in the later part of Alfred's reign. It was built around the possession of fortified places and the close pursuit of the Danes to harass them and impede their preferred occupation of plundering. Alfred and his lieutenants were able to fight the Danes to a standstill by their repeated ability to pursue and closely besiege them in fortified camps at Nottingham, Wareham, Exeter, Chippenham, Rochester, Milton, Appledore, Thorney, Buttington, Chester and Hertford. It was only in the later part of Edward the Elder's reign that we see a type of war which a twelfth Century soldier would have recognised. In this phase of the war the West Saxons conquered land by building and holding burhs from which to threaten and dominate Danish territory. The fortification of sites at Witham, Buckingham, Towcester and Colchester persuaded the Danes of the surrounding regions to submit. The key to this warfare was sieges and the control of fortified places. It is clear that the new fortresses had permanent garrisons, and that they were supported by the inhabitants of the existing burhs when danger threatened. This is brought out most clearly in the description of the campaigns of 917 in the Chronicle, but throughout the conquest of the Danelaw by Edward and Æthelflæd it is clear that a sophisticated and coordinated strategy was being applied.
There was another means of dealing with military issues. In 973 a single currency was introduced into England in order to bring about political unification, but by concentrating bullion production at many coastal mints, the new rulers of England created a honey-pot which attracted a new wave of Viking invasions, which came close to breaking up the kingdom of the English. From 980 onwards the Anglo -Saxon Chronicle records renewed raiding against England . At first the raids were probing ventures by small numbers of ships' crews, but soon grew in size and effect, until the only way of dealing with the Vikings appeared to be to pay protection money to buy them off: "And in that year [991] it was determined that tribute should first be paid to the Danish men because of the great terror they were causing along the coast. The first payment was 10,000 pounds." 
The payment of Danegeld had to be underwritten by a huge balance of payments surplus; this could only be achieved by stimulating exports and cutting imports, itself accomplished through currency devaluation. This affected everyone in the Kingdom.
Settlements and working life.
The third aspect of Alfred's society is the working man. Helena Hamerow suggest the prevailing model of working life and settlement, particularly for the early period, as one of shifting settlement and building tribal kinship. The mid-Saxon period saw diversification, the development of enclosures, the beginning of the toft system, closer management of livestock, the gradual spread of the mould-board plough, 'informally regular plots' and a greater permanence, with further settlement consolidation thereafter foreshadowing post-Conquest villages. The later periods saw a proliferation of 'service features' including barns, mills and latrines, most markedly on high-status sites. Throughout the Anglo-Saxon period as Helena Hamerow suggests: "local and extended kin groups remained...the essential unit of production". This is very noticeable in the early period. However by the tenth and eleventh centuries, the rise of the manor and its significance in terms of both settlement and the management of land, which becomes very evident in the Domesday Book.
The collection of buildings discovered at Yeavering, formed part of an Anglo-Saxon royal vill or king's tun. These 'tun' consisted of a series of buildings designed to provide short-term accommodation for the king and his household. It is thought that the king would have travelled throughout his land dispensing justice and authority and collecting rents from his various estates. Such visits would be periodic and it is likely that he would visit each royal villa only once or twice a year. The Latin term "villa regia" which Bede used of the site suggests an estate centre as the functional heart of a territory held in the King's demesne. The territory is the land whose surplus production is taken into the centre as food-render to support the king and his retinue on their periodic visits as part of a progress around the kingdom. This territorial model, known as a multiple estate or shire has been developed in a range of studies and Colm O'Brien, in applying this to Yeavering has proposed a geographical definition of the wider shire of Yeavering and also a geographical definition of the principal estate whose structures Hope-Taylor excavated. One characteristic that the king's tun shared with some other groups of places is that it was a point of public assembly. People came together not only to give the king and his entourage board and lodging; they 'attended upon the king' in order to have disputes settled, cases appealed, lands granted, gifts given, appointments made, laws promulgated, policy debated, and ambassadors heard and replied to. People also assembled for other reasons, such as to hold fairs and to trade.
The first creations of towns are linked to a system of specialism at individual settlements, which is evidenced in studying place-names. Sutterton, 'shoe-makers' tun' (in the area of the Danelaw such places are Sutterby) was so-named because local circumstances allowed the growth of a craft recognised by the people of surrounding places. Similarly with Sapperton, the 'soap-makers' tun. While Boultham, the 'meadow with burdock plants', may well have developed a specialism in the production of burrs for wool-carding, since meadows with burdock merely growing in them must have been relatively numerous. From places named for their services or location within a single district, a category of which the most obvious perhaps are the Eastons and Westons, it is possible to move outwards to glimpse component settlements within larger economic units. Names betray some role within a system of seasonal pasture, Winderton in Warwickshire is the winter tun and various Somertons are self-explanatory. Hardwicks are dairy farms and Swinhopes the valleys where pigs were pastured.
Settlement patterns as well as village plans in England fall into two great categories: scattered farms and homesteads in upland and woodland Britain, nucleated villages across a swathe of central England. The chronology of nucleated villages is much debated and not yet clear. Yet there is strong evidence to support the view that nucleation occurred in the tenth century or perhaps the ninth, and was a development parallel to the growth of towns.
Women, children and slaves.
Alfred's view of his society overlooks certain classes of people. The main division in Anglo-Saxon society was between slave and free. Both groups were hierarchically structured, with several classes of freemen and many types of slaves. These varied at different times and in different areas, but the most prominent ranks within free society were the king, the nobleman or thegn, and the ordinary freeman or ceorl. They were differentiated primarily by the value of their wergild or 'man price', which was not only the amount payable in compensation for homicide (see above, section 2), but was also used as the basis for other legal formulations such as the value of the oath that they could swear in a court of law. Slaves had no wergild, as offences against them were taken to be offences against their owners, but the earliest laws set out a detailed scale of penalties depending both on the type of slave and the rank of owner.
A certain amount of social mobility is implied by regulations detailing the conditions under which a ceorl could become a thegn. Again these would have been subject to local variation, but one text refers to the possession of five hides of land (around 600 acres), a bell and a castle-gate, a seat and a special office in the king's hall. England had trading connections with the continent, and a merchant who had travelled overseas three times at his own expense could similarly be raised to the rank of thegn. Loss of status could also occur, as with penal slavery, which could be imposed not only on the perpetrator of a crime but on his wife and family. Some slaves may have been members of the native British population conquered by the Anglo-Saxons when they arrived from the continent; others may have been captured in wars between the early kingdoms, or have sold themselves for food in times of famine. However, slavery was not always permanent, and slaves who had gained their freedom would become part of an underclass of freedmen below the rank of ceorl.
Anglo-Saxon women appear to have enjoyed considerable independence, whether as abbesses of the great 'double monasteries' of monks and nuns founded during the seventh and eighth centuries, as major land-holders recorded in Domesday Book (1086), or as ordinary members of society. They could act as principals in legal transactions, were entitled to the same wergild as men of the same class, and were considered 'oath-worthy', with the right to defend themselves on oath against false accusations or claims. Sexual and other offences against them were penalised heavily. There is evidence that even married women could own property independently, and some surviving wills are in the joint names of husband and wife. Marriage comprised a contract between the woman's family and the prospective bridegroom, who was required to pay a 'bride-price' in advance of the wedding and a 'morning gift' following its consummation. The latter became the woman's personal property, but the former may have been paid to her relatives, at least during the early period. Widows were in a particularly favourable position, with inheritance rights, custody of their children and authority over dependants. However, a degree of vulnerability may be reflected in laws stating that they should not be forced into nunneries or second marriages against their will. The system of primogeniture (inheritance by the first-born male) was not introduced to England until after the Norman Conquest, so Anglo-Saxon siblings — girls as well as boys — were more equal in terms of status. The age of majority was usually either ten or twelve, when a child could legally take charge of inherited property, or be held responsible for a crime. It was common for children to be fostered, either in other households or in monasteries, perhaps as a means of extending the circle of protection beyond the kin group. Laws also make provision for orphaned children and foundlings.
Culture.
Architecture.
Early Anglo-Saxon buildings in Britain were generally simple, not using masonry except in foundations but constructed mainly using timber with thatch for roofing. Generally preferring not to settle within the old Roman cities, the Anglo-Saxons built small towns near their centres of agriculture, at fords in rivers or sited to serve as ports. In each town, a main hall was in the centre, provided with a central hearth.
Only ten of the hundreds of settlement sites that have been excavated in England from this period have revealed masonry domestic structures and confined to a few quite specific contexts. The usual explanation for the tendency of Anglo–Saxons to build in timber is one of technological inferiority or incompetence. However it is now accepted that technology and materials were part of conscious choices indivisible from their social meaning. Le Goff, suggests that the Anglo-Saxon period was defined by its use of wood, providing evidence for the care and craftsmanship that the Anglo–Saxon invested into their wooden material culture, from cups to halls, and the concern for trees and timber in Anglo–Saxon place–names, literature and religion. Michael Shapland suggests:
"The stone buildings imposed on England by the Romans would have been 'startling' and 'exceptional', and following the collapse of Roman society in the fifth century there was a widespread return to timber building, a 'cultural shift' that it is not possible to explain by recourse to technological determinism."
Anglo–Saxon building forms were very much part of this general building tradition.58 Timber was 'the natural building medium of the age': the very Anglo–Saxon word for 'building' is 'timbe'. Unlike in the Carolingian world, late Anglo–Saxon royal halls continued to be of timber in the manner of Yeavering centuries before, even though the king could clearly have mustered the resources to build in stone. Their preference must have been a conscious choice, perhaps an expression of 'deeply–embedded Germanic identity' on the part of the Anglo–Saxon royalty.
The major rural buildings were sunken-floor ("Grubenhäuser") or post-hole buildings, although Helena Hamerow suggest this distinction is less clear. Even the elite had simple buildings, with a central fire and a hole in the roof to let the smoke escape and the largest of which rarely had more than one floor, and one room. Buildings vary widely in size, most were square or rectangular, though some round houses have been found. Frequently these buildings have sunken floors; a shallow pit over which a plank floor was suspended. The pit may have been used for storage, but more likely was filled with straw for winter insulation. A variation on the sunken floor design is found in towns, where the "basement" may be as deep as 9 feet, suggesting a storage or work area below a suspended floor. Another common design was simple post framing, with heavy posts set directly into the ground, supporting the roof. The space between the posts was filled in with wattle and daub, or occasionally, planks. The floors were generally packed earth, though planks were sometimes used. Roofing materials varied, with thatch being the most common, though turf and even wooden shingles were also used.
Stone could be was used, and it was used to build churches. Bede makes it clear in both his Ecclesiastical History and his Historiam Abbatum that the masonry construction of churches, including his own at Jarrow, was undertaken morem Romanorum, 'in the manner of the Romans,' in explicit contrast to existing traditions of timber construction. Even at Canterbury, Bede believed that St Augustine's first cathedral had been 'repaired' or 'recovered' (recuperavit) from an existing Roman church, when in fact it had been newly constructed from Roman materials.85 The belief was "the Christian Church was Roman therefore a masonry church was a Roman building".
The building of churches in Anglo-Saxon England essentially began with Augustine of Canterbury in Kent following 597; for this he probably imported workmen from Frankish Gaul. The cathedral and abbey in Canterbury, together with churches in Kent at Minster in Sheppey (c.664) and Reculver (669), and in Essex at the Chapel of St Peter-on-the-Wall at Bradwell-on-Sea, define the earliest type in southeast England. A simple nave without aisles provided the setting for the main altar; east of this a chancel arch separated off the apse for use by the clergy. Flanking the apse and east end of the nave were side chambers serving as sacristies; further porticus might continue along the nave to provide for burials and other purposes. In Northumbria the early development of Christianity was influenced by the Irish mission, important churches being built in timber. Masonry churches became prominent from the late 7th century with the foundations of Wilfrid at Ripon and Hexham, and of Benedict Biscop at Monkwearmouth-Jarrow. These buildings had long naves and small rectangular chancels; porticus sometimes surrounded the naves. Elaborate crypts are a feature of Wilfrid's buildings. The best preserved early Northumbrian church is Escomb Church.
From the mid-8th century to the mid-10th a number of important buildings survive. One group comprises the first evidenced aisled churches: Brixworth, the most ambitious Anglo-Saxon church to survive largely intact, Wareham St Mary's, and Cirencester; also the rebuilding of Canterbury Cathedral. These buildings may be compared with aisled churches in the Carolingian empire. Other lesser churches may be dated to the late eighth and early ninth centuries on the basis of their elaborate sculptured decoration and have simple naves with side porticus. The tower of Barnack (near Peterborough) takes the picture forward to the West Saxon reconquest in the early 10th century, when decorative features that were to be characteristic of Late Anglo-Saxon architecture were already developed, such as narrow raised bands of stone ('pilaster strips') to surround archways and to articulate wall surfaces, as at Barton-upon-Humber and Earls Barton. In plan, however, the churches remained essentially conservative.
From, the monastic revival of the second half of the tenth century only a few documented buildings survive or have been excavated, for example: the abbeys of Glastonbury; Old Minster, Winchester; Romsey; Cholsey; and Peterborough Cathedral. The majority of churches that have been described as Anglo-Saxon fall into the period between the late 10th century and the early 12th. During this period many settlements were first provided with stone churches, but timber also continued to be used; the best wooden survival is Greensted Church in Essex, no earlier than the 9th century, and no doubt typical of many parish churches. On the Continent during the eleventh century was developed a group of interrelated Romanesque styles, associated with the rebuilding of many churches on a grand scale, made possible by a general advance in architectural technology and mason-craft.
The first fully Romanesque church in England was Edward the Confessor's rebuilding of Westminster Abbey (c.1050s and following), while the main development of the style only followed the Norman Conquest. However, at Stow Minster the crossing piers of the early 1050s are clearly 'proto-Romanesque'. A more decorative interpretation of Romanesque in lesser churches can be dated only somewhere between the mid and late 11th century, e.g. Hadstock (Essex), Clayton and Sompting (Sussex); this style continued towards the end of the century as at Milborne Port (Somerset). At St Augustine's Abbey in Canterbury c.1048–61 Abbot Wulfric aimed to retain the earlier churches while linking them with an octagonal rotunda: but the concept was still essentially Pre-Romanesque. Anglo-Saxon churches of all periods would have been embellished with a range of arts, including wall-paintings, some stained glass, metalwork and statues.
Art.
Early Anglo-Saxon art, as it survives, is seen mostly in decorated jewellery, like brooches, buckles, beads and wrist-clasps, some of outstanding quality. Characteristic of the 5th century is the quoit brooch with motifs based on crouching animals, as seen on the silver quoit brooch from Sarre, Kent. While the origins of this style are disputed, it is either an offshoot of provincial Roman art, Frank, or Jute art. One style flourished from the late 5th century, and continued throughout the 6th, and is on many square-headed brooches, it is characterised by chip-carved patterns based on animals and masks. A different style, which gradually superseded it is dominated by serpentine beasts with interlacing bodies. 
By the later 6th century the best works from the south-east are distinguished by greater use of expensive materials, above all gold and garnets, reflecting the growing prosperity of a more organised society which had greater access to imported precious materials, as seen in the buckle from the Taplow burial and the jewellery from that at Sutton Hoo, c.600 and c.625 respectively. The possible symbolism of the decorative elements like interlace and beast forms that were used in these early works remains unclear, it is clear. These objects were the products of a society that invested its modest surpluses in personal display, who fostered craftsmen and jewellers of a high standard, and a society where the possession of a fine brooch or buckle was a valuable status symbol and possible tribal emblem – in death as much as in life.
The Staffordshire Hoard is the largest hoard of Anglo-Saxon gold and silver metalwork . Discovered in a field near the village of Hammerwich, near Lichfield, in Staffordshire, England, it consists of over 3,500 items that are nearly all martial in character and contains no objects specific to female uses. It demonstrates that considerable quantities of high-grade goldsmiths' work were in circulation among the elite during the 7th century. It also shows that, superb though individual pieces may be in terms of craftsmanship, the value of such items as currency and their potential roles as tribute or the spoils of war could, in a warrior society, outweigh appreciation of their integrity and artistry.
The coming of Christianity revolutionised the visual arts, as well as other aspects of society. Art had to fulfil new functions, and whereas pagan art was abstract, Christianity required images clearly representing subjects. The transition between the Christian and pagan traditions is occasionally apparent in 7th century works; examples include the Crundale buckle and the Canterbury pendant. In addition to fostering metalworking skills, Christianity stimulated stone sculpture and manuscript illumination. In these Germanic motifs, such as interlace and animal ornament along with Celtic spiral patterns, are juxtaposed with Christian imagery and Mediterranean decoration, notably vine-scroll. The Ruthwell Cross, Bewcastle Cross and Easby Cross are leading Northumbrian examples of the Anglo-Saxon version of the Celtic high cross, generally with a slimmer shaft.
The jamb of the doorway at Monkwearmouth, carved with a pair of lacertine beasts, probably dates from the 680s; the golden, garnet-adorned pectoral cross of St Cuthbert was presumably made before 687; while his wooden inner coffin (incised with Christ and the Evangelists' symbols, the Virgin and Child, archangels and apostles), the Lindisfarne Gospels, and the Codex Amiatinus all date from c.700. The fact that these works are all from Northumbria might be held to reflect the particular strength of the church in that kingdom during the second half of the century. Works from the south were more restrained in their ornamentation than are those from Northumbria.
Lindisfarne was a very important centre of book production, along with Ripon and Monkwearmouth-Jarrow. The Lindisfarne Gospels might be the single most beautiful book produced in the Middle Ages, and the Echternach Gospels and (probably) the Book of Durrow are other products of Lindisfarne. A Latin gospel book, the Lindisfarne Gospels are richly illuminated and decorated in an Insular style that blends not only Irish and Western Mediterranean elements but, incorporates imagery from the Eastern Mediterranean, including Coptic Christianity as well. Produced in the north of England at the same time was the Codex Amiatinus, which has been called "the finest book in the world." It is certainly one of the largest, weighing 34 kilograms. It is a pandect, which was rare in the Middle Ages: all the books of the Bible in one volume. The Codex Amiatinus was produced at Monkwearmouth-Jarrow in 692 under the direction of Abbot Ceolfrith. Bede probably had something to do with it. The production of the Codex shows the riches of the north of England at this time. We have records of the monastery needing a new grant of land to raise two thousand more cattle to get the calf skins to make the vellum to make the manuscript. The Codex Amiatinus was meant to be a gift to the Pope, and Ceolfrith was taking it to Rome when he died on the way. The copy ended up in Florence, where it still is today - a ninth-century copy of this book is even today the personal Bible of the Pope.
In the 8th century, Anglo-Saxon Christian art flourished with grand decorated manuscripts and sculptures, along with 'secular' works which bear comparable ornament, like the Witham pins and the Coppergate helmet. The flourishing of sculpture in Mercia, occurred slightly later than in Northumbria and is dated to the second half of the 8th century. Some fine decorated southern books, above all the Bible fragment, can be securely assigned to the earlier 9th century, owing to the similarity of their script to that of charters from that period; The Book of Cerne is an early 9th century Insular or Anglo-Saxon Latin personal prayer book with Old English components. This manuscript was decorated and embellished with four painted full-page miniatures, major and minor letters, continuing panels, and litterae notibiliores. Further decorated motifs used in these manuscripts, such as hunched, triangular beasts, also appear on objects from the Trewhiddle hoard (buried in the 870s) and on the rings which bear the names of King Æthelwulf and Queen Æthelswith, which are the centre of a small corpus of fine ninth-century metalwork.
There was demonstrable continuity in the south, even though the Danish settlement represented a watershed in England's artistic tradition. Wars and pillaging removed or destroyed much Anglo-Saxon art, while the settlement introduced new Scandinavian craftsmen and patrons. The result was to accentuate the pre-existing distinction between the art of the north and that of the south. In the 10th and 11th centuries, the Viking dominated areas were characterised by stone sculpture in which the Anglo-Saxon tradition of cross shafts took on new forms, and a distinctive Anglo-Scandinavian monument, the 'hogback' tomb, was produced. The decorative motifs used on these northern carvings (as on items of personal adornment or everyday use) echo Scandinavian styles. The Wessexan hegemony and the monastic reform movement appear to have been the catalysts for the rebirth of art in southern England from the end of the 9th century. Here artists responded primarily to continental art; foliage supplanting interlace as the preferred decorative motif. Key early works are the Alfred Jewel, which has fleshy leaves engraved on the back plate; and the stole and maniples of Bishop Frithestan of Winchester, which are ornamented with acanthus leaves, alongside figures that bear the stamp of Byzantine art. The surviving evidence points to Winchester and Canterbury as the leading centres of manuscript art in the second half of the 10th century: they developed colourful paintings with lavish foliate borders, and coloured line drawings.
By the early 11th century, these two traditions had fused and had spread to other centres. Though manuscripts dominate the corpus, sufficient architectural sculpture, ivory carving and metalwork survives to show that the same styles were current in secular art, and became widespread in the south at parochial level. The wealth of England in the later tenth and eleventh century is clearly reflected in the lavish use of gold in manuscript art as well as for vessels, textiles and statues (now known only from descriptions). Widely admired, southern English art was highly influential in Normandy, France and Flanders from c.1000. Indeed, keen to possess it, or recover its materials, the Normans appropriated it in large quantities in the wake of the Conquest. The Bayeux Tapestry, probably designed by a Canterbury artist for Bishop Odo of Bayeux, is arguably the swansong of Anglo-Saxon art. Surveying nearly 600 years of continuous change, three common strands stand out: lavish colour and rich materials; an interplay between abstract ornament and representational subject matter; and a fusion of art styles reflects England was linked in the 11th century.
Language.
Old English ("Ænglisc, Anglisc, Englisc") or Anglo-Saxon is the early form of the English language that was spoken and written by the Anglo-Saxons and their descendants in parts of what are now England and southern and eastern Scotland between at least the mid-5th century and the mid-12th century. Old English is a West Germanic language closely related to Old Frisian and Old Saxon. It had a grammar similar in many ways to Classical Latin. In most respects, including its grammar, it was much closer to modern German and Icelandic than to modern English. It was fully inflected with five grammatical cases (nominative, accusative, genitive, dative, and instrumental), three grammatical numbers (singular, plural, and dual) and three grammatical genders (masculine, feminine, and neuter). The dual forms occurred in the first and second persons only and referred to groups of two.
Some of the characteristics of the language were: adjectives, pronouns and (sometimes) participles that agreed with their antecedent nouns in case, number and gender; finite verbs that agreed with their subject in person and number; and nouns that came in numerous declensions (with deep parallels in Latin, Ancient Greek and Sanskrit). Verbs came in nine main conjugations (seven "strong" and two "weak"), each with numerous subtypes, as well as a few additional smaller conjugations and a handful of irregular verbs. The main difference from other ancient Indo-European languages, such as Latin, is that verbs can be conjugated in only two tenses (vs. the six "tenses" – really tense/aspect combinations – of Latin), and have no synthetic passive voice (although it did still exist in Gothic). Gender in nouns was grammatical, as opposed to the natural gender that prevails in modern English.
Many linguists believe that Old English received little influence from the local insular languages especially Common Brittonic (the language that may have been the majority language in Lowland Britain). Linguists such as Richard Coates have suggested there could not have been meaningful contact between the languages, which is reasonable argued from the small amount of loanwords. Recently a number of linguists have argued that many of the grammar changes observed in English were due to a Brythonic influence. John McWhorter suggests that the language changes seen later in English were always there in vernacular speech and this was not written, especially since those who did the writing were educated individuals that most likely spoke a standard form of Old English. The speech of an illiterate "ceorl", on the other hand, can not be reconstructed. The progressive nature of this language acquisition, and the 'retrospective reworking' of kinship ties to the dominant group led, ultimately, to the "myths which tied the entire society to immigration as an explanation of their origins in Britain".
What survives through writing represents primarily the register of Anglo-Saxon, and this is most often in the West Saxon dialect. Little is known about the everyday spoken language of people living in the migration period. Old English is a contact language and it is hard to reconstruct the pidgin used in this period from the written language found in the West Saxon literature of some 400 years later. Two general theories are proposed regarding why people changed their language to Old English (or an early form of such): either, a person or household changed so as to serve an elite; or, a person or household changed through choice as it provided some advantage economically or legally. Over time, Old English developed into four major dialects: Northumbrian, spoken north of the river Humber; Mercian, spoken in the Midlands; Kentish, spoken in Kent in the far southeastern part of the island; and West Saxon, spoken in the southwest. All of these dialects have direct descendants in modern England, and American regional dialects also have their roots in the dialects of Old English. "Standard" Modern English (if there is such a thing), or at least modern English spelling, owes most to the Mercian dialect, since that was the dialect of London.
Near the end of the Old English period the English language underwent a third foreign influence, namely the Scandinavian influence of Old Norse. In addition to a great many place names, these consist mainly of items of basic vocabulary, and words concerned with particular administrative aspects of the Danelaw (that is, the area of land under Viking control, which included extensive holdings all along the eastern coast of England and Scotland). The Scandinavians spoke Old Norse, a language related to Old English in that both derived from the same ancestral Proto-Germanic language. It is very common for the intermixing of speakers of different dialects, such as those that occur during times of political unrest, to result in a mixed language, and one theory holds that exactly such a mixture of Old Norse and Old English is thought to have accelerated the decline of case endings in Old English. The influence of Old Norse on the lexicon of the English language has been profound: responsible for such basic vocabulary items as "sky", "leg", the pronoun "they", the verb form "are", and hundreds of other words.
Nick Highham has provided a summary of the importance of language to the Anglo-Saxon culture:
"As Bede later implied, language was a key indicator of ethnicity in early England. In circumstances where freedom at law, acceptance with the kindred, access to patronage, and the use of possession of weapons were all exclusive to those who could claim Germanic descent, then speaking Old English without Latin or Brittonic inflection had considerable value."
Kinship.
Helena Hamerow has made an observation that in Anglo-Saxon society "local and extended kin groups remained...the essential unit of production throughout the Anglo-Saxon period". "Local and extended kin groups" was a key aspect of Anglo-Saxon culture. Kinship fueled societal advantages, freedom and the relationships to an elite, that allowed the Anglo-Saxons' culture and language to flourish.
The ties of loyalty to a lord, were to the person of a lord, not to his station; there was no real concept of patriotism or loyalty to a cause. This explains why dynasties waxed and waned so quickly, a kingdom was only as strong as its leader-king. There was no underlying administration or bureaucracy to maintain any gains beyond the lifetime of a leader. An example of this was the leadership Rædwald of East Anglia and how the East Anglian primacy did not survive his death. Kings could not, except in exceptional circumstances, make new laws. Their role instead was to uphold and clarify previous custom and to assure his subjects that he would uphold their ancient privileges, laws, and customs. Although the person of the king as a leader could be exalted, the office of kingship was not in any sense as powerful or as invested with authority as it was to become. One of the tools kings used was to tie themselves closely to the new Christian church; through the practice of having a church leader anoint and crown the king; God and king were joined in peoples' minds.
The ties of kinship meant that the relatives of a murdered person were obliged to exact vengeance for his or her death. This led to bloody and extensive feuds. As a way out of this deadly and futile custom the system of 'wergilds' was instituted. The 'wergild' set a monetary value on each person's life according to their wealth and social status. This value could also be used to set the fine payable if a person was injured or offended against. Robbing a thane called for a higher penalty than robbing a ceorl. On the other hand, a thane who thieved could pay a higher fine than a ceorl who did likewise. Men were willing to die for the lord and to support their 'comitatus'; their warrior band. Evidence of this behavior (though it may be more a literary ideal than an actual social practice), can be observed in the story, made famous in the Anglo-Saxon Chronicle entry for 755, of Cynewulf and Cyneheard, in which the followers of a defeated king decided to fight to the death rather than be reconciled after the death of their lord.
This emphasis on social standing affected all parts of the Anglo-Saxon world. The courts, for example did not attempt to discover the facts in a case; instead, in any dispute it was up to each party to get as many people as possible to swear to the rightness of their case; "oath-swearing". The word of a thane counted for that of six ceorls. It was assumed that any person of good character would be able to find enough people to swear to his innocence that his case would prosper. Anglo-Saxon society was also decidedly patriarchal, but women were in some ways better off than they would be in later times. A woman could own property in her own right. She could and did rule a kingdom if her husband died. She could not be married without her consent and any personal goods, including lands, that she brought into a marriage remained her own property. If she were injured or abused in her marriage her relatives were expected to look after her interests.
Law.
The most noticeable feature of the Anglo-Saxon legal system is the apparent prevalence of legislation in the form of law codes. The early Anglo-Saxons were organised in various small kingdoms often corresponding to later shires or counties. The kings of these small kingdoms issued written Laws, one of earliest of which is that attributed to Ethelbert, king of Kent, ca.560-616. The Anglo-Saxon law codes follow a pattern found in continental Europe where other groups of the former Roman empire encountered government dependent upon written sources of law and hastened to display the claims of their own native traditions by reducing them to writing. These legal systems should not be thought of as operating like modern legislation, rather they are educational and political tools designed to demonstrate standards of good conduct rather than act as criteria for subsequent legal judgment.
Although not themselves sources of law, Anglo-Saxon charters are a most valuable historical source for tracing the actual legal practices of the various Anglo-Saxon communities. A charter was a written document from a king or other authority confirming a grant either of land or some other valuable right. Their prevalence in the Anglo-Saxon state is a sign of sophistication. They were frequently appealed to and relied upon in litigation. Making grants and confirming those made by others was a major way in which Anglo-Saxon kings demonstrated their authority.
The royal council or witan played a central but limited role in the Anglo-Saxon period. The main feature of the system was its high degree of decentralisation. The interference by the king through his granting of charters and the activity of his witan in litigation are exceptions rather than the rule in Anglo-Saxon times. The most important court in the later Anglo-Saxon period was the Shire Court. It is of interest that many shires (such as Kent and Sussex) were in the early days of the Anglo-Saxon settlement the centre of small independent kingdoms. As the kings first of Mercia and then of Wessex slowly extended their authority over the whole of England they left the Shire Courts with overall responsibility for the administration of law. The Shire met in one or more traditional places, earlier in the open air and then later in a Moot or meeting hall. The meeting of the Shire Court was presided over by an officer, the shire reeve or sheriff, whose appointment came in later Anglo-Saxon times into the hands of the king but had in earlier times been elective. The sheriff was not the judge of the court, merely its president. The judges of the court were all those who had the right and duty of attending the court, the suitors. These were originally all free male inhabitants of the neighbourhood but, over time, suit of court became an obligation attached to particular holdings of land. The sessions of a Shire Court resembled more closely those of a modern local administrative body than a modern court. It could and did act judicially but this was not its prime function. In the Shire Court, charters and writs would be read out for all to hear.
Below the level of the shire each county was divided into areas known as hundreds (or wapentakes in the north of England). These were original groups of families rather than geographical areas. The Hundred Court was a smaller version of the shire, presided over by the hundred bailiff, formerly a sheriff's appointment, but over the years many hundreds fell into the private hands of a local large landowner. We are not well-informed about Hundred Court business, which must have been a mix of the administrative and judicial, but they remained in some areas an important forum for the settlement of local disputes well into the post-Conquest period. The Anglo-Saxon system put an emphasis upon compromise and arbitration: litigating parties were enjoined to settle their differences if at all possible. If they persisted in bringing a case for decision before a Shire Court then it could be determined there. The suitors of the court would pronounce a judgment which fixed how the case would be decided: legal problems were considered to be too complex and difficult for mere human decision and so proof or demonstration of the right would depend upon some irrational, non-human criterion. The normal methods of proof were oath-helping or the ordeal.
Oath-helping involved the party undergoing proof swearing to the truth of his claim or denial and having that oath reinforced by five or more others, chosen either by the party or by the court. The numbers of helpers required and the form of their oath differed from place to place and upon the nature of the dispute. If either the party or any of the helpers failed in the oath, either refusing to take it or sometimes even making an error in the required formula, the proof failed and the case was adjudged to the other side. It appears surprising to moderns that so important a matter might be settled by one and his friends falsely swearing an oath. In a society in which each was known to his neighbour and in which religious emphasis was placed upon the sanctity of an oath, the system was probably more satisfactory. As 'wager of law' it remained a way of determining cases in the common law until its abolition in the 19th century.
The ordeal offered an alternative for those unable or unwilling to swear an oath. The two most common methods were the ordeal by hot iron and by cold water. The former consisted in carrying a red-hot iron for five paces: the wound was immediately bound up and if, on unbinding, it was found to be festering the case was lost. In the ordeal by water the victim, usually an accused person, was cast bound into water: if he sunk he was innocent, if he floated, guilty. Although for perhaps understandable reasons the ordeals became associated with trials in criminal matters they were in essence tests of the truth of a claim or denial of a party and appropriate for trying any
legal issue. The allocation of a mode of proof and who should bear it was the substance of the Shire Court's judgment or doom and perhaps followed known customary rules of which we have no knowledge. Some measure of discretion must have existed in the determining of the outcome of an ordeal by hot iron but result of the cold water and the oath-helping would have been obvious to all.
Literature.
Old English literary works include genres such as epic poetry, hagiography, sermons, Bible translations, legal works, chronicles, mainly the Anglo-Saxon Chronicle, riddles and others. In all there are about 400 surviving manuscripts from the period, a significant corpus of both popular interest and specialist research. The manuscripts use a modified Roman alphabet, but Anglo-Saxon runes or "futhorc" are used in under 200 inscriptions on objects, sometimes mixed with Roman letters.
This literature is remarkable for being in the vernacular (Old English) in the early medieval period: almost all other written literature was in Latin at this time, but due to Alfred's programme of vernacular literacy, the oral traditions of Anglo-Saxon England ended up being converted into writing and preserved. We owe much of this preservation to the monks of the tenth century, who made - at the very least - the copies of most of the literary manuscripts that still exist. Manuscripts were not common items. They were expensive and hard to make. First, cows or sheep had to be slaughtered and their skins tanned. Then people had to decide to use this leather for manuscripts rather than for any of the other things leather can be used for. The leather was then scraped, stretched, and cut into sheets, which were sewn into books. Then inks had to be made from oak galls and other ingredients, and the books had to be hand written by monks using quill pens. Every manuscript is slightly different from every other one, even if they are copies of each other, because every scribe had different handwriting and made different errors. We can sometimes identify individual scribes from their handwriting, and we can often guess where manuscripts were written because different scriptoria (centres of manuscript production) wrote in different styles of hand.
There are four great poetic codices of Old English poetry (a codex is a book in modern format, as opposed to a scroll): the Junius Manuscript, the Vercelli Book, the Exeter Book, and the Nowell Codex or "Beowulf" Manuscript; most of the well known lyric poems such as "The Wanderer", "The Seafarer", "Deor" and "The Ruin" are found in the Exeter Book, while the Vercelli Book has the "Dream of the Rood", some of which is also carved on the Ruthwell Cross. The Franks Casket also has carved riddles, a popular form with the Anglo-Saxons. Old English secular poetry is mostly characterized by a somewhat gloomy and introspective cast of mind, and the grim determination found in "The Battle of Maldon", recounting an action against the Vikings in 991. This is from a book that was lost in the Cotton Library fire of 1731, but it had been transcribed previously.
Rather than being organized around rhyme, the poetic line in Anglo-Saxon is organised around alliteration, the repetition of stressed sounds, any repeated stressed sound, vowel or consonant, could be used. Anglo-Saxon lines are made up of two half-lines (in old-fashioned scholarship, these are called hemistiches) divided by a breath-pause or caesura. There must be at least one of the alliterating sounds on each side of the caesura.
"hreran mid hondumhrimcealde sæ"
The line above illustrates the principle: note that there is a natural pause after 'hondum' and that the first stressed syllable after that pause begins with the same sound as a stressed line from the first half-line (the first halfline is called the a-verse and the second is the b-verse).
There is very strong evidence that Anglo-Saxon poetry has deep roots in oral tradition, but, keeping with the cultural practices we have seen elsewhere in Anglo-Saxon culture, there was a blending between tradition and new learning. Thus while all Old English poetry has common features, we can also identify three strands: religious poetry, which includes poems about specifically Christian topics, such as the cross and the saints; Heroic or epic poetry, such as "Beowulf", which is about heroes, warfare, monsters, and the Germanic past; and poetry about "smaller" topics, including introspective poems (the so-called elegies), "wisdom" poems (which communicate both traditional and Christian wisdom), and riddles. For a long time all Anglo-Saxon poetry was divided into three groups: Cædmonian (the biblical paraphrase poems), heroic, and "Cynewulfian," named after Cynewulf, one of the only named poets in Anglo-Saxon.The most famous works from this period include the epic poem "Beowulf", which has achieved national epic status in Britain.
There are about 30,000 surviving lines of Old English poetry and about ten times that much prose, and the majority of both is religious. The prose was influential and obviously very important to the Anglo-Saxons and more important than the poetry to those who came after the Anglo-Saxons. Homilies are sermons, lessons to be given on moral and doctrinal matters, and the two most prolific and respected writers of Anglo-Saxon prose, Ælfric and Wulfstan, were both homilists. Ælfric also wrote the 'Lives of Saints' which very popular and were highly prized. Almost all surviving poetry is found in only one manuscript copy, but there are a number of different versions of some prose works, especially the Anglo-Saxon Chronicle, which was apparently promulgated to monasteries by the royal court. Anglo-Saxon clergy also continued to write in Latin, the language of Bede's works, monastic chronicles, and theological writing, although Bede's biographer records that he was familiar with Old English poetry and gives a five line lyric which he either wrote or liked to quote - the sense is unclear.
Symbolism.
Symbolism was an essential element to Anglo-Saxon culture. Julian D. Richards suggested that in societies with strong oral traditions, material culture is used to store and pass on information and stand instead of literature in those cultures. This symbolism is less logical than literature and more difficult to read. Anglo-Saxons used symbolism, not just to communicate, but as tools to aid their thinking about the world. Symbols were also used to change the world, Anglo-Saxons used symbols to differentiate between groups and people, status and role in society.
The visual riddles and ambiguities of early Anglo-Saxon animal art, for example has been seen as emphasing the protective roles of animals on dress accessories, weapons, armour and horse equipment, and its evocation of pre-Christian mythological themes. However Howard Williams and Ruth Nugent have suggest that the number of artefact categories that have animals or eyes; from pots to combs, buckets to weaponry was to make artefacts 'see' by impressing and punching circular and lentoid shapes onto them. This symbolism of making the object seems to be more than decoration.
Conventional interpretations of the symbolism of grave goods revolved around religion (equipment for the hereafter), legal concepts (inalienable possessions) and social structure (status display, ostentatious destruction of wealth). There was multiplicity of messages and variability of meanings characterised the deposition of objects in Anglo-Saxon graves. In Early Anglo-Saxon cemeteries, 47% of male adults and 9% of all juveniles were buried with weapons, some of which were very young. The proportion of adult weapon burials is much too high to suggest that they all represent a social élite. The usual assumption is that these are 'warrior burials', and this term is used throughout the archaeological and historical literature. However, a systematic comparison of burials with and without weapons, using archaeological and skeletal data, suggests that this assumption is much too simplistic and even misleading. Anglo-Saxon weapon burial rite involved a complex ritual symbolism: it was multi-dimensional, displaying ethnic affiliation, descent, wealth, élite status, and age groups. This symbol continued until c.700 when it ceased to have the symbolic power that it had before. Heinrich Härke suggests this change was due to the changing structure of society and especially in ethnicity and assimilation implying the lowering of ethnic boundaries in the Anglo-Saxon settlement areas of England, towards a common culture.
The word bead comes from the Anglo Saxon words bidden (to pray) and bede (prayer). The vast majority of early Anglo-Saxon female graves contain beads, which are often found in large numbers in the area of the neck and chest. Beads are also sometimes found in male burials, with large beads often associated with prestigious weapons. A variety of materials other than glass were available for Anglo-Saxon beads including; amber, rock crystal, amethyst, bone, shells, coral and even metal. These beads are usually considered to have a social or ritual function. Anglo-Saxon glass beads show a wide variety of bead manufacturing techniques, sizes, shapes, colours and decorations. Various studies have been carried out investigating the distribution and chronological change of bead types. The crystal beads which appear on bead strings in the pagan Anglo-Saxon period seems to gone through various changes in meaning in the Christian period, which Gale Owen-Crocker suggests was linked to symbolism of the Virgin Mary, and hence to intercession. John Hines has suggested that the over 2000 different types of beads found at Lakenheath show that the beads symbolise identity, roles, status and micro cultures within the tribal landscape of the early Anglo-Saxon world.
Symbolism continued to have a hold on the minds of Anglo-Saxon people into the Christian eras. The interiors of churches would have glowed with colour, and the walls of the halls were painted with decorative scenes from the imagination telling stories of monsters and heroes like those in the poem Beowulf. Although nothing much is left of the wall paintings, evidence of their pictorial art is found in Bibles and Psalters, in illuminated manuscripts. The poem, 'The Dream of the Rood', is an example how symbolism of trees was fused into Christian symbolism.
Richard North suggests that the sacrifice of the tree was in accordance with pagan virtues and "the image of Christ's death was constructed in this poem with reference to an Anglian ideology of the world tree". North suggests that the author of "The Dream of the Rood" "uses the language of the myth of Ingui in order to present the Passion to his newly Christianized countrymen as a story from their native tradition". Furthermore, the tree's triumph over death is celebrated by adorning the cross with gold and jewels.
The most distinctive feature of coinage of the first half of the 8th century is its portrayal of animals, to an extent found in no other European coinage of the Early Middle Ages. Some animals, such as lions or peacocks, would have been known in England only through descriptions in texts or through images in manuscripts or on portable objects. The animals were not merely illustrated out of an interest in the natural world. Each was imbued with meanings and acted as a symbol which would have been understood at the time.
Contemporary meanings.
"Anglo-Saxon" in linguistics is still used as a term for the original West Germanic component of the modern English language, which was later expanded and developed through the influence of Old Norse and Norman French, though linguists now more often refer to it as Old English.
Throughout the history of the Anglo-Saxons studies producing a dispassionate narrative of the people has been difficult. In the early Middle Ages the views of Geoffrey of Monmouth produced a personally inspired history that wasn't challenged for five hundred years. In the reformation, churchman looking for signs of an English church reinterpreted Anglo-Saxon Christianity. In the 19th century the term "Anglo-Saxon" was broadly used in philology, and is sometimes so used at present. In Victorian Britain, some writers such as Robert Knox,
James Anthony Froude, Charles Kingsley and Edward A. Freeman used the term "Anglo-Saxon" to justify racism and imperialism, claiming that the "Anglo-Saxon" ancestry of the English made them racially superior to the colonised peoples. Similar racist ideas were advocated in the 19th-century United States by Samuel George Morton and George Fitzhugh. These views have influenced how versions of early English history are embedded in the sub-conscious of people "re-emerging in school textbooks and television programmes and still very congenial to some strands of political thinking."
The term "Anglo-Saxon" is sometimes used to refer to peoples descended or associated in some way with the English ethnic group, but there is no universal definition for the term. In contemporary Anglophone cultures outside Britain, "Anglo-Saxon" may be contrasted with "Celtic" as a socioeconomic identifier, invoking or reinforcing historical prejudices against non-English British immigrants. "White Anglo-Saxon Protestant", i.e. WASP, is a term especially popular in the United States that refers chiefly to old wealthy families with mostly English ancestors. As such, WASP is not a historical label or a precise ethnological term, but rather a reference to contemporary family-based political, financial and cultural power— e.g., The Boston Brahmin. The French often use "Anglo-Saxon" to refer to the combined power of Britain and the US today.
Outside Anglophone countries, both in Europe and in the rest of the world, the term "Anglo-Saxon" and its direct translations are used to refer to the Anglophone peoples and societies of Britain, the United States, and other countries such as Australia, Canada and New Zealand – areas which are sometimes referred to as the Anglosphere. The term "Anglo-Saxon" can be used in a variety of contexts, often to identify the English-speaking world's distinctive language, culture, technology, wealth, markets, economy, and legal systems. Variations include the German "Angelsachsen", French "Anglo-Saxon", Spanish "anglosajón", Portuguese "Anglo-saxão", Polish "anglosaksoński", Italian "anglosassone", Catalan "anglosaxó", Japanese "Angurosakuson" and Ukrainian "aнглосакси" (anhlosaksy). As with the English-language use of the term, what constitutes the "Anglo-Saxon" varies from speaker to speaker.
See also.
Modern concepts:
Further reading.
Historical.
</dl>

</doc>
<doc id="37782" url="http://en.wikipedia.org/wiki?curid=37782" title="Edward Teller">
Edward Teller

Edward Teller (Hungarian: "Teller Ede"; January 15, 1908 – September 9, 2003) was a Hungarian-born American theoretical physicist who, although he claimed he did not care for the title, is known colloquially as "the father of the hydrogen bomb". He made numerous contributions to nuclear and molecular physics, spectroscopy (in particular, the Jahn–Teller and Renner–Teller effects) and surface physics. His extension of Enrico Fermi's theory of beta decay, in the form of the so-called Gamow–Teller transitions, provided an important stepping stone in its application, while the Jahn–Teller effect and the Brunauer–Emmett–Teller (BET) theory have retained their original formulation and are still mainstays in physics and chemistry. Teller also made contributions to Thomas–Fermi theory, the precursor of density functional theory, a standard modern tool in the quantum mechanical treatment of complex molecules. In 1953, along with Nicholas Metropolis and Marshall Rosenbluth, Teller co-authored a paper which is a standard starting point for the applications of the Monte Carlo method to statistical mechanics.
Teller immigrated to the United States in the 1930s, and was an early member of the Manhattan Project charged with developing the first atomic bombs. During this time he made a serious push to develop the first fusion-based weapons as well, but these were deferred until after World War II. After his controversial testimony in the security clearance hearing of his former Los Alamos colleague J. Robert Oppenheimer, Teller was ostracized by much of the scientific community. He continued to find support from the U.S. government and military research establishment, particularly for his advocacy for nuclear energy development, a strong nuclear arsenal, and a vigorous nuclear testing program. He was a co-founder of Lawrence Livermore National Laboratory (LLNL), and was both its director and associate director for many years.
In his later years, Teller became especially known for his advocacy of controversial technological solutions to both military and civilian problems, including a plan to excavate an artificial harbor in Alaska using thermonuclear explosive in what was called Project Chariot. He was a vigorous advocate of Reagan's Strategic Defense Initiative. Throughout his life, Teller was known both for his scientific ability and his difficult interpersonal relations and volatile personality, and is considered one of the inspirations for the character Dr. Strangelove in the 1964 movie of the same name.
Early life and education.
Teller was born in Budapest, Hungary (then Austria-Hungary), into a Jewish family in 1908. His parents were Ilona (née Deutsch), a pianist, and Max Teller, an attorney. Despite being raised in a Jewish family, he later on became an agnostic. He developed the ability to speak later than most children but became very interested in numbers, and would calculate large numbers in his head for fun.
He left Hungary in 1926 (partly due to the discriminatory "numerus clausus" rule under Horthy's regime). The political climate and revolutions in Hungary during his youth instilled a lingering animosity for both Communism and Fascism in Teller. When he was a young student, his right foot was severed in a streetcar accident in Munich, requiring him to wear a prosthetic foot and leaving him with a lifelong limp. Werner Heisenberg said that it was the hardiness of Teller's spirit, rather than stoicism, that allowed him to cope so well with the accident. Teller graduated in chemical engineering at the University of Karlsruhe and received his Ph.D. in physics under Werner Heisenberg at the University of Leipzig. Teller's Ph.D. dissertation dealt with one of the first accurate quantum mechanical treatments of the hydrogen molecular ion. In 1930 he befriended Russian physicists George Gamow and Lev Landau. Teller's lifelong friendship with a Czech physicist, George Placzek, was very important for Teller's scientific and philosophical development. It was Placzek who arranged a summer stay in Rome with Enrico Fermi for young Teller, thus orienting his scientific career in nuclear physics.
Teller spent two years at the University of Göttingen, and left in 1933 through the aid of the International Rescue Committee. He went briefly to England, and moved for a year to Copenhagen, where he worked under Niels Bohr. In February 1934, he married Augusta Maria "Mici" (pronounced "Mitzi") Harkanyi, the sister of a longtime friend.
In 1935, thanks to George Gamow's incentive, Teller was invited to the United States to become a Professor of Physics at George Washington University (GWU), where he worked with Gamow until 1941. Prior to the discovery of fission in 1939, Teller was engaged as a theoretical physicist, working in the fields of quantum, molecular, and nuclear physics. In 1941, after becoming a naturalized citizen of the United States, his interest turned to the use of nuclear energy, both fusion and fission.
At GWU, Teller predicted the Jahn–Teller effect (1937), which distorts molecules in certain situations; this affects the chemical reactions of metals, and in particular the coloration of certain metallic dyes. Teller and Hermann Arthur Jahn analyzed it as a piece of purely mathematical physics. In collaboration with Brunauer and Emmet, Teller also made an important contribution to surface physics and chemistry: the so-called Brunauer–Emmett–Teller (BET) isotherm.
When World War II began, Teller wanted to contribute to the war effort. On the advice of the well-known Caltech aerodynamicist and fellow Hungarian émigré Theodore von Kármán, Teller collaborated with his friend Hans Bethe in developing a theory of shock-wave propagation. In later years, their explanation of the behavior of the gas behind such a wave proved valuable to scientists who were studying missile re-entry.
Manhattan Project.
In 1942, Teller was invited to be part of Robert Oppenheimer's summer planning seminar at the University of California, Berkeley for the origins of the Manhattan Project, the Allied effort to develop the first nuclear weapons. A few weeks earlier, Teller had been meeting with his friend and colleague Enrico Fermi about the prospects of atomic warfare, and Fermi had nonchalantly suggested that perhaps a weapon based on nuclear fission could be used to set off an even larger nuclear fusion reaction. Even though he initially explained to Fermi why he thought the idea would not work, Teller was fascinated by the possibility and was quickly bored with the idea of "just" an atomic bomb (even though this was not yet anywhere near completion). At the Berkeley session, Teller diverted discussion from the fission weapon to the possibility of a fusion weapon—what he called the "Super" (an early version of what was later to be known as a hydrogen bomb).
On December 6, 1941, the United States had begun development of the atomic bomb, under the supervision of Arthur Compton, chairman of the University of Chicago physics department, who coordinated uranium research with Columbia University, Princeton University, University of Chicago, and University of California, Berkeley. Eventually Compton transferred the Columbia and Princeton scientists to the Metallurgical Laboratory at Chicago, and Enrico Fermi moved in at the end of April 1942 and the construction of Chicago Pile 1 began. Teller was left behind at first, but then called to Chicago two months later. In early 1943, the Los Alamos laboratory was built to design an atomic bomb under the supervision of Oppenheimer in Los Alamos, New Mexico. Teller moved there in April 1943.
Teller became part of the Theoretical Physics division at the then-secret Los Alamos laboratory during the war, and continued to push his ideas for a fusion weapon even though it had been put on a low priority during the war (as the creation of a fission weapon was proving to be difficult enough by itself). Because of his interest in the H-bomb, and his frustration at having been passed over for director of the theoretical division (the job was instead given to Hans Bethe), Teller refused to engage in the calculations for the implosion mechanism of the fission bomb. This caused tensions with other researchers, as additional scientists had to be employed to do that work—including Klaus Fuchs, who was later revealed to be a Soviet spy. Apparently, Teller managed to also irk his neighbors by playing the piano late in the night. However, Teller made valuable contributions to bomb research, especially in the elucidation of the implosion mechanism; he is believed to have been the first to suggest the imploding design that was eventually successful with the Trinity test explosion, a design that despite becoming known as a "Christy pit" (after physicist Robert F. Christy, who made the solid pit design a reality), was initially proposed by Teller.
He also was one of the few scientists to actually watch (with eye protection) the first test detonation in July 1945, rather than follow orders to lie on the ground with backs turned. He later said that the atomic flash "was as if I had pulled open the curtain in a dark room and broad daylight streamed in."
Decision to drop the bombs.
In the days before and after the first demonstration of a nuclear weapon, the Trinity test in July 1945, his fellow Hungarian Leo Szilard circulated the Szilard petition that argued that a demonstration to the Japanese of the new weapon should occur prior to actual use on Japan, and with that hopefully the weapons would never be used on people. In response to Szilard's petition, Teller consulted his friend Robert J. Oppenheimer. Teller believed that Oppenheimer was a natural leader and could help him with such a formidable political problem. Oppenheimer reassured Teller that the nation’s fate should be left to the sensible politicians in Washington. Bolstered by Oppenheimer’s influence, he decided to not sign the petition.
Teller therefore penned a letter in response to Szilard that read...I am not really convinced of your objections. I do not feel that there is any chance to outlaw any one weapon. If we have a slim chance of survival, it lies in the possibility to get rid of wars. The more decisive a weapon is the more surely it will be used in any real conflict and no agreements will help.
Our only hope is in getting the facts of our results before the people. This might help to convince everybody that the next war would be fatal. For this purpose actual combat-use might even be the best thing.
On reflection on this letter years later when he was writing his memoirs, Teller wrote.First, Szilard was right. As scientists who worked on producing the bomb, we bore a special responsibility. Second, Oppenheimer was right. We did not know enough about the political situation to have a valid opinion. Third, what we should have done but failed to do was to work out the technical changes required for demonstrating the bomb [very high] over Tokyo and submit that information to President Truman.
Unknown to Teller at the time, four of his colleagues were solicited by the then secret May to June 1945 Interim Committee. It is this organization which ultimately decided on how the new weapons should initially be used. The committee's 4 member "Scientific Panel" was led by Oppenheimer, and concluded immediate military use on Japan was the best option:
The opinions of our scientific colleagues on the initial use of these weapons are not unanimous: they range from the proposal of a purely technical demonstration to that of the military application best designed to induce surrender...Others emphasize the opportunity of saving American lives by immediate military use...We find ourselves closer to these latter views; we can propose no technical demonstration likely to bring an end to the war; we see no acceptable alternative to direct military use.
Teller later learned of Oppenheimer's solicitation, and his role in the Interim Committees decision to drop the bombs, having secretly endorsed an immediate military use of the new weapons. This was contrary to the impression that Teller had received when he had personally asked Oppenheimer about the Szilard petition—that the nation’s fate should be left to the sensible politicians in Washington—following Teller’s discovery of this, his relationship with his advisor began to deteriorate.
Post Manhattan days.
In 1946, Teller participated in a conference in which the properties of thermonuclear fuels such as deuterium and the possible design of a hydrogen bomb were discussed. It was concluded that Teller's assessment of a hydrogen bomb had been too favourable, and that both the quantity of deuterium needed, as well as the radiation losses during deuterium burning, would shed doubt on its workability. Addition of expensive tritium to the thermonuclear mixture would likely lower its ignition temperature, but even so, nobody knew at that time how much tritium would be needed, and whether even tritium addition would encourage heat propagation. At the end of the conference, in spite of opposition by some members such as Robert Serber, Teller submitted an unduly optimistic report in which he said that a hydrogen bomb was feasible, and that further work should be encouraged on its development. Fuchs had also participated in this conference, and transmitted this information to Moscow. The model of Teller's "classical Super" was so uncertain that Oppenheimer would later say that he wished the Russians were building their own hydrogen bomb based on that design, so that it would almost certainly retard their progress on it.
In 1946, Teller left Los Alamos to return to the University of Chicago as a professor and close associate of Enrico Fermi and Maria Mayer.
Hydrogen bomb.
By 1949 Soviet backed Communist governments had already begun seizing control throughout Eastern Europe, forming such puppet states as the Hungarian People's Republic on 20 August 1949, this was Teller's homeland of Hungary, where much of his family still lived.
Following the Soviet Union's first test detonation of an atomic bomb on 29 August 1949, President Truman announced a crash development program for a hydrogen bomb. Teller returned to Los Alamos in 1950 to work on the project. He insisted on involving more theorists, such as Klaus Fuchs; it was Fuchs who together with John von Neumann later claimed to invent compression by means of radiation implosion back in 1946. However many of Teller's prominent colleagues, like Bethe and Oppenheimer, were sure that the project of the H-bomb was technically infeasible and politically undesirable. None of the available designs were yet workable. However Soviet scientists who had worked on their own hydrogen bomb have claimed that they developed it independently.
In 1950, calculations by the Polish mathematician Stanislaw Ulam and his collaborator Cornelius Everett, along with confirmations by Fermi, had shown that not only was Teller's earlier estimate of the quantity of tritium needed for the H-bomb a low one, but that even with higher amounts of tritium, the energy loss in the fusion process would be too great to enable the fusion reaction to propagate. However, in 1951 Teller and Ulam made a breakthrough, and invented a new design, proposed in a classified March 1951 paper, "On Heterocatalytic Detonations I: Hydrodynamic Lenses and Radiation Mirrors", for a practical megaton-range H-bomb. The exact contribution provided respectively from Ulam and Teller to what became known as the Teller–Ulam design is not definitively known in the public domain, and the exact contributions of each and how the final idea was arrived upon has been a point of dispute in both public and classified discussions since the early 1950s.
In an interview with "Scientific American" from 1999, Teller told the reporter:
I contributed; Ulam did not. I'm sorry I had to answer it in this abrupt way. Ulam was rightly dissatisfied with an old approach. He came to me with a part of an idea which I already had worked out and had difficulty getting people to listen to. He was willing to sign a paper. When it then came to defending that paper and really putting work into it, he refused. He said, 'I don't believe in it.'
The issue is controversial. Bethe considered Teller's contribution to the invention of the H-bomb a true innovation as early as 1952, and referred to his work as a "stroke of genius" in 1954. In both cases, however, Bethe emphasized Teller's role as a way of stressing that the development of the H-bomb could not have been hastened by additional support or funding, and Teller greatly disagreed with Bethe's assessment. Other scientists (antagonistic to Teller, such as J. Carson Mark) have claimed that Teller would have never gotten any closer without the assistance of Ulam and others. Ulam himself claimed that Teller only produced a "more generalized" version of Ulam's original design.
The breakthrough—the details of which are still classified—was apparently the separation of the fission and fusion components of the weapons, and to use the X-rays produced by the fission bomb to first compress the fusion fuel (by process known as "radiation implosion") before igniting it. Ulam's idea seems to have been to use mechanical shock from the primary to encourage fusion in the secondary, while Teller quickly realized that X-rays from the primary would do the job much more symmetrically. Some members of the laboratory (J. Carson Mark in particular) later expressed the opinion that the idea to use the x-rays would have eventually occurred to anyone working on the physical processes involved, and that the obvious reason why Teller thought of it right away was because he was already working on the "Greenhouse" tests for the spring of 1951, in which the effect of x-rays from a fission bomb on a mixture of deuterium and tritium was going to be investigated.
Whatever the actual components of the so-called Teller–Ulam design and the respective contributions of those who worked on it, after it was proposed it was immediately seen by the scientists working on the project as the answer which had been so long sought. Those who previously had doubted whether a fission-fusion bomb would be feasible at all were converted into believing that it was only a matter of time before both the USA and the USSR had developed multi-megaton weapons. Even Oppenheimer, who was originally opposed to the project, called the idea "technically sweet."
Though he had helped to come up with the design and had been a long-time proponent of the concept, Teller was not chosen to head the development project (his reputation of a thorny personality likely played a role in this). In 1952 he left Los Alamos and joined the newly established Livermore branch of the University of California Radiation Laboratory, which had been created largely through his urging. After the detonation of "Ivy Mike", the first thermonuclear weapon to utilize the Teller–Ulam configuration, on November 1, 1952, Teller became known in the press as the "father of the hydrogen bomb." Teller himself refrained from attending the test—he claimed not to feel welcome at the Pacific Proving Grounds—and instead saw its results on a seismograph in the basement of a hall in Berkeley.
There was an opinion that by analyzing the fallout from this test, the Soviets (led in their H-bomb work by Andrei Sakharov) could have deciphered the new American design. However, this was later denied by the Soviet bomb researchers. Because of official secrecy, little information about the bomb's development was released by the government, and press reports often attributed the entire weapon's design and development to Teller and his new Livermore Laboratory (when it was actually developed by Los Alamos).
Many of Teller's colleagues were irritated that he seemed to enjoy taking full credit for something he had only a part in, and in response, with encouragement from Enrico Fermi, Teller authored an article titled "The Work of Many People," which appeared in "Science" magazine in February 1955, emphasizing that he was not alone in the weapon's development. He would later write in his memoirs that he had told a "white lie" in the 1955 article in order to "soothe ruffled feelings", and claimed full credit for the invention.
Teller was known for getting engrossed in projects which were theoretically interesting but practically unfeasible (the classic "Super" was one such project.) About his work on the hydrogen bomb, Bethe said:
Nobody will blame Teller because the calculations of 1946 were wrong, especially because adequate computing machines were not available at Los Alamos. But he was blamed at Los Alamos for leading the laboratory, and indeed the whole country, into an adventurous programme on the basis of calculations, which he himself must have known to have been very incomplete.
During the Manhattan Project, Teller also advocated the development of a bomb using uranium hydride, which many of his fellow theorists said would be unlikely to work. At Livermore, Teller continued work on the hydride bomb, and the result was a dud. Ulam once wrote to a colleague about an idea he had shared with Teller: "Edward is full of enthusiasm about these possibilities; this is perhaps an indication they will not work." Fermi once said that Teller was the only monomaniac he knew who had several manias.
Carey Sublette of Nuclear Weapon Archive argues that Ulam came up with the radiation implosion compression design of thermonuclear weapons, but that on the other hand Teller has gotten little credit for being the first to propose fusion boosting in 1945, which is essential for miniaturization and reliability and is used in all of today's nuclear weapons.
Oppenheimer controversy.
Teller became controversial in 1954 when he testified against J. Robert Oppenheimer, a former head of Los Alamos and an advisor to the Atomic Energy Commission, at Oppenheimer's security clearance hearing. Teller had clashed with Oppenheimer many times at Los Alamos over issues relating both to fission and fusion research, and during Oppenheimer's trial he was the only member of the scientific community to state that Oppenheimer should not be granted security clearance.
Asked at the hearing by AEC attorney Roger Robb whether he was planning "to suggest that Dr. Oppenheimer is disloyal to the United States", Teller replied that:
However, he was immediately asked whether he believed that Oppenheimer was a "security risk", to which he testified:
Teller also testified that Oppenheimer's opinion about the thermonuclear program seemed to be based more on the scientific feasibility of the weapon than anything else. He additionally testified that Oppenheimer's direction of Los Alamos was "a very outstanding achievement" both as a scientist and an administrator, lauding his "very quick mind" and that he made "just a most wonderful and excellent director."
After this, however, he detailed ways in which he felt that Oppenheimer had hindered his efforts towards an active thermonuclear development program, and at length criticized Oppenheimer's decisions not to invest more work onto the question at different points in his career, saying:
By recasting a difference of judgment over the merits of the early work on the hydrogen bomb project into a matter of a security risk, Teller effectively damned Oppenheimer in a field where security was necessarily of paramount concern. Teller's testimony thereby rendered Oppenheimer vulnerable to charges by a Congressional aide that he was a Soviet spy, which resulted in the destruction of Oppenheimer's career.
Oppenheimer's security clearance was revoked after the hearings. Most of Teller's former colleagues disapproved of his testimony and he became ostracized by much of the scientific community. After the fact, Teller consistently denied that he was intending to damn Oppenheimer, and even claimed that he was attempting to exonerate him. Documentary evidence has suggested that this was likely not the case, however. Six days before the testimony, Teller met with an AEC liaison officer and suggested "deepening the charges" in his testimony. It has been suggested that Teller's testimony against Oppenheimer was an attempt to remove Oppenheimer from power so that Teller could become the leader of the American nuclear scientist community.
Teller always insisted that his testimony had not significantly harmed Oppenheimer. In 2002, Teller contended that Oppenheimer was "not destroyed" by the security hearing but "no longer asked to assist in policy matters." He claimed his words were an overreaction, because he had only just learned of Oppenheimer's failure to immediately report an approach by Haakon Chevalier, who had approached Oppenheimer to help the Russians. Teller said that, in hindsight, he would have responded differently.
Prior to the Oppenheimer controversy, Teller maintained a friendly relationship with Oppenheimer. When Leó Szilárd asked Teller to help circulate a petition that would discourage the United States from using an atomic bomb against Japan unless Japan was made fully aware of the possibility of such an attack, he consulted Oppenheimer’s wisdom. Teller believed that Oppenheimer was a natural leader and could help him with such a formidable political problem. Oppenheimer reassured Teller that the nation’s fate should be left to the sensible politicians in Washington. Bolstered by Oppenheimer’s influence, he decided to not sign the petition. However, Teller learned soon after his meeting that Oppenheimer conversely endorsed a political use of the super bomb. Following Teller’s discovery, his relationship with his advisor began to deteriorate.
Historian Richard Rhodes states that in his opinion it was already a foregone conclusion that Oppenheimer would have his security clearance revoked by then AEC head Lewis Strauss, regardless of Teller's testimony. However as Teller's testimony was the most damning, he was singled out and blamed for the hearing's ruling, losing friends due to it, such as Robert Christy who refused to shake his hand in one infamous incident. This was emblematic of his later treatment which resulted in him being forced into the role of an outcast of the physics community and thus leaving him little choice but to align himself with industrialists.
US Government work and political advocacy.
After the Oppenheimer controversy, Teller became ostracized by much of the scientific community, but was still quite welcome in the government and military science circles. Along with his traditional advocacy for nuclear energy development, a strong nuclear arsenal, and a vigorous nuclear testing program, he had helped to develop nuclear reactor safety standards as the chair of the Reactor Safeguard Committee of the AEC in the late 1940s, and in the late 1950s headed an effort at General Atomics which designed research reactors in which a nuclear meltdown would be impossible (the TRIGA "Training, Research, Isotopes, General Atomic") which has been built and used at almost a hundreds hospitals and universities worldwide for Medical isotope production and research assistance.
Teller promoted increased defense spending to counter the perceived Soviet missile threat. He was a signatory to the 1958 report by the military sub-panel of the Rockefeller Brothers funded Special Studies Project, which called for a $3 billion annual increase in America's military budget.
In 1956 he attended the Project Nobska anti-submarine warfare conference, where discussion ranged from oceanography to nuclear weapons. In the course of discussing a small nuclear warhead for the Mark 45 torpedo, he started a discussion on the possibility of developing a physically small one-megaton nuclear warhead for the Polaris missile. His counterpart in the discussion, J. Carson Mark of Los Alamos National Laboratory, at first insisted it could not be done. However, Dr. Mark eventually stated that a half-megaton warhead of small enough size could be developed. This yield, roughly thirty times that of the Hiroshima bomb, was enough for Chief of Naval Operations Admiral Arleigh Burke, who was present in person, and Navy strategic missile development shifted from Jupiter to Polaris by the end of the year.
He was Director of the Lawrence Livermore National Laboratory (1958–1960), which he helped to found (along with Ernest O. Lawrence), and after that he continued as an Associate Director. He chaired the committee that founded the Space Sciences Laboratory at Berkeley. He also served concurrently as a Professor of Physics at the University of California, Berkeley. He was a tireless advocate of a strong nuclear program and argued for continued testing and development—in fact, he stepped down from the directorship of Livermore so that he could better lobby against the proposed test ban. He testified against the test ban both before Congress as well as on television.
Teller established the Department of Applied Science at the University of California, Davis and LLNL in 1963, which holds the Edward Teller endowed professorship in his honor. In 1975 he retired from both the lab and Berkeley, and was named Director Emeritus of the Livermore Laboratory and appointed Senior Research Fellow at the Hoover Institution. In 1983, he spoke at "The Thomas Jefferson School", a conference of intellectuals discussing Objectivism organized by economist Professor George Reisman, where he received a standing ovation. After the fall of communism in Hungary in 1989, he made several visits to his country of origin, and paid careful attention to the political changes there.
Global Climate Change.
Teller was one of the first prominent people to raise the danger of climate change driven by the burning of fossil fuels. At an address to the membership of the American Chemical Society in December 1957, Teller warned that the large amount of carbon-based fuel that had been burnt since the mid-19th century was increasing the concentration of carbon dioxide in the atmosphere, which would (as a contemporary account of his comments summarized) "act in the same way as a greenhouse and will raise the temperature at the surface", and that he had calculated that if the concentration of carbon dioxide in the atmosphere reached 10% "an appreciable part of the polar ice might melt."
Operation Plowshare and Project Chariot.
Teller was one of the strongest and best-known advocates for investigating non-military uses of nuclear explosives, which the United States explored under Operation Plowshare. One of the most controversial projects he proposed was a plan to use a multi-megaton hydrogen bomb to dig a deep-water harbor more than a mile long and half a mile wide to use for shipment of resources from coal and oil fields through Point Hope, Alaska. The Atomic Energy Commission accepted Teller's proposal in 1958 and it was designated Project Chariot. While the AEC was scouting out the Alaskan site, and having withdrawn the land from the public domain, Teller publicly advocated the economic benefits of the plan, but was unable to convince local government leaders that the plan was financially viable.
Other scientists criticized the project as being potentially unsafe for the local wildlife and the Inupiat people living near the designated area, who were not officially told of the plan until March 1960. Additionally, it turned out that the harbor would be ice-bound for nine months out of the year. In the end, due to the financial infeasibility of the project and the concerns over radiation-related health issues, the project was cancelled in 1962.
A related experiment which also had Teller's endorsement was a plan to extract oil from the tar sands in northern Alberta with nuclear explosions, titled Project Oilsands. The plan actually received the endorsement of the Alberta government, but was rejected by the Government of Canada under Prime Minister John Diefenbaker, who was opposed to having any nuclear weapons in Canada, although Canada had nuclear weapons, from a US nuclear sharing agreement, from 1963 to 1984.
Nuclear technology and Israel.
For some twenty years, Teller advised Israel on nuclear matters in general, and on the building of a hydrogen bomb in particular. In 1952, Teller and Oppenheimer had a long meeting with David Ben-Gurion in Tel Aviv, telling him that the best way to accumulate plutonium was to burn natural uranium in a nuclear reactor. Starting in 1964, a connection between Teller and Israel was made by the physicist Yuval Neeman, who had similar political views. Between 1964 and 1967, Teller visited Israel six times, lecturing at Tel Aviv University, and advising the chiefs of Israel's scientific-security circle as well as prime ministers and cabinet members.
At each of his talks with members of the Israeli security establishment's highest levels, he would make them swear that they would never be tempted into signing the Nuclear Non-Proliferation Treaty. In 1967 when the Israeli nuclear program was nearing completion, Teller informed Neeman that he was going to tell the CIA that Israel had built nuclear weapons and explain that it was justified by the background of the Six-Day War. After Neeman cleared it with Prime Minister Levi Eshkol, Teller briefed the head of the CIA's Office of Science and Technology, Carl Duckett. It took a year for Teller to convince the CIA that Israel had obtained nuclear capability; the information then went through CIA Director Richard Helms and then to the US president at that time, Lyndon B. Johnson. Teller also persuaded them to end the American attempts to inspect the Negev Nuclear Research Center in Dimona. Teller's personal opinion became factual assertion, when in 1976 Carl Duckett testified in Congress before the Nuclear Regulatory Commission, that after receiving information from "American scientist", he drafted a National Intelligence Estimate (NIE) on Israel's nuclear capability.
In the 1980s, Teller again visited Israel to advise the Israeli government on building a nuclear reactor. Three decades later, Teller confirmed that it was during his visits that he concluded that Israel was in possession of nuclear weapons. After conveying the matter to the U.S. government, Teller reportedly said: "They [Israeli] have it, and they were clever enough to trust their research and not to test, they know that to test would get them into trouble."
Three Mile Island.
Teller suffered a heart attack in 1979, and many observers described him as blaming it on Jane Fonda: She had starred in "The China Syndrome", which depicted a fictional reactor accident and was released less than two weeks before the Three Mile Island accident. She spoke out against nuclear power while promoting the film. After the accident, Teller acted quickly to lobby in favor of nuclear energy, testifying to its safety and reliability, and soon after one flurry of activity suffered the attack. He signed a two-page-spread ad in the July 31, 1979, "Wall Street Journal" with the headline "I was the only victim of Three-Mile Island". It opened with:
On May 7, a few weeks after the accident at Three-Mile Island, I was in Washington. I was there to refute some of that propaganda that Ralph Nader, Jane Fonda and their kind are spewing to the news media in their attempt to frighten people away from nuclear power. I am 71 years old, and I was working 20 hours a day. The strain was too much. The next day, I suffered a heart attack. You might say that I was the only one whose health was affected by that reactor near Harrisburg. No, that would be wrong. It was not the reactor. It was Jane Fonda. Reactors are not dangerous.
The next day, "The New York Times" ran an editorial criticizing the ad, noting that it was sponsored by Dresser Industries, the firm that had manufactured one of the defective valves that contributed to the Three Mile Island accident.
Strategic Defense Initiative.
In the 1980s, Teller began a strong campaign for what was later called the Strategic Defense Initiative (SDI), derided by critics as "Star Wars," the concept of using ground and satellite-based lasers, particle beams and missiles to destroy incoming Soviet ICBMs. Teller lobbied with government agencies—and got the approval of President Ronald Reagan—for a plan to develop a system using elaborate satellites which used atomic weapons to fire X-ray lasers at incoming missiles—as part of a broader scientific research program into defenses against nuclear weapons. Scandal erupted when Teller (and his associate Lowell Wood) were accused of deliberately overselling the program and perhaps had encouraged the dismissal of a laboratory director (Roy Woodruff) who had attempted to correct the error. His claims led to a joke which circulated in the scientific community, that a new unit of unfounded optimism was designated as the teller; one teller was so large that most events had to be measured in nanotellers or picotellers. Many prominent scientists argued that the system was futile. Bethe, along with IBM physicist Richard Garwin and Cornell University colleague Kurt Gottfried, wrote an article in "Scientific American" which analyzed the system and concluded that any putative enemy could disable such a system by the use of suitable decoys. The project's funding was eventually scaled back.
Many scientists opposed strategic defense on moral or political rather than purely technical grounds. They argued that, even if an effective system could be produced, it would undermine the system of Mutually Assured Destruction (MAD) that had prevented all-out war between the western democracies and the communist bloc. An effective defense, they contended, would make such a war "winnable" and therefore more likely.
Despite (or perhaps because of) his hawkish reputation, Teller made a public point of noting that he regretted the use of the first atomic bombs on civilian cities during World War II. He further claimed that before the bombing of Hiroshima he had indeed lobbied Oppenheimer to use the weapons first in a "demonstration" which could be witnessed by the Japanese high-command and citizenry before using them to inflict thousands of deaths.
However contained in a 1987 book by Teller, a letter dated July 2, 1945 from Teller to Leó Szilárd states in part:
...Our only hope is in getting the facts of our results before the people. This might help convince everybody the next war would be fatal. For this purpose, actual combat-use might even be the best thing.
In 1990, the historian Barton Bernstein argued that it is an "unconvincing claim" by Teller that he was a "covert dissenter" to the use of the weapon. In his 2001 "Memoirs", Teller claims that he did lobby Oppenheimer, but that Oppenheimer had convinced him that he should take no action and that the scientists should leave military questions in the hands of the military; Teller claims he was not aware that Oppenheimer and other scientists were being consulted as to the actual use of the weapon and implies that Oppenheimer was being hypocritical.
Teller had used this quasi-anti-nuclear weapons stance (he would say that he believed nuclear weapons to be unfortunate, but that the arms race was unavoidable due to the intractable nature of Communism) to promote technologies such as SDI, arguing that they were needed to make sure that nuclear weapons could never be used again.
In 1987 he published a book supporting civil defense and active protection systems such as SDI which was titled "Better a shield than a sword" and his views on the role of lasers in SDI, as disclosed in live panel discussions, were published, and are available, in two 1986-7 laser conference proceedings.
Asteroid impact avoidance.
At a 1995 meeting at Lawrence Livermore National Laboratory (LLNL) in Calif., Edward Teller proposed to a collective of U.S. and Russian ex-Cold War weapons designers and space engineers the use of nuclear fusion warheads in diverting the paths of extinction event class asteroids. Edward Teller suggested the creation of an orbital platform for faster missile delivery. He further suggested the need for nuclear weapons more powerful than the Tsar Bomba for this purpose.
Death and legacy.
Teller died in Stanford, California on September 9, 2003, at the age of 95.
A wish for his 100th birthday, made around the time of his 90th, was for Lawrence Livermore's scientists to give him "excellent predictions-calculations and experiments-about the interiors of the planets".
In his early career, Teller made contributions to nuclear and molecular physics, spectroscopy (the Jahn–Teller and Renner–Teller effects), and surface physics. His extension of Fermi's theory of beta decay (in the form of the so-called Gamow–Teller transitions) provided an important stepping stone in the applications of this theory. The Jahn–Teller effect and the BET theory have retained their original formulation and are still mainstays in physics and chemistry. Teller also made contributions to Thomas–Fermi theory, the precursor of density functional theory, a standard modern tool in the quantum mechanical treatment of complex molecules. In 1953, along with Nicholas Metropolis and Marshall Rosenbluth, Teller co-authored a paper which is a standard starting point for the applications of the Monte Carlo method to statistical mechanics.
Teller's vigorous advocacy for strength through nuclear weapons, especially when so many of his wartime colleagues later expressed regret about the arms race, made him an easy target for the "mad scientist" stereotype. In 1991 he was awarded one of the first Ig Nobel Prizes for Peace in recognition of his "lifelong efforts to change the meaning of peace as we know it". He was also rumored to be one of the inspirations for the character of Dr. Strangelove in Stanley Kubrick's 1964 satirical film of the same name (others speculated to be RAND theorist Herman Kahn, rocket scientist Wernher von Braun, and Secretary of Defense Robert McNamara). In the aforementioned "Scientific American" interview from 1999, he was reported as having bristled at the question: "My name is not Strangelove. I don't know about Strangelove. I'm not interested in Strangelove. What else can I say?... Look. Say it three times more, and I throw you out of this office."
Nobel Prize winning physicist Isidor I. Rabi once suggested that "It would have been a better world without Teller." In addition, Teller's false claims that Stanislaw Ulam made no significant contribution to the development of the hydrogen bomb (despite Ulam's key insights of using compression and staging elements to generate the thermonuclear reaction) and his personal attacks on Oppenheimer caused even greater animosity within the general physics community towards Teller.
In 1986, he was awarded the United States Military Academy's Sylvanus Thayer Award. He was a fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the American Nuclear Society. Among the honors he received were the Albert Einstein Award, the Enrico Fermi Award, the and the National Medal of Science. He was also named as part of the group of "U.S. Scientists" who were "Time" magazine's People of the Year in 1960, and an asteroid, 5006 Teller, is named after him. He was awarded with the Presidential Medal of Freedom by President George W. Bush less than two months before his death. His final paper, published posthumously, advocated the construction of a prototype liquid fluoride thorium reactor.
Sources.
Herken (2002) is the source where not otherwise indicated.
Further reading.
Written by Teller
Books about Teller
References to Teller in Other Writings

</doc>
<doc id="37784" url="http://en.wikipedia.org/wiki?curid=37784" title="Media of Venezuela">
Media of Venezuela

Media of Venezuela comprise the mass and niche news and information communications infrastructure of Venezuela. Thus, the media of Venezuela consists of several different types of communications media: television, radio, newspapers, magazines, cinema, and Internet-based news outlets and websites. Venezuela also has a strong music industry and arts scene.
Since 2003, Freedom House has ranked Venezuela as "not free" when it comes to press freedom. According to Freedom House in their "Freedom of the Press 2014" report, the media in Venezuela is classified as "not free". Freedom House explained that Venezuela's freedom of press had declined during Hugo Chavez's "15 years in power", stating that the Venezuelan government's relation to the media "led to sharp declines in press freedom and a vastly expanded government information apparatus".
According to the Ministry of Popular Power for Communication and Information of the Venezuelan government, 70% of media in Venezuela is private, 5% is government owned and 25% is community media.
Social networking is an important way of communication for the Venezuelan people, and is being established as an alternative means of information to mainstream media. According to state news, the analytical company comScore stated that the audience of Venezuela in Twitter increased from 4.8% to 19.0% after president Hugo Chávez created an account there. The article named it as just another way in which the Bolivarian Revolution is increasing participation. Venezuela now has the 4th highest percentage of Twitter users.
Overview.
Most of Venezuela's mass media are privately operated and derive most of their revenues from advertising, subscriptions, and sale or distribution of copyrighted materials. A small proportion of the Venezuelan television, newspaper, and radio markets is controlled by state-owned outlets. The government has its own news agency, "Agencia Bolivariana de Noticias".
The main private television networks are RCTV; Televen; Venevisión; Globovisión. State television includes Venezolana de Televisión, TVes, ViVe (cultural network) and teleSUR (Caracas-based pan-Latin American channel sponsored by seven Latin American states). There are also local community-run television stations such as Televisora Comunitaria del Oeste de Caracas (CatiaTVe). The Venezuelan government also provides funding to Avila TV, Buena TV and Asamblea Nacional TV (ANTV).
The major Venezuelan newspapers are "El Nacional, Últimas Noticias" and "El Universal"; all of which are private companies and based in Caracas. There are also many regional newspapers.
History.
Venezuela was the ninth country in the world to have television, introduced in 1952 by Marcos Pérez Jiménez. By 1963 a quarter of Venezuelan households had television; a figure rising to 45% by 1969 and 85% by 1982.
During the period when the political system was dominated by Accion Democratica (AD) and COPEI (1958–1998), after the closure of Accion Democratica's "La Republica" in 1969, none of the major newspapers or broadcasters were affiliated with a political party. However because of the importance of the two main parties, most newspapers had regular columnists or editorialists presenting the views of AD and COPEI on the issues of the day. During this period, both parties promised Congressional seats to publishers in exchange for favourable coverage. In 1983, a deal with Jaime Lusinchi's presidential campaign resulted in four representatives of the Bloque DeArmas publishing group being elected to Congress on AD slates. A similar deal had been struck by COPEI in 1968 on behalf of Rafael Caldera, promising Miguel Angel Capriles a Senate seat and the right to designate eleven Congressional candidates.
Post-1998.
After the 1998 election of Hugo Chavez, the Venezuelan press "failed miserably in their duty to provide information that their fellow citizens needed to navigate the storms of Venezuelan politics under Chavez. Instead, media owners and their editors used the news - print and broadcast - to spearhead an opposition movement against Chavez." The programme of Bolivarian Missions was (until 2005) "virtually invisible in the mainstream press". Encouraged by verbal attacks by Chavez and other officials, editors "began routinely winking at copy containing unfounded speculation, rumor, and unchecked facts." This contributed to a polarization such that for a time reporters were regularly attacked in the street by Chavez supporters with bottles and sticks. According to a political reporter for "El Nacional" speaking in 2005, "the common attitude has been that we can leave aside ethics and the rules of journalism". Alonso Moleiro said that "Reporters bought the argument that you have to put journalistic standards aside, that if we don't get rid of Chavez, we will have communism and Fidelismo." The head of the Institute for Press and Society in Venezuela said that "here you had the convergence in the media of two things: grave journalistic errors - to the extreme of silencing information on the most important news events - and taking political positions to the extreme of advocating a nondemocratic, insurrectional path." After the 2002 Venezuelan coup d'état attempt, in which the media played a significant role, there was a change in editorial policy of the major newspapers, with a wider mix of opposition, pro-Chavez and independent commentators. The generally non-partisan "Últimas Noticias" gained circulation at the expense of "El Nacional" and "El Universal", which remained more associated with the opposition. Television networks also moderated their tone, with several of the opposition talk shows with the most extreme rhetoric, including talk of violence against Chavez and his followers, taken off the air.
In 2009 the government reviewed the broadcast licences of hundreds of radio and television stations, and declared many to have been operating without a licence or without having paid the appropriate regulatory fees. As a result over 60 radio stations were closed. The government said the frequencies would be reallocated to community media, and passed a law limiting ownership of radio and television licences to three per private owner. This was aimed at tackling what it called "media latifundios", with 27 families controlling a third of radio and television.
Television.
Television in Venezuela began in 1952 when the dictator Marcos Pérez Jiménez launched the state channel Televisora Nacional, making Venezuela the ninth country in the world to have television. By 1963 a quarter of Venezuelan households had television; a figure rising to 45% by 1969 and 85% by 1982. Telenovelas are popular in Venezuela, and some Venezuelan productions (such as 1992's "Cara Sucia") are distributed internationally. Perhaps the best known television show internationally is however President Hugo Chávez' weekly talkshow "Aló Presidente", which began in 1999.
The main private television networks are RCTV (launched 1953, losing its terrestrial broadcast licence 2007); Venevisión (1961); Televen (1988); Globovisión (1994). State television includes Venezolana de Televisión (1964 as a private channel, nationalised in 1974), TVes (2007), ViVe (cultural network, 2003) and teleSUR (Caracas-based pan-Latin American channel sponsored by seven Latin American states, 2005). There are also local community-run television stations such as Televisora Comunitaria del Oeste de Caracas (CatiaTVe, 2001) and a range of regional networks such as Zuliana de Televisión. The Venezuelan government also provides funding to Avila TV (2006), Buena TV and Asamblea Nacional TV (ANTV, network of the National Assembly of Venezuela, 2005).
In recent years, the audience share of private terrestrial broadcasters has fallen from around 80% in 2000 to around 60% in 2010, with the bulk of the lost audience going to cable and satellite broadcasters, which increased audience share from around 17% to around 33% over the same period. State television's low share, of around 2%, increased to 5%, although the government also makes regular use of "cadenas" (mandatory interruptions on all channels to show government broadcasts).
TeleSUR.
TeleSUR was founded in 2005 to provide 24-hour news and cultural programming that reflects the diversity of the Latin American region. It is owned and paid for by several countries: Venezuela (which provides 54% of the network's budget), Argentina (15%), Cuba (14%), Uruguay (7%), Bolivia (5%) and Nicaragua (5%). TeleSUR has regional offices in Caracas, Bogotá, Brasília, Buenos Aires, Mexico City, Havana, La Paz, Lima, Quito, Managua and Washington DC.
Internet.
Move of journalists to the web.
In an article by "El Tiempo (Anzoátegui)", journalists explain reasons of why they have moved from traditional media outlets such as newspapers and organizations to websites. Journalists explained how after allegations of censorship after the sale of Cadena Capriles organization and "El Universal", journalists have found refugee on the Internet. Some journalists have even created their own websites, though with some difficulties.
Newspapers.
Large newspaper organizations include El Universal (Caracas) and El Nacional (Caracas). In 2014, newspapers throughout the country have reported shortages of paper and have depleted their reserves; resulting in cuts of services for customers. Despite this, the Venezuelan government has announced the creation of two new state newspapers in September 2014. In October 2014, the Vice President of The Commission of Propaganda, Agitation and Communication of the PSUV, Ernesto Villegas also announced the Venezuelan government's acquisition of "Diario Vea", where President of the National Assembly Diosdado Cabello commented on the acquisition stating "having our own media is one of the goals for this year. God willing, tin the following days we could have a newspaper, for which we are already doing everything relevant to occur."
Verbal attacks on media.
In the "Annual Report of the Inter-American Commission on Human Rights 2013", the Organization of American States' Inter-American Commission on Human Rights said that it had received information about "persistent use of stigmatizing declarations by public officials to discredit journalists, communicators and members of the opposition who express ideas, opinions or disseminate information contrary to the interests of the Venezuelan Government". President Maduro has frequently accused the media of “psychological war”, “media terrorism”, being “ultra-rightwing” and "ignorant, perverse and manipulators”. President Maduro had also called the newspaper "El Nacional", “El Nazi–onal” and said that “[b]uying El Nacional is like buying muriatic acid and breakfasting on muriatic acid every day. That’s right, it’s poison! I don’t buy it, I don’t recommend that anyone buy it either, really; not even the people of the opposition because if they do they will make a bad impression.” The Inter-American Commission on Human Rights stressed how important it was for “creating a climate of respect and tolerance for all ideas and opinions” in Venezuela.
During treatment of Hugo Chavez's cancer.
Employees of "Globovision" filed complaints to the Public Prosecutor about "supposed threats by representatives of the Executive Branch against the media" and that "[s]tatements by senior officials constitute an official discourse that incites physical and verbal attacks on the employees of Globovisión, and guarantees impunity for the aggressors”. Nicolas Maduro used harsh accusations on media organizations who were reporting on the health of Hugo Chávez calling them “ultra-rightwing”, saying that they "“have an absolutely wretched soul, absolutely wretched, and answer to anti-patriotic plans" and that they are "a very venomous minority of that ultra-right that never stops in its attack against President Chávez". President Maduro also accused the newspapers "El Universal" and "El Nacional" of “media terrorism” and a “psychological war”. Diosdado Cabello, The President of the National Assembly, said that the private media are "“the enemies of the homeland, of the people, of the Revolution, of the Constitution” and that "encouraging 
activities of this type because it might backfire […] and in the face of these media who are going with the ruin of the peace in this country, with the destruction of the peace of this country, I’m going to tell them: the day that something happens here, the people know what they are going to grab on to – and I’m almost certain that the rightwing media are not going to go without visits from the people. And this is not threats, I am just trying to interpret the reality of a people that is tired, that is sick and tired of being subjected and harassed, every day, to a thousand pressures by the rightwing media with their lies".
After the 2013 presidential elections.
President Maduro said that the time had come for media organizations to show "“who they are with […] with the homeland, with peace, with 
the people, or are they going to be on the side of fascism once again". President Maduro also made several verbal attacks at the time against the media saying they “are sadists of journalism and communication” and that “they celebrate [with] the feast of death”.
2013 Uribana jail riot.
After the government had already announced the plans of searching a jail in Uribana, Minister of Popular Power for Penitentiary Services, Iris Varela, blamed "Globovisión" and "El Impulso" for attacks on authorities. She said, “[W]e were surprised at the announcement of the search by the privately held Globovisión network, the social networks and the webpage of newspaper El Impulso, which undoubtedly constituted a detonator for the violence, as shown by the beginning of a mutiny within the Penitentiary Center hours later, during which the gang leaders attacked members of the National Guard, resulting in an unfortunate number of casualties”.
Releasing private information.
In 2014, "Diario Las Americas" reported that the Venezuelan news website Noticias24 had sent messages to current and formal members of the Venezuelan intelligence agency SEBIN, releasing "personal records of citizens who frequent the forums portal journalistic institution with critical views about government performance Nicolas Maduro". The director of "Noticias24", Frank Prada, sent screenshots of the critical comments to SEBIN and to former director and now Minister of Interior and Justice, Miguel Rodríguez Torres. It was alleged by "Diario Las Americas" that since the Venezuelan government knew the users IP address, they would be able to block future critical comments in the future with the "state-owned CANTV" and know the location of the user.
Media Freedom.
According to Freedom House in their "Freedom of the Press 2014" report, the media in Venezuela is classified as "not free". Venezuela's press freedom was also ranked low, with a ranking of 171 out of 197 countries. Freedom House explained that Venezuela's freedom of press had declined during Hugo Chavez's "15 years in power", stating that the Venezuelan government's relation to the media "led to sharp declines in press freedom and a vastly expanded government information apparatus". After the Venezuelan National Telecommunications Commission (CONATEL) implemented the "Resorte Law" claiming that “democratic security" was in danger and imposed heavy fines on private media, the media responded by "softening their coverage of national and international news". This law also requires all media outlets to air live government broadcasts (cadenas) "which the government issues frequently, at random, and without regard for regular programming."
In the "Annual Report of the Inter-American Commission on Human Rights 2013", the Organization of American States' Inter-American Commission on Human Rights stated that "the "Penal Code of Venezuela", the "Organic Code of Military Justice", and the "Law on Social Responsibility in Radio, Television and Electronic Media (Resorte Law)" all have sections that are not compatible with Inter-American standards on freedom of expression". They also reported that the media had been attacked by government authorities. There are reports of authorities destroying work and equipment belonging to the media, arrests and interrogations of media correspondents, reporters being held in prison being "civil rebellion" after expressing opinion, journalists being accused of being spies and multiple reports of arrests of journalists after reporting on alleged election irregularities. Media workers have also been physically and verbally assaulted by government authorities, had received death threats against them and their families and had been intimidated by both government supporters and authorities following the death of Hugo Chavez. Cartoonists, journalists, writers and artists were sent death threats through "phone calls, text messages to their mobile telephones, and through social network Twitter". During a radio interview, Nicolas Maduro blamed Televen for violence occurring in the country after the election and accused Globovision of being "fascist". The Venezuelan government has also been accused of not allowing public media outlets to attend official events and places such as the National Assembly, where only government-run media outlets are allowed to participate.
In the "World Report 2014" by Human Rights Watch, the Venezuelan government "has expanded and abused its powers to regulate media". The report says that "sharp criticism of the government is still common in several newspapers and some radio stations, fear of government reprisals has made self-censorship a serious problem". The report also criticized the amended telecommunications law where the government could take away concessions to private media outlets if it is "convenient for the interests of the nation".
In a 2015 report by the Institute for Press and Society (IPYS), over 25 media organizations had changed in ownerships between 2010 and 2015 with the new owners having "a direct relationship" to local governments and the national government that were linked to Chavismo.
Alternate media.
According to media protection organizations, Venezuelans "have been forced to find alternatives as newspapers and broadcasters struggle with state efforts to control coverage", with a growing trend of Venezuelans using online news media to bypass government censors.websites such as La Patilla and Efecto Cocuyo have emerged to counter the censorship.
Journalists and press-freedom advocates state that news websites like La Patilla "have helped fill a gap" since individuals linked to the Venezuelan government had purchased media organizations in Venezuela, such as "El Universal", Globovisión and "Ultimas Noticias". In an article by "The Wall Street Journal" discussing the rising popularity of news websites in Venezuela, La Patilla CEO Alberto Federico Ravell stated that, "The editorial line of La Patilla is to call it like it is ... We don't need paper. We don't need a broadcasting license. There's little they can do to squeeze us."

</doc>
<doc id="37785" url="http://en.wikipedia.org/wiki?curid=37785" title="Monte Cassino">
Monte Cassino

Monte Cassino (sometimes written Montecassino) is a rocky hill about 130 km southeast of Rome, Italy, 2 km to the west of the town of Cassino and 520 m altitude. Site of the Roman town of Casinum, it is best known for its historic abbey. St. Benedict of Nursia established his first monastery, the source of the Benedictine Order, here around 529. 
The hilltop sanctuary was the site of the Battle of Monte Cassino in 1944, where the building was destroyed by Allied bombing and rebuilt after the war. The site has been visited many times by the Popes and other senior clergy, including Pope Benedict XVI in May 2009. The monastery was one of the last remaining territorial abbeys within the Catholic Church, until 2014. 
History.
Ancient history.
The history of Monte Cassino is linked to the nearby town of Cassino which was first settled in the fifth century B.C.E. by the Volsci people who held much of central and southern Italy. It was the Volsci who first built a citadel on the summit of Monte Cassino. The Volsci in the area were defeated by the Romans in 312 B.C.E. The Romans renamed the settlement Casinum and build a temple to Apollo at the citadel. Modern excavations have found no remains of the temple, but ruins of an amphitheatre, a theatre, and a mausoleum indicate the lasting presence the Romans had there. 
Generations after the Roman Empire adopted Christianity the town became the seat of a bishop in the fifth century C.E. Lacking strong defences the area was subject to barbarian attack and became abandoned and neglected with only a few struggling inhabitants holding out.
Medieval history.
According to Gregory the Great's biography of Benedict, "Life of Saint Benedict of Nursia", the monastery was constructed on an older pagan site, a temple of Apollo that crowned the hill. The biography records that the area was still largely pagan at the time and Benedict's first act was to smash the sculpture of Apollo and destroy the altar. He then reused the temple, dedicating it to Saint Martin, and built another chapel on the site of the altar dedicated to Saint John the Baptist. Archaeologist Neil Christie notes that it was common in such hagiographies for the protagonist to encounter areas of strong paganism. Once established at Monte Cassino, Benedict never left. He wrote the Benedictine Rule that became the founding principle for Western monasticism, received a visit from Totila, king of the Ostrogoths (perhaps in 543, the only remotely secure historical date for Benedict), and died there.
Monte Cassino became a model for future developments. Unfortunately its prominent site has always made it an object of strategic importance. It was sacked or destroyed a number of times. In 581, during the abbacy of Bonitus, the Lombards sacked the abbey, and the surviving monks fled to Rome, where they remained for more than a century. During this time the body of St Benedict was transferred to Fleury, the modern Saint-Benoit-sur-Loire near Orleans, France.
A flourishing period of Monte Cassino followed its re-establishment in 718 by Abbot Petronax, when among the monks were Carloman, son of Charles Martel; Ratchis, predecessor of the great Lombard Duke and King Aistulf; and Paul the Deacon, the historian of the Lombards.
In 744, a donation of Gisulf II of Benevento created the "Terra Sancti Benedicti", the secular lands of the abbacy, which were subject to the abbot and nobody else save the Pope. Thus, the monastery became the capital of a state comprising a compact and strategic region between the Lombard principality of Benevento and the Byzantine city-states of the coast (Naples, Gaeta, and Amalfi).
In 884 Saracens sacked and then burned it down, and Abbot Bertharius was killed during the attack. Among the great historians who worked at the monastery, in this period there is Erchempert, whose "Historia Langobardorum Beneventanorum" is a fundamental chronicle of the ninth-century Mezzogiorno.
Library.
It was rebuilt and reached the apex of its fame in the 11th century under the abbot Desiderius (abbot 1058–1087), who later became Pope Victor III. The number of monks rose to over two hundred, and the library, the manuscripts produced in the scriptorium and the school of manuscript illuminators became famous throughout the West. The unique Beneventan script flourished there during Desiderius' abbacy.
The buildings of the monastery were reconstructed on a scale of great magnificence, artists being brought from Amalfi, Lombardy, and even Constantinople to supervise the various works. The abbey church, rebuilt and decorated with the utmost splendor, was consecrated in 1071 by Pope Alexander II. A detailed account of the abbey at this date exists in the "Chronica monasterii Cassinensis" by Leo of Ostia and Amatus of Monte Cassino gives us our best source on the early Normans in the south.
Abbot Desiderius sent envoys to Constantinople some time after 1066 to hire expert Byzantine mosaicists for the decoration of the rebuilt abbey church. According to chronicler Leo of Ostia the Greek artists decorated the apse, the arch and the vestibule of the basilica. Their work was admired by contemporaries but was totally destroyed in later centuries except two fragments depicting greyhounds (now in the Monte Cassino Museum). "The abbot in his wisdom decided that great number of young monks in the monastery should be thoroughly initiated in these arts" - says the chronicler about the role of the Greeks in the revival of mosaic art in medieval Italy.
An earthquake damaged the Abbey in 1349, and although the site was rebuilt it marked the beginning of a long period of decline. In 1321, Pope John XXII made the church of Monte Cassino a cathedral, and the carefully preserved independence of the monastery from episcopal interference was at an end. In 1505 the monastery was joined with that of St. Justina of Padua.
Modern history.
The site was sacked by Napoleon's troops in 1799. From the dissolution of the Italian monasteries in 1866, Monte Cassino became a national monument.
During the Battle of Monte Cassino (January–May 1944) the Abbey made up one section of the 161-kilometre (100-mile) Gustav Line, a German defensive line designed to hold the Allied troops from advancing any further into Italy. The Gustav Line stretched from the Tyrrhenian to the Adriatic coast and the monastery was one of the key strongholds, overlooking Highway 6 and blocking the path to Rome. On 15 February 1944 the abbey was almost completely destroyed in a series of heavy American-led air raids. The bombing was conducted because many reports from troops on the ground suggested that Germans were occupying the monastery, and it was considered a key observational post by all those who were fighting in the field. However, during the bombing no Germans were present in the abbey. Subsequent investigations have since confirmed that the only people killed in the monastery by the bombing were 230 Italian civilians seeking refuge there. Only after the bombing were the ruins of the monastery occupied by German "Fallschirmjäger" (paratroopers), aiding them in their defence, because the ruins provided excellent defensive cover. The heavily outnumbered Germans held the position until withdrawing on 17 May 1944, having repulsed four main offensives by the 2nd New Zealand Division, the 4th Indian Division and II Polish Corps. The Allied forces broke the Gustav Line between 11 and 17 May. The Polish 12th Podolian Uhlans Regiment of the Polish II Corps, commanded by Lt. Gen. Władysław Anders, raised the Polish flag over the ruins 18 May 1944. The road to Rome was then open. 
The Abbey was rebuilt after the war; Pope Paul VI reconsecrated it in 1964. During reconstruction, its library was housed at the Pontifical Abbey of St Jerome-in-the-City. Until his resignation was accepted by Pope Francis on 12 June 2013, the Territorial Abbot of Monte Cassino was Pietro Vittorelli.
The Vatican daily bulletin of October 23, 2014, announced that with the appointment of his successor Donato Ogliari the territory of the abbey outside the immediate monastery grounds had been transferred to the Diocese of Sora-Aquino-Pontecorvo.
Treasures.
In December 1942, some 1,400 irreplaceable manuscript codices, chiefly patristic and historical, in addition to a vast number of documents relating to the history of the abbey and the collections of the Keats-Shelley Memorial House in Rome, had been sent to the abbey archives for safekeeping. Fortunately, German officers Lt. Col. Julius Schlegel (a Roman Catholic) and Capt. Maximilian Becker (a Protestant), both from the Panzer-Division Hermann Göring, had them transferred to the Vatican at the beginning of the battle.
Another account however, from Kurowski ("The History of the Fallschirmpanzerkorps Hermann Göring: Soldiers of the Reichsmarschall") notes that 120 trucks were loaded with monastic assets and art which had been stored there for safekeeping. Robert Edsel ("Rescuing DaVinci") is more to the point about German looting. The trucks were loaded and left in October 1943, and only "strenuous" protests resulted in their delivery to the Vatican, minus the 15 cases which contained the property of the Capodimonte Museum in Naples. Edsel goes on to note that these cases had been delivered to Göring in December 1943, for "his birthday."

</doc>
<doc id="37787" url="http://en.wikipedia.org/wiki?curid=37787" title="Augsburg">
Augsburg

Augsburg (]) is a city in the south-west of Bavaria, Germany. It was a Free Imperial City for over 500 years.
It is a university town and home of the Regierungsbezirk Schwaben and the Bezirk Schwaben. Augsburg is an urban district and home to the institutions of the Landkreis Augsburg. It is the third-largest city in Bavaria (after Munich and Nuremberg) with a population of 284,000 citizens. After Neuss and Trier, Augsburg is Germany's third oldest city, being founded by the Romans as Augusta Vindelicorum, named after the Roman emperor Augustus.
Augsburg is the only German city with its own legal holiday, the "", celebrated on August 8 of every year. This gives Augsburg more legal holidays than any other region or city in Germany.
Augsburg was the home of two patrician families that rose to great prominence internationally, replacing the Medicis as Europe's leading bankers, the Fugger and the Welser families.
Geography.
Augsburg lies at the convergence of the Alpine rivers Lech and Wertach and on the Singold. The oldest part of the city and the southern quarters are on the northern foothills of a high terrace, which emerged between the steep rim of the hills of Friedberg in the east and the high hills of the west. In the south extends the Lechfeld, a Outwash plain of the post ice age between the rivers Lech and Wertach, where rare primeval landscapes were preserved. The Augsburg city forest and the Lech valley heaths today rank among the most species-rich middle European habitats.
On Augsburg borders the nature park Augsburg Western Woods - a large forestland. The city itself is also heavily greened. Because of that the city won in the Europe-wide contest Entente Florale 1997 as the first German city the prize as greenest and most livable city.
Neighboring municipalities.
Augsburg is surrounded by the counties Landkreis Augsburg in the west and Aichach-Friedberg in the east.
The neighboring towns and cities are Friedberg, Königsbrunn, Stadtbergen, Neusäß, Gersthofen, Rehling, Affing, Kissing, Mering, Merching, Bobingen, Gessertshausen und Diedorf.
Climate.
Augsburg has a humid continental climate ("Dfb" in the Koeppen climate classification).
History.
Early History.
The city was founded in 15 BC by Drusus and Tiberius as Augusta Vindelicorum (] ), on the orders of their stepfather Emperor Augustus. The name means "Augusta of the Vindelici". This garrison camp soon became the capital of the Roman province of Raetia.
Early development was due to a 400-year affiliation with the Roman Empire, especially because of its excellent military, economic and geographic position at the convergence of the Alpine rivers Lech and Wertach, and with direct access to most important Alpine passes. Thus, Augsburg was the intersection of many important European east-west and north-south connections, which later evolved as major trade routes of the Middle Ages.
Around 120 AD Augsburg became the capital of the Roman province Raetia. Augsburg was sacked by the Huns in the 5th century AD, by Charlemagne in the 8th century, and by Welf of Bavaria in the 11th century, but arose each time to greater prosperity.
Historical spellings of the name of the city include "Ausburch" and "Ausbourch."
Augsburg Confession.
Augsburg was granted the status of a Free Imperial City on March 9, 1276 and from then until 1803, it was independent of its former overlord, the Prince-Bishop of Augsburg. Frictions between the city-state and the prince-bishops were to remain frequent however, particularly after Augsburg became Protestant and curtailed the rights and freedoms of Catholics.
With a strategic location as intersection of trade routes to Italy, the Free Imperial City became a major trading center. Augsburg produced large quantities of woven goods, cloth and textiles. Augsburg became the base of two banking families that rose to great prominence, the Fuggers and the Welsers. The Fugger family donated the Fuggerei part of the city devoted to housing for needy citizens in 1516, which remains in use today.
In 1530, the Augsburg Confession was presented to the Holy Roman Emperor at the Diet of Augsburg. Following the Peace of Augsburg in 1555, after which the rights of religious minorities in imperial cities were to be legally protected, a mixed Catholic–Protestant city council presided over a majority Protestant population; "see ".
Thirty Years' War.
Religious peace in the city was largely maintained despite increasing Confessional tensions until the Thirty Years' War (1618–1648). In 1629, Holy Roman Emperor Ferdinand II issued the Edict of Restitution, which restored the legal situation. of 1552 which again curtailed the rights of the Protestant citizens. The inequality of the Edict of Restitution was rescinded when in April 1632, the Swedish army under Gustavus Adolphus captured Augsburg without resistance.
In 1634, the Swedish army was routed at nearby Nördlingen. By October 1634, Catholic troops had surrounded Augsburg. The Swedish garrison refused to surrender and a siege ensued through the winter of 1634/35 and thousands died from hunger and disease. According to J. N. Hays, "In the period of the Swedish occupation and the Imperial siege the population of the city was reduced from about 70,000 to about 16,000, with typhus and plague playing major roles."
Nine Years' War.
In 1686, Emperor Leopold I formed the "League of Augsburg", termed by the English as the "Grand Alliance" after England joined in 1689: a European coalition, consisting (at various times) of Austria, Bavaria, Brandenburg, England, the Holy Roman Empire, the Palatinate of the Rhine, Portugal, Savoy, Saxony, Spain, Sweden, and the United Provinces. It was formed to defend the Palatinate from France. This organization fought against France in the Nine Years War.
Augsburg's peak boom years occurred during the 15th and 16th centuries thanks to the bank and metal businesses of the merchant families Fugger and Welser, who held a local near total monopoly on their respective industries. Augsburg's wealth attracted artists seeking patrons and rapidly became a creative centre for famous painters, sculptors and musicians notably birthplace of : the Holbein painter family. In later centuries the city was the birthplace of the composer Leopold Mozart and the playwright Berthold Brecht. Rococo became so prevalent that it became known as “Augsburg style” throughout Germany.
End of Free Imperial City status and Industrial Revolution revival.
In 1806, when the Holy Roman Empire was dissolved, Augsburg lost its independence and was annexed to the Kingdom of Bavaria. In 1817, the city became an administrative capital of the "Oberdonaukreis", then administrative capital in 1837 for the district Swabia and Neuburg.
During the end of the 19th century, Augsburg's textile industry again rose to prominence followed by the connected machine manufacturing industry.
Military.
Augsburg was historically a militarily important city due to its strategic location.
During the German re-armament before the Second World War, the Wehrmacht enlarged Augsburg's one original Kaserne (barracks) to three: Somme Kaserne ((housing Wehrmacht Artillerie-Regiment 27)); Arras Kaserne ((housing Wehrmacht Infanterie Regiment 27)) and Panzerjäger Kaserne (housing Panzerabwehr-Abteilung 27 (later Panzerjäger-Abteilung 27). Wehrmacht Panzerjäger-Abteilung 27 was later moved to Füssen.
During World War II, one subcamp of the Dachau concentration camp was located outside Augsburg, supplying approximately 1,300 forced labourers to local military-related industry, most especially the Messerschmitt AG military aircraft firm headquartered in Augsburg.
In 1941, Rudolf Hess without Adolf Hitler's permission secretly took off from a local airport and flew to Scotland to meet the Duke of Hamilton, and crashed in Eaglesham in an attempt to mediate the end of the European front of World War II and join sides for the upcoming Russian Campaign.
The Reichswehr Infanterie Regiment 19 was stationed in Augsburg and became the base unit for the Wehrmacht Infanterie Regiment 40, a subsection of the Wehrmacht Infanterie Division 27 (which later became the Wehrmacht Panzerdivision 17). Elements of Wehrmacht II Battalion of Gebirgs-Jäger-Regiment 99 (especially Wehrmacht Panzerjäger Kompanie 14) was composed of parts of the Wehrmacht Infanterie Division 27. The Infanterie Regiment 40 remained in Augsburg until the end of the war, finally surrendering to the United States when in 1945, the U.S. Army occupied the heavily bombed and damaged city.
Following the war, the three Kaserne would change hands confusingly between the American and Germans, finally ending up in US hands for the duration of the Cold War. The former Wehrmacht Kaserne became the three main US barracks in Augsburg: Reese;, Sheridan and FLAK. US Base FLAK had been an anti-aircraft barracks since 1936 and US Base Sheridan "united" the former infantry barracks with a smaller Kaserne for former Luftwaffe communications units.
The American military presence in the city started with the 11th Airborne Division, followed by the 24th Infantry Division, U.S. Army Seventh Corps Artillery, 701st Military Intelligence Brigade and finally the 66th Military Intelligence Brigade, which returned the former Kaserne to German hands in 1998. Originally the Heeresverpflegungshauptamt Südbayern and an Officers' caisson existed on or near the location of Reese-Kaserne, but was demolished by the occupying Americans.
Politics.
Municipality.
From 1266 until 1548, the terms "Stadtpfleger" (head of town council) and "Mayor" were used interchangeably, or occasionally, simultaneously.
In 1548 the title was finally fixed to "Stadtpfleger", who officiated for several years and was then awarded the title for life (though no longer governing), thus resulting confusingly, in records of two or more simultaneous "Stadtpfleger".
After the transfer to Bavaria in 1806, Augsburg was ruled by a Magistrate with two mayors, supported by an additional council of "Community Commissioners": the "Gemeindebevollmächtige".
As of 1907, the Mayor was entitled Oberbürgermeister, as Augsburg had reached a population of 100,000, as per the Bavarian Gemeindeordnung.
Town Council.
12002 PDS, until 1984 DKP    2Christlich Soziale Mitte (CSM): 3, Freie Wähler: 2, Polit-WG e.V: 1
Members of the Bundestag.
Augsburg is located in the "Wahlkreis 253 Augsburg-Stadt" constituency, which includes Königsbrunn and the District of Augsburg (Landkreis Augsburg).
Volker Ullrich of the CSU was directly elected to the Bundestag in the 18th German Bundestag.
Indirectly elected to the Bundestag to adhere to the Landesliste were Ulrike Bahr for the SPD and Claudia Roth for Bündnis 90/Die Grünen.
Population.
Historical development.
¹ Census result
Partner cities.
Information on the partner cities can also be found at 
Transport.
Roads.
The main road link is autobahn A 8 between Munich and Stuttgart.
Public transport.
Public transport is very well catered for. It is controlled by the Augsburger Verkehrsverbund (Augsburg transport union, AVV) extended over central Swabia. There are seven rail Regionalbahn lines, five tram lines, 27 city bus lines and six night bus lines, as well as, several taxi companies.
The Augsburg tramway network is now 35.5 km-long after the opening of new lines to the university in 1996, the northern city boundary in 2001 and to the Klinikum Augsburg (Augsburg hospital) in 2002. Tram line 6, which runs 5.2 km from Friedberg West to Rotes Tor, opened in December 2010.
Rail services.
Augsburg has six stations, the Central Station ("Hauptbahnhof"), Hochzoll, Oberhausen, Morellstraße and "Messe". The Central Station, built from 1843 to 1846, is Germany’s oldest main station in a large city still providing services in the original building. It is currently being modernized and an underground tram station is built underneath it. Hauptbahnhof is on the Munich–Augsburg and Ulm–Augsburg lines and is connected by ICE and IC services to Munich, Berlin, Dortmund, Frankfurt, Hamburg and Stuttgart. As of December 2007, the French TGV connected Augsburg with a direct High Speed Connection to Paris. In addition EC and night train services connect to Amsterdam, Paris and Vienna and connections will be substantially improved by the creation of the planned Magistrale for Europe.
The AVV operates seven Regionalbahn lines from the main station to:
Starting in 2008, the regional services are planned to be altered to S-Bahn frequencies and developed long term as integrated into the Augsburg S-Bahn.
Air transport.
Until 2005 Augsburg was served by nearby Augsburg Airport (AGB). In that year all air passenger transport was relocated to Munich Airport. Since then the Airport has only served for General aviation and business aviation.
Economy.
Augsburg is a vibrant industrial city. Many global market leaders namely MAN, EADS or KUKA produce high technology products like printing systems, large diesel engines, industrial robots or components for the Airbus A380 and the Ariane carrier rocket. After Munich, Augsburg is considered the high-tech centre for Information and Communication in Bavaria and takes advantage of its lower operating costs, yet close proximity to Munich and potential customers.
Education.
Augsburg is home to the following universities and colleges:
Media.
The local newspaper is the "Augsburger Allgemeine" first published in 1807. There are also several local radio stations and a local TV station (a.tv).
Sports.
FC Augsburg is a football team based in Augsburg and plays in the SGL arena. FC Augsburg was promoted to Bundesliga in 2011. The new stadium (opened in July 2009) also hosted games of the 2011 FIFA Women's World Cup.
The city is home to a DEL (first-division) ice hockey team, the Augsburger Panther. The original club, AEV, was formed in 1878, the oldest German ice sport club and regularly draws around 4000 spectators, quite reasonable for German ice hockey. Home games are played at the Curt Frenzel Stadion: a recently rebuilt (2012-2013) indoor rink and modern stadium. Also Augsburg is home to one of the most traditional German Baseball clubs, the Augsburg Gators.
For the 1972 Olympic Games in Munich, a Lech River dam protective diversionary canal for river ice was converted into the world's first artificial whitewater slalom course: the Eiskanal and remains a world-class venue for whitewater competition and served as prototype for two dozen similar foreign courses.
Local city nicknames.
While commonly called "Fuggerstadt" (Fuggers' city) due to the Fuggers residing there, within Swabia it is also often referred to as "Datschiburg": which originated sometime in the 19th century refers to Augsburg's favorite sweet: the "Datschi" made from fruit, preferably prunes, and thin cake dough. The "Datschiburger Kickers" charity football team (founded in 1965) reflects this in its choice of team name.
Among the younger people, the city is commonly called "Aux" as a short form.

</doc>
<doc id="37789" url="http://en.wikipedia.org/wiki?curid=37789" title="Mosquito">
Mosquito

Mosquitoes are small, midge-like flies which compose the family Culicidae. Although a few species are harmless or even useful to humanity, the females of most species are ectoparasites, whose tube-like mouthparts (called a proboscis) pierce the hosts' skin to suck the blood. The word "mosquito" (formed by "mosca" and diminutive "ito") is from the Spanish or Portuguese for "little fly". Thousands of species feed on the blood of various kinds of hosts, mainly vertebrates, including mammals, birds, reptiles, amphibians, and even some kinds of fish. Some mosquitoes also attack invertebrates, mainly arthropods. Though the loss of blood is seldom of any importance to the victim, the saliva of the mosquito often causes an irritating rash that is a serious nuisance. Much more serious though, are the roles of many species of mosquitoes as vectors of diseases. In passing from host to host, some transmit extremely harmful infections such as malaria, yellow fever, west nile virus and filariasis.
Species.
Mosquitoes are members of a family of nematocerid flies: the Culicidae (from the Latin "culex", genitive "culicis", meaning "midge" or "gnat"). Superficially, mosquitoes resemble crane flies (family Tipulidae) and chironomid flies (family Chironomidae). In particular, the females of many species of mosquitoes are blood-eating pests and dangerous vectors of diseases, whereas members of the similar-looking Chironomidae and Tipulidae are not. Many species of mosquitoes are not blood eaters and of those that are, many create a "high to low pressure" in the blood to obtain it and do not transmit disease. Also, in the bloodsucking species, only the females suck blood. Furthermore, even among mosquitoes that do carry important diseases, neither all species of mosquitoes, nor all strains of a given species transmit the same kinds of diseases, nor do they all transmit the diseases under the same circumstances; their habits differ. For example, some species attack people in houses, and others prefer to attack people walking in forests. Accordingly, in managing public health, knowing which species, even which strains, of mosquitoes with which one is dealing is important.
Over 3,500 species of mosquitoes have already been described from various parts of the world. Some mosquitoes that bite humans routinely act as vectors for a number of infectious diseases affecting millions of people per year. Others that do not routinely bite humans, but are the vectors for animal diseases, may become disastrous agents for zoonosis of new diseases when their habitats are disturbed, for instance by sudden deforestation.
Life cycle.
Like all flies, mosquitoes go through four stages in their lifecycles: egg, larva, pupa, and adult or imago. In most species, adult females lay their eggs in stagnant water; some lay eggs near the water's edge; others attach their eggs to aquatic plants. Each species selects the situation of the water into which it lays its eggs and does so according to its own ecological adaptations. Some are generalists and are not very fussy. Some breed in lakes, some in temporary puddles. Some breed in marshes, some in salt-marshes. Among those that breed in salt water, some are equally at home in fresh and salt water up to about one-third the concentration of seawater, whereas others must acclimatize themselves to the salinity. Such differences are important because certain ecological preferences keep mosquitoes away from most humans, whereas other preferences bring them right into houses at night.
Some species of mosquitoes prefer to breed in phytotelmata (natural reservoirs on plants), such as rainwater accumulated in holes in tree trunks, or in the leaf-axils of bromeliads. Some specialize in the liquid in pitchers of particular species of pitcher plants, their larvae feeding on decaying insects that had drowned there or on the associated bacteria; the genus "Wyeomyia" provides such examples — the harmless "Wyeomyia smithii" breeds only in the pitchers of "Sarracenia purpurea".
However, some of the species of mosquitoes that are adapted to breeding in phytotelmata are dangerous disease vectors. In nature, they might occupy anything from a hollow tree trunk to a cupped leaf. Such species typically take readily to breeding in artificial water containers, such as the odd plastic bucket, flowerpot "saucer", or discarded bottle or tire. Such casual puddles are important breeding places for some of the most serious disease vectors, such as species of "Aedes" that transmit dengue and yellow fever. Some with such breeding habits are disproportionately important vectors because they are well-placed to pick up pathogens from humans and pass them on. In contrast, no matter how voracious, mosquitoes that breed and feed mainly in remote wetlands and salt marshes may well remain uninfected, and if they do happen to become infected with a relevant pathogen, might seldom encounter humans to infect, in turn.
The first three stages—egg, larva, and pupa—are largely aquatic. These stages typically last five to 14 days, depending on the species and the ambient temperature, but there are important exceptions. Mosquitoes living in regions where some seasons are freezing or waterless spend part of the year in diapause; they delay their development, typically for months, and carry on with life only when there is enough water or warmth for their needs. For instance, "Wyeomyia" larvae typically get frozen into solid lumps of ice during winter and only complete their development in spring. The eggs of some species of "Aedes" remain unharmed in diapause if they dry out, and hatch later when they are covered by water.
Eggs hatch to become larvae, which grow until they are able to change into pupae. The adult mosquito emerges from the mature pupa as it floats at the water surface. Bloodsucking mosquitoes, depending on species, gender, and weather conditions, have potential adult lifespans ranging from as short as a week to as long as several months.
Some species can overwinter as adults in diapause.
Eggs and oviposition.
Mosquito habits of oviposition, the ways in which they lay their eggs, vary considerably between species, and the morphologies of the eggs vary accordingly. The simplest procedure is that followed by many species of "Anopheles"; like many other gracile species of aquatic insects, females just fly over the water, bobbing up and down to the water surface and dropping eggs more or less singly. The bobbing behavior occurs among some other aquatic insects as well, for example mayflies and dragonflies; it is sometimes called "dapping". The eggs of "Anopheles" species are roughly cigar-shaped and have floats down their sides. Females of many common species can lay 100–200 eggs during the course of the adult phase of their lifecycles. Even with high egg and intergenerational mortality, over a period of several weeks, a single successful breeding pair can create a population of thousands.
Some other species, for example members of the genus "Mansonia", lay their eggs in arrays, attached usually to the under-surfaces of waterlily pads. Their close relatives, the genus "Coquillettidia", lay their eggs similarly, but not attached to plants. Instead, the eggs form layers called "rafts" that float on the water. This is a common mode of oviposition, and most species of "Culex" are known for the habit, which also occurs in some other genera, such as "Culiseta" and "Uranotaenia". "Anopheles" eggs may on occasion cluster together on the water, too, but the clusters do not generally look much like compactly glued rafts of eggs.
In species that lay their eggs in rafts, rafts do not form adventitiously; the female "Culex" settles carefully on still water with her hind legs crossed, and as she lays the eggs one by one, she twitches to arrange them into a head-down array that sticks together to form the raft.
"Aedes" females generally drop their eggs singly, much as "Anopheles" do, but not as a rule into water. Instead, they lay their eggs on damp mud or other surfaces near the water's edge. Such an oviposition site commonly is the wall of a cavity such as a hollow stump or a container such as a bucket or a discarded vehicle tire. The eggs generally do not hatch until they are flooded, and they may have to withstand considerable desiccation before that happens. They are not resistant to desiccation straight after oviposition, but must develop to a suitable degree first. Once they have achieved that, however, they can enter diapause for several months if they dry out. Clutches of eggs of the majority of mosquito species hatch as soon as possible, and all the eggs in the clutch hatch at much the same time. In contrast, a batch of "Aedes" eggs in diapause tends to hatch irregularly over an extended period of time. This makes it much more difficult to control such species than those mosquitoes whose larvae can be killed all together as they hatch. Some "Anopheles" species do also behave in such a manner, though not to the same degree of sophistication.
Larva.
The mosquito larva has a well-developed head with mouth brushes used for feeding, a large thorax with no legs, and a segmented abdomen.
Larvae breathe through spiracles located on their eighth abdominal segments, or through a siphon, so must come to the surface frequently. The larvae spend most of their time feeding on algae, bacteria, and other microbes in the surface microlayer.
They dive below the surface only when disturbed. Larvae swim either through propulsion with their mouth brushes, or by jerky movements of their entire bodies, giving them the common name of "wigglers" or "wrigglers".
Larvae develop through four stages, or instars, after which they metamorphose into pupae. At the end of each instar, the larvae molt, shedding their skins to allow for further growth.
Pupa.
As seen in its lateral aspect, the mosquito pupa is comma-shaped. The head and thorax are merged into a cephalothorax, with the abdomen curving around underneath. The pupa can swim actively by flipping its abdomen, and it is commonly called a "tumbler" because of its swimming action. As with the larva, the pupa of most species must come to the surface frequently to breathe, which they do through a pair of respiratory trumpets on their cephalothoraces. However, pupae do not feed during this stage; typically they pass their time hanging from the surface of the water by their respiratory trumpets. If alarmed, say by a passing shadow, they nimbly swim downwards by flipping their abdomens in much the same way as the larvae do. If undisturbed, they soon float up again.
After a few days or longer, depending on the temperature and other circumstances, the pupa rises to the water surface, the dorsal surface of its cephalothorax splits, and the adult mosquito emerges. The pupa is less active than the larva because it does not feed, whereas the larva feeds constantly.
Adult.
The period of development from egg to adult varies among species and is strongly influenced by ambient temperature. Some species of mosquitoes can develop from egg to adult in as few as five days, but a more typical period of development in tropical conditions would be some 40 days or more for most species. The variation of the body size in adult mosquitoes depends on the density of the larval population and food supply within the breeding water.
Adult mosquitoes usually mate within a few days after emerging from the pupal stage. In most species, the males form large swarms, usually around dusk, and the females fly into the swarms to mate.
Males typically live for about 5–7 days, feeding on nectar and other sources of sugar. After obtaining a full blood meal, the female will rest for a few days while the blood is digested and eggs are developed. This process depends on the temperature, but usually takes two to three days in tropical conditions. Once the eggs are fully developed, the female lays them and resumes host-seeking.
The cycle repeats itself until the female dies. While females can live longer than a month in captivity, most do not live longer than one to two weeks in nature. Their lifespans depend on temperature, humidity, and their ability to successfully obtain a blood meal while avoiding host defenses and predators.
The length of the adult varies, but is rarely greater than 16 mm, and it weighs up to 2.5 mg. All mosquitoes have slender bodies with three segments: a head, a thorax and an abdomen.
The head is specialized for receiving sensory information and for feeding. It has eyes and a pair of long, many-segmented antennae. The antennae are important for detecting host odors, as well as odors of breeding sites where females lay eggs. In all mosquito species, the antennae of the males in comparison to the females are noticeably bushier and contain auditory receptors to detect the characteristic whine of the females.
The compound eyes are distinctly separated from one another. Their larvae only possess a pit-eye ocellus. The compound eyes of adults develop in a separate region of the head. New ommatidia are added in semicircular rows at the rear of the eye. During the first phase of growth, this leads to individual ommatidia being square, but later in development they become hexagonal. The hexagonal pattern will only become visible when the carapace of the stage with square eyes is molted.
The head also has an elongated, forward-projecting, "stinger-like" proboscis used for feeding, and two sensory palps. The maxillary palps of the males are longer than their proboscises, whereas the females’ maxillary palps are much shorter. In typical bloodsucking species, the female has an elongated proboscis.
The thorax is specialized for locomotion. Three pairs of legs and a pair of wings are attached to the thorax. The insect wing is an outgrowth of the exoskeleton. The "Anopheles" mosquito can fly for up to four hours continuously at 1 to-, traveling up to 12 km in a night. Males beat their wings between 450 and 600 times per second.
The abdomen is specialized for food digestion and egg development; the abdomen of a mosquito can hold three times its own weight in blood. This segment expands considerably when a female takes a blood meal. The blood is digested over time, serving as a source of protein for the production of eggs, which gradually fill the abdomen.
Feeding by adults.
A mosquito has a variety of ways of finding their prey, including chemical, visual, and heat sensors.
Typically, both male and female mosquitoes feed on nectar and plant juices, but in many species the mouthparts of the females are adapted for piercing the skin of animal hosts and sucking their blood as ectoparasites. In many species, the female needs to obtain nutrients from a blood meal before she can produce eggs, whereas in many other species, she can produce more eggs after a blood meal. The feeding preferences of mosquitoes include those with type O blood, heavy breathers, those with a lot of skin bacteria, people with a lot of body heat, and the pregnant. Both plant materials and blood are useful sources of energy in the form of sugars, and blood also supplies more concentrated nutrients, such as lipids, but the most important function of blood meals is to obtain proteins as materials for egg production.
The strategy of only females risking their lives on blood sucking is not limited to mosquitoes; it also occurs in some other insect families, such as the Tabanidae. When a female reproduces without such parasitic meals, she is said to practice autogenous reproduction, as in "Toxorhynchites"; otherwise, the reproduction may be termed anautogenous, as occurs in mosquito species that serve as disease vectors, particularly "Anopheles" and some of the most important disease vectors in the genus "Aedes". In contrast, some mosquitoes, for example, many "Culex", are partially anautogenous; they do not need a blood meal for their first cycle of egg production, which they produce autogenously; however, subsequent clutches of eggs are produced anautogenously, at which point their disease vectoring activity becomes operative.
With regard to host location, female mosquitoes hunt their blood host by detecting organic substances such as carbon dioxide (CO2) and 1-octen-3-ol produced from the host, and through optical recognition. Mosquitoes prefer some people over others. The preferred victim's sweat simply smells better than others because of the proportions of the carbon dioxide, octenol and other compounds that make up body odor. The most powerful semiochemical that triggers the keen sense of smell of "Culex quinquefasciatus" is nonanal. Another compound identified in human blood that attracts mosquitoes is sulcatone or 6-methyl-5-hepten-2-one, especially for "Aedes aegypti" mosquitoes with the odor receptor gene Or4. A large part of the mosquito’s sense of smell, or olfactory system, is devoted to sniffing out blood sources. Of 72 types of odor receptors on its antennae, at least 27 are tuned to detect chemicals found in perspiration. In "Aedes", the search for a host takes place in two phases. First, the mosquito exhibits a nonspecific searching behavior until the perception of host stimulants, then it follows a targeted approach.
Most mosquito species are crepuscular (dawn or dusk) feeders. During the heat of the day, most mosquitoes rest in a cool place and wait for the evenings, although they may still bite if disturbed. Some species, such as the Asian tiger mosquito, are known to fly and feed during daytime. 
Prior to and during blood feeding, blood-sucking mosquitoes inject saliva into the bodies of their source(s) of blood. This saliva serves as an anticoagulant; without it one might expect the female mosquito's proboscis to become clogged with blood clots. The saliva also is the main route by which mosquito physiology offers passenger pathogens access to the hosts' interior. The salivary glands are a major target to most pathogens, whence they find their way into the host via the stream of saliva.
The bump left on the victim's skin after a mosquito bites is called a wheal, which is caused by histamines trying to fight off the protein left by the attacking insect.
Mosquitoes of the genus "Toxorhynchites" never drink blood. This genus includes the largest extant mosquitoes, the larvae of which prey on the larvae of other mosquitoes. These mosquito eaters have been used in the past as mosquito control agents, with varying success.
Hosts of blood-feeding mosquito species.
Many, if not all, blood-sucking species of mosquitoes are fairly selective feeders that specialise in particular host species, though they often relax their selectivity when they experience severe competition for food, defensive activity on the part of the hosts, or starvation. Some species feed selectively on monkeys, while others prefer particular kinds of birds, but they become less selective as conditions become more difficult. For example, "Culiseta melanura" sucks the blood of passerine birds for preference and such birds are typically the main reservoir of the Eastern equine encephalitis virus in North America. Early in the season while mosquito numbers are low, they concentrate on passerine hosts, but as mosquito numbers rise and the birds are forced to defend themselves more vigorously, the mosquitoes become less selective in attacking their avian hosts. Soon the mosquitoes begin attacking mammals more readily, thereby becoming the major vector of the virus, and causing epidemics of the disease, most conspicuously in humans and horses.
Even more dramatically, in most of its range in North America, the main vector for the Western equine encephalitis virus is "Culex tarsalis", because it is known to feed variously on mammals, birds, reptiles, and amphibians. Even fish may be attacked by some mosquito species if they expose themselves above water level, as mudskippers do.
It has long been known that some species of blood-sucking flies, such as many of the Ceratopogonidae, will attack large, live insects and suck their haemolymph and that others, such as the so-called "jackal flies" (Milichiidae), will attack the recently dead prey of say, crab spiders (Thomisidae), but in the late 1960s it was reported that some species of anautogenous mosquitoes would feed on the haemolymph of caterpillars. Other observations include mosquitoes feeding on cicadas, and mantids. More recently it has been shown that malaria transmitting mosquitoes will actively seek out some species of caterpillars and feed on their haemolymph, and do so to their apparent physical detriment.
Mouthparts.
Mosquito mouthparts are very specialized, particularly those of the females, which in most species are adapted to piercing skin and then sucking blood. Apart from bloodsucking, the females generally also drink assorted fluids rich in dissolved sugar, such as nectar and honeydew, to obtain the energy they need. For this, their blood-sucking mouthparts are perfectly adequate. In contrast, male mosquitoes are not bloodsuckers; they only drink sugary fluids. Accordingly, their mouthparts do not require the same degree of specialization as those of females.
Externally, the most obvious feeding structure of the mosquito is the proboscis. More specifically, the visible part of the proboscis is the labium, which forms the sheath enclosing the rest of the mouthparts. When the mosquito first lands on a potential host, her mouthparts will be enclosed entirely in this sheath, and she will touch the tip of the labium to the skin in various places. Sometimes, she will begin to bite almost straight away, while other times, she will prod around, apparently looking for a suitable place. Occasionally, she will wander for a considerable time, and eventually fly away without biting. Presumably, this probing is a search for a place with easily accessible blood vessels, but the exact mechanism is not known. It is known that there are two taste receptors at the tip of the labium which may well play a role.
The female mosquito does not insert her labium into the skin; it bends back into a bow when the mosquito begins to bite. The tip of the labium remains in contact with the skin of the victim, acting as a guide for the other mouthparts. In total, there are six mouthparts besides the labium: two mandibles, two maxillae, the hypopharynx, and the labrum.
The mandibles and the maxillae are used for piercing the skin. The mandibles are pointed, while the maxillae end in flat, toothed "blades". To force these into the skin, the mosquito moves its head backwards and forwards. On one movement, the maxillae are moved as far forward as possible. On the opposite movement, the mandibles are pushed deeper into the skin by levering against the maxillae. The maxillae do not slip back because the toothed blades grip the skin.
The hypopharynx and the labrum are both hollow. Saliva with anticoagulant is pumped down the hypopharynx to prevent clotting, and blood is drawn up the labrum.
To understand the mosquito mouthparts, it is helpful to draw a comparison with an insect that chews food, such as a dragonfly. A dragonfly has two mandibles, which are used for chewing, and two maxillae, which are used to hold the food in place as it is chewed. The labium forms the floor of the dragonfly's mouth, the labrum forms the top, while the hypopharynx is inside the mouth and is used in swallowing. Conceptually, then, the mosquito's proboscis is an adaptation of the mouthparts that occur in other insects. The labium still lies beneath the other mouthparts, but also enfolds them, and it has been extended into a proboscis. The maxillae still "grip" the "food" while the mandibles "bite" it. The top of the mouth, the labrum, has developed into a channeled blade the length of the proboscis, with a cross-section like an inverted "U". Finally, the hypopharynx has extended into a tube that can deliver saliva at the end of the proboscis. Its upper surface is somewhat flattened so, when pressed against it, the labrum forms a closed tube for conveying blood from the victim.
Saliva.
For the mosquito to obtain a blood meal, it must circumvent the vertebrate's physiological responses. The mosquito, as with all blood-feeding arthropods, has mechanisms to effectively block the hemostasis system with their saliva, which contains a mixture of secreted proteins. Mosquito saliva negatively affects vascular constriction, blood clotting, platelet aggregation, angiogenesis and immunity, and creates inflammation. Universally, hematophagous arthropod saliva contains at least one anticlotting, one antiplatelet, and one vasodilatory substance. Mosquito saliva also contains enzymes that aid in sugar feeding and antimicrobial agents to control bacterial growth in the sugar meal. The composition of mosquito saliva is relatively simple, as it usually contains fewer than 20 dominant proteins. Despite the great strides in knowledge of these molecules and their role in bloodfeeding achieved recently, scientists still cannot ascribe functions to more than half of the molecules found in arthropod saliva. One promising application is the development of anticlotting drugs, such as clotting inhibitors and capillary dilators, that could be useful for cardiovascular disease.
It is now well recognized that feeding ticks, sandflies, and, more recently, mosquitoes, have an ability to modulate the immune response of the animals (hosts) on which they feed. The presence of this activity in vector saliva is a reflection of the inherent overlapping and interconnected nature of the host hemostatic and inflammatory/immunological responses and the intrinsic need to prevent these host defenses from disrupting successful feeding. The mechanism for mosquito saliva-induced alteration of the host immune response is unclear, but the data have become increasingly convincing that such an effect occurs. Early work described a factor in saliva that directly suppresses TNF-α release, but not antigen-induced histamine secretion, from activated mast cells. Experiments by Cross et al. (1994) demonstrated that the inclusion of "Ae. aegypti" mosquito saliva into naïve cultures led to a suppression of interleukin (IL)-2 and IFN-γ production, while the cytokines IL-4 and IL-5 are unaffected by mosquito saliva. Cellular proliferation in response to IL-2 is clearly reduced by prior treatment of cells with SGE. Correspondingly, activated splenocytes isolated from mice fed upon by either "Ae. aegypti" or "Cx. pipiens" mosquitoes produce markedly higher levels of IL-4 and IL-10 concurrent with suppressed IFN-γ production. Unexpectedly, this shift in cytokine expression is observed in splenocytes up to 10 days after mosquito exposure, suggesting natural feeding of mosquitoes can have a profound, enduring, and systemic effect on the immune response.
T cell populations are decidedly susceptible to the suppressive effect of mosquito saliva, showing increased mortality and decreased division rates. Parallel work by Wasserman et al. (2004) demonstrated that T- and B-cell proliferation was inhibited in a dose dependent manner with concentrations as low as 1/7 of the saliva in a single mosquito. Depinay et al. (2005) observed a suppression of antibody-specific T cell responses mediated by mosquito saliva and dependent on mast cells and IL-10 expression.
A recent study suggests mosquito saliva can also decrease expression of interferon−α/β during early mosquito-borne virus infection. The contribution of type I interferons (IFN) in recovery from infection with viruses has been demonstrated "in vivo" by the therapeutic and prophylactic effects of administration of IFN-inducers or IFN, and recent research suggests mosquito saliva exacerbates West Nile virus infection, as well as other mosquito-transmitted viruses.
Egg development and blood digestion.
Female mosquitoes use two very different food sources. They need sugar for energy, which is taken from sources such as nectar, and they need blood as a source of protein for egg development. Because biting is risky and hosts may be difficult to find, mosquitoes take as much blood as possible when they have the opportunity. This, however, creates another problem. Digesting that volume of blood takes a while, and the mosquito will require energy from sugar in the meantime.
To avoid this problem, mosquitoes have a digestive system which can store both food types, and give access to both as they are needed. When the mosquito drinks a sugar solution, it is directed to a crop. The crop can release sugar into the stomach as it is required. At the same time, the stomach never becomes full of sugar solution, which would prevent the mosquito taking a blood meal if it had the chance.
Blood is directed straight into the mosquito's stomach. In species that feed on mammalian or avian blood, hosts whose blood pressure is high, the mosquito feeds selectively from active blood vessels, where the pressure assists in filling the gut rapidly. If, instead of slapping a feeding mosquito, one stretches one's skin so that it grips the proboscis and the mosquito cannot withdraw it, the pressure will distend the gut until it breaks and the mosquito dies. In the unmolested mosquito, however, the mosquito will withdraw, and as the gut fills up, the stomach lining secretes a peritrophic membrane that surrounds the blood. This membrane keeps the blood separate from anything else in the stomach. However, like certain other insects that survive on dilute, purely liquid diets, notably many of the Hemiptera, many adult mosquitoes must excrete unwanted aqueous fractions even as they feed. (See the photograph of a feeding "Anopheles stephensi": Note that the excreted droplet patently is not whole blood, being far more dilute). As long as they are not disturbed, this permits mosquitoes to continue feeding until they have accumulated a full meal of nutrient solids. As a result, a mosquito replete with blood can continue to absorb sugar, even as the blood meal is slowly digested over a period of several days. Once blood is in the stomach, the midgut of the female synthesizes proteolytic enzymes that hydrolyze the blood proteins into free amino acids. These are used as building blocks for the synthesis of egg yolk proteins.
In the mosquito "Anopheles stephensi" Liston, trypsin activity is restricted entirely to the posterior midgut lumen. No trypsin activity occurs before the blood meal, but activity increases continuously up to 30 hours after feeding, and subsequently returns to baseline levels by 60 hours. Aminopeptidase is active in the anterior and posterior midgut regions before and after feeding. In the whole midgut, activity rises from a baseline of approximately three enzyme units (EU) per midgut to a maximum of 12 EU at 30 hours after the blood meal, subsequently falling to baseline levels by 60 hours. A similar cycle of activity occurs in the posterior midgut and posterior midgut lumen, whereas aminopeptidase in the posterior midgut epithelium decreases in activity during digestion. Aminopeptidase in the anterior midgut is maintained at a constant, low level, showing no significant variation with time after feeding. Alpha-glucosidase is active in anterior and posterior midguts before and at all times after feeding. In whole midgut homogenates, alpha-glucosidase activity increases slowly up to 18 hours after the blood meal, then rises rapidly to a maximum at 30 hours after the blood meal, whereas the subsequent decline in activity is less predictable. All posterior midgut activity is restricted to the posterior midgut lumen. Depending on the time after feeding, greater than 25% of the total midgut activity of alpha-glucosidase is located in the anterior midgut. After blood meal ingestion, proteases are active only in the posterior midgut. Trypsin is the major primary hydrolytic protease and is secreted into the posterior midgut lumen without activation in the posterior midgut epithelium. Aminoptidase activity is also luminal in the posterior midgut, but cellular aminopeptidases are required for peptide processing in both anterior and posterior midguts. Alpha-glucosidase activity is elevated in the posterior midgut after feeding in response to the blood meal, whereas activity in the anterior midgut is consistent with a nectar-processing role for this midgut region.
Distribution.
In the sense of the entire family Culicidae, mosquitoes are cosmopolitan; in every land region except for Antarctica and a few islands, mainly in polar or subpolar climates, at least some species of mosquito will be present. Iceland is an unusual example of such an island, being essentially free of mosquitoes. In warm and humid tropical regions, various mosquito species are active for the entire year, but in temperate and cold regions they hibernate or enter diapause. Arctic or subarctic mosquitoes, like some other arctic midges in families such as Simuliidae and Ceratopogonidae may be active for only a few weeks annually as melt-water pools form on the permafrost. During that time, though, they emerge in huge numbers in some regions and may take up to 300 ml of blood per day from each animal in a caribou herd.
The absence of mosquitoes from Iceland and similar regions is probably because of quirks of their climate, which differs in some respects from mainland regions. At the start of the uninterrupted continental winter of Greenland and the northern regions of Eurasia and America, the pupa enters diapause under the ice that covers sufficiently deep water. The imago ecloses only after the ice breaks in late spring. In Iceland however, the weather is less predictable. In mid-winter it frequently warms up suddenly, causing the ice to break, but then to freeze again after a few days. By that time the mosquitoes will have emerged from their pupae, but the new freeze sets in before they can complete their life cycle. Any anautogenous adult mosquito would need a host to supply a blood meal before it could lay viable eggs; it would need time to mate, mature the eggs and oviposit in suitable wetlands. These requirements would not be realistic in Iceland and in fact the absence of mosquitoes from such subpolar islands is in line with the islands' low biodiversity; Iceland has fewer than 1500 described species of insects, many of them probably accidentally introduced by human agency. In Iceland most ectoparasitic insects live in sheltered conditions or actually on mammals; examples include lice, fleas and bedbugs, in whose living conditions freezing is no concern, and most of which were introduced inadvertently by humans.
Some other aquatic Diptera, such as Simuliidae, do survive in Iceland, but their habits and adaptations differ from those of mosquitoes; Simuliidae for example, though they, like mosquitoes, are bloodsuckers, generally inhabit stones under running water that does not readily freeze and which is totally unsuited to mosquitoes; mosquitoes are generally not adapted to running water.
Eggs of species of mosquitoes from the temperate zones are more tolerant of cold than the eggs of species indigenous to warmer regions. Many even tolerate subzero temperatures. In addition, adults of some species can survive the winter by taking shelter in suitable microhabitats such as buildings or hollow trees.
Means of dispersal.
Worldwide introduction of various mosquito species over large distances into regions where they are not indigenous has occurred through human agencies, primarily on sea routes, in which the eggs, larvae, and pupae inhabiting water-filled used tires and cut flowers are transported. However, apart from sea transport, mosquitoes have been effectively carried by personal vehicles, delivery trucks, trains, and aircraft. Man-made areas such as storm water retention basins, or storm drains also provide sprawling sanctuaries. Sufficient quarantine measures have proven difficult to implement. In addition, outdoor pool areas make a perfect place for them to grow.
Disease.
Mosquitoes can act as vectors for many disease-causing viruses and parasites. Infected mosquitoes carry these organisms from person to person without exhibiting symptoms themselves. Mosquito-borne diseases include:
Potential transmission of HIV was originally a public health concern, but practical considerations and detailed studies of epidemiological patterns suggest that any transmission of the HIV virus by mosquitoes is at worst extremely unlikely.
Various species of mosquitoes are estimated to transmit various types of disease to more than 700 million people annually in Africa, South America, Central America, Mexico, Russia, and much of Asia, with millions of resultant deaths. At least two million people annually die of these diseases, and the morbidity rates are many times higher still.
Methods used to prevent the spread of disease, or to protect individuals in areas where disease is endemic, include:
Since most such diseases are carried by "elderly" female mosquitoes, some scientists have suggested focusing on these to avoid the evolution of resistance.
Control.
Many methods are used for mosquito control. Depending on the situation, the most important usually include:
Source reduction.
"Source reduction" means elimination of breeding places of mosquitoes. It includes engineering measures such as filling, leveling and drainage of breeding places, and water management (such as intermittent irrigation). Source reduction can also be done by making water unsuitable for mosquitoes to breed in (such as changing the salinity of the water if ecologically viable). Some specific measures are:
Details of the biology of different species of mosquitoes differ too widely for any limited set of rules to be sufficient in all circumstances. However, the foregoing are the most economical/ecological and practical measures for most purposes. The importance of peridomestic control arises largely because most species of mosquitoes rarely travel more than a few hundred meters unless the wind is favorable.
Exclusion.
In combination with scrupulous attention to control of breeding areas, window screens and mosquito nets are the most effective measures for residential areas. Insecticide-impregnated mosquito nets are particularly effective because they selectively kill those insects that attack humans, without affecting the general ecology of the area.
An ideal mosquito net is white in color (to allow easy detection of mosquitoes), rectangular, netted on the sides and top, and without a hole. The size of the opening in net should not exceed 1.2 mm (0.05 in) in diameter, or about 23 holes per square centimeter (150 per square inch). Window screens should have copper or bronze gauze with 16 wires per inch.
Biocontrol.
Biological control or "biocontrol" is the use of natural enemies to manage mosquito populations. There are several types of biological control methods including the direct introduction of non-ecologically invasive parasites, pathogens, vegetation, and predators (aquatic and non-aquatic) to target mosquitoes.
Fish.
Various small fishes, such as species of "Galaxias" and members of the Poeciliidae, such as "Gambusia" (so-called mosquitofish), guppies ("Poecilia"), and Banded killifish ("Fundulus diaphanus"), eat mosquito larvae and may sometimes be a viable introduction into ponds to assist in control. Some cyprinids (carps and minnows) and tilapia also consume mosquito larvae. Many other types of fish consume mosquito larvae, including bass, bluegills, piranhas, Arctic char, salmon, trout, catfish, fathead minnows and goldfish.
Some cyclopoid copepods are predators on first-instar larvae, killing up to 40 "Aedes" larvae per day.
Others.
Other predators include dragonfly nymphs, which consume mosquito larvae in the breeding waters, adult dragonflies, which eat adult mosquitoes, and some species of lizard and gecko. Biocontrol agents that have had lesser degrees of success include the predatory mosquito "Toxorhynchites" and predatory crustaceans— such as copepods of the genus "Mesocyclops", nematodes and fungi. Predators such as birds, bats, lizards and frogs, have been used, but their effectiveness is only anecdotal.
Dead spores of the soil bacterium "Bacillus thuringiensis", especially "Bt israelensis" (BTI) interfere with larval digestive systems. It can be dispersed by hand or dropped by helicopter in large areas.
Two species of fungi can kill adult mosquitoes: "Metarhizium anisopliae" and "Beauveria bassiana". as can nematodes. Though important at times, their effectiveness varies with circumstances.
Reproduction.
Introducing large numbers of sterile males is another approach to reducing mosquito numbers.
Experimental genetic methods including cytoplasmic incompatibility, chromosomal translocations, sex distortion and gene replacement have been explored. They are cheaper and not subject to vector resistance. Larvae of the non-biting "Toxorhynchites" mosquitoes are also natural predators of other Culicidae. Each larva can eat 10 to 20 mosquito larvae per day. During its entire development, a "Toxorhynchites" larva can consume an equivalent of 5,000 larvae of the first-instar (L1) or 300 fourth-instar larvae (L4). However, "Toxorhynchites" can consume all types of prey, organic debris, or even exhibit cannibalistic behavior.
"Bacillus thuringiensis israelensis" has also been used to control them as a biological agent.
Repellents.
Insect repellents are applied on skin and give short-term protection against mosquito bites. The chemical DEET repels some mosquitoes and other insects. Some CDC-recommended repellents are picaridin, eucalyptus oil (PMD) and IR3535. Others are indalone, dimethyl phthalate, dimethyl carbate, and ethyl hexanediol.
There are also electronic insect repellent devices which produce ultrasounds that were developed to keep away insects (and mosquitoes). However, no scientific research based on the EPA's and many universities' studies has ever sought evidence that these devices prevent a human from being bitten by a mosquito.
Eradication.
Many scientists have suggested that complete eradication of mosquitoes would not have serious ecological consequences.
Bites and treatment.
Visible, irritating bites are due to an immune response from the binding of IgG and IgE antibodies to antigens in the mosquito's saliva. Some of the sensitizing antigens are common to all mosquito species, whereas others are specific to certain species. There are both immediate hypersensitivity reactions (types I and III) and delayed hypersensitivity reactions (type IV) to mosquito bites. Both reactions result in itching, redness and swelling. Immediate reactions develop within a few minutes of the bite and last for a few hours. Delayed reactions take around a day to develop, and last for up to a week.
Several anti-itch medications are commercially available, including those taken orally, such as Benadryl, or topically applied antihistamines and, for more severe cases, corticosteroids, such as hydrocortisone and triamcinolone.
A study published by the Wageningen University and Research Centre in the Netherlands suggests that sufficiently high temperatures are able to denature IgG.
Evolution.
The oldest known mosquito with an anatomy similar to modern species was found in 79-million-year-old Canadian amber from the Cretaceous. An older sister species with more primitive features was found in Burmese amber that is 90 to 100 million years old. Two mosquito fossils have been found that show very little morphological change in modern mosquitoes against their counterpart from 46 million years ago.
Genetic analyses indicate the Culicinae and Anophelinae clades may have diverged about 150 million years ago. The Old and New World "Anopheles" species are believed to have subsequently diverged about 95 million years ago.
The mosquito "Anopheles gambiae" is currently undergoing speciation into the M(opti) and S(avanah) molecular forms. Consequently, some pesticides that work on the M form no longer work on the S form.
Taxonomy of the Culicidae.
Over 3,500 species of the Culicidae have already been described. They are generally divided into two subfamilies which in turn comprise some 43 genera. These figures are subject to continual change, as more species are discovered, and as DNA studies compel rearrangement of the taxonomy of the family. The two main subfamilies are the Anophelinae and Culicinae, with their genera as shown in the subsection below. The distinction is of great practical importance because the two subfamilies tend to differ in their significance as vectors of different classes of diseases. Roughly speaking, arboviral diseases such as yellow fever and dengue fever tend to be transmitted by Culicine species, not necessarily in the genus "Culex". Some transmit various species of avian malaria, but it is not clear that they ever transmit any form of human malaria. Some species do however transmit various forms of filariasis, much as many Simuliidae do.
Anopheline mosquitoes, again not necessarily in the genus "Anopheles", sometimes bear pathogenic arboviruses, but it is not yet clear that they ever transmit them as effective vectors. However, all the most important vectors of human malaria are Anopheline.
Further reading.
</dl>

</doc>
<doc id="37794" url="http://en.wikipedia.org/wiki?curid=37794" title="Felix Dzerzhinsky">
Felix Dzerzhinsky

Felix Edmundovich Dzerzhinsky (Russian: Фе́ликс Эдму́ндович Дзержи́нский; Polish: "Feliks Dzierżyński" ]; 11 September [O.S. 30 August] 1877 – 20 July 1926), nicknamed Iron Felix, was a Soviet statesman and a prominent member of Polish and Russian revolutionary movements. His party pseudonyms were "Yatsek", "Yakub", "Pereplyotchik", "Franek", "Astronom", "Yuzef", and "Domanski".
He was a member of several revolutionary committees such as the Polish Revkom as well as several Russian and Soviet official positions. Dzerzhinsky is best known for establishing and developing the Soviet secret police forces, serving as their director from 1917 to 1926. Later he was a member of the Soviet government heading several commissariats, while being the chief of the Soviet secret police. The Cheka soon became notorious for mass summary executions, performed especially during the Red Terror and the Russian Civil War.
Early life.
Felix Dzerzhinsky was born on 11 September 1877 at the Dzerzhinovo family estate, about 15 km away from a small town of Ivyanets, in the Minsk Region, a part of the Russian Empire (today Belarus). His aristocratic family belonged to the former Polish "szlachta" (nobility), of the Sulima coat of arms. As a child, before taking to Marxist ideology, Felix considered becoming a Jesuit priest.
His sister Wanda died at the age of 12, when she was accidentally shot with a hunting rifle on the family estate by one of the brothers. At the time of the incident, there were conflicting claims as to who was responsible for the accident Felix or his brother Stanislav.
His father, Edmund-Rufin Dzierżyński, graduated from the Saint Petersburg University in 1863 and moved to Wilno, where he worked as a home teacher for a professor of Saint Petersburg University named Januszewski and eventually married Januszewski's daughter Helena Ignatievna. In 1868, after a short stint in Kherson gymnasium, he worked as a gymnasium teacher of physics and mathematics at the gymnasiums of Taganrog, particularly the Chekhov Gymnasium. In 1875 Edmund Dzierżyński retired due to health conditions and moved with his family to his estate near Ivyanets and Rakaw, Russian Empire. In 1882 Felix's father died from tuberculosis.
As a youngster Dzerzhinsky became fluent in four languages: Polish, Russian, Yiddish, and Latin. He attended the Wilno gymnasium from 1887 to 1895. One of the older students at this gymnasium was his future arch-enemy, Józef Piłsudski. Years later, as Marshal of Poland, Piłsudski recalled that Dzerzhinsky... "distinguished himself as a student with delicacy and modesty. He was rather tall, thin and demure, making the impression of an ascetic with the face of an icon... Tormented or not, this is an issue history will clarify; in any case this person did not know how to lie." School documents show that Dzerzhinsky attended his first year in school twice, while his eighth year he was not able to finish. Dzerzhinsky received a school diploma which stated: "Dzerzhinsky Feliks, who is 18 years of age, of Catholic faith, along with a satisfactory attention and satisfactory diligence showed the following successes in sciences, namely: Divine law—"good"; Logic, Latin, Algebra, Geometry, Mathematical geography, Physics, History (of Russia), French—"satisfactory"; Russian and Greek—"unsatisfactory".
Political affiliations and arrests.
Two months before graduating, Dzerzhinsky was expelled from the gymnasium for "revolutionary activity". He had joined a Marxist group—the Union of Workers (Socjaldemokracja Królestwa Polskiego "SDKP") in 1895. In late April 1896, he was one of 15 delegates at the first congress of the Lithuanian Social Democratic Party (LSDP). In 1897, he attended the second congress of the LSDP where it rejected independence in favour of national autonomy. On 18 March 1897, he was sent to Kaunas, to take advantage of the arrest of the Polish Socialist Party (PPS) branch. He worked in a book-binding factory and set up an illegal press. As an organizer of a shoemaker's strike, Dzerzhinsky was arrested for "criminal agitation among the Kaunas workers" and the police files from this time state that: "Felix Dzerzhinsky, considering his views, convictions and personal character, will be very dangerous in the future, capable of any crime." Dzerzhinsky envisioned merging of the LSDP with the RSDLP and was a follower of Rosa Luxemburg on a national issue.
He was arrested on a denunciation for his revolutionary activities for the first time in 1897 after which he served almost a year in the Kaunas prison. In 1898, Dzerzhinsky was sent for three years to the Vyatka Governorate (city of Nolinsk) where he worked at a local tobacco factory. There Dzerzhinsky was caught for conducting agitation for revolutionary activities and was sent out 500 verst north to the village of Kaigorodskoye. In August 1899, he ran from there back to Wilno. Dzerzhinsky subsequently became one of the founders of Social Democracy of the Kingdom of Poland and Lithuania (SDKPiL) in 1899. In February 1900, he was arrested again and served his time at first in the Alexander Citadel in Warsaw and later at the Siedlce prison. In 1902, Dzerzhinsky was sent deep into Siberia for the next five years in a remote town of Vilyuysk, while "en route" being temporarily held at the Alexandrovsk Transitional Prison near Irkutsk. To the place of exile he ran on a boat and later emigrated out of the country. He then traveled to Berlin where at the SDKPiL conference Dzerzhinsky was elected a secretary of its party committee abroad (KZ) and met with several prominent leaders of the Polish Social Democratic movement Rosa Luxemburg and Leo Jogiches. They gained control of the party organization through the creation of a committee called the "Komitet Zagraniczny"—KZ, which dealt with the party's foreign relations. As secretary of the KZ, Dzerzhinsky was able to dominate the SDKPiL. In Berlin, he organized publishing of "Czerwony Sztandar" and transportation of illegal literature from Kraków to the Congress Poland. Being a delegate to the IV Congress of SDKPiL in 1903 Dzerzhinsky was elected as a member of its General Board.
Dzerzhinsky went to Switzerland where his fiancée Julia Goldman was undergoing treatment for tuberculosis. She died in his arms on 4 June 1904. Her illness and death depressed him; and, in letters to his sister, Dzerzhinsky explained that he no longer saw any meaning for his life. That changed with the Russian Revolution of 1905 as Dzerzhinsky was involved with work again. After the revolution failed, he was again jailed in July 1905, this time by the Okhrana. In October, he was released on amnesty. As a delegate to the 4th Congress of the Russian Social Democratic Labour Party, Dzerzhinsky entered the central body of the party. From July through September 1906, he stayed in Saint Petersburg and then returned to Warsaw where he was arrested again in December of same year. In June 1907, Dzerzhinsky was released on bail. At the 5th Congress of the Russian Social Democratic Labour Party, he was elected in absentia as a member of the Central Committee of the Russian Social-Democratic Labor Party. In April 1908, Dzerzhinsky was arrested once again in Warsaw and in 1909 he was exiled to Siberia again (Yeniseysk Governorate). As before Dzerzhinsky managed to escape by November 1909 to Maxim Gorky on Capri and then back to Poland in 1910.
Back in Kraków in 1910, Dzerzhinsky married party member Zofia Muszkat, who was already pregnant. A month later, she was arrested and she gave birth to their son Janek in Pawiak prison. In 1911, Zofia was sentenced to permanent Siberian exile, and she left the child with her father. Dzerzhinsky saw his son for the first time in March 1912 in Warsaw. In attending the welfare of his child, Dzerzhinsky repeatedly exposed himself to the danger of arrest. On one occasion, Dzerzhinsky narrowly escaped an ambush that the police had prepared at the apartment of his father-in-law.
Dzerzhinsky remained to direct the Social Democratic Party, while considering his continued freedom "only a game of the Okhrana". The Okhrana, however, was not playing a game; Dzerzhinsky simply was a master of conspiratorial techniques and was therefore extremely difficult to find. A police file from this time says: "Dzerzhinsky continued to lead the Social Democratic party and at the same time he directed party work in Warsaw, he led strikes, he published appeals to workers ... and he traveled on party matters to Łódź and Kraków". The police however were unable to arrest Dzerzhinsky until the end of 1912, when they found the apartment where he lived, by the name of Władysław Ptasiński.
Revolution.
Dzerzhinsky would spend the next four and one-half years in tsarist prisons, first at the notorious Tenth Pavilion of the Warsaw Citadel. When World War I began in 1914, all political prisoners were relocated from Warsaw into Russia proper. Dzerzhinsky was taken to Oryol Prison. He was very concerned about the fate of his wife and son, with whom he did not have any communication. Moreover, Dzerzhinsky was beaten frequently by the Russian prison guards, which caused the permanent disfigurement of his jaw and mouth. In 1916 Dzerzhinsky was moved to the Moscow Butyrka prison, where he was soon hospitalized because the chains that he was forced to wear had caused severe cramps in his legs. Despite the prospects of amputation, Dzerzhinsky recovered and was put to labor sewing military uniforms.
Felix Dzerzhinsky was freed from Butyrka after the February Revolution of 1917. Soon after his release, Dzerzhinsky's goal was to organize Polish refugees in Russia and then go back to Poland and fight for the revolution there, writing to his wife: "together with these masses we will return to Poland after the war and become one whole with the SDKPiL". However, he remained in Moscow where he joined the Bolshevik party, writing to his comrades that "the Bolshevik party organization is the only Social Democratic organization of the proletariat, and if we were to stay outside of it, then we would find ourselves outside of the proletarian revolutionary struggle".
Already in April he entered the Moscow Committee of the Bolsheviks and soon thereafter was elected to the Executive Committee of the Moscow Soviet. Dzerzhinsky endorsed Lenin's "April Theses"—demanding uncompromising opposition to the Russian Provisional Government, the transfer of all political authority to the Soviets, and the immediate withdrawal of Russia from the war. Ironically, Dzerzhinsky's brother, Stanislaw, was murdered on the Dzerzhinsky estate by deserting Russian soldiers that same year.
Dzerzhinsky was elected subsequently to the Bolshevik Central Committee at the Sixth Party Congress in late July. He then moved from Moscow to Petrograd to begin his new responsibilities. In Petrograd, Dzerzhinsky participated in the crucial session of the Central Committee in October and he strongly endorsed Lenin's demands for the immediate preparation of a rebellion, after which Felix Dzerzhinsky had an active role with the Military Revolutionary Committee during the October Revolution. With the acquisition of power by the Bolsheviks, Dzerzhinsky eagerly assumed responsibility for making security arrangements at the Smolny Institute where the Bolsheviks had their headquarters.
Director of Cheka.
Lenin regarded Felix Dzerzhinsky as a revolutionary hero and appointed him to organize a force to combat internal threats. On 20 December 1917, the Council of People's Commissars officially established the All-Russia Extraordinary Commission to Combat Counter-revolution and Sabotage—usually known as the Cheka (based on the Russian acronym ВЧК). Dzerzhinsky became its director. The Cheka received a large number of resources, and became known for ruthlessly pursuing any perceived counterrevolutionary elements. As the Russian Civil War expanded, Dzerzhinsky also began organizing internal security troops to enforce the Cheka's authority.
The Cheka undertook drastic measures during the Russian Civil War. Tens of thousands of political opponents were shot without trial in the basements of prisons and in public places. Dzerzhinsky said: "We represent in ourselves organized terror—this must be said very clearly." and "[The Red Terror involves] the terrorization, arrests and extermination of enemies of the revolution on the basis of their class affiliation or of their pre-revolutionary roles."
In 1922, at the end of the Civil War, the Cheka was renamed as the GPU (State Political Directorate), a section of the NKVD. This did not diminish Dzerzhinsky's power; he was Minister of the Interior, director of the Cheka/GPU/OGPU, Minister for Communications, and director of the Vesenkha (Supreme Council of National Economy) 1921–24.
At his office in Lubyanka, Dzerzhinsky kept a portrait of Rosa Luxemburg on the wall.
Besides his leadership of the Cheka, Dzerhinsky also took on a number of other roles; he led the fight against typhus in 1918, was chair of the Commissariat for Internal Affairs from 1919 to 1923, initiated a vast orphanage construction program, chaired the Transport Commissariat, organised the embalming of Lenin's body in 1924 and chaired the Society of Friends of Soviet Cinema.
Dzerzhinsky and Lenin.
Dzerzhinsky became a Bolshevik as late as 1917. Therefore, it was wrong to claim, as the official Soviet historians later did, that Dzerzhinsky had been one of Lenin's oldest and most reliable comrades, or that Lenin had exercised some sort of spellbinding influence on Dzerzhinsky and the SDKPiL. Lenin and Dzerzhinsky frequently had opposing opinions about many important ideological and political issues of the pre-revolutionary period, and also after the October Revolution. After 1917, Dzerzhinsky would oppose Lenin on such crucial issues as the Brest-Litovsk peace, the trade unions, and Soviet nationality policy, during the April 1917 Party Conference when Lenin accused Dzerzhinsky of Great-Russian chauvinism he replied: "I can reproach him (Lenin) with standing at the point of view of the Polish, Ukrainian and other chauvinists." He had creative organizational ability and was willing to perform unwelcome and difficult tasks.
From 1917 to his death in 1926, Dzerzhinsky was first and foremost a Russian Communist, and Dzerzhinsky's involvement in the affairs of the Polish Communist Party (which was founded in 1918) was minimal. The energy and dedication that had previously been responsible for the building of the SDKPiL would henceforth be devoted to the priorities of the struggle for proletarian power in Russia, to the defense of the revolution during the civil war, and eventually, to the tasks of socialist construction.
Death and legacy.
Dzerzhinsky died of heart failure on 20 July 1926 in Moscow, immediately after a two-hour-long speech to the Bolshevik Central Committee during which, visibly quite ill, he violently denounced the United Opposition directed by Leon Trotsky, Grigory Zinoviev, and Lev Kamenev. Upon hearing of his death, Joseph Stalin eulogized Dzerzhinsky as "...a devout knight of the proletariat". Nicholas Roerich and his son George were waiting in the Cheka office to see Dzerzhinsky when they heard of Dzerzhinsky's death. Dzerzhinsky was succeeded as head of the Cheka by fellow ethnic Pole Vyacheslav Menzhinsky.
Dzierżyńszczyzna, one of the two Polish Autonomous Districts in the Soviet Union, was named to commemorate Dzerzhinsky. Located in Belarus, near Minsk and close to the Soviet-Polish border of the time, it was created on 15 March 1932, with the capital at Dzyarzhynsk (Dzerzhynsk, formerly known as Kojdanów). The district was disbanded in 1935 at the onset of the Great Purge and most of its administration was executed. (The Dzerzhinsky estate itself remained inside Poland from 1921 to 1939).
His name and image were used widely throughout the KGB and the Soviet Union—and other socialist countries: there were six towns named after him. The town Kojdanava, which is not very far from the estate, was renamed to Dzyarzhynsk. In Russia there is a city of Dzerzhinsk, a village of Dzerzhinsk and three other cities called Dzerzhinskiy; in former Soviet republics, there are cities named for him in Armenia, Belarus, and Ukraine. A Ukrainian village in the Zhytomyr Oblast was also named Dzerzhinsk until 2005 when it was renamed Romaniv. The Dzerzhinskiy Tractor Works in Stalingrad were named in his honor and became a scene of bitter fighting during the Second World War. The FED camera, produced from 1934 to 1990, is named for him, as was the FD class steam locomotive.
The "Iron Felix".
"Iron Felix" also refers to a 15-ton iron monument of Dzerzhinsky, which once dominated the Lubyanka Square in Moscow, near the KGB headquarters. It was built in 1958 by the sculptor Yevgeny Vuchetich and was a Moscow landmark during Soviet times. Symbolically, the Memorial to the Victims of the Gulag (a simple stone from Solovki) was erected beside the Iron Felix and the latter was removed in August 1991, after the failed coup d'état attempt by hard-line Communist members of the government. A mock-up of the removal of Dzerzhinsky's statue can be found in the entrance hall of the International Spy Museum in Washington, D.C.
The figure of Dzerzhinsky remains controversial in the Russian society. The return of the statue to its plinth was proposed six times during the 1999-2013 period. The proposals were rejected by the Monument Art Commission of the Moscow City Duma due to concerns that this would cause "unnecessary tension" in the society. According to a December 2013 VTSIOM poll, 45% of Russians favor the restoration of the statue to the Lubyanka Square, with 25% unconditionally opposing it. The statue remained in a yard for old Soviet memorials at the Central House of Artists. A smaller bust of Dzerzhinsky in the courtyard of the Moscow police headquarters at Petrovka 38 was restored in November 2005 (this bust had been removed by the police officers on 22 August 1991).
Other statues.
As it was a symbol of the Soviet Union and its domination over Poland, his monument in Dzerzhinsky Square (pl. Plac Dzierżyńskiego) in the center of Warsaw was toppled in 1989 as the Polish United Workers' Party lost power as part of the collapse of communism. The name of the square was soon changed to its pre–Second World War name, "Bank Square" (pl: "Plac Bankowy").
A 10-foot bronze replica of the original Iron Felix statue was placed on the grounds of the military academy in Minsk, Belarus, in May 2006.
In April 2012, the Moscow authorities stated that they would be renovating the "Iron Felix" monument in full and put the statue on a list of monuments to be renovated, as well as officially designated it an object of cultural heritage.
Dzerzhinovo.
In 2005, the Government of Belarus rebuilt the manor house of Dzerzhinovo, where Dzerzhinsky was born, and established a museum. Annually, the graduating class of the KDB academy holds its swearing-in at the manor. In 1943, the manor had been destroyed and family members (including Dzerzhinsky's brother Kazimierz) were killed by the Germans, because of their support for the Polish Home Army.

</doc>
<doc id="37796" url="http://en.wikipedia.org/wiki?curid=37796" title="West Nile virus">
West Nile virus

West Nile virus (WNV) is a mosquito-borne zoonotic arbovirus belonging to the genus "Flavivirus" in the family "Flaviviridae". This flavivirus is found in temperate and tropical regions of the world. It was first identified in the West Nile subregion in the East African nation of Uganda in 1937. Prior to the mid-1990s, WNV disease occurred only sporadically and was considered a minor risk for humans, until an outbreak in Algeria in 1994, with cases of WNV-caused encephalitis, and the first large outbreak in Romania in 1996, with a high number of cases with neuroinvasive disease. WNV has now spread globally, with the first case in the Western Hemisphere being identified in New York City in 1999; over the next five years, the virus spread across the continental United States, north into Canada, and southward into the Caribbean islands and Latin America. WNV also spread to Europe, beyond the Mediterranean Basin, and a new strain of the virus was identified in Italy in 2012. 
WNV is now considered to be an endemic pathogen in Africa, Asia, Australia, the Middle East, Europe and in the United States, which in 2012 has experienced one of its worst epidemics. In 2012, WNV killed 286 people in the United States, with the state of Texas being hard hit by this virus, making the year the deadliest on record for the United States.
The main mode of WNV transmission is via various species of mosquitoes, which are the prime vector, with birds being the most commonly infected animal and serving as the prime reservoir host—especially passerines, which are of the largest order of birds, Passeriformes. WNV has been found in various species of ticks, but current research suggests they are not important vectors of the virus. WNV also infects various mammal species, including humans, and has been identified in reptilian species, including alligators and crocodiles, and also in amphibians. Not all animal species that are susceptible to WNV infection, including humans, and not all bird species develop sufficient viral levels to transmit the disease to uninfected mosquitoes, and are thus not considered major factors in WNV transmission.
Approximately 80% of West Nile virus infections in humans are subclinical, which cause no symptoms. In the cases where symptoms do occur—termed West Nile fever in cases without neurological disease—the time from infection to the appearance of symptoms (incubation period) is typically between 2 and 15 days. Symptoms may include fever, headaches, fatigue, muscle pain or aches (myalgias), malaise, nausea, anorexia, vomiting, and rash. Less than 1% of the cases are severe and result in neurological disease when the central nervous system is affected. People of advanced age, the very young, or those with immunosuppression, either medically induced, such as those taking immunosupressive drugs, or due to a pre-existing medical condition such as HIV infection, are most susceptible. The specific neurological diseases that may occur are West Nile encephalitis, which causes inflammation of the brain, West Nile meningitis, which causes inflammation of the meninges, which are the protective membranes that cover the brain and spinal cord, West Nile meningoencephalitis, which causes inflammation of the brain and also the meninges surrounding it, and West Nile poliomyelitis—spinal cord inflammation, which results in a syndrome similar to polio, which may cause acute flaccid paralysis.
Currently, no vaccine against WNV infection is available. The best method to reduce the rates of WNV infection is mosquito control on the part of municipalities, businesses and individual citizens to reduce breeding populations of mosquitoes in public, commercial and private areas via various means including eliminating standing pools of water where mosquitoes breed, such as in old tires, buckets, unused swimming pools, etc. On an individual basis, the use of personal protective measures to avoid being bitten by an infected mosquito, via the use of mosquito repellent, window screens, avoiding areas where mosquitoes are more prone to congregate, such as near marshes, areas with heavy vegetation etc., and being more vigilant from dusk to dawn when mosquitoes are most active offers the best defense. In the event of being bitten by an infected mosquito, familiarity of the symptoms of WNV on the part of laypersons, physicians and allied health professions affords the best chance of receiving timely medical treatment, which may aid in reducing associated possible complications and also appropriate palliative care.
Signs and symptoms.
The incubation period for WNV—the amount of time from infection to symptom onset—is typically from between 2 and 15 days. Headache can be a prominent symptom of WNV fever, meningitis, encephalitis, meningoencephalitis, and it may or may not be present in poliomyelytis-like syndrome. Thus, headache is not a useful indicator of neuroinvasive disease.(CDC)
Virology.
WNV is one of the Japanese encephalitis antigenic serocomplex of viruses.
Image reconstructions and cryoelectron microscopy reveal a 45–50 nm virion covered with a relatively smooth protein surface. This structure is similar to the dengue fever virus; both belong to the genus "Flavivirus" within the family "Flaviviridae". The genetic material of WNV is a positive-sense, single strand of RNA, which is between 11,000 and 12,000 nucleotides long; these genes encode seven nonstructural proteins and three structural proteins. The RNA strand is held within a nucleocapsid formed from 12-kDa protein blocks; the capsid is contained within a host-derived membrane altered by two viral glycoproteins.
Phylogeny.
Studies of phylogenetic lineages determined WNV emerged as a distinct virus around 1000 years ago. This initial virus developed into two distinct lineages, lineage 1 and its multiple profiles is the source of the epidemic transmission in Africa and throughout the world. Lineage 2 was considered an Africa zoonosis. However, in 2008, lineage 2, previously only seen in horses in sub-Saharan Africa and Madagascar, began to appear in horses in Europe, where the first known outbreak affected 18 animals in Hungary in 2008. Lineage 1 West Nile virus was detected in South Africa in 2010 in a mare and her aborted fetus; previously, only lineage 2 West Nile virus had been detected in horses and humans in South Africa. A 2007 fatal case in a killer whale in Texas broadened the known host range of West Nile virus to include cetaceans.
The United States virus was very closely related to a lineage 1 strain found in Israel in 1998. Since the first North American cases in 1999, the virus has been reported throughout the United States, Canada, Mexico, the Caribbean, and Central America. There have been human cases and equine cases, and many birds are infected. The Barbary macaque, "Macaca sylvanus", was the first nonhuman primate to contract WNV. Both the United States and Israeli strains are marked by high mortality rates in infected avian populations; the presence of dead birds—especially Corvidae—can be an early indicator of the arrival of the virus.
Transmission.
West Nile virus (WNV) is transmitted through female mosquitoes, which are the prime vectors of the virus. Only females feed on blood, and different species take a blood meal's from different types of vertebrate hosts. The important mosquito vectors vary according to geographical area; in the United States, "Culex pipiens" (Eastern United States, and urban and residential areas of the United States north of 36-39°N), "Culex tarsalis" (Midwest and West), and "Culex quinquefasciatus" (Southeast) are the main vector species.
The mosquito species that are most frequently infected with WNV feed primarily on birds. Mosquitoes show further selectivity, exhibiting preference for different species of birds. In the United States, WNV mosquito vectors feed on members of the Corvidae and thrush family more often that would be expected from their abundance. Among the preferred species within these families are the American crow, a corvid, and the American robin ("Turdus migratorius"), a thrush.
Some species of birds develop sufficient viral levels (>~104.2 log PFU/ml;) after being infected to transmit the infection to biting mosquitoes that in turn go on to infect other birds. In birds that die from WNV, death usually occurs 4–6 days. In mammals, and several species of birds the virus does not multiply as readily (i.e., does not develop high viremia during infection), and mosquitoes biting infected these hosts are not believed to ingest sufficient virus to become infected, making them so-called dead-end hosts. As a result of the differential infectiousness of hosts, the feeding patterns of mosquitoes play an important role in WNV transmission, and they are partly genetically controlled, even within a species.
Direct human-to-human transmission initially was believed to be caused only by occupational exposure, such as in a laboratory setting, or conjunctive exposure to infected blood. The US outbreak identified additional transmission methods through blood transfusion, organ transplant, intrauterine exposure, and breast feeding. Since 2003, blood banks in the United States routinely screen for the virus among their donors. As a precautionary measure, the UK's National Blood Service initially ran a test for this disease in donors who donate within 28 days of a visit to the United States, Canada, or the northeastern provinces of Italy, and the Scottish National Blood Transfusion Service asks prospective donors to wait 28 days after returning from North America or the northeastern provinces of Italy before donating.
Recently, the potential for mosquito saliva to affect the course of WNV disease was demonstrated. Mosquitoes inoculate their saliva into the skin while obtaining blood. Mosquito saliva is a pharmacological cocktail of secreted molecules, principally proteins, that can affect vascular constriction, blood coagulation, platelet aggregation, inflammation, and immunity. It clearly alters the immune response in a manner that may be advantageous to a virus. Studies have shown it can specifically modulate the immune response during early virus infection, and mosquito feeding can exacerbate WNV infection, leading to higher viremia and more severe forms of disease.
Vertical transmission.
Vertical transmission, the transmission of a viral or bacterial disease from the female of the species to her offspring, has been observed in various West Nile virus studies, amongst different species of mosquitoes in both the laboratory and in nature. Mosquito progeny infected vertically in autumn, may potentially serve as a mechanism for WNV to overwinter and initiate enzootic horizontal transmission the following spring, although it likely plays little role in transmission in the summer and fall.
Risk factors.
Risk factors independently associated with developing a clinical infection with WNV include a suppressed immune system and a patient history of organ transplantation. For neuroinvasive disease the additional risk factors include older age (>50+), male sex, hypertension, and diabetes mellitus.
A genetic factor also appears to increase susceptibility to West Nile disease. A mutation of the gene "CCR5" gives some protection against HIV but leads to more serious complications of WNV infection. Carriers of two mutated copies of "CCR5" made up 4.0 to 4.5% of a sample of West Nile disease sufferers, while the incidence of the gene in the general population is only 1.0%.
Diagnosis.
Preliminary diagnosis is often based on the patient's clinical symptoms, places and dates of travel (if patient is from a nonendemic country or area), activities, and epidemiologic history of the location where infection occurred. A recent history of mosquito bites and an acute febrile illness associated with neurologic signs and symptoms should cause clinical suspicion of WNV.
Diagnosis of West Nile virus infections is generally accomplished by serologic testing of blood serum or cerebrospinal fluid (CSF), which is obtained via a lumbar puncture.
Typical findings of WNV infection include lymphocytic pleocytosis, elevated protein level, reference glucose and lactic acid levels, and no erythrocytes.
Definitive diagnosis of WNV is obtained through detection of virus-specific antibody IgM and neutralizing antibodies. Cases of West Nile virus meningitis and encephalitis that have been serologically confirmed produce similar degrees of CSF pleocytosis and are often associated with substantial CSF neutrophilia.
Specimens collected within eight days following onset of illness may not test positive for West Nile IgM, and testing should be repeated. A positive test for West Nile IgG in the absence of a positive West Nile IgM is indicative of a previous flavavirus infection and is not by itself evidence of an acute West Nile virus infection.
If cases of suspected West Nile virus infection, sera should be collected on both the acute and
convalescent phases of the illness. Convalescent specimens should be collected 2–3 weeks after acute specimens.
It is common in serologic testing for cross-reactions to occur among flaviviruses such as dengue virus (DENV) and tick-borne encephalitis virus; this necessitates caution when evaluating serologic results of flaviviral infections.
Four FDA-cleared WNV IgM ELISA kits are commercially available from different manufacturers in the U.S., each of these kits is indicated for use on serum to aid in the presumptive laboratory diagnosis of WNV infection in patients with clinical symptoms of meningitis or encephalitis. Positive WNV test kits obtained via use of these kits should be confirmed by additional testing at a state health department laboratory or CDC.
In fatal cases, nucleic acid amplification, histopathology with immunohistochemistry, and virus culture of autopsy tissues can also be useful. Only a few state laboratories or other specialized laboratories, including those at CDC, are capable of doing this specialized testing
Differential diagnosis.
A number of various diseases may present with symptoms similar to those caused by a clinical West Nile virus infection. Those causing neuroinvasive disease symptoms include the enterovirus infection and bacterial meningitis. Accounting for differential diagnoses is a crucial step in the definitive diagnosis of WNV infection. Consideration of a differential diagnosis is required when a patient presents with unexplained febrile illness, extreme headache, encephalitis or meningitis. Diagnostic and serologic laboratory testing using Polymerase chain reaction testing and viral culture of CSF to identify the specific pathogen causing the symptoms, is the only currently available means of differentiating between causes of encephalitis and meningitis.
Prevention.
Personal protective measures can be taken to greatly reduce the risk of being bitten by an infected mosquito:
Monitoring and control.
West Nile virus can be sampled from the environment by the pooling of trapped mosquitoes via ovitraps, carbon dioxide-baited light traps, and gravid traps, testing blood samples drawn from wild birds, dogs, and sentinel monkeys, as well as testing brains of dead birds found by various animal control agencies and the public.
Testing of the mosquito samples requires the use of RT-PCR to directly amplify and show the presence of virus in the submitted samples. When using the blood sera of wild birds and sentinel chickens, samples must be tested for the presence of WNV antibodies by use of immunohistochemistry (IHC) or Enzyme-Linked Immunosorbent Assay (ELISA).
Dead birds, after necropsy, or their oral swab samples collected on specific RNA-preserving filter paper card, can have their virus presence tested by either RT-PCR or IHC, where virus shows up as brown-stained tissue because of a substrate-enzyme reaction.
West Nile control is achieved through mosquito control, by elimination of mosquito breeding sites such as abandoned pools, applying larvacide to active breeding areas, and targeting the adult population via lethal ovitraps and aerial spraying of pesticides.
Environmentalists have condemned attempts to control the transmitting mosquitoes by spraying pesticide, saying the detrimental health effects of spraying outweigh the relatively few lives that may be saved, and more environmentally friendly ways of controlling mosquitoes are available. They also question the effectiveness of insecticide spraying, as they believe mosquitoes that are resting or flying above the level of spraying will not be killed; the most common vector in the northeastern United States, "Culex pipiens", is a canopy feeder.
<Gallery>
File:CDC-LightTrap 200.jpg|A carbon dioxide-baited CDC light trap at NPSmonitoring site: The highest individual light trap total for 2010 was from a trap located in a salt marsh in the Fire Island National Seashore: around 25,142 mosquitoes were collected during a 16-hour period on August 31.
File:Culex sp larvae.png|Eggs of permanent water mosquitoes can hatch, and the larvae survive, in only a few ounces of water. Less than half the amount that may collect in a discarded coffee cup. Floodwater species lay their eggs on wet soil or other moist surfaces. Hatch time is variable for both types; under favorable circumstances, i.e. warm weather, the eggs of some species may hatch in as few as 1–3 days after being laid.
File:Used tires.jpg|Used tires often hold stagnant water and are a breeding ground for many species of mosquitoes. Some species such as the Asian tiger mosquito prefer manmade containers, such as tires, in which to lay their eggs. The rapid spread of this aggressive daytime feeding species beyond their native range has been attributed to the used tire trade.
</Gallery>
Treatment.
No specific treatment is available for WNV infection. In severe cases treatment consists of supportive care that often involves hospitalization, intravenous fluids, respiratory support, and prevention of secondary infections.
Prognosis.
While the general prognosis is favorable, current studies indicate that West Nile Fever can often be more severe than previously recognized, with studies of various recent outbreaks indicating that it may take as long as 60–90 days to recover. Patients with milder WNF are just as likely as those with more severe manifestations of neuroinvasive disease to experience multiple long term (>1+ years) somatic complaints such as tremor, and dysfunction in motor skills and executive functions. Patients with milder illness are just as likely as patients with more severe illness to experience adverse outcomes. Recovery is marked by a long convalescence with fatigue. One study found that neuroinvasive WNV infection was associated with an increased risk for subsequent kidney disease.
Epidemiology.
WNV was first isolated from a feverish 37-year-old woman at Omogo in the West Nile District of Uganda in 1937 during research on yellow fever virus. A series of serosurveys in 1939 in central Africa found anti-WNV positive results ranging from 1.4% (Congo) to 46.4% (White Nile region, Sudan). It was subsequently identified in Egypt (1942) and India (1953), a 1950 serosurvey in Egypt found 90% of those over 40 years in age had WNV antibodies. The ecology was characterized in 1953 with studies in Egypt and Israel. The virus became recognized as a cause of severe human meningoencephalitis in elderly patients during an outbreak in Israel in 1957. The disease was first noted in horses in Egypt and France in the early 1960s and found to be widespread in southern Europe, southwest Asia and Australia.
The first appearance of WNV in the Western Hemisphere was in 1999 with encephalitis reported in humans, dogs, cats, and horses, and the subsequent spread in the United States may be an important milestone in the evolving history of this virus. The American outbreak began in College Point, Queens in New York City and was later spread to the neighboring states of New Jersey and Connecticut. The virus is believed to have entered in an infected bird or mosquito, although there is no clear evidence. West Nile virus is now endemic in Africa, Europe, the Middle East, west and central Asia, Oceania (subtype Kunjin), and most recently, North America and is spreading into Central and South America.
Recent outbreaks of West Nile virus encephalitis in humans have occurred in Algeria (1994), Romania (1996 to 1997), the Czech Republic (1997), Congo (1998), Russia (1999), the United States (1999 to 2009), Canada (1999–2007), Israel (2000) and Greece (2010).
Epizootics of disease in horses occurred in Morocco (1996), Italy (1998), the United States (1999 to 2001), and France (2000), Mexico (2003) and Sardinia (2011).
Research.
A vaccine for horses (ATCvet code: QI05) based on killed viruses exists; some zoos have given this vaccine to their birds, although its effectiveness is unknown. Dogs and cats show few if any signs of infection. There have been no known cases of direct canine-human or feline-human transmission; although these pets can become infected, it is unlikely they are, in turn, capable of infecting native mosquitoes and thus continuing the disease cycle.
AMD3100, which had been proposed as an antiretroviral drug for HIV, has shown promise against West Nile encephalitis. Morpholino antisense oligos conjugated to cell penetrating peptides have been shown to partially protect mice from WNV disease. There have also been attempts to treat infections using ribavirin, intravenous immunoglobulin, or alpha interferon. GenoMed, a U.S. biotech company, has found that blocking angiotensin II can treat the "cytokine storm" of West Nile virus encephalitis as well as other viruses.
A vaccine called Chimerivax-WNV is being actively researched and has undergone phase II Clinical trials in 2011.

</doc>
<doc id="37797" url="http://en.wikipedia.org/wiki?curid=37797" title="Hilbert's paradox of the Grand Hotel">
Hilbert's paradox of the Grand Hotel

Hilbert's paradox of the Grand Hotel is a veridical paradox (a valid argument with a seemingly absurd conclusion, as opposed to a "falsidical paradox", which is a seemingly valid demonstration of an actual contradiction) about infinite sets meant to illustrate certain counterintuitive properties of infinite sets. The idea was introduced by David Hilbert in a lecture he gave in 1924 and was popularized through George Gamow's 1947 book "One Two Three... Infinity".
The paradox.
Consider a hypothetical hotel with a countably infinite number of rooms, all of which are occupied. One might be tempted to think that the hotel would not be able to accommodate any newly arriving guests, as would be the case with a finite number of rooms.
Finitely many new guests.
Suppose a new guest arrives and wishes to be accommodated in the hotel. Because the hotel has infinite rooms, we can move any guest occupying any room n to room n+1, then fit the newcomer into room 1. By repeating this procedure, it is possible to make room for any finite number of new guests.
Infinitely many new guests.
It is also possible to accommodate a "countably infinite" number of new guests: just move the person occupying room 1 to room 2, the guest occupying room 2 to room 4, and, in general, the guest occupying room "n" to room 2"n", and all the odd-numbered rooms (which are countably infinite) will be free for the new guests.
Infinitely many coaches with infinitely many guests each.
It is possible to accommodate countably infinitely many coachloads of countably infinite passengers each, by several different methods. Most methods depend on the seats in the coaches being already numbered (alternatively, the hotel manager must have the axiom of countable choice at his or her disposal). In general any pairing function can be used to solve this problem. For each of these methods, consider a passenger's seat number on a coach to be formula_1, and their coach number to be formula_2, and the numbers formula_1 and formula_2 are then fed into the two arguments of the pairing function.
Prime powers method.
Empty the odd numbered rooms by sending the guest in room formula_5 to room formula_6, then put the first coach's load in rooms formula_7, the second coach's load in rooms formula_8; for coach number formula_2 we use the rooms formula_10 where formula_11 is the formula_2th odd prime number. This solution leaves certain rooms empty (which may or may not be useful to the hotel); specifically, all odd numbers that are not prime powers, such as 15 or 847, will no longer be occupied. (So, strictly speaking, this shows that the number of arrivals is "less than or equal to" the number of vacancies created. It is easier to show, by an independent means, that the number of arrivals is also "greater than or equal to" the number of vacancies, and thus that they are "equal", than to modify the algorithm to an exact fit.) (The algorithm works equally well if one interchanges formula_1 and formula_2, but whichever choice is made, it must be applied uniformly throughout.)
Interleaving method.
For each passenger, compare the lengths of formula_1 and formula_2 as written in decimal. (Treat each hotel resident as being in coach #0.) If either number is shorter, add leading zeroes to it until both values have the same number of digits. Interleave the digits to produce a room number: its digits will be [first digit of coach number]-[first digit of seat number]-[second digit of coach number]-[second digit of seat number]-etc. The hotel (coach #0) guest in room number 1729 moves to room 01070209 (i.e., room 1,070,209.) The passenger on seat 1234 of coach 789 goes to room 01728394 (or just 1728394).
Unlike the prime powers solution, this one fills the hotel completely, and we can extrapolate a guest's original coach and seat by reversing the interleaving process. First add a leading zero if the room has an odd number of digits. Then de-interleave the number into two numbers: the seat number consists of the odd-numbered digits and the coach number is the even-numbered ones. Of course, the original encoding is arbitrary, and the roles of the two numbers can be reversed (seat-odd and coach-even), so long as it is applied consistently.
Triangular number method.
Those already in the hotel will be moved to room formula_17, or the formula_1th triangular number. Those in a coach will be in room formula_19, or the formula_20 triangular number, plus formula_21. In this way all the rooms will be filled by one, and only one, guest.
This pairing function can be demonstrated visually by structuring the hotel as a one-room-deep, infinitely tall pyramid. The pyramid's topmost row is a single room: room 1; its second row is rooms 2 and 3; and so on. The column formed by the set of rightmost rooms will correspond to the triangular numbers. Once they are filled (by the hotel's redistributed occupants), the remaining empty rooms form the shape of a pyramid exactly identical to the original shape. Thus, the process can be repeated for each infinite set. Doing this one at a time for each coach would require an infinite number of steps, but by using the prior formulas, a guest can determine what his room "will be" once his coach has been reached in the process, and can simply go there immediately.
Further layers of infinity.
Suppose the hotel is next to an ocean, and an infinite number of aircraft carriers arrive, each bearing an infinite number of coaches, each with an infinite number of passengers. This is a situation involving three "levels" of infinity, and it can be solved by extensions of any of the previous solutions.
The prime power solution can be applied with further exponentiation of prime numbers, resulting in very large room numbers even given small inputs. For example, the passenger in the second seat of the third bus on the second aircraft carrier (address 2-3-2) would raise the 2nd odd prime (5) to 49, which is the result of the 3rd odd prime (7) being raised to the power of his seat number (2). This room number would have over thirty decimal digits.
The interleaving method can be used with three interleaved "strands" instead of two. The passenger with the address 2-3-2 would go to room 232, while the one with the address 4935-198-82217 would go to room #008,402,912,391,587 (the leading zeroes can be removed).
Anticipating the possibility of any number of layers of infinite guests, the hotel may wish to assign rooms such that no guest will need to move, no matter how many guests arrive afterward. One solution is to convert each arrival's address into a binary number in which ones are used as separators at the start of each layer, while a number within a given layer (such as a guests' coach number) is represented with that many zeroes. Thus, a guest with the prior address 2-5-1-3-1 (five infinite layers) would go to room 10010000010100010 (decimal 295458).
As an added step in this process, one zero can be removed from each section of the number; in this example, the guest's new room is 101000011001 (decimal 2585). This ensures that every room could be filled by a hypothetical guest. If no infinite sets of guests arrive, then only rooms that are a power of two will be occupied.
Infinite layers of nesting.
Although a room can be found for any finite number of nested infinities of people, the same is not always true for an infinite number of layers, even if a finite number of elements exists at each layer. For example, suppose some people arrive in a set of flying saucer spaceships which are nested in accordance to the following rules: the smallest ships, each 100 cubic meters in volume, contain ten people. After this, every ship (of any size) is grouped with nine other ships of the same size, inside a mothership exactly 100 times the volume of each of its ten daughter ships. All ships of the same size are isomorphic to one another; for example, each 1,000,000-cubic-meter ship contains exactly ten 10,000-cubic-meter ships, each of which contains exactly ten 100-cubic-meter ships, each containing ten people. This extends upward infinitely, so that there is no "largest ship".
A given passenger's address in this system would be infinite in length, corresponding to the decimal form of one of the real numbers ranging from 0 (address 0-0-0...) to 1 (address 9-9-9...). Exactly one guest would have the address corresponding to one-sixth (1-6-6-6...), for example, and another to the value of pi minus three (1-4-1-5...). The set of real numbers, and the set of guests in this example, is uncountably infinite. Because no one-to-one pairing can be made between countable and uncountable sets, rooms at the hotel cannot be made for all of these guests, although any countably infinite subset of them can still be accommodated -- for example, the set of guests whose addresses terminate in an infinitely repeating sequence, corresponding to a rational number.
If this variant is modified in certain ways, then the set of people is countable again. For example, suppose there "were" a largest ship, directly containing a finite (or countably infinite) number of both ships and people, and each of these ships in turn contained both ships and people, and so forth. This time, any given person is a finite number of levels "down" from the top, and thus can be identified with a unique finite address. The set of people is countable again, even if the total number of layers is infinite, because we do not have to consider an "infinitieth layer" in either direction.
Analysis.
These cases constitute a paradox not in the sense that they entail a logical contradiction, but in the sense that they demonstrate a counter-intuitive result that is provably true: the statements "there is a guest to every room" and "no more guests can be accommodated" are not equivalent when there are infinitely many rooms. An analogous situation is presented in Cantor's diagonal proof.
Initially, this state of affairs might seem to be counter-intuitive. The properties of "infinite collections of things" are quite different from those of "finite collections of things". The paradox of Hilbert's Grand Hotel can be understood by using Cantor's theory of transfinite numbers. Thus, while in an ordinary (finite) hotel with more than one room, the number of odd-numbered rooms is obviously smaller than the total number of rooms. However, in Hilbert's aptly named Grand Hotel, the quantity of odd-numbered rooms is not smaller than total "number" of rooms. In mathematical terms, the cardinality of the subset containing the odd-numbered rooms is the same as the cardinality of the set of all rooms. Indeed, infinite sets are characterized as sets that have proper subsets of the same cardinality. For countable sets (sets with the same cardinality as the natural numbers) this cardinality is formula_22.
Rephrased, for any countably infinite set, there exists a bijective function which maps the countably infinite set to the set of natural numbers, even if the countably infinite set contains the natural numbers. For example, the set of rational numbers—those numbers which can be written as a quotient of integers—contains the natural numbers as a subset, but is no bigger than the set of natural numbers since the rationals are countable: There is a bijection from the naturals to the rationals.
The Grand Hotel Cigar Mystery.
Another story regarding the Grand Hotel can be used to show that mathematical induction only works from an induction basis.
Suppose that the Grand Hotel does not allow smoking, and no cigars may be taken into the Hotel. Despite this, the guest in room 1 goes to the guest in room 2 to get a cigar. The guest in room 2 goes to room 3 to get two cigars—one for himself and one for the guest in room 1. In general, the guest in room N goes to room (N+1) to get N cigars. They each return, smoke one cigar and give the rest to the guest from room (N-1). Thus despite the fact no cigars have been brought into the hotel, each guest can smoke a cigar inside the property.
The fallacy of this story derives from the fact that there is no inductive point (base-case) from which the induction can derive. Although it is shown that if the guest from room N has N cigars then both he and all guests in lower-numbered rooms can smoke, it is never proved that any of the guests actually have cigars. Therefore it does not follow that any guest can smoke a cigar inside the Hotel. The fact that the story mentions that cigars are not allowed into the hotel is designed to highlight the fallacy. However, since there is an infinite number of rooms in the hotel and each guest (N) must go to guest (N+1) for his cigar, this process of going up one room never ends and no cigars are ever smoked.

</doc>
<doc id="37799" url="http://en.wikipedia.org/wiki?curid=37799" title="Thor Heyerdahl">
Thor Heyerdahl

Thor Heyerdahl (]; October 6, 1914 – April 18, 2002) was a Norwegian adventurer and ethnographer with a background in zoology, botany, and geography. He became notable for his "Kon-Tiki" expedition in 1947, in which he sailed 8,000 km (5,000 mi) across the Pacific Ocean in a hand-built raft from South America to the Tuamotu Islands. The expedition was designed to demonstrate that ancient people could have made long sea voyages, creating contacts between separate cultures. This was linked to a diffusionist model of cultural development. Heyerdahl subsequently made other voyages designed to demonstrate the possibility of contact between widely separated ancient people. He was appointed a government scholar in 1984.
In May 2011, the Thor Heyerdahl Archives were added to UNESCO's "Memory of the World" Register. At the time, this list included 238 collections from all over the world. The Heyerdahl Archives span the years 1937 to 2002 and include his photographic collection, diaries, private letters, expedition plans, articles, newspaper clippings, original book, and article manuscripts. The Heyerdahl Archives are administered by the Kon-Tiki Museum and the National Library of Norway in Oslo.
Youth and personal life.
Heyerdahl was born in Larvik, Norway, the son of master brewer Thor Heyerdahl and his wife, Alison Lyng. As a young child, Heyerdahl showed a strong interest in zoology. He created a small museum in his childhood home, with a common adder ("Vipera berus") as the main attraction. He studied zoology and geography at the faculty of biological science at the University of Oslo. At the same time, he privately studied Polynesian culture and history, consulting what was then the world's largest private collection of books and papers on Polynesia, owned by Bjarne Kropelien, a wealthy wine merchant in Oslo. (This collection was later purchased by the University of Oslo Library from Kropelien's heirs and was attached to the Kon-Tiki Museum research department.) After seven terms and consultations with experts in Berlin, a project was developed and sponsored by Heyerdahl's zoology professors, Kristine Bonnevie and Hjalmar Broch. He was to visit some isolated Pacific island groups and study how the local animals had found their way there.
Just before sailing together to the Marquesas Islands in 1936, Heyerdahl married his first wife, Liv Coucheron-Torp (1916–1969), whom he had met shortly before enrolling at the university, and who had studied economics there. The couple had two sons; Thor Jr and Bjørn. The marriage ended in divorce.
After the Occupation of Norway by Nazi Germany he served with the Free Norwegian Forces from 1944, in the far north province of Finnmark.
In 1949 Heyerdahl married Yvonne Dedekam-Simonsen (1924–2006). They had three daughters: Annette, Marian and Helene Elisabeth. They were divorced in 1969. Heyerdahl blamed their separation on his being away from home and differences in their ideas for bringing up children. In his autobiography, he concluded that he should take the entire blame for their separation.
In 1991, Heyerdahl married Jacqueline Beer (born 1932) as his third wife. They lived in Tenerife, Canary Islands and were very actively involved with archaeological projects, especially in Túcume, Peru, and Azov until his death in 2002. He still had been hoping to undertake an archaeological project in Samoa before he died.
Heyerdahl died on April 18, 2002, in Colla Micheri, Liguria, Italy, where he had gone to spend the Easter holidays with some of his closest family members. The Norwegian government gave him a state funeral in Oslo Cathedral on April 26, 2002. He is buried in the garden of the family home in Colla Micheri.
Fatu Hiva.
The events surrounding his stay on the Marquesas, most of the time on Fatu Hiva, were told first in his book "På Jakt etter Paradiset" ("Hunt for Paradise") (1938), which was published in Norway but, following the outbreak of World War II, never translated and largely forgotten. Many years later, having achieved notability with other adventures and books on other subjects, Heyerdahl published a new account of this voyage under the title "Fatu Hiva" (London: Allen & Unwin, 1974). The story of his time on Fatu Hiva and his side trip to Hivaoa and Mohotani is also related in "Green Was the Earth on the Seventh Day " (Random House, 1996).
"Kon-Tiki" expedition.
In 1947, Heyerdahl and five fellow adventurers sailed from Peru to the Tuamotus, French Polynesia, in a pae-pae raft they constructed from balsa wood and other native materials, and christened the "Kon-Tiki". The "Kon-Tiki" expedition was inspired by old reports and drawings made by the Spanish Conquistadors of Inca rafts, and by native legends and archaeological evidence suggesting contact between South America and Polynesia. On August 7, 1947, after a 101-day, 4,300 nautical mile (4,948 miles or 7,964 km) journey across the Pacific Ocean, the "Kon-Tiki" smashed into the reef at Raroia in the Tuamotu Islands. Heyerdahl, who had nearly drowned at least twice in childhood and did not take easily to water, said later that there were times in each of his raft voyages when he feared for his life.
"Kon-Tiki" demonstrated that it was possible for a primitive raft to sail the Pacific with relative ease and safety, especially to the west (with the trade winds). The raft proved to be highly maneuverable, and fish congregated between the nine balsa logs in such numbers that ancient sailors could have possibly relied on fish for hydration in the absence of other sources of fresh water. Inspired by "Kon-Tiki", other rafts have repeated the voyage. Heyerdahl's book about the expedition, "", has been translated into 70 languages. The documentary film of the expedition, itself entitled "Kon-Tiki", won an Academy Award in 1951. A dramatised version was released in 2012, also called "Kon-Tiki", and was nominated for both the Best Foreign Language Oscar at the 85th Academy Awards and a Golden Globe Award for Best Foreign Language Film at the 70th Golden Globe Awards. It is the first time a Norwegian film has been nominated for both an Oscar and a Golden Globe.
Anthropologists continue to believe, based on linguistic, physical, and genetic evidence, that Polynesia was settled from west to east, migration having begun from the Asian mainland. There are controversial indications, though, of some sort of South American/Polynesian contact, most notably in the fact that the South American sweet potato is served as a dietary staple throughout much of Polynesia. Blood samples taken in 1971 and 2008 from Easter Islanders without any European or other external descent were analysed in a 2011 study, which concluded that the evidence supported some aspects of Heyerdahl's hypothesis. This result has been questioned because of the possibility of contamination by South Americans after European contact with the islands. However, more recent DNA work (after Heyerdahl's death) contradicts the post-European-contact contamination hypothesis, finding the South American DNA sequences to be far older than that. Heyerdahl had attempted to counter the linguistic argument with the analogy that, guessing the origin of African-Americans, he would prefer to believe that they came from Africa, judging from their skin colour, and not from England, judging from their speech.
Theory on Polynesian origins.
Heyerdahl claimed that in Incan legend there was a sun-god named Con-Tici Viracocha who was the supreme head of the mythical fair-skinned people in Peru. The original name for Viracocha was "Kon-Tiki" or "Illa-Tiki", which means "Sun-Tiki" or "Fire-Tiki". Kon-Tiki was high priest and sun-king of these legendary "white men" who left enormous ruins on the shores of Lake Titicaca. The legend continues with the mysterious bearded white men being attacked by a chief named Cari who came from the Coquimbo Valley. They had a battle on an island in Lake Titicaca, and the fair race was massacred. However, Kon-Tiki and his closest companions managed to escape and later arrived on the Pacific coast. The legend ends with Kon-Tiki and his companions disappearing westward out to sea.
When the Spaniards came to Peru, Heyerdahl asserted, the Incas told them that the colossal monuments that stood deserted about the landscape were erected by a race of white gods who had lived there before the Incas themselves became rulers. The Incas described these "white gods" as wise, peaceful instructors who had originally come from the north in the "morning of time" and taught the Incas' primitive forefathers architecture as well as manners and customs. They were unlike other Native Americans in that they had "white skins and long beards" and were taller than the Incas. The Incas said that the "white gods" had then left as suddenly as they had come and fled westward across the Pacific. After they had left, the Incas themselves took over power in the country.
Heyerdahl said that when the Europeans first came to the Pacific islands, they were astonished that they found some of the natives to have relatively light skins and beards. There were whole families that had pale skin, hair varying in color from reddish to blonde. In contrast, most of the Polynesians had golden-brown skin, raven-black hair, and rather flat noses. Heyerdahl claimed that when Jakob Roggeveen first discovered Easter Island in 1722, he supposedly noticed that many of the natives were white-skinned. Heyerdahl claimed that these people could count their ancestors who were "white-skinned" right back to the time of Tiki and Hotu Matua, when they first came sailing across the sea "from a mountainous land in the east which was scorched by the sun." The ethnographic evidence for these claims is outlined in Heyerdahl's book "Aku Aku: The Secret of Easter Island".
Heyerdahl proposed that Tiki's neolithic people colonized the then-uninhabited Polynesian islands as far north as Hawaii, as far south as New Zealand, as far east as Easter Island, and as far west as Samoa and Tonga around 500 AD. They supposedly sailed from Peru to the Polynesian islands on "pae-paes"—large rafts built from balsa logs, complete with sails and each with a small cottage. They built enormous stone statues carved in the image of human beings on Pitcairn, the Marquesas, and Easter Island that resembled those in Peru. They also built huge pyramids on Tahiti and Samoa with steps like those in Peru. But all over Polynesia, Heyerdahl found indications that Tiki's peaceable race had not been able to hold the islands alone for long. He found evidence that suggested that seagoing war canoes as large as Viking ships and lashed together two and two had brought Stone Age Northwest American Indians to Polynesia around 1100 , and they mingled with Tiki's people. The oral history of the people of Easter Island, at least as it was documented by Heyerdahl, is completely consistent with this theory, as is the archaeological record he examined (Heyerdahl 1958). In particular, Heyerdahl obtained a radiocarbon date of 400 for a charcoal fire located in the pit that was held by the people of Easter Island to have been used as an "oven" by the "Long Ears," which Heyerdahl's Rapa Nui sources, reciting oral tradition, identified as a white race which had ruled the island in the past (Heyerdahl 1958).
Heyerdahl further argued in his book "American Indians in the Pacific" that the current inhabitants of Polynesia migrated from an Asian source, but via an alternate route. He proposes that Polynesians travelled with the wind along the North Pacific current. These migrants then arrived in British Columbia. Heyerdahl called contemporary tribes of British Columbia, such as the Tlingit and Haida, descendants of these migrants. Heyerdahl claimed that cultural and physical similarities existed between these British Columbian tribes, Polynesians, and the Old World source. Heyerdahl's claims aside, however, there is no evidence that the Tlingit, Haida or other British Columbian tribes have an affinity with Polynesians.
Heyerdahl's theory of Polynesian origins has not gained acceptance among anthropologists. Physical and cultural evidence had long suggested that Polynesia was settled from west to east, migration having begun from the Asian mainland, not South America. In the late 1990s, genetic testing found that the mitochondrial DNA of the Polynesians is more similar to people from southeast Asia than to people from South America, showing that their ancestors most likely came from Asia.
Anthropologist Robert Carl Suggs included a chapter titled "The Kon-Tiki Myth" in his 1960 book on Polynesia, concluding that "The "Kon-Tiki" theory is about as plausible as the tales of Atlantis, Mu, and 'Children of the Sun.' Like most such theories it makes exciting light reading, but as an example of scientific method it fares quite poorly."
Anthropologist and National Geographic Explorer-in-Residence Wade Davis also criticised Heyerdahl's theory in his 2009 book "The Wayfinders", which explores the history of Polynesia. Davis says that Heyerdahl "ignored the overwhelming body of linguistic, ethnographic, and ethnobotanical evidence, augmented today by genetic and archaeological data, indicating that he was patently wrong."
A recent study by Norwegian researcher Erik Thorsby suggests that there is some merit to Heyerdahl's ideas and that while Polynesia was colonized from Asia, some contact with South America also existed. Some critics suggest, however, that Thorsby's research is inconclusive because his data may have been influenced by recent population contact.
However, more recent work indicates that the South American component of Easter Island people's genomes predates European contact: a team including Anna-Sapfo Malaspinas (from the Natural History Museum of Denmark) analysed the genomes of 27 native Rapanui people and found that their DNA was on average 76 per cent Polynesian, eight per cent Native American and 16 per cent European. Analysis showed that: "although the European lineage could be explained by contact with white Europeans after the island was “discovered” in 1722 by Dutch sailors, the South American component was much older, dating to between about 1280 and 1495, soon after the island was first colonised by Polynesians in around 1200." Together with ancient skulls found in Brazil - with solely Polynesian DNA - this does suggest some pre-European-contact travel to and from South America from Polynesia.
Expedition to Rapa Nui (Easter Island).
In 1955–1956, Heyerdahl organized the Norwegian Archaeological Expedition to Rapa Nui (Easter Island). The expedition's scientific staff included Arne Skjølsvold, Carlyle Smith, Edwin Ferdon, Gonzalo Figueroa and William Mulloy. Heyerdahl and the professional archaeologists who traveled with him spent several months on Rapa Nui investigating several important archaeological sites. Highlights of the project include experiments in the carving, transport and erection of the notable moai, as well as excavations at such prominent sites as Orongo and Poike. The expedition published two large volumes of scientific reports ("Reports of the Norwegian Archaeological Expedition to Easter Island and the East Pacific") and Heyerdahl later added a third ("The Art of Easter Island"). Heyerdahl's popular book on the subject, "Aku-Aku" was another international best-seller.
In "Easter Island: The Mystery Solved" (Random House, 1989), Heyerdahl offered a more detailed theory of the island's history. Based on native testimony and archaeological research, he claimed the island was originally colonized by Hanau eepe ("Long Ears"), from South America, and that Polynesians Hanau momoko ("Short Ears") arrived only in the mid-16th century; they may have come independently or perhaps were imported as workers. According to Heyerdahl, something happened between Admiral Roggeveen's discovery of the island in 1722 and James Cook's visit in 1774; while Roggeveen encountered white, Indian, and Polynesian people living in relative harmony and prosperity, Cook encountered a much smaller population consisting mainly of Polynesians and living in privation.
Heyerdahl notes the oral tradition of an uprising of "Short Ears" against the ruling "Long Ears." The "Long Ears" dug a defensive moat on the eastern end of the island and filled it with kindling. During the uprising, Heyerdahl claimed, the "Long Ears" ignited their moat and retreated behind it, but the "Short Ears" found a way around it, came up from behind, and pushed all but two of the "Long Ears" into the fire. This moat was found by the Norwegian expedition and it was partly cut down into the rock. Layers of fire were revealed but no fragments of bodies. As for the origin of the people of Easter Island today (2013) DNA-tests have shown a total agreement with people from the Pacific and no connection to South America. If the story that all (almost) long-ears were killed in a civil war, this is what to be expected if their blood-line was totally destroyed. Recent (2006?) test has shown traces to South America from some proteins, but whether this is inherited from a person coming in later times is hard to know.
Boats "Ra" and "Ra II".
In 1969 and 1970, Heyerdahl built two boats from papyrus and attempted to cross the Atlantic Ocean from Morocco in Africa. Based on drawings and models from ancient Egypt, the first boat, named "Ra" (after the Egyptian Sun god), was constructed by boat builders from Lake Chad using papyrus reed obtained from Lake Tana in Ethiopia and launched into the Atlantic Ocean from the coast of Morocco. The Ra crew included Thor Heyerdahl (Norway), Norman Baker (USA), Carlo Mauri (Italy), Yuri Senkevich (USSR), Santiago Genoves (Mexico), Georges Sourial (Egypt) and Abdullah Djibrine (Chad). Only Heyerdahl and Baker had sailing and navigation experiences. After a number of weeks, "Ra" took on water after its crew made modifications to the vessel that caused it to sag and break apart after sailing more than 6440 km (4000 miles). The crew was forced to abandon Ra some hundred miles before Caribbean islands and was saved by a yacht.
The following year, 1970, another similar vessel, "Ra II", was built of papyrus by Demetrio, Juan and Jose Limachi from Lake Titicaca in Bolivia and likewise set sail across the Atlantic from Morocco, this time with great success. The crew was mostly the same; only Djibrine had been replaced by Kei Ohara from Japan and Madani Ait Ouhanni from Morocco. The boat reached Barbados, thus demonstrating that mariners could have dealt with trans-Atlantic voyages by sailing with the Canary Current. The "Ra II" is now in the Kon-Tiki Museum in Oslo, Norway.
The book "The Ra Expeditions" and the film documentary "Ra" (1972) were made about the voyages. Apart from the primary aspects of the expedition, Heyerdahl deliberately selected a crew representing a great diversity in race, nationality, religion and political viewpoint in order to demonstrate that at least on their own little floating island, people could cooperate and live peacefully. Additionally, the expedition took samples of marine pollution and presented their report to the United Nations.
"Tigris".
Heyerdahl built yet another reed boat, "Tigris", which was intended to demonstrate that trade and migration could have linked Mesopotamia with the Indus Valley Civilization in what is now Pakistan and western India. Tigris was built in Iraq and sailed with its international crew through the Persian Gulf to Pakistan and made its way into the Red Sea. After about five months at sea and still remaining seaworthy, the "Tigris" was deliberately burnt in Djibouti, on April 3, 1978, as a protest against the wars raging on every side in the Red Sea and Horn of Africa. In his Open Letter to the UN Secretary-General Kurt Waldheim, Heyerdahl explained his reasons:
Today we burn our proud ship ... to protest against inhuman elements in the world of 1978 ... Now we are forced to stop at the entrance to the Red Sea. Surrounded by military airplanes and warships from the world's most civilized and developed nations, we have been denied permission by friendly governments, for reasons of security, to land anywhere, but in the tiny, and still neutral, Republic of Djibouti. Elsewhere around us, brothers and neighbors are engaged in homicide with means made available to them by those who lead humanity on our joint road into the third millennium.
To the innocent masses in all industrialized countries, we direct our appeal. We must wake up to the insane reality of our time ... We are all irresponsible, unless we demand from the responsible decision makers that modern armaments must no longer be made available to people whose former battle axes and swords our ancestors condemned.
Our planet is bigger than the reed bundles that have carried us across the seas, and yet small enough to run the same risks unless those of us still alive open our eyes and minds to the desperate need of intelligent collaboration to save ourselves and our common civilization from what we are about to convert into a sinking ship.
In the years that followed, Heyerdahl was often outspoken on issues of international peace and the environment.
The Tigris was crewed by eleven men: Thor Heyerdahl (Norway), Norman Baker (USA),
Carlo Mauri (Italy), Yuri Senkevich (USSR), Germán Carrasco (Mexico), Hans Petter Bohn (Norway), Rashad Nazar Salim (Iraq), Norris Brock (USA), Toru Suzuki (Japan), Detlef Zoltze (Germany), and Asbjørn Damhus (Denmark).
"The Search for Odin" in Azerbaijan and Russia.
Heyerdahl made four visits to Azerbaijan in 1981, 1994, 1999 and 2000. Heyerdahl had long been fascinated with the rock carvings that date back to about 8th-7th millennia BCE at Gobustan (about 30 miles west of Baku). He was convinced that their artistic style closely resembles the carvings found in his native Norway. The ship designs, in particular, were regarded by Heyerdahl as similar and drawn with a simple sickle–shaped lines, representing the base of the boat, with vertical lines on deck, illustrating crew or, perhaps, raised oars.
Based on this and other published documentation, Heyerdahl proposed that Azerbaijan was the site of an ancient advanced civilization. He believed natives migrated north through waterways to present-day Scandinavia using ingeniously constructed vessels made of skins that could be folded like cloth. When voyagers traveled upstream, they conveniently folded their skin boats and transported them via pack animals.
On Heyerdahl's visit to Baku in 1999, he lectured at the Academy of Sciences about the history of ancient Nordic Kings. He spoke of a notation made by Snorri Sturluson, a 13th-century historian-mythographer in "Ynglinga Saga" which relates that "Odin (a Scandinavian god who was one of the kings) came to the North with his people from a country called Aser." (see also House of Ynglings and Mythological kings of Sweden). Heyerdahl accepted Snorri's story as literal truth, and believed that a chieftain led his people in a migration from the east, westward and northward through Saxony, to Fyn in Denmark, and eventually settling in Sweden. Heyerdahl claimed that the geographic location of the mythic Aser or Æsir matched the region of contemporary Azerbaijan - "east of the Caucasus mountains and the Black Sea". "We are no longer talking about mythology," Heyerdahl said, "but of the realities of geography and history. Azerbaijanis should be proud of their ancient culture. It is just as rich and ancient as that of China and Mesopotamia."
One of the last projects of his life, "Jakten på Odin", 'The Search for Odin', was a sudden revision of his Odin hypothesis, in furtherance of which he initiated 2001–2002 excavations in Azov, Russia, near the Sea of Azov at the northeast of the Black Sea. He searched for the remains of a civilization to match the account of Odin in Snorri Sturlusson, quite a bit north of his original target of Azerbaijan on the Caspian Sea only two years earlier. This project generated harsh criticism and accusations of pseudo-science from historians, archaeologists and linguists in Norway, who accused Heyerdahl of selective use of sources, and a basic lack of scientific methodology in his work.
His central claims were based on similarities of names in Norse mythology and geographic names in the Black Sea region, e.g. "Azov" and "Æsir", Udi and Odin, Tyr and Turkey. Philologists and historians reject these parallels as mere coincidences, and also anachronisms, for instance the city of Azov did not have that name until over 1000 years after Heyerdahl claims the Æsir dwelt there. The controversy surrounding the Search for Odin project was in many ways typical of the relationship between Heyerdahl and the academic community. His theories rarely won any scientific acceptance, whereas Heyerdahl himself rejected all scientific criticism and concentrated on publishing his theories in popular books aimed at the general public .
s of 2012[ [update]], Heyerdahl's Odin hypothesis has yet to be validated by any historian, archaeologist or linguist.
Other projects.
Heyerdahl also investigated the mounds found on the Maldive Islands in the Indian Ocean. There, he found sun-oriented foundations and courtyards, as well as statues with elongated earlobes. Heyerdahl believed that these finds fit with his theory of a seafaring civilization which originated in what is now Sri Lanka, colonized the Maldives, and influenced or founded the cultures of ancient South America and Easter Island. His discoveries are detailed in his book "The Maldive Mystery".
In 1991 he studied the Pyramids of Güímar on Tenerife and declared that they were not random stone heaps but pyramids. Based on the discovery made by the astrophysicists Aparicio, Belmonte and Esteban, from the Instituto de Astrofísica de Canarias that the "pyramids" were astronomically oriented and being convinced that they were of ancient origin, he claimed that the ancient people who built them were most likely sun worshipers. Heyerdahl advanced a theory according to which the Canaries had been bases of ancient shipping between America and the Mediterranean.
Heyerdahl was also an active figure in Green politics. He was the recipient of numerous medals and awards. He also received 11 honorary doctorates from universities in the Americas and Europe.
Death.
In subsequent years, Heyerdahl was involved with many other expeditions and archaeological projects. He remained best known for his boat-building, and for his emphasis on cultural diffusionism. He died, aged 87, from a brain tumor. After receiving the diagnosis he prepared for dying by refusing to eat or take medication. The Norwegian government granted Heyerdahl the honor of a state funeral in the Oslo Cathedral on April 26, 2002. His cremated remains lie in the garden of his family's home in Colla Micheri.
Decorations and honorary degrees.
Asteroid 2473 Heyerdahl is named after him, as are HNoMS "Thor Heyerdahl", a Norwegian Nansen class frigate, along with "MS Thor Heyerdahl" (now renamed "MS Vana Tallinn") and "Thor Heyerdahl", a German three-masted sail training vessel originally owned by a participant of the Tigris expedition. Thor Heyerdahl Upper Secondary School in Larvik, the town of his birth, is also named after him.
Heyerdahl's numerous awards and honors include the following:

</doc>
<doc id="37800" url="http://en.wikipedia.org/wiki?curid=37800" title="Dendrochronology">
Dendrochronology

Dendrochronology (from δένδρον, "dendron", "tree limb"; χρόνος, "khronos", "time"; and -λογία, "-logia") or tree-ring dating, is the scientific method of dating based on the analysis of patterns of "tree rings", also known as "growth rings". Dendrochronology can date the time at which tree rings were formed, in many types of wood, to the exact calendar year. This has three main areas of application: paleoecology, where it is used to determine certain aspects of past ecologies (most prominently climate); archaeology and the history of art and architecture, where it is used to date old panel paintings on wood, buildings, etc.; and radiocarbon dating, where it is used to calibrate radiocarbon ages (see below). In some areas of the world, it is possible to date wood back a few thousand years, or even many thousands. As of 2013, fully anchored chronologies in the northern hemisphere extend back 13,900 years.
History.
The Greek botanist Theophrastus (ca. 371 – ca. 287 BC) first mentioned that the wood of trees has rings. In his "Trattato della Pittura" (Treatise on Painting), Leonardo da Vinci was the first person to mention that trees form rings annually and that their thickness is determined by the conditions under which they grew. In 1737, French investigators Henri-Louis Duhamel du Monceau and Georges-Louis Leclerc de Buffon examined the effect of growing conditions on the shape of tree rings. They found that in 1709, a severe winter produced a distinctly dark tree ring, which served as a reference for subsequent European naturalists.
In the U.S., Alexander Catlin Twining (1801-1884) suggested in 1833 that patterns among tree rings could be used to synchronize the dendrochronologies of various trees and thereby to reconstruct past climates across entire regions. The English polymath Charles Babbage proposed using dendrochronology to date the remains of trees in peat bogs or even in geological strata (1835, 1838).
During the latter half of the nineteenth century, the scientific study of tree rings and the application of dendrochronology began. In 1859, the German-American Jacob Kuechler (1823-1893) used crossdating to examine oaks ("Quercus stellata") in order to study the record of climate in western Texas. In 1866, the German botanist, entomologist, and forester Julius Ratzeburg (1801-1871) observed the effects on tree rings of defoliation caused by insect infestations. By 1882, this observation was already appearing in forestry textbooks. In the 1870s, the Dutch astronomer Jacobus C. Kapteyn (1851-1922) was using crossdating to reconstruct the climates of Holland and Germany. In 1881, the Swiss-Austrian forester Arthur von Seckendorff-Gudent (1845-1886) was using crossdating. From 1869 to 1901, Robert Hartig (1839-1901), a German professor of forest pathology, wrote a series of papers on the anatomy and ecology of tree rings. In 1892, the Russian physicist Fedor Nikiforovich Shvedov (Фёдор Никифорович Шведов) (1841-1905) wrote that he had used patterns found in tree rings to predict droughts in 1882 and 1891.
During the first half of the 20th century, the astronomer A. E. Douglass founded the Laboratory of Tree-Ring Research at the University of Arizona. Douglass sought to better understand cycles of sunspot activity and reasoned that changes in solar activity would affect climate patterns on earth which would subsequently be recorded by tree-ring growth patterns ("i.e.", sunspots → climate → tree rings).
Growth rings.
Growth rings, also referred to as "tree rings" or "annual rings", can be seen in a horizontal cross section cut through the trunk of a tree. Growth rings are the result of new growth in the vascular cambium, a layer of cells near the bark that is classified as a lateral meristem; this growth in diameter is known as secondary growth. Visible rings result from the change in growth speed through the seasons of the year; thus, critical for the title method, one ring generally marks the passage of one year in the life of the tree.
The rings are more visible in temperate zones, where the seasons differ more markedly. The inner portion of a growth ring is formed early in the growing season, when growth is comparatively rapid (hence the wood is less dense) and is known as "early wood" (or "spring wood", or "late-spring wood"); the outer portion is the "late wood" (and has sometimes been termed "summer wood", often being produced in the summer, though sometimes in the autumn) and is denser.
Many trees in temperate zones make one growth ring each year, with the newest adjacent to the bark. Hence, for these, for the entire period of a tree's life, a year-by-year record or ring pattern is formed that reflects the age of the tree and the climatic conditions in which the tree grew. Adequate moisture and a long growing season result in a wide ring, while a drought year may result in a very narrow one.
Direct reading of tree ring chronologies is a learned science, for several reasons. First, contrary to the single ring per year paradigm, alternating poor and favorable conditions, such as mid-summer droughts, can result in several rings forming in a given year. In addition, particular tree species may present "missing rings", and this influences the selection of trees for study of long time spans. For instance, missing rings are rare in oak and elm trees.
Critical to the science, trees from the same region tend to develop the same patterns of ring widths for a given period of historical study. These patterns can be compared and matched ring for ring with trees growing at the same time, in the same geographical zone (and therefore under similar climatic conditions). When these tree-ring patterns are carried back, from tree to tree in the same locale, in overlapping fashion, chronologies can be built up—both for entire geographical regions and sub-regions. Moreover, wood from ancient structures with known chronologies can be matched to the tree ring data (a technique called "cross-dating"), and the age of the wood can thereby be determined precisely. Cross-dating was originally done by visual inspection; computers have been harnessed to do the task, applying statistical techniques to assess the matching.
To eliminate individual variations in tree-ring growth, dendrochronologists take the smoothed average of the tree-ring widths of multiple tree samples to build up a ring history, a process termed replication. A tree-ring history whose beginning and end dates are not known is called a "floating chronology". It can be anchored by cross-matching a section against another chronology (tree-ring history) whose dates are known. Fully anchored chronologies extending back more than 11,000 years exist for river oak trees from South Germany (from the Main and Rhine rivers) and for pine from Northern Ireland. The consistency of these two independent dendrochronological sequences has been supported through comparison of their radiocarbon and dendrochronological ages. Another fully anchored chronology which extends back 8500 years exists for the bristlecone pine in the Southwest US (White Mountains of California).
Sampling and dating.
Dendrochronology makes available specimens of once-living material accurately dated to a specific year. Dates are often represented as estimated calendar years B.P., for before present, where "present" refers to 1 January 1950. 
Timber core samples are sampled and used to measure the width of annual growth rings; by taking samples from different sites within a particular region, researchers can build a comprehensive historical sequence. The techniques of dendrochronology are more consistent in areas where trees grew in marginal conditions such as aridity or semi-aridity where the ring growth is more sensitive to the environment, rather than in humid areas where tree-ring growth is more uniform (complacent). In addition, some genera of trees are more suitable than others for this type of analysis. For instance, the bristlecone pine is exceptionally long-lived and slow growing, and has been used extensively for chronologies; still-living and dead specimens of this species provide tree-ring patterns going back thousands of years, in some regions more than 10,000 years. Currently, the maximum span for fully anchored chronology is a little over 11,000 years B.P.
In 2004 a new calibration curve, INTCAL04, was internationally ratified to provide calibrated dates back to 26,000 B.P. (based on an agreed worldwide data set of trees and marine sediments). The part of the new calibration curves that relies on tree-ring evidence spans 12,410 calendar B.P., and a further 14,700 calendar years prior to that.
Dendrochronology practice faces many obstacles, including the existence of species of ants that inhabit trees and extend their galleries into the wood, thus destroying ring structure.
Reference sequences.
European chronologies derived from wooden structures initially found it difficult to bridge the gap in the 14th century when there was a building hiatus which coincided with the Black Death, however there do exist unbroken chronologies dating back to prehistoric times, for example the Danish chronology dating back to 352 BC.
Given a sample of wood, the variation of the tree-ring growths provides not only a match by year, it can also match location because the climate across a continent is not consistent. This makes it possible to determine the source of ships as well as smaller artifacts made from wood but which were transported long distances, such as panels for paintings and ship timbers.
Applications.
Radiocarbon dating calibration.
Dates from dendrochronology can be used as a calibration and check of radiocarbon dating
Climatology.
In areas where the climate is reasonably predictable, trees develop annual rings of different properties depending on weather, rain, temperature, soil pH, plant nutrition, CO2 concentration, etc. in different years. These variations are used in dendroclimatology to infer past climate variations.
Art history.
Dendrochronology has become important to art historians in the dating of panel paintings. However, unlike analysis of samples from buildings which are typically sent to a laboratory, wooden supports for paintings usually have to be measured in a museum conservation department, which places limitations on the techniques that can be used.
In addition to dating, dendrochronology can also provide information as to the source of the panel. Many Early Netherlandish paintings have turned out to be painted on panels of "Baltic oak" shipped from the Vistula region via ports of the Hanseatic League. Oak panels were used in a number of northern countries such as England, France and Germany. Wooden supports other than oak were rarely used by Netherlandish painters.
Since panels of seasoned wood were used, an uncertain number of years has to be allowed for seasoning when estimating dates. Panels were trimmed of the outer rings, and often each panel only uses a small part of the radius of the trunk. Consequently, dating studies usually result in a "terminus post quem" (earliest possible) date, and a tentative date for the actual arrival of a seasoned raw panel using assumptions as to these factors. As a result of establishing numerous sequences, it was possible to date 85% - 90% of the 250 paintings from the 14th to 17th century analysed between 1971 and 1982; by now a much greater number have been analysed.
A portrait of Mary, Queen of Scots in the National Portrait Gallery, London was believed to be an 18th-century copy. However, dendrochronology revealed that the wood dated from the second half of the 16th century. It is now regarded as an original 16th century painting by an unknown artist.
On the other hand, dendrochronology was applied to four paintings depicting the same subject, that of Christ expelling the money-lenders from the Temple. The results showed that the age of the wood was too late for any of them to have been painted by Hieronymus Bosch.
While dendrochronology has become an important tool for dating oak panels, it is not effective in dating the poplar panels often used by Italian painters because of the erratic growth rings in poplar.
The 16th century saw a gradual replacement of wooden panels by canvas as the support for paintings which means the technique is less often applicable to later paintings. In addition, many panel paintings were transferred onto canvas or other supports during the 19th and 20th centuries.
Building history.
The dating of buildings with wooden structures and components has also been done by using dendrochronology. While archaeologists can date wood and when it was felled, it may be difficult to definitively determine the age of a building or structure in which the wood was used; the wood could have been reused from an older structure, may have been felled and left for many years before use, or could have been used to replace a damaged piece of wood. The dating of building via dendrochronology thus requires knowledge of the history of building technology.
Examples:
Related chronologies.
Similar seasonal patterns also occur in ice cores and in varves (layers of sediment deposition in a lake, river, or sea bed). The deposition pattern in the core will vary for a frozen-over lake versus an ice-free lake, and with the fineness of the sediment. 
Some columnar cactus also exhibit similar seasonal patterns in the isotopes of carbon and oxygen in their spines (acanthochronology). These are used for dating in a manner similar to dendrochronology, and such techniques are used in combination with dendrochronology, to plug gaps and to extend the range of the seasonal data available to archaeologists and paleoclimatologists.
A related technique is used to analyse fish stocks through the analysis of growth rings in the otolith bones of fish.

</doc>
<doc id="37802" url="http://en.wikipedia.org/wiki?curid=37802" title="Ovid">
Ovid

Publius Ovidius Naso (]; 20 March 43 BC – AD 17/18), known as Ovid () in the English-speaking world, was a Roman poet, living during the reign of Augustus, and a contemporary of Virgil and Horace.
He is best known for the "Metamorphoses", a 15-book continuous mythological narrative written in the meter of epic, and for collections of love poetry in elegiac couplets, especially the "Amores" ("Love Affairs") and "Ars Amatoria" ("The Art of Love"). His poetry was much imitated during Late Antiquity and the Middle Ages, and greatly influenced Western art and literature. The "Metamorphoses" remains one of the most important sources of classical mythology.
Ovid is traditionally ranked alongside Virgil and Horace, his older contemporaries, as one of the three canonic poets of Latin literature. He was the first major Roman poet to begin his career during the reign of Augustus, and the Imperial scholar Quintilian considered him the last of the Latin love elegists. He enjoyed enormous popularity, but in one of the mysteries of literary history he was sent by Augustus into exile in a remote province on the Black Sea, where he remained until his death. Ovid himself attributes his exile to "carmen et error", "a poem and a mistake", but his discretion in discussing the causes has resulted in much speculation among scholars.
Ovid's prolific poetry includes the "Heroides", a collection of verse epistles written as though by mythological heroines to the lovers who abandoned them; the "Fasti", an incomplete six-book exploration of Roman religion with a calendar structure; and the "Tristia" and "Epistulae ex Ponto", two collections of elegies in the form of complaining letters from his exile. His shorter works include the "Remedia Amoris" ("Cure for Love"), the curse-poem "Ibis", and an advice poem on women's cosmetics. He wrote a lost tragedy, "Medea", and mentions that some of his other works were adapted for staged performance.
Life.
Ovid talks more about his own life than most other Roman poets. Information about his biography is drawn primarily from his poetry, especially "Tristia" 4.10, which gives a long autobiographical account of his life. Other sources include Seneca the Elder and Quintilian.
Birth, early life, and marriage.
Ovid was born in Sulmo (modern Sulmona), in an Apennine valley east of Rome, to an important equestrian family, on March 20, 43 BC. That was a significant year in Roman politics.[b] He was educated in rhetoric in Rome under the teachers Arellius Fuscus and Porcius Latro with his brother who excelled at oratory.
His father wished him to study rhetoric toward the practice of law. According to Seneca the Elder, Ovid tended to the emotional, not the argumentative pole of rhetoric. After the death of his brother at 20 years of age, Ovid renounced law and began travelling to Athens, Asia Minor, and Sicily. He held minor public posts, as one of the "tresviri capitales", as a member of the Centumviral court and as one of the "decemviri litibus iudicandis", but resigned to pursue poetry probably around 29–25 BC, a decision of which his father apparently disapproved.
His first recitation has been dated to around 25 BC, when Ovid was eighteen. He was part of the circle centered on the patron Marcus Valerius Messalla Corvinus, and seems to have been a friend of poets in the circle of Maecenas. In "Trist." 4.10.41–54, Ovid mentions friendships with Macer, Propertius, Horace, Ponticus and Bassus (he only barely met Virgil and Tibullus, a fellow member of Messalla's circle whose elegies he admired greatly). Ovid was very popular at the time of his early works, but was later exiled by Augustus in AD 8. He married three times and divorced twice by the time he was thirty years old. He had one daughter, who eventually bore him grandchildren. His last wife was connected in some way to the influential "gens Fabia" and would help him during his exile in Tomis.
Literary success.
The first 25 years of Ovid's literary career were spent primarily writing poetry in elegiac meter with erotic themes. The chronology of these early works is not secure; tentative dates, however, have been established by scholars. His earliest extant work is thought to be the "Heroides", letters of mythological heroines to their absent lovers, which may have been published in 19 BC, although the date is uncertain as it depends on a notice in "Am." 2.18.19–26 which seems to describe the collection as an early published work.
The authenticity of some of these poems has been challenged, but this first edition probably contained the first 14 poems of the collection. The first five-book collection of the "Amores", a series of erotic poems addressed to a lover, Corinna, is thought to have been published in 16–15 BC; the surviving version, redacted to three books according to an epigram prefixed to the first book, is thought to have been published c. 8–3 BC. Between the publications of the two editions of the "Amores" can be dated the premiere of his tragedy "Medea", which was admired in antiquity but is no longer extant.
Ovid's next poem, the "Medicamina Faciei", a fragmentary work on women's beauty treatments, preceded the "Ars Amatoria", the "Art of Love", a parody of didactic poetry and a three-book manual about seduction and intrigue, which has been dated to AD 2 (Books 1–2 would go back to 1 BC). Ovid may identify this work in his exile poetry as the "carmen", or song, which was one cause of his banishment. The "Ars Amatoria" was followed by the "Remedia Amoris" in the same year. This corpus of elegiac, erotic poetry earned Ovid a place among the chief Roman elegists Gallus, Tibullus, and Propertius, of whom he saw himself as the fourth member.
By AD 8, he had completed his most ambitious work, the "Metamorphoses", a hexameter epic poem in 15 books which encyclopedically catalogues transformations in Greek and Roman mythology from the emergence of the cosmos to the deification of Julius Caesar. The stories follow each other in the telling of human beings transformed to new bodies: trees, rocks, animals, flowers, constellations etc. At the same time, he was working on the "Fasti", a six-book poem in elegiac couplets which took as its theme the calendar of Roman festivals and astronomy. The composition of this poem was interrupted by Ovid's exile,[c] and it is thought that Ovid abandoned work on the piece in Tomis. It is probably in this period, if they are indeed by Ovid, that the double letters (16–21) in the "Heroides" were composed.
Exile to Tomis.
In AD 8, Ovid was banished to Tomis, on the Black Sea, by the exclusive intervention of the Emperor Augustus, without any participation of the Senate or of any Roman judge. This event shaped all of his following poetry. Ovid wrote that the reason for his exile was "carmen et error" – "a poem and a mistake", claiming that his crime was worse than murder, more harmful than poetry.
The Emperor's grandchildren, Julia the Younger and Agrippa Postumus (the latter adopted by him), were also banished around the same time. Julia's husband, Lucius Aemilius Paullus, was put to death for conspiracy against Augustus, a conspiracy about which Ovid might have known.
The Julian Marriage Laws of 18 BC, which promoted monogamous marriage to increase the population's birth rate, were fresh in the Roman mind. Ovid's writing in the "Ars Amatoria" concerned the serious crime of adultery, and he may have been banished for these works which appeared subversive to the emperor's moral legislation. However, in view of the long time that had elapsed between the publication of this work (1 BC) and the exile (AD 8), some authors suggest that Augustus used the poem as a mere justification for something more personal.
In exile, Ovid wrote two poetry collections titled "Tristia" and "Epistulae ex Ponto", illustrating his sadness and desolation. Being far from Rome, he had no access to libraries, and thus might have been forced to abandon the "Fasti" poem about the Roman calendar, of which only the first six books exist – January through June. The five books of the elegiac "Tristia", a series of poems expressing the poet's despair in exile and advocating his return to Rome, are dated to AD 9–12. The "Ibis", an elegiac curse poem attacking an adversary at home, may also be dated to this period. The "Epistulae ex Ponto", a series of letters to friends in Rome asking them to effect his return, are thought to be his last compositions, with the first three books published in AD 13 and the fourth book between AD 14 and 16. The exile poetry is particularly emotive and personal. In the "Epistulae" he claims friendship with the natives of Tomis (in the "Tristia" they are frightening barbarians) and to have written a poem in their language ("Ex P". 4.13.19–20). And yet he pined for Rome and for his third wife; many of the poems are addressed to her. Some are also to the Emperor Augustus, yet others are to himself, to friends in Rome, and sometimes to the poems themselves, expressing loneliness and hope of recall from banishment or exile.
The obscure causes of Ovid's exile have given rise to endless explanations from scholars. The medieval texts that mention the exile offer no credible explanations: their statements seem incorrect interpretations drawn from the works of Ovid. Ovid himself wrote many references to his offense, giving obscure or contradictory clues.
In 1923, scholar J. J. Hartman proposed a theory that is little considered among scholars of Latin civilization today: that Ovid was never exiled from Rome and that all of his exile works are the result of his fertile imagination. This theory was supported and rejected in the 1930s, especially by Dutch authors.
In 1985 a new research paper by Fitton Brown advanced new arguments in support of the theory. The article was followed by a series of supports and refutations in the short space of five years. Among the reasons given by Brown are: that Ovid's exile is only mentioned by his own work, except in "dubious" passages by Pliny the Elder, Statius, but no other author until the 4th century; that the author of "Heroides" was able to separate the poetic "I" of his own and real life; and that information on the geography of Tomis was already known by Virgil, by Herodotus and by Ovid himself in his "Metamorphoses".[d]
Orthodox scholars, however, are opposed to these hypotheses. One of the main arguments of these scholars is that Ovid would not let his "Fasti" remain unfinished, mainly because this poem meant his consecration as an imperial poet.
Death.
Ovid died at Tomis in AD 17 or 18. It is thought that the "Fasti", which he spent time revising, were published posthumously. He was allegedly buried a few kilometers away in a nearby town. 
Works.
"Heroides" ("The Heroines").
The "Heroides" ("Heroines") or "Epistulae Heroidum" are a collection of 21 poems in elegiac couplets. The "Heroides" take the form of letters addressed by famous mythological characters to their partners expressing their emotions at being separated from them, pleas for their return, and allusions to their future actions within their own mythology. The authenticity of the collection, partially or as a whole, has been questioned, although most scholars would consider the letters mentioned specifically in Ovid's description of the work at "Am." 2.18.19–26 as safe from objection. The collection comprises a new type of generic composition without parallel in earlier literature.
The first 14 letters are thought to comprise the first published collection and are written by the heroines Penelope, Phyllis, Briseis, Phaedra, Oenone, Hypsipyle, Dido, Hermione, Deianeira, Ariadne, Canace, Medea, Laodamia, and Hypermestra to their absent male lovers. Letter 15, from the historical Sappho to Phaon, seems spurious (although referred to in "Am." 2.18) because of its length, its lack of integration in the mythological theme, and its absence from Medieval manuscripts. The final letters (16–21) are paired compositions comprising a letter to a lover and a reply. Paris and Helen, Hero and Leander, and Acontius and Cydippe are the addressees of the paired letters. These are considered a later addition to the corpus because they are never mentioned by Ovid and may or may not be spurious. The "Heroides" markedly reveal the influence of rhetorical declamation and may derive from Ovid's interest in rhetorical "suasoriae", persuasive speeches, and "ethopoeia", the practice of speaking in another character. They also play with generic conventions; most of the letters seem to refer to works in which these characters were significant, such as the "Aeneid" in the case of Dido and Catullus 64 for Ariadne, and transfer characters from the genres of epic and tragedy to the elegiac genre of the "Heroides". The letters have been admired for their deep psychological portrayals of mythical characters, their rhetoric, and their unique attitude to the classical tradition of mythology.
"Amores" ("The Loves").
The "Amores" is a collection in three books of love poetry in elegiac meter, following the conventions of the elegiac genre developed by Tibullus and Propertius. Elegy originates with Propertius and Tibullus; however, Ovid is an innovator in the genre. Ovid changes the leader of his elegies from the poet, to Amor (love). This switch in focus from the triumphs of the poet, to the triumphs of love over people is the first of its kind for this genre of poetry. This Ovidian innovation can be summarized as the use of love as a metaphor for poetry. The books describe the many aspects of love and focus on the poet's relationship with a mistress called Corinna. Within the various poems are several which describe events in the relationship, thus presenting the reader with some vignettes and a loose narrative.
Book 1 contains 15 poems; the first poem tells of Ovid's intention to write epic poetry which is thwarted when Cupid steals a metrical foot from him, changing his work into love elegy.
Poem 4 is didactic and describes principles which Ovid would develop in the "Ars Amatoria". The fifth poem, describing a noon tryst, introduces Corinna by name. Poems 8 and 9 deal with Corinna selling her love for gifts, while 11 and 12 describe the poet's failed attempt to arrange a meeting. Poem 14 discusses Corinna's disastrous experiment in dyeing her hair and 15 stresses the immortality of Ovid and love poets.
The second book has 19 pieces; the opening poem tells of Ovid's abandonment of a Gigantomachy in favor of elegy. Poems 2 and 3 are entreaties to a guardian to let the poet see Corinna, poem 6 is a lament for Corinna's dead parrot; poems 7 and 8 deal with Ovid's affair with Corinna's servant and her discovery of it, and 11 and 12 try to prevent Corinna from going on vacation. Poem 13 is a prayer to Isis for Corinna's illness, 14 a poem against abortion, and 19 a warning to unwary husbands.
Book 3 has 15 poems. The opening piece depicts personified Tragedy and Elegy fighting over Ovid. Poem 2 describes a visit to the races, 3 and 8 focus on Corinna's interest in other men, 10 is a complaint to Ceres because of her festival that requires abstinence, 13 is a poem on a festival of Juno, and 9 a lament for Tibullus. In poem 11 Ovid decides not to love Corinna any longer and regrets the poems he has written about her. The final poem is Ovid's farewell to the erotic muse. Critics have seen the poems as highly self-conscious and extremely playful specimens of the elegiac genre.
"Medicamina Faciei Femineae" ("Women's Facial Cosmetics").
About a hundred elegiac lines survive from this poem on beauty treatments for women's faces, which seems to parody serious didactic poetry. The poem says that women should concern themselves first with manners and then prescribes several compounds for facial treatments before breaking off. The style is not unlike the shorter Hellenistic didactic works of Nicander and Aratus.
"Ars Amatoria" ("The Art of Love").
<poem>
 Si quis in hoc artem populo non novit amandi,
 hoc legat et lecto carmine doctus amet.
</poem>The "Ars Amatoria" is a , a didactic elegiac poem in three books which sets out to teach the arts of seduction and love. The first book is addressed to men and teaches them how to seduce women, the second, also to men, teaches one how to keep a lover. The third is addressed to women and teaches seduction techniques. The first book opens with an invocation to Venus in which Ovid establishes himself as a "praeceptor amoris" (1.17) a teacher of love. Ovid describes the places one can go to find a lover, like the theater, a triumph, which is thoroughly described, or arena, and ways to get the girl to take notice, including seducing her covertly at a banquet. Choosing the right time is significant, as is getting into her associates' confidence. Ovid emphasizes care of the body for the lover. Mythological digressions include a piece on the Rape of the Sabine women, Pasiphaë, and Ariadne. Book 2 invokes Apollo and begins with a telling of the story of Icarus. Ovid advises men to avoid giving too many gifts, keep up their appearance, hide affairs, compliment their lovers, and ingratiate themselves with slaves to stay on their lover's good side. The care of Venus for procreation is described as is Apollo's aid in keeping a lover; Ovid then digresses on the story of Vulcan's trap for Venus and Mars. The book ends with Ovid asking his "students" to spread his fame. Book 3 opens with a vindication of women's abilities and Ovid's resolution to arm women against his teaching in the first two books. Ovid gives women detailed instructions on appearance telling them to avoid too many adornments. He advises women to read elegiac poetry, learn to play games, sleep with people of different ages, flirt, and dissemble. Throughout the book, Ovid playfully interjects, criticizing himself for undoing all his didactic work to men and mythologically digresses on the story of Procris and Cephalus. The book ends with his wish that women will follow his advice and spread his fame saying "Naso magister erat," "Ovid was our teacher".
"Remedia Amoris" ("The Cure for Love").
This elegiac poem proposes a cure for the love which Ovid teaches in the "Ars Amatoria" and is primarily addressed to men. The poem criticizes suicide as a means for escaping love and, invoking Apollo, goes on to tell lovers not to procrastinate and be lazy in dealing with love. Lovers are taught to avoid their partners, not perform magic, see their lover unprepared, take other lovers, and never be jealous. Old letters should be burned and the lover's family avoided. The poem throughout presents Ovid as a doctor and utilizes medical imagery. Some have interpreted this poem as the close of Ovid's didactic cycle of love poetry and the end of his erotic elegiac project.
"Metamorphoses" ("Transformations").
The "Metamorphoses", Ovid's most ambitious and popular work, consists of a 15-book catalogue written in dactylic hexameter about transformations in Greek and Roman mythology set within a loose mytho-historical framework. Within an extent of nearly 12,000 verses, almost 250 different myths are mentioned. Each myth is set outdoors where the mortals are often vulnerable to external influences. The poem stands in the tradition of mythological and aetiological catalogue poetry such as Hesiod's "Catalogue of Women", Callimachus' "Aetia", Nicander's "Heteroeumena", and Parthenius' "Metamorphoses". The first book describes the formation of the world, the ages of man, the flood, the story of Daphne's rape by Apollo and Io's by Jupiter. The second book opens with Phaethon and continues describing the love of Jupiter with Callisto and Europa. The third book focuses on the mythology of Thebes with the stories of Cadmus, Actaeon, and Pentheus. The fourth book focuses on three pairs of lovers: Pyramus and Thisbe, Salmacis and Hermaphroditus, and Perseus and Andromeda. The fifth book focuses on the song of the Muses, which describes the rape of Proserpina. The sixth book is a collection of stories about the rivalry between gods and mortals, beginning with Arachne and ending with Philomela. The seventh book focuses on Medea, as well as Cephalus and Procris. The eighth book focuses on Daedalus' flight, the Calydonian boar hunt, and the contrast between pious Baucis and Philemon and the wicked Erysichthon. The ninth book focuses on Heracles and the incestuous Byblis. The tenth book focuses on stories of doomed love, such as Orpheus, who sings about Hyacinthus, as well as Pygmalion, Myrrha, and Adonis. The eleventh book compares the marriage of Peleus and Thetis with the love of Ceyx and Alcyone. The twelfth book moves from myth to history describing the exploits of Achilles, the battle of the centaurs, and Iphigeneia. The thirteenth book discusses the contest over Achilles' arms, and Polyphemus. The fourteenth moves to Italy, describing the journey of Aeneas, Pomona and Vertumnus, and Romulus. The final book opens with a philosophical lecture by Pythagoras and the deification of Caesar. The end of the poem praises Augustus and expresses Ovid's belief that his poem has earned him immortality.
In analyzing the "Metamorphoses", scholars have focused on Ovid's organization of his vast body of material. The ways that stories are linked by geography, themes, or contrasts creates interesting effects and constantly forces the reader to evaluate the connections. Ovid also varies his tone and material from different literary genres; G. B. Conte has called the poem "a sort of gallery of these various literary genres." In this spirit, Ovid engages creatively with his predecessors, alluding creatively to the full spectrum of classical poetry. Ovid's use of Alexandrian epic, or elegiac couplets, shows his fusion of erotic and psychological style with traditional forms of epic.
"Fasti" ("The Festivals").
Six books in elegiacs survive of this second ambitious poem on which Ovid was working at the time he was exiled. The six books cover the first semester of the year, with each book dedicated to a different month of the Roman calendar (January to June). The project seems unprecedented in Roman literature. It seems that Ovid planned to cover the whole year, but was unable to finish because of his exile, although he did revise sections of the work at Tomis, and he claims at "Trist." 2.549–52 that his work was interrupted after six books. Like the "Metamorphoses", the "Fasti" was to be a long poem and emulated aetiological poetry by writers like Callimachus and, more recently, Propertius and his fourth book. The poem goes through the Roman calendar, explaining the origins and customs of important Roman festivals, digressing on mythical stories, and giving astronomical and agricultural information appropriate to the season. The poem was probably dedicated to Augustus initially, but perhaps the death of the emperor prompted Ovid to change the dedication to honor Germanicus. Ovid uses direct inquiry of gods and scholarly research to talk about the calendar and regularly calls himself a "vates", a priest. He also seems to emphasize unsavory, popular traditions of the festivals, imbuing the poem with a popular, plebeian flavor, which some have interpreted as subversive to the Augustan moral legislation. While this poem has always been invaluable to students of Roman religion and culture for the wealth of antiquarian material it preserves, it recently has been seen as one of Ovid's finest literary works and a unique contribution to Roman elegiac poetry.
"Ibis" ("The Ibis").
The "Ibis" is an elegiac poem in 644 lines, in which Ovid uses a dazzling array of mythic stories to curse and attack an enemy who is harming him in exile. At the beginning of the poem, Ovid claims that his poetry up to that point had been harmless, but now he is going to use his abilities to hurt his enemy. He cites Callimachus' "Ibis" as his inspiration and calls all the gods to make his curse effective. Ovid uses mythical exempla to condemn his enemy in the afterlife, cites evil prodigies that attended his birth, and then in the next 300 lines wishes that the torments of mythological characters befall his enemy. The poem ends with a prayer that the gods make his curse effective.
"Tristia" ("Sorrows").
The "Tristia" consist of five books of elegiac poetry composed by Ovid in exile in Tomis.
Book 1 contains 11 poems; the first piece is an address by Ovid to his book about how it should act when it arrives in Rome. Poem 3 describes his final night in Rome, poems 2 and 10 Ovid's voyage to Tomis, 8 the betrayal of a friend, and 5 and 6 the loyalty of his friends and wife. In the final poem Ovid apologizes for the quality and tone of his book, a sentiment echoed throughout the collection.
Book 2 consists of one long poem in which Ovid defends himself and his poetry, uses precedents to justify his work, and begs the emperor for forgiveness.
Book 3 in 14 poems focuses on Ovid's life in Tomis. The opening poem describes his book's arrival in Rome to find Ovid's works banned. Poems 10, 12, and 13 focus on the seasons spent in Tomis, 9 on the origins of the place, and 2, 3, and 11 his emotional distress and longing for home. The final poem is again an apology for his work.
The fourth book has ten poems addressed mostly to friends. Poem 1 expresses his love of poetry and the solace it brings; while 2 describes a triumph of Tiberius. Poems 3–5 are to friends, 7 a request for correspondence, and 10 an autobiography.
The final book of the "Tristia" with 14 poems focuses on his wife and friends. Poems 4, 5, 11, and 14 are addressed to his wife, 2 and 3 are prayers to Augustus and Bacchus, 4 and 6 are to friends, 8 to an enemy. Poem 13 asks for letters, while 1 and 12 are apologies to his readers for the quality of his poetry.
"Epistulae ex Ponto" ("Letters from the Black Sea").
The "Epistulae ex Ponto" is a collection in four books of further poetry from exile. The "Epistulae" are each addressed to a different friend and focus more desperately than the "Tristia" on securing his recall from exile. The poems mainly deal with requests for friends to speak on his behalf to members of the imperial family, discussions of writing with friends, and descriptions of life in exile. The first book has ten pieces in which Ovid describes the state of his health (10), his hopes, memories, and yearning for Rome (3, 6, 8), and his needs in exile (3). Book 2 contains impassioned requests to Germanicus (1 and 5) and various friends to speak on his behalf at Rome while he describes his despair and life in exile. Book 3 has nine poems in which Ovid addresses his wife (1) and various friends. It includes a telling of the story of Iphigenia in Tauris (2), a poem against criticism (9), and a dream of Cupid (3). Book 4, the final work of Ovid, in 16 poems talks to friends and describes his life as an exile further. Poems 10 and 13 describe Winter and Spring at Tomis, poem 14 is halfhearted praise for Tomis, 7 describes its geography and climate, and 4 and 9 are congratulations on friends for their consulships and requests for help. Poem 12 is addressed to a Tuticanus, whose name, Ovid complains, does not fit into meter. The final poem is addressed to an enemy whom Ovid implores to leave him alone. The last elegiac couplet is translated: "Where’s the joy in stabbing your steel into my dead flesh?/ There’s no place left where I can be dealt fresh wounds."
Lost works.
One loss which Ovid himself described is the first five-book edition of the "Amores" from which nothing has come down to us. The greatest loss is Ovid's only tragedy, "Medea", from which only a few lines are preserved. Quintilian admired the work a great deal and considered it a prime example of Ovid's poetic talent. Lactantius quotes from a lost translation by Ovid of Aratus' "Phaenomena", although the poem's ascription to Ovid is insecure because it is never mentioned in Ovid's other works. 
A line from a work entitled "Epigrammata" is cited by Priscian.
Even though it is unlikely, if the last six books of the "Fasti" ever existed, they constitute a great loss. Ovid also mentions some occasional poetry ("Epithalamium", dirge, even a rendering in Getic) which does not survive. Also lost is the final portion of the "Medicamina".
Spurious works.
"Consolatio ad Liviam" ("Consolation to Livia").
The "Consolatio" is a long elegiac poem of consolation to Augustus' wife Livia on the death of her son Drusus. The poem opens by advising Livia not to try to hide her sad emotions and contrasts Drusus' military virtue with his death. Drusus' funeral and the tributes of the imperial family are described as are his final moments and Livia's lament over the body, which is compared to birds. The laments of the city of Rome as it greets his funeral procession and the gods are mentioned, and Mars from his temple dissuades the Tiber river from quenching the pyre out of grief.
Grief is expressed for his lost military honors, his wife, and his mother. The poet asks Livia to look for consolation in Tiberius. The poem ends with an address by Drusus to Livia assuring him of his fate in Elysium. Although this poem was connected to the "Elegiae in Maecenatem", it is now thought that they are unconnected. The date of the piece is unknown, but a date in the reign of Tiberius has been suggested because of that emperor's prominence in the poem.
"Halieutica" ("On Fishing").
The "Halieutica" is a fragmentary didactic poem in 134 poorly preserved hexameter lines and is considered spurious. The poem begins by describing how every animal possesses the ability to protect itself and how fish use "ars" to help themselves. The ability of dogs and land creatures to protect themselves is described. The poem goes on to list the places which are best for fishing and which types of fish should be caught. Although Pliny the Elder mentions a "Halieutica" by Ovid, which was composed at Tomis near the end of Ovid's life, modern scholars believe Pliny was mistaken in his attribution and that the poem is not genuine.
"Nux" ("The Walnut Tree").
This short poem in 91 elegiac couplets is a monologue spoken by a walnut tree asking that boys not pelt her with stones to get her fruit. The tree contrasts the formerly fruitful golden age with the present barren time, in which its fruit is violently ripped off and its branches broken. The tree compares itself to several mythological characters, praises the peace the emperor provides, and prays to be destroyed rather than suffer. The poem is considered spurious because it incorporates allusions to Ovid's works in an uncharacteristic way, although the piece is thought to be contemporary or by a poet of the same period.
"Somnium" ("The Dream").
This poem, traditionally placed at "Amores" 3.5, is considered spurious. The poet describes a dream to an interpreter, saying that he sees while escaping from the heat of noon a white heifer near a bull; when the heifer is pecked by a crow, it leaves the bull for a meadow with other bulls. The interpreter interprets the dream as a love allegory; the bull represents the poet, the heifer a girl, and the crow an old woman. The old woman spurs the girl to leave her lover and find someone else. The poem is known to have circulated independently and its lack of engagement with Tibullan or Propertian elegy argue in favor of its spuriousness; however, the poem does seem to be datable to the early empire.
Style.
Ovid is traditionally considered the final significant love elegist in the evolution of the genre and one of the most versatile in his handling of the genre's conventions. Like the other canonical elegiac poets Ovid takes on a persona in his works that emphasizes subjectivity and personal emotion over traditional militaristic and public goals, a convention which has been linked by some scholars with the relative stability provided by the Augustan settlement. However, although Catullus, Tibullus and Propertius may have been inspired in part by personal experience, the validity of "biographical" readings of these poets' works is a serious point of scholarly contention.
Ovid has been seen as taking on a persona in his poetry which is far more emotionally detached from his mistress and less involved in crafting a unique emotional realism within the text than the other elegists. This attitude, coupled with the lack of testimony which identifies Ovid's Corinna with a real person has led scholars to conclude that Corinna was never a real person and that Ovid's relationship with her is an invention for his elegiac project. Some scholars have even interpreted Corinna as a metapoetic symbol for the elegiac genre itself.
Ovid has been considered a highly inventive love elegist who plays with traditional elegiac conventions and elaborates the themes of the genre; Quintilian even calls him a "sportive" elegist. In some poems, he uses traditional conventions in new ways, such as the "paraklausithyron" of "Am." 1.6, while other poems seem to have no elegiac precedents and appear to be Ovid's own generic innovations, such as the poem on Corinna's ruined hair ("Am." 1.14). Ovid has been traditionally seen as far more sexually explicit in his poetry than the other elegists.
His erotic elegy covers a wide spectrum of themes and viewpoints; the "Amores" focus on Ovid's relationship with Corinna, the love of mythical characters is the subject of the "Heroides", and the "Ars Amatoria" and the other didactic love poems provide a handbook for relationships and seduction from a (mock-)"scientific" viewpoint. In his treatment of elegy, scholars have traced the influence of rhetorical education in his enumeration, in his effects of surprise, and in his transitional devices.
Some commentators have also noted the influence of Ovid's interest in love elegy in his other works, such as the "Fasti," and have distinguished his "elegiac" style from his "epic" style. Richard Heinze in his famous "Ovids elegische Erzählung" (1919) delineated the distinction between Ovid's styles by comparing the "Fasti" and "Metamorphoses" versions of the same legends, such as the treatment of the Ceres–Proserpina story in both poems. Heinze demonstrated that, "whereas in the elegiac poems a sentimental and tender tone prevails, the hexameter narrative is characterized by an emphasis on solemnity and awe..." His general line of argument has been accepted by Brooks Otis, who wrote:
The gods are "serious" in epic as they are not in elegy; the speeches in epic are long and infrequent compared to the short, truncated and frequent speeches of elegy; the epic writer conceals himself while the elegiac fills his narrative with familiar remarks to the reader or his characters; above all perhaps, epic narrative is continuous and symmetrical... whereas elegiac narrative displays a marked asymmetry ...
Otis wrote that in the Ovidian poems of love, he "was burlesquing an old theme rather than inventing a new one." Otis states that the "Heroides" are more serious and, though some of them are "quite different from anything Ovid had done before [...] he is here also treading a very well-worn path" to relate that the motif of females abandoned by or separated from their men was a "stock motif of Hellenistic and neoteric poetry (the classic example for us is, of course, Catullus 66)."
Otis also states that Phaedra and Medea, Dido and Hermione (also present in the poem) "are clever re-touchings of Euripides and Vergil." Some scholars, such as Kenney and Clausen, have compared Ovid with Virgil. According to them, Virgil was ambiguous and ambivalent while Ovid was defined and, while Ovid wrote only what he could express, Virgil wrote for the use of language.
Legacy.
Criticism.
Ovid's works have been interpreted in various ways over the centuries with attitudes that depended on the social, religious and literary contexts of different times. It is known that since his own lifetime, he was already famous and criticized. In the "Remedia Amoris", Ovid reports criticism from people who considered his books insolent.
Ovid responded to this criticism by writing the following: "Gluttonous Envy, burst: my name’s well known already:/it will be more so, if only my feet travel the road they’ve started./But you’re in too much of a hurry: if I live you’ll be more than sorry:/many poems, in fact, are forming in my mind." After such criticism subsided, Ovid became one of the best known and most loved Roman poets during the Middle Ages and the Renaissance.
Writers in the Middle Ages used his work as a way to read and write about sex and violence without orthodox "scrutiny routinely given to commentaries on the Bible". In the Middle Ages the voluminous "", a French work that moralizes 15 books of the "Metamorphoses" was composed. This work then influenced Chaucer. Ovid's poetry provided inspiration for the Renaissance idea of humanism, and more specifically, for many Renaissance painters and writers.
Likewise, Arthur Golding moralized his own translation of the full 15 books, and published it in 1567. This version was the same version used as a supplement to the original Latin in the Tudor-era grammar schools that influenced such major Renaissance authors as Christopher Marlowe and William Shakespeare. Many non-English authors were heavily influence from Ovid's works as well. Montaigne, for example, alluded to Ovid several times in his "Essais", specifically in his comments on "Education of Children" when he says:
The first taste I had for books came to me from my pleasure in the fables of the "Metamorphoses" of Ovid. For at about seven or eight years of age I would steal away from any other pleasure to read them, inasmuch as this language was my mother tongue, and it was the easiest book I knew and the best suited by its content to my tender age.
 Cervantes also used the "Metamorphoses" as a platform of inspiration for his prodigious novel "Don Quixote."
In the 16th century, some Jesuit schools of Portugal cut several passages from Ovid's "Metamorphoses". While the Jesuits saw his poems as elegant compositions worthy of being presented to students for educational purposes, they also felt his works as a whole might corrupt students. The Jesuits took much of their knowledge of Ovid to the Portuguese colonies. According to Serafim Leite (1949), the "ratio studiorum" was in effect in Colonial Brazil during the early 17th century, and in this period Brazilian students read works like the "Epistulae ex Ponto" to learn Latin grammar.
In Spain, Ovid is both praised and criticized by Cervantes in his "Don Quixote" where he warns against satires that can exile poets, as happened to Ovid. In the 16th century, Ovid's works were criticized in England. The Archbishop of Canterbury and the Bishop of London ordered that a contemporary translation of Ovid's love poems be publicly burned in 1599. The Puritans of the following century viewed Ovid as pagan, thus as an immoral influence.
John Dryden composed a famous translation of the "Metamorphoses" into stopped rhyming couplets during the 17th century, when Ovid was "refashioned [...] in its own image, one kind of Augustanism making over another." The Romantic movement of the 19th century, in contrast, considered Ovid and his poems "stuffy, dull, over-formalized and lacking in genuine passion." Romantics might have preferred his poetry of exile.
The picture "Ovid among the Scythians", painted by Delacroix, portrays the last years of the poet in exile in Scythia, and was seen by Baudelaire, Gautier and Edgar Degas. Baudelaire took the opportunity to write a long essay about the life of an exiled poet like Ovid. This shows that the exile of Ovid had some influence in 19th century Romanticism since it makes connections with its key concepts such as wildness and the misunderstood genius.
Ovid's Influence.
Literary and artistic.
Dante twice mentions him in:
Notes.
</dl>

</doc>
<doc id="37803" url="http://en.wikipedia.org/wiki?curid=37803" title="Cubism">
Cubism

Cubism is an early-20th-century avant-garde art movement that revolutionized European painting and sculpture, and inspired related movements in music, literature and architecture. Cubism has been considered the most influential art movement of the 20th century. The term is broadly used in association with a wide variety of art produced in Paris (Montmartre, Montparnasse and Puteaux) during the 1910s and extending through the 1920s.
The movement was pioneered by Georges Braque and Pablo Picasso, joined by Jean Metzinger, Albert Gleizes, Robert Delaunay, Henri Le Fauconnier, Fernand Léger and Juan Gris. A primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul Cézanne. A retrospective of Cézanne's paintings had been held at the Salon d'Automne of 1904, current works were displayed at the 1905 and 1906 Salon d'Automne, followed by two commemorative retrospectives after his death in 1907.
In Cubist artwork, objects are analyzed, broken up and reassembled in an abstracted form—instead of depicting objects from one viewpoint, the artist depicts the subject from a multitude of viewpoints to represent the subject in a greater context.
The impact of Cubism was far-reaching and wide-ranging. Cubism spread rapidly across the globe and in doing so evolved to greater or lesser extent. In essence, Cubism was the starting point of an evolutionary processes that produced diversity; it was the antecedent of diverse art movements.
In France, offshoots of Cubism developed, including Orphism, Abstract art and later Purism. In other countries Futurism, Suprematism, Dada, Constructivism and De Stijl developed in response to Cubism. Early Futurist paintings hold in common with Cubism the fusing of the past and the present, the representation of different views of the subject pictured at the same time, also called multiple perspective, simultaneity or multiplicity, while Constructivism was influenced by Picasso's technique of constructing sculpture from separate elements. Other common threads between these disparate movements include the faceting or simplification of geometric forms, and the association of mechanization and modern life.
Conception and origins.
Cubism began between 1907 and 1911. Pablo Picasso's 1907 painting "Les Demoiselles d'Avignon" has often been considered a proto-Cubist work. Georges Braque's 1908 "Houses at L’Estaque" (and related works) prompted the critic Louis Vauxcelles to refer to "bizarreries cubiques" (cubic oddities). Gertrude Stein referred to landscapes made by Picasso in 1909, such as "Reservoir at Horta de Ebro", as the first Cubist paintings. The first organized group exhibition by Cubists took place at the Salon des Indépendants in Paris during the spring of 1911 in a room called ‘Salle 41’; it included works by Jean Metzinger, Albert Gleizes, Fernand Léger, Robert Delaunay and Henri Le Fauconnier, yet no works by Picasso and Braque were exhibited.
By 1911 Picasso was recognized as the inventor of Cubism, while Braque’s importance and precedence was argued later, with respect to his treatment of space, volume and mass in the L’Estaque landscapes. But "this view of Cubism is associated with a distinctly restrictive definition of which artists are properly to be called Cubists," wrote the art historian Christopher Green: "Marginalizing the contribution of the artists who exhibited at the Salon des Indépendants in 1911 [...]"
Historians have divided the history of Cubism into phases. In one scheme, the first phase of Cubism, known as "Analytic Cubism", a phrase coined by Juan Gris a posteriori, was both radical and influential as a short but highly significant art movement between 1910 and 1912 in France. A second phase, "Synthetic Cubism", remained vital until around 1919, when the Surrealist movement gained popularity. English art historian Douglas Cooper proposed another scheme, describing three phases of Cubism in his book, "The Cubist Epoch". According to Cooper there was "Early Cubism", (from 1906 to 1908) when the movement was initially developed in the studios of Picasso and Braque; the second phase being called "High Cubism", (from 1909 to 1914) during which time Juan Gris emerged as an important exponent (after 1911); and finally Cooper referred to "Late Cubism" (from 1914 to 1921) as the last phase of Cubism as a radical avant-garde movement. Douglas Cooper's restrictive use of these terms to distinguish the work of Braque, Picasso, Gris (from 1911) and Léger (to a lesser extent) implied an intentional value judgement.
The assertion that the Cubist depiction of space, mass, time, and volume supports (rather than contradicts) the flatness of the canvas was made by Daniel-Henry Kahnweiler as early as 1920, but it was subject to criticism in the 1950s and 1960s, especially by Clement Greenberg. Contemporary views of Cubism are complex, formed to some extent in response to the "Salle 41" Cubists, whose methods were too distinct from those of Picasso and Braque to be considered merely secondary to them. Alternative interpretations of Cubism have therefore developed. Wider views of Cubism include artists who were later associated with the "Salle 41" artists, e.g., Francis Picabia; the brothers Jacques Villon, Raymond Duchamp-Villon and Marcel Duchamp, who beginning in late 1911 formed the core of the Section d'Or (or the Puteaux Group); the sculptors Alexander Archipenko, Joseph Csaky and Ossip Zadkine as well as Jacques Lipchitz and Henri Laurens; and painters such as Louis Marcoussis, Roger de La Fresnaye, František Kupka, Diego Rivera, Léopold Survage, Auguste Herbin, André Lhote, Gino Severini (after 1916), María Blanchard (after 1916) and Georges Valmier (after 1918). More fundamentally, Christopher Green argues that Douglas Cooper's terms were "later undermined by interpretations of the work of Picasso, Braque, Gris and Léger that stress iconographic and ideological questions rather than methods of representation."
John Berger identifies the essence of Cubism with the mechanical diagram. "The metaphorical model of Cubism is the diagram: The diagram being a visible symbolic representation of invisible processes, forces, structures. A diagram need not eschew certain aspects of appearance but these too will be treated as signs not as imitations or recreations."
Technical and stylistic aspects.
During the late 19th and early 20th centuries, Europeans were discovering African, Polynesian, Micronesian and Native American art. Artists such as Paul Gauguin, Henri Matisse, and Pablo Picasso were intrigued and inspired by the stark power and simplicity of styles of those foreign cultures. Around 1906, Picasso met Matisse through Gertrude Stein, at a time when both artists had recently acquired an interest in primitivism, Iberian sculpture, African art and African tribal masks. They became friendly rivals and competed with each other throughout their careers, perhaps leading to Picasso entering a new period in his work by 1907, marked by the influence of Greek, Iberian and African art. Picasso's paintings of 1907 have been characterized as Protocubism, as notably seen in "Les Demoiselles d'Avignon", the antecedent of Cubism.
The art historian Douglas Cooper states that Paul Gauguin and Paul Cézanne "were particularly influential to the formation of Cubism and especially important to the paintings of Picasso during 1906 and 1907". Cooper goes on to say: "The "Demoiselles" is generally referred to as the first Cubist picture. This is an exaggeration, for although it was a major first step towards Cubism it is not yet Cubist. The disruptive, expressionist element in it is even contrary to the spirit of Cubism, which looked at the world in a detached, realistic spirit. Nevertheless, the "Demoiselles" is the logical picture to take as the starting point for Cubism, because it marks the birth of a new pictorial idiom, because in it Picasso violently overturned established conventions and because all that followed grew out of it."
The most serious objection to regarding the "Demoiselles" as the origin of Cubism, with its evident influence of primitive art, is that "such deductions are unhistorical", wrote the art historian Daniel Robbins. This familiar explanation "fails to give adequate consideration to the complexities of a flourishing art that existed just before and during the period when Picasso's new painting developed." Between 1905 and 1908, a conscious search for a new style caused rapid changes in art across France, Germany, Holland, Italy, and Russia. The Impressionists had used a double point of view, and both Les Nabis and the Symbolists (who also admired Cézanne) flattened the picture plane, reducing their subjects to simple geometric forms. Neo-Impressionist structure and subject matter, most notably to be seen in the works of Georges Seurat (e.g., "Parade de Cirque", "Le Chahut" and "Le Cirque"), was another important influence. There were also parallels in the development of literature and social thought.
In addition to Seurat, the roots of cubism are to be found in the two distinct tendencies of Cézanne's later work: first his breaking of the painted surface into small multifaceted areas of paint, thereby emphasizing the plural viewpoint given by binocular vision, and second his interest in the simplification of natural forms into cylinders, spheres, and cones. However, the cubists explored this concept further than Cézanne. They represented all the surfaces of depicted objects in a single picture plane, as if the objects had all their faces visible at the same time. This new kind of depiction revolutionized the way objects could be visualized in painting and art.
The historical study of Cubism began in the late 1920s, drawing at first from sources of limited data, namely the opinions of Guillaume Apollinaire. It came to rely heavily on Daniel-Henry Kahnweiler's book "Der Weg zum Kubismus" (published in 1920), which centered on the developments of Picasso, Braque, Léger, and Gris. The terms "analytical" and "synthetic" which subsequently emerged have been widely accepted since the mid-1930s. Both terms are historical impositions that occurred after the facts they identify. Neither phase was designated as such at the time corresponding works were created. "If Kahnweiler considers Cubism as Picasso and Braque," wrote Daniel Robbins, "our only fault is in subjecting other Cubists' works to the rigors of that limited definition."
The traditional interpretation of "Cubism", formulated "post facto" as a means of understanding the works of Braque and Picasso, has affected our appreciation of other twentieth-century artists. It is difficult to apply to painters such as Jean Metzinger, Albert Gleizes, Robert Delaunay and Henri Le Fauconnier, whose fundamental differences from traditional Cubism compelled Kahnweiler to question their right to be called Cubists at all. According to Daniel Robbins, "To suggest that merely because these artists developed differently or varied from the traditional pattern they deserved to be relegated to a secondary or satellite role in Cubism is a profound mistake."
The history of the term "Cubism" usually stresses the fact that Matisse referred to "cubes" in connection with a painting by Braque in 1908, and that the term was published twice by the critic Louis Vauxcelles in a similar context. However, the word "cube" was used in 1906 by another critic, Louis Chassevent, with reference not to Picasso or Braque but rather to Metzinger and Delaunay:
The critical use of the word "cube" goes back at least to May 1901 when Jean Béral, reviewing the work of Henri-Edmond Cross at the Indépendants in "Art et Littérature", commented that he "uses a large and square pointillism, giving the impression of mosaic. One even wonders why the artist has not used cubes of solid matter diversely colored: they would make pretty revetments." (Robert Herbert, 1968, p. 221)
The term Cubism did not come into general usage until 1911, mainly with reference to Metzinger, Gleizes, Delaunay, and Léger. In 1911, the poet and critic Guillaume Apollinaire accepted the term on behalf of a group of artists invited to exhibit at the Brussels Indépendants. The following year, in preparation for the Salon de la Section d'Or, Metzinger and Gleizes wrote and published "Du "Cubisme"" in an effort to dispel the confusion raging around the word, and as a major defence of Cubism (which had caused a public scandal following the 1911 Salon des Indépendants and the 1912 Salon d'Automne in Paris). Clarifying their aims as artists, this work was the first theoretical treatise on Cubism and it still remains the clearest and most intelligible. The result, not solely a collaboration between its two authors, reflected discussions by the circle of artists who met in Puteaux and Courbevoie. It mirrored the attitudes of the "artists of Passy", which included Picabia and the Duchamp brothers, to whom sections of it were read prior to publication. The concept developed in "Du "Cubisme"" of observing a subject from different points in space and time simultaneously, i.e., the act of moving around an object to seize it from several successive angles fused into a single image (multiple viewpoints, mobile perspective, simultaneity or multiplicity), is a generally recognized device used by the Cubists.
The 1912 manifetso "Du "Cubisme"" by Metzinger and Gleizes was followed in 1913 by "Les Peintres Cubistes", a collection of reflections and commentaries by Guillaume Apollinaire. Apollinaire had been closely involved with Picasso beginning in 1905, and Braque beginning in 1907, but gave as much attention to artists such as Metzinger, Gleizes, Delaunay, Picabia, and Duchamp.
Cubism before 1914.
There was a distinct difference between Kahnweiler’s Cubists and the Salon Cubists. Prior to 1914, Picasso, Braque, Gris and Léger (to a lesser extent) gained the support of a single committed art dealer in Paris, Daniel-Henry Kahnweiler, who guaranteed them an annual income for the exclusive right to buy their works. Kahnweiler sold only to a small circle of connoisseurs. His support gave his artists the freedom to experiment in relative privacy. Picasso worked in Montmartre until 1912, while Braque and Gris remained there until after the First World War. Léger was based in Montparnasse.
In contrast, the Salon Cubists built their reputation primarily by exhibiting regularly at the Salon d'Automne and the Salon des Indépendants, both major non-academic Salons in Paris. They were inevitably more aware of public response and the need to communicate. Already in 1910 a group began to form which included Metzinger, Gleizes, Delaunay and Léger. They met regularly at Henri le Fauconnier's studio near the Boulevard de Montparnasse. These soirées often included writers such as Guillaume Apollinaire and André Salmon. Together with other young artists, the group wanted to emphasise a research into form, in opposition to the Neo-Impressionist emphasis on color.
Louis Vauxcelles, in his review of the 26th Salon des Indépendants (1910), made a passing and imprecise reference to Metzinger, Gleizes, Delaunay, Léger and Le Fauconnier as "ignorant geometers, reducing the human body, the site, to pallid cubes." At the 1910 Salon d'Automne, a few months later, Metzinger exhibited his highly fractured "Nu à la cheminée (Nude)", which was subsequently reproduced in "Les Peintres Cubistes" by Apollinaire (1913).
The first public controversy generated by Cubism resulted from Salon showings at the Indépendants during the spring of 1911. This showing by Metzinger, Gleizes, Delaunay, le Fauconnier and Léger brought Cubism to the attention of the general public for the first time. Amongst the Cubist works presented, Robert Delaunay exhibited his "Eiffel Tower, Tour Eiffel" (Solomon R. Guggenheim Museum, New York).
At the Salon d'Automne of the same year, in addition to the Indépendants group of "Salle 41", were exhibited works by André Lhote, Marcel Duchamp, Jacques Villon, Roger de La Fresnaye, André Dunoyer de Segonzac and František Kupka. The exhibition was reviewed in the October 8, 1911 issue of The New York Times. This article was published a year after Gelett Burgess' "The Wild Men of Paris", and two years prior to the Armory Show, which introduced astonished Americans, accustomed to realistic art, to the experimental styles of the European avant garde, including Fauvism, Cubism, and Futurism. The 1911 New York Times article portrayed works by Picasso, Matisse, Derain, Metzinger and others dated before 1909; not exhibited at the 1911 Salon. The article is titled: "The "Cubists" Dominate Paris' Fall Salon" and subtitled, "Eccentric School of Painting Increases Its Vogue in the Current Art Exhibition - What Its Followers Attempt to Do."
The subsequent 1912 Salon des Indépendants was marked by the presentation of Marcel Duchamp's "Nude Descending a Staircase, No. 2", which itself caused a scandal, even amongst the Cubists. It was in fact rejected by the hanging committee, which included his brothers and other Cubists. Although the work was shown in the Salon de la Section d'Or in October 1912 and the 1913 Armory Show in New York, Duchamp never forgave his brothers and former colleagues for censoring his work. Juan Gris, a new addition to the Salon scene, exhibited his "Portrait of Picasso" (Art Institute of Chicago), while Metzinger's two showings included "La Femme au Cheval (Woman with a horse)" 1911-1912 (Statens Museum for Kunst, National Gallery of Denmark). Delaunay's monumental "La Ville de Paris" (Musée d'art moderne de la Ville de Paris) and Léger's "La Noce, The Wedding" (Musée National d'Art Moderne, Paris) were also exhibited.
The Cubist contribution to the 1912 Salon d'Automne created scandal regarding the use of government owned buildings, such as the Grand Palais, to exhibit such artwork. The indignation of the politician Jean Pierre Philippe Lampué made the front page of "Le Journal", 5 October 1912. The controversy spread to the Municipal Council of Paris, leading to a debate in the Chambre des Députés about the use of public funds to provide the venue for such art. The Cubists were defended by the Socialist deputy, Marcel Sembat.
It was against this background of public anger that Jean Metzinger and Albert Gleizes wrote "Du "Cubisme"" (published by Eugène Figuière in 1912, translated to English and Russian in 1913). Among the works exhibited were Le Fauconnier's vast composition "Les Montagnards attaqués par des ours (Mountaineers Attacked by Bears)" now at Rhode Island School of Design Museum, Joseph Csaky's "Deux Femme, Two Women" (a sculpture now lost), in addition to the highly abstract paintings by Kupka, "Amorpha" (The National Gallery, Prague), and Picabia, "La Source, The Spring" (Museum of Modern Art, New York).
Abstraction and the Ready-made.
The most extreme forms of Cubism were not those practiced by Picasso and Braque, who resisted total abstraction. Other Cubists, by contrast, especially František Kupka, and those considered Orphists by Apollinaire (Delaunay, Léger, Picabia and Duchamp), accepted abstraction by removing visible subject matter entirely. Kupka’s two entries at the 1912 Salon d'Automne, "Amorpha-Fugue à deux couleurs" and "Amorpha chromatique chaude", were highly abstract (or nonrepresentational) and metaphysical in orientation. Both Duchamp in 1912 and Picabia from 1912 to 1914 developed an expressive and allusive abstraction dedicated to complex emotional and sexual themes. Beginning in 1912 Delaunay painted a series of paintings entitled "Simultaneous Windows", followed by a series entitled "Formes Circulaires", in which he combined planar structures with bright prismatic hues; based on the optical characteristics of juxtaposed colors his departure from reality in the depiction of imagery was quasi-complete. In 1913–14 Léger produced a series entitled "Contrasts of Forms", giving a similar stress to color, line and form. His Cubism, despite its abstract qualities, was associated with themes of mechanization and modern life. Apollinaire supported these early developments of abstract Cubism in "Les Peintres cubistes" (1913), writing of a new "pure" painting in which the subject was vacated. But in spite of his use of the term Orphism these works were so different that they defy attempts to place them in a single category.
Also labeled an Orphist by Apollinaire, Marcel Duchamp was responsible for another extreme development inspired by Cubism. The Ready-made arose from a joint consideration that the work itself is considered an object (just as a painting), and that it uses the material detritus of the world (as collage and papier collé in the Cubist construction and Assemblage). The next logical step, for Duchamp, was to present an ordinary object as a self-sufficient work of art representing only itself. In 1913 he attached a bicycle wheel to a kitchen stool and in 1914 selected a bottle-drying rack as a sculpture in its own right.
Section d'Or.
The "Section d'Or", also known as "Groupe de Puteaux", founded by some of the most conspicuous Cubists, was a collective of painters, sculptors and critics associated with Cubism and Orphism, active from 1911 through about 1914, coming to prominence in the wake of their controversial showing at the 1911 Salon des Indépendants. The "Salon de la Section d'Or" at the "Galerie La Boétie" in Paris, October 1912, was arguably the most important pre-World War I Cubist exhibition; exposing Cubism to a wide audience. Over 200 works were displayed, and the fact that many of the artists showed artworks representative of their development from 1909 to 1912 gave the exhibition the allure of a Cubist retrospective.
The group seems to have adopted the name Section d'Or to distinguish themselves from the narrower definition of Cubism developed in parallel by Pablo Picasso and Georges Braque in the Montmartre quarter of Paris, and to show that Cubism, rather than being an isolated art-form, represented the continuation of a grand tradition (indeed, the golden ratio had fascinated Western intellectuals of diverse interests for at least 2,400 years).
The idea of the Section d'Or originated in the course of conversations between Metzinger, Gleizes and Jacques Villon. The group's title was suggested by Villon, after reading a 1910 translation of Leonardo da Vinci's "Trattato della Pittura" by Joséphin Péladan.
The fact that the 1912 exhibition had been curated to show the successive stages through which Cubism had transited, and that "Du "Cubisme"" had been published for the occasion, indicates the artists' intention of making their work comprehensible to a wide audience (art critics, art collectors, art dealers and the general public). Undoubtedly, due to the great success of the exhibition, Cubism became recognized as a tendency, genre or style in art with a specific common philosophy or goal: a new avant-garde movement.
Intentions and interpretations.
The Cubism of Picasso, Braque and Gris had more than a technical or formal significance, and the distinct attitudes and intentions of the Salon Cubists produced different kinds of Cubism, rather than a derivative of their work. "It is by no means clear, in any case," wrote Christopher Green, "to what extent these other Cubists depended on Picasso and Braque for their development of such techniques as faceting, 'passage' and multiple perspective; they could well have arrived at such practices with little knowledge of 'true' Cubism in its early stages, guided above all by their own understanding of Cézanne." The works exhibited by these Cubists at the 1911 and 1912 Salons extended beyond the conventional Cézanne-like subjects—the posed model, still-life and landscape—favored by Picasso and Braque to include large-scale modern-life subjects. Aimed at a large public, these works stressed the use of multiple perspective and complex planar faceting for expressive effect while preserving the eloquence of subjects endowed with literary and philosophical connotations.
In "Du "Cubisme"" Metzinger and Gleizes explicitly related the sense of time to multiple perspective, giving symbolic expression to the notion of ‘duration’ proposed by the philosopher Henri Bergson according to which life is subjectively experienced as a continuum, with the past flowing into the present and the present merging into the future. The Salon Cubists used the faceted treatment of solid and space and effects of multiple viewpoints to convey a physical and psychological sense of the fluidity of consciousness, blurring the distinctions between past, present and future. One of the major theoretical innovations made by the Salon Cubists, independently of Picasso and Braque, was that of "simultaneity", drawing to greater or lesser extent on theories of Henri Poincaré, Ernst Mach, Charles Henry, Maurice Princet, and Henri Bergson. With simultaneity, the concept of separate spatial and temporal dimensions was comprehensively challenged. Linear perspective developed during the Renaissance was vacated. The subject-matter was no longer considered from a specific point of view at a moment in time, but built following a selection of successive viewpoints, i.e., as if viewed simultaneously from numerous angles (and in multiple dimensions) with the eye free to roam from one to the other.
This technique of representing simultaneity, multiple viewpoints (or relative motion) is pushed to a high degree of complexity in Gleizes' monumental "Le Dépiquage des Moissons (Harvest Threshing)", exhibited at the 1912 Salon de la Section d'Or, Le Fauconnier’s "Abundance" shown at the Indépendants of 1911, and Delaunay's "City of Paris", shown at the Indépendants in 1912. These ambitious works are some of the largest paintings in the history of Cubism. Léger’s "The Wedding", also shown at the Salon des Indépendants in 1912, gave form to the notion of simultaneity by presenting different motifs as occurring within a single temporal frame, where responses to the past and present interpenetrate with collective force. The conjunction of such subject-matter with simultaneity aligns Salon Cubism with early Futurist paintings by Umberto Boccioni, Gino Severini and Carlo Carrà; themselves made in response to early Cubism.
Cubism and modern European art was introduced into the United States at the now legendary 1913 Armory Show in New York City, which then traveled to Chicago and Boston. In the Armory show Pablo Picasso exhibited "La Femme au pot de moutarde" (1910), the sculpture "Head of a Woman (Fernande)" (1909–10), "Les Arbres" (1907) amongst other cubist works. Jacques Villon exhibited seven important and large drypoints, his brother Marcel Duchamp shocked the American public with his painting "Nude Descending a Staircase, No. 2" (1912). Francis Picabia exhibited his abstractions "La Danse à la source" and "La Procession, Seville" (both of 1912). Albert Gleizes exhibited "La Femme aux phlox" (1910) and "L'Homme au balcon" (1912), two highly stylized and faceted cubist works. Georges Braque, Fernand Léger, Raymond Duchamp-Villon, Roger de La Fresnaye and Alexander Archipenko also contributed examples of their cubist works.
Cubist sculpture.
Just as in painting, Cubist sculpture is rooted in Paul Cézanne's reduction of painted objects into component planes and geometric solids (cubes, spheres, cylinders, and cones). And just as in painting, it became a pervasive influence and contributed fundamentally to Constructivism and Futurism.
Cubist sculpture developed in parallel to Cubist painting. During the autumn of 1909 Picasso sculpted "Head of a Woman (Fernande)" with positive features depicted by negative space and vice versa. According to Douglas Cooper: "The first true Cubist sculpture was Picasso's impressive "Woman's Head", modeled in 1909-10, a counterpart in three dimensions to many similar analytical and faceted heads in his paintings at the time." These positive/negative reversals were ambitiously exploited by Alexander Archipenko in 1912–13, for example in "Woman Walking". Joseph Csaky, after Archipenko, was the first sculptor in Paris to join the Cubists, with whom he exhibited from 1911 onwards. They were followed by Raymond Duchamp-Villon and then in 1914 by Jacques Lipchitz, Henri Laurens and Ossip Zadkine.
Indeed, Cubist construction was as influential as any pictorial Cubist innovation. It was the stimulus behind the proto-Constructivist work of both Naum Gabo and Vladimir Tatlin and thus the starting-point for the entire constructive tendency in 20th-century modernist sculpture.
Cubism after 1918.
The most innovative period of Cubism was before 1914. After World War I, with the support given by the dealer Léonce Rosenberg, Cubism returned as a central issue for artists, and continued as such until the mid-1920s when its avant-garde status was rendered questionable by the emergence of geometric abstraction and Surrealism in Paris. Many Cubists, including Picasso, Braque, Gris, Léger, Gleizes, and Metzinger, while developing other styles, returned periodically to Cubism, even well after 1925. Cubism reemerged during the 1920s and the 1930s in the work of the American Stuart Davis and the Englishman Ben Nicholson. In France, however, Cubism experienced a decline beginning in about 1925. Léonce Rosenberg exhibited not only the artists stranded by Kahnweiler’s exile but others including Laurens, Lipchitz, Metzinger, Gleizes, Csaky, Herbin and Severini. In 1918 Rosenberg presented a series of Cubist exhibitions at his Galerie de l’Effort Moderne in Paris. Attempts were made by Louis Vauxcelles to claim that Cubism was dead, but these exhibitions, along with a well-organized Cubist show at the 1920 Salon des Indépendants and a revival of the Salon de la Section d’Or in the same year, demonstrated it was still alive.
The reemergence of Cubism coincided with the appearance from about 1917–24 of a coherent body of theoretical writing by Pierre Reverdy, Maurice Raynal and Daniel-Henry Kahnweiler and, among the artists, by Gris, Léger and Gleizes. The occasional return to classicism—figurative work either exclusively or alongside Cubist work—experienced by many artists during this period (called Neoclassicism) has been linked to the tendency to evade the realities of the war and also to the cultural dominance of a classical or Latin image of France during and immediately following the war. Cubism after 1918 can be seen as part of a wide ideological shift towards conservatism in both French society and culture. Yet, Cubism itself remained evolutionary both within the oeuvre of individual artists, such as Gris and Metzinger, and across the work of artists as different from each other as Braque, Léger and Gleizes. Cubism as a publicly debated movement became relatively unified and open to definition. Its theoretical purity made it a gauge against which such diverse tendencies as Realism or Naturalism, Dada, Surrealism and abstraction could be compared.
Architecture.
Cubism formed an important link between early-20th-century art and architecture. The historical, theoretical, and socio-political relationships between avant-garde practices in painting, sculpture and architecture had early ramifications in France, Germany, the Netherlands and Czechoslovakia. Though there are many points of intersection between Cubism and architecture, only a few direct links between them can be drawn. Most often the connections are made by reference to shared formal characteristics: faceting of form, spatial ambiguity, transparency, and multiplicity.
Architectural interest in Cubism centered on the dissolution and reconstitution of three-dimensional form, using simple geometric shapes, juxtaposed without the illusions of classical perspective. Diverse elements could be superimposed, made transparent or penetrate one another, while retaining their spatial relationships. Cubism had become an influential factor in the development of modern architecture from 1912 ("La Maison Cubiste", by Raymond Duchamp-Villon and André Mare) onwards, developing in parallel with architects such as Peter Behrens and Walter Gropius, with the simplification of building design, the use of materials appropriate to industrial production, and the increased use of glass.
Cubism was relevant to an architecture seeking a style that needed not refer to the past. Thus, what had become a revolution in both painting and sculpture was applied as part of "a profound reorientation towards a changed world". The Cubo-Futurist ideas of Filippo Tommaso Marinetti influenced attitudes in avant-garde architecture. The influential De Stijl movement embraced the aesthetic principles of Neo-plasticism developed by Piet Mondrian under the influence of Cubism in Paris. De Stijl was also linked by Gino Severini to Cubist theory through the writings of Albert Gleizes. However, the linking of basic geometric forms with inherent beauty and ease of industrial application—which had been prefigured by Marcel Duchamp from 1914—was left to the founders of Purism, Amédée Ozenfant and Charles-Édouard Jeanneret (better known as Le Corbusier,) who exhibited paintings together in Paris and published "Après le cubisme" in 1918. Le Corbusier's ambition had been to translate the properties of his own style of Cubism to architecture. Between 1918 and 1922, Le Corbusier concentrated his efforts on Purist theory and painting. In 1922, Le Corbusier and his cousin Jeanneret opened a studio in Paris at 35 rue de Sèvres. His theoretical studies soon advanced into many different architectural projects.
La Maison Cubiste (Cubist House).
At the 1912 Salon d'Automne an architectural installation was exhibited that quickly became known as "Maison Cubiste" (Cubist House), signed Raymond Duchamp-Villon and André Mare along with a group of collaborators. Metzinger and Gleizes in "Du "Cubisme"", written during the assemblage of the "Maison Cubiste", wrote about the autonomous nature of art, stressing the point that decorative considerations should not govern the spirit of art. Decorative work, to them, was the "antithesis of the picture". "The true picture" wrote Metzinger and Gleizes, "bears its "raison d'être" within itself. It can be moved from a church to a drawing-room, from a museum to a study. Essentially independent, necessarily complete, it need not immediately satisfy the mind: on the contrary, it should lead it, little by little, towards the fictitious depths in which the coordinative light resides. It does not harmonize with this or that ensemble; it harmonizes with things in general, with the universe: it is an organism...". "Mare's ensembles were accepted as frames for Cubist works because they allowed paintings and sculptures their independence", writes Christopher Green, "creating a play of contrasts, hence the involvement not only of Gleizes and Metzinger themselves, but of Marie Laurencin, the Duchamp brothers (Raymond Duchamp-Villon designed the facade) and Mare's old friends Léger and Roger La Fresnaye". "La Maison Cubiste" was a fully furnished house, with a staircase, wrought iron banisters, a living room—the "Salon Bourgeois", where paintings by Marcel Duchamp, Metzinger ("Woman with a Fan"), Gleizes, Laurencin and Léger were hung—and a bedroom. It was an example of "L'art décoratif", a home within which Cubist art could be displayed in the comfort and style of modern, bourgeois life. Spectators at the Salon d'Automne passed through the full-scale 10-by-3-meter plaster model of the ground floor of the facade, designed by Duchamp-Villon. This architectural installation was subsequently exhibited at the 1913 Armory Show, New York, Chicago and Boston, listed in the catalogue of the New York exhibit as Raymond Duchamp-Villon, number 609, and entitled "Facade architectural, plaster" ("Façade architecturale").
Cubism in other fields.
The influence of cubism extended to other artistic fields, outside painting and sculpture. In literature, the written works of Gertrude Stein employ repetition and repetitive phrases as building blocks in both passages and whole chapters. Most of Stein's important works utilize this technique, including the novel "The Making of Americans" (1906–08). Not only were they the first important patrons of Cubism, Gertrude Stein and her brother Leo were also important influences on Cubism as well. Picasso in turn was an important influence on Stein's writing.
In the field of American fiction, William Faulkner's 1930 novel "As I Lay Dying" can be read as an interaction with the cubist mode. The novel features narratives of the diverse experiences of 15 characters which, when taken together, produce a single cohesive body.
The poets generally associated with Cubism are Guillaume Apollinaire, Blaise Cendrars, Jean Cocteau, Max Jacob, André Salmon and Pierre Reverdy. As American poet Kenneth Rexroth explains, Cubism in poetry "is the conscious, deliberate dissociation and recombination of elements into a new artistic entity made self-sufficient by its rigorous architecture. This is quite different from the free association of the Surrealists and the combination of unconscious utterance and political nihilism of Dada." Nonetheless, the Cubist poets' influence on both Cubism and the later movements of Dada and Surrealism was profound; Louis Aragon, founding member of Surrealism, said that for Breton, Soupault, Éluard and himself, Reverdy was "our immediate elder, the exemplary poet." Though not as well remembered as the Cubist painters, these poets continue to influence and inspire; American poets John Ashbery and Ron Padgett have recently produced new translations of Reverdy's work. Wallace Stevens' "Thirteen Ways of Looking at a Blackbird" is also said to demonstrate how cubism's multiple perspectives can be translated into poetry.

</doc>
<doc id="37807" url="http://en.wikipedia.org/wiki?curid=37807" title="Colin Turnbull">
Colin Turnbull

Colin Macmillan Turnbull (November 23, 1924 – July 28, 1994) was a British-American anthropologist who came to public attention with the popular books "The Forest People" (on the Mbuti Pygmies of Zaire) and "The Mountain People" (on the Ik people of Uganda), and one of the first anthropologists to work in the field of ethnomusicology.
Early life.
Turnbull was born in London and educated at Westminster School and Magdalen College, Oxford, where he studied politics and philosophy. During World War II he was in the Royal Naval Volunteer Reserve after which he was awarded a two year grant in the Department of Indian Religion and Philosophy, Banaras Hindu University, India, from which he graduated with a master's degree in Indian Religion and Philosophy.
Career.
In 1951, after his graduation from Banaras, he traveled to the Belgian Congo (present-day Democratic Republic of the Congo) with Newton Beal, a schoolteacher from Ohio he met in India. Turnbull and Beal first studied the Mbuti pygmies during this time, though that was not the complete goal of the trip.
An "odd job" Turnbull picked up while in Africa at this time was working for the Hollywood producer Sam Spiegel. Spiegel hired Turnbull to assist in the construction and transportation of a boat needed for his film. This boat was the "African Queen", which was used for the feature film "The African Queen" (starring Humphrey Bogart and Katharine Hepburn; 1951). After his first trip to Africa, Turnbull traveled to Yellowknife in the northwest territories of Canada, where he worked as a geologist and gold miner for approximately a year, before he went back to school to obtain another degree.
Upon returning to Oxford in 1954, he began specializing in the anthropology of Africa. Turnbull remained in Oxford for two years before another field trip to Africa, finally focusing on the Belgian Congo (1957–58) and Uganda. After years of fieldwork, he finally achieved his anthropology doctorate from Oxford in 1964.
Turnbull became a naturalized citizen of the United States in 1965, after he moved to New York City to become curator in charge of African Ethnology at the American Museum of Natural History in 1959. He later resided in Lancaster County, Virginia, and was on staff in the Department of Sociology and Anthropology, Virginia Commonwealth University, Richmond. Other professional associations included Corresponding Membership of Royal Museum for Central Africa and fellowship in the British Royal Anthropological Institute. He first gained prominence with his book "The Forest People" (1961), an admiring study of the Mbuti. 
In 1972, having been commissioned to come up with an explanation and solution, the highly controversial "The Mountain People" was published. It concerned the Ik, a hunter/gatherer tribe who had been forced to stop moving around ancestral lands, through the seasons, because it now involved the three national borders of Uganda, Kenya and Sudan. Forced to become stationary in Uganda, and without a knowledge base and culture for doing so, they failed to thrive, even to the point of starvation and death. The book remains in print and on the reading list of University courses teaching anthropology.
Turnbull was in unique position to study and document what happens to a society and culture. His book documented the society he witnessed and described the culture of the Ik using the recollections of older Ik from the pre-stressed society. He extrapolated his observations to warn that civilization is shallow.
He later worked on a theatrical adaptation of "The Mountain People" with his friend, playwright Peter Brook.
Contributions to music.
Some of Turnbull's recordings of Mbuti music were commercially released, and his works have inspired other ethnomusicological studies, such as those of Simha Arom and Mauro Campagnoli. His most famous recording is "Music of the Rainforest Pygmies", recorded in 1961, now released on CD by Lyrichord Discs, Inc. His recording of a Zaire pygmy girls' initiation song was used on the Voyager Golden Record.
Joseph Towles.
Joseph Allen Towles was born in Senora, Virginia, on August 17, 1937. In 1957 he moved to New York City to pursue a career as an actor and writer. He met Turnbull in 1959 and they exchanged marriage vows the following year.
Towles' initiation into anthropology occurred as a volunteer in the Anthropology Department at the American Museum of Natural History with Turnbull. From 1965 to 1967, he assisted with the creation of the "Man in Africa Hall", a permanent exhibit (re-titled in 1990 as "Hall of African Peoples"). He also researched and constructed the "Slavery in the New World" subsection of the museum. In 1963, he entered Pace College to study history and anthropology, graduating in 1968. He received his Ph.D. from Makerere University in 1979.
From 1965 to 1967, Turnbull and Towles conducted fieldwork among the Ik of Northern Uganda in Africa. In the Congo in 1970, they conducted fieldwork on the Nkumbi circumcision initiation ritual for boys and the Asa myth of origin among the Mbo of the Ituri forest.
In 1979, they traveled the world studying the concept of tourism as pilgrimage. Towles next turned to biblical research and writing plays and novels. He reacted angrily to Turnbull's semi-autobiographical work "The Human Cycle" (1983), which omitted all references to their relationship. Towles' health declined slowly from that time. He died from complications of AIDS in 1988.
Turnbull arranged for Towles' research to be published posthumously. It appeared in 1993 as "Nkumbi initiation ritual and structure among the Mbo of Zaïre" and as "Asa: Myth of Origin of the Blood Brotherhood Among the Mbo of the Ituri Forest", both in "Annales" of the Royal Museum for Central Africa (Tervuren, Belgium), vol. 137.
Later years.
Late in life Turnbull took up the political cause of death row inmates. After his partner's death, Turnbull donated all his belongings to the United Negro College Fund. He donated all their research materials, most of which were the product of his career, to the College of Charleston, insisting that the collection be known under Towles' name alone.
In 1989, Turnbull moved to Bloomington, Indiana, to participate to the building of Tibetan Cultural Center with his friend Thupten Jigme Norbu, elder brother of the 14th Dalai Lama. Later Turnbull moved to Dharamsala, India where he took the monks' vow of Tibetan Buddhism, given to him by the Dalai Lama.
Controversy.
Many people found Turnbull's description of the Ik disturbing. Turnbull was explicitly describing what happens to a society that is forced to abandon its culture, and the fierce individualism and hardship that results. His graphic descriptions were placed into context by the careful interviews he did with older Ik to contrast the older society that existed prior to displacement. 
Bernd Heine exemplifies the strong reaction evoked by Turnbull's evaluation of the Ik in a scathing 1985 article in , , using information gained 20 years afer Turnbull's researches. He provided new information that appeared to discredit the portrayal of the Ik provided by Turnbull. It calls the issue of informants into question. Was Turnbull misled or just careless? Had 20 years changed the Ik to an extent that would make Heine's account less accurately comparable?
Sources.
</dl>

</doc>
<doc id="37808" url="http://en.wikipedia.org/wiki?curid=37808" title="Catalase">
Catalase

Catalase is a common enzyme found in nearly all living organisms exposed to oxygen (such as vegetables, fruit or animals). It catalyzes the decomposition of hydrogen peroxide to water and oxygen. It is a very important enzyme in protecting the cell from oxidative damage by reactive oxygen species (ROS). Likewise, catalase has one of the highest turnover numbers of all enzymes; one catalase molecule can convert approximately 5 million molecules of hydrogen peroxide to water and oxygen each second.
Catalase is a tetramer of four polypeptide chains, each over 500 amino acids long. It contains four porphyrin heme (iron) groups that allow the enzyme to react with the hydrogen peroxide. The optimum pH for human catalase is approximately 7, and has a fairly broad maximum (the rate of reaction does not change appreciably at pHs between 6.8 and 7.5). The pH optimum for other catalases varies between 4 and 11 depending on the species. The optimum temperature also varies by species.
History.
Catalase was not noticed until 1818 when Louis Jacques Thénard, who discovered H2O2 (hydrogen peroxide), suggested its breakdown is caused by an unknown substance. In 1900, Oscar Loew was the first to give it the name catalase, and found it in many plants and animals. In 1937 catalase from beef liver was crystallised by James B. Sumner and Alexander Dounce and the molecular weight was found in 1938.
In 1969, the amino acid sequence of bovine catalase was discovered. Then in 1981, the three-dimensional structure of the protein was revealed.
Action.
The reaction of catalase in the decomposition of hydrogen peroxide in living tissue:
The presence of catalase in a microbial or tissue sample can be tested by adding a volume of hydrogen peroxide and observing the reaction. The formation of bubbles, oxygen, indicates a positive result. This easy assay, which can be seen with the naked eye, without the aid of instruments, is possible because catalase has a very high specific activity, which produces a detectable response. Alternative splicing may result in different protein variants.
Molecular mechanism.
While the complete mechanism of catalase is not currently known, the reaction is believed to occur in two stages:
As hydrogen peroxide enters the active site, it interacts with the amino acids Asn147 (asparagine at position 147) and His74, causing a proton (hydrogen ion) to transfer between the oxygen atoms. The free oxygen atom coordinates, freeing the newly formed water molecule and Fe(IV)=O. Fe(IV)=O reacts with a second hydrogen peroxide molecule to reform Fe(III)-E and produce water and oxygen. The reactivity of the iron center may be improved by the presence of the phenolate ligand of Tyr357 in the fifth iron ligand, which can assist in the oxidation of the Fe(III) to Fe(IV). The efficiency of the reaction may also be improved by the interactions of His74 and Asn147 with reaction intermediates. In general, the rate of the reaction can be determined by the Michaelis-Menten equation. 
Catalase can also catalyze the oxidation, by hydrogen peroxide, of various metabolites and toxins, including formaldehyde, formic acid, phenols, acetaldehyde and alcohols. It does so according to the following reaction:
The exact mechanism of this reaction is not known.
Any heavy metal ion (such as copper cations in copper(II) sulfate) can act as a noncompetitive inhibitor of catalase. Furthermore, the poison cyanide is a competitive inhibitor of catalase at high concentrations of hydrogen peroxide.
Arsenate acts as an activator. Three-dimensional protein structures of the peroxidated catalase intermediates are available at the Protein Data Bank. This enzyme is commonly used in laboratories as a tool for learning the effect of enzymes upon reaction rates.
Cellular role.
Hydrogen peroxide is a harmful byproduct of many normal metabolic processes; to prevent damage to cells and tissues, it must be quickly converted into other, less dangerous substances. To this end, catalase is frequently used by cells to rapidly catalyze the decomposition of hydrogen peroxide into less-reactive gaseous oxygen and water molecules.
The true biological significance of catalase is not always straightforward to assess: Mice genetically engineered to lack catalase are phenotypically normal, indicating this enzyme is dispensable in animals under some conditions. A catalase deficiency may increase the likelihood of developing type 2 diabetes. Some humans have very low levels of catalase (acatalasia), yet show few ill effects. The predominant scavengers of H2O2 in normal mammalian cells are likely peroxiredoxins rather than catalase.
Human catalase works at an optimum temperature of 45 °C. In contrast, catalase isolated from the hyperthermophile archaeon "Pyrobaculum calidifontis" has a temperature optimum of 90 °C.
Catalase is usually located in a cellular, bipolar environment organelle called the peroxisome. Peroxisomes in plant cells are involved in photorespiration (the use of oxygen and production of carbon dioxide) and symbiotic nitrogen fixation (the breaking apart of diatomic nitrogen (N2) to reactive nitrogen atoms). Hydrogen peroxide is used as a potent antimicrobial agent when cells are infected with a pathogen. Catalase-positive pathogens, such as "Mycobacterium tuberculosis", "Legionella pneumophila", and "Campylobacter jejuni", make catalase to deactivate the peroxide radicals, thus allowing them to survive unharmed within the host.
Catalase contributes to ethanol metabolism in the body after ingestion of alcohol, but it only breaks down a small fraction of the alcohol in the body.
Distribution among organisms.
The large majority of known organisms use catalase in every organ, with particularly high concentrations occurring in the liver . One unique use of catalase occurs in the bombardier beetle. This beetle has two sets of chemicals ordinarily stored separately in its paired glands. The larger of the pair, the storage chamber or reservoir, contains hydroquinones and hydrogen peroxide, whereas the smaller of the pair, the reaction chamber, contains catalases and peroxidases. To activate the noxious spray, the beetle mixes the contents of the two compartments, causing oxygen to be liberated from hydrogen peroxide. The oxygen oxidizes the hydroquinones and also acts as the propellant. The oxidation reaction is very exothermic (ΔH = −202.8 kJ/mol) which rapidly heats the mixture to the boiling point.
Catalase is also universal among plants, and many fungi are also high producers of the enzyme.
Almost all aerobic microorganisms use catalase. It is also present in some anaerobic microorganisms, such as "Methanosarcina barkeri".
According to a March 2015 Scientific American Special Report on Aging article, laboratory mice at a University of Washington laboratory who produced more catalase, which is an antioxidant, lived longer. Research on the topic both supports and cautions against the benefit of antioxidants for health effects on aging.
Applications.
Catalase is used in the food industry for removing hydrogen peroxide from milk prior to cheese production. Another use is in food wrappers where it prevents food from oxidizing. Catalase is also used in the textile industry, removing hydrogen peroxide from fabrics to make sure the material is peroxide-free.
A minor use is in contact lens hygiene - a few lens-cleaning products disinfect the lens using a hydrogen peroxide solution; a solution containing catalase is then used to decompose the hydrogen peroxide before the lens is used again. Recently, catalase has also begun to be used in the aesthetics industry. Several mask treatments combine the enzyme with hydrogen peroxide on the face with the intent of increasing cellular oxygenation in the upper layers of the epidermis.
Catalase test.
The catalase test is also one of the main three tests used by microbiologists to identify species of bacteria. The presence of catalase enzyme in the test isolate is detected using hydrogen peroxide. If the bacteria possess catalase (i.e., are catalase-positive), when a small amount of bacterial isolate is added to hydrogen peroxide, bubbles of oxygen are observed.
The catalase test is done by placing a drop of hydrogen peroxide on a microscope slide. Using an applicator stick, a scientist touches the colony, and then smears a sample into the hydrogen peroxide drop.
While the catalase test alone cannot identify a particular organism, combined with other tests, such as antibiotic resistance, it can aid identification. The presence of catalase in bacterial cells depends on both the growth condition and the medium used to grow the cells.
Capillary tubes may also be used. A small amount of bacteria is collected on the end of the capillary tube (it is essential to ensure that the end is not blocked, otherwise it may present a false negative). The opposite end is then dipped into hydrogen peroxide which will draw up the liquid (through capillary action), and turned upside down, so the bacterial end is closest to the bench. A few taps of the arm should then move the hydrogen peroxide closer to the bacteria. When the hydrogen peroxide and bacteria are touching, bubbles may begin to rise, giving a positive catalase result.
Gray hair.
According to recent scientific studies, low levels of catalase may play a role in the graying process of human hair. Hydrogen peroxide is naturally produced by the body and catalase breaks it down. If catalase levels decline, hydrogen peroxide cannot be broken down as well. This allows the hydrogen peroxide to bleach the hair from the inside out. This finding is under investigation in hopes of developing cosmetic treatments for graying hair based on catalase supplements.
Interactions.
Catalase has been shown to interact with the "ABL2" and "Abl" genes.

</doc>
<doc id="37815" url="http://en.wikipedia.org/wiki?curid=37815" title="Bulgakov">
Bulgakov

Bulgakov (Russian: Булгаков) is a Russian surname. Notable people with the surname include:

</doc>
<doc id="37817" url="http://en.wikipedia.org/wiki?curid=37817" title="Möbius strip">
Möbius strip

The Möbius strip or Möbius band ( (non-rhotic) or ; ]), also Mobius or Moebius, is a surface with only one side and only one boundary. The Möbius strip has the mathematical property of being non-orientable. It can be realized as a ruled surface. It was discovered independently by the German mathematicians August Ferdinand Möbius and Johann Benedict Listing in 1858.
An example of a Möbius strip can be created by taking a paper strip and giving it a half-twist, and then joining the ends of the strip together to form a loop. However, the Möbius strip is not a surface of only one exact size and shape, such as the half-twisted paper strip depicted in the illustration. Rather, mathematicians refer to the closed Möbius band as any surface that is homeomorphic to this strip. Its boundary is a simple closed curve, i.e., homeomorphic to a circle. This allows for a very wide variety of geometric versions of the Möbius band as surfaces each having a definite size and shape. For example, any closed rectangle with length L and width W can be glued to itself (by identifying one edge with the opposite edge after a reversal of orientation) to make a Möbius band. Some of these can be smoothly modeled in Euclidean space, and others cannot.
A half-twist clockwise will give a different embedding of the Möbius strip than a half-twist counterclockwise – that is, as an embedded object in Euclidean space the Möbius strip is a chiral object with right- or left-handedness. However, the underlying topological spaces within the Möbius strip are homeomorphic in each case. There are an infinite number of topologically different embeddings of the same topological space into three-dimensional space, as the Möbius strip can also be formed by twisting the strip an odd number of times greater than one, or by knotting and twisting the strip, before joining its ends. The complete open Möbius band is an example of a topological surface that is closely related to the standard Möbius strip but that is not homeomorphic to it.
It is straightforward to find algebraic equations, the solutions of which have the topology of a Möbius strip, but in general these equations do not describe the same geometric shape that one gets from the twisted paper model described above. In particular, the twisted paper model is a developable surface, having zero Gaussian curvature. A system of differential-algebraic equations that describes models of this type was published in 2007 together with its numerical solution.
The Euler characteristic of the Möbius strip is zero.
Properties.
The Möbius strip has several curious properties. A line drawn starting from the seam down the middle will meet back at the seam but at the other side. If continued the line will meet the starting point and will be double the length of the original strip. This single continuous curve demonstrates that the Möbius strip has only one boundary.
Cutting a Möbius strip along the center line with a pair of scissors yields one long strip with two full twists in it, rather than two separate strips; the result is not a Möbius strip. This happens because the original strip only has one edge that is twice as long as the original strip. Cutting creates a second independent edge, half of which was on each side of the scissors. Cutting this new, longer, strip down the middle creates two strips wound around each other, each with two full twists.
If the strip is cut along about a third of the way in from the edge, it creates two strips: One is a thinner Möbius strip – it is the center third of the original strip, comprising 1/3 of the width and the same length as the original strip. The other is a longer but thin strip with two full twists in it – this is a neighborhood of the edge of the original strip, and it comprises 1/3 of the width and twice the length of the original strip.
Other analogous strips can be obtained by similarly joining strips with two or more half-twists in them instead of one. For example, a strip with three half-twists, when divided lengthwise, becomes a strip tied in a trefoil knot. (If this knot is unravelled, the strip is made with eight half-twists in addition to an overhand knot.) A strip with "N" half-twists, when bisected, becomes a strip with "N" + 1 full twists. Giving it extra twists and reconnecting the ends produces figures called paradromic rings.
Geometry and topology.
One way to represent the Möbius strip as a subset of three-dimensional Euclidean space is using the parametrization:
where 0 ≤ "u" < 2π and −1 ≤ "v" ≤ 1. This creates a Möbius strip of width 1 whose center circle has radius 1, lies in the "xy" plane and is centered at (0, 0, 0). The parameter "u" runs around the strip while "v" moves from one edge to the other.
In cylindrical polar coordinates ("r", "θ", "z"), an unbounded version of the Möbius strip can be represented by the equation:
Widest isometric embedding in 3-space.
If a smooth Möbius strip in 3-space is a rectangular one – that is, created from identifying two opposite sides of a geometrical rectangle with bending but not stretching the surface – then such an embedding is known to be possible if the aspect ratio of the rectangle is greater than the square root of 3. (Note that it is the shorter sides of the rectangle that are identified to obtain the Möbius strip.) For an aspect ratio less than or equal to the square root of 3, however, a smooth embedding of a rectangular Möbius strip into 3-space may be impossible.
As the aspect ratio approaches the limiting ratio of √3 from above, any such rectangular Möbius strip in 3-space seems to approach a shape that in the limit can be thought of as a strip of three equilateral triangles, folded on top of one another so that they occupy just one equilateral triangle in 3-space.
If the Möbius strip in 3-space is only once continuously differentiable (in symbols: C1), however, then the theorem of Nash-Kuiper shows that there is no lower bound.
A method of making a Möbius strip from a rectangular strip too wide to be simply twisted and joined (e.g., a rectangle only 1 unit long and 1 unit wide) is to first fold the wide direction back and forth using an even number of folds – an "accordion fold" – so that the folded strip becomes narrow enough that it can be twisted and joined, much as a single long-enough strip can be joined. With two folds, for example, a 1 × 1 strip would become a 1 × ⅓ folded strip whose cross section is in the shape of an 'N' and which would remain an 'N' after a half-twist. This folded strip, three times as long as it is wide, would be long enough to then join at the ends. This method works in principle but becomes impractical after sufficiently many folds, if paper is used. Using normal paper, this construction can be folded flat, with all the layers of the paper in a single plane. But mathematically, it is not clear whether this is possible without stretching the surface of the rectangle.
Topology.
Topologically, the Möbius strip can be defined as the square [0, 1] × [0, 1] with its top and bottom sides identified by the relation ("x", 0) ~ (1 − "x", 1) for 0 ≤ "x" ≤ 1, as in the diagram on the right.
A less used presentation of the Möbius strip is as the topological quotient of a torus. A torus can be constructed as the square [0, 1] × [0, 1] with the edges identified as (0, "y") ~ (1, "y") (glue left to right) and ("x", 0) ~ ("x", 1) (glue bottom to top). If one then also identified ("x", "y") ~ ("y", "x"), then one obtains the Möbius strip. The diagonal of the square (the points ("x", "x") where both coordinates agree) becomes the boundary of the Möbius strip, and carries an orbifold structure, which geometrically corresponds to "reflection" – geodesics (straight lines) in the Möbius strip reflect off the edge back into the strip. Notationally, this is written as T2/S2 – the 2-torus quotiented by the group action of the symmetric group on two letters (switching coordinates), and it can be thought of as the configuration space of two unordered points on the circle, possibly the same (the edge corresponds to the points being the same), with the torus corresponding to two ordered points on the circle.
The Möbius strip is a two-dimensional compact manifold (i.e. a surface) with boundary. It is a standard example of a surface which is not orientable. In fact, the Möbius strip is the epitome of the topological phenomenon of nonorientability. This is because 1) two-dimensional shapes (surfaces) are the lowest-dimensional shapes for which nonorientability is possible, and 2) the Möbius strip is the only surface that is topologically a subspace of every non-orientable surface. As a result, any surface is non-orientable if and only if it contains a Möbius band as a subspace.
The Möbius strip is also a standard example used to illustrate the mathematical concept of a fiber bundle. Specifically, it is a nontrivial bundle over the circle "S"1 with a fiber the unit interval, "I" = [0, 1]. Looking only at the edge of the Möbius strip gives a nontrivial two point (or Z2) bundle over "S"1.
Computer graphics.
A simple construction of the Möbius strip which can be used to portray it in computer graphics or modeling packages is as follows :
Open Möbius band.
The open Möbius band is formed by deleting the boundary of the standard Möbius band. It is constructed from the set "S" = { ("x", "y") ∈ R2 : 0 ≤ "x" ≤ 1 and 0 < "y" < 1 } by identifying (glueing) the points (0, "y") and (1, 1 − "y") for all 0 < "y" < 1.
It may be constructed as a surface of constant positive, negative, or zero (Gaussian) curvature. In the cases of negative and zero curvature, the Möbius band can be constructed as a (geodesically) complete surface, which means that all geodesics ("straight lines" on the surface) may be extended indefinitely in either direction.
Constant negative curvature:
Like the plane and the open cylinder, the open Möbius band admits not only a complete metric of constant curvature 0, but also a complete metric of constant negative curvature, say −1. One way to see this is to begin with the upper half plane (Poincaré) model of the hyperbolic plane ℍ, namely ℍ = { ("x", "y") ∈ ℝ2 | "y" > 0} with the Riemannian metric given by ("dx"2 + "dy"2) / "y"2. The orientation-preserving isometries of this metric are all the maps "f" : ℍ → ℍ of the form "f"("z") := ("az" + "b") / ("cz" + "d"), where "a", "b", "c", "d" are real numbers satisfying "ad" − "bc" = 1. Here "z" is a complex number with Im("z") > 0, and we have identified ℍ with {"z" ∈ ℂ | Im("z") > 0} endowed with the Riemannian metric that was mentioned. Then one orientation-reversing isometry "g" of ℍ given by "g"("z") := -conj("z"), where conj("z") denotes the complex conjugate of "z". These facts imply that the mapping "h" : ℍ → ℍ given by "h"("z") := −2⋅conj("z") is an orientation-reversing isometry of ℍ that generates an infinite cyclic group "G" of isometries. (Its square is the isometry "h"("z") := 4⋅z, which can be expressed as ("2z" + "0") / ("0z" + "1/2").) The quotient ℍ / "G" of the action of this group can easily be seen to be topologically a Möbius band. But it is also easy to verify that it is complete and noncompact, with constant negative curvature −1.
The group of isometries of this Möbius band is 1-dimensional and is isomorphic to the special orthogonal group SO(2).
(Constant) zero curvature:
This may also be constructed as a complete surface, by starting with portion of the plane R2 defined by 0 ≤ y ≤ 1 and identifying ("x", 0) with (−"x", 1) for all "x" in R (the reals). The resulting metric makes the open Möbius band into a (geodesically) complete flat surface (i.e., having Gaussian curvature equal to 0 everywhere). This is the only metric on the Möbius band, up to uniform scaling, that is both flat and complete.
The group of isometries of this Möbius band is 1-dimensional and is isomorphic to the orthogonal group SO(2).
Constant positive curvature:
A Möbius band of constant positive curvature cannot be complete, since it is known that the only complete surfaces of constant positive curvature are the sphere and the projective plane. The projective plane P2 of constant curvature +1 may be constructed as the quotient of the unit sphere "S"2 in R3 by the antipodal map "A": "S"2 → "S"2, defined by "A"("x", "y", "z") = (−"x", −"y", −"z"). The open Möbius band is homeomorphic to the once-punctured projective plane, that is, P2 with any one point removed. This may be thought of as the closest that a Möbius band of constant positive curvature can get to being a complete surface: just one point away.
The group of isometries of this Möbius band is also 1-dimensional and isomorphic to the orthogonal group O(2).
The space of unoriented lines in the plane is diffeomorphic to the open Möbius band. To see why, let "L"("θ") denote the line through the origin at an angle "θ" to the positive x-axis. For each "L"("θ") there is the family "P"("θ") of all lines in the plane that are perpendicular to "L"("θ"). Topologically, the family "P"("θ") is just a line (because each line in "P"("θ") intersects the line "L"("θ") in just one point). In this way, as "θ" increases in the range 0° ≤ "θ" < 180°, the line "L"("θ") represents a line's worth of distinct lines in the plane. But when "θ" reaches 180°, "L"(180°) is identical to "L"(0), and so the families "P"(0°) and "P"(180°) of perpendicular lines are also identical families. The line "L"(0°), however, has returned to itself as "L"(180°) "pointed in the opposite direction". Every line in the plane corresponds to exactly one line in some family "P"("θ"), for exactly one "θ", for 0° ≤ "θ" < 180°, and "P"(180°) is identical to "P"(0°) but returns pointed in the opposite direction. This ensures that the space of all lines in the plane – the union of all the "L"("θ") for 0° ≤ "θ" ≤ 180° – is an open Möbius band.
The group of bijective linear transformations GL(2, R) of the plane to itself (real 2 × 2 matrices with non-zero determinant) naturally induces bijections of the space of lines in the plane to itself, which form a group of self-homeomorphisms of the space of lines. Hence the same group forms a group of self-homeomorphisms of the Möbius band described in the previous paragraph. But there is no metric on the space of lines in the plane which is invariant under the action of this group of homeomorphisms. In this sense the space of lines in the plane has no natural metric on it.
This means that the Möbius band possesses a natural 4-dimensional Lie group of self-homeomorphisms, given by GL(2, R), but this high degree of symmetry cannot be exhibited as the group of isometries of any metric.
Möbius band with round boundary.
The edge, or boundary, of a Möbius strip is homeomorphic (topologically equivalent) to a circle. Under the usual embeddings of the strip in Euclidean space, as above, the boundary is not a true circle. However, it is possible to embed a Möbius strip in three dimensions so that the boundary is a perfect circle lying in some plane. For example, see Figures 307, 308, and 309 of "Geometry and the imagination".
A much more geometric embedding begins with a minimal Klein bottle immersed in the 3-sphere, as discovered by Blaine Lawson. We then take half of this Klein bottle to get a Möbius band embedded in the 3-sphere (the unit sphere in 4-space). The result is sometimes called the "Sudanese Möbius Band"
. Here "sudanese" is a portmanteau of the names of two topologists, Sue Goodman and Daniel Asimov. Applying stereographic projection to the Sudanese band places it in 3-dimensional space, as can be seen below – a version due to George Francis can be found .
From Lawson's minimal Klein bottle we derive an embedding of the band into the 3-sphere "S"3, regarded as a subset of C2, which is geometrically the same as R4. We map angles "η", "φ" to complex numbers "z"1, "z"2 via
Here the parameter "η" runs from 0 to "π" and "φ" runs from 0 to 2"π". Since | "z"1 |2 + | "z"2 |2 = 1, the embedded surface lies entirely in "S"3. The boundary of the strip is given by | "z"2 | = 1 (corresponding to "η" = 0, "π"), which is clearly a circle on the 3-sphere.
To obtain an embedding of the Möbius strip in R3 one maps "S"3 to R3 via a stereographic projection. The projection point can be any point on "S"3 which does not lie on the embedded Möbius strip (this rules out all the usual projection points). One possible choice is formula_7. Stereographic projections map circles to circles and will preserve the circular boundary of the strip. The result is a smooth embedding of the Möbius strip into R3 with a circular edge and no self-intersections.
The Sudanese Möbius band in the three-sphere "S"3 is geometrically a fibre bundle over a great circle, whose fibres are great semicircles. The most symmetrical image of a stereographic projection of this band into R3 is obtained by using a projection point that lies on that great circle that runs through the midpoint of each of the semicircles. Each choice of such a projection point results in an image that is congruent to any other. But because such a projection point lies on the Möbius band itself, two aspects of the image are significantly different from the case (illustrated above) where the point is not on the band: 1) the image in R3 is not the full Möbius band, but rather the band with one point removed (from its centerline); and 2) the image is unbounded – and as it gets increasingly far from the origin of R3, it increasingly approximates a plane. Yet this version of the stereographic image has a group of 4 symmetries in R3 (it is isomorphic to the Klein 4-group), as compared with the bounded version illustrated above having its group of symmetries the unique group of order 2. (If all symmetries and not just orientation-preserving isometries of R3 are allowed, the numbers of symmetries in each case doubles.)
But the most geometrically symmetrical version of all is the original Sudanese Möbius band in the three-sphere "S"3, where its full group of symmetries is isomorphic to the Lie group O(2). Having an infinite cardinality (that of the continuum), this is far larger than the symmetry group of any possible embedding of the Möbius band in R3.
Related objects.
A closely related 'strange' geometrical object is the Klein bottle. A Klein bottle can be produced by gluing two Möbius strips together along their edges; this cannot be done in ordinary three-dimensional Euclidean space without creating self-intersections.
Another closely related manifold is the real projective plane. If a circular disk is cut out of the real projective plane, what is left is a Möbius strip. Going in the other direction, if one glues a disk to a Möbius strip by identifying their boundaries, the result is the projective plane. In order to visualize this, it is helpful to deform the Möbius strip so that its boundary is an ordinary circle (see above). The real projective plane, like the Klein bottle, cannot be embedded in three-dimensions without self-intersections.
In graph theory, the Möbius ladder is a cubic graph closely related to the Möbius strip.
In 1968, Gonzalo Vélez Jahn (UCV, Caracas, Venezuela) discovered three dimensional bodies with Möbian characteristics, later described by Martin Gardner as prismatic rings that became toroidal polyhedrons.
Applications.
There have been several technical applications for the Möbius strip. Giant Möbius strips have been used as conveyor belts that last longer because the entire surface area of the belt gets the same amount of wear, and as continuous-loop recording tapes (to double the playing time). Möbius strips are common in the manufacture of fabric computer printer and typewriter ribbons, as they allow the ribbon to be twice as wide as the print head while using both halves evenly.
A Möbius resistor is an electronic circuit element that cancels its own inductive reactance. Nikola Tesla patented similar technology in 1894: "Coil for Electro Magnets" was intended for use with his system of global transmission of electricity without wires.
The Möbius strip is the configuration space of two unordered points on a circle. Consequently, in music theory, the space of all two-note chords, known as dyads, takes the shape of a Möbius strip; this and generalizations to more points is a significant application of orbifolds to music theory.
In physics/electro-technology:
In chemistry/nano-technology:

</doc>
<doc id="37824" url="http://en.wikipedia.org/wiki?curid=37824" title="SAT (disambiguation)">
SAT (disambiguation)

The SAT (formerly Scholastic Aptitude Test, Scholastic Assessment Test, and SAT Reasoning Test) is a college admissions test in the United States.
SAT or Sat may also refer to:

</doc>
<doc id="37825" url="http://en.wikipedia.org/wiki?curid=37825" title="CNF">
CNF

CNF may refer to:

</doc>
<doc id="37828" url="http://en.wikipedia.org/wiki?curid=37828" title="DNF">
DNF

DNF may refer to:

</doc>
<doc id="37830" url="http://en.wikipedia.org/wiki?curid=37830" title="Solid-fuel rocket">
Solid-fuel rocket

A solid rocket or a solid-fuel rocket is a rocket with a rocket engine that uses solid propellants (fuel/oxidizer). The earliest rockets were solid-fuel rockets powered by gunpowder; they were used in warfare by the Chinese, Indians, Mongols and Arabs, as early as the 13th century.
All rockets used some form of solid or powdered propellant up until the 20th century, when liquid-propellant rockets offered more efficient and controllable alternatives. Solid rockets are still used today in model rockets and on larger applications for their simplicity and reliability.
Since solid-fuel rockets can remain in storage for long periods, and then reliably launch on short notice, they have been frequently used in military applications such as missiles. The lower performance of solid propellants (as compared to liquids) does not favor their use as primary propulsion in modern medium-to-large launch vehicles customarily used to orbit commercial satellites and launch major space probes. Solids are, however, frequently used as strap-on boosters to increase payload capacity or as spin-stabilized add-on upper stages when higher-than-normal velocities are required. Solid rockets "are" used as light launch vehicles for low Earth orbit (LEO) payloads under 2 tons or escape payloads up to 1100 lb.
Basic concepts.
A simple solid rocket motor consists of a casing, nozzle, grain (propellant charge), and igniter.
The grain behaves like a solid mass, burning in a predictable fashion and producing exhaust gases. The nozzle dimensions are calculated to maintain a design chamber pressure, while producing thrust from the exhaust gases.
Once ignited, a simple solid rocket motor cannot be shut off, because it contains all the ingredients necessary for combustion within the chamber in which they are burned. More advanced solid rocket motors can not only be throttled but also be extinguished and then re-ignited by controlling the nozzle geometry or through the use of vent ports. Also, pulsed rocket motors that burn in segments and that can be ignited upon command are available.
Modern designs may also include a steerable nozzle for guidance, avionics, recovery hardware (parachutes), self-destruct mechanisms, APUs, controllable tactical motors, controllable divert and attitude control motors, and thermal management materials.
Design.
Design begins with the total impulse required, which determines the fuel/oxidizer mass. Grain geometry and chemistry are then chosen to satisfy the required motor characteristics.
The following are chosen or solved simultaneously. The results are exact dimensions for grain, nozzle, and case geometries:
The grain may or may not be bonded to the casing. Case-bonded motors are more difficult to design, since the deformation of the case and the grain under flight must be compatible.
Common modes of failure in solid rocket motors include fracture of the grain, failure of case bonding, and air pockets in the grain. All of these produce an instantaneous increase in burn surface area and a corresponding increase in exhaust gas and pressure, which may rupture the casing.
Another failure mode is casing seal design. Seals are required in casings that have to be opened to load the grain. Once a seal fails, hot gas will erode the escape path and result in failure. This was the cause of the Space Shuttle "Challenger" disaster.
Grain geometry.
Solid rocket fuel deflagrates from the surface of exposed propellant in the combustion chamber. In this fashion, the geometry of the propellant inside the rocket motor plays an important role in the overall motor performance. As the surface of the propellant burns, the shape evolves (a subject of study in internal ballistics), most often changing the propellant surface area exposed to the combustion gases. The mass flow rate (kg/s) [and, therefore, pressure] of combustion gases generated is a function of the instantaneous surface area formula_1, (m2), and linear burn rate formula_2 (m/s):
formula_3
Several geometric configurations are often used depending on the application and desired thrust curve:
Casing.
The casing may be constructed from a range of materials. Cardboard is used for small black powder model motors, whereas aluminum is used for larger composite-fuel hobby motors. Steel is used for the space shuttle boosters. Filament wound graphite epoxy casings are used for high-performance motors.
The casing must be designed to withstand the pressure and resulting stresses of the rocket motor, possibly at elevated temperature. For design, the casing is considered a pressure vessel.
To protect the casing from corrosive hot gases, a sacrificial thermal liner on the inside of the casing is often implemented, which ablates to prolong the life of the motor casing.
Nozzle.
A convergent-divergent design accelerates the exhaust gas out of the nozzle to produce thrust. The nozzle must be constructed from a material that can withstand the heat of the combustion gas flow. Often, heat-resistant carbon-based materials are used, such as amorphous graphite or carbon-carbon.
Some designs include directional control of the exhaust. This can be accomplished by gimballing the nozzle, as in the Space Shuttle SRBs, by the use of jet vanes in the exhaust similar to those used in the V-2 rocket, or by liquid injection thrust vectoring (LITV).
An early Minuteman first stage used a single motor with four gimballed nozzles to provide pitch, yaw, and roll control.
LITV consists of injecting a liquid into the exhaust stream after the nozzle throat. The liquid then vaporizes, and in most cases chemically reacts, adding mass flow to one side of the exhaust stream and thus providing a control moment. For example, the Titan IIIC solid boosters injected nitrogen tetroxide for LITV; the tanks can be seen on the sides of the rocket between the main center stage and the boosters.
Performance.
A typical, well-designed ammonium perchlorate composite propellant (APCP) first-stage motor may have a vacuum specific impulse (Isp) as high as 285.6 seconds (Titan IVB SRMU). This compares to 339.3 s for kerosene/liquid oxygen (RD-180) and 452.3 s for hydrogen/oxygen (Block II SSME) bipropellant engines. Upper stage specific impulses are somewhat greater: as much as 303.8 s for APCP (Orbus 6E), 359 s for kerosene/oxygen (RD-0124) and 465.5 s for hydrogen/oxygen (RL10B-2). Propellant fractions are usually somewhat higher for (non-segmented) solid propellant first stages than for upper stages. The 117,000 lb Castor 120 first stage has a propellant mass fraction of 92.23% while the 31,000 lb Castor 30 upper stage recently developed for Orbital Science's Taurus II COTS (International Space Station resupply) launch vehicle has a 91.3% propellant fraction with 2.9% graphite epoxy motor casing, 2.4% nozzle, igniter and thrust vector actuator, and 3.4% non-motor hardware including such things as payload mount, interstage adapter, cable raceway, instrumentation, etc. Castor 120 and Castor 30 are 93 and in diameter, respectively, and serve as stages on the Athena IC and IIC commercial launch vehicles. A four-stage Athena II using Castor 120s as both first and second stages became the first "commercially developed" launch vehicle to launch a lunar probe ("Lunar Prospector") in 1998.
Solid rockets can provide high thrust for relatively low cost. For this reason, solids have been used as initial stages in rockets (the classic example being the Space Shuttle), while reserving high specific impulse engines, especially less massive hydrogen-fueled engines for higher stages. In addition, solid rockets have a long history as the final boost stage for satellites due to their simplicity, reliability, compactness and reasonably high mass fraction. A spin-stabilized solid rocket motor is sometimes added when extra velocity is required, such as for a mission to a comet or the outer solar system, because a spinner does not require a guidance system (on the newly added stage). Thiokol's extensive family of mostly titanium-cased "Star" space motors has been widely used, especially on Delta launch vehicles and as spin-stabilized upper stages to launch satellites from the cargo bay of the Space Shuttle. "Star" motors have propellant fractions as high as 94.6% but add-on structures and equipment reduce the operating mass fraction by 2% or more.
Higher performing solid rocket propellants are used in large strategic missiles (as opposed to commercial launch vehicles). HMX, C4H8N4(NO2)4, a nitramine with greater energy than ammonium perchlorate, was used in the propellant of the Peacekeeper ICBM and is the main ingredient in NEPE-75 propellant used in the Trident II D-5 Fleet Ballistic Missile. It is because of explosive hazard that the higher energy military solid propellants containing HMX are not used in commercial launch vehicles except when the LV is an adapted ballistic missile already containing HMX propellant (Minotaur IV and V based on the retired Peacekeeper ICBMs). The Naval Air Weapons Station at China Lake, CA developed a new compound, C6H6N6(NO2)6, called simply CL-20 (China Lake compound #20). Compared to HMX, CL-20 has 14% more energy per mass, 20% more energy per volume, and a higher oxygen-to-fuel ratio. One of the motivations for development of these very high energy density military solid propellants is to achieve mid-course exo-atmospheric ABM capability from missiles small enough to fit in existing ship-based below-deck vertical launch tubes and air-mobile truck-mounted launch tubes. CL-20 propellant compliant with Congress' 2004 insensitive munitions (IM) law has been demonstrated and may, as its cost comes down, be suitable for use in commercial launch vehicles, with a very significant increase in performance compared with the currently favored APCP solid propellants. With a specific impulse of 309 s already demonstrated by Peacekeeper's second stage using HMX propellant, the higher energy of CL-20 propellant can be expected to increase specific impulse to around 320 s in similar ICBM or launch vehicle upper stage applications, without the explosive hazard of HMX.
An attractive attribute for military use is the ability for solid rocket propellant to remain loaded in the rocket for long durations and then reliably launched at a moment's notice.
Propellant families.
Black powder (gunpowder) propellants.
Black powder (gunpowder) is composed of charcoal (fuel), potassium nitrate (oxidizer), and sulfur (fuel). It is one of the oldest pyrotechnic compositions with application to rocketry. In modern times, black powder finds use in low-power model rockets (such as Estes and Quest rockets), as it is cheap and fairly easy to produce. The fuel grain is typically a mixture of pressed fine powder (into a solid, hard slug), with a burn rate that is highly dependent upon exact composition and operating conditions. The performance or specific impulse of black powder is low, around 80 seconds. The grain is sensitive to fracture and, therefore, catastrophic failure. Black powder does not typically find use in motors above 40 N.
Zinc–sulfur (ZS) propellants.
Composed of powdered zinc metal and powdered sulfur (oxidizer), ZS or "micrograin" is another pressed propellant that does not find any practical application outside specialized amateur rocketry circles due to its poor performance (as most ZS burns outside the combustion chamber) and incredibly fast linear burn rates on the order of 2 m/s. ZS is most often employed as a novelty propellant as the rocket accelerates extremely quickly leaving a spectacular large orange fireball behind it.
"Candy" propellants.
In general, candy propellants are an oxidizer (typically potassium nitrate) and a sugar fuel (typically dextrose, sorbitol, or sucrose) that are cast into shape by gently melting the propellant constituents together and pouring or packing the amorphous colloid into a mold. Candy propellants generate a low-medium specific impulse of roughly 130 s and, thus, are used primarily by amateur and experimental rocketeers.
Double-base (DB) propellants.
DB propellants are composed of two monopropellant fuel components where one typically acts as a high-energy (yet unstable) monopropellant and the other acts as a lower-energy stabilizing (and gelling) monopropellant. In typical circumstances, nitroglycerin is dissolved in a nitrocellulose gel and solidified with additives. DB propellants are implemented in applications where minimal smoke is required yet medium-high performance (Isp of roughly 235 s) is required. The addition of metal fuels (such as aluminum) can increase the performance (around 250 s), though metal oxide nucleation in the exhaust can turn the smoke opaque.
Composite propellants.
A powdered oxidizer and powdered metal fuel are intimately mixed and immobilized with a rubbery binder (that also acts as a fuel). Composite propellants are often either ammonium nitrate-based (ANCP) or ammonium perchlorate-based (APCP). Ammonium nitrate composite propellant often uses magnesium and/or aluminum as fuel and delivers medium performance (Isp of about 210 s) whereas Ammonium Perchlorate Composite Propellant often uses aluminum fuel and delivers high performance (vacuum Isp up to 296 s with a single piece nozzle or 304 s with a high area ratio telescoping nozzle). Composite propellants are cast, and retain their shape after the rubber binder, such as Hydroxyl-terminated polybutadiene (HTPB), cross-links (solidifies) with the aid of a curative additive. Because of its high performance, moderate ease of manufacturing, and moderate cost, APCP finds widespread use in space rockets, military rockets, hobby and amateur rockets, whereas cheaper and less efficient ANCP finds use in amateur rocketry and gas generators. Ammonium dinitramide, NH4N(NO2)2, is being considered as a 1-to-1 chlorine-free substitute for ammonium perchlorate in composite propellants. Unlike ammonium nitrate, ADN can be substituted for AP without a loss in motor performance.
In 2009, a group succeeded in creating a propellant of water and nanoaluminum (ALICE).
The Constellation Program was to use a mix of aluminum, ammonium perchlorate, a polymer of polybutadiene and acrylonitrile, epoxy and iron oxide.
High-energy composite (HEC) propellants.
Typical HEC propellants start with a standard composite propellant mixture (such as APCP) and add a high-energy explosive to the mix. This extra component usually is in the form of small crystals of RDX or HMX, both of which have higher energy than ammonium perchlorate. Despite a modest increase in specific impulse, implementation is limited due to the increased hazards of the high-explosive additives.
Composite modified double base propellants.
Composite modified double base propellants start with a nitrocellulose/nitroglycerin double base propellant as a binder and add solids (typically ammonium perchlorate and powdered aluminum) normally used in composite propellants. The ammonium perchlorate makes up the oxygen deficit introduced by using nitrocellulose, improving the overall specific impulse. The aluminum also improves specific impulse as well as combustion stability. High performing propellants such as NEPE-75 used in Trident II D-5, replace most of the AP with HMX, further increasing specific impulse. The mixing of composite and double base propellant ingredients has become so common as to blur the functional definition of double base propellants.
Minimum-signature ("smokeless") propellants.
One of the most active areas of solid propellant research is the development of high-energy, minimum-signature propellant using CL-20 (China Lake compound #20), C6H6N6(NO2)6, which has 14% higher energy per mass and 20% higher energy density than HMX. The new propellant has been successfully developed and tested in tactical rocket motors. The propellant is non-polluting: acid-free, solid particulates-free, and lead-free. It is also smokeless and has only a faint shock diamond pattern that is visible in the otherwise transparent exhaust. Without the bright flame and dense smoke trail produced by the burning of aluminized propellants, these smokeless propellants all but eliminate the risk of giving away the positions from which the missiles are fired. The new CL-20 propellant is shock-insensitive (hazard class 1.3) as opposed to current HMX smokeless propellants which are highly detonable (hazard class 1.1). CL-20 is considered a major breakthrough in solid rocket propellant technology but has yet to see widespread use because costs remain high.
Electric Solid Propellants.
Electric Solid Propellants (ESPs) are a family of high performance plastisol solid propellants that have the unique property of being ignited and throttled by the application of electric current. Unlike conventional rocket motor propellants that are difficult to control and extinguish, ESPs can be ignited reliably at precise intervals and durations. Moreover, the technology is attractive because it requires no moving parts and the propellant is insensitive to flames or electrical sparks. 
Hobby and amateur rocketry.
Solid propellant rocket motors can be bought for use in model rocketry; they are normally small cylinders of black powder fuel with an integral nozzle and sometimes a small charge that is set off when the propellant is exhausted after a time delay. This charge can be used to trigger a camera, or deploy a parachute. Without this charge and delay, the motor may ignite a second stage (black powder only).
In mid- and high-power rocketry, commercially made APCP motors are widely used. They can be designed as either single-use or reloadables. These motors are available in impulse ranges from "D" to "O", from several manufacturers. They are manufactured in standardized diameters, and varying lengths depending on required impulse. Standard motor diameters are 13, 18, 24, 29, 38, 54, 75, 98, and 150 millimeters. Different propellant formulations are available to produce different thrust profiles, as well as "special effects" such as colored flames, smoke trails, or large quantities of sparks (produced by adding titanium sponge to the mix).
Designing solid rocket motors is particularly interesting to amateur rocketry enthusiasts. The design of a successful solid-fuel motor requires application of continuum mechanics, combustion chemistry, materials science, fluid dynamics (including compressible flow), heat transfer, geometry (particle spectrum packing), and machining. The vast majority of amateur-built rocket motors utilize a composite propellant, most commonly APCP and candy rocket propellant.
History.
Solid rockets were invented by the Chinese, the earliest versions were recorded in the 13th century.
Hyder Ali, king of Mysore, developed war rockets with an important change: the use of metal cylinders to contain the combustion powder.
Castable composite solid rocket motors were invented by John Whiteside "Jack" Parsons at Caltech in 1942 when he replaced double base propellant with roofing asphalt and potassium perchlorate. This made possible slow-burning rocket motors of adequate size and with sufficient shelf-life for jet-assisted take off applications. Charles Bartley, employed at JPL (Caltech), substituted curable synthetic rubber for the gooey asphalt, creating a flexible but geometrically stable load-bearing propellant grain that bonded securely to the motor casing. This made possible much larger solid rocket motors. Atlantic Research Corporation significantly boosted composite propellant Isp in 1954 by increasing the amount of powdered aluminum in the propellant to as much as 20%.
The largest solid rocket motors ever built were Aerojet's three 260 in monolithic solid motors cast in Florida. Motors 260 SL-1 and SL-2 were 261 in in diameter, 80 ft long, weighed 1,858,300 lb and had a maximum thrust of 3.5 e6lbf. Burn duration was two minutes. The nozzle throat was large enough to walk through standing up. The motor was capable of serving as a 1-to-1 replacement for the 8-engine Saturn I liquid-propellant first stage but was never used as such. Motor 260 SL-3 was of similar length and weight but had a maximum thrust of 5.4 e6lbf thrust and a shorter duration.
Usage.
Sounding rockets.
Almost all sounding rockets use solid motors.
Missiles.
Due to reliability, ease of storage and handling, solid rockets are used on a number of missiles and ICBMs.
Orbital rockets.
Solid rockets are suitable for launching small payloads to orbital velocities, especially if three or more stages are used. Many of these are based on repurposed ICBMs.
Larger liquid-fueled orbital rockets often use solid rocket boosters to gain enough initial thrust to launch the fully fueled rocket.
Solid fuel is also used for some upper stages, particularly the Star 37 (sometimes referred to as the "Burner" upper stage) and the Star 48 (sometimes referred to as the "Payload Assist Module", or PAM), both manufactured originally by Thiokol, and today by Orbital ATK. They are used to lift large payloads to intended orbits (such as the Global Positioning System satellites), or smaller payloads to interplanetary—or even interstellar—trajectories. Another solid-fuel upper stage, used by the Space Shuttle and the Titan IV, was the Boeing-manufactured Inertial Upper Stage (IUS).
Some rockets, like the Antares (manufactured by Orbital ATK), have mandatory solid-fuel upper stages. The Antares rocket uses the Aerojet Rocketdyne-manufactured Castor 30 as an upper stage.

</doc>
<doc id="37831" url="http://en.wikipedia.org/wiki?curid=37831" title="Hybrid rocket">
Hybrid rocket

A hybrid rocket is a rocket with a rocket motor which uses rocket propellants in two different phases. - one solid and the other either gas or liquid. The hybrid rocket concept can be traced back at least 75 years.
Hybrid rockets exhibit advantages over both liquid rockets and solid rockets especially in terms of simplicity, safety, and cost. Because it is nearly impossible for the fuel and oxidizer to be mixed intimately (being different states of matter), hybrid rockets tend to fail more benignly than liquids or solids. Like liquid rocket motors, but unlike solid rocket motors, hybrid rocket motors can be shut down easily and the thrust can be controlled with a simple throttle. The theoretical specific impulse(formula_1) performance of hybrids is generally higher than solid motors, and roughly equivalent to hydrocarbon-based liquid motors. formula_1 as high as 400s has been measured in a hybrid rocket using metalized fuels. Hybrid systems are more complex than solid ones, but the significant hazards of manufacturing, shipping and handling solid rocket motors offset the system simplicity advantages.
Basic concepts.
In its simplest form a hybrid rocket consists of a pressure vessel (tank) containing the liquid propellant, the combustion chamber containing the solid propellant, and a valve isolating the two. When thrust is desired, a suitable ignition source is introduced in the combustion chamber and the valve is opened. The liquid propellant (or gas) flows into the combustion chamber where it is vaporized and then reacted with the solid propellant. Combustion occurs in a boundary layer diffusion flame adjacent to the surface of the solid propellant.
Generally the liquid propellant is the oxidizer and the solid propellant is the fuel because solid oxidizers are problematic and lower performing than liquid oxidizers. Furthermore, using a solid fuel such as Hydroxyl-terminated polybutadiene (HTPB) or paraffin wax allows for the incorporation of high-energy fuel additives such as aluminium, lithium, or metal hydrides.
Common oxidizers include gaseous or liquid oxygen or nitrous oxide.
Common fuels include polymers such as polyethylene, cross-linked rubber such as HTPB or liquefying fuels such as paraffin wax.
Properties.
Hybrid rocket motors exhibit some obvious as well as some subtle advantages over liquid-fuel rockets and solid-fuel rockets. A brief summary of some of these is given below:
Disadvantages of hybrid rockets.
Hybrid rockets also exhibit some disadvantages when compared with liquid and solid rockets. These include:
For a well-designed hybrid, O/F shift has a very small impact on performance because formula_1 is insensitive to O/F shift near the peak.
In general, much less development work has been performed with hybrids than liquids or solids and it is likely that some of these disadvantages could be rectified through further investment in research and development.
One problem in designing large hybrid orbital rockets is that turbopumps become necessary to achieve high flow rates and pressurization of the oxidizer. This turbopump must be powered by something. In a traditional liquid-propellant rocket, the turbopump uses the same fuel and oxidizer as the rocket, since they are both liquid and can be fed to the pre-burner. But in a hybrid, the fuel is solid and cannot be fed to a turbopump's engine. Some hybrids use an oxidizer that can also be used as a monopropellant, such as nitromethane or hydrogen peroxide, and so a turbopump can run on it alone. But nitromethane and hydrogen peroxide are significantly less efficient than liquid oxygen, which cannot be used alone to run a turbopump. Another fuel would be needed, requiring its own tank and decreasing rocket performance.
Hybrid safety.
Generally, well designed and carefully constructed hybrids are very safe. The primary hazards associated with hybrids are:
Because the fuel in a hybrid does not contain an oxidizer, it will not combust explosively on its own. For this reason, hybrids are classified as having no TNT equivalent explosive power. In contrast, solid rockets often have TNT equivalencies similar in magnitude to the mass of the propellant grain. Liquid-fuel rockets typically have TNT equivalencies calculated based on the amount of fuel and oxidizer which could realistically intimately combine before igniting explosively; this is often taken to be 10–20% of the total propellant mass. For hybrids, even filling the combustion chamber with oxidizer prior to ignition will not generally create an explosion with the solid fuel, the explosive equivalence is often quoted as 0%.
Operational hybrids.
In 1998 SpaceDev acquired all of the intellectual property, designs, and test results generated by over 200 hybrid rocket motor firings by the American Rocket Company over its eight-year life. SpaceShipOne, the first private manned spacecraft, was powered by SpaceDev's hybrid rocket motor burning HTPB with nitrous oxide. However, nitrous oxide was the prime substance responsible for the explosion that killed three in the development of the successor of SpaceShipOne at Scaled Composites in 2007. The Virgin Galactic SpaceShipTwo follow-on commercial suborbital spaceplane uses a scaled-up hybrid motor.
SpaceDev was developing the SpaceDev Streaker, an expendable small launch vehicle, and SpaceDev Dream Chaser, capable of both suborbital and orbital human space flight. Both Streaker and Dream Chaser use hybrid rocket motors that burn nitrous oxide and the synthetic rubber HTPB. SpaceDev was acquired by Sierra Nevada Corporation in 2009, becoming its Space Systems division, which continues to develop Dream Chaser for NASA's Commercial Crew Development contract. Sierra Nevada also developed RocketMotorTwo, the hybrid engine for SpaceShipTwo. On October 31, 2014 SpaceShipTwo was lost, initial speculation had suggested that its hybrid engine had in fact exploded and killed one test pilot and seriously injured the other. However investigation data now indicates an early deployment of the SpaceShip-Two feather system was the cause for aerodynamic breakup of the vehicle. sytemsystem
U.S. Rockets manufactures and deploys hybrids using self-pressurizing nitrous oxide N2O and HTPB as well as HTP and HTPB. The High Test Hydrogen Peroxide H2O2 86% and Hydroxyl-terminated polybutadiene (HTPB) and aluminum hybrids developed by U.S. Rockets produce a sea level delivered specific impulse (Isp) of 240, well above the typical 180 of N2O-HTPB hybrids. In addition to that, they are self-starting, restartable, have considerably lower combustion instability making them suitable for fragile or manned missions such as Bloodhound SSC, SpaceShip Two or SpaceShip Three. The company has successfully tested and deployed both pressure fed and pump fed versions of the latter HTP-HTPB style. Deliverables to date have ranged from 6 inch to 18 inch diameter, and development units up to 54 inch diameter. The vendor claims scalability to over 5 meters diameter with regression rates approaching solids, according to literature distributed at the November 2013 Defense Advanced Research Projects Agency meeting for XS-1.
Organizations working on hybrids.
Space Propulsion Group was founded in 1999 by Dr. Arif Karabeyoglu, Prof. Brian Cantwell and others from Stanford University to develop high regression-rate liquefying hybrid rocket fuels. They have successfully fired motors as large as 12.5 in. diameter which produce 13,000 lbf. using the technology and are currently developing a 24 in. diameter, 25,000 lbf. motor to be initially fired in 2010. Stanford University is the institution where liquid-layer combustion theory for hybrid rockets was developed. The SPaSE group at Stanford is currently working with NASA Ames Research Center developing the Peregrine Sounding rocket which will be capable of 100 km altitude. Engineering challenges include various types of combustion instabilities.
Orbital Technologies Corporation (Orbitec) has been involved in some US government-funded research on hybrid rockets including the "Vortex Hybrid" concept.
Environmental Aerospace Corporation (eAc) was incorporated in 1994 to develop hybrid rocket propulsion systems. It was included in the design competition for the SpaceShipOne motor but lost the contract to SpaceDev.
Rocket Lab sells hybrid sounding rockets and related technology.
The Reaction Research Society (RRS), although known primarily for their work with liquid rocket propulsion, has a long history of research and development with hybrid rocket propulsion.
Copenhagen Suborbitals, a Danish rocket group, has designed and test-fired several hybrids using N2O at first and currently LOX. Their fuel is epoxy, paraffin wax, or polyurethane. The group eventually moved away from hybrids because of thrust instabilities, and now uses a motor similar to that of the V-2 rocket.
Several universities have recently experimented with hybrid rockets. Brigham Young University (BYU), the University of Utah, and Utah State University launched a student-designed rocket called Unity IV in 1995 which burned the solid fuel hydroxyl-terminated polybutadiene (HTPB) with an oxidizer of gaseous oxygen, and in 2003 launched a larger version which burned HTPB with nitrous oxide.
The WARR student-team at the Technical University of Munich has been developing hybrid engines and rockets since the early 1970s. Using acids, oxygen or nitrous oxide in combination with polyethylene or HTPB. The development includes test stand engines as well as airborne versions, like the first German hybrid rocket Barbarella.
University of Brasilia's Hybrid Team has extensive research in paraffin wax/nitrous oxide hybrids having already made more than 50 tests fires. Hybrid Team is currently working liquefied propellant, numeric optimization and rocket design
In India, Birla Institute of Technology, Mesra Space engineering and rocketry department has been working on Hybrid Projects with various fuels and oxidizers.
Many other universities, such as Embry-Riddle Aeronautical University, Purdue University, the University of Michigan at Ann Arbor, the University of Arkansas at Little Rock, Hendrix College, the University of Illinois, Portland State University, and Texas A&M University have hybrid motor test stands that allow for student research with hybrid rockets. Boston University's student-run "Rocket Propulsion Group", which in the past has launched only solid motor rockets, is attempting to design and build a single-stage hybrid sounding rocket to launch into sub-orbital space by July 2015.
Florida Institute of Technology has successfully tested and evaluated hybrid technologies with their Panther Project.
A United Kingdom-based team (laffin-gas) is using four N2O hybrid rockets in a drag-racing style car. Each rocket has an outer diameter of 150mm and is 1.4m long. They use a fuel grain of high-density wound paper soaked in cooking oil. The N2O supply is provided by Nitrogen-pressurised piston accumulators which provide a higher rate of delivery than N2O gas alone and also provide damping of any reverse shock.
Also in the United Kingdom the Bloodhound SSC team have The Falcon Project led by Daniel Jubb deploying a fully developed hybrid rocket using HTP and HTPB.
There are a number of hybrid rocket motor systems available for amateur/hobbyist use in high-powered model rocketry. These include the popular HyperTek systems and a number of 'Urbanski-Colburn Valved' (U/C) systems such as RATTWorks, HyperTek, West Coast Hybrids, Contrail Rockets, and Propulsion Polymers. 
All of these systems use nitrous oxide as the oxidizer and a plastic fuel (such as Polyvinyl chloride(PVC) or Polypropylene) or a polymer-based fuel such as HTPB. This reduces the cost per flight compared to solid rocket motors, although there is generally more 'GSE' (ground support equipment) required with hybrids.
In Italy one of the leading centers for research in hybrid propellants rockets is CISAS (Center of Studies and Activities for Space) "G. Colombo", University of Padua. The activities cover all stages of the development: from theoretical analysis of the combustion process to numerical simulation using CFD codes, and then by conducting ground tests of small scale and large-scale rockets (up to 20 kN, N2O-Paraffin wax based motors). One of these engines flew successfully in 2009.
In Taiwan, hybrid rocket system developments began in 2009 through R&D projects of NSPO with two university teams. Both teams employed nitrous oxide/HTPB propellant system with different improvement schemes. One team (NCKU) added 50 percent of paraffin in the solid grain for boosting the regression rates. The other team (ARRC/NCTU) incorporated innovative mixing enhancement devices to push the overall combustion efficiency towards the theoretical value. This team takes full advantage of high-fidelity simulations and experimental works for very cost-effective developments. Several hybrid rockets have been successfully launched so far, reaching altitudes of 10~20 km. Their plans include attempting 100~200 km altitude launch to test nanosatellites by the end of 2014, and developing orbital launch capabilities for nanosatellites in the long run. A sub-scale N2O/PE Dual-Vortical-Flow (DVF) hybrid engine hot-fire test in 2014 has delivered an averaged sea-level Isp of 280 sec, which indicates that the system has reached around 97% combustion efficiency.
History.
In 1953 Pacific Rocket Society (est. 1943) was developing the XDF-23, a 4" x 72" hybrid rocket, designed by Jim Nuding, using LOX and rubber polyall called "Thiokol". They had already tried other fuels in prior iterations including cotton, paraffin wax and wood. The XDF name itself comes from eXperimental Douglas Fir from one of the first units.
Korey Kline of Environmental Aeroscience Corporation (eAc) first fired a gaseous oxygen and rubber hybrid in 1982 at Lucerne Dry Lake, CA, after discussions on the technology with Bill Wood, formerly with Westinghouse. The first SpaceShipOne hybrid tests were successfully conducted by Kline and eAc at Mojave, CA.
American Rocket Company fired the first very large hybrids and tailored N2O and HTPB hybrids to government uses with limited adoption due to combustion instability and low Isp.
In popular culture.
An October 26, 2005 episode of the Television show "MythBusters" entitled "Confederate Rocket" featured a hybrid rocket motor using liquid nitrous oxide and paraffin wax. The myth purported that during the American Civil War, the Confederate Army was able to construct a rocket of this type. The myth was revisited in a later episode entitled "Salami Rocket", using hollowed out dry salami as the solid fuel.
In the February 18, 2007 episode of Top Gear, a Reliant Robin was used by Richard Hammond and James May in an attempt to modify a normal K-reg Robin into a reusable space shuttle. Steve Holland, a professional radio-controlled aircraft pilot, helped Hammond to work out how to land a Robin safely. The craft was built by Senior members of the United Kingdom Rocketry Association (UKRA) and achieved a successful launch, flew for several seconds into the air and managed to successfully jettison the solid-fuel rocket boosters on time. This was the largest rocket launched by a non-government organisation in Europe. It used 6 x 40960 NS O Contrail Rockets motors giving a maximum thrust of 8 metric tons. However, the car failed to separate from the large external fuel tank due to faulty explosive bolts between the Robin and the external tank and the Robin subsequently crashed into the ground and "seemed" to have exploded soon after. In fact this explosion was added for dramatic effect as neither Reliant Robins nor hybrid rocket motors explode in the way depicted.

</doc>
<doc id="37832" url="http://en.wikipedia.org/wiki?curid=37832" title="Monopropellant rocket">
Monopropellant rocket

A monopropellant rocket (or "monoprop rocket") is a rocket that uses a single chemical as its propellant.
Chemical-reaction monopropellant rockets.
For monopropellant rockets that depend on a chemical reaction, the power for the propulsive reaction and resultant thrust is provided by the chemical itself. That is, the energy needed to propel the spacecraft is contained within the chemical bonds of the chemical molecules involved in the reaction.
The most commonly used monopropellant is hydrazine (N2H4), a chemical which is a strong reducing agent. The most common catalyst is granular alumina coated with iridium (e.g. S-405 or KC 12 GA). There is no igniter with hydrazine. Shell 405 is a spontaneous catalyst, that is, hydrazine decomposes on contact with the catalyst. The decomposition is highly exothermic and produces an 1800 °F (1000 °C) gas that is a mixture of nitrogen, hydrogen and ammonia.
Another monopropellant is hydrogen peroxide, which, when purified to 90% or higher concentration, is self-decomposing at high temperatures or when a catalyst is present.
Most chemical-reaction monopropellant rocket systems consist of a fuel tank, usually a titanium or aluminium sphere, with an ethylene-propylene rubber container or a surface tension propellant management device filled with the fuel. The tank is then pressurized with helium or nitrogen, which pushes the fuel out to the motors. A pipe leads from the tank to a poppet valve, and then to the decomposition chamber of the rocket motor. Typically, a satellite will have not just one motor, but two to twelve, each with its own valve.
The attitude control rocket motors for satellites and space probes are often very small, 25mm (1 inch) or so in diameter, and mounted in groups that point in four directions (within a plane).
The rocket is fired when the computer sends direct current through a small electromagnet that opens the poppet valve. The firing is often very brief, a few thousandths of a second, and — if operated in air — would sound like a pebble thrown against a metal trash can; if on for long, it would make a piercing hiss.
Chemical-reaction monopropellants are not as efficient as some other propulsion technologies. Engineers choose monopropellant systems when the need for simplicity and reliability outweigh the need for high delivered impulse. If the propulsion system must produce large amounts of thrust, or have a high specific impulse, as on the main motor of an interplanetary spacecraft, other technologies are used.
Solar-thermal monopropellant thrusters.
A concept to provide low Earth orbit (LEO) propellant depots that could be used as way-stations for other spacecraft to stop and refuel on the way to beyond-LEO missions has proposed that waste gaseous hydrogen—an inevitable byproduct of long-term liquid hydrogen storage in the radiative heat environment of space—would be usable as a monopropellant in a solar-thermal propulsion system. The waste hydrogen would be productively utilized for both orbital stationkeeping and attitude control, as well as providing limited propellant and thrust to use for orbital maneuvers to better rendezvous with other spacecraft that would be inbound to receive fuel from the depot.
Solar-thermal monoprop thrusters are also integral to the design of a next-generation cryogenic upper stage rocket proposed by U.S. company United Launch Alliance (ULA). The Advanced Common Evolved Stage (ACES) is intended as a lower-cost, more-capable and more-flexible upper stage that would supplement, and perhaps replace, the existing ULA Centaur and ULA Delta Cryogenic Second Stage (DCSS) upper stage vehicles. The ACES Integrated Vehicle Fluids option eliminates all hydrazine and helium from the space vehicle—normally used for attitude control and station keeping—and depends instead on solar-thermal monoprop thrusters using waste hydrogen.
New Developments.
NASA is developing a new monopropellant propulsion system for small, cost-driven spacecraft with delta-v requirements in the range of 10–150 m/s. This system is based on a hydroxylammonium nitrate (HAN)/water/fuel monopropellant blend which is extremely dense, environmentally benign, and promises good performance and simplicity.
The EURENCO Bofors company produced LMP-103S as a 1-to-1 substitute for hydrazine by dissolving 65% ammonium dinitramide, NH4N(NO2)2, in 35% water solution of methanol and ammonia. LMP-103S has 6% higher specific impulse and 30% higher impulse density than hydrazine monopropellant. Additionally, hydrazine is highly toxic and carcinogenic, while LMP-103S is only moderately toxic. LMP-103S is UN Class 1.4S allowing for transport on commercial aircraft, and was demonstrated on the Prisma satellite in 2010. Special handling is not required. LMP-103S could replace hydrazine as the most commonly used monopropellant.

</doc>
<doc id="37834" url="http://en.wikipedia.org/wiki?curid=37834" title="Dual mode propulsion rocket">
Dual mode propulsion rocket

Dual mode propulsion systems combine the high efficiency of bipropellant rockets with the reliability and simplicity of monopropellant rockets. Dual mode systems are either hydrazine/N2O4, or MMH/hydrogen peroxide (the former is much more common). Typically, this system works as follows: During the initial high-impulse orbit-raising maneuvers, the system operates in a bipropellant fashion, providing high thrust at high efficiency; when it arrives on orbit, it closes off either the fuel or oxidizer, and conducts the remainder of its mission in a simple, predictable monopropellant
fashion.

</doc>
<doc id="37835" url="http://en.wikipedia.org/wiki?curid=37835" title="Resistojet rocket">
Resistojet rocket

A resistojet is a method of spacecraft propulsion (electric propulsion) that provides thrust by heating a (typically non-reactive) fluid. Heating is usually achieved by sending electricity through a resistor consisting of a hot incandescent filament, with the expanded gas expelled through a conventional nozzle.
Resistojets have been flown in space since 1965 on board military Vela satellites. However, they only became used in commercial applications in 1980 with the launch of the first satellites in the INTELSAT-V program. Nowadays resistojet propulsion is used for orbit insertion, attitude control, and deorbit of LEO satellites, including satellites in the Iridium satellite constellation and do well in situations where energy is much more plentiful than mass, and where propulsion efficiency needs to be reasonably high but low thrust is acceptable.

</doc>
<doc id="37836" url="http://en.wikipedia.org/wiki?curid=37836" title="Arcjet rocket">
Arcjet rocket

An arcjet rocket or arcjet thruster is a form of electrically powered spacecraft propulsion, in which an electrical discharge (arc) is created in a flow of propellant (typically hydrazine or ammonia). This imparts additional energy to the propellant, so that one can extract more work out of each kilogram of propellant, at the expense of increased power consumption and (usually) higher cost. Also, the thrust levels available from typically used arcjet engines are very low compared with chemical engines.
When the energy is available, arcjets are well suited to keeping stations in orbit and can replace monopropellant rockets.
In Germany, researchers at the University of Stuttgart's Institute of Space Aviation Systems have been looking into these challenges for years and have developed various hydrogen-powered arcjet engines capable of power outputs from 1 to 100 kW. The heated hydrogen reaches exit speeds of 16 km/s. An arcjet-propelled test satellite by the name of Baden-Württemberg 1 (BW1) is scheduled to go to the Moon. Baden-Württemberg 1 would use polytetrafluoroethylene PTFE propellant.

</doc>
<doc id="37838" url="http://en.wikipedia.org/wiki?curid=37838" title="Hall effect thruster">
Hall effect thruster

In spacecraft propulsion, a Hall effect thruster (HET) is a type of ion thruster in which the propellant is accelerated by an electric field. Hall effect thrusters wrap electrons in a magnetic field and then use the electrons to ionize propellant, efficiently accelerate the ions to produce thrust, and neutralize the ions in the plume. Hall effect thrusters are sometimes referred to as Hall thrusters or Hall current thrusters. Hall thrusters are often regarded as a moderate specific impulse (1,600 s) space propulsion technology. The Hall effect thruster has benefited from considerable theoretical and experimental research since the 1960s.
Hall thrusters operate on a variety of propellants, the most common being xenon. Other propellants of interest include krypton, argon, bismuth, iodine, magnesium, and zinc.
Hall thrusters are able to accelerate their exhaust to speeds between 10–80 km/s (1,000–8,000 s specific impulse), with most models operating between 15–30 km/s (1,500–3,000 s specific impulse). The thrust produced by a Hall thruster varies depending on the power level. Devices operating at 1.35 kW produce about 83 mN of thrust. High power models have demonstrated up to 3 N in the laboratory. Power levels up to 100 kW have been demonstrated by xenon Hall thrusters.
, Hall effect thrusters ranged in input power levels from 1.35–10 kilowatts, and had exhaust velocities of 10–50 kilometers per second, with thrust of 40–600 millinewtons and efficiency in the range of 45–60 percent.
The applications of Hall effect thrusters include control of the orientation and position of orbiting satellites and use as a main propulsion engine for medium-size robotic space vehicles.
History.
Hall thrusters were studied independently in the United States and the Soviet Union. They were first described publicly in the US in the early 1960s. However, the Hall thruster was first developed into an efficient propulsion device in the Soviet Union. In the US, scientists focused instead on developing gridded ion thrusters.
Two types of Hall thrusters were developed in the Soviet Union:
The SPT design was largely the work of A. I. Morozov. The first SPT to operate in space, an SPT-50 aboard a Soviet Meteor spacecraft, was launched December 1971. They were mainly used for satellite stabilization in North-South and in East-West directions. Since then until the late 1990s 118 SPT engines completed their mission and some 50 continued to be operated. Thrust of the first generation of SPT engines, SPT-50 and SPT-60 was 20 and 30 mN respectively. In 1982, SPT-70 and SPT-100 were introduced, their thrusts being 40 and 83 mN, respectively. In the post-Soviet Russia high-power (a few kilowatts) SPT-140, SPT-160, SPT-200, T-160 and low-power (less than 500 W) SPT-35 were introduced.
Soviet and Russian TAL-type thrusters include the D-38, D-55, D-80, and D-100.
Soviet-built thrusters were introduced to the West in 1992 after a team of electric propulsion specialists from NASA's Jet Propulsion Laboratory, Glenn Research Center, and the Air Force Research Laboratory, under the support of the Ballistic Missile Defense Organization, visited Russian laboratories and experimentally evaluated the SPT-100 (i.e., a 100 mm diameter SPT thruster). Over 200 Hall thrusters have been flown on Soviet/Russian satellites in the past thirty years. No failures have ever occurred on orbit. Hall thruster continue to be used on Russian spacecraft and have also flown on European and American spacecraft. Space Systems/Loral, an American commercial satellite manufacturer, now flies Fakel SPT-100's on their GEO communications spacecraft.
Since their introduction to the west in the early 1990s, Hall thrusters have been the subject of a large number of research efforts throughout the United States, France, Italy, Japan, and Russia (with many smaller efforts scattered in various countries across the globe). Hall thruster research in the US is conducted at several government laboratories, universities and private companies. Government and government funded centers include NASA's Jet Propulsion Laboratory, NASA's Glenn Research Center, the Air Force Research Laboratory (Edwards AFB, CA), and The Aerospace Corporation. Universities include the , University of Michigan, Stanford University, The Massachusetts Institute of Technology, Princeton University, Michigan Technological University, and Georgia Tech. A considerable amount of development is being conducted in industry, such as Aerojet and Busek in the USA, SNECMA in France and in Italy.
The first use of Hall thrusters on lunar orbit was the European Space Agency (ESA) lunar mission SMART-1 in 2003.
On a western satellite Hall thrusters were first demonstrated on the Naval Research Laboratory (NRL) STEX spacecraft, which flew the Russian D-55. The first American Hall thruster to fly in space was the Busek BHT-200 on TacSat-2 technology demonstration spacecraft. The first flight of an American Hall thruster on an operational mission, was the Aerojet BPT-4000, which launched August 2010 on the military Advanced Extremely High Frequency GEO communications satellite. At 4.5 kW, the BPT-4000 is also the highest power Hall thruster ever flown in space. Besides the usual stationkeeping tasks, the BPT-4000 is also providing orbit raising capability to the spacecraft. Several countries worldwide continue efforts to qualify Hall thruster technology for commercial uses.
Operation.
The essential working principle of the Hall thruster is that it uses an electrostatic potential to accelerate ions up to high speeds. In a Hall thruster the attractive negative charge is provided by an electron plasma at the open end of the thruster instead of a grid. A radial magnetic field of a hundred gauss (about 100–300 G, 0.01–0.03 T) is used to confine the electrons, where the combination of the radial magnetic field and axial electric field cause the electrons to drift azimuthally, forming the Hall current from which the device gets its name.
A schematic of a Hall thruster is shown in the image to the right. An electric potential between 150 and 800 volts is applied between the anode and cathode.
The central spike forms one pole of an electromagnet and is surrounded by an annular space and around that is the other pole of the electromagnet, with a radial magnetic field in between.
The propellant, such as xenon gas, is fed through the anode, which has numerous small holes in it to act as a gas distributor. Xenon propellant is used because of its high atomic weight and low ionization potential. As the neutral xenon atoms diffuse into the channel of the thruster, they are ionized by collisions with high energy circulating electrons (typically 10–40 eV, or about 10% of the discharge voltage). Once ionized, the xenon ions typically have a charge of +1, though a small fraction (~20%) are +2.
The xenon ions are then accelerated by the electric field between the anode and the cathode. For discharge voltages of 300 V, the ions reach speeds of around 15 km/s for a specific impulse of 1,500 seconds (15 kN·s/kg). Upon exiting, however, the ions pull an equal number of electrons with them, creating a plasma plume with no net charge.
The radial magnetic field is designed to be strong enough to substantially deflect the low-mass electrons, but not the high-mass ions which have a much larger gyroradius and are hardly impeded. The majority of electrons are thus stuck orbiting in the region of high radial magnetic field near the thruster exit plane, trapped in E"×"B (axial electric field and radial magnetic field). This orbital rotation of the electrons is a circulating Hall current, and it is from this that the Hall thruster gets its name. Collisions with other particles and walls, as well as plasma instabilities, allow some of the electrons to be freed from the magnetic field, and they drift towards the anode.
About 20–30% of the discharge current is an electron current, which does not produce thrust, so limits the energetic efficiency of the thruster; the other 70–80% of the current is in the ions. Because the majority of electrons are trapped in the Hall current, they have a long residence time inside the thruster and are able to ionize almost all of the xenon propellant, allowing for mass utilizations of 90–99%. The mass utilization efficiency of the thruster is thus around 90%, while the discharge current efficiency is around 70% for a combined thruster efficiency of around 63% (= 90% × 70%). Modern Hall thrusters have achieved efficiencies as high as 75% through advanced designs.
Compared to chemical rockets, the thrust is very small, on the order of 83 mN for a typical thruster operating at 300 V, 1.5 kW. For comparison, the weight of a coin like the U.S. quarter or a 20-cent Euro coin is approximately 60 mN. As with all forms of electrically powered spacecraft propulsion, thrust is limited by available power, efficiency, and specific impulse.
However, Hall thrusters operate at the high specific impulses that is typical of electric propulsion. One particular advantage of Hall thrusters, as compared to a gridded ion thruster, is that the generation and acceleration of the ions takes place in a quasi-neutral plasma and so there is no Child-Langmuir charge (space charge) saturated current limitation on the thrust density. This allows for much smaller thrusters compared to gridded ion thrusters.
Another advantage is that these thrusters can use a wider variety of propellants supplied to the anode, even oxygen, although something easily ionized is needed at the cathode.
Cylindrical Hall thrusters.
Although conventional (annular) Hall thrusters are efficient in the kilowatt power regime, they become inefficient when scaled to small sizes. This is due to the difficulties associated with holding the performance scaling parameters constant while decreasing the channel size and increasing the applied magnetic field strength. This led to the design of the cylindrical Hall Thruster. The cylindrical Hall thruster can be more readily scaled to smaller sizes due to its nonconventional discharge-chamber geometry and associated magnetic field profile. The cylindrical Hall thruster more readily lends itself to miniaturization and low-power operation than a conventional (annular) Hall thruster. The primary reason for cylindrical Hall thrusters is that it is difficult to achieve a regular Hall thruster that operates over a broad envelope from ~1 kW down to ~100 W while maintaining an efficiency of 45-55%.
Applications.
Hall thrusters have been flying in space since December 1971 when the Soviets launched an SPT-50 on a Meteor satellite. Over 240 thrusters have flown in space since that time with a 100% success rate. Hall thrusters are now routinely flown on commercial GEO communications satellites where they are used for orbital insertion and stationkeeping.
The first Hall thruster to fly on a western satellite was a Russian D-55 built by TsNIIMASH, on the NRO's STEX spacecraft, launched on October 3, 1998.
The solar electric propulsion system of the European Space Agency's SMART-1 spacecraft used a Snecma PPS-1350-G Hall thruster. SMART-1 was a technology demonstration mission that orbited the Moon. This use of the PPS-1350-G, starting on September 28, 2003, was the first use of a Hall thruster outside geosynchronous earth orbit (GEO). Unlike most Hall thruster propulsion systems used in commercial applications, the Hall thruster on SMART-1 could be throttled over a range of power, specific impulse, and thrust.

</doc>
<doc id="37839" url="http://en.wikipedia.org/wiki?curid=37839" title="Ion thruster">
Ion thruster

An ion thruster is a form of electric propulsion used for spacecraft propulsion that creates thrust by accelerating ions. The term is strictly used to refer to gridded electrostatic ion thrusters, but may often more loosely be applied to all electric propulsion systems that accelerate plasma, since plasma consists of ions.
Ion thrusters are categorized by how they accelerate the ions, using either electrostatic or electromagnetic force. Electrostatic ion thrusters use the Coulomb force and accelerate the ions in the direction of the electric field. Electromagnetic ion thrusters use the Lorentz force to accelerate the ions. In either case, when an ion passes through an electrostatic grid engine, the potential difference of the electric field converts to the ion's kinetic energy.
Ion thrusters have an input power spanning 1–7 kilowatts, exhaust velocity 20–50 kilometers per second, thrust 20–250 millinewtons and efficiency 60–80%.
The Deep Space 1 spacecraft, powered by an ion thruster, changed velocity by 4.3 km/s while consuming less than 74 kilograms of xenon. The Dawn spacecraft broke the record, reaching 10 km/s.
Applications include control of the orientation and position of orbiting satellites (some satellites have dozens of low-power ion thrusters) and use as a main propulsion engine for low-mass robotic space vehicles (for example Deep Space 1 and Dawn).
Ion thrusters are not the most promising type of electrically powered spacecraft propulsion (although in practice they have been more successful than others). The ion drive is comparable to a car that takes two days to accelerate from zero to 60 miles per hour; a real ion engine's technical characteristics, and especially its thrust, are considerably inferior to its literary prototypes. Technical capabilities of the ion engine are limited by the space charge created by ions. This limits the thrust density (force per cross-sectional area of the engine). Ion thrusters create small thrust levels (for example the thrust of Deep Space 1's engine approximately equals the weight of one sheet of paper) compared to conventional chemical rockets, but achieve very high specific impulse, or propellant mass efficiency, by accelerating their exhaust to high speed. However, ion thrusters carry a fundamental price: the power imparted to the exhaust increases with the square of its velocity while thrust increases linearly. Chemical rockets, on the other hand, can provide high thrust, but are limited in total impulse by the small amount of energy that can be stored chemically in the propellants. Given the practical weight of suitable power sources, the accelerations given by ion thrusters are frequently less than one thousandth of standard gravity. However, since they operate as electric (or electrostatic) motors, a greater fraction of the input power is converted into kinetic exhaust power than in a chemical rocket. Chemical rockets operate as heat engines, hence Carnot's theorem bounds their possible exhaust velocity.
Due to their relatively high power needs, given the specific power of power supplies and the requirement of an environment void of other ionized particles, ion thrust propulsion is currently only practical on spacecraft that have already reached space, and is unable to take vehicles from Earth to space. Spacecraft rely on conventional chemical rockets to initially reach orbit.
Origins.
The first person to publish mention of the idea was Konstantin Tsiolkovsky in 1911. However, the first documented instance where the possibility of electric propulsion was considered is found in Robert H. Goddard's handwritten notebook in an entry dated September 6, 1906.
The first experiments with ion thrusters were carried out by Goddard at Clark University from 1916–1917. The technique was recommended for near-vacuum conditions at high altitude, but thrust was demonstrated with ionized air streams at atmospheric pressure. The idea appeared again in Hermann Oberth's "Wege zur Raumschiffahrt” (Ways to Spaceflight), published in 1923, where he explained his thoughts on the mass savings of electric propulsion, predicted its use in spacecraft propulsion and attitude control, and advocated electrostatic acceleration of charged gases.
A working ion thruster was built by Harold R. Kaufman in 1959 at the NASA Glenn Research Center facilities. It was similar to the general design of a gridded electrostatic ion thruster with mercury as its fuel. Suborbital tests of the engine followed during the 1960s and in 1964 the engine was sent into a suborbital flight aboard the Space Electric Rocket Test 1 (SERT 1). It successfully operated for the planned 31 minutes before falling back to Earth. This test was followed by an orbital test, SERT-2, in 1970.
An alternate form of electric propulsion, the Hall effect thruster was studied independently in the U.S. and the Soviet Union in the 1950s and 1960s. Hall effect thrusters had operated on Soviet satellites since 1972. Until the 1990s they were mainly used for satellite stabilization in North-South and in East-West directions. Some 100–200 engines completed their mission on Soviet and Russian satellites until the late 1990s. Soviet thruster design was introduced to the West in 1992 after a team of electric propulsion specialists, under the support of the Ballistic Missile Defense Organization, visited Soviet laboratories.
General description.
Ion thrusters use beams of ions (electrically charged atoms or molecules) to create thrust in accordance with momentum conservation. The method of accelerating the ions varies, but all designs take advantage of the charge/mass ratio of the ions. This ratio means that relatively small potential differences can create very high exhaust velocities. This reduces the amount of reaction mass or fuel required, but increases the amount of specific power required compared to chemical rockets. Ion thrusters are therefore able to achieve extremely high specific impulses. The drawback of the low thrust is low spacecraft acceleration, because the mass of current electric power units is directly correlated with the amount of power given. This low thrust makes ion thrusters unsuited for launching spacecraft into orbit, but they are ideal for in-space propulsion applications.
Various ion thrusters have been designed and they all generally fit under two categories. The thrusters are categorized as either electrostatic or electromagnetic. The main difference is how the ions are accelerated.
Electric power supplies for ion thrusters are usually solar panels but, at sufficiently large distances from the Sun, nuclear power is used. In each case the power supply mass is essentially proportional to the peak power that can be supplied, and they both essentially give, for this application, no limit to the energy.
Electric thrusters tend to produce low thrust, which results in low acceleration. Using 1 g is 9.81 m/s2; F = m a ⇒ a = F/m. An NSTAR thruster producing a thrust (force) of 92 mN will accelerate a satellite with a mass of 1,000 kg by 0.092 N / 1,000 kg =  m/s2 (or 9.38×10−6 g).
thrust = 2*η*power/(g * Isp)
Where
Electrostatic ion thrusters.
Gridded electrostatic ion thrusters.
Gridded electrostatic ion thrusters commonly utilize xenon gas. This gas has no charge and is ionized by bombarding it with energetic electrons. These electrons can be provided from a hot cathode filament and when accelerated in the electrical field of the cathode, fall to the anode. Alternatively, the electrons can be accelerated by the oscillating electric field induced by an alternating magnetic field of a coil, which results in a self-sustaining discharge and omits any cathode (radio frequency ion thruster).
The positively charged ions are extracted by an extraction system consisting of 2 or 3 multi-aperture grids. After entering the grid system via the plasma sheath the ions are accelerated due to the potential difference between the first and second grid (named screen and accelerator grid) to the final ion energy of typically 1–2 keV, thereby generating the thrust.
Ion thrusters emit a beam of positive charged xenon ions only. To avoid charging up the spacecraft, another cathode is placed near the engine, which emits electrons (basically the electron current is the same as the ion current) into the ion beam. This also prevents the beam of ions from returning to the spacecraft and cancelling the thrust.
Gridded electrostatic ion thruster research (past/present):
Hall effect thrusters.
Hall effect thrusters accelerate ions with the use of an electric potential maintained between a cylindrical anode and a negatively charged plasma that forms the cathode. The bulk of the propellant (typically xenon gas) is introduced near the anode, where it becomes ionized, and the ions are attracted towards the cathode; they accelerate towards and through it, picking up electrons as they leave to neutralize the beam and leave the thruster at high velocity.
The anode is at one end of a cylindrical tube, and in the center is a spike that is wound to produce a radial magnetic field between it and the surrounding tube. The ions are largely unaffected by the magnetic field, since they are too massive. However, the electrons produced near the end of the spike to create the cathode are far more affected and are trapped by the magnetic field, and held in place by their attraction to the anode. Some of the electrons spiral down towards the anode, circulating around the spike in a Hall current. When they reach the anode they impact the uncharged propellant and cause it to be ionized, before finally reaching the anode and closing the circuit.
Field-emission electric propulsion.
Field-emission electric propulsion (FEEP) thrusters use a very simple system of accelerating ions to create thrust. Most designs use either caesium or indium as the propellant. The design comprises a small propellant reservoir that stores the liquid metal, a narrow tube or a system of parallel plates that the liquid flows through, and an accelerator (a ring or an elongated aperture in a metallic plate) about a millimeter past the tube end. Caesium and indium are used due to their high atomic weights, low ionization potentials, and low melting points. Once the liquid metal reaches the end of the tube, an electric field applied between the emitter and the accelerator causes the liquid surface to deform into a series of protruding cusps ("Taylor cones"). At a sufficiently high applied voltage, positive ions are extracted from the tips of the cones. The electric field created by the emitter and the accelerator then accelerates the ions. An external source of electrons neutralizes the positively charged ion stream to prevent charging of the spacecraft.
Electromagnetic thrusters.
Pulsed inductive thrusters (PIT).
Pulsed inductive thrusters (PIT) use pulses of thrust instead of one continuous thrust, and have the ability to run on power levels in the order of Megawatts (MW). PITs consist of a large coil encircling a cone shaped tube that emits the propellant gas. Ammonia is the gas commonly used in PIT engines. For each pulse of thrust the PIT gives, a large charge first builds up in a group of capacitors behind the coil and is then released. This creates a current that moves circularly in the direction of jθ. The current then creates a magnetic field in the outward radial direction (Br), which then creates a current in the ammonia gas that has just been released in the opposite direction of the original current. This opposite current ionizes the ammonia and these positively charged ions are accelerated away from the PIT engine due to the electric field jθ crossing with the magnetic field Br, which is due to the Lorentz Force.
Magnetoplasmadynamic (MPD) / lithium Lorentz force accelerator (LiLFA).
Magnetoplasmadynamic (MPD) thrusters and lithium Lorentz force accelerator (LiLFA) thrusters use roughly the same idea with the LiLFA thruster building off of the MPD thruster. Hydrogen, argon, ammonia, and nitrogen gas can be used as propellant. In a certain configuration, the ambient gas in Low Earth Orbit (LEO) can be used as a propellant. The gas first enters the main chamber where it is ionized into plasma by the electric field between the anode and the cathode. This plasma then conducts electricity between the anode and the cathode. This new current creates a magnetic field around the cathode, which crosses with the electric field, thereby accelerating the plasma due to the Lorentz force. The LiLFA thruster uses the same general idea as the MPD thruster, except for two main differences. The first difference is that the LiLFA uses lithium vapor, which has the advantage of being able to be stored as a solid. The other difference is that the cathode is replaced by multiple smaller cathode rods packed into a hollow cathode tube. The cathode in the MPD thruster is easily corroded due to constant contact with the plasma. In the LiLFA thruster the lithium vapor is injected into the hollow cathode and is not ionized to its plasma form/corrode the cathode rods until it exits the tube. The plasma is then accelerated using the same Lorentz Force.
Electrodeless plasma thrusters.
Electrodeless plasma thrusters have two unique features: the removal of the anode and cathode electrodes and the ability to throttle the engine. The removal of the electrodes takes away the factor of erosion, which limits lifetime on other ion engines. Neutral gas is first ionized by electromagnetic waves and then transferred to another chamber where it is accelerated by an oscillating electric and magnetic field, also known as the ponderomotive force. This separation of the ionization and acceleration stage give the engine the ability to throttle the speed of propellant flow, which then changes the thrust magnitude and specific impulse values.
Helicon double layer thruster.
A helicon double layer thruster is a type of plasma thruster, which ejects high velocity ionized gas to provide thrust to a spacecraft. In this thruster design, gas is injected into a tubular chamber (the "source tube") with one open end. Radio frequency AC power (at 13.56 MHz in the prototype design) is coupled into a specially shaped antenna wrapped around the chamber. The electromagnetic wave emitted by the antenna causes the gas to break down and form a plasma. The antenna then excites a helicon wave in the plasma, which further heats the plasma. The device has a roughly constant magnetic field in the source tube (supplied by solenoids in the prototype), but the magnetic field diverges and rapidly decreases in magnitude away from the source region, and might be thought of as a kind of magnetic nozzle. In operation, there is a sharp boundary between the high density plasma inside the source region, and the low density plasma in the exhaust, which is associated with a sharp change in electrical potential. The plasma properties change rapidly across this boundary, which is known as a "current-free electric double layer". The electrical potential is much higher inside the source region than in the exhaust, and this serves both to confine most of the electrons, and to accelerate the ions away from the source region. Enough electrons escape the source region to ensure that the plasma in the exhaust is neutral overall.
Comparisons.
The following table compares actual test data of some ion thrusters:
The following thrusters are highly experimental and have been tested only in pulse mode.
Lifetime.
A major limiting factor of ion thrusters is their small thrust; however, it is generated at a high propellant efficiency (mass utilisation, specific impulse). The efficiency comes from the high exhaust velocity, which in turn demands high energy, and the performance is ultimately limited by the available spacecraft power.
The low thrust requires ion thrusters to provide continuous thrust for a long time to achieve the needed change in velocity (delta-v) for a particular mission. To cause enough change in momentum, ion thrusters are designed to last for periods of weeks to years.
In practice the lifetime of electrostatic ion thrusters is limited by several processes:
A test of the NASA Solar Technology Application Readiness (NSTAR) electrostatic ion thruster resulted in 30,472 hours (roughly 3.5 years) of continuous thrust at maximum power. The test was concluded prior to any failure and examination indicated the engine was not approaching failure either.
More recently, the NASA Evolutionary Xenon Thruster (NEXT) Project, conducted at NASA's Glenn Research Center in Cleveland, Ohio, operated continuously for more than 48,000 hours. The test was conducted in a high vacuum test chamber at Glenn Research Center. Over the course of the 5 1/2 + year test, the engine consumed approximately 870 kilograms of xenon propellant. The total impulse provided by the engine would require over 10,000 kilograms of conventional rocket propellant for similar application. The engine was designed by Aerojet Rocketdyne of Sacramento, California.
NASA's Jet Propulsion Laboratory has created ion drives with a time of continuous operation of more than 3 years.
Propellants.
Ionization energy represents a very large percentage of the energy needed to run ion drives. The ideal propellant for ion drives is thus a propellant molecule or atom that is easy to ionize, that has a high mass/ionization energy ratio. In addition, the propellant should not cause erosion of the thruster to any great degree to permit long life; and should not contaminate the vehicle.
Many current designs use xenon gas, as it is easy to ionize, has a reasonably high atomic number, its inert nature, and low erosion. However, xenon is globally in short supply and very expensive.
Older designs used mercury, but this is toxic and expensive, tended to contaminate the vehicle with the metal and was difficult to feed accurately.
Other propellants, such as bismuth, show promise and are areas of research, particularly for gridless designs, such as Hall effect thrusters.
VASIMR design (and other plasma-based engines) are theoretically able to use practically any material for propellant. However, in current tests the most practical propellant is argon, which is a relatively abundant and inexpensive gas.
Energy efficiency.
Ion thrusters are frequently quoted with an efficiency metric. This efficiency is the kinetic energy of the exhaust jet emitted per second divided by the electrical power into the device.
The actual overall system energy efficiency in use is determined by the propulsive efficiency, which depends on vehicle speed and exhaust speed. Some thrusters can vary exhaust speed in operation, but all can be designed with different exhaust speeds. At the lower end of Isps the overall efficiency drops, because the ionization takes up a larger percentage energy, and at the high end propulsive efficiency is reduced.
Optimal efficiencies and exhaust velocities can thus be calculated for any given mission to give minimum overall cost.
Applications.
Ion thrusters have many applications for in-space propulsion. The best applications of the thrusters make use of the long lifetime when significant thrust is not needed. Examples of this include orbit transfers, attitude adjustments, drag compensation for low Earth orbits, transporting cargo such as chemical fuels between propellant depots and ultra-fine adjustments for scientific missions. Ion thrusters can also be used for interplanetary and deep-space missions where time is not crucial. Continuous thrust over a very long time can build up a larger velocity than traditional chemical rockets.
Missions.
Of all the electric thrusters, ion thrusters have been the most seriously considered commercially and academically in the quest for interplanetary missions and orbit raising maneuvers. Ion thrusters are seen as the best solution for these missions, as they require very high change in velocity overall that can be built up over long periods of time.
Pure demonstration vehicles.
Ion propulsion systems were first demonstrated in space by the NASA Lewis (now Glenn Research Center) missions "Space Electric Rocket Test" (SERT) I and II. The first was SERT-1, launched July 20, 1964, successfully proved that the technology operated as predicted in space. These were electrostatic ion thrusters using mercury and cesium as the reaction mass. The second test, SERT-II, launched on February 3, 1970, verified the operation of two mercury ion engines for thousands of running hours.
Operational missions.
Ion thrusters are routinely used for station-keeping on commercial and military communication satellites in geosynchronous orbit, including satellites manufactured by Boeing and by Hughes Aerospace. The pioneers in this field were the Soviet Union, who used SPT thrusters on a variety of satellites starting in the early 1970s.
Two geostationary satellites (ESA's Artemis in 2001–03 and the US military's AEHF-1 in 2010–12) have used the ion thruster for orbit raising after the failure of the chemical-propellant engine. Boeing have been using ion thrusters for station-keeping since 1997, and plan in 2013–14 to offer a variant on their 702 platform, which will have no chemical engine and use ion thrusters for orbit raising; this enables a significantly lower launch mass for a given satellite capability. AEHF-2 used a chemical engine to raise perigee to 10150 miles and is then proceeding to geosynchronous orbit using electric propulsion.
In Earth orbit.
ESA's Gravity Field and Steady-State Ocean Circulation Explorer was launched on March 16, 2009. It used ion propulsion throughout its twenty-month mission to combat the air-drag it experienced in its low orbit before intentionally deorbiting on November 11, 2013.
In deep space.
NASA developed the NSTAR ion engine for use in their interplanetary science missions beginning in the late-1990s. This xenon-propelled ion thruster was first space-tested in the highly successful space probe Deep Space 1, launched in 1998. This was the first use of electric propulsion as the interplanetary propulsion system on a science mission.
Based on the NASA design criteria, Hughes Research Labs, developed the XIPS (Xenon Ion Propulsion System) for performing station keeping on geosynchronous satellites.. Hughes (EDD) manufactured the NSTAR thruster used on the spacecraft.
The Japanese space agency's Hayabusa, which was launched in 2003 and successfully rendezvoused with the asteroid 25143 Itokawa and remained in close proximity for many months to collect samples and information, was powered by four xenon ion engines. It used xenon ions generated by microwave electron cyclotron resonance, and a carbon / carbon-composite material (which is resistant to erosion) for its acceleration grid. Although the ion engines on Hayabusa had some technical difficulties, in-flight reconfiguration allowed one of the four engines to be repaired, and allowed the mission to successfully return to Earth.
The European Space Agency's satellite SMART-1, launched in 2003, used a Snecma PPS-1350-G Hall thruster to get from GTO to lunar orbit. This satellite completed its mission on September 3, 2006, in a controlled collision on the Moon's surface, after a trajectory deviation so scientists could see the 3 meter crater the impact created on the visible side of the moon.
Dawn was launched on September 27, 2007, to explore the asteroid Vesta and the dwarf planet Ceres. To cruise from Earth to its targets it uses three Deep Space 1 heritage xenon ion thrusters (firing only one at a time) to take it in a long outward spiral. An extended mission in which Dawn explores other asteroids after Ceres is also possible. Dawn's ion drive is capable of accelerating from 0 to 60 mi/h in 4 days, firing continuously.
Planned missions.
In addition, several missions are planned to use ion thrusters in the next few years.
ESA will launch the BepiColombo mission to Mercury in 2016. It uses ion thrusters in combination with swing-bys to get to Mercury, where a chemical rocket will be fired for orbit insertion.
LISA Pathfinder is an ESA spacecraft to be launched in 2015. It will not use ion thrusters as its primary propulsion system, but will use both colloid thrusters and FEEP for very precise attitude control -— the low thrusts of these propulsion devices make it possible to move the spacecraft incremental distances very accurately. It is a test for the possible LISA mission.
s of March 2011[ [update]], a future launch of an Ad Astra VF-200 200 kW VASIMR electromagnetic thruster was being considered for placement and testing on the International Space Station. The VF-200 is a flight version of the VX-200.
Since the available power from the ISS is less than 200 kW, the ISS VASIMR will include a trickle-charged battery system allowing for 15 min pulses of thrust. Testing of the engine on ISS is valuable, because ISS orbits at a relatively low altitude and experiences fairly high levels of atmospheric drag, making periodic boosts of altitude necessary. Currently, altitude reboosting by chemical rockets fulfills this requirement. If the tests of VASIMR reboosting of the ISS goes according to plan, the increase in specific impulse could mean that the cost of fuel for altitude reboosting will be one-twentieth of the current $210 million annual cost. Hydrogen is generated by the ISS as a by-product, which is currently vented into space.
In June 2011, NASA launched a request-for-proposals for a test mission (from context probably using the NEXT engine) capable of being extended to 300 kW electrical power; this was awarded to Northrop Grumman in February 2012.
Proposal.
Geoffrey A. Landis proposed for interstellar travel future-technology project interstellar probe with supplying the energy from an external source (laser of base station) and ion thruster.
References.
</dl>

</doc>
<doc id="37840" url="http://en.wikipedia.org/wiki?curid=37840" title="Magnetoplasmadynamic thruster">
Magnetoplasmadynamic thruster

A magnetoplasmadynamic (MPD) thruster (MPDT) is a form of electrically powered spacecraft propulsion which uses the Lorentz force (the force on a charged particle by an electromagnetic field) to generate thrust. It is sometimes referred to as Lorentz Force Accelerator (LFA) or (mostly in Japan) MPD arcjet.
Generally, a gaseous material is ionized and fed into an acceleration chamber, where the magnetic and electrical fields are created using a power source. The particles are then propelled by the Lorentz force resulting from the interaction between the current flowing through the plasma and the magnetic field (which is either externally applied, or induced by the current) out through the exhaust chamber. Unlike chemical propulsion, there is no combustion of fuel. As with other electric propulsion variations, both specific impulse and thrust increase with power input, while thrust per watt drops.
There are two main types of MPD thrusters, applied-field and self-field. Applied-field thrusters have magnetic rings surrounding the exhaust chamber to produce the magnetic field, while self-field thrusters have a cathode extending through the middle of the chamber. Applied fields are necessary at lower power levels, where self-field configurations are too weak. Various propellants such as xenon, neon, argon, hydrogen, hydrazine, and lithium have been used, with lithium generally being the best performer.
According to Edgar Choueiri magnetoplasmadynamic thrusters have input power 100-500 kilowatts, exhaust velocity 15-60 kilometers per second, thrust 2.5-25 newtons and efficiency 40-60 percent.
One potential application of magnetoplasmadynamic thrusters is the main propulsion engine for heavy cargo and piloted space vehicles (example engine formula_1 for Manned mission to Mars).
Advantages.
In theory, MPD thrusters could produce extremely high specific impulses (Isp) with an exhaust velocity of up to and beyond , triple the value of current xenon-based ion thrusters, and about 25 times better than liquid rockets. MPD technology also has the potential for thrust levels of up to 200 newtons (N) (), by far the highest for any form of electric propulsion, and nearly as high as many interplanetary chemical rockets. This would allow use of electric propulsion on missions which require quick delta-v maneuvers (such as capturing into orbit around another planet), but with many times greater fuel efficiency.
Problems with MPDT.
MPD thruster technology has been explored academically, but commercial interest has been low due to several remaining problems. One big problem is that power requirements on the order of hundreds of kilowatts are required for optimum performance. Current interplanetary spacecraft power systems (such as radioisotope thermoelectric generators (RTGs)) and solar arrays are incapable of producing that much power. NASA's Project Prometheus reactor was expected to generate power in the hundreds of kilowatts range but was discontinued in 2005.
A project to produce a space-going nuclear reactor designed to generate 600 kilowatts of electrical power began in 1963 and ran for most of the 1960s in the USSR. It was to power a communication satellite which was in the end not approved. Nuclear reactors supplying kilowatts of electrical power (of the order of ten times more than current RTG power supplies) have been orbited by the USSR: RORSAT; and TOPAZ.
Plans to develop a megawatt-scale nuclear reactor for the use aboard a manned spaceship were announced in 2009 by Russian nuclear Kurchatov Institute, national space agency Roskosmos, and confirmed by Russian President Dmitry Medvedev in his November 2009 address to the Federal Assembly.
Another plan, proposed by Bradley C. Edwards, is to beam power from the ground. This plan utilizes 5 200 kW free electron lasers at 0.84 micrometres with adaptive optics on the ground to beam power to the MPD-powered spacecraft, where it is converted to electricity by GaAs photovoltaic panels. The tuning of the laser wavelength of 0.840 micrometres ( per photon) and the PV panel bandgap of to each other produces an estimated conversion efficiency of 59% and a predicted power density of up to . This would be sufficient to power a MPD upper stage, perhaps to lift satellites from LEO to GEO.
Another problem with MPD technology has been the degradation of cathodes due to evaporation driven by high current densities (in excess of ). The use of lithium and barium propellant mixtures and multi-channel hollow cathodes has been shown in the laboratory to be a promising solution for the cathode erosion problem.
Research.
Research on MPD thrusters has been carried out in the US, the former Soviet Union, Japan, Germany, and Italy. Experimental prototypes were first flown on Soviet spacecraft and, most recently, in 1996, on the Japanese Space Flyer Unit, which demonstrated the successful operation of a quasi-steady pulsed MPD thruster in space. Research at Moscow Aviation Institute, RKK Energiya, University of Stuttgart, ISAS, , , Osaka University, University of Southern California, Princeton University's (where MPD thruster research has continued uninterrupted since 1967), and NASA centers (Jet Propulsion Laboratory and Glenn Research Center), has resolved many problems related to the performance, stability and lifetime of MPD thrusters.
An MPD thruster was tested on board the Japanese Space Flyer Unit as part of EPEX (Electric Propulsion EXperiment) that was launched March 18, 1995 and retrieved by space shuttle mission STS-72 January 20, 1996. To date, it is the only operational MPD thruster to have flown in space as a propulsion system.

</doc>
<doc id="37841" url="http://en.wikipedia.org/wiki?curid=37841" title="Pulsed plasma thruster">
Pulsed plasma thruster

A pulsed plasma thruster (PPT), also known as a plasma jet engine, is a form of electric spacecraft propulsion. PPTs are generally considered the simplest form of electric spacecraft propulsion and were the first form of electric propulsion to be flown in space, having flown on two Soviet probes (Zond 2 and Zond 3) starting in 1964. PPTs are generally flown on spacecraft with a surplus of electricity from abundantly available solar energy.
Operation.
Most PPTs use a solid material (normally PTFE, more commonly known as Teflon) for propellant, although a minority use liquid or gaseous propellants. The first stage in PPT operation involves an arc of electricity passing through the fuel, causing ablation and sublimation of the fuel. The heat generated by this arc causes the resultant gas to turn into plasma, thereby creating a charged gas cloud. Due to the force of the ablation, the plasma is propelled at low speed between two charged plates (an anode and cathode). Since the plasma is charged, the fuel effectively completes the circuit between the two plates, allowing a current to flow through the plasma. This flow of electrons generates a strong electromagnetic field which then exerts a Lorentz force on the plasma, accelerating the plasma out of the PPT exhaust at high velocity. The pulsing occurs due to the time needed to recharge the plates following each burst of fuel, and the time between each arc. The frequency of pulsing is normally very high and so it generates an almost continuous and smooth thrust. While the thrust is very low, a PPT can operate continuously for extended periods of time, yielding a large final speed.
The energy used in each pulse is stored in a capacitor. By varying the time between each capacitor discharge, the thrust and power draw of the PPT can be varied allowing versatile use of the system.
Comparison to chemical propulsion.
The equation for the change in velocity of a spacecraft is given by the rocket equation as follows:
where:
PPTs have much higher exhaust velocities than chemical propulsion engines, but have a much smaller fuel flow rate. From the Tsiolkovsky equation stated above, this results in a proportionally higher final velocity of the propelled craft. The exhaust velocity of a PPT is of the order of tens of km/s while conventional chemical propulsion generates thermal velocities in the range of 2-4.5 km/s. Due to this lower thermal velocity, chemical propulsion units become exponentially less effective at higher vehicle velocities, necessitating the use of electric spacecraft propulsion such as PPTs. It is therefore advantageous to use an electric propulsion system such as a PPT to generate high interplanetary speeds in the range 20–70 km/s.
NASA's research PPT (flown in 2000) achieved an exhaust velocity of 13,700 m/s, generated a thrust of 860 µN, and consumed 70W of electrical power.
Advantages and disadvantages.
PPTs are very robust due to their inherently simple design (relative to other electric spacecraft propulsion techniques), and draw very little electrical power relative to other comparable thrusters. As an electric propulsion system, PPTs benefit from reduced fuel consumption compared to traditional chemical rockets, reducing launch mass and therefore launch costs, as well as high specific impulse improving performance.
However, due to energy losses caused by late time ablation and rapid conductive heat transfer from the propellant to the rest of the spacecraft, propellant efficiency is very low compared to other forms of electric propulsion, at around just 10%.
Uses.
PPTs are well-suited to uses on relatively small spacecraft with a mass of less than 100 kg (particularly CubeSats) for roles such as attitude control, station keeping, de-orbiting manoeuvres and deep space exploration. Using PPTs could double the life-span of these small satellite missions without significantly increasing complexity or cost due to the inherent simplicity and relatively low cost nature of PPTs. A PPT was flown by NASA in November, 2000, as a flight experiment on the Earth Observing-1 spacecraft. The thrusters successfully demonstrated the ability to perform roll control on the spacecraft and also demonstrated that the electromagnetic interference from the pulsed plasma did not affect other spacecraft systems. Pulsed Plasma Thrusters are also an avenue of research used by universities for starting experiments with electric propulsion due to the relative simplicity and lower costs involved with PPTs as opposed to other forms of electric propulsion such as Hall effect ion thrusters.

</doc>
<doc id="37842" url="http://en.wikipedia.org/wiki?curid=37842" title="Nuclear thermal rocket">
Nuclear thermal rocket

A nuclear thermal rocket is a proposed spacecraft propulsion technology. In a nuclear thermal rocket a working fluid, usually liquid hydrogen, is heated to a high temperature in a nuclear reactor, and then expands through a rocket nozzle to create thrust. In this kind of thermal rocket, the nuclear reactor's energy replaces the chemical energy of the propellant's reactive chemicals in a chemical rocket. The thermal heater / inert propellant paradigm as opposed to the reactive propellants of chemical rockets turns out to produce a superior effective exhaust velocity, and therefore a superior propulsive efficiency, with specific impulses on the order of twice that of chemical engines. The overall gross lift-off mass of a nuclear rocket is about half that of a chemical rocket, and hence when used as an upper stage it roughly doubles or triples the payload carried to orbit.
A nuclear engine was considered for some time as a replacement for the J-2 used on the S-II and S-IVB stages on the Saturn V and Saturn I rockets. Originally "drop-in" replacements were considered for higher performance, but a larger replacement for the S-IVB stage was later studied for missions to Mars and other high-load profiles, known as the S-N. Nuclear thermal space "tugs" were planned as part of the Space Transportation System to take payloads from a propellant depot in Low Earth Orbit to higher orbits, the Moon, and other planets. Robert Bussard proposed the Single-Stage-To-Orbit "Aspen" vehicle using a nuclear thermal rocket for propulsion and liquid hydrogen propellant for partial shielding against neutron back scattering in the lower atmosphere. The Soviet Union studied nuclear engines for their own moon rockets, notably upper stages of the N-1, although they never entered an extensive testing program like the one the U.S. conducted throughout the 1960s at the Nevada Test Site. Despite many successful firings, American nuclear rockets did not fly before the space race ended.
To date, no nuclear thermal rocket has flown, although the NERVA NRX/EST and NRX/XE were built and tested with flight design components. The highly successful U.S. Project Rover which ran from 1955 through 1972 accumulated over 17 hours of run time. The NERVA NRX/XE, judged by SNPO to be the last "technology development" reactor necessary before proceeding to flight prototypes, accumulated over 2 hours of run time, including 28 minutes at full power. The Russian nuclear thermal rocket RD-0410 was also claimed by the Soviets to have gone through a series of tests at the nuclear test site near Semipalatinsk.
The United States tested twenty different sizes and designs during Project Rover and NASA's NERVA program from 1959 through 1972 at the Nevada Test Site, designated Kiwi, Phoebus, NRX/EST, NRX/XE, Pewee, Pewee 2 and the Nuclear Furnace, with progressively higher power densities culminating in the Pewee (1970) and Pewee 2. Tests of the improved Pewee 2 design were cancelled in 1970 in favor of the lower-cost Nuclear Furnace (NF-1), and the U.S. nuclear rocket program officially ended in spring of 1973. Current (2010) 25000 lbf reference designs (NERVA-Derivative Rockets, or NDRs) are based on the Pewee, and have specific impulses of 925 seconds.
Types.
A nuclear thermal rocket can be categorized by the construction of its reactor, which can range from a relatively simple solid reactor up to a much more complicated but more efficient reactor with a gas core. As with all thermal rocket designs, the specific impulse produced is proportional to the square root of the temperature to which the working fluid (reaction mass) is heated, and hence the most efficient designs require the highest temperatures possible. This is typically limited by the properties of materials.
Solid core.
The most traditional type uses a conventional (albeit light-weight) nuclear reactor running at high temperatures to heat the working fluid that is moving through the reactor core. This is known as the solid-core design, and is the simplest design to construct.
The simplest of nuclear thermal rockets, solid core reactors are limited by the melting point of the materials used in the reactor cores. The solid core design needs to be constructed of materials that remain strong at as high a temperature as possible. Nuclear reactions can create much higher temperatures than the temperatures the materials can withstand, meaning that much of the potential of the reactor for very high temperatures is sacrificed. Even more limiting is the cracking of fuel coatings due to the large temperature ranges (from 22 K up to 3000 K over the length of a 1.3 m fuel rod), and the necessity of matching coefficients of expansion in all the components. Using hydrogen propellant, a solid-core design typically delivers specific impulses ("I"sp) on the order of 850 to 1000 seconds, about twice that of liquid hydrogen-oxygen designs such as the Space Shuttle Main Engine. Other propellants are sometimes proposed, such as ammonia, water or LOX. Although these propellants would provide reduced exhaust velocity, their greater availability can reduce payload costs by a very large factor where the mission delta-v is not too high, such as within cislunar space or between Earth orbit and Martian orbit. Above about 1500 K hydrogen begins to dissociate at low pressures, or 3000 K at high pressures, a potential area of promise for increasing the "I"sp of solid core reactors.
Immediately after World War II, the weight of a complete nuclear reactor was so great that it was feared that solid-core engines would be hard-pressed to achieve a thrust-to-weight ratio of 1:1, which is needed to overcome the gravity of the Earth at launch. The problem was quickly overcome, however, and over the next twenty-five years U.S. nuclear thermal rocket designs eventually reached thrust-to-weight ratios of approximately 7:1. Still, the lower thrust-to-weight ratio of nuclear thermal rockets versus chemical rockets (which have thrust-to-weight ratios of 70:1) and the large tanks necessary for liquid hydrogen storage mean that solid-core engines are best used in upper stages where vehicle velocity is already near orbital, in space "tugs" used to take payloads between gravity wells, or in launches from a lower gravity planet, moon or minor planet where the required thrust is lower. To be a useful Earth launch engine, the system would have to be either much lighter, or provide even higher specific impulse. The true strength of nuclear rockets currently lies in solar system exploration, outside Earth's gravity well.
One way to increase the temperature, and thus the specific impulse, is to isolate the fuel elements so they no longer have to be rigid. This is the basis of the particle-bed reactor, also known as the fluidized-bed, dust-bed, or rotating-bed design. In this design the fuel is placed in a number of (typically spherical) elements which "float" inside the hydrogen working fluid. Spinning the entire engine forces the fuel elements out to walls that are being cooled by the hydrogen. This design increases the specific impulse to about 1000 seconds (9.8 kN·s/kg), allowing for thrust-to-weight ratios greater than 1:1, although at the cost of increased complexity. Such a design could share design elements with a pebble-bed reactor, several of which are currently generating electricity.
From 1987 through 1991, the SDI Office funded Project Timberwind, a non-rotating nuclear thermal rocket based on particle bed technology. Although the project was canceled before testing in 1992 by the incoming Clinton Administration, the design was thought to achieve thrust-to-weight ratios of 30:1 and specific impulses of at least 1000 seconds.
Liquid core.
Dramatically greater improvements are theoretically possible by mixing the nuclear fuel into the working fluid and allowing the reaction to take place in the liquid mixture itself. This idea is the basis of the liquid-core engine which can operate at temperatures above the melting point of the nuclear fuel; the maximum operating temperature of the engine is determined by the maximum temperature that the container wall (typically a neutron reflector of some sort) can withstand while it is actively cooled by the hydrogen. The liquid-core design is expected to deliver performance on the order of 1300 to 1500 seconds (12.8–14.8 kN·s/kg).
These engines are currently considered to be very difficult to build. The reaction time of the nuclear fuel is much longer than the heating time of the working fluid and therefore requires a method to trap the fuel inside the engine while allowing the working fluid to easily exit through the nozzle. Most liquid-phase engines have focused on rotating the fuel/fluid mixture at very high speeds to force the fuel to the outside by centripetal force (uranium is more massive than hydrogen). The design mirrors the particle-bed design in many ways but operates at even higher temperatures.
Robert Zubrin has proposed an alternative liquid-core design, the nuclear salt-water rocket. In this design, water is the working fluid and also serves as the neutron moderator. The nuclear fuel is not retained which drastically simplifies the design. However, by its very design, the rocket would discharge massive quantities of extremely radioactive waste and could only be safely operated well outside the Earth's atmosphere and perhaps even entirely outside earth's magnetosphere.
Gas core.
The final classification is the gas-core engine. This is a modification to the liquid-core design which uses rapid circulation of the fluid to create a toroidal pocket of gaseous uranium fuel in the middle of the reactor, surrounded by hydrogen. In this case the fuel does not touch the reactor wall at all, so temperatures could reach several tens of thousands of degrees, which would allow specific impulses of 3000 to 5000 seconds (30 to 50 kN·s/kg). In this basic design, the "open cycle", the losses of nuclear fuel would be difficult to control, which has led to studies of the "closed cycle" or nuclear lightbulb engine, where the gaseous nuclear fuel is contained in a super-high-temperature quartz container, over which the hydrogen flows. The closed cycle engine actually has much more in common with the solid-core design, but this time is limited by the critical temperature of quartz instead of the fuel stack. Although less efficient than the open-cycle design, the closed-cycle design is expected to deliver a rather respectable specific impulse of about 1500–2000 seconds (15–20 kN·s/kg).
History.
Although engineering studies of all of these designs were made, only the solid-core engine was ever built. Development of such engines started under the aegis of the Atomic Energy Commission in 1955 as Project Rover, with work on a suitable reactor starting at Los Alamos National Laboratory and Area 25 in the Nevada Test Site. Four basic designs came from this project: KIWI, Phoebus, Pewee and the Nuclear Furnace. Twenty rockets were tested.
When NASA was formed in 1958, it was given authority over all non-nuclear aspects of the Rover program. In order for NASA to cooperate with the AEC, the Space Nuclear Propulsion Office was created at the same time. In 1961, the NERVA program ("Nuclear Engine for Rocket Vehicle Applications") was created. Marshall Space Flight Center had been increasingly using KIWI for mission planning, and NERVA was formed to formalize the entry of nuclear thermal rocket engines into space exploration. Unlike the AEC work, which was intended to study the reactor design itself, NERVA's goal was to produce a real engine that could be deployed on space missions. A 75,000 lbf (334 kN) thrust baseline NERVA design was based on the KIWI B4 series, and was considered for some time as the upper stages for the Saturn V, in place of the J-2s that were actually flown.
Although the Kiwi/Phoebus/NERVA designs were the only ones to be tested in any substantial program, a number of other solid-core engines were also studied to some degree. The Small Nuclear Rocket Engine, or SNRE, was designed at the Los Alamos National Laboratory (LANL) for upper stage use, both on unmanned launchers as well as the Space Shuttle. It featured a split-nozzle that could be rotated to the side, allowing it to take up less room in the Shuttle cargo bay. The design provided 73 kN of thrust and operated at a specific impulse of 875 seconds (8.58 kN·s/kg), and it was planned to increase this to 975 with fairly basic upgrades. This allowed it to achieve a mass fraction of about 0.74, comparing with 0.86 for the SSME, one of the best conventional engines.
A related design that saw some work, but never made it to the prototype stage, was Dumbo. Dumbo was similar to KIWI/NERVA in concept, but used more advanced construction techniques to lower the weight of the reactor. The Dumbo reactor consisted of several large barrel-like tubes which were in turn constructed of stacked plates of corrugated material. The corrugations were lined up so that the resulting stack had channels running from the inside to the outside. Some of these channels were filled with uranium fuel, others with a moderator, and some were left open as a gas channel. Hydrogen was pumped into the middle of the tube, and would be heated by the fuel as it travelled through the channels as it worked its way to the outside. The resulting system was lighter than a conventional design for any particular amount of fuel. The project developed some initial reactor designs and appeared to be feasible.
Between 1987 and 1991 an advanced engine design was studied under Project Timberwind, under the aegis of the Strategic Defense Initiative ("Star Wars"), which was later expanded into a larger design in the Space Thermal Nuclear Propulsion (STNP) program. Advances in high-temperature metals, computer modelling and nuclear engineering in general resulted in dramatically improved performance. While the NERVA engine was projected to weigh about 6,803 kg, the final STNP offered just over 1/3 the thrust from an engine of only 1,650 kg by improving the Isp to between 930 and 1000 seconds.
In January 2012, the propulsion group for Project Icarus began a technology development project, known as Project Bifrost, under the auspices of Icarus Interstellar and General Propulsion Sciences, to develop an NTR propulsion system, initially aimed at interplanetary missions.
Test firings.
KIWI was the first to be fired, starting in July 1959 with KIWI 1. The reactor was not intended for flight, hence the naming of the rocket after a flightless bird. This was unlike later tests because the engine design could not really be used; the core was simply a stack of uncoated uranium oxide plates onto which the hydrogen was dumped. Nevertheless it generated 70 MW and produced an exhaust temperature of 2683 K. Two additional tests of the basic concept, A' and A3, added coatings to the plates to test fuel rod concepts.
The KIWI B series fully developed the fuel system, which consisted of the uranium fuel in the form of tiny uranium dioxide (UO2) spheres embedded in a low-boron graphite matrix, and then coated with niobium carbide. Nineteen holes ran the length of the bundles, and through these holes the liquid hydrogen flowed for cooling. A final change introduced during the KIWI program changed the fuel to uranium carbide, which was run for the last time in 1964.
On the initial firings immense reactor heat and vibration cracked the fuel bundles. Likewise, while the graphite materials used in the reactor's construction were indeed resistant to high temperatures, they eroded under the heat and pressure of the enormous stream of superheated hydrogen. The fuel bundle problem was largely (but not completely) solved by the end of the program, and related materials work at Argonne National Laboratory looked promising. Fuel and engine coatings never wholly solved this problem before the program ended.
Building on the KIWI series, the Phoebus series were much larger reactors. The first 1A test in June 1965 ran for over 10 minutes at 1090 MW, with an exhaust temperature of 2370 K. The B run in February 1967 improved this to 1500 MW for 30 minutes. The final 2A test in June 1968 ran for over 12 minutes at 4,000 MW, at the time the most powerful nuclear reactor ever built. In contrast, the Itaipu Dam, one of the most powerful hydroelectric plants in the world, produces 14,000 MW, enough to supply 19% of all the electricity used in Brazil, and 90% of that used in Paraguay.
NERVA NRX (Nuclear Rocket Experimental), started testing in September 1964. The final engine in this series was the XE, designed with flight design hardware and fired in a downward position into a low-pressure chamber to simulate a vacuum. SNPO fired NERVA NRX/XE twenty-eight times in March 1968. The series all generated 1100 MW, and many of the tests concluded only when the test-stand ran out of hydrogen propellant. NERVA NRX/XE produced the baseline 75,000 lbf (334 kN) thrust that Marshall required in Mars mission plans.
A smaller version of KIWI, the Pewee was also built. It was fired several times at 500 MW in order to test coatings made of zirconium carbide (instead of niobium carbide) but Pewee also increased the power density of the system. An unrelated water-cooled system known as NF-1 (for "Nuclear Furnace") was used for future materials testing. Pewee became the basis for current NTR designs being researched at NASA's Glenn and Marshall Research Centers.
The last NRX firing lost a relatively small 38 lb of fuel in 2 hours of testing, enough to be judged sufficient for space missions by SNPO. Pewee 2's fuel elements reduced fuel corrosion still further, by a factor of 3 in Nuclear Furnace testing, but Pewee 2 was never tested on the stand. Later designs were deemed by NASA to be usable for space exploration and Los Alamos felt that it had cured the last of the materials problems with the untested Pewee.
The NERVA/Rover project was eventually cancelled in 1972 with the general wind-down of NASA in the post-Apollo era. Without a manned mission to Mars, the need for a nuclear thermal rocket was unclear. To a lesser extent it was becoming clear that there could be intense public outcry against any attempt to use a nuclear engine.
Nuclear vs. chemical.
Directly comparing the performance of a nuclear engine and a chemical one is not easy; the design of any rocket is a study in compromises and different ideas of what constitutes "better". The outline considers the NERVA-derived engine proposed by NASA in the 1960s, comparing it with the S-IVB stage from the Saturn it was intended to replace.
For any given thrust, the amount of power that needs to be generated is defined by formula_1, where "T" is the thrust and formula_2 is the exhaust velocity. formula_2 can be calculated from the specific impulse, "I"sp, where formula_4 (when "I"sp is in seconds and "g""n" is the standard, not local, acceleration of gravity), Using the J-2 on the S-IVB as a baseline design, we have "P" = (1014 kN)(414 s)(9.81 m/s2)/2 = 2,060 MW, or about the amount generated in a large nuclear reactor.
However, as outlined above, even the simple solid-core design provided a large increase in "I"sp to about 850 seconds. Using the formula above, we can calculate the amount of power that needs to be generated, at least given extremely efficient heat transfer: "P" = (1014 kN)(850 s * 9.81 m/s2)/2 = 4,227 MW. The "I"sp improvement demands higher energy. Given inefficiencies in the heat transfer, the actual NERVA designs were planned to produce about 5 GW, which would make them the most powerful nuclear reactors in the world.
The fuel flow for any given thrust level can be found from formula_5. For the J-2, this is "m" = 1014 kN/(414 * 9.81), or about 250 kg/s. For the NERVA replacement considered above, this fuel flow would be 121 kg/s. The mass of hydrogen is much lower than the hydrogen/oxygen mix in the J-2, where only about 1/6 of the mass is hydrogen. Since liquid hydrogen has a density of about 70 kg/m³, this represents a flow of about 1,725 litres per second, about three times that of the J-2. This requires additional plumbing but is by no means a serious problem; the famed F-1 had flow rates on the order of 2,500 l/s.
Finally, one must consider the design of the stage as a whole. The S-IVB carried just over 300,000 litres of fuel; 229,000 litres of liquid hydrogen (17,300 kg), and 72,700 litres of liquid oxygen (86,600 kg). The S-IVB uses a common bulkhead between the tanks, so removing it to produce a single larger tank would increase the total load only slightly. A new hydrogen-only nuclear stage would thus carry just over 300,000 litres in total (300 m³), or about 21,300 kg (47,000 lb). At 1,725 litres per second, this is a burn time of only 175 seconds, compared to about 500 in the original S-IVB (although some of this is at a lower power setting).
The total change in velocity, the so-called delta-"v", can be found from the rocket equation, which is based on the starting and ending masses of the stage:
Where formula_7 is the initial mass with fuel, formula_8 the final mass without it, and "V""e" is as above. The total empty mass of the J-2 powered S-IVB was 13,311 kg, of which about 1,600 kg was the J-2 engine. Removing the inter-tank bulkhead to improve hydrogen storage would likely lighten this somewhat, perhaps to 10,500 kg for the tankage alone. The baseline NERVA designs were about 15,000 lb, or 6,800 kg, making the total unfueled mass (formula_8) of a "drop-in" S-IVB replacement around 17,300 kg. The lighter weight of the fuel more than makes up for the increase in engine weight; whereas the fueled mass (formula_7) of the original S-IVB was 119,900 kg, for the nuclear-powered version this drops to only 38,600 kg.
Following the formula above, this means the J-2 powered version generates a Δ"v" of (414 s * 9.81) ln(119,900/13,311), or 8,900 m/s. The nuclear-powered version assumed above would be (850*9.81) ln(38,600/17,300), or 6,700 m/s. This drop in overall performance is due largely to the much higher "burnout" weight of the engine, and to smaller burn time due to the less-dense fuel. As a drop-in replacement, then, the nuclear engine does not seem to offer any advantages.
However, this simple examination ignores several important issues. For one, the new stage weighs considerably less than the older one, which means that the lower stages below it will leave the new upper stage at a higher velocity. This alone will make up for much of the difference in performance. More importantly, the comparison assumes that the stage would otherwise remain the same design overall. This is a bad assumption; one generally makes the upper stages as large as they can be given the throw-weight of the stages below them. In this case one would not make a drop-in version of the S-IVB, but a larger stage whose overall "weight" was the same as the S-IVB.
Following that line of reasoning, we can envision a replacement S-IVB stage that weighs 119,900 kg fully fueled, which would require much larger tanks. Assuming that the tankage mass triples, we have a "m"1 of 31,500 + 6,800 = 38,300 kg, and since we have fixed formula_7 at 119,900 kg, we get
Δ"v" = (850 s*9.81) ln(119,900/38,300), or 9,500 m/s. Thus, given the same mass as the original S-IVB, one can expect a moderate increase in overall performance using a nuclear engine. This stage would be about the same size as the S-II stage used on the Saturn.
Of course this increase in tankage might not be easy to arrange. NASA actually considered a new S-IVB replacement, the S-N, built to be as physically large as possible while still being able to be built in the VAB. It weighed only 10,429 kg empty and 53,694 kg fueled (suggesting that structural loading is the dominant factor in stage mass, not the tankage). The combination of lower weight and higher performance improved the payload of the Saturn V as a whole from 127,000 kg delivered to low earth orbit (LEO) to 155,000 kg.
It is also worth considering the improvement in stage performance using the more advanced engine from the SNTP program. Using the same S-IVB baseline, which does make sense in this case due to the lower thrust, we have an unfueled weight (formula_8) of 10,500 + 1,650 = 12,150 kg, and a fueled mass (formula_7) of 22,750 + 12,150 = 34,900 kg. Putting these numbers into the same formula we get a Δ"v" of just over 10,000 m/s—remember, this is from the smaller S-IV-sized stage. Even with the lower thrust, the stage also has a thrust-to-weight ratio similar to the original S-IVB, 34,900 kg being pushed by 350 kN (10.0 N/kg or 1.02 lbf/lb), as opposed to 114,759 kg pushed by 1,112 kN (9.7 N/kg or 0.99 lbf/lb). The STNP-based S-IVB would indeed be a "drop-in replacement" for the original S-IVB, offering higher performance from much lower weight.
In summation, NASA's current reasoning is that a NPR can be developed that would be twice as efficient as its chemical counterpart, though it is likely such an engine would only be used beyond the Earth's atmosphere.
Risks.
An atmospheric or orbital rocket failure could result in the dispersal of radioactive material into the environment. A collision with orbital debris, material failure due to uncontrolled fission, material imperfections or fatigue, or human design flaws could cause a containment breach of the fissile material. Such a catastrophic failure while in flight could release radioactive material over the Earth in a wide and unpredictable area. The amount of contamination would depend on the size of the nuclear thermal rocket engine, while the zone of contamination and its concentration would be dependent on prevailing weather conditions and orbital parameters at the time of re-entry. 
It is unlikely that a reactor's fuel elements would be spread over a wide area because the fuel elements in solid-core nuclear thermal rockets are designed to withstand very high temperatures (up to 3500K) and high pressures (up to 200 atm): they are composed of very strong materials such as carbon composites or carbides and are normally coated with zirconium hydride. Conventionally, the solid core NTR fuel itself is a small percentage of U-235 buried well inside an extremely strong carbon or carbide mixture. The radioactivity of these elements is quite low and would pose a minimal hazard unless the physically small reactors have been run for an extended period.
Kiwi-TNT.
In January 1965, the U.S. Rover program purposely placed a Kiwi Reactor (KIWI-TNT) on "fast excursion" to simulate a worst-case scenario of a fall from altitude into the ocean such as might occur in a booster failure after launch. The rocket was positioned on a railroad car in the Jackass Flats area of the Nevada Test Site, with the reactor specially modified so as to go prompt critical. 
The radiation released would have caused fatalities out to 600 feet and injuries out to 2000 feet.
Current solid-core nuclear thermal rocket designs may greatly limit the dispersion and break-up of potentially radioactive fuel elements and thereby confine the overall hazard from the elements to near the launch site and reduce it to a level that would be lower than the many open-air nuclear weapons tests of the 1950s.
Current research.
At its Marshall Space Flight Center, NASA is (in 2013) simulating nuclear thermal rocket fuels with the interim goal of developing a Nuclear Cryogenic Propulsion Stage in support of the Space Launch System. The project could see rocket stages twice as efficient as their chemical counterparts propelling crewed missions to the Moon, Mars and beyond.

</doc>
<doc id="37843" url="http://en.wikipedia.org/wiki?curid=37843" title="Nuclear electric rocket">
Nuclear electric rocket

Also known as nuclear electric propulsion and space nuclear fission electric power systems, in a nuclear electric rocket, nuclear thermal energy is changed into electrical energy that is used to power one of the electrical propulsion technologies. Technically the powerplant is nuclear, not the propulsion system, but the terminology is standard. A number of heat-to-electricity schemes have been proposed: Rankine cycle, Brayton cycle, Stirling cycle, thermoelectric (including graphene-based thermal power conversion), pyroelectric, thermophotovoltaic, thermionic and magnetohydrodynamic type thermoelectric materials.
Possible uses.
One of the more practical schemes is a variant of a pebble bed reactor. It would use a high mass-flow nitrogen coolant near normal atmospheric pressures. This would take advantage of highly developed conventional gas turbine technologies. The fuel for this reactor would be highly enriched, and encapsulated in low-boron graphite balls probably 5–10 cm in diameter. The graphite serves to slow, or moderate, the neutrons.
This style of reactor can be designed to be inherently safe. As it heats, the graphite expands, separating the fuel and reducing the reactor's criticality. This property can simplify the operating controls to a single valve throttling the turbine. When closed, the reactor heats, but produces less power. When open, the reactor cools, but becomes more critical and produces more power.
The graphite encapsulation simplifies refueling and waste handling. Graphite is mechanically strong, and resists high temperatures. This reduces the risk of an unplanned release of radioactives.
Since this style of reactor produces high power without heavy castings to contain high pressures, it is well suited to power spacecraft.
Research.
Research in nuclear propulsion began with studies for nuclear thermal propulsion, where the reactor heated a propellant (usually hydrogen) that was allowed to expand through a nozzle. This was essentially an ordinary chemical rocket with the nuclear reaction replacing chemical combustion as the rocket's heat source. Because the reactor could supply more heat to the propellant than chemical combustion, higher exhaust velocities, i.e., higher specific impulses were possible. See KIWI, NERVA. The reports at the time (and since) indicated that keeping the system light would require high temperature, densely packed designs, such as fast metal cooled reactors or hexagonal pin fueled, high temperature gas cooled reactors. In the past several decades the attention has turned to using the nuclear reactor to drive a turbine to produce electricity, which is used to create a plasma which is accelerated. See Project Prometheus. The present best of tech is the SAFE-400, which uses a 400 kW thermal reactor and a gas turbine (called a closed Brayton cycle) to produce electric power. Heat rejection is kept low-mass using advanced heat pipe systems (such as are now used in some laptop computers for cooling as well). Safety comes from ruggedness, proper shielding, control pins and spoiler pins inside the reactor which arrest the reaction.
The key elements to NEP, as they are being pursued today are:
The SAFE-400 is the current best of tech for items 1-3. Item 4 is common to all spacecraft. Some examples of thrusters that might be suitable for this are VASIMR, DS4G and Pulsed inductive thruster. PIT and VASIMR are unique in their ability to trade between power usage, specific impulse (a measure of efficiency, see specific impulse) and thrust in-flight. PIT has the additional advantage of not needing the power conditioning system between itself and the electric generators.
Other types of nuclear power in space.
Nuclear electric propulsion is a field that is distinct from other space nuclear power areas, such as radioisotope systems (including radioisotope thermoelectric generators, radioisotope heater units, radioisotope piezoelectric generators & the radioisotope rocket - all of which use the heat from a static radioactive source (usually Plutonium-238) for a low level of electric or direct propulsion power), a nuclear thermal rocket (energy is used to heat the liquid hydrogen propellant), direct nuclear (fission products from a nuclear reaction directly propel the rocket), nuclear pulse propulsion (nuclear explosions propel the rocket), or space based nuclear fusion systems, either a fusion rocket, or some as-yet theoretical or unproven experimental fusion technology.

</doc>
<doc id="37844" url="http://en.wikipedia.org/wiki?curid=37844" title="Mass driver">
Mass driver

A mass driver or electromagnetic catapult is a proposed method of non-rocket spacelaunch which would use a linear motor to accelerate and catapult payloads up to high speeds. All existing and contemplated mass drivers use coils of wire energized by electricity to make electromagnets. Sequential firing of a row of electromagnets accelerates the payload along a path. After leaving the path, the payload continues to move due to momentum (at constant velocity, assuming lack of friction with the environment).
Although any device used to propel a ballistic payload is technically a mass driver, in this context a mass driver is essentially a coilgun that magnetically accelerates a package consisting of a magnetizable holder containing a payload. Once the payload has been accelerated, the two separate, and the holder is slowed and recycled for another payload.
Mass drivers can be used to propel spacecraft in three different ways: A large, ground-based mass driver could be used to launch spacecraft away from Earth, the Moon, or another body. A small mass driver could be on board a spacecraft, flinging pieces of material into space to propel itself. Another variation would have a massive facility on a moon or asteroid send projectiles to assist a distant craft.
Miniaturized mass drivers can also be used as weapons in a similar manner as classic firearms or cannon using chemical combustion. Hybrids between coilguns and railguns such as helical railguns are also possible.
Fixed mass drivers.
Mass drivers need no physical contact between moving parts due to the projectile being guided by dynamic magnetic levitation, allowing extreme reusability in the case of solid-state power switching, a life of theoretically up to millions of launches. While marginal costs tend to be accordingly low, initial development and construction costs are highly dependent on performance, especially the intended mass, acceleration, and velocity of projectiles. For instance, while Gerard O'Neill built his first mass driver in 1976–77 with a $2000 budget, a short test model firing a projectile at 40 m/s and 33 g, his next model was an order of magnitude greater acceleration after a comparable increase in funding, and, a few years later, the University of Texas estimated that a mass driver firing a 10 kilogram projectile at 6000 m/s would cost $47 million.
For a given amount of energy involved, heavier objects go proportionally slower. Light objects may be projected at 20 km/s or more. The limits are generally the expense of energy storage able to be discharged quickly enough and the cost of power switching, which may be by semiconductors or by gas-phase switches (which still often have a niche in extreme pulse power applications). However, energy can be stored inductively in superconducting coils. A 1 km long mass driver made of superconducting coils can accelerate a 20 kg vehicle to 10.5 km/s at a conversion efficiency of 80%, and average acceleration of 5,600 g.
Earth-based mass drivers for propelling vehicles to orbit, such as the StarTram concept, would require large capital investment.
The Earth's strong gravity and thick atmosphere make such an installation difficult, thus many proposals have been put forward to install mass drivers on the moon where the lower gravity and lack of atmosphere greatly reduces the required velocity to reach lunar orbit.
Most serious mass driver designs use superconducting coils to achieve reasonable energetic efficiency (often 50% to 90+%, depending on design). Methods include a superconducting bucket or aluminum coil as the payload. The coils of a mass-driver can induce eddy currents in a payload's aluminum coil, and then act on the resulting magnetic field. There are two sections of a mass-driver. The maximum acceleration part spaces the coils at constant distances, and synchronize the coil currents to the bucket. In this section, the acceleration increases as the velocity increases, up to the maximum that the bucket can take. After that, the constant acceleration region begins. This region spaces the coils at increasing distances to give a fixed amount of velocity increase per unit of time.
In this mode, a major proposal for use of mass-drivers was to transport lunar surface material to space habitats so that it could be processed using solar energy. The Space Studies Institute showed that this application was reasonably practical.
In some designs, the payload would be held in a bucket and then released, so that the bucket can be decelerated and reused. A disposable bucket, on the other hand, would avail acceleration along the whole track.
On Earth.
In contrast to cargo-only chemical space gun concepts, a mass driver could be any length, affordable, and with relatively smooth acceleration throughout, optionally even lengthy enough to reach target velocity without excessive g forces for passengers. It can be constructed as a very long and mainly horizontally aligned launch track for spacelaunch, targeted upwards at the end, partly by bending of the track upwards and partly by Earth's curvature in the other direction.
Natural elevations, such as mountains, may facilitate the construction of the distant, upwardly targeted part. The higher up the track terminates, the less resistance from the atmosphere the launched object will receive.
The 40 megajoules per kilogram or less kinetic energy of projectiles launched at up to 9000 m/s velocity (if including extra for drag losses) towards Low Earth Orbit is a few kilowatt-hours per kilogram if efficiencies are relatively high, which accordingly has been hypothesized to be under $1 of electrical energy cost per kilogram shipped to LEO, though total costs would be far more than electricity alone. By being mainly located slightly above, on or beneath the ground, a mass driver may be easier to maintain compared with many other structures of non-rocket spacelaunch. Whether or not underground, it needs to be housed in a pipe that is vacuum pumped in order to prevent internal air drag, such as with a mechanical shutter kept closed most of the time but a plasma window used during the moments of firing to prevent loss of vacuum.
A mass driver on Earth would usually be a compromise system. A mass driver would accelerate a payload up to some high speed which would not be enough for orbit. It would then release the payload, which would complete the launch with rockets. This would drastically reduce the amount of velocity needed to be provided by rockets to reach orbit. Well under a tenth of orbital velocity from a small rocket thruster is enough to raise perigee if a design prioritizes minimizing such, but hybrid proposals optionally reduce requirements for the mass driver itself by having a greater portion of delta-v by a rocket burn (or orbital momentum exchange tether). On Earth, a mass driver design could possibly use well-tested maglev components.
To launch a space vehicle with humans on board, a mass driver's track would need to be several hundreds of kilometers long if providing almost all the velocity to Low Earth Orbit, though lesser length can provide major launch assist. Required length, if accelerating mainly at near a constant maximum acceptable g-force for passengers, is proportional to velocity squared. For instance, half of the velocity goal could correspond to a quarter as long of a tunnel needing to be constructed, for the same acceleration. For rugged objects, much higher accelerations may suffice, allowing a far shorter track, potentially circular or helical (spiral). Another concept is a large ring design whereby a space vehicle would circle the ring numerous times, gradually gaining speed, before being released into a launch corridor leading skyward.
Mass drivers have been proposed for space disposal of nuclear waste, where a projectile launched at much above Earth's escape velocity would escape the Solar System, with atmospheric passage at such speed calculated as survivable through an elongated projectile and very substantial heatshield.
Spacecraft-based mass drivers.
A spacecraft could carry a mass driver as its primary engine. With a suitable source of electrical power (probably a nuclear reactor) the spaceship could then use the mass driver to accelerate pieces of matter of almost any sort, boosting itself in the opposite direction. At the smallest scale of reaction mass, this type of drive is called an ion drive.
No absolute theoretical limit is known for the size, acceleration or muzzle energy of linear motors. However, practical engineering constraints apply for such as the power to mass ratio, waste heat dissipation, and the energy intake able to be supplied and handled. Exhaust velocity is best neither too low nor too high.
There is a mission-dependent limited optimal exhaust velocity and specific impulse for any thruster constrained by a limited amount of onboard spacecraft power. Thrust and momentum from exhaust, per unit mass expelled, scales up linearly with its velocity (momentum = mv), yet kinetic energy and energy input requirements scale up faster with velocity squared (kinetic energy =  1⁄2 mv2). Too low exhaust velocity would excessively increase propellant mass needed under the rocket equation, with too high a fraction of energy going into accelerating propellant not used yet. Higher exhaust velocity has both benefit and tradeoff, increasing propellant usage efficiency (more momentum per unit mass of propellant expelled) but decreasing thrust and the current rate of spacecraft acceleration if available input power is constant (less momentum per unit of energy given to propellant).
Electric propulsion methods like mass drivers are systems where energy does not come from the propellant itself. (Such contrasts to chemical rockets where propulsive efficiency varies with the ratio of exhaust velocity to vehicle velocity at the time, but near maximum obtainable specific impulse tends to be a design goal when corresponding to the most energy released from reacting propellants). Although the specific impulse of an electric thruster itself optionally could range up to where mass drivers merge into particle accelerators with fractional-lightspeed exhaust velocity for tiny particles, trying to use extreme exhaust velocity to accelerate a far slower spacecraft could be suboptimally low thrust when the energy available from a spacecraft's reactor or power source is limited (a lesser analogue of feeding onboard power to a row of spotlights, photons being an example of an extremely low momentum to energy ratio).
For instance, if limited onboard power fed to its engine was the dominant limitation on how much payload a hypothetical spacecraft could shuttle (such as if intrinsic propellant economic cost was minor from usage of extraterrestrial soil or ice), ideal exhaust velocity would rather be around 62.75% of total mission delta v if operating at constant specific impulse, except greater optimization could come from varying exhaust velocity during the mission profile (as possible with some thruster types, including mass drivers and variable specific impulse magnetoplasma rockets).
Since a mass driver could use any type of mass for reaction mass to move the spacecraft, a mass driver or some variation seems ideal for deep-space vehicles that scavenge reaction mass from found resources.
One possible drawback of the mass driver is that it has the potential to send solid reaction mass travelling at dangerously high relative speeds into useful orbits and traffic lanes. To overcome this problem, most schemes plan to throw finely-divided dust. Alternatively, liquid oxygen could be used as reaction mass, which upon release would boil down to its molecular state. Propelling the reaction mass to solar escape velocity is another way to ensure that it will not remain a hazard.
Hybrid mass drivers.
A mass driver on a spacecraft could be used to "reflect" masses from a stationary mass driver. Each deceleration and acceleration of the mass contributes to the momentum of the spacecraft. The lightweight, fast spacecraft need not carry reaction mass, and does not need much electricity beyond the amount needed to replace losses in the electronics, while the immobile support facility can run off power plants able to be much larger than the spacecraft if needed. This could be considered a form of beam-powered propulsion (a macroscopic-scale analogue of a particle beam propelled magsail). A similar system could also deliver pellets of fuel to a spacecraft to power another propulsion system.
Another theoretical use for this concept of propulsion can be found in space fountains, a system in which a continuous stream of pellets in a circular track holds up a tall structure.
Mass drivers as weapons.
Small to moderate size high-acceleration electromagnetic projectile launchers are currently undergoing active research by the US Navy for use as ground-based or ship-based weapons (most often railguns but coilguns in some cases). On larger scale than weapons currently near deployment but sometimes suggested in long-range future projections, a sufficiently high velocity linear motor, a mass driver, could in principle be used as intercontinental artillery (or, if built on the Moon or in orbit, used to attack a location on Earth's surface). As the mass driver would be located further up the gravity well than the theoretical targets, it would enjoy a significant energy imbalance in terms of counter-attack.
Practical attempts.
One of the first engineering descriptions of an "Electric Gun" appears in the technical supplement of "Zero to Eighty" by "Akkad Pseudoman", a pen name for the Princeton physicist and electrical entrepreneur Edwin Fitch Northrup. Dr. Northrup built prototype coil guns powered by kHz-frequency three phase electrical generators, and the book contains photographs of some of these prototypes. The book describes a fictional circumnavigation of the moon by a two-person vehicle launched by a Northrup electric gun.
Later prototype mass drivers have been built since 1976 (Mass Driver 1), some constructed by the U.S. Space Studies Institute in order to prove their properties and practicality. Military R&D on coilguns is related, as are also maglev trains.

</doc>
<doc id="37845" url="http://en.wikipedia.org/wiki?curid=37845" title="Magnetic sail">
Magnetic sail

A magnetic sail or magsail is a proposed method of spacecraft propulsion which would use a static magnetic field to deflect charged particles radiated by the Sun as a plasma wind, and thus impart momentum to accelerate the spacecraft. A magnetic sail could also thrust directly against planetary and solar magnetospheres.
History.
The magnetic sail was invented by Dana Andrews and Robert Zubrin working in collaboration in 1988. At that time, Andrews was working on a concept to use a magnetic scoop to gather ions to provide propellant for a nuclear electric ion drive spacecraft, allowing the craft to operate in the same manner of a Bussard ramjet, but without the need for a proton-proton fusion propulsion drive. He asked Zubrin to help him compute the drag that the magnetic scoop would create against the interplanetary medium. Zubrin agreed, but found that the drag created by the scoop would be much greater than the thrust created by the ion drive. He therefore proposed that the ion drive component of the system be dropped, and the device simply used as a sail. Andrews agreed, and the magsail was born. The two then proceeded to elaborate their analysis of the magsail for interplanetary, interstellar, and planetary orbital propulsion in a series of papers published from 1988 through the 1990s.
Principles of operation and design.
The "magsail" operates by creating drag against the local medium (planet's magnetic field, solar wind, or interstellar winds), thereby allowing a spacecraft accelerated to very high velocities by other means, such as a fusion rocket or laser pushed lightsail, to slow down - even from relativistic velocities - without requiring the use of onboard propellant. It can thus reduce the delta-V propulsion required for an interstellar mission by a factor of two. This capability is the most unique feature of the magsail, and perhaps the most significant in the long term.
In typical magnetic sail designs, the magnetic field is generated by a loop of superconducting wire. Because loops of current-carrying conductors tend to be forced outwards towards a circular shape by their own magnetic field, the sail could be deployed simply by unspooling the conductor and applying a current through it.
Solar wind example.
The solar wind is a continuous stream of plasma that flows outwards from the Sun: near the Earth's orbit, it contains several million protons and electrons per cubic meter and flows at 400 to. The magnetic sail introduces a magnetic field into this plasma flow which can deflect the particles from their original trajectory: the momentum of the particles is then transferred to the sail, leading to a thrust on the sail. One advantage of magnetic or solar sails over (chemical or ion) reaction thrusters is that no reaction mass is depleted or carried in the craft.
For a sail in the solar wind one AU away from the Sun, the field strength required to resist the dynamic pressure of the solar wind is 50 nT. Zubrin's proposed magnetic sail design would create a bubble of space of 100 km where solar-wind ions are substantially deflected using a hoop 50 km in radius. The minimum mass of such a coil is constrained by material strength limitations at roughly 40 tonne and it would generate 70 N of thrust, giving a mass/thrust ratio of 600 kg/N. If operated within the solar system, high temperature superconducting wire would be required to make the magsail practical. If operated in interstellar space conventional superconductors would be adequate.
The operation of magnetic sails using plasma wind is analogous to the operation of solar sails using the radiation pressure of photons emitted by the Sun. Although solar wind particles have rest mass and photons do not, sunlight has thousands of times more momentum than the solar wind. Therefore, a magnetic sail must deflect a proportionally larger area of the solar wind than a comparable solar sail to generate the same amount of thrust. However, it need not be as massive as a solar sail because the solar wind is deflected by a magnetic field instead of a large physical sail. Conventional materials for solar sails weigh around 7 g/m2, giving a thrust of 0.01 mPa at 1 AU. This gives a mass/thrust ratio of at least 700 kg/N, similar to a magnetic sail, neglecting other structural components.
The solar and magnetic sails have a thrust that falls off as the square of the distance from the Sun.
When close to a planet with a strong magnetosphere such as Earth or a gas giant, the magnetic sail could generate more thrust by interacting with the magnetosphere instead of the solar wind, and may therefore be more efficient.
Mini-magnetospheric plasma propulsion (M2P2).
In order to reduce the size and weight of the magnet of the magnetic sail, it may be possible to "inflate" the magnetic field using a plasma in the same way that the plasma around the Earth stretches out the Earth's magnetic field in the magnetosphere. In this approach, called mini-magnetospheric plasma propulsion (M2P2), currents that run through the plasma will augment and partially replace the currents in the coil. This is expected to be especially useful far from the Sun, where the increased effective size of a M2P2 sail compensates for the reduced dynamic pressure of the solar wind. The original NASA design proposes a spacecraft containing a can-shaped electromagnet into which a plasma is injected. The plasma pressure stretches the magnetic field and inflates a bubble of plasma around the spacecraft. The plasma then generates a kind of miniaturized magnetosphere around the spacecraft, analogous to the magnetosphere that surrounds the Earth. The protons and electrons which make up the solar wind are deflected by this magnetosphere and the reaction accelerates the spacecraft. The thrust of the M2P2 device would be steerable to some extent, potentially allowing the spacecraft to 'tack' into the solar wind and allowing efficient changes of orbit.
In the case of the (M2P2) system the spacecraft releases gas to create the plasma needed to maintain the somewhat leaky plasma bubble. The M2P2 system therefore has an effective "specific impulse" which is the amount of gas consumed per newton second of thrust. This is a figure of merit usually used for rockets, where the fuel is actually reaction mass. Robert Winglee, who originally proposed the M2P2 technique, calculates a "specific impulse" of 200 kN·s/kg (roughly 50 times better than the space shuttle main engine). These calculations suggest that the system requires on the order of a kilowatt of power per newton of thrust, considerably lower than electric thrusters, and that the system generates the same thrust anywhere within the heliopause because the sail spreads automatically as the solar wind becomes less dense. However, this technique is less understood than the simpler magnetic sail and issues of how large and heavy the magnetic coil would have to be or whether the momentum from the solar wind can be efficiently transferred to the spacecraft are under dispute.
The expansion of the magnetic field using plasma injected has been successfully tested in a large vacuum chamber on Earth, but the development of thrust was not part of the experiment. A beam-powered variant, MagBeam, is also under development.
Modes of operation.
In a plasma wind.
When operating away from planetary magnetospheres, a magnetic sail would force the positively charged protons of the solar wind to curve as they passed through the magnetic field. The change of momentum of the protons would thrust against the magnetic field, and thus against the field coil.
Just as with solar sails, magnetic sails can "tack." If a magnetic sail orients at an angle relative to the solar wind, charged particles are deflected preferentially to one side and the magnetic sail is pushed laterally. This means that magnetic sails could maneuver to most orbits.
In this mode, the amount of thrust generated by a magnetic sail falls off with the square of its distance from the Sun as the flux density of charged particles reduces. Solar weather also has major effects on the sail. It is possible that the plasma eruption from a severe solar flare could damage an efficient, fragile sail.
A common misconception is that a magnetic sail cannot exceed the speed of the plasma pushing it. As the speed of a magnetic sail increases, its acceleration becomes more dependent on its ability to tack efficiently. At high speeds, the plasma wind's direction will seem to come increasingly from the front of the spacecraft. Advanced sailing spacecraft might deploy field coils as "keels," so the spacecraft could use the difference in vector between the solar magnetic field and the solar wind, much as sailing yachts do.
Inside a planetary magnetosphere.
Inside a planetary magnetosphere, a magnetic sail can thrust against a planet's magnetic field, especially in an orbit that passes over the planet's magnetic poles, in a similar manner to an electrodynamic tether.
The range of maneuvers available to a magnetic sail inside a planetary magnetosphere are more limited than in a plasma wind. Just as with the more familiar small-scale magnets used on Earth, a magnetic sail can only be attracted towards the magnetosphere's poles or repelled from them, depending on its orientation.
When the magnetic sail's field is oriented in the opposite direction to the magnetosphere it experiences a force inward and toward the nearest pole, and when it is oriented in the same direction as the magnetosphere it experiences the opposite effect. A magnetic sail oriented in the same direction as the magnetosphere is not stable, and will have to prevent itself from being flipped over to the opposite orientation by some other means.
The thrust that a magnetic sail delivers within a magnetosphere decreases with the fourth power of its distance from the planet's internal magnetic dynamo.
This limited maneuvering capability is still quite useful. By varying the magnetic sail's field strength over the course of its orbit, a magnetic sail can give itself a "perigee kick" raising the altitude of its orbit's apogee.
Repeating this process with each orbit can drive the magnetic sail's apogee higher and higher, until the magnetic sail is able to leave the planetary magnetosphere and catch the solar wind. The same process in reverse can be used to lower or circularize the apogee of a magsail's orbit when it arrives at a destination planet.
In theory, it is possible for a magnetic sail to launch directly from the surface of a planet near one of its magnetic poles, repelling itself from the planet's magnetic field. However, this requires the magnetic sail to be maintained in its "unstable" orientation. A launch from Earth requires superconductors with 80 times the current density of the best known high-temperature superconductors.
Interstellar travel.
Interstellar space contains very small amounts of hydrogen. A fast-moving sail would ionize this hydrogen by accelerating the electrons in one direction and the oppositely charged protons in the other direction. The energy for the ionization and cyclotron radiation would come from the spacecraft's kinetic energy, slowing the spacecraft. The cyclotron radiation from the acceleration of particles would be an easily detected howl in radio frequencies.
Thus, in interstellar spaceflight outside the heliopause of a star a magnetic sail could act as a parachute to decelerate a spacecraft. This removes any fuel requirements for the deceleration half of an interstellar journey, which would benefit interstellar travel enormously. The magsail was first proposed for this purpose in 1988 by Robert Zubrin and Dana Andrews, predating other uses, and evolved from a concept of the Bussard ramjet which used a magnetic scoop to collect interstellar material.
Magnetic sails could also be used with beam-powered propulsion by using a high-power particle accelerator to fire a beam of charged particles at the spacecraft. The magsail would deflect this beam, transferring momentum to the vehicle. This would provide much higher acceleration than a solar sail driven by a laser, but a charged particle beam would disperse in a shorter distance than a laser due to the electrostatic repulsion of its component particles. This dispersion problem could potentially be resolved by accelerating a stream of sails which then in turn transfer their momentum to a magsail vehicle, as proposed by Jordin Kare.
Fictional uses.
The ancestor of the magsail, the Bussard magnetic scoop, first appeared in science-fiction in Poul Anderson's 1967 short story "To Outlive Eternity", which was followed by the novel "Tau Zero" in 1970. The magsail appears as a crucial plot device in "The Children's Hour", a "Man-Kzin Wars" novel by Jerry Pournelle and S.M. Stirling (1991). It also features prominently in the science-fiction novels of Michael Flynn, particularly in "The Wreck of the River of Stars" (2003); this book is the tale of the last flight of a magnetic sail ship when fusion rockets based on the Farnsworth-Hirsch Fusor have become the preferred technology.

</doc>
<doc id="37846" url="http://en.wikipedia.org/wiki?curid=37846" title="Gaseous fission reactor">
Gaseous fission reactor

A gas nuclear reactor (or "gas fueled reactor") is a nuclear reactor in which the nuclear fuel is in a gaseous state rather than liquid or solid. In this type of reactor, the only temperature-limiting materials are the reactor walls. Conventional reactors have stricter limitations because the core would melt if the fuel temperature were to rise too high. It may also be possible to confine gaseous fission fuel magnetically, electrostatically or electrodynamically so that it would not touch (and melt) the reactor walls. A potential benefit of the gaseous reactor core concept is that instead of relying on the traditional Rankine or Brayton conversion cycles, it may be possible to extract electricity magnetohydrodynamically, or with simple direct electrostatic conversion of the charged particles.
Theory of operation.
The vapor core reactor (VCR), also called a gas core reactor (GCR), has been studied for some time. It would have a gas or vapor core composed of UF4 with some 4He added to increase the electrical conductivity, the vapor core may also have tiny UF4 droplets in it. It has both terrestrial and space based applications. Since the space concept doesn't necessarily have to be economical in the traditional sense, it allows the enrichment to exceed what would be acceptable for a terrestrial system. It also allows for a higher ratio of UF4 to helium, which in the terrestrial version would be kept just high enough to ensure criticality in order to increase the efficiency of direct conversion. The terrestrial version is designed for a vapor core inlet temperature of about 1,500 K and exit temperature of 2,500 K and a UF4 to helium ratio of around 20% to 60%. It is thought that the outlet temperature could be raised to that of the 8,000 K to 15,000 K range where the exhaust would be a fission-generated non-equilibrium electron gas, which would be of much more importance for a rocket design. A terrestrial version of the VCR's flow schematic can be found in reference 2 and in the summary of non-classical nuclear systems in the second external link. The space based concept would be cut off at the end of the MHD channel.
Reasoning for He-4 addition.
4He may be used in increase the ability of the design to extract energy and be controlled. A few sentences from Anghaie et al. sheds light on the reasoning:
Spacecraft.
The spacecraft variant of the gaseous fission reactor is called the gas core reactor rocket. There are two approaches: the open and closed cycle. In the open cycle, the propellant, most likely hydrogen, is fed to the reactor, heated up by the nuclear reaction in the reactor, and exits out the other end. Unfortunately, the propellant will be contaminated by fuel and fission products, and although the problem can be mitigated by engineering the hydrodynamics within the reactor, it renders the rocket design completely unsuitable for use in atmosphere.
One might attempt to circumvent the problem by confining the fission fuel magnetically, in a manner similar to the fusion fuel in a tokamak. Unfortunately it is not likely that this arrangement will actually work to contain the fuel, since the ratio of ionization to particle momentum is not favourable. Whereas a tokamak would generally work to contain singly ionized deuterium or tritium with a mass of two or three daltons, the uranium vapour would be at most triply ionized with a mass of 235 dalton (unit). Since the force imparted by a magnetic field is proportional to the charge on the particle, and the acceleration is proportional to the force divided by the mass of the particle, the magnets required to contain uranium gas would be impractically large; most such designs have focused on fuel cycles that do not depend upon retaining the fuel in the reactor.
In the closed cycle, the reaction is entirely shielded from the propellant. The reaction is contained in a quartz vessel and the propellant merely flows outside of it, being heated in an indirect fashion. The closed cycle avoids contamination because the propellant can't enter the reactor itself, but the solution carries a significant penalty to the rocket's Isp.
Energy production.
For energy production purposes, one might use a container located inside a solenoid. The container is filled with gaseous uranium hexafluoride, where the uranium is enriched, to a level just short of criticality. Afterward, the uranium hexafluoride is compressed by external means, thus initiating a nuclear chain reaction and a great amount of heat, which in turn causes an expansion of the uranium hexafluoride. Since the UF6 is contained within the vessel, it can't escape and thus compresses elsewhere. The result is a plasma wave moving in the container, and the solenoid converts some of its energy into electricity at an efficiency level of about 20%. In addition, the container must be cooled, and one can extract energy from the coolant by passing it through a heat exchanger and turbine system as in an ordinary thermal power plant.
However, there are enormous problems with corrosion during this arrangement, as the uranium hexafluoride is chemically very reactive.

</doc>
<doc id="37849" url="http://en.wikipedia.org/wiki?curid=37849" title="Nuclear salt-water rocket">
Nuclear salt-water rocket

A nuclear salt-water rocket (or NSWR) is a proposed type of nuclear thermal rocket designed by Robert Zubrin that would be fueled by water bearing dissolved salts of plutonium or U235. These would be stored in tanks that would prevent a critical mass from forming by some combination of geometry or neutron absorption (for example: long tubes made out of boron in an array with considerable spacing between tubes). Thrust would be generated by nuclear fission reactions from the nuclear salts heating the water and being expelled through a nozzle. The water would serve as both a neutron moderator and propellant.
Design.
In a conventional chemical rocket, chemical reactions of the fuel and oxidizer (e.g. oxygen and kerosene) heat the by-products of the chemical reaction (e.g. CO2 and H2O) to high temperatures as they are forced through a rocket nozzle. The fast moving molecules in the exhaust focused in one direction create thrust. In a nuclear thermal rocket (or NTR) a nuclear fission reactor would serve as a source of heat which would be transferred to a propellant that is then exhausted through a rocket nozzle. The propellant in this case can be any material with suitable properties, it need not react during the operation of the rocket, it is simply a source of mass to be heated up and exhausted out of the rocket at high speeds. In an NSWR the nuclear salt-water would be made to flow through a reaction chamber and out an exhaust nozzle in such a way and at such speeds that the peak neutron flux in the fission reaction would occur outside the vehicle.
Advantages.
There are several advantages relative to conventional NTR designs. As the peak neutron flux and fission reaction rates would occur outside the vehicle, these activities could be much more vigorous than they could be if it was necessary to house them in a vessel (which would have temperature limits due to materials constraints). Additionally, a contained reactor can only allow a small percentage of its fuel to undergo fission at any given time, otherwise it would overheat and meltdown (or explode in a runaway fission chain reaction). The fission reaction in an NSWR is dynamic and because the reaction products are exhausted into space it doesn't have a limit on the proportion of fission fuel that reacts. In many ways this makes NSWRs like a hybrid between fission reactors and fission bombs.
Due to their ability to harness the power of what is essentially a continuous nuclear fission explosion, NSWRs would have both very high thrust and very high exhaust velocity, a rare combination of traits in the rocket world, meaning that the rocket would be able to accelerate quickly as well as be extremely efficient in terms of propellant usage. One design would generate 13 meganewtons of thrust at 66 km/s exhaust velocity (compared to ~4.5 km/s exhaust velocity for the best chemical rockets of today). Another design would achieve much higher exhaust velocities (4,700 km/s) and use 2,700 tonnes of highly enriched uranium salts in water to propel a 300 tonne spacecraft up to 3.6% of the speed of light.
NSWRs share many of the features of Orion propulsion systems, except that NSWRs would generate continuous rather than pulsed thrust and may be workable on much smaller scales than the smallest feasible Orion designs (which are generally large, due to the requirements of the shock-absorber system and the minimum size of efficient nuclear explosives) "
Limitations.
The vessel's exhaust would contain radioactive isotopes, but these would be rapidly dispersed after travelling only a short distance; the exhaust would also be travelling at high speed (in Zubrin's scenario, faster than Solar escape velocity, allowing it to eventually leave the Solar System). This is however, little use on the surface of a planet, where a NSWR would eject massive quantities of superheated steam, still containing fissioning nuclear salts. Terrestrial testing might be subject to reasonable objections; as one physicist wrote, "Writing the environmental impact statement for such tests [...] might present an interesting problem ..."
It is also not certain that fission in a NSWR could be controlled: "Whether fast criticality can be controlled in a rocket engine remains an open question.".

</doc>
<doc id="37850" url="http://en.wikipedia.org/wiki?curid=37850" title="Beam-powered propulsion">
Beam-powered propulsion

Beam-powered propulsion is a class of aircraft or spacecraft propulsion mechanisms that uses energy beamed to the spacecraft from a remote power plant to provide energy. Most designs are thermal rockets where the energy is provided by the beam, and is used to superheat propellant that then provides propulsion, although some obtain propulsion directly from light pressure acting on a light sail structure, and at low altitude heating air gives extra thrust.
The beam would typically either be a beam of microwaves or a laser. Lasers are subdivided into either pulsed or continuous beamed.
The rule of thumb that is usually quoted is that it takes a megawatt of power beamed to a vehicle per kg of payload while it is being accelerated to permit it to reach low earth orbit.
Other than launching to orbit, applications for moving around the world quickly have also been proposed.
Background.
Rockets are momentum machines; they use mass ejected from the rocket to provide momentum to the rocket. Momentum is the product of mass and velocity, so rockets generally attempt to put as much velocity into their working mass as possible, thereby minimizing the amount of working mass that is needed. In order to accelerate the working mass, energy is required. In a conventional rocket, the fuel is chemically combined to provide the energy, and the resulting fuel products, the ash or exhaust, are used as the working mass.
There is no particular reason why the same fuel has to be used for both energy and momentum. In the jet engine, for instance, the fuel is used only to produce energy, the working mass is provided from the air that the jet aircraft flies through. In modern jet engines, the amount of air propelled is much greater than the amount of air used for energy. This is not a solution for the rocket, however, as they quickly climb to altitudes where the air is too thin to be useful as a source of working mass.
Rockets can, however, carry their working mass and use some other source of energy. The problem is finding an energy source with a power-to-weight ratio that competes with chemical fuels. Small nuclear reactors can compete in this regard, and considerable work on nuclear thermal propulsion was carried out in the 1960s, but environmental concerns and rising costs led to the ending of most of these programs.
A further improvement can be made by removing the energy creation from the spacecraft. If the nuclear reactor is left on the ground and its energy transmitted to the spacecraft, the weight of the reactor is removed as well. The issue then is to get the energy into the spacecraft. This is the idea behind beamed power.
With beamed propulsion one can leave the power-source stationary on the ground, and directly (or via a heat exchanger) heat propellant on the spacecraft with a maser or a laser beam from a fixed installation. This permits the spacecraft to leave its power-source at home, saving significant amounts of mass, greatly improving performance.
Laser propulsion.
Since a laser can heat propellant to extremely high temperatures, this potentially greatly improves the efficiency of a rocket, as exhaust velocity is proportional to the square root of the temperature. Normal chemical rockets have an exhaust speed limited by the fixed amount of energy in the propellants, but beamed propulsion systems have no particular theoretical limit (although in practice there are temperature limits).
Microwave propulsion.
In addition, microwaves can be used to heat a suitable heat exchanger, which in turn heats a propellant (very typically hydrogen). This can give a combination of high specific impulse (700–900 seconds) as well as good thrust/weight ratio (50-150).
A variation, developed by brothers James Benford and Gregory Benford, is to use thermal desorption of propellant trapped in the material of a very large microwave-sail. This produces a very high acceleration compared to microwave pushed sails alone.
Electric propulsion.
Some proposed spacecraft propulsion mechanisms use power in the form of electricity. Usually these schemes assume either solar panels, or an on-board reactor. However, both power sources are heavy.
Beamed propulsion in the form of laser can be used to send power to a photovoltaic panel, for "Laser electric propulsion." In this system, careful design of the panels is necessary as the extra power tends to cause a fall-off of the conversion efficiency due to heating effects.
A microwave beam could be used to send power to a rectenna, for "microwave electric propulsion". Microwave broadcast power has been practically demonstrated several times (e.g. Goldstone, California in 1974), rectennas are potentially lightweight and can handle high power at high conversion efficiency. However, rectennas tend to need to be very large for a significant amount of power to be captured.
Direct impulse.
A beam could also be used to provide impulse by directly "pushing" on the sail.
One example of this would be using a solar sail to reflect a laser beam. This concept, called a "laser-pushed lightsail," was analyzed by physicist Robert L. Forward in 1989 as a method of Interstellar travel that would avoid extremely high mass ratios by not carrying fuel. His work elaborated on a proposal initially made by Marx. Further analysis of the concept was done by Landis, Mallove and Matloff, Andrews and others.
In a later paper, Forward proposed pushing a sail with a microwave beam. This has the advantage that the sail need not be a continuous surface. Forward tagged his proposal for an ultralight sail "Starwisp". A later analysis by Landis suggested that the Starwisp concept as originally proposed by Forward would not work, but variations on the proposal continue to be proposed.
The beam has to have a large diameter so that only a small portion of the beam misses the sail due to diffraction and the laser or microwave antenna has to have a good pointing stability so that the craft can tilt its sails fast enough to follow the center of the beam. This gets more important when going from interplanetary travel to interstellar travel, and when going from a fly-by mission, to a landing mission, to a return mission. The laser or the microwave sender would probably be a large phased array of small devices, which get their energy directly from solar radiation. The size of the array obsoletes any lens or mirror.
Another beam-pushed concept would be to use a magnetic sail or MMPP sail to divert a beam of charged particles from a particle accelerator or plasma jet. Jordin Kare has proposed a variant to this whereby a "beam" of small laser accelerated light sails would transfer momentum to a magsail vehicle.
Another beam-pushed concept uses ordinary matter and works in vacuum. The matter from a stationary mass-driver is "reflected" by the spacecraft, cf. mass driver. The spacecraft neither needs energy nor reaction mass for propulsion of its own.
Proposed systems.
Lightcraft.
A lightcraft is a vehicle currently under development that uses an external pulsed source of laser or maser energy to provide power for producing thrust.
The laser shines on a parabolic reflector on the underside of the vehicle that concentrates the light to produce a region of extremely high temperature. The air in this region is heated and expands violently, producing thrust with each pulse of laser light. In space, a lightcraft would need to provide this gas itself from onboard tanks or from an ablative solid. By leaving the vehicle's power source on the ground and by using ambient atmosphere as reaction mass for much of its ascent, a lightcraft would be capable of delivering a very large percentage of its launch mass to orbit. It could also potentially be very cheap to manufacture.
Testing.
Early in the morning of 2 October 2000 at the High Energy Laser Systems Test Facility (HELSTF), Lightcraft Technologies, Inc. (LTI) with the help of Franklin B. Mead of the U.S. Air Force Research Laboratory and Leik Myrabo set a new world's altitude record of 233 feet (71 m) for its 4.8 inch (12.2 cm) diameter, 1.8 oz, laser-boosted rocket in a flight lasting 12.7 seconds. Although much of the 8:35 am flight was spent hovering at 230+ feet, the Lightcraft earned a world record for the longest ever laser-powered free flight and the greatest "air time" (i.e., launch-to-landing/recovery) from a light-propelled object. This is comparable to Robert Goddard's first test flight of his rocket design. Increasing the laser power to 100 kilowatts will enable flights up to a 30-kilometer altitude. Their goal is to accelerate a one-kilogram microsatellite into low Earth orbit using a custom-built, one megawatt ground-based laser. Such a system would use just about 20 dollars' worth of electricity, placing launch costs per kilogram to many times less than current launch costs (which are measured in thousands of dollars).
Myrabo's "lightcraft" design is a reflective funnel-shaped craft that channels heat from the laser, towards the center, using a reflective parabolic surface causing the laser to literally explode the air underneath it, generating lift. Reflective surfaces in the craft focus the beam into a ring, where it heats air to a temperature nearly five times hotter than the surface of the sun, causing the air to expand explosively for thrust.
Jordin Kare's heat exchanger system.
In 2004, Jordin Kare proposed a simpler, nearer term concept which has a rocket containing liquid hydrogen and water. The propellant is heated in a heat exchanger that the laser beam shines on before leaving the vehicle via a conventional nozzle. This concept can use continuous beam lasers, and the semiconductor lasers are now cost effective for this application.
Kevin L. Parkin has proposed a similar system using microwaves.
Non-spacecraft applications.
In 1964 William C. Brown demonstrated a miniature helicopter equipped with a combination antenna and rectifier device called a rectenna. The rectenna converted microwave power into electricity, allowing the helicopter to fly.
In 2002 a Japanese group propelled a tiny aluminium airplane by using a laser to vaporize a water droplet clinging to it, and in 2003 NASA researchers flew an 11-ounce (312 g) model airplane with a propeller powered with solar panels illuminated by a laser. It is possible that such beam-powered propulsion could be useful for long-duration high altitude unmanned aircraft or balloons, perhaps designed to serve – like satellites do today – as communication relays, science platforms, or surveillance platforms.
A "laser broom" has been proposed to sweep space debris from Earth orbit. This is another proposed use of beam-powered propulsion, used on objects that were not designed to be propelled by it, for example small pieces of scrap knocked off ("spalled") satellites. The technique works since the laser power ablates one side of the object, giving an impulse that changes the eccentricity of the object's orbit. The orbit would then intersect the atmosphere and burn up.

</doc>
<doc id="37851" url="http://en.wikipedia.org/wiki?curid=37851" title="Nuclear photonic rocket">
Nuclear photonic rocket

In a nuclear photonic rocket, a nuclear reactor would generate such high temperatures that the blackbody radiation from the reactor would provide significant thrust. The disadvantage is that it takes a lot of power to generate a small amount of thrust this way, so acceleration is very slow. The photon radiators would most likely be constructed using graphite or tungsten. Photonic rockets are technologically feasible, but rather impractical with current technology.
Energy requirements and comparisons.
The power per thrust required for a perfectly collimated output beam is 300 MW/N (half this if it can be reflected off the craft); very high energy density power sources would be required to provide reasonable thrust without unreasonable weight. The specific impulse of a photonic rocket is harder to define, since the output has no (rest) mass and is not expended fuel; if we take the momentum per inertia of the photons, the specific impulse is just "c", which is impressive. However, considering the mass of the source of the photons, e.g., atoms undergoing nuclear fission, brings the specific impulse down to 300 km/s ("c"/1000) or less; considering the infrastructure for a reactor (some of which also scales with the amount of fuel) reduces the value further. Finally, any energy loss not through radiation that is redirected precisely to aft but is instead conducted away by engine supports, radiated in some other direction, or lost via neutrinos or so will further degrade the efficiency. If we were to set 80% of the mass of the photon rocket = fissionable fuel, and recognizing that nuclear fission converts about 0.10% of the mass into energy: then if the photon rocket masses 300,000 kg then 240,000 kg of that is atomic fuel. Therefore the fissioning of all of the fuel will result in the loss of just 240 kg of mass. Then 300,000/299,760 kg = an "m"i/"m"f of 1.0008. "V"f = ln 1.008 × "c" where "c" = 300,000,000 m/s.
"V"f then may be 240,096 m/s which is 240 km/s. The nuclear fission powered photon rocket may accelerate at a maximum of perhaps 1/10,000 m/s² (0.1 mm/s²) which is 10−5"g". The velocity change would be at the rate of 3,000 m/s per year of thrusting by the photon rocket. 
If a photon rocket begins its journey in low earth orbit, then one year of thrusting may be required to achieve an earth escape velocity of 11.2 km/s if the vehicle is already in orbit at a velocity of 9,100 m/s. Upon escaping the Earth's gravitational field the rocket will have a heliocentric velocity of 30 km/s in interplanetary space. Eighty years of steady photonic thrusting would be then required to obtain a final velocity of 240 km/s in this hypothetical case.
It is possible to obtain even higher specific impulse; that of some other photonic propulsion devices (e.g., solar sails) is effectively infinite because no carried fuel is required. Alternatively, such devices as ion thrusters, while having a notably lower specific impulse, give a much better thrust-to-power ratio; for photons, that ratio is formula_1, whereas for slow particles (that is, nonrelativistic; even the output from typical ion thrusters counts) the ratio is formula_2, which is much larger (since formula_3). (This is in a sense an unfair comparison, since the photons must be "created" and other particles are merely "accelerated", but nonetheless the impulses per carried mass and per applied energy—the practical quantities—are as given.) The photonic rocket is thus wasteful when power and not mass is at a premium, or when enough mass can be saved through the use of a weaker power source that reaction mass can be included without penalty.
A laser could be used as a photon rocket engine, and would solve the reflection/collimation problem, but lasers are absolutely less efficient at converting energy into light than blackbody radiation is—though one should also note the benefits of lasers vs blackbody source, including unidirectional controllable beam and the mass and durability of the radiation source.
Power sources.
Feasible current, or near-term fission reactor designs can generate up to 2.2 kW per kilogram of reactor mass. Without any payload, such a reactor could drive a photon rocket at nearly 10−4 m/s² (10−5"g"; see "g"-force). This could perhaps provide interplanetary spaceflight capability from Earth orbit. Nuclear fusion reactors could also be used, perhaps providing somewhat higher power.
A design proposed in the 1950s by Eugen Sänger used positron-electron annihilation to produce gamma rays. Sänger was unable to solve the problem of how to reflect, and collimate the gamma rays created by positron-electron annihilation; however, by shielding the reactions (or other annihilations) and absorbing their energy, a similar blackbody propulsion system could be created. An antimatter-matter powered photon rocket would (disregarding the shielding) obtain the maximum "c" specific impulse; for this reason, an antimatter-matter annihilation powered photon rocket could potentially be used for interstellar spaceflight.

</doc>
<doc id="37852" url="http://en.wikipedia.org/wiki?curid=37852" title="Fusion rocket">
Fusion rocket

A fusion rocket is a theoretical design for a rocket driven by fusion power which could provide efficient and long-term acceleration in space without the need to carry a large fuel supply. The design relies on the development of fusion power technology beyond current capabilities, and the construction of rockets much larger and more complex than any current spacecraft. A smaller and lighter fusion reactor might be possible in the future when more sophisticated methods have been devised to control magnetic confinement and prevent plasma instabilities. Fusion power could provide a lighter and more compact alternative.
For space flight, the main advantage of fusion would be the very high specific impulse, and the main disadvantage the (likely) large mass of the reactor. However, a fusion rocket may produce less radiation than a fission rocket, reducing the mass needed for shielding. The surest way of building a fusion rocket with current technology is to use hydrogen bombs as proposed in Project Orion, but such a spacecraft would also be massive and the Partial Nuclear Test Ban Treaty prohibits the use of nuclear bombs. Therefore, the use of nuclear bombs to propel rockets on Earth is problematic, but possible in space in theory. An alternate approach would be electrical (e.g. ion) propulsion with electric power generation via fusion power instead of direct thrust.
Electricity generation vs. direct thrust.
Many spacecraft propulsion methods such as ion thrusters require an input of electric power to run but are highly efficient. In some cases their maximum thrust is limited by the amount of power that can be generated (for example, a mass driver). An electric generator that ran on fusion power could be installed purely to drive such a ship. One disadvantage is that conventional electricity production requires a low-temperature energy sink, which is difficult (i.e. heavy) in a spacecraft. Direct conversion of the kinetic energy of the fusion products into electricity is in principle possible and would mitigate this problem.
An attractive possibility is to simply direct the exhaust of fusion product out the back of the rocket to provide thrust without the intermediate production of electricity. This would be easier with some confinement schemes (e.g. magnetic mirrors) than with others (e.g. tokamaks). It is also more attractive for "advanced fuels" (see aneutronic fusion). Helium-3 propulsion is a proposed method of spacecraft propulsion that uses the fusion of helium-3 atoms as a power source. Helium-3, an isotope of helium with two protons and one neutron, could be fused with deuterium in a reactor. The resulting energy release could be used to expel propellant out the back of the spacecraft. Helium-3 is proposed as a power source for spacecraft mainly because of its abundance on the moon. Currently, scientists estimate that there are 1 million tons of helium-3 present on the moon, mainly due to solar wind colliding with the moon's surface and depositing it, among other elements, into the soil. Only 20% of the power produced by the D-T reaction could be used this way; the other 80% is released in the form of neutrons which, because they cannot be directed by magnetic fields or solid walls, would be very difficult to use for thrust. Helium-3 is also produced via beta decay of tritium, which in turn can be produced from deuterium, lithium, or boron.
Even if a self-sustaining fusion reaction cannot be produced, it might be possible to use fusion to boost the efficiency of another propulsion system, such as a VASIMR engine.
Confinement concept.
To sustain a fusion reaction, the plasma must be confined. The most widely studied configuration for terrestrial fusion is the tokamak, a form of magnetic confinement fusion. Currently tokamaks weigh a great deal, so the thrust to weight ratio would seem unacceptable. NASA's Glenn Research Center has proposed a small aspect ratio spherical torus reactor for its "Discovery II" conceptual vehicle design. "Discovery II" could deliver a manned 172 000-kilogram payload to Jupiter in 118 days (or 212 days to Saturn) using 861 metric tons of hydrogen propellant, plus 11 metric tons of Helium-3-Deuterium (D-He3) fusion fuel. The hydrogen is heated by the fusion plasma debris to increase thrust, at a cost of reduced exhaust velocity (348–463 km/s) and hence increased propellant mass.
The main alternative to magnetic confinement is inertial confinement fusion (ICF), such as that proposed by Project Daedalus. A small pellet of fusion fuel (with a diameter of a couple of millimeters) would be ignited by an electron beam or a laser. To produce direct thrust, a magnetic field would form the pusher plate. In principle, the Helium-3-Deuterium reaction or an aneutronic fusion reaction could be used to maximize the energy in charged particles and to minimize radiation, but it is highly questionable whether it is technically feasible to use these reactions. Both the detailed design studies in the 1970s, the Orion drive and Project Daedalus, used inertial confinement. In the 1980s, Lawrence Livermore National Laboratory and NASA studied an ICF-powered "Vehicle for Interplanetary Transport Applications" (VISTA). The conical VISTA spacecraft could deliver a 100-tonne payload to Mars orbit and return to Earth in 130 days, or to Jupiter orbit and back in 403 days. 41 tonnes of deuterium/tritium (D-T) fusion fuel would be required, plus 4,124 tonnes of hydrogen expellant. The exhaust velocity would be 157 km/s.
Magnetized target fusion (MTF) is a relatively new approach that combines the best features of the more widely studied magnetic confinement fusion (i.e. good energy confinement) and inertial confinement fusion (i.e. efficient compression heating and wall free containment of the fusing plasma) approaches. Like the magnetic approach, the fusion fuel is confined at low density by magnetic fields while it is heated into a plasma, but like the inertial confinement approach, fusion is initiated by rapidly squeezing the target to dramatically increase fuel density, and thus temperature. MTF uses "plasma guns" (i.e. electromagnetic acceleration techniques) instead of powerful lasers, leading to low cost and low weight compact reactors. The NASA/MSFC Human Outer Planets Exploration (HOPE) group has investigated a manned MTF propulsion spacecraft capable of delivering a 163933-kilogram payload to Jupiter's moon Callisto using 106-165 metric tons of propellant (hydrogen plus either D-T or D-He3 fusion fuel) in 249–330 days. This design would thus be considerably smaller and more fuel efficient due to its higher exhaust velocity (700 km/s) than the previously mentioned "Discovery II", "VISTA" concepts.
Another popular confinement concept for fusion rockets is inertial electrostatic confinement (IEC), such as in the Farnsworth-Hirsch Fusor or the Polywell variation being researched by the Energy-Matter Conversion Corporation. The University of Illinois has defined a 500-tonne "Fusion Ship II" concept capable of delivering a 100,000 kg manned payload to Jupiter's moon Europa in 210 days. Fusion Ship II utilizes ion rocket thrusters (343 km/s exhaust velocity) powered by ten D-He3 IEC fusion reactors. The concept would need 300 tonnes of argon propellant for a 1-year round trip to the Jupiter system. Dr. Robert Bussard published a series of technical articles discussing its application to spaceflight throughout the 1990s. His work was popularised by an article in the Analog Science Fiction and Fact publication, where Tom Ligon (who has also written several science fiction stories) described how the fusor would make for a highly effective fusion rocket. It was also featured in this role in the science fiction novel "The Wreck of the River of Stars", by Michael Flynn.
A still more speculative concept is antimatter catalyzed nuclear pulse propulsion, which would use tiny quantities of antimatter to catalyze a fission and fusion reaction, allowing much smaller fusion explosions to be created.
Development projects.
See MSNW Magneto-Inertial Fusion Driven Rocket.

</doc>
<doc id="37853" url="http://en.wikipedia.org/wiki?curid=37853" title="Bussard ramjet">
Bussard ramjet

The Bussard ramjet is a theoretical method of spacecraft propulsion proposed in 1960 by the physicist Robert W. Bussard, popularized by Poul Anderson's novel "Tau Zero", Larry Niven in his Known Space series of books, Vernor Vinge in his Zones of Thought series, and referred to by Carl Sagan in the television series and book "". Bussard ramscoops are also seen in "Star Trek", where they are situated at the glowing tips of the warp nacelles of spacecraft, although the hydrogen is not used as nuclear fuel.
Bussard proposed a ramjet variant of a fusion rocket capable of reasonable interstellar spaceflight, using enormous electromagnetic fields (ranging from kilometers to many thousands of kilometers in diameter) as a ram scoop to collect and compress hydrogen from the interstellar medium. High speeds force the reactive mass into a progressively constricted magnetic field, compressing it until thermonuclear fusion occurs. The magnetic field then directs the energy as rocket exhaust opposite to the intended direction of travel, thereby accelerating the vessel.
Design discussion.
A major problem with using rocket propulsion to reach the velocities required for interstellar flight is the enormous amounts of fuel required. Since that fuel must itself be accelerated, this results in an approximately exponential increase in mass as a function of velocity change at non-relativistic speeds, tending to infinity as it approaches the speed of light. In principle, the Bussard ramjet avoids this problem by not carrying fuel with it. An ideal ramjet design could in principle accelerate indefinitely until its mechanism failed. Ignoring drag, a ship driven by such an engine could theoretically accelerate arbitrarily close to the speed of light, and would be a very effective interstellar spacecraft. In practice, since the force of drag produced by collecting the interstellar medium increases approximately as its speed squared at non-relativistic speeds and tends to infinity as it approaches the speed of light (taking all measurements from the ship's perspective), any such ramjet would have a limiting speed where the drag equals thrust. To produce positive thrust, the fusion reactor must be capable of producing fusion while still giving the incident ions a net rearward acceleration (relative to the ship).
An object's velocity can be calculated by summing over time the acceleration supplied (ignoring the effects of special relativity, which would quickly become significant at useful interstellar accelerations). If a ramjet could accelerate at 10 m/s2, slightly more than one Earth gravity, it would attain 77% of light velocity within a year. However, if the ramjet has an average acceleration of 0.1 m/s2, then it needs 100 years to go as fast, and so on.
The top speed of a ramjet-driven spaceship depends on five things:
The collected propellant can be used as reaction mass in a plasma rocket engine, ion rocket engine, or even in an antimatter-matter annihilation powered rocket engine. Interstellar space contains an average of 10−21 kg of mass per cubic meter of space, primarily in the form of non-ionized and ionized hydrogen, with smaller amounts of helium, and no significant amounts of other gases. This means that the ramjet scoop must sweep 1021 cubic meters of space (approximately the volume of the Earth) to collect one kilogram of hydrogen.
A large energy source adds more mass to the ramjet system, and this makes it harder to accelerate. Therefore, the specific power, ("A") of the ramjet's energy source is crucial. The specific power A is the number of joules of energy the starship's reactor generates per kilogram of its mass. This depends on the ramjet fuel's energy density, and on the specific design of the ramjet's nuclear power reactors.
The obvious fuel source, the one proposed by Bussard, is fusion of hydrogen, the most common component of interstellar gas. Unfortunately, the proton-proton fusion rate is close to zero for this purpose: protons in the Sun on average survive for a billion years or more before reacting. Accordingly, an interstellar ramjet would have to be powered by other nuclear reactions, but the required isotopes are rare in the interstellar medium. A fusion reactor used to power a ramjet starship might be a steady state magnetic fusion reactor based on the following nuclear fusion reactions. 2H + 2H → 3He + 1n0 + 4 MeV, or 2H + 3H → 4He + 1n0 + 17.8 MeV.
This problem was solved, in principle, according to Dr. Bussard by use of the stellar CNO cycle in which carbon is used as a catalyst to burn hydrogen via the strong nuclear reaction. This cycle occurs in the sun (<4%) and is dominant in higher mass stars. The power improvement over the slow PPI chain is by a factor of 1016.
Bussard ramjet designs that use the collected hydrogen only as reaction mass are sometimes referred to as "ram-augmented" interplanetary or interstellar rockets (RAIR) to distinguish them from the designs that use the collected hydrogen as fuel.
The mass of the ion ram scoop must be minimized on an interstellar ramjet. The size of the scoop is large enough that the scoop cannot be solid. This is best accomplished by using an electromagnetic field, or alternatively using an electrostatic field to build the ion ram scoop. Such an ion scoop will use electromagnetic funnels, or electrostatic fields to collect ionized hydrogen gas from space for use as propellant by ramjet propulsion systems (since much of the hydrogen is not ionized, some versions of a scoop propose ionizing the hydrogen, perhaps with a laser, ahead of the ship.) An electric field can electrostatically attract the positive ions, and thus draw them inside a ramjet engine. The electromagnetic funnel would bend the ions into helical spirals around the magnetic field lines to scoop up the ions via the starship's motion through space. Ionized particles moving in spirals produce an energy loss, and hence drag; the scoop must be designed to both minimize the circular motion of the particles and simultaneously maximize the collection. Likewise, if the hydrogen is heated during collection, thermal radiation will represent an energy loss, and hence also drag; so an effective scoop must collect and compress the hydrogen without significant heating. A magnetohydrodynamic generator drawing power from the exhaust could power the scoop.
The collection-radius of such an ionic ramscoop is the distance from the ramjet at which the ramscoop's electric field is greater than the galactic electric field of 1.6×10−19 V/m, or the ramscoop's electromagnetic field is greater than the natural galactic magnetic field of 0.1 nanotesla (1×10−6 gauss). The strength of the ramscoop collection field would decline proportionately to 1/"d"3 in distance from the ramscoop generator.
Feasibility.
Since the time of Bussard's original proposal, it has been discovered that the region surrounding the sun has a much lower density of interstellar hydrogen than was believed at that time (see Local Interstellar Cloud). T. A. Heppenheimer analyzed Bussard's original suggestion of fusing protons, but found the bremsstrahlung losses from compressing protons to fusion densities was greater than the power that could be produced by a factor of about 1 billion, thus indicating that the proposed version of the Bussard ramjet was infeasible. However Daniel P. Whitmire's 1975 analysis indicates that a ramjet may achieve net power via the CNO cycle, which produces fusion at a much higher rate (~1016 times higher) than the proton-proton chain.
Robert Zubrin and Dana Andrews analyzed one hypothetical version of the Bussard ramscoop and ramjet design in 1985. They determined that their version of the ramjet would be unable to accelerate into the solar wind. However, in their calculations they assumed that:
In the Zubrin/Andrews interplanetary ramjet design, they calculated that the drag force d/dt("mv"1) equals the mass of the scooped ions collected per second multiplied by the velocity of the scooped ions within the solar system relative to the ramscoop. The velocity of the (scooped) collected ions from the solar wind was assumed to be 500,000 m/s.
The exhaust velocity of the ions when expelled by the ramjet was assumed not to exceed 100,000 m/s. The thrust of the ramjet d/dt("mv"2) was equal to the mass of ions expelled per second multiplied by 100,000 meters per second. In the Zubrin/Andrews design of 1985, this resulted in the condition that d/dt("mv"1) > d/dt("mv"2). This condition resulted in the drag force exceeding the thrust of the hypothetical ramjet in the Zubrin/Andrews version of the design.
Consider also the case of a vessel leaving a star system, or heading to the outer planets. In this case, the force produced by the solar wind is beneficial. Since the values for drag are based on relative velocity, using the scoop as a form of electromagnetic sail will provide additional thrust as long as the vessel is traveling at less than 500,000 m/s away from a star. While interstellar matter is relatively scarce, this abundance of high-energy ions in the neighborhood of stars has potential for initial acceleration and braking on arrival.
The key condition that determines whether or not an interstellar ramjet will accelerate forward in the direction of its thrust is that the thrust of the ramjet must exceed drag that results from scooping up ions from space. Or, as discussed above, the condition d/dt("mv"2) > d/dt("mv"1) must be true.
Example.
For example, a ramjet might collect 1 gram of incoming ions per second from interstellar space beyond the heliopause, at a velocity of 50 km/s relative to the ramjet driven spacecraft. In this case d/dt("mv"1) is (0.001 kg/s) (50,000 m/s), yielding a drag force of 50 newtons.
If the gram of ions is then accelerated to 500,000 m/s then d/dt("mv"2) is (0.001 kg/s) (500,000 m/s) = 500 N.
Therefore, -50 newtons + 500 newtons yields a net force forward of 450 newtons.
The typical velocity of the solar wind within the solar system is 500 km/s. The typical velocity of the interstellar wind is 50 km/s beyond the heliopause. In the solar system, if the exhaust velocity of the ramjet exceeds 500 km/s there will be a net thrust that will accelerate the ramjet. Figures here assume the spacecraft is traveling towards the sun (since the solar wind is directional), under the worst conditions for thrust.
If the example were set in the solar system, the drag force, d/dt("mv"1), would be about (0.001 kg/s) (500,000 m/s), or 500 newton.
If the exhaust velocity of the ramjet were 1,000,000 m/s then d/dt("mv"2) = (0.001 kg/s) (1,000,000 m/s) = 1000 N of thrust, and -500 newtons + 1000 newtons = net thrust of 500 newtons to accelerate the ramjet forward.
If the Zubrin/Andrews assumption were correct then d/dt("mv"1) = 500 N, and d/dt("mv"2) = 100 N, and the drag forces would exceed the thrust of the ramjet. Under those conditions, the ramjet would likely only function along vectors perpendicular to the solar wind.
Related inventions.
Ram Augmented Interstellar Rocket (RAIR).
Due to the potential for drag caused by a ramjet attempting to accelerate the hydrogen it captures up to its speed before the hydrogen gas can undergo fusion a concept had been proposed which uses a ramjet in partnership with a fusion rocket. In this concept an onboard hydrogen fuel supply is used to provide power to a fusion reactor but a ramscoop is used to provide propellant. By this method the hydrogen entering the ramscoop need not be accelerated up to the ship's speed before fusion can occur, because the hydrogen being collected is not used for fusion. Instead this hydrogen can continue to travel relative to the ship at high speed as it passes through the engine and has some energy transferred to it from the reactor on board. This hydrogen propellant leaves the rear of the vessel travelling relative to the vessel at its own initial velocity relative to the vessel plus the velocity provided to it by energy transfer as it passed the reactor. The fusion reactor itself may provide some thrust by release of fusion products but the majority of the thrust on such a vehicle will come from the interstellar sourced propellant hydrogen.
Magnetic sail.
The calculations (by Robert Zubrin and an associate) inspired the idea of a magnetic parachute or sail. This could be important for interstellar travel because it means that deceleration at the destination can be performed with a magnetic parachute rather than a rocket.
Electrostatic ion scoop.
One possible modification of the ramjet design is to use an electrostatic ion scoop, instead of an electromagnetic ion scoop to achieve the ion collection from space. In an electrostatic scoop a negative electric field on a forward grid electrostatically attracts the positive charged ions present in interstellar space and thus draws them into the ramjet engines. This can be a 100% electrostatic scoop in which an electromagnetic field is not used at all. There will be no converging electromagnetic field lines that can potentially generate drag effects by scooping the ions from interstellar space if this pure electrostatic approach is used. The scooped ions will however have an electric field-induced velocity when they are drawn inside of the ion ramjet engine. So long as the velocity of the ramjet engine exhaust jet is greater than the electric field-induced velocity of the incoming scooped ions there can be a net force in the direction of the ramjet's flight that will accelerate the spacecraft.
Furthermore, the net potential difference of the galactic electric field in interstellar space is only 1.6×10−19 volt. The effective ion collection radius of an electrostatic ion ram scoop will be the range at which the ramscoop electric field has a greater potential difference from the galactic electric field. This potential difference declines proportionately to 1/"d"² for distance "d" from the source of the ram scoop electric field.
Pre-seeded trajectory.
Several of the obvious technical difficulties with the Bussard Ramjet can be overcome by prelaunching fuel along the spacecraft's trajectory using something like a magnetic rail-gun.
The advantages of this system include
The major disadvantages of this system include

</doc>
<doc id="37854" url="http://en.wikipedia.org/wiki?curid=37854" title="Antimatter rocket">
Antimatter rocket

An antimatter rocket is a proposed class of rockets that use antimatter as their power source. There are several designs that attempt to accomplish this goal. The advantage to this class of rocket is that a large fraction of the rest mass of a matter/antimatter mixture may be converted to energy, allowing antimatter rockets to have a far higher energy density and specific impulse than any other proposed class of rocket.
Methods.
Antimatter rockets can be divided into three types of application: those that directly use the products of antimatter annihilation for propulsion, those that heat a working fluid or an intermediate material which is then used for propulsion, and those that heat a working fluid or an intermediate material to generate electricity for some form of electric spacecraft propulsion system.
The propulsion concepts that employ these mechanisms generally fall into four categories: solid core, gaseous core, plasma core, and beamed core configurations. The alternatives to direct antimatter annihilation propulsion offer the possibility of feasible vehicles with, in some cases, vastly smaller amounts of antimatter but require a lot more matter propellant.
Then there are hybrid solutions using antimatter to catalyze fission/fusion reactions for propulsion.
Pure antimatter rocket: direct use of reaction products.
Antiproton annihilation reactions produce charged and uncharged pions, in addition to neutrinos and gamma rays. The charged pions can be channelled by a magnetic nozzle, producing thrust. This type of antimatter rocket is a pion rocket or beamed core configuration. It is not perfectly efficient; energy is lost as the rest mass of the charged (22.3%) and uncharged pions (14.38%), lost as the kinetic energy of the uncharged pions (which can't be deflected for thrust), and lost as neutrinos and gamma rays (see antimatter as fuel).
Positron annihilation has also been proposed for rocketry. Annihilation of positrons produces only gamma rays. Early proposals for this type of rocket, such as those developed by Eugen Sänger, assumed the use of some material that could reflect gamma rays, used as a light sail or parabolic shield to derive thrust from the annihilation reaction, but no known form of matter (consisting of atoms or ions) interacts with gamma rays in a manner that would enable specular reflection. The momentum of gamma rays can, however, be partially transferred to matter by Compton scattering. A recent approach is to utilize an ultra-intense laser capable of generating positrons when striking a high atomic number target, such as gold. The positron generation of antimatter occurs on demand, hence, this technology would circumvent the difficulties of antimatter storage.
Thermal antimatter rocket: heating of a propellant.
This type of antimatter rocket is termed a thermal antimatter rocket as the energy or heat from the annihilation is harnessed to create an exhaust from non-exotic material or propellant.
The solid core concept uses antiprotons to heat a solid, high-atomic weight (Z), refractory metal core. Propellant is pumped into the hot core and expanded through a nozzle to generate thrust. The performance of this concept is roughly equivalent to that of the nuclear thermal rocket (formula_1 ~ 103 sec) due to temperature limitations of the solid. However, the antimatter energy conversion and heating efficiencies are typically high due to the short mean path between collisions with core atoms (efficiency formula_2 ~ 85%).
Several methods for the liquid-propellant thermal antimatter engine using the gamma rays produced by antiproton or positron annihilation have been proposed. These methods resemble those proposed for nuclear thermal rockets. One proposed method is to use positron annihilation gamma rays to heat a solid engine core. Hydrogen gas is ducted through this core, heated, and expelled from a rocket nozzle. A second proposed engine type uses positron annihilation within a solid lead pellet or within compressed xenon gas to produce a cloud of hot gas, which heats a surrounding layer of gaseous hydrogen. Direct heating of the hydrogen by gamma rays was considered impractical, due to the difficulty of compressing enough of it within an engine of reasonable size to absorb the gamma rays. A third proposed engine type uses annihilation gamma rays to heat an ablative sail, with the ablated material providing thrust. As with nuclear thermal rockets, the specific impulse achievable by these methods is limited by materials considerations, typically being in the range of 1000–2000 seconds. 
The gaseous core system substitutes the low-melting point solid with a high temperature gas (i.e. tungsten gas/plasma), thus permitting higher operational temperatures and performance (formula_1 ~ 2 × 103 sec). However, the longer mean free path for thermalization and absorption results in much lower energy conversion efficiencies (formula_2 ~ 35%).
The plasma core allows the gas to ionize and operate at even higher effective temperatures. Heat loss is suppressed by magnetic confinement in the reaction chamber and nozzle. Although performance is extremely high (formula_1 ~ 104-105 sec), the long mean free path results in very low energy utilization (formula_2 ~ 10%)
Antimatter power generation.
The idea of using antimatter to power an electric space drive has also been proposed. These proposed designs are typically similar to those suggested for nuclear electric rockets. Antimatter annihilations are used to directly or indirectly heat a working fluid, as in a nuclear thermal rocket, but the fluid is used to generate electricity, which is then used to power some form of electric space propulsion system. The resulting system shares many of the characteristics of other charged particle/electric propulsion proposals (typically high specific impulse and low thrust).
Catalyzed fission/fusion or spiked fusion.
This is a hybrid approach in which antiprotons are used to catalyze a fission/fusion reaction or to "spike" the propulsion of a Fusion rocket or any similar applications.
The antiproton-driven Inertial confinement fusion (ICF) Rocket concept uses pellets for the D-T reaction. The pellet consists of a hemisphere of fissionable material such as U235 with a hole through which a pulse of antiprotons and positrons is injected. It is surrounded by a hemisphere of fusion fuel, for example deuterium-tritium, or lithium deuteride. Antiproton annihilation occurs at the surface of the hemisphere, which ionizes the fuel. These ions heat the core of the pellet to fusion temperatures.
The antiproton-driven Magnetically Insulated Inertial Confinement Fusion Propulsion (MICF) concept relies on self-generated magnetic field which insulates the plasma from the metallic shell that contains it during the burn. The lifetime of the plasma was estimated to be two orders of magnitude greater than implosion inertial fusion, which corresponds to a longer burn time, and hence, greater gain.
The antimatter-driven P-B11 concept uses antiprotons to ignite the P-B11 reactions in an MICF scheme. Excessive radiation losses are a major obstacle to ignition and require modifying the particle density, and plasma temperature to increase the gain. It was concluded that it is entirely feasible that this system could achieve Isp~105s.
A different approach was envisioned for AIMStar in which small fusion fuel droplets would be injected into a cloud of antiprotons confined in a very small volume within a reaction Penning trap. Annihilation takes place on the surface of the antiproton cloud, pealing back 0.5% of the cloud. The power density released is roughly comparable to a 1 kJ, 1 ns laser depositing its energy over a 200 mm ICF target.
The ICAN-II project employs the antiproton catalyzed microfission (ACMF) concept which uses pellets with a molar ratio of 9:1 of D-T:U235 for Nuclear pulse propulsion.
Difficulties with antimatter rockets.
The chief practical difficulties with antimatter rockets are the problems of creating antimatter and storing it. Creating antimatter requires input of vast amounts of energy, at least equivalent to the rest energy of the created particle/antiparticle pairs, and typically (for antiproton production) tens of thousands to millions of times more. Most proposed antimatter rocket designs require a large amount of antimatter (around 10 grams to reach Mars in one month). Most storage schemes proposed for interstellar craft require the production of frozen pellets of antihydrogen. This requires cooling of antiprotons, binding to positrons, and capture of the resulting antihydrogen atoms - tasks which have, as of 2010[ [update]], been performed only for small numbers of individual atoms. Storage of antimatter is typically done by trapping electrically charged frozen antihydrogen pellets in Penning or Paul traps. There is no theoretical barrier to these tasks being performed on the scale required to fuel an antimatter rocket. However, they are expected to be extremely (and perhaps prohibitively) expensive due to current production abilities being only able to produce small numbers of atoms, a scale approximately 1023 times smaller than needed for a 10-gram trip to Mars.
A secondary problem is the extraction of useful energy or momentum from the products of antimatter annihilation, which are primarily in the form of extremely energetic ionizing radiation. The antimatter mechanisms proposed to date have for the most part provided plausible mechanisms for harnessing energy from these annihilation products. The classic Rocket Equation with its "wet" mass (formula_7)(with propellant mass fraction) to "dry" mass (formula_8)(with payload) fraction (formula_9), the velocity change (formula_10) and specific impulse (formula_1) no longer holds due to the mass loses occurring in antimatter annihilation.
Another general problem with high powered propulsion is excess heat or waste heat, and as with antimatter-matter annihilation also includes extreme radiation. A proton-antiproton annihilation propulsion system transforms 38% of the propellant mass into an intense highenergy flux of gamma radiation. The gamma rays and the high-energy charged pions will cause heating and radiation damage if they are not shielded against. Unlike neutrons, they will not cause the exposed material to become radioactive by transmutation of the nuclei. The components needing shielding are the crew, the electronics, the cryogenic tankage, and the magnetic coils for magnetically assisted rockets. Two types of shielding are needed: radiation protection and thermal protection (different from Heat shield or thermal insulation).
Finally, relativistic considerations have to be taken into account. As the by products of annihilation move at relativistic velocities the rest mass changes according to relativistic mass-energy. For example the total mass-energy content of the neutral pion is converted into gammas, not just its rest mass. It is necessary to use a Relativistic Rocket Equation that takes into account the relativistic effects of both the vehicle and propellant exhaust (charged pions) moving near the speed of light. These two modifications to the two Rocket Equations results in a mass ratio (formula_9) for a given (formula_10) and (formula_1) that is much higher for a relativistic antimatter rocket than for either a classical or relativistic "conventional" rocket.
Modified relativistic Rocket Equation.
The loss of mass specific to antimatter annihilation requires a modification of the relativistic Rocket Equation given as
where formula_15 is the speed of light, and formula_1 is the specific impulse (i.e. formula_1=0.69formula_15).
The derivative form of the equation is
}{M_{\text{ship}}}=
where formula_19 is the non-relativistic (rest) mass of the rocket ship, and formula_20 is the fraction of the original (on-board) propellant mass (non-relativistic) remaining after annihilation (i.e., formula_20=0.22 for the charged pions).
Eq.II cannot be integrated analytically. If it is assumed that formula_22, such that formula_23 then the resulting equation is
}{M_{\text{ship}}}=
Eq.III can be integrated and the integral evaluated for formula_7 and formula_8, and initial and final velocities (formula_26 and formula_27).
The resulting relativistic Rocket Equation with loss of propellant is
Other general issues.
The cosmic background hard radiation will ionize the rocket's hull over time and poses a health threat. Gas plasma interactions may cause space charge, too. The major interaction of concern is differential charging of various parts of a spacecraft, leading to high electric fields and arcing between spacecraft components. This can be resolved with well placed plasma contactor. However, there is no solution yet for when plasma contactors are turned off to allow maintenance work on the hull. Long term space flight at interstellar velocities causes erosion of the rocket's hull due to collision with particles, gas, dust and micrometeorites. At 0.2formula_15 erosion is estimated to be in the order of about 30 kg/m2 or about 1 cm of aluminum shielding.
Diagram.
A diagram of beamed-core starship concept by Robert Frisbee

</doc>
<doc id="37856" url="http://en.wikipedia.org/wiki?curid=37856" title="Alcubierre drive">
Alcubierre drive

The Alcubierre drive or Alcubierre metric (referring to metric tensor) is a speculative idea based on a solution of Einstein's field equations in general relativity as proposed by theoretical physicist Miguel Alcubierre, by which a spacecraft could achieve faster-than-light travel if a configurable energy-density field lower than that of vacuum (i.e. negative mass) could be created. Rather than exceeding the speed of light within a local reference frame, a spacecraft would traverse distances by contracting space in front of it and expanding space behind it, resulting in effective faster-than-light travel.
Objects cannot accelerate to the speed of light within normal spacetime; instead, the Alcubierre drive shifts space around an object so that the object would arrive at its destination faster than light would in normal space. Although the metric proposed by Alcubierre is mathematically valid in that it is consistent with the Einstein field equations, it may not be physically meaningful or indicate that such a drive could be constructed. The proposed mechanism of the Alcubierre drive implies a negative energy density and therefore requires exotic matter, so if exotic matter with the correct properties does not exist then it could not be constructed. However, at the close of his original paper Alcubierre argued (following an argument developed by physicists analyzing traversable wormholes) that the Casimir vacuum between parallel plates could fulfill the negative-energy requirement for the Alcubierre drive. Another possible issue is that although the Alcubierre metric is consistent with general relativity, general relativity does not incorporate quantum mechanics, and some physicists have presented arguments to suggest that a theory of quantum gravity, which incorporates both theories, would eliminate those solutions in general relativity that allow for backwards time travel ("see" the chronology protection conjecture), of which the Alcubierre drive is one.
History.
In 1994, Alcubierre proposed a method for changing the geometry of space by creating a wave that would cause the fabric of space ahead of a spacecraft to contract and the space behind it to expand. The ship would then ride this wave inside a region of flat space, known as a "warp bubble", and would not move within this bubble but instead be carried along as the region itself moves due to the actions of the drive. It was thought to use too much negative energy until Harold Sonny White said that the amount of energy required could be reduced if the warp bubble were changed into a warp ring.
Alcubierre metric.
The Alcubierre metric defines the warp-drive spacetime. It is a Lorentzian manifold that, if interpreted in the context of general relativity, allows a warp bubble to appear in previously flat spacetime and move away at effectively superluminal speed. Inhabitants of the bubble feel no inertial effects. This method of transport does not involve objects in motion at speeds faster than light with respect to the contents of the warp bubble; that is, a light beam within the warp bubble would still always move faster than the ship. Because objects within the bubble are not moving (locally) faster than light, the mathematical formulation of the Alcubierre metric is consistent with the conventional claims of the laws of relativity (namely, that an object with mass cannot attain or exceed the speed of light) and conventional relativistic effects such as time dilation would not apply as they would with conventional motion at near-light speeds.
The Alcubierre drive, however, remains a hypothetical concept with seemingly difficult problems, though the amount of energy required is no longer thought to be unobtainably large.
Mathematics of the Alcubierre drive.
Using the ADM formalism of general relativity, the spacetime is described by a foliation of space-like hypersurfaces of constant coordinate time "t", with the metric taking the following general form:
where
The particular form that Alcubierre studied is defined by:
where
and
with arbitrary parameters formula_12 and formula_13. Alcubierre's specific form of the metric can thus be written
With this particular form of the metric, it can be shown that the energy density measured by observers whose 4-velocity is normal to the hypersurfaces is given by
where formula_16 is the determinant of the metric tensor.
Thus, because the energy density is negative, one needs exotic matter to travel faster than the speed of light. The existence of exotic matter is not theoretically ruled out; however, generating and sustaining enough exotic matter to perform feats such as faster-than-light travel (and also to keep open the 'throat' of a wormhole) is thought to be impractical. Low has argued that within the context of general relativity, it is impossible to construct a warp drive in the absence of exotic matter.
Physics.
For those familiar with the effects of special relativity, such as Lorentz contraction and time dilation, the Alcubierre metric has some apparently peculiar aspects. In particular, Alcubierre has shown that a ship using an Alcubierre drive travels on a free-fall geodesic even while the warp bubble is accelerating: its crew would be in free fall while accelerating without experiencing accelerational g-forces. Enormous tidal forces, however, would be present near the edges of the flat-space volume because of the large space curvature there, but suitable specification of the metric would keep them very small within the volume occupied by the ship.
The original warp-drive metric and simple variants of it happen to have the ADM form, which is often used in discussing the initial-value formulation of general relativity. This may explain the widespread misconception that this spacetime is a "solution" of the field equation of general relativity. Metrics in ADM form are "adapted" to a certain family of inertial observers, but these observers are not really physically distinguished from other such families. Alcubierre interpreted his "warp bubble" in terms of a contraction of space ahead of the bubble and an expansion behind, but this interpretation may be misleading because the contraction and expansion actually refers to the relative motion of nearby members of the family of ADM observers.
In general relativity, one often first specifies a plausible distribution of matter and energy, and then finds the geometry of the spacetime associated with it; but it is also possible to run the Einstein field equations in the other direction, first specifying a metric and then finding the energy–momentum tensor associated with it, and this is what Alcubierre did in building his metric. This practice means that the solution can violate various energy conditions and require exotic matter. The need for exotic matter raises questions about whether one can distribute the matter in an initial spacetime that lacks a warp bubble in such a way that the bubble is created at a later time, although some physicists have proposed models of dynamical warp-drive spacetimes in which a warp bubble is formed in a previously flat space. Moreover, according to Serguei Krasnikov, generating a bubble in a previously flat space for a "one-way" FTL trip requires forcing the exotic matter to move at local faster-than-light speeds, something that would require the existence of tachyons, although Krasnikov also notes that when the spacetime is not flat from the outset, a similar result could be achieved without tachyons by placing in advance some devices along the travel path and programming them to come into operation at preassigned moments and to operate in a preassigned manner. Some suggested methods avoid the problem of tachyonic motion, but would probably generate a naked singularity at the front of the bubble. Allen Everett and Thomas Roman comment that Krasnikov's finding "does not mean that Alcubierre bubbles, if it were possible to create them, could not be used as a means of superluminal travel. It only means that the actions required to change the metric and create the bubble must be taken beforehand by some observer whose forward light cone contains the entire trajectory of the bubble." For example, if one wanted to travel to Deneb (2,600 light years away) and arrive less than 2,600 years in the future according to external clocks, it would be required that someone had already begun work on warping the space from Earth to Deneb at least 2,600 years ago, in which case "A spaceship appropriately located with respect to the bubble trajectory could then choose to enter the bubble, rather like a passenger catching a passing trolley car, and thus make the superluminal journey." Everett and Roman also write that "as Krasnikov points out, causality considerations do not prevent the crew of a spaceship from arranging, by their own actions, to complete a "round trip" from Earth to a distant star and back in an arbitrarily short time, as measured by clocks on Earth, by altering the metric along the path of their outbound trip."
In conformal gravity.
Within the framework of conformal gravity, an extension of general relativity in which the angles of spacetime are locally preserved, the Alcubierre metric does not violate the weak energy condition for particular spacetime shapes, and hence faster-than-light travel would not require exotic matter.
Difficulties.
The metric of this form has significant difficulties because all known warp-drive spacetime theories violate various energy conditions. Nevertheless, Alcubierre type warp might be realized by exploiting certain experimentally verified quantum phenomena, such as the Casimir effect, that lead to stress–energy tensors that also violate the energy conditions, such as negative mass–energy, when described in the context of the quantum field theories.
Mass–energy requirement.
If certain quantum inequalities conjectured by Ford and Roman hold, then the energy requirements for some warp drives may be unfeasibly large as well as negative. For example, the energy equivalent of −1064 kg might be required to transport a small spaceship across the Milky Way—an amount orders of magnitude greater than the estimated mass of the observable universe. Counterarguments to these apparent problems have also been offered.
Chris Van den Broeck of the Catholic University of Louvain in Belgium, in 1999, tried to address the potential issues. By contracting the 3+1-dimensional surface area of the bubble being transported by the drive, while at the same time expanding the three-dimensional volume contained inside, Van den Broeck was able to reduce the total energy needed to transport small atoms to less than three solar masses. Later, by slightly modifying the Van den Broeck metric, Serguei Krasnikov reduced the necessary total amount of negative mass to a few milligrams.
In 2012, physicist Harold White and collaborators announced that modifying the geometry of exotic matter could reduce the mass–energy requirements for a macroscopic space ship from the equivalent of the planet Jupiter to that of the Voyager 1 spacecraft (~700 kg) or less, and stated their intent to perform small-scale experiments in constructing warp fields. White proposed changing the shape of the warp bubble from a sphere to a torus. Furthermore, if the intensity of the space warp can be oscillated over time, the energy required is reduced even more. According to White, a modified Michelson–Morley interferometer could test the idea: one of the legs of the interferometer would appear to be a slightly different length when the test devices were energised.
Placement of matter.
Krasnikov proposed that if tachyonic matter cannot be found or used, then a solution might be to arrange for masses along the path of the vessel to be set in motion in such a way that the required field was produced. But in this case, the Alcubierre drive vessel can only travel routes that, like a railroad, have first been equipped with the necessary infrastructure. The pilot inside the bubble is causally disconnected with its walls and cannot carry out any action outside the bubble: the bubble cannot be used for the first trip to a distant star because the pilot cannot place infrastructure ahead of the bubble while "in transit". For example, travelling to Vega (which is 25 light-years from Earth) requires arranging everything so that the bubble moving toward Vega with a superluminal velocity would appear; such arrangements will always take more than 25 years.
Coule has argued that schemes, such as the one proposed by Alcubierre, are infeasible because matter placed "en route" of the intended path of a craft must be placed at superluminal speed—that constructing an Alcubierre drive requires an Alcubierre drive even if the metric that allows it is physically meaningful. Coule further argues that an analogous objection will apply to "any" proposed method of constructing an Alcubierre drive.
Survivability inside the bubble.
A paper by José Natário (2002) argues that crew members could not control, steer or stop the ship because the ship could not send signals to the front of the bubble.
A more recent paper by Carlos Barceló, Stefano Finazzi, and Stefano Liberati uses quantum theory to argue that the Alcubierre drive at faster-than-light velocities is impossible mostly because extremely high temperatures caused by Hawking radiation would destroy anything inside the bubble at superluminal velocities and destabilize the bubble itself; the paper also argues that these problems are absent if the bubble velocity is subluminal, although the drive still requires exotic matter.
Damaging effect on destination.
Brendan McMonigal, Geraint F. Lewis, and Philip O'Byrne have argued that when an Alcubierre-driven ship decelerates from superluminal speed, the particles that its bubble has gathered in transit would be released in energetic outbursts akin to a sonic boom shockwave; in the case of forward-facing particles, energetic enough to destroy anything at the destination directly in front of the ship.
Wall thickness.
The amount of negative energy required for such a propulsion is not yet known. Pfenning and Allen Everett of Tufts hold that a warp bubble traveling at 10 times light-speed must have a wall thickness of no more than 10−32 meters—close to the limiting Planck length, 1.6 × 10−35 meters. In Miguel Alcubierre's original calculations, a bubble macroscopically large enough to enclose a ship of 200 meters would require a total amount of exotic matter greater than the mass of the observable universe, and straining the exotic matter to an extremely thin band of 10−32 meters is considered impractical. Similar constraints apply to Krasnikov's superluminal subway. Chris Van den Broeck recently constructed a modification of Alcubierre's model that requires much less exotic matter but places the ship in a curved space-time "bottle" whose neck is about 10−32 meters.
Causality violation and semiclassical instability.
Calculations by physicist Allen Everett show that warp bubbles could be used to create closed timelike curves in general relativity, meaning that the theory predicts that they could be used for backwards time travel. While it is possible the fundamental laws of physics might allow closed timelike curves, the chronology protection conjecture hypothesizes that in all cases where the classical theory of general relativity allows them, quantum effects would intervene to eliminate the possibility, making these spacetimes impossible to realize (a possible type of effect that would accomplish this is a buildup of vacuum fluctuations on the border of the region of spacetime where time travel would first become possible, causing the energy density to become high enough to destroy the system that would otherwise become a time machine). Some results in semiclassical gravity appear to support the conjecture, including a calculation dealing specifically with quantum effects in warp-drive spacetimes that suggested that warp bubbles would be semiclassically unstable, but ultimately the conjecture can only be decided by a full theory of quantum gravity.
Miguel Alcubierre briefly discusses some of these issues in a series of lecture slides posted online, where he writes "beware: in relativity, any method to travel faster than light can in principle be used to travel back in time (a time machine)." In the next slide he brings up the chronology protection conjecture, and writes "The conjecture has not been proven (it wouldn’t be a conjecture if it had), but there are good arguments in its favor based on quantum field theory. The conjecture does not prohibit faster-than-light travel. It just states that if a method to travel faster than light exists, and one tries to use it to build a time machine, something will go wrong: the energy accumulated will explode, or it will create a black hole."
Experiments.
In 2012, a NASA laboratory announced that they have constructed an interferometer that they claim will detect the spatial distortions produced by the expanding and contracting spacetime of the Alcubierre metric. The work has been described in "Warp Field Mechanics 101", a NASA paper by Harold Sonny White. Alcubierre has expressed skepticism about the experiment, saying "from my understanding there is no way it can be done, probably not for centuries if at all".
In 2013, The Jet Propulsion Laboratory (JPL) a federally funded research and development center and NASA field center published results of a 19.6-second warp field from early Alcubierre-drive tests under vacuum conditions. Results have been reported as "inconclusive".
Relation to "Star Trek" warp drive.
The "Star Trek" television series used the term "warp drive" to describe their method of faster-than-light travel. Neither the Alcubierre theory, nor anything similar, existed when the series was conceived, but Alcubierre stated in an email to William Shatner that his theory was directly inspired by the term used in the show, and references it in his 1994 paper.

</doc>
