<doc id="42345" url="http://en.wikipedia.org/wiki?curid=42345" title="Hyman G. Rickover">
Hyman G. Rickover

Hyman George Rickover (January 27, 1900 – July 8, 1986) was a United States Navy admiral who directed the original development of naval nuclear propulsion and controlled its operations for three decades as director of Naval Reactors. In addition, he oversaw the development of the Shippingport Atomic Power Station, the world's first commercial pressurized water reactor used for generating electricity.
Rickover is known as the "Father of the Nuclear Navy", which as of July 2007 had produced 200 nuclear-powered submarines, and 23 nuclear-powered aircraft carriers and cruisers, though many of these U.S. vessels are now decommissioned and others under construction.
On 16 November 1973 Rickover was promoted to four-star admiral after 51 years of commissioned service. With his unique personality, political connections, responsibilities, and depth of knowledge regarding naval nuclear propulsion, Rickover became the longest-serving naval officer in U.S. history with 63 years active duty.
Rickover's substantial legacy of technical achievements includes the United States Navy's continuing record of zero reactor accidents, as defined by the uncontrolled release of fission products to the environment subsequent to reactor core damage.
A documentary on his life, "", had its first pre-release screening in February 2014. The film had its official premiere in Washington, D.C. on April 29, 2014, and it was first broadcast on PBS on December 9, 2014.
Early life and education.
Rickover was born Chaim Godalia Rickover, to Abraham Rickover and Rachel (née Unger) Rickover, a Jewish family in Maków Mazowiecki of Poland, at that time ruled by the last Russian tsar, Nicholas II. His parents later changed his name to "Hyman," also derived from the same Hebrew: חַיִּים (Chayyim), meaning "life." He did not use his middle name, Godalia (Yiddish: "God is great"), but when required to list one for the Naval Academy oath, he substituted "George". The family name "Rickover" is derived from the village and the estate of Ryki, located within 100 km of Warsaw, as is Maków Mazowiecki.
Rickover made passage to New York City with his mother and sister Faygele (Americanized: "Fannie") in March 1906, fleeing anti-Semitic Russian pogroms during the Revolution of 1905 that killed over 3,000 Jews, joining Abraham who had made earlier, initial trips there beginning in 1897 to become established. Decades later, the entire remaining Jewish communities of Ryki and Maków Mazowiecki were killed or otherwise perished during the Holocaust.
Rickover's immediate family lived initially on the East Side of Manhattan and moved two years later to the North Lawndale neighborhood in Chicago, which at that time was a heavily Jewish neighborhood, where Rickover's father continued work as a tailor. Rickover took his first paid job at nine years of age, earning three cents an hour for holding a light as his neighbor operated a machine. Later, he delivered groceries. He graduated from grammar school at 14.
While attending John Marshall High School in Chicago (from which he graduated with honors in 1918), Rickover held a full-time job as a telegraph boy delivering Western Union telegrams, through which he became acquainted with U.S. Congressman Adolph J. Sabath, himself a Czech Jewish immigrant. Through the intervention of a family friend, Sabath nominated Rickover for appointment to the United States Naval Academy. Rickover was only a third alternate for appointment, but through disciplined self-directed study and good fortune, the future four-star admiral passed the entrance exam and was accepted.
Early naval career through World War II.
Rickover's active duty naval career began in 1918, during a time when attending military academies was considered active duty service, due in part to World War I. On 2 June 1922, Rickover graduated 107th out of 540 midshipmen and was commissioned as an ensign. He joined the destroyer "La Vallette" on 5 September 1922. Rickover impressed his commanding officer with his hard work and efficiency, and was made engineer officer on 21 June 1923, becoming the youngest such officer in the squadron.
He next served on board the battleship "Nevada" before earning a Master of Science (M.Sc.) in Electrical Engineering by way of a year at the Naval Postgraduate School at the Naval Academy, followed by further work at Columbia University. At Columbia, he met Ruth D. Masters, a Christian and graduate student in international law, whom he married in 1931 after she returned from her doctoral studies at the Sorbonne in Paris. Shortly after marrying, Rickover wrote to his parents of his decision to become an Episcopalian, remaining so for the remainder of his life.
Rickover had a high regard for the quality of the education that he had received at Columbia, as demonstrated in this excerpt from a speech he gave at the university some 52 years after attending, in which he recalled and thanked particular teachers who influenced him:
"In 1929 I attended the Columbia School of Engineering for postgraduate study in electrical engineering. Columbia was the first institution that encouraged me to think rather than memorize. My teachers were notable in that many had gained practical engineering experience outside the university and were able to share their experience with their students. I am grateful, among others, to Professors Morecroft, Hehre, and Arendt. Much of what I have subsequently learned and accomplished in engineering is based on the solid foundation of principles I learned from them. I am therefore especially gratified by your invitation to return and speak this evening."
Rickover preferred life on smaller ships, and he also knew that young officers in the submarine service were advancing quickly, so he went to Washington and volunteered for submarine duty. His application was turned down due to his age, at that time 29 years. Fortunately for Rickover, he ran into his former commanding officer from "Nevada" while leaving the building, who interceded successfully on his behalf. From 1929 to 1933, Rickover qualified for submarine duty and command aboard the submarines "S-9" and "S-48".
While at the Office of the Inspector of Naval Material in Philadelphia, Pennsylvania during 1933, Rickover translated "Das Unterseeboot" ("The Submarine") by World War I German Imperial Navy Admiral Hermann Bauer. Rickover's translation became a basic text for the U.S. submarine service.
On 17 July 1937, he reported aboard the minesweeper "Finch" at Tsingtao, China to relieve Lt. Joseph P. Rockwell, USN. The future longest-serving U.S. Navy officer assumed his only ship-command with additional duty as Commander, Mine Division Three, Asiatic Fleet. The Marco Polo Bridge Incident had occurred ten days earlier, and by mid-August, troops of the National Revolutionary Army of the Republic of China were fighting in downtown Shanghai, China and outlying towns in an ultimately unsuccessful attempt to vanquish invading Imperial Japanese Army troops. In August, "Finch" stood out for Shanghai to protect American citizens and interests from the conflict between out-gunned Chinese troops and the increasingly belligerent Japanese ground, naval, and air forces. On 26 August, "Finch" disembarked 102 U.S. Marines at Shanghai and "observed" two Japanese destroyers firing into Woosung, China. On 26 September, Rickover was promoted to lieutenant commander, retroactive to 1 July. In October, his designation as an engineering duty officer became effective, and he was relieved of his three-month command of "Finch" by Lt. D.S. Evans at Shanghai on 5 October, detaching on 24 October 1937 from "Finch" and what came to be known as the Battle of Shanghai, the first of 22 major engagements fought between the Chinese and Japanese during the Second Sino-Japanese War.
Rickover was assigned to the Cavite Navy Yard in the Philippines, expecting to be transferred shortly to the Bureau of Engineering in Washington, D.C. Rickover arrived in Washington after a trip overland across China, Burma, and India, by air across the Mideast to Athens and then London, and by ship to the U.S. Once there, he took up his duties as assistant chief of the Electrical section of the Bureau of Engineering on 15 August 1939.
On 10 April 1942, after America's entry into World War II, Rickover flew to Pearl Harbor to organize repairs to the electrical power plant of USS "California". In that role he was "a leading figure in putting the ship's electric alternators and motors back into operating condition," enabling the battleship to sail under her own power from Pearl Harbor to Puget Sound Navy Yard.
Rickover had been promoted to the rank of commander on 1 January 1942, and in late June of that year had been made a temporary captain. In late 1944 he appealed for a transfer to an active command. He was sent to investigate inefficiencies at the naval supply depot at Mechanicsburg, Pennsylvania. Having identified a number of problems there he was appointed in July 1945 to command of a ship repair facility on Okinawa.
Later during the war, his service as head of the Electrical Section in the Bureau of Ships brought him a Legion of Merit and gave him experience in directing large development programs, choosing talented technical people, and working closely with private industry. "Time" magazine featured him on the cover of its January 11, 1954 issue. The accompanying article described his wartime service:
"Sharp-tongued Hyman Rickover spurred his men to exhaustion, ripped through red tape, drove contractors into rages. He went on making enemies, but by the end of the war he had won the rank of captain. He had also won a reputation as a man "who gets things done.""
Naval Reactors and the Atomic Energy Commission.
In 1946, an initiative was begun at the Manhattan Project's nuclear-power focused Clinton Laboratory (now the Oak Ridge National Laboratory) to develop a nuclear electric generating plant. The United States Navy decided to send eight men to this project, including three civilians and one senior and four junior naval officers. Realizing the potential that nuclear energy held for the Navy, Rickover applied.
Since December 1945 Rickover had been Inspector General of the 19th Fleet on the west coast. He had been assigned to work with General Electric at Schenectady, New York, to develop a nuclear propulsion plant for destroyers. Rickover was sent to Oak Ridge as the deputy manager of the entire project in May 1946 through the efforts of his wartime boss, Rear Admiral Earle Mills (who became the head of the Navy's Bureau of Ships that same year), granting him access to all facilities, projects, and reports. Following efforts by physicists Ross Gunn, Philip Abelson, and others in the Manhattan Project, he became an early convert to the idea of nuclear marine propulsion.
Rickover's vision was not initially shared by his immediate superiors. He was recalled from Oak Ridge and assigned "advisory duties" with an office in an abandoned ladies room in the Navy Building. He subsequently went around several layers of superior officers, and in 1947 went directly to the Chief of Naval Operations, Fleet Admiral Chester Nimitz, by chance also a former submariner. Nimitz immediately understood the potential of nuclear propulsion and recommended the project to the Secretary of the Navy, John L. Sullivan. Sullivan's endorsement to build the world's first nuclear-powered vessel, USS "Nautilus", later caused Rickover to state that Sullivan was "the true father of the Nuclear Navy."
Subsequently, Rickover became chief of a new section in the Bureau of Ships, the Nuclear Power Division, and began work with Alvin M. Weinberg, the Oak Ridge director of research, both to establish the Oak Ridge School of Reactor Technology and to begin the design of the pressurized water reactor for submarine propulsion.
In February 1949, he received an assignment to the Atomic Energy Commission's Division of Reactor Development, and then assumed control of the Navy's effort as Director of the Naval Reactors Branch in the Bureau of Ships, reporting to Mills. This twin role enabled him to lead the effort to develop "Nautilus", which was launched and commissioned in 1954, as well as to oversee the development of the Shippingport Atomic Power Station, the first commercial pressurized water reactor nuclear power plant.
The decision for selecting Rickover to head the development of the nation's nuclear submarine program ultimately rested with Admiral Mills. According to Lieutenant General Leslie Groves, the primary military leader in charge of the Manhattan Project, Mills was anxious to have a very determined man involved. He knew that Rickover was "not too easy to get along with" and "not too popular," but in his judgment Rickover was the man whom the Navy could depend on "no matter what opposition he might encounter, once he was convinced of the potentialities of the atomic submarine."
Rickover did not disappoint. The imagination, drive, creativity, and engineering expertise demonstrated by Rickover and his team during that era resulted in a highly reliable nuclear reactor in a form-factor that would fit into a submarine hull with no more than a 28-foot beam. These were substantial technical achievements, given that:
Rickover was promoted to the rank of vice admiral in 1958, the same year that he was awarded the first of two Congressional Gold Medals. Rickover exercised tight control for the next three decades over the ships, technology, and personnel of the nuclear Navy, interviewing and approving or denying every prospective officer being considered for a nuclear ship. Over the course of Rickover's record-length career, these personal interviews amounted to tens of thousands of highly impressionable events; over 14,000 interviews were with recent college-graduates alone. These legendary interviews loomed large in the minds of midshipmen from both the U.S. Naval Academy and Naval ROTC. They varied from arcane to combative to humorous, and ranged from midshipmen to very senior naval aviators who sought command of aircraft carriers (which sometimes lapsed into ego battles). The content of most of these interviews has been lost to history, though some were later chronicled in the several books on Rickover's career, as well as in a with Diane Sawyer in 1984.
Rickover's stringent standards and powerful focus on personal integrity are largely credited with being responsible for the United States Navy's continuing record of zero reactor accidents. During the mid-late 1950s, Rickover revealed the source of his obsession with safety in a personal conversation with a fellow Navy captain:
"I have a son. I love my son. I want everything that I do to be so safe that I would be happy to have my son operating it. That's my fundamental rule." (p. 55, "Power at Sea: A Violent Peace, 1946-2006" (2006))
He also made it a point to be aboard during the initial sea trial of almost every nuclear submarine completing its new-construction period, and by his presence both set his stamp of personal integrity that the ship was ready for the rigors of the open seas, and ensured adequate testing to either prove as much or to establish issues requiring resolution.
As head of Naval Reactors, Rickover's focus and responsibilities were dedicated to reactor safety rather than tactical or strategic submarine warfare training. It could be argued that Rickover's singular focus on reactor operations, and his direct line of communications with each nuclear submarine's captain, acted together against the captains' war-fighting abilities. However, the accident-free record of United States Navy reactor operations stands in stark contrast to those of the Soviet Union, America's primary competitor during the Cold War, which had fourteen known reactor accidents.
As stated in a retrospective analysis in October 2007:
"U.S. submarines far outperformed the Soviet ones in the crucial area of stealth, and Rickover's obsessive fixation on safety and quality control gave the U.S. nuclear Navy a vastly superior safety record to the Soviet one. This was especially crucial as in a democratic society, particularly after the Three Mile Island nuclear power station crisis in March 1979, a host of nuclear accidents or well-publicized near misses could have shut down the nuclear fleet completely."
However, the extreme focus on nuclear propulsion plant operation and maintenance was well known during Rickover's era as a potential hindrance to balancing operational priorities. One way by which this was addressed after the admiral retired was that only the very strongest, former at-sea submarine commanders have held Rickover's now unique eight-year position as NAVSEA-08, the longest chartered tenure in the U.S. military. From Rickover's first replacement, Kinnaird R. McKee, to today's head of Naval Reactors, John M. Richardson, all have held command of nuclear submarines, their squadrons and ocean fleets; not one has been a long-term Engineering Duty Officer such as Rickover.
Three Mile Island.
Following the Three Mile Island (TMI) power plant's partial core melt on March 28, 1979, President Jimmy Carter commissioned a study, "Report of the President's Commission on the Accident at Three Mile Island" (1979). Subsequently, Admiral Rickover was asked to testify before Congress in the general context of answering the question as to why naval nuclear propulsion had succeeded in achieving a record of zero reactor-accidents (as defined by the uncontrolled release of fission products to the environment resulting from damage to a reactor core) as opposed to the dramatic one that had just taken place at Three Mile Island. In his testimony, he said:
"Over the years, many people have asked me how I run the Naval Reactors Program, so that they might find some benefit for their own work. I am always chagrined at the tendency of people to expect that I have a simple, easy gimmick that makes my program function. Any successful program functions as an integrated whole of many factors. Trying to select one aspect as the key one will not work. Each element depends on all the others."
Controversy.
Admiral Hyman G. Rickover has been declared in retrospect as "the most famous and controversial admiral of his era." Hyperactive, political, blunt, confrontational, insulting, flamboyant, and an unexcelled workaholic, Rickover was always demanding of others — without regard for rank or position — as well as himself. Moreover, he had "little tolerance for mediocrity, none for stupidity." "If a man is dumb," said a Chicago friend, "Rickover thinks he ought to be dead." Even while a Captain, Rickover did not conceal his opinions, and many of the officers whom he regarded as dumb eventually rose in rank to be admirals and were assigned to the Pentagon.
Rickover found himself frequently and loudly in bureaucratic combat with these senior naval officers, to the point that he almost missed becoming "Admiral" Rickover: Two admiral-selection boards — exclusively made up of admirals — passed over Captain Rickover for promotion, even while he was in the process of becoming famous. One of these selection boards even met the day after USS "Nautilus" had its keel-laying ceremony in the presence of President Truman — and indicative of the Navy's attitude toward the ship's creator, Rickover had not been originally invited to this key event and was only eventually invited by way of his AEC role, not his Navy role. 
It eventually took the intervention of the White House, U.S. Congress, and the Secretary of the Navy — and the very real threat of changing the Navy's admiral-selection system to include civilians — before the next flag-selection board welcomed the twice passed-over Rickover (normally a career-ending event) into their ranks.
Even the most senior, renowned, and professionally accomplished nuclear-trained officers that Rickover had personally selected, such as Edward L. Beach, Jr., had mixed feelings about "the kindly old gentleman," or simply "KOG", as Rickover became euphemistically known in inner circles. Beach, in his later years, once referred to him as a "tyrant" with "no account of his gradually failing powers" (p. 179, "United States Submarines", 2002).
However, President Nixon's comments upon awarding the admiral's fourth star in 1973 are germane:
"I don't mean to suggest ... that he is a man who is without controversy. He speaks his mind. Sometimes he has rivals who disagree with him; sometimes they are right, and he is the first to admit that sometimes he might be wrong. But the greatness of the American military service, and particularly the greatness of the Navy, is symbolized in this ceremony today, because this man, who is controversial, this man, who comes up with unorthodox ideas, did not become submerged by the bureaucracy, because once genius is submerged by bureaucracy, a nation is doomed to mediocrity."
Rickover's military authority and congressional mandate were absolute with regard to the U.S. fleet's reactor operations, but his exceptional degree of control was frequently a subject of internal Navy controversy. He was head of the Naval Reactors branch, and thus responsible for "signing off" on a crew's competence to operate the reactor safely, giving him the power to effectively remove a warship from active service — and he did so on several occasions, much to the consternation of those affected.
In short, Rickover was obsessed with a safe, details-focused, and successful nuclear program. Coincident with this success, the perception became established among many observers that he sometimes used the raw exercise of power to settle scores or tweak noses.
Full accountability.
Rickover adamantly took full responsibility for everything within the scope of the naval nuclear propulsion program (NNPP)--in distinct contrast to numerous examples of admirals and senior naval officers who would point their finger at individuals or groups in the fleet when something went seriously awry. Sample Rickover quote:
"My program is unique in the military service in this respect: You know the expression 'from the womb to the tomb'; my organization is responsible for initiating the idea for a project; for doing the research, and the development; designing and building the equipment that goes into the ships; for the operations of the ship; for the selection of the officers and men who man the ship; for their education and training. In short, I am responsible for the ship throughout its life — from the very beginning to the very end." ("Hearings on Military Posture and H.R. 12564", U.S. G.P.O., 1974, page 1,392)
Distinguishing the academic from the practical.
In a statement to the U.S. Congress in 1953, early on in the development of nuclear reactors, Rickover addressed the confusion amongst the nation's decision-makers in his typical head-on fashion, and notably pointed out the chasm between the world of academia and the world of practical engineering:
“An academic reactor or reactor plant almost always has the following basic characteristics: (1) It is simple. (2) It is small. (3) It is cheap. (4) It is light. (5) It can be built very quickly. (6) It is very flexible in purpose (“omnibus reactor”). (7) Very little development is required. It will use mostly “off-the-shelf” components. (8) The reactor is in the study phase. It is not being built now.
“On the other hand, a practical reactor plant can be distinguished by the following characteristics: (1) It is being built now. (2) It is behind schedule. (3) It is requiring an immense amount of development on apparently trivial items. Corrosion, in particular, is a problem. (4) It is very expensive. (5) It takes a long time to build because of the engineering development problems. (6) It is large. (7) It is heavy. (8) It is complicated.
"The tools of the academic-reactor designer are a piece of paper and pencil with an eraser. It a mistake is made, it can always be erased and changed. If the practical-reactor designer errs, he wears the mistake around his neck; it cannot be erased. Everyone can see it.
“The academic-reactor designer is a dilettante. He has not had to assume any real responsibility in connection with his projects. He is free to luxuriate in elegant ideas, the practical shortcomings of which can be relegated to the category of “mere technical details.” The practical-reactor designer must live with these same technical details. Although recalcitrant and awkward, they must be solved and cannot be put off until tomorrow. Their solutions require manpower, time and money."
Willingness to "sink them all".
Given Rickover's single-minded focus on naval nuclear propulsion, design, and operations, it came as a surprise to many in 1982, near the end of his career, when he testified before the U.S. Congress that, were it up to him, he "would sink them all." A seemingly outrageous enigma of a statement — and perhaps one attributable to an old man beyond his time — in context, Rickover's personal integrity and honesty were such that he was lamenting the need for such war machines in the modern world, and specifically acknowledged as well that the employment of nuclear energy ran counter to the course of nature over time.
At a congressional hearing Rickover testified that:
"I do not believe that nuclear power is worth it if it creates radiation. Then you might ask me why do I have nuclear powered ships. That is a necessary evil. I would sink them all. I am not proud of the part I played in it. I did it because it was necessary for the safety of this country. That's why I am such a great exponent of stopping this whole nonsense of war. Unfortunately limits — attempts to limit war have always failed. The lesson of history is when a war starts every nation will ultimately use whatever weapon it has available." Further remarking: "Every time you produce radiation, you produce something that has a certain half-life, in some cases for billions of years. There are, of course, many other things mankind is doing which, in the broadest sense, are having an adverse impact, such as using up scarce resources. I think the human race is ultimately going to wreck itself. It is important that we control these forces and try to eliminate them." (Economics of Defense Policy: Hearing before the Joint Economic Committee, Congress of the United States, 97th Cong., 2nd sess., Pt. 1 (1982))
However, after his retirement — and only a few months later, in May 1982 — Admiral Rickover spoke more specifically regarding the questions "Could you comment on your own responsibility in helping to create a nuclear navy? Do you have any regrets?":
"I do not have regrets. I believe I helped preserve the peace for this country. Why should I regret that? What I accomplished was approved by Congress — which represents our people. All of you live in safety from domestic enemies because of security from the police. Likewise, you live in safety from foreign enemies because our military keeps them from attacking us. Nuclear technology was already under development in other countries. My assigned responsibility was to develop our nuclear navy. I managed to accomplish this."
Willingness to forgo all accomplishments to avoid nuclear weapons.
As quoted by President Jimmy Carter during his 1984 interview with Diane Sawyer:
"One of the most remarkable things that he ever told me was when we were together on the submarine and he said that he wished that a nuclear explosive had never been evolved. And then he said, 'I wish that nuclear power had never been discovered.' And I said, 'Admiral, this is your life.' He said, 'I would forgo all the accomplishments of my life, and I would be willing to forgo all the advantages of nuclear power to propel ships, for medical research and for every other purpose of generating electric power, if we could have avoided the evolution of atomic explosives.'"
Focus on education.
When he was a child still living in Russian-occupied Poland, Rickover was not allowed to attend public schools because of his Jewish faith. Starting at the age of four, he attended a religious school where the teaching was solely from the "Tanakh", i.e., "Old Testament", in Hebrew. School hours were from sunrise to sunset, six days a week.
Following his formal education in the U.S. as described above and the birth of his son, Robert, Admiral Rickover developed a decades-long and outspoken interest in the educational standards of the United States, stating in 1957:
"I suggest that this is a good time to think soberly about our responsibilities to our descendants - those who will ring out the Fossil Fuel Age. Our greatest responsibility, as parents and as citizens, is to give America's youngsters the best possible education. We need the best teachers and enough of them to prepare our young people for a future immeasurably more complex than the present, and calling for ever larger numbers of competent and highly trained men and women."
Rickover was particularly of the opinion that U.S. standards of education were unacceptably low. His first book centered on education was a collection of essays calling for improved standards of education, particularly in math and science, entitled "Education and Freedom" (1959). In this book, the admiral states that, "education is the most important problem facing the United States today” and “only the massive upgrading of the scholastic standards of our schools will guarantee the future prosperity and freedom of the Republic." A second book, "Swiss Schools and Ours" (1962) was a scathing comparison of the educational systems of Switzerland and America. He argued that the higher standards of Swiss schools, including a longer school day and year, combined with an approach stressing student choice and academic specialization produced superior results.
His persistent interest in education led to some related discussions with President John F. Kennedy. While still on active duty, the admiral had suggested that there are three things that a school must do: First, it must transmit to the pupil a substantial body of knowledge; second, it must develop in him the necessary intellectual skill to apply this knowledge to the problems he will encounter in adult life; and third, it must inculcate in him the habit of judging issues on the basis of verified fact and logical reasoning.
Recognizing "that nurturing careers of excellence and leadership in science and technology in young scholars is an essential investment in the United States national and global future," following his retirement Admiral Rickover founded the Center for Excellence in Education in 1983.
Additionally, the Research Science Institute (formerly the Rickover Science Institute), founded by Admiral Rickover in 1984, is a highly respected summer science program hosted by the Massachusetts Institute of Technology for rising high school seniors from around the world.
Forced retirement.
By the late 1970s, Rickover's position seemed stronger than it had ever been. He had survived more than two decades of attempts by the Navy brass to force him into retirement — including being made to work out of a converted ladies room and being passed over twice for promotion. Over many years, powerful friends on both the House and Senate Armed Services Committees ensured that he remained on active duty long after most other admirals had retired from their second careers.
But on January 31, 1982, in his 80s, Rickover was forced to retire from the Navy as a full admiral by Secretary of the Navy John Lehman, with the knowledge and consent of President Reagan—after 63 years of service to his country under 13 presidents (Woodrow Wilson through Ronald Reagan). This was done in a premeditated fashion. As Lehman, a reservist naval aviator while serving as Secretary of the Navy, put it in his book, "Command of the Seas":
[O]ne of my first orders of business as secretary of the navy would be to solve ... the Rickover problem. Rickover's legendary achievements were in the past. His present viselike grip on much of the navy was doing it much harm. I had sought the job because I believed the navy had deteriorated to the point where its weakness seriously threatened our future security. The navy's grave afflictions included loss of a strategic vision; loss of self-confidence, and morale; a prolonged starvation of resources, leaving vast shortfalls in capability to do the job; and too few ships to cover a sea so great, all resulting in cynicism, exhaustion, and an undercurrent of defeatism. The cult created by Admiral Rickover was itself a major obstacle to recovery, entwining nearly all the issues of culture and policy within the navy.
Fitting to the end of Rickover's decades-long reign and reputation, his career concluded in both a battle with the defense establishment and a coming-to-terms with his own human limitations.
In the early 1980s, structural welding flaws — whose nature and existence had been covered up by falsified inspection records — led to significant delays and expenses in the delivery of several submarines being built at the General Dynamics Electric Boat Division shipyard. In some cases, the repairs resulted in practically dismantling and then rebuilding what had been a nearly completed submarine. The yard tried to pass the vast cost overruns directly on to the Navy, while Rickover fought Electric Boat's general manager tooth and nail at every possible turn, demanding that the yard make good on its shoddy workmanship.
The Navy eventually settled with General Dynamics in 1981, paying out $634 million of $843 million in Los Angeles class submarine cost-overrun and reconstruction claims. Rickover was bitter over the yard having successfully sued the Navy for its own incompetence and deceit. Of no small irony, the United States Navy was also the yard's insurer. The concept of reimbursing General Dynamics under these conditions was initially considered "preposterous," in the words of Secretary Lehman, but the legal basis of General Dynamics' claims included insurance compensation.
Outraged, Rickover furiously lambasted both the settlement and Secretary Lehman, who was partly motivated to seek an agreement in order to continue to focus on achieving President Reagan's goal of a 600-ship Navy. This was hardly Rickover's first clash with the defense industry; he was historically hard, even harsh, in exacting high standards from these contractors – but now his relationship with Electric Boat took on the characteristics of an all-out, no-holds-barred war ("Running Critical: The Silent War, Rickover & General Dynamics", 1986).
Veliotis came to be indicted by a federal grand jury under racketeering and fraud charges in 1983 for demanding $1.3 million in kickbacks from a subcontractor. He nonetheless eventually escaped into exile and a life of luxury in his native Greece where he remains a fugitive from U.S. justice.
Subsequent to accusations by the indicted Veliotis, a Navy Ad Hoc Gratuities Board determined that Rickover had received gifts from General Dynamics over a 16-year period valued at $67,628, including jewelry, furniture, exotic knives and gifts that Rickover had in turn presented to U.S. politicians. Charges were investigated as well that gifts were provided by two other major nuclear ship contractors for the navy, General Electric and the Newport News Shipbuilding and Dry Dock.
Veliotis also charged, without providing substantiating evidence, that General Dynamics had given gifts to other senior naval officers, and had routinely underbid contracts with the intention of charging the government for cost overruns. These charges were not pursued by the Navy, at least in part due to Veliotis' flight from justice.
Secretary Lehman admonished Rickover for this impropriety via a nonpunitive letter and stating that Rickover's "fall from grace with these little trinkets should be viewed in the context of his enormous contributions to the Navy." Rickover released a statement through his lawyer saying his "conscience is clear" with respect to the gifts. "No gratuity or favor ever affected any decision I made." Senator William Proxmire of Wisconsin, a longtime supporter of Rickover, later publicly associated a debilitating stroke suffered by the admiral to his having been censured and "dragged through the mud by the very institution to which he rendered his invaluable service."
Secretary Lehman finally attained enough political clout to have Rickover retired, beyond any personal enmity or power struggles between the two naval leaders, through Rickover's nearly insubordinate stance against paying the fraudulently inflated submarine construction claims—as well as his advanced age and waning political power regarding nuclear power. On July 27, 1981, Lehman gained the final impetus for ending Rickover's career through a moderate loss of ship control and depth excursion while performing a submerged "crash back" maneuver during the sea trials of the newly constructed . Rickover was the actual man-in-charge during this specific performance test, and his actions and inactions came to be viewed as the causal factor.
Upon being apprised of Lehman's decision that it was time for the admiral to finally retire, President Reagan asked to meet with Rickover. As quoted from Lehman's "Command of the Seas", Rickover was unhappy with the course of events and held forth in a tirade against Lehman, with Secretary of Defense Caspar Weinberger in attendance, at the meeting with the President:
(Rickover, referring to Lehman:) "Mr. President, that piss-ant knows nothing about the Navy." The admiral turned toward (Lehman) and raised his voice now to a fearsome shout. "You just want to get rid of me, you want me out of the program because you want to dismantle the program." Shifting now toward President Reagan, he roared on: "He's a goddamn liar, he knows he is just doing the work of the contractors. The contractors want me fired because of all the claims and because I am the only one in the government who keeps them from robbing the taxpayers."
 (Lehman, as later quoted by CNN:) "... it was a difficult moment for the president in the Oval Office. And he was so concerned about the man, about Admiral Rickover and that he not be embarrassed, that he asked us all to leave. He said, "Admiral Rickover and I see things the same way. Could you leave us a while? We want to talk about policy."
The meeting ended as follows, according to former President Jimmy Carter, who had served as an officer in the nuclear submarine program under Rickover:
[In the context of Rickover's recommendation to Carter that he again run for president, after first remaining quiet for a couple of years:] "Admiral Rickover never had much political judgment, but he understood the relationships among the Congress, defense contractors, and the Department of Defense as well as anyone. His long and distinguished career ended abruptly: in late 1981 Rickover's wife heard on the radio that President Reagan had retired the admiral, who was on a new submarine conducting sea trials, and she had to give him the news. Several weeks later, he was invited to the Oval Office and decided to don his full dress uniform. He told me that he refused to take a seat, listened to the president ask him to be his special nuclear advisor, replied 'Mr. President that is bullshit,' and then walked out."
The Navy's official investigation of General Dynamics' Electric Boat division was ended shortly afterward. According to Theodore Rockwell, Rickover's Technical Director for more than 15 years, more than one source at that time stated that General Dynamics officials were bragging around Washington that they had "gotten Rickover."
On February 28, 1983, a post-retirement party honoring Admiral Rickover was attended by all three living former U.S. Presidents at the time, Nixon, Ford, and Carter, all of whom were formerly officers in the U.S. Navy. President Reagan was not in attendance.
Final public words and thoughts.
Admiral Rickover's final public remarks after his retirement included a lecture in May 1982 at the Morgenthau Memorial Lecture series under the auspices of the Carnegie Council (""The Voice for Ethics in International Policy")," developed and polished over the course of the last five of his 63 years of public service.
In his lecture "Thoughts On Man's Purpose in Life", Rickover presented his summary comments on the subject, drawing upon wide-ranging philosophers and dignitaries such as Voltaire, Emerson, Sir Thomas More, Robert Browning, President Theodore Roosevelt, Justice Louis Brandeis, Aristotle, and Martin Luther, as well as extracts from the "I Ching." He presented some of the fundamentally guiding thoughts and beliefs that he had acquired during his lifetime.
Rickover's core comments centered around the thoughts that "principles of existence — responsibility, perseverance, excellence, creativity, courage — must be wedded to intellectual growth and development if we are to find meaning and purpose in our lives" and that "a final principle of existence essential to man's purpose in life is the development of standards of ethical and moral conduct."
Earnest in pointing out the triumph of action over thoughts alone, Rickover's comments included the following:
"Man has a large capacity for effort. In fact it is so much greater than we think it is that few ever reach this capacity.
We should value the faculty of knowing what we ought to do and having the will to do it. Knowing is easy; it is the doing that is difficult. The critical issue is not what we know but what we "do" with what we know. The great end of life is not knowledge, but action.
I believe that it is the duty of each of us to act as if the fate of the world depended on him ... we must live for the future, not for our own comfort or success."
He closed his remarks at the lecture with a question and answer period that addressed various aspects of Rickover's public service record, opinions, philosophies and anticipation for the future.
Death.
After suffering strokes, pneumonia and generally declining health over time, Admiral Rickover died at his home in Arlington, Virginia, on Tuesday, July 8, 1986 at 86 years of age, the same as that of his father, Abraham, before him. He was buried the Friday of that same week in a small, private ceremony at Arlington National Cemetery. On Monday, July 14, 1986, memorial services were led by Admiral James D. Watkins at the Washington National Cathedral, with President Carter, Secretary of State George P. Shultz, Secretary Lehman, senior naval officers and about 1,000 other people in attendance. Mrs. Rickover had asked President Carter to read from John Milton's "On His Blindness". Carter was at first puzzled by her choice, but then came to believe that the last line had special meaning for all wives and family members of submariners who were away at sea: "They also serve who only stand and wait."
Clearly a man of conscience, despite Admiral Rickover's last public and instructive remarks he went to his deathbed questioning the meaning and purpose of his own life, and specifically whether or not it was led in consonance with God's intentions ("How the hell are you supposed to know what God wants you to do with your life, eh?"). Milton's poetic words regarding a man's inherent blindness and potential-yet-unknown ability to otherwise serve God may well thus have also held a special meaning to Rickover himself, as it paradoxically answers one of the admiral's last questions in life:
Admiral Rickover is buried in Section 5 at Arlington National Cemetery. His first wife, Ruth Masters Rickover (1903–1972), is buried with him and the name of his second wife, Eleonore A. Bednowicz Rickover, whom he met and married while she was serving as a Commander in the Navy Nurse Corps, is also inscribed on his gravestone. He is survived by Eleanore and by Robert Rickover, his sole son by his first wife, who today teaches the Alexander Technique.
At Arlington, Rickover's burial site overlooks the John F. Kennedy Eternal Flame. Of note, it was Rickover who gave President Kennedy the old Breton fisherman’s prayer plaque, which states, "O God, thy sea is so great and my boat is so small." The plaque is displayed in the John F. Kennedy Presidential Library and Museum as part of the Oval Office exhibit.
During the last century, only a few names naturally come to mind of those who have made a truly major impact on both their navies and their nations: Mahan, Fisher and Gorshkov. Rickover joined them. Creating a detail-focused pursuit of excellence to a degree previously unknown, he redirected the United States Navy’s ship propulsion, quality control, personnel selection, and training and education, and has had far reaching effects on the defense establishment and the civilian nuclear energy field.
Honorariums.
The "Los Angeles"-class submarine USS "Hyman G. Rickover" (SSN-709) was named for him. It was commissioned two years before the admiral's death, making it one of the relatively few United States Navy ships to be named for a living person.
USS "Hyman G. Rickover" was launched on August 27, 1983, sponsored by the admiral's second wife, Mrs. Eleonore Ann Bednowicz Rickover, commissioned on July 21, 1984, and deactivated on December 14, 2006.
In 2015 the navy announced that a new Virginia class submarine, "USS Hyman G. Rickover" (SSN-795) would be named for Rickover.
"Rickover Hall" at the United States Naval Academy, houses the departments of Mechanical Engineering, Naval Architecture, Ocean Engineering, Aeronautical and Aerospace Engineering. "Rickover Center" at Naval Nuclear Power Training Command, where officer and enlisted U.S. Navy personnel begin their engineering training, is located at Joint Base Charleston.
In 2011, the U.S. Navy Museum included Admiral Rickover as part of the "Technology for the Nuclear Age: Nuclear Propulsion" display for its Cold War exhibit, which featured the following, most-often misquoted quote:
Others:
Awards.
Decorations and Medals
Foreign Order
Qualification Badge
In recognition of his wartime service, he was made Honorary Commander of the Military Division of the Most Excellent Order of the British Empire in 1946.
Admiral Rickover was twice awarded the Congressional Gold Medal for exceptional public service; the first in 1958, and the second 25 years later in 1983, becoming one of only three persons to be awarded more than one. In 1980, President Jimmy Carter presented Admiral Rickover with the Presidential Medal of Freedom, the nation's highest non-military honor, for his contributions to world peace.
He also received 61 civilian awards and 15 honorary degrees, including the prestigious Enrico Fermi Award "For engineering and demonstrative leadership in the development of safe and reliable nuclear power and its successful application to our national security and economic needs." In addition to the Enrico Fermi Award, some of the most notable awards include:
Some of his Honorary degrees included:
Resources.
In order of publication:

</doc>
<doc id="42348" url="http://en.wikipedia.org/wiki?curid=42348" title="First Amendment (disambiguation)">
First Amendment (disambiguation)

The First Amendment or Amendment One/1 may refer to the:

</doc>
<doc id="42350" url="http://en.wikipedia.org/wiki?curid=42350" title="List of IOC country codes">
List of IOC country codes

The International Olympic Committee (IOC) uses three-letter abbreviation country codes to refer to each group of athletes that participate in the Olympic Games. Each code usually identifies a National Olympic Committee (NOC), but there are several codes that have been used for other instances in past Games, such as teams composed of athletes from multiple nations, or groups of athletes not formally representing any nation.
Several of the IOC codes are different from the standard ISO 3166-1 alpha-3 codes. Other sporting organisations, such as FIFA, use similar country codes to refer to their respective teams, but with some differences. Still others, such as the Commonwealth Games Federation or Association of Tennis Professionals, use the IOC list verbatim.
History.
The 1956 Winter Olympics and 1960 Summer Olympics were the first Games to feature "Initials of Nations" to refer to each NOC in the published official reports. However, the codes used at the next few Games were often based on the host nation's language (e.g., GIA for Japan at the 1956 Winter Olympics and 1960 Summer Olympics, both held in Italy, from Italian "Giappone") or based on the French name for the nation (e.g., COR for Korea, from "Corée"). By the 1972 Winter Olympics, most codes were standardized on the current usage, but several have changed in recent years. Additionally, the dissolution of the Soviet Union, division and unification of Germany, breakup of Yugoslavia, dissolution of Czechoslovakia, and several other instances of geographical renaming have all resulted in code changes.
In addition to this list of over 200 NOCs, the participation of National Paralympic Committees (NPCs) at the Paralympic Games requires standardised IOC codes, such as Macau and the Faroe Islands, coded MAC and FRO respectively.
Current NOCs.
There are 205 current NOCs (National Olympic Committees) within the Olympic Movement. The following tables show the currently used code for each NOC and any different codes used in past Games, per the official reports from those Games. Some of the past code usage is further explained in the following sections. Codes used specifically for a Summer Games only or a Winter Games only, within the same year, are indicated by "S" and "W" respectively.
Historic NOCs and teams.
Codes still in use.
Fourteen historical NOCs or teams have codes that are still used in the IOC results database to refer to past medal winners from these teams.
Obsolete codes.
Two other significant code changes have occurred, both because of a change in the nation's designation as used by the IOC:
References.
</dl>

</doc>
<doc id="42353" url="http://en.wikipedia.org/wiki?curid=42353" title="Acupressure">
Acupressure

Acupressure [from Latin acus "needle" (see acuity) + pressure (n.)] is an alternative medicine technique similar in principle to acupuncture. It is based on the concept of life energy which flows through "meridians" in the body. In treatment, physical pressure is applied to acupuncture points with the aim of clearing blockages in these meridians. Pressure may be applied by hand, by elbow, or with various devices.
Some medical studies have suggested that acupressure may be effective at helping manage nausea and vomiting, for helping lower back pain, tension headaches, stomach ache, among other things, although such studies have been found to have a high likelihood of bias. It may probably not be as effective as acupuncture, but some claim it provides temporary relief.
According to Quackwatch acupressure is a dubious practice, and its practitioners use irrational methods.
Background.
Acupoints used in treatment may or may not be in the same area of the body as the targeted symptom. The traditional Chinese medicine (TCM) theory for the selection of such points and their effectiveness is that they work by stimulating the meridian system to bring about relief by rebalancing yin, yang and qi (also spelled "chi").
Many East Asian martial arts also make extensive study and use of acupressure for self-defense and health purposes, (chin na, tui na). The points or combinations of points are said to be used to manipulate or incapacitate an opponent. Also, martial artists regularly massage their own acupressure points in routines to remove blockages from their own meridians, claiming to thereby enhance their circulation and flexibility and keeping the points "soft" or less vulnerable to an attack.
Efficacy.
A 2011 systematic review of acupressure's effectiveness at treating symptoms found that 35 out of 43 randomized controlled trials had concluded that acupressure was effective at treating certain symptoms; however, the nature of these 43 studies "indicated a significant likelihood of bias." The authors of this systematic review concluded that this "review of clinical trials from the past decade did not provide rigorous support for the efficacy of acupressure for symptom management. Well-designed, randomized controlled studies are needed to determine the utility and efficacy of acupressure to manage a variety of symptoms in a number of patient populations."
A 2011 Cochrane review of four trials using acupuncture and nine studies using acupressure to control pain in childbirth concluded that "acupuncture or acupressure may help relieve pain during labour, but more research is needed". Another Cochrane Collaboration review found that massage provided some long-term benefit for low back pain, and stated: "It seems that acupressure or pressure point massage techniques provide more relief than classic (Swedish) massage, although more research is needed to confirm this." 
P6 acupuncture point.
An acupressure wristband that is claimed to relieve the symptoms of motion sickness and other forms of nausea provides pressure to the P6 acupuncture point, a point that has been extensively investigated. The Cochrane Collaboration reviewed the use of P6 for nausea and vomiting, and found it to be effective for reducing post-operative nausea, but not vomiting. The Cochrane review included various means of stimulating P6, including acupuncture, electro-acupuncture, transcutaneous nerve stimulation, laser stimulation, acustimulation device and acupressure; it did not comment on whether one or more forms of stimulation were more effective. EBM reviewer Bandolier said that P6 in two studies showed 52% of patients with control having a success, compared with 75% with P6.
Quackwatch includes acupressure in a list of methods which have no "rational place" as massage therapy and states that practitioners "may also use irrational diagnostic methods to reach diagnoses that do not correspond to scientific concepts of health and disease."
Theory.
A variant system known as two point acupressure attempts to bypass a blockage of vital flow by using one acupoint to create a link with one of the collateral meridians, and then using one additional acupoint to stimulate or reduce the flow around the obstruction.
Criticism.
Clinical use of acupressure frequently relies on the conceptual framework of Traditional Chinese Medicine (TCM). There is no physically verifiable anatomical or histological basis for the existence of acupuncture points or meridians. Proponents reply that TCM is a prescientific system that continues to have practical relevance. Acupuncturists tend to perceive TCM concepts in functional rather than structural terms (e.g., as being useful in guiding evaluation and care of patients).
Instruments.
There are several different instruments for applying nonspecific pressure by rubbing, rolling, or applying pressure on the reflex zones of the body. The acuball is a small ball made of rubber with protuberances that is heatable. It is used to apply pressure and relieve muscle and joint pain. The energy roller is a small cylinder with protuberances. It is held between the hands and rolled back and forth to apply acupressure. The foot roller (also "krupa chakra") is a round, cylindrical roller with protuberances. It is placed on the floor and the foot is rolled back and forth over it. The power mat (also pyramid mat) is a mat with small pyramid-shaped bumps that you walk on. The spine roller is a bumpy roller containing magnets that is rolled up and down the spine. The Teishein is one of the original nine classical acupuncture needles described in the original texts of acupuncture. Even though it is described as an acupuncture needle it did not pierce the skin. It is used to apply rapid percussion pressure to the points being treated.

</doc>
<doc id="42357" url="http://en.wikipedia.org/wiki?curid=42357" title="Elizabeth Taylor">
Elizabeth Taylor

Dame Elizabeth Rosemond "Liz" Taylor, DBE (February 27, 1932 – March 23, 2011) was a British-American actress. From her early years as a child star with MGM, she became one of the great screen actresses of Hollywood's Golden Age. As one of the world's most famous film stars, Taylor was recognized for her acting ability and for her glamorous lifestyle, beauty, and distinctive dark blue eyes, which famously appeared to be violet.
"National Velvet" (1944) was Taylor's first success, and she starred in "Father of the Bride" (1950), "A Place in the Sun" (1951), "Giant" (1956), "Cat on a Hot Tin Roof" (1958), and "Suddenly, Last Summer" (1959). She won the Academy Award for Best Actress for "BUtterfield 8" (1960), played the title role in "Cleopatra" (1963), and married her co-star Richard Burton. They appeared together in 11 films, including "Who's Afraid of Virginia Woolf?" (1966), for which Taylor won a second Academy Award. From the mid-1970s, she appeared less frequently in film, and made occasional appearances in television and theatre.
Her much-publicized personal life included eight marriages and several life-threatening illnesses. From the mid-1980s, Taylor championed HIV and AIDS programs; she co-founded the American Foundation for AIDS Research in 1985, and The Elizabeth Taylor AIDS Foundation in 1991. She received the Presidential Citizens Medal, the Legion of Honour, the Jean Hersholt Humanitarian Award and a Life Achievement Award from the American Film Institute, who named her seventh on their list of the "Greatest American Screen Legends". Taylor died of congestive heart failure in March 2011 at the age of 79, having suffered many years of ill health.
Early life.
Elizabeth Rosemond Taylor was born at Heathwood on February 27, 1932, her parents' home at 8 Wildwood Road in Hampstead Garden Suburb, a northwestern suburb of London. She was the daughter of Francis Lenn Taylor (1897–1968) and Sara Sothern (née Sara Viola Warmbrodt; 1895–1994), who were United States Citizens residing in England. Taylor had one older brother named Howard (born 1929). Her parents were originally from Arkansas City, Kansas. Francis Taylor was an art dealer, and Sara was a former actress whose stage name was "Sara Sothern". Sothern retired from the stage in 1926 when she married Francis in New York City. Taylor's two first names are in honor of her paternal grandmother, Elizabeth Mary (Rosemond) Taylor. One of her maternal great-grandfathers was Swiss.
Colonel Victor Cazalet, one of their closest friends, had an important influence on the family. He was a rich, well-connected bachelor, a Member of Parliament and close friend of Winston Churchill. Cazalet loved both art and theatre and was passionate when encouraging the Taylor family to think of England as their permanent home. Additionally, as a Christian Scientist and lay preacher, his links with the family were spiritual. He also became Elizabeth's godfather. In one instance, when she was suffering with a severe infection as a child, she was kept in her bed for weeks. She "begged" for his company: "Mother, please call Victor and ask him to come and sit with me.":14
Biographer Alexander Walker suggests that Elizabeth's conversion to Judaism at the age of 27 and her lifelong support for Israel, may have been influenced by views she heard at home. Walker notes that Cazalet actively campaigned for a Jewish homeland, and her mother also worked in various charities, which included sponsoring fundraisers for Zionism. Her mother recalls the influence that Cazalet had on Elizabeth:
Victor sat on the bed and held Elizabeth in his arms and talked to her about God. Her great dark eyes searched his face, drinking in every word, believing and understanding.:14
A dual citizen of the United Kingdom and the United States, she was born British through her birth on British soil and a US citizen through her parents. In October 1965, as her then-husband was British, she signed an oath of renunciation at the U.S. Embassy in Paris, but with the phrase "abjure all allegiance and fidelity to the United States" struck out. U.S. State Department officials declared that her renunciation was invalid due to the alteration and Taylor signed another oath, this time without alteration, in October 1966. She applied for restoration of U.S. citizenship in 1977, during then-husband John Warner's Senate campaign, stating she planned to remain in America for the rest of her life.
At the age of three, Taylor began taking ballet lessons. Shortly before the beginning of World War II, her parents decided to return to the United States to avoid hostilities. Her mother took the children first, arriving in New York in April 1939, while her father remained in London to wrap up matters in his art business, arriving in November. They settled in Los Angeles, California, where her father established a new art gallery, which included many paintings he shipped from England. The gallery soon attracted numerous Hollywood celebrities who appreciated its modern European paintings. According to Walker, the gallery "opened many doors for the Taylors, leading them directly into the society of money and prestige" within Hollywood's movie colony.:27
Acting career.
Child actress.
Soon after settling in Los Angeles, Taylor's mother discovered that Hollywood people "habitually saw a movie future for every pretty face". Some of her mother's friends, and even total strangers, urged her to have Taylor screen-tested for the role of Bonnie Blue, Scarlett's child in "Gone with the Wind", then being filmed. Her mother refused the idea, as a child actress in film was alien to her, and in any case they would return to England after the war.:28
Hollywood columnist Hedda Hopper introduced the Taylors to Andrea Berens, the fiancée of John Cheever Cowdin, chairman and major shareholder of Universal Pictures. Berens insisted that Sara take Taylor to see Cowdin who, she assured, would be dazzled by her breathtaking beauty. Metro-Goldwyn-Mayer also became interested in Taylor, and MGM head Louis B. Mayer reportedly told his producer, "Sign her up, sign her up! What are you waiting for?" As a result, she soon had both Universal and MGM willing to place her under contract. When Universal learned that MGM was equally interested, however, Cowdin telephoned Universal from New York: "Sign her up, he ordered, don't even wait for the screen test." Universal then gave her a seven-year contract.:31
Taylor appeared in her first motion picture at the age of nine in "There's One Born Every Minute" (1942), her only film for Universal.
After less than a year, however, the studio fired Taylor for unknown reasons. Some speculate that she did not live up to Cowdin's promise. Walker believes that Taylor's intuition told her "she wasn't really welcome at Universal." She learned, for instance, that her casting director complained, "The kid has nothing", after a test. Even her beautiful eyes did not impress him. Taylor's eyes were a deep blue that appeared violet and stunned those who met her in person, with a mutation that gave Taylor double eyelashes "Her eyes are too old, she doesn't have the face of a child," he said.:32
But Walker admits that "this was not so far off the mark as it may appear now". He explains:
There "was" something slightly odd about Elizabeth's looks, even at this age—an expression that sometimes made people think she was older than she was. She already had her mother's air of concentration. Later on, it would prove an invaluable asset. At the time, it disconcerted people who compared her unfavorably with Shirley Temple's cute bubbling innocence or Judy Garland's plainer and more vulnerable juvenile appeal.:32
Taylor herself remembers that when she was a child in England, adults used to describe her as having an "old soul," because, as she says, "I was totally direct." She also recognized similar traits in her baby daughter:
I saw my daughter as a baby, before she was a year old, look at people, steadily, with those eyes of hers, and see people start to fidget, and drop things out of their pockets and finally, unable to stand the heat, get out of the room.
Taylor's father served as an air raid warden with MGM producer Sam Marx, and learned that the studio was searching for an English actress for a Lassie film. Taylor received the role and was offered a long-term contract at the beginning of 1943. She chose MGM because "the people there had been nicer to her when she went to audition", Taylor recalled.:32 MGM's production chief, Benny Thau, was to remain the "only MGM executive" she fully trusted during subsequent years, because, writes Walker, "he had, out of kindly habit, made the gesture that showed her she was loved".:32 Thau remembered her as a "little dark-haired beauty ... [with] those strange and lovely eyes that gave the face its central focus, oddly powerful in someone so young.":34 MGM, in addition, was considered a "glamorous studio", boasting that it had "more stars than there are in heaven." Before Taylor's mother would sign the contract, however, she sought certainty that Taylor had a "God-given talent" to become an actress. Walker describes how they came to a decision:
[Mrs. Taylor] wanted a final sign of revelation ... Was there a divine plan for her? Mrs. Taylor took her old script for "The Fool", in which she had played the scene of the girl whose faith is answered by a miracle cure. Now she asked Elizabeth to read her own part, while she read the lines of the leading man. She confessed to weeping openly. She said, 'There sat my daughter playing perfectly the part of the child as I, a grown woman, had tried to do it. It seemed that she must have been in my head all those years I was acting'.:38–39
Adolescent star.
MGM cast Taylor in "Lassie Come Home" (1943) with child-star Roddy McDowall, with whom she would share a lifelong friendship. He later recalled regarding her beauty, "who has double eyelashes except a girl who was absolutely born to be on the big screen?" The film received favorable attention for both actors, and MGM signed Taylor to a conventional seven-year contract, starting at $100 a week with regular raises. Her first assignment under her new contract was a loan-out to 20th Century Fox for the character of Helen Burns in a film version of the Charlotte Brontë novel "Jane Eyre" (1943). Taylor returned to England to appear in another McDowall picture for MGM, "The White Cliffs of Dover" (1944).
Taylor's persistence in seeking the role of Velvet Brown in MGM's "National Velvet" made her a star at the age of 12. Her character was a young girl, training her beloved horse to win the Grand National. "Velvet", which costarred fellow young actor Mickey Rooney and English newcomer Angela Lansbury, became a great success upon its release in December 1944. Many years later Taylor called it "the most exciting film" she had ever made, although the film caused many of her later back problems due to her falling off a horse during filming.
As Walker states in Taylor's biography, viewers and critics "fell in love with Elizabeth Taylor when they saw her in it" and he explained why the film was popular:
Its enormous popularity rubs off on to its heroine because she expresses, with the strength of an obsession, the aspirations of people—people who have never seen a girl on horseback, or maybe even a horse race for that matter—who believe that anything is possible ... A philosophy of life, in other words ... a film which ... has acquired the status of a generational classic ...:41
"National Velvet" grossed over US$4 million and MGM signed Taylor to a new long-term contract. Because of the movie's success she was cast in another animal film, "Courage of Lassie" (1946), in which Bill the dog outsmarts the Japanese. The film's success led to another contract for Taylor paying her $750 per week. Her roles as the neurotic Mary Skinner in a loan-out to Warner Brothers' "Life With Father" (1947), Cynthia Bishop in "Cynthia" (1947), Carol Pringle in "A Date with Judy" (1948), and Susan Prackett in "Julia Misbehaves" (1948) were all successful. Taylor earned a reputation as a consistently successful adolescent actress, with a nickname of "One-Shot Liz" (referring to her ability to shoot a scene in one take) and a promising career. Taylor's portrayal of Amy in the American classic "Little Women" (1949) was her last adolescent role.
MGM studios provided schooling for its child stars with classrooms within the studio grounds. Taylor, however, came to dislike being cut off from typical schools with average students who were not treated like stars. She recalls her life before studio acting as a happier period in her childhood:
One of the few times I've ever really been happy in my life was when I was a kid before I started acting. With the other kids I'd make up games, play with dolls, pretend games ... As I got more famous—after "National Velvet", when I was 12—I still wanted to be part of their lives, but I think in a way they began to regard me as a sort of an oddity, a freak.<br>
I hated school—because it wasn't school. I wanted terribly to be with kids. On the set the teacher would take me by my ear and lead me into the schoolhouse. I would be infuriated; I was 16 and they weren't taking me seriously. Then after about 15 minutes I'd leave class to play a passionate love scene as Robert Taylor's wife.
Transition into adult roles.
The teenage Taylor was reluctant to continue making films. Her stage mother forced Taylor to relentlessly practice until she could cry on cue and watched her during filming, signaling to change her delivery or a mistake. Taylor met few others her age on movie sets, and was so poorly educated that she needed to use her fingers to do basic arithmetic. When, at age 16, Taylor told her parents that she wanted to quit acting for a normal childhood, Sara Taylor told her that she was ungrateful: "You have a responsibility, Elizabeth. Not just to this family, but to the country now, the whole world".
In October 1948, Taylor sailed aboard the to England to begin filming "Conspirator". Unlike some other child actors, Taylor made an easy transition to adult roles. Before "Conspirator"‍‍ '​‍s 1949 release, a "TIME" cover article called her "a jewel of great price, a true star sapphire", and the leader among Hollywood's next generation of stars such as Montgomery Clift, Kirk Douglas, and Ava Gardner. The petite Taylor had the figure of a mature woman, with a 19" waist. "Conspirator" failed at the box office, but 16-year-old Taylor's portrayal of a 21-year-old debutante who unknowingly marries a communist spy played by 38-year old Robert Taylor, was praised by critics for her first adult lead in a film. Taylor's first picture under her new salary of $2,000 per week was "The Big Hangover"(1950), both a critical and box office failure, that paired her with screen idol Van Johnson. The picture also failed to present Taylor with an opportunity to exhibit her newly realized sensuality.
Her first box office success in an adult role came as Kay Banks in the comedy "Father of the Bride" (1950), alongside Spencer Tracy and Joan Bennett. The film spawned a sequel, "Father's Little Dividend" (1951), which Taylor's co-star Spencer Tracy summarized with "boring... boring... boring". The film did well at the box office, but it would be Taylor's next picture that would set the course for her career as a dramatic actress.
In late 1949, Taylor had begun filming George Stevens' "A Place in the Sun". Upon its release in 1951, Taylor was hailed for her performance as Angela Vickers, a spoiled socialite who comes between George Eastman (Montgomery Clift) and his poor, pregnant factory-working girlfriend Alice Tripp (Shelley Winters). The film, based on Theodore Dreiser's novel, "An American Tragedy," was an indictment of "the American dream" and its corrupting influences, notes biographer Kitty Kelley.
Although Taylor, then only 17, was unaware of the psychological implications of the story and its powerful nuances, it became the pivotal performance of Taylor's career. Kelley explains that Stevens, its director, knew that with Elizabeth Taylor as the young and beautiful star, the "audience would understand why George Eastman (Clift) would kill for a place in the sun with her." Hollywood columnist Hedda Hopper, allowed on the set to watch the filming, became "wide-eyed watching the little girl from "National Velvet" seduce Montgomery Clift in front of the camera," writes Kelley. When the scene was over, Hopper went to her, "Elizabeth, where on earth did you ever learn how to make love like that?"
Critics acclaimed the film as a classic, a reputation it sustained throughout the next 50 years of cinema history. "The New York Times"‍ '​ A.H. Weiler wrote, "Elizabeth's delineation of the rich and beauteous Angela is the top effort of her career", and the "Boxoffice" reviewer unequivocally stated "Miss Taylor deserves an Academy Award".
Taylor became increasingly unsatisfied with the roles being offered to her at the time. While she wanted to play the lead roles in "The Barefoot Contessa" and "I'll Cry Tomorrow", MGM continued to restrict her to mindless and somewhat forgettable films such as: a cameo as herself in "Callaway Went Thataway" (1951), "Love Is Better Than Ever" (1952), "Ivanhoe" (1952), and "The Girl Who Had Everything" (1953).
Taylor's next screen endeavor, "Rhapsody" (1954), another tedious romantic drama, proved equally frustrating. Taylor portrayed Louise Durant, a beautiful rich girl in love with a temperamental violinist (Vittorio Gassman) and an earnest young pianist (John Ericson). A film critic for the "New York Herald Tribune" wrote: "There is beauty in the picture all right, with Miss Taylor glowing into the camera from every angle... but the dramatic pretenses are weak, despite the lofty sentences and handsome manikin poses."
Taylor's fourth period picture, "Beau Brummell", made just after "Elephant Walk" and "Rhapsody", cast her as the elaborately costumed Lady Patricia, which many felt was only a screen prop—a ravishing beauty whose sole purpose was to lend romantic support to the film's title star, Stewart Granger."The Last Time I Saw Paris" (1954) fared only slightly better than her previous pictures, with Taylor being reunited with "The Big Hangover" costar Van Johnson. The role of Helen Ellsworth Willis was based on that of Zelda Fitzgerald and, although pregnant with her second child, Taylor went ahead with the film, her fourth in 12 months. Although proving somewhat successful at the box office, she still yearned for more substantial roles.
1955–79.
Following a more substantial role opposite Rock Hudson and James Dean in George Stevens' epic "Giant" (1956), Taylor was nominated for an Academy Award for Best Actress four years in a row for "Raintree County" (1957) opposite Montgomery Clift; "Cat on a Hot Tin Roof" (1958) opposite Paul Newman; "Suddenly, Last Summer" (1959) with Montgomery Clift, Katharine Hepburn and Mercedes McCambridge; and finally winning for "BUtterfield 8" (1960). The film co-starred then-husband Eddie Fisher and ended her contract, which Taylor said had made her an "MGM chattel" for 18 years.
"Suddenly, Last Summer"'s success placed Taylor among the box-office top-ten, and she remained there almost every year for the next decade. In 1960, Taylor became the highest-paid actor in Hollywood when she signed a $1 million dollar contract to play the title role in 20th Century Fox's lavish production of "Cleopatra", which was released in 1963. During the filming, she began a romance with her future husband Richard Burton, who played Mark Antony in the film. The romance received much attention from the tabloid press, as both were married to other spouses at the time. Taylor ultimately received $7 million for her role.
Her second Academy Award, also for Best Actress in a Leading Role, was for her performance as Martha in "Who's Afraid of Virginia Woolf?" (1966), playing opposite then-husband Richard Burton. The film was a turning point for both Taylor and Burton, as it was the "most exciting and daunting project either of them had ever contemplated," writes Walker. Taylor saw the film as her chance to act, "to really "act"," and a chance to emulate one of her favorite dramatic actresses, Vivien Leigh, who played roles as a "tragic heroine." For this part, however, Taylor worried that she did not look old enough, as her character was to be twenty years older. To compensate, she added gray hairs and transformed herself both physically and vocally: she intentionally gained weight, minimized makeup, and added excessive mascara to her eyes along with smudgy bags beneath them.:281–282
Taylor and Burton appeared together in six other films during the decade, among them "The V.I.P.s" (1963), "The Sandpiper" (1965), and "The Taming of the Shrew" (1967). By 1967 their films had earned $200 million at the box office. When Taylor and Burton considered not working for three months, the possibility caused alarm in Hollywood as "nearly half of the U.S. film industry's income" came from movies starring one or both of them. Their next films "Doctor Faustus" (1967), "The Comedians" (1967) and "Boom!" (1968), however, all failed at the box office.
Taylor appeared in John Huston's "Reflections in a Golden Eye" (1967) opposite Marlon Brando (replacing Clift, who died before production began) and "Secret Ceremony" (1968) opposite Mia Farrow. By the end of the decade her box-office drawing power had considerably diminished, as evidenced by the failure of "The Only Game in Town" (1970), with Warren Beatty.
Although limited by a "thin and inflexible voice", Taylor continued to star in numerous theatrical films throughout the 1970s, such as "Zee and Co." (1972) with Michael Caine, "Ash Wednesday" (1973), "The Blue Bird" (1976) with Jane Fonda and Ava Gardner, and "A Little Night Music" (1977). With then-husband Richard Burton, she co-starred in the 1972 films "Under Milk Wood" and "Hammersmith Is Out", and the 1973 made-for-TV movie "Divorce His, Divorce Hers".
1980–2003.
Taylor starred in the 1980 mystery film "The Mirror Crack'd", based on an Agatha Christie novel. In 1985, she played movie gossip columnist Louella Parsons in the TV film "Malice in Wonderland" opposite Jane Alexander, who played Hedda Hopper. Taylor appeared in the miniseries "North and South" as well as playing the titular role in a 1987 Western TV-movie entitled "Poker Alice" with Tom Skerritt and George Hamilton. Her last theatrical film was 1994's "The Flintstones".
In February 1996, she appeared on the TV program, "The Nanny" as herself, and the star of the show, Fran, identified her to a friend by using all of her husbands' names, stating that she would be meeting "Elizabeth Taylor-Hilton-Wilding-Todd-Fisher-Burton-Burton-Warner-Fortensky". In 2001 she played an agent in the TV film "These Old Broads". She appeared on a number of television series, including the soap operas "General Hospital" and "All My Children", as well as the animated series "The Simpsons"—once as herself, and once as the voice of Maggie Simpson, uttering one word, "Daddy".
Taylor also acted on the stage, making her Broadway and West End debuts in 1982 with a revival of Lillian Hellman's "The Little Foxes". She was then in a production of Noël Coward's "Private Lives" (1983), in which she starred with her former husband, Richard Burton. The student-run Burton Taylor Studio in Oxford was named for the famous couple after Burton appeared as Doctor Faustus in the Oxford University Dramatic Society (OUDS) production of the Marlowe play. Taylor played the ghostly, wordless Helen of Troy, who is entreated by Faustus to "make [him] immortal with a kiss".
In the early 1980s, Taylor moved to Bel Air, California, which was her residence until her death. She also owned homes in Gstaad, Switzerland and Puerto Vallarta, Mexico.
2003–11.
In March 2003, Taylor declined to attend the 75th Annual Academy Awards, due to her opposition to the Iraq War. She publicly condemned then President George W. Bush for calling on Saddam Hussein to leave Iraq, and said she feared the conflict would lead to "World War III".
The February 2007 issue of "Interview" magazine was devoted entirely to Taylor. It celebrated her life, career and her upcoming 75th birthday.
On December 1, 2007, Taylor acted onstage again, appearing opposite James Earl Jones in a benefit performance of the A. R. Gurney play "Love Letters". The event's goal was to raise $1 million for Taylor's AIDS foundation. Tickets for the show were priced at $2,500, and more than 500 people attended. The event happened to coincide with the 2007 Writers Guild of America strike and, rather than cross the picket line, Taylor requested a "one night dispensation". The Writers Guild agreed not to picket the Paramount Pictures lot that night to allow for the performance.
Personal life.
Marriages, romances, and children.
Taylor was married eight times to seven husbands. When asked why she married so often, she replied, "I don't know, honey. It sure beats the hell out of me," but also said that, "I was taught by my parents that if you fall in love, if you want to have a love affair, you get married. I guess I'm very old-fashioned." Taylor's husbands were:
Taylor had many romances outside her marriages. Before marrying Hilton, she was engaged to Heisman Trophy winner Glenn Davis—who did not know until the relationship ended that Taylor's mother had encouraged it to build publicity for her daughter—and also to the son of William D. Pawley, the United States Ambassador to Brazil. Howard Hughes promised Taylor's parents that if they would encourage her to marry him, the enormously wealthy industrialist and film producer would finance a movie studio for her; Sara Taylor agreed, but Taylor refused. After she left Hilton, Hughes returned, proposing to Taylor by suddenly landing a helicopter nearby and sprinkling diamonds on her. Other dates included Frank Sinatra, Henry Kissinger, and Malcolm Forbes. In 2007 Taylor denied rumors of a ninth marriage to Jason Winters but referred to him as "one of the most wonderful men I've ever known."
Taylor had two sons, Michael Howard (born January 6, 1953) and Christopher Edward (born February 27, 1955; her own 23rd birthday), with Michael Wilding. She had a daughter, Elizabeth Frances "Liza" (born August 6, 1957), with Michael Todd. During her marriage to Eddie Fisher, Taylor started proceedings to adopt a two-year-old girl from Germany, Maria (born August 1, 1961); the adoption process was finalized in 1964 following their divorce. Richard Burton later adopted Taylor's daughters Liza and Maria.
In 1971, Taylor became a grandmother at the age of 39. At the time of her death, she was survived by her four children, ten grandchildren, and four great-grandchildren.
Religion and identity.
In 1959, at age 27, after nine months of study, Taylor converted from Christian Science to Judaism, taking the Hebrew name Elisheba Rachel. She stated that her conversion was something she had long considered and was not related to her marriages. After Mike Todd's death, Taylor said that she "felt a desperate need for a formalized religion", and explained that neither Roman Catholicism nor Christian Science were able to address many of the "questions she had about life and death".:175
Biographer Randy Taraborrelli notes that after studying the philosophy of Judaism for nine months, "she felt an immediate connection to the faith.":176 Although Taylor rarely attended synagogue, she stated, "I'm one of those people who think you can be close to God anywhere, not just in a place designed for worship ...":176 At the conversion ceremony, with her parents present as witnesses and in full support of her decision, Taylor repeated the words of Ruth:
... for whither thou goest, I will go; and where thou lodgest, I will lodge; thy people shall be my people and thy God my God.:176
Taylor was a follower of Kabbalah and a member of the Kabbalah Centre.
During an interview when she was 55, Taylor described how her inner sense of identity, when a child actress, kept her from giving in to many of the studio's demands, especially with regard to altering her appearance to fit in:
God forbid you do anything individual or go against the fad. But I did. I figured this looks absurd. And I agreed with my dad: God must have had some reason for giving me bushy eyebrows and black hair. I guess I must have been pretty sure of my sense of identity. It was me. I accepted it all my life and I can't explain it. Because I've always been very aware of the inner me that has nothing to do with the physical me.
Taylor added that she began to recognize her "inner being" during her adulthood:
Eventually the inner you shapes the outer you, especially when you reach a certain age, and you have been given the same features as everybody else, God has arranged them in a certain way. But around 40 the inner you actually chisels your features ... Life is to be embraced and enveloped. Surgeons and knives have nothing to do with it. It has to do with a connection with nature, God, your inner being—whatever you want to call it—it's being in contact with yourself and allowing yourself, allowing God, to mold you.
Her impressions of career and marriage.
In 1964, at the age of 32, Taylor described herself as an actress: "The Elizabeth Taylor who's famous, the one on film, really has no depth or meaning to me. She's a totally superficial working thing, a commodity." She was also able to explain her acting skills as "minuscule—it's not technique. It's instinct and a certain ability to concentrate." Although most of her film roles during the previous decade portrayed her beauty and sexuality, Taylor claimed they merely exaggerated or contradicted who she was in real life, stating, "I am "not" a 'sex queen' or a 'sex symbol.' I don't think I "want" to be one ... If my husband thinks I'm sexy, that's good enough for me." She also implied that the reverse is also true:
I can tell you what I think is sexy in a man. It has to do with warmth, a personal givingness, not self-awareness. Richard [Burton] is a very sexy man. He's got that sort of jungle essence that one can sense. It's not the way he combs his hair, not the things he wears; he doesn't think about having muscles. It's what he says and thinks.
By this point Taylor was married for the fifth time, to Richard Burton. Except for her third husband, Mike Todd, who died in a plane accident, she partly blamed her young romances and divorces on her "puritanical upbringing and beliefs":
At first, I guess I didn't know what was love and what was not. I always chose to think I was in love and that love was synonymous with marriage. I couldn't just have a romance; it had to be a marriage ... When I was first divorced, I was 18 and I had only been married nine months. I was very naïve and really totally crushed. It was the first divorce in my family.
Taylor credited Burton's strong relationship with their children as a factor in expecting their marriage to last, stating that he was the "absolute boss of the household and they respect him for that." She was surprised in hindsight by how they became romantically involved, recalling one of their first meetings:
The first day I saw Richard on the "Cleopatra" set, there was a lot of hemming and hawing, and he said hello to Joe Mankiewicz and everyone. And then he sort of sidled over to me and said, "Has anybody ever told you that you're a very pretty girl?" I said to myself, "oy gevaldt", here's the great lover, the great wit, the great intellectual of Wales, and he comes out with a line like that. I couldn't believe it. I couldn't wait to go back to the dressing room where all the girls were and tell them.
Fashion and commerce.
Taylor had a passion for jewelry. At her death, Taylor's jewelry collection was reportedly worth $150 million.
Over the years she owned a number of well-known pieces, two of the most famous being the 33.19 carat Krupp Diamond, which she wore daily, and the 69.42 carat pear-shaped Taylor-Burton Diamond; both were among many gifts from husband Richard Burton. Taylor also owned the 50 carat La Peregrina Pearl, purchased by Burton at a Sotheby's auction for $37,000; as a Valentine's Day present in 1969, and formerly owned by Mary I of England. La Peregrina is one of the most famous pearls in the world and remains one of the largest perfectly symmetrical pear-shaped pearls in the world.
Her collection of jewelry has been documented in her book "My Love Affair with Jewelry" (2002).
Taylor was a fashion icon during her years as an active film star. In addition to her own purchases, MGM costumers Edith Head and Helen Rose helped Taylor choose clothes that emphasized her face, chest, and waist. Taylor helped popularize Valentino and Halston's designs, and in the 1980s Schering-Plough developed violet contact lenses, citing Taylor's eyes as inspiration.
Fragrances.
In addition to being a critically acclaimed actress and highly regarded social activist, Elizabeth Taylor was also a savvy business woman. She launched her House of Taylor fragrance line at a time when celebrity perfumes by and large did not exist. The first was Passion in 1988, followed by White Diamonds, which is still one of the top selling celebrity fragrances of all time and has generated over $1 billion in its 20+ year history.
Not only is White Diamonds a commercial success, the perfume was named Best Women’s Fragrance and was inducted into the Fragrance Foundation’s Hall of Fame in 2009. Ms. Taylor was heavily involved in the creation of her fragrances, from the scent to packaging. She directed the composition of the fragrance notes for White Diamonds to represent the love she had for her gardens – Amazon Lily, Italian Neroli, Egyptian Tuberose, Narcisse, Turkish Rose, Jasmine, Italian Orris, Amber, Oakmoss, Patchouli, and Sandalwood. The product name and bottle design, also art directed by Elizabeth Taylor, reflect the eternal connection between the legendary actress and her famous diamonds.
In 2014, the White Diamonds fragrance line expanded with a new fragrance – White Diamonds Lustre, a modern interpretation of the original classic.
Below is the complete list of House of Taylor fragrances to date:
Passion (1988)
Passion for Men (1989)
White Diamonds (1991)
Diamonds and Emeralds (1993)
Diamonds and Rubies (1993)
Diamonds and Sapphires (1993)
Black Pearls (1996)
Sparkling White Diamonds (1999)
Brilliant White Diamonds (2001)
Forever Elizabeth (2002)
Gardenia (2003)
Violet Eyes (2010)
White Diamonds Lustre (2014)
Activism.
HIV/AIDS.
Taylor devoted consistent and generous humanitarian time, advocacy efforts, and funding to HIV and AIDS-related projects and charities, helping to raise more than $270 million for the cause. She was one of the first celebrities and public personalities to do so at a time when few acknowledged the disease, organizing and hosting the first AIDS fundraiser in 1984, to benefit AIDS Project Los Angeles.
Taylor was cofounder of the American Foundation for AIDS Research (amfAR) with Dr. Michael Gottlieb and Dr. Mathilde Krim in 1985. Her longtime friend and former co-star Rock Hudson had disclosed having AIDS and died of it that year. She also founded The Elizabeth Taylor AIDS Foundation (ETAF) in 1991, created to provide critically needed support services for people with HIV/AIDS. For example, in 2006 Taylor commissioned a 37 ft "Care Van" equipped with examination tables and xray equipment, the New Orleans donation made by her Elizabeth Taylor AIDS Foundation and Macy's. That year, in the wake of Hurricane Katrina, Taylor donated $500,000 to the NO/AIDS Task Force, a non-profit organization serving the community of those affected by HIV/AIDS in and around New Orleans. The donation was shared by Taylor in celebration of her 74th birthday and to help NO/AIDS Task Force continue their work fighting AIDS.
Taylor was honored with a special Academy Award, the Jean Hersholt Humanitarian Award, in 1992 for her HIV/AIDS humanitarian work. Speaking of that work, former President Bill Clinton said at her death, "Elizabeth's legacy will live on in many people around the world whose lives will be longer and better because of her work and the ongoing efforts of those she inspired."
Jewish causes.
After her conversion to Judaism, Taylor worked for Jewish causes throughout her life.
In 1959, her large-scale purchase of Israeli Bonds caused Arab boycotts of her films. In 1962, she was barred from entering Egypt to complete "Cleopatra"; its government announcing that she would not be allowed to come to Egypt because she had adopted the Jewish faith and "supports Israeli causes". However the ban was lifted in 1964 after it was considered that the film had brought favourable publicity to Egypt.
In 1974 Taylor and Richard Burton considered marrying in Israel, but were unable to do so because Burton was not Jewish. Taylor helped to raise money for organizations such as the Jewish National Fund; advocated for the right of Soviet Jews to emigrate to Israel and canceled a visit to the USSR because of its condemnation of Israel due to the Six-Day War, along with signing a letter protesting the United Nations General Assembly Resolution 3379 of 1975.
She offered herself as a replacement hostage after more than 100 Israeli civilians were taken hostage in the Entebbe skyjacking in 1976. After the success of the operation in which the hostages were freed, she acted with Kirk Douglas in a TV special, "Victory at Entebbe", broadcast in January 1977. Of her role, she stated, "I couldn't pass up this opportunity. I have strong ties to Israel and I firmly believe in the courage and dedication of the Entebbe mission."
Illnesses and death.
Taylor struggled with health problems much of her life. At twelve, she had broken her back in a fall during the filming of "National Velvet", and this would continue to affect her in later years. From the time of her divorce from Hilton, Taylor experienced serious medical issues whenever she faced problems in her personal life. Taylor was hospitalized more than 70 times and had at least 20 major operations. Many times newspaper headlines erroneously announced that Taylor was close to death; she herself only claimed to have almost died on four occasions.
At 5'4", Taylor constantly gained and lost significant amounts of weight (known as yo-yo dieting), reaching both 119 pounds and 180 pounds in the 1980s. She was a heavy smoker until having to quit following a severe bout of pneumonia in 1990. She feared she had lung cancer in October 1975 after an X-ray showed spots on her lungs, but was later found not to have the disease. Taylor broke her back five times, had both her hips replaced, had a hysterectomy, suffered from dysentery and phlebitis, punctured her esophagus, survived a benign brain tumor operation in 1997 and skin cancer, and faced life-threatening bouts with pneumonia twice, one in 1961 requiring an emergency tracheotomy. Due to numerous back injuries, she admitted to having been addicted to sleeping pills and painkillers for 35 years. Taylor was treated for alcoholism and prescription drug addiction at the Betty Ford Center for seven weeks from December 1983 to January 1984, and again from the autumn of 1988 until early 1989.
On May 30, 2006, Taylor appeared on "Larry King Live" to refute the claims that she had been ill, and denied the allegations that she was suffering from Alzheimer's disease and was close to death. Near the end of her life, however, she was reclusive and sometimes failed to make scheduled appearances due to illness or other personal reasons. She used a wheelchair and, when asked about it, stated that she had osteoporosis and was born with scoliosis.
The mutation that gave Taylor her striking double eyelashes may also have contributed to her history of heart trouble. In November 2004, Taylor announced a diagnosis of congestive heart failure, a progressive condition. In 2009 she underwent cardiac surgery to replace a leaky valve. In February 2011, new symptoms related to heart failure caused her to be admitted to Cedars-Sinai Medical Center in Los Angeles for treatment, where she remained until her death at age 79 on March 23, 2011, surrounded by her four children.
She was buried in a private Jewish ceremony, presided over by Rabbi Jerome Cutler, the day after she died, at Forest Lawn Memorial Park in Glendale, California. Taylor is entombed in the Great Mausoleum. At her request, the funeral began 15 minutes after it was scheduled to begin; as her representative told the media "She even wanted to be late for her own funeral."
Legacy.
Taylor has been called the "greatest movie star of all.":2 A child-star at the age of 12, she was soon after launched into public awareness by MGM and a string of successful films, many of which are today considered "classics". Her resulting celebrity made her into a Hollywood icon, as she set the "gold standard" for Hollywood fame, and "created the model for stardom," adds Mann.:3
Other observers, such as social critic Camille Paglia, similarly describe Taylor as "the greatest actress in film history," partly as a result of the "liquid realm of emotion" she expressed on screen. Paglia describes the effect Taylor had in some of her films:
An electric, erotic charge vibrates the space between her face and the lens. It is an extrasensory, pagan phenomenon.:4
Taylor had a major role in sparking the sexual revolution of the 1960s, as she pushed the envelope on sexuality: she was one of the first major stars to pose (mostly) nude in "Playboy", and among the first to remove her clothes onscreen.:5 In "A Place in the Sun", filmed when she was 17, her surprising maturity shocked Hollywood columnist Hedda Hopper, who wrote of her precocious sexuality. Film historian Andrew Sarris describes her love scenes in the film with Montgomery Clift as "unnerving—sybaritic—like gorging on chocolate sundaes.":6
In real life, she was considered "a star without airs," notes Mann. Writer Gloria Steinem likewise described her as a "movie queen with no ego ... expert at what she does, uncatty in her work relationships with other actresses".:7 Mike Nichols, who directed her in "Who's Afraid of Virginia Woolf?" (1966), said that of all the actors he had worked with, Taylor had the "most democratic soul." Mann adds that she treated electricians and studio crew the "same way she would a Rothschild at a charity gala.":6 Director George Cukor told Taylor that she possessed "that rarest of virtues—simple kindness.":7
Taylor's ex‑husband, actor Richard Burton, who co‑starred with her in eleven films, expressed great admiration for her talent as an actress. Burton said, "I think she's one of the most underrated screen actresses that ever lived, and I think she's one of the best ones who ever lived. At her finest she's incomparable."
Awards and honors.
Throughout her sixty-two year career, Elizabeth Taylor received more than 40 awards, honors, and nominations. With six Academy Award nominations, Taylor won twice for Best Actress in "BUtterfield 8" in 1960, and for "Who's Afraid of Virginia Woolf?" in 1966. Additionally, she received the Jean Hersholt Humanitarian Academy Award in 1992 for her work fighting AIDS. Taylor received six Golden Globe nominations, and won for Best Actress in "Suddenly, Last Summer" in 1960, and received the Hollywood Foreign Press Association's Cecil B. DeMille Award in 1985. In 1997 Taylor was honored by the Screen Actors Guild (SAG) with the Life Achievement Award. As Taylor could not be in attendance, Gregory Peck read a statement from her in which she explained that the eradication of the AIDS epidemic had become a key part of her life, and she thanked SAG for their contributions to The Elizabeth Taylor AIDS Foundation. Taylor also received four BAFTA Awards nominations with a win in 1966 for "Who's Afraid of Virginia Woolf?”.
Taylor received the French Legion of Honour in 1987, and in 2000 was appointed Dame Commander of the Order of the British Empire (DBE). In 2001, she received a Presidential Citizens Medal for her humanitarian work, most notably for helping to raise more than $200 million for AIDS research and bringing international attention and resources to addressing the epidemic. Taylor was inducted into the California Hall of Fame in 2007.
Additional awards include five Golden Laurel Awards, a New York City Film Critics Circle Award, a Silver Bear for Best Actress in the 22nd Berlin International Film Festival, Women in Film Crystal Award, The Vanguard Award for GLAAD Media Awards, a Kansas City Film Critics Circle Award, two David di Donatello Awards, Hasty Pudding’s Woman of the Year Award and a Marian Anderson Award.
In 1994 a Golden Palm Star on the Palm Springs, California, Walk of Stars was dedicated to her.
Books.
Taylor was the subject of at least 53 books as of 2006; Kitty Kelley wrote an unauthorized biography of the actress in 1981, which Taylor denounced. She never wrote a comprehensive autobiography due to her desire for privacy, but did publish several books besides "My Love Affair with Jewelry". Taylor's first, "Nibbles and Me" (1946), discussed the child star's "adventures with her pet chipmunk". Reviewers criticized another, "Elizabeth Taylor" (1964), for being uninteresting and lacking in new information. She received a $750,000 advance payment for "Elizabeth Takes Off: On Weight Gain, Weight Loss, Self-Image and Self-Esteem" (1988).
References.
</dl>

</doc>
<doc id="42361" url="http://en.wikipedia.org/wiki?curid=42361" title="On the Waterfront">
On the Waterfront

On the Waterfront is a 1954 American crime drama film about union violence and corruption amongst longshoremen. The film was directed by Elia Kazan and written by Budd Schulberg. It stars Marlon Brando and features Karl Malden, Lee J. Cobb, Rod Steiger, and, in her film debut, Eva Marie Saint. The soundtrack score was composed by Leonard Bernstein. It is based on "Crime on the Waterfront", a series of articles published in the "New York Sun" by Malcolm Johnson that won the 1949 Pulitzer Prize for Local Reporting. The stories detailed widespread corruption, extortion, and racketeering on the waterfronts of Hoboken, New Jersey.
"On the Waterfront" was a critical and commercial success and received 12 Academy Award nominations, winning eight, including Best Picture, Best Actor for Brando, Best Supporting Actress for Saint, and Best Director for Kazan. In 1997 it was ranked by the American Film Institute as the eighth-greatest American movie of all time. It is Bernstein's only original film score not adapted from a stage production with songs.
In 1989, "On the Waterfront" was deemed "culturally, historically or aesthetically significant" by the Library of Congress and selected for preservation in the United States National Film Registry.
Plot.
Mob-connected union boss Johnny Friendly (Lee J. Cobb) gloats about his iron-fisted control of the waterfront. The police and the Waterfront Crime Commission know that Friendly is behind a number of murders, but witnesses play "D and D" ("deaf and dumb"), accepting their subservient position rather than risking the danger and shame of informing.
Terry Malloy (Marlon Brando) is a dockworker whose brother Charley "The Gent" (Rod Steiger) is Friendly's right-hand man. Some years earlier, Terry had been a promising boxer, until Friendly had Charley instruct him to deliberately lose a fight that he could have won, so that Friendly could win money betting against him.
Terry meets and is smitten by Edie (Eva Marie Saint), the sister of Joey Doyle (Ben Wagner). She has shamed "waterfront priest" Father Barry (Karl Malden) into fomenting action against the mob-controlled union. Terry is used to coax Joey, a popular dockworker, into an ambush, preventing him from testifying against Friendly before the Crime Commission. Terry assumed that Friendly's enforcers were only going to "lean" on Joey in an effort to pressure him to avoid talking, and is surprised when Joey is killed. Although Terry resents being used as a tool in Joey's death, and despite Father Barry's impassioned "sermon on the docks" reminding the longshoremen that Christ walks among them and that every murder is a Calvary, Terry is nevertheless willing to remain "D and D".
Soon both Edie and Father Barry urge Terry to testify. Another dockworker, Timothy J. "Kayo" Dugan (Pat Henning), who agrees to testify after Father Barry's promise of unwavering support, ends up dead after Friendly arranges for him to be crushed by a load of whiskey in a staged accident.
As Terry, tormented by his awakening conscience, increasingly leans toward testifying, Friendly decides that Terry must be killed unless Charley can coerce him into keeping quiet. Charley tries bribing Terry with a good job and finally threatens Terry by holding a gun against him, but recognizes that he has failed to sway Terry, who places the blame for his own downward spiral on his well-off brother. In what has become an iconic scene, Terry reminds Charley that had it not been for the fixed fight, Terry's career would have bloomed. "I coulda' been a contender", laments Terry to his brother, "Instead of a bum, which is what I am – let's face it." Charley gives Terry the gun and advises him to run. Friendly, having had Charley watched, has Charley murdered, his body hanged in an alley as bait to get at Terry. Terry sets out to shoot Friendly, but Father Barry obstructs that course of action, telling Terry that violence is pointless because as long as Johnny is in charge, the law will always be on his side, and finally convinces Terry to fight Friendly by testifying.
After the testimony, Friendly announces that Terry will not find employment anywhere on the waterfront. Edie tries persuading him to leave the waterfront with her, but he nonetheless shows up during recruitment at the docks. When he is the only man not hired, Terry openly confronts Friendly, calling him out and proclaiming that he is proud of what he did.
Finally the confrontation develops into a vicious brawl, with Terry getting the upper hand until Friendly's thugs gang up on Terry and nearly beat him to death. The dockworkers, who witnessed the confrontation, declare their support for Terry and refuse to work unless Terry is working too and push Friendly into the lake. Finally, the badly wounded Terry forces himself to his feet and enters the dock, followed by the other longshoremen. A soaking wet and face-scarred Friendly, now left with nothing, swears revenge on all the workers, but his threats fall on deaf ears as they enter the garage and the door closes behind them.
Production.
"On the Waterfront" was filmed over 36 days on location in various places in Hoboken, New Jersey, including the docks, workers' slum dwellings, bars, littered alleys, and rooftops. Furthermore, some of the labor boss's goons in the film—Abe Simon as Barney, Tony Galento as Truck, and Tami Mauriello as Tullio—were actual former professional heavyweight boxers.
Terry Malloy's (Brando's) fight against corruption was in part modeled after whistle-blowing longshoreman Anthony DiVincenzo, who testified before a real-life Waterfront Commission on the facts of life on the Hoboken Docks and suffered a degree of ostracism for his deed. DeVincenzo sued and settled, many years after, with Columbia Pictures over the appropriation of what he considered his story. DeVincenzo claimed to have recounted his story to screenwriter Budd Schulberg during a month-long session of waterfront barroom meetings. Schulberg attended DeVincenzo's waterfront commission testimony every day during the hearing.
Karl Malden's character, Father Barry, was based on the real-life "waterfront priest" Father John M. Corridan, S.J., a Jesuit priest, graduate of Regis High School who operated a Roman Catholic labor school on the west side of Manhattan. Father Corridan was interviewed extensively by Budd Schulberg, who wrote the foreword to a biography of Father Corridan, "Waterfront Priest", by Allen Raymond. The church used for the exterior scenes in the film was the historic Our Lady of Grace in Hoboken, built in 1874, while the interiors were shot at the Church of St. Peter and St. Paul, also in Hoboken, at 400 Hudson Street.
Political context.
The film is widely considered to be Kazan's answer to those who criticized him for identifying eight (former) Communists in the film industry before the House Committee on Un-American Activities (HUAC) in 1952. Kazan's critics included his friend and collaborator, the noted playwright Arthur Miller, who had written the original screenplay—titled "The Hook—"for the film that would become "On the Waterfront." Miller was replaced by Budd Schulberg, also a witness before HUAC.
Budd Schulberg later published a novel simply titled "Waterfront" that was much closer to his original screenplay than the version released on screen. Among several differences is that Terry Malloy is brutally murdered.
Reception.
Upon its release, the film received positive reviews from critics and was a commercial success, earning an estimated $4.2 million in rentals at the North American box office in 1954. In his July 29, 1954, review, "New York Times" critic A. H. Weiler hailed the film as a masterpiece, calling it "an uncommonly powerful, exciting, and imaginative use of the screen by gifted professionals."
In 1989, the film was deemed "culturally, historically or aesthetically significant" by the Library of Congress and selected for preservation in the United States National Film Registry. Film critic Roger Ebert lauded the film, stating that Brando and Kazan changed acting in American movies forever, and then added it to his list of The Great Movies.
It is also on the Vatican's list of 45 greatest films, compiled in 1995.
Review aggregation website Rotten Tomatoes retrospectively collected 55 reviews and gave the film a score of 100%, with an average rating of 9.1 out of 10.
Awards.
Academy Awards
"On the Waterfront" received twelve Academy Awards nominations in ten categories and won in eight of the categories.
After Marlon Brando won the Academy Award for Best Actor, it was stolen and did not turn up until much later, when a London auction house contacted him and informed him of its whereabouts. Before that he had been using it to help hold his front door open.
American Film Institute recognition
Home media.
 The first home video release of the film was in 1984, on VHS and Beta. The first DVD version was released in 2001. Among the special features is the featurette "Contender: Mastering the Method," a video photo gallery, an interview with Elia Kazan, an audio commentary, filmographies, production notes, and theatrical trailers. The film has been added to the Criterion Collection.
References.
Notes
Bibliography

</doc>
<doc id="42363" url="http://en.wikipedia.org/wiki?curid=42363" title="John Perry Barlow">
John Perry Barlow

John Perry Barlow (born October 3, 1947) is an American poet and essayist, a retired Wyoming cattle rancher, and a cyberlibertarian political activist who has been associated with both the Democratic and Republican parties. He is also a former lyricist for the Grateful Dead and a founding member of the Electronic Frontier Foundation and Freedom of the Press Foundation. Since May 1998, he has been a Fellow at Harvard University's Berkman Center for Internet and Society. He has been identified by "Time" magazine as one of the "School of Rock: 10 Supersmart Musicians".
Life and career.
John Perry Barlow was born in Sublette County, Wyoming to parents Norman Barlow, a Republican state legislator, and his wife, Miriam. He grew up on the 22,000-acre Bar Cross Ranch near Pinedale, Wyoming that was founded by his great uncle in 1907 and attended elementary school in a one-room schoolhouse. At age 15, he became a student at the Fountain Valley School in Colorado. Barlow met Bob Weir there, who would later join the music group the Grateful Dead. Weir and Barlow maintained contact throughout the years; a frequent visitor to Timothy Leary's facility in Millbrook, New York, Barlow introduced the musical group to Leary in 1967. In 1969, Barlow graduated with high honors in comparative religion from Wesleyan University in Middletown, Connecticut, and spent two years traveling around India. In 1971, while on his way to California to go join back up with the Grateful Dead, he stopped at his family's ranch not intending to stay, but ended up changing his plans and began practicing animal husbandry in Cora, Wyoming at the Bar Cross Land and Livestock Company for almost two decades, until he sold that business in 1988. In the meantime, Barlow was still able to play an active role in the Grateful Dead, and also recruit many unconventional part-time ranch hands from the mainstream as well as counterculture. John Byrne Cooke is currently producing "The Bar Cross Ranch" (working title), a film featuring this era.
The seeds of the Barlow–Weir collaboration were sown at a Grateful Dead show at the Capitol Theater in Port Chester, New York, in February 1971. Until then, Weir had mostly worked with resident Dead lyricist Robert Hunter. Hunter preferred that those who sang his songs stick to his "canonical" lyrics rather than improvising additions or rearranging words. A feud erupted backstage over a couplet in "Sugar Magnolia" from the band's most recent release (most likely "She can dance a Cajun rhythm/Jump like a Willys in four-wheel drive"), culminating in a disgruntled Hunter summoning Barlow and telling him "take him (Weir)—he's yours". In the fall of 1971, with a deal for a solo album in hand and only two songs completed, Weir and Barlow began to write together for the first time. Note: Capitol Theater New York Shows from February 1971 have no changes to lyrics noted above, all shows are on Archive.org.
The twosome hammered out such enduring songs as "Cassidy", "Mexicali Blues", and "Black Throated Wind", all three of which would remain in the repertoires of the Grateful Dead and Weir's varied solo projects for years to come. Other songs to emerge from the Weir-Barlow collaboration include "Let It Grow", "The Music Never Stopped", "Estimated Prophet", "I Need A Miracle", "Lost Sailor", "Saint of Circumstance", "Hell In A Bucket", and "Throwing Stones". Barlow also collaborated with Grateful Dead keyboardists Brent Mydland then later Vince Welnick.
In 1986 Barlow joined The WELL online community, then known for a strong Deadhead presence. He served on the company's board of directors for several years. In 1990, Barlow founded the Electronic Frontier Foundation (EFF) along with fellow digital-rights activists John Gilmore and Mitch Kapor. As a founder of EFF, Barlow helped publicize the Secret Service raid on Steve Jackson Games. Barlow's involvement is later documented in the ' (1992) by Bruce Sterling. EFF later sponsored the ground-breaking case Steve Jackson Games, Inc. v. United States Secret Service. Steve Jackson Games won the case in 1993.
He married Elaine Parker Barlow in 1977, with whom he had three daughters: Amelia Rose, Anna Winter, and Leah Justine. Elaine and John separated in 1992. Elaine and John Perry officially divorced in 1995. In 2002, he helped his friend realtor/ entrepreneur/ model/ actress Simone Banos deliver her daughter Emma Victoria, who became his surrogate daughter henceforth.
He was engaged to Dr. Cynthia Horner, whom he met in 1993 at the Moscone Center in San Francisco while she was attending a psychiatry conference and Barlow was participating in a Steve Jobs comedy roast at a convention for the NeXT Computer. She died unexpectedly in 1994 while asleep on a flight from Los Angeles to New York, days before her 30th birthday, from a heart arrhythmia apparently caused by undetected viral cardiomyopathy. Barlow describes this experience on This American Life Episode 74, "Conventions," which originally aired on August 29, 1997. Barlow had been a good friend of John F. Kennedy, Jr. ever since his mother Jacqueline Kennedy Onassis had made arrangements for her son to be a wrangler at the Bar Cross ranch for 6 months in 1978, and later the two men went on many double dates in New York City with Kennedy's then-girlfriend Daryl Hannah and Cynthia.
In the September 1, 1995 article for the Shambhala Sun, "bell hooks talks to John Perry Barlow," Barlow reflects upon Cynthia Horner passing away: "It seems to me that what we’re here to do is to learn about love in the presence of fear... You pass away from the moment into the infinite, where there are no moments and where there’s no time. Here in an embodied state, the body, like all physical things, participates in entropy and all the other artifacts of time. There’s a thin but nevertheless impermeable membrane between the chronological and the timeless that has become much more real to me since my lover died a year ago. Even though I feel her soul, the absence of her body feels like an enormous barrier. The absence of the spoken word, the absence of the sound of her voice, or the touch of her skin. All the things that only can be done by souls with bodies on them... But you know the only time that I feel in contact with her, really, is when her spirit temporarily borrows someone else’s body to dance. Like the moment that you and I were dancing up in your apartment a few months ago. And suddenly she was in you and I could feel her there. You quit dancing the way you danced and started dancing the way she danced. And it was almost like a practical joke that she was playing in a way."
In his piece "A Ladies' Man and Shameless" Barlow professes his love of many women at the same time, and summarizes the relationships in his personal life, "I doubt I’ll ever be monogamous again... I want to know as many more women as time and their indulgence will permit me... There are probably twenty-five or thirty women—I certainly don’t count them—for whom I feel an abiding and deep emotional attachment. They’re scattered all over the planet. They range in age from less than half to almost twice my own. Most of these relationships are not actively sexual. Some were at one time. More never will be. But most of them feel as if they could become so. I love the feel of that tension, the delicious gravity of possibilities."
In 1996, Barlow was invited to speak about his work in Cyberspace to a middle school classroom at North Shore Country Day School, which was a highly influential event in the early life of student Aaron Swartz, as Swartz's father Robert recalls Aaron coming home that day a changed person. Although they were not close as adults, they shared many common causes and Barlow's face shows up clearly in the background of several shots in .
In 2003, Barlow met the recently appointed Minister of Culture Gilberto Gil at the event Tactic Media Brazil to discuss the perspectives of digital inclusion and political participation, which in the following years would help shape Brazilian governmental policy on intellectual property and digital media. In 2004, the two began working together to expand the availability and variety of Brazilian music to remix and share online. At the same time, being one of the Digerati, Barlow was among the very first users of the invitation-only social network Orkut at its inception, and decided to send all of his 100 invitations to friends in Brazil. Two years later, out of 14 million total internet users in Brazil, 11 million were on Orkut.
Barlow is a friend and former roommate of entrepreneur Sean Parker, and attended Parker's controversial 2013 wedding.
In 2014, Barlow suffered the loss of Buck, his beloved Maine Coon cat that he believed to be a bodhisattva and who had many fans via social media.
Politics.
Barlow is a former chairman of the Sublette County Republican Party and served as western Wyoming campaign coordinator for Dick Cheney during his 1978 Congressional campaign. Barlow was President of the Wyoming Outdoor Council from 1978 to 1984. He was Chairman of the Sublette County Master Plan Design Commission and on the Sublette County Planning and Zoning for many years and was one of 5 ranchers who administered water distribution in the New Fork Irrigation District, an area of nearly 100,000 acres serving about 35 ranchers.
By the early 2000s, Barlow was unable to reconcile his ardent libertarianism with the prevailing neoconservative movement and "didn't feel tempted to vote for Bush"; after an arrest for possession of a small quantity of marijuana while traveling, he joined the Democratic Party and publicly committed himself to outright political activism for the first time since his spell with the Republican Party. Barlow has subsequently declared that he is a Republican, including during an appearance on "The Colbert Report" on March 26, 2007, and also claimed on many occasions to be an anarchist. Barlow has said he voted for Natural Law Party Presidential candidate John Hagelin in 2000 after discovering in the voting booth that his friend Nat Goldhaber was Hagelin's running mate. He said in 2004: "I'm embarrassed for my country that in my entire voting life, there has never been a major-party candidate whom I felt I could vote for. All of my presidential votes, whether for George Wallace, Dick Gregory, or John Hagelin, have been protest votes." Barlow said that year he was "voting for John Kerry, though with little enthusiasm."
Current work.
Barlow currently serves as vice-chairman of the EFF's board of directors. The EFF was designed to mediate the "inevitable conflicts that have begun to occur on the border between Cyberspace and the physical world." They were trying to build a legal wall that would separate and protect the Internet from territorial government, and especially from the US government.
In 2012, Barlow was one of the founders of the EFF-related organization the Freedom of the Press Foundation and also currently serves on its Board of Directors. Barlow has had several public conversations via video conference with fellow Freedom of the Press Foundation Board of Directors member Edward Snowden, and has appeared in interviews with Julian Assange of WikiLeaks touting Snowden as "a Hero."
He is a Fellow with the Berkman Center for Internet and Society at Harvard Law School and Diamond Management & Technology Consultants, and a member of the International Academy of Digital Arts and Sciences. He is listed as a member of the faculty of the European Graduate School (EGS), in Saas-Fee, Wallis, Switzerland. He spends much of his time on the road, lecturing and consulting about civil rights, freedom of speech, the state of the internet and the Electronic Frontier Foundation. He delivered lectures and panel discussions at TWiT Live, TedxHamburg, Hamburg (Germany), Greenfest SF, Civitas (Norwegian think tank), Internet Society (NY Chapter, New York), the USC Center on Public Diplomacy, and the European Graduate School (EGS), Saas-Fee, Switzerland. On September 16, 2012, he presented at TEDxSantaCruz, in Santa Cruz, California. On September 8, 2014, Barlow was the first speaker in the Art, Activism, and Technology: The 50th Anniversary of the Free Speech Movement colloquium series at University of California, Berkeley.
Barlow also serves on the advisory boards of the Marijuana Policy Project, Clear Path International, TTI/Vanguard, the Hypothes.is project, the stakeholder engagement non-profit Future 500 and the global company Touch Light Media founded by Anita Ondine. He is a collaborator on the WetheData project founded by Juliette Powell.
He is listed as Vice President at Algae Systems, a Nevada-based company with a working demo-scale pilot plant in Daphne, Alabama, dedicated to commercializing novel methods at the water-energy nexus for growing microalgae offshore as a second-generation biofuels feedstock and converting it to useful crude via hydrothermal liquefaction, while simultaneously treating wastewater, reducing carbon dioxide in Earth's atmosphere, and producing biochar. At Startup Grind Jackson Hole on March 13, 2015, Barlow said that he was motivated to team up with Algae Systems after undergoing back surgery to address pain from an old ranching injury, while he had been an advisor to Herb Allison (president of Merrill Lynch at the time) and working to completely "electronify" financial transactions and speculative asset assembly (Barlow was named "One of the 25 Most Influential People in Financial Services" in the June 1999 issue of FutureBanker Magazine). The surgery successfully alleviated the pain and catalyzed Barlow to change his focus from building wealth to building infrastructure in order to do something about the “amount of alterations we are already enacting on Planet Earth... We are not necessarily making it warmer, but weirder.” At Startup Grind Jackson Hole, Barlow also explained how once over tea with “Grandmother of the Conservation Movement” Mardy Murie, he was inspired by her words, “Environmentalists can be a pain in the ass... But they make great ancestors.” Adopting this philosophy, Barlow says, “I want to be a good ancestor.".
For several years, Barlow has attended Burning Man and led a town hall meeting with Burning Man co-founder Larry Harvey about "the current state Practical Anarchy at Burning Man". General Wesley Clark caused a stir in the media when he attended Burning Man in 2013 and spent time with Barlow and Harvey.
Barlow has played a role in many films and television shows, both as an actor and as himself. Interviews with Barlow have been featured in documentaries such as the Tao Ruspoli-directed film Monagamish (under production), Bits & Bytes (under production), and Dying to Know: Ram Dass & Timothy Leary.
The iPhone app Detour released in February 2015 by Groupon founder and ex-CEO Andrew Mason features a 75-minute audio tour narrated by Barlow as he walks through the Tenderloin neighborhood in downtown San Francisco.
Barlow is a self-ordained minister who performs baptisms and weddings.
Writing.
From 1971 until 1995, Barlow wrote lyrics for the Grateful Dead, mostly through his relationship with Bob Weir. Among others, Barlow's songs include "Cassidy" (about Neal Cassady and Cassidy Law), "Estimated Prophet", "Black-Throated Wind", "Hell in a Bucket", "Mexicali Blues", "The Music Never Stopped", and "Throwing Stones".
Barlow has written extensively for "Wired" magazine, as well as "The New York Times", "Nerve", and "Communications of the ACM". In his writings, he explained the wonder of the Internet. The Internet to him is more than a computer network. It is a place that he called an "electronic frontier". "He frequently wrote in language that echoed Henry Stanley's African diary. ‘Imagine discovering a continent so vast that it may have no end to its dimensions. Imagine a new world with more resources than all our future greed might exhaust, more opportunities than there will ever be entrepreneurs enough to exploit, and a peculiar kind of real estate that expands with development. Imagine a place where trespassers leave no footprints, where goods can be stolen infinite number of times and yet remain in the possession of their original owners, where business you never heard of can own the history of your personal affairs.’" He wanted to encourage and provoke youngsters to explore the cyberspace through his writing.
His writings include "A Declaration of the Independence of Cyberspace," which was written in response to the enactment of the Communications Decency Act in 1996 as the EFF saw the law as a threat to the independence and sovereignty of cyberspace. He argued that the cyberspace legal order would reflect the ethical deliberation of the community instead of the coercive power that characterized real-space governance. Since online "identities have no bodies," they found it inappropriate to obtain order in the cyberspace by physical coercion. Instead ethics, enlightened self-interest and the commonwealth were the elements they believed to create a civilization of the Mind in Cyberspace.. An article published in April 2015 by Paper magazine recounts the events surrounding this piece: 
 Barlow's prescient Declaration of the Independence of Cyberspace was written at the World Economic Forum, where he had been invited to speak and was late on a deadline for the book 24 Hours in Cyberspace. Barlow's prescient Declaration of the Independence of Cyberspace was written at the World Economic Forum, where he had been invited to speak and was late on a deadline for the book 24 Hours in Cyberspace. "I was there to be a dancing bear because they had just discovered the Internet and they wanted to show how hip they were," he says. "We had passed the Communications Decency Act, which would have made it a felony and up to a $100,000 fine using such words that I had heard used many times in the Senate cafeteria. It was just the most ridiculous. I was simply stating that it was going to be very difficult for the physical world to impose sovereignty on cyberspace. Even though the relationship of cyberspace to the physical world is exactly that of mind and body, it is difficult for the body to locate the mind and impose anything on it."
He was at a party with a lot of hot women, he recalls, running back and forth from the dance floor as the words struck him. He never did make the deadline, but the Declaration was completed. "I sent it out to my friends, about 400 people, the Barlow spam list, people that didn't have anything in common except that I liked them and had their email address. First thing I've ever seen go viral. It was everywhere overnight.
Later, articles such as "The Economy of Ideas" were also widely circulated in providing a vision for human creativity online.
In his 1990 piece "Crime and Puzzlement: in advance of the law on the electronic frontier," Barlow wrote about his first-hand experience with Phiber Optik (Mark Abene) and Acid Phreak (Eli Ladopoulos) from the hackers group Masters of Deception, and mentions Kevin Mitnick, all of whom were engaged in phone phreaking. The title alludes to "Crime and Punishment" by Fyodor Dostoyevsky.
Barlow is credited for modern popularization of the concept of pronoia and was considered a celebrity ally of the Zippy Pronoia Tour in 1994.
In 1998, Barlow wrote the article "Africa Rising: Everything You Know About Africa Is Wrong" for "Wired", which documented the start of his extensive travels as he worked to expand Internet access across the continent: "I went from Mombasa to Tombouctou, experiencing various parts of Kenya, Ghana, the Ivory Coast, Mali, Uganda, and the Virunga volcano area where Uganda, Rwanda, and the Congo meet. Part of the idea was that I would attempt to email Wired a series of dispatches on my travels. The act of finding a port into cyberspace would be part of the adventure... Before I left, I believed Africans could proceed directly from the agricultural epoch into an information economy without having to submit to the dreary indignities and social pathologies of industrialization."
Barlow has also returned to writing lyrics, most recently with The String Cheese Incident's mandolinist and vocalist Michael Kang, including their song "Desert Dawn." Barlow has been seen many times with Carolyn Garcia (whose monologue is dubbed on the eponymous track "Mountain Girl") at their concerts mixing with the fans and members in the band, and is a close friend of String Cheese Incident producer Jerry Harrison. He also participated with the Chicago-based jam band Mr. Blotto on their release "Barlow Shanghai". Barlow is a Spiritual Mentor/Student of Kemp Muhl and Sean Lennon, collaborating with their band The Ghost of a Saber Tooth Tiger and making a cameo in their 2014 music video "Animals."
On August 15, 2013, Barlow participated in a Reddit AMA, where he shared his "Principles of Adult Behavior", which were originally written in 1977 on the eve of his 30th birthday and have been in circulation ever since:

</doc>
<doc id="42366" url="http://en.wikipedia.org/wiki?curid=42366" title="Continuity of Operations">
Continuity of Operations

Continuity of Operations (COOP) is a United States federal government initiative, required by U.S. Presidential directive, to ensure that agencies are able to continue performance of essential functions under a broad range of circumstances.
National Security Presidential Directive-51 (NSPD-51)/Homeland Security Presidential Directive-20 (HSPD-20), National Continuity Policy, specifies certain requirements for continuity plan development, including the requirement that all Federal executive branch departments and agencies develop an integrated, overlapping continuity capability. FCD 1 also serves as guidance to State, local, and tribal governments.
FEMA has developed Continuity Guidance Circular 1, Continuity Guidance for Non-Federal Agencies (CGC 1). CGC 1 parallels the information in FCD 1 closely, but is geared to States, territories, tribal and local governments, and private-sector organizations.
History.
A Continuity of Operations Plan (or Continuity of Government Plan) has been a part of U.S. government operations since at least the Cold War, when President Dwight D. Eisenhower provided (via executive order) various measures designed to ensure that the government of the United States would be able to continue operating after a nuclear war.
These measures included construction of underground facilities such as "Mount Weather", a hollowed-out putatively nuclear-proof mountain in western Virginia with a mailing address in Berryville, Virginia. The public can now tour one such facility, intended to house the entire United States Congress, on the grounds of the Greenbrier Resort in White Sulphur Springs, West Virginia. Other provisions of the plans included executive orders that designated certain government officials to assume Cabinet and other executive branch positions and carry out the responsibilities of the position if the primary office holders are killed. There has been a formal line of succession to the presidency since 1792 (currently found in the Presidential Succession Act of 1947, #Redirect ). This runs from the Vice President to the Speaker of the House of Representatives, President "pro tempore" of the Senate, and then through the Cabinet secretaries in a sequence specified by Congress.
Continuity of government plans are not limited to the federal government. The majority of states have constitutional provisions that provide for the succession of government in the event of an "enemy attack."
COG activated.
The George W. Bush administration put the Continuity of Operations plan into effect for the first time directly following the September 11 attacks. Their implementation involved a rotating staff of 75 to 150 senior officials and other government workers from every federal executive department and other parts of the executive branch in two secure bunkers on the East Coast. Friends, family and co-workers were only able to reach them through a toll-free number and personal extensions.
The Bush administration did not acknowledge the implementation of the COG plan until March 1, 2002.
Since its inception, the newly created Department of Homeland Security has conducted at least three exercises to test continuity plans. The first, named "Forward Challenge '04", took place from May 12 to May 13, 2004, and included more than 40 government agencies. The second major exercise took place from June 20 to June 24, 2005. Titled "Pinnacle", the exercise tested responses to various emergencies, including a hypothetical act of terrorism. "Forward Challenge '06" was the third major exercise, and took place on June 19, 2006. It reportedly involved nearly 4,000 government personnel.
In September 2010, President Barack Obama informed Congress that the State of Emergency in effect since September 14, 2001, will be extended another year. The National Emergencies Act grants various powers to the president during times of emergency, and was intended to prevent a president from declaring a state of emergency of indefinite duration.
In 2007, Professor Larry J. Sabato criticized the incomplete nature of the plan in his book "A More Perfect Constitution". In particular, he objected to the fact that there is no Constitutional procedure for replacing U.S. House members in the case of a large-scale attack which could potentially kill a large number of representatives. In regard to the Continuity of Operations Plan, Sabato said it "failed outright" during the September 11 attacks.
The NORAD- and USNORTHCOM-sponsored exercise "Vigilant Shield 2008" took place from October 15 to October 20, 2007.
Lack of Congressional oversight.
On July 18, 2007, Rep. Peter DeFazio (D-OR), a member of the U.S. House Committee on Homeland Security, requested the classified and more detailed version of the government's continuity of government plan in a letter signed by him and the chairperson of the House Homeland Committee, which is supposed to have access to confidential government information. The president refused to provide the information, to the surprise of the congressional committee. s of 2007[ [update]], efforts by the committee to secure a copy of the plan continue.
Documents.
A document named in italics supersedes the following document.
Reagan administration.
An unknown contingency plan (which some believe was Rex 84) was publicly mentioned during the Iran-Contra Hearings in 1987. 
 Transcripts from the hearing in the New York Times record the following dialogue between Congressman Jack Brooks, North's attorney Brendan Sullivan and Senator Daniel Inouye, the Democratic Chair of the Committee:
[Congressman Jack] Brooks: Colonel North, in your work at the N.S.C. were you not assigned, at one time, to work on plans for the continuity of government in the event of a major disaster?
Brendan Sullivan [North's counsel, agitatedly]: Mr. Chairman?
[Senator Daniel] Inouye: I believe that question touches upon a highly sensitive and classified area so may I request that you not touch upon that?
Brooks: I was particularly concerned, Mr. Chairman, because I read in Miami papers, and several others, that there had been a plan developed, by that same agency, a contingency plan in the event of emergency, that would suspend the American constitution. And I was deeply concerned about it and wondered if that was an area in which he had worked. I believe that it was and I wanted to get his confirmation.
Inouye: May I most respectfully request that that matter not be touched upon at this stage. If we wish to get into this, I'm certain arrangements can be made for an executive session.
Section 202
The head of each Federal department and agency shall ensure the continuity of essential functions in any national security emergency by providing for: succession to office and emergency delegation of authority in accordance with applicable law; safekeeping of essential resources, facilities, and records; and establishment of emergency operating capabilities.
Hardware and facilities.
The Continuity of Operations Plan involves numerous bunkers, special airplanes, and communication systems. Much of the information about them is classified, however information on various systems has been released by the government or described to the public by reporters and writers. Since many of the details are classified, the public information may be incorrect. Also they are subject to change without public notice so this list may not reflect current plans.
Facilities.
During the Cold War, the United States constructed bunkers to help provide survivability to military command and government officials. Some have been decommissioned since the Cold War. The ones that are still considered to be in operation are listed here.
Ships.
These vessels were decommissioned in 1970.
Communication.
Communication is vital during a catastrophic event. Military communication links are designed for extreme situations such as nuclear war and thus considered more "survivable" than civilian networks. The Defense Information Systems Agency is in charge of supporting command, control, communications, and information systems for the military and would support the NCA. It is assumed that the various bunkers and airplanes have been equipped with special communication equipment to survive a catastrophe.

</doc>
<doc id="42368" url="http://en.wikipedia.org/wiki?curid=42368" title="Honoré de Balzac">
Honoré de Balzac

Honoré de Balzac (; ]; 20 May 1799 – 18 August 1850) was a French novelist and playwright. His "magnum opus" was a sequence of short stories and novels collectively entitled "La Comédie humaine", which presents a panorama of French life in the years after the 1815 fall of Napoleon Bonaparte.
Owing to his keen observation of detail and unfiltered representation of society, Balzac is regarded as one of the founders of realism in European literature. He is renowned for his multifaceted characters, who are morally ambiguous. His writing influenced many subsequent novelists such as Marcel Proust, Émile Zola, Charles Dickens, Anthony Trollope, Edgar Allan Poe, Eça de Queirós, Fyodor Dostoyevsky, Oscar Wilde, Gustave Flaubert, Benito Pérez Galdós, Marie Corelli, Henry James, William Faulkner, Jack Kerouac, and Italo Calvino, and philosophers such as Friedrich Engels and Karl Marx. Many of Balzac's works have been made into or have inspired films, and they are a continuing source of inspiration for writers, filmmakers and critics.
An enthusiastic reader and independent thinker as a child, Balzac had trouble adapting to the teaching style of his grammar school. His willful nature caused trouble throughout his life and frustrated his ambitions to succeed in the world of business. When he finished school, Balzac was an apprentice in a law office, but he turned his back on the study of law after wearying of its inhumanity and banal routine. Before and during his career as a writer, he attempted to be a publisher, printer, businessman, critic, and politician; he failed in all of these efforts. "La Comédie humaine" reflects his real-life difficulties, and includes scenes from his own experience.
Balzac suffered from health problems throughout his life, possibly brought on by scant attention to proper nutrition, strict nightly rest, or daily heart-healthy exercise. His relationship with his family was often strained by financial and personal difficulties, and he ended several friendships over critical reviews. In 1850 he married Ewelina Hańska, his longtime love; he died five months later.
Biography.
Family.
Honoré de Balzac was born into a family which had struggled nobly to achieve respectability. His father, born Bernard-François Balssa, was one of eleven children from a poor family in Tarn, a region in the south of France. In 1760 he set off for Paris with only a "louis" coin in his pocket, determined to improve his social standing; by 1776 he had become Secretary to the King's Council and a Freemason (he had also changed his name to the more noble sounding "Balzac," his son later adding—without any official cause—the nobiliary particle "de"). After the Reign of Terror (1793–94), he was sent to Tours to coordinate supplies for the Army.
Balzac's mother, born Anne-Charlotte-Laure Sallambier, came from a family of haberdashers in Paris. Her family's wealth was a considerable factor in the match: she was eighteen at the time of the wedding, and Bernard-François fifty. As British writer and critic V. S. Pritchett explained, "She was certainly drily aware that she had been given to an old husband as a reward for his professional services to a friend of her family and that the capital was on her side. She was not in love with her husband."
Honoré (named after Saint Honoré of Amiens, who is commemorated on 16 May, four days before Balzac's birthday) was actually the second child born to the Balzacs; exactly one year previous, Louis-Daniel had been born, but he lived for only a month. Honoré's sisters Laure and Laurence were born in 1800 and 1802, and his brother Henry-François in 1807.
Early life.
As an infant Balzac was sent to a wet-nurse; the following year he was joined by his sister Laure and they spent four years away from home. (Although Genevan philosopher Jean-Jacques Rousseau's influential book "" convinced many mothers of the time to nurse their own children, sending babies to wet-nurses was still common among the middle and upper classes.) When the Balzac children returned home, they were kept at a frigid distance by their parents, which affected the author-to-be significantly. His 1835 novel "Le Lys dans la Vallée" features a cruel governess named Miss Caroline, modeled after his own caregiver.
At age ten Balzac was sent to the Oratorian grammar school in Vendôme, where he studied for seven years. His father, seeking to instill the same hardscrabble work ethic which had gained him the esteem of society, intentionally gave little spending money to the boy. This made him the object of ridicule among his much wealthier schoolmates.
Balzac had difficulty adapting to the rote style of learning at the school. As a result, he was frequently sent to the "alcove," a punishment cell reserved for disobedient students. (The janitor at the school, when asked later if he remembered Honoré, replied: "Remember M. Balzac? I should think I do! I had the honour of escorting him to the dungeon more than a hundred times!") Still, his time alone gave the boy ample freedom to read every book which came his way.
Balzac worked these scenes from his boyhood—as he did many aspects of his life and the lives of those around him—into "La Comédie Humaine". His time at Vendôme is reflected in "Louis Lambert", his 1832 novel about a young boy studying at an Oratorian grammar school at Vendôme. The narrator says : "He devoured books of every kind, feeding indiscriminately on religious works, history and literature, philosophy and physics. He had told me that he found indescribable delight in reading dictionaries for lack of other books."
Balzac often fell ill, finally causing the headmaster to contact his family with news of a "sort of a coma". When he returned home, his grandmother said: "Voilà donc comme le collège nous renvoie les jolis que nous lui envoyons!" ("Look how the academy returns the pretty ones we send them!") Balzac himself attributed his condition to "intellectual congestion", but his extended confinement in the "alcove" was surely a factor. (Meanwhile, his father had been writing a treatise on "the means of preventing thefts and murders, and of restoring the men who commit them to a useful role in society", in which he heaped disdain on prison as a form of crime prevention.)
In 1814 the Balzac family moved to Paris, and Honoré was sent to private tutors and schools for the next two and a half years. This was an unhappy time in his life, during which he attempted suicide on a bridge over the Loire River.
In 1816 Balzac entered the Sorbonne, where he studied under three famous professors. François Guizot, who later became Prime Minister, was Professor of Modern History. Abel-François Villemain, a recent arrival from the "Collège Charlemagne", lectured on French and classical literature. And—most influential of all—Victor Cousin's courses on philosophy encouraged his students to think independently.
Once his studies were completed, Balzac was persuaded by his father to follow him into the law; for three years he trained and worked at the office of Victor Passez, a family friend. During this time Balzac began to understand the vagaries of human nature. In his 1840 novel "Le Notaire", he wrote that a young person in the legal profession sees "the oily wheels of every fortune, the hideous wrangling of heirs over corpses not yet cold, the human heart grappling with the Penal Code."
In 1819 Passez offered to make Balzac his successor, but his apprentice had had enough of the law. He despaired of being "a clerk, a machine, a riding-school hack, eating and drinking and sleeping at fixed hours. I should be like everyone else. And that's what they call living, that life at the grindstone, doing the same thing over and over again... I am hungry and nothing is offered to appease my appetite." He announced his intention to be a writer.
The loss of this opportunity caused serious discord in the Balzac household, although Honoré was not turned away entirely. Instead, in April 1819 he was allowed to live in the French capital—as English critic George Saintsbury describes it—"in a garret furnished in the most Spartan fashion, with a starvation allowance and an old woman to look after him", while the rest of the family moved to a house twenty miles [32 km] outside Paris.
First literary efforts.
Balzac's first project was a libretto for a comic opera called "Le Corsaire", based on Lord Byron's The Corsair. Realizing he would have trouble finding a composer, however, he turned to other pursuits.
In 1820 Balzac completed the five-act verse tragedy "Cromwell". Although it pales in comparison to later works, some critics consider it a quality text. When he finished, Balzac went to Villeparisis and read the entire work to his family; they were unimpressed. He followed this effort by starting (but never finishing) three novels: "Sténie", "Falthurne", and "Corsino".
In 1821 Balzac met the enterprising Auguste Lepoitevin, who convinced the author to write short stories, which Lepoitevin would then sell to publishers. Balzac quickly turned to longer works, and by 1826 he had written nine novels, all published under pseudonyms and often produced in collaboration with other writers. For example, the scandalous novel "Vicaire des Ardennes" (1822)—banned for its depiction of nearly-incestuous relations and, more egregiously, of a married priest—attributed to a 'Horace de Saint-Aubin'. These books were potboiler novels, designed to sell quickly and titillate audiences. In Saintsbury's view, "They are curiously, interestingly, almost enthrallingly bad." Saintsbury indicates that Robert Louis Stevenson tried to dissuade him from reading these early works of Balzac. American critic Samuel Rogers, however, notes that "without the training they gave Balzac, as he groped his way to his mature conception of the novel, and without the habit he formed as a young man of writing under pressure, one can hardly imagine his producing "La Comédie Humaine"." Biographer Graham Robb suggests that as he discovered the Novel, Balzac discovered himself.
During this time Balzac wrote two pamphlets in support of primogeniture and the Society of Jesus. The latter, regarding the Jesuit order, illustrated his lifelong admiration for the Catholic Church. In the preface to "La Comédie Humaine" he wrote: "Christianity, above all, Catholicism, being...a complete system for the repression of the depraved tendencies of man, is the most powerful element of social order."
"Une bonne spéculation".
In the late 1820s Balzac dabbled in several business ventures, a penchant his sister blamed on the temptation of an unknown neighbor. His first venture was a publishing enterprise which turned out cheap one-volume editions of French classics including the works of Molière. This business failed miserably, with many of the books "sold as waste paper". Balzac had better luck publishing the memoirs of Laure Junot, Duchess of Abrantès—with whom he also had an affair.
Balzac borrowed money from his family and friends, and tried to build a printing business, then a typefounder enterprise. His inexperience and lack of capital caused his ruin in these trades. He gave the businesses to a friend (who made them successful) but carried the debts for many years. As of April 1828 Balzac owed 50,000 francs to his mother.
Balzac never lost his penchant for "une bonne spéculation". It resurfaced painfully later when—as a renowned and busy author—he traveled to Sardinia in the hopes of reprocessing the slag from the Roman mines in that country. Near the end of his life Balzac was captivated by the idea of cutting 20000 acre of oak wood in Ukraine and transporting it for sale in France.
"La Comédie Humaine" and literary success.
After writing several novels, in 1832 Balzac conceived the idea for an enormous series of books that would paint a panoramic portrait of "all aspects of society." When the idea struck, he raced to his sister's apartment and proclaimed: "I am about to become a genius." Although he originally called it "Etudes des Mœurs" (Study of Mores), it eventually became known as "La Comédie Humaine", and he included in it all the fiction that he had published in his lifetime under his own name. This was to be Balzac's life work and his greatest achievement.
After the collapse of his businesses, Balzac traveled to Brittany and stayed with the de Pommereul family outside Fougères. There he drew inspiration for "Les Chouans" (1829), a tale of love gone wrong amid the Chouan royalist forces. Although Balzac was a supporter of the crown, Balzac paints the counter-revolutionaries in a sympathetic light—even though they are the center of the book's most brutal scenes. This was the first book Balzac released under his own name, and it gave him what one critic called "passage into the Promised Land". It established him as an author of note (even if the surface owes a debt to Walter Scott) and provided him with a name outside his past pseudonyms.
Soon afterwards, around the time of his father's death, Balzac wrote "El Verdugo"—about a 30-year-old man who kills his father (Balzac was 30 years old at the time). This was the first work signed "Honoré "de" Balzac". Like his father, he added the aristocratic-sounding particle to help him fit into respected society, but it was a choice based on skill, not birthright. "The aristocracy and authority of talent are more substantial than the aristocracy of names and material power", he wrote in 1830. The timing of the decision was also significant; as Robb explained: "The disappearance of the father coincides with the adoption of the nobiliary particle. A symbolic inheritance." Just as his father had worked his way up from poverty into respectable society, Balzac considered toil and effort his real mark of nobility.
When the July Revolution overthrew Charles X in 1830, Balzac declared himself a Legitimist, supporting Charles' House of Bourbon—but with qualifications. He felt that the new July Monarchy (which claimed widespread popular support) was disorganized and unprincipled, in need of a mediator to keep the political peace between the King and insurgent forces. He called for "a young and vigorous man who belongs neither to the Directoire nor to the Empire, but who is 1830 incarnate..." He planned to be such a candidate, appealing especially to the higher classes in Chinon. But after a near-fatal accident in 1832 (he slipped and cracked his head on the street), Balzac decided not to stand for election.
1831 saw the success of "La Peau de Chagrin" ("The Wild Ass's Skin" or "The Magic Skin"), a fable-like tale about a despondent young man named Raphaël de Valentin who finds an animal skin which promises great power and wealth. He obtains these things, but loses the ability to manage them. In the end, his health fails and he is consumed by his own confusion. Balzac meant the story to bear witness to the treacherous turns of life, its "serpentine motion."
In 1833 Balzac released "Eugénie Grandet", his first best-selling novel. The tale of a young lady who inherits her father's miserliness, it also became the most critically acclaimed book of his career. The writing is simple, yet the individuals (especially the bourgeois title character) are dynamic and complex.
"Le Père Goriot" ("Old Father Goriot", 1835) was his next success, in which Balzac transposes the story of "King Lear" to 1820s Paris in order to rage at a society bereft of all love save the love of money. The centrality of a father in this novel matches Balzac's own position—not only as mentor to his troubled young secretary, Jules Sandeau, but also the fact that he had fathered a child, Marie-Caroline Du Fresnay, with his otherwise-married lover, Maria Du Fresnay, who had been his source of inspiration for "Eugénie Grandet".
In 1836 Balzac took the helm of the "Chronique de Paris", a weekly magazine of society and politics. He tried to enforce strict impartiality in its pages and a reasoned assessment of various ideologies. As Rogers notes, "Balzac was interested in any social, political, or economic theory, whether from the right or the left." The magazine failed, but in July 1840 he founded another publication, the "Revue Parisienne". It lasted for three issues.
These dismal business efforts—and his misadventures in Sardinia—provided an appropriate "milieu" in which to set the two-volume "Illusions Perdues" ("Lost Illusions", 1843). The novel concerns Lucien de Rubempré, a young poet trying to make a name for himself, who becomes trapped in the morass of society's darkest contradictions. Lucien's journalism work is informed by Balzac's own failed ventures in the field. "Splendeurs et misères des courtisanes" ("The Harlot High and Low", 1847) continues Lucien's story. He is trapped by the Abbé Herrera (Vautrin) in a convoluted and disastrous plan to regain social status. The book undergoes a massive temporal rift; the first part (of four) covers a span of six years, while the final two sections focus on just three days.
"Le Cousin Pons" (1847) and "La Cousine Bette" (1848) tell the story of "Les Parents Pauvres" ("The Poor Relations"). The conniving and wrangling over wills and inheritances reflect the expertise gained by the author as a young law clerk. Balzac's health was deteriorating by this point, making the completion of this pair of books a significant accomplishment.
Many of his novels were initially serialized, like those of Dickens. Their length was not predetermined. "Illusions Perdues" extends to a thousand pages after starting inauspiciously in a small-town print shop, whereas "La Fille aux yeux d'or" ("The Girl with the Golden Eyes", 1835) opens with a broad panorama of Paris but becomes a closely plotted novella of only fifty pages.
Work habits.
Balzac's work habits are legendary—he did not work quickly, but toiled with an incredible focus and dedication. His preferred method was to eat a light meal at five or six in the afternoon, then sleep until midnight. He then rose and wrote for many hours, fueled by innumerable cups of black coffee. He would often work for fifteen hours or more at a stretch; he claimed to have once worked for 48 hours with only three hours of rest in the middle.
Balzac revised obsessively, covering printer's proofs with changes and additions to be reset. He sometimes repeated this process during the publication of a book, causing significant expense for both himself and the publisher. As a result, the finished product was frequently quite different from the original book. While some of his books never reached a finished state, some of those—such as "Les employés" ("The Government Clerks", 1841)—are nonetheless noted by critics.
Although Balzac was "by turns a hermit and a vagrant", he managed to stay connected to the social world which nourished his writing. He was friends with Théophile Gautier and Pierre-Marie-Charles de Bernard du Grail de la Villette, and he knew Victor Hugo. Nevertheless, he did not spend as much time in "salons" and clubs as did many of his characters. "In the first place he was too busy", explains Saintsbury, "in the second he would not have been at home there... [H]e felt it was his business not to frequent society but to create it." Nonetheless he often spent long periods at Château de Saché, near Tours, the home of his friend Jean de Margonne, his mother's lover and father to her youngest child. Many of Balzac's tormented characters were created in the small second-floor bedroom. Today the Château is a museum dedicated to the author's life.
Sentimental life.
In 1833, as he revealed in a letter to his sister, Balzac entered into a secret affair, with fellow writer Maria Du Fresnay, who was then 24. Her marriage with a considerably older man had been a failure from the start. In this letter, Balzac also reveals that the young woman had just come to tell him she was pregnant with him. In 1834, 8 months after the event, Maria Du Fresnay's daughter with Balzac, Marie-Caroline Du Fresnay, was born. This revelation from French journalist Roger Pierrot in 1955 confirmed what was already suspected by several historians: the dedicatee of the novel Eugenie Grandet, a certain "Maria", was Maria Du Fresnay herself.
In February 1832 Balzac received a letter from Odessa—lacking a return address and signed only by "L'Étrangère" ("The Foreigner")—expressing sadness at the cynicism and atheism in "La Peau de Chagrin" and its negative portrayal of women. He responded by purchasing a classified advertisement in the "Gazette de France", hoping that his anonymous critic would find it. Thus began a fifteen-year correspondence between Balzac and "the object of [his] sweetest dreams": Ewelina Hańska.
Hańska was married to a man twenty years her senior, Wacław Hański, a wealthy Polish landowner living near Kiev. It had been a marriage of convenience to preserve her family's fortune. In Balzac Ewelina found a kindred spirit for her emotional and social desires, with the added benefit of feeling a connection to the glamorous capital of France. Their correspondence reveals an intriguing balance of passion, propriety and patience; Robb says it is "like an experimental novel in which the female protagonist is always trying to pull in extraneous realities but which the hero is determined to keep on course, whatever tricks he has to use."
Wacław Hański died in 1841, and his widow and her admirer finally had the chance to pursue their affections. Competing with the Hungarian composer Franz Liszt, Balzac visited her in St. Petersburg in 1843 and impressed himself on her heart. After a series of economic setbacks, health problems, and prohibitions from the Tsar, the couple were finally able to wed. On 14 March 1850, with Balzac's health in serious decline, they drove from her estate in Wierzchownia (village of Verkhivnia) to a church in Berdyczów (city of Berdychiv, today in Ukraine) and were married. The ten-hour journey to and from the ceremony took a toll on both husband and wife: her feet were too swollen to walk, and he endured severe heart trouble.
Although he married late in life, Balzac had already written two treatises on marriage: "Physiologie du Mariage" and "Scènes de la Vie Conjugale". These works suffered from a lack of firsthand knowledge; Saintsbury points out that "Cœlebs cannot talk of [marriage] with much authority." In late April the newly-weds set off for Paris. His health deteriorated on the way, and Ewelina wrote to her daughter about Balzac being "in a state of extreme weakness" and "sweating profusely". They arrived in the French capital on 20 May, his fifty-first birthday.
Five months after his wedding, on 18 August, Balzac died. His mother was the only one with him when he expired; Mme. Hańska had gone to bed. He had been visited that day by Victor Hugo, who later served as pallbearer and eulogist at Balzac's funeral.
Balzac was buried at the Cimetière du Père Lachaise in Paris. "Today", said Hugo at the ceremony, "we have a people in black because of the death of the man of talent; a nation in mourning for a man of genius." The funeral was attended by "almost every writer in Paris", including Frédérick Lemaître, Gustave Courbet, Dumas "père" and Dumas "fils".
Later, Balzac became the subject of a monumental statue by the French sculptor Auguste Rodin. Cast in bronze for the first time in 1939, the Monument to Balzac stands near the intersection of Boulevard Raspail and Boulevard Montparnasse. Rodin featured Balzac in several of his smaller sculptures as well.
Writing style.
The "Comédie Humaine" remained unfinished at the time of his death—Balzac had plans to include numerous other books, most of which he never started. He frequently moved between works in progress, and "finished" works were often revised between editions. This piecemeal style is reflective of the author's own life, a possible attempt to stabilize it through fiction. "The vanishing man", writes Pritchett, "who must be pursued from the rue Cassini to ... Versailles, Ville d'Avray, Italy, and Vienna can construct a settled dwelling only in his work."
Realism.
Balzac's extensive use of detail, especially the detail of objects, to illustrate the lives of his characters made him an early pioneer of literary realism. While he admired and drew inspiration from the Romantic style of Scottish novelist Walter Scott, Balzac sought to depict human existence through the use of particulars. In the preface to the first edition of "Scènes de la Vie privée", he writes: "The author firmly believes that details alone will henceforth determine the merit of works..." Plentiful descriptions of décor, clothing, and possessions help breathe life into the characters. For example, Balzac's friend Hyacinthe de Latouche had knowledge of hanging wallpaper. Balzac transferred this to his descriptions of the Pension Vauquer in "Le Père Goriot", making the wallpaper speak of the identities of those living inside.
Some critics consider Balzac's writing exemplary of naturalism—a more pessimistic and analytical form of realism, which seeks to explain human behavior as intrinsically linked with the environment. French novelist Émile Zola declared Balzac the father of the naturalist novel. Zola indicated that, whereas Romantics saw the world through a colored lens, the naturalist sees through a clear glass—precisely the sort of effect Balzac attempted to achieve in his works.
Characters.
Balzac sought to present his characters as real people, neither fully good nor fully evil, but fully human. "To arrive at the truth", he wrote in the preface to "Le Lys dans la vallée", "writers use whatever literary device seems capable of giving the greatest intensity of life to their characters." "Balzac's characters", Robb notes, "were as real to him as if he were observing them in the outside world." This reality was noted by playwright Oscar Wilde, who said: "One of the greatest tragedies of my life is the death of ["Illusions Perdues" protagonist] Lucien de Rubempré... It haunts me in my moments of pleasure. I remember it when I laugh."
At the same time, the characters represent a particular range of social types: the noble soldier, the scoundrel, the proud workman, the fearless spy, the alluring mistress. That Balzac was able to balance the strength of the individual against the representation of the type is evidence of the author's skill. One critic explained that "there is a center and a circumference to Balzac's world."
Balzac's use of repeating characters, moving in and out of the "Comédie"'s books, strengthens the realist representation. "When the characters reappear", notes Rogers, "they do not step out of nowhere; they emerge from the privacy of their own lives which, for an interval, we have not been allowed to see." He also used a realist technique which French novelist Marcel Proust later named "retrospective illumination", whereby a character's past is revealed long after she or he first appears.
A nearly infinite reserve of energy propels the characters in Balzac's novels. Struggling against the currents of human nature and society, they may lose more often than they win—but only rarely do they give up. This universal trait is a reflection of Balzac's own social wrangling, that of his family, and an interest in the Austrian mystic and physician Franz Mesmer, who pioneered the study of animal magnetism. Balzac spoke often of a "nervous and fluid force" between individuals, and Raphaël Valentin's decline in "La Peau de Chagrin" exemplifies the danger of withdrawing from the company of other people.
Place.
Representations of the city, countryside, and building interiors are essential to Balzac's realism, often serving to paint a naturalistic backdrop before which the characters' lives follow a particular course; this gave him a reputation as an early naturalist. Intricate details about locations sometimes stretch for fifteen or twenty pages. As he did with the people around him, Balzac studied these places in depth, traveling to remote locations and surveying notes that he had made on previous visits.
The influence of Paris permeates "La Comédie". Nature defers to the artificial metropolis, in contrast to the depictions of weather and wildlife in the countryside. "If in Paris", Rogers says, "we are in a man-made region where even the seasons are forgotten, these provincial towns are nearly always pictured in their natural setting." Balzac said, "the streets of Paris possess human qualities and we cannot shake off the impressions they make upon our minds." His labyrinthine city provided a literary model used later by English novelist Charles Dickens and Russian author Fyodor Dostoevsky. The centrality of Paris in "La Comédie Humaine" is key to Balzac's legacy as a realist. "Realism is nothing if not urban", notes critic Peter Brooks; the scene of a young man coming into the city to find his fortune is ubiquitous in the realist novel, and appears repeatedly in Balzac's works, such as "Illusions Perdues".
Perspective.
Balzac's literary mood evolved over time from one of despondency and chagrin to one of solidarity and courage—but not optimism. "La Peau de Chagrin", among his earliest novels, is a pessimistic tale of confusion and destruction. But the cynicism declined as his "oeuvre" progressed, and the characters of "Illusions Perdues" reveal sympathy for those who are pushed to one side by society. As part of the 19th-century evolution of the novel as a "democratic literary form", Balzac wrote that "les livres sont faits pour tout le monde," ("books are written for everybody").
Balzac concerned himself overwhelmingly with the darker essence of human nature and the corrupting influence of middle and high societies. He worked to observe humanity in its most representative state, frequently passing "incognito" among the masses of Parisian society to do research. He used incidents from his life and the people around him, in works like "Eugénie Grandet" and "Louis Lambert".
Politics.
Balzac was a highly conservative Royalist; in many ways, he is the antipode to Victor Hugo's democratic republicanism. Nevertheless, his keen insight regarding working-class conditions earned him the esteem of many Socialists and Marxists. Engels said that Balzac was his favorite writer. Marx's work "Das Kapital" also makes constant reference to the works of Balzac and urged Engels to read Balzac's work "The Unknown Masterpiece".
Legacy.
Balzac influenced the writers of his time and beyond. He has been compared to Charles Dickens and has been called one of Dickens' influences. Critic W. H. Helm calls one "the French Dickens" and the other "the English Balzac". Critic Richard Lehan says that "Balzac was the bridge between the comic realism of Dickens and the naturalism of Zola."
Gustave Flaubert was also substantially influenced by Balzac. Praising his portrayal of society while attacking his prose style, Flaubert once wrote: "What a man he would have been had he known how to write!" While he disdained the label of "realist", Flaubert clearly took heed of Balzac's close attention to detail and unvarnished depictions of bourgeois life. This influence shows in Flaubert's work "L'education sentimentale," which owes a debt to Balzac's "Illusions Perdues". "What Balzac started", says Lehan, "Flaubert helped finish."
Marcel Proust similarly learned from the Realist example; he adored Balzac and studied his works carefully, although he criticised what he called Balzac's "vulgarity." Balzac's story "Une Heure de ma Vie" ("An Hour of my Life", 1822), in which minute details are followed by deep personal reflections, is a clear ancestor of the style which Proust used in "À la recherche du temps perdu". However, Proust wrote later in life that the contemporary fashion to rank Balzac higher than Tolstoy was "madness."
Perhaps the author most affected by Balzac was American expatriate novelist Henry James. In 1878 James wrote with sadness about the lack of contemporary attention paid to Balzac, and lavished praise on him in four essays (in 1875, 1877, 1902, and 1913). In 1878 James wrote: "Large as Balzac is, he is all of one piece and he hangs perfectly together." He wrote with admiration of Balzac's attempt to portray in writing "a beast with a hundred claws." In his own novels James explored more of the psychological motives of the characters and less of the historical sweep exhibited by Balzac—a conscious style preference. "[T]he artist of the "Comédie Humaine"," he wrote, "is half smothered by the historian." Still, both authors used the form of the realist novel to probe the machinations of society and the myriad motives of human behavior.
Balzac's vision of a society in which class, money and personal ambition are the major players has been endorsed by critics of both left-wing and right-wing political tendencies. Marxist Friedrich Engels wrote: "I have learned more [from Balzac] than from all the professional historians, economists and statisticians put together." Balzac has received high praise from critics as diverse as Walter Benjamin and Camille Paglia. In 1970 Roland Barthes published "S/Z", a detailed analysis of Balzac's story "Sarrasine" and a key work in structuralist literary criticism.
Balzac has also influenced popular culture. Many of his works have been made into popular films and television serials, including: Travers Vale's "Père Goriot" (1915), "Les Chouans" (1947), "Le Père Goriot" (1968 BBC mini-series), and "La Cousine Bette" (1974 BBC mini-series, starring Margaret Tyzack and Helen Mirren; 1998 film, starring Jessica Lange). He is included in François Truffaut's 1959 film, "The 400 Blows". Truffaut believed Balzac and Proust to be the greatest of French writers. He was also adapted into a character in Orson Scott Card's alternate history series "The Tales of Alvin Maker"; he is presented as a crude but deeply witty and insightful man. Chinese author Dai Sijie published "Balzac et la Petite Tailleuse Chinoise" ("Balzac and the Little Chinese Seamstress")(2000), in which a suitcase filled with novels helps to sustain city youths sent to the countryside for "re-education" during the Chinese Cultural Revolution. It was made into a film (adapted and directed by the author) in 2002. The Japanese rock band Balzac is also named in his honor.
Works.
Tragic verse
Incomplete at time of death
Published pseudonymously
As "Lord R'Hoone", in collaboration
As "Horace de Saint-Aubin"
Published anonymously
Selected titles from "La Comédie humaine"
Plays
Tales
Summaries, reviews and other information about Balzac and his works are being collated at the collaborative blog La Comedie Humaine.

</doc>
<doc id="42370" url="http://en.wikipedia.org/wiki?curid=42370" title="History of Belgium">
History of Belgium

The history of Belgium stretches back before the origin of the modern state of that name in 1830. Belgium's history is intertwined with those of its neighbours: the Netherlands, Germany, France and Luxembourg. For most of its history, what is now Belgium was either a part of a larger territory, such as the Carolingian Empire, or divided into a number of smaller states, prominent among them being the Duchy of Brabant, the County of Flanders, the Prince-Bishopric of Liège and Luxembourg. Due to its strategic location and the many armies fighting on its soil, Belgium since the Thirty Years' War (1618-1648) has often been called the "battlefield of Europe" or the "cockpit of Europe". It is also remarkable as a European nation which contains, and is divided by, a language boundary between Latin-derived French, and Germanic Dutch.
Belgium's formation, like that of its Benelux neighbours, can be traced back to the "Seventeen Provinces" within the Burgundian Netherlands. These were brought together under the House of Valois-Burgundy, and eventually declared independent of both France and Germany by their descendant Charles V, Holy Roman Emperor, in his Pragmatic Sanction of 1549. The Eighty Years' War (1568–1648), led to the split between a northern Dutch Republic, and the Southern Netherlands from which Belgium and Luxembourg developed. This southern territory continued to be ruled by the Habsburg descendants of the Burgundian house, at first as the "Spanish Netherlands". Invasions from France under Louis XIV led to the loss of most of what is now Nord-Pas-de-Calais to France, while the remainder finally became the "Austrian Netherlands". The French Revolutionary wars led to Belgium becoming part of France in 1795, bringing the end of the semi-independence of areas which had belonged to the Catholic church. After the defeat of the French in 1814, a new United Kingdom of the Netherlands was created, which eventually split one more time during the Belgian Revolution of 1830–1839, giving three modern nations, Belgium, the Netherlands, and Luxembourg.
Belgium was one of the first countries to experience an Industrial Revolution, which brought prosperity in the 19th century but also opened a political dichotomy between liberal businessmen and socialist workers. The king set up his own private colonial empire in the Belgian Congo, which the government took over after a major scandal in 1908. Belgium was neutral but its strategic location as a pathway to France made it an invasion target for Germany in 1914 and 1940. Conditions under the occupation were severe. In the postwar period Belgium was a leader in European unification, as a founding member of what has become the European Union. Brussels is now host to the headquarters of NATO and is the "de facto" capital of the European Union. The colonies became independent in the early 1960s.
Politically the country was polarized on matters of religion and, in recent decades, it has faced new divisions over differences of language and the unequal economic development. This ongoing antagonism has caused far-reaching reforms since the 1970s, changing the formerly unitary Belgian state into a federal state, and repeated governmental crises. It now is divided into three regions, Flanders (Dutch speaking) in the north, Wallonia (French speaking) in the South, and bilingual Brussels in the middle. The economy is prosperous and well integrated into Europe.
Before independence.
Prehistory.
On Belgian territory Neanderthal fossils were discovered at Engis in 1829-30 and elsewhere, some dating back to at least 100,000 BCE.
The earliest Neolithic farming technology of northern Europe, the so-called LBK culture, reached the east of Belgium at its furthest northwesterly stretch from its origins in southeast Europe. Its expansion stopped in the Hesbaye region of eastern Belgium around 5000 BCE. The Belgian LBK is notable for its use of defensive walls around villages, something which may or may not have been necessary because of the proximity of hunter gatherers.
So-called Limburg pottery and La Hoguette pottery are styles which stretch into northwestern France and the Netherlands, but it has sometimes been argued that these technologies are the result of pottery technology spreading beyond the original LBK farming population of eastern Belgium and northeastern France, and being made by hunter gatherers. A slightly later-starting Neolithic culture found in central Wallonia is the so-called "Groupe de Blicquy", which may represent an offshoot of the LBK settlers. One notable archaeological site in this region is the Neolithic flint mines of Spiennes.
Farming in Belgium however failed to take permanent hold at first. The LBK and Blicquy cultures disappeared and there is a long gap before a new farming culture, the Michelsberg culture, appeared and became widespread. Hunter gatherers of the Swifterbant culture apparently remained in the sandy north of Belgium, but apparently became more and more influenced by farming and pottery technology.
In the third and late fourth millennia BCE, the whole of Flanders shows relatively little evidence of human habitation. Although it is felt that there was a continuing human presence, the types of evidence available make judgement about the details very difficult. The Seine-Oise-Marne culture spread into the Ardennes, and is associated with megalithic sites there (for example Wéris), but did not disperse over all of Belgium. To the north and east, in the Netherlands, a semi-sedentary culture group has been proposed to have existed, the so-called Vlaardingen-Wartburg-Stein complex, which possibly developed from the above-mentioned Swifterbant and Michelsburg cultures. The same pattern continues into the late Neolithic and early Bronze Age. In the last part of the Neolithic, evidence is found for the Corded Ware and Bell Beaker cultures in the south of the Netherlands, but these cultures also do not seem to have had a big impact in all of Belgium.
The population of Belgium started to increase permanently with the late Bronze age from around 1750 BCE. Three possibly related European cultures arrived in sequence. First the Urnfield culture arrived (for example, tumuli are found at Ravels and Hamont-Achel in the Campine). Then, coming into the Iron Age, the Hallstatt culture, and the La Tène culture. All three of these are associated with Indo-European languages, with specifically Celtic languages being especially associated with La Tène material culture, and possibly Halstatt. This is because historical Greek and Roman records from areas where this culture settled show Celtic placenames and personal names.
However it is possible in Belgium that especially in the northern areas the Hallstatt and La Tène cultures were brought by new elites, and that the main language of the population was not Celtic. From 500 BC Celtic tribes settled in the region and traded with the Mediterranean world. From c. 150 BC, the first coins came into use, under the influence of trade with the Mediterranean.
Celtic and Roman periods.
When Julius Caesar arrived in the region, as recorded in his "De Bello Gallico", the inhabitants of Belgium, northwestern France, and the German Rhineland were known as the Belgae (after whom modern Belgium is named), and they were considered to be the northern part of Gaul. (The region of Luxembourg, including the Belgian province of Luxembourg, was inhabited by the Treveri, who were probably not strictly considered to be Belgae.) The distinction between the Belgae to the North and the Celts to the south, and the Germani across the Rhine, is disputed.
Caesar says that the Belgae were separated from the rest of Gaul by language, law and custom, and he also says they had Germanic ancestry, but he does not go into detail. It seems clear that Celtic culture and language were very influential upon the Belgae, especially those in modern France. On the other hand, linguists have proposed that there is evidence that the northern part of the Belgic population had previously spoken an Indo European language related to, but distinct from, Celtic and Germanic, and among the northern Belgae, Celtic may never have been the language of the majority. (See Belgian language and Nordwestblock.)
The leaders of the Belgic alliance which Caesar confronted were in modern France, the Suessiones, Viromandui and Ambiani and perhaps some of their neighbours, in an area that he appears to distinguish as the true "Belgium" of classical times. Concerning the territory of modern Belgium, he reported that the more northerly allies of the Belgae, from west to east the Menapii, Nervii, and "Germani cisrhenani", were less economically developed and more warlike, similar to the "Germani" east of the Rhine river. The Menapii and Germani lived among low thorny forests, islands and swamps, and the central Belgian Nervii lands were deliberately planted with thick hedges, in order to be impenetrable to cavalry. There is also less archaeological evidence of large settlements and trade in the area. According to Tacitus, writing a generation later, the "Germani cisrhenani" (who included the Eburones) were in fact the original tribe to be called "Germani", and all other uses of the term extended from them, though in his time the same people were now called the Tungri.
Modern linguists use the word "germanic" to refer to languages but it is not known for sure whether even the Belgian "Germani" spoke a Germanic language, and their tribal and personal names are clearly Celtic. This is in fact also true of the possibly related tribes across the Rhine from them at this time. Archaeologists have also had difficulty finding evidence of the exact migrations from east of the Rhine which Caesar reports and more generally there has been skepticism about using him in this way due to the political motives of his commentaries. But the archaeological record gives the impression that the classical Belgian "Germani" were a relatively stable population going back to Urnfield times, with a more recently immigrated elite class who would have been of more interest to Caesar.
The western and southern Belgae flourished within the Roman province of Gallia Belgica, along with the Treveri. Gallia Belgica originally included five regional capitals, four of which are today in France, Nemetacum (Arras), Divodurum (Metz), Bagacum (Bavay), and Durocorturum (Reims). One, Augusta Treverorum (Trier) is in Germany, near Luxembourg. Only one, Atuatuca Tongrorum (Tongeren), was in modern Belgium.
The northeastern corner of this province, including Tongeren and the area of the earlier "Germani", was united with the militarized Rhine border to form a newer province known as Germania Inferior. Its cities included Ulpia Noviomagus (Nijmegen in the modern Netherlands), Colonia Ulpia Trajana (Xanten in modern Germany) and the capital Colonia Agrippina (Cologne in Germany). Later, Emperor Diocletian restructured the provinces around 300, and split the remaining Belgica into two provinces: "Belgica Prima" and "Belgica Secunda". Belgica Prima was the eastern part and had Trier as its main city, and included the Belgian province of Luxembourg.
Christianity was also first introduced to Belgium during the late-Roman period, and the first known bishop in the region Servatius taught in the middle of the Fourth century in Tongeren.
Early Middle Ages.
As the Western Roman Empire collapsed during the 5th and 6th centuries, Germanic tribes invaded and established themselves. One of these peoples, the Franks, settled in Germania Inferior, and proceeded to expand into a new kingdom covering all of Belgium and much of France, under the rule of the Merovingian Dynasty. Clovis I was the best-known king of this dynasty. He ruled from his base in northern France. He converted to Christianity. Christian scholars, mostly Irish monks, preached Christianity to the populace and started a wave of conversion (Saint Servatius, Saint Remacle, Saint Hadelin).
The Merovingians were short-lived and were succeeded by the Carolingian Dynasty, whose family power base was in the eastern part of modern Belgium. After Charles Martel countered the Moorish invasion from Spain (732 — Poitiers), the King Charlemagne (born close to Liège in Herstal or Jupille) brought a huge part of Europe under his rule and was crowned the "Emperor of the new Holy Roman Empire" by the Pope Leo III (800 in Aachen).
The Vikings raided widely throughout this period, but a major settlement that had caused problems in the area of Belgium was defeated in 891 by Arnulf of Carinthia near Leuven.
The Frankish lands were divided and reunified several times under the Merovingian and Carolingian dynasties, but eventually were firmly divided into France and the Holy Roman Empire. The parts of the County of Flanders stretching out west of the river Scheldt (Schelde in Dutch, Escaut in French) became part of France during the Middle Ages, but the remainders of the County of Flanders and the Low Countries were part of the Holy Roman Empire.
Through the early Middle Ages, the northern part of present-day Belgium (now commonly referred to as Flanders) was a Germanic language-speaking area, whereas in the southern part people had continued to be Romanized and spoke derivatives of Vulgar Latin.
As the Holy Roman Emperors and French Kings lost effective control of their domains in the 11th and 12th centuries, the territory more or less corresponding to the present Belgium was divided into relatively independent feudal states, including:
The coastal county of Flanders was one of the wealthiest parts of Europe in the late Middle Ages, from trading with England, France and Germany, and it became culturally important. During the 11th and 12th centuries, the Rheno-Mosan or Mosan art movement flourished in the region moving its centre from Cologne and Trier to Liège, Maastricht and Aachen. Some masterpieces of this Romanesque art are the shrine of the Three Kings at Cologne Cathedral, the Baptismal font at St Bartholomew's Church, Liège by Renier de Huy, the Stavelot Triptych, the shrine of Saint Remacle in Stavelot, the shrine of Saint Servatius in Maastricht or, Notger's gospel in Liège.
13th-16th centuries.
In this period, many cities, including Ypres, Bruges and Ghent got their city charter. The Hanseatic League stimulated trade in the region, and the period saw the erection of many Gothic cathedrals and city halls. With the decline of the Holy Roman emperors' power starting in the 13th century, the Low Countries were largely left to their own devices. The lack of imperial protection also meant that the French and English began vying for influence in the region.
In 1214, King Philip II of France defeated the Count of Flanders in the Battle of Bouvines and forced his submission to the French crown. Through the remainder of the 13th century, French control over Flanders steadily increased until 1302 when an attempt at total annexation by Philip IV met a stunning defeat when Count Guy (who had the support of the guilds and craftsmen) rallied the townspeople and humiliated the French knights at the Battle of the Golden Spurs. Undaunted, Philip launched a new campaign that ended with the inconclusive Battle of Mons-en-Pévèle in 1304. The king imposed harsh peace terms on Flanders, which included ceding the important textile-making centers of Lille and Douai.
Thereafter, Flanders remained a French tributary until the start of the Hundred Years' War in 1337. In Brabant, skillful work by the duke of that territory and the Count of Hainaut-Holland foiled various French manipulations. Paris's influence in the Low Countries was counterbalanced by England, which maintained important ties to the coastal ports.
Flanders faced the difficult situation of being politically subservient to France, but also reliant on trade with England. Many craftsmen emigrated to England, which also came to dominate the wool-shipping business. Flemish cloth nonetheless remained a highly valued product, and it was highly dependent on English wool. Any interruption in the supply of that invariably resulted in riots and violence from the weavers' guilds. On the whole though, Flemish trade became a passive one. Flanders received imports from other areas of Europe, but itself purchased little abroad except wine from Spain and France. Bruges became a great commercial center after the Hanseatic League set up business there and the Italian banking houses followed suit.
A few towns in the Low Countries dated back to Roman times, but most had been founded from the 9th century onward. The oldest were in the Scheldt and Meuse areas, with many towns in what's now the Netherlands being much younger and only dating from the 13th century. From early on, the Low Countries began to develop as a commercial and manufacturing center. Merchants became the dominant class in the towns, with the nobility largely limited to countryside estates.
By 1433 most of the Belgian and Luxembourgish territory along with much of the rest of the Low Countries became part of Burgundy under Philip the Good. When Mary of Burgundy, granddaughter of Philip the Good married Maximilian I, the Low Countries became Habsburg territory. Their son, Philip I of Castile (Philip the Handsome) was the father of the later Charles V. The Holy Roman Empire was unified with Spain under the Habsburg Dynasty after Charles V inherited several domains.
Especially during the Burgundy period (the 15th and 16th centuries), Tournai, Bruges, Ypres, Ghent, Brussels, and Antwerp took turns at being major European centers for commerce, industry (especially textiles) and art. Bruges was the pioneer. had a strategic location at the crossroads of the northern Hanseatic League trade and the southern trade routes. Bruges was already included in the circuit of the Flemish and French cloth fairs at the beginning of the 13th century, but when the old system of fairs broke down the entrepreneurs of Bruges innovated. They developed, or borrowed from Italy, new forms of merchant capitalism, whereby several merchants would share the risks and profits and pool their knowledge of markets. They employed new forms of economic exchange, including bills of exchange ("i.e." promissory notes) and letters of credit. Antwerp eagerly welcomed foreign traders, most notably the Portuguese pepper and spice traders.
In art the Renaissance was represented by the Flemish Primitives, a group of painters active primarily in the Southern Netherlands in the 15th and early 16th centuries (for example, Johannes Van Eyck and Rogier Van der Weyden), and the Franco-Flemish composers (e.g. Guillaume Dufay). Flemish tapestries and, in the 16th and 17th centuries, Brussels tapestry hung on the walls of castles throughout Europe.
The Pragmatic Sanction of 1549, issued by Roman Emperor Charles V, established the so-called Seventeen Provinces, or Belgica Regia in its official Latin term, as an entity on its own, apart from the Empire and from France. This comprised all of Belgium, present-day north-western France, present-day Luxembourg, and present-day Netherlands, except for the lands of the Prince Bishop of Liège.
The Burgundian princes from Philip II (the Bold) to Charles the Bold, enhanced their political prestige with economic growth and artistic splendour. These “Great Dukes of the West” were effectively sovereigns, with domains extending from the Zuiderzee to the Somme. The urban and other textile industries, which had developed in the Belgian territories since the 12th century, became the economic center of northwestern Europe.
The death of Charles the Bold (1477) and the marriage of his daughter Mary to the archduke Maximilian of Austria ended the independence of the Low Countries by bringing them increasingly under the sway of the Habsburg dynasty. Mary and Maximilian’s grandson Charles became king of Spain as Charles I in 1516 and Holy Roman emperor as Charles V in 1519.
In Brussels on Oct. 25, 1555, Charles V abdicated Belgica Regia to his son, who in January 1556 assumed the throne of Spain as Philip II.
Dutch Revolt.
The northern part of Belgica Regia, comprising seven provinces and eventually forming the Dutch Republic, became increasingly Protestant ("i.e." Calvinistic), while the larger part, called 't Hof van Brabant and comprising the ten southern provinces, remained primarily Catholic. This schism, and other cultural differences which had been present since ancient times, launched the Union of Atrecht in the Belgian regions, later followed by the Union of Utrecht in the northern regions. When Philip II, son of Charles V, ascended the Spanish throne he tried to abolish all Protestantism. Portions of Belgica Regia revolted, what would eventually result in the Eighty Years' War between Spain and the Dutch Republic.
For the conquered Southern Netherlands the war ended in 1585 with the Fall of Antwerp. That same year, the northern provinces seized independence in the Act of Abjuration ("Plakkaat van Verlatinghe"), launching the Seven United Provinces.
King Philip II sent in Alexander Farnese, Duke of Parma, as Governor-General of the Spanish Netherlands from 1578 to 1592. Farnese led a successful campaign 1578-1592 against the Dutch Revolt, in which he captured the main cities of the south and returned them to the control of Catholic Spain. He took advantage of the divisions in the ranks of his opponents between the Dutch-speaking Flemish and the French-speaking Walloons, using persuasion to take advantage of the divisions and foment the growing discord.
By doing so he was able to bring back the Walloon provinces to an allegiance to the king. By the treaty of Arras in 1579, he secured the support of the 'Malcontents', as the Catholic nobles of the south were styled. The seven northern provinces, controlled by Calvinists, responded with the Union of Utrecht, where they resolved to stick together to fight Spain. Farnese secured his base in Hainaut and Artois, then moved against Brabant and Flanders. City after city fell: Tournai, Maastricht, Breda, Bruges and Ghent opened their gates.
Farnese finally laid siege to the great seaport of Antwerp. The city was open to the sea, strongly fortified, and well defended under the leadership of Marnix van St. Aldegonde. Farnese cut off all access to the sea by constructing a bridge of boats across the Scheldt. The city surrendered in 1585 as 60,000 Antwerp citizens (60% of the pre-siege population) fled north.
All of the Belgian regions were once more under Spanish control. In a war composed mostly of sieges rather than battles, he proved his mettle. His strategy was to offer generous terms for surrender: there would be no massacres or looting; historic urban privileges were retained; there was a full pardon and amnesty; return to the Catholic Church would be gradual. Meanwhile Catholic refugees from the North regrouped in Cologne and Douai and developed a more militant, tridentine identity. They became the mobilising forces of a popular Counter-Reformation in the South, thereby facilitating the eventual emergence of the state of Belgium.
While the former northern part of Belgica Regia, the Seven United Provinces, gained independence, Southern Belgica Regia remained under the rule of Spain (1556–1713).
17th and 18th centuries.
During the 17th century, Antwerp continued to be blockaded by the Dutch but became a major European center for industry and art. The Brueghels, Peter Paul Rubens and Van Dyck's baroque paintings were created during this period.
Wars between France and the Dutch Republic.
Under Louis XIV (1643-1715), France pursued an expansionist policy, particularly affecting Belgium. France frequently held control of territories in the Southern Netherlands, confronted by various opponents including the Netherlands and Austria. There was the War of Devolution (1667-1668), the Franco-Dutch War (1672-1678), the War of the Reunions (1683-1684), and the Nine Years' War (1688-1697). These were then followed by the War of the Spanish Succession (1701-1714).
When Charles II of Spain died in 1700, two dynasties of foreign relatives contested for the throne, the House of Bourbon, who ruled France, and the Habsburgs, who were emperors of the Holy Roman Empire as well as holding various territories in central Europe. The Austrian Habsburgs were supported by an alliance led by Britain, the Dutch Republic, and several other northern European Protestant states, and the French were supported by Bavaria. Much of the war occurred on Belgian soil, with the allies there being led upon the field by John Churchill, the Duke of Marlborough.
After the victory of Austria and its allies, the Belgian and present-day Luxembourg territories (except the lands under the lordship of the Prince Bishop of Liège) were transferred to the Austrian Habsburgs while the Bourbon Dynasty succeeded in inheriting Spain itself. They were thus called Belgium Austriacum from 1705 to 1795. Louis XIV died in 1715.
Brabant Revolution.
The Belgian Revolution of 1789-90 overlapped with the French Revolution which began in 1789. The movement called for independence from Austrian rule. Brabant rebels defeated the Austrians at the Battle of Turnhout and launched the United States of Belgium together with the Prince Bishopric of Liège. The new state was beset by factionalism between the radical "Vonckists," led by Jan Frans Vonck and the more conservative "Statists" of the Henri Van der Noot. Businessmen with widescale operations generally supported the Statists, while the Vonckists attracted small business and members of the trade guilds. They called for independence from Austria but were conservative in social and religious questions. By November 1790, the revolt had been crushed and the Austrian had returned to power.
French control.
Following the of the French Revolutionary Wars, Belgium Austriacum was invaded and annexed by France in 1795, ending Habsburg rule.
Belgium was divided into nine united "départements" and became an integral part of France. The Bishopric of Liège was dissolved. Its territory was divided over the "départements" Meuse-Inférieure and Ourte. Austria confirmed the loss of Belgium Austriacum, which had been the only autonomous part of the Austrian Empire, by the Treaty of Campo Formio, in 1797.
The French invaded and controlled Belgium, 1794-1814, imposing all their new reforms and incorporating what had been the "Austrian Netherlands" and the Diocese of Liege into France. New rulers were sent in by Paris. Belgian men were drafted into the French wars and heavily taxed. Nearly everyone was Catholic, but the Church was repressed. Resistance was strong in every sector, as Belgian nationalism emerged to oppose French rule. The French legal system, however, was adopted, with its equal legal rights, and abolition of class distinctions. Belgium now had a government bureaucracy selected by merit, but it was not at all popular.
Until the establishment of the Consulate in 1799, Catholics were heavily repressed by the French. The first University of Leuven was closed in 1797 and churches were plundered. During this early period of the French rule, the Belgian economy was completely paralyzed as taxes had to be paid in gold and silver coin while goods bought by the French were paid for with worthless assignats. During this period of systematic exploitation, about 800,000 Belgians fled the Southern Netherlands. The French occupation in Belgium led to further suppression of the Dutch language across the country, including its abolition as an administrative language. With the motto "one nation, one language", French became the only accepted language in public life as well as in economic, political, and social affairs.
The measures of the successive French governments and in particular the 1798 massive conscription into the French army were unpopular everywhere, especially in Flemish regions, where it sparked the Peasants' War. The brutal suppression of the Peasants' War marks the starting point of the modern Flemish movement.
In 1814, the Allies drove out Napoleon and ended French rule. The plan was to join Belgium and the Netherlands, under Dutch control. Napoleon briefly returned to power during the Hundred Days in 1815, but was decisively defeated at the Battle of Waterloo, south of Brussels.
Economics.
France promoted commerce and capitalism, paving the way for the ascent of the bourgeoisie and the rapid growth of manufacturing and mining. In economics, therefore, the nobility declined while the middle class Belgian entrepreneurs flourished because of their inclusion in a large market, paving the way for Belgium's leadership role after 1815 in the Industrial Revolution on the Continent.
Godechot finds that after the annexation, Belgium's business community supported the new regime unlike the peasants, who remained hostile. Annexation opened new markets in France for wool and other goods from Belgium. Bankers and merchants helped finance and supply the French army. France ended the prohibition against seaborne trade on the Scheldt that had been enforced by the Netherlands. Antwerp quickly became a major French port with a world trade, and Brussels grew as well.
United Kingdom of the Netherlands.
After Napoleon's defeat at Waterloo in 1815, the major victorious powers (Britain, Austria, Prussia, and Russia) agreed at Congress of Vienna on uniting the former Belgium Austriacum and the former Seven United Provinces, creating the United Kingdom of the Netherlands, which was to serve as a buffer state against any future French invasions. This was under the rule of a Protestant king, namely William I. Most of the small and ecclesiastical states in the Holy Roman Empire were given to larger states at this time, and this included the Prince-Bishopric of Liège which became now formally part of the United Kingdom of the Netherlands.
The enlightened despot William I, who reigned from 1815–1840, had almost unlimited constitutional power, the constitution having been written by a number of notable people chosen by him. As despot, he had no difficulty in accepting some of the changes resulting from the social transformation of the previous 25 years, including equality of all before the law. However, he resurrected the estates as a political class and elevated a large number of people to the nobility. Voting rights were still limited, and only the nobility were eligible for seats in the upper house.
William I was a Calvinist and intolerant of the Catholic majority in the newly created United Kingdom of the Netherlands. He promulgated the "Fundamental Law of Holland", with some modifications. This entirely overthrew the old order of things in the southern Netherlands, suppressed the clergy as an order, abolished the privileges of the Catholic Church, and guaranteed equal protection to every religious creed and the enjoyment of the same civil and political rights to every subject of the king. It reflected the spirit of the French Revolution and in so doing did not please the Catholic bishops in the south, who had detested the Revolution.
William I actively promoted economic modernization. His position as monarch was ambivalent, however; his sovereignty was real, but his authority was shared with a legislature elected partly by himself and partly by the wealthy citizens under a constitution granted by the king. Government was in the hands of ministries of state. The old provinces were reestablished in name only. The government was now fundamentally unitary, and all authority flowed from the center. The first 15 years of the Kingdom showed progress and prosperity, as industrialization proceeded rapidly in the south, where the Industrial Revolution allowed entrepreneurs and labor to combine in a new textile industry, powered by local coal mines. There was little industry in the northern provinces, but most overseas colonies were restored, and highly profitable trade resumed after a 25-year hiatus. Economic liberalism combined with moderate monarchical authoritarianism to accelerate the adaptation of the Netherlands to the new conditions of the 19th century. The country prospered until a crisis arose in relations with the southern provinces.
Unrest in the southern provinces.
Protestants controlled the new country although they formed only a quarter of the population. In theory, Catholics had full legal equality; in practice their voice was not heard. Few Catholics held high state or military offices. The king insisted that schools in the South end their traditional teaching of Catholic doctrine, even though everyone there was Catholic. Socially, the French-speaking Walloons strongly resented the king's policy to make Dutch the language of government. There was also growing outrage at the king's insensitivity to social differences. According to Schama, there was growing hostility to the Dutch government whose "initiatives were met at first with curiosity, then with apprehension and finally with fierce and unyielding hostility."
Political liberals in the south had their own grievances, especially regarding the king's authoritarian style; he seemed uncaring about the issue of regionalism, flatly vetoing a proposal for a French-language teacher-training college in francophone Liège. Finally, all factions in the South complained of unfair representation in the national legislature. The south was industrializing faster and was more prosperous than the north, leading to resentment of northern arrogance and political domination.
The outbreak of revolution in France in 1830 was used as a signal for revolt. The demand at first was autonomy for Belgium, as the southern provinces were now called. Eventually, revolutionaries began demanding total independence.
Independence.
The Belgian Revolution broke out in August 1830 when crowds, stirred by a performance of Auber's "La Muette de Portici" at the Brussels opera house of "La Monnaie", spilled out onto the streets singing patriotic songs. Violent street fighting soon broke out, as anarchy reigned in Brussels. The liberal bourgeoisie who had initially been at the forefront of the revolution, were appalled by the violence and willing to accept a compromise with the Dutch.
The revolution broke out for numerous reasons. On a political level, the Belgians felt significantly under-represented in the Netherlands' elected Lower Assembly and disliked the unpopular Dutch prince, the future William II who was the representative of King William I in Brussels. The French-speaking Walloons also felt ostracised in a majority Dutch speaking country. There were also significant religious grievances felt by the majority Catholic Belgians in a nation controlled by the Dutch Protestants.
The king assumed the protest would blow itself out. He waited for a surrender, announcing an amnesty for all revolutionaries, except foreigners and the leaders. When this did not succeed he sent in the army. Dutch forces were able to penetrate the Schaerbeek Gate into Brussels, but the advance was stalled in the Parc de Bruxelles under a hail of sniper fire. Royal troops elsewhere met determined resistance from revolutionaries at makeshift barricades. It is estimated that there were no more than 1,700 revolutionaries (described by the French Ambassador as an "undisciplined rabble") in Brussels at the time, faced with over 6,000 Dutch troops. However, faced with strong opposition, Dutch troops were ordered out of the capital on the night of September 26 after three days of street fighting. There were also battles around the country as revolutionaries clashed with Dutch forces. In Antwerp, eight Dutch warships bombarded the city following its capture by revolutionary forces.
Belgian independence was not allowed by the 1815 Congress of Vienna; nevertheless the revolutionaries were regarded sympathetically by the major powers of Europe, especially the British. In November 1830, the London Conference of 1830 or "Belgian Congress" (comprising delegates from five major powers) ordered an armistice on November 4. The British foreign secretary Lord Palmerston was fearful of Belgium either becoming a republic or being annexed to France, and so invited a monarch from the House of Saxe-Coburg and Gotha in Germany to take the throne. On July 21, 1831, the first "King of the Belgians", Leopold I of Saxe-Coburg was inaugurated. The date of his acceptance of the constitution - 21 July 1831 - is marked a national holiday.
The liberal bourgeoisie who had been thrown off balance by the early stages of the revolution, hastily formed a provisional government under Charles Rogier to negotiate with the Dutch, officially declaring Belgian independence on October 4, 1830. The Belgian National Congress was formed to draw up a constitution. Under the new constitution, Belgium became a sovereign, independent state with a constitutional monarchy. However, the constitution did severely limit voting rights to the French-speaking haute-bourgeoisie and the clergy, in a country where French was not the majority language. The Catholic church was afforded a good deal of freedom from state intervention.
The war with the Netherlands lasted another eight years, but in 1839, the Treaty of London was signed between the two countries. By the treaty of 1839, Luxembourg did not join Belgium, but remained a possession of the Netherlands until different inheritance laws caused it to separate as an independent Grand Duchy. Belgium also lost Eastern Limburg, Zeeuws Vlaanderen and French Flanders and Eupen: four territories which it had claimed on historical grounds. The Netherlands retained the former two while French Flanders, which had been annexed at the time of Louis XIV remained in French possession, and Eupen remained within the German Confederation, although it would pass to Belgium after World War I in reparations.
At the Treaty of London, Britain also made a guarantee of Belgian Neutrality that would be the stated "Casus belli" of Britain's entry into the First World War.
Independence to World War I.
Industrial Revolution.
Most of society was highly traditional, especially in the small villages and rural areas and the quality of education was low. Few people expected that Belgium-seemingly a "sluggish" and "culturally dormant" bastion of traditionalism-would leap to the forefront of the industrial revolution on the Continent. Nevertheless Belgium was the second country, after Britain, in which the industrial revolution took place and it set the pace for all of continental Europe, while leaving the Netherlands behind.
Industrialization took place in Wallonia (French speaking southern Belgium), starting in the middle of the 1820s, and especially after 1830. The availability of cheap coal was a main factor that attracted entrepreneurs. Numerous works comprising coke blast furnaces as well as puddling and rolling mills were built in the coal mining areas around Liège and Charleroi. The leader was a transplanted Englishman John Cockerill. His factories at Seraing integrated all stages of production, from engineering to the supply of raw materials, as early as 1825.
Industry spread through the Sillon industriel ("industrial district"), Haine, Sambre and Meuse valleys. By 1830 when iron became important the Belgium coal industry had long been established, and used steam-engines for pumping. Coal was sold to local mills and railways as well as to France and Prussia.
The textile industry, based on cotton and flax, employed about half of the industrial workforce for much of the industrial period. Ghent was the premier industrial city in Belgium until the 1880s, when the center of growth moved to Liège, with its steel industry.
Wallonia had rich coalfields over much of its area, and the highly folded nature of coal seams meant that it could be found at relatively shallow depths. Deep mines were not required at first so there were a large number of small operations. There was a complex legal system for concessions, often multiple layers had different owners. Entrepreneurs started going deeper and deeper (thanks to the innovation of steam pumping). In 1790, the maximum depth of mines was 220 meters. By 1856, the average depth in the area west of Mons was 361, and in 1866, 437 meters and some pits had reached down 700 and 900 meters; one was 1,065 meters deep, probably the deepest coal mine in Europe at this time. Gas explosions were a serious problem, and Belgium had high fatality rates. By the late 19th century the seams were becoming exhausted and the steel industry was importing some coal from the Ruhr.
Cheap and readily available coal attracted firms producing metals and glass, both of which required considerable amounts of coal, and so regions around coal fields became highly industrialised. The "Sillon industriel" ("Industrial Valley"), and in particular the "Pays Noir" around Charleroi, were the centre of the steel industry until the Second World War.
Railways.
The nation provided an ideal model for showing the value of the railways for speeding the Industrial Revolution. After 1830, the new nation decided to stimulate industry. It funded a simple cross-shaped system that connected the major cities, ports and mining areas, and linked to neighboring countries. Belgium thus became the railway center of the region. The system was very soundly built along British lines, so that profits and wages were low but the infrastructure necessary for rapid industrial growth was put in place. Léopold I went on to build the first railway in continental Europe in 1835, between Brussels and Mechelen. The first trains were drawn by Stephenson engines imported from Great Britain. The development of smaller railways in Belgium, notably the Liège-Jemappes line, was launched by tendering contracts to private companies which "became the model for the extension of small local railways all over the low countries."
By the 1900s, Belgium was a major exporter of trams and other rail components, exporting vast quantities of railway materials. In South America, 3,800 kilometers of track were owned by Belgian firms, with a further 1,500 kilometers in China. One Belgian entrepreneur, Édouard Empain, known as the "Tramway King," built many public transport systems across the world, including the Paris Métro, as well as the tram systems in Cairo, Boulogne and Astrakhan. Empain's firm also built the new Cairo suburb of Heliopolis.
Other important businesses included Cockerill-Sambre (steel), the chemical factories of Ernest Solvay, and the firearms maker Fabrique Nationale de Herstal.
Liberalism and Catholicism.
Politics, says Clark, "was dominated by a struggle between two political groups, known as the Catholics and the Liberals. In general terms, the Catholics represented the relatively religious, conservative and rural elements in the society, while the Liberals represented the more secular, more progressive and more urban middle-class elements." Before the arrival of the socialists in the 1890s, the nation was therefore polarised between the conservative Catholic Party and the secular Liberal Party. The Liberals were anticlerical and wanted to reduce the power of the Church. The conflict came to a head during the "First School War" of 1879-1884 as Liberal attempts to introduce a greater level of secularism in primary education were beaten back by outraged Catholics. The School War ushered in a period of Catholic Party dominance in Belgian politics that lasted (almost unbroken) until 1917.
Religious conflict also extended to university education, where secular universities like the Free University of Brussels competed with Catholic universities like the Catholic University of Leuven.
Linguistic conflict.
The majority of those in the north of the country spoke Dutch and other Low Franconian languages while those in the south spoke Langues d'oïl such as French, Walloon and Picard. French became the official language of government after the separation from the Netherlands in 1830 and Belgian cultural life was especially dominated by the French influence, reinforced by economic domination of the industrial south. Flemish was "reduced to the tongue of a second-class culture." Parts of the Flemish population reacted against this, agitating for the equality of their language with French. This was partly due to a sense of growing Flemish identity, made possible through greater awareness of Flemish culture and history from the 1840s. Flemish victories, like the Battle of the Golden Spurs in 1302 were celebrated and a Flemish cultural movement, led by figures like Hendrik Conscience was born. About the same time a Walloon Movement emerged, led by Jules Destrée (1863-1936) and based on loyalty to the French language. Universal suffrage meant the Francophones were a political minority, so the Walloon Movement concentrated on protecting French where it had a majority, and did not contest the expanded use of Dutch in Flemish areas.
The Flemish goal of linguistic equality (especially in schools and courts) was finally achieved by a series of laws in the 1920s and 1930s. Dutch became the language of government, education, and the courts in the northern provinces of East Flanders and West Flanders, Antwerp, Limburg, and eastern Brabant. French remained the official language in Wallonia; Brussels, which had seen a major language shift to French, became an officially bilingual region. Meanwhile a small separatist Flemish movement had emerged; the Germans had supported it during the war, and in the 1930s it turned fascist. In the Second World War it collaborated with the Nazis.
Foreign relations and military policy.
In the mid-1860s during the "Mexican Adventure", around 1,500 Belgian soldiers joined the "Belgian Expeditionary Corps," better known as the "Belgian Legion" to fight for Emperor Maximilian I, whose wife, Charlotte was the daughter of Leopold I of Belgium.
Belgium was not a belligerent in the Franco-Prussian War 1870–71, but the proximity of the war led to the mobilisation of the army. The 1839 international guarantee of Belgian neutrality was not violated.
After the conflict, there was talk of modernising the military. The system of "Remplacement" (whereby wealthy Belgians conscripted into the military could pay for a "replacement") was abolished and an improved system of conscription implemented. These reforms, led by d'Anethan under pressure from Leopold II, divided Belgian politics. The Catholics united with the Liberals under Frère-Orban to oppose them, and the reforms were finally defeated when d'Anethan's government fell during an unrelated scandal. Eventually, the military was reformed. The 1909 System instituted compulsory military service of eight years' service on active duty and five years in the reserves. This swelled the size of the Belgian army to over 100,000 well-trained men. Construction of a chain of forts along the border was intensified, and let to a series of very modern fortifications, including the so-called "National redoubt" at Antwerp, at Liège and Namur, many of them designed by the great Belgian fortress architect, Henri Alexis Brialmont.
Rise of the Socialist Party and the trade unions.
The economy was stagnant during the long depression of 1873-95, as prices and wages fell and labour unrest grew. The Belgian Workers' Party was founded in 1885 in Brussels. It issued the Charter of Quaregnon in 1894 calling for an end to capitalism and a thorough reorganization of society. Though, the Belgian Workers' Party was not elected to government until the late 20th century, it exerted considerable pressure on the rest of the political process, both through direct participation in politics themselves, but also through general strikes.
During the late 19th century, general strikes became an established aspect of the political process. Between 1892 and 1961, there were 20 major strikes, including 7 general strikes. Many of these had overtly political motives, like the 1893 General Strike that helped achieve universal suffrage.
On several occasions, Belgian general strikes escalated into violence. In 1893, soldiers fired on the striking crowd, killing several. Karl Marx wrote, "There exists but one country in the civilised world where every strike is eagerly and joyously turned into a pretext for the official massacre of the Working Class. That country of single blessedness is Belgium!"
Nevertheless, Belgium created a welfare net particularly early, thanks in part to the trade unions. Sickness compensation was established in 1894, voluntary old-age insurance in 1900 and unemployment insurance in 1907, achieving good coverage nationwide much more quickly than its neighbours.
Voting Rights.
In 1893 the government rejected a proposal for universal male suffrage. Outraged, the Belgian Labour Party called a General Strike; by April 17, there were more than 50,000 strikers. Violent confrontations broke out with the "Garde Civique" (the "Civil Guard" or militia) around the country, as in Mons, where several strikers were killed. Violence escalated. The government soon backed down, and passed male universal suffrage but reduced its impact by creating plural votes based on wealth, education and age. The Catholic conservatives, with 68% of the seats, remained in power, as the Liberals dropped to only 13% of the seats and the Socialists held their share.
As in many countries, women's suffrage was introduced at the end of the First World War; however the last restrictions on women's voting were only lifted in 1948.
Culture.
Artistic and literary culture in Belgium began a revival towards the late 19th century. Particularly, among Walloons with the new French language literary and artistic review "La Jeune Belgique".
A core element of Belgian nationalism was the scientific study of its national history. The movement was led by Godefroid Kurth (1847-1916), a student of the German historian Ranke. Kurth taught modern historical methods to his students at the University of Liège. The most prominent Belgian historian was Henri Pirenne (1862-1935), who was influenced by this method during his period as a student of Kurth.
Architecture and Art Nouveau.
At the end of the 19th century and at the beginning of the 20th century, monumental Historicism and Neoclassicism dominated the urban Belgian landscape, particularly in government buildings, between the 1860s and 1890s. Championed in part by King Leopold II (known as the "Builder King"), the style can be seen in the Palais de Justice (designed by Joseph Poelaert) and the Cinquantenaire, both of which survive in Brussels.
Nevertheless, Brussels became one of the major European cities for the development of the Art Nouveau style in the late 1890s. The architects Victor Horta, Paul Hankar, and Henry van de Velde became particularly famous for their designs, many of which survive today in Brussels. Four buildings designed by Horta are listed by UNESCO World Heritage Sites. Tragically, Horta's largest work, the "Maison du Peuple" was demolished in 1960.
Empire.
Stanard rejects the widely held notion that Belgians were "reluctant imperialists." He argues that "ordinary people came to understand and support the colony. Belgians not only sustained the empire in significant ways, but many became convinced imperialists, evidenced by the widespread, enduring and eagerly embraced propaganda in favor of the Congo."
Congo Free State and Belgian Congo.
At the Berlin Conference of 1884–1885 the Congo was attributed solely to Leopold II of Belgium, who named the territory the Congo Free State, originally intended to be an international Free Trade zone, open all European traders. King Leopold had been the principal shareholder in the Belgian trading company which established trading stations on the lower Congo between 1879 and 1884. Power was finally transferred to Belgium in 1908 under considerable international pressure following numerous reports of misconduct and abuse to native labourers. The Congo territory was acquired formally by Leopold at the Conference of Berlin in 1885. The country, under his personal jurisdiction, was named the Congo Free State. Congolese territory, covering just under 1 million miles squared, more than 80 times the size of Belgium. The first development projects took place during the Free State period, such as a railway that ran from the Léopoldville to the coast which took several years to complete.
The era of the Congo Free State is most infamous for the large number of atrocities committed under it. Since it was, in effect, a business proposition (it was run by a private company, headed by Leopold himself), it aimed to gain as much money as possible from primary exports from the territory. Leopold's personal fortune was greatly increased through the proceeds of Congolese rubber, which had never previously been mass-produced in such surplus quantities, for the growing market for tyres. During the period between 1885 and 1908. As many as eight million Congolese died through of exploitation and disease while the birth rate also dropped. However, these estimates are guesses and no figures are available for the period.
To enforce the rubber quotas, the Force Publique (FP) was created. Whilst the Force Publique was nominally a military force (it would later fight during both First and Second World Wars), during the Congo Free State period its primary duties involved enforcing rubber quotas in rural areas. Imprisonment and summary executions were common. Severing of limbs was sometimes used by the Force Publique as a method of enforcing the quotas.
Following reports from missionaries a moral outrage campaign emerged, particularly in Britain and the United States. The Congo Reform Association, led by Edmund Dene Morel, was particularly important in the campaign, and published numerous best-selling tracts and pamphlets (including "Red Rubber") which were reached a vast public. King Leopold appointed and financed his own commission to put these rumours about the Congo Free State to rest, but in the end his own commission confirmed and investigated the atrocities.
The Belgian parliament long refused to take over the colony as a financial burden. In 1908, the Belgian parliament responded to the international pressure, annexing the Free State, as the campaigners had argued for. After World War II, Belgium was criticized by the United Nations for making no progress on the political front as other contemporary colonial states were doing. Despite propaganda campaigns within Belgium, few Belgians showed much interest in the colony; very few went there, and imperial enthusiasm was never widespread. The government limited the possibility of Congolese settling inside Belgium.
Political rights were not granted to the Africans until 1956 when a the growing middle class (the so-called "Évolué") received the franchise and the economy remained relatively undeveloped despite the mineral wealth of Katanga. For 18 months from January 1, 1959 there was political uncertainty and African national feeling became more apparent with the effect that the Belgian government resolved on independence for the colony in June 1960.
At the Round Table Talks on independence, Belgium requested a process of gradual independence over 4 years, but following a series of riots in 1959, the decision was made to bring forward independence in matter of months. The chaos in which Belgium departed the Congo caused the secession of rich Western-backed province Katanga and the prolonged civil war known as the Congo Crisis.
China 1902-31.
The Belgian Tianjin Concession in China was established in 1902. There was little investment and no settlement. However it led to a contract to supply an electric light and trolley system. In 1906, Tianjin became the first city in China with a modern public transportation system. The supply of electricity and lighting and the trolley business were profitable ventures. All the rolling stock was supplied by Belgian industries and by 1914, the network also reached nearby Austrian, French, Italian, Japanese and Russian concessions.
Ruanda-Urundi 1917-61.
After the defeat of Germany in World War I, Belgium inherited League of Nations mandates over Ruanda-Urundi.
The colony was administered in a similar way as by the former German administrators, continuing policies such as ethnic identity cards. In 1959, moves towards independence could be seen in the territory and agitation by PARMEHUTU a Hutu political party was evident. In 1960, the Rwandan Revolution occurred and Belgium changed the appointments of chiefs and vice-chiefs to promote Hutus into the posts.
Ruanda-Urundi gained independence in 1962 and its two regions, Rwanda and Burundi, separated.
World War One.
When World War I began, Germany invaded neutral Belgium and Luxembourg as part of the Schlieffen Plan, trying to take Paris quickly. It was this action that caused the British to enter the war, as they were still bound by the 1839 agreement to protect Belgium in the event of a war. The Belgians army is remembered for their stubborn resistance during the early days of the war, with the army - around a tenth the size of the Germany Army - holding up the German offensive for nearly a month, giving the French and British forces time to prepare for the Marne counteroffensive later in the year. The German invaders treated any resistance—such as sabotaging rail lines—as illegal and subversive, and shot the offenders and burned buildings in retaliation.
Belgium had a prosperous economy in 1914 but after four years of occupation, it emerged ruined at the end of the war. On the other hand it suffered few deaths in combat. The Germans had "brutally and efficiently stripped the country bare. Machinery, spare parts, whole factories including the roofs, had disappeared eastward. In 1919, 80 percent of its workforce was unemployed."
Military Role.
Belgian soldiers fought delaying actions in 1914 during the initial invasion. They succeeded in throwing the elaborate German invasion plan off schedule and helped sabotage the Schlieffen Plan that Berlin had counted on a for a quick victory over France, At the Battle of Liège, the town's fortifications were able to hold off the invaders for over a week, buying valuable time for the Allies. The German "Race to the Sea" was held off by Belgian forces at the Battle of the Yser. King Albert I stayed in the Yser as commander of the military to lead the army while Broqueville's government withdrew to nearby Le Havre in France.
Belgian units continued to serve on the front until 1918.
Forces from the Belgian Congo also played a major role in the African Campaign and a small unit of Belgian soldiers also served on the Eastern Front.
Occupation 1914-18.
The Germans governed the occupied areas of Belgium through a General Governorate of Belgium, while a small area of the country remained unoccupied by the Germans.
The whole country was ruled under martial law. On the advice of the government, civil servants remained in their posts for the duration of the conflict, carrying out the day-to-day functions of government.
The German army executed between 5,500 and 6,500 French and Belgian civilians between August and November 1914, usually in near-random large-scale shootings of civilians ordered by junior German officers. Individuals suspected of partisan activities were summarily shot. Several important Belgian figures, including politician Adolphe Max and historian Henri Pirenne were deported to Germany.
Flemish feeling of identity and consciousness grew through the events and experiences of war. The German occupying authorities viewed the Flemish as an oppressed people and had had taken several Flemish-friendly measures, known as "Flamenpolitik". This included introducing Dutch as the language of instruction of all state-supported schools in Flanders in 1918. This prompted a renewed Flemish movement in the years following the war. The Flemish "Frontbeweging" ("Soldiers' Movement") was formed from Flemish soldiers in the Belgian army to campaign for greater use of Dutch language in education and government, though not separatist.
The Germans left Belgium stripped and barren. Over a 1.4 million refugees fled to France or to neutral Netherlands. After the systematic atrocities by the German army in the first few weeks of the war, German civil servants took control and were generally correct, albeit strict and severe. There was never a violent resistance movement, but there was a large-scale spontaneous passive resistance of refusal to work for the benefit of German victory. Belgium was heavily industrialized; while farms operated and small shops stayed open most large establishments shut down or drastically reduced their output. The faculty closed the universities; many publishers shut down their newspapers. Most Belgians "turned the four war years into a long and extremely dull vacation," says Kossmann. In 1916 Germany shipped 120,000 men and boys to work in Germany; this set off a storm of protest from neutral countries and they were returned. Germany then stripped the factories of all useful machinery, and used the rest as scrap iron for its steel mills.
International relief.
Belgium faced a food crisis and an international response was organized by the American engineer Herbert Hoover. It was unprecedented in world history. Hoover's Commission for Relief in Belgium (CRB) had the permission of Germany and the Allies. As chairman of the CRB, Hoover worked with the leader of the Belgian "Comité National de Secours et d'Alimentation" (CNSA), Émile Francqui, to feed the entire nation for the duration of the war. The CRB obtained and imported millions of tons of foodstuffs for the CN to distribute, and watched over the CN to make sure the German army didn't appropriate the food. The CRB became a veritable independent republic of relief, with its own flag, navy, factories, mills, and railroads. Private donations and government grants (78%) supplied an $11-million-a-month budget.
At its peak, the American arm, the ARA fed 10.5 million people daily. Great Britain grew reluctant to support the CRB, preferring instead to emphasize Germany's obligation to supply the relief; Winston Churchill led a military faction that considered the Belgian relief effort "a positive military disaster."
Belgium had a prosperous economy in 1914 but after four years of occupation, Belgium emerged ruined at the end of the war—the Germans had "brutally and efficiently stripped the country bare. Machinery, spare parts, whole factories including the roofs, had disappeared eastward. In 1919, 80 percent of its workforce was unemployed."
Interwar Period.
King Albert returned as a war hero, leading the victorious army and acclaimed by the population. In contrast, the government and the exiles came back discreetly. Belgium had been wrecked—not so much by combat as by German seizure of valuable machinery. Only 81 operable locomotives remained, out of the 3,470 available in 1914. 46 of 51 steel mills were damaged, with 26 destroyed totally. More than 100,000 houses had been destroyed, as well as and more than 300,000 acres of farmland.
Waves of popular violence accompanied liberation in November and December 1918 and the government responded through the judiciary punishment of collaboration with the enemy conducted between 1919 and 1921. Shop windows were broken and houses sacked, men were harassed, and women's heads were shaved. Manufacturers who had closed their businesses sought the severe repression of those who had pursued their activities. Journalists who had boycotted and stopped writing called for harsh treatment of the newspapers that submitted to German censorship. Many people stigmatized profiteers and demanded justice. Thus in 1918, Belgium was already confronted with the problems associated with occupation that most European countries only discovered at the end of World War II.
However, despite the status quo, Belgium recovered surprisingly quickly. The first postwar Olympic Games were held in Antwerp in 1920. In 1921, Luxembourg formed a customs union with Belgium.
Reparations.
German reparations to Belgium for damage incurred during the First World War was set at £12.5 billion pounds sterling.
In 1919 under the Treaty of Versailles the area of Eupen-Malmedy, along with Moresnet was transferred to Belgium. "Neutral Moresnet" was transferred to Belgium, as well as the Vennbahn railway. An opportunity was given to the population to "oppose" against the transfer by signing a petition, which gathered few signatures, in large part thanks to intimidation by local authorities, and all regions remain part of Belgium today.
Belgian requests to annex territory considered as historically theirs, from the Dutch, who were perceived as collaborators, was denied.
Between 1923 and 1926, Belgian and French soldiers were sent to the Ruhr in Germany to force the German government to agree to continue reparation payments. The Occupation of the Ruhr led the Dawes Plan which allowed the German government more leniency in paying reparations.
The League of Nations in 1925 made Belgium the trustee for the former German East Africa which bordered the Belgian Congo to the east. It became Rwanda-Urundi (or "Ruanda-Urundi") (modern day Rwanda and Burundi). Although promising the League it would promote education, Belgium left the task to subsidised Catholic missions and unsubsidised Protestant missions. As late as 1962, when independence arrived, fewer than 100 natives had gone beyond secondary school. The policy was one of low-cost paternalism, as explained by Belgium's special representative to the Trusteeship Council: "The real work is to change the African in his essence, to transform his soul, [and] to do that one must love him and enjoy having daily contact with him. He must be cured of his thoughtlessness, he must accustom himself to living in society, he must overcome his inertia."
Art and culture.
The Expressionism painting movement found a distinctive form in Flanders under artists like James Ensor, Constant Permeke and Léon Spilliaert.
Belgian Surrealist art grew during the inter-war period. René Magritte's first surrealist painting, "The Lost Jockey", appeared in 1926. Paul Delvaux was also an extremely influential painter in this genre.
Comic strips became extremely popular in Belgium during the 1930s. One of the most popular comics of the 20th century, Hergé's "The Adventures of Tintin" first appeared in 1929. The growth of comic strips was also accompanied by a popular art movement, exemplified by Edgar P. Jacobs, Jijé, Willy Vandersteen and André Franquin.
Second World War.
Belgium tried to pursue a policy of unaligned neutrality before the war, but on May 10, 1940 the country was invaded by German forces. In the initial attacks, the fortifications which had been constructed to protect the borders like Fort Eben-Emael and the K-W Line were captured or bypassed by German forces. On May 28, after 18 days of fighting, Belgian forces (including the commander in chief, King Leopold III) surrendered. The elected government of Belgium, under Hubert Pierlot, escaped to form a government in exile.
Belgian Army in the United Kingdom.
After the defeat in 1940, significant numbers of Belgian soldiers and civilians managed to escape to Britain to join the Belgian army in Exile.
Belgian soldiers formed the 1st Belgian Infantry Brigade, which also included a battery of soldiers from Luxembourg, more often known as the "Brigade Piron" after its commanding officer, Jean-Baptiste Piron. The Brigade Piron was involved in the Normandy Invasion and the battles in France and the Netherlands until liberation. Belgians also served in British special forces units during the war, forming a troop of No.10 Commando which was heavily involved in the Italian Campaign and Landings on Walcheren. The 5th Special Air Service (SAS) was entirely made up of Belgians.
Two Belgian squadrons, amounting to over 400 pilots, served in the Royal Air Force during the war, both 349 and 350 Squadrons, which claimed over 50 'kills'.
Two Corvettes and a group of Minesweepers were also operated by the Belgians during the Battle of the Atlantic, comprising some 350 men in 1943
A significant contribution was made by the Belgian Congo. Congolese soldiers of the Force Publique were involved in fighting with Italian forces during the East African Campaign. Congolese soldiers also served in the Middle East and Burma. The Congo was also a vitally important economic assett to the allied powers, particularly through its exports of rubber and uranium; in fact the uranium used during the Manhattan Project - including that used for the atomic bombs dropped on Hiroshima and Nagasaki was supplied by the Belgian firm Union Minière du Haut Katanga from Katanga Province in the Belgian Congo.
Occupation 1940-44.
Belgium was run by a Germany military government between its surrender and liberation in September 1944.
The former fort at Breendonk, near Mechelen was requisitioned by the Nazis and used for detainment and interrogation of Jews, political prisoners and captured members of the reistance. Of the 3,500 incarcerated in Breendonk between 1940–44, 1,733 died. About 300 people were killed in the camp itself, with at least 98 of them dying from deprivation or torture.
In 1940, nearly 70,000 Jews were living in Belgium. Of these, 46 percent were deported from the Mechelen transit camp, while a further 5,034 people were deported via the Drancy internment camp (close to Paris). From the summer of 1942 until 1944, twenty-eight transports left Belgium carrying 25,257 Jews and 351 Roma to eastern Europe. Their destination was often Auschwitz Death Camp. Over the course of the war, 25,257 Jews were transported (including 5,093 children) and 352 Roma over the Mechelen-Leuven railway to concentration camps. Only 1,205 returned home alive at the end of the war.
Resistance.
Resistance against the German occupiers of Belgium can be seen at all levels and from all quarters of the political spectrum, but was highly fragmented. The Government in Exile dealt with resistance collectively under the name "Armée Secrète", however this was just a broad name for the many resistance organisations which existed. Some organisations were very left-wing, like the Communist "Front de l'Indépendance", but there was also a far-right resistance movement, the "Légion Belge" which comprised dissident Rexists. However, there were also other groups like "Groupe G" which had no obvious political affiliation.
Resistance to the occupiers chiefly came in the form of helping allied airmen escape, and numerous lines were set up to organise this, for instance the Comet line which evacuated an estimated 14,000 allied airmen to Gibraltar. Sabotage was also used, and "Group G's" activities alone are estimated to have cost the Nazis 20 million man-hours of labor to repair damages done. The resistance were also instrumental in saving Jews and Roma from deportation to death camps, for instance the attack on the "Twentieth convoy" to Auschwitz Death Camp.There was also significant low-level resistance, for instance in June 1941, the City Council of Brussels refused to distribute Stars of David badges. Many Belgians also hid Jews and political dissidents during the occupation, with one estimate putting the number at some 20,000 people.
Collaboration.
During the period of Nazi occupation, some Belgians collaborated with their occupiers. There were pro-Nazi political organizations in both Flemish and Walloon communities before and during the war. The most significant were the Flemish DeVlag and "Vlaamsch Nationaal Verbond" (VNV) as well as the Catholic Walloon "Rexist" movement. These organisations were also fundamental to encouraging Belgians to enlist into the German army. Two divisions of the Waffen SS, the Flemish 27th SS "Langemarck" Division and the Walloon 28th SS "Wallonien" Division. Some organisations, like Verdinaso appealed directly to Flemish separatist ideologies, though they did not become very popular.
After the war, many of those who had collaborated - including many of the guards at Fort Breendonk - were tried, imprisoned or shot.
Allied liberation 1944-45.
Belgium was liberated late in 1944 by Allied forces, including British, Canadian, and American armies, including the Brigade Piron. On 3 September 1944 the Welsh Guards liberated Brussels. The British Second Army seized Antwerp on 4 of September 1944, and the First Canadian Army began conducting combat operations around the port that same month. Antwerp became a highly prized and heavily fought-over objective because its deep-water port was necessary to keep the allied armies supplied. The Battle of the Scheldt in October 1944 was fought primarily on Dutch soil, but with the objective of opening the way for boats to Antwerp. The port city was also the ultimate objective of German armies during the Ardennes Offensive which resulted in heavy fighting on Belgian soil during the winter of 1944-5.
Following liberation, large numbers of Belgians who had remained in the country during the occupation were mobilised into the Belgian army in 57 "Fusilier Battalions". 100,000 Belgians were mobilised for the allies by the end of the war.
Postwar Belgium.
The "Royal Question".
Immediately after the war, Léopold III, who had surrendered himself to the German army in 1940, was released; however, the issue of whether he had betrayed his country by surrendering, while most government ministers had escaped to the United Kingdom, presented an important constitutional dilemma. In particular, the Belgian public was concerned that he might be a collaborator with the Nazis. He had met Hitler in Berchtesgaden on November 19, 1940 and had even remarried (to Lilian Baels) during the war. Many Belgians, especially the Socialists, strongly opposed his return to power. He was kept in exile in Switzerland until 1950, while his brother Prince Charles presided as regent.
A referendum was proposed in 1950 to solve the problem. However, it produced a very close result. In Flanders, the electorate voted 70% in favour ("Yes") of his return but Wallonia voted 58% against. Brussels also returned a 51% "No" vote. Although the referendum narrowly produced a favourable result for Léopold (about 57.68% in the country as a whole), the militant socialist movement in Liège, Hainaut and other urban centres incited major protests and even called a General Strike against his return.
Because of the possibility that the situation might escalate even further, Léopold III abdicated on July 16, 1951, in favour of his 20-year-old son Baudouin.
Occupation of Germany, Korean War and EDC.
After the defeat of Germany in 1945, Belgian soldiers were assigned to occupy a section of West Germany, known as "Belgian Forces in Germany" or FBA-BSD. The last Belgian soldiers left Germany in 2002.
The European Defence Community planned in the early 1950s would have involved Belgian soldiers, as well as soldiers from Germany, France and other Benelux countries. Though the planned EDC was never actually realised, it was still responsible for a major re-organisation of the Belgian army along US Army lines. Belgium was also involved in NATO.
In 1950, a unit of volunteers from the Belgian army was sent to fight for the United Nations in the Korean War against Chinese and North Korean troops. The Belgian United Nations Command (or BUNC) arrived in Korea in early 1951, and fought at several key engagements of the conflict, including at the Battle of the Imjin River, Haktang-ni and Chatkol. BUNC was decorated and received presidential citations from both the United States and Republic of Korea. Over 300 Belgians were killed in action during the conflict. The last Belgian soldiers returned from Korea in 1955.
Benelux and Europe.
On September 5, 1944, the Benelux Customs Union was created. It entered into force in 1948, and ceased to exist on 1 November 1960, when it was replaced by the Benelux Economic Union after a treaty signed in The Hague on February 3, 1958. The Benelux Parliament was created in 1955.
The Treaty of Brussels, signed on 17 March 1948 by Belgium, the Netherlands, Luxembourg, France, and the United Kingdom, is considered the precursor to the NATO agreement, which Belgium became an official member of on April 4, 1949. The headquarters of NATO are located in Brussels, and the headquarters of SHAPE near Mons.
Belgium was also one of the original founding members of the European Coal and Steel Community (ECSC) in July 1952 and of the European Economic Community formed by the Treaty of Rome on March 25, 1957. Belgium has been a member of the Schengen area since 1985.
The Belgian "Economic Miracle".
During the period 1945–1975, Keynesian economic theory guided politicians throughout Western Europe and this was particularly influential in Belgium. After the war, the government cancelled Belgium's debts. It was during this period that the well-known Belgian highways were built. In addition, both the economy the average standard of living rose significantly. As noted by Robert Gildea:
Despite postwar affluence, however, many Belgians continued to live in poverty. An organisation of several poverty action groups, known as the National Action for Security of Subsistence, claimed that more than 900,000 Belgians (about 10% of the population) lived in poverty in 1967, while in the early Seventies, a group of social scientists called the Working Group on Alternative Economics estimated that about 14.5% of the Belgian population lived in poverty.
In the sphere of economics, World War II marks a turning point. Because Flanders had been widely devastated during the war and had been largely agricultural since the Belgian uprising, it benefited most from the Marshall Plan. Its standing as an economically backward agricultural region meant that it obtained support from Belgium's membership of the European Union and its predecessors. At the same time, Wallonia experienced a slow relative decline as the products of its mines and mills came to be less in demand. The economic balance between the two parts of the country has remained less in favour of Wallonia than it was before 1939.
The Second "School War" 1950–59.
After victory in the 1950 elections, a Christian Social Party (PSC-CVP) government came to power in Belgium. The new education minister, Pierre Harmel increased the wages of teachers in private (Catholic) schools and introduced laws linking the subsidies for private schools to the number of pupils. These measures were perceived by the anti-clerical Liberals and Socialists as a "declaration of war".
When the 1954 elections brought to power a coalition of Socialists and Liberals, the new Education Minister, Leo Collard, immediately set out to reverse the measures taken by his predecessor, founding a large number of secular schools and only permitting teachers with a diploma, forcing many priests out of the profession. These measures sparked mass protests from the Catholic bloc. A compromise was eventually found by the next government (a Catholic minority led by Gaston Eyskens), and the "Schools War" was concluded by the November 6, 1958 "School Pact".
Congolese independence and the Congo Crisis.
After riots in the Congo in 1959, the scheduled gradual transition to independence was speeded up dramatically. In June 1960, the Belgian Congo was replaced by the short lived First Republic of Congo, led by the democratically elected and charismatic Congolese statesman Patrice Lumumba, a former political prisoner. Belgian forces withdrew, leaving the military force, the Force Publique, under Congo's control. Order broke down as mutinying soldiers attacked whites who remained in the country. Belgians forces were briefly sent in to evacuate Belgian nationals and army officers.
In July 1960, the southern state of Katanga Province declared its independence, forming the State of Katanga. Katanga's bid for sovereignty was supported by Belgian mining companies and soldiers, who had considerable assets in the area. Later that month, United Nations peacekeepers were deployed to the country. During this period of anarchy, the region of South Kasai also declared independence. Faced with the possibility that the Soviet Union would attempt to use the situation to install a sympathetic regime, western powers including Belgium, supported Joseph Mobutu who installed his own, right-wing regime in the Congo. Lumumba was murdered and civil war ensued. Belgian paratroopers were again deployed to the country, this time to rescue civilian hostages captured in Stanleyville during an operation known as "Dragon Rouge". At the end Mobutu emerged as the ruler of the re-unified country, which he named Zaire.
The General Strike of 1960-61.
In December 1960, Wallonia was gripped by a general strike in response the general decline of Wallonian manufacturing but it succeeded only in Wallonia, in a period of turbulence in the aftermath of the "Second Schools War". The Wallonian workers demanded federalism, in addition to structural reforms. Even though the strike had been intended to be nationwide, Flemish workers appeared reluctant to support it.
The Strike was led by André Renard, the founder of "Renardism" which combined militant socialism with Walloon nationalism. The historian Renée Fox described Wallonia's alienation:
Nationwide the economy was generally healthy with an annual growth rate of 5% in the 1960s. However old inefficient factories were being shut down in textiles and leather goods. Coal miners were angered by the closure of used-up mines. Limburg miners at the Zwartberg mine rioted in 1966 to protest its closure. Two miners were killed by police and ten were injured, while nineteen policemen were hurt. In 1973 a series of worldwide crises adversely affected the Belgian economy.
The "Linguistic Wars".
This Flemish resurgence has been accompanied by a corresponding shift of political power to the Flemish, who constituted the majority of the population of around 60%. An official Dutch translation of the constitution was only accepted in 1967.
The linguistic wars reached a climax in 1968 with the splitting of the Catholic University of Leuven along linguistic lines into the Katholieke Universiteit Leuven and Université Catholique de Louvain. The government of Paul Vanden Boeynants fell over the issue in 1968.
The rise of the federal state.
The successive linguistic disputes have made the successive Belgian governments very unstable. The three major parties (Liberal -right wing-, Catholic -center- and, Socialist -left wing-) all split in two according to their French- or Dutch-speaking electorate. A language border was determined by the first Gilson Act of November 8, 1962. The boundaries of certain provinces, arrondissements and municipalities were modified (among others, Mouscron became a part of Hainaut and Voeren became a part of Limburg) and facilities for linguistic minorities were introduced in 25 municipalities. On August 2, 1963, the second Gilson Act entered into force, fixing the division of Belgium into four language areas: a Dutch, a French and a German language area, with Brussels as a bilingual area.
In 1970, there was a first state reform, which resulted in the establishment of three cultural communities: the Dutch Cultural Community, the French Cultural Community and the German Cultural Community. This reform was a response to the Flemish demand for cultural autonomy. The constitutional revision of 1970 also laid the foundations for the establishment of three Regions, which was a response to the demand of the Walloons and the French-speaking inhabitants of Brussels for economic autonomy. On February 18, 1970, Prime Minister Gaston Eyskens announces the end of "La Belgique de papa".
The second state reform took place in 1980, when the cultural communities became Communities. The Communities assumed the competencies of the cultural communities with regard to cultural matters, and became responsible for the 'matters relating to the person', such as health and youth policy. From then on, these three Communities were known as the Flemish Community, the French Community and the German-speaking Community. Two Regions were established as well in 1980: the Flemish Region and the Walloon Region. However, in Flanders it was decided in 1980 to immediately merge the institutions of the Community and the Region. Although the creation of a Brussels Region was provided for in 1970, the Brussels-Capital Region was not established until the third state reform.
During the third state reform in 1988 and 1989, under Prime Minister Wilfried Martens, the Brussels-Capital Region was established with its own regional institutions, as well as Dutch and French institutions for community matters. The Brussels-Capital Region remained limited to 19 municipalities. Other changes included that the competencies of the Communities and Regions were expanded. One notable responsibility that was transferred to the Communities during the third state reform was education.
The fourth state reform, which took place in 1993 under Prime Minister Jean-Luc Dehaene, consolidated the previous state reforms and turned Belgium into a fully-fledged federal state. The first article of the Belgian Constitution was amended to read as follows, “Belgium is a Federal State which consists of Communities and Regions”. During the fourth state reform, the responsibilities of the Communities and the Regions were expanded again, their resources were increased and they were given more fiscal responsibilities. Other major changes included the direct election of the parliaments of the Communities and the Regions, the splitting up of the Province of Brabant into Flemish Brabant and Walloon Brabant, and the reformation of the Federal Parliament's bicameral system and the relations between the Federal Parliament and the Federal Government. The first direct elections for the parliaments of the Communities and the Regions took place on May 21, 1995.
However, the fourth state reform was not the end of the process of federalization. In 2001, a fifth state reform took place, under Prime Minister Guy Verhofstadt, with the Lambermont and the Lombard Accords. During the fifth state reform, more powers were transferred to the Communities and the Regions, with regard to agriculture, fisheries, foreign trade, development cooperation, auditing of electoral expenses and the supplementary financing of the political parties. The Regions became responsible for twelve regional taxes, and local and provincial government became a matter for the Regions. The first municipal and provincial elections under the supervision of the Regions were the 2006 municipal elections. The functioning of the Brussels institutions was also amended during the fifth state reform, which resulted among other things in a guaranteed representation of the Flemish inhabitants of Brussels in the Parliament of the Brussels-Capital Region.
The fifth state reform is the last state reform to date. However, several Flemish political parties want a sixth state reform following the 2007 federal election, while the vast majority of Walloon politicians oppose this. Major issues that a sixth state reform would have to deal with include, among others, Brussels-Halle-Vilvoorde. After the 2007 elections nine months of extremely troublesome negotiations between Flemish and Walloon parties followed, resulting in the formation of the first Leterme cabinet on March 20, 2008. Decisions on further state reforms were delayed and remained a matter of considerable debate.
Belgium was one of the founders of the European Union. Between 1999 and 2002, the Euro gradually replaced the Belgian franc (the currency of Belgium since 1830) at the rate of 1 EUR=40.3399 BEF Belgian Euro coins usually depict King Albert II on the reverse.
Political parties.
From the 1960s, most political parties, which had previously stood in elections in both Flemish and Walloon areas, split down linguistic divides. The Catholic party split in 1968 while the Belgian Socialist Party split in 1978 into the French-speaking Parti Socialiste and Flemish Socialistische Partij. The Liberals also split on regional lines in 1992.
"Green" politics in Belgium became quite successful in the aftermath of the Marc Dutroux Scandal and the "Dioxin Affair" which led to disillusionment with the preexisting parties and the decline of the Catholic vote.
1990 to present.
The Marc Dutroux Scandal.
In 1996, confidence in the political and criminal justice systems was shaken by the news that one Marc Dutroux and his accomplices had kidnapped, tortured, and murdered young girls. Parliamentary inquiries found the police forces were incompetent and bureaucratic, and the judicial system suffered from bureaucracy, very poor communication with, and support for, the victims, slow procedures and many loopholes for criminals. On October 26, 1996, about 300,000 Belgians joined the "White March" in Brussels in protest.
Belgian military intervention since 1990.
The United Nations mission in Rwanda during the Rwandan Civil War, known as UNAMIR, involved a significant Belgian contingent under the command of Roméo Dallaire. Belgium, as the former colonial power in the country, sent the largest force of around 400 soldiers from the 2nd Commando Battalion.
After the downing of the Rwandan and Burundian presidential plane 10 Belgian peacekeepers were kidnapped, mutilated and murdered by the Hutu-dominated government army. In response, Belgium withdrew all of its peacekeepers, blaming UNAMIR for failing to rescue their men. The Belgians had represented the largest and most capable element in the UNAMIR mission, leaving it incapacitated and unable to cope with the events of the Rwandan Genocide.
Belgian paratroopers were deployed to Somalia during Operation Restore Hope as part of UNOSOM tasked with securing aid deliveries and peacekeeping. Several Belgian soldiers were killed during the deployment.
During the Kosovo crisis of 1999, 600 Belgian paratroopers participated in Operation Allied Harbour, a NATO operation to protect and provide assistance to the huge number of ethnic Albanian refugees in Albania and Macedonia. That same year, 1,100 Belgian soldiers left for Kosovo to participate in the Kosovo Force (KFOR), a NATO-led peacekeeping force.
Belgian soldiers have served in Lebanon, under the United Nations Interim Force in Lebanon (UNIFIL). Approximately 394 Belgians have served in Lebanon, in demining and medical operations, and a frigate is also present.
In the 2011, the Belgian Air Force deployed six F-16 fighter jets in support of the NATO intervention in the Libyan Civil War in accordance with United Nations Security Council Resolution 1973. Belgian aircraft were involved in airstrikes on pro-Ghadaffi forces.
Belgium is part of the ISAF mission in Afghanistan, joint with soldiers from Luxembourg. Its continent is named "BELU ISAF 21," with the main objective of providing security at Kabul International Airport, while detachments ("KUNDUZ 16") assist in the northern PRTs of Kunduz and Mazar-i-Sharif. In September 2008, four F‑16 jets with about 140 support personnel were deployed. They operate from Kandahar Airport. The Belgian Air Force operated close together with the Dutch F-16 fighter jets already deployed there.
Debt and economic slowdown.
Belgium created huge debts during times when rates were low and generated new debts to service the initial debt. Its debts amounted to about 130% of the GDP in 1992 and were reduced to about 99% in 2001 when Belgium entered the Eurozone. This drastic economic policy resulted in deep budget spending cuts, such as significant cuts to scientific research.
Internal politics.
In the 1999 Belgian federal election, the traditional government parties were suffered a significant defeat due to the so-called "Dioxin Affair", leading to the fall of Jean-Luc Dehaene's government after eight years in office. Guy Verhofstadt formed a government of Liberals, Socialists and Greens, forming a government without the Catholic Christian People's Party for the first time since 1958.
In July 1999, a government of Greens and Flemish Liberals and Democrats announced a gradual phase-out of Belgium's seven nuclear reactors after 40 years of operation. Though it was speculated that the next government without Greens would immediately revoke this legislation. after the 2003 elections there was still no sign of a policy reversal, particularly in the aftermath of the incident at Tihange reactor in 2002. In 2006, the Christian-Democratic and Flemish proposed a reconsideration of the phase out.
The Belgian government was strongly opposed to the Iraq War during the Iraq crisis of 2003. The Verhofstadt government proposed a diplomatic solution to the WMD and that military action could only be taken with UN approval.
On January 30, 2003, Belgium became the second country in the world to legally recognize same-sex marriage. However, this law did not permit adoption by same-sex partners. In December 2005, a controversial proposal by the Socialistische Partij Anders to permit adoption was approved by the Belgian Chamber of Representatives.
Political Crisis 2010–11.
The 2010 Belgian federal election produced a highly fragmented political landscape, with 11 parties elected to the Chamber of Representatives, none of which had more than 20% of the seats. The separatist New Flemish Alliance (N-VA), the largest party in Flanders and the country as a whole, controlled 27 of 150 seats in the lower chamber. The Francophone Socialist Party (PS), the largest party in Wallonia, controlled 26 seats. Belgium beat the world record for time taken to form a new democratic government after an election, at 353 days. Finally a government coalition was sworn in on 6 December 2011, with Socialist Elio Di Rupo becoming Prime Minister of the Di Rupo Government.
Historiography.
Modern historiography of Belgium began to appear in the later 18th century, as scholars moved beyond the chronicles particular provinces, cities or leaders and relied on rapidly accumulating data. The wrote dissertations using critical approach to particular historical problems. This development was sponsored by the The Royal Academies for Science and the Arts of Belgium and reflected Enlightenment influences—such as that of Voltaire—in exploring the history of the people. They pondered questions of causality. Their goal was building the blocks for a general history of the Austrian Netherlands, thus marking an important step toward the creation of a Belgian national history.
Since Belgium became an independent nation only in 1830, defining nationhood was a special issue for the historians of the late 19th century. The usual European solutions which defined nationhood in terms of language would not work. The Romantic Joseph-Jean de Smet portrayed his country as a "phoenix" (a reference to the great bird that rose from the dead.) The challenge of defining the nation's past and present in the face of Dutch, Spanish, Austrian, French, and German influences posed a central problem. Defending the boundaries of Belgium (especially why Flanders should not be in the Netherlands) was another issue that preoccupied historical writers such as Pirenne.
The medievalist Godefroid Kurth (1847-1916) was a student of Germany's famous professor Leopold von Ranke. Kurth introduced Ranke's advanced scholarly methods in his seminar at the Universite de Liège. Belgian historiography achieved international stature in the early 20th century with the work of medievalist Henri Pirenne (1862-1935).
Historiography at Ghent University was pioneered by medievalists, especially Hubert Van Houtte. After 1945 Charles Verlinden introduced the methods of the French Annales School of social history. Research topics at Ghent included colonial and maritime history, the history of prices and wages, agrarian history, business history, and the textile industry. In the 1970 and 1980s came a broadening to such topics as historical demography; living standards and lifestyles; beggary and crime; and the history of culture and mind-sets.

</doc>
<doc id="42373" url="http://en.wikipedia.org/wiki?curid=42373" title="Logarithmic spiral">
Logarithmic spiral

A logarithmic spiral, equiangular spiral or growth spiral is a self-similar spiral curve which often appears in nature. The logarithmic spiral was first described by Descartes and later extensively investigated by Jacob Bernoulli, who called it "Spira mirabilis", "the marvelous spiral".
Definition.
In polar coordinates formula_1 the logarithmic curve can be written as
or
with formula_4 being the base of natural logarithms, and formula_5 and formula_6 being arbitrary positive real constants.
In parametric form, the curve is
with real numbers formula_5 and formula_6.
The spiral has the property that the angle "φ" between the tangent and radial line at the point formula_1 is constant. This property can be expressed in differential geometric terms as
The derivative of formula_13 is proportional to the parameter formula_6. In other words, it controls how "tightly" and in which direction the spiral spirals. In the extreme case that formula_15 (formula_16) the spiral becomes a circle of radius formula_5. Conversely, in the limit that formula_6 approaches infinity ("φ" → 0) the spiral tends toward a straight half-line. The complement of "φ" is called the "pitch".
"Spira mirabilis" and Jacob Bernoulli.
Spira mirabilis, Latin for "miraculous spiral", is another name for the logarithmic spiral. Although this curve had already been named by other mathematicians, the specific name ("miraculous" or "marvelous" spiral) was given to this curve by Jacob Bernoulli, because he was fascinated by one of its unique mathematical properties: the size of the spiral increases but its shape is unaltered with each successive curve, a property known as self-similarity. Possibly as a result of this unique property, the spira mirabilis has evolved in nature, appearing in certain growing forms such as nautilus shells and sunflower heads. Jacob Bernoulli wanted such a spiral engraved on his headstone along with the phrase "Eadem mutata resurgo" ("Although changed, I shall arise the same."), but, by error, an Archimedean spiral was placed there instead.
Properties.
The logarithmic spiral can be distinguished from the Archimedean spiral by the fact that the distances between the turnings of a logarithmic spiral increase in geometric progression, while in an Archimedean spiral these distances are constant.
Logarithmic spirals are self-similar in that the result of applying any similarity transformation to the spiral is congruent to the original untransformed spiral. Scaling by a factor formula_19, where "b" is the parameter from the definition of the spiral, with the center of scaling at the origin, gives the same curve as the original; other scale factors give a curve that is rotated from the original position of the spiral. Logarithmic spirals are also congruent to their own involutes, evolutes, and the pedal curves based on their centers.
Starting at a point formula_20 and moving inward along the spiral, one can circle the origin an unbounded number of times without reaching it; yet, the total distance covered on this path is finite; that is, the limit as formula_21 goes toward formula_22 is finite. This property was first realized by Evangelista Torricelli even before calculus had been invented.
The total distance covered is formula_23, where formula_24 is the straight-line distance from formula_20 to the origin.
The exponential function exactly maps all lines not parallel with the real or imaginary axis in the complex plane, to all logarithmic spirals in the complex plane with centre at 0. (Up to adding integer multiples of formula_26 to the lines, the mapping of all lines to all logarithmic spirals is onto.) The pitch angle of the logarithmic spiral is the angle between the line and the imaginary axis.
The function formula_27, where the constant formula_28 is a complex number with non-zero imaginary part, maps the real line to a logarithmic spiral in the complex plane.
The golden spiral is a logarithmic spiral that grows outward by a factor of the golden ratio for every 90 degrees of rotation (pitch about 17.03239 degrees). It can be approximated by a "Fibonacci spiral", made of a sequence of quarter circles with radii proportional to Fibonacci numbers.
Logarithmic spirals in nature.
In several natural phenomena one may find curves that are close to being logarithmic spirals. Here follows some examples and reasons:

</doc>
<doc id="42374" url="http://en.wikipedia.org/wiki?curid=42374" title="Ljubljana">
Ljubljana

Ljubljana (]; locally also [luˈblàːna], German: "Laibach", Italian: "Lubiana", Latin: "Labacum" or "Aemona") is the capital and largest city of Slovenia.
Located at the middle of a trade route between the northern Adriatic Sea and the Danube region, it was the historical capital of Carniola, a Slovene-inhabited part of Austria-Hungary, and it has been the cultural, educational, economic, political, and administrative center of independent Slovenia since 1991. Its central geographic location within Slovenia, transport connections, concentration of industry, scientific and research institutions and cultural tradition are contributing factors to its leading position.
Name and symbol.
The origin of the city's name is unclear. In the Middle Ages, both the river and the town were also known by the German name "Laibach", which was in official use until 1918. For most scholars, the problem has been in how to connect the Slovene and the German names. The origin from the Slavic "ljub"- "to love, like" was in 2007 supported as the most probable by the linguist Tijmen Pronk, a specialist in comparative Indo-European linguistics and Slovene dialectology from the University of Leiden. He supported the thesis that the name of the river derived from the name of the settlement. The linguist Silvo Torkar, who specializes in Slovene personal and place names, argued at the same place for the thesis that the name "Ljubljana" derives from "Ljubija", the original name of the Ljubljanica River flowing through it, itself derived from the Old Slavic male name "Ljubovid", "the one of a kind appearance". The name "Laibach", he claimed, was actually a hybrid of German and Slovene and derived from the same personal name.
The symbol of the city is the Ljubljana Dragon. It is depicted on the top of the tower of the Ljubljana Castle in the Ljubljana coat-of-arms and on the Ljubljanica-crossing Dragon Bridge (Ljubljana) ("Zmajski most"). It symbolizes power, courage, and greatness.
There are several explanations on the origin of the Ljubljana Dragon. According to the Slavic myth the slaying of dragon releases the waters and ensures the fertility of the earth, and it is thought the myth in this area is tied to the Ljubljana Marshes, the expansive area that has been threatening because of frequent flooding that reached Ljubljana. According to the celebrated Greek legend, the Argonauts on their return home after having taken the Golden Fleece found a large lake surrounded by a marsh between the present-day towns of Vrhnika and Ljubljana. It is there that Jason struck down a monster. This monster has become the dragon that today is present on the city coat of arms and flag. It is historically more believable that the dragon was adopted from Saint George, the patron of the Ljubljana Castle chapel built in the 15th century. In the legend of Saint George, the dragon represents the old ancestral paganism overcome by Christianity. According to another explanation, related to the second, the dragon was at first only a decoration above the city coat of arms. In Baroque, it became part of the coat of arms and in the 19th and especially the 20th century, it outstripped the tower and other elements.
History.
Prehistory.
Around 2000 BC, the Ljubljana Marshes in the immediate vicinity of Ljubljana were settled by people living in pile dwellings. These lake-dwelling people lived through hunting, fishing and primitive agriculture. To get around the marshes, they used dugout canoes made by cutting out the inside of tree trunks. Their archeological remains, nowadays in the Municipality of Ig, have been designated a UNESCO World Heritage Site since June 2011, in the common nomination of six Alpine states.
Later, the area remained a transit point for numerous tribes and peoples, among them Illyrians, followed by a mixed nation of Celts and Illyrians called the Iapydes, and then in the 3rd century BC a Celtic tribe, the Taurisci.
Antiquity.
Around 50 BC, the Romans built a military encampment that later became a permanent settlement called Iulia Aemona. This entrenched fort was occupied by the "Legio XV Apollinaris". In 452, it was destroyed by the Huns under Attila's orders, and later by the Ostrogoths and the Lombards. Emona housed 5,000–6,000 inhabitants and played an important role during numerous battles. Its plastered brick houses, painted in different colors, were already connected to a drainage system. In the 6th century, the ancestors of the Slovenes moved in. In the 9th century, the Slovenes fell under Frankish domination, while experiencing frequent Magyar raids. Not much is known about the area during the settlement of Slavs in the period between the downfall of Emona and the Early Middle Ages.
Middle Ages.
The parchment sheet "Nomina defunctorum" ("Names of the Dead"), most probably written in the second half of 1161, mentions the nobleman Rudolf of Tarcento, a lawyer of the Patriarchate of Aquileia, who had bestowed a canon with 20 farmsteads beside the castle of Ljubljana ("castrum Leibach") to the Patriarchate. According to the historian Peter Štih's deduction, this happened between 1112 and 1125, thus representing the earliest mention of Ljubljana.
Originally owned by a number of possessors, until the first half of the 12th century the territory south of the Sava where the town of Ljubljana developed gradually became property of the Carinthian family of the Dukes of Sponheim. Urban settlement in Ljubljana started in the second half of the 12th century. At around 1200, the market rights were granted to the Old Square ("Stari trg"), which was at the time one of the three districts Ljubljana originated from, that additionally included area called "Town" ("Mesto") built around the predecessor of the present-day Ljubljana Cathedral at one side of the Ljubljanica river, and New Square ("Novi trg") at the other side. The Franciscan Bridge, a predecessor of the present-day Triple Bridge, and the Butchers' Bridge connected the walled areas with wood-made buildings. Ljubljana acquired the town privileges at some time between 1220 and 1243. Seven fires erupted in the town during the Middle Ages. Artisans organized themselves into guilds. The Teutonic Knights, the Conventual Franciscans, and the Franciscans settled in the town.
In the late 1270, Ljubljana was conquered by King Ottokar II of Bohemia. In 1278, after the defeat of Ottokar, it became—together with the rest of Carniola—property of Rudolph of Habsburg and administered by the Counts of Gorizia from 1279 until 1335, when it became the capital town of Carniola. Renamed "Laibach", it would be owned by the House of Habsburg until 1797. In 1327, the Ljubljana's "Jewish Quarter"—now only the name of Ljubljana "Jewish Street" ("Židovska ulica") is a remainder of it—with a synagogue was established, until Emperor Maximilian I in 1515 succumbed to medieval antisemitism and expelled Jews from Ljubljana, for which he demanded a certain payment from the town. In 1382, in front of St. Bartholomew's church in Šiška, at the time a nearby village, now part of Ljubljana, a peace treaty between the Republic of Venice and Leopold III of Habsburg was signed.
Early modern.
In the 15th century, Ljubljana became recognized for its art, particularly painting and sculpture. The Roman Rite Catholic Diocese of Ljubljana was established in 1461 and the Church of St. Nicholas became the diocesan cathedral. After an earthquake in 1511, the city was rebuilt in Renaissance style and a new wall was built around it. Wooden buildings were forbidden after a large fire at New Square in 1524.
In the 16th century, the population of Ljubljana numbered 5,000, 70% of whom spoke Slovene as their first language, with most of the rest using German. The first secondary school, public library and printing house opened in Ljubljana. Ljubljana became an important educational center.
From 1529 to 1599, Ljubljana had an active Slovene Protestant community until their expulsion after which Catholic Bishop Tomaž Hren ordered the burning of eight cartloads of Protestant books in public marking the beginning of the Counter-Reformation.
In 1597, Jesuits arrived in the city, followed in 1606 by Capuchins, to eradicate Protestantism. Only 5% of all the residents of Ljubljana at the time were of Catholic confession, so it took quite a while to make it again Catholic. Jesuits organized the first theatrical productions in the town, fostered the development of Baroque music and established Catholic schools. In the middle and the second half of the 17th century, foreign architects built and renovated numerous monasteries, churches, and palaces in Ljubljana and introduced the Baroque architecture. In 1702, the Ursulines settled in the town, where, the following year, they opened the first public school for girls in the Slovene Lands. Some years later, the construction of the Ursuline Church of the Holy Trinity started. In 1779, St. Christopher's Cemetery replaced the cemetery at St. Peter's Church as the main Ljubljana cemetery.
Late modern.
During the Napoleonic interlude, Ljubljana (under the name "Laybach") was the capital of the Illyrian Provinces from 1809 to 1813. In 1815, the city became Austrian again and from 1816 to 1849 was the administrative center of the Kingdom of Illyria in the Austrian Empire. In 1821 it hosted the Congress of Laibach, which fixed European political borders for years to come. The first train arrived in 1849 from Vienna and in 1857 the line was extended to Trieste.
In 1895, Ljubljana, then a city of 31,000, suffered a serious earthquake measuring 6.1 degrees Richter and 8–9 degrees MCS. Some 10% of its 1,400 buildings were destroyed, although casualties were light. During the reconstruction that followed, a number of districts were rebuilt in the Vienna Secession style. Public electric lighting appeared in the city in 1898. The rebuilding period between 1896 and 1910 is referred to as the "revival of Ljubljana" because of architectural changes from which a great deal of the city dates back to today and for reform of urban administration, health, education and tourism that followed. The rebuilding and quick modernization of the city were led by the mayor Ivan Hribar.
In 1918, following the end of World War I and the dissolution of Austria-Hungary, the region joined the Kingdom of Serbs, Croats and Slovenes. In 1929, Ljubljana became the capital of the Drava Banovina, a Yugoslav province.
In 1941, during World War II, Fascist Italy occupied the city, and on 3 May 1941 made "Lubiana" the capital of an Italian "Provincia di Lubiana" with the former Yugoslav general Leon Rupnik as mayor. After the Italian capitulation, Nazi Germany with SS-general Erwin Rösener and Friedrich Rainer took control in 1943 but formally the city remained the capital of an Italian province until 9 May 1945. In Ljubljana, the occupying forces established strongholds and command centers of Quisling organisations, the Anti-Communist Volunteer Militia under Italy and the Home Guard under German occupation. The city was surrounded by over 30 km of barbed wire to prevent co-operation between the resistance movement that operated within and outside the fence. Since 1985, a commemorative path has ringed the city where this iron fence once stood. Postwar reprisals resulted in a number of mass graves in Ljubljana.
After World War II, Ljubljana became the capital of the Socialist Republic of Slovenia, part of Communist Yugoslavia, a status it retained until Slovenia became independent in 1991.
Contemporary.
Ljubljana remains the capital of independent Slovenia, which entered the European Union in 2004.
Geography.
The city, with an area of 163.8 km2, is situated in Central Slovenia in the Ljubljana Basin between the Alps and the Karst. Ljubljana is located some 320 km south of München, 477 km east of Zürich, 250 km east of Venice, 350 km southwest of Vienna, 224 km south of Salzburg and 400 km southwest of Budapest. The extent of Ljubljana has changed considerably in the past 30 years, mainly because some of the nearby settlements have merged with Ljubljana.
Geology.
The city stretches out on an alluvial plain dating to the Quaternary era. The nearby, older mountainous regions date back to the Mesozoic (Triassic) or Paleozoic. A number of earthquakes have devastated Ljubljana, including in 1511 and 1895.
Topography.
Ljubljana has an altitude of 295 m The city center, located along the Ljubljanica River, has an altitude of 298 m. The Ljubljana Castle, which sits atop the Castle Hill ("Grajski grič") south of the city center, has an altitude of 366 m. The highest point of the city, called Grmada, reaches 676 m, seven meters more than the nearby Šmarna Gora peak, a popular hiking destination. These are located in the northern part of the city.
View to the north from Ljubljana Castle with the Alps in the background.
View to the south from Ljubljana Castle with Ljubljana Marshes in the back. Note substantial lower building density due to unsuitable ground for construction.
Waters.
The main watercourses in Ljubljana are the Ljubljanica, the Sava, the Gradaščica, the Mali Graben, the Iška and the Iščica rivers. From the Trnovo District to the Moste District, around the Castle Hill, the Ljubljanica partly flows through the Gruber Canal, built upon the plans by Gabriel Gruber in 1772–1782. Next to the eastern border of the city, the Ljubljanica, the Sava, and the Kamnik Bistrica Rivers flow together. The lowest point of Ljubljana, with an altitude of 261 m, is located at the confluence.
Ljubljana has been struck through its history also by floods. The latest took place in 2010. Southern and western parts of the city are more flood-endangered than northern parts. The Gruber Canal has partly diminished the danger of floods at Ljubljana Marshes, the largest marshes in Slovenia, to the south of Ljubljana.
There are two major ponds in the park. The Koseze Pond is located in the District of Šiška and the Tivoli Pond is located in the southern part of the Tivoli Park. The Koseze Pond is home to a number of rare plant and animal species and is a popular place of meeting and recreation. The Tivoli Pond is a shallow pond with a small volume that was originally used for boating and ice skating, but has been abandoned over the years and is now used only for fishing.
Climate.
Ljubljana's climate is Oceanic (Köppen climate classification "Cfb"), bordering on a Humid subtropical climate zone (Köppen climate classification "Cfa"), with continental characteristics such as warm summers and moderately cold winters. July and August are the warmest months with daily highs generally between 25 and, and January is the coldest month with the temperatures mostly oscillating around 0 °C. The city experiences 90 days of frost per year, and 11 days with temperatures above 30 °C. The precipitation is relatively evenly distributed throughout the seasons, although winter and spring tend to be somewhat drier than summer and autumn. Yearly precipitation is about 1400 mm, making Ljubljana one of the wettest European capitals. Thunderstorms are very common from May to September and can occasionally be quite heavy. Snow is common from December to February; on average, there are 48 days with snow cover recorded each winter season. The city is known for its fog, which is recorded on average on 64 days per year, mostly in autumn and winter, and can be particularly persistent in conditions of temperature inversion. In summer, the weather in the city is under the influence of Mediterranean air currents, so the summers are sunny and warm.
Cityscape.
The city architecture is a mix of styles. Despite the appearance of large buildings, especially at the city's edge, Ljubljana's historic center remains intact. Although the oldest architecture has been preserved from the Roman period, Ljubljana's downtown got its outline in the Middle Ages. After the 1511 earthquake, it was rebuilt in the Baroque style following Italian, particularly Venetian, models. After the quake in 1895, it was once again rebuilt, this time in the Vienna Secession style, which today is juxtaposed against the earlier Baroque style buildings that remain. The large sectors built in the inter-war period often include a personal touch by the architects Jože Plečnik and Ivan Vurnik. In the second half of the 20th century, parts of Ljubljana were redesigned by Edvard Ravnikar.
Prominent buildings.
The central square in Ljubljana is Prešeren Square ("Prešernov trg") where the Franciscan Church of the Annunciation ("Frančiškanska cerkev") is located. It is the parish church of Ljubljana - Annunciation Parish. Built between 1646 and 1660 (the belltowers following later), it replaced an older Gothic church on the same site. The layout takes the form of an early-Baroque basilica with one nave and two rows of lateral chapels. The Baroque main altar was executed by the sculptor Francesco Robba. Much of the original frescos were ruined by the cracks in the ceiling caused by the Ljubljana earthquake in 1895. The new frescos were painted by the Slovene impressionist painter Matej Sternen.
Ljubljana Castle ("Ljubljanski grad") is a medieval castle with Romanesque, Gothic, and Renaissance architectural elements, located at the summit of the Castle Hill that dominates the city center. The area surrounding today's castle has been continuously inhabited since 1200 BC. The castle was built in the 12th century and was a residence of the Margraves, later the Dukes of Carniola. The castle's Outlook Tower dates to 1848; this was inhabited by a guard whose duty it was to fire cannons warning the city in case of fire or announcing important visitors or events, a function the castle still holds today. Cultural events and weddings also take place there. Since 2006, a funicular has linked the city center to the castle atop the hill.
The Town Hall ("Mestna hiša", "Magistrat"), located on the Town Square, is the seat of the City Municipality of Ljubljana. The original building was built in a Gothic style in 1484. Between 1717 and 1719, the building underwent a Baroque renovation with a Venetian inspiration by the architect Gregor Maček. Near the Town Hall, on Town Square, is a replica of the Robba fountain, in the Baroque style. The original has been moved into the National Gallery in 2006. Robba's fountain is decorated with an obelisk at the foot of which are three figures in white marble symbolising the three chief rivers of Carniola. It is the work of Francesco Robba, who designed numerous other Baroque statues in the city.
Ljubljana Cathedral ("Ljubljanska stolnica"), or Saint Nicholas's Cathedral ("Stolnica svetega Nikolaja"), serves the Archdiocese of Ljubljana. Easily identifiable due to its green dome and twin towers, it is located on Cyril and Methodius Square ("Ciril-Metodov trg") by the nearby Ljubljana Central Market and the Town Hall. The Diocese of Ljubljana was set up in 1461. Between 1701 and 1706, the Jesuit architect Andrea Pozzo designed the Baroque church with two side chapels shaped in the form of a Latin cross. The dome was built in the center in 1841. The interior is decorated with Baroque frescos painted by Giulio Quaglio between 1703–1706 and 1721–1723.
Nebotičnik (pronounced ], "Skyscraper") is a thirteen-story building that rises to a height of 70.35 m. It combines elements of the Neoclassical and the Art-Deco architecture. Predominantly a place of business, Nebotičnik is home to a variety of shops on the ground floor and first story, and various offices are located on floors two to five. The sixth to ninth floors are private residences. Located on the top three floors are a café, bar and observation deck. It was designed by the Slovenian architect Vladimir Šubic. Construction began in July 1930 and the building opened on 21 February 1933. It was for some time the tallest residential building in Europe.
Parks and other green spaces.
Tivoli Park ("Park Tivoli") is the largest park in Ljubljana. It was designed in 1813 by the French engineer Jean Blanchard and now covers approximately 5 km2. The park was laid out during the French imperial administration of Ljubljana in 1813 and named after the Parisian Jardins de Tivoli. Between 1921 and 1939, it was renovated by the Slovene architect Jože Plečnik, who designed a broad central promenade, called the Jakopič Promenade ("Jakopičevo sprehajališče") after the leading Slovene impressionist painter Rihard Jakopič. Within the park, there are different types of trees, flower gardens, several statues, and fountains. Several notable buildings stand in the Park, among them the Tivoli Castle, the National Museum of Contemporary History and the Tivoli Sports Hall.
The Tivoli–Rožnik Hill–Šiška Hill Landscape Park is located in the western part of the city.
The University Botanic Gardens (Slovene: "Univerzitetni botanični vrt Univerze v Ljubljani") stretch on 2.40 ha next to the junction of the Gruber Canal and the Ljubljanica, to the south of the Old Town. These are the central Slovenian botanical garden and the oldest cultural, scientific, and educational organisation in the country. It started operating under the leadership of Franc Hladnik in 1810. Of over 4,500 plant species and subspecies, roughly a third is endemic to Slovenia, whereas the rest originate from other European places and other continents. The institution is a member of the international network Botanic Gardens Conservation International and cooperates with more than 270 botanical gardens all across the world.
In 2014, Ljubljana won the European Green Capital Award for 2016 for its environmental achievements.
Streets and squares.
Existing already in the 18th century, the Ljubljana central square, the Prešeren Square's modern appearance has developed since the end of the 19th century. After the 1895 Ljubljana earthquake, Max Fabiani designed the square as the hub of four streets and four banks, and in the 1980s, Edvard Ravnikar proposed the circular design and the granite block pavement. A statue of the Slovene national poet France Prešeren with a muse stands in the middle of the square. The Prešeren Statue was created by Ivan Zajec in 1905, whereas the pedestal was designed by Max Fabiani. The square and surroundings have been closed to traffic since 1 September 2007. Only a tourist train leaves Prešeren Square every day, transporting tourists to the Ljubljana Castle.
Republic Square, at first named Revolution Square, is the largest square in Ljubljana. It was designed in the second half of the 20th century by Edvard Ravnikar. Independence of Slovenia was declared here on 26 June 1991. The National Assembly Building stands at its northern side, and Cankar Hall, the largest Slovenian cultural and congress center, at the southern side. At its eastern side stands the two-storey building of Maximarket, also work of Ravnikar. It houses one of the oldest department stores in Ljubljana and a cafe, which is a popular meeting place and a place of political talks and negotiations.
Congress Square ("Kongresni trg") is one of the most important centers of the city. It was built in 1821 for ceremonial purposes such as Congress of Ljubljana after which it was named. Since then it became an important center for political ceremonies, demonstrations and protests, such as the ceremony at creation of Kingdom of Yugoslavia, ceremony of liberation of Belgrade, protests against Yugoslav authority in 1988 etc. The square also houses several important buildings, such as University of Ljubljana, Slovenian Philharmonic, Ursuline Church of the Holy Trinity, and Slovenska matica. Star Park ("Park Zvezda") is located in the center of the square. In 2010 and 2011, the square was heavily renovated and is now mostly closed to road traffic on ground area, however there are five floors for commercial purposes and a parking lot located underground.
Čop Street ("Čopova ulica") is a major thoroughfare in the center of Ljubljana. The street is named after Matija Čop, an early 19th-century literary figure and close friend of the Slovene Romantic poet France Prešeren. It leads from the Main Post Office ("Glavna pošta") on Slovenian Street ("Slovenska cesta") downward to Prešeren Square and is lined with bars and stores, including the oldest McDonald's restaurant in Slovenia. It is a pedestrian zone and regarded as the capital's central promenade.
Bridges.
The most notable Ljubljana bridges are the Triple Bridge ("Tromostovje"), the Trnovo Bridge ("Trnovski most"), the Dragon Bridge ("Zmajski most"), the Hradecky Bridge (Slovene: "Hradeckega most"), and the Butchers' Bridge ("Mesarski most"). The Trnovo Bridge crosses the Gradaščica, whereas the others cross the Ljubljanica.
The Triple Bridge is a group of three bridges, connecting two parts of Ljubljana's downtown, located on both banks of Ljubljanica. There was originally only one bridge, which linked Central Europe and the Balkans. In order to prevent an 1842 stone arch bridge from being a bottleneck, two additional pedestrian bridges on either side of the central one were added in 1932 according to the Plečnik's 1929 design. He decorated them with large stone balusters and lamps. There are two staircases, leading to terraces above the river, the banks with poplars, and the Ljubljana fish market. Two Plečnik's urban axes of Ljubljana, the water axis and the Ljubljana Castle–Rožnik Axis, cross at the bridge.
The Trnovo Bridge is the most prominent object of Plečnik's renovation of the banks of the Gradaščica. It is located in front of the Trnovo Church to the south of the city center. It connects the neighborhoods of Krakovo and Trnovo, the oldest Ljubljana suburbs, known for their market gardens and cultural events. It was built between 1929 and 1932. It is distinguished by its width and two rows of birches that it bears, because it was meant to serve as a public space in front of the church. Each corner of the bridge is capped with a small pyramid, a signature motif of Plečnik's, whereas the mid-span features a pair of Art-Deco male sculptures. There is also a statue of Saint John the Baptist on the bridge, the patron of the Trnovo Church. It was designed by Nikolaj Pirnat.
The Dragon Bridge, built by Josef Melan and designed by Jurij Zaninović, is often regarded as the most beautiful bridge produced by the Vienna Secession. It is located in the northeast of Vodnik Square ("Vodnikov trg") It is a triple-hinged arch bridge and has a span of 33.34 m. When opened in 1901, it had the third largest arch in Europe. Today, it is protected as a technical monument. The chief attraction of the bridge are four sheet-copper dragon statues, which stand on pedestals at its four corners and have become a symbol of the city.
The Hradecky Bridge is one of the first hinged bridges in the world, the first and the only preserved cast iron bridge in Slovenia, and one of its most highly valued technical achievements. It has been situated on an extension of Hren Street ("Hrenova ulica"), between the Krakovo Embankment ("Krakovski nasip") and the Gruden Embankment ("Grudnovo nabrežje"), connecting the Trnovo District and the Prule neighbourhood in the Center District. The Hradecky Bridge was manufactured according to the plans of the senior engineer Johann Hermann from Vienna in the Auersperg iron foundry in Dvor near Žužemberk, and installed in Ljubljana in 1867, at the location of today's Cobblers' Bridge.
The Butchers' Bridge is a footbridge crossing the river Ljubljanica River. It connects Ljubljana Central Market ("Osrednja ljubljanska tržnica") and the Petkovšek embankment ("Petkovškovo nabrežje"). It was officially opened in July 2010 and completes Plečnik's plans from the 1930s. The largest sculptures on the bridge, created by the sculptor Jakov Brdar, represent figures from Ancient Greek mythology and Biblical stories. Shortly after the opening, padlocks of couples in love started appearing on its steel wires, symbolizing declarations of eternal love, a phenomenon similar to the one on the Parisian Pont des Arts.
Culture.
Accent.
Ljubljana accent and/or dialect (; as pronounced in the dialect itself) is part of the Upper Carniolan dialect group. The Ljubljana dialect has also been used as literary means in novels, such as in the novel "Nekdo drug" by Branko Gradišnik, or in poems, such as "Pika Nogavička" (Slovene for Pippi Longstocking) by Andrej Rozman - Roza.
In literary fiction.
Ljubljana appears in the 2005 "The Historian", written by Elisabeth Kostova, and is called by its Roman name (Emona). Ljubljana is also the setting of Paulo Coelho's 1998 novel "Veronika Decides to Die".
Festivals.
Each year, over 10,000 cultural events take place in the city, including ten international theater, music, and art festivals. The Ljubljana Festival is one of the two oldest festivals in former Yugoslavia (the Dubrovnik festival was established in 1950, and the Ljubljana one in 1953). Guests have included Dubravka Tomšič, Marjana Lipovšek, Tomaž Pandur, Katja Ricciarelli, Grace Bumbry, Lord Yehudi Menuhin, Mstislav Rostropovič, José Carreras, Slid Hampton, Zubin Mehta, Vadim Repin, Valerij Gergijev, Sir Andrew Davis, Danjulo Išizaka, Midori, Jurij Bašmet, Ennio Morricone, and Manhattan Transfer. Orchestras have included the New York Philharmonic, Israel Philharmonic, Royal Philharmonic Orchestra, Orchestras of the Bolshoi Theatre from Moscow, La Scala from Milan, and Mariinsky Theatre from Saint Petersburg. In recent years there have been 80 different kinds of events and some 80,000 visitors from Slovenia and abroad. Other cultural venues include Križanke, Cankar Hall and the Exhibition and Convention Center. During Book Week, starting each year on World Book Day, events and book sales take place on Congress Square. A flea market is held every Sunday in the old city. On the evening of International Workers' Day, a celebration with a bonfire takes place on Rožnik Hill.
Museums and art galleries.
Ljubljana has numerous art galleries and museums. The first purpose-built art gallery in Ljubljana was Jakopič Pavilion, which was in the first half of the 20th century the central exhibition venue of Slovene artists. In the early 1960s, it was succeeded by the Ljubljana City Art Gallery, which has presented a number of modern Slovene and foreign artists. In 2010, there were 14 museums and 56 art galleries in Ljubljana. There is for example an architecture museum, a railway museum, a school museum, a sports museum, a museum of modern art, a museum of contemporary art, a brewery museum, the Slovenian Museum of Natural History and the Slovene Ethnographic Museum. The National Gallery ("Narodna galerija"), founded in 1918, and the Museum of Modern Art ("Moderna galerija") exhibit the most influential Slovenian artists. In 2006, the museums received 264,470 visitors, the galleries 403,890 and the theatres 396,440. The Museum of Contemporary Art Metelkova (Muzej sodobne umetnosti Metelkova), opened in 2011, hosts various simultaneous exhibitions, a research library, archives, and a bookshop.
Entertainment and performing arts.
Cankar Hall is the largest Slovenian cultural and congress center with multiple halls and a large foyer in which art film festivals, artistic performances, book fairs, and other cultural events are held.
The cinema in Ljubljana appeared for the first time at the turn of the 20th century, and quickly gained popularity among the residents. After World War II, the Cinema Company Ljubljana, later named "Ljubljana Cinematographers", was established and managed a number of already functioning movie theaters in Ljubljana, including the only Yugoslav children's theater. A number of cinema festivals took place in the 1960s, and a cinematheque opened its doors in 1963. With the advent of television, video, and recently the Internet, most cinema theaters in Ljubljana closed, and the cinema mainly moved to Kolosej, a multiplex in the BTC City. It features twelve screens, including an IMAX 3D screen. The remaining theaters are Kino Komuna, Kinodvor, where art movies are accompanied by events, and the Slovenian Cinematheque.
The Slovenian Philharmonics is the central music institution in Ljubljana and Slovenia. It holds classical music concerts of domestic and foreign performers as well as educates youth. It was established in 1701 as part of Academia operosorum Labacensis and is among the oldest such institutions in Europe. The Slovene National Opera and Ballet Theatre also resides in Ljubljana, presenting a wide variety of domestic and foreign, modern and classic, opera, ballet and concert works. It serves as the national opera and ballet house. Numerous music festivals are held in Ljubljana, chiefly in European classical music and jazz, for instance the Ljubljana Summer Festival ("Ljubljanski poletni festival"), and Trnfest.
In addition to the main houses, with the SNT Drama Ljubljana as the most important among them, a number of small producers are active in Ljubljana, involved primarily in physical theatre (e.g. Betontanc), street theatre (e.g. Ana Monró Theatre), theatresports championship Impro League, and improvisational theatre (e.g. IGLU Theatre). A popular form is puppetry, mainly performed in the Ljubljana Puppet Theatre. Theater has a rich tradition in Ljubljana, starting with the 1867 first ever Slovene-language drama performance.
The modern dance was presented in Ljubljana for the first time at the end of the 19th century and developed rapidly since the end of the 1920s. Since the 1930s when in Ljubljana was founded a Mary Wigman dance school, the first one for modern dance in Slovenia, the field has been intimately linked to the development in Europe and the United States. Ljubljana Dance Theatre is today the only venue in Ljubljana dedicated to contemporary dance. Despite this, there's a vivid happening in the field.
Several folk dance groups are active in Ljubljana.
Popular urban culture and alternative scene.
In the 1980s with the emergence of subcultures in Ljubljana, an alternative culture begun to develop in Ljubljana organized around two student organisations. This caused an influx of young people to the city center, caused political and social changes, and led to the establishment of alternative art centers.
A Ljubljana equivalent of the Copenhagen's Freetown Christiania, a self-proclaimed autonomous Metelkova neighbourhood, was set up in a former Austro-Hungarian barracks that were built in 1882 (completed in 1911).
In 1993, the seven buildings and 12,500 m2 of space were turned into art galleries, artist studios, and seven nightclubs, including two gay venues, playing host to all range of music from hardcore to jazz to dub to techno. Adjacent to the Metelkova are located the Celica Hostel with rooms all artistically decorated by the Metelkova artists, and a new part of the Museum of Modern Art, Museum of Contemporary Art. Another alternative culture center is located in the former Rog factory.
The Šiška Cultural Quarter hosts a number of art groups and cultural organisations dedicated to contemporary and avant-garde arts. Part of it is also Kino Šiška Center for Urban Culture, a venue where music concerts of indie, punk, and rock bands as well as exhibitions take place.
Sports.
Societies and clubs.
A tension between German and Slovene residents dominated the development of sport of Ljubljana in the 19th century. The first sports society in Ljubljana was the Gymnastic Society South Sokol (Slovene: "Gimnastično društvo Južni Sokol"), established in 1863 and succeeded in 1868 by the Ljubljana Sokol. It was the parent society of all Slovene Sokol societies as well as an encouragement for the establishment of the Croatian Sokol society in Zagreb. Members were also active in culture and politics, striving for greater integration of the Slovenes from different Crown lands of Austria–Hungary and for their cultural, political, and economic independence.
In 1885, German residents established the first sports club in the territory of nowadays Slovenia, "Der Laibacher Byciklistischer Club" ("Ljubljana Cycling Club"). In 1887, Slovene cyclists established the Slovene Cyclists Club (Slovenski biciklistični klub). In 1893 followed the first Slovene mountaineering club, named Slovene Mountaineering Society, later succeeded by the Ljubljana-Matica Mountaineering Club, which is today the largest mountaineering club in Slovenia. In 1900, the sporting club "Laibacher Sportverein" (English: "Ljubljana Sports Club") was established by the city's German residents and functioned until 1909. In 1906, Slovenes organized themselves in its Slovene counterpart, the "Ljubljanski športni klub". Its members were primarily interested in rowing, but also swimming and football. In 1911, the first Slovene football club, "Ilirija", started operating in the city. Winter sports started to develop in the area of the nowadays Ljubljana already before World War II. In 1929, the first ice hockey club in Slovenia (then Yugoslavia) SK Ilirija was established.
Nowadays, the city's football team which plays in the Slovenian PrvaLiga is NK Olimpija Ljubljana. Ljubljana's ice hockey clubs are HK Olimpija Ljubljana, HK Alfa, HK Slavija and HDD Olimpija. They all compete in the Slovenian Hockey League; HDD Olimpija Ljubljana also takes part in the Austrian Hockey League. The basketball teams are KD Slovan, ŽKD Ježica Ljubljana and KK Union Olimpija. The latter, which has a green dragon as its mascot, hosts its matches in the 13,000-seat Arena Stožice since 2010. AMTK Ljubljana is the most successful speedway club in Slovenia. In the last 20 years, it won the title of the national champion 19 times individually and 17 times in team. The Ljubljana Sports Club has been succeeded by the Livada Canoe and Kayak Club.
Mass sport activities.
Each year since 1957, on 8–10 May, the traditional recreational "March along the Path of Remembrance and Comradeship" has taken place to mark the liberation of Ljubljana on 9 May 1945. At the same occasion, a triples competition is run on the path, and a few days later, a student run from Prešeren Square to Ljubljana Castle is held. The last Sunday in October, the Ljubljana Marathon and a few minor competition runs take place on the city streets. The event attracts several thousand runners each year.
Sport venues.
The Stožice Stadium, opened since August 2010 and located in Stožice Sports Park in the Bežigrad District, is the biggest football stadium in the country and the home of the NK Olimpija Ljubljana. It is one of the two main venues of Slovenia national football team. The park also has an indoor arena, used for indoor sports such as basketball, handball and volleyball and is the home venue of KK Olimpija, RK Krim and ACH Volley Bled among others. Beside football, the stadium is designed to host cultural events as well. Another stadium in the Bežigrad district, Bežigrad Stadium, is closed since 2008 and is deteriorating. It was built according to the plans of Jože Plečnik and was the home of the NK Olimpija Ljubljana, dissolved in 2004. Joc Pečečnik, a Slovenian multimillionaire, plans to renovate it.
The Sports Park Ljubljana is located in Lower Šiška, part of the Šiška District. It has a football stadium with five courts, an athletic hall, outdoor athletic areas, tennis courts, a Boules court, and a sand volleyball court. The majority of competitions are in athletics. Another sports park in Lower Šiška is Ilirija Sports Park, known primarily for its stadium with a speedway track. At the northern end of Tivoli Park stands the Ilirija Swimming Pool Complex, which was built as part of a swimming and athletics venue following plans by Bloudek in the 1930s and has been nearly abandoned since then, but there are plans to renovate it.
A number of sport venues are located in Tivoli Park. An outdoor swimming pool in Tivoli, constructed by Bloudek in 1929, was the first Olympic-size swimming pool in Yugoslavia. Currently, the Tivoli Recreational Center in Tivoli is Ljubljana's largest recreational center and has three swimming pools, saunas, a Boules court, a health club, and other facilities. There are two skating rinks, a basketball court, a winter ice rink, and ten tennis courts in its outdoor area. The Tivoli Hall consists of two halls. The smaller one accepts 4,050 spectators and is used for basketball matches. The larger one can accommodate 6,000 spectators and is primarily used for hockey, but also for basketball matches. The halls are also used for concerts and other cultural events. The Slovenian Olympic Committee has its office in the building.
The Tacen Whitewater Course, located on a course on the Sava, 8 km northwest of the city center, hosts a major international canoe/kayak slalom competition almost every year, examples being the ICF Canoe Slalom World Championships in 1955, 1991, and 2010.
Since the 1940s, a ski slope has been in use in Gunclje, in the northwestern part of the city. It is 600 m long and has two ski lifts, its maximum incline is 60° and the difference in height from the top to the bottom is 155 m. Five ski jumping hills stand near the ski slope. Several Slovenian Olympic and World Cup medalists trained and competed there. In addition, the Arena Triglav complex of six jumping hills is located in the Šiška District. A ski jumping hill, build in 1954 upon the plans by Stanko Bloudek, was located in Šiška near Vodnik Street ("Vodnikova cesta") until 1976. International competitions for the Kongsberg Cup were held there, attended by thousands of spectators. The ice rinks in Ljubljana include Koseze Pond and Tivoli Hall. In addition, in the 19th century and the early 20th century, Tivoli Pond and a marshy meadow in Trnovo, named Kern, were used for ice skating.
Economy.
Industry remains the most important employer, notably in the pharmaceuticals, petrochemicals and food processing. Other fields include banking, finance, transport, construction, skilled trades and services and tourism. The public sector provides jobs in education, culture, health care and local administration.
The Ljubljana Stock Exchange ("Ljubljanska borza"), purchased in 2008 by the Vienna Stock Exchange, deals with large Slovenian companies. Some of these have their headquarters in the capital: for example, the retail chain Mercator, the oil company Petrol d.d. and the telecommunications concern Telekom Slovenije. Over 15,000 enterprises operate in the city, most of them in the tertiary sector.
Numerous companies and over 450 shops are located in the BTC City, the largest business, shopping, recreational, entertainment and cultural center in Slovenia. It is visited each year by 21 million people. It occupies an area of 475000 m2 in the Moste District in the eastern part of Ljubljana.
Government.
The city of Ljubljana is governed by the City Municipality of Ljubljana (Slovene: "Mestna občina Ljubljana"; MOL), which is led by the city council. The president of the city council is called the mayor. Members of the city council and the mayor are elected in the local election, held every four years. Among other roles, the city council drafts the municipal budget, and is assisted by various boards active in the fields of health, sports, finances, education, environmental protection and tourism. The municipality is subdivided into 17 districts represented by district councils. They work with the municipality council to make known residents' suggestions and prepare activities in their territories.
Between 2002 and 2006, Danica Simšič was mayor of the municipality. Since the municipal elections of 22 October 2006 until his confirmation as a deputy in the National Assembly of Slovenian in December 2011, Zoran Janković, previously the managing director of the Mercator retail chain, was the mayor of Ljubljana. In 2006, he won 62.99% of the popular vote. On 10 October 2010, Janković was re-elected for another four-year term with 64.79% of the vote. From 2006 until October 2010, the majority on the city council (the Zoran Janković List) held 23 of 45 seats. On 10 October 2010, Janković's list won 25 out of 45 seats in the city council. From December 2011 onwards, when Janković's list won the early parliamentary election, the deputy mayor Aleš Čerin was decided by him to lead the municipality. Čerin did not hold the post of mayor. After Janković had failed to be elected as the Prime Minister in the National Assembly, he participated at the mayoral by-election on 25 March 2012 and was elected for the third time with 61% of the vote. He retook the leadership of the city council on 11 April 2012.
Public order in Ljubljana is enforced by the Ljubljana Police Directorate ("Policijska uprava Ljubljana"). There are five areal police stations and four sectoral police stations in Ljubljana. Public order and municipal traffic regulations are also supervised by the city traffic wardens ("Mestno redarstvo"). Ljubljana has a quiet and secure reputation.
Demographics.
In 1869, Ljubljana had about 22,600 inhabitants, a figure that grew to almost 60,000 by 1931.
At the 2002 census, 39% of Ljubljana inhabitants were Catholic; 30% had no religion, an unknown religion or did not reply; 19% atheist; 6% Eastern Orthodox; 5% Muslim; and the remaining 0.7% Protestant or another religion.
Approximately 84% of the population speaks Slovene as their primary native language. The second most-spoken language is Bosnian with Serbian being the third most-spoken language.
Demographic evolution
Education.
In Ljubljana today there are over 50 public elementary schools with over 20,000 pupils. This also includes an international elementary school for foreign pupils. There are two private elementary schools: a Waldorf elementary school and a Catholic elementary school. In addition, there are several elementary music schools.
Historically the first school in Ljubljana belonged to Teutonic Knights and was established in the 13th century. It originally accepted only boys; girls were accepted from the beginning of the 16th century. Parochial schools are attested in the 13th century, at St. Peter's Church and at Saint Nicholas's Church, the later Ljubljana Cathedral. Since 1291, there were also trade-oriented private schools in Ljubljana. In the beginning of the 17th century, there were six schools in Ljubljana and later three. A girls' school was established by Poor Clares, followed in 1703 by the Ursulines. Their school was for about 170 years the only public girls' school in Carniola. These schools were mainly private or established by the city.
In 1775, the Austrian Empress Maria Theresa proclaimed elementary education obligatory and Ljubljana got its normal school, intended as a learning place for teachers. In 1805, the first state music school was established in Ljubljana. In the time of Illyrian Provinces, "école primaire", a unified four-year elementary school program with a greater emphasis on Slovene, was introduced. The first public schools, unrelated to religious education, appeared in 1868.
Currently in Ljubljana there are ten public and three private grammar schools. The public schools divide into general gymnasiums and classical gymnasiums, the latter offering Latin and Greek as foreign languages. Some general schools offer internationally oriented European departments, and some offer sport departments, allowing students to more easily adjust their sport and school obligations. All state schools are free, but the number of students they can accept is limited. The private secondary schools include a Catholic grammar school and a Waldorf grammar school. There are also professional grammar schools in Ljubljana, offering economical, technical, or artistic subjects (visual arts, music). All grammar schools last four years and conclude with the matura exam.
Historically, upon a proposal by Primož Trubar, the Carniolan Estates' School (1563–1598) was established in 1563 in the period of Slovene Reformation. Its teaching languages were mainly Latin and Greek, but also German and Slovene, and it was open for both sexes and all social strata. In 1597, Jesuits established the Jesuit College (1597–1773), intended to transmit general education. In 1773, secondary education came under the control of the state. A number of reforms were implemented in the 19th century; there was more emphasis on general knowledge and religious education was removed from state secondary schools. In 1910, there were 29 secondary schools in Ljubljana, among them classical and real gymnasiums and Realschules (technical secondary schools).
In 2011, the University had 23 faculties and three academies, located in different parts of Ljubljana. They offer Slovene-language courses in medicine, applied sciences, arts, law, administration, natural sciences, and other subjects. The university has more than 63,000 students and some 4,000 teaching faculty. Students make up one-seventh of Ljubljana's population, giving the city a youthful character.
Historically, higher schools offering the study of general medicine, surgery, architecture, law and theology, started to operate in Ljubljana during the French occupation of the Slovene Lands, in 1810–11. Austro-Hungarian Empire never allowed Slovenes to establish their own university in Ljubljana and the University of Ljubljana, Slovenia's most important university, was founded in 1919 after Slovenes joined the first Yugoslavia. When it was founded, the university comprised five faculties: law, philosophy, technology, theology and medicine. From the beginning, the seat of the university has been at Congress Square in a building that served as the State Mansion of Carniola from 1902 to 1918.
Libraries.
The National and University Library of Slovenia is the Slovene national and university library. In 2011, it held about 1,307,000 books, 8,700 manuscripts, and numerous other textual, visual and multimedia resources, altogether 2,657,000 volumes.
The second largest university library in Ljubljana is the Central Technological Library, the national library and information hub for natural sciences and technology.
The Municipal City Library of Ljubljana, established in 2008, is the central regional library and the largest Slovenian general public library. In 2011, it held 1,657,000 volumes, among these 1,432,000 books and a multitude of other resources in 36 branches. Altogether, there are 5 general public libraries and over 140 specialized libraries in Ljubljana.
Besides the two largest university libraries there are a number of libraries at individual faculties, departments and institutes of the University of Ljubljana. The largest among them are the Central Humanist Library in the field of humanities, the Central Social Sciences Library, the Central Economic Library in the field of economics, the Central Medical Library in the field of medical sciences, and the Libraries of the Biotechnical Faculty in the field of biology and biotechnology.
The first libraries in Ljubljana were located in monasteries. The first public library was the Carniolan Estates' Library, established in 1569 by Primož Trubar. In the 17th century, the Jesuit Library collected numerous works, particularly about mathematics. In 1707, the Seminary Library was established; it is the first and oldest public scientific library in Slovenia. Around 1774, after the dissolution of Jesuits, the Lyceum Library was formed from the remains of the Jesuit Library as well as several monastery libraries.
Science.
The first society of the leading scientists and public workers in Carniola was the Dismas Fraternity (Latin:"Societas Unitorum"), formed in Ljubljana in 1688. In 1693, the "Academia Operosorum Labacensium" was founded and lasted with an interruption until the end of the 18th century. The next academy in Ljubljana, the Slovenian Academy of Sciences and Arts, was not established until 1938.
Transport.
Air.
Ljubljana Jože Pučnik Airport (IATA code LJU), located 26 km northwest of the city, has flights to numerous European destinations. Among the companies that fly from there are Adria Airways, Air France, easyJet, Finnair, Job Air, Montenegro Airlines, Wizz Air and Turkish Airlines. The destinations are mainly European. This airport has superseded the original Ljubljana airport, in operation from 1933 until 1963. It was located in the Municipality of Polje (nowadays the Moste District), on a plain between Ljubljanica and Sava next to the railroad in Moste. There was a military airport in Šiška from 1918 until 1929.
Rail.
In the Ljubljana Rail Hub, the Pan-European railway corridors V (the fastest link between the North Adriatic, and Central and Eastern Europe) and X (linking Central Europe with the Balkans) and the main European lines (E 65, E 69, E 70) intersect. All international transit trains in Slovenia drive through the Ljubljana hub, and all international passenger trains stop there. The area of Ljubljana has six passenger stations and nine stops. For passengers, the Slovenian Railways company offers the possibility to buy a daily or monthly city pass that can be used to travel between them. The Ljubljana railway station is the central station of the hub. The Ljubljana Moste Railway Station is the largest Slovenian railway dispatching place. The Ljubljana Zalog Railway Station is the central Slovenian rail yard. There are a number of industrial rails in Ljubljana. At the end of 2006, the Ljubljana Castle funicular started to operate. The rail goes from Krek Square ("Krekov trg") near the Ljubljana Central Market to Ljubljana Castle. It is especially popular among tourists. The full trip lasts 60 s.
Roads.
Ljubljana is located where Slovenia's two main freeways intersect, connecting the freeway route from east to west, in line with Pan-European Corridor V, and the freeway in the north–south direction, in line with Pan-European Corridor X. The city is linked to the southwest by A1-E70 to the Italian cities of Trieste and Venice and the Croatian port of Rijeka. To the north, A1-E57 leads to Maribor, Graz and Vienna. To the east, A2-E70 links it with the Croatian capital Zagreb, from where one can go to Hungary or important cities of the former Yugoslavia, such as Belgrade. To the northwest, A2-E61 goes to the Austrian towns of Klagenfurt and Salzburg, making it an important entry point for northern European tourists. A toll sticker system has been in use on the Ljubljana Ring Road since 1 July 2008. The center of the city is more difficult to access especially in the peak hours due to long arteries with traffic lights and a large number of daily commuters. The strict city center has been closed for motor traffic since September 2007, except for residents with permissions.
Historical Ljubljana tram system was completed in 1901 and was replaced by buses in 1928, which were in turn abolished and replaced by trams in 1931 in its final length of 18.5 km in 1940, In 1959, it was abolished in favor of automobiles; the tracks were dismantled and tram cars were transferred to Osijek and Subotica. Reintroduction of an actual tram system to Ljubljana has been proposed repeatedly in the 2000s.
City bus.
The Ljubljana Bus Station, the Ljubljana central bus hub, is located next to the Ljubljana railway station. The city bus network, run by the Ljubljana Passenger Transport ("LPP") company, is Ljubljana's most widely used means of public transport. The fleet is relatively modern. The number of dedicated bus lines is limited, which can cause problem in peak hours when traffic becomes congested.
Bus rides may be paid with the Urbana payment card (also used for the funicular) or with a mobile phone. Sometimes the buses are called "trole" (referring to trolley poles), harking back to the 1951–71 days when Ljubljana had trolleybus ("trolejbus") service. There were five trolleybus lines in Ljubljana, until 1958 alongside the tram.
There are numerous taxi companies in the city, but their services have been evaluated as bad.
Another means of public road transport in the city center is the Cavalier ("Kavalir"), an electric vehicle operated by LPP since May 2009. There are three such vehicles in Ljubljana. The ride is free and there are no stations because it can be stopped anywhere. It can carry up to five passengers; most of them are elderly people and tourists. The Cavalier drives in the car-free zone in the Ljubljana downtown. The first line links Čop Street, Wolf Street and Hribar Embankment, whereas the second links Town Square, Upper Square, and Old Square. There is also a tractor with wagons decorated to look like a train for tourists in Ljubljana, linking Cyril and Methodius Square in the city center with Ljubljana Castle.
Bicycles.
There is a considerable amount of bicycle traffic in Ljubljana, especially in the warmer months of the year. It is also possible to rent a bike. Since May 2011, the BicikeLJ, a self-service bicycle rental system offers the residents and visitors of Ljubljana 300 bicycles and 600 parking spots at 31 stations in the wider city center area. The daily number of rentals is around 2,500. There was a possibility to rent a bike even before the establishment of BicikeLJ.
However, the conditions for cyclists in Ljubljana have been criticized as unfortunate to date. This refers to cycle lanes in poor condition and constructed in a way that motorized traffic is privileged. In contrast to other European capitals, on some of the main streets cycling is forbidden; for example, on part of Slovenska cesta (Slovene Street) and on a new link road on the Fabiani Bridge across the Ljubljanica River connecting Hrvatski trg and Roška cesta. There are also many one-way streets which therefore cannot be used as alternate routes so it is difficult to legally travel by bicycle through the city center. Through years, some prohibitions have been partially abolished by marking cycle lanes on the pavement.
Water.
The river transport on the Ljubljanica and the Sava was the main means of cargo transport to and from the city until the mid-19th century, when railroads were built. Today, the Ljubljanica is used by a number of tourist ships, with wharves under the Butchers' Bridge, at Fish Square, at Court Square, at Breg, at the Poljane Embankment, and elsewhere.
Healthcare.
Ljubljana has a rich history of discoveries in medicine and innovations in medical technology. The majority of secondary and tertiary care in Slovenia takes place in Ljubljana. The Ljubljana University Medical Center is the largest hospital center in Slovenia. The Faculty of Medicine (University of Ljubljana) and the Ljubljana Institute of Oncology are other two central medical institutions in Slovenia. The Ljubljana Community Health Center is the largest health center in Slovenia. It has seven units at 11 locations. Since 1986, Ljubljana is part of the WHO European Healthy Cities Network.
International relations.
Twin towns — Sister cities.
Ljubljana is twinned with:

</doc>
<doc id="42378" url="http://en.wikipedia.org/wiki?curid=42378" title="200">
200

Year 200 (CC) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Severus and Victorinus (or, less frequently, year 953 "Ab urbe condita"). The denomination 200 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42379" url="http://en.wikipedia.org/wiki?curid=42379" title="300">
300

Year 300 (CCC) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Constantius and Valerius (or, less frequently, year 1053 "Ab urbe condita"). The denomination 300 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>

</doc>
<doc id="42380" url="http://en.wikipedia.org/wiki?curid=42380" title="Tin whistle">
Tin whistle

The tin whistle, also called the penny whistle, English flageolet, Scottish penny whistle, tin flageolet, Irish whistle, feadóg stáin (or simply feadóg) and Clarke London Flageolet is a simple, six-holed woodwind instrument. It is a fipple flute, putting it in the same category as the recorder, Native American flute, and other woodwind instruments that meet such criteria. A tin whistle player is called a tin whistler or simply a whistler. The tin whistle is closely associated with Celtic music.
History of the whistle.
The tin whistle in its modern form is from a wider family of fipple flutes which have been seen in many forms and cultures throughout the world. In Europe such instruments have a long and distinguished history and take various forms; most widely known of these are the recorder, tin whistle, Flabiol, Txistu and tabor pipe. 
Almost all primitive cultures had a type of fipple flute and is most likely the first pitched flute type instrument in existence. A possible Neanderthal fipple flute from Slovenia dates from 81,000-53,000 B.C., a German flute from 35,000 years ago, and flute made from sheep's bone in West Yorkshire dating to the Iron Age. Written sources that describe a fipple-type flute include the Roman and Greek aulos and tibia. In the early Middle Ages peoples of northern Europe were playing the instrument as seen in 3rd-century British bone flutes, and Irish Brehon Law describes flute like instrument. By the 12th century Italian flutes came in a variety of sizes, and fragments of 12th-century Norman bone whistles have been found in Ireland, and an intact 14 cm Tusculum clay whistle from the 14th century in Scotland. In the 17th century whistles were called flageolets; a term to describe a whistle with a French made fipple headpiece (common to the modern penny whistle) and such instruments are linked to the development of the English flageolet, French flageolet and recorders of the renaissance and baroque period. The term flageolet is still preferred by some modern tin whistle who feel this better describes the instrument, as this characterises a wide variety of fipple flutes, including penny whistles.
Modern tin whistle.
The modern penny whistle is indigenous to the British Isles particularly England when factory-made "tin whistles" were produced by Robert Clarke from 1840–1882 in Manchester and later New Moston, England. Down to 1900, they were also marketed as "Clarke London Flageolets" or "Clarke Flageolets". The whistle's fingering system is similar to that of the six hole, "simple system English flutes" ("simple" in comparison to Boehm system flutes). The six hole, diatonic system is also used on baroque flutes, and was of course well known before Robert Clarke began producing his tin whistles. Clarke's first whistle, the Meg, was pitched in high A and was later made in other keys suitable for Victorian parlour music. The company showed the whistles in The Great Exhibition of 1851. The Clark tin whistle is voiced somewhat on an organ-pipe with a flattened tube forming the lip of the fipple mouthpiece and is usually made from rolled tin sheet or brass. Manufactured tin whistles became available no earlier than 1840, and were mass-produced and widespread due to their relative affordability. 
As the penny whistle was generally considered a toy it has been suggested that children or street musicians were paid a penny by those who heard them playing the whistle. However in reality the instrument was so called because it could be purchased for a penny. The name "tin-whistle" was also coined as early as 1825. but neither the tin whistle nor the penny whistle name seems to have been common until the 20th century. The instrument became popular in several musical traditions namely; English, Scottish, Irish and American traditional music. Due to its affordability the tin whistle was a popular household instrument, as ubiquitous as the harmonica. In the second half of the 19th century, some flute manufacturers such as Barnett Samuel and Joseph Wallis also sold whistles. These had a cylindrical brass tube. Like many old whistles, they had lead fipple plugs, and since lead is poisonous, caution should be exercised before playing an old whistle.
The Generation whistle was introduced in the first half of the 20th century, and also featured a brass tube with a lead fipple plug. The design was updated somewhat over the years, most notably the substitution of a plastic fipple for the lead plug design.
While whistles have most often been produced in higher pitches, the "low" whistle is not unknown historically. The Museum of Fine Arts, Boston has in its collection an example of a 19th-century low whistle from the famous Galpin collection. During the 1960s revival of traditional Irish music the low whistle was "recreated" by Bernard Overton at the request of Finbar Furey.
Contemporary whistles.
The most common whistles today are made of brass tubing, or nickel plated brass tubing, with a plastic fipple (mouthpiece). Generation, Feadóg, Oak, Acorn, Soodlum's (now Walton's), and other brands fall in this category. The next most common form is the conical sheet metal whistle with a wooden stop in the wide end to form the fipple, the Clarke's brand being the most prevalent. Other less common variants are the all-metal whistle, the PVC whistle, the Flanna square holed whistle, and the wooden whistle.
Gaining popularity as a folk instrument in the early 19th century in the Celtic music revivals, penny whistles now play an integral part of several folk traditions. Whistles are a prevalent starting instrument in English traditional music, Scottish traditional music and Irish traditional music, since they are often cheap (under US$10), relatively easy to start with (no tricky embouchure such as found with the flute), and the fingerings are nearly identical to those on the traditional six holed flute (Irish flute, baroque flute). The tin whistle is a good starting instrument to learn the uilleann pipes, which has similar finger technique, range of notes and repertoire. The tin whistle is the most popular instrument in Irish traditional music today.
In recent years a number of instrument builders have started lines of "high-end," hand-made whistles, which can cost hundreds of dollars US each — expensive in comparison to cheap whistles, but nevertheless cheaper than most other instruments. These companies are typically either a single individual or a very small group of craftsmen who work closely together. The instruments are distinguished from the inexpensive whistles in that each whistle is individually manufactured and "voiced" by a skilled person rather than made in a factory.
Tuning.
Whistle keys.
The whistle is tuned diatonically, which allows it to be used to easily play music in two major keys and their corresponding minor keys and modes. The whistle is identified by its lowest note, which is the tonic of the lowest major key. Note that this method of determining the key of the instrument is different from the method used to determine the key of a chromatic instrument, which is based on the relationship between notes on a score and sounded pitch. Whistles are available in a wide variety of different keys.
The most common whistles can easily play notes in the keys of D and G major. Since the D major key is lower these whistles are identified as "D whistles." The next most common whistle tuning is a "C whistle," which can easily play notes in the keys of C and F major. The D whistle is the most common choice for Irish and Scottish music.
Although the whistle is essentially a diatonic instrument, it is possible to get notes outside the principal major key of the whistle, either by "half-holing" (partially covering the highest open finger hole) or by "cross-fingering" (covering some holes while leaving some higher ones open). However, half-holing is somewhat more difficult to do correctly, and whistles are available in many keys, so for other keys a whistler will typically use a different whistle instead, reserving half-holing for accidentals. Some whistle designs allow a single fipple, or mouthpiece, to be used on differently keyed bodies.
Low whistles.
There are larger whistles, which by virtue of being longer and wider produce tones an octave (or in rare cases two octaves) lower. Whistles in this category are likely to be made of metal or plastic tubing, sometimes with a tuning-slide head, and are almost always referred to as "low whistles" but sometimes called "concert whistles". The low whistle operates on identical principles to the standard whistles, but musicians in the tradition may consider it a separate instrument.
The term "soprano whistle" is sometimes used for the higher-pitched whistles when it is necessary to distinguish them from low whistles.
Playing technique.
Fingering and range.
The notes are selected by opening or closing holes with the fingers. With all the holes closed, the whistle generates its lowest note, the tonic of a major scale. Successively opening holes from the bottom upward produces the rest of the notes of the scale in sequence: with the lowest hole open it generates the second, with the lowest two holes open, it produces the third and so on. With all six holes open, it produces the seventh.
As with a number of woodwind instruments, the tin whistle's second and higher registers are achieved by increasing the air velocity into the ducted flue windway. 
On a transverse flute this is generally done by narrowing the lip/embouchure. Since the size and direction of the tin whistle's windway is fixed, like that of the recorder or fipple flute, it is necessary to increase the velocity of the air stream. (See overblowing).
Fingering in the second register is generally the same as in the first/fundamental, though alternate fingerings are sometimes employed in the higher end of the registers to correct a flattening effect caused by higher aircolumn velocity. Also, the tonic note of the second register is usually played with the top hole of the whistle partially uncovered instead of covering all holes as with the tonic note of the first register; this makes it harder to accidentally drop into the first register and helps to correct pitch. Recorders perform this by "pinching" open the dorsal thumb hole.
Various other notes (relatively flat or sharp with respect to those of the major scale) can be accessed by "cross fingering" techniques, and all the notes (except the lowest of each octave/register) can be flattened by "half holing". Perhaps the most effective and most used cross fingering is that which produces a flattened form of the seventh note (B flat instead of B on a C whistle, for example, or C natural instead of C sharp on a D whistle). This makes available another major scale (F on a C whistle, G on a D whistle).
The standard range of the whistle is two octaves. For a D whistle, this includes notes from the second D (D5) above middle C to the fourth D (D7) above middle C (D7). It is possible to make sounds above this range, by blowing with sufficient force, but, in most musical contexts, the result will be loud and out of tune due to a cylindrical bore.
Ornamentation.
Traditional whistle playing uses a number of ornaments to embellish the music, including cuts, strikes and rolls. Most playing is legato with ornaments to create breaks between notes, rather than tongued. The traditional music concept of the word "ornamentation" differs somewhat from that of European classical music in that ornaments are more commonly changes in how a note is articulated rather than the addition of separately-perceived notes to the piece. Common ornaments and articulations include:
Repertoire.
A number of music genres commonly feature the tin whistle.
Irish and Scottish music.
Traditional music from Ireland and Scotland is by far the most common music to play on the tin whistle, and comprises the vast majority of published scores suitable for whistle players. While the tin whistle is very common in Irish music to the point that it could be called characteristic of the genre and fairly common in Scottish music, it is not "required" in either genre.
Kwela.
Kwela is a genre of music created in South Africa in the 1950s, and is characterized by an upbeat, jazzy tin whistle lead. Kwela is the only music genre created around the sound of the tin whistle. The low cost of the tin whistle, or jive flute, made it an attractive instrument in the impoverished, apartheid-era townships; the Hohner tin whistle was especially popular in kwela performance. The kwela craze accounted for the sale of more than one million tin whistles.
In the late 1950s, mbaqanga music largely superseded kwela in South Africa, and so it followed that the saxophone surpassed the tin whistle as the township people's wind instrument of choice. Kwela master Aaron "Big Voice Jack" Lerole continued to perform into the 1990s; a few bands, such as The Positively Testcard of London, continue to record kwela music.
Kwela sheet music is rarely published, and many of the recordings of founding kwela artists are out of print. One representative compilation is "South African Jazz and Jive" (Rhino Entertainment, 2000).
Other music.
The tin whistle is used in many other types of music, though not to the extent that it could be called characteristic as with Irish music and kwela. In some Irish music composed for symphonic ensembles, it is often replaced with piccolo. It is not unusual to hear the tin whistle used in praise music and film soundtracks, and published scores suitable for tin whistle performance are available in both of these genres. The tin whistle also appears in "crossover" genres like world music, folk rock, folk metal and folk punk.
Notation.
Tin whistle music collections are generally notated in one of three different formats.
Standard musical notation.
It is common to score music for the whistle using standard musical notation. The tin whistle is not a transposing instrument - for example, music for the D tin whistle is written in concert pitch, not transposed down a tone as would be normal for transposing instruments. Nevertheless, there is no real consensus on how tin whistle music should be written, or on how reading music onto the whistle should be taught. However, when music is scored for a soprano whistle it will be written an octave lower than it sounds, to spare ledger lines and make it much easier to read.
The traditional music of Ireland and Scotland constitutes the majority of published scores for the whistle. Since the majority of that music is written in D major, G major, or one of the corresponding musical modes, use of the D major or G major key signatures is a "de facto" standard. For example, the "C whistle" edition of Bill Ochs's popular "The Clarke Tin Whistle Handbook" is scored in D and differs from the D edition only in that the accompanying audio CD is played on a C whistle.
Reading directly onto the C whistle is popular for the obvious reason that its "home key" or "name key" is the "all-natural" major key (C major). Some musicians are encouraged to learn to read directly onto one whistle, while others are taught to read directly onto another.
The whistle player who wants music to read on to all whistles will need to learn the mechanics of written transposition, taking music with one key signature and rewriting it with another.
Tablature notation for the tin whistle is a graphical representation of which tone holes the player should cover. The most common format is a vertical column of six circles, with holes to be covered for a given note shown filled with black, and a plus sign (+) at the top for notes in the second octave. Tablature is most commonly found in tutorial books for beginners.
Tonic solfa.
The tonic solfa is found in Ireland and possibly Wales, especially in schools. Many schools have printed sheets with tunes notated in tonic solfa, although in Ireland more have teaching by rote. With the availability of good standard notation tutor books, teaching is possibly moving in this direction.
Abc notation.
Since the majority of popular tin whistle music is traditional and out of copyright, it is common to share tune collections on the Internet. Abc notation is the most common means of electronic exchange of tunes. It is also designed to be easy to read by people, and many musicians learn to read it directly instead of using a computer program to transform it into a standard musical notation score.
Well-known performers.
During the 1960s, Tommy Makem played the tin whistle as a member of The Clancy Brothers and Tommy Makem, one of the most influential Irish folk groups, especially popular during the American folk music revival. 
In 1973, Paddy Moloney (of The Chieftains) and Sean Potts released the album "Tin Whistles", which helped to popularise the tin whistle in particular, and Irish music in general. Mary Bergin's "Feadóga Stáin" (1979) and "Feadóga Stáin 2" (1993) were similarly influential.
Other notable players include Carmel Gunning, Micho Russell, Joanie Madden, Brian Finnegan, and Seán Ryan. Many traditional pipers and flute players also play the whistle to a high standard. Festy Conlon, often considered the best slow air player.
Award winning singer and musician Julie Fowlis recorded several tracks on the tin whistle, both in her solo work and with the band Dòchas. 
Aaron "Big Voice Jack" Lerole and his band recorded a single called "Tom Hark", which sold five million copies worldwide, and which Associated Television used as the theme song for the 1958 television series "The Killing Stones". But the most famous star of the kwela era was Spokes Mashiyane. Paul Simon's 1986 album "Graceland" draws heavily on South African music, and includes pennywhistle solos in the traditional style, played by Morris Goldberg.
As a traditional Irish musical instrument, the 
Irish rock bands The Cranberries and The Pogues (with Spider Stacy as whistler) incorporate the tin whistle in some of their songs, as do such American Celtic punk bands as The Tossers, Dropkick Murphys, and Flogging Molly (in which Bridget Regan plays the instrument).
Andrea Corr of Irish folk rock band The Corrs also plays the tin whistle. Saxophonist LeRoi Moore, founding member of the American jam band Dave Matthews Band, plays the tin whistle in a few of the band's songs.
Bob Hallett of the Canadian folk rock group Great Big Sea is also a renowned performer of the tin whistle, playing it in arrangements of both traditional and original material.
Icelandic post rock band Sigur Rós concludes their song "Hafsól" with a tin whistle solo.
Barry Privett of the American Celtic rock band Carbon Leaf performs several songs using the tin whistle.
Lambchop uses the tin whistle in the song "The Scary Caroler."
The Unicorns use the tin whistle in the song "Sea Ghost".
Steve Buckley, a British jazz musician is renowned for using the penny whistle as a serious instrument. His whistle playing can be heard on recordings with Loose Tubes, Django Bates and his album with Chris Batchelor Life As We Know It. Les Lieber is a celebrated American Jazz Tinwhistle player. Lieber has played with Paul Whiteman's Band and also with the Benny Goodman Sextet. Lieber made a record with Django Reinhardt in the AFN Studios in Paris in the post Second World War era and started an event called "Jazz at Noon" every Friday in a New York restaurant playing with a nucleus of advertising men, doctors, lawyers, and business executives who had been or could have been jazz musicians. Howard Johnson has also been known to play this instrument. Musical polymath Howard Levy introduces the tune True North with a jazz and very traditionally Celtic-inspired whistle piece on Bela Fleck and the Flecktones' UFO TOFU. 
Howard Shore called for a tin whistle in D for a passage in his "Concerning Hobbits" from "The Lord of the Rings" film trilogy. The tin whistle symbolizes the Shire, together with other instruments such as the guitar, the double bass, and the bodhrán. The tin whistle also plays a passage in the main theme in the same trilogy.
The tin whistle is heard (most notably during the introduction) in the song "My Heart Will Go On" by Celine Dion in the movie "Titanic".
The tin whistle also features prominently in the soundtrack of the film "How to Train Your Dragon", and is connected to the main character, Hiccup.
The tin whistle is featured in the winning song of the 2013 Eurovision Song Contest Only Teardrops by Emmile De Forrest

</doc>
<doc id="42382" url="http://en.wikipedia.org/wiki?curid=42382" title="900">
900

Year 900 (CM) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Medicine.
</onlyinclude>

</doc>
<doc id="42383" url="http://en.wikipedia.org/wiki?curid=42383" title="Going My Way">
Going My Way

Going My Way is a 1944 American musical comedy-drama film directed by Leo McCarey and starring Bing Crosby and Barry Fitzgerald. Based on a story by Leo McCarey, the film is about a new young priest taking over a parish from an established old veteran. Crosby sings five songs in the film. "Going My Way" was followed the next year by a sequel, "The Bells of St. Mary's".
"Going My Way" was the highest-grossing picture of 1944, and was nominated for 10 Academy Awards, winning 7, including Best Picture. Its success helped to make movie exhibitors choose Crosby as the biggest box-office draw of the year, a record he would hold for the remainder of the 1940s. After World War II, Bing Crosby and Leo McCarey presented a copy of the motion picture to Pope Pius XII at the Vatican.
Plot.
The film follows Father Charles “Chuck” O’Malley (Bing Crosby), an incoming priest from East St. Louis whose unconventional style transforms the parish life of St. Dominic’s Church in New York City.
On his first day at the new parish, O'Malley gets into a series of mishaps; his informal appearance and attitude make a very poor impression with the elder pastor, Father Fitzgibbon (Barry Fitzgerald). The very traditional Fitzgibbon is further put off by O’Malley’s recreational habits – particularly his golf-playing – and his friendship with the even more casual Father Timmy O’Dowd (Frank McHugh). In a discussion between O'Malley and O'Dowd without Fitzgibbon present, it is revealed that O’Malley was sent by the bishop to take charge of the affairs of the parish, but that Fitzgibbon is to remain as pastor. To spare Fitzgibbon’s feelings, the older pastor is kept unaware of this arrangement and believes that O’Malley is simply his assistant.
A series of events in the first half of the movie highlight the differences between O’Malley and Fitzgibbon’s styles, as they deal with events like a parishioner being evicted and a young woman named Carol James (Jean Heather) coming to the church having run away from home. The most consequential difference of opinion between O’Malley and Fitzgibbon arises in their handling of the youth of the church, many of whom are consistently getting into trouble with the law in a gang led by Tony Scaponi (Stanley Clements). Fitzgibbon is inclined to look the other way, siding with the boys because of their frequent church attendance. O’Malley instead seeks to make inroads into the boys’ lives, befriending Scaponi and eventually using this connection to convince the boys, against some initial reluctance, to become a church choir.
The noise of the practising choir annoys Fitzgibbon, who finally decides to go to the bishop and ask for O’Malley to be transferred away. In the course of the conversation, Fitzgibbon infers the bishop’s intention to put O’Malley in charge of the parish. To avoid an uncomfortable situation, instead of making his initial request, Fitzgibbon asks the bishop to put O’Malley in charge, and then, resigned to his fate of losing control over the church, he informs O’Malley of his new role.
Distressed, Fitzgibbon then runs away from the parish, leading to a search. He returns late at night, and as O’Malley puts the older priest to bed, the two begin to bond, discussing Fitzgibbon’s long-put-off desire to go to Ireland and see his mother, whom he's not seen in 45 years, since he left Ireland as a young priest to come to America, and who is now over 90. O’Malley puts Fitzgibbon to sleep with an Irish lullaby, “Too-ra-loo-ra-loo-ral”.
We now meet Jenny Tuffel (now Genevieve Linden) (Risë Stevens), an old girlfriend of O'Malley's whom he left in order to join the priesthood, but who has since risen to a highly successful acting and singing career. O'Malley and Jenny discuss their past, and he then watches from the side of the stage as she performs a number for her starring role as Carmen at the Metropolitan Opera.
O'Malley next pays a visit to Carol, who is now suspected of living in sin with Ted Haines Jr. (James Brown), the son of the church's mortgage-holder, Ted Haines Sr. (Gene Lockhart). On this visit, O’Malley describes to the young couple his calling in life to “go his way”, which to him means to follow after the joyous side of religion and lead others to do the same. He performs for them the song “Going My Way”, which he wrote on this theme.
The elements of the story now begin to come together. Jenny visits O’Malley at the church, sees the boys’ choir, and reads the sheet music of “Going My Way”. She, O'Malley, and Father O’Dowd devise a plan to rent out the Metropolitan, perform “Going My Way” with the choir and a full orchestra, and sell the rights to the song, thereby saving the church from its financial woes. The plan fails, as the music executive brought on to listen to the song does not believe that it will sell. As the executive (William Frawley) is leaving, the choir decides to make the most of its opportunity on the grand stage, and sings another song, "Swinging on a Star". The executive overhears the song and decides to buy it, providing enough money to pay off the church mortgage.
With the church affairs in order, O’Malley and Fitzgibbon begin to bond more closely, and even go out on the golf course together. Just as everything seems to have fallen into place, though, the parish church is damaged in a massive fire. At about the same time, O'Malley prepares to move on to a new assignment from the bishop. He leaves O’Dowd as Fitzgibbon’s new assistant, and puts Tony Scaponi in charge of the choir. On Christmas Eve the people gather in a temporary church, in a service that also serves as O'Malley's farewell. As a going away present to Fitzgibbon, O’Malley flies Fitzgibbon’s mother in from Ireland. As mother and son embrace for the first time in forty-five years, the choir sings “Too-ra-loo-ra-loo-ral”; Father O’Malley quietly slips away.
Production.
Filming locations included the following:
Reception.
According to "The New York Times", "Going My Way" was "the best" of Crosby's career, which is "saying a lot for a performer who has been one of the steadiest joys of the screen. But, in this Leo McCarey film...he has definitely found his sturdiest role to date." NYT's critic Bosley Crowther criticized the film's length while lauding Crosby, and noting that "he has been stunningly supported by Barry Fitzgerald, who plays one of the warmest characters the screen has ever known. As a matter of fact, it is a cruel slight to suggest that this is Mr. Crosby's show. It is his and Mr. Fitzgerald's together. And they make it one of the rare delights of the year."
Awards.
At the 17th Academy Awards, "Going My Way" was nominated for 10 Academy Awards, including two for Barry Fitzgerald, whose work on the film was nominated for both Best Actor and Best Supporting Actor. (Subsequently, the rules were changed to prevent a reoccurrence.) It won seven, including Best Picture.
In 2004, "Going My Way" was selected for preservation in the United States National Film Registry by the Library of Congress as being "culturally, historically, or aesthetically significant".
Adaptations.
"Going My Way" was adapted as a radio play for the January 8, 1945, broadcast of The Screen Guild Theater starring Bing Crosby, Barry Fitzgerald and Paul Lukas. It was also adapted for the May 3, 1954, broadcast of Lux Radio Theater with Barry Fitzgerald.
The film also inspired an hour-long comedy-drama of the same name during the 1962–63 television season. It starred Gene Kelly in the role of Father O'Malley. The series ran on ABC for one season.

</doc>
<doc id="42386" url="http://en.wikipedia.org/wiki?curid=42386" title="History of Benin">
History of Benin

The Republic of Benin was formed in 1960 when the colony of French Dahomey gained independence from France. Prior to this, the area that is now the Republic of Benin was divided largely between two coastal kingdoms, Dahomey and Porto-Novo, and a large area of various tribes in the north. The French assembled these various groups together into the colony of French Dahomey, which was part of the various colonies of French West Africa from 1904 until 1960. In the independence era, the republic was extremely unstable for the first decade and a half of existence, with multiple governments and multiple military coups. In 1972, Mathieu Kérékou led a military coup deposing the Presidential Council and appointing himself as the head of state, a position he held until 1991 when the country returned to multiparty elections. Since that point, the state has held multiple presidential and legislative elections and a number of different parties have become important.
Colonial Benin (formerly, République du Dahomey/Republic of Dahomey).
Dahomey was a French colony of and a part of French West Africa from 1904 to 1958. Under the French, a port was constructed at Cotonou, and railroads were built. School facilities were expanded by Roman Catholic missions. In 1946, Dahomey became an overseas territory with its own parliament and representation in the French national assembly. On December 4, 1958, it became the République du Dahomey, self-governing within the French Community. On 11 July 1960 France agreed to Dahomey becoming fully independent. Dahomey declared independence on 1 August 1960.
Post-colonial Benin.
Between 1960 and 1972, a succession of military coups brought about many changes of government. The last of these brought to power Major Mathieu Kérékou as the head of a regime professing strict Marxist-Leninist principles. By 1975 the Republic of Dahomey changed its name to the People's Republic of Benin. The People's Revolutionary Party of Benin (PRPB) remained in complete power until the beginning of the 1990s. Kérékou, encouraged by France and other democratic powers, convened a national conference that introduced a new democratic constitution and held presidential and legislative elections. Kérékou's principal opponent at the presidential poll, and the ultimate victor, was Prime Minister Nicéphore Soglo. Supporters of Soglo also secured a majority in the National Assembly. Benin was thus the first African country to effect successfully the transition from dictatorship to a pluralistic political system.
In the second round of National Assembly elections held in March 1995, Soglo's political vehicle, the Parti de la Renaissance du Benin, was the largest single party but lacked an overall majority. The success of a party formed by supporters of ex-president Kérékou, who had officially retired from active politics, allowed him to stand successfully at both the 1996 and 2001 presidential elections.
During the 2001 elections, however, alleged irregularities and dubious practices led to a boycott of the run-off poll by the main opposition candidates. The four top-ranking contenders following the first round presidential elections were Mathieu Kérékou (incumbent) 45.4%, Nicephore Soglo (former president) 27.1%, Adrien Houngbédji (National Assembly Speaker) 12.6%, and Bruno Amoussou (Minister of State) 8.6%. The second round balloting, originally scheduled for March 18, 2001, was postponed for days because both Soglo and Houngbedji withdrew, alleging electoral fraud. This left Kérékou to run against his own Minister of State, Amoussou, in what was termed a "friendly match."
In December 2002, Benin held its first municipal elections since before the institution of Marxism-Leninism. The process was smooth with the significant exception of the 12th district council for Cotonou, the contest that would ultimately determine who would be selected for the mayoralty of the capital city. That vote was marred by irregularities, and the electoral commission was forced to repeat that single election. Nicephore Soglo's Renaissance du Benin (RB) party won the new vote, paving the way for the former president to be elected Mayor of Cotonou by the new city council in February 2002.
National Assembly elections took place in March 2003 and were generally considered to be free and fair. Although there were some irregularities, these were not significant and did not greatly disrupt the proceedings or the results. These elections resulted in a loss of seats by RB—the primary opposition party. The other opposition parties, the Party for Democratic Renewal (PRD) led by the former Prime Minister Adrien Houngbedji and the Alliance Etoile (AE), joined the government coalition.
Former West African Development Bank Director Yayi Boni won the March 2006 election for the presidency in a field of 26 candidates. International observers including the United Nations, Economic Community of West African States (ECOWAS), and others called the election free, fair, and transparent. President Kérékou was barred from running under the 1990 constitution due to term and age limitations. President Yayi was inaugurated on April 6, 2006.
Benin held legislative elections on March 31, 2007, for the 83 seats in the National Assembly. The Force Cowrie for an Emerging Benin (FCBE), a coalition of parties, closely linked to President Yayi, won a plurality of the seats in the National Assembly, providing the president with considerable influence over the legislative agenda.

</doc>
<doc id="42387" url="http://en.wikipedia.org/wiki?curid=42387" title="Whistle">
Whistle

An aerodynamic whistle (or call) is a simple aerophone, an instrument which produces sound from a stream of gas, most commonly air. It may be mouth-operated, or powered by air pressure, steam, or other means. Whistles vary in size from a small slide whistle or nose flute type to a large multi-piped church organ.
Whistles have been around since early humans first carved out a gourd or branch and found they could make sound with it. Many present day musical instruments are inheritors. With the rise of more mechanical power, other forms of whistles have been developed. One characteristic of a whistle is that it creates a pure, or nearly pure, tone. There are many ways to create pure tones, but we restrict the descriptions here to what are called aerodynamic whistles. Strictly speaking, they are fluid mechanical whistles since they occur in gases, such as air or steam, as well as in liquids, such as water. The only difference between them is the fluid density and the sound speed. The word aerodynamic whistle will be retained here since it is in common use. The conversion of flow energy to sound comes from an interaction between a solid material and a fluid stream. The forces in some whistles are sufficient to set the solid material in motion. Classic examples are Aeolian tones that result in galloping power lines, or the Tacoma Narrows Bridge (galloping Gertie). Other examples are circular disks set into vibration. The whistles described in this article are in a subclass where only the fluid is in motion and there is no significant dependent motion of the interacting solid. Depending on the geometry there are two basic types of whistles, those that generate sound though oscillations of fluid mass flow and those that generate sound through oscillations of the force applied to the surrounding medium.
Early police whistles.
Night watchmen in Ancient China would blow into the tops of acorns to alert the towns to invading Mongolians, in the third century. 
Joseph Hudson set up J Hudson & Co in Birmingham, UK in 1870. With his younger brother James, he designed the 'Acme City' brass whistle. This became the first referee whistle used at association football matches during the 1878–79 Football Association Cup match between Nottingham Forest and Sheffield. Prior to the introduction of the whistle, handkerchiefs were used by the umpires to signal to the players.
In 1883 he began experimenting with pea-whistle designs that could produce an intense sound that could grab attention from over a mile away. His invention was discovered by accident, when he accidentally dropped his violin and it shattered on the floor. Observing how the discordant sound of the breaking strings travelled (trill effect), Hudson had the idea to put a pea in the whistle. Prior to this, whistles were much quieter, and were only thought of as musical instruments or toys for children. After observing the problems that local police were having with effectively communicating with rattles, he realised that his whistle designs could be used as an effective aid to their work.
Hudson demonstrated his whistle to Scotland Yard and was awarded his first contract in 1884. Both Ratchet rattles and whistles were used to call for back-up in areas where neighborhood beats overlapped, and following their success in London, the whistle was adopted by most police in the United Kingdom.
This police whistle monopoly gradually made Hudson the largest whistle manufacturer in the world, supplying police forces and other general services everywhere. His whistle is still used by many forces worldwide. His design, was improved as the 'Acme Thunderer', the first ever pea whistle, which remains the most used whistle in the world; for train guards, dog handlers and police officers.From the 1880s and 90s, J. Hudson & Co began facing greater competition, as other whistle manufacturing companies were established, including W. Dowler & Sons, J. Barrall, R. A. Walton, H. A. Ward and A. De Courcy & Co. In 1987, Ron Foxcroft released the Fox 40 pealess whistle, designed to replace the pea whistle and be more reliable.
Typical whistle sources and uses.
There are numerous sources and uses of aerodynamic whistles. They can be used for hunting, controlling dogs, as toys, for sports events, as musical instruments, for police or military use, as ship or lighthouse fog horns, as steam whistles on trains, for scheduling and emergency use in industrial settings such as mines, in fluidic circuits, in domestic settings such at the tea pot whistle, for reducing foam bubbles, and for human whistling. They also occur as accidental byproducts of fluid flow such as supersonic jets, cavity resonances, whistling telephone wires, and idling circular saws.
Types.
Wilson, et al., in their study of human whistling (see below), pointed out the importance of including the symmetry or asymmetry of the unstable flow in addition to the feedback classes listed below. Because of the close relationship of flow symmetry to the sound field generated, their concept was included here as part of the sound source description (monopole -symmetric and dipole - asymmetric).
The Monopole Whistle.
Whistles that generate sound through fluctuations of mass flow across a boundary are called monopole-like sources The figure on the right is an example of a small sphere whose volume is oscillating. Any arbitrary fixed boundary drawn around the sphere will show a net mass flow across it. If the sphere is small enough relative to the sound wavelength it is emitting, it can be called a point monopole. For this type of source, the sound is emitted radially so the sound field is the same in every direction and decays with the inverse square of the distance. Real whistles are only approximations to this idealized model. most have boundaries around them such as the Hole Tone described below. Nevertheless, much can be learned about whistles with the useful form of the sound power equation for the monopole. Using the definitions below, it can be expressed as
formula_1
The variables U and L are considered characteristic of the source and their correct choice is important.
The Dipole Whistle.
Whistles that generate sound through fluctuations of momentum or a force exerted on the surrounding medium are called dipole-like sources. The figure on the right is example of a small "rigid" sphere that is moving back and forth in a given direction. If the sphere is small with respect to the wavelength of the sound emitted, it can be called a point dipole. A force must be applied to the sphere in a specific direction to move it. The surrounding medium in the direction of motion is compressed to radiate sound, but the medium at right angles slides past the sphere and is not compressed. This results in a non-uniform sound field, unlike the monopole whistle. Real whistles are only approximations to this idealized model. Although tuning forks are not whistles, they create sound fields that are very close to the idealized dipole model. Nevertheless, much can be learned about whistles with the useful form of the sound power equation for the dipole. Using the definitions below, it can be expressed as
formula_2
Once again, U and L must be chosen correctly.
Feedback categories.
Aerodynamic whistles rely on the instability of flows and some mechanism downstream to send the disturbance back to the origin to continue the instability. There are several ways that feedback can occur.
Category I.
The sound from a Category I whistle is primarily a "byproduct" of source motion. In every case, there is a back reaction of the medium on the source (resistive and reactive impedance). One example of a weak back reaction is a vibrating iron body in air. The densities are so different the back reaction is often ignored. Back reactions of air on an air source or water on a water source can be different. In many cases, say turbulent jets, the sound created is random and it is convenient to consider the sound to be merely a byproduct of the flow. In this category the back reaction is insufficient to strongly control source motion, so whistles are not in this category.
Category II.
The back reaction of the medium is an "determinant" of source motion. In many important cases, linear thinking (small cause = small effect) is fallacious. Unstable fluid motion or the sound generated by it can feedback to the source and control it, much like audio feedback squeal. The basic requirements for a feedback controlled system are: (1) a source of steady power; (2) an amplification mechanism that can convert the steady power to time varying power; (3) a disturbance which supplies the oscillations to be amplified; (4) a means of generating sound or other oscillatory fluid motion; and (5) a means for feedback of that oscillatory motion as a disturbance to the input of the amplifier. Whistles are in this category. There are several ways to describe the feedback process.
Class 1.
The feedback is essentially incompressible; the speed of sound, although finite, is sufficiently large that it can be considered infinite. This action may be called near field or hydrodynamic feedback. There are a number Class I devices. The feedback that causes a stick in a water stream to vibrate, or a flag to wave, is due to hydrodynamic feedback.
Class II.
The feedback is compressible and depends on the speed of sound. This action may be called intermediate field, quasi-compressible feedback. A well known example is the hole tone (described below) where the feedback distance of a compressible (sound) wave is very small as compared to the wavelength of the sound.
Class III.
The feedback is compressible and depends on the speed of sound. This may be called far field or acoustic feedback. the feedback distance of a compressible wave can be an appreciable fraction of the wavelength of the sound. An example is the flute.
The figure on the right shows a block diagram of these feedback mechanisms. All aerodynamic whistles operate under one of the classes.
Stages.
There are feedback loops associated with many whistle operations and they are non-linear. Because of the nonlinearity, there can be several possible conditions for a given flow speed or geometry. Which of these is dominant is determined by the gain of the unstable flow at a particular frequency and whether the feedback is constructive or destructive. Early studies have used the term stage to describe the possible states of feedback as shown schematically in the figure on the right. As the flow speed increases (Reynolds number - Re) the frequency slowly climbs (nearly constant Strouhal number -St) but then the frequency jumps up abruptly to a higher stage. As the flow speed is later decreased the frequency slowly decreases but then jumps down abruptly to a lower stage. This pattern is called a "hysteresis loop". At any particular flow speed it is possible for one of several loops to be dominant, depending on how that speed was achieved. In a number of the whistles described here, Stage I is associated with the development of a single vortex in the distance between initiation of the flow instability and initiation of the feedback signal. Higher stages are associated with more vortices in that distance, hinting that this distance can be an important characteristic dimension. In several whistles, three stages have been identified (edge tone). By blowing hard in some musical wind instruments Stage I jumps to Stage II; it is called "overblowing".
Flow instability.
Flow instability is the engine for whistles. It converts steady energy to time dependent energy. Conversion of laminar flow to turbulent flow is a well known example. Small disturbances to the laminar flow cause the transition. An example is shown in the figure on the right with a water jet. The laminar two-dimensional jet amplifies small disturbances at the orifice to generate a "vortex street". For this case, the flow speed, in terms of Reynolds Number, was graphed against the disturbance frequency, in terms of the Strouhal Number for a variety of disturbance amplitudes to reveal the region of instability as shown in the figure on the left. The value of D in the figure represents the ratio of the lateral disturbance displacement to the nozzle width; the disturbances were minute. The disturbance was temporal in the example, but can also be spatial. Transition to turbulence can occur over a rough surface or over an irregular shape, such as an aircraft spoiler. All whistle mechanisms described here are created by temporal disturbances that are in one of the three classes. One important source of instability in a fluid is the presence of a velocity gradient or shear layer with an inflection point. Thus, fluid instability can be described as a three dimensional region with flow speed on one axis, disturbance amplitude on the second, and velocity profile on the third. In a whistle, the instability starts at some point in the three dimensional region and then moves along some path in that region as the local variables change. This makes the comprehensive understanding of whistle instability mechanisms very difficult.
Scaling.
Whistles come in all shapes and sizes, but their operation can be unified through the concepts of dynamic and geometric similarity. Nature knows nothing of the specific measurement systems we use; it cares only about ratios between the various forces, time scales, and the several dimensions. To compare them we need to take into account the established ratios that are relevant to whistle operation. Similarity is best exposed by determining a speed, U, that is characteristic of the dynamics, and a dimension, L, that is characteristic of the geometry. If these values are used in dimensionless numbers, such as those listed below, much understanding of the phenomenon can be achieved.
Strouhal number.
formula_3
The first number is the ratio of unsteady inertial forces to steady inertial forces. The number was named in honor of Vincenz Strouhal who first deduced the relationship between the vortex shedding frequency around a cylinder and the flow speed. The characteristic variables were the cylinder diameter L1, and the speed of the flow over it U. He found the number to be reasonably constant over given a Reynolds number range This number permits relationships to be developed between the different sizes and speeds. Now the Strouhal Number can be derived directly from the dimensionless form of the mass continuity equation. This equation may be referred to as a "fluid mechanical" Strouhal number in comparison with the second version which may be referred to as the "acoustical" Strouhal number. The first version is used for dynamic similarity of the fluid motion in whistles while the second version is used for dynamic similarity of the acoustical motion in whistles. Many whistles, especially those with Class III feedback, require use of both numbers (see (Monopole-Dipole Whistles). The acoustical Strouhal number is essentially the Helmholtz number with the formula_4 deleted.
Mach number.
formula_5
It is the ratio of the steady speed to the speed of sound. The number was named in honor of Ernst Mach who first studied (among other things) supersonic flow and shock waves. This number describes the range between flows that can be considered incompressible and flows where compressibility is important. Now the Mach number can be derived directly from the dimensionless form of the momentum equation.
Reynolds number.
formula_6
It is The ratio of the steady inertial forces to the steady viscous forces. The number was named in honor of Osborne Reynolds, an engineer who did pioneering studies on the transition of laminar to turbulent flow in pipes. Now the Reynolds number can be derived directly from the dimensionless form of the momentum equation.
Rossby number.
formula_7
It is the ratio of linear velocity to tangential velocity for swirl flows. The frequency is characteristic of the rotation rate of the flow. The number was named in honor of Carl-Gustav Rossby, a meteorologist who first described the large scale motions of the atmosphere in terms of fluid mechanics. He described the jet stream, and his number was first used to describe the motion associated with the Coriolis force in the atmosphere. Now the Rossby number can be derived directly from the dimensionless form of the momentum equation in curvilinear coordinates.
Dimensionless force.
formula_8 The ratio of the actual dynamic force to the steady momentum..
Dimensionless volumetric flow rate.
formula_9 The ratio of the dynamic volumetric flow rate to the steady volumetric flow rate.
Monopole-like whistles.
In these whistles, the flow instability is symmetric, often resulting in periodic ring vortices and the sound generation is associated with fluctuations of volumetric (mass) flow rates. The sound field is as close to the directivity of an actual monopole source as local geometry allows.
Hole tone (tea pot whistle, bird call).
The steady flow from a circular orifice can be converted to an oscillatory flow by adding a downstream plate with a circular hole aligned with the orifice. Small perturbations in the flow feedback to the orifice to cause a variable volumetric flow rate through the downstream hole because of the symmetry of the feedback. The disturbance in the jet is a symmetric vortex ring that moves at some speed slower than the mean jet speed until it encounters the hole and some fluid is forced through it, resulting in a monopole-like sound field in the half space outside. The oscillatory volumetric flow in the hole sends a wave back to the orifice to complete the feedback loop and causing a nearly pure tone. The figure on the right shows a schematic of the geometry. To invoke dynamic similarity, the characteristic speed in a study was chosen to be the average speed of the jet at the orifice U (deduced from measured volumetric flow rate) and the characteristic length was chosen to be the orifice diameter δ. Tests were made at five spacing distances h/δ from the orifice. Two scaling laws were used; the Strouhal number was graphed as a function of Reynolds number. The results are shown in the figure on the right. The frequency of the tone determined by how often a vortex encountered the hole while moving at some speed u less than the initial jet speed. Since the jet slowed as it proceeded toward the hole, the speed of the vortex slowed with it so the frequency and Strouhal number was greater at closer spacing. The Strouhal number data showed clearly the almost linear relation between frequency and initial jet speed. The number would be more constant if the actual jet speed at the hole could have been used as the characteristic speed. In four of the distances tested, there were jumps between Stage I and Stage II. The hysteresis loops are clear indications of the complex nature of the jet instability gain structure. The uniformity of the measured sound field for this whistle confirmed its monopole-like nature. Measurements of speed dependence of the sound level showed it to be very close to formula_10, further confirming the monopole nature of the source. At these speeds and spacings, the feedback was normally Class II, but reflecting surfaces as far away as three meters and with proper phasing, controlled the tone, converting the feedback to Class III. At higher Reynolds Numbers, the flow became chaotic resulting in broad-band sound. The hole tone has been rediscovered in the form of the tea pot whistle. They found that above a Reynolds number of 2000, hole tone operation occurred with symmetric vortex evolution and a constant Strouhal Number with Reynolds number. Comparison of their data with data in the figure suggests that the cylindrical enclosure between the two orifices raises the Strouhal number. There was no mention of frequency jumps. They noted that at lower speeds, the cylindrical volume responded as a Helmholtz resonator. Baron Rayleigh was aware of this whistle; it was called the "bird call" then. There seems to be evidence that events similar to the hole tone occur on aircraft landing gear covers with circular holes. In Australia, there is the "Tenterfield Fox Whistle" and the "Traditional Fox Whistle" that appear to operate as hole tones.
Corrugated pipe whistle.
This whistle has dozens of popular names. Pipes with sinusoidal variations of radius are often created to permit bending. Steady flow through the pipe at low Reynolds numbers results in a fluctuating volumetric flow rate that generates a monopole-like sound field at the pipe exit. Examples of such pipes are shown in figure on the right. The yellow plastic pipe is actually a child’s toy that sounds when the pipe is whirled around. The metal pipe shown was actually used in the Concorde cockpit to provide cooling air to the pilots, but its loud tone got it canceled. This whistle is similar in many respects to the hole tone, in particular the teapot whistle. It is subject to frequency jumps and hysteresis loops. There are numerous articles on the internet about this whistle and it has been studied. The characteristic speed is the mean flow through the pipe U and the characteristic length must be a multiple of the spacing between corrugations, nL, where n is an integer number and L is the distance between corrugations. At low speeds, the unstable interior flow needs to travel several corrugations to establish the feedback loop. As the speed increases, the loop can be established with fewer corrugations. Simple tests were performed on the yellow plastic tube. The Strouhal number,
formula_11 was used as the scaling factor. The highest frequency (7554 Hz) was found in the “overblown” condition and n was presumed as one corrugation. At the least flow rate, the frequency of 2452 Hz compared favorably to n=3. At intermediate flow rates, several non-harmonically related frequencies occurred simultaneously suggesting that several corrugations were involved in the sound generation. In the smaller metal tube, a predominant tone appeared at 6174 Hz and corresponded to n=2. A unique aspect of this whistle is that the internal flow carries both the unstable vortex downstream and the returning feedback signal upstream.
Pipe tone (Pfeifenton).
The unique feature of this whistle is that the tone sounds only with flow through the orifice from outside; it is an acoustical diode. A cylindrical cavity with a small circular, square-edged hole at one end and totally open at the other is known to generate a tone when air is passed through it. It is subject to frequency jumps and hysteresis loops similar to the hole tone. There appear to be two stages and the feedback is likely Class II if the tube is lshort. The fundamental tone occurs near formula_12, so one characteristic dimension is L, the length of the tube. The characteristic speed U is that of the flow through the hole. A monopole-like sound field is generated by volumetric flow rate oscillations. Karthik and Anderson have studied this phenomenon and concluded that symmetric vortex shedding on the cavity side is the driving agency. An example of this device is shown in the figure on the right; it had a 0.125 inch diameter hole, was 1.9 inches long, and 0.8 inches in diameter. The quarter wave resonance was calculated to be 1780 Hz, while the measured fundamental was 1625 Hz with detectable second and third harmonics. End corrections for radiation from the openings is needed to bring the two frequencies in consonance. To determine the end corrections, two additional dimensions are needed: the diameter of the orifice d1 and the diameter of the tube d2.
Hartmann, Galton whistles (stem jet).
The previous whistles occur at low flow speeds, this whistle occurs at very high speeds. When a subsonic jet impinges on a cavity, jet instability becomes part of the feedback loop as with the hole tone. When a supersonic jet impinges on a cavity, shock wave instability becomes part of the feedback loop. The figure on the right is one example of this whistle. A cylindrical cavity with one end open and facing the supersonic circular jet will result in extremely intense sound. The shapes in the figure represent the shock/expansion cells within the jet. A related configuration, called the "stem jet", has a central rod in the jet that extends to support and align the cavity. There are a number of other geometric variations, all of which operate in similar fashion. These devices have been studied, and reviewed by Raman. Here we look primarily at the Hartmann whistle. The shock cells of the jet interact with the shock in front of the cavity (the flow in the cavity being subsonic). Small symmetric disturbances in the jet stream are amplified as they proceed toward the cavity (similar in some respects to the hole tone) causing the shock in front of the cavity to oscillate. The shock front acts much like a piston source of high energy resulting in a monopole-like sound field. Again the volumetric flow is directional unlike the theoretical monopole. The sound field may be similar to that created by oscillatory flow from a pipe, except for presence of the supersonic jet structure which can strongly modify the directivity. The original equation of Hartmann is shown below.
formula_13
The diameter of the orifice and cavity is d, the distance between orifice and cavity is h, and the orifice pressure P was given in kilograms per meter squared. At the lower limit of h the second term disappears. In this case, the equation could have been reformatted in terms of the acoustical Strouhal Number as shown in the second equation above. The characteristic speed U at the nozzle is the sound speed formula_10. It is interesting that the number is very close to that found by Strouhal for flow over a cylinder. There are two characteristic length scales. Nozzle diameter d characterizes the sound power while the separation distance h characterizes the frequency. Comprehensive studies of this phenomenon have shown that the position of the cavity is critical in creating sound. The process has hysteresis loops and the frequencies are related to multiples of the quarter wavelength resonance of the cavity. After reformatting Hartmann’s formula, and using the new formulation above, an equation for sound power can be written.
formula_15
Since the characteristic speed U and sound speed are essentially the same, it can be rewritten as the second equation. This equation has the same structure as the one for the point monopole shown above. Although the amplitude factor A replaces the dimensionless volumetric flow rate in these equations, the speed dependence strongly confirms the monopole-like characteristics of the Hartmann whistle. A cousin to the Hartmann whistle is shown in the figure on the right, the "Galton whistle". Here the cavity is excited by an "annular jet" which oscillates symmetrically around the sharp edges of the cavity. It appears to be a circular version of the edge tone (discussed below) in which the symmetry of the otherwise dipole source of the edge tone is converted to a monopole source. Since it is highly likely that the oscillations are coherent around the periphery, there should be a fluctuating volumetric flow rate from the cavity with only a small net lateral force. Thus the source is yet another version of a monopole-like geometry; the volumetric flow rate is a cylindrical area between the jet and cavity.
Rijke tube.
There are a number of whistle phenomena in which heat plays a role. The temperature in a sound wave varies, but since it is so small normally it is common to neglect its effects. When amplification can occur a small variation can grow and have important influence on the sound field created. The most well known thermal whistle is the "Rijke Tube". Peter Rijke placed a heated a gauze material inside a vertical tube. Originally, the gauze was heated with a Bunsen burner; later, a wire grid was heated electrically. The heat transferred to the air in the tube sets it into near half-wave resonance if the gauze is placed below the midpoint of the tube as shown in the figure on the right. There is no theoretically optimum position, as the wave speed upward is the sound speed formula_10 plus u, the convection speed, while the wave speed downward is formula_10 minus u. Without a convection flow, the midpoint and the lower tube end are the best locations for heat transfer. With convection, a compromise position halfway between the two points is normally chosen which depends on the amount of heat added. One characteristic length associated with frequency is tube length L. Another characteristic length associated with sound power is αL, the position of the gauze. The characteristic speed must be the convection speed u at the heat source. For detailed study of the whistle, see Matveev. Since the first mode resonance is about half-wave, the sound field emitted from the tube is from two in-phase monopole-like sources, one at either end. A gas flame inside a tube can drive resonance; it was called a "singing flame". There is a reverse Rijke Tube when hot air passes through a cold grid.
Sondhauss and Taconis tubes.
The Sondhauss Tube is one of the early thermal tone generators; it was discovered in the glass blowing industry. A bulb with hot air is connected to one end of a tube that is at room temperature. When the cold tube is blown, tube acoustic oscillations occur. It was discussed by Baron Rayleigh in his Theory of Sound. This device is not considered a true whistle since the oscillations decay as the temperatures equalize. In analyzing this tube, Rayleigh noted that if heat had been added at the point of highest density in the sound wave, and subtracted at the point of lowest density, the vibration would be encouraged. Another thermal effect is called the Taconis oscillation. If a stainless steel tube has one side at room temperature and the other side in contact with liquid helium, spontaneous acoustic oscillations are observed. Again, the Sondhauss tube is not a true whistle.
Human whistle.
The number and variety of whistles created by humans is quite large, yet very little has been done to examine the physics of the process. There are three possible mechanisms: Helmholtz resonance, symmetric hole tone operation (monopole), or asymmetric edge tone operation (dipole). Wilson and his colleagues have simulated the human whistle by creating a cylinder 2.04 inches in diameter with a rounded orifice at one end that supplied a jet and another rounded orifice at the other end of the same diameter and on the same axis. The geometry was very similar to that of the tea pot whistle. After a number of tests at various speeds, orifice diameters, and orifice thicknesses, they concluded that the whistle was created by a Helmholtz resonance in the cylinder volume. There was enough data for one case in their study to calculate the Strouhal and Reynolds numbers. The results are shown in the figure on the right. The Strouhal number was essentially constant over the limited speed range, suggesting hole tone operation with Class I or Class II feedback. Their work indicated symmetric unstable vortex flow as would be expected but there was no mention of stages. In the study by Henrywood, it was noted that Helmholtz resonance could occur at low speeds. The flexibility of the mouth suggests that although a hole tone feedback mechanism is highly likely, the possibility of Helmholtz resonances in the mouth cavity and asymmetric edge tone actions with the teeth are considered possible.
Dipole-like whistles.
In these whistles, the flow instability is asymmetric, often resulting in rows of alternate vortices and the sound generation is associated with fluctuations of applied force. The sound field is as close to a dipole source as local geometry allows.
Aeolian tone.
The steady flow over a cylinder (or similar object) will generate vortex shedding and consequent sound. The early Greeks used this phenomenon to develop a harp and the sound was called an Aeolian tone after Aeolus, God of the Wind. Whistling telephone wires, automobile radio antennae, certain automobile front grilles, and smoke stacks are other examples of this tone. At very low Reynolds numbers the flow around a cylinder is stable, forming two fixed vortices behind it. As the speed increases, the flow, although laminar, becomes unstable and vortices are shed "alternately". Hydrodynamic feedback (Class I) influences the formation of new vortices and exerts a fluctuating force on the cylinder. The flow field is shown in the upper figure on the right (created by Gary Koopman). Theodor von Karman identified and analyzed the flow behind objects like a cylinder and since then this special flow has been called the "Karman vortex street". Vincenz Strouhal was the first to scientifically investigate the sound emitted by flow around a rigid cylinder. At low Reynolds numbers the tone was pure and the frequency was proportional to the steady flow speed U and inversely proportional to the cylinder diameter d. For many applications, the first equation below is often used. A review of the literature produced the figure on the right for the Strouhal number. At low Reynolds numbers the Strouhal number rises as inertial effects begin to dominate and then decays slightly at higher numbers. The second equation below is a best fit for the data between 1000<Re<100000.
formula_18
It is surprising how often oscillatory flow phenomenon have Strouhal Numbers in this range. For shape comparison, the strouhal number for an ellipse has been measured at 0.218, a cylinder at 0.188, a square at 0.160, and a triangle at 0.214. The characteristic dimension is that of the object lateral to the flow and the characteristic speed is that of the impinging flow. The second equation suggests that the Strouhal Number is a weak negative function of Reynolds number. This suggests that the dynamic similarity approximation is reasonable. The fluctuating force exerted on the cylinder is a result of the flow circulation around it caused by the alternate vortex separation as suggested in the third figure. The fact that the vortices are not directly behind the cylinder suggests that the force vector has both a lift and drag component resulting in lift and drag dipoles. An approximate way to relate the sound generated to the flow characteristics is to perturb the standard drag equation with velocity perturbations as shown in the upper equation below.(lift measurements for cylinders are generally not available). The upper equation is the modified drag equation with both drag component u and lift component v and the cross sectional area dL where d is the cylinder diameter and w is the length.
formula_19
Manipulation of the equation yields the lower two equations for the dipole sound power of both lift and drag. Each time a vortex is shed, the drag velocity fluctuation u has the same sign, but the lateral velocity fluctuation v, has opposite signs, since the vortex is shed on alternate sides. As a result The drag dipole would be expected to be twice the frequency of the lift dipole. Phillips found the lateral velocity fluctuations were two orders of magnitude greater than the longitudinal, so the lift dipole is 20 dB above the drag dipole. He found the drag dipole did occur at twice the frequency of the lift dipole. At higher speeds, the vortex separation may not be correlated over the entire length of the cylinder resulting in multiple essentially independent dipole sources and lower sound power. The lower figure on the right shows the correlation coefficient as a function of distance along the cylinder and is from the Etkin, et al. study.
Vortex meters.
Is there a use of Aeolian tone knowledge other than making musical instruments? There are several accurate flow meters that are designed to take advantage of the constancy of the Strouhal Number with Reynolds Number to provide a linear relationship between flow rate and measured frequency. They are called "vortex meters". A particular shaped object is placed within a pipe and a pressure sensor is embedded either in the pipe wall or in the inserted object. Although a number of shapes have been used, there are several that work well. The figure on the right shows data from a meter called the "Deltameter". The inserted shape was that of a trapezoid with the wider end facing upstream. The graph shows a nearly linear relationship with flow speed over nearly a 1000 to 1 range of Reynolds Numbers (12,530 to 1,181,000). Orifice plates as flow meters typically have a 5 to 1 speed range, while turbine meters may have up to 100 to 1 range. It should be noted that three dimensional (viscous) effects occur at low Reynolds numbers so dynamic similarity is not achieved there. At higher speeds the Strouhal Number is close to that for the Aeolian tone. The dependence of Strouhal Number on Reynolds Number for this confined geometry is slightly negative as was found also for the Aeolian tone.
Mountain vortex tone.
Photographs taken from space have shown alternate arrangements of clouds around mountains; The figure on the right shows an example. Does this type of event create periodic sound? The NOAA laboratories in Boulder, Colorado, were tasked with detecting the extremely low frequency sound of nuclear tests. They detected one and by triangulation determined it was occurring in the Aleutian chain. As the figure suggests, it was vortex shedding from a volcanic cone. There are numerous satellite photos available on the web showing this phenomena in many places of the world. These whistles generate enough sound to be detected but at frequencies below 1 Hz the are inaudible. Like the Aeolian tone, the feedback is Class I. Using Strouhal's number, it might be possible to estimate the wind velocities; they appear to be quite high.
Trailing edge tone.
The boundary layer on the airfoil of a glider is laminar and vortex shedding similar to that of a cylinder occurs at the trailing edge. The sound can be a nearly pure tone. The figure on the left shows a one-third octave band spectrum taken under a glider flyover; the tone is 15 dB above the broad band sound. The aircraft speed U was 51 m/sec (157 ft/sec) and the frequency was near 1400 Hz. Based on a Strouhal Number of 0.20, the characteristic dimension δ was calculated to be near ¼ inch; the boundary layer thickness. A dipole sound field was created at the trailing edge due to the fluctuating force exerted on it. At higher speeds on powered aircraft, the boundary layer on the airfoil is turbulent and more complex vortex shedding patterns have been observed. Since it is difficult to measure in flight, Hayden made static tests. The figure on the right shows an example. A boundary layer flow was created on both sides of a thin rigid flat plate which terminated with a square trailing edge. Note the nearly pure tone at 2000 Hz with a Strouhal number of 0.21 protruding above the turbulent sound spectrum. Once again the magic number of Strouhal appears. The characteristic speed was the mean speed of the jet, U and the characteristic dimension was chosen as the trailing edge thickness.t. The better characteristic dimension would have been the boundary layer thickness, but fortunately the two dimensions were almost the same. The measured sound field was clearly dipole-like (modified slightly by the plate presence). The lower figure on the right shows a number of turbulent sound spectra measured at various speeds. The frequencies were Strouhal number scaled with U and the sound levels were scaled with the dipole sound power rule of formula_10 over a speed range of 3 to 1. The data fit was quite good, confirming dynamic similarity and the dipole model. The slight discrepancy in level and frequency overlap suggests that both the dimensionless force and the Strouhal number had weak dependence on the Reynolds number. Another characteristic dimension is the airfoil chord. In these tests the jet width was sufficient to keep the vortex shedding coherent across it. On an airfoil there would be a correlation length less than the wingspan resulting in a number independent dipoles arrayed laterally. The sound power would be diminished somewhat. Since the dipole model is based on the time rate of change of the force, reduction of sound power might be accomplished by reducing that rate. One possible means would be for the opposite sides of the surface to gradually sense each other spatially prior to the trailing edge and thus reduce the rate at the edge. This might be done by a section of graduated porous or flexible materials.
Circular saw whistle.
An edge tone occurs when a jet impinges on a fixed surface. A trailing edge tone occurs when an exterior flow passes over a trailing edge. There is a whistle that is a combination of an edge tone and a trailing edge tone and might be called a "wake-edge tone". It occurs in rotating circular saws under idling conditions and may be called the "circular saw whistle". Under load conditions, blade vibration plays a role which is not addressed here. There have been several studies of the fundamental sound generating mechanisms of this whistle. A drawing of typical blade construction is shown in the figure on the right. Research has shown that the sound field is dipole with the primary axis perpendicular to the blade plane. The sources are fluctuating forces acting on each cutting blade. Bies determined that the characteristic speed was the blade velocity, formula_21, and the characteristic dimension was the tooth area. Other researchers used blade thickness as the characteristic dimension. Cho and Mote found that the Strouhal number formula_22 was between 0.1 and 0.2 where h was the blade thickness. Poblete, et al., found Strouhal numbers between 0.12 and 0.18. If the edge tone is relevant, perhaps the characteristic dimension should be the gap between the blades. The researchers deduced that the fluctuating force was proportional to formula_10, but the sound power was found to vary from formula_10 to formula_10. If the measurement bandwidth is broad and the measurement distance is out of the near field, there are two dynamic factors (Strouhal number and dimensionless force), that can cause the exponent to be less than six. Both the Deltameter and hole tone data show the Strouhal number is a weak negative function of Reynolds number, which is squared in the sound power equation. This would result in a reduced speed exponent. This factor is not likely to explain the large reduction in exponent however. The blade geometry was highly variable in the tests, so it is likely that the negative dependence of the dimensionless force on Reynolds number is the major factor. This whistle has two features that separate it from the other whistles described here. The first is that there are a multiplicity of these dipole sources arrayed around the periphery, that most likely are radiating at the same frequency, but incoherently. The second is that blade motion creates a steady, but rotating, pressure field at each blade. The rotating steady force creates a rotating dipole field which has an influence in the geometric near field. The feedback is Class I (hydrodynamic) and there is no indication that stages other than Stage 1 occur.
Ring tone.
The word "ring" here refers to something akin to that worn on the finger and not the sound from a cellphone. The flow from a circular orifice impinging on a toroidal ring of the same diameter as the orifice will result in a tone; it is called a "ring tone". It is similar to the hole tone described above except that because the plate was replaced by a ring a fundamental change in the resultant sound field occurs. .Small disturbances at the ring feed back to the orifice to be amplified by the flow instability (Class I). The unstable flow creates a set of symmetric (ring) vortices that later impinge on the physical ring. The passage of a vortex by the ring is shown schematically in the figure on the right in three steps. The flow vectors in the figure are merely suggestive of direction. When two vortices are equidistant from the ring, one being beyond and the other approaching, the net circulation around the ring is zero; the null point for the flow oscillation. Each vortex creates a circular (ring) flow field whose axis varies slightly from the vertical as it passes. The figure suggests that the main component of the force on the physical ring is in the direction of the jet flow. If the vortex is a true ring (all parts are in phase), a dipole sound field directed along the jet axis is created. The figure also suggests that there is a lateral component of force which can only be interpreted as a weak radial dipole. Experiments have been performed on the ring tone. The lower figure on the right shows the relationship of frequency to Reynolds number. If the Strouhal number were graphed in lieu of the frequency, it would have shown that contours were reasonably constant similar to those for the hole tone. Close examination of the data in the figure showed a slight negative dependence of Strouhal number on Reynolds number. It appears that this whistle has only two stages. The sound field was measured and clearly indicated a dipole whose axis was aligned with the jet axis. Since there were no reflecting surfaces near the source, the data also indicated that a weaker radial dipole component also existed. Such a field can only exist if there is a time delay at a distant point between each of the force components.
Inaudible whistles.
Most of the whistles described generate nearly pure tones that can be heard. The mountain tones discussed above are examples of tones that are inaudible because they are below the frequency range of humans. There are others whose sound levels are below the audible range of humans. For example, the vortex street behind a stick underwater might radiate at audible frequencies but not sufficiently to be heard by a Scuba diver. There are others that are both below audible frequencies and below audible levels. An unstable water jet, similar to the one shown in the flow instability section above, was not disturbed deliberately, but was allowed to rise to a free water surface. On contact with the surface, a slight jet asymmetry caused an unsymmetrical raised surface that fed back to the jet origin and began a process that looked like a weak version of the flow instability figure. If the jet was not powered, but warmer than the surrounding fluid, it would rise and when encountering the surface would generate a similar feedback system. Such a phenomenon was observed, but not photographed, in the Owens Valley of California. Early in the morning with no wind, thin clouds were observed to form above the valley. The distinction was that they were created alternately and moved in opposite directions away from a central location on the valley floor, suggesting the existence of an inaudible free convection whistle. The reason for including this type of whistle is that we tend to think that it is necessary for a forced jet flow to encounter a solid material to create a whistle. Perhaps it would be more correct to generalize the concept to a particular impedance mismatch rather than a solid object. The Hartmann whistle and the jet screech fits into this generalization. And also to any fluid motion as opposed to a forced flow.
Vortex whistle.
When the swirling flow within a pipe encounters the exit, it can become unstable. An example of the original system is shown in the figure on the left. The instability arises when there is a reversed flow on the axis. The axis of rotation itself precesses around the pipe axis resulting in a rotating force at the pipe exit and results in a rotating dipole sound field. Studies of this whistle have shown that dynamic similarity based on the pipe diameter d as the characteristic length scale, and inlet mean flow speed U as the characteristic speed was not achieved, as shown in the lower figure on the right. A more correct speed would be that characteristic of the swirl fd, where f is the precession (and sound) frequency, based on the Rossby number. To test the relevance of this new characteristic speed, the flow rate was increased and the frequency and level of the sound was measured. Using the dipole model, the calculated force was found to be nearly proportional to formula_10, confirming the correctness of the new characteristic speed. Measurements showed that the vortex whistle was created by a rotating asymmetric vortex which created a rotating force vector in the plane of the exit and a rotating dipole sound field. The phenomenon of swirl instability has been shown to occur in other situations. One was the flow separation on the upper side of delta-shaped airfoils of high speed aircraft (Concorde), The angle of attack of the leading edge resulted in a swirl flow that became unstable. Another is the flow within cyclone separators; the swirling flow there occurs in an annular region between two tubes. The flow reverses at the closed end of the outer tube and exits through the inner tube. Under certain conditions, the flow in the reversal region becomes unstable, resulting in a period rotating force on the outer tube. Periodic vibration of a cyclone separator would indicate vortex instability. Large centrifugal fans sometimes use radial inlet blades that can be rotated to control the flow into the fan; they create a swirling flow. At near shutoff, where the swirl is very high, "rotating blade stall" of the fan blades occurs. Although not researched, it is highly likely that swirl instability is the cause. The feedback is clearly hydrodynamic (Class I) and there is no indication that more than one stage occurs.
Swirl meter.
The method of creating swirl in the vortex whistle was considered the cause for lack of dynamic similarity, so the swirl was created in a pipe with a contraction having swirl blades followed by an expansion to create the required axial backflow. This was the vortex whistle in a pipe. Measurements made with this geometry, are shown in the figure on the right. As can be seen, dynamic similarity was achieved with both air and water. This whistle became a flow meter called the "swirlmeter". Its accuracy rivals that of the vortex shedding meters described above but has a higher pressure drop. The feedback is hydrodynamic (Class I) and only one stage was found.
Edge tone.
When a rectangular jet impinges on a sharp edged object such as a wedge, a feedback loop can be established resulting in a nearly pure tone. The figure on the right shows schematically the circulation of two vortices as they pass the wedge. This simple diagram suggests that there is a force applied to the wedge whose angle varies as the vortices pass. As found in the Aeolian tone, the vertical component (lift) is large and results in a dipole-like sound field at the wedge (shown in the lower figure) and a much weaker horizontal component (drag) at twice the frequency (not shown). The drag component may contribute as part of the driving force for musical instruments (discussed below). A seminal study by Powell of this phenomenon has exposed many details of the edge tone phenomenon. He showed that this whistle has three stages and the feedback loop was hydrodynamic (Class I). A semi-empirical equation for the frequency, developed by Curle, when converted to Strouhal Number, is
formula_27
This equation, applicable for formula_28, shows the mean speed U of the jet at the orifice as the characteristic speed and the distance h from orifice to the edge as the characteristic dimension. The integer n represents the various vortex modes. It also suggests that dynamic similarity is achieved to a first approximation; one deviation is that the speed at the wedge, which is less than that at the orifice, should be the characteristic speed. A weak negative Reynolds number effect is likely. The orifice width d also has some influence; it is related to vortex size and lateral correlation of the shedding process. The presence of a dipole sound field and a periodic force proportional to formula_10 was confirmed by Powell. Numerical simulations of the edge tone and extensive references can be found in a NASA report. The lower figure on the right may be called a "wake edge tone". If the preferred frequencies of the trailing edge instability match the preferred frequencies of the free edge tone, a stronger dipole sound should arise. There does not appear to be any research on this configuration.
Shallow cavity tone.
The study of sound generated by flow over cavities at high speed has been well funded by the federal government so a considerable amount of effort has been made. The problem relates to flow over aircraft cavities in flight such as bomb bays or wheel wells. Flow over a cavity in a surface can result in excitation of a feedback loop and nearly pure tones. Unlike the edge tone noted above, the cavity edge is typically square, but also can be an edge as part of a thin structural shell. Cavities can be separated into "shallow" or "deep" ones, the difference being that for deep cavities a Class III (acoustical) feedback path may be controlling. Shallow cavities are addressed here and are those in which the cavity length L is greater than the cavity depth D. At high speeds U, the flow is turbulent and in some studies the speed can be supersonic and the sound generated can be quite high level. One study has shown that several modes of oscillation (stages) can occur in a shallow cavity; the modes being related to the number of vortices in the distance L. For shorter cavities and lower Mach Numbers, there is a "shear-layer mode", while for longer cavities and higher Mach Numbers there is a "wake mode". The shear-layer mode is characterized well by the feedback process described by Rossiter. The wake mode is characterized instead by a large-scale vortex shedding with a Strouhal number independent of Mach number. There is an empirical equation for these data; it is called "Rossiter’s formula". Lee and others have shown it in Strouhal number form as
formula_30
The bracketed term includes two feedback loop speeds; the downstream speed is the speed of the vortices u and the upstream speed is that of soundformula_10. The various modes are described by an integer n with an empirical delay constant β (near 0.25). The integer n is closely related to the number of vortices en route to the edge. It is clear from shadowgraphs that the fluctuating force near the downstream edge is the sound source. Since the Mach number of the flow can be appreciable, refraction makes it difficult to determine the major axis of the dipole-like sound field. The preferred frequencies in shallow cavities are different from those for the edge tone.
Police whistle.
The title above will be retained since it is commonly used to describe whistles similar to those used by American police. There are a number of whistles that operate in the same manner as the police whistle and there are number of whistles that are used by police elsewhere that do not operate in the same manner as the police whistle. The London Metropolitan police use a linear whistle, more like a small recorder. Police whistles are commonly used by referees and umpires in sporting events. The cross section of a common whistle is shown in the figure on the right. The cavity is a closed end cylinder (3/4 inch diameter), but with the cylinder axis lateral to the jet axis. The orifice is 1/16 inch wide and the sharp edge is 1/4 inch from the jet orifice. When blown weakly, the sound is mostly broad band with a weak tone. When blown more forcefully, a strong tone is established near 2800 Hz and adjacent bands are at least 20 dB down. If the whistle is blown yet more forcefully, the level of the tone increases and the frequency increases only slightly suggesting Class I hydrodynamic feedback and operation only in Stage I. There does not appear to be any detailed research on police whistle operation. Considering the edge tone, noted above, one might expect several jumps in frequency, but none occur. This suggests that if multiple vortices exist in the unstable jet, they do not control. The diagram on the right suggests a plausible explanation of whistle operation. Within the cavity is an off-center vortex. In the upper drawing, the vortex center is near the jet; the nearby cavity flow is slower and the pressure is less than atmospheric so the jet is directed into the cavity. When the jet moves toward the cavity an additional thrust is given to the interior vertical flow which then rotates around and back to the edge. At that point, the cavity flow and the local pressure are sufficient to force the jet to move away from the cavity. An interior vortex of this type would explain why no frequency jumps occur. Since the excess fluid in the cavity must be discharged, the jet lateral movement must be considerably larger than that found in the edge tone; this is likely the reason for the high level sound. The flow over the edge results in an applied force and a dipole-like sound field. The characteristic speed must be U the jet exit speed. The characteristic dimension must be D, the cavity diameter. The frequency of the sound is closely related to the rotation rate of the cavity vortex. With a frequency near 2800 Hz the interior rotation rate must be very high. It is likely that the Rossby number formula_32 would be a valuable dynamic similarity number. The Boatswain's pipe is similar to the police whistle except the cavity is spherical creating a more complex vortex.
Levavasseur whistle.
This whistle is essentially the police whistle turned into a torus, magnifying its sound making potential. A cross-section through the middle of the whistle is shown in the figure on the right. An annular duct carries the fluid that creates the annular jet. The jet impinges on a sharp ended ring with two toroidal cavities on either side. In Levavasseur's patent, a structure is added downstream of the annular opening to act as a coupling horn to direct the sound. The sound generated is very intense. It appears that no scientific study has been done to elucidate the detailed feedback mechanisms of its operation, although it is clear that this whistle has Class I feedback mechanism, similar to the police whistle. The characteristic speed U is that of the annular jet. The characteristic dimension D is the cavity diameter and it appears that both cavities have similar dimensions. Again, the Rossby number Vformula_32 is likely to be a relevant dynamic number, since the operation of the inner cavity must be similar to that in the police whistle. It is likely that the vortex in the outer cavity is in anti-phase with the inner cavity to amplify jet displacement and thus the sound output.
Screech tone.
Strong tones can occur in both rectangular and circular jets when the pressure ratio is greater than the critical and the flow becomes supersonic on exit, resulting in a sequence of repetitive shock cells. These cells can be seen in the exhaust of rockets or jets operating with an afterburner. As with subsonic jets, these flows can be unstable. In a rectangular jet, the instability can show as asymmetric cell distortions. The asymmetry sends waves back to the nozzle which sets up a Class III feedback loop and a strong periodic dipole sound field; it is called "screech tone". Powell first described the phenomenon and because of application to military aircraft and potential structural fatigue, much subsequent work has been done. The sound field is sufficiently intense for it to appear on a shadowgraph as shown in the figure on the right (from M.G. Davies) for a rectangular supersonic jet. The dipole nature of the source is clear by the phase reversal on either side of the jet. There is lateral motion of the shock cells that gives the dipole its axis. Supersonic flows can be quite complex and some tentative explanations are available. As with hole and ring tones, these jets can be sensitive to local sound reflecting surfaces. The characteristic speed, U, is that in the exit plane, and the characteristic dimension L is the nozzle width, to which the cell dimensions are proportional. Circular supersonic jets also generate screech tones. In this case, however, there can be three "modes" of motion: symmetric (toroidal), asymmetric (sinuous), and helical. These whistles are unlike the others listed above; the sound is generated without interaction with a solid; it is truly an aerodynamic whistle.
Fluidic oscillators.
These devices are whistles that do not radiate sound, but are still aerodynamic whistles.
The upper figure on the right shows the basic arrangement of one version of the device. The circle on the left is the fluid source (air or liquid). A jet is formed that either goes into the upper or lower channel. The black lines are the feedback paths. If the fluid is in the lower channel, some fluid is fed back to the jet origin via the black tube and pushes the jet to the upper channel. There has been considerable development of these devices from circuit switches that are immune to electromagnetic pulses to more modern uses. One uniqueness of this whistle compared to the others described is that the length of the feedback path can be chosen arbitrarily. Although the channels are divided by a wedge shape, edge tone operation is avoided by the Coanda effect. The second figure on the right shows results from one study indicating a constant Strouhal number with Reynolds number. The data had been normalized to a reference value. In another study one set of their frequency data was recalculated in terms of Strouhal number and it was found to rise slowly and then be constant over a range of flow rates. Kim found a similar result; the Strouhal number increased with Reynolds number and then stayed constant as shown in the lower figure on the right. Another uniqueness of this whistle is that the feedback is sufficiently strong that the jet is bodily diverted instead of depending on flow instability vortex development to control it. The geometry of the device suggests that it is essentially a dipole source that operates in Stage I with Class I (hydrodynamic) feedback.
Monopole-dipole whistles.
There are a number of whistles that possess the characteristics of both monopole and dipole sound sources. In several of the whistles described below, the driving source is dipole (generally an edge tone) and the responding source is a monopole (generally a tube or cavity in proximity to the dipole). The fundamental difference of these whistles from those described above is that there are now two sets of characteristic variables. For the driving source, the characteristic speed is U, and the characteristic dimension is L1. For the responding source, the characteristic speed is formula_10 and the characteristic dimension is L2, typically the corrected cavity depth or tube length. The non dimensional descriptors for each of these are the "fluid mechanical" Strouhal number and the "acoustical" Strouhal number. The tie between these two numbers is the commonality of the frequency.
Jug whistle.
Blowing over the edge of a jug or bottle can create a nearly pure tone of low frequency. The driving force is the flow over the jug edge so one might expect an edge tone dipole sound field. In this case, The curvature and roundness of the edge makes a strong edge tone unlikely. Any periodicity at the edge is likely submerged in the Class III feedback from the jug volume. The unsteady edge flow sets up a classical Helmholtz resonator response in which the interior geometry and the jug neck determines the resultant frequency. A resonance equation is shown below.
formula_35
It is a transcendental equation where Ac is the cross sectional area of a cylindrical cavity of depth L. Ao is the area of the circular orifice of depth Lo, δe is the exterior end correction, δi is the interior end correction, and kL is the Helmholtz number (acoustical Strouhal Number with formula_4 added). A cylindrical cavity nine inches deep and 4.25 inches in diameter was connected to a circular orifice 1.375 inches in diameter and 1.375 inches deep. The measured frequency was close to 140 Hz. If the cavity acted as a one-quarter wavelength resonator, the frequency would have been 377 Hz; clearly not a longitudinal resonance. The equation above indicated 146 Hz and the Nielsen equation indicated 138 Hz. Clearly, the whistle was being driven by a cavity resonance. This is an example of a whistle being driven in edge tone fashion but the result is a monopole sound field.
Deep cavity tone.
Flow over a cavity that is considered "deep" can create a whistle similar to that over shallow cavities. "Deep" is generally distinguished from "shallow" by the cavity depth being greater than the width. There are two geometries that have been studied. The first geometry is flow exterior to the cavity such as on an aircraft. There are two characteristic dimensions (cavity width L associated with vortex development and cavity depth D associated with acoustical response). There are two characteristic speeds (flow speed U associated with vortex development and sound speed formula_10 associated with cavity response). It was found that the feedback was Class III and the Strouhal Numbers ranging from 0.3 to 0.4 were associated with a single vortex pattern (Stage I) across the gap while Strouhal numbers ranging from 0.6 to 0.9 were associated with two vortices across the gap (Stage II). The second geometry is flow in a duct with a side branch. Selamet and his colleagues have made extensive studies of whistle phenomena in ducts with side branches that are closed at one end. For these studies, The cavity depth was L and D was the side branch diameter. The "fluid mechanical" Strouhal and "acoustical" Strouhal numbers were
formula_38
An arbitrary constant β was used to represent the impedance at the junction of the side branch with the duct. n was an integer representing the stage number. They noted that the Strouhal number remained constant with increase of speed.
Pipe organ.
The pipe organ is another example of a potentially dipole sound source being driven as a monopole source. An air jet is directed at a sharp edge setting up flow oscillations as in the edge tone. The edge is part of a generally cylindrical tube of length L. An example is shown in the figure on the right. The unstable jet drives fluid alternately into the tube and out. The streamlines clearly are distorted from those of the free edge tone. There is a stagnation point opposite the source. The dashed lines, colored in red, are those most strongly modified. The red streamlines in the tube are now augmented by the oscillatory flow in the tube, a superposition of resistive and reactive dipole flow and resistive acoustic flow. The tube length determines whether the tube acoustic pressure or velocity is the dominant influence on the frequency of the tube. Simple models of organ pipe resonance is based on open-open pipe resonance (formula_39 but corrections must be made to take into account that one end of the pipe radiates into the surrounding medium and the other radiates through a slit with a jet flow. Boelkes and Hoffmann have made measurements of end correction for open-open tubes and derived the relation δ=0.33D. This cannot be exact since the driving end is not open. The radiation ±impedance at the driving end should move the tube toward aformula_40 condition, further lowering the frequency. Since there are two coupled systems, so there are two characteristics scales. For the pipe component, the characteristic dimension is L and the characteristic speed is formula_10. For the edge tone component, the characteristic dimension is the orifice to edge distance h and the characteristic speed is that of the jet U. It would seem that the maximum oscillatory gain of the system would occur when the preferred pipe frequency matches the preferred edge tone frequency with suitable phase. This relationship expressed in terms of Strouhal Numbers is:
formula_42
If dynamic similarity holds for both resonances, the latter equation suggests how organ pipes are scaled. The apparent simplicity of the equation hides important variable factors such as the effective pipe length formula_43 where δ1 is correction for the open end and δ2 is the correction for the end near the jet. The jet disturbance (vortex) speed from orifice to edge will vary with mean speed U, edge distance h, and slit width d as suggested in the Edge Tone section. The Strouhal relationship suggests that the jet Mach number and the ratio of effective pipe length to the edge distance are important in a first approximation. Normal pipe operation would be a monopole sound source in Stage I with Class III feedback.
Flutes, recorders and piccolos.
A number of musical instruments, other than the pipe organ, are based on the edge tone phenomenon, he most common of which are the flute, the piccolo (a small version of the flute), and the recorder. The flute can be blown lateral to the instrument or at the end as the other ones are. A native end blown flute is shown in the figure. They are all subject to frequency jumps when overblown, suggesting the dipole-monopole relationship. The monopole aspects are relatively fixed. The characteristic dimension of the tube, L2, is fixed; the characteristic speed,formula_10, is fixed. The effective length of the tube is fixed since the radiation impedances at each end are fixed. Unlike the pipe organ, however, these instruments have side ports to change the resonance frequency and thus the acoustical Strouhal number. The dipole aspects are also relatively fixed. The jet orifice dimension and the distance to the edge, h is fixed. Although the jet speed U can vary, the fluid mechanical Strouhal number is relatively constant and normally operates in Stage I. When there is phase coherent gain of the two aspects, they operate as Class III monopole sources. The efficiency of the monopole radiation is considerably greater than that of the dipole so the dipole pattern is not noticed, The details of system gain and interaction between these two dynamic systems is yet to be fully uncovered. It is a testimony to the skills of early instrument makers that they were able to achieve the right port sizes and positions for a given note without scientific measurement instruments.
Singing Sand.
For many years, people have heard tones from the motion of sand, mostly on sand dunes. In many cases, the tune was akin to a whistle in that it could be at a single frequency. In most cases, the wind over the peak of a dune sets the sand on the dune into motion, and it is that motion that generates the sound. In the recent past a number of researchers have attempted to explain the origin of the sound. One might consider this source an aerodynamic whistle since it is wind caused and one proposal is that the sand moves as an unstable fluidized sand/air mixture. There are several other theories, but the aerodynamic whistle possibility is not correct since it can occur by simple mechanical motion of the sand. It is likely a stick/slip mechanism which would be a dipole like source rather than a volumetric (monopole) oscillation of the sand particles.

</doc>
<doc id="42388" url="http://en.wikipedia.org/wiki?curid=42388" title="History of Bermuda">
History of Bermuda

Initial discovery.
Bermuda was discovered by Juan de Bermudez in 1505.
The island is shown as "La Bermuda" in Peter Martyr's "Legatio Babylonica" (1511). Bermudez returned again in 1515, with the chronicler Oviedo y Valdés. Oviedo's account of the second visit (published in 1526) records that they made no attempt to land because of weather.
In 1609, Sir George Somers set sail aboard the "Sea Venture," the new flagship of the Virginia Company, leading a fleet of nine vessels, loaded with provisions and settlers for the new English colony of Jamestown, in Virginia. The fleet was caught in a storm, and the Sea Venture was separated and began to flounder. When the reefs to the East of Bermuda were spotted, the ship was deliberately driven on them to prevent its sinking, thereby saving all aboard (150 sailors and settlers, and one dog). The survivors spent ten months on Bermuda. Several were lost-at-sea when the Sea Venture's longboat was rigged with a mast and sent in search of Jamestown. Neither it nor its crew were ever seen again. The remainder built two new ships: the Deliverance, largely from the material stripped from the Sea Venture (which sat high-and-dry on the reef, and was still being cannibalised in 1612 – its guns were used to arm a fort) and the Patience. The latter was made necessary by the food stores the survivors had begun to collect and stockpile in Bermuda, and which could not be accommodated aboard the Deliverance. It was built almost entirely from material sourced on the islands. When the two new vessels were complete, most of the survivors set sail, completing their journey to Jamestown.
They arrived there only to find the colony's population almost annihilated by the Starving Time, which had left only 60 survivors out of the 500 who had preceded them, and most of these survivors were sick or dying. The food the Sea Venture survivors brought with them was woefully insufficient, and the colony seemed unviable. It was decided to abandon it, and to return everyone to England. Loaded aboard the two ships, they were prevented from making this evacuation by the timely arrival of another relief fleet, bearing Governor Lord De La Warre, among others. The Sea Venture survivors had brought pork from the pigs that had been found wild on the island, which had presumably been left by previous visitors. This led the Jamestown colonists to refer to "Bermuda Hogs" as a form of currency. Somers returned to Bermuda with the Patience to obtain more food supplies, but died there from a "surfeit of pork". The Patience, captained by his nephew, Matthew Somers, returned to England, instead of Virginia. Somers left three volunteers – Carter, Chard and Waters – behind on Bermuda (two when the Deliverance and Patience had departed, and the third following the Patience's return) to maintain the claim of the island for the England, leaving the Virginia Company in possession of the island. As a result, Bermuda has been continuously inhabited since the wrecking of the Sea Venture, and claims its origin from that date, and not the official settlement of 1612.
Returning to Somers' hometown of Lyme Regis, in Dorset, his body (which had been pickled in a barrel) was landed via "The Cobb", the notable breakwater which protects town's harbour. His heart, however, was left buried on what would subsequently also be known as "The Somers Isles". After reaching England, the reports of the survivors of the "Sea Venture" aroused great interest about Bermuda. Accounts were published by two survivors, William Strachey and Sylvester Jordain. Two years later, in 1612, the Virginia Company's Royal Charter was officially extended to include the island, and a party of 60 settlers was sent, under the command of Sir Richard Moore, the island's first governor. Joining the three men left behind by the "Deliverance" and the "Patience" (who had taken up residence on Smith's Island), they founded and commenced construction of the town of St. George.
Bermuda struggled throughout the following seven decades to develop a viable economy. The Virginia Company, finding the colony unprofitable, briefly handed its administration to the Crown in 1614. The following year, 1615, King James I granted a charter to a new company, the Somers Isles Company, formed by the same shareholders, which ran the colony until it was dissolved in 1684 (The Virginia Company itself was dissolved after its charter was revoked in 1624). Representative government was introduced to Bermuda in 1620, when its House of Assembly held its first session, and it became a self-governing colony.
Early colony.
Bermuda was divided into nine equally-sized administrative areas. These comprised one public territory (today known as St. George's) and eight "tribes" (today known as "parishes"). These "tribes" were areas of land partitioned off to the "adventurers" (investors) of the Company – Devonshire, Hamilton, Paget, Pembroke, Sandys, Smith's, Southampton and Warwick (thus far, this usage of the word "tribes" is unique to the Bermuda example).
Initially, the colony grew tobacco as its only crop. The Company repeatedly advised more variety, not only because of the risks involved in a single-crop economy, but also because the Bermuda-grown tobacco was of particularly low quality (the Company was frequently forced to burn the supply that arrived back in England). It would take Bermuda some time to move away from this, especially as tobacco was the main form of currency.
Agriculture was not a profitable business for Bermudians in any case. The land area under cultivation was so small (especially by comparison to the plots granted settlers in Virginia), that fields could not be allowed to lie fallow, and farmers attempted to produce three crops each year. Islanders quickly turned to shipbuilding and maritime trades, but the Company, which gained its profits only from the land under cultivation, forbade the construction of any vessels without its license. Its interference in Bermudians livelihood would lead to its dissolution in 1684.
Indentured Servitude and Slavery in 17th Century Bermuda.
The first slaves were brought to Bermuda soon after the colony was established. Despite this, Bermuda's 17th Century agricultural economy did not become dependent on slavery. Unlike the plantation economies that developed English colonies in the southeast region of North America and in the West Indies, the of indentured servitude, which lasted in Bermuda until 1684, ensured a large supply of cheap labour. As a result, Bermuda's white Anglo-Saxon population remained the majority into the 18th Century despite a continuous influx of Latin American and African Blacks, Native Americans, Irish and Scots. The first Blacks to come to Bermuda in numbers were free West Indians, who emigrated from territories taken from Spain. They worked under seven years indenture, as did most English settlers, to repay the Company for the cost of their transport. As the size of the Black population grew, however, many attempts were made to reduce it. The terms of indenture for Blacks were successively raised to 99 years. Many of the Black slaves brought to Bermuda arrived as part of the cargoes seized by Bermudian privateers.
Slaves could be obtained by sale or purchase, auction debt, legal seizure or by gift. The price of a slave depended on demand. Throughout the 17th century Black children sold for £8, women from £10 to £20, and able bodied Black and Indian men for around £26. Blacks and Indians never willingly accepted their status as slaves and seized any available opportunity to escape or rebel. It was not easy to escape because of the size of the island and the nearest land being more than 700 mi away, but still slaves ran off from their masters and hid in the caves along Bermuda's coast. Others sought to plot against their masters. One such plot occurred in 1656 when a dozen Black men, led by William Force, a free Black man plotted to murder their English masters. As the appointed night arrived for the uprising, two of the slaves lost their nerve and reported the conspiracy to authorities. The conspirators were rounded up and tried by court martial. Two were hung and Force was later sent to the Bahamas with most of the island's other free blacks. In 1673 15 Blacks conspired to kill their masters, Again, one of the conspirators lost his nerve and reported the conspiracy. He was granted his freedom, five were branded, had their noses slit, and were whipped before being executed. The other conspirators were branded and whipped. This conspiracy resulted in the passage, in 1674, of more stringent laws effecting a slave's freedom of movement. A slave found off his estate without a ticket from his owner could be beaten with a rod or whip. A second offense would result in an ear being cut off. Offending for a third time resulted in being whipped until the skin was broken and being branded.
The local government attempted to legislate the emigration of free blacks, and during times of war, with food supplies scarce, it was considered patriotic to export horses and slaves. The first two slaves brought into the Island, a Black and a Native American, had been sought for their skills in pearl diving, but Bermuda proved to have no pearls. Slaves were also brought directly from Africa, and in large numbers from North America, especially from New England, where various Algonquian peoples were falling victim to English expansion. Native American slaves were brought in large numbers possibly from as far as Mexico. Native American slaves were reportedly preferred as house servants as they proved less troublesome than the Blacks and Irish, who were constantly fomenting rebellion.
Bermuda had actually tended towards the Royalist side in the English Civil War, but largely escaped the effects of the conflict, and the aftermath of the Parliamentary forces' victory. However, in the 1650s, following Cromwell's adventures in Ireland, and his attempt to force his protectorship on independent Scotland, Irish prisoners-of-war (POW) and ethnically-cleansed civilians, and smaller numbers of Scots POWs, were also sent to Bermuda. 
The English overlords of Ireland had used forced emigration as a way of pacifying Ireland since the start of the century, but the Cromwellian invasion gave vent to a holocaust in Ireland. Between 1641 and 1652, over 550,000 Irish were killed by the English. 300,000 were sold as slaves, and the Irish population of Ireland fell from 1,466,000 to 616,000. Between 1652 and 1659, another 50,000 Irish men, women and children were sent to the West Indies, Virginia and Bermuda. 
After the uncovering of a coup-plot by Irish and Black slaves, however, the import of further Irish slaves was banned. The slave trade would be outlawed in Bermuda in 1807, and all slaves were freed in 1834. At the end of the 17th century, whites, whether free or enslaved, composed the majority of Bermuda's population. Blacks and Native Americans were both small minorities. They combined, however, absorbing the Irish and Scots, and no small part of the White English bloodline, to be described as a single demographic group a century later, with the Bermuda's population being divided into White and Black Bermudians. As 10,000 Bermudians had emigrated, prior to American independence, most of them White, this left Blacks with a slight majority. Portuguese immigration, which began with a shipload of Madeiran families in the 1840s has been offset by sustained immigration from the West Indies which began at the end of the 19th century. Today, about 60% of Bermudians are described as being of African descent, although many may have greater European ancestry, and almost all Bermudians would be able to easily find ancestors and relatives of either African or European descent.
As Bermuda's primary industry became maritime, following the 1684 removal of the impediments placed by the Somers Isles Company, most Bermudian slaves worked in shipbuilding and seafaring, or, in the case of the most unfortunate, in raking salt in the Turks Islands.
Bermuda, salt and the Turks Islands.
After the elimination of their indigenous population by Spanish slavers, the "Turks Islands", or "Salt Islands", were not fully colonised until 1681, when salt collectors from Bermuda built the first permanent settlement on Grand Turk Island. The salt collectors were drawn by the shallow waters around the islands that made salt mining a much easier process than in Bermuda. They occupied the Turks only seasonally, for six months a year, however, returning to Bermuda when it was no longer viable to rake salt. Their colonization established the English (subsequently, "British") dominance of the archipelago that has lasted to the present day. The Bermudians destroyed the local habitat in order to develop the salt industry that became the central pillar of Bermuda's economy, felling huge numbers of trees to discourage rainfall that would adversely affect their operation. This deforestation, a foretaste of the deforestation of Bermuda by shipbuilding a century before the cedar blight, has yet to be repaired. Most of the salt mined in the Turks and Caicos Islands was sold through Bermudian merchant houses on the American seaboard, including in New England and Newfoundland where it was used for preserving cod. Bermudian vessels carried salted cod on their returns to Bermuda, establishing it as a traditional part of the Bermudian diet (at least on Sundays).
Bermuda spent much of the 18th century in a protracted legal battle with the Bahamas (which had itself been colonised by Bermudians in 1647) over the Turks Islands. Under British law, no colony could hold colonies of its own. The Turks Islands were not recognised by Britain either as a colony in its own right, or as a part of Bermuda. They were held to be, like rivers in Britain, for the common use. As a result, there was a great deal of political turmoil surrounding the ownership of the Turks (and Caicos).
When the Bermudian sloop "Seaflower" was seized by the Bahamians in 1701, the response of Bermuda Governor Bennett was to issue letters of marque to Bermudian Privateers. In 1706, Spanish and French forces ousted the Bermudians, but were driven out themselves three years later by a Bermudian privateer under the command of Captain Lewis Middleton in what was probably Bermuda's only independent military operation. His ship, the "Rose", attacked a Spanish and a French privateer holding a captive English vessel. Defeating the two enemy vessels, the "Rose" then cleared out the thirty-man garrison left by the Spanish and French.
The struggle with the Bahamas began in earnest in 1766, when the King's representative in the Bahamas, Mr Symmer, on his own authority, wrote a constitution which legislated for and taxed the Bermudians on the Turks. The Secretary of State, Lord Hillsborough, for the Crown, issued orders that the Bermudian activities on the Turks should not be obstructed or restrained in any way. As a result of this order, Symmer's constitution was dissolved. The Bermudians on the Turks appointed commissioners to govern themselves, with the assent of the King's local agent. They drew up regulations for good government, but the Bahamian governor, William Shirley, drew up his own regulations for the Turks and ordered that no one might work at salt raking who had not signed assent to his regulations.
Following this, a raker was arrested and the salt pans were seized and divided by force. The Bahamas government attempted to appoint judicial authorities for the Turks in 1768, but these were refused by the Bermudians. In 1773 the Bahamian government passed an act attempting to tax the salt produced in the Turks, but the Bermudians refused to pay it. In 1774, the Bahamians passed another, similar act, and this they submitted for the Crown's assent. The Crown passed this act on to the Bermudian government which objected to it, and which rejected Bahamian jurisdiction over the Turks. The Crown, as a consequence, refused assent of the Act as applied to include the Turks, and, in the form in which it finally passed, the Bahamas, but not the Turks, were included.
The Bermudians on the Turks continued to be governed under their own regulations, with the assent of the royal agent, until 1780, when a more formal version of those regulations was submitted for the assent of the Crown, which was given. Those regulations, issued as a royal order, stated that all British subjects had the right ("free liberty") to rake and gather salt on the Turks, providing that they conformed to the regulations, which expressly rejected Bahamian jurisdiction over the Turks. Despite this refutation by a higher authority of their right to impinge upon Bermudian activities on the Turks, the Bahamian government continued to harass the Bermudians (unsurprisingly, given the lucrativeness of the Turks salt trade).
Although the salt industry on the Turks had largely been a Bermudian preserve, it had been seen throughout the 17th century as the right of all British subjects to rake there, and small numbers of Bahamians had been involved. In 1783, the French had landed a force on Grand Turk which a British force of 100 men, under then-Captain Horatio Nelson, had been unable to dislodge, but which was soon withdrawn.
Following this, the Bahamians were slow to return to the Turks, while the Bermudians quickly resumed salt production, sending sixty to seventy-five ships to the Turks each year, during the six months that salt could be raked. Nearly a thousand Bermudians spent part of the year on the Turks engaged in salt production, and the industry became more productive.
The Bahamas, meanwhile, was incurring considerable expense in absorbing loyalist refugees from the now-independent American colonies, and returned to the idea of taxing Turks salt for the needed funds. The Bahamian government ordered that all ships bound for the Turk Islands obtain a license at Nassau first. The Bermudians refused to do this. Following this, Bahamian authorities seized the Bermuda sloops "Friendship" and "Fanny" in 1786. Shortly after, three Bermudian vessels were seized at Grand Caicos, with $35,000 worth of goods salvaged from a French ship. French privateers were becoming a menace to Bermudian operations in the area, at the time, but the Bahamians were their primary concern.
The Bahamian government re-introduced a tax on salt from the Turks, annexed them to the Bahamas, and created a seat in the Bahamian parliament to represent them. The Bermudians refused these efforts also, but the continual pressure from the Bahamians had a negative effect on the salt industry. In 1806, the Bermudian customs authorities went some way toward acknowledging the Bahamian annexation when it ceased to allow free exchange between the Turks and Bermuda (this affected many enslaved Bermudians, who, like the free ones, had occupied the Turks only seasonally, returning to their homes in Bermuda after the year's raking had finished).
That same year, French privateers attacked the Turks, burning ships and absconding with a large sloop. The Bahamians refused to help, and the Admiralty in Jamaica claimed the Turks were beyond its jurisdiction. Two hurricanes, the first in August 1813, the second in October 1815, destroyed more than two hundred buildings and significant salt stores; and sank many vessels. By 1815, the United States, the primary client for Turks salt, had been at war with Britain (and hence Bermuda) for three years, and had established other sources of salt.
With the destruction wrought by the storm, and the loss of market, many Bermudians abandoned the Turks, and those remaining were so distraught that they welcomed the visit of the Bahamian governor in 1819. The British government eventually assigned political control to the Bahamas, which the Turks and Caicos remained a part of until the 1840s.
One Bermudian salt raker, Mary Prince, however, was to leave a scathing record of Bermuda's activities there in "The History of Mary Prince", a book which helped to propel the abolitionist cause to the 1834 emancipation of slaves throughout the Empire.
Shipbuilding and the maritime economy.
Due to the islands' isolation, for many years Bermuda remained an outpost of 17th-century British civilization, with an economy based on the use of the islands' Bermuda cedar ("Juniperus bermudiana") trees for shipbuilding, and Bermudians' control of the Turks Islands, and their salt trade. Especially as its control of the Turks became threatened, Bermuda's mariners also diversified their trade to include activities such as whaling and privateering.
Privateering.
Bermudians turned from their failed agricultural economy to the sea after the 1684 dissolution of the Somers Isles Company. With a total landmass of 21 sqmi, and lacking any natural resources, other than the Bermuda cedar, the colonists applied themselves fully to the maritime trades, developing the speedy Bermuda sloop, which was well suited both to commerce and to commerce raiding. Bermudian merchant vessels turned to privateering at every opportunity, during the 18th Century, preying on the shipping of Spain, France and other nations during a series of wars. They typically left Bermuda with very large crews. This advantage in manpower was vital in seizing larger vessels, which themselves often lacked enough crewmembers to put up a strong defence. The extra crew men were also useful as prize crews for returning captured vessels. Despite close links to the American colonies (and the material aid provided the continental rebels in the form of a hundred barrels of stolen gunpowder), Bermudian privateers turned as aggressively on American shipping during the American War of Independence. An American naval captain, ordered to take his ship out of Boston Harbour to eliminate a pair of Bermudian privateering vessels, which had been picking off vessels missed by the Royal Navy, returned frustrated, saying "the Bermudians sailed their ships two feet for every one of ours". The only attack on Bermuda during the war was carried out by two sloops captained by a pair of Bermudian-born brothers (they damaged a fort and spiked its guns before retreating). It greatly surprised the Americans to discover that the crews of Bermudian privateers included Black slaves, as, with limited manpower, Bermuda had legislated that a part of all Bermudian crews must be made up of Blacks. In fact, when the Bermudian privateer "Regulator" was captured, virtually all of her crew were found to be Black slaves. Authorities in Boston offered these men their freedom, but all 70 elected to be treated as Prisoners of War. Sent to New York on the sloop "Duxbury", they seized the vessel and sailed it back to Bermuda. The American War of 1812 was to be the encore of Bermudian privateering, which had died out after the 1790s, due partly to the buildup of the naval base in Bermuda, which reduced the Admiralty's reliance on privateers in the western Atlantic, and partly to successful American legal suits, and claims for damages pressed against British privateers, a large portion of which were aimed squarely at the Bermudians. During the course of the American War of 1812, Bermudian privateers were to capture 298 ships (the total captures by "all" British naval and privateering vessels between the Great Lakes and the West Indies was 1,593 vessels).
Bermuda and the American War of Independence.
American independence was to lead to tremendous changes for Bermuda. Prior to the war, with no useful landmass or natural resources, Bermuda was largely ignored and left to its own devices by the London government.
This ensured that the guiding hands on shaping the colony's society and economy were Bermudian ones. Although the British Government retained theoretical control via the appointed Governor, the real power in Bermuda remained with the wealthy Bermudian merchant families who dominated the economy, and filled the benches of the House of Assembly and the Privy Council, with the President of the Privy Council being undoubtedly the Bermudian with the greatest political power.
The same lack of economic opportunities within Bermuda had led islanders to abandon agriculture following the dissolution of the Somers Isles Company in 1684, and turn wholeheartedly towards maritime activities. Bermuda played key roles in settling the New World, especially the southern colonies of what would become the USA. Bermudian merchant families established branches in ports on the American Atlantic Seaboard, and used their social networks, merchant fleet and their control of the salt trade (with resulted from de facto Bermudian control of the Turks Islands) to achieve a leading position in the merchant trade through those ports.
Bermudians diversified their interests widely, wherever they could reach by the sea. Involved in logging in Central America, merchant shipping between the North American colonies and the West Indies, fishing the Grand Banks ('til forbidden to by the Palliser's Act of 1775), whaling, and privateering.
As Bermuda's economy became wholly concerned with the sea, the colony became dependent on food imports from North America.
The primary enabler of the development of Bermuda's web of commerce across the Americas was the growth of the British Empire, and from the beginning its primary trading partners were the British colonies on the North American continent.
When thirteen of these colonies rebelled, entering a war of secession, the strong bonds of blood, commerce, and history meant that most Bermudians sympathised with the rebels. It is entirely probable that, if Bermuda had not been so remote from the continental coastline, and had the Royal Navy not enjoyed near supremacy on the ocean, Bermuda would have been the fourteenth colony to join the rebellion. As this was not possible, Bermudians initially assisted the colonists by selling them Bermuda sloops via neutral ports to use as privateers. The number is unclear, but seems to have been very many, with British authorities reporting up to a thousand, although this number is clearly impossible given other sources state the number of ships built in Bermuda during the entire century numbered a thousand. Some historians state that the Bermudian-built privateers played a decisive role in the Americans achieving independence. With trade between the rebelling colonies and the rest of the Empire banned by both sides, Bermudians were faced with the threat of starvation, as well as the destruction of their trade. The Americans were dependent on Bermuda for salt, which the islanders offered the rebels in exchange for food. The Americans insisted on receiving gunpowder. Benjamin Franklin and Henry Tucker Sr. (a colonel of the Bermuda Militia, and a former President of the Privy Council, whose son, Henry Tucker, was then President of the Privy Council and son-in-law to Governor Breure, and whose other two sons were a colonel in the Virginia Militia and a politician in the rebel administration), orchestrated the theft of a hundred barrels of gunpowder from a magazine in St. George's, which was supplied to the Americans. Following this, the Continental Congress authorised trade with Bermuda (although this trade remained illegal in Bermuda).
As the war progressed, with no hope of joining the rebellion due to power of the Royal Navy (in the letter he had addressed to Bermudians soliciting the theft of the gunpowder, George Washington had written "We would not wish to in volve you in an Opposition, in which from your Situation, we should be unable to support you: – We knew not therefore to what Extent to sollicit your Assistance in availing ourselves of this Supply"), with increasing numbers of American loyalists in Bermuda (such as the privateer Bridger Goodrich), and with their economic opportunities dwindling, Bermudians overcame their sympathies for their erstwhile countrymen and unleashed their privateers (which, by the middle of the 18th Century already outnumbered those of any of the mainland colonies) upon American shipping. The Bermudian effectiveness was such that, when the US sued British privateers for wrongful seizures in British courts, following the war, a sizable part of the damages they were awarded were to have come from Bermudians, like Hezekiah Frith (although, with the local authorities tasked with collecting these damages being in sympathy with the defendants, most of these damages were never paid).
The fallout of the war was that Britain lost all of its continental naval bases between the Maritimes and Spanish Florida, ultimately the West Indies. This launched Bermuda into a new prominence with the London Government, as its location, near the halfway point from Nova Scotia to the Caribbean, and off the US Atlantic Seaboard, allowed the Royal Navy to operate fully in the area, protecting British trade routes, and potentially commanding the American Atlantic coast in the event of war. The value of Bermuda in the hands of, or serving as a base for, enemies of the United States was shown by the roles it played in the American War of 1812 and the American Civil War. The blockade of the Atlantic ports by the Royal Navy throughout the first war (described in the USA as the "Second War of Independence") was orchestrated from Bermuda, and the task force that burned Washington DC in 1814 was launched from the colony. During the latter war, Confederate blockade runners delivered European munitions into Southern harbours from Bermuda, smuggling cotton in the reverse direction.
Consequently, the very features that made Bermuda such a prized base for the Royal Navy (its headquarters in the North Atlantic and West Indies 'til after the Second World War, also meant it was perpetually threatened by US invasion, as the US would have liked to both deny the base to an enemy, and use it as a way to extend its defences hundreds of miles out to sea, which would not happen 'til the Second World War.
As a result of the large regular army garrison established to protect the naval facilities, Bermuda's parliament allowed the Bermudian militia to become defunct after the end of the American war in 1815. More profound changes took place, however. The post American independence buildup of Royal Navy facilities in Bermuda meant the Admiralty placed less reliance on Bermudian privateers in the area. Combined with the effects of the American lawsuits, this meant the activity died out in Bermuda until a brief resurgence during the American War of 1812. With the American continental ports having become foreign territory, the Bermudian merchant shipping trade was seriously injured. During the course of American War of 1812, the Americans had developed other sources for salt, and Bermudians salt trade fell upon hard times. Control of the Turks Islands ultimately passed into the hands of Bermuda's sworn enemy, the Bahamas, in 1619. The shipbuilding industry had caused the deforestation of Bermuda's cedar by the start of the 19th Century. As ships became larger, increasingly were built from metal, and with the advent of steam, and with the vastly reduced opportunities Bermudians found for commerce due to US independence and the greater control exerted over their economies by developing territories, Bermuda's shipbuilding industry and maritime trades were slowly strangled.
The chief leg of the Bermudian economy became defence infrastructure. Even after tourism began in the later 19th Century, Bermuda remained, in the eyes of London, a base more than a colony, and this led to a change in the political dynamics within Bermuda as its political and economic ties to Britain were strengthened, and its independence on the world stage was diminished. By the end of the 19th Century, except for the presence of the naval and military facilities, Bermuda was thought of by non-Bermudians and Bermudians alike as a quiet, rustic backwater, completely at odds with the role it had played in the development of the English-speaking Atlantic world, a change that had begun with American independence.
Naval and military base.
Following the loss of Britain's ports in thirteen of its former continental colonies, Bermuda was also used as a stop-over point between Canada and Britain's Caribbean possessions, and assumed a new strategic prominence for the Royal Navy. Hamilton, a centrally located port founded in 1790, became the seat of government in 1815. This was partly resultant from the Royal Navy having invested twelve years, following American independence, in charting Bermuda's reefs. It did this in order to locate the deepwater channel by which shipping might reach the islands in, and at the West of, the Great Sound, which it had begun acquiring with a view to building a naval base. However, that channel also gave access to Hamilton Harbour.
With the buildup of the Royal Naval establishment in the first decades of the 19th century, a large number of military fortifications and batteries were constructed, and the numbers of regular infantry, artillery, and support units that composed the British Army garrison were steadily increased. The investment into military infrastructure by the War Office proved unsustainable, and poorly thought-out, with far too few artillery men available to man the hundreds of guns emplaced. Many of the forts were abandoned, or removed from use, soon after construction. Following the Crimean War, the trend was towards reducing military garrisons in colonies like Bermuda, partly for economic reasons, and partly as it became recognised that the Royal Navy's own ships could provide a better defence for the Dockyard, and Bermuda. Still, the important strategic location of Bermuda meant that the withdrawal, which began, at least in intent, in the 1870s, was carried out very slowly over several decades, continuing until after World War I. The last Regular Army units were not withdrawn until the Dockyard itself closed in the 1950s. In the 1860s, however, the major build-up of naval and military infrastructure brought vital money into Bermuda at a time when its traditional maritime industries were giving way under the assault of steel hulls and steam propulsion. The American Civil War, also, briefly, provided a shot-in-the-arm to the local economy. Tourism and agricultural industries would develop in the latter half of the 19th century. However, it was defence infrastructure that formed the central platform of the economy into the 20th century.
Anglo-Boer War.
During the Anglo-Boer War (1899–1902), Bermuda received and housed a total of 5,000 Boer prisoners of war on five of its islands. They were placed related to their views and authorities' assessment of risk. "Bitterenders" (Afrikaans: "Bittereinders"), men who refused to pledge allegiance to the British Crown, were interned on Darrell's Island and closely guarded. Other islands were allowed to be nearly self-governing: Morgan's Island held 884 men, including 27 officers; Tucker's Island held 809 Boer prisoners, Burt's Island had 607, and Port's Island held 35.
In June 1901, "The New York Times" reported an attempted mutiny by 900 Boer prisoners of war en route to Bermuda on the "Armenian", noting it was suppressed. It described the preparation of the camps for the men and said that martial law would hold on Darrell's Island. Several escapes happened soon after their arrival. A young Boer soldier escaped from Darrell's Island soon after arrival, reached the main docks, and stowed away on the steamship "Trinidad", arriving in New York 9 July. He hoped to be allowed to stay in the US. Three prisoners of war escaped on 10 July from Darrell's Island to mainland Bermuda.
Tourism.
Panorama of Hamilton, 1911. View from Fort Hamilton.
Tourism in Bermuda first developed in Victorian times, catering to a wealthy elite seeking to escape North American winters. Many also came hoping to find young aristocrats among the officers of the Garrison and Naval base to whom they might marry their daughters. Local hoteliers were quick to exploit this, and organised many dances and gatherings during the 'season', to which military and naval officers were given a blanket invitation.
Due historically to a third of Bermuda's manpower being at sea at any one time, and to many of those seamen ultimately settling elsewhere, especially as the Bermudian maritime industry began to suffer, the colony was noted for having a high proportion of unmarried women well into the 20th century. Many Bermudian women had traditionally wed naval or military officers. With the arrival of tourism, young local women had to compete with American girls. Most Bermudian women who married officers left Bermuda when their husbands were stationed elsewhere. Enlisted men married Bermudians, and many of those remained in Bermuda when they left the Army.
In the early 20th century, as modern transportation and communication systems developed, Bermuda's tourism industry began to develop and thrive. The island became a popular destination for a broader spectrum of wealthy US, Canadian, and British tourists. In addition, the tariff enacted by the United States against its trading partners in 1930 cut off Bermuda's once-thriving agricultural export trade—primarily fresh vegetables to the US—spurring the island to put more effort into developing the tourism industry,
Imperial Airways and Pan-American World Airways both began flying to Bermuda in the 1930s (by which time the summer had become more important for tourists making briefer visits). It was not until after the Second World War, when the first airport for landplanes was built and the advent of the Jet Age, that tourism fully realised its potential.
World Wars.
Bermuda sent volunteer troops to fight in Europe with the British Army. They suffered severe losses.
During World War II, Bermuda's importance as a military base increased because of its location on the major trans-Atlantic shipping route. The Royal Naval dockyard on Ireland Island played a role similar to that it had during World War I, overseeing the formation of trans-Atlantic convoys composed of hundreds of ships. The military garrison, which included four local territorial units, maintained a guard against potential enemy attacks on the Island.
In 1941, the United States signed a lend-lease agreement with the United Kingdom, giving the British surplus U.S. Navy destroyers in exchange for 99-year lease rights to establish naval and air bases in certain British territories. Although not included in this trade, Winston Churchill granted the US similar 99-year leases "freely and without consideration" in both Bermuda and Newfoundland. (The commonly held belief that the Bermudian bases were part of the trade is not correct.) The advantage for Britain of granting these base rights was that the neutral US effectively took responsibility for the security of these territories, freeing British forces to be deployed to the sharper ends of the War. The terms of the base rights granted for Bermuda provided that the airfield constructed by the US would be used jointly with the Royal Air Force (RAF).
The Bermuda bases consisted of 5.8 km2 of land, largely reclaimed from the sea. The USAAF airfield, Fort Bell (later, US Air Force Base Kindley Field, and, later still, US Naval Air Station Bermuda) was on St. David's Island, while the Naval Operations Base, a Naval Air Station for maritime patrol flying boats, (which became the Naval Air Station Annex after US Naval air operations relocated to ) was at the western end of the island in the Great Sound. These joined two other air stations already operating on Bermuda, the pre-war civil airport on Darrell's Island, which had been taken over by the RAF, and the Fleet Air Arm's Royal Naval Air Station, HMS Malabar, on Boaz Island.
Recent history.
Bermuda has prospered economically since World War II, developing into a highly successful offshore financial centre. Although tourism remains important to Bermuda's economy, it has for three decades been second to international business in terms of economic importance to the island.
On 10 March 1973, the Governor of the island Sir Richard Sharples was assassinated, along with his aide-de-camp and his dog. Erskine Burrows was found guilty of this assassination. His hanging, on 2 December 1977 was followed by three days of riots.
Though Bermuda has been classified as a self-governed colony since 1620, internal self-government was bolstered by the establishment of a formal constitution in 1968, and the introduction of universal adult suffrage; debate about independence has ensued, although a 1995 independence referendum was soundly defeated. For many, Bermudian independence would mean little other than the obligation to staff foreign missions and embassies around the world, which would be a heavy obligation for Bermuda's small population, and the loss of British passports (which could severely restrict travel, as few enough countries have even heard of little Bermuda, and could regard travellers with suspicion). Another concern, which raised its head during the 1991 Gulf War, was the loss of the protection provided by the Royal Navy, especially, to the large number of merchant vessels on Bermuda's shipping register. The Bermuda government is unlikely to be able to provide naval protection to oil tankers plying the Persian Gulf, or other potentially dangerous waters. At present, Bermuda is able to take advantage of its status as part of the United Kingdom to attract overseas shipping operators to its register, although it does not contribute to the navy's budget. With independence, it was feared, a large chunk of the money currently flowing into the Bermuda Government's coffers would disappear. The current government is promoting independence – by means of a general election (that is, the government of the day would have the power to decide whether to go independent or not) as opposed to a referendum (a direct vote by the people) – by establishing a committee to investigate (though the committee is notably staffed with party members, and without representation by the opposition party). This stance is being supported by the UN, who have sent delegations to the island claiming that Bermuda is being suppressed by the British.
Effective 1 September 1995, both US military bases were closed; British and Canadian bases on the island closed at about the same time. Unresolved issues concerning the 1995 withdrawal of US forces—primarily related to environmental factors—delayed the formal return of the base lands to the Government of Bermuda. The United States formally returned the base lands in 2002.
The island suffered major damage from Hurricane Fabian in 2003. It was also hit by Hurricane Bertha in July 2008.

</doc>
<doc id="42389" url="http://en.wikipedia.org/wiki?curid=42389" title="History of Bhutan">
History of Bhutan

Bhutan's early history is steeped in mythology and remains obscure. Some of the structures provide evidence that Bhutan as early as 2000 BC. According to a legend it was ruled or controlled by a Cooch-Behar king, Sangaldip, around the 7th century B.C., but not much is known prior to the introduction of Tibetan Buddhism in the 9th century, when turmoil in Tibet forced many monks to flee to Bhutan. In the 12th century, the Drukpa Kagyupa school was established and remains the dominant form of Buddhism in Bhutan today. The country's political history is intimately tied to its religious history and relations among the various monastic schools and monasteries.
Bhutan is one of only a few countries which have been independent throughout their history, never conquered, occupied, or governed by an outside power (notwithstanding occasional nominal tributary status). Although there has been speculation that it was under the Kamarupa Kingdom or the Tibetan Empire in the 7th to 9th centuries, firm evidence is lacking. From the time historical records are clear, Bhutan has continuously and successfully defended its sovereignty.
The consolidation of Bhutan occurred in 1616 when Ngawanag Namgyal, a lama from western Tibet known as the Zhabdrung Rinpoche, defeated three Tibetan invasions, subjugated rival religious schools, codified the "Tsa Yig", an intricate and comprehensive system of law, and established himself as ruler over a system of ecclesiastical and civil administrators. After his death, infighting and civil war eroded the power of the Zhabdrung for the next 200 years. In 1885 Ugyen Wangchuck was able to consolidate power, and began cultivating closer ties with the British in India.
In 1907, Ugyen Wangchuck was elected as the hereditary ruler of Bhutan, crowned on December 17, 1907, and installed as the head of state, the Druk Gyalpo (Dragon King). In 1910, King Ugyen and the British signed the Treaty of Punakha which provided that British India would not interfere in the internal affairs of Bhutan if the country accepted external advice in its external relations. When Ugyen Wangchuck died in 1926, his son Jigme Wangchuck became ruler, and when India gained independence in 1947, the new Indian Government recognized Bhutan as an independent country. In 1949 India and Bhutan signed the Treaty of Peace and Friendship, which provided that India would not interfere in Bhutan's internal affairs, but would guide its foreign policy. Succeeded in 1952 by his son Jigme Dorji Wangchuck, Bhutan began to slowly emerge from its isolation and began a program of planned development. The National Assembly of Bhutan, the Royal Bhutanese Army, and the Royal Court of Justice were established, along with a new code of law. Bhutan became a member of the United Nations in 1971. 
In 1972, Jigme Singye Wangchuck ascended the throne at age 20. He emphasized modern education, decentralization of governance, the development of hydroelectricity and tourism and improvements in rural developments. He was perhaps best known internationally for his overarching development philosophy of "gross national happiness." It recognizes that there are many dimensions to development and that economic goals alone are not sufficient. Satisfied with Bhutan's transitioning democratization process, he abdicated in December 2006 rather than wait until the promulgation of the new constitution in 2008. His son, Jigme Khesar Namgyel Wangchuck, became King upon his abdication.
Origins and early settlement, AD 600–1600.
Although knowledge of prehistoric Bhutan has yet to emerge through archaeological study, stone tools and weapons, remnants of large stone structures, and megaliths that may have been used for boundary markers or rituals provide evidence of civilization as early as 2000 BC. The absence of neolithic mythological legends argues against earlier inhabitation. A more certain prehistoric period has been theorized by historians as that of the state of Lhomon (literally, southern darkness) or Monyul (dark land, a reference to the Monpa aboriginal peoples of Bhutan), possibly a part of Tibet that was then beyond the pale of Buddhist teachings. Monyul is thought to have existed between 500 BC. and AD 600. The names Lhomon Tsendenjong (southern Mon sandalwood country) and Lhomon Khashi (southern Mon country of four approaches), found in ancient Bhutanese and Tibetan chronicles, may also have credence and have been used by some Bhutanese scholars when referring to their homeland. Variations of the Sanskrit words Bhota-ant (end of Bhot) or Bhu-uttan (meaning highlands) have been suggested by historians as origins of the name Bhutan, which came into common foreign use in the late nineteenth century and is used in Bhutan only in English-language official correspondence. The traditional name of the country since the seventeenth century has been Drukyul—country of the Drukpa, the Dragon people, or the Land of the Thunder Dragon, a reference to the country's dominant Buddhist sect.
Some scholars believe that during the early historical period the inhabitants were fierce mountain aborigines, the Monpa, who were of neither the Tibetan or Mongol stock that later overran northern Bhutan. The people of Monyul practiced a shamanistic religion, which emphasized worship of nature and the existence of good and evil spirits. During the latter part of this period, historical legends relate that the mighty king of Monyul invaded a southern region known as the Duars, subduing the regions of modern Assam, West Bengal, and Bihar in India.
Arrival of Buddhism.
Buddhism was first introduced to Bhutan in the 7th century AD. Tibetan king Songtsän Gampo (reigned 627–49), a convert to Buddhism, ordered the construction of two Buddhist temples, at Bumthang in central Bhutan and at Kyichu (near Paro) in the Paro Valley. Buddhism was propagated in earnest in 746 under King Sindhu Rāja ("also" Künjom; Sendha Gyab; Chakhar Gyalpo), an exiled Indian king who had established a government in Bumthang at Chakhar Gutho Palace. :35 :13
Buddhism replaced but did not eliminate the Bon religious practices that had also been prevalent in Tibet until the late sixth century. Instead, Buddhism absorbed Bon and its believers. As the country developed in its many fertile valleys, Buddhism matured and became a unifying element. It was Buddhist literature and chronicles that began the recorded history of Bhutan.
In 747, a Buddhist saint, Padmasambhava (known in Bhutan as Guru Rimpoche and sometimes referred to as the Second Buddha), came to Bhutan from India at the invitation of one of the numerous local kings. After reportedly subduing eight classes of demons and converting the king, Guru Rimpoche moved on to Tibet. Upon his return from Tibet, he oversaw the construction of new monasteries in the Paro Valley and set up his headquarters in Bumthang. According to tradition, he founded the Nyingmapa sect—also known as the "old sect" or Red Hat sect—of Mahayana Buddhism, which became for a time the dominant religion of Bhutan. Guru Rimpoche plays a great historical and religious role as the national patron saint who revealed the tantras—manuals describing forms of devotion to natural energy—to Bhutan. Following the guru's sojourn, Indian influence played a temporary role until increasing Tibetan migrations brought new cultural and religious contributions.
There was no central government during this period. Instead, small independent monarchies began to develop by the early ninth century. Each was ruled by a deb (king), some of whom claimed divine origins. The kingdom of Bumthang was the most prominent among these small entities. At the same time, Tibetan Buddhist monks (lam in Dzongkha, Bhutan's official national language) had firmly rooted their religion and culture in Bhutan, and members of joint Tibetan-Mongol military expeditions settled in fertile valleys. By the eleventh century, all of Bhutan was occupied by Tibetan-Mongol military forces.
Sectarian rivalry.
By the tenth century, Bhutan's political development was heavily influenced by its religious history. Following a period in which Buddhism was in decline in Tibet in the eleventh century, contention among a number of subsects emerged. The Mongol overlords of Tibet and Bhutan patronized a sequence of subsects until their own political decline in the fourteenth century. By that time, the Gelugpa or Yellow Hat school had, after a period of anarchy in Tibet, become a powerful force resulting in the flight to Bhutan of numerous monks of various minor opposing sects. Among these monks was the founder of the Lhapa subsect of the Kargyupa school, to whom is attributed the introduction of strategically built dzong. Although the Lhapa subsect had been successfully challenged in the twelfth century by another Kargyupa subsect—the Drukpa—led by Tibetan monk Phajo Drugom Shigpo, it continued to proselytize until the seventeenth century. The Drukpa spread throughout Bhutan and eventually became a dominant form of religious practice. Between the twelfth century and the seventeenth century, the two Kargyupa subsects vied with one another from their respective dzong as the older form of Nyingmapa Buddhism was eclipsed.
Theocratic government, 1616–1907.
Consolidation and defeat of Tibetan invasions, 1616–51.
In the seventeenth century, a theocratic government independent of Tibetan political influence was established, and premodern Bhutan emerged. The theocratic government was founded by an expatriate Drukpa monk, Ngawang Namgyal, who arrived in Bhutan in 1616 seeking freedom from the domination of the Gelugpa subsect led by the Dalai Lama (Ocean Lama) in Lhasa. After a series of victories over rival subsect leaders and Tibetan invaders, Ngawang Namgyal took the title Zhabdrung (At Whose Feet One Submits, or, in many Western sources, Dharma Raja), becoming the temporal and spiritual leader of Bhutan. Considered the first great historical figure of Bhutan, he united the leaders of powerful Bhutanese families in a land called Drukyul. He promulgated a code of law and built a network of impregnable dzong, a system that helped bring local lords under centralized control and strengthened the country against Tibetan invasions. Many dzong were extant in the late twentieth century.
Circa 1627, during the first war with Tibet, Portuguese Jesuits Estêvão Cacella and João Cabral were the first recorded Europeans to visit Bhutan on their way to Tibet. They met with Ngawang Namgyal, presented him with firearms, gunpowder and a telescope, and offered him their services in the war against Tibet, but the Zhabdrung declined the offer. After a stay of nearly eight months Cacella wrote a long letter from the Chagri Monastery reporting the travel. This is a rare report of the Zhabdrung remaining.
Tibetan armies invaded Bhutan around 1629, in 1631, and again in 1639, hoping to throttle Ngawang Namgyal's popularity before it spread too far. In 1634 Ngawang Namgyal defeated Karma Tenkyong's army in the Battle of Five Lamas. The invasions were thwarted, and the Drukpa subsect developed a strong presence in western and central Bhutan, leaving Ngawang Namgyal supreme. In recognition of the power he accrued, goodwill missions were sent to Bhutan from Cooch Behar in the Duars (present-day northeastern West Bengal), Nepal to the west, and Ladakh in western Tibet. The ruler of Ladakh even gave a number of villages in his kingdom to Ngawang Namgyal.
Bhutan's troubles were not over, however. In 1643, a joint Mongol-Tibetan force sought to destroy Nyingmapa refugees who had fled to Bhutan, Sikkim, and Nepal. The Mongols had seized control of religious and civil power in Tibet in the 1630s and established Gelugpa as the state religion. Bhutanese rivals of Ngawang Namgyal encouraged the Mongol intrusion, but the Mongol force was easily defeated in the humid lowlands of southern Bhutan. Another Tibetan invasion in 1647 also failed.
During Ngawang Namgyal's rule, administration comprised a state monastic body with an elected head, the Je Khenpo (lord abbot), and a theocratic civil government headed by the Druk Desi (regent of Bhutan, also known as Deb Raja in Western sources). The Druk Desi was either a monk or a member of the laity—by the nineteenth century, usually the latter; he was elected for a three-year term, initially by a monastic council and later by the State Council (Lhengye Tshokdu). The State Council was a central administrative organ that included regional rulers, the Zhabdrung's chamberlains, and the Druk Desi. In time, the Druk Desi came under the political control of the State Council's most powerful faction of regional administrators. The Zhabdrung was the head of state and the ultimate authority in religious and civil matters. The seat of government was at Thimphu, the site of a thirteenth-century dzong, in the spring, summer, and fall. The winter capital was at Punakha Dzong, a dzong established northeast of Thimphu in 1527. The kingdom was divided into three regions (east, central, and west), each with an appointed ponlop, or governor, holding a seat in a major dzong. Districts were headed by dzongpon, or district officers, who had their headquarters in lesser dzong. The ponlop were combination tax collectors, judges, military commanders, and procurement agents for the central government. Their major revenues came from the trade between Tibet and India and from land taxes.
Ngawang Namgyal's regime was bound by a legal code called the Tsa Yig, which described the spiritual and civil regime and provided laws for government administration and for social and moral conduct. The duties and virtues inherent in the Buddhist dharma (religious law) played a large role in the new legal code, which remained in force until the 1960s.
Administrative integration and conflict with Tibet, 1651–1728.
To keep Bhutan from disintegrating, Ngawang Namgyal's death in 1651 apparently was kept a carefully guarded secret for fifty-four years. Initially, Ngawang Namgyal was said to have entered into a religious retreat, a situation not unprecedented in Bhutan, Sikkim, or Tibet during that time. During the period of Ngawang Namgyal's supposed retreat, appointments of officials were issued in his name, and food was left in front of his locked door.
Ngawang Namgyal's son and stepbrother, in 1651 and 1680, respectively, succeeded him. They started their reigns as minors under the control of religious and civil regents and rarely exercised authority in their own names. For further continuity, the concept of multiple reincarnation of the first Zhabdrung—in the form of either his body, his speech, or his mind—was invoked by the Je Khenpo and the Druk Desi, both of whom wanted to retain the power they had accrued through the dual system of government. The last person recognized as the bodily reincarnation of Ngawang Namgyal died in the mid-eighteenth century, but speech and mind reincarnations, embodied by individuals who acceded to the position of Zhabdrung Rinpoche, were recognized into the early twentieth century. The power of the state religion also increased with a new monastic code that remained in effect in the early 1990s. The compulsory admission to monastic life of at least one son from any family having three or more sons was instituted in the late seventeenth century. In time, however, the State Council became increasingly secular as did the successive Druk Desi, ponlop, and dzongpon, and intense rivalries developed among the ponlop of Tongsa and Paro and the dzongpon of Punakha, Thimphu, and Wangdue Phodrang.
During the first period of succession and further internal consolidation under the Druk Desi government, there was conflict with Tibet and Sikkim. Internal opposition to the central government resulted in overtures by the opponents of the Druk Desi to Tibet and Sikkim. In the 1680s, Bhutan invaded Sikkim in pursuit of a rebellious local lord. In 1700, Bhutan again invaded Sikkim, and in 1714 Tibetan forces, aided by Mongolia, invaded Bhutan but were unable to gain control.
Western outposts.
During the 17th century Bhutan maintained close relations with Ladakh, and assisted Ladakh in its 1684 war with Tibet. Ladakh had earlier granted Bhutan several enclaves near Mount Kailash in western Tibet; these were monasteries of the Drukpa sect and so fell under the authority of the Bhutanese Je Khenpo and the Zhabdrung. These enclaves persisted under Bhutanese control even after the rest of western Tibet came under the control of the Dalai Lama and his Gelugpa sect. Not until 1959 were the Bhutanese enclaves seized by the Chinese. In addition to these outposts in Tibet, Bhutan for a time held monastic fiefs in Ladakh, Zanskar, and Lahul (now part of India), as well as in Lo Manthang and Dolpo (now part of Nepal).
Civil conflict, 1728–72.
Though the invaders were unable to take control, the political system remained unstable. Regional rivalries contributed to the gradual disintegration of Bhutan at the time the first British agents arrived.
In the early eighteenth century, Bhutan had successfully developed control over the principality of Cooch Behar. The raja of Cooch Behar had sought assistance from Bhutan against the Indian Mughals in 1730, and Bhutanese political influence was not long in following. By the mid-1760s, Thimphu considered Cooch Behar its dependency, stationing a garrison force there and directing its civil administration. When the Druk Desi invaded Sikkim in 1770, Cooch Behari forces joined their Bhutanese counterparts in the offensive. In a succession dispute in Cooch Behar two years later, however, the Druk Desi's nominee for the throne was opposed by a rival who invited British troops, and, in effect, Cooch Behar became a dependency of the British East India Company.
British intrusion, 1772–1907.
Under the Cooch Behari agreement with the British, a British expeditionary force drove the Bhutanese garrison out of Cooch Behar and invaded Bhutan in 1772–73. The Druk Desi petitioned Lhasa for assistance from the Panchen Lama, who was serving as regent for the youthful Dalai Lama. In correspondence with the British governor general of India, however, the Panchen Lama instead punished the Druk Desi and invoked Tibet's claim of suzerainty over Bhutan.
Failing to receive help from Tibet, the Druk Desi signed a Treaty of Peace with the British East India Company on April 25, 1774. Bhutan agreed to return to its pre-1730 boundaries, paid a symbolic tribute of five horses to Britain, and, among other concessions, allowed the British to harvest timber in Bhutan. Subsequent missions to Bhutan were made by the British in 1776, 1777, and 1783, and commerce was opened between British India and Bhutan, and, for a short time, Tibet. In 1784, the British turned over to Bhutanese control Bengal Duars territory, where boundaries were poorly defined. As in its other foreign territories, Bhutan left administration of the Bengal Duars territory to local officials and collected its revenues. Although major trade and political relations failed to develop between Bhutan and Britain, the British had replaced the Tibetans as the major external threat.
Boundary disputes plagued Bhutanese–British relations. To reconcile their differences, Bhutan sent an emissary to Calcutta in 1787, and the British sent missions to Thimphu in 1815 and 1838. The 1815 mission was inconclusive. The 1838 mission offered a treaty providing for extradition of Bhutanese officials responsible for incursions into Assam, free and unrestricted commerce between India and Bhutan, and settlement of Bhutan's debt to the British. In an attempt to protect its independence, Bhutan rejected the British offer. Despite increasing internal disorder, Bhutan had maintained its control over a portion of the Assam Duars more or less since its reduction of Cooch Behar to a dependency in the 1760s. After the British gained control of Lower Assam in 1826, tension between the countries began to rise as Britain exerted its strength. Bhutanese payments of annual tribute to the British for the Assam Duars gradually fell into arrears. British demands for payment led to military incursions into Bhutan in 1834 and 1835, resulting in defeat for Bhutan's forces and a temporary loss of territory.
The British proceeded in 1841 to annex the formerly Bhutanese-controlled Assam Duars, paying a compensation of 10,000 rupees a year to Bhutan. In 1842, Bhutan gave to the British control of some of the troublesome Bengal Duars territory it had administered since 1784.
Charges and countercharges of border incursions and protection of fugitives led to an unsuccessful Bhutanese mission to Calcutta in 1852. Among other demands, the mission sought increased compensation for its former Duars territories; instead the British deducted nearly 3,000 rupees from the annual compensation and demanded an apology for alleged plundering of British-protected lands by members of the mission. Following more incidents and the prospect of an anti-Bhutan rebellion in the Bengal Duars, British troops deployed to the frontier in the mid-1850s. The Sepoy Rebellion in India in 1857-58 and the demise of the British East India Company's rule prevented immediate British action. Bhutanese armed forces raided Sikkim and Cooch Behar in 1862, seizing people, property, and money. The British responded by withholding all compensation payments and demanding release of all captives and return of stolen property. Demands to the Druk Desi went unheeded, as he was alleged to be unaware of his frontier officials' actions against Sikkim and Cooch Behar.
Britain sent a peace mission to Bhutan in early 1864, in the wake of the recent conclusion of a civil war there. The dzongpon of Punakha—who had emerged victorious—had broken with the central government and set up a rival Druk Desi, while the legitimate Druk Desi sought the protection of the ponlop of Paro and was later deposed. The British mission dealt alternately with the rival ponlop of Paro and the ponlop of Tongsa (the latter acting on behalf of the Druk Desi), but Bhutan rejected the peace and friendship treaty it offered. Britain declared war in November 1864. Bhutan had no regular army, and what forces existed were composed of dzong guards armed with matchlocks, bows and arrows, swords, knives, and catapults. Some of these dzong guards, carrying shields and wearing chainmail armor, engaged the well-equipped British forces.
The Duar War (1864–65) lasted only five months and, despite some battlefield victories by Bhutanese forces, resulted in Bhutan's defeat, loss of part of its sovereign territory, and forced cession of formerly occupied territories. Under the terms of the Treaty of Sinchula, signed on November 11, 1865, Bhutan ceded territories in the Assam Duars and Bengal Duars, as well as the eighty-three-square-kilometer territory of Dewangiri in southeastern Bhutan, in return for an annual subsidy of 50,000 rupees. The land that was to become Bhutan House was ceded from Bhutan to British India in 1865 at the conclusion the Duar War and as a condition of the Treaty of Sinchula.
In the 1870s and 1880s, renewed competition among regional rivals—primarily the pro-British ponlop of Tongsa and the anti-British, pro-Tibetan ponlop of Paro—resulted in the ascendancy of Ugyen Wangchuck, the Ponlop of Tongsa. From his power base in central Bhutan, Ugyen Wangchuck had defeated his political enemies and united the country following several civil wars and rebellions in 1882-85. His victory came at a time of crisis for the central government, however. British power was becoming more extensive to the south, and in the west Tibet had violated its border with Sikkim, incurring British disfavor. After 1,000 years of close ties with Tibet, Bhutan faced the threat of British military power and was forced to make serious geopolitical decisions. The British, seeking to offset potential Russian advances in Lhasa, wanted to open trade relations with Tibet. Ugyen Wangchuck, on the advice of his closest adviser Ugyen Dorji, saw the opportunity to assist the British and in 1903-4 volunteered to accompany a British mission to Lhasa as a mediator. For his services in securing the Anglo-Tibetan Convention of 1904, Ugyen Wangchuck was knighted and thereafter continued to accrue greater power in Bhutan. Ugyen Dorji, as well as his descendants, went on to maintain British favor on behalf of the government from Bhutan House in Kalimpong, India.
Establishment of the hereditary monarchy, 1907.
Ugyen Wangchuck's emergence as the national leader coincided with the realization that the dual political system was obsolete and ineffective. He had removed his chief rival, the ponlop of Paro, and installed a supporter and relative, a member of the pro-British Dorji family, in his place. When the last Zhabdrung died in 1903 and a reincarnation had not appeared by 1906, civil administration came under the control of Ugyen Wangchuck. Finally, in 1907, the fifty-fourth and last Druk Desi was forced to retire, and despite recognitions of subsequent reincarnations of Ngawang Namgyal, the Zhabdrung system came to an end.
In November 1907, an assembly of leading Buddhist monks, government officials, and heads of important families was held to end the moribund 300-year-old dual system of government and to establish a new absolute monarchy. Ugyen Wangchuck was elected its first hereditary Druk Gyalpo (Dragon King, reigned 1907–26). The Dorji family became hereditary holders of the position of gongzim (chief chamberlain), the top government post. The British, wanting political stability on their northern frontier, approved of the entire development.
Britain's earlier entreaties in Lhasa had unexpected repercussions at this time. The Chinese, concerned that Britain would seize Tibet, invaded Tibet in 1910 and asserted political authority. In the face of the Chinese military occupation, the Dalai Lama fled to India. China laid claim not only to Tibet but also to Bhutan, Nepal, and Sikkim. With these events, Bhutanese and British interests coalesced.
On January 8, 1910, Sikkim Political Officer and Tibetologist Sir Charles Alfred Bell engaged Bhutan and signed the Treaty of Punakha. The Treaty of Punakha amended two articles of the 1865 treaty: the British agreed to double their annual stipend to 100,000 rupees and "to exercise no interference in the internal administration of Bhutan." In turn, Bhutan agreed "to be guided by the advice of the British Government in regard to its external relations." The Treaty of Punakha guaranteed Bhutan's defense against China; China, in no position to contest British power, conceded the end of the millennium-long Tibetan-Chinese influence. It also assigned land in Motithang (Thimphu) and a hill station between Chukha and Thimphu to the British, assigning a portion of Kalimpong (Bhutan House) to Bhutan.
Much of Bhutan's modern development has been attributed by Bhutanese historians to the first Druk Gyalpo. Internal reforms included introducing Western-style schools, improving internal communications, encouraging trade and commerce with India, and revitalizing the Buddhist monastic system. Toward the end of his life, Ugyen Wangchuck was concerned about the continuity of the family dynasty, and in 1924 he sought British assurance that the Wangchuck family would retain its preeminent position in Bhutan. His request led to an investigation of the legal status of Bhutan vis-à-vis the suzerainty held over Bhutan by Britain and the ambiguity of Bhutan's relationship to India. Both the suzerainty and the ambiguity were maintained.
Development of centralized government, 1926–52.
Ugyen Wangchuck died in 1926 and was succeeded by his son, Jigme Wangchuck (reigned 1926–52). The second Druk Gyalpo continued his father's centralization and modernization efforts and built more schools, dispensaries, and roads. During Jigme Wangchuck's reign, monasteries and district governments were increasingly brought under royal control. However, Bhutan generally remained isolated from international affairs.
The issue of Bhutan's status vis-à-vis the government of India was reexamined by London in 1932 as part of the issue of the status of India itself. It was decided to leave the decision to join an Indian federation up to Bhutan when the time came. When British rule over India ended in 1947, so too did Britain's association with Bhutan. India succeeded Britain as the de facto protector of the Himalayan kingdom, and Bhutan retained control over its internal government. It was two years, however, before a formal agreement recognized Bhutan's independence.
Following the precedent set by the Treaty of Punakha, on August 8, 1949, Thimphu signed the Treaty of Friendship Between the Government of India and the Government of Bhutan, according to which external affairs, formerly guided by Britain, were to be guided by India. Like Britain, India agreed not to interfere in Bhutan's internal affairs. India also agreed to increase the annual subsidy to 500,000 rupees per year. Important to Bhutan's national pride was the return of Dewangiri. Some historians believe that if India had been at odds with China at this time, as it was to be a decade later, it might not have acceded so easily to Bhutan's request for independent status.
Modernization under Jigme Dorji, 1952–72.
The third Druk Gyalpo, Jigme Dorji Wangchuck, was enthroned in 1952. Earlier he had married the European-educated cousin of the chogyal (king) of Sikkim and with her support made continual efforts to modernize his nation throughout his twenty-year reign. Among his first reforms was the establishment of the National Assembly — the Tshogdu — in 1953. Although the Druk Gyalpo could issue royal decrees and exercise veto power over resolutions passed by the National Assembly, its establishment was a major move toward a constitutional monarchy.
When the Chinese communists took over Tibet in 1951, Bhutan closed its frontier with Tibet and sided with its powerful neighbor to the south. To offset the chance of Chinese encroachment, Bhutan began a modernization program. Land reform was accompanied by the abolition of slavery and serfdom and the separation of the judiciary from the executive branch of government. Mostly funded by India after China's invasion of Tibet in 1959, the modernization program also included the construction of roads linking the Indian plains with central Bhutan. An all-weather road was completed in 1962 between Thimphu and Phuntsholing, the overland gateway town on the southwest border with India. Dzongkha was made the national language during Jigme Dorji's reign. Additionally, development projects included establishing such institutions as a national museum in Paro and a national library, national archives, and national stadium, as well as buildings to house the National Assembly, the High Court (Thrimkhang Gongma), and other government entities in Thimphu. The position of gongzim, held since 1907 by the Dorji family, was upgraded in 1958 to lonchen (prime minister) and was still in the hands of the Dorji. Jigme Dorji Wangchuck's reforms, however, although lessening the authority of the absolute monarchy, also curbed the traditional decentralization of political authority among regional leaders and strengthened the role of the central government in economic and social programs.
Modernization efforts moved forward in the 1960s under the direction of the lonchen, Jigme Palden Dorji, the Druk Gyalpo's brother-in-law. In 1962, however, Dorji incurred disfavor with the Royal Bhutan Army over the use of military vehicles and the forced retirement of some fifty officers. Religious elements also were antagonized by Dorji's efforts to reduce the power of the state-supported religious institutions. In April 1964, while the Druk Gyalpo was in Switzerland for medical care, Dorji was assassinated in Phuntsholing by an army corporal. The majority of those arrested and accused of the crime were military personnel and included the army chief of operations, Namgyal Bahadur, the Druk Gyalpo's uncle, who was executed for his part in the plot.
The unstable situation continued under Dorji's successor as acting lonchen, his brother Lhendup Dorji, and for a time under the Druk Gyalpo's brother, Namgyal Wangchuck, as head of the army. According to some sources, a power struggle ensued between pro-Wangchuck loyalists and "modernist" Dorji supporters. The main issue was not an end to or lessening of the power of the monarchy but "full freedom from Indian interference." Other observers believe the 1964 crisis was not so much a policy struggle as competition for influence on the palace between the Dorji family and the Druk Gyalpo's Tibetan consort, Yanki, and her father. Lhendup Dorji had earlier threatened to kill Yanki—his sister's rival—and ordered her arrest when, fearing for her life and that of her 2-year-old son by the Druk Gyalpo, she sought refuge in India during the political crisis. Lhendup also incurred the disapproval of the Druk Gyalpo by seeking to become sole regent of the kingdom after his brother's death, eliminating the Queen and the king's brother. Before returning to Bhutan from Switzerland, Jigme Dorji met with the Indian Secretary General and Foreign Secretary in Calcutta who offered Indian support, including paratroopers if necessary, to help the Druk Gyalpo restore order in the kingdom. Unable to regain the Druk Gyalpo's trust, Lhendup fled to London, while other supporters in the military and government fled to Nepal and Calcutta. Afterwards, in concurrence of the National Assembly, Lhendup Dorji and other family members were exiled in 1965. However, the exiles continued their attacks on the Druk Gyalpo and India, worsening relations between India and China. The tense political situation continued and in July 1965 there was an assassination attempt on the Druk Gyalpo. The Dorjis were not implicated in the attempt—which was described as a "private matter"—and the would-be assassins were pardoned by the Druk Gyalpo.
In 1966, to increase the efficiency of government administration, Jigme Dorji Wangchuck made Thimphu the year-round capital. In May 1968, the comprehensive Rules and Regulations of the National Assembly revised the legal basis of the power granted to the National Assembly. The Druk Gyalpo decreed that henceforth sovereign power, including the power to remove government ministers and the Druk Gyalpo himself, would reside with the National Assembly. The following November, the Druk Gyalpo renounced his veto power over National Assembly bills and said he would step down if two-thirds of the legislature passed a no-confidence vote. Although he did nothing to undermine the retention of the Wangchuck dynasty, the Druk Gyalpo in 1969 called for a triennial vote of confidence by the National Assembly (later abolished by his successor) to renew the Druk Gyalpo's mandate to rule.
Diplomatic overtures also were made during Jigme Dorji Wangchuck's reign. Although always seeking to be formally neutral and nonaligned in relations with China and India, Bhutan also sought more direct links internationally than had occurred previously under the foreign-policy guidance of India. Consequently, in 1962 Bhutan joined the Colombo Plan for Cooperative, Economic, and Social Development in Asia and the Pacific known as the Colombo Plan, and in 1966 notified India of its desire to become a member of the United Nations (UN). In 1971, after holding observer status for three years, Bhutan was admitted to the UN. In an effort to maintain Bhutan as a stable buffer state, India continued to provide substantial amounts of development aid.
Jigme Dorji Wangchuck ruled until his death in July 1972 and was succeeded by his seventeen-year-old son, Jigme Singye Wangchuck. The close ties of the Wangchuck and Dorji families were reemphasized in the person of the new king, whose mother, Ashi Kesang Dorji (ashi means princess), was the sister of the lonchen, Jigme Palden Dorji. Jigme Singye Wangchuck, who had been educated in India and Britain, had been appointed ponlop of Tongsa in May 1972 and by July that year had become the Druk Gyalpo. With his mother and two elder sisters as advisers, the new Druk Gyalpo was thrust into the affairs of state. He was often seen among the people, in the countryside, at festivals, and, as his reign progressed, meeting with foreign dignitaries in Bhutan and abroad. His formal coronation took place in June 1974, and soon thereafter the strains between the Wangchucks and Dorjis were relieved with the return that year of the exiled members of the latter family. The reconciliation, however, was preceded by reports of a plot to assassinate the new Druk Gyalpo before his coronation could take place and to set fire to the Tashichho Dzong (Fortress of the Glorious Religion, the seat of government in Thimphu). Yanki (who had four children with the Druk Gyalpo, including two sons, between 1962–1972) was the alleged force behind the plot, which was uncovered three months before the coronation; thirty persons were arrested, including high government and police officials. However, Lawrence Sittling, secretary to Jigme Dorji Wangchuck, later reported that the assassination plot was a fabrication by a Chinese diplomat designed to alienate Bhutan from India. But the truth was not any more politically acceptable—those arrested were Tibetan Khampas rebels, trained in India, who were traveling through Bhutan on a mission to Tibet. (Encyclopaedia of Saarc Nations, Syed) Under pressure from China, the Bhutanese government demanded that the four thousand Tibetan refugees living in Bhutan either become Bhutanese citizens or go into exile. Most chose exile. (Syed)
International relations, 1972–present.
When civil war broke out in Pakistan in 1971, Bhutan was the first nation to recognize the new government of Bangladesh, and formal diplomatic relations were established in 1973. An event in 1975 may have served as a major impetus to Bhutan to speed up reform and modernization. In that year, neighboring Sikkim's monarchy, which had endured for more than 300 years, was ousted following a plebiscite in which the Nepalese majority outvoted the Sikkimese minority. Sikkim, long a protectorate of India, became India's twenty-second state.
To further ensure its independence and international position, Bhutan gradually established diplomatic relations with other nations and joined greater numbers of regional and international organizations. Many of the countries with which Bhutan established relations provided development aid. Moderization of daily life brought new problems to Bhutan in the late 1980s. Television broadcast was official introduced in Bhutan in 1999.
Assamese separatists.
Several guerrilla groups seeking to establish an independent Assamese state in northeast India have set up guerrilla bases in the forests of southern Bhutan, from which they launched cross-border attacks on targets in Assam. The largest guerrilla group was the ULFA (United Liberation Front of Asom). Negotiations aimed at removing them peacefully from these bases failed in the spring of 2003. Bhutan was faced with the prospect of having to strengthen its token army force to evict the guerrillas.
Military action against Assamese separatists December 2003.
On 15 December 2003 the Royal Bhutan Army began military operations against guerrilla camps in southern Bhutan, in coordination with Indian armed forces who lined the border to the south to prevent the guerrillas from dispersing back into Assam. News sources indicated that of the 30 camps that were target, 13 were controlled by ULFA, 12 camps by the National Democratic Front of Bodoland (NDFB), and 5 camps controlled by the Kamatapur Liberation Organisation (KLO). By January, government news reports indicated the guerillas had been routed from their bases.
Refugee community.
In 1988, Bhutan was reported to have evicted some number of Nepali-speaking residents (Bhutanese reports say about 5,000 and Refugee reports says over 100,000) from districts in southern Bhutan, creating a large refugee community that was now being detained in seven temporary United Nations refugee camps in Nepal and Sikkim. The actual numbers were difficult to establish, as many of those in the camps were reported to be holding forged identity papers, and impoverished Nepalese citizens and started to migrate to the Nepalese community leaving their refugee camps. The reason for leaving refugee camps was to find a job, and services to those living in camps. Few of them returned to the refugee camps. As a result, the number of people living in the camps decreased exponentially. Although the Bhutanese government claimed that only about 5000 initially left the country, the number of actual migration was more than that.
After years of negotiations between Nepal and Bhutan, in 2000 Bhutan agreed in principle to allow certain classes of the refugees to return to Bhutan. However the situation was at a standstill, after violence was committed on Bhutanese officials by the angered people in the camps. Significant unrest was now reported to be fermenting in the camps, especially as the United Nations terminated a number of educational and welfare programmes in an effort to force Bhutan and Nepal to come to terms.
As the Bhutanese government was unwilling to take them into their country many developed nations offered the refugees to allow them to settle in their own countries which included USA and Australia. As many as 20,000 Bhutanese refugees have been resettled in these countries.
Formalized democracy.
Constitution.
On March 26, 2005, "an auspicious day when the stars and elements converge favourably to create an environment of harmony and success", the king and government distributed a draft of the country's first constitution, requesting that every citizen review it. A new house of parliament, the National Council, is chartered consisting of 20 elected representatives from each of the dzonghags, persons selected by the King. The National Council would be paired with the other already existing house, the National Assembly.
Per the Constitution, the monarchy is given a leadership role in setting the direction for the government as long as the King shall demonstrate his commitment and ability to safeguard the interests of the kingdom and its people.
Jigme Khesar Namgyel Wangchuck.
On December 15, 2006, the fourth Druk Gyalpo, His Majesty Jigme Singye Wangchuck, abdicated all of his powers as King to his son, Prince Jigme Khesar Namgyel Wangchuck, with a specific intention to prepare the young King for the country's transformation to a full-fledged, democratic form of government due to occur in 2008.
The previous King's abdication in favour of his son was originally set to occur in 2008 as well, but there was an apparent concern that the new King should have hands-on experience as the nation's leader before presiding over a transformation in the country's form of government. According to the national newspaper, the Kuensel, the previous King stated to his cabinet that "as long as he himself continued to be King, the Crown Prince would not gain the actual experience of dealing with issues and carrying out the responsibilities of a head of state. With parliamentary democracy to be established in 2008, there was much to be done; so it was necessary that he gained this valuable experience."
The fourth Druk Gyalpo further stated that
Further reading.
</dl>
See also.
</dl>

</doc>
<doc id="42395" url="http://en.wikipedia.org/wiki?curid=42395" title="Warsaw Ghetto">
Warsaw Ghetto

 
The Warsaw Ghetto (German: "Warschauer Ghetto", called by the German authorities: „Jüdischer Wohnbezirk in Warschau“ (Jewish residential district in Warsaw); Polish: "getto warszawskie") was the largest of all the Jewish ghettos in Nazi-occupied Europe during World War II. It was established in the Polish capital between October and November 16, 1940, in the territory of the General Government of German-occupied Poland, with over 400,000 Jews from the vicinity residing in an area of 3.4 km2. From there, at least 254,000 Ghetto residents were sent to the Treblinka extermination camp over the course of two months in the summer of 1942.
The death toll among the Jewish inhabitants of the Ghetto, between deportations to extermination camps, "Großaktion Warschau", the Warsaw Ghetto Uprising, and the subsequent razing of the ghetto, is estimated to be at least 300,000.
Creation.
The construction of the ghetto wall started on April 1, 1940.
The Warsaw Ghetto was established by the German Governor-General Hans Frank on October 16, 1940 in an area of Warsaw primarily occupied by Polish Jews. Frank ordered all Jews in Warsaw and its suburbs rounded up and herded into the Ghetto. At this time, the population in the Ghetto was estimated to be 400,000 people, about 30% of the population of Warsaw; however, the area of the Ghetto was only about 2.4% of that of Warsaw.
The Germans closed the Warsaw Ghetto to the outside world on November 16, 1940. The wall was typically 3 m high and topped with barbed wire. Escapees could be shot on sight. The borders of the ghetto changed many times during the next years.
The ghetto was divided by Chłodna Street, which due to its importance (as one of Warsaw's major east-west arteries) was excluded from it. The area south of Chłodna was known as the “Small Ghetto”, while the area north of this street was the “Large Ghetto”. Those two parts were connected by Żelazna Street, and a special gate was built at its intersection with Chłodna Street. In January 1942, the gate was closed and a wooden footbridge was built in its place, which after the war became one of the symbols of the Holocaust.
The first commissioner of the Warsaw ghetto was his chief organizer SA-Standartenführer Waldemar Schön. He was succeeded in May 1941 by Heinz Auerswald.
Administration of the Ghetto.
Like all the ghettos in Poland, the Germans ascribed the administration to a Judenrat (a council of the Jews), led by an "Ältester" (the eldest). In Warsaw this role was attributed to Adam Czerniaków, who chose a policy of collaboration with the Nazis rather than revolt. Adam Czerniaków confided his harrowing experience in several diaries. He became aware of his own tragic duplicity in July 1942 and committed suicide.
Although his personality has remained less infamous than Mordechai Chaim Rumkowski, the "Ältester" of the Lodz Ghetto, Adam Czerniaków's collaboration with the Nazi policy is the paradigm of the attitude of the majority of the European Jews vis à vis Nazism. The Jewish collaboration authority was supported by a Jewish Ghetto Police. According to Lucy S. Dawidowicz:
From its inception, the Judenrat was looked upon as a reincarnation of the kehillas. Czerniakow's first draft of October, 1939; for organizing the Warsaw Judenrat, was just a rehash of conventional kehilla departments: chancellery, welfare, education, rabbinate...
In performing these functions, the kehilla had operated a "gemeinschaft" institution... But the Kehilla was an anomalous institution. Throughout its history in czarist Russia, it served also as an instrument of the state, obligated to carry out the regime's policies within the Jewish community, even though these policies were frequently oppressive and specifically anti-Jewish...
Conditions.
During the next year and a half, thousands of Polish Jews as well as some Romani people from smaller cities and the countryside were brought into the Ghetto, while diseases (especially typhus), and starvation kept the inhabitants at about the same number. Average food rations in 1941 for Jews in Warsaw were limited to 184 calories, compared to 699 calories for gentile Poles and 2,613 calories for Germans.
Unemployment was a major problem in the ghetto. Illegal workshops were created to manufacture goods to be sold illegally on the outside and raw goods were smuggled in, often by children. Hundreds of four- to eight-year-old Jewish children went across en masse to the "Aryan side," sometimes several times a day, smuggling food into the ghettos, returning with goods that often weighed more than they did. Smuggling was often the only source of subsistence for Ghetto inhabitants, who would otherwise have died of starvation.
Despite the grave hardships, life in the Warsaw Ghetto was rich with educational and cultural activities, conducted by its underground organizations. Hospitals, public soup kitchens, orphanages, refugee centers and recreation facilities were formed, as well as a school system. Some schools were illegal and operated under the guise of a soup kitchen. There were secret libraries, classes for the children and even a symphony orchestra. Rabbi Alexander Zusia Friedman, secretary-general of Agudath Israel of Poland, was one of the Torah leaders in the Warsaw Ghetto. He organized an underground network of religious schools, including "a Yesodei HaTorah school for boys, a Bais Yaakov school for girls, a school for elementary Jewish instruction, and three institutions for advanced Jewish studies". These schools, operating under the guise of kindergartens, medical centers and soup kitchens, were a place of refuge for thousands of children and teens, and hundreds of teachers. In 1941, when the Germans gave official permission to the local Judenrat to open schools, these schools came out of hiding and began receiving financial support from the official Jewish community.
Over 100,000 of the Ghetto's residents died due to rampant disease or starvation, as well as random killings, even before the Nazis began massive deportations of the inhabitants from the Ghetto's "Umschlagplatz" to the Treblinka extermination camp during the Grossaktion Warschau, part of the countrywide Operation Reinhard. Between "Tisha B'Av" (July 23) and "Yom Kippur" (September 21) of 1942, about 254,000 Ghetto residents (or at least 300,000 by different accounts) were sent to Treblinka and murdered there.
Friedman alerted world Jewry to the start of deportations from the Warsaw Ghetto in a coded message. His telegram read: "Mr. Amos kept his promise from the fifth-third." He was referring to the Book of Amos, chapter 5, verse 3, which reads: "The city that goes out a thousand strong will have a hundred left, and the one that goes out a hundred strong will have ten left to the House of Israel".
Polish resistance officer Jan Karski reported to the Western governments in 1942 on the situation in the Ghetto and on the extermination camps. By the end of 1942, it was clear that the deportations were to their deaths, and many of the remaining Jews decided to fight.
For years, Ghetto residents in the group "Oyneg Shabbos" had discreetly chronicled conditions and hid their photos, writings, and short films in improvised time capsules; their activity increased after learning that transports to "resettlement" actually led to the mass killings. In May 1942, Germans began filming a propaganda movie titled "Das Ghetto" which was never completed. Footage is shown in the 2010 documentary called "A Film Unfinished" which concerns the making of "Das Ghetto" and correlates scenes from 'Das Ghetto' with descriptions of the filming of these scenes that Czerniakow mentions in his diary.
Warsaw Ghetto Uprising and destruction of the Ghetto.
On January 18, 1943, after almost four months without any deportations, the Germans suddenly entered the Warsaw ghetto intent upon a further deportation. Within hours, some 600 Jews were shot and 5,000 others rounded up. 
The Germans expected no resistance, but preparations to resist had been going on since the previous autumn. The first instances of Jewish armed resistance began that day. The Jewish fighters had some success: the expulsion stopped after four days and the ŻOB and ŻZW resistance organizations took control of the Ghetto, building shelters and fighting posts and operating against Jewish collaborators.
The final battle started on the eve of Passover of April 19, 1943, when a Nazi force consisting of several thousand troops entered the ghetto. After initial setbacks, the Germans under the field command of Jürgen Stroop systematically burned and blew up the ghetto buildings, block by block, rounding up or murdering anybody they could capture. Significant resistance ended on April 28, and the Nazi operation officially ended in mid-May, symbolically culminating with the demolition of the Great Synagogue of Warsaw on May 16. According to the official report, at least 56,065 people were killed on the spot or deported to German Nazi concentration and death camps (Treblinka, Poniatowa, Majdanek, Trawniki).
Remnants of the Ghetto today.
The ghetto was almost entirely leveled during the uprising; however, a number of buildings and streets survived, mostly in the "small ghetto" area, which had been included into the Aryan part of the city in August 1942 and was not involved in the fighting.
In 2008 and 2010 Warsaw Ghetto boundary markers were built along the borders of the former Jewish former quarter, where from 1940−1943 stood the gates to the ghetto, wooden footbridges over Aryan streets, and the buildings important to the ghetto inmates.
The four buildings at 7, 9, 12 and 14 Próżna Street are among the best known original residential buildings that in 1940-41 housed Jewish families in the Warsaw Ghetto. They have largely remained empty since the war. The street is a focus of the annual Warsaw Jewish Festival. In 2011−2013 buildings at number 7 and 9 underwent extensive renovations and have become office space.
Nearby, the Nożyk Synagogue also survived the war. It was used as a horse stable by the German Wehrmacht. The synagogue has today been restored and is once again used as an active synagogue.
The best preserved fragments of the ghetto wall are located 55 Sienna Street, 62 Złota Street, and 11 Waliców Street (the last two being walls of the pre-war buildings).
There are two Warsaw Ghetto Heroes' monuments, unveiled in 1946 and 1948 respectively, near the place where the German troops entered the ghetto on 19 April 1943.
In 1988 a stone monument was built to mark the Umschlagplatz.
There is also a small memorial at ul. Mila 18 to commemorate the site of the Jewish underground headquarters during the Ghetto Uprising.
In December 2012, a controversial statue of a kneeling and praying Adolf Hitler was installed in a courtyard of the Ghetto. The artwork by Italian artist, Maurizio Cattelan, entitled "HIM", has received mixed reactions worldwide. Many feel that it is unnecessarily offensive, while others, such as Poland's chief rabbi, Michael Schudrich, feel that is thought-provoking, even "educational".

</doc>
<doc id="42398" url="http://en.wikipedia.org/wiki?curid=42398" title="201">
201

Year 201 (CCI) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Fabianus and Arrius (or, less frequently, year 954 "Ab urbe condita"). The denomination 201 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42399" url="http://en.wikipedia.org/wiki?curid=42399" title="History of Bosnia and Herzegovina">
History of Bosnia and Herzegovina

This is a history of Bosnia and Herzegovina. 
Prehistory and Roman era.
Bosnia has been inhabited at least since Neolithic times. In the late Bronze Age, the Neolithic population was replaced by more warlike Indo-European tribes known as the Illyrians. Celtic migrations in the 4th and 3rd century BCE displaced many Illyrian tribes from their former lands, but some Celtic and Illyrian tribes mixed. Concrete historical evidence for this period is scarce, but overall it appears that the region was populated by a number of different peoples speaking distinct languages. Conflict between the Illyrians and Romans started in 229 BCE, but Rome wouldn't complete its annexation of the region until 9 CE. In the Roman period, Latin-speaking settlers from all over the Roman empire settled among the Illyrians and Roman soldiers were encouraged to retire in the region.
Christianity had already arrived in the region by the end of the 1st century, and numerous artifacts and objects from the time testify to this. Following events from the years 337 and 395 when the Empire split, Dalmatia and Pannonia were included in the Western Roman Empire. The region was conquered by the Ostrogoths in 455, and further exchanged hands between the Alans and Huns in the years to follow.
Middle Ages.
By the 6th century, Emperor Justinian had re-conquered the area for the Byzantine Empire. The Slavs, a migratory people from southeastern Europe, were allied by the Eurasian Avars in the 6th century, and together they invaded the Eastern Roman Empire in the 6th and 7th centuries, settling in what is now Bosnia and Herzegovina and the surrounding lands. More South Slavs came in a second wave, and according to some scholars were invited by Emperor Heraclius to drive the Avars from Dalmatia.
Modern knowledge of Bosnia in the western Balkans during the Dark Ages is patchy. Upon the looter invasions by the Avars and Slavs from 6th-9th century, bringing Slavic languages, both probably gave way to feudalism only with the might by the Frankish penetrating into the region in the late 9th century (Bosnia probably originated as one such pre-feudal entity). It was also around this time that the Bosnians were Christianized. Bosnia, due to its geographic position and terrain, was probably one of the last areas to go through this process, which presumably originated from the urban centers along the Dalmatian coast.
Banate of Bosnia.
It is only from the 9th century that Frankish and Byzantine sources begin to mention early Slavic polities in the region. In this regard, the earliest widely acknowledged reference to Bosnia dates from the 10th century "De Administrando Imperio" written by Byzantine emperor Constantine Porphyrogenitus, during which period Bosnia is briefly a part of the short-lived Serbian state of Časlav, after whose death in battle in about 960, much of Bosnia finds itself briefly incorporated into the Croatian state of Krešimir II. Shortly thereafter, in 997, Samuel of Bulgaria marches through Bosnia and asserts his over-lordship in parts of it, however, only to be defeated by the Byzantine Empire in 1018 which annexes Bulgaria and asserts its suzerainty in Bosnia. This lasted until later in the century when some parts of Bosnia are briefly incorporated into Croatia and others into Duklja from which the latter Bosnia appears to have seceded in about 1101, upon which Bosnia's bans tried to rule for themselves. However, they all too often found themselves in a tug-of-war between Hungary and the Byzantine Empire. In the year of 1137, Hungary annexes most of Bosnia, then briefly losing her in 1167 to the Byzantine Empire before regaining her in 1180. Thus, prior to 1180 and the reign of Ban Kulin parts of Bosnia were briefly found in Serb or Croat units, but neither neighbor had held the Bosnians long enough to acquire their loyalty or to impose any serious claim to Bosnia.
The first recorded Ban (viceroy) was Ban Borić, vassal to the Hungarian king. However, he was deposed when he backed the loser in a succession crisis over the Hungarian throne. In 1167, Byzantium reconquered Bosnia and eventually emplaced their own vassal as Ban – the native Ban Kulin (r. 1180-1204). However, this vassalage was largely nominal, and Bosnia had for all practical purposes made itself into an independent state under Kulin. Ban Kulin presided over nearly three decades of peace and stability during which he strengthened the country's economy through treaties with Dubrovnik and Venice. His rule also marked the start of a controversy with the Bosnian Church, an indigenous Christian sect considered heretical by both the Roman Catholic and Eastern Orthodox churches. In response to Hungarian attempts to use church politics regarding the issue as a way to reclaim sovereignty over Bosnia, Kulin held a council of local church leaders to renounce the heresy in 1203. Despite this, Hungarian ambitions remained unchanged long after Kulin's death in 1204, waning only after an unsuccessful invasion in 1254.
Kingdom of Bosnia.
Bosnian history from then until the early 14th century was marked by the power struggle between the Šubić and Kotromanić families. This conflict came to an end in 1322, when Stjepan II Kotromanić became ban. By the time of his death in 1353, he had succeeded in annexing territories to the north and west, as well as Zahumlje and parts of Dalmatia. He was succeeded by his nephew Tvrtko who, following a prolonged struggle with nobility and inter-family strife, gained full control of the country in 1367. Under Tvrtko, Bosnia grew in both size and power, finally becoming an independent kingdom in 1377. Following his death in 1391 however, Bosnia fell into a long period of decline. The Ottoman Empire had already started its conquest of Europe and posed a major threat to the Balkans throughout the first half of the 15th century. Finally, after decades of political and social instability, Bosnia officially fell in 1463, while resistance was active and fierce for a few more centuries. Southern regions of Bosnia, nowadays known as "Herzegovina" would follow in 1483, with a Hungarian-backed reinstated "Bosnian Kingdom" being the last to succumb in 1527.
Ottoman Era (1463–1878).
The Ottoman conquest of Bosnia marked a new era in the country's history and introduced tremendous changes in the political and cultural landscape of the region. Although the kingdom had been crushed and its high nobility executed, the Ottomans nonetheless allowed for the preservation of Bosnia's identity by incorporating it as an integral province of the Ottoman Empire with its historical name and territorial integrity - a unique case among subjugated states in the Balkans. Within this sandžak (and eventual vilayet) of Bosnia, the Ottomans introduced a number of key changes in the territory's socio-political administration; including a new landholding system, a reorganization of administrative units, and a complex system of social differentiation by class and religious affiliation.
The four centuries of Ottoman rule also had a drastic impact on Bosnia's population make-up, which changed several times as a result of the empire's conquests, frequent wars with European powers, migrations, and epidemics. A native Slavic-speaking Muslim community emerged and eventually became the largest ethno-religious group (mainly as a result of a gradually rising number of conversions to Islam), while a significant number of Sephardi Jews arrived following their expulsion from Spain in the late 15th century. The Bosnian Christian communities also experienced major changes. The Bosnian Franciscans (and the Catholic population as a whole) were protected by official imperial decree, although on the ground these guarantees were often disregarded and their numbers dwindled. The Orthodox community in Bosnia, initially confined to Herzegovina and southeastern Bosnia, spread throughout the country during this period and went on to experience relative prosperity until the 19th century. Meanwhile, the native schismatic Bosnian Church disappeared altogether.
As the Ottoman Empire thrived and expanded into Central Europe, Bosnia was relieved of the pressures of being a frontier province and experienced a prolonged period of general welfare and prosperity. A number of cities, such as Sarajevo and Mostar, were established and grew into major regional centers of trade and urban culture. Within these cities, various Sultans and governors financed the construction of many important works of Bosnian architecture (such as the Stari most and Gazi Husrev-beg's Mosque). Furthermore, numerous Bosnians played influential roles in the Ottoman Empire's cultural and political history during this time. Bosnian soldiers formed a large component of the Ottoman ranks in the battles of Mohács and Krbava field, two decisive military victories, while numerous other Bosnians rose through the ranks of the Ottoman military bureaucracy to occupy the highest positions of power in the Empire, including admirals, generals, and grand viziers. Many Bosnians also made a lasting impression on Ottoman culture, emerging as mystics, scholars, and celebrated poets in the Turkish, Arabic, and Persian languages.
By the late 17th century, however, the Ottoman Empire's military misfortunes caught up with the country, and the conclusion of the Great Turkish War with the Treaty of Karlowitz in 1699 once again made Bosnia the empire's westernmost province. But they allowed some of the Bosnian tribes to immigrate into the Arabian countries (Palestine, Jordan). The following hundred years were marked by further military failures, numerous revolts within Bosnia, and several outbursts of plague. The Porte's efforts at modernizing the Ottoman state were met with great hostility in Bosnia, where local aristocrats stood to lose much through the proposed reforms. This, combined with frustrations over political concessions to nascent Christian states in the east, culminated in a famous (albeit ultimately unsuccessful) revolt by Husein Gradaščević in 1831. Related rebellions would be extinguished by 1850, but the situation continued to deteriorate. Later, agrarian unrest eventually sparked the Herzegovinian rebellion, a widespread peasant uprising, in 1875. The conflict rapidly spread and came to involve several Balkan states and Great Powers, which eventually forced the Ottomans to cede administration of the country to Austria-Hungary through the Treaty of Berlin in 1878.
Occupation by Austria-Hungary (1878–1918).
Though an Austria-Hungary military force quickly subjugated initial armed resistance upon take-over, tensions remained in certain parts of the country (particularly Herzegovina) and a mass emigration of predominantly Muslim dissidents occurred. However, a state of relative stability was reached soon enough and Austro-Hungarian authorities were able to embark on a number of social and administrative reforms which intended to make Bosnia and Herzegovina into a "model colony". With the aim of establishing the province as a stable political model that would help dissipate rising South Slav nationalism, Habsburg rule did much to codify laws, to introduce new political practices, and generally to provide for modernization.
Although successful economically, Austro-Hungarian policy - which focused on advocating the ideal of a pluralist and multi-confessional Bosnian nation (largely favored by the Muslims) - failed to curb the rising tides of nationalism. The concept of Croat and Serb nationhood had already spread to Bosnia and Herzegovina's Catholics and Orthodox communities from neighboring Croatia and Serbia in the mid 19th century, and was too well-entrenched to allow for the widespread acceptance of a parallel idea of Bosnian nationhood. By the latter half of the 1910s, nationalism was an integral factor of Bosnian politics, with national political parties corresponding to the three groups dominating elections.
The idea of a unified South Slavic state (typically expected to be spearheaded by independent Serbia) became a popular political ideology in the region at this time, including in Bosnia and Herzegovina. The Austro-Hungarian government's decision to formally annex Bosnia-Herzegovina in 1908 (the Bosnian Crisis) added to a sense of urgency among these nationalists. The political tensions caused by all this culminated on 28 June 1914, when Serb nationalist youth Gavrilo Princip assassinated the heir to the Austro-Hungarian throne, Archduke Franz Ferdinand, in Sarajevo; an event that proved to be the spark that set off World War I. Although 10% of the Bosniak population died serving in the armies or being killed by the various warring states, Bosnia and Herzegovina itself managed to escape the conflict relatively unscathed.
Kingdom of Yugoslavia (1918–41).
Following World War I, Bosnia was incorporated into the South Slav kingdom of Serbs, Croats and Slovenes (soon renamed Yugoslavia). 
Political life in Bosnia at this time was marked by two major trends: social and economic unrest over the Agrarian Reform of 1918–19 manifested through mass colonization and property confiscation; also formation of several political parties that frequently changed coalitions and alliances with parties in other Yugoslav regions. The dominant ideological conflict of the Yugoslav state, between Croatian regionalism and Serbian centralization, was approached differently by Bosnia's major ethnic groups and was dependent on the overall political atmosphere. Although the initial split of the country into 33 oblasts erased the presence of traditional geographic entities from the map, the efforts of Bosnian politicians such as Mehmed Spaho ensured that the six oblasts carved up from Bosnia and Herzegovina corresponded to the six sanjaks from Ottoman times and, thus, matched the country's traditional boundary as a whole.
The establishment of the Kingdom of Yugoslavia in 1929, however, brought the redrawing of administrative regions into banates that purposely avoided all historical and ethnic lines, removing any trace of a Bosnian entity. Serbo-Croat tensions over the structuring of the Yugoslav state continued, with the concept of a separate Bosnian division receiving little or no consideration. The famous Cvetković-Maček agreement that created the Croatian banate in 1939 encouraged what was essentially a partition of Bosnia between Croatia and Serbia. However, outside political circumstances forced Yugoslav politicians to shift their attention to the rising threat posed by Adolf Hitler's Nazi Germany. Following a period that saw attempts at appeasement, the joining of the Tripartite Pact, and a coup d'état, Yugoslavia was finally invaded by Germany on 6 April 1941.
World War II (1941–1945).
Bosnia was the geographical mother of the partisan movement, providing ample space amongst its mountains for training and development.—Basil Davidson
Once the kingdom of Yugoslavia was conquered by Nazi forces in World War II, all of Bosnia was ceded to the Independent State of Croatia (NDH). The NDH rule over Bosnia led to widespread persecution and genocide. The Jewish population was nearly exterminated. Hundreds of thousands of Serbs died either in Ustaše concentration camps or in widespread mass killings by Ustaše militia. Many Serbs themselves took up arms and joined the Chetniks, a Serb nationalist movement with the aim of establishing an ethnically homogeneous 'Greater Serbian' state.
The Chetniks were responsible for widespread persecution and murder of non-Serbs and communist sympathizers, with the Muslim population of Bosnia, Herzegovina and Sandžak being a primary target. Once captured, Muslim villages were systematically massacred by the Chetniks. The total estimate of Muslims killed by Chetniks is between 80,000 and 100,000, most likely about 86,000 or 6.7 percent of their population (8.1 percent in Bosnia and Herzegovina alone). Several Bosnian Muslim paramilitary units joined the NDH forces to counter their own persecution in the hands of the Serbs in Bosnia. On 12 October 1941 a group of 108 notable Muslim citizens of Sarajevo signed the Resolution of Sarajevo Muslims by which they condemned the persecution of Serbs organized by Ustaše, made distinction between Muslims who participated in such persecutions and the wider Muslim population, presented information about the persecutions of Muslims by Serbs and requested security for all citizens of the country, regardless of their identity. According to the US Holocaust Museum, 320,000-340,000 ethnic Serbs were murdered. According to the Yad Vashem Holocaust Museum and Research Center, "More than 500,000 Serbs were murdered in horribly sadistic ways, 250,000 were expelled, and another 200,000 were forced to convert" during WWII in the Independent State of Croatia (modern day Croatia and Bosnia).
Starting in 1941, Yugoslav communists under the leadership of Josip Broz Tito organized their own multi-ethnic resistance group, the Partisans, who fought against Axis, Ustaše, and Chetnik forces. They too, committed numerous atrocities, mainly against political opponents of all ethnicities. Some Bosnian Muslims joined the SS Handschar division, an SS division of the Nazis that pledged allegiance to both Adolf Hitler and NDH leader, Ante Pavelić. The division was the first SS division which was constituted of non-Germans. On 25 November 1943 the Anti-Fascist Council of National Liberation of Yugoslavia with Tito at its helm held a founding conference in Jajce where Bosnia and Herzegovina was reestablished as a republic within the Yugoslavian federation in its Ottoman borders. Military success eventually prompted the Allies to support the Partisans. On 6 April 1945 Sarajevo was captured by the Partisans. The end of the war resulted in the establishment of the Federal People's Republic of Yugoslavia, with the constitution of 1946 officially making Bosnia and Herzegovina one of six constituent republics in the new state.
Socialist Yugoslavia (1945–1992).
Because of its central geographic position within the Yugoslavian federation, post-war Bosnia was strategically selected as a base for the development of the military defense industry. This contributed to a large concentration of arms and military personnel in Bosnia, a significant factor in the war that followed the breakup of Yugoslavia in the 1990s. However, Bosnia's existence within Yugoslavia was, for the most part, peaceful and prosperous. While it was one of the poorer republics in the early 1950s, Bosnia's economy recovered quickly, as its extensive natural resources were exploited to stimulate industrial development. The Yugoslavian communist doctrine of "brotherhood and unity" particularly suited Bosnia's diverse and multi-ethnic society that, because of such an imposed system of tolerance, thrived culturally and socially.
Though considered a political backwater of the federation for much of the 1950s and 1960s, the 1970s saw the ascension of a strong Bosnian political elite. While working within the communist system, politicians such as Džemal Bijedić, Branko Mikulić and Hamdija Pozderac reinforced and protected the sovereignty of Bosnia and Herzegovina Their efforts proved key during the turbulent period following Tito's death in 1980, and are today considered some of the early steps towards Bosnian independence. However, the republic could not escape the increasingly nationalistic climate of the time unscathed. With the fall of communism and the start of the breakup of Yugoslavia, the old communist doctrine of tolerance began to lose its potency, creating an opportunity for nationalist elements in the society to spread their influence.
Bosnian War (1992–1995).
   Bosniaks 
   Serbs 
   Croats 
The first multi-party parliamentary elections held on 18 and 25 November 1990 led to a national assembly dominated by three ethnically-based parties, which had formed a loose coalition to oust the communists from power. Croatia and Slovenia's subsequent declarations of independence and the warfare that ensued placed Bosnia and Herzegovina and its three constituent peoples in an awkward position. A significant split soon developed on the issue of whether to stay with the Yugoslav federation (overwhelmingly favored among Serbs) or seek independence (overwhelmingly favored among Bosniaks and Croats). A declaration of sovereignty on 15 October 1991 was followed by a referendum for independence from Yugoslavia on 29 February and 1 March 1992. The referendum was boycotted by the great majority of Bosnian Serbs, so with a voter turnout of 64%, 98% of which voted in favor of the proposal. Bosnia and Herzegovina became an independent state on 3 March 1992.
While the first casualty of the war is debated, significant Serbian offensives began in March 1992 in Eastern and Northern Bosnia. Following a tense period of escalating tensions the opening shots in the incipient Bosnian conflict were fired when Serb paramilitary forces attacked Bosniak villages around Čapljina on 7 March 1992 and around Bosanski Brod and Goražde on 15 March. These minor attacks were followed by much more serious Serb artillery attacks on Neum on 19 March and on Bosanski Brod on 24 March. The killing of a Bosniak civilian woman on 5 April 1992 by a sniper, while she was demonstrating in Sarajevo against the raising of barricades by Bosnian Serbs, is widely regarded as marking the start of warfare between the three major communities. Open warfare began in Sarajevo on 6 April.
International recognition of Bosnia and Herzegovina meant that the Yugoslav People's Army (JNA) officially withdrew from the republic's territory, although their Bosnian Serb members merely joined the Army of Republika Srpska. Armed and equipped from JNA stockpiles in Bosnia, supported by volunteers, Republika Srpska's offensives in 1992 managed to place much of the country under its control. By 1993, when an armed conflict erupted between the Sarajevo government and the Croat statelet of Herzeg-Bosnia, about 70% of the country was controlled by the Serbs.
In March 1994, the signing of the Washington accords between the Bosniak and ethnic-Croatian leaders led to the creation of a joint Bosniak-Croat Federation of Bosnia and Herzegovina. This, along with international outrage at Serb war crimes and atrocities (most notably the Srebrenica massacre of as many as 8,000 Bosniak males in July 1995) helped turn the tide of war. The signing of the Dayton Agreement in Paris by the presidents of Bosnia and Herzegovina (Alija Izetbegović), Croatia (Franjo Tuđman), and Yugoslavia (Slobodan Milošević) brought a halt to the fighting, roughly establishing the basic structure of the present-day state. The three years of war and bloodshed had left between 90,000 and 110,000 people killed and more than 2 million displaced.
Independent Bosnia and Herzegovina (1995–present).
Since its 1992 independence and the 1995 Constitutional framework of the Dayton Agreement, Bosnia and Herzegovina has followed a path of state-building, while remaining under final international supervision through the figure of the High Representative for Bosnia and Herzegovina. Bosnia and Herzegovina is a confederation of two "Entities" - the Federation of Bosnia and Herzegovina and the Republika Srpska, as well as the district of Brčko. Each of the Entities has its own constitution and extensive legislative powers.
Bosnia and Herzegovina is a potential candidate country for accession into the EU; an EU-BiH Stabilization and Association Agreement was signed in 2008. Its accession to NATO is in the negotiation phase, and a Membership Action Plan was signed in April 2010.

</doc>
<doc id="42400" url="http://en.wikipedia.org/wiki?curid=42400" title="Socialization">
Socialization

Socialization, also spelled socialisation, is a term used by sociologists, social psychologists, anthropologists, political scientists and educationalists to refer to the lifelong process of inheriting and disseminating norms, customs and ideologies, providing an individual with the skills and habits necessary for participating within their own society. Socialization is thus "the means by which social and cultural continuity are attained".
Socialization describes a process which may lead to desirable outcomes – sometimes labeled "moral" – as regards the society where it occurs. Individual views on certain issues, for instance race or economics, are influenced by the society's consensus and usually tend toward what that society finds acceptable or "normal". Many socio-political theories postulate that socialization provides only a partial explanation for human beliefs and behaviors, maintaining that agents are not blank slates predetermined by their environment; scientific research provides evidence that people are shaped by both social influences and genes. Genetic studies have shown that a person's environment interacts with his or her genotype to influence behavioral outcomes.
Theories.
Socialization is the process by which human infants begin to acquire the skills necessary to perform as a functioning member of their society, and is the most influential learning process one can experience. Unlike many other living species, whose behavior is biologically set, humans need social experiences to learn their culture and to survive. Although cultural variability manifests in the actions, customs, and behaviors of whole social groups (societies), the most fundamental expression of culture is found at the individual level. This expression can only occur after an individual has been socialized by his or her parents, family, extended family, and extended social networks. This reflexive process of both learning and teaching is how cultural and social characteristics attain continuity. Many scientists say socialization essentially represents the whole process of learning throughout the life course and is a central influence on the behavior, beliefs, and actions of adults as well as of children.
Klaus Hurrelmann.
From the late 1980s, sociological and psychological theories have been connected with the term socialization. One example of this connection is the theory of Klaus Hurrelmann. In his book "Social Structure and Personality Development" (Hurrelmann 1989/2009), he develops "The "Model of Productive Processing of Reality" (PPR)." The core idea is that socialization refers to an individual's personality development. It is the result of the productive processing of interior and exterior realities. Bodily and mental qualities and traits constitute a person's inner reality; the circumstances of the social and physical environment embody the external reality. Reality processing is productive because human beings actively grapple with their lives and attempt to cope with the attendant developmental tasks. The success of such a process depends on the personal and social resources available. Incorporated within all developmental tasks is the necessity to reconcile personal individuation and social integration and so secure the "I-dentity." (Hurrelmann1989/2009: 42)
Lawrence Kohlberg.
Lawrence Kohlberg's (1981) theory of moral development studied moral reasoning (how individuals reason situations as right from wrong) within three stages of young childhood. The first is the pre-conventional stage, where children experience the world in terms of pain and pleasure. Second, the conventional stage appears in the teen years of maturation. Teenagers learn to define right and wrong according to the desires of their parents and begin to conform to cultural norms resulting in a decrease of selfishness. The last stage of moral development is the post-conventional level where people move beyond society's norms and consider abstract ethical principles.
Carol Gilligan.
Carol Gilligan compared the moral development of girls and boys in her theory of gender and moral development. She claimed (1982, 1990) that boys have a justice perspective meaning that they rely on formal rules to define right and wrong. Girls, on the other hand, have a care and responsibility perspective where personal relationships are considered when judging a situation. Gilligan also studied the effect of gender on self-esteem. She claimed that society's socialization of females is the reason why girls' self-esteem diminishes as they grow older. Girls struggle to regain their personal strength when moving through adolescence as they have fewer female teachers and most authority figures are men.
Erik H. Erikson.
Erik H. Erikson (1902–1994) explained the challenges throughout the life course. The first stage in the life course is infancy, where babies learn trust and mistrust. The second stage is toddlerhood where children around the age of two struggle with the challenge of autonomy versus doubt. In stage three, preschool, children struggle to understand the difference between initiative and guilt. Stage four, pre-adolescence, children learn about industriousness and inferiority. In the fifth stage called adolescence, teenagers experience the challenge of gaining identity versus confusion. The sixth stage, young adulthood, is when young people gain insight to life when dealing with the challenge of intimacy and isolation. In stage seven, or middle adulthood, people experience the challenge of trying to make a difference (versus self-absorption). In the final stage, stage eight or old age, people are still learning about the challenge of integrity and despair.
George Herbert Mead.
George Herbert Mead (1863–1931) developed a theory of social behaviorism to explain how social experience develops an individual's self-concept. Mead's central concept is the self: It is composed of self-awareness and self-image. Mead claimed that the self is not there at birth, rather, it is developed with social experience. Since social experience is the exchange of symbols, people tend to find meaning in every action. Seeking meaning leads us to imagine the intention of others. Understanding intention requires imagining the situation from the others' point of view. In effect, others are a mirror in which we can see ourselves. Charles Horton Cooley (1902-1983) coined the term looking glass self, which means self-image based on how we think others see us. According to Mead the key to developing the self is learning to take the role of the other. With limited social experience, infants can only develop a sense of identity through imitation. Gradually children learn to take the roles of several others. The final stage is the generalized other, which refers to widespread cultural norms and values we use as a reference for evaluating others.
Judith R. Harris.
Judith R. Harris (b. 1938) graduated magna cum laude with her master's degree in psychology from Harvard University. She received the George A. Miller Award for her proposed theory of group socialization (GS theory). This theory states that a child’s adult personality is determined by childhood and adolescent peer groups outside of the home environment and that “parental behaviors have no effect on the psychological characteristics their children will have as adults.” Harris proposes this theory based on behavioral genetics, sociological views of group processes, context-specific learning, and evolutionary theory. While Harris proposed this theory, she attributes the original idea to Eleanor E. Maccoby and John A. Martin both of whom are doctors at Stanford University and wrote the chapter on family socialization found in the fourth edition of The "Handbook of Child Psychology". After extensively reviewing the research conducted on parent-child interactions, Maccoby and Martin (1983) state that their findings suggest that parental behavior and the home environment has either no effect on the social development of children, or the effect varies significantly between children.
Behavioral genetics suggest that up to fifty percent of the variance in adult personality is due to genetic differences. The environment in which a child is raised accounts for only approximately ten percent in the variance of an adult’s personality. As much as twenty percent of the variance is due measurement error. This suggests that only a very small part of an adult’s personality is influenced by factors parents control (i.e. the home environment). Harris claims that while it’s true that siblings don’t have identical experiences in the home environment (making it difficult to associate a definite figure to the variance of personality due to home environments), the variance found by current methods is so low that researchers should look elsewhere to try to account for the remaining variance.
Harris also states that developing long-term personality characteristics away from the home environment would be evolutionarily beneficial because future success is more likely to depend on interactions with peers than interactions with parents and siblings. Also, because of already existing genetic similarities with parents, developing personalities outside of childhood home environments would further diversify individuals, increasing their evolutionary success.
Language Socialization.
Based on comparative research in different societies, focusing on the role of language in child development, linguistic anthropologists Elinor Ochs and Bambi Schieffelin have developed the theory of language socialization. 
They discovered that the processes of enculturation and socialization do not occur apart from the process of language acquisition, but that children acquire language and culture together in what amounts to an integrated process. Members of all societies socialize children both "to" and "through" the use of language; acquiring competence in a language, the novice is by the same token socialized into the categories and norms of the culture, while the culture, in turn, provides the norms of the use of language.
Stages.
Richard Moreland and John Levine (1982) created a model of group socialization based upon the assumption that individuals and groups change their evaluations and commitments to each other over time. Since these changes happen in all groups, Moreland and Levine speculate that there is a predictable sequence of stages that occur in order for an individual to transition through a group.
Moreland and Levine identify five stages of socialization which mark this transition; investigation, socialization, maintenance, resocialization, and remembrance. During each stage, the individual and the group evaluate each other which leads to an increase or decrease in commitment to socialization. This socialization pushes the individual from prospective, new, full, marginal, and ex member.
Stage 1: Investigation
This stage is marked by a cautious search for information. The individual compares groups in order to determine which one will fulfill their needs ("reconnaissance"), while the group estimates the value of the potential member ("recruitment"). The end of this stage is marked by entry to the group, whereby the group asks the individual to join and they accept the offer.
Stage 2: Socialization
Now that the individual has moved from prospective member to new member, they must accept the group’s culture. At this stage, the individual accepts the group’s norms, values, and perspectives ("assimilation"), and the group adapts to fit the new member’s needs ("accommodation"). The acceptance transition point is then reached and the individual becomes a full member. However, this transition can be delayed if the individual or the group reacts negatively. For example, the individual may react cautiously or misinterpret other members’ reactions if they believe that they will be treated differently as a new comer.
Stage 3: Maintenance 
During this stage, the individual and the group negotiate what contribution is expected of members (role negotiation). While many members remain in this stage until the end of their membership, some individuals are not satisfied with their role in the group or fail to meet the group’s expectations ("divergence").
Stage 4: Resocialization
-If the divergence point is reached, the former full member takes on the role of a marginal member and must be resocialized. There are two possible outcomes of resocialization: differences are resolved and the individual becomes a full member again ("convergence"), or the group expels the individual or the individual decides to leave ("exit").
Stage 5: Remembrance 
In this stage, former members reminisce about their memories of the group, and make sense of their recent departure. If the group reaches a consensus on their reasons for departure, conclusions about the overall experience of the group become part of the group’s "tradition".
Types.
Primary socialization for a child is very important because it sets the ground work for all future socialization. Primary Socialization occurs when a child learns the attitudes, values, and actions appropriate to individuals as members of a particular culture. It is mainly influenced by the immediate family and friends. For example if a child saw his/her mother expressing a discriminatory opinion about a minority group, then that child may think this behavior is acceptable and could continue to have this opinion about minority groups.
Secondary socialization
Secondary socialization refers to the process of learning what is the appropriate behavior as a member of a smaller group within the larger society. Basically, it is the behavioral patterns reinforced by socializing agents of society. Secondary socialization takes place outside the home. It is where children and adults learn how to act in a way that is appropriate for the situations they are in. Schools require very different behavior from the home, and Children must act according to new rules. New teachers have to act in a way that is different from pupils and learn the new rules from people around them. Secondary Socialization is usually associated with teenagers and adults, and involves smaller changes than those occurring in primary socialization. Such examples of Secondary Socialization are entering a new profession or relocating to a new environment or society.
Anticipatory socialization 
Anticipatory socialization refers to the processes of socialization in which a person "rehearses" for future positions, occupations, and social relationships. For example, a couple might move in together before getting married in order to try out, or anticipate, what living together will be like. Research by Kenneth J. Levine and Cynthia A. Hoffner suggests that parents are the main source of anticipatory socialization in regards to jobs and careers.
 Re-socialization 
Re-socialization refers to the process of discarding former behavior patterns and reflexes, accepting new ones as part of a transition in one's life. This occurs throughout the human life cycle. Re-socialization can be an intense experience, with the individual experiencing a sharp break with his or her past, as well as a need to learn and be exposed to radically different norms and values. One common example involves re-socialization through a total institution, or "a setting in which people are isolated from the rest of society and manipulated by an administrative staff". Re-socialization via total institutions involves a two step process: 1) the staff work to root out a new inmate's individual identity & 2) the staff attempt to create for the inmate a new identity. Other examples of this are the experience of a young man or woman leaving home to join the military, or a religious convert internalizing the beliefs and rituals of a new faith. An extreme example would be the process by which a transsexual learns to function socially in a dramatically altered gender role.
 Organizational socialization 
Organizational socialization is the process whereby an employee learns the knowledge and skills necessary to assume his or her organizational role. As newcomers become socialized, they learn about the organization and its history, values, jargon, culture, and procedures. This acquired knowledge about new employees' future work environment affects the way they are able to apply their skills and abilities to their jobs. How actively engaged the employees are in pursuing knowledge affects their socialization process. They also learn about their work group, the specific people they work with on a daily basis, their own role in the organization, the skills needed to do their job, and both formal procedures and informal norms. Socialization functions as a control system in that newcomers learn to internalize and obey organizational values and practices.
Group socialization
Group socialization is the theory that an individual's peer groups, rather than parental figures, influences his or her personality and behavior in adulthood. Adolescents spend more time with peers than with parents. Therefore, peer groups have stronger correlations with personality development than parental figures do. For example, twin brothers, whose genetic makeup are identical, will differ in personality because they have different groups of friends, not necessarily because their parents raised them differently.
Entering high school is a crucial moment in many adolescent's lifespan involving the branching off from the restraints of their parents. When dealing with new life challenges, adolescents take comfort in discussing these issues within their peer groups instead of their parents. Peter Grier, staff writer of the Christian Science Monitor describes this occurrence as,"Call it the benign side of peer pressure. Today's high-schoolers operate in groups that play the role of nag and nanny-in ways that are both beneficial and isolating."
Gender socialization
Henslin (1999:76) contends that "an important part of socialization is the learning of culturally defined gender roles." Gender socialization refers to the learning of behavior and attitudes considered appropriate for a given sex. Boys learn to be boys and girls learn to be girls. This "learning" happens by way of many different agents of socialization. The family is certainly important in reinforcing gender roles, but so are one’s friends, school, work and the mass media. Gender roles are reinforced through "countless subtle and not so subtle ways" (1999:76).
As parents are present in a child's life from the beginning, their influence in a child's early socialization is very important, especially in regards to gender roles. Sociologists have identified four ways in which parents socialize gender roles in their children: Shaping gender related attributes through toys and activities, differing their interaction with children based on the sex of the child, serving as primary gender models, and communicating gender ideals and expectations.
Racial socialization
Racial socialization has been defined as "the developmental processes by which children acquire the behaviors, perceptions, values, and attitudes of an ethnic group, and come to see themselves and others as members of the group". The existing literature conceptualizes racial socialization as having multiple dimensions. Researchers have identified five dimensions that commonly appear in the racial socialization literature: cultural socialization, preparation for bias, promotion of mistrust, egalitarianism, and other. Cultural socialization refers to parenting practices that teach children about their racial history or heritage and is sometimes referred to as pride development. Preparation for bias refers to parenting practices focused on preparing children to be aware of, and cope with, discrimination. Promotion of mistrust refers to the parenting practices of socializing children to be wary of people from other races. Egalitarianism refers to socializing children with the belief that all people are equal and should be treated with a common humanity.
Planned socialization
Planned socialization occurs when other people take actions designed to teach or train others—from infancy on.
Natural Socialization
Natural socialization occurs when infants and youngsters explore, play and discover the social world around them. Natural socialization is easily seen when looking at the young of almost any mammalian species (and some birds). Planned socialization is mostly a human phenomenon; and all through history, people have been making plans for teaching or training others. Both natural and planned socialization can have good and bad features: It is wise to learn the best features of both natural and planned socialization and weave them into our lives.
Positive socialization
Positive socialization is the type of social learning that is based on pleasurable and exciting experiences. We tend to like the people who fill our social learning processes with positive motivation, loving care, and rewarding opportunities.
Negative socialization
Negative socialization occurs when others use punishment, harsh criticisms or anger to try to "teach us a lesson;" and often we come to dislike both negative socialization and the people who impose it on us. There are all types of mixes of positive and negative socialization; and the more positive social learning experiences we have, the happier we tend to be—especially if we learn useful information that helps us cope well with the challenges of life. A high ratio of negative to positive socialization can make a person unhappy, defeated or pessimistic about life.
Social institutions.
In the social sciences, institutions are the structures and mechanisms of social order and cooperation governing the behavior of a set of individuals within a given human collectivity. Institutions are identified with a social purpose and permanence, transcending individual human lives and intentions, and with the making and enforcing of rules governing cooperative human behavior. Types of institution include:
Some sociologists and theorists of culture have recognized the power of mass communication as a socialization device. Denis McQuail recognizes the argument:… the media can teach norms and values by way of symbolic reward and punishment for different kinds of behavior as represented in the media. An alternative view is that it is a learning process whereby we all learn how to behave in certain situations and the expectations which go with a given role or status in society.—McQuail 2005: 494.
Learning can be social or nonsocial. Consider the example of a child learning about bees. If is child is exploring and playing with no one else around, the child may see a bee and touch it (out of curiosity). If the child is stung by the bee, the child learns that touching bees is associated with pain. This is nonsocial learning, since no one else was around. In contrast, a child may benefit from social learning about bees. If the child is with mom, dad or anyone else, the child's inquisitive approach to a bee may lead to some kind of social intervention. Maybe Aunt Emy sees the child reaching for a bee and simply points the child in another direction, saying "Look at that pretty butterfly." Maybe Uncle Ed would say, "Don’t touch the bee, because it can hurt you and make you cry." Maybe Mom would have said, "Honey, stay away from bees because they sting." There are all sorts of ways that people can interact with a child to help the child learn to avoid ever being stung. Any and all of these social interventions allow the child to benefit from social learning, though some of these social interventions may be more educational and useful than others.
Other uses.
To "socialize" may also mean simply to associate or mingle with people socially. In American English, "socialized" has come to refer, usually in a pejorative sense, to the ownership structure of socialism or to the expansion of the welfare state. Traditionally, socialists and Marxists both used the term "socialization of industry" to refer to the reorganization of institutions so that the workers are all owners (cooperatives) and to refer to the implementation of workplace democracy.

</doc>
<doc id="42402" url="http://en.wikipedia.org/wiki?curid=42402" title="Persecution of homosexuals in Nazi Germany and the Holocaust">
Persecution of homosexuals in Nazi Germany and the Holocaust

Upon the rise of Adolf Hitler and the National Socialist German Workers Party (the Nazi Party) in Germany, gay men and, to a lesser extent, lesbians, were two of the numerous groups targeted by the Nazis and were ultimately among Holocaust victims. Beginning in 1933, gay organizations were banned, scholarly books about homosexuality, and sexuality in general, were burned, (such as those from the Institut für Sexualwissenschaft, run by Jewish gay rights campaigner Magnus Hirschfeld) and homosexuals within the Nazi Party itself were murdered. The Gestapo compiled lists of homosexuals, who were compelled to sexually conform to the "German norm."
Between 1933 and 1945, an estimated 100,000 men were arrested as homosexuals, of whom some 50,000 were officially sentenced. Most of these men served time in regular prisons, and an estimated 5,000 to 15,000 of those sentenced were incarcerated in Nazi concentration camps. It is unclear how many of the 5,000 to 15,000 eventually perished in the camps, but leading scholar Rüdiger Lautmann believes that the death rate of homosexuals in concentration camps may have been as high as 60%. Homosexuals in the camps were treated in an unusually cruel manner by their captors.
After the war, the treatment of homosexuals in concentration camps went unacknowledged by most countries, and some men were even re-arrested and imprisoned based on evidence found during the Nazi years. It was not until the 1980s that governments began to acknowledge this episode, and not until 2002 that the German government apologized to the gay community. This period still provokes controversy, however. In 2005, the European Parliament adopted a resolution on the Holocaust which included the persecution of homosexuals.
Purge.
In late February 1933, as the moderating influence of Ernst Röhm weakened, the Nazi Party launched its purge of homosexual (gay, lesbian, and bisexual; then known as homophile) clubs in Berlin, outlawed sex publications, and banned organized gay groups. As a consequence, many fled Germany (e.g., Erika Mann, Richard Plant). In March 1933, Kurt Hiller, the main organizer of Magnus Hirschfeld's Institute of Sex Research, was sent to a concentration camp.
On May 6, 1933, Nazi Youth of the Deutsche Studentenschaft made an organized attack on the Institute of Sex Research. A few days later the Institute's library and archives were publicly hauled out and burned in the streets of the Opernplatz. Around 20,000 books and journals, and 5,000 images, were destroyed. Also seized were the Institute's extensive lists of names and addresses of homosexuals. In the midst of the burning, Joseph Goebbels gave a political speech to a crowd of around 40,000 people. Hitler initially protected Röhm from other elements of the Nazi Party which held his homosexuality to be a violation of the party's strong anti-gay policy. However, Hitler later changed course when he perceived Röhm to be a potential threat to his power. During the Night of the Long Knives in 1934, a purge of those whom Hitler deemed threats to his power took place, he had Röhm murdered and used Röhm's homosexuality as a justification to suppress outrage within the ranks of the SA. After solidifying his power, Hitler would include gay men among those sent to concentration camps during the Holocaust.
Heinrich Himmler had initially been a supporter of Röhm, arguing that the charges of homosexuality against him were manufactured by Jews. But after the purge, Hitler elevated Himmler's status and he became very active in the suppression of homosexuality. He exclaimed, "We must exterminate these people root and branch... the homosexual must be eliminated." 
Shortly after the purge in 1934, a special division of the Gestapo was instituted to compile lists of gay individuals. In 1936, Himmler created the "Reichszentrale zur Bekämpfung der Homosexualität und Abtreibung" (Reich Central Office for the Combating of Homosexuality and Abortion).
Nazi Germany thought of German gay men as against the plan of creating a "master race" and sought to force them into sexual and social conformity. Gay men who would not change or feign a change in their sexual orientation were sent to concentration camps under the "Extermination Through Work" campaign.
More than one million gay Germans were targeted, of whom at least 100,000 were arrested and 50,000 were serving prison terms as "convicted homosexuals". Hundreds of European gay men living under Nazi occupation were castrated under court order.
Some persecuted under these laws would not have identified themselves as gay. Such "anti-homosexual" laws were widespread throughout the western world until the 1960s and 1970s, so many gay men did not feel safe to come forward with their stories until the 1970s when many so-called "sodomy laws" were repealed.
Lesbians were not widely persecuted under Nazi anti-gay laws, as it was considered easier to persuade or force them to comply with accepted heterosexual behavior. However, they were viewed as a threat to state values.
Definition of homosexuality.
The first event that led towards the fight against homosexuality in Nazi Germany was the unification of the German state in 1871 known as the Second Reich. The new state brought forth a new penal code which included paragraph 175. It read, "An unnatural sex act committed between persons of male sex or by humans with animals is punishable by imprisonment; the loss of civil rights might also be imposed." The law was interpreted differently across the nation until the ruling of a court case on April 23, 1880. The Reichsgericht’s (Imperial Court of Justice) ruled that a criminal homosexual act had to involve either anal, oral, or intracrural sex between two men. Anything less of that was deemed harmless play. The German police force found this new interpretation of paragraph 175 extremely difficult to prove in court since it was hard to find witness to these acts. This left the attitude towards homosexuality very relaxed during World War I and early in the rise of the National Socialist German Worker's Party (NSDAP).
After the Purge of homosexual officers in the SA, the NSDAP amended paragraph 175 due to what they saw as loopholes in the law. The most significant change to the law was the change from "An unnatural sex act committed between persons of male sex" to "A male who commits a sex offense with another male." This expanded the reach of the law to persecute gay men. Kissing, mutual masturbation and love-letters between men served as a legitimate reason for the police to make an arrest. Unfortunately for homosexuals, the law never states what a sex offence actually is, leaving it open to subjective interpretation. Men who practiced what was known to be harmless amusement with other men were now being arrested under the law.
Homosexuality and the SS.
According to Geoffrey J. Giles (mentioned earlier) the SS, and its leader Heinrich Himmler, were particularly concerned about homosexuality. More than any other Nazi leader, Himmler's writing and speeches denounced homosexuality. On February 18, 1937 Himmler gave his most detailed speech on the topic in Bad Tölz. However, despite consistently condemning homosexuals and homosexual activity, Himmler was less consistent in his punishment of homosexuals. In Geoffrey Giles' article "The Denial of Homosexuality: Same-Sex Incidents in Himmler's SS", several cases are put forward where members of the Nazi SS are tried for homosexual offences. On a case by case basis, the outcomes vary widely, and Giles gives documented evidence where the judges could be swayed by evidence demonstrating the accused's "aryan-ness" or "manliness", that is, by describing him as coming from true Germanic stock and perhaps fathering children. Reasons for Himmler's leniency in some cases may derive from the difficulty in defining homosexuality, particularly in a society that glorifies the masculine ideal and brotherhood.
Not only was Himmler's persecution of homosexuals based on this masculine ideal, but it was also driven by societal issues. In his speech to the SS on February 18, 1937, Himmler starts his speech off covering the social aspect of the problem. He begins by reminding people of the number of registered members in homosexual associations. He was not convinced that every homosexual was registered in these clubs, but he was also not convinced everyone registered was a homosexual. Himmler estimated the number of homosexuals from one to two million people, or 7 to 10% of men in Germany. He explained "If this remains the case, it means that our nation (Volk) will be destroyed (lit. ‘go kaput’) by this plague." Adding the number of homosexuals to the number of men that died in the previous war, Himmler estimated that this would equal four million men. If these four million men are no longer capable of having sex with a female, then this 'upsets the balance of the sexes in Germany and is leading to catastrophe.' Apparently, Germany was having population issues with the number of killed men during the First World War. Himmler believed "A people of good race which has too few children has a sure ticket for the grave, for insignificance in fifty to one hundred years, for burial in two hundred and fifty years." 
Concentration camps.
Estimates vary widely as to the number of gay men imprisoned in concentration camps during the Holocaust, ranging from 5,000 to 15,000, many of whom died. In addition, records as to the specific reasons for internment are non-existent in many areas, making it hard to put an exact number on exactly how many gay men perished in death camps. See "pink triangle".
Gay men suffered unusually cruel treatment in the concentration camps. They faced persecution not only from German soldiers but also from other prisoners, and many gay men were beaten to death. Additionally, gay men in forced labor camps routinely received more grueling and dangerous work assignments than other non-Jewish inmates, under the policy of "Extermination Through Work". SS soldiers also were known to use gay men for target practice, aiming their weapons at the pink triangles their human targets were forced to wear .
The harsh treatment can be attributed to the view of the SS guards toward gay men, as well as to the homophobic attitudes present in German society at large. The marginalization of gay men in Germany was reflected in the camps. Many died from beatings, some of them inflicted by other prisoners. Nazi doctors often used gay men for scientific experiments in an attempt to locate a "gay gene" to "cure" any future Aryan children who were gay.
Experiences such as these can account for the high death rate of gay men in the camps as compared to the other "asocial" groups. A study by Rüdiger Lautmann found that 60% of gay men in concentration camps died, as compared to 41% for political prisoners and 35% for Jehovah's Witnesses. The study also shows that survival rates for gay men were slightly higher for internees from the middle and upper classes and for married bisexual men and those with children.
Post-War.
Homosexual concentration camp prisoners were not acknowledged as victims of Nazi persecution. Reparations and state pensions available to other groups were refused to gay men, who were still classified as criminals — the 1935 version of Paragraph 175 remained in force in West Germany until 1969 when the "Bundestag" voted to return to the pre-1935 version. Paragraph 175 was not repealed until 1994, although both East and West Germany liberalized their criminal laws against adult homosexuality in the late 1960s.
Holocaust survivors who were homosexual could be re-imprisoned for "repeat offences", and were kept on the modern lists of "sex offenders". Under the Allied Military Government of Germany, some homosexuals were forced to serve out their terms of imprisonment, regardless of the time spent in concentration camps.
The Nazis' anti-gay policies and their destruction of the early gay rights movement were generally not considered suitable subject matter for Holocaust historians and educators. It was not until the 1970s and 1980s that there was some mainstream exploration of the theme, with Holocaust survivors writing their memoirs, plays such as "Bent", and more historical research and documentaries being published about the Nazis' homophobia and their destruction of the German gay-rights movement.
Since the 1980s, some European and international cities have erected memorials to remember the thousands of homosexual people who were murdered and persecuted during the Holocaust. Major memorials can be found in Berlin, Amsterdam (Netherlands), Montevideo (Uruguay), San Francisco (United States of America), Tel Aviv (Israel) and Sydney (Australia). In 2002, the German government issued an official apology to the gay community.
In 2005, the European Parliament marked the 60th anniversary of the liberation of the Auschwitz concentration camp with a minute's silence and the passage of a resolution which included the following text:
An account of a gay Holocaust survivor, Pierre Seel, details life for gay men during Nazi control. In his account he states that he participated in his local gay community in the town of Mulhouse. When the Nazis gained power over the town his name was on a list of local gay men ordered to the police station. He obeyed the directive to protect his family from any retaliation. Upon arriving at the police station he notes that he and other gay men were beaten. Some gay men who resisted the SS had their fingernails pulled out. Others had their bowels punctured, causing them to bleed profusely. After his arrest he was sent to the concentration camp at Schirmeck. There, Seel stated that during a morning roll-call, the Nazi commander announced a public execution. A man was brought out, and Seel recognized his face. It was the face of his eighteen-year-old lover from Mulhouse. Seel states that the Nazi guards then stripped the clothes of his lover, placed a metal bucket over his head, and released trained German Shepherd dogs on him, which mauled him to death.
Rudolf Brazda, believed to be the last surviving person who was sent to a Nazi concentration camp because of his homosexuality, died in France in August 2011, aged 98. Brazda was sent to Buchenwald in August 1942 and held there until its liberation by U.S. forces in 1945. Brazda, who settled in France after the war, was later awarded the Legion of Honour.
Early Holocaust and genocide discourse.
Arising from the dominant discourse of the Jewish suffering during the years of Nazi domination, and building on the divergence of differential victimhoods brought to light by studies of the Roma and the mentally ill, who suffered massively under the eugenics programs of the Third Reich, the idea of a "Gay Holocaust" was first explored in the early 1970s. However, extensive research on the topic was impeded by a continuation of Nazi policies on homosexuals in post-war East and West Germany and continued western notions of homophobia.
The word "genocide" was generated from a need for new terminology in order to understand the gravity of the crimes committed by the Nazis. First coined by Raphael Limkin in 1944, the word became politically charged when The Genocide Act was enacted by the United Nations on December 9, 1948, which created an obligation for governments to respond to such atrocities in the future. The debate on the "Gay Holocaust" is therefore a highly loaded debate which would result in an international acknowledgement of state sponsored homophobia as a precursor to genocide should the proponents of the "Gay Holocaust" succeed. However the United Nations definition does not include sexual orientation (or even social and political groups) within its qualifications for the crime. Genocide by the U.N. definition is limited to national, ethnical, racial or religious groups and as this is the only accord to which nations have pledged allegiance, it stands as the dominant understanding of the term. It is, however, what Michel-Rolph Trouillot terms "an age when collective apologies are becoming increasingly common" as well as a time when the established Holocaust discourse has settled and legitimized claims of the Jewish, Roma and mentally ill victims of Nazi persecution so it would seem an appropriate time to at least bring attention to the debate of the Gay Holocaust, even if the issue is not to be settled.
A lack of research means that there is relatively little data on the dispersion of gay men throughout the camps however Heinz Heger suggests in his book "The Men with the Pink Triangle" that they were subjected to harsher labor than smaller targeted groups, such as the political prisoners, and furthermore suffered a much higher mortality rate. They also lacked a support network within the camps and were ostracized in the prison community. Homosexuals, like the mentally ill and many Jews and Roma, were also subjected to medical experimentation in the hopes of finding a cure to homosexuality at the camp in Buchenwald.
The conception of Jewish exclusivity in the Holocaust went unchallenged in the early years of study on the subject. It is undeniable that the Jews suffered the greatest death toll, and entire communities were obliterated in Eastern Europe and to a great extent in western countries. The notion of exclusivity however is challenged by the existence of similar forces working against different social and ethnic groups such as homosexuals and the Roma, which resulted in the victimization and systematic destruction of homosexual lives and lifestyles, as well as those of the Roma. An inclusion of social groups in a definition of genocide would further challenge the notion of the Jewish genocide as unique within the context of the Holocaust. This sentiment has been further articulated by Elie Weisel, who argued that "a focus on other victims may detract from the Judaic ["sic"] specificity of the Holocaust". Other scholars such as William J. Spurlin have suggested that such positions foster a misrepresentation of history and devalue the suffering of other victims of Nazi atrocities. Simon Wiesenthal argues, for example, that "the Holocaust transcended the confines of Jewish community and that there were other victims." In the mid-1970s new discourses emerged that challenged the exclusivity of the Jewish genocide within the Holocaust, though not without great resistance.
Changes with the civil rights movement.
The civil rights movements of North America in the 1970s saw an emergence of victim claims through revision and appropriation of historical narratives. The shift from the traditionally conservative notion of history as the story of power and those who held it, social historians emerged with narratives of those who suffered and resisted these powers. African Americans created their own narrative, as firmly based on evidence as the discourses already in existence, as part of a social movement towards civil rights based on a history of victimization and racism. Along similar lines, the gay and lesbian movement in the United States also utilized revisionism to write the narrative that had only just garnered an audience willing to validate it.
There were two processes at work in this new discourse, revisionism and appropriation, which Arlene Stein teases out in her article "Whose Memory, Whose Victimhood?", both of which were used at different points in the movement for civil rights. The revisionist project was taken on in a variety of mediums, historical literature being only one of many. The play "Bent" and a limited number of memoirs, which recall "The Diary of Anne Frank" coincided with the appropriation of the pink triangle as a symbol of the new movement and a reminder to "never forget." While the focus of these early revisions was not necessarily to determine the Nazi policy on homosexuals as genocidal, they began a current towards legitimizing the victimization of homosexuals under the regime, a topic that had not been addressed until the 1970s.
Historical works eventually focused on the nature and intent of Nazi policy. Heinz Heger, Gunter Grau and Richard Plant all contributed greatly to the early Holocaust discourse which emerged throughout the 1970s and early 1980s. Central to these studies was the notion that statistically speaking, homosexuals suffered greater losses than many of the smaller minorities under Nazi persecution such as the Jehovah’s Witnesses and within the camps experienced harsher treatments and ostracization as well as execution at the hands of firing squads and the gas chambers.
These early revisionist discourses were joined by a popular movement of appropriation, which invoked the global memory of the Holocaust to shed light on social disparities for homosexuals within the United States. Larry Kramer who was one of the founders of ACT UP, an HIV/AIDS activist group that used shock tactics to bring awareness to the disease and attention to the need for funding popularized the AIDS-as-Holocaust discourse. "The slowness of government response at federal and local levels of government, the paucity of funds for research and treatment, particularly in the early days of the epidemic stems, Kramer argued, from deep-seated homophobic impulses and constituted 'intentional genocide'."
While the appropriation of the Holocaust discourse helped to grab the attention needed for an appropriate response to the pandemic it is highly problematic and perhaps counterproductive to the historical discourse of the time. The notion of AIDS-as-Holocaust and the accompanying notion of AIDS-as-genocide greatly oversimplify the meaning and the intention of genocide as a crime. While parallels can be drawn such as specific group experiencing disproportionate mortality resulting from a seeming neglect by the institutions designed to protect them, the central factors of intention and systematic planning are absent and the use of the word dilutes the severity of the act.
The Holocaust frame was used again in the early 1990s this time in relation to right-wing homophobic campaigns throughout the United States. The conservative response yielded a new discourse working against the "Gay Holocaust" academia which emphasized the gay and lesbian revisionism as a victimist discourse which sought sympathy and recognition as a pragmatic means of garnering special status and civil rights outside those of the moral majority. Arlene Stein identifies four central elements to the conservative reaction to the Gay Holocaust discourse, she argues that the right is attempt to dispel the notion that gays are victims, pit two traditionally liberal constituencies against one another (gays and Jews) thereby draw parallels between Jews and Christians and thereby legitimate its own status as an oppressed and morally upright group.
The victimist argument raises a central tenet as to the reasons for which the discourse of a "Gay Holocaust" has experienced so much resistance politically and popularly (in the conscious of the public). Alyson M. Cole addresses the anti-victim discourse that has emerged in western politics since the end of the 1980s. She asserts "anti-victimists transformed discussions of social obligation, compensations and remedial or restorative procedures into criticisms of the alleged propensity of self-anointed victims to engage in objectionable conduct." Though she is clear that the anti-victimist discourse is not limited to right-wing politics, the case of the "Gay Holocaust" situates itself along these political boundaries and the anti-victim discourse is highly relevant to the debate on homosexual claims to genocide under the Third Reich. Cole also identifies a central conflict within the anti-victim discourse, which sheds light on the weakness in the conservative argument against the Gay Holocaust. While anti-victimists shun the victim and target it for ridicule as a pity-seeking subject-person while simultaneously extolling the virtues of what Cole identifies as the true victim. The true victim holds certain personal qualities, which allow for it to be beyond the ridicule given to the victimist. Propriety, responsibility, individuality and innocence are the central attributes of the true victim and in the case of the Gay Holocaust discourse, the claims made for the recognition of genocide or genocidal processes under Nazi Germany allow the claimants to be relegated to the victimist status, making their 'anti-victim' claims bogus.
Post-revisionist framing of the "Gay Holocaust".
In recent years new work has been done on the Gay Holocaust and rather than emphasizing the severity of destruction to communities or the exclusivity of the genocidal process of the Nazi regime, it focuses on the intersections of social constructions such as gender and sexuality within the context of social organization and political domination. Spurlin claims that these all functioned with one another in forming Germany’s social order and final solution to these social problems. Rather than being autonomous policies, "They were part of a much larger strategy of social disenfranchisement and the marking of enemies..." This discourse incorporates numerous disciplines including gender studies, queer studies, Holocaust studies and genocide studies to tease out the axis at which they meet in social control specifically under National Socialism in Germany.
Further reading.
</dl>

</doc>
<doc id="42404" url="http://en.wikipedia.org/wiki?curid=42404" title="Kibology">
Kibology

Kibology is a parody religion. It grew out of the Usenet newsgroup "alt.religion.kibology" named after Kibo, the central figure. Practitioners of Kibology are called "Kibologists" or (sometimes more disdainfully) "Kibozos".
James "Kibo" Parry and his friends began Kibology about 1989
at the suggestion of Mark Jason Dominus. In its early Usenet days it was centered in the newsgroups talk.bizarre and alt.slack, until the creation of alt.religion.kibology in late 1991. The faux religion aspect faded in the mid-1990s, and the newsgroup became oriented to the sense of humor of Kibo and his "followers". The newsgroup also follows various internet "mad scientists" and "crackpots" with a mixture of mockery and appreciation for the unintended humor they produce. A similar Internet phenomenon exists surrounding the Church of the SubGenius. Some posters also "wackyparse," which is to say, they comment on misreadings with humorous effect.
In addition to "Leader Kibo," other Kibologists have developed cult followings of their own from their unusual and humorous writing. The most prominent of these include David Pacheco, Lisa Pea (Elisabeth Rea Higgins), Matt McIrvin, Stephen Will Tanner, Stefan Kapusniak, M Otis Beard, Joe Bay, Gardner S Trask III, Dag Ågren, and E Teflon Piano. In 2003, the group spawned a band, Interröbang Cartel, which by early late 2011 had written and recorded more than 80 songs with the assistance of their heavy metal umlaut.

</doc>
<doc id="42405" url="http://en.wikipedia.org/wiki?curid=42405" title="Ichthyology">
Ichthyology

Ichthyology (from Greek: ἰχθύς, "ikhthus", "fish"; and λόγος, "logos", "study"), also known as Fish Science, is the branch of biology devoted to the study of fish. This includes bony fishes (Osteichthyes), cartilaginous fish (Chondrichthyes), and jawless fish (Agnatha). While a large number of species have been discovered and described, approximately 250 new species are officially described by science each year. According to FishBase, 32,200 species of fish had been described by March 2012. There are more species of fishes than the combined total of all other vertebrates: mammals, amphibians, reptiles and birds.
History.
The study of fish dates from the Upper Paleolithic Revolution (with the advent of 'high culture'). The science of ichthyology was developed in several interconnecting epochs, each with various significant advancements.
The study of fish receives its origins from human's desire to feed, clothe, and equip themselves with useful implements. According to Michael Barton, a prominent ichthyologist and professor at Centre College, "the earliest ichthyologists were hunters and gatherers who had learned how to obtain the most useful fish, where to obtain them in abundance, and at what times they might be the most available". Early cultures manifested these insights in abstract and identifiable artistic expressions.
1500 BC–40 AD.
Informal, scientific descriptions of fish are represented within the Judeo-Christian tradition. The kashrut forbade the consumption of fishes without scales or appendages. Theologians and ichthyologists speculate that the apostle Peter and his contemporaries harvested the fish that are today sold in modern industry along the Sea of Galilee, presently known as Lake Kinneret. These fish include cyprinids of the genera "Barbus" and "Mirogrex", cichlids of the genus "Sarotherodon", and "Mugil cephalus" of the family Mugilidae.
335 BC–80 AD.
Aristotle incorporated ichthyology into formal scientific study. Between 335 BC–322 BC, he provided the earliest taxonomic classification of fish, accurately describing 117 species of Mediterranean fish. Furthermore, Aristotle documented anatomical and behavioral differences between fish and marine mammals. After his death, some of his pupils continued his ichthyological research. Theophrastus, for example, composed a treatise on amphibious fish. The Romans, although less devoted to science, wrote extensively about fish. Pliny the Elder, a notable Roman naturalist, compiled the ichthyological works of indigenous Greeks, including verifiable and ambiguous peculiarities such as the sawfish and mermaid respectively. Pliny's documentation was the last significant contribution to ichthyology until the European Renaissance.
European Renaissance.
The writings of three sixteenth century scholars, Hippolito Salviani, Pierre Belon, and Guillaume Rondelet, signify the conception of modern ichthyology. The investigations of these individuals were based upon actual research in comparison to ancient recitations. This property popularized and emphasized these discoveries. Despite their prominence, Rondelet's "De Piscibus Marinum" is regarded as the most influential, identifying 244 species of fish.
16th–17th century.
The incremental alterations in navigation and shipbuilding throughout the Renaissance marked the commencement of a new epoch in ichthyology. The Renaissance culminated with the era of exploration and colonization, and upon the cosmopolitan interest in navigation came the specialization in naturalism. Georg Marcgrave of Saxony composed the "Naturalis Brasilae" in 1648. This document contained a description of 100 species of fish indigenous to the Brazilian coastline. In 1686, John Ray and Francis Willughby collaboratively published "Historia Piscium", a scientific manuscript containing 420 species of fish, 178 of these newly discovered. The fish contained within this informative literature were arranged in a provisional system of classification.
The classification used within the "Historia Piscium" was further developed by Carolus Linnaeus, the "father of modern taxonomy". His taxonomic approach became the systematic approach to the study of organisms, including fish. Linnaeus was a professor at the University of Uppsala and an eminent botanist; however, one of his colleagues, Peter Artedi, earned the title "father of ichthyology" through his indispensable advancements. Artedi contributed to Linnaeus's refinement of the principles of taxonomy. Furthermore, he recognized five additional orders of fish: Malacopterygii, Acanthopterygii, Branchiostegi, Chondropterygii, and Plagiuri. Artedi developed standard methods for making counts and measurements of anatomical features that are modernly exploited. Another associate of Linnaeus, Albertus Seba, was a prosperous pharmacist from Amsterdam. Seba assembled a cabinet, or collection, of fish. He invited Artedi to utilize this assortment of fish; unfortunately, in 1735, Artedi fell into an Amsterdam canal and drowned at the age of 30.
Linnaeus posthumously published Artedi's manuscripts as "Ichthyologia, sive Opera Omnia de Piscibus" (1738). His refinement of taxonomy culminated in the development of the binomial nomenclature which is in use by contemporary ichthyologists. Furthermore, he revised the orders introduced by Artedi, placing significance on pelvic fins. Fishes lacking this appendage were placed within the order Apodes; fishes containing abdominal, thoracic, or jugular pelvic fins were termed Abdominales, Thoracici, and Jugulares respectively. However, these alterations were not grounded within evolutionary theory. Therefore, it would take over a century until Charles Darwin would provide the intellectual foundation from which we would be permitted to perceive that the degree of similarity in taxonomic features was a consequence of phylogenetic relationship.
Modern era.
Close to the dawn of the nineteenth century, Marcus Elieser Bloch of Berlin and Georges Cuvier of Paris made attempts to consolidate the knowledge of ichthyology. Cuvier summarized all of the available information in his monumental "Histoire Naturelle des Poissons". This manuscript was published between 1828 and 1849 in a 22 volume series. This documentat describes 4,514 species of fish, 2,311 of these new to science. It remains one of the most ambitious treatises of the modern world. Scientific exploration of the Americas advanced our knowledge of the remarkable diversity of fishes. Charles Alexandre Lesueur was a student of Cuvier. He made a cabinet of fishes dwelling within the Great Lakes and Saint Lawrence River regions.
Adventurous individuals such as John James Audubon and Constantine Samuel Rafinesque figure in the faunal documentation of North America. These persons often traveled with one another. Rafinesque wrote "Ichthyologia Ohiensis" in 1820. In addition, Louis Agassiz of Switzerland established his reputation through the study of freshwater fishes and the first comprehensive treatment of paleoichthyology, Poissons Fossiles. In the 1840s, Agassiz moved to the United States, where he taught at Harvard University until his death in 1873.
Albert Günther published his "Catalogue of the Fishes of the British Museum" between 1859 and 1870, describing over 6,800 species and mentioning another 1,700. Generally considered one of the most influential ichthyologists, David Starr Jordan wrote 650 articles and books on the subject as well as serving as president of Indiana University and Stanford University.
Notable ichthyologists.
Members of this list meet one or more of the following criteria: 1) Author of 50 or more fish taxon names, 2) Author of major reference work in ichthyology, 3) Founder of major journal or museum, 4) Person most notable for other reasons who has also worked in ichthyology.
Paleoichthyologists.
</dl>

</doc>
<doc id="42408" url="http://en.wikipedia.org/wiki?curid=42408" title="Single non-transferable vote">
Single non-transferable vote

Single non-transferable vote or SNTV is an electoral system used in multi-member constituency elections.
Voting.
In any election, each voter casts one vote for one candidate in a multi-candidate race for multiple offices. Posts are filled by the candidates with the most votes. Thus, in a three-seat constituency, the three candidates receiving the largest numbers of votes would win office.
SNTV can be used with non-partisan ballots.
Example.
There are three seats to be filled and five candidates: A, B, C, D and E. 
C, D and E are the winning candidates.
This breaks down by party as:
Party Y has more votes than Party Z, but fewer seats because of an inefficient spread of votes across the candidates. If either party had risked trying to win all three seats, then Party X would have a higher chance of winning a seat, in the event of an uneven distribution of votes.
Proportional representation.
SNTV facilitates minority representation.
SNTV can result in proportional representation when political parties have accurate information about their relative levels of electoral support, and nominate candidates in accordance with their respective level of electoral support. If there are "n" candidates to be elected, Candidate A can guarantee being elected by receiving one more than 1/("n"+1) of the votes (the Droop quota), because "n" other candidates cannot all receive more than Candidate A. It can become very difficult for parties to receive representation proportional to their strength, because they are forced to judge their strength prior to deciding how many candidates to field (strategic nomination). If they field too many, their supporters votes might be split across too many candidates, evenly diluting their share to the point where they "all" lose to a less diluted opposing party. If the party fields too few candidates, they might not win seats proportional to their hypothetical true level of support and excess votes would be wasted on their winning candidates. 
The relative risks of strategic nomination are not the same for parties in other positions of electoral success. A large party with a majority of seats would have much more to lose from the split vote effect than to gain from avoiding the wasted vote effect, and so would likely decide to err on the side of fielding fewer candidates. A small party with little representation would be more risk-tolerant and err on the side of too many candidates, potentially gaining seats greater than their proportion of the electorate by winning with narrower margins of victory than the candidates from larger parties.
SNTV electoral systems, like proportional electoral systems generally, typically produce more proportional electoral outcomes as the size of the electoral districts (number of seats in each constituency) increases.
Potential for tactical voting.
The potential for tactical voting in a single non-transferable vote system is large. Receiving only one vote, the rational voter must only vote for a candidate that has a chance of winning, but will not win by too great a margin, thus taking votes away from party colleagues. This also creates opportunities for tactical nominations, with parties nominating candidates similar to their opponents' candidates in order to split the vote. SNTV has been measured through the lens of such concepts as "decision-theoretic analysis". Professor Gary W. Cox, an expert on SNTV, has studied the results of this system’s use in Japan. Cox has an explanation of real-world data finding the, “two systems [plurality and semi-proportional] are alike in their strategic voting equilibria.” (Cox 608) His research shows that voters use the information offered in campaigns (polls, reporting, fundraising totals, endorsements, etc.), to rationally decide who the most viable candidates are then vote for them. 
SNTV can also result in complicated intra-party dynamics because in a SNTV system, a candidate must not only run against candidates from the other party, but must also run against candidates from their own party. 
Because running on issues may lead to a situation in which a candidate becomes too popular and therefore draws votes away from other allied candidates, it has been argued that SNTV encourages legislators to join factions which consist of patron-client relationships in which a powerful legislator can apportion votes to his or her supporters. It has been argued that many of the characteristics of the Kuomintang in Taiwan and the Liberal Democratic Party of Japan have arisen on account of this.
In addition, parties must ensure that their supporters evenly distribute their votes among the party's candidates. Historically, in Taiwan, the Kuomintang did this by sending members a letter telling them which candidate to vote for. With the Democratic Progressive Party, vote sharing is done informally, as members of a family or small group will coordinate their votes. The New Party had a surprisingly effective system by asking party supporters to vote for the candidate that corresponded to their birthdate. This led to a system of vote allocation which had been adopted by all parties for the 2004 ROC Legislative elections.
Usage.
SNTV is used for legislative elections in Afghanistan, Jordan and for the elections to the upper house of Indonesia and for the senate of Thailand under the 1997 constitution.
Puerto Rico.
In Puerto Rico, where SNTV is known as "at-large representation" ("representación por acumulación" in Spanish), political parties vary the ballot order of their candidates across electoral divisions, in order to ensure each candidate has a roughly equal chance of being elected. Since most voters choose the candidates placed at the top of their party lists on the ballots they receive, at-large candidates from the same party usually obtain approximately equal vote totals.
The two major Puerto Rican political parties, the Popular Democratic Party and the New Progressive Party, usually nominate six candidates for each chamber, while the much smaller Puerto Rican Independence Party runs single-candidate slates for both the Senate and the House of Representatives. The overall distribution of legislative seats is largely determined by the results for the sixteen Senate and forty House district seats, elected by plurality voting.
Japan, South Korea, and Taiwan.
SNTV was once used to elect the parliaments of Japan, South Korea and the Republic of China (Taiwan), but its use has been discontinued for the most part. It is still used in Japan for some seats in the House of Councillors (Sangi-in), prefectural assemblies and municipal assemblies, and in Taiwan for the six aboriginal seats in the Legislative Yuan (national legislature), as well as local assemblies.
In Taiwan, the party structure was further complicated by the fact that while members of the Legislative Yuan were elected by SNTV, executive positions were (and still are) elected by a First Past the Post. This created a party system in which smaller factionalized parties, which SNTV promotes, have formed two large coalitions that resembles the two party system which First Past the Post rewards. Starting with the 2008 legislative elections, the SNTV system was discarded in favor of a mixed "single member district" (SMD) with proportional representation based on national party votes, similar to Japan.
Hong Kong.
Although the electoral system for about half of the seats of the Legislative Council of the territory is nominally a proportional representation system with party lists and Hare quota, in practice political parties would field multiple lists in the same constituency. For example, the Democratic Party fielded three separate lists in the eight-seat New Territories West constituency in the 2008 election, aiming to win three seats (which they ended up with two winners). Split list or split tickets is done in order to win more seats with fewer votes, since the first candidate on each list would require less than the Hare quota to get a seat. Supporters are asked to split their votes among the lists of the same party, usually along geographical location of residence.
In the 2012 election, no candidate list won more than one seat in any of the six PR constituencies which returned a total of 40 seats, rendering the result effectively the same as SNTV.

</doc>
<doc id="42411" url="http://en.wikipedia.org/wiki?curid=42411" title="John Wesley">
John Wesley

John Wesley (; 28 June [O.S. 17 June] 1703 – 2 March 1791) was an Anglican divine and theologian who, with his brother Charles Wesley and fellow cleric George Whitefield, is credited with the foundation of the evangelical movement known as Methodism. His work and writings also played a leading role in the development of the Holiness movement and Pentecostalism.
Educated at Charterhouse School and Oxford University, Wesley was elected a fellow of Lincoln College, Oxford in 1726 and ordained a priest two years later. Returning to Oxford in 1729 after serving as curate at his father's parish, he led the Holy Club, a club for the purpose of study and the pursuit of a devout Christian life; it had been founded by his brother Charles, and counted George Whitefield among its members. After an unsuccessful ministry of two years at Savannah in the Georgia Colony, Wesley returned to London and joined a religious society led by Moravian Christians. On 24 May 1738 he experienced what has come to be called his evangelical conversion, when he felt his "heart strangely warmed". He subsequently departed from the Moravians, beginning his own ministry.
A key step in the development of Wesley's ministry was, like Whitefield, to travel and preach outdoors. In contrast to Whitefield's Calvinism, however, Wesley embraced the Arminian doctrines that dominated the Church of England at the time. Moving across Great Britain, North America and Ireland, he helped to form and organise small Christian groups that developed intensive and personal accountability, discipleship and religious instruction. Most importantly, he appointed itinerant, unordained evangelists to travel and preach as he did and to care for these groups of people. Under Wesley's direction, Methodists became leaders in many social issues of the day, including prison reform and abolitionism.
Although he was not a systematic theologian, Wesley argued for the notion of Christian perfection and against Calvinism – and, in particular, against its doctrine of predestination. He held that, in this life, Christians could achieve a state where the love of God "reigned supreme in their hearts", giving them outward holiness. His evangelicalism, firmly grounded in sacramental theology, maintained that means of grace were the manner by which God sanctifies and transforms the believer, encouraging people to experience Jesus Christ personally.
Throughout his life, Wesley remained within the established Anglican church, insisting that the Methodist movement lay well within its tradition. Although sometimes maverick in his interpretation and use of church policy, he became widely respected and, by the end of his life, had been described as "the best loved man in England".
Early life.
John Wesley was born in 1703 in Epworth, 23 miles (37 km) north-west of Lincoln, as the fifteenth child of Samuel Wesley and his wife Susanna Wesley (née Annesley). Samuel Wesley was a graduate of the University of Oxford and a poet who, since 1696, had been rector of Epworth. He had married Susanna, the twenty-fifth child of Samuel Annesley, a Dissenting minister, in 1689. Ultimately, she bore him nineteen children, of which nine lived beyond infancy. She and Samuel Wesley had both become members of the Church of England as young adults.
As in many families at the time, Wesley's parents gave their children their early education. Each child, including the girls, was taught to read as soon as they could walk and talk. They were expected to become proficient in Latin and Greek and to have learned major portions of the New Testament by heart. Susanna Wesley examined each child before the midday meal and prior to evening prayers. Children were not allowed to eat between meals and were interviewed singularly by their mother one evening each week for the purpose of intensive spiritual instruction. In 1714, at age 11, Wesley was sent to the Charterhouse School in London (under the mastership of John King from 1715), where he lived the studious, methodical and—for a while—religious life in which he had been trained at home.
Apart from his disciplined upbringing, a rectory fire which occurred on 9 February 1709, when Wesley was five years old, left an indelible impression. Some time after 11:00 p.m., the rectory roof caught on fire. Sparks falling on the children’s beds and cries of "fire" from the street roused the Wesleys who managed to shepherd all their children out of the house except for John who was left stranded on the second floor. With stairs aflame and the roof about to collapse, Wesley was lifted out of the second floor window by a parishioner standing on another man’s shoulders. Wesley later utilized the phrase, "a brand plucked out of the fire", quoting Zechariah 3:2, to describe the incident. This childhood deliverance subsequently became part of the Wesley legend, attesting to his special destiny and extraordinary work.
Education.
In June 1720, Wesley entered Christ Church, Oxford. In 1724, Wesley graduated as a Bachelor of Arts and decided to pursue a Master of Arts degree. He was ordained a deacon on 25 September 1725, holy orders being a necessary step toward becoming a fellow and tutor at the university.
In the year of his ordination he read Thomas à Kempis and Jeremy Taylor, and began to seek the religious truths which underlay the great revival of the 18th century. The reading of Law's "Christian Perfection" and "A Serious Call to a Devout and Holy Life" gave him, he said, a sublimer view of the law of God; and he resolved to keep it, inwardly and outwardly, as sacredly as possible, believing that in obedience he would find salvation. He pursued a rigidly methodical and abstemious life, studied the Scriptures, and performed his religious duties diligently, depriving himself so that he would have alms to give. He began to seek after holiness of heart and life.
In March 1726, Wesley was unanimously elected a fellow of Lincoln College, Oxford. This carried with it the right to a room at the college and regular salary. While continuing his studies, Wesley taught Greek, lectured on the New Testament and moderated daily disputations at the university. However, a call to ministry intruded upon his academic career. In August 1727, after taking his master’s degree, Wesley returned to Epworth. His father had requested his assistance in serving the neighbouring cure of Wroote. Ordained a priest on 22 September 1728, Wesley served as a parish curate for two years. He returned to Oxford in November 1729 at the request of the Rector of Lincoln College and to maintain his status as junior Fellow.
Holy Club.
During Wesley's absence, his younger brother Charles (1707–88) matriculated at Christ College. Along with two fellow students, he formed a small club for the purpose of study and the pursuit of a devout Christian life. On Wesley's return, he became the leader of the group which increased somewhat in number and greatly in commitment. The group met daily from six until nine for prayer, psalms, and reading of the Greek New Testament. They prayed every waking hour for several minutes and each day for a special virtue. While the church's prescribed attendance was only three times a year, they took communion every Sunday. They fasted on Wednesdays and Fridays until three o'clock as was commonly observed in the ancient church. In 1730, the group began the practice of visiting prisoners in jail. They preached, educated, and relieved jailed debtors whenever possible, and cared for the sick.
Given the low ebb of spirituality in Oxford at that time, it was not surprising that Wesley's group provoked a negative reaction. They were considered to be religious "enthusiasts" which in the context of the time meant religious fanatics. University wits styled them the "Holy Club," a title of derision. Currents of opposition became a furor following the mental breakdown and death of a group member, William Morgan. In response to the charge that "rigorous fasting" had hastened his death, Wesley noted that Morgan had left off fasting a year and a half since. In the same letter, which was widely circulated, Wesley referred to the name "Methodist" which "some of our neighbors are pleased to compliment us." That name was used by an anonymous author in a published pamphlet (1733) describing Wesley and his group, "The Oxford Methodists."
For all of his outward piety, Wesley sought to cultivate his inner holiness or at least his sincerity as evidence of being a true Christian. A list of "General Questions" which he developed in 1730 evolved into an elaborate grid by 1734 in which he recorded his daily activities hour-by-hour, resolutions he had broken or kept, and ranked his hourly "temper of devotion" on a scale of 1 to 9. Wesley also regarded the contempt with which he and his group were held to be a mark of a true Christian. As he put it in a letter to his father, "Till he be thus contemned, no man is in a state of salvation."
Journey to Savannah, Georgia.
On 14 October 1735, Wesley and his brother Charles sailed on "The Simmonds" from Gravesend in Kent for Savannah in the Province of Georgia in the American colonies at the request of James Oglethorpe, who had founded the colony in 1733 on behalf of the Trustees for the Establishment of the Colony of Georgia in America. Oglethorpe wanted Wesley to be the minister of the newly formed Savannah parish, a new town laid out in accordance with the famous Oglethorpe Plan.
It was on the voyage to the colonies that the Wesleys first came into contact with Moravian settlers. Wesley was influenced by their deep faith and spirituality rooted in pietism. At one point in the voyage a storm came up and broke the mast off the ship. While the English panicked, the Moravians calmly sang hymns and prayed. This experience led Wesley to believe that the Moravians possessed an inner strength which he lacked. The deeply personal religion that the Moravian pietists practised heavily influenced Wesley's theology of Methodism.
Wesley arrived in the colony in February 1736. He approached the Georgia mission as a High Churchman, seeing it as an opportunity to revive "primitive Christianity" in a primitive environment. Although his primary goal was to evangelize the Native Americans, a shortage of clergy in the colony largely limited his ministry to European settlers in Savannah. While his ministry has often been judged to have been a failure in comparison to his later success as a leader in the Evangelical Revival, Wesley gathered around him a group of devoted Christians who met in a number of small group religious societies. At the same time, attendance at church services and communion increased over the course of nearly two years in which he served as Savannah's parish priest.
Nonetheless, Wesley's High Church ministry was controversial amongst the colonists and it ended in disappointment after Wesley fell in love with a young woman named Sophia Hopkey. Following her marriage to William Williamson, Wesley believed Sophia's former zeal for practising the Christian faith declined. In strictly applying the rubrics of the Book of Common Prayer, Wesley denied her communion after she failed to signify to him in advance her intention of taking it. As a result, legal proceedings against him ensued in which a clear resolution seemed unlikely. In December 1737, Wesley fled the colony and returned to England. 
It has been widely-recognized that one of the most significant accomplishments of Wesley's Georgia mission was his publication of a "". The "Collection" was the first Anglican hymnal published in America, and the first of many hymn-books Wesley published. It included five hymns he translated from German.
Conversion and open-air preaching.
Wesley returned to England depressed and beaten. It was at this point that he turned to the Moravians. Both he and Charles received counsel from the young Moravian missionary Peter Boehler, who was temporarily in England awaiting permission to depart for Georgia himself. John's famous "Aldersgate experience" of 24 May 1738, at a Moravian meeting in Aldersgate Street, London, in which he heard a reading of Martin Luther's preface to the Epistle to the Romans, and penned the now famous lines "I felt my heart strangely warmed", revolutionised the character and method of his ministry. The previous week he had been highly impressed by the sermon of John Heylyn, whom he was assisting in the service at St Mary-le-Strand, an occasion followed immediately by news of the death of his brother Samuel. Earlier that day, he had heard the choir at St. Paul's Cathedral singing Psalm 130, where the Psalmist calls to God "Out of the depths." This experience with the Psalms as reflecting his own experience continues throughout his life, as the Psalms function as central texts throughout the writings of Wesley. A few weeks later, Wesley preached a sermon on the doctrine of personal salvation by faith, which was followed by another, on God's grace "free in all, and free for all."
Wesley allied himself with the Moravian society in Fetter Lane. In 1738 he went to Herrnhut, the Moravian headquarters in Germany, to study. On his return to England, Wesley drew up rules for the "bands" into which the Fetter Lane Society was divided and published a collection of hymns for them. He met frequently with this and other religious societies in London but did not preach often in 1738, because most of the parish churches were closed to him.
Wesley's Oxford friend, the evangelist George Whitefield, was also excluded from the churches of Bristol upon his return from America. Going to the neighbouring village of Kingswood, in February 1739, Whitefield preached in the open air to a company of miners. Later he preached in Whitefield's Tabernacle. Wesley hesitated to accept Whitefield's call to copy this bold step. Overcoming his scruples, he preached the first time at Whitefield's invitation sermon in the open air, near Bristol, in April 1739. Wesley wrote,
I could scarce reconcile myself to this strange way of preaching in the fields, of which he [Whitefield] set me an example on Sunday; having been all my life till very lately so tenacious of every point relating to decency and order, that I should have thought the saving of souls almost a sin if it had not been done in a church.
Wesley was unhappy about the idea of field preaching as he believed Anglican liturgy had much to offer in its practice. Earlier in his life he would have thought that such a method of saving souls was "almost a sin." He recognised the open-air services were successful in reaching men and women who would not enter most churches. From then on he took the opportunities to preach wherever an assembly could be brought together, more than once using his father's tombstone at Epworth as a pulpit. Wesley continued for fifty years – entering churches when he was invited, and taking his stand in the fields, in halls, cottages, and chapels, when the churches would not receive him.
Late in 1739 Wesley broke with the Moravians in London. Wesley had helped them organise the Fetter Lane Society, and those converted by his preaching and that of his brother and Whitefield had become members of their bands. But he believed they fell into heresy by supporting quietism, so he decided to form his own followers into a separate society. "Thus," he wrote, "without any previous plan, began the Methodist Society in England." He soon formed similar societies in Bristol and Kingswood, and wherever Wesley and his friends made converts.
Persecutions and lay preaching.
From 1739 onward, Wesley and the Methodists were persecuted by clergy and magistrates for various reasons. Though Wesley had been ordained an Anglican priest, many other Methodist leaders had not received ordination. And for his own part, Wesley flouted many regulations of the Church of England concerning parish boundaries and who had authority to preach. This was seen as a social threat that disregarded institutions. Clergy attacked them in sermons and in print, and at times mobs attacked them. Wesley and his followers continued to work among the neglected and needy. They were denounced as promulgators of strange doctrines, fomenters of religious disturbances; as blind fanatics, leading people astray, claiming miraculous gifts, attacking the clergy of the Church of England, and trying to re-establish Catholicism.
Wesley felt that the church failed to call sinners to repentance, that many of the clergy were corrupt, and that people were perishing in their sins. He believed he was commissioned by God to bring about revival in the church, and no opposition, persecution, or obstacles could prevail against the divine urgency and authority of this commission. The prejudices of his high-church training, his strict notions of the methods and proprieties of public worship, his views of the apostolic succession and the prerogatives of the priest, even his most cherished convictions, were not allowed to stand in the way.
Unwilling that people should perish in their sins and unable to reach them from church pulpits, following the example set by George Whitefield, Wesley began field preaching. Seeing that he and the few clergy co-operating with him could not do the work that needed to be done, he was led, as early as 1739, to approve local preachers. He evaluated and approved men who were not ordained by the Anglican Church to preach and do pastoral work. This expansion of lay preachers was one of the keys of the growth of Methodism.
Chapels and organisations.
As his societies needed houses to worship in, Wesley began to provide chapels, first in Bristol at the New Room, then in London and elsewhere. The Bristol chapel (1739) was at first in the hands of trustees. A large debt was contracted, and Wesley's friends urged him to keep it under his own control, so the deed was cancelled and he became sole trustee. Following this precedent, all Methodist chapels were committed in trust to him until by a "deed of declaration", all his interests in them were transferred to a body of preachers called the "Legal Hundred".
When disorder arose among some members of the societies, Wesley adopted giving tickets to members, with their names written by his own hand. These were renewed every three months. Those deemed unworthy did not receive new tickets and dropped out of the society without disturbance. The tickets were regarded as commendatory letters.
When the debt on a chapel became a burden, it was proposed that one in 12 members should collect offerings regularly from the 11 allotted to him. Out of this grew the Methodist class-meeting system in 1742. In order to keep the disorderly out of the societies, Wesley established a probationary system. He undertook to visit each society regularly in what became the quarterly visitation, or conference. As the number of societies increased, Wesley could not keep personal contact, so in 1743 he drew up a set of "General Rules" for the "United Societies". These were the nucleus of the Methodist "Discipline", still the basis.
Over time, a shifting pattern of societies, circuits, quarterly meetings, annual Conferences, classes, bands, and select societies took shape. At the local level, there were numerous societies of different sizes which were grouped into circuits to which traveling preachers were appointed for two-year periods. Circuit officials met quarterly under a senior traveling preacher or "assistant." Conferences with Wesley, traveling preachers and others were convened annually for the purpose of coordinating doctrine and discipline for the entire connection. Classes of a dozen or so society members under a leader met weekly for spiritual fellowship and guidance. In early years, there were "bands" of the spiritually gifted who consciously pursued perfection. Those who were regarded to have achieved it were grouped in select societies or bands. In 1744, there were 77 such members. There also was a category of penitents which consisted of backsliders.
As the number of preachers and preaching-places increased, doctrinal and administrative matters needed to be discussed; so John and Charles Wesley, along with four other clergy and four lay preachers, met for consultation in London in 1744. This was the first Methodist conference; subsequently, the conference (with Wesley as its president) became the ruling body of the Methodist movement. Two years later, to help preachers work more systematically and societies receive services more regularly, Wesley appointed "helpers" to definitive circuits. Each circuit included at least 30 appointments a month. Believing that the preacher's efficiency was promoted by his being changed from one circuit to another every year or two, Wesley established the "itinerancy" and insisted that his preachers submit to its rules.
Foundry Church London.
John Wesley’s Foundry Church in London no longer exists. Despite this fact, some have attempted to piece together an accurate accounting of the structure which resided on Windmill Hill in Moorfields. For further information, see .
This is truly an effort where little information exists. The location for John Wesley’s Foundry Church is shown on an 18th-century map where it rests between Tabernacle Street and Worship Street in the Moorfields section of London. From this hilltop location and during the years of 1739 to 1778, John Wesley centred from the Foundry Church reached out to the London faithful. The reason for the ceasing of operations In 1778 is that John Wesley’s congregation grew too large, forcing the abandonment of the building which used to cast armament for King Charles. The new location for John Wesley’s ministry was the newly constructed, Chapel on City Road.
Rich is the history behind the Foundry Church. Limited details are given in the , “In 1704, Mr. Mathew Bagley took the Moorfields Foundry and, for twelve years, cast guns and mortars out of metal supplied for the purpose by the Board of Ordinance.”
In the winter of 1739 the cold which seemed to imprison the Christian faithful indoors came in direct conflict with the ill favour of the Anglican priests who eventually banned John Wesley from preaching inside the Anglican churches of England. This forced John Wesley and his faithful outdoors. The unexpected problem resulted in John Wesley, along with his brother, acquiring and renovating the artillery foundry that in the century before cast weapons for King Charles. When John Wesley and his brother Charles spotted the building atop Windmill Hill, north of Finsbury Fields, the structure which previously cast brass guns and mortars for the Royal Ordinance had been sitting vacant for 23 years.
The building was dormant for a very important reason. A historical reason which dates to 10 May 1716, twenty-three years before.
On the infamous date of 10 May 1716 the operation of the artillery foundry was closed to a tragic accident. Again from the Minutes of Proceedings of the Royal Artillery Institution, “After the peace of Utrecht in 1713, the guns captured from the French by Marlborough were placed outside the Moorfields foundry upon Windmill Hill. It was afterwards determined to utilize the metal by recasting it in the form of English ordinance; and on the appointed day- Thursday the 10th of May, 1716- a large number of spectators attracted by the interest felt in the tropics, and in the manufacture of large ordinance, attended at the foundry to witness the operation.” The event is also mentioned in the Mercurius Politicus dated 18 May 1716, “Several Gentlemen were invited to see the Metal run, which being a very great and curious Piece of Art, a great many persons of Quality came to see it, and some general officers of the army among the rest; but whether it was some unusual hindrance in the work, or their better fate that occasioned the Metal to be longer preparing than usual, we know not, but be that as it will, the Gentleman waiting past Ten O’clock, went all or most away. About 11 at Night, the Metal being ready, was let go… the burning metal no sooner sunk down to the bottom of the mold, but with a noise and force equal to that of gunpowder, it came pouring up again, blowing like the mouth of a volcano or a little Vesuvius. There was in that place about 20 men, as well workman as spectators, 17 of whom were so burnt that nothing more horrible can be thought of, neither can words describe their misery. About 9 of the 17 are already dead, the other 8 are yet living, but in such a condition that the surgeons say that they have very small hopes of above 2 of them.”
The explosion killed several key employees including Mr. Hall, the clerk of ordinance. Other clerks received life-threatening wounds. The owner, and his son also lost their lives in this accident. The cause of the tragic event is placed on moisture at the bottom of the mould. Reported later was the fact that Mr. Bagley was warned by a journeyman founder who noticed moisture in the bottom of the mould several hours before. Unfortunately, Mr. Bagley decided that the process needed to continue. The decision was a costly mistake. When the hot liquid of the melted brass touched the latent water, the result was a catastrophic explosion. The blast immediately killed both workers and owners.
The tragic explosion and loss of life forced the British government to take charge of such facilities. The immediate result being the setting up of a new facility at the , taking over the process of producing brass ordinance. Naturally, the foundry in Moorfields was forced to cease operations.
The 1739 acquisition of the closed foundry in Upper Moorfields by John Wesley and his brother Charles transpired without hitch. The subsequent renovations costing the London Methodists nearly eight-hundred British Pounds. The completed building now as a church seated fifteen-hundred people in the main room. In a space directly behind the sanctuary, an additional 300 could seat. The Foundry Church’s simple layout was supported by its brick and mortar construction. Several wood support columns and wooden pews completed the renovated space. Upstairs, two apartments were created for use by the Wesley family.
It wasn't long before the transformed artillery foundry was transforming lives. In fact, John Wesley’s ministry efforts transformed the converted war-foundry in London into the cradle of Methodism.
Ordination of ministers.
As the societies multiplied, they adopted the elements of an ecclesiastical system. The divide between Wesley and the Church of England widened. The question of division from the Church of England was urged by some of his preachers and societies, but most strenuously opposed by his brother Charles. Wesley refused to leave the Church of England, believing that Anglicanism was "with all her blemishes, [...] nearer the Scriptural plans than any other in Europe". In 1745 Wesley wrote that he would make any concession which his conscience permitted, in order to live in peace with the clergy. He could not give up the doctrine of an inward and present salvation by faith itself. He would not stop preaching, nor dissolve the societies, nor end preaching by lay members. As a cleric of the established church he had no plans to go further.
When, in 1746, Wesley read Lord King on the primitive church, he became convinced that the concept of apostolic succession in Anglicanism was a "fable". He wrote that he was "a scriptural "episkopos" as much as many men in England."
Many years later, Edward Stillingfleet's "Irenicon" led him to decide that ordination could be valid when performed by a presbyter rather than a bishop. Nevertheless, many believe that Wesley was consecrated a bishop in 1763 by Erasmus of Arcadia, and that Wesley could not openly announce his episcopal consecration without incurring the penalty of the Præmunire Act.
In 1784, he believed he could not longer wait for the Bishop of London to ordain someone for the American Methodists, who were without the sacraments after the American War of Independence. The Church of England had been disestablished in the United States, where it had been the state church in most of the southern colonies. The Church of England had not yet appointed a United States bishop to what would become the Protestant Episcopal Church in America. Wesley ordained Thomas Coke by the laying on of hands although Coke was already a priest in the Church of England. Wesley appointed him to be superintendent of Methodists in the United States. He also ordained Richard Whatcoat and Thomas Vasey as presbyters. Whatcoat and Vasey sailed to America with Coke. Wesley intended that Coke and Asbury (whom Coke ordained) should ordain others in the newly founded Methodist Episcopal Church in the United States.
His brother Charles grew alarmed and begged Wesley to stop before he had "quite broken down the bridge" and not embitter his [Charles'] last moments on earth, nor "leave an indelible blot on our memory." Wesley replied that he had not separated from the church, nor did he intend to, but he must and would save as many souls as he could while alive, "without being careful about what may possibly be when I die." Although Wesley rejoiced that the Methodists in America were free, he advised his English followers to remain in the established church and he himself died within it.
Doctrine and theology.
The 20th-century Wesley scholar Albert Outler argued in his introduction to the 1964 collection "John Wesley" that Wesley developed his theology by using a method that Outler termed the Wesleyan Quadrilateral. In this method, Wesley believed that the living core of the Christian faith was revealed in Scripture; and the Bible was the sole foundational source of theological or doctrinal development. The centrality of Scripture was so important for Wesley that he called himself "a man of one book"—meaning the Bible—although he was well-read for his day. However, he believed that doctrine had to be in keeping with Christian orthodox tradition. So, tradition was considered the second aspect of the Quadrilateral.
Wesley contended that a part of the theological method would involve experiential faith. In other words, truth would be vivified in personal experience of Christians (overall, not individually), if it were really truth. And every doctrine must be able to be defended rationally. He did not divorce faith from reason. Tradition, experience and reason, however, were subject always to Scripture, Wesley argued, because only there is the Word of God revealed "so far as it is necessary for our salvation."
The doctrines which Wesley emphasised in his sermons and writings are prevenient grace, present personal salvation by faith, the witness of the Spirit, and sanctification. Prevenient grace was the theological underpinning of his belief that all persons were capable of being saved by faith in Christ. Unlike the Calvinists of his day, Wesley did not believe in predestination, that is, that some persons had been elected by God for salvation and others for damnation. He understood that Christian orthodoxy insisted that salvation was only possible by the sovereign grace of God. He expressed his understanding of humanity's relationship to God as utter dependence upon God's grace. God was at work to enable all people to be capable of coming to faith by empowering humans to have actual existential freedom of response to God.
Wesley defined the witness of the Spirit as: "an inward impression on the soul of believers, whereby the Spirit of God directly testifies to their spirit that they are the children of God." He based this doctrine upon certain Biblical passages (see Romans 8:15–16 as an example). This doctrine was closely related to his belief that salvation had to be "personal." In his view, a person must ultimately believe the Good News for himself or herself; no one could be in relation to God for another.
Sanctification he described in 1790 as the "grand "depositum" which God has lodged with the people called `Methodists'." Wesley taught that sanctification was obtainable after justification by faith, between justification and death. He did not contend for "sinless perfection"; rather, he contended that a Christian could be made "perfect in love". (Wesley studied Eastern Orthodoxy and particularly the doctrine of Theosis). This love would mean, first of all, that a believer's motives, rather than being self-centred, would be guided by the deep desire to please God. One would be able to keep from committing what Wesley called, "sin rightly so-called." By this he meant a conscious or intentional breach of God's will or laws. A person could still be able to sin, but intentional or wilful sin could be avoided.
Secondly, to be made perfect in love meant, for Wesley, that a Christian could live with a primary guiding regard for others and their welfare. He based this on Christ's quote that the second great command is "to love your neighbour as you love yourself." In his view, this orientation would cause a person to avoid any number of sins against his neighbour. This love, plus the love for God that could be the central focus of a person's faith, would be what Wesley referred to as "a fulfilment of the law of Christ."
Advocacy of Arminianism.
Wesley entered controversies as he tried to enlarge church practice. The most notable of his controversies was that on Calvinism. His father was of the Arminian school in the church. Wesley came to his own conclusions while in college and expressed himself strongly against the doctrines of Calvinistic election and reprobation.
Whitefield inclined to Calvinism. In his first tour in America, he embraced the views of the New England School of Calvinism. When in 1739 Wesley preached a sermon on "Freedom of Grace", attacking the Calvinistic understanding of predestination as blasphemous, as it represented "God as worse than the devil," Whitefield asked him not to repeat or publish the discourse, as he did not want a dispute. Wesley published his sermon anyway. Whitefield was one of many who responded. The two men separated their practice in 1741. Wesley wrote that those who held to unlimited atonement did not desire separation, but "those who held 'particular redemption' would not hear of any accommodation."
Whitefield, Harris, Cennick, and others, became the founders of Calvinistic Methodism. Whitefield and Wesley, however, were soon back on friendly terms, and their friendship remained unbroken although they travelled different paths. When someone asked Whitefield if he thought he would see Wesley in heaven, Whitefield replied, "I fear not, for he will be so near the eternal throne and we at such a distance, we shall hardly get sight of him."
In 1770, the controversy broke out anew with violence and bitterness, as people's view of God related to their views of men and their possibilities. Augustus Montague Toplady, Rowland, Richard Hill and others were engaged on the one side, while Wesley and Fletcher stood on the other. Toplady was editor of "The Gospel Magazine", which had articles covering the controversy.
In 1778, Wesley began the publication of "The Arminian Magazine", not, he said, to convince Calvinists, but to preserve Methodists. He wanted to teach the truth that "God willeth all men to be saved." A "lasting peace" could be secured in no other way.
His system of thought has become known as Wesleyan Arminianism, the foundations of which were laid by Wesley and Fletcher.
Support for abolitionism.
Later in his ministry, Wesley was a keen abolitionist, speaking out and writing against the slave trade. He published a pamphlet on slavery entitled "Thoughts Upon Slavery" in 1774. To quote from one of his tracts against the slave trade: "Liberty is the right of every human creature, as soon as he breathes the vital air; and no human law can deprive him of that right which he derives from the law of nature". Wesley was a friend of John Newton and William Wilberforce who were also influential in the abolition of slavery in Britain.
Personality and activities.
John Wesley travelled generally on horseback, preaching two or three times each day. Stephen Tomkins writes that he "rode 250,000 miles, gave away 30,000 pounds, ... and preached more than 40,000 sermons... "
He formed societies, opened chapels, examined and commissioned preachers, administered aid charities, prescribed for the sick, helped to pioneer the use of electric shock for the treatment of illness, superintended schools and orphanages, and received at least £20,000 for his publications but used little of it for himself.
Wesley practiced a vegetarian diet and abstained from wine.
After attending a performance in Bristol Cathedral in 1758, Wesley said: "I went to the cathedral to hear Mr. Handel's "Messiah". I doubt if that congregation was ever so serious at a sermon as they were during this performance. In many places, especially several of the choruses, it exceeded my expectation."
He is described as below medium height, well proportioned, strong, with a bright eye, a clear complexion, and a saintly, intellectual face. Wesley married very unhappily at the age of 48 to a widow, Mary Vazeille, described as "a well-to-do widow and mother of four children."
 The couple had no children. Vazeille left him 15 years later. John Singleton writes: "By 1758 she had left him—unable to cope, it is said, with the competition for his time and devotion presented by the ever-burgeoning Methodist movement. Molly, as she was known, was to return and leave him again on several occasions before their final separation." Wesley wryly reported in his journal, "I did not forsake her, I did not dismiss her, I will not recall her."
In 1770, at the death of George Whitefield, Wesley wrote a memorial sermon which praised Whitefield's admirable qualities and acknowledged the two men's differences: "There are many doctrines of a less essential nature ... In these we may think and let think; we may 'agree to disagree.' But, meantime, let us hold fast the essentials..." Wesley was the first to put the phrase 'agree to disagree' in print.
Wesley died on 2 March 1791, in his 87th year. As he lay dying, his friends gathered around him, Wesley grasped their hands and said repeatedly, "Farewell, farewell." At the end, he said "The best of all is, God is with us", lifted his arms and raised his feeble voice again, repeating the words, "The best of all is, God is with us." He was entombed at Wesley's Chapel, which he built in City Road, London, in England. The site also is now both a place of worship and a visitor attraction, incorporating the Museum of Methodism and John Wesley's House.
Because of his charitable nature he died poor, leaving as the result of his life's work 135,000 members and 541 itinerant preachers under the name "Methodist". It has been said that "when John Wesley was carried to his grave, he left behind him a good library of books, a well-worn clergyman's gown" and the Methodist Church.
Literary work.
Wesley was a logical thinker and expressed himself clearly, concisely and forcefully in writing. His written sermons are characterised by spiritual earnestness and simplicity. They are doctrinal but not dogmatic. His "Notes on the New Testament" (1755) are enlightening. Both the "Sermons" (about 140) and the "Notes" are doctrinal standards. Wesley was a fluent, powerful and effective preacher. He usually preached spontaneously and briefly, though occasionally at great length.
As an organiser, a religious leader and a statesman, he was eminent. He knew how to lead and control men to achieve his purposes. He used his power, not to provoke rebellion, but to inspire love. His mission was to spread "Scriptural holiness"; his means and plans were such as Providence indicated. The course thus mapped out for him he pursued with a determination from which nothing could distract him.
Wesley's prose "Works" were first collected by himself (32 vols., Bristol, 1771–74, frequently reprinted in editions varying greatly in the number of volumes). His chief prose works are a standard publication in seven octavo volumes of the Methodist Book Concern, New York. The "Poetical Works" of John and Charles, ed. G. Osborn, appeared in 13 vols., London, 1868–72.
In addition to his "Sermons" and "Notes" are his "Journals" (originally published in 20 parts, London, 1740–89; new ed. by N. Curnock containing notes from unpublished diaries, 6 vols., vols. i.-ii., London and New York, 1909–11); "The Doctrine of Original Sin" (Bristol, 1757; in reply to Dr. John Taylor of Norwich); "An Earnest Appeal to Men of Reason and Religion" (originally published in three parts; 2d ed., Bristol, 1743), an elaborate defence of Methodism, describing the evils of the times in society and the church; a "Plain Account of Christian Perfection" (1766).
Wesley adapted the Book of Common Prayer for use by American Methodists. In his Watch Night service, he made use of a pietist prayer now generally known as the Wesley Covenant Prayer, perhaps his most famous contribution to Christian liturgy. He also was a noted hymn-writer, translator and compiler of a hymnal.
Wesley also wrote on divine physics, such as in "Desideratum", subtitled "Electricity made Plain and Useful by a Lover of Mankind and of Common Sense" (1759).
In spite of the proliferation of his literary output, Wesley was challenged for plagiarism for borrowing heavily from an essay by Samuel Johnson, publishing in March 1775. Initially denying the charge, Wesley later recanted and apologised officially.
Legacy.
Wesley continues to be the primary theological interpreter for Methodists the world over; the largest bodies being the United Methodist Church, the Methodist Church of Great Britain and the African Methodist Episcopal Church. Wesleyan teachings also serve as a basis for the holiness movement, which includes denominations like the Wesleyan Church, the Free Methodist Church, the Church of the Nazarene, the Christian and Missionary Alliance, and several smaller groups, and from which Pentecostalism and parts of the Charismatic Movement are offshoots. Wesley's call to personal and social holiness continues to challenge Christians who attempt to discern what it means to participate in the Kingdom of God. In addition, he refined Arminianism with a strong evangelical emphasis on the Reformed doctrine of justification by faith.
He is commemorated in the Calendar of Saints of the Evangelical Lutheran Church in America on 2 March with his brother Charles. The Wesley brothers are also commemorated on 3 March in the Calendar of Saints of the Episcopal Church and on 24 May in the Anglican calendar.
Wesley's legacy is preserved in Kingswood School, which he founded in 1748 in order to educate the children of the growing number of Methodist preachers. Also, one of the four form houses at the St Marylebone Church of England School, London, is named after John Wesley.
In 2002, Wesley was listed at number 50 on the BBC's list of the 100 Greatest Britons.
In 1831, Wesleyan University in Middletown, Connecticut, was the first institution of higher education in the United States to be named after Wesley. The now secular institution was founded as an all-male Methodist college. About 20 unrelated colleges and universities in the US were subsequently named after him.
In film.
In 1954, the Radio and Film Commission of the Methodist Church in cooperation with J. Arthur Rank produced the film "John Wesley". The film was a live-action re-telling of the story of the life of John Wesley, with Leonard Sachs as Wesley.
In 2009, a more ambitious feature film, "Wesley", was released by Foundery Pictures, starring Burgess Jenkins as John Wesley, with June Lockhart as Susanna Wesley, R. Keith Harris as Charles Wesley, and the Golden Globe winner Kevin McCarthy as Bishop Ryder. The film was directed by the award-winning film-maker John Jackman.

</doc>
<doc id="42412" url="http://en.wikipedia.org/wiki?curid=42412" title="1062">
1062

Year 1062 (MLXII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="42415" url="http://en.wikipedia.org/wiki?curid=42415" title="Electric power control">
Electric power control

The textbook "Electronic Power Control" from Jean Pollefliet (author) covers the most areas of "power electronics" (volume 1: ISBN 9789038217918), while in volume 2 (ISBN 9789038219110) the electronic motor control is treated. Available (USA) on amazon.com
(Electric) Power Control deals with routing electric power, controlling its quality, and controlling the devices attached to a power line.
A number of technologies have evolved for using the power wiring to turn devices attached to the power line on and off, monitoring attached devices, and similar activities. A collective term for one set of technologies is smart buildings. It should be mentioned that unlike within commercial buildings smart building technologies within peoples homes have been less than an overwhelming success. Problems include reliability, cost, questions about how great the need is, and the fact that many smart building tasks such as turning on a lamp at dusk can be performed equally well by simpler, cheaper, and often more reliable, mechanical or electro-mechanical devices. The best known smart building technologies for the home environment are X10 and CEBus and for the commercial Lonworks, DyNet, DSI, DALI and analog systems.
See also domotics, Universal Plug and Play (UPnP), distributed generation.

</doc>
<doc id="42416" url="http://en.wikipedia.org/wiki?curid=42416" title="X10 (industry standard)">
X10 (industry standard)

X10 is a protocol for communication among electronic devices used for home automation ("domotics"). It primarily uses power line wiring for signaling and control, where the signals involve brief radio frequency bursts representing digital information. A wireless radio based protocol transport is also defined.
X10 was developed in 1975 by Pico Electronics of Glenrothes, Scotland, in order to allow remote control of home devices and appliances. It was the first general purpose domotic network technology and remains the most widely available.
Although a number of higher bandwidth alternatives exist, X10 remains popular in the home environment with millions of units in use worldwide, and inexpensive availability of new components.
History.
In 1970, a group of engineers started a company in Glenrothes, Scotland called Pico Electronics. The company revolutionized the calculator industry by developing the first single chip calculator. When calculator IC prices started to fall, Pico refocused on commercial products rather than plain ICs.
In 1974, the Pico engineers jointly developed a vinyl LP turntable, the , with BSR, at the time the largest manufacturer of record changers in the world (an Accutrac changer came later). It could be programmed to play selected tracks, and could be operated by a remote control using ultrasound signals, which sparked the idea of remote control for lights and appliances. By 1975, the X10 project was conceived, named so because it was the tenth project. In 1978, X10 products started to appear in Radio Shack and Sears stores. Together with BSR a partnership was formed, with the name X10 Ltd. At that time the system consisted of a 16 channel command console, a lamp module, and an appliance module. Soon after came the wall switch module and the first X10 timer.
In the 1980s, the CP-290 computer interface was released. Software for the interface runs on the Apple II, Macintosh, MS-DOS, and MS-Windows.
In 1985, BSR went out of business, and X10 (USA) Inc. was formed. In the early 1990s, the consumer market was divided into two main categories, the ultra-high-end with a budget at US$100,000 and the mass market with budgets at US$2,000 to US$35,000. CEBus (1984) and LonWorks (1991) were attempts to improve reliability and replace X10, but have yet to succeed with market ubiquity.
Power line carrier control overview.
Household electrical wiring (the same which powers lights and appliances) is used to send digital data between X10 devices. This digital data is encoded onto a 120 kHz carrier which is transmitted as bursts during the relatively quiet zero crossings of the 50 or 60 Hz AC alternating current waveform. One bit is transmitted at each zero crossing.
The digital data consists of an address and a command sent from a controller to a controlled device. More advanced controllers can also query equally advanced devices to respond with their status. This status may be as simple as "off" or "on", or the current dimming level, or even the temperature or other sensor reading. Devices usually plug into the wall where a lamp, television, or other household appliance plugs in; however some built-in controllers are also available for wall switches and ceiling fixtures.
The relatively high-frequency carrier frequency carrying the signal cannot pass through a power transformer or across the phases of a multiphase system. For split phase systems, the signal can be passively coupled from phase-to-phase using a passive capacitor, but for three phase systems or where the capacitor provides insufficient coupling, an active X10 repeater can be used. To allow signals to be coupled across phases and still match each phase's zero crossing point, each bit is transmitted three times in each half cycle, offset by 1/6 cycle.
It may also be desirable to block X10 signals from leaving the local area so, for example, the X10 controls in one house do not interfere with the X10 controls in a neighboring house. In this situation, inductive filters can be used to attenuate the X10 signals coming into or going out of the local area.
Protocol.
Whether using power line or radio communications, packets transmitted using the X10 control protocol consist of a four bit "house code" followed by one or more four bit "unit codes", finally followed by a four bit command. For the convenience of users configuring a system, the four bit house code is selected as a letter from A through P while the four bit unit code is a number 1 through 16.
When the system is installed, each controlled device is configured to respond to one of the 256 possible addresses (16 house codes × 16 unit codes); each device reacts to commands specifically addressed to it, or possibly to several broadcast commands.
The protocol may transmit a message that says "select code A3", followed by "turn on", which commands unit "A3" to turn on its device. Several units can be addressed before giving the command, allowing a command to affect several units simultaneously. For example, "select A3", "select A15", "select A4", and finally, "turn on", causes units A3, A4, and A15 to all turn on.
Note that there is no restriction that prevents using more than one house code within a single house. The "all lights on" command and "all units off" commands will only affect a single house code, so an installation using multiple house codes effectively has the devices divided into separate zones.
One way vs two way.
Inexpensive X10 devices only receive commands and do not acknowledge their status to the rest of the network. Two-way controller devices allow for a more robust network but cost two to four times more and require two-way X10 devices.
Physical layer details.
In the 60 Hz AC current flow, a bit value of one is represented by a 1 millisecond burst of 120 kHz at the zero crossing point (nominally 0°, but within 200 microseconds of the zero crossing point), immediately followed by the absence of a pulse. A zero value is represented by the absence of 120 kHz at the zero crossing point (pulse), immediately followed by the presence of a pulse. All messages are sent twice to reduce false signaling. After allowing for retransmission, line control, etc., data rates are around 20 bit/s, making X10 data transmission so slow that the technology is confined to turning devices on and off or other very simple operations.
In order to provide a predictable start point, every data frame transmitted always begin with a "start code" of 1110. Immediately after the start code, a "house code" (A–P) appears, and after the letter code comes a "function code". Function codes may specify a unit number code (1–16) or a command code, the selection between the two modes being determined by the last bit where 0=unit number and 1=command. One start code, one letter code, and one function code is known as an X10 frame and represent the minimum components of a valid X10 data packet.
Each frame is sent twice in succession to make sure the receivers understand it over any power line noise for purposes of redundancy, reliability, and to accommodate line repeaters.
Whenever the data changes from one address to another address, from an address to a command, or from one command to another command, the data frames must be separated by at least 6 clear zero crossings (or "000000"). The sequence of six zeros resets the device decoder hardware.
Later developments (1997) of hardware are improvements of the native X10 hardware. This is called "Advanced X10" or A10. These devices contain improved hardware with a receiver and transmitter allowing two-way communication between the devices. In Europe (2001) for the 230 VAC 50 Hz market, this improvement is brought into market under the name Xanura by Eaton/Holec till 2009 (http://www.bwired.nl/How_xanuranew.asp. All improved products use the same X10 protocol and are compatible.
RF protocol.
To allow for wireless keypads, remote switches, motion sensors, et cetera, an RF protocol is also defined. X10 wireless devices send data packets that are nearly identical to the NEC IR protocol used by many IR remotes, and a radio receiver then provides a bridge which translates these radio packets to ordinary X10 power line control packets. The wireless protocol operates at a frequency of 310 MHz in the U.S. and 433.92 MHz in European systems.
The devices available using the radio protocol include:
Hardware support.
Device modules.
Depending on the load that is to be controlled, different modules must be used. For incandescent lamp loads, a "lamp module" or "wall switch" module can be used. These modules switch the power using a TRIAC solid state switch and are also capable of dimming the lamp load. Lamp modules are almost silent in operation, and generally rated to control loads ranging from approximately 40 to 500 watts.
For loads other than incandescent lamps, such as fluorescent lamps, high-intensity discharge lamps, and electrical home appliances, the triac-based electronic switching in the lamp module is unsuitable and an "appliance module" must be used instead. These modules switch the power using an impulse relay. In the U.S., these modules are generally rated to control loads up to 15 amperes (1800 watts at 120V).
Many device modules offer a feature called "local control". If the module is switched off, operating the power switch on the lamp or appliance will cause the module to turn on. In this way, a lamp can still be lit or a coffee pot turned on without the need to use an X10 controller. Wall switch modules may not offer this feature.
Some wall switch modules offer a feature called "local dimming". Ordinarily, the local push button of a wall switch module simply offers on/off control with no possibility of locally dimming the controlled lamp. If local dimming is offered, holding down the push button will cause the lamp to cycle through its brightness range.
Higher end modules have more advanced features such as programmable on levels, customizable fade rates, the ability to transmit commands when used (referred to as 2-way devices), and "scene" support.
There are sensor modules that sense and report temperature, light, infra-red, motion, or contact openings and closures. Device modules include thermostats, audible alarms and controllers for low voltage switches.
Controllers.
X10 controllers range from extremely simple to very sophisticated.
The simplest controllers are arranged to control four X10 devices at four sequential addresses (1–4 or 5–8). The controllers typically contain the following buttons:
More sophisticated controllers can control more units and/or incorporate timers that perform preprogrammed functions at specific times each day. Units are also available that use passive infrared motion detectors or photocells to turn lights on and off based on external conditions.
Finally, very sophisticated units are available that can be fully programmed or, like the X10 Firecracker, use a program running in an external computer. These systems can execute many different timed events, respond to external sensors, and execute, with the press of a single button, an entire "scene", turning lights on, establishing brightness levels, and so on. Control programs are available for computers running Microsoft Windows, Apple's Macintosh, Linux and FreeBSD operating systems.
Burglar alarm systems are also available. These systems contain door/window sensors, as well as motion sensors that use a coded radio frequency (RF) signal to identify when they are tripped or just to routinely check-in and give a heart-beat signal to show that the system is still active. Users can arm and disarm their system via several different remote controls that also use a coded RF signal to ensure security. When an alarm is triggered the console will make an outbound telephone call with a recorded message. The console will also use X10 protocols to flash lights when an alarm has been triggered while the security console sounds an external siren. Using X10 protocols, signals will also be sent to remote sirens for additional security.
Bridges.
There are bridges to translate X10 to other domotic standards (e.g., KNX). ioBridge can be used to translate the X10 protocol to a web service API via the X10 PSC04 Powerline Interface Module. The home controller from allows a transparent interconnection and inter-operation between most home automation technologies.
Limitations.
Compatibility.
Solid-state switches used in X10 controls pass a very small leakage current. Compact fluorescent lamps may display nuisance blinking when switched off; CFL manufacturers recommend against controlling lamps with solid-state timers or remote controls.
Some X10 controllers with triac solid-state outputs may not work well or at all with low power devices (below 50 watts) or devices like fluorescent bulbs that do not present resistive loads, due to the small leakage current of the device and any protective filtering around the triac. Use of an appliance module, which has a relay with metallic contacts, rather than a lamp module, may resolve this problem.
Not all devices can be used on a dimmer. Fluorescent lamps are not dimmable with incandescent lamp dimmers; certain models of compact fluorescent lamps are dimmable but cost more. Motorized appliances such as fans, etc. generally will not operate as expected on a dimmer.
Wiring and interfering sources.
One problem with X10 is excessive attenuation of signals between the two live conductors in the 3-wire 120/240 volt system used in typical North American residential construction. Signals from a transmitter on one live conductor may not propagate through the high impedance of the distribution transformer winding to the other live conductor. Often, there's simply no reliable path to allow the X10 signals to propagate from one transformer leg wire to the other; this failure may come and go as large 240 volt devices such as stoves or dryers are turned on and off. (When turned on, such devices provide a low-impedance bridge for the X10 signals between the two leg wires.) This problem can be permanently overcome by installing a capacitor between the leg wires as a path for the X10 signals; manufacturers commonly sell signal couplers that plug into 240 volt sockets that perform this function. More sophisticated installations install an active repeater device between the legs, while others combine signal amplifiers with a coupling device. A repeater is also needed for inter-phase communication in homes with three-phase electric power. In many countries outside North America, entire houses are typically wired from a single 240 volt single-phase wire, so this problem does not occur.
An RCD/GFCI can attenuate X10 signals passing through the device. This means that X10 signals passing through an RCD may not be strong enough to provide reliable communication.
Television receivers or household wireless devices may cause spurious "off" or "on" signals. Noise filtering (as installed on computers as well as many modern appliances) may help keep external noise out of X10 signals, but noise filters not designed for X10 may also attenuate X10 signals traveling on the branch circuit to which the appliance is connected.
Certain types of power supplies used in modern electronic equipment, such as computers, television receivers and satellite receivers, attenuate passing X10 signals by providing a low impedance path to high frequency signals. Typically, the capacitors used on the inputs to these power supplies short the X10 signal from line to neutral, suppressing any hope of X10 control on the circuit near that device. Filters are available that will block the X10 signals from ever reaching such devices; plugging offending devices into such filters can cure mysterious X10 intermittent failures.
Having a backup power supply or standby power supply such as used with computers or other electronic devices can totally kill that leg in a household installation because of the filtering used in the power supply.
Commands getting lost.
X10 signals can only be transmitted one command at a time, first by addressing the device to control, and then sending an operation for that device to perform. If two X10 signals are transmitted at the same time they may collide or interleave, leading to commands that either cannot be decoded or that trigger incorrect operations. The CM15A and RR501 Transceiver can avoid these signal collisions that can sometimes occur with other models.
Relatively slow.
The X10 protocol is slow. It takes roughly three quarters of a second to transmit a device address and a command. While generally not noticeable when using a tabletop controller, it becomes a noticeable problem when using 2-way switches or when utilizing some sort of computerized controller. The apparent delay can be lessened somewhat by using slower device dim rates. With more advanced modules another option is to use group control (lighting scene) extended commands. These allow adjusting several modules at once by a single command.
Limited functionality.
X10 protocol does support more advanced control over the dimming speed, direct dim level setting and group control (scene settings). This is done via extended message set, which is an official part of X10 standard. However support for all extended messages is not mandatory, and many cheaper modules implement only the basic message set. These require adjusting each lighting circuit one after the other, which can be visually unappealing and also very slow.
Interference and lack of encryption.
The standard X10 power line and RF protocols lack support for encryption, and can only address 256 devices. Unfiltered power line signals from close neighbors using the same X10 device addresses may interfere with each other. Interfering RF wireless signals may similarly be received, with it being easy for anyone nearby with an X10 RF remote to wittingly or unwittingly cause mayhem if an RF to power line device is being used on a premises.

</doc>
<doc id="42418" url="http://en.wikipedia.org/wiki?curid=42418" title="Cable">
Cable

An electrical cable comprises two or more wires running side by side and bonded, twisted, or braided together to form a single assembly, the ends of which can be connected to two devices, enabling the transfer of electrical signals from one device to the other. Cables are used for a wide range of purposes, and each must be tailored for that purpose. Cables are used extensively in electronic devices for power and signal circuits. Long-distance communication takes place over undersea cables. Power cables are used for bulk transmission of alternating and direct current power, especially using high-voltage cable. Electrical cables are extensively used in building wiring for lighting, power and control circuits permanently installed in buildings. Since all the circuit conductors required can be installed in a cable at one time, installation labor is saved compared to certain other wiring methods.
The term originally referred to a nautical line of specific length where multiple ropes, each laid clockwise, are then laid together anti-clockwise and shackled to produce a strong thick line, resistant to water absorption, that was used to anchor large ships. In mechanics, cables, otherwise known as wire ropes, are used for lifting, hauling, and towing or conveying force through tension. In electrical engineering cables are used to carry electric currents. An optical cable contains one or more optical fibers in a protective jacket that supports the fibers.
Etymology.
Ropes made of multiple strands of natural fibers such as, hemp, sisal, manila, and cotton have been used for millennia for hoisting and hauling. By the 19th century, deeper mines as well as construction of larger and larger sailing ships increased demand for stronger ropes. In 1830 the Royal Navy defined a cable as three hawser laid (clockwise) ropes, each approximately 120 fathoms in length, laid anti-clockwise, tightly twisted and shackled to a resulting length of approximately 100 fathoms. The tight twists, shortened the overall length of the ropes but both strengthened the ropes and reduced the ability of the rope to absorb water making them ideal for mooring.
Improvements to steelmaking techniques made high-quality steel available at lower cost, and so wire ropes became common in mining and other industrial applications while continuing the practice of anti-cyclical twists to strengthen them even further. By the middle of the 19th century, manufacture of large submarine telegraph cables was done using machines similar to those used for manufacture of mechanical cables. As the move from rope to wire happened, the specific length associated with a cable fell into disuse.
As electricity became more and more ubiquitous the practice of using more than bare copper led to groupings of wires and various sheathing and shackling methods that resembled the mechanical cabling so the term was adopted for electrical wiring. In the 19th century and early 20th century, electrical cable was often insulated using cloth, rubber or paper. Plastic materials are generally used today, except for high-reliability power cables. The term has also come to be associated with communications because of its use in electrical communications.
Electrical cables.
Electrical cable is an assembly consisting of one or more conductors with their own insulations and optional screens, individual covering(s), assembly protection and protective covering(s). Electrical cables may be made more flexible by stranding the wires. In this process, smaller individual wires are twisted or braided together to produce larger wires that are more flexible than solid wires of similar size. Bunching small wires before concentric stranding adds the most flexibility. Copper wires in a cable may be bare, or they may be plated with a thin layer of another metal, most often tin but sometimes gold, silver or some other material. Tin, gold, and silver are much less prone to oxidation than copper, which may lengthen wire life, and makes soldering easier. Tinning is also used to provide lubrication between strands. Tinning was used to help removal of rubber insulation. Tight lays during stranding makes the cable extensible (CBA – as in telephone handset cords).
Cables can be securely fastened and organized, such as by using trunking, cable trays, cable ties or cable lacing. Continuous-flex or flexible cables used in moving applications within cable carriers can be secured using strain relief devices or cable ties.
At high frequencies, current tends to run along the surface of the conductor. This is known as the skin effect.
Cables and electromagnetic fields.
Any current-carrying conductor, including a cable, radiates an electromagnetic field. Likewise, any conductor or cable will pick up energy from any existing electromagnetic field around it. These effects are often undesirable, in the first case amounting to unwanted transmission of energy which may adversely affect nearby equipment or other parts of the same piece of equipment; and in the second case, unwanted pickup of noise which may mask the desired signal being carried by the cable, or, if the cable is carrying power supply or control voltages, pollute them to such an extent as to cause equipment malfunction.
The first solution to these problems is to keep cable lengths in buildings short, since pick up and transmission are essentially proportional to the length of the cable. The second solution is to route cables away from trouble. Beyond this, there are particular cable designs that minimize electromagnetic pickup and transmission. Three of the principal design techniques are shielding, coaxial geometry, and twisted-pair geometry.
Shielding makes use of the electrical principle of the Faraday cage. The cable is encased for its entire length in foil or wire mesh. All wires running inside this shielding layer will be to a large extent decoupled from external electric fields, particularly if the shield is connected to a point of constant voltage, such as earth. Simple shielding of this type is not greatly effective against low-frequency magnetic fields, however - such as magnetic "hum" from a nearby power transformer. A grounded shield on cables operating at 2.5 kV or more gathers leakage current and capacitive current, protecting people from electric shock and equalizing stress on the cable insulation.
Coaxial design helps to further reduce low-frequency magnetic transmission and pickup. In this design the foil or mesh shield has a circular cross section and the inner conductor is exactly at its center. This causes the voltages induced by a magnetic field between the shield and the core conductor to consist of two nearly equal magnitudes which cancel each other.
A twisted pair has two wires of a cable twisted around each other. This can be demonstrated by putting one end of a pair of wires in a hand drill and turning while maintaining moderate tension on the line. Where the interfering signal has a wavelength that is long compared to the pitch of the twisted pair, alternate lengths of wires develop opposing voltages, tending to cancel the effect of the interference.
Fire protection.
In building construction, electrical cable jacket material is a potential source of fuel for fires. To limit the spread of fire along cable jacketing, one may use cable coating materials or one may use cables with jacketing that is inherently fire retardant. The plastic covering on some metal clad cables may be stripped off at installation to reduce the fuel source for fires. Inorganic coatings and boxes around cables safeguard the adjacent areas from the fire threat associated with unprotected cable jacketing. However, this fire protection also traps heat generated from conductor losses, so the protection must be thin.
To provide fire protection to a cable, the insulation is treated with fire retardant materials, or non-combustible mineral insulation is used (MICC cables).
Hybrid cables.
Hybrid optical and electrical cables can be used in wireless outdoor fiber-to-the-antenna (FTTA) applications. In these cables, the optical fibers carry information, and the electrical conductors are used to transmit power. These cables can be placed in several environments to serve antenna mounted on poles, towers or other structures.
According to Telcordia "Generic Requirements for Hybrid Optical and Electrical Cables for Use in Wireless Outdoor Fiber To The Antenna (FTTA) Applications," these hybrid cables are intended to carry optical fibers, twisted pair/quad elements, coaxial cables or current-carrying electrical conductors under a common outer jacket. The power conductors used in these hybrid cables are for directly powering an antenna or for powering tower-mounted electronics exclusively serving an antenna. They have a nominal voltage normally less than 60 VDC or 108/120 VAC. However, other voltages may be present depending on the application and the relevant National Electrical Code (NEC).
Since the voltage levels and power levels used within these hybrid cables vary, for the purposes of applicable codes, the hybrid cable shall be considered a power cable. As noted in GR-3173, from an NESC perspective (i.e., IEEE C2, "National Electrical Safety Code® [NESC®]"), since these cables are not communications cables and are not power limited, they are considered power cables and need to comply with clearance, separation, and other safety rules.
See also.
For transmission see: Power cable, High-voltage cable and HVDC

</doc>
<doc id="42419" url="http://en.wikipedia.org/wiki?curid=42419" title="Harald Bluetooth">
Harald Bluetooth

Harald "Bluetooth" Gormsson (Old Norse: "Haraldr blátǫnn Gormsson", Danish: "Harald Blåtand Gormsen") (probably born c. 935) was a King of Denmark and Norway. He was the son of King Gorm the Old and of Thyra Dannebod. He died in 985 or 986 having ruled as King of Denmark from c. 958 and King of Norway for a few years; probably around 970. Some sources say his son Sweyn Forkbeard forcibly deposed him.
The Jelling stones.
Harald had the Jelling stones erected to honour his parents. The "Encyclopædia Britannica" considers the runic inscriptions as the most well known in Denmark. The biography of Harald Bluetooth is summed up by this runic inscription from the Jelling stones:
"King Harald bade these memorials to be made after Gorm, his father, and Thyra, his mother. The Harald who won the whole of Denmark and Norway and turned the Danes to Christianity."
Denmark's conversion to Christianity.
King Harald Bluetooth's conversion to Christianity is a contested bit of history, not least because medieval writers such as Widukind of Corvey and Adam of Bremen give conflicting accounts of how it came about.
Widukind of Corvey, writing during the lives of King Harald and Otto I, claims that Harald was converted by a "cleric by the name of Poppa" who, when asked by Harald to prove his faith in Christ, carried a "great weight" of iron heated by a fire without being burned.
Adam of Bremen, writing 100 years after King Harald's death in "History of the Archbishops of Hamburg-Bremen", finished in 1076, describes Harald being forcibly converted by Otto I, after a defeat in battle. However, Widukind does not mention such an event in his contemporary "Res gestae saxonicae sive annalium libri tres" or "Deeds of the Saxons". Four hundred years later, the "Heimskringla" relates that Harald was converted with Earl Haakon, by Otto II.
A cleric named Poppa, perhaps the same one, also appears in Adam of Bremen's history, but in connection with Eric of Sweden, who had supposedly conquered Denmark (there is no evidence anywhere else that this happened). The story of this otherwise unknown Poppo or Poppa's miracle and baptism of Harald is also depicted on the gilded altar piece in the Church of Tandrup in Denmark (see image at top of this article). The altar itself dates to about 1200. Adam of Bremen's claim regarding Otto I and Harald appears to have been inspired by an attempt to manufacture a historical reason for the archbishops of Hamburg-Bremen to claim jurisdiction over Denmark (and thus the rest of Scandinavia); in the 1070s, the Danish King was in Rome asking for Denmark to have its own arch-bishop, and Adam's account of Harald's supposed conversion (and baptism of both him and his "little son" Sweyn, with Otto serving as Sweyn's godfather) is followed by the unambiguous claim that "At that time Denmark on this side of the sea, which is called Jutland by the inhabitants, was divided into three dioceses and subjected to the bishopric of Hamburg."
As noted above, Harald's father, Gorm the Old, had died in 958, and had been buried in a mound with many goods, after the pagan practice. The mound itself was from c. 500 BCE, but Harald had it built higher over his father's grave, and added a second mound to the south. Mound-building was a newly revived custom in the 10th century, perceivably as an "appeal to old traditions in the face of Christian customs spreading from Denmark's southern neighbors, the Germans."
After his conversion, around the 960s, Harald had his father's body reburied in the church next to the now empty mound, and erected one of the Jelling stones described above.
Harald undoubtedly professed Christianity at that time and contributed to its growth, but with limited success in Denmark and Norway.
Reign.
During his reign, Harald oversaw the reconstruction of the Jelling runic stones, and numerous other public works. Some believe these projects were a way for him to consolidate economic and military control of his country. Ring forts were built in five strategic locations: Trelleborg on Zealand, Borrering in eastern Zealand (the inner construction of this fort is still yet to be established), Nonnebakken on Funen, Fyrkat in Himmerland (northern Jutland) and Aggersborg near Limfjord. All five fortresses had similar designs: "perfectly circular with gates opening to the four corners of the earth, and a courtyard divided into four areas which held large houses set in a square pattern." A sixth "Trelleborg" of similar design, located at Borgeby, in Scania, has been dated to about 1000 and may also have been built by King Harald and a second fort named Trelleborg is located near the modern town of Trelleborg in Scania in present-day Sweden, but is of older date and thus pre-dates the reign of Harald Bluetooth.
He constructed the oldest known bridge in southern Scandinavia, the 5 meters wide, 760 meters long Ravninge Bridge at Ravninge meadows.
While quiet prevailed throughout the interior, he turned his energies to foreign enterprises. He came to the help of Richard the Fearless of Normandy in 945 and 963, while his son conquered Samland, and after the assassination of King Harald Greycloak of Norway, managed to force the people of that country into temporary subjugation to himself.
The Norse sagas present Harald in a rather negative light. He was forced twice to submit to the renegade Swedish prince Styrbjörn the Strong of the Jomsvikings- first by giving Styrbjörn a fleet and his daughter Thyra, the second time by giving up himself as hostage, along with yet another fleet. When Styrbjörn brought this fleet to Uppsala to claim the throne of Sweden, Harald broke his oath and fled with his Danes to avoid facing the Swedish army at the Battle of Fýrisvellir.
As a consequence of Harald's army having lost to the Germans at the Danevirke in 974, he no longer had control of Norway, and Germans settled back into the border area between Scandinavia and Germany. They were driven out of Denmark in 983 by an alliance of Obodrite soldiers and troops loyal to Harald, but soon after, Harald was killed fighting off a rebellion led by his son Swein. He is believed to have died in 986, although several accounts claim 985 as his year of death.
From 1835 to 1977 it was believed that Harald ordered the death of Haraldskær Woman, a bog body thought to be Gunnhild, Mother of Kings until radiocarbon dating proved otherwise.
The nickname "Bluetooth".
Harald's nickname "Bluetooth" first documented appearance is in the "Chronicon Roskildense" from 1140. The usual explanation is that Harald must have had a conspicuous bad tooth that has been "blue" (i.e. black, as "blue" meant dark).
Another explanation, is that he was called Thegn in England (corrupted to "tan" when the name came back into Old Norse) — in England, Thane meant chief. Since blue meant "dark", his nickname was really "dark chieftain".
A third theory, according to curator at the Royal Jelling Hans Ole Mathiesen, was that Harald went about clothed in blue. The blue color was in fact the most expensive, so by walking in blue Harald underlined his royal dignity.
Cultural depictions and references.
Sid Meier's Civilization V.
Harald Bluetooth, depicted as leader of Denmark in the video game Sid Meier's Civilization V. He was released along with Denmark as DLC, in the May 2011 DLC The Civilization and Scenario Pack.
Bluetooth communication protocol.
"Bluetooth" now commonly refers to the Bluetooth wireless specification design started by Ericsson, Nokia, Intel and Toshiba to enable cable-free connections between computers, mobile phones, PDAs, printers, etc. The Bluetooth communications protocol in these devices is named after the king, because he unified Denmark and Norway much like the technology whose goal was to unify computers and cellular phones.
The Bluetooth logo consists of the younger futhark runes, also known as the Nordic runes for his initials, H ( hagall) and B ( berkanan) (Long-branch runes version). The younger futhark rune names have been documented; "hagalaz" and "berkana" etc. are posited elder futhark rune names in a posited proto-Germanic 

</doc>
<doc id="42420" url="http://en.wikipedia.org/wiki?curid=42420" title="LAN switching">
LAN switching

LAN switching is a form of packet switching used in local area networks (LAN). Switching technologies are crucial to network design, as they allow traffic to be sent only where it is needed in most cases, using fast, hardware-based methods. LAN switching uses different kinds of network switches. Basic switch is marked as "layer 2 switch" and could be found in nearly all LAN around. "Layer 3" or "layer 4" switch requires advanced technology (see managed switch) and are more expensive, and thus could be found in larger LAN or in the special network environment.
Layer 2 switching.
Layer 2 switching uses the media access control address (MAC address) from the host's network interface cards (NICs) to decide where to forward frames. Layer 2 switching is hardware-based, which means switches use application-specific integrated circuit (ASICs) to build and maintain filter tables (also known as MAC address tables or CAM tables). One way to think of a layer 2 switch is as a multiport bridge.
Layer 2 switching provides the following
Layer 2 switching is highly efficient because there is no modification to the data packet, only to the frame encapsulation of the packet, and only when the data packet is passing through dissimilar media (such as from Ethernet to FDDI). Layer 2 switching is used for workgroup connectivity and network segmentation (breaking up collision domains). This allows a flatter network design with more network segments than traditional 10BaseT shared networks.
Layer 2 switching has helped develop new components in the network infrastructure.
These new technologies allow more data to flow off from local subnets and onto a routed network, where a router's performance can become the bottleneck.
Limitations.
Layer 2 switches have the same limitations as bridge networks. Bridges are good if a network is designed by the 80/20 rule: users spend 80 percent of their time on their local segment.
Bridged networks break up collision domains, but the network remains one large broadcast domain. Similarly, layer 2 switches (bridges) cannot break up broadcast domains, which can cause performance issues and limits the size of your network. Broadcast and multicasts, along with the slow convergence of spanning tree, can cause major problems as the network grows. 
Because of these problems, layer 2 switches cannot completely replace routers in the internetwork.
Layer 3 switching.
Layer 3 switching is solely based on (destination) IP address stored in the header of IP datagram (see layer 4 switching later on this page for the difference). The difference between a layer 3 switch and router is the way the device is making the routing decision. Traditionally, routers use microprocessors to make forwarding decisions, while the switch performs only hardware-based packet switching (by specialized ASIC with the help of CAM memory). However, some traditional routers can have advanced hardware functions as well in some of the higher-end models.
The main advantage of layer 3 switches is low latency. A traditional router receives a whole datagram and then analyzes it (i.e. store and forward). The layer 3 switch is able perform cut-through switching which means that the routing decision could be made by receiving only first part of the datagram (which contains IP addresses). This cut-through operation lowers network latency significantly and, for example, benefits in supercomputer environments with storage attached by iSCSI.
As layer 3 switches have no different functionally than a traditional router, they could be placed anywhere in the network because they cost-effectively replace expensive advanced routers with similar throughput and latency. The operations that a layer 3 switch does in the same manner as a traditional switch are:
The benefits of layer 3 switching include the following:
The switching algorithm is relatively simple and is the same for most of the routed protocols: a host would like to send a packet to a host on another network. Having acquired a router's address by some means, the source host sends the packet directly to that router's physical (MAC) address. The protocol (network layer) address is that of the destination host.
The router examines the packet's destination protocol address and determines whether it knows how to forward the packet or not. If the router does not know how to forward the packet, it typically drops the packet. If it knows how to forward packet, it changes the destination physical address to that of the next hop router and transmits the packet.
The next hop may be the destination or the next router, which executes the same switching process. As the packet moves through the internetwork, its physical address changes, but its protocol address remains same.
IEEE has developed the hierarchical terminology that is useful in describing this process. The network devices without capability to forward packets between subnetworks are called end system (ES), whereas network devices with these capabilities are called intermediate systems (IS). IS are further divided into those that can communicate within routing domain (Intradomain ES) and those that communicate both within and between routing domains (Interdomains IS). A routing domain is generally considered as portion of an internetwork under common administrative authority and is regulated by a particular set of administrative guidelines. Routing domains are also called as autonomous systems.
Layer 4 switching.
Layer 4 switching means hardware-based layer 3 switching technology that can also consider the type of network traffic (for example, distinguish between HTTP, FTP or VoIP). Layer 4 switching provides additional datagram inspection by reading the port numbers found in the Transport layer header to make routing decisions (i.e. ports used by UDP or TCP). These port numbers are found in RFC 1700 and reference the upper-layer protocol, program, or application.
The largest benefit of layer 4 switching is that the network administrator can configure a layer 4 switch to prioritize data traffic by application, which means a QoS can be defined for each user. For example, a number of users can be defined as a Video group and be assigned more priority, or band-width, based on the need for video conferencing.
Layer 4 information has been used to help make routing decisions for quite a while. For example, extended access lists can filter packets based on layer 4 port numbers. Another example is accounting information gathered by open standards using sFlow provided by companies like Arista Networks or proprietary solutions like NetFlow switching in Cisco's higher-end routers.
Multi-layer switching (MLS).
Multi-layer switching combines layer 2, 3 and 4 switching technologies and provides high-speed scalability with low latency. It accomplishes this high combination of high-speed scalability with low latency by using huge filter tables based on the criteria designed by the network administrator.
Multi-layer switching can move traffic at wire speed and also provide layer 3 routing, which can remove the bottleneck from the network routers. This technology is based on the idea of "route once, switch many".
Multi-layer switching can make routing/switching decisions based on the following
There is no performance difference between a layer 3 and a layer 4 switch because the routing/switching is all hardware based (routing decision is done by specialized ASIC with the help of CAM memory).

</doc>
<doc id="42423" url="http://en.wikipedia.org/wiki?curid=42423" title="Monetarism">
Monetarism

In monetary economics, monetarism is a school of thought that emphasises the role of governments in controlling the amount of money in circulation. Monetarists believe that variation in the money supply has major influences on national output in the short run and the price level over longer periods, and that objectives of monetary policy are best met by targeting the growth rate of the money supply rather than by engaging in discretionary monetary policy.
Monetarism today is mainly associated with the work of Milton Friedman, who was among the generation of economists to accept Keynesian economics and then criticise Keynes' theory of gluts using fiscal policy (government spending). Friedman and Anna Schwartz wrote an influential book, "A Monetary History of the United States, 1867–1960", and argued "inflation is always and everywhere a monetary phenomenon." Though he opposed the existence of the Federal Reserve, Friedman advocated, given its existence, a central bank policy aimed at keeping the supply and demand for money at equilibrium, as measured by growth in productivity and demand.
Description.
Monetarism is an economic theory that focuses on the macroeconomic effects of the supply of money and central banking. Formulated by Milton Friedman, it argues that excessive expansion of the money supply is inherently inflationary, and that monetary authorities should focus solely on maintaining price stability.
This theory draws its roots from two historically antagonistic schools of thought: the hard money policies that dominated monetary thinking in the late 19th century, and the monetary theories of John Maynard Keynes, who, working in the inter-war period during the failure of the restored gold standard, proposed a demand-driven model for money. While Keynes had focused on the value stability of currency, with the resulting panics based on an insufficient money supply leading to alternate currency and collapse, then Friedman focused on price stability, which is the equilibrium between supply and demand for money.
The result was summarised in a historical analysis of monetary policy, "Monetary History of the United States 1867–1960", which Friedman coauthored with Anna Schwartz. The book attributed inflation to excess money supply generated by a central bank. It attributed deflationary spirals to the reverse effect of a failure of a central bank to support the money supply during a liquidity crunch.
Friedman originally proposed a fixed "monetary rule", called Friedman's k-percent rule, where the money supply would be automatically increased by a fixed percentage per year. Under this rule, there would be no leeway for the central reserve bank as money supply increases could be determined "by a computer", and business could anticipate all money supply changes. With other monetarists he believed that the active manipulation of the money supply or its growth rate is more likely to destabilise than stabilise the economy.
Opposition to the gold standard.
Most monetarists oppose the gold standard. Friedman, for example, viewed a pure gold standard as impractical. For example, whereas one of the benefits of the gold standard is that the intrinsic limitations to the growth of the money supply by the use of gold or silver would prevent inflation, if the growth of population or increase in trade outpaces the money supply, there would be no way to counteract deflation and reduced liquidity (and any attendant recession) except for the mining of more gold or silver under a gold or silver standard.
Rise.
Clark Warburton is credited with making the first solid empirical case for the monetarist interpretation of business fluctuations in a series of papers from 1945.p. 493 Within mainstream economics, the rise of monetarism accelerated from Milton Friedman's 1956 restatement of the quantity theory of money. Friedman argued that the demand for money could be described as depending on a small number of economic variables.
Thus, where the money supply expanded, people would not simply wish to hold the extra money in idle money balances; i.e., if they were in equilibrium before the increase, they were already holding money balances to suit their requirements, and thus after the increase they would have money balances surplus to their requirements. These excess money balances would therefore be spent and hence aggregate demand would rise. Similarly, if the money supply were reduced people would want to replenish their holdings of money by reducing their spending. In this, Friedman challenged a simplification attributed to Keynes suggesting that "money does not matter." Thus the word 'monetarist' was coined.
The rise of the popularity of monetarism also picked up in political circles when Keynesian economics seemed unable to explain or cure the seemingly contradictory problems of rising unemployment and inflation in response to the collapse of the Bretton Woods system in 1972 and the oil shocks of 1973. On the one hand, higher unemployment seemed to call for Keynesian reflation, but on the other hand rising inflation seemed to call for Keynesian disinflation.
In 1979, President Jimmy Carter appointed a Federal Reserve chief Paul Volcker, who made inflation fighting his primary objective, and restricted the money supply (in accordance with the Friedman rule) to tame inflation in the economy. The result was the creation of the desired price stability.
Monetarists not only sought to explain present problems; they also interpreted historical ones. Milton Friedman and Anna Schwartz in their book "A Monetary History of the United States, 1867–1960" argued that the Great Depression of 1930 was caused by a massive contraction of the money supply and not by the lack of investment Keynes had argued. They also maintained that post-war inflation was caused by an over-expansion of the money supply.
They made famous the assertion of monetarism that 'inflation is always and everywhere a monetary phenomenon'. Many Keynesian economists initially believed that the Keynesian vs. monetarist debate was solely about whether fiscal or monetary policy was the more effective tool of demand management. By the mid-1970s, however, the debate had moved on to other issues as monetarists began presenting a fundamental challenge to Keynesianism.
Many monetarists sought to resurrect the pre-Keynesian view that market economies are inherently stable in the absence of major unexpected fluctuations in the money supply. Because of this belief in the stability of free-market economies they asserted that active demand management (e.g. by the means of increasing government spending) is unnecessary and indeed likely to be harmful. The basis of this argument is an equilibrium between "stimulus" fiscal spending and future interest rates. In effect, Friedman's model argues that current fiscal spending creates as much of a drag on the economy by increased interest rates as it creates present consumption: that it has no real effect on total demand, merely that of shifting demand from the investment sector (I) to the consumer sector (C).
When Margaret Thatcher, leader of the Conservative Party in the United Kingdom, won the 1979 general election defeating the incumbent Labour Party led by James Callaghan, Britain had endured several years of severe inflation, which was rarely below 10% and by the time of the election in May 1979 stood at 10.3%. Thatcher implemented monetarism as the weapon in her battle against inflation, and succeeded at reducing it to 4.6% by 1983.
James Callaghan himself had adopted policies echoing monetarism while serving as prime minister from 1976 to 1979, adopting deflationary policies and reducing public spending in response to high inflation and national debt. He initially had some success, as inflation was below 10% by the summer of 1978, although unemployment now stood at 1,500,000. However, by the time of his election defeat barely a year later, inflation had soared to 27%.
Criticism.
According to Alan Blinder and Robert Solow, fiscal policy becomes impotent only when an interest-elasticity of the demand for money is zero. Empirically, such a perfect inelasticity does not occur. However, there are limited policy options when the interest rate is at or near the zero lower bound
Although Milton Friedman believed that wealth effects make deficit spending contractionary, Blinder and Solow believed that in reality fiscal stimulus is effective. To see this, they used a government budget constraint equation which includes interest on government bonds: 
where B is the number of bonds whose face value per unit bond is 1 dollar. T is the tax function. In the long-run stationary state, 
which gives 
Immediately, it turns out that under money financing the fiscal multiplier becomes 
because in this case 
formula_5. Both monetarists and Keynesians agree with the idea that money-financed deficit spending has an expansionary impact on the economy. If deficits are financed by bonds, the long-run fiscal multiplier becomes larger than that by money-creation:
Thus their research shows that, in the long run, bond-financed government spending increases the income level more than money-financed deficit spending does.
Practice.
A realistic theory should be able to explain the deflationary waves of the late 19th century, the Great Depression, and the stagflation period beginning with the uncoupling of exchange rates in 1972. Monetarists argue that there was no inflationary investment boom in the 1920s. Instead, monetarist thinking centers on the contraction of the M1 during the 1931–1933 period, and argues from there that the Federal Reserve could have avoided the Great Depression by moves to provide sufficient liquidity. In essence, they argue that there was an insufficient supply of money.
From their conclusion that incorrect central bank policy is at the root of large swings in inflation and price instability, monetarists argued that the primary motivation for excessive easing of central bank policy is to finance fiscal deficits by the central government. Hence, restraint of government spending is the most important single target to restrain excessive monetary growth.
With the failure of demand-driven fiscal policies to restrain inflation and produce growth in the 1970s, the way was paved for a new policy of fighting inflation through the central bank, which would be the bank's cardinal responsibility. In typical economic theory, this would be accompanied by austerity shock treatment, as is generally recommended by the International Monetary Fund: such a course was taken in the United Kingdom, where government spending was slashed in the late 1970s and early 1980s under the political ascendance of Prime Minister Margaret Thatcher. In the United States, the opposite approach was taken and real government spending increased much faster during President Ronald Reagan's first four years (4.22%/year) than it did under Carter (2.55%/year).
In the ensuing short term, unemployment in both countries remained stubbornly high while central banks raised interest rates to restrain credit. These policies dramatically reduced inflation rates in both countries (the United States' inflation rate fell from almost 14% in 1980 to around 3% in 1983 ), allowing liberalisation of credit and the reduction of interest rates, which led ultimately to the inflationary economic booms of the 1980s. Arguments have been raised, however, that the fall of the inflation rate may be less from control of the money supply and more to do with the unemployment level's effect on demand; some also claim the use of credit to fuel economic expansion is itself an anti-monetarist tool, as it can be argued that an increase in money supply alone constitutes inflation.
Monetarism re-asserted itself in central bank policy in western governments at the end of the 1980s and beginning of the 1990s, with a contraction both in spending and in the money supply, ending the booms experienced in the US and UK.
1990s.
In the late 1980s, Paul Volcker was succeeded by Alan Greenspan. His handling of monetary policy in the run-up to the 1991 recession was criticised from the right as being excessively tight, and costing George H. W. Bush re-election. The incoming Democratic president Bill Clinton reappointed Alan Greenspan, and kept him as a core member of his economic team. Greenspan, while still fundamentally monetarist in orientation, argued that doctrinaire application of theory was insufficiently flexible for central banks to meet emerging situations.
The crucial test of this flexible response by the Federal Reserve was the Asian financial crisis of 1997–1998, which the Federal Reserve met by flooding the world with dollars, and organising a bailout of Long-Term Capital Management. Some have argued that 1997–1998 represented a monetary policy bind, just as the early 1970s had represented a fiscal policy bind, and that while asset inflation had crept into the United States (which demanded that the Fed tighten the money supply), the Federal Reserve needed to ease liquidity in response to the capital flight from Asia. Greenspan himself noted this when he stated that the American stock market showed signs of irrationally high valuations.
In 2000, Alan Greenspan raised interest rates several times. These actions were believed by many to have caused the bursting of the dot-com bubble. In late 2001, as a decisive reaction to the September 11 attacks and the various corporate scandals which undermined the economy, the Greenspan-led Federal Reserve initiated a series of interest rate cuts that brought the Federal Funds rate down to 1% in 2004. His critics, notably Steve Forbes, attributed the rapid rise in commodity prices and gold to Greenspan's loose monetary policy, and by late 2004 the price of gold was higher than its 12-year moving average; these same forces were also blamed for excessive asset inflation and the weakening of the dollar . These policies of Alan Greenspan are blamed by the followers of the Austrian School for creating excessive liquidity, causing lending standards to deteriorate, and resulting in the housing bubble of 2004–2006.
Currently, the American Federal Reserve follows a modified form of monetarism, where broader ranges of intervention are possible in light of temporary instabilities in market dynamics. This form does not yet have a generally accepted name.
In Europe, the European Central Bank follows a more orthodox form of monetarism, with tighter controls over inflation and spending targets as mandated by the Economic and Monetary Union of the European Union under the Maastricht Treaty to support the euro. This more orthodox monetary policy followed credit easing in the late 1980s through 1990s to fund German reunification, which was blamed for the weakening of European currencies in the late 1990s.
Current state.
Since 1990, the classical form of monetarism has been questioned because of events that many economists have interpreted as being inexplicable in monetarist terms, namely the unhinging of the money supply growth from inflation in the 1990s and the failure of pure monetary policy to stimulate the economy in the 2001–2003 period. Alan Greenspan, former chairman of the Federal Reserve System, argued that the 1990s decoupling was explained by a virtuous cycle of productivity and investment on one hand, and a certain degree of "irrational exuberance" in the investment sector on the other.
There are also arguments linking monetarism and macroeconomics, and treat monetarism as a special case of Keynesian theory. The central test case over the validity of these theories would be the possibility of a liquidity trap, like that experienced by Japan. Ben Bernanke, Princeton professor and former chairman of the U.S. Federal Reserve, has argued that monetary policy could respond to zero interest rate conditions by direct expansion of the money supply. In his words, "We have the keys to the printing press, and we are not afraid to use them." Progressive economist Paul Krugman has advanced the counterargument that this would have a corresponding devaluationary effect, like the sustained low interest rates of 2001–2004 produced against world currencies.
These disagreements — along with the role of monetary policies in trade liberalisation, international investment and central bank policy — remain lively topics of investigation and argument.
See also.
General:

</doc>
<doc id="42424" url="http://en.wikipedia.org/wiki?curid=42424" title="Treblinka extermination camp">
Treblinka extermination camp

Treblinka (]) was an extermination camp built by Nazi Germany in occupied Poland during World War II. It was located near the village of Treblinka in what is now the Masovian Voivodeship north-east of Warsaw. The camp operated between 23 July 1942 and 19 October 1943 as part of Operation Reinhard, the most deadly phase of the Final Solution. During this time, it is estimated that between 700,000 and 900,000 Jews were killed in its gas chambers, along with 2,000 Romani people. More Jews were killed at Treblinka than at any other Nazi extermination camp apart from Auschwitz.
Managed by the German SS and the Eastern European "Trawnikis" (also known as "Hiwi" guards), the camp consisted of two separate units. Treblinka I was a forced-labour camp ("Arbeitslager") whose prisoners worked in the gravel pit or irrigation area and in the forest, where they cut wood to fuel the crematoria. Between 1941 and 1944, more than half of its 20,000 inmates died from summary executions, hunger, disease and mistreatment.
The second camp, Treblinka II, was an extermination camp ("Vernichtungslager"). A small number of men who were not killed immediately upon arrival became its Jewish slave-labour units called "Sonderkommandos," forced to bury the victims' bodies in mass graves. These bodies were exhumed in 1943 and cremated on large open-air pyres along with the bodies of new victims. Gassing operations at Treblinka II ended in October 1943 following a revolt by the "Sonderkommandos" in early August. Several ethnic German SS guards were killed and 200 prisoners escaped from the camp; almost a hundred survived the subsequent chase. The camp was dismantled ahead of the Soviet advance. A farmhouse for a watchman was built on the site in an attempt to hide the evidence of genocide.
In postwar Poland, the government bought part of the land where the camp had stood, and built a large stone memorial there between 1959 and 1962. In 1964 Treblinka was declared a national monument of Jewish martyrology in a ceremony at the site of the former gas chambers. In the same year the first former camp personnel were tried for war crimes committed at Treblinka. The number of visitors coming to Treblinka from abroad increased after the end of communism in Poland in 1989. An exhibition centre at the camp opened in 2006. It was later expanded and made into a branch of the Siedlce Regional Museum.
Background.
Following the invasion of Poland in 1939 most of the 3.5 million Polish Jews were rounded up and put into newly established ghettos by Nazi Germany. The system was intended to economically isolate the Jews from the outside world to assist their exploitation. The supply of food was inadequate, living accommodation was cramped and unsanitary, and the Jews had no way to earn money, all of which led to increased mortality. The initial victories of the Wehrmacht over the Soviet Union inspired plans for the German colonisation of occupied Poland, including all territory within the General Government. At the Wannsee Conference on 20 January 1942, new plans were outlined for the genocide of the Jews, known as the "Final Solution of the Jewish Question". The extermination programme was codenamed Operation Reinhard (German: "Aktion Reinhard") to differentiate it from the "Einsatzgruppen's" activities in territories conquered by Nazi Germany, in which half a million Jews had already been killed.
Treblinka was one of three secret extermination camps set up for Operation Reinhard; the other two were Bełżec and Sobibór. All three were equipped with gas chambers disguised as showers for the "processing" of entire transports of people. They were based on a pilot project of mobile killing conducted at the Chełmno extermination camp (German: "Kulmhof") that began operating in late 1941 and used gas vans. Chełmno was not a part of Reinhard, which was marked by the construction of stationary facilities for mass murder; rather, it was a testing ground for the establishment of faster methods of killing and incinerating people. Treblinka was the third extermination camp of Operation Reinhard to be built, following Bełżec and Sobibór, and incorporated lessons learned from their construction.<ref name="Arad-1984/pdf"></ref> Alongside the Reinhard camps, mass killing facilities using Zyklon B were developed at the Majdanek concentration camp in March 1942 and at Auschwitz II-Birkenau in September.
The Nazi plan to kill Polish Jews from across the General Government during "Aktion Reinhard" was overseen in occupied Poland by "SS-Obergruppenführer" Odilo Globocnik, the deputy of "Reichsführer-SS" Heinrich Himmler in Berlin. The Operation Reinhard camps reported directly to the Reich Main Security Office (German: "Reichssicherheitshauptamt" or RSHA for short), which was also headed by Himmler. The staff of Operation Reinhard, most of whom had been involved in the Action T4 euthanasia programme, used T4 as a framework for the construction of facilities. All of the Jews who were killed in the Reinhard camps came from ghettos.
Location.
The two parallel camps of Treblinka were located 50 mi northeast of the Polish capital Warsaw, near the Małkinia–Sokołów Podlaski railway junction connecting the major cities of central Poland with the Treblinka village station. Before World War II, it was the site of a gravel mining enterprise for the production of concrete. It was owned and operated by the Polish industrialist Marian Łopuszyński, who built a 6 km railway track to the existing line. When the Germans built Treblinka I, the quarry was already equipped with heavy machinery that was ready to use. Treblinka was well-connected but isolated enough as it was halfway between some of the largest Jewish ghettos in Nazi-occupied Europe, including the ghetto in Warsaw and the ghetto in Białystok, the capital of the newly formed "Bezirk Bialystok". The Warsaw Ghetto had about 500,000 Jewish inmates, and the Białystok Ghetto had about 60,000.
From the beginning Treblinka was split into two parallel camps, Treblinka I and Treblinka II. The Schoenbronn Company of Leipzig and the Warsaw branch of Schmidt–Munstermann oversaw the construction of the camps. Between 1942 and 1943 the extermination camp was further redeveloped with a mechanical digger. New brick-built gas chambers and mass cremation pyres were also introduced. The perimeter was enlarged to provide a buffer zone, making it impossible to approach the camp from the outside. The number of trains caused panic among the residents of nearby settlements. They would likely have been killed if caught near the railway tracks.
Treblinka I.
Founded officially on 15 November 1941, Treblinka I was a forced-labour camp ("Arbeitslager"), initially for Poles and Jews captured nearby. It replaced an "ad hoc" company set up in June 1941 by "Sturmbannführer" Ernst Gramss. A new barracks and barbed wire fencing 2 m tall were erected in late 1941. To obtain the workforce for Treblinka I, civilians were sent to the camp "en masse" for real or imagined offences, and sentenced to hard labour by the Gestapo office in Sokołów, which was headed by Gramms. The average length of a sentence was six months, but many prisoners had their sentences extended indefinitely. Twenty thousand people passed through Treblinka I during its three-year existence. About half of them died there from exhaustion, hunger and disease. Those who survived were released after serving their sentences; these were generally Poles from nearby villages.
At any given time, Treblinka I had a workforce of 1,000–2,000 prisoners, most of whom worked 12- to 14-hour shifts in the large quarry and later also harvested wood from the nearby forest as fuel for the open-air crematoria in Treblinka II. There were German, Czech and French Jews among them, as well as Poles captured in "łapankas", farmers unable to deliver food requisitions, hostages trapped by chance, and people who attempted to harbour Jews outside the Jewish ghettos or who performed restricted actions without permits. Beginning in July 1942, Jews and non-Jews were separated. Women mainly worked in the sorting barracks, where they repaired and cleaned military clothing delivered by freight trains, while most of the men worked at the gravel mine. There were no work uniforms, and inmates who lost their own shoes were forced to go barefoot or scavenge them from dead prisoners. Water was rationed, and punishments were regularly delivered at roll-calls. From December 1943 the inmates were no longer carrying any specific sentences. The camp operated officially until 23 July 1944, when the imminent arrival of Soviet forces led to its abandonment.
During its entire operation, Treblinka I's commandant was "Sturmbannführer" Theodor van Eupen. He ran the camp with several SS men and almost 100 "Hiwi" guards. The quarry, spread over an area of 17 ha, supplied road construction material for German military use and was part of the strategic road-building programme in the war with the Soviet Union. It was equipped with a mechanical digger for shared use by both Treblinka I and II. Eupen worked closely with the SS and German police commanders in Warsaw during the deportation of Jews in early 1943 and had prisoners brought to him from the Warsaw Ghetto for the necessary replacements. According to Franciszek Ząbecki, the local station master, Eupen often killed prisoners by "taking shots at them, as if they were partridges". A widely feared overseer was "Untersturmführer" Franz Schwarz, who executed prisoners with a pickaxe or hammer.
Treblinka II.
Treblinka II (officially the "SS-Sonderkommando Treblinka") was divided into three parts: Camp 1 was the administrative compound where the guards lived, Camp 2 was the receiving area where incoming transports of prisoners were offloaded, and Camp 3 was the location of the gas chambers. All three parts were built by two groups of German Jews expelled from Berlin and imprisoned at the Warsaw Ghetto (a total of 238 men from 17 to 35 years of age). "Hauptsturmführer" Richard Thomalla, the head of construction, brought in German Jews because they could speak German. Construction began on 10 April 1942, when Bełżec and Sobibór were already in operation. The entire death camp, which was either 17 ha or 13.5 ha in size (sources vary), was surrounded by two rows of barbed-wire fencing 2.5 m tall. This fence was later woven with pine tree branches to obstruct the view of the camp. More Jews were brought in from the surrounding settlements to work on the new railway ramp within the Camp 2 receiving area, which was ready by June 1942.
The first section of Treblinka II (Camp 1) was the "Wohnlager" administrative and residential compound; it had a telephone line. The main road within the camp was paved and named "Seidel Straße" after "Unterscharführer" Kurt Seidel, the SS corporal who supervised its construction. A few side roads were lined with gravel. The main gate for road traffic was erected on the north side. Barracks were built with supplies delivered from Warsaw, Sokołów Podlaski, and Kosów Lacki. There was a kitchen, a bakery, and dining rooms; all were equipped with high-quality items taken from Jewish ghettos. The Germans and Ukrainians each had their own sleeping quarters, positioned at an angle for better control of all entrances. There were also two barracks behind an inner fence for the Jewish work commandos. "SS-Untersturmführer" Kurt Franz set up a small zoo in the centre next to his horse stables, with two foxes, two peacocks and a roe deer (brought in 1943). Smaller rooms were built as laundry, tailors, and cobblers, and for woodworking and medical aid. Closest to the SS quarters were separate barracks for the Polish and Ukrainian serving, cleaning and kitchen women.
The next section of Treblinka II (Camp 2, also called the lower camp or "Auffanglager"), was the receiving area where the railway unloading ramp extended from the Treblinka line into the camp. There was a platform surrounded by barbed-wire fencing. A new building, erected on the platform, was disguised as a railway station complete with a wooden clock and fake rail terminal signs. "SS-Scharführer" Josef Hirtreiter worked on the unloading ramp and was remembered for being especially cruel; he grabbed children by their feet and smashed their heads against wagons. Behind a second fence, about 100 m from the track, there were two long barracks used for undressing, with a cashier's booth which collected money and jewellery, ostensibly for safekeeping. Jews who resisted were taken away or beaten to death by the guards. The area where the women and children were shorn of their hair was on the other side of the path from the men. All buildings in the lower camp, including the barber barracks, contained the piled up clothing and belongings of the prisoners. Further to the right, there was a fake infirmary called "Lazaret", with the Red Cross sign on it. It was a small barracks surrounded by barbed wire where the sick, old, wounded and "difficult" prisoners were taken. Directly behind the "Lazaret" building there was an open excavation pit seven metres (23 ft) deep. These prisoners were led to the edge of the pit and shot one at a time by "Blockführer" Willi Mentz, nicknamed "Frankenstein" by the inmates. Mentz single-handedly executed thousands of Jews, aided by his supervisor, August Miete, who was called the "Angel of Death" by the prisoners. The pit was also used to burn identity papers deposited by new arrivals at the undressing area.
The third section of Treblinka II (Camp 3, also called the upper camp) was the main killing zone with gas chambers at its centre. It was completely screened from the railway tracks by an earth bank built with the help of a mechanical digger. This mound was elongated in shape, similar to a retaining wall, and can be seen in a sketch produced during the 1967 trial of Treblinka II commandant Franz Stangl. On the other sides, the zone was camouflaged from new arrivals like the rest of the camp, using tree branches woven into barbed wire fences by the "Tarnungskommando" (the work detail led out to collect them). From the undressing barracks there was a fenced-off path leading through the forested area into the gas chambers. It was cynically called "die Himmelstraße" ("the road to heaven") or "der Schlauch" ("the tube") by the SS. For the first eight months of the camp's operation, the digger was used to dig burial ditches on both sides of the gas chambers; these ditches were 50 m long, 25 m wide, and 10 m deep. In early 1943, they were replaced with cremation pyres up to 30 m long, with rails laid across the pits on concrete blocks. The 300 prisoners who operated the upper camp lived in separate barracks behind the gas chambers.
Killing process.
Unlike other Nazi concentration camps across German-occupied Europe, in which prisoners were used as forced labour for the German war effort, death camps ("Vernichtungslager") like Treblinka, Bełżec, and Sobibór had only one function: to kill those sent there. To prevent incoming victims from realising its nature, Treblinka II was disguised as a transit camp for deportations further east, complete with made-up train schedules, a fake train-station clock with hands painted on it, names of destinations, a fake ticket window, and the sign "Ober Majdan", a code word for Treblinka commonly used to deceive passengers departing from Western Europe. Majdan was a prewar landed estate 5 km away from the camp.
Polish Jews.
The mass deportation of Jews from the Warsaw Ghetto began on 22 July 1942 with the first shipment of 6,000 people. The gas chambers started operation the following morning. For the next two months, deportations from Warsaw continued on a daily basis via two shuttle trains (the second one, from 6 August 1942), each carrying about 4,000 to 7,000 people crying for water. No other trains were allowed to stop at the Treblinka station. The first daily trains came in the early morning, often after an overnight wait, and the second, in mid-afternoon. All new arrivals were sent immediately to the undressing area by the "Sonderkommando" squad that managed the arrival platform, and from there to the gas chambers. According to German records, including the official report by SS "Brigadeführer" Jürgen Stroop, 265,000 Jews were transported in freight trains from the Warsaw Ghetto to Treblinka during the period from 22 July to 12 September 1942.
Hundreds of prisoners died from exhaustion, suffocation and thirst while in transit to the camp in the overcrowded wagons. From September 1942 on, both Polish and foreign Jews were greeted with a brief verbal announcement. An earlier signboard with directions was removed because it was clearly insufficient. The deportees were told that they had arrived at a transit point on the way to Ukraine and needed to shower and have their clothes disinfected before receiving work uniforms and new orders.
Foreign Jews and Romani people.
Treblinka received transports of almost 20,000 foreign Jews between October 1942 and March 1943, including 8,000 from the German Protectorate of Bohemia and Moravia via Theresienstadt and over 11,000 from Bulgarian-occupied Thrace, Macedonia and Pirot following an agreement with the Nazi-allied Bulgarian government. They had train tickets and arrived predominantly in passenger carriages with considerable luggage, travel foods and drinks, all of which were taken by the SS to the food storage barracks. The provisions included such items as smoked mutton, speciality breads, wine, cheese, fruit, tea, coffee and sweets. Unlike Polish Jews arriving in Holocaust trains from nearby ghettos in cities like Warsaw, Radom and those of "Bezirk Bialystok", the foreign Jews received a warm welcome upon arrival from an SS man (either Otto Stadie or Willy Mätzig), after which they were killed like the others. Treblinka dealt mainly with Polish Jews, Bełżec handled the Jews from Austria and the Sudetenland, and Sobibór was the final destination for Jews from France and the Netherlands. Auschwitz-Birkenau "processed" Jews from almost every other country in Europe. The frequency of arriving transports slowed down in winter.
The decoupled locomotive went back to the Małkinia layover for the next load, while the victims were pulled from the carriages onto the platform by "Kommando Blau", one of the Jewish work details forced to assist the Germans at the camp. They were led through the gate amidst the chaos and screaming. They were separated by gender behind the gate; women were pushed into the undressing barracks and barber on the left, and men were sent to the right. They were ordered to tie their shoes together and strip. Some kept their own towels. The Jews who resisted were taken to the "Lazaret", also called the "Red Cross infirmary", and shot behind it. Women had their hair cut off, meaning that it took longer to prepare them for the gas chambers than men. The hair was used in the manufacture of socks for U-boat crews and hair-felt footwear for the "Deutsche Reichsbahn".
Most of those killed at Treblinka were Jews, but about 2,000 Romani people also died there. Like the Jews, the Romani were first rounded up and sent to the ghettos; at a conference on 30 January 1940 it was decided that all 30,000 Romani living in Germany proper were to be deported to former Polish territory. Most of these were sent to Jewish ghettos in the General Government, such as those in Warsaw or Łódź. As with the Jews, most Romani who went to Treblinka died in the gas chambers, although some were shot. The majority of the Jews living in ghettos were sent to Bełżec, Sobibór, or Treblinka to be executed; most of the Romani living in the ghettos were shot on the spot. There were no known Romani escapees or survivors from Treblinka.
Gas chambers.
After undressing, the newly arrived Jews were beaten with whips to drive them towards the gas chambers; hesitant men were treated particularly brutally. Rudolf Höss, the commandant at Auschwitz, contrasted the practice at Treblinka of deceiving the victims about the showers with his own camp's practice of telling them they had to go through a "delousing" process. According to the postwar testimony of some SS officers, men were always gassed first, while women and children waited outside the gas chambers for their turn. During this time, the women and children could hear the sounds of suffering from inside the chambers, and they became aware of what awaited them, which caused panic, distress, and even involuntary defecation. According to Stangl, a train transport of about 3,000 people could be "processed" in three hours. In a 14-hour workday, 12,000 to 15,000 people were killed. After the new gas chambers were built, the duration of the killing process was reduced to an hour and a half.
The gassing area was entirely closed off with tall wooden fencing made of vertical boards. Originally, it consisted of three interconnected barracks 8 m long and 4 m wide, disguised as showers. They had double walls insulated by earth packed down in between. The interior walls and ceilings were lined with roofing paper. The floors were covered with tin-plated sheet metal, the same material used for the roof. Solid wooden doors were insulated with rubber and bolted from the outside by heavy cross-bars. The victims were gassed with the exhaust fumes from the engine of a Red Army tank captured during Operation Barbarossa; "SS-Scharführer" Erich Fuchs was responsible for installing it. The engine was brought in by the SS at the time of the camp's construction and was also used to generate electricity. It was erected in a separate shack with its exhaust pipe just below the ground. The exhaust tubing opened into all three gas chambers. The fumes could be seen seeping out. After about 20 minutes the bodies were removed by dozens of "Sonderkommandos", placed onto carts and wheeled away. The system was imperfect and required a lot of effort; trains that arrived later in the day had to wait on layover tracks overnight at Treblinka, Małkinia, or Wólka Okrąglik.
Between August and September 1942, a large new building with a concrete foundation was built from bricks and mortar under the guidance of Action T4 euthanasia expert Erwin Lambert. It contained 8–10 gas chambers, each of which was 8 metres by 4 metres (26 ft by 13 ft), and it had a corridor in the centre. Stangl supervised its construction and brought in building materials from the nearby village of Małkinia by dismantling factory stock. During this time victims continued to arrive daily and were led naked past the building site to the original gas chambers. The new gas chambers became operational after five weeks of construction, equipped with two fume-producing engines instead of one. The metal doors, which had been taken from Soviet military bunkers around Białystok, had portholes through which it was possible to examine the dead before removing them. Stangl said that the old death chambers were capable of killing 3,000 people in three hours. The new ones had the highest possible "output" of any gas chambers in the three Reinhard death camps and could kill up to 22,000 or 25,000 people every day, a fact which Globocnik once boasted about to Kurt Gerstein, a fellow SS officer from Disinfection Services. The new gas chambers were seldom used to their full capacity; 12,000–15,000 victims remained the daily average.
The killing process at Treblinka differed significantly from the method used at Auschwitz and Majdanek, where the poison gas Zyklon B (hydrogen cyanide) was used. At Treblinka, Sobibór and Bełżec, the victims died from suffocation and carbon monoxide poisoning. After visiting Treblinka on a guided tour, Auschwitz commandant Rudolf Höss concluded that using exhaust gas was inferior to the cyanide used at his extermination camp. The chambers became silent after twelve minutes and were closed for twenty minutes or less. According to Jankiel Wiernik, who survived the 1943 prisoner uprising and escaped, when the doors of the gas chambers had been opened, the bodies of the dead were standing and kneeling rather than lying down, due to the severe overcrowding. Dead mothers embraced the bodies of their children. Prisoners who worked in the "Sonderkommandos" later testified that the dead frequently let out a last gasp of air when they were extracted from the chambers. Some victims showed signs of life during the disposal of the corpses, but the guards routinely refused to react.
Cremation pits.
The Germans became aware of the political danger associated with the mass burial of corpses in 1943, when the Polish victims of the Soviet Katyn massacre were discovered near Smolensk in Russia and reported to Berlin. Those 22,000 officers' bodies were well preserved underground, attesting to the Soviet mass murder. By April, Nazi propaganda began to draw the attention of the international community to this war crime using newsfilm. To prove their claim, the Germans brought in the Katyn Commission (a group of twelve forensic experts from various European countries) to examine the bodies in detail and report its findings; it concluded that the Soviets were responsible. The Germans attempted to use the commission's results to drive a wedge between the Allies. The secret orders to exhume the corpses buried at Treblinka and burn them came directly from the Nazi leadership, possibly from Himmler, who was very concerned about covering up Nazi crimes. The cremations began shortly after his visit to the camp in late February or early March 1943.
Within Treblinka II, there were at least two large cremation pits constructed to incinerate bodies. The pits were used to cremate the new corpses along with the old ones, which had to be dug up as they had been buried during the first six months of the camp's operation. They used rails as grates under the instructions of Herbert Floß, the camp's cremation expert. The bodies were placed on grates over wood, splashed with petrol, and burned. It was a harrowing sight, according to Jankiel Wiernik, with the bellies of pregnant women exploding from boiling amniotic fluid. He wrote that "the heat radiating from the pits was maddening." The bodies burned for five hours, without the ashing of bones. The pyres operated 24 hours a day. Once the system had been perfected, 10,000–12,000 bodies at a time could be incinerated.
The open air burn pits were located east of the new gas chambers and refuelled from 4 a.m. (or after 5 a.m. depending on work-load) to 6 p.m. in roughly 5-hour intervals. The current camp memorial includes a flat grave marker resembling one of them. It is constructed from melted basalt and has a concrete foundation. It is a symbolic grave, as the Nazis spread the actual human ashes, mixed with sand, over 22,000 square metres (237,000 square feet).
Organisation of the camp.
The camp was operated by 20–25 SS overseers (Germans and Austrians) and 80–120 "Wachmänner" ("watchmen") guards who had been trained at a special SS facility in the Trawniki concentration camp near Lublin, Poland; all "Wachmänner" guards were trained at Trawniki. The guards were mainly ethnic German "Volksdeutsche" from the east and Ukrainians, with some Russians, Tatars, Moldovans, Latvians, and Central Asians, all of whom had served in the Red Army. They were enlisted by Karl Streibel, the commander of the Trawniki camp, from the prisoner of war (POW) camps for Soviet soldiers. The degree to which their recruitment was voluntary remains disputed; while conditions in the Soviet POW camps were dreadful, some Soviet POWs collaborated with the Germans even before cold, hunger, and disease began devastating the POW camps in mid-September 1941.
The work at Treblinka was carried out under threat of death by Jewish prisoners organised into specialised "Sonderkommando" squads or work details. At the Camp 2 "Auffanglager" receiving area each squad had a different coloured triangle. The triangles made it impossible for new arrivals to try to blend in with members of the work details. The blue unit ("Kommando Blau") managed the rail ramp and unlocked the freight wagons. They met the new arrivals, carried out people who had died en route, removed bundles, and cleaned the wagon floors. The red unit ("Kommando Rot"), which was the largest squad, unpacked and sorted the belongings of victims after they had been "processed". The red unit delivered these belongings to the storage barracks, which were managed by the yellow unit ("Kommando Gelb"), who separated the items by quality, removed the Star of David from all outer garments, and extracted any money sewn into the linings. The yellow unit was followed by the "Desinfektionskommando", who disinfected the belongings, including sacks of hair from "processed" women. The "Goldjuden" unit ("money Jews") collected and counted banknotes and evaluated the gold and jewellery.
A different group of about 300 men, called the "Totenjuden" ("Jews of death"), lived and worked in Camp 3 across from the gas chambers. For the first six months they took the corpses away for burial after gold teeth had been extracted. Once cremation began in early 1943 they took the corpses to the pits, refuelled the pyres, crushed the remaining bones with mallets, and collected the ashes for disposal. Each trainload of "deportees" brought to Treblinka consisted of an average of sixty heavily guarded wagons. They were divided into three sets of twenty at the layover yard. Each set was processed within the first two hours of backing onto the ramp, and was then made ready by the "Sonderkommandos" to be exchanged for the next set of twenty wagons.
Members of all work units were continuously beaten by the guards and often shot or hanged at the gallows. Only the strongest men were selected from new arrivals daily to obtain the necessary replacements. There were other work details which had no contact with the transports: the "Holzfällerkommando" ("woodcutter unit") cut and chopped firewood, and the "Tarnungskommando" ("disguise unit") camouflaged the structures of the camp. Another work detail was responsible for cleaning the common areas. The Camp 1 "Wohnlager" residential compound contained barracks for about 700 "Sonderkommandos" which, when combined with the 300 "Totenjuden" living across from the gas chambers, brought their grand total to roughly one thousand at a time.
Going to work bloodied and bruised would lead to execution. If a prisoner was beaten and sustained black eyes, open wounds and severe swelling, he was called a "clepsydra" (Greek for "water clock") by the other prisoners and most likely shot that evening at roll call or the next day if the bruised cheeks began to swell up. Many "Sonderkommando" prisoners hanged themselves at night. Suicides in the "Totenjuden" barracks occurred at the rate of 15 to 20 per day. The work crews – usually unable to eat or sleep from fear and anxiety – were almost entirely replaced every few days; members of the old work detail were sent to their deaths except for the most resilient.
Treblinka prisoner uprising.
In early 1943 an underground Jewish resistance organisation was formed at Treblinka with the goal of seizing control of the camp and escaping to freedom. The planned revolt was preceded by a long period of secret preparations. The clandestine unit was first organised by a former Jewish captain of the Polish Army, Dr. Julian Chorążycki, who was described by fellow plotter Samuel Rajzman as noble and essential to the action. His organising committee included Zelomir Bloch (leadership), Rudolf Masaryk, Marceli Galewski, Samuel Rajzman, Dr. Irena Lewkowska ("Irka", from the sick bay for the "Hiwis"), Leon Haberman, Hershl (Henry) Sperling from Częstochowa, and several others. Chorążycki (who treated the German patients) killed himself with poison on 19 April 1943 when faced with imminent capture so that the Germans could not discover the plot by torturing him. The next leader was another former Polish Army officer, Dr. Berek Lajcher, who arrived on 1 May. Born in Częstochowa, he had practised medicine in Wyszków, and was expelled by the Nazis to Wegrów in 1939.
The initial date of the revolt was set for 15 June 1943 but it had to be postponed. A fighter smuggled a grenade in one of the early May trains carrying captured rebels from the Warsaw Ghetto Uprising, which had begun on 19 April 1943. When he detonated it in the undressing area, the SS and guards were thrown into a panic. After the explosion, Treblinka received only about 7,000 Jews from the capital for fear of similar incidents; the remaining 42,000 Warsaw Jews were deported to Majdanek instead. The burning of unearthed corpses continued at full speed until the end of July. The Treblinka II conspirators became increasingly concerned about their future as the amount of work for them began to decline. With fewer transports arriving, they realised that "they were next in line for the gas chambers."
Day of the revolt and survivors.
The uprising was launched on the hot summer day of 2 August 1943 (Monday, a regular day of rest from gassing), when a group of Germans and forty Ukrainians drove off to the River Bug to swim. The door to the arsenal near the train tracks was silently unlocked with a key that had been duplicated earlier, and 20–25 rifles, 20 hand grenades and a dozen pistols were stolen and delivered in a cart to the gravel work detail. At 3:45 p.m. 700 Jews launched an insurgency that lasted for 30 minutes. They set buildings ablaze, and a tank of petrol exploded and set fire to the surrounding structures. A group of armed Jews attacked the main gate and others attempted to climb the fence. Machine-gun fire from about 25 Germans and 60 Ukrainian "Trawnikis" resulted in near-total slaughter. Lajcher was killed along with most of the insurgents. About 200 Jews escaped from the camp. Half of them were killed after a chase in cars and on horses. The Jews did not cut the phone wires, and Stangl called in hundreds of German reinforcements, who arrived from four different towns and set up roadblocks along the way. Partisans of the "Armia Krajowa" (Polish: Home Army) transported some of the surviving escapees across the river and others like Sperling ran 30 kilometres (19 miles) and were then helped and fed by Polish villagers. Of those who broke through, around 70 are known to have survived until the end of the war, including the future authors of published Treblinka memoirs: Jankiel Wiernik, Chil Rajchman, Samuel Willenberg, and Richard Glazar.
Among the Jewish prisoners who escaped after setting fire to the camp, there were two 19-year-olds, Samuel Willenberg and Kalman Taigman, who had both arrived in 1942 and had been forced to work there under pain of death. Taigman died in 2012 Taigman stated of his experience, "It was hell, absolutely hell. A normal man cannot imagine how a living person could have lived through it – killers, natural-born killers, who without a trace of remorse just murdered every little thing." Willenberg and Taigman emigrated to Israel after the war and devoted their last years to retelling the story of Treblinka. Escapees Hershl Sperling and Richard Glazar both suffered from survivor guilt syndrome and eventually killed themselves.
After the uprising.
In spite of the revolt, Treblinka II continued to function and remained a top priority for the SS for another year. Stangl met the head of Operation Reinhard Odilo Globocnik and inspector Christian Wirth in Lublin and decided not to draft a report, as no native Germans had died putting down the revolt. Stangl wanted to rebuild the camp, but Globocnik told him that it would be closed down shortly and that he would be transferred to Trieste to help fight the partisans there. The Nazi high command may have felt that Stangl, Globocnik, Wirth and other Reinhard personnel knew too much and wanted to dispose of them by sending them to the front. With almost all the Jews from the German ghettos (established in Poland) killed, there would have been little point in rebuilding the facility. Auschwitz had enough capacity to fulfil the Nazis' remaining extermination needs, making Treblinka redundant.
The camp's new commandant Kurt Franz, formerly its deputy commandant, took over in August. After the war he testified that gassings had stopped by then. In reality, despite the extensive damage to the camp, the gas chambers were intact, and the killing of Polish Jews continued. Speed was reduced, with only ten wagons rolled onto the ramp at a time, while the others had to wait. The last two rail transports of Jews were brought to the camp for gassing from the Białystok Ghetto on 18 and 19 August 1943. They consisted of 78 wagons (37 the first day and 39 the second), according to a communiqué published by the Office of Information of the "Armia Krajowa", based on observation of Holocaust trains passing through the village of Treblinka. The 39 wagons that came to Treblinka on 19 August 1943 were carrying at least 7,600 survivors of the Białystok Ghetto Uprising.
On 19 October 1943, Operation Reinhard was terminated by a letter from Odilo Globocnik. The following day, a large group of Jewish "Arbeitskommandos" who had worked on dismantling the camp structures over the previous few weeks were loaded onto the train and transported via Siedlce and Chełm to Sobibór for gassing on 20 October 1943. Franz followed Globocnik and Stangl to Trieste in November. Cleanup operations continued over the winter. As part of these operations, Jews from the surviving work detail dismantled the gas chambers brick-by-brick and used them to erect a farmhouse on the site of the camp's former bakery. Globocnik confirmed its purpose as a secret guard post for a Nazi-Ukrainian agent to remain behind the scenes in a letter he sent to Himmler from Trieste on 5 January 1944. A "Hiwi" guard called Oswald Strebel, a Ukrainian "Volksdeutscher" (ethnic German) was given permission to bring his family from Ukraine for "reasons of surveillance", wrote Globocnik; Strebel had worked as a guard at Treblinka II. He was instructed to tell visitors that he had been farming there for decades, but the local Poles were well aware of the existence of the camp.
Operational command of Treblinka II.
Irmfried Eberl.
"SS-Obersturmführer" Irmfried Eberl was appointed the camp's first commandant on 11 July 1942. He was a psychiatrist from Bernburg Euthanasia Centre and the only physician-in-chief to command an extermination camp during World War II. According to some, his poor organisational skills caused the operation of Treblinka to turn disastrous; others point out that the number of transports that were coming in reflected the Nazi high command's wildly unrealistic expectations of Treblinka's ability to "process" these prisoners. The early gassing machinery frequently broke down due to overuse, forcing the SS to shoot Jews assembled for suffocation. The workers did not have enough time to bury them, and the mass graves were overflowing. According to the testimony of his colleague "Unterscharführer" Hans Hingst, Eberl's ego and thirst for power exceeded his ability: "So many transports arrived that the disembarkation and gassing of the people could no longer be handled." On incoming Holocaust trains to Treblinka, many of the Jews locked inside correctly guessed what was going to happen to them. The odour of decaying corpses could be smelled up to 10 km away.
Oskar Berger, a Jewish eyewitness who escaped during the 1943 uprising, told of the camp's state when he arrived there in August 1942:
When we were unloaded, we noticed a paralysing view – all over the place there were hundreds of human bodies. Piles of packages, clothes, suitcases, everything in a mess. German and Ukrainian SS-men stood at the corners of the barracks and were shooting blindly into the crowd.
When Odilo Globocnik made a surprise visit to Treblinka on 26 August 1942 with Christian Wirth and Wirth's adjutant from Bełżec, Josef Oberhauser, Eberl was dismissed on the spot. Among the reasons for dismissal were: incompetently disposing of the tens of thousands of dead bodies, using inefficient methods of killing, and not properly concealing the mass killing. Eberl was transferred to Berlin, closer to operational headquarters in Hitler's Chancellery, where the main architect of the Holocaust, Heinrich Himmler, had just stepped up the pace of the programme. Globocnik assigned Wirth to remain in Treblinka temporarily to help clean up the camp. On 28 August 1942, Globocnik suspended deportations. He chose Franz Stangl, who had previously been the commandant of the Sobibór extermination camp, to assume command of the camp as Eberl's successor. Stangl had a reputation as a competent administrator with a good understanding of the project's objectives, and Globocnik trusted that he would be capable of resuming control.
Franz Stangl.
Stangl arrived at Treblinka in late August 1942. He replaced Eberl on 1 September. Years later, he described what he first saw when he came on the scene, in a 1971 interview with Gitta Sereny:
The road ran alongside the railway. When we were about fifteen, twenty minutes' drive from Treblinka, we began to see corpses by the line, first just two or three, then more, and as we drove into Treblinka station, there were what looked like hundreds of them – just lying there – they'd obviously been there for days, in the heat. In the station was a train full of Jews, some dead, some still alive ... that too, looked as if it had been there for days.
Stangl reorganised the camp, and the transports of Warsaw and Radom Jews began to arrive again on 3 September 1942. According to Israeli historian Yitzhak Arad, Stangl wanted the camp to look attractive, so he ordered the paths paved in the "Wohnlager" administrative compound. Flowers were planted along "Seidel Straße" as well as near the SS living quarters. He ordered that all arriving prisoners should be greeted by the SS with a verbal announcement translated by the working Jews. The deportees were told that they were at a transit point on the way to Ukraine. Some of their questions were answered by Germans wearing lab coats as tools for deception. At times Stangl carried a whip and wore a white uniform, so he was nicknamed the "White Death" by prisoners. Although he was directly responsible for the camp's operations, according to his own testimony Stangl limited his contact with Jewish prisoners as much as possible. He claimed that he rarely interfered with the cruel acts perpetrated by his subordinate officers at the camp. He became desensitised to the killings, and came to perceive prisoners not as humans but merely as "cargo" that had to be destroyed, he said.
Treblinka song.
According to postwar testimonies, when transports were temporarily halted, then-deputy commandant Kurt Franz wrote lyrics to a song meant to celebrate the Treblinka extermination camp. In reality, prisoner Walter Hirsch wrote them for him. The melody came from something Franz remembered from Buchenwald. The music was upbeat, in the key of D major. The song was taught to the newly arriving Jews assigned to work in the "Sonderkommando". They were forced to memorise it by nightfall of their first day at the camp. Survivor Samuel Willenberg remembered the song beginning: "With firm steps we march ..."
A musical ensemble was formed, under duress, by Artur Gold, a popular Jewish prewar composer from Warsaw. He arranged the theme to the Treblinka song for the 10-piece orchestra which he conducted. Gold arrived in Treblinka in 1942 and played music in the SS mess hall at the "Wohnlager" on German orders. He died during the uprising.
Kurt Franz.
After the Treblinka revolt in August 1943 and termination of Operation Reinhard in October 1943, Stangl went with Globocnik to Trieste in northern Italy where SS reinforcements were needed. The third and last Treblinka II commandant was Kurt Franz, nicknamed "Lalka" (Polish: "the doll") by the prisoners because he had "an innocent face".<ref name="Berliner/Biala"></ref> According to survivor Hershl Sperling, as deputy commandant Franz beat prisoners to death for minor infractions or had his dog Barry tear them to pieces. He managed Treblinka II until November 1943. The subsequent cleanup of the Treblinka II perimeter was completed by prisoners of nearby Treblinka I "Arbeitslager" in the following months. Franz's deputy was "Hauptscharführer" Fritz Küttner, who maintained a network of "Sonderkommando" informers and did the hands-on killings.
Kurt Franz maintained a photo album against orders never to take photographs inside Treblinka. He named it "Schöne Zeiten" ("Good Times"). His album is a rare source of images illustrating the mechanised grave digging, brickworks in Małkinia and the Treblinka zoo, among others. Franz was careful not to photograph the gas chambers.
The Treblinka I gravel mine functioned at full capacity under the command of Theodor van Eupen until July 1944, with new forced labourers sent to him by "Kreishauptmann" Ernst Gramss from Sokołów. The mass shootings continued into 1944. With Soviet troops closing in, the last 300 to 700 "Sonderkommandos" disposing of the incriminating evidence were executed by "Trawnikis" in late July 1944, long after the camp's official closure. Strebel, the ethnic German who had been installed in the farmhouse built in place of the camp's original bakery using bricks from the gas chambers, set fire to the building and fled to avoid capture.
Arrival of the Soviets.
In late July 1944 Soviet forces began to approach from the east. The departing Germans who already destroyed most direct evidence of genocidal intent burned surrounding villages to the ground, including 761 buildings in Poniatowo, Prostyń, and Grądy. Many families were killed. The fields of grain that once fed the SS were burned. On 19 August 1944 German forces blew up the church in Prostyń and its bell tower, the last defensive strongpoint against the Red Army in the area.<ref name="Rytel-Andrianik/Prostyń"></ref> When the Soviets entered Treblinka on 16 August, the extermination zone had been levelled, ploughed over, and planted with lupins. What remained, wrote visiting Soviet war correspondent Vasily Grossman, were small pieces of bone in the soil, human teeth, scraps of paper and fabric, broken dishes, jars, shaving brushes, rusted pots and pans, cups of all sizes, mangled shoes, and lumps of human hair. The road leading to the camp was pitch black. Until mid-1944 human ashes (up to 20 carts every day) had been regularly strewn by the remaining prisoners along the road for 2 km in the direction of Treblinka I. When the war ended, destitute and starving locals started walking up the Black Road (as they began to call it) in search of man-made nuggets shaped from melted gold in order to buy bread.
Early attempts at preservation.
The new Soviet-installed government did not preserve evidence of the camp. The scene was not legally protected at the conclusion of World War II. In September 1947, 30 students from the local school, led by their teacher Feliks Szturo and priest Józef Ruciński, collected larger bones and skull fragments into farmers' wicker baskets and buried them in a single mound. The same year the first remembrance committee "Komitet Uczczenia Ofiar Treblinki" (KUOT; Committee to Remember the Victims of Treblinka) formed in Warsaw, and launched a design competition for the memorial. 
Stalinist officials allocated no funding for the design competition nor for the memorial, and the committee disbanded in 1948; by then many survivors had left the country. In 1949 the town of Sokołów Podlaski protected the camp with a new fence and gate. A work crew with no archaeological experience was sent in to landscape the grounds. In 1958, after the end of Stalinism in Poland, the Warsaw provincial council declared Treblinka to be a place of martyrology. Over the next four years, 127 hectares (318 acres) of land that had formed part of the camp was purchased from 192 farmers in the villages of Prostyń, Grądy, Wólka Okrąglik and Nowa Maliszewa.
Construction of the memorial.
The construction of a monument 8 m tall designed by sculptor Franciszek Duszeńko was inaugurated on 21 April 1958 with the laying of the cornerstone at the site of the former gas chambers. The sculpture represents the trend toward large avant-garde forms introduced in the 1960s throughout Europe, with a granite tower cracked down the middle and capped by a mushroom-like block carved with abstract reliefs and Jewish symbols. Treblinka was declared a national monument of martyrology on 10 May 1964 during an official ceremony attended by 30,000 people. The monument was unveiled by Zenon Kliszko, the Marshal of the Sejm of the Republic of Poland, in the presence of survivors of the Treblinka uprising from Israel, France, Czechoslovakia and Poland. The camp custodian's house (built nearby in 1960) was turned into an exhibition space following the collapse of communism in Poland in 1989 and the retirement of the custodian; it opened in 2006. It was later expanded and made into a branch of the Siedlce Regional Museum.
Death count.
There are many estimates of the total number of people killed at Treblinka; most scholarly estimates range from 700,000 to 900,000, meaning that more Jews died at Treblinka than at any other Nazi extermination camp apart from Auschwitz. The Treblinka museum in Poland states that at least 800,000 people died at Treblinka; Yad Vashem, which is Israel's Holocaust museum, puts the number killed at 870,000; and the United States Holocaust Memorial Museum gives a range of 870,000 to 925,000.
First estimates.
The first estimate of the number of people killed at Treblinka came from Vasily Grossman, a Soviet war reporter who visited Treblinka in July 1944 as the Soviet forces marched westward across Poland. He published an article called "The Hell Called Treblinka", which appeared in the November 1944 issue of "Znayma", a monthly Russian literary magazine. In the article he claimed that 3 million people had been killed at Treblinka. He may not have been aware that the short station platform at Treblinka II greatly reduced the number of wagons that could be unloaded at one time, and may have been adhering to the Soviet trend of exaggerating Nazi crimes for propaganda purposes. In 1947 the Polish historian Zdzisław Łukaszkiewicz estimated the death count as 780,000, based on the accepted record of 156 transports with an average of 5,000 prisoners each.
Court exhibits and affidavits.
The Treblinka trials of the 1960s took place in Düsseldorf and produced the two official West German estimates. During the 1965 trial of Kurt Franz, the Court of Assize in Düsseldorf concluded that at least 700,000 people were killed at Treblinka, following a report by Dr. Helmut Krausnick, director of the Institute for Contemporary History in Munich. During Franz Stangl's trial in 1969 the same court reassessed the number to be at least 900,000 after new evidence from Dr. Wolfgang Scheffler.
A chief witness for the prosecution at Düsseldorf in the 1965, 1966, 1968 and 1970 trials was Franciszek Ząbecki, who was employed by the "Deutsche Reichsbahn" as a rail traffic controller at Treblinka village from 22 May 1941. In 1977 he published his book "Old and New Memories", in which he used his own records to estimate that at least 1,200,000 people died at Treblinka. His estimate was based on the maximum capacity of a trainset during the "Grossaktion" Warsaw of 1942 rather than its yearly average. The original German waybills in his possession did not have the number of prisoners listed. Ząbecki, a Polish member of railway staff before the war, was one of the few non-German witnesses to see most transports that came into the camp; he was present at the Treblinka station when the first Holocaust train arrived from Warsaw. Ząbecki was a member of the "Armia Krajowa" (Polish: Home Army), which formed most of the Polish resistance movement in World War II, and kept a daily record of the extermination transports. He also clandestinely photographed the burning Treblinka II perimeter during the uprising in August 1943. Ząbecki witnessed the last set of five enclosed freight wagons carrying "Sonderkommandos" to the Sobibór gas chambers on 20 October 1943. In 2013, his son Piotr Ząbecki wrote an article about him for "Życie Siedleckie" that revised the number to 1,297,000. Ząbecki's daily records of transports to the camp, and demographic information regarding the number of people deported from each ghetto to Treblinka, were the two main sources for estimates of the death toll.
In his 1987 book "Belzec, Sobibor, Treblinka: The Operation Reinhard Death Camps", Israeli historian Yitzhak Arad stated that at least 763,000 people were killed at Treblinka between July 1942 and April 1943. A considerable number of other estimates followed: see table (below).
Höfle Telegram.
A further source of information became available in 2001. The Höfle Telegram was an encrypted message Operation Reinhard deputy commander Hermann Höfle sent to Berlin on 31 December 1942, detailing the number of Jews deported to each Operation Reinhard death camp up to that point. Discovered among declassified documents in Britain, it shows that by the official count 713,555 Jews were sent to Treblinka in 1942. The number of deaths was probably higher, according to the "Armia Krajowa" communiqués. On the basis of the telegram and additional undated German evidence for 1943 listing 67,308 people deported, historian Jacek Andrzej Młynarczyk calculated that by the official count, 780,863 people were brought by "Deutsche Reichsbahn" to Treblinka.
Treblinka trials.
The first official trial for war crimes committed at Treblinka was held in Düsseldorf between 12 October 1964 and 24 August 1965, preceded by the 1951 trial of "SS-Scharführer" Josef Hirtreiter, which was triggered by charges of war crimes unrelated to his service at the camp. The trial was delayed because the United States and the Soviet Union had lost interest in prosecuting German war crimes with the onset of the Cold War. Many of the more than 90,000 Nazi war criminals recorded in German files were serving in positions of prominence under West German chancellor Konrad Adenauer. In 1964 and 1965 eleven former SS camp personnel were brought to trial by West Germany, including commandant Kurt Franz. He was sentenced to life imprisonment, along with Artur Matthes ("Totenlager") and Willi Mentz and August Miete (both from "Lazaret"). Gustav Münzberger (gas chambers) received 12 years, Franz Suchomel (gold and money) 7 years, Otto Stadie (operation) 6 years, Erwin Lambert (gas chambers) 4 years, and Albert Rum ("Totenlager") 3 years. Otto Horn (corpse detail) was acquitted.
The second commandant of Treblinka II, Franz Stangl, escaped with his wife and children from Austria to Brazil in 1951. Stangl found work at a Volkswagen factory in São Paulo. His role in the mass murder of Jews was known to the Austrian authorities, but Austria did not issue a warrant for his arrest until 1961. Stangl was registered under his real name at the Austrian consulate in Brazil. It took another six years before the famous Nazi hunter Simon Wiesenthal tracked him down and triggered his arrest. After his extradition from Brazil to West Germany Stangl was tried for the deaths of around 900,000 people. He admitted to the killings but argued: "My conscience is clear. I was simply doing my duty." Stangl was found guilty on 22 October 1970, and sentenced to life imprisonment. He died of heart failure in prison in Düsseldorf on 28 June 1971.
Material gain.
The theft of cash and valuables, collected from the victims of gassing, was conducted by the higher-ranking SS men on an enormous scale. It was a common practice among the concentration camps' top echelon everywhere; two Majdanek concentration camp commandants, Koch and Florstedt, were tried and executed by the SS for the same offence in April 1945. When the top-ranking officers went home, they would sometimes request a private locomotive from Klinzman and Emmerich at the Treblinka station to transport their personal "gifts" to Małkinia for a connecting train. Then, they would drive out of the camp in cars without any incriminating evidence on their person, and later arrive at Małkinia to transfer the goods.
The overall amount of material gain by Nazi Germany is unknown except for the period between 22 August and 21 September 1942, when there were 243 wagons of goods sent and recorded. Globocnik delivered a written tally to Reinhard headquarters on 15 December 1943 with the SS profit of RM 178,745,960.59, including 2,909.68 kilograms of gold (6,415 lb), 18,733.69 kg of silver (41,300 lb), 1,514 kg of platinum (3,338 lb), and 249,771.50 American dollars, as well as 130 diamond solitaires, 2,511.87 carats of brilliants, 13,458.62 carats of diamonds, and 114 kg of pearls (251 lb). The amount of loot Globocnik stole is unknown; Suchomel claimed in court to have filled a box with one million Reichsmarks for him.
Archaeological studies.
Neither the Jewish religious leaders in Poland nor the authorities allowed archaeological excavations at the camp out of respect for the dead. Approval for a limited archaeological study was issued for the first time in 2010 to a British team from Staffordshire University using non-invasive technology and Lidar remote sensing. The soil resistance was analysed at the site with ground-penetrating radar. Features that appeared to be structural were found, two of which were thought to be the remains of the gas chambers, and the study was allowed to continue.
The archaeological team performing the search discovered three new mass graves. The remains were reinterred out of respect for the victims. At the second dig the findings included yellow tiles stamped with a Star of David from a Jewish-style bathhouse, and building foundations with a wall. The star was a logo of the ceramics factory founded by Jan Dziewulski and brothers Józef and Władysław Lange (D✡L since 1886) nationalised under communism after the war. As explained by forensic archaeologist Caroline Sturdy Colls, the new evidence was important because the second gas chambers built at Treblinka were housed in the only brick building in the camp; this provides the first physical evidence for their existence. In his memoir describing his stay in the camp, survivor Jankiel Wiernik says that the floor in the gas chambers (which he helped build) was made of similar tiles. The discoveries became a subject of the 2014 documentary by the Smithsonian Channel. More forensic work has been planned.
March of the Living.
Treblinka museum receives most visitors per day during the annual March of the Living educational programme which brings young people from around the world to Poland, to explore the remnants of the Holocaust. The visitors whose primary destination is the march at Auschwitz II-Birkenau, visit Treblinka in the preceding days. In 2009, 300 Israeli students attended the ceremony led by Eli Shaish from the Ministry of Education. In total 4,000 international students visited. In 2013 the number of students who came, ahead of the Auschwitz commemorations, was 3,571. In 2014, 1,500 foreign students visited.
References.
</dl>

</doc>
<doc id="42431" url="http://en.wikipedia.org/wiki?curid=42431" title="San Juan Mountains">
San Juan Mountains

The San Juan Mountains are a high and rugged mountain range in the Rocky Mountains in southwestern Colorado, and is the largest mountain range in Colorado by area. The area is highly mineralized (the Colorado Mineral Belt) and figured in the gold and silver mining industry of early Colorado. Major towns, all old mining camps, include Creede, Lake City, Silverton, Ouray, and Telluride. Large scale mining has ended in the region, although independent prospectors still work claims throughout the range. The last large scale mines were the Sunnyside Mine near Silverton, which operated until late in the 20th century and the Idarado Mine on Red Mountain Pass that closed down in the 1970s. Famous old San Juan mines include the Camp Bird and Smuggler Union mines, both located between Telluride and Ouray.
The Summitville mine was the scene of a major environmental disaster in the 1990s when the liner of a cyanide-laced tailing pond began leaking heavily. Summitville is in the Summitville caldera, one of many extinct volcanoes making up the San Juan volcanic field. One, La Garita Caldera, is 35 mi in diameter. Large beds of lava, some extending under the floor of the San Luis Valley, are characteristic of the eastern slope of the San Juans.
Tourism is now a major part of the regional economy, with the narrow gauge railway between Durango and Silverton being an attraction in the summer. Jeeping is popular on the old trails which linked the historic mining camps, including the notorious Black Bear Road. Visiting old ghost towns is popular, as is wilderness trekking and mountain climbing. Many of the old mining camps are now popular sites of summer homes. Though the San Juans are extremely steep and receive a lot of snow, so far only Telluride has made the transition to a major ski resort. Purgatory (now known as Durango Mountain Resort) is a small ski area north of Durango near the Tamarron Resort. There is also skiing on Wolf Creek Pass at the Wolf Creek ski area. Recently Silverton Mountain ski area has begun operation near Silverton.
The Rio Grande rises on the east side of the range. The other side of the San Juans, the western slope of the continental divide, is drained by tributaries of the San Miguel, Dolores and Gunnison rivers, which all flow into the Colorado River.
The San Juan and Uncompahgre National Forests cover a large portion of the San Juan Mountains.
The San Juan Mountains also have the distinction of being the location of the highest airport with scheduled airline service in the U.S., being Telluride Airport at an elevation of 9,070 feet.
History of the area.
Mining operators in the San Juan mountain area formed the San Juan District Mining Association (SJDMA) in 1903, as a direct result of a Western Federation of Miners proposal to the Telluride Mining Association for the eight hour day, which had been approved in a referendum by 72 percent of Colorado voters. The new association consolidated the power of thirty-six mining properties in San Miguel, Ouray, and San Juan counties. The SJDMA refused to consider any reduction in hours or increase in wages, helping to provoke a bitter strike.
Gallery.
360° panorama of the southwestern San Juans, photographed from the Gold Hill Ridge of the Telluride Ski Resort. Ridgeline annotation indicates the names and elevations of 43 visible peaks
Panorama of the San Juan Mountains' Sneffels Range looking south.
Acceleration of snowmelt by dust.
Dust blown in from adjoining deserts sometimes accelerates snowmelt in the San Juans. 

</doc>
<doc id="42437" url="http://en.wikipedia.org/wiki?curid=42437" title="Quest Software">
Quest Software

Quest Software, now part of Dell Software a division of Dell Inc., was a software manufacturer headquartered in Aliso Viejo, California. Founded in 1987, Quest developed and supported software used in a variety of industries to simplify IT management. Quest Software was acquired by Dell, announced on July 2, 2012, for $2.36 billion.
The company was known for TOAD, a product used by database professionals, in addition to other products for IT development, management, monitoring and protection. It offered both packaged and custom software applications, as well as associated software infrastructure components, such as databases, application servers, operating systems and hypervisors. The company had a reputation for following IT spending trends and investing in technology areas such as virtualization, cloud automation and backup and recovery.
Quest had a worldwide presence, with more than 60 offices in 23 countries with a customer base of more than 100,000. As of December 2011, Quest had 3,900 full-time employees worldwide and annual revenues of $857 million.
Dell's acquisition of Quest Software became official on September 27, 2012.
Products.
Quest offers products for application management, database management, Microsoft Windows management (including Active Directory, Exchange and SharePoint) and Virtualization Management (including desktop virtualization, server virtualization and cloud automation). Quest's application management products focus in the ERP, Java EE and Microsoft .NET market spaces. Quest was recognized as a leader in Gartner's Magic Quadrant for Application Performance Monitoring in 2011.
Database management tools include support for MySQL, SQL Server, DB2, Sybase, and Oracle. The company's well-known TOAD product is also now available for cloud and NoSQL databases.
In the Windows infrastructure management arena, products cater to Active Directory, Exchange, SharePoint, Microsoft Windows, and System Center users.
The company also offers products to manage virtualized environments, including desktop virtualization, server virtualization and cloud automation tools.
The company divides its products into six solution families:
History.
1987 to 2000.
1987 – Quest Software was founded in Newport Beach, California with a line of high availability and middleware products for HP Multi-Programming Executive (MPE).
1995 – Vinny Smith joined the company, which at the time had 35 employees and $9.5 million in revenue.
1996 – Quest entered the database management market with an Oracle SQL database tuning product;
1997 – Quest expanded beyond North America by opening an office in the United Kingdom.
1998 – Doug Garn joined Quest as the vice president of sales. Quest also added offices in Germany and Australia. Smith became CEO.
1999 – On August 13, 1999, Quest Software went public. The company also entered the application change management market by acquiring Stat.
2000 – Quest expanded further into application management by acquiring Foglight, a monitoring product; and continued the global expansion with new offices in France and the Netherlands. At the end of 2000, the company had 1,400 employees and $167 million in revenue.
2000 to present.
2001 – Quest entered the Microsoft management market by acquiring Fastlane Technologies, and broadened its database offerings beyond Oracle with a new product for the IBM DB2 database.
2002 – Quest opened an office in Japan and expanded their application management offerings to custom web applications written in Java with the acquisition of Sitraka.
2003 – Quest officially entered the Microsoft SQL Server market, and IDC named Quest #1 in distributed database management software.
2004 – The company expanded its Microsoft infrastructure management capabilities by acquiring Aelita Software, and won Microsoft's prestigious Global ISV of the Year award for the first time. Gartner also named Quest #1 in Application Management. 2004 also saw Quest expand operations in Asia with new offices in Singapore, Korea and China.
2005 – Doug Garn became president of Quest. The company acquired Imceda Software that year to add SQL Server backup and recovery capabilities, and Vintela for identity management. At the end of 2005, Quest had 2,750 employees worldwide and revenues of $476 million.
2006 – The company entered the Microsoft SharePoint market. Quest acquired ScriptLogic, which provided a solid entry into the small-to-medium-sized business market. Quest also acquired Charonware s.r.o from the Czech Republic, the makers of CASE Studio2, and folded it into the TOAD Data Modeler product. This year also saw Quest ranked #1 by Gartner for application management in North America, and #1 in Database Development and Management by IDC.
2007 – Quest received Microsoft's Global ISV of the Year award for the second time. The company also begin its focus on virtualization by acquiring Provision Networks, a desktop virtualization management company.
2008 – Doug Garn became CEO and president, and Vinny Smith became executive chairman. Quest purchased Vizioncore as an entry into the server virtualization market.
2009 – Alan Fudge becomes vice president of sales, and Quest acquired PacketTrap for network monitoring.
2010 – The company acquired Voelcker to round out their identity management offerings. Quest continued building out its virtualization business and also entered the private cloud automation market by acquiring Surgient. Quest was also ranked in the leaders' quadrant by Gartner for application performance monitoring. Revenues were $767 million at the end of 2010, and the company counted approximately 3,500 employees.
2011 – Quest acquired BakBone Software, e-DMZ, RemoteScan, Symlabs,ChangeBASE, VKernel and BiTKOO.
2011 – Vinny Smith became CEO and Chairman, and Doug Garn became Vice Chairman.
2012 – On Friday September 28, 2012, Dell announced that it has completed the acquisition of Quest Software

</doc>
<doc id="42440" url="http://en.wikipedia.org/wiki?curid=42440" title="1096">
1096

Year 1096 (MXCVI) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42441" url="http://en.wikipedia.org/wiki?curid=42441" title="Physical modelling synthesis">
Physical modelling synthesis

In sound synthesis, physical modelling synthesis refers to methods in which the waveform of the sound to be generated is computed by using a mathematical model, being a set of equations and algorithms to simulate a physical source of sound, usually a musical instrument. Such a model consists of (possibly simplified) laws of physics that govern the sound production, and will typically have several parameters, some of which are constants that describe the physical materials and dimensions of the instrument, while others are time-dependent functions that describe the player's interaction with it, such as plucking a string, or covering toneholes.
For example, to model the sound of a drum, there would be a formula for how striking the drumhead injects energy into a two dimensional membrane. Thereafter the properties of the membrane (mass density, stiffness, etc.), its coupling with the resonance of the cylindrical body of the drum, and the conditions at its boundaries (a rigid termination to the drum's body) would describe its movement over time and thus its generation of sound. 
Similar stages to be modelled can be found in instruments such as a violin, though the energy excitation in this case is provided by the slip-stick behavior of the bow against the string, the width of the bow, the resonance and damping behavior of the strings, the transfer of string vibrations through the bridge, and finally, the resonance of the soundboard in response to those vibrations.
Although physical modelling was not a new concept in acoustics and synthesis, having been implemented using finite difference approximations of the wave equation by Hiller and Ruiz in 1971, it was not until the development of the Karplus-Strong algorithm, the subsequent refinement and generalization of the algorithm into the extremely efficient digital waveguide synthesis by Julius O. Smith III and others, and the increase in DSP power in the late 1980s that commercial implementations became feasible. 
Yamaha signed a contract with Stanford University in 1989 to jointly develop digital waveguide synthesis, and as such most patents related to the technology are owned by Stanford or Yamaha.
The first commercially available physical modelling synthesizer made using waveguide synthesis was the Yamaha VL1 in 1994.
While the efficiency of digital waveguide synthesis made physical modelling feasible on common DSP hardware and native processors, the convincing emulation of physical instruments often requires the introduction of non-linear elements, scattering junctions, etc. In these cases, digital waveguides are often combined with FDTD, finite element or wave digital filter methods, increasing the computational demands of the model.
Technologies associated with physical modelling.
"Examples of physical modelling synthesis:"
Hardware synthesizers.
While not purely a hardware synth, the DS-XG sound cards based on the Yamaha YMF-7#4 family of audio chipsets (including 724, 744, 754, and 764), including the Yamaha WaveForce 192 (SW192XG) as well as many from other manufacturers and even some PC motherboards with such an audio chipset, included hardware-assisted software VL physical modelling (like a VL70m or PLG-VL, and compatible with same) along with the Yamaha XG, wave audio, and 3D gaming sound capabilities of the chipset. Unfortunately, only the VxD (Virtual Device Drivers) drivers for pre-NT kernel versions of Windows (3.x, 9#, and ME) support the physical modelling feature. Neither the WDM (Windows Device Model) drivers for Windows 98, 98SE, nor ME, nor any driver for any NT-kernel version of Windows (NT, 2000, XP, Vista, Windows 2003 Server, Windows 7, Windows 2008 Server, nor likely any future OSes) support this, nor can they due to OS limitations. Those OSes do support the other features of the card, though.
In their prime, the DS-XG sound cards were easily the most affordable way of obtaining genuine VL technology for anyone who already had a Windows 3.x, 9#, or ME PC. Such cards could be had brand new for as low as $12 USD (YMF-724 versions). But since they were not fully compatible with the AC-97 and later AC-98 standards, these chipsets faded from the market and have not been manufactured by Yamaha in nearly a decade.
Technics WSA1 and its rackmounted counterpart WSA1R was Technics' first and only try at high-end synthesizers. It featured 64 voices of polyphony with a combination of sample playback (for initial transients) and DSP acoustic modelling. Technics WSA1 was launched in 1995, but the musical community did not have enough confidence in Technics to buy a $5000 hardware synth. Only about 600 keyboards and 300 rack models were ever made, and most were sold at highly discounted prices.
Various Roland synth models (V-Synth, V-Combo, XV-5080, Fantom, etc.), use a technology called COSM ("Composite Object Sound Modeling") which uses physical modeling techniques to more accurately replicate guitars, brass and other instruments. COSM has been superseded by "SuperNatural", which is also based on physical modeling techniques. Introduced first in 2008 as part of the ARX expansion boards for Fantom hardware synthesizers, "SuperNatural" modeling is used in Roland's V-Drums (TD-30, TD-15, TD-11), V-Accordions (FR-7, FR-8) and various synth models (Jupiter 80, Integra 7, FA-08, JD-Xi, etc.)

</doc>
<doc id="42442" url="http://en.wikipedia.org/wiki?curid=42442" title="Terrorism in Yemen">
Terrorism in Yemen

In the War on Terrorism in Yemen, the US government describes Yemen as "an important partner in the global war on terrorism".
Attacks against civilian targets.
On December 30, 2002, a suspected Islamic fundamentalist killed three US workers and wounded one in a hospital in Jibla, using a semi-automatic rifle. The suspect was arrested and identified as Abid Abdulrazzaq Al-Kamil.
Jews in Yemen reportedly fled their homes due to threats from Muslim extremists. A notable incident was the murder of Moshe Ya'ish al-Nahari of Raydah in December 2008.
Al Qaeda members sent letters to 45 Jews living in al-Salem, near Sanaa, on January 19, 2007, accusing them of involvement in an "international Zionist conspiracy". The letters said that if the Jews did not abandon their homes in ten days, they would be abducted and murdered and their homes would be looted. The Jewish community sent a complaint to President Abdullah Salah and are temporarily staying in a hotel near Sanaa. The Yemeni government has promised that their homes will be protected and they may return to them.
On September 17, 2008, Al Qaeda militants attacked the U.S. Embassy in Sana'a. 20 people were killed, including: six militants, six policemen and seven civilians. One American was among those killed.
Attacks on tourists.
On July 2, 2007, a suicide bomber killed eight Spanish tourists and their two Yemeni drivers in Ma'rib.
On January 18, 2008, Al Qaeda militants opened fire on a convoy of tourists in Hadhramaut killing two Belgian tourists and two Yemenis, the tourists' driver and their guide.
Attacks targeted South Korean tourists in March 2009. Four Korean tourists alongside their local Yemeni guide were killed. Two attackers also died.
2010 cargo plane bomb plot.
On October 29, 2010, UK Prime Minister David Cameron said the device in a package sent from Yemen and found on a US-bound cargo plane was designed to go off on the aircraft. But Cameron said investigators could not yet be certain about when the device, intercepted at East Midlands Airport, was supposed to explode. A second device containing explosives was found on a cargo plane in Dubai. The US suspected al-Qaeda involvement.
In Yemen, police arrested but later released a woman suspected of posting the packages. President Ali Abdullah Saleh pledged that his country would continue fighting al-Qaeda "in co-operation with its partners". "But we do not want anyone to interfere in Yemeni affairs by hunting down al-Qaeda," he added, as heavily armed troops patrolled Sanaa. Yemeni authorities also closed down the local offices of the US cargo firms United Parcel Service and FedEx, who had already suspended all shipments out of the country and pledged full co-operation with investigators. US President Barack Obama's national security adviser, John Brennan, has phoned Saleh to offer US help in fighting al-Qaeda, the White House said.
The explosive devices, which triggered security alerts in the US, UK, and Middle East, were apparently both inserted in printer cartridges and placed in packages addressed to synagogues in the Chicago area. Pentaerythritol tetranitrate (PETN) - an explosive favoured by the Yemeni-based militant group, al-Qaeda in the Arabian Peninsula (AQAP) - was discovered in both devices. Obama discussed the apparent terrorist plot with Cameron by phone, expressing his "appreciation for the professionalism of American and British services involved" in disrupting it.
Later, Cameron told reporters at his country residence, Chequers, that it was believed the explosive device intercepted at East Midlands Airport was "designed to go off on the aeroplane". "We cannot be sure about when that was supposed to take place," he added. "There is no early evidence that it was meant to take place over British soil, but of course we cannot rule it out." The prime minister said the authorities had immediately banned packages coming to or through the UK from Yemen, and would be "looking extremely carefully at any further steps we have to take". UK Home Secretary Theresa May said the government did not believe the plotters would have known the location of the device when it was planned to explode. While details of the device found in Britain were not released, photographs emerged on the US media of an ink toner cartridge covered in white powder and connected to a circuit board. The British government's remarks suggest the authorities in both the UK and the US remain uncertain about the precise targets and, indeed, aim of this latest apparent plot. According to Dubai police, the explosives they found were also inside the toner cartridge of a printer, placed in a cardboard box containing English-language books and souvenirs.The cartridge contained PETN and plastic explosives mixed with lead azide, they said. Lead azide is an explosive commonly used in detonators. "The device was prepared in a professional manner and equipped with an electrical circuit linked to a mobile telephone [Sim] card concealed in the printer," the police said. For US Homeland Security Secretary Janet Napolitano, the plot bore "all the hallmarks of al-Qaeda and in particular [AQAP]". Unnamed US officials quoted by the Associated Press said al-Qaeda's explosives expert in Yemen, Ibrahim Hassan al-Asiri, was the likely suspect behind the bomb-making. They said Asiri had helped make the bomb used in the failed Detroit Christmas Day bomb attack and another PETN device used in a failed suicide attack against a top Saudi counter-terrorism official last year. The White House has said Saudi Arabia provided information that helped identify the threat, while the UK's "Daily Telegraph" reported that an MI6 officer responsible for Yemen had received a tip-off.
Military/police counter-terrorism operations.
Following the September 11, 2001 attacks in the United States, President Ali Abdullah Saleh made an effort to eliminate the Islamist militant presence. By November 2002, Yemeni government troops detained 104 suspected al-Qaeda members.
In December 2001, a search by government forces for two Yemeni believed to be senior al Qaeda members hiding near Ma'rib led to a gun battle with tribesmen which ended in the deaths of 34 people, including 18 soldiers. To defuse the situation, ten Ma'rib sheiks were detained as hostages of the state in comfortable rooms in the presidential palace for 35 days, until 43 lesser tribesmen took their place.
In the first months of 2002 the Bush Administration approved sending about 100 Special Operations Forces to Yemen, a power base for Al Qaeda.
In November 2002, six Yemenis suspected of being members of al Qaeda were blown up in their car in the province of Marib by a Hellfire missile attack from an unmanned CIA RQ-1 Predator aircraft. Among the dead was Abu Ali al-Harithi.
In 2004, the Australian Broadcasting Corporation's (ABC-TV) international affairs program "Foreign Correspondent" investigated this targeted killing and the involvement of then US Ambassador as part of a special report titled "The Yemen Option". The report also examined the evolving tactics and countermeasures in dealing with Al Qaeda inspired attacks.
In December 2002, Spanish troops boarded and detained a ship, at the request of the United States, that was transporting Scud missiles from North Korea to Yemen. After two days, when the United States determined it had no right under international law to continue to detain the shipment, they let it continue on to Yemen.
On July 30, 2009, three soldiers were killed in a clash with al-Qaeda militants in Marib province.
A raid on an alleged al-Qaeda camp on December 17, 2009, led to the deaths of 46 civilians, 14 of which were female and 21 were children ABC News reported that US cruise missiles were part of the bombardment of the camps, which targeted Abu Hureira Qasm al-Rimi. A local official and a tribal source claimed that 49 civilians, including 23 women and 17 children, were among those killed in the strike. The same day a clash between security forces and al-Qaeda members in Abhar left four militants dead.
An air raid targeted an al-Qaeda meeting in Wadi Rafadh in Shabwa province on December 24, 2009. Another 34 al-Qaeda militants were killed in the attack. Among the dead were also Saudis and Iranians, according to the security forces. The number of al-Qaeda members arrested in the previous week rose to 29.
US air attacks.
The U.S. first said it used targeted killing in November 2002, with the cooperation and approval of the government of Yemen.
A CIA-controlled Predator drone fired a Hellfire missile at a SUV in the Yemeni desert containing Qaed Salim Sinan al-Harethi, a Yemeni suspected senior al-Qaeda lieutenant believed to have been the mastermind behind the October 2000 USS "Cole" bombing that killed 17 Americans. He was on a list of targets whose capture or death had been called for by US President George W. Bush. In addition to al-Harethi, five other occupants of the SUV were killed, all of whom were suspected al-Qaeda terrorists, and one of whom (Kamal Derwish) was an American.
On December 17, 2009, the village of Al Ma`jalah was hit by a cruise missile, killing 41 people, including 14 women, 21 children, and 14 alleged al-Qaeda members. While the Yemeni government initially took responsibility, photographs of American components and a Wikileaks cable suggest that it was carried out by the United States.
In May 2010 an errant US drone attack targeting al Qaeda terrorists in Wadi Abida, Yemen, killed five people, among them Jaber al-Shabwani, deputy governor of Maarib province who was mediating between the government and the militants. The killing so angered Shabwani's tribesmen that in the subsequent weeks they fought heavily with government security forces, twice attacking a major oil pipeline in Maarib.
On May 5, 2011, a missile fired from a U.S. drone killed Abdullah and Mosaad Mubarak, brothers who may have been militants. The missile was fired on their car and both died instantly. The strike was aimed at killing Anwar al-Awlaki, but al-Awlaki appears to have survived.
On 3 June 2011 American manned jets or drones attacked and killed Abu Ali al-Harithi, a midlevel al-Qaeda operative, and several other militant suspects, including Ammar Abadah Nasser al-Wa'eli, in a strike in southern Yemen. Four civilians were also reportedly killed in the strike. The strike was reportedly coordinated by American special forces and CIA operatives based in Sana. According to the Associated Press, in 2011 the US government began building an airbase near or in Yemen from which the CIA and US military plans to operate drones over Yemen. The "Washington Post" reported that the US previously used a base in Djibouti to operate drones over Yemen. The "Wall Street Journal" reports that a US drone base in the Seychelles could be used to operate drones over Yemen.
According to local residents and unnamed American and Yemeni government officials, on 14 July 2011 US manned aircraft or drones attacked and destroyed a police station in Mudiya in Abyan Province which had been occupied by al Qaeda militants. Yemeni media and government gave conflicting accounts on the number of casualties, estimated at between 6 and 50 killed. The same day and nearby, drone missiles reportedly hit a car belonging to Yemeni al Qaeda leader Fahd al-Quso, but al-Quso survived the attack.
On 1 August 2011, US drones and reportedly Yemeni aircraft attacked three targets with bombs and missiles in South Yemen, killing 15 suspected al Qaeda militants and wounding 17 others. The locations targeted included al-Wahdah, al-Amodiah, and al-Khamilah in Abyan province. One of those killed was reportedly militant leader Naser al-Shadadi.
According to the Yemen Post "At least 35 US drone attacks were reported in Yemen over the last two month."
On 24 August 2011, unidentified aircraft attacked suspected al-Qaeda militants near Zinjibar. The strikes reportedly killed 30 militants and wounded 40 others.
According to Yemeni officials as reported in the "Long War Journal", US airstrikes in southeast Abyan province on 30 August to 1 September 2011 killed 30 AQAP militants. The militants were reportedly engaged in combat with Yemeni military forces.
Two airstrikes by US-operated aircraft on 21 September 2011 reportedly killed four AQAP fighters in Abyan and seven AQAP fighters in Shaqra.
On 30 September 2011, US drone-launched missiles killed four people, including Al Qaeda propagandist Anwar al-Awlaki, in Al Jawf Governorate. The strike also killed Samir Kahn, American-born editor of "Inspire" magazine. The strike marked the first known time that the US had deliberately targeted US citizens in a drone attack.
A reported drone strike in Zinjibar on 5 October 2011 killed five AQAP militants. According to Yemeni government officials, a US airstrike on 14 October 2011 killed seven AQAP militants, including Egyptian-born Ibrahim al-Bana, AQAP's media chief.
A drone strike on 22 December 2011 near Zinjibar reportedly killed Abdulrahman al-Wuhayshi, a relative of Yemeni al-Qaeda leader Nasir al-Wuhayshi. A further eight militants were reported killed in an air strike near Jaar on 17 December 2011.
An airstrike, reportedly performed by US aircraft, on 31 January 2012 near the city of Lawder in Abyan province, killed 11 AQAP militants. The dead reportedly included Abdul Monem al-Fahtani, a participant in the USS Cole bombing.
Drones engaged in three attacks over three days from 9–11 March 2012. The first strike targeted an AQAP hideout near Al Baydah, Baydah province, reportedly killing local AQAP leader Abdulwahhab al-Homaiqani and 16 of his militants. The second strike hit Jaar in Abyan province, reportedly killing 20 AQAP fighters. The third strike, also in Jaar, reportedly killed three AQAP militants and targeted a storage location for weapons AQAP had seized after overruning a Yemeni military base in Al Koud the week before. A fourth drone strike on 14 March 2012 in Al Bydah reportedly killed four AQAP militants in a vehicle.
On April 11, 14 militants were killed in a drone strike in Lauder town, northeast of Zinjibar, Abyan province. A drone strike on 22 April in the Al Samadah area, near the border of Marib and Al Jawf provinces, killed AQAP senior leader Mohammed Saeed al Umda (also known as Ghareeb al Taizi).
On 6 May 2012 a suspected US drone strike killed Fahd Mohammed Ahmed al-Quso and another al Qaida militant in southern Shabwa province.
On 12 December 2013, 17 people were killed in a wedding convoy in the District of Rada' which falls in the Governorate of Al-Bayda'. The U.S. drone mistakenly targeted a wedding convoy after intelligence reports identified the vehicles as carrying suspects of the AQAP organization. Five of the killed had been suspected, but the remainder were civilians. 
On 3 March 2014 an airstrike, believed to have been carried out by an American drone, killed three people suspected of being members of AQAP. Mujahid Gaber Saleh al Shabwani, who is one of Yemen's 25 most wanted AQAP operatives, is thought to have been killed in the strike.
On 20 and 21 April 2014, three drone strikes by the US government killed at least two dozen suspected AQAP members and destroyed one of the group's training camps in southern Yemen, according to a statement released by the Yemeni Interior Ministry. In a statement, the group admitted that five civilians had been wounded and three killed during the attack. 
On 13 June 2014 a suspected US drone strike targeted a car in the Mafraq al-Saeed area of the Shabwah province, killing five alleged AQAP operatives on board.
Thus far, it is estimated that a total of 98 US drone attacks have been conducted in Yemen since 2002; 41 in 2012, 26 in 2013 and 14 in 2014.

</doc>
<doc id="42445" url="http://en.wikipedia.org/wiki?curid=42445" title="Atomic mass unit">
Atomic mass unit

The unified atomic mass unit (symbol: u) or dalton (symbol: Da) is the standard unit that is used for indicating mass on an atomic or molecular scale (atomic mass). One unified atomic mass unit is approximately the mass of one nucleon (either a single proton or neutron) and is equivalent to 1g/mol. It is defined as one twelfth of the mass of an unbound neutral atom of carbon-12 in its nuclear and electronic ground state, and has a value of . The CIPM has categorised it as a non-SI unit accepted for use with the SI, and whose value in SI units must be obtained experimentally.
The amu without the "unified" prefix is technically an obsolete unit based on oxygen, which was replaced in 1961. However, some sources may still use the term "amu" but now define it in the same way as u (ie. based on carbon-12). In this sense, most uses of the terms "atomic mass units" and "amu" today actually refer to unified atomic mass units. For standardization a specific atomic nucleus (carbon-12 vs. oxygen-16) had to be chosen because average mass of a nucleon depends on the count of the nucleons in the atomic nucleus due to mass defect. This is also why the mass of a proton (or neutron) by itself is more than (and not equal to) 1 u.
Atomic mass unit does "not" stand for the unit of mass in the atomic units system, which is rather "m"e.
History.
The relative atomic mass (atomic weight) scale has traditionally been a relative scale, that is without an explicit unit, with the first relative atomic mass basis suggested by John Dalton in 1803 as 1H. Despite the initial mass of 1H being used as the natural unit for relative atomic mass, it was suggested by Wilhelm Ostwald that relative atomic mass would be best expressed in terms of units of 1/16 mass of oxygen. This evaluation was made prior to the discovery of the existence of elemental isotopes, which occurred in 1912.
The discovery of isotopic oxygen in 1929 led to a divergence in relative atomic mass representation, with isotopically weighted oxygen (i.e., naturally occurring oxygen relative atomic mass) given a value of exactly 16 atomic mass units (amu) in chemistry, while pure 16O (oxygen-16) was given the mass value of exactly 16 amu in physics.
The divergence of these values could result in errors in computations, and was unwieldy. The chemistry amu, based on the relative atomic mass (atomic weight) of natural oxygen (including the heavy naturally-occurring isotopes 17O and 18O), was about as massive as the physics amu, based on pure isotopic 16O.
For these and other reasons, the reference standard for both physics and chemistry was changed to carbon-12 in 1961. The choice of carbon-12 was made to minimise further divergence with prior literature. The new and current unit was referred to as the "unified atomic mass unit" u. and given a new symbol, "u," which replaced the now deprecated "amu" that had been connected to the old oxygen-based system. The Dalton (Da) is another name for the unified atomic mass unit.
Despite this change, modern sources often still use the old term "amu" but define it as u (1/12 of the mass of a carbon-12 atom), as mentioned in the article's introduction. Therefore, in general, "amu" likely does not refer to the old oxygen standard unit, unless the source material originates from or before the 1960s.
The unified atomic mass unit u was defined as:
Terminology.
The unified atomic mass unit and the dalton are different names for the same unit of measure. As with other unit names such as watt and newton, "dalton" is not capitalized in English, but its symbol Da is capitalized. With the introduction of the name "dalton", there has been a gradual change towards using that name in preference to the name "unified atomic mass unit":
Relationship to SI.
The definition of the mole, an SI base unit, was accepted by the CGPM in 1971 as:
The definition of the mole also determines the value of the universal constant that relates the number of entities to amount of substance for any sample. This constant is called the Avogadro constant, symbol "N"A or "L", and is equal to entities per mole.
Given that the unified atomic mass unit is one twelfth the mass of one atom of carbon-12, meaning the mass of such an atom is 12 u, it follows that there are "N"A atoms of carbon-12 in 0.012 kg of carbon-12. This can be expressed mathematically as
Masses of proteins are often expressed in daltons. For example, a protein with a molecular weight of has a mass of 64 kDa.

</doc>
<doc id="42446" url="http://en.wikipedia.org/wiki?curid=42446" title="Reason">
Reason

Reason is the capacity for consciously making sense of things, applying logic, establishing and verifying facts, and changing or justifying practices, institutions, and beliefs based on new or existing information. It is closely associated with such characteristically human activities as philosophy, science, language, mathematics, and art and is normally considered to be a definitive characteristic of human nature.
The concept of reason is sometimes referred to as rationality and sometimes as discursive reason, in opposition to intuitive reason.
Reason or "reasoning" is associated with thinking, cognition, and intellect. Reason, like habit or intuition, is one of the ways by which thinking comes from one idea to a related idea. For example, it is the means by which rational beings understand themselves to think about cause and effect, truth and falsehood, and what is good or bad. It is also closely identified with the ability to self-consciously change beliefs, attitudes, traditions, and institutions, and therefore with the capacity for freedom and self-determination.
In contrast to reason as an abstract noun, a reason is a consideration which explains or justifies some event, phenomenon or behaviour. The field of logic studies ways in which human beings reason through argument. 
Psychologists and cognitive scientists have attempted to study and explain how people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field of automated reasoning studies how reasoning may or may not be modeled computationally. Animal psychology considers the question of whether animals other than humans can reason.
Etymology and related words.
In the English language and other modern European languages, "reason", and related words, represent words which have always been used to translate Latin and classical Greek terms in the sense of their philosophical usage.
The earliest major philosophers to publish in English, such as Francis Bacon, Thomas Hobbes, and John Locke also routinely wrote in Latin and French, and compared their terms to Greek, treating the words ""logos", "ratio", "raison"" and "reason" as inter-changeable. The meaning of the word "reason" in senses such as "human reason" also overlaps to a large extent with "rationality" and the adjective of "reason" in philosophical contexts is normally "rational", rather than "reasoned" or "reasonable". Some philosophers such as Thomas Hobbes, for example, also used the word "ratiocination" as a synonym for "reasoning".
Philosophical history.
The proposal that reason gives humanity a special position in nature has been argued to be a defining characteristic of western philosophy and later western modern science, starting with classical Greece. Philosophy can be described as a way of life based upon reason, and in the other direction reason has been one of the major subjects of philosophical discussion since ancient times. Reason is often said to be reflexive, or "self-correcting," and the critique of reason has been a persistent theme in philosophy. It has been defined in different ways, at different times, by different thinkers.
Classical philosophy.
For many classical philosophers, nature was understood teleologically, meaning that every type of thing had a definitive purpose which fit within a natural order that was itself understood to have aims. Perhaps starting with Pythagoras or Heraclitus, the cosmos is even said to have reason. Reason, by this account, is not just one characteristic that humans happen to have, and that influences happiness amongst other characteristics. Reason was considered of higher stature than other characteristics of human nature, such as sociability, because it is something humans share with nature itself, linking an apparently immortal part of the human mind with the divine order of the cosmos itself. Within the human mind or soul ("psyche"), reason was described by Plato as being the natural monarch which should rule over the other parts, such as spiritedness ("thumos") and the emotions. Aristotle, Plato's student, defined human beings as rational animals, emphasizing reason as a characteristic of human nature. He "defined" the highest human happiness or well being ("eudaimonia") as a life which is lived consistently, excellently and completely in accordance with reason.
The conclusions to be drawn from the discussions of Aristotle and Plato on this matter are amongst the most debated in the history of philosophy. But teleological accounts such as Aristotle's were highly influential for those who attempt to explain reason in a way which is consistent with monotheism and the immortality and divinity of the human soul. For example, in the neo-platonist account of Plotinus, the cosmos has one soul, which is the seat of all reason, and the souls of all individual humans are part of this soul. Reason is for Plotinus both the provider of form to material things, and the light which brings individuals souls back into line with their source. Such neo-Platonist accounts of the rational part of the human soul were standard amongst medieval Islamic philosophers, and under this influence, mainly via Averroes, came to be debated seriously in Europe until well into the renaissance, and they remain important in Iranian philosophy.
Subject-centred reason in early modern philosophy.
The early modern era was marked by a number of significant changes in the understanding of reason, starting in Europe. One of the most important of these changes involved a change in the metaphysical understanding of human beings. Scientists and philosophers began to question the teleological understanding of the world. Nature was no longer assumed to be human-like, with its own aims or reason, and human nature was no longer assumed to work according to anything other than the same "laws of nature" which affect inanimate things. This new understanding eventually displaced the previous world view that derived from a spiritual understanding of the universe.
Accordingly, in the 17th century, René Descartes explicitly rejected the traditional notion of humans as "rational animals," suggesting instead that they are nothing more than "thinking things" along the lines of other "things" in nature. Any grounds of knowledge outside that understanding was, therefore, subject to doubt.
In his search for a foundation of all possible knowledge, Descartes deliberately decided to throw into doubt "all" knowledge – "except" that of the mind itself in the process of thinking:
At this time I admit nothing that is not necessarily true. I am therefore precisely nothing but a thinking thing; that is a mind, or intellect, or understanding, or reason – words of whose meanings I was previously ignorant.
This eventually became known as epistemological or "subject-centred" reason, because it is based on the "knowing subject", who perceives the rest of the world and itself as a set of objects to be studied, and successfully mastered by applying the knowledge accumulated through such study. Breaking with tradition and many thinkers after him, Descartes explicitly did not divide the incorporeal soul into parts, such as reason and intellect, describing them as one indivisible incorporeal entity.
A contemporary of Descartes, Thomas Hobbes described reason as a broader version of "addition and subtraction" which is not limited to numbers. This understanding of reason is sometimes termed "calculative" reason. Similar to Descartes, Hobbes asserted that "No discourse whatsoever, can end in absolute knowledge of fact, past, or to come" but that "sense and memory" is absolute knowledge.
In the late 17th century, through the 18th century, John Locke and David Hume developed Descartes' line of thought still further. Hume took it in an especially skeptical direction, proposing that there could be no possibility of deducing relationships of cause and effect, and therefore no knowledge is based on reasoning alone, even if it seems otherwise.
Hume famously remarked that, "We speak not strictly and philosophically when we talk of the combat of passion and of reason. Reason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them." Hume also took his definition of reason to unorthodox extremes by arguing, unlike his predecessors, that human reason is not qualitatively different from either simply conceiving individual ideas, or from judgments associating two ideas, and that "reason is nothing but a wonderful and unintelligible instinct in our souls, which carries us along a certain train of ideas, and endows them with particular qualities, according to their particular situations and relations." It followed from this that animals have reason, only much less complex than human reason.
In the 18th century, Immanuel Kant attempted to show that Hume was wrong by demonstrating that a "transcendental" self, or "I", was a necessary condition of all experience. Therefore, suggested Kant, on the basis of such a self, it is in fact possible to reason both about the conditions and limits of human knowledge. And so long as these limits are respected, reason can be the vehicle of morality, justice and understanding.
Substantive and formal reason.
In the formulation of Kant, who wrote some of the most influential modern treatises on the subject, the great achievement of reason is that it is able to exercise a kind of universal law-making. Kant was able therefore to re-formulate the basis of moral-practical, theoretical and aesthetic reasoning, on "universal" laws.
Here practical reasoning is the self-legislating or self-governing formulation of universal norms, and theoretical reasoning the way humans posit universal laws of nature.
Under practical reason, the moral autonomy or freedom of human beings depends on their ability to behave according to laws that are given to them by the proper exercise of that reason. This contrasted with earlier forms of morality, which depended on religious understanding and interpretation, or nature for their substance.
According to Kant, in a free society each individual must be able to pursue their goals however they see fit, so long as their actions conform to principles given by reason. He formulated such a principle, called the "categorical imperative", which would justify an action only if it could be universalized:
Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.
In contrast to Hume then, Kant insists that reason itself (German "Vernunft") has natural ends itself, the solution to the metaphysical problems, especially the discovery of the foundations of morality. Kant claimed that this problem could be solved with his "transcendental logic" which unlike normal logic is not just an instrument, which can be used indifferently, as it was for Aristotle, but a theoretical science in its own right and the basis of all the others.
According to Jürgen Habermas, the "substantive unity" of reason has dissolved in modern times, such that it can no longer answer the question "How should I live?" Instead, the unity of reason has to be strictly formal, or "procedural." He thus described reason as a group of three autonomous spheres (on the model of Kant's three critiques):
For Habermas, these three spheres are the domain of experts, and therefore need to be mediated with the "lifeworld" by philosophers. In drawing such a picture of reason, Habermas hoped to demonstrate that the substantive unity of reason, which in pre-modern societies had been able to answer questions about the good life, could be made up for by the unity of reason's formalizable procedures.
The critique of reason.
Hamann, Herder, Kant, Hegel, Kierkegaard, Nietzsche, Heidegger, Foucault, Rorty, and many other philosophers have contributed to a debate about what reason means, or ought to mean. Some, like Kierkegaard, Nietzsche, and Rorty, are skeptical about subject-centred, universal, or instrumental reason, and even skeptical toward reason as a whole. Others, including Hegel, believe that it has obscured the importance of intersubjectivity, or "spirit" in human life, and attempt to reconstruct a model of what reason should be.
Some thinkers, e.g. Foucault, believe there are other "forms" of reason, neglected but essential to modern life, and to our understanding of what it means to live a life according to reason.
In the last several decades, a number of proposals have been made to "re-orient" this critique of reason, or to recognize the "other voices" or "new departments" of reason:
For example, in opposition to subject-centred reason, Habermas has proposed a model of communicative reason that sees it as an essentially cooperative activity, based on the fact of linguistic intersubjectivity.
Nikolas Kompridis has proposed a widely encompassing view of reason as "that ensemble of practices that contributes to the opening and preserving of openness" in human affairs, and a focus on reason's possibilities for social change.
The philosopher Charles Taylor, influenced by the 20th century German philosopher Martin Heidegger, has proposed that reason ought to include the faculty of disclosure, which is tied to the way we make sense of things in everyday life, as a new "department" of reason.
In the essay "What is Enlightenment?", Michel Foucault proposed a concept of critique based on Kant's distinction between "private" and "public" uses of reason. This distinction, as suggested, has two dimensions:
Reason compared to related concepts.
Reason compared to Logic.
The terms "logic" or "logical" are sometimes used as if they were identical with the term "reason" or with the concept of being "rational", or sometimes logic is seen as the most pure or the defining form of reason. For example in modern economics, rational choice is assumed to equate to logically consistent choice.
Reason and logic can however be thought of as distinct, although logic is one important aspect of reason. Author Douglas Hofstadter, in "Gödel, Escher, Bach", characterizes the distinction in this way. Logic is done inside a system while reason is done outside the system by such methods as skipping steps, working backward, drawing diagrams, looking at examples, or seeing what happens if you change the rules of the system.
Reason is a type of thought, and the word "logic" involves the attempt to describe rules or norms by which reasoning operates, so that orderly reasoning can be taught. The oldest surviving writing to explicitly consider the rules by which reason operates are the works of the Greek philosopher Aristotle, especially "Prior Analysis" and "Posterior Analysis". Although the Ancient Greeks had no separate word for logic as distinct from language and reason, Aristotle's newly coined word "syllogism" ("syllogismos") identified logic clearly for the first time as a distinct field of study. When Aristotle referred to "the logical" ("hē logikē"), he was referring more broadly to rational thought.
Reason compared to cause-and-effect thinking, and symbolic thinking.
As pointed out by philosophers such as Hobbes, Locke and Hume, some animals are also clearly capable of a type of "associative thinking", even to the extent of associating causes and effects. A dog once kicked, can learn how to recognize the warning signs and avoid being kicked in the future, but this does not mean the dog has reason in any strict sense of the word. It also does not mean that humans acting on the basis of experience or habit are using their reason.
Human reason requires more than being able to associate two ideas, even if those two ideas might be described by a reasoning human as a cause and an effect, perceptions of smoke, for example, and memories of fire. For reason to be involved, the association of smoke and the fire would have to be thought through in a way which can be explained, for example as cause and effect. In the explanation of Locke, for example, reason requires the mental use of a third idea in order to make this comparison by use of syllogism.
More generally, reason in the strict sense requires the ability to create and manipulate a system of symbols, as well as indices and icons, according to Charles Sanders Peirce, the symbols having only a nominal, though habitual, connection to either smoke or fire. One example of such a system of artificial symbols and signs is language.
The connection of reason to symbolic thinking has been expressed in different ways by philosophers. Thomas Hobbes described the creation of "Markes, or Notes of remembrance" ("Leviathan" Ch.4) as "speech". He used the word "speech" as an English version of the Greek word "logos" so that speech did not need to be communicated. When communicated, such speech becomes language, and the marks or notes or remembrance are called "Signes" by Hobbes. Going further back, although Aristotle is a source of the idea that only humans have reason ("logos"), he does mention that animals with imagination, for whom sense perceptions can persist, come closest to having something like reasoning and "nous", and even uses the word "logos" in one place to describe the distinctions which animals can perceive in such cases.
Reason, imagination, mimesis, and memory.
Reason and imagination rely on similar mental processes. Imagination is not only found in humans. Aristotle, for example, stated that "phantasia" (imagination: that which can hold images or "phantasmata") and "phronein" (a type of thinking that can judge and understand in some sense) also exist in some animals. According to him, both are related to the primary perceptive ability of animals, which gathers the perceptions of different senses and defines the order of the things that are perceived without distinguishing universals, and without deliberation or "logos". But this is not yet reason, because human imagination is different.
The recent modern writings of Terrence Deacon and Merlin Donald, writing about the origin of language, also connect reason connected to not only language, but also mimesis, More specifically they describe the ability to create language as part of an internal modeling of reality specific to humankind. Other results are consciousness, and imagination or fantasy. In contrast, modern proponents of a genetic pre-disposition to language itself include Noam Chomsky and Steven Pinker, to whom Donald and Deacon can be contrasted.
As reason is symbolic thinking, and peculiarly human, then this implies that humans have a special ability to maintain a clear consciousness of the distinctness of "icons" or images and the real things they represent. Starting with a modern author, Merlin Donald writes
A dog might perceive the "meaning" of a fight that was realistically play-acted by humans, but it could not reconstruct the message or distinguish the representation from its referent (a real fight). [...] Trained apes are able to make this distinction; young children make this distinction early – hence, their effortless distinction between play-acting an event and the event itself
In classical descriptions, an equivalent description of this mental faculty is "eikasia", in the philosophy of Plato. This is the ability to perceive whether a perception is an image of something else, related somehow but not the same, and therefore allows humans to perceive that a dream or memory or a reflection in a mirror is not reality as such. What Klein refers to as "dianoetic eikasia" is the "eikasia" concerned specifically with thinking and mental images, such as those mental symbols, icons, "signes", and marks discussed above as definitive of reason. Explaining reason from this direction: human thinking is special in the way that we often understand visible things as if they were themselves images of our intelligible "objects of thought" as "foundations" ("hypothēses" in Ancient Greek). This thinking ("dianoia") is "...an activity which consists in making the vast and diffuse jungle of the visible world depend on a plurality of more 'precise' "noēta"."
Both Merlin Donald and the Socratic authors such Plato and Aristotle emphasize the importance of "mimesis", often translated as "imitation" or "representation". Donald writes
Imitation is found especially in monkeys and apes [... but ...] Mimesis is fundamentally different from imitation and mimicry in that it involves the invention of intentional representations. [...] Mimesis is not absolutely tied to external communication.
"Mimēsis" is a concept, now popular again in academic discussion, that was particularly prevalent in Plato's works, and within Aristotle, it is discussed mainly in the "Poetics". In Michael Davis's account of the theory of man in this work.
It is the distinctive feature of human action, that whenever we choose what we do, we imagine an action for ourselves as though we were inspecting it from the outside. Intentions are nothing more than imagined actions, internalizings of the external. All action is therefore imitation of action; it is poetic...
Donald like Plato (and Aristotle, especially in "On Memory and Recollection"), emphasizes the peculiarity in humans of voluntary initiation of a search through one's mental world. The ancient Greek "anamnēsis", normally translated as "recollection" was opposed to "mneme" or "memory". Memory, shared with some animals, requires a consciousness not only of what happened in the past, but also "that" something happened in the past, which is in other words a kind of "eikasia" "...but nothing except man is able to recollect." Recollection is a deliberate effort to search for and recapture something once known. Klein writes that, "To become aware of our having forgotten something means to begin recollecting." Donald calls the same thing "autocueing", which he explains as follows: "Mimetic acts are reproducible on the basis of internal, self-generated cues. This permits voluntary recall of mimetic representations, without the aid of external cues – probably the earliest form of representational "thinking"."
In a celebrated paper in modern times, the fantasy author and philologist J.R.R. Tolkien wrote in his essay "On Fairy Stories" that the terms "fantasy" and "enchantment" are connected to not only "...the satisfaction of certain primordial human desires..." but also "...the origin of language and of the mind."
Logical reasoning methods and argumentation.
Looking at logical categorizations of different types of reasoning the traditional main division made in philosophy is between deductive reasoning and inductive reasoning. Formal logic has been described as "the science of deduction". The study of inductive reasoning is generally carried out within the field known as informal logic or critical thinking.
Deductive reasoning.
A subdivision of Philosophy is Logic. Logic is the study of reasoning. Deduction is a form of reasoning in which a conclusion follows necessarily from the stated premises. A deduction is also the conclusion reached by a deductive reasoning process. One classic example of deductive reasoning is that found in syllogisms like the following:
The reasoning in this argument is valid, because there is no way in which the premises, 1 and 2, could be true and the conclusion, 3, be false.
Inductive reasoning.
Induction is a form of inference producing propositions about unobserved objects or types, either specifically or generally, based on previous observation. It is used to ascribe properties or relations to objects or types based on previous observations or experiences, or to formulate general statements or laws based on limited observations of recurring phenomenal patterns.
Inductive reasoning contrasts strongly with deductive reasoning in that, even in the best, or strongest, cases of inductive reasoning, the truth of the premises does not guarantee the truth of the conclusion. Instead, the conclusion of an inductive argument follows with some degree of probability. Relatedly, the conclusion of an inductive argument contains more information than is already contained in the premises. Thus, this method of reasoning is ampliative.
A classic example of inductive reasoning comes from the empiricist David Hume:
Abductive reasoning.
Abductive reasoning, or argument to the best explanation, is a form of inductive reasoning, since the conclusion in an abductive argument does not follow with certainty from its premises and concerns something unobserved. What distinguishes abduction from the other forms of reasoning is an attempt to favour one conclusion above others, by attempting to falsify alternative explanations or by demonstrating the likelihood of the favoured conclusion, given a set of more or less disputable assumptions. For example, when a patient displays certain symptoms, there might be various possible causes, but one of these is preferred above others as being more probable.
Analogical reasoning.
Analogical reasoning is incorrectly reasoning from the particular to the particular. An example follows:
Analogical reasoning can be viewed as a form of inductive reasoning from a single example, but if it is intended as inductive reasoning it is a bad example, because inductive reasoning typically uses a large number of examples to reason from the particular to the general. Analogical reasoning often leads to wrong conclusions. For example
Fallacious reasoning.
Flawed reasoning in arguments is known as fallacious reasoning. Bad reasoning within arguments can be because it commits either a formal fallacy or an informal fallacy.
Formal fallacies occur when there is a problem with the form, or structure, of the argument. The word "formal" refers to this link to the "form" of the argument. An argument that contains a formal fallacy will always be invalid. 
An informal fallacy is an error in reasoning that occurs due to a problem with the "content", rather than mere "structure", of the argument.
Traditional problems raised concerning reason.
Philosophy is sometimes described as a life of reason, with normal human reason pursued in a more consistent and dedicated way than usual. Two categories of problem concerning reason have long been discussed by philosophers concerning reason, essentially being reasonings about reasoning itself as a human aim, or philosophizing about philosophizing. The first question is concerning whether we can be confident that reason can achieve knowledge of truth better than other ways of trying to achieve such knowledge. The other question is whether a life of reason, a life that aims to be guided by reason, can be expected to achieve a happy life more so than other ways of life (whether such a life of reason results in knowledge or not).
Reason versus truth, and "first principles".
Since classical times a question has remained constant in philosophical debate (which is sometimes seen as a conflict between movements called Platonism and Aristotelianism) concerning the role of reason in confirming truth. People use logic, deduction, and induction, to reach conclusions they think are true. Conclusions reached in this way are considered more certain than sense perceptions on their own. On the other hand, if such reasoned conclusions are only built originally upon a foundation of sense perceptions, then, our most logical conclusions can never be said to be certain because they are built upon the very same fallible perceptions they seek to better.
This leads to the question of what types of first principles, or starting points of reasoning, are available for someone seeking to come to true conclusions. In Greek, "first principles" are "archai", "starting points", and the faculty used to perceive them is sometimes referred to in Aristotle and Plato as "nous" which was close in meaning to "awareness" or "consciousness".
Empiricism (sometimes associated with Aristotle but more correctly associated with British philosophers such as John Locke and David Hume, as well as their ancient equivalents such as Democritus) asserts that sensory impressions are the only available starting points for reasoning and attempting to attain truth. This approach always leads to the controversial conclusion that absolute knowledge is not attainable. Idealism, (associated with Plato and his school), claims that there is a "higher" reality, from which certain people can directly arrive at truth without needing to rely only upon the senses, and that this higher reality is therefore the primary source of truth.
Philosophers such as Plato, Aristotle, Al-Farabi, Avicenna, Averroes, Maimonides, Aquinas and Hegel are sometimes said to have argued that reason must be fixed and discoverable—perhaps by dialectic, analysis, or study. In the vision of these thinkers, reason is divine or at least has divine attributes. Such an approach allowed religious philosophers such as Thomas Aquinas and Étienne Gilson to try to show that reason and revelation are compatible. According to Hegel, "...the only thought which Philosophy brings with it to the contemplation of History, is the simple conception of reason; that reason is the Sovereign of the World; that the history of the world, therefore, presents us with a rational process."
Since the 17th century rationalists, reason has often been taken to be a subjective faculty, or rather the unaided ability (pure reason) to form concepts. For Descartes, Spinoza and Leibniz, this was associated with mathematics. Kant attempted to show that pure reason could form concepts (time and space) that are the conditions of experience. Kant made his argument in opposition to Hume, who denied that reason had any role to play in experience.
Reason versus emotion or passion.
After Plato and Aristotle, western literature often treated reason as being opposed to emotions or feelings. This was an understanding of human nature developed, for example, by Stoic philosophy in Roman times. People might say their passions made them behave contrary to reason, or that their reason kept the passions under control. This is often expressed colloquially as the dilemma between following "the head" (reason) "or the heart" (emotions).
Reason has been seen as a slave, or judge, of the passions, notably in the work of David Hume, and more recently of Freud. Reasoning which claims that the object of a desire is demanded by logic alone is called "rationalization".
Rousseau first proposed, in his second "Discourse", that reason and political life is not natural and possibly harmful to mankind. He asked what really can be said about what is natural to mankind. What, other than reason and civil society, "best suits his constitution"? Rousseau saw "two principles prior to reason" in human nature. First we hold an intense interest in our own well-being. Secondly we object to the suffering or death of any sentient being, especially one like ourselves. These two passions lead us to desire more than we could achieve. We become dependent upon each other, and on relationships of authority and obedience. This effectively puts the human race into slavery. Rousseau says that he almost dares to assert that nature does not destine men to be healthy. According to Velkley, "Rousseau outlines certain programs of rational self-correction, most notably the political legislation of the "Contrat Social" and the moral education in "". All the same, Rousseau understands such corrections to be only ameliorations of an essentially unsatisfactory condition, that of socially and intellectually corrupted humanity."
This quandary presented by Rousseau led to Kant's new way of justifying reason as freedom to create good and evil. These therefore are not to be blamed on nature or God. In various ways, German Idealism after Kant, and major later figures such Nietzsche, Bergson, Husserl, Scheler, and Heidegger, remain pre-occupied with problems coming from the metaphysical demands or "urges" of "reason". The influence of Rousseau and these later writers is also large upon art and politics. Many writers (such as Nikos Kazantzakis) extol passion and disparage reason. In politics modern nationalism comes from Rousseau's argument that rationalist cosmopolitanism brings man ever further from his natural state.
Another view on reason and emotion was proposed in the 1994 book titled "Descartes' Error" by Antonio Damasio. In it, Damasio presents the "Somatic Marker Hypothesis" which states that emotions guide behavior and decision-making. Damasio argues that these somatic markers (known collectively as "gut feelings") are "intuitive signals" that direct our decision making processes in a certain way that cannot be solved with rationality alone. Damasio further argues that rationality requires emotional input in order to function.
Reason versus faith or tradition.
Though theologies and religions typically do not claim to be irrational, there is often a perceived conflict or tension between faith and tradition on the one hand, and reason on the other, as potentially competing sources of wisdom, law and truth. Defenders of traditions and faiths from claims that they are irrationalist for ignoring or even attempting to forbid reason and argument concerning some subjects, typically maintain that there is no real conflict with reason, because reason itself is not enough to explain such things as the origins of the universe, or right and wrong, and so reason can and should be complemented by other sources of knowledge, or in other words "first principles". The counter claim to this is that such a defense does not logically explain why some arguments from reason would be forbidden or ignored, while others are favoured.
There are enormously wide differences between different faiths, or even schools within different faiths, concerning this matter.
Some commentators have claimed that Western civilization can be almost defined by its serious testing of the limits of tension between "unaided" reason and faith in "revealed" truths—figuratively summarized as Athens and Jerusalem, respectively. Leo Strauss spoke of a "Greater West" that included all areas under the influence of the tension between Greek rationalism and Abrahamic revelation, including the Muslim lands. He was particularly influenced by the great Muslim philosopher Al-Farabi. To consider to what extent Eastern philosophy might have partaken of these important tensions, Strauss thought it best to consider whether dharma or tao may be equivalent to Nature (by which we mean "physis" in Greek). According to Strauss the beginning of philosophy involved the "discovery or invention of nature" and the "pre-philosophical equivalent of nature" was supplied by "such notions as 'custom' or 'ways'", which appear to be "really universal in all times and places". The philosophical concept of nature or natures as a way of understanding "archai" (first principles of knowledge) brought about a peculiar tension between reasoning on the one hand, and tradition or faith on the other.
Although there is this special history of debate concerning reason and faith in the Islamic, Christian and Jewish traditions, the pursuit of reason is sometimes argued to be compatible with the other practice of other religions of a different nature, such as Hinduism, because they do not define their tenets in such an absolute way.
Reason in particular fields of study.
Reason in political philosophy and ethics.
Aristotle famously described reason (with language) as a part of human nature, which means that it is best for humans to live "politically" meaning in communities of about the size and type of a small city state ("polis" in Greek). For example...
It is clear, then, that a human being is more of a political ["politikon" = of the "polis"] animal ["zōion"] than is any bee or than any of those animals that live in herds. For nature, as we say, makes nothing in vain, and humans are the only animals who possess reasoned speech ["logos"]. Voice, of course, serves to indicate what is painful and pleasant; that is why it is also found in other animals, because their nature has reached the point where they can perceive what is painful and pleasant and express these to each other. But speech ["logos"] serves to make plain what is advantageous and harmful and so also what is just and unjust. For it is a peculiarity of humans, in contrast to the other animals, to have perception of good and bad, just and unjust, and the like; and the community in these things makes a household or city ["polis"]. [...] By nature, then, the drive for such a community exists in everyone, but the first to set one up is responsible for things of very great goodness. For as humans are the best of all animals when perfected, so they are the worst when divorced from law and right. The reason is that injustice is most difficult to deal with when furnished with weapons, and the weapons a human being has are meant by nature to go along with prudence and virtue, but it is only too possible to turn them to contrary uses. Consequently, if a human being lacks virtue, he is the most unholy and savage thing, and when it comes to sex and food, the worst. But justice is something political [to do with the "polis"], for right is the arrangement of the political community, and right is discrimination of what is just. (Aristotle's Politics 1253a 1.2. Peter Simpson's translation, with Greek terms inserted in square brackets.)
The concept of human nature being fixed in this way, implied, in other words, that we can define what type of community is always best for people. This argument has remained a central argument in all political, ethical and moral thinking since then, and has become especially controversial since firstly Rousseau's Second Discourse, and secondly, the Theory of Evolution. Already in Aristotle there was an awareness that the "polis" had not always existed and had needed to be invented or developed by humans themselves. The household came first, and the first villages and cities were just extensions of that, with the first cities being run as if they were still families with Kings acting like fathers.
Friendship ["philia"] seems to prevail [in] man and woman according to nature ["kata phusin"]; for people are by nature ["tēi phusei"] pairing ["sunduastikon"] more than political ["politikon" = of the "polis"], inasmuch as the household ["oikos"] is prior ["proteron" = earlier] and more necessary than the "polis" and making children is more common ["koinoteron"] with the animals. In the other animals, community ["koinōnia"] goes no further than this, but people live together ["sumoikousin"] not only for the sake of making children, but also for the things for life; for from the start the functions ["erga"] are divided, and are different [for] man and woman. Thus they supply each other, putting their own into the common ["eis to koinon"]. It is for these [reasons] that both utility ["chrēsimon"] and pleasure ["hēdu"] seem to be found in this kind of friendship. (Nicomachean Ethics, VIII.12.1162a. Rough literal translation with Greek terms shown in square brackets.)
Rousseau in his Second Discourse finally took the shocking step of claiming that this traditional account has things in reverse: with reason, language and rationally organized communities all having developed over a long period of time merely as a result of the fact that some habits of cooperation were found to solve certain types of problems, and that once such cooperation became more important, it forced people to develop increasingly complex cooperation—often only to defend themselves from each other.
In other words, according to Rousseau, reason, language and rational community did not arise because of any conscious decision or plan by humans or gods, nor because of any pre-existing human nature. As a result, he claimed, living together in rationally organized communities like modern humans is a development with many negative aspects compared to the original state of man as an ape. If anything is specifically human in this theory, it is the flexibility and adaptability of humans. This view of the animal origins of distinctive human characteristics later received support from Charles Darwin's Theory of Evolution.
The two competing theories concerning the origins of reason are relevant to political and ethical thought because, according to the Aristotelian theory, a best way of living together exists independently of historical circumstances. According to Rousseau, we should even doubt that reason, language and politics are a good thing, as opposed to being simply the best option given the particular course of events that lead to today. Rousseau's theory, that human nature is malleable rather than fixed, is often taken to imply, for example by Karl Marx, a wider range of possible ways of living together than traditionally known.
However, while Rousseau's initial impact encouraged bloody revolutions against traditional politics, including both the French Revolution and the Russian Revolution, his own conclusions about the best forms of community seem to have been remarkably classical, in favor of city-states such as Geneva, and rural living.
Psychology.
Scientific research into reasoning is carried out within the fields of psychology and cognitive science. Psychologists attempt to determine whether or not people are capable of rational thought in a number of different circumstances.
Assessing how well someone engages in reasoning is the project of determining the extent to which the person is rational or acts rationally. It is a key research question in the psychology of reasoning. Rationality is often divided into its respective theoretical and practical counterparts.
Behavioral experiments on human reasoning.
Experimental cognitive psychologists carry out research on reasoning behaviour. Such research may focus, for example, on how people perform on tests of reasoning such as intelligence or IQ tests, or on how well people's reasoning matches ideals set by logic (see, for example, the Wason test). Experiments examine how people make inferences from conditionals e.g., "If A then B" and how they make inferences about alternatives, e.g., "A or else B". They test whether people can make valid deductions about spatial and temporal relations, e.g., "A is to the left of B", or "A happens after B", and about quantified assertions, e.g., "All the A are B". Experiments investigate how people make inferences about factual situations, hypothetical possibilities, probabilities, and counterfactual situations.
Developmental studies of children's reasoning.
Developmental psychologists investigate the development of reasoning from birth to adulthood. Piaget's theory of cognitive development was the first complete theory of reasoning development. Subsequently, several alternative theories were proposed, including the neo-Piagetian theories of cognitive development.
Neuroscience of reasoning.
The biological functioning of the brain is studied by neurophysiologists and neuropsychologists. Research in this area includes research into the structure and function of normally functioning brains, and of damaged or otherwise unusual brains. In addition to carrying out research into reasoning, some psychologists, for example, clinical psychologists and psychotherapists work to alter people's reasoning habits when they are unhelpful.
Computer science.
Automated reasoning.
In artificial intelligence and computer science, scientists study and use automated reasoning for diverse applications including automated theorem proving the formal semantics of programming languages, and formal specification in software engineering.
Meta-reasoning.
Meta-reasoning is reasoning about reasoning. In computer science, a system performs meta-reasoning when it is reasoning about its own operation. This requires a programming language capable of reflection, the ability to observe and modify its own structure and behaviour.
Evolution of reason.
A species could benefit greatly from better abilities to reason about, predict and understand the world. French social and cognitive scientist Dan Sperber, with his colleague Hugo describes the idea that there could have been other forces driving the evolution of reason. Sperber points out that reasoning is very difficult for humans to do effectively, and that it is hard for individuals to doubt their own beliefs. Reasoning is most effective when it is done as a collective - as demonstrated by the success of projects like science. Sperber says this could suggest that there are not just individual, but group selection pressures at play. Any group that managed to find ways of reasoning effectively would reap benefits for all its members, increasing their fitness. This could also help explain why humans, according to Sperber, are not optimized to reason effectively alone. Patricia Cohen, writing for The New York Times, summarizes some of Mercier's thoughts on this "Argumentative Theory" (which states that reason is adapted to persuasion). To Cohen, the idea is that humans debate like lawyers: they often commit to one side of an argument and converse until the truth is discovered.

</doc>
<doc id="42451" url="http://en.wikipedia.org/wiki?curid=42451" title="Pentaerythritol tetranitrate">
Pentaerythritol tetranitrate

Pentaerythritol tetranitrate (PETN), also known as PENT, PENTA, TEN, corpent, penthrite (or—rarely and primarily in German—as nitropenta), is the nitrate ester of pentaerythritol, and is structurally very similar to nitroglycerin. Penta refers to the five carbon atoms of the neopentane skeleton.
PETN is best known as an explosive. It is one of the most powerful high explosives known, with a relative effectiveness factor of 1.66.
PETN mixed with a plasticizer forms a plastic explosive. As a mixture with RDX and other minor additives, it forms another plastic explosive called Semtex.
It is also used as a vasodilator drug to treat certain heart conditions, such as for management of angina.
History.
Penthrite was first synthesized in 1891 by Bernhard Tollens and P. Wigand by nitration of pentaerythritol. The production of PETN started in 1912, when it was patented by the German government. PETN was used by the German Military in World War I. It was also used in the MG FF/M autocannons and many other weapon systems of the Luftwaffe in World War II, specifically in the high explosive "Minengeschoß" shell.
Properties.
PETN is practically insoluble in water (0.01 g/100 ml at 50 °C), weakly soluble in common nonpolar solvents such as aliphatic hydrocarbons (like gasoline) or tetrachloromethane, but soluble in some other organic solvents, particularly in acetone (about 15 g/100 g of the solution at 20 °C, 55 g/100 g at 60 °C) and dimethylformamide (40 g/100 g of the solution at 40 °C, 70 g/100 g at 70 °C). PETN forms eutectic mixtures with some liquid or molten aromatic nitro compounds, "e.g." trinitrotoluene (TNT) or tetryl. Due to its highly symmetrical structure, PETN is resistant to attack by many chemical reagents; it does not hydrolyze in water at room temperature or in weaker alkaline aqueous solutions. Water at 100 °C or above causes hydrolysis to dinitrate; presence of 0.1% nitric acid accelerates the reaction.
The chemical stability of PETN is of interest, because of the presence of PETN in aging weapons. A review has been published. Neutron radiation degrades PETN, producing carbon dioxide and some pentaerythritol dinitrate and trinitrate. Gamma radiation increases the thermal decomposition sensitivity of PETN, lowers melting point by few degrees Celsius, and causes swelling of the samples. Like other nitrate esters, the primary degradation mechanism is the loss of nitrogen dioxide; this reaction is autocatalytic. Studies were performed on thermal decomposition of PETN.
In the environment, PETN undergoes biodegradation. Some bacteria denitrate PETN to trinitrate and then dinitrate, which is then further degraded. PETN has low volatility and low solubility in water, and therefore has low bioavailability for most organisms. Its toxicity is relatively low, and its transdermal absorption also seems to be low. It poses a threat for aquatic organisms. It can be degraded to pentaerythritol by iron.
Production.
Production is by the reaction of pentaerythritol with concentrated nitric acid to form a precipitate which can be recrystallized from acetone to give processable crystals.
Variations of a method first published in a US Patent 2,370,437 by Acken and Vyverberg (1945 to Du Pont) forms the basis of all current commercial production.
PETN is manufactured by numerous manufacturers as a powder, or together with nitrocellulose and plasticizer as thin plasticized sheets (e.g. Primasheet 1000 or Detasheet). PETN residues are easily detectable in hair of people handling it. The highest residue retention is on black hair; some residues remain even after washing.
Explosive use.
The most common use of PETN is as an explosive with high brisance. It is more difficult to detonate than primary explosives, so dropping or igniting it will typically not cause an explosion (at atmospheric pressure it is difficult to ignite and burns relatively slowly), but is more sensitive to shock and friction than other secondary explosives such as TNT or tetryl. Under certain conditions a deflagration to detonation transition can occur.
It is rarely used alone, but primarily used in booster and bursting charges of small caliber ammunition, in upper charges of detonators in some land mines and shells, and as the explosive core of detonation cord. PETN is the least stable of the common military explosives, but can be stored without significant deterioration for longer than nitroglycerin or nitrocellulose.
During World War II, PETN was most importantly used in exploding-bridgewire detonators for the atomic bombs. These exploding-bridgewire detonators gave more precise detonation, compared with primacord. PETN was used for these detonators because it was safer than primary explosives like lead azide: while it was sensitive, it would not detonate below a threshold amount of energy. Exploding bridgewires containing PETN remain used in current nuclear weapons. In spark detonators, PETN is used to avoid the need for primary explosives; the energy needed for a successful direct initiation of PETN by an electric spark ranges between 10–60 mJ.
Its basic explosion characteristics are:
In mixtures.
PETN is used in a number of compositions. It is a major ingredient of the Semtex plastic explosive. It is also used as a component of pentolite, a 50/50 blend with TNT. The XTX8003 extrudable explosive, used in the W68 and W76 nuclear warheads, is a mixture of 80% PETN and 20% of Sylgard 182, a silicone rubber. It is often phlegmatized by addition of 5–40% of wax, or by polymers (producing polymer-bonded explosives); in this form it is used in some cannon shells up to 30 mm caliber, though unsuitable for higher calibers. It is also used as a component of some gun propellants and solid rocket propellants. Nonphlegmatized PETN is stored and handled with approximately 10% water content. PETN alone cannot be cast as it explosively decomposes slightly above its melting point, but it can be mixed with other explosives to form castable mixtures.
PETN can be initiated by a laser. A pulse with duration of 25 nanoseconds and 0.5–4.2 joules of energy from a Q-switched ruby laser can initiate detonation of a PETN surface coated with a 100 nm thick aluminium layer in less than half of a microsecond.
PETN has been replaced in many applications by RDX, which is thermally more stable and has a longer shelf life. PETN can be used in some ram accelerator types. Replacement of the central carbon atom with silicon produces Si-PETN, which is extremely sensitive.
Terrorist use.
In 1983, the "Maison de France" house in Berlin was brought to a near-total collapse by the detonation of 24 kg of PETN by terrorist Johannes Weinrich.
In 1999, Alfred Heinz Reumayr used PETN as the main charge for his fourteen improvised explosive devices that he constructed in a thwarted attempt to damage the Trans-Alaska Pipeline System.
In 2001, al-Qaeda member Richard Reid, the "Shoe Bomber", used PETN in the sole of his shoe in his unsuccessful attempt to blow up American Airlines Flight 63 from Paris to Miami. He had intended to use the solid triacetone triperoxide (TATP) as a detonator.
In 2009, PETN was used in an attempt by al-Qaeda in the Arabian Peninsula to murder the Saudi Arabian Deputy Minister of Interior Prince Muhammad bin Nayef, by Saudi suicide bomber Abdullah Hassan al Asiri. The target survived and the bomber died in the blast. The PETN was hidden in the bomber's rectum, which security experts described as a novel technique.
On December 25, 2009, PETN was found in the underwear of Umar Farouk Abdulmutallab, the "Underwear bomber", a Nigerian with links to al-Qaeda in the Arabian Peninsula.
According to U.S. law enforcement officials, he had attempted to blow up Northwest Airlines Flight 253 while approaching Detroit from Amsterdam. Abdulmutallab had tried, unsuccessfully, to detonate approximately 80 g of PETN sewn into his underwear by adding liquid from a syringe; however, only a small fire resulted.
In the al-Qaeda in the Arabian Peninsula October 2010 cargo plane bomb plot, two PETN-filled printer cartridges were found at East Midlands Airport and in Dubai on flights bound for the U.S. on an intelligence tip. Both packages contained sophisticated bombs concealed in computer printer cartridges filled with PETN. The bomb found in England contained 400 g of PETN, and the one found in Dubai contained 300 g of PETN. Hans Michels, professor of safety engineering at University College London, told a newspaper that 6 g of PETN—"around 50 times less than was used—would be enough to blast a hole in a metal plate twice the thickness of an aircraft's skin". In contrast, according to an experiment conducted by a BBC documentary team designed to simulate Abdulmutallab's Christmas Day bombing, using a Boeing 747 airplane, even 80 grams of PETN was not sufficient to materially damage the airplane's fuselage.
Detection.
In the wake of terrorist PETN bomb plots, an article in "Scientific American" noted that even if all cargo were screened, PETN is difficult to detect because it has a very low vapor pressure at room temperature, meaning very little of it gets into the air around the bomb, where it can be detected. The "Los Angeles Times" noted in November 2010 that because of its more stable molecules, and lower vapor, it is more difficult to detect by bomb-sniffing dogs and the trace swabs then used by the U.S. Transportation Security Administration.
Many technologies can be used to detect PETN, some of which have been implemented in public screening applications, primarily for air travel. PETN is one of the explosive chemicals typically of interest in that area, and it belongs to a family of common nitrate-based explosive chemicals which can often be detected by the same tests.
One technology, detectors that test swabs wiped on passengers and their baggage for traces of explosives, is generally reserved for travelers who are thought to merit additional scrutiny. Whole-body imaging scanners, use radio-frequency electromagnetic waves, low-intensity X-rays, or T-rays of terahertz frequency to detect objects under clothing; these devices were of limited availability because of cost, privacy groups' opposition and industry concerns about bottlenecks.
Both parcels in the 2010 cargo plane bomb plot were x-rayed without the bombs being spotted. Qatar Airways said the PETN bomb "could not be detected by x-ray screening or trained sniffer dogs". The Bundeskriminalamt received copies of the Dubai x-rays, and an investigator said German staff would not have identified the bomb either. New airport security procedures followed in the U.S., largely to protect against PETN.
Medical use.
Like nitroglycerin (glyceryl trinitrate) and other nitrates, PETN is also used medically as a vasodilator in the treatment of heart conditions. These drugs work by releasing the signaling gas nitric oxide in the body. The heart medicine "Lentonitrat" is nearly pure PETN.
Monitoring of oral usage of the drug by patients has been performed by determination of plasma levels of several of its hydrolysis products, pentaerythritol dinitrate, pentaerythritol mononitrate and pentaerythritol, in plasma using gas chromatography-mass spectrometry.

</doc>
<doc id="42453" url="http://en.wikipedia.org/wiki?curid=42453" title="Kirkendall effect">
Kirkendall effect

The Kirkendall effect is the motion of the boundary layer between two metals that occurs as a consequence of the difference in diffusion rates of the metal atoms. The effect can be observed for example by placing insoluble markers at the interface between a pure metal and an alloy containing that metal, and heating to a temperature where atomic diffusion is possible; the boundary will move relative to the markers.
This process was named after Ernest Kirkendall (1914–2005) assistant professor of chemical engineering at Wayne State University from 1941 to 1946. He discovered the effect in 1947.
The Kirkendall effect has important practical consequences. One of these is the prevention or suppression of voids formed at the boundary interface in various kinds of alloy to metal bonding. These are referred to as Kirkendall voids.
In 1972, C.W. Horsting of the RCA Corporation published a paper which reported test results on the reliability of semiconductor devices in which the connections were made using aluminium wires bonded ultrasonically to gold plated posts. His paper demonstrated the importance of the Kirkendall effect in wire bonding technology, but also showed the significant contribution of any impurities present to the rate at which precipitation occurred at the wire bonds. Two of the important contaminants that have this effect, known as Horsting effect (Horsting voids) are fluorine and chlorine. Both Kirkendall voids and Horsting voids are known causes of wire bond fractures, though historically this cause is often confused with the purple colored appearance of one of the five different gold-aluminium intermetallics, commonly referred to as "purple plague" and less often "white plague".
History.
The Kirkendall effect was discovered by Ernest Kirkendall and Alice Smigelskas in 1947, in the course of Kirkendall’s ongoing research into diffusion in brass. The paper in which he discovered the famous effect was the third in his series of papers on brass diffusion, the first being his thesis. His second paper revealed that zinc diffused more quickly than copper in alpha-brass, which led to the research producing his revolutionary theory. Until this point, substitutional and ring methods were the dominant ideas for diffusional motion. Kirkendall’s experiment produced evidence of a vacancy diffusion mechanism, which is the accepted mechanism to this day. At the time it was submitted, the paper and Kirkendall’s ideas were rejected from publication by Robert Franklin Mehl, director of the Metals Research Laboratory at Carnegie Institute of Technology. Mehl refused to accept Kirkendall’s evidence of this new diffusion mechanism, and denied publication for over six months, only relenting after a conference was held and several other researchers confirmed Kirkendall’s results.
Kirkendall's experiment.
A bar of brass (70% Cu, 30% Zn) was used as a core, with molybdenum wires stretched along its length, and then coated in a layer of pure copper. Molybdenum was chosen as the marker material due to it being very insoluble in brass, eliminating any error due to the markers diffusing themselves. Diffusion was allowed to take place at 785°C over the course of 56 days, with cross-sections being taken at six times throughout the span of the experiment. Over time, it was observed that the wire markers moved closer together as the zinc diffused out of the brass and into the copper. A difference in location of the interface was visible in cross sections of different times. Compositional change of the material from diffusion was confirmed by x-ray diffraction.
Diffusion mechanism.
Early diffusion models postulated that atomic motion in substitutional alloys occurs via a direct exchange mechanism, in which atoms migrate by switching positions with atoms on adjacent lattice sites. Such a mechanism implies that the atomic fluxes of two different materials across an interface must be equal, as each atom moving across the interface causes another atom to move across in the other direction.
Another possible diffusion mechanism involves lattice vacancies. An atom can move into a vacant lattice site, effectively causing the atom and the vacancy to switch places. If large-scale diffusion takes place in a material, there will be a flux of atoms in one direction and a flux of vacancies in the other.
The Kirkendall effect arises when two distinct materials are placed next to each other and diffusion is allowed to take place between them. In general, the diffusion coefficients of the two materials in each other are not the same. This is only possible if diffusion occurs by a vacancy mechanism; with an exchange mechanism, atoms will cross the interface in pairs, so the diffusion rates will be identical. The material with the higher diffusion coefficient will have a larger associated vacancy flux into it, so the net movement of vacancies will be from the material with the lower diffusion coefficient into the material with the higher diffusion coefficient.
Macroscopic evidence for the Kirkendall effect can be gathered by placing inert markers at the initial interface between the two materials, such as molybdenum markers at an interface between copper and brass. The diffusion coefficient of zinc is higher than the diffusion coefficient of copper in this case. Since zinc atoms leave the brass at a higher rate than copper atoms enter, the size of the brass region decreases as diffusion progresses. Relative to the molybdenum markers, the copper-brass interface moves toward the brass at an experimentally measurable rate.
Darken's equations.
Shortly after the publication of Kirkendall’s paper, L.S. Darken published an analysis of diffusion in binary systems much like the one studied by Smigelskas and Kirkendall. By separating the actual diffusive flux of the materials from the movement of the interface relative to the markers, Darken found the marker velocity formula_1 to be 
formula_2
where formula_3 and formula_4 are the diffusion coefficients of the two materials and formula_5 is an atomic fraction.
One consequence of this equation is that the movement of an interface varies linearly with the square root of time, which is exactly the experimental relationship discovered by Smigelskas and Kirkendall.
Darken also developed a second equation that defines a combined chemical diffusion coefficient formula_6 in terms of the diffusion coefficients of the two interfacing materials:
formula_7
This chemical diffusion coefficient can be used to mathematically analyze Kirkendall effect diffusion via the Boltzmann-Matano method.
Kirkendall porosity.
One important consideration deriving from Kirkendall’s work is the presence of pores formed during diffusion. These voids act as sinks for vacancies, and when enough accumulate they can become substantial and expand in an attempt to restore equilibrium. Porosity occurs due to the difference in diffusion rate of the two species.
Pores in metals have ramifications for mechanical, thermal, and electrical properties, and thus control over their formation is often desired. The equation 
formula_8
where formula_9 is the distance moved by a marker, formula_10 is a coefficient determined by intrinsic diffusivities of the materials, and formula_11 is a concentration difference between components, has proven to be an effective model for mitigating Kirkendall porosity. Controlling annealing temperature is another method of reducing or eliminating porosity. Kirkendall porosity typically occurs at a set temperature in a system, so annealing can be performed at lower temperatures for longer times to avoid formation of pores.
Nanotechnology applications.
The Catalan Institute of Nanotechnology in Bellaterra, Spain has developed a chemical process creating hollows in nano-particles and forming double-walled boxes and multi-chambered tubes. The results of the study have appeared in the journal Science.
Minute silver cubes were treated with cationic gold which at room temperatures led to a loss of electrons from the silver atoms which were taken up by an electrolytic solution. The gaining of electrons transformed the cationic gold into metallic gold which then attached to the surface of the silver cube. This covering protects the underlying silver, confining the reaction to the uncoated parts. Finally, there remains only a single hole on the surface through which the reaction enters the cube. A secondary effect then takes place when silver atoms from inside the cube begin to migrate through the hole to the gold on the surface, creating a void inside the cube.
The process will have a wide range of applications. Small changes in the chemical environment will allow control of reaction and diffusion at room temperatures, permitting manufacture of diverse polymetallic hollow nanoparticles through galvanic replacement and the Kirkendall effect.

</doc>
<doc id="42454" url="http://en.wikipedia.org/wiki?curid=42454" title="1063">
1063

Year 1063 (MLXIII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42455" url="http://en.wikipedia.org/wiki?curid=42455" title="1064">
1064

Year 1064 (MLXIV) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By area.
Europe.
</onlyinclude>

</doc>
<doc id="42456" url="http://en.wikipedia.org/wiki?curid=42456" title="1065">
1065

Year 1065 (MLXV) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42457" url="http://en.wikipedia.org/wiki?curid=42457" title="1067">
1067

Year 1067 (MLXVII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42458" url="http://en.wikipedia.org/wiki?curid=42458" title="1069">
1069

Year 1069 (MLXIX) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>* Harrying of the North: King William of England (William the Conqueror) reacts to rebellions made by his Anglo-Saxon subjects against him. He rides through the north of England with his army and burns houses, crops, cattle and land from York to Durham, which results in the deaths of over 100,000 people, mainly from starvation and winter cold.

</doc>
<doc id="42459" url="http://en.wikipedia.org/wiki?curid=42459" title="1074">
1074

Year 1074 (MLXXIV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42460" url="http://en.wikipedia.org/wiki?curid=42460" title="1075">
1075

Year 1075 (MLXXV) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42461" url="http://en.wikipedia.org/wiki?curid=42461" title="1076">
1076

Year 1076 (MLXXVI) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42462" url="http://en.wikipedia.org/wiki?curid=42462" title="1077">
1077

Year 1077 (MLXXVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42463" url="http://en.wikipedia.org/wiki?curid=42463" title="1081">
1081

Year 1081 (MLXXXI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42464" url="http://en.wikipedia.org/wiki?curid=42464" title="1082">
1082

Year 1082 (MLXXXII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42465" url="http://en.wikipedia.org/wiki?curid=42465" title="1083">
1083

Year 1083 (MLXXXIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Africa.
</onlyinclude>

</doc>
<doc id="42466" url="http://en.wikipedia.org/wiki?curid=42466" title="1085">
1085

Year 1085 (MLXXXV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42467" url="http://en.wikipedia.org/wiki?curid=42467" title="1089">
1089

Year 1089 (MLXXXIX) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42468" url="http://en.wikipedia.org/wiki?curid=42468" title="1090">
1090

Year 1090 (MXC) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Technology.
</onlyinclude>

</doc>
<doc id="42469" url="http://en.wikipedia.org/wiki?curid=42469" title="1091">
1091

Year 1091 (MXCI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>
Deaths.
Robert D'Oyly, first Lord of Oxford Castle

</doc>
<doc id="42470" url="http://en.wikipedia.org/wiki?curid=42470" title="1092">
1092

Year 1092 (MXCII) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42471" url="http://en.wikipedia.org/wiki?curid=42471" title="1094">
1094

Year 1094 (MXCIV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42472" url="http://en.wikipedia.org/wiki?curid=42472" title="1102">
1102

Year 1102 (MCII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42473" url="http://en.wikipedia.org/wiki?curid=42473" title="1104">
1104

Year 1104 (MCIV) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42474" url="http://en.wikipedia.org/wiki?curid=42474" title="1105">
1105

Year 1105 (MCV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42475" url="http://en.wikipedia.org/wiki?curid=42475" title="1106">
1106

Year 1106 (MCVI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42476" url="http://en.wikipedia.org/wiki?curid=42476" title="1108">
1108

Year 1108 (MCVIII) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42477" url="http://en.wikipedia.org/wiki?curid=42477" title="1109">
1109

Year 1109 (MCIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Education.
</onlyinclude>

</doc>
<doc id="42478" url="http://en.wikipedia.org/wiki?curid=42478" title="The Rime of the Ancient Mariner">
The Rime of the Ancient Mariner

The Rime of the Ancient Mariner (originally The Rime of the Ancyent Marinere) is the longest major poem by the English poet Samuel Taylor Coleridge, written in 1797–98 and published in 1798 in the first edition of "Lyrical Ballads". Modern editions use a revised version printed in 1817 that featured a gloss. Along with other poems in "Lyrical Ballads", it was a signal shift to modern poetry and the beginning of British Romantic literature.
Plot summary.
"The Rime of the Ancient Mariner" relates the experiences of a sailor who has returned from a long sea voyage. The mariner stops a man who is on the way to a wedding ceremony and begins to narrate a story. The wedding-guest's reaction turns from bemusement to impatience to fear to fascination as the mariner's story progresses, as can be seen in the language style: Coleridge uses narrative techniques such as personification and repetition to create a sense of danger, the supernatural, or serenity, depending on the mood in different parts of the poem.
The mariner's tale begins with his ship departing on its journey. Despite initial good fortune, the ship is driven south by a storm and eventually reaches Antarctic waters. An albatross appears and leads them out of the ice jam where they are stuck, but even as the albatross is praised by the ship's crew, the mariner shoots the bird:
The crew is angry with the mariner, believing the albatross brought the south wind that led them out of the Antarctic. However, the sailors change their minds when the weather becomes warmer and the mist disappears:
However, they made a grave mistake in supporting this crime, as it arouses the wrath of spirits who then pursue the ship "from the land of mist and snow"; the south wind that had initially led them from the land of ice now sends the ship into uncharted waters near the equator, where it is becalmed.
The sailors change their minds again and blame the mariner for the torment of their thirst. In anger, the crew forces the mariner to wear the dead albatross about his neck, perhaps to illustrate the burden he must suffer from killing it, or perhaps as a sign of regret:
Eventually, the ship encounters a ghostly hulk. On board are Death (a skeleton) and the "Night-mare Life-in-Death",a deathly-pale woman, who are playing dice for the souls of the crew. With a roll of the dice, Death wins the lives of the crew members and Life-in-Death the life of the mariner, a prize she considers more valuable. Her name is a clue to the mariner's fate: he will endure a fate worse than death as punishment for his killing of the albatross.
One by one, all of the crew members die, but the mariner lives on, seeing for seven days and nights the curse in the eyes of the crew's corpses, whose last expressions remain upon their faces. Eventually, this stage of the mariner's curse is lifted after he appreciates the sea creatures swimming in the water. Despite his cursing them as "slimy things" earlier in the poem, he suddenly sees their true beauty and blesses them ("a spring of love gush'd from my heart, and I bless'd them unaware"); suddenly, as he manages to pray, the albatross falls from his neck and his guilt is partially expiated. The bodies of the crew, possessed by good spirits, rise again and help steer the ship. In a trance, the mariner hears two spirits discussing his voyage and penance, and learns that the ship is being powered preternaturally:
Eventually the mariner comes in sight of his homeland, but is initially uncertain as to whether or not he is hallucinating.
The rotten remains of the ship sink in a whirlpool, leaving only the mariner behind. A hermit on the mainland had seen the approaching ship and had come to meet it with a pilot and his boy, in a boat. When they pull him from the water, they think he is dead, but when he opens his mouth, the pilot has a fit. The hermit prays, and the mariner picks up the oars to row. The pilot's boy goes crazy and laughs, thinking the mariner is the devil, and cries, "The Devil knows how to row". As penance for shooting the albatross, the mariner, driven by guilt, is forced to wander the earth, telling his story over and over, and teaching a lesson to those he meets:
After relaying the story, the mariner leaves, and the wedding guest returns home, and wakes the next morning "a sadder and a wiser man".
Background.
The poem may have been inspired by James Cook's second voyage of exploration (1772–1775) of the South Seas and the Pacific Ocean; Coleridge's tutor, William Wales, was the astronomer on Cook's flagship and had a strong relationship with Cook. On this second voyage Cook crossed three times into the Antarctic Circle to determine whether the fabled great southern continent existed. Critics have also suggested that the poem may have been inspired by the voyage of Thomas James into the Arctic. "Some critics think that Coleridge drew upon James's account of hardship and lamentation in writing "The Rime of the Ancient Mariner"."
According to William Wordsworth, the poem was inspired while Coleridge, Wordsworth, and Wordsworth's sister Dorothy were on a walking tour through the Quantock Hills in Somerset in the spring of 1798. The discussion had turned to a book that Wordsworth was reading, "A Voyage Round The World by Way of the Great South Sea" (1726) by Captain George Shelvocke. In the book, a melancholy sailor, Simon Hatley, shoots a black albatross:
As they discussed Shelvocke's book, Wordsworth proffers the following developmental critique to Coleridge, which importantly contains a reference to tutelary spirits: "Suppose you represent him as having killed one of these birds on entering the south sea, and the tutelary spirits of these regions take upon them to avenge the crime." By the time the trio finished their walk, the poem had taken shape.
Bernard Martin argues in "The Ancient Mariner and the Authentic Narrative" that Coleridge was also influenced by the life of Anglican clergyman John Newton, who had a near-death experience aboard a slave ship.
The poem may also have been inspired by the legends of the Wandering Jew, who was forced to wander the earth until Judgement Day for taunting Jesus on the day of the Crucifixion, and of the Flying Dutchman.
The poem received mixed reviews from critics, and Coleridge was once told by the publisher that most of the book's sales were to sailors who thought it was a naval songbook. Coleridge made several modifications to the poem over the years. In the second edition of "Lyrical Ballads", published in 1800 (see 1800 in poetry), he replaced many of the archaic words.
Coleridge's comments.
In "Biographia Literaria", Coleridge wrote:
In "Table Talk", Coleridge wrote:
Wordsworth's comments.
Wordsworth wrote to Joseph Cottle in 1799:
However, when "Lyrical Ballads" was reprinted, Wordsworth included it despite Coleridge's objections, writing:
Early criticisms.
Upon its release, the poem was criticized for being obscure and difficult to read. The use of archaic spelling of words was seen as not in keeping with Wordsworth's claims of using common language. Criticism was renewed again in 1815–16, when Coleridge added marginal notes to the poem that were also written in an archaic style. These notes or glosses, placed next to the text of the poem, ostensibly interpret the verses much like marginal notes found in the Bible. There were many opinions on why Coleridge inserted the gloss. Charles Lamb, who had deeply admired the original for its attention to "Human Feeling", claimed that the gloss distanced the audience from the narrative, weakening the poem's effects. The entire poem was first published in the collection of "Lyrical Ballads". Another version of the poem was published in the 1817 collection entitled "Sibylline Leaves" (see 1817 in poetry).
Interpretations.
On a surface level the poem explores a violation of nature and the resulting psychological effects on the mariner and on all those who hear him. According to Jerome McGann the poem is like a salvation story. The poem's physical structure is multi-layered text based on Coleridge's interest in Higher Criticism. "Like the Iliad or Paradise Lost or any great historical product, the "Rime" is a work of transhistorical rather than so-called universal significance. This verbal distinction is important because it calls attention to a real one. Like The Divine Comedy or any other poem, the "Rime" is not valued or used always or everywhere or by everyone in the same way or for the same reasons".
George Whalley, in his 1946–47 essay, "The Mariner and the Albatross", suggests that the Ancient Mariner is an autobiographical portrait of Coleridge himself, comparing the mariner's loneliness with Coleridge's own feelings of loneliness expressed in his letters and journals.
In popular culture.
In addition to being referred to in several other notable works, due to the popularity of the poem the phrase "albatross around one's neck" has become an English language idiom referring to "A heavy burden of guilt that becomes an obstacle to success".

</doc>
<doc id="42479" url="http://en.wikipedia.org/wiki?curid=42479" title="1240">
1240

Year 1240 (MCCXL) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42481" url="http://en.wikipedia.org/wiki?curid=42481" title="1241">
1241

Year 1241 (MCCXLI) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42482" url="http://en.wikipedia.org/wiki?curid=42482" title="1242">
1242

Year 1242 (MCCXLII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42483" url="http://en.wikipedia.org/wiki?curid=42483" title="1243">
1243

Year 1243 (MCCXLIII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42484" url="http://en.wikipedia.org/wiki?curid=42484" title="1244">
1244

Year 1244 (MCCXLIV) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42485" url="http://en.wikipedia.org/wiki?curid=42485" title="1245">
1245

Year 1245 (MCCXLV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42486" url="http://en.wikipedia.org/wiki?curid=42486" title="1246">
1246

Year 1246 (MCCXLVI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42487" url="http://en.wikipedia.org/wiki?curid=42487" title="1247">
1247

Year 1247 (MCCXLVII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42488" url="http://en.wikipedia.org/wiki?curid=42488" title="1249">
1249

Year 1249 (MCCXLIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Science.
</onlyinclude>

</doc>
<doc id="42489" url="http://en.wikipedia.org/wiki?curid=42489" title="1253">
1253

Year 1253 (MCCLIII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="42490" url="http://en.wikipedia.org/wiki?curid=42490" title="1254">
1254

Year 1254 (MCCLIV) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Religion.
</onlyinclude>

</doc>
<doc id="42491" url="http://en.wikipedia.org/wiki?curid=42491" title="1255">
1255

Year 1255 (MCCLV) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Markets.
</onlyinclude>

</doc>
<doc id="42492" url="http://en.wikipedia.org/wiki?curid=42492" title="1257">
1257

Year 1257 (MCCLVII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42493" url="http://en.wikipedia.org/wiki?curid=42493" title="1258">
1258

Year 1258 (MCCLVIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42494" url="http://en.wikipedia.org/wiki?curid=42494" title="1259">
1259

Year 1259 (MCCLIX) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="42495" url="http://en.wikipedia.org/wiki?curid=42495" title="1260">
1260

Year 1260 (MCCLX) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42496" url="http://en.wikipedia.org/wiki?curid=42496" title="1261">
1261

Year 1261 (MCCLXI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42497" url="http://en.wikipedia.org/wiki?curid=42497" title="1262">
1262

Year 1262 (MCCLXII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42498" url="http://en.wikipedia.org/wiki?curid=42498" title="1263">
1263

Year 1263 (MCCLXIII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42499" url="http://en.wikipedia.org/wiki?curid=42499" title="1264">
1264

Year 1264 (MCCLXIV) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42500" url="http://en.wikipedia.org/wiki?curid=42500" title="1265">
1265

Year 1265 (MCCLXV) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Africa and Asia.
</onlyinclude>

</doc>
<doc id="42501" url="http://en.wikipedia.org/wiki?curid=42501" title="1266">
1266

Year 1266 (MCCLXVI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="42502" url="http://en.wikipedia.org/wiki?curid=42502" title="1267">
1267

Year 1267 (MCCLXVII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia and Africa.
</onlyinclude>

</doc>
<doc id="42503" url="http://en.wikipedia.org/wiki?curid=42503" title="1268">
1268

Year 1268 (MCCLXVIII) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="42504" url="http://en.wikipedia.org/wiki?curid=42504" title="1269">
1269

Year 1269 (MCCLXIX) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Science.
</onlyinclude>

</doc>
<doc id="42505" url="http://en.wikipedia.org/wiki?curid=42505" title="1278">
1278

Year 1278 (MCCLXXVIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42506" url="http://en.wikipedia.org/wiki?curid=42506" title="1279">
1279

Year 1279 A.D (MCCLXXIX) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42507" url="http://en.wikipedia.org/wiki?curid=42507" title="In the Bedroom">
In the Bedroom

 
In the Bedroom is a 2001 American crime drama film directed by Todd Field, and dedicated to Andre Dubus, whose short story "Killings" is the source material on which the screenplay, by Field and Robert Festinger, is based. The film stars Sissy Spacek, Tom Wilkinson, Nick Stahl, Marisa Tomei, and William Mapother.
The title refers to the rear compartment of a lobster trap known as the "bedroom" and the fact that it can only hold up to two lobsters before they begin to turn on each other.
Plot.
The film is set in the Mid-Coast town of Camden, Maine. Ruth Fowler (Sissy Spacek) and Matt Fowler (Tom Wilkinson) enjoy a happy marriage and a good relationship with their son Frank (Nick Stahl), a recent college graduate who has come home for the summer. Frank has fallen in love with an older woman with children, Natalie Strout (Marisa Tomei). Frank is also applying to graduate school for architecture, but is considering staying in town to work in the fishing industry and be near to Natalie. Natalie's ex-husband, Richard Strout (William Mapother), whose family owns a local fish-processing and delivery business, is violent and abusive. Richard tries to find a way into his ex-wife and son's lives, going to increasingly violent lengths to get his intentions across to Natalie. Ruth is openly concerned about Frank's relationship with Natalie, while Matt sees past his wife's worries.
Midway through the film, Richard kills Frank during a confrontation at Natalie's house following a domestic dispute. Though equally devastated, Matt and Ruth grieve in different ways, with Matt putting on a brave face while Ruth becomes reclusive and quiet. Richard is set free on bail, paid by his well-to-do family, and both Matt and Ruth are forced to see Richard around town. The tension between the pair increases when they learn that the lack of a witness to their son's shooting allows the killer to avoid murder charges, since the district attorney may have difficulty proving that Richard killed Frank intentionally, as opposed to accidental manslaughter during a struggle, which defense attorney Marla Keyes (Karen Allen) argues. The silence between the couple erupts in an argument where each is confronted with the truth about each parent's relationship with their son: Ruth was overbearing, and Matt let him get away with everything. With the strain between them broken, the couple is finally able to find common ground in their grief.
Matt then abducts and kills Richard. He and a friend bury the body on the friend's wooded property. Matt returns home to Ruth, who is awake and smoking in bed. She asks him, "Did you do it?" Matt appears troubled and unresponsive. He climbs into bed and then turns away from her. Finally, Ruth gets up to make coffee. Matt rolls over onto his back and pulls a band-aid from a finger he injured hauling traps. Ruth calls from the kitchen, "Matt, do you want coffee?" Matt doesn't answer.
Critical reception.
Upon its release, the film received positive responses for its direction, script, and performances (notably Wilkinson and Spacek), garnering a 93% certified fresh rating on Rotten Tomatoes based on 137 reviews with an average score of 7.9/10. The site's consensus states "Expertly crafted and performed, In the Bedroom is a quietly wrenching portrayal of grief."
David Edelstein of "Slate Magazine" wrote on his review that it is the "best movie of the last several years" and described it "the most evocative, the most mysterious, the most inconsolably devastating" film. He further mentioned that the effect of the film "isn't over when you leave the theater" and that it's "always going to be there". He also called "In the Bedroom" a "masterpiece".
Neil Norman of "The Evening Standard" stated that "...Field has not only studied the masters of cinematic understatement, such as Ozu and Bergman, but that he fully understands their processes... Field's achievement is such a perfectly consummated marriage of intent and execution that he need never make another movie. I would not be alone, I think, in hoping he will make many more."
William Arnold of the "Seattle Post-Intelligencer" compared Field's direction to Kubrick saying that it "manages to feel both highly controlled and effortlessly spontaneous at the same time; and his lifting of the facade of this picturesque, Norman Rockwell setting is carried out with surgical precision". He further mentioned that "like Kubrick, Field doesn't make any moral judgments about his characters, and his film remains stubbornly enigmatic. It can be read as a high-class revenge thriller, an ode to the futility of vengeance or almost anything in between."
Roger Ebert of the "Chicago Sun-Times" stated on his review that it is "one of the best-directed films of the year" and that "every performance has a perfect tone". He listed "In the Bedroom" as his third best film of the year 2001.
"Rolling Stones"' Peter Travers called the film "an uncommonly good movie" that "will hit you hard." He also mentioned that the "Oscar would be a fool" if they ignore Sissy Spacek and Tom Wilkinson's "career-crowning performances".
A. O. Scott included the film in his "New York Times" essay ""The most important films of the past decade — and why they mattered"."
Among the negative reviews of the film include Paul Tatara of the "CNN" mentioning that the film "flounders" despite the good performances. Stephen Hunter of "The Washington Post" said "it opens brilliantly" but goes on to "self-negating absurdity."
Sundance.
"In the Bedroom" was the first official Sundance Film Festival film to get an Academy Award nomination for Best Picture including three more nominations for acting and an adapted screenplay nomination. It nabbed the most nominations than any Sundance film until 2009's "Precious".
Box office.
With the exception of "Napoleon Dynamite", "In the Bedroom" had the largest box office of any film premiering at the Sundance Film Festival in the last decade. The film grossed a worldwide total of $43,368,779. It went on to become, at-the-time, the highest-grossing non-IMAX film in history to never reach the top 10 in a given week.
Film archives.
A 35mm safety print is housed in the permanent collection of the UCLA Film & Television Archive.

</doc>
<doc id="42508" url="http://en.wikipedia.org/wiki?curid=42508" title="1280">
1280

Year 1280 (MCCLXXX) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="42509" url="http://en.wikipedia.org/wiki?curid=42509" title="1281">
1281

Year 1281 (MCCLXXXI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42510" url="http://en.wikipedia.org/wiki?curid=42510" title="1283">
1283

Year 1283 (MCCLXXXIII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42511" url="http://en.wikipedia.org/wiki?curid=42511" title="1285">
1285

Year 1285 (MCCLXXXV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42512" url="http://en.wikipedia.org/wiki?curid=42512" title="1287">
1287

Year 1287 (MCCLXXXVII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42513" url="http://en.wikipedia.org/wiki?curid=42513" title="1288">
1288

Year 1288 (MCCLXXXVIII) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Technology.
</onlyinclude>

</doc>
<doc id="42514" url="http://en.wikipedia.org/wiki?curid=42514" title="1289">
1289

Year 1289 (MCCLXXXIX) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Markets.
Religion.
</onlyinclude>

</doc>
<doc id="42515" url="http://en.wikipedia.org/wiki?curid=42515" title="Infinite monkey theorem">
Infinite monkey theorem

The infinite monkey theorem states that a monkey hitting keys at random on a typewriter keyboard for an infinite amount of time will almost surely type a given text, such as the complete works of William Shakespeare.
In this context, "almost surely" is a mathematical term with a precise meaning, and the "monkey" is not an actual monkey, but a metaphor for an abstract device that produces an endless random sequence of letters and symbols. One of the earliest instances of the use of the "monkey metaphor" is that of French mathematician Émile Borel in 1913, but the earliest instance may be even earlier. The relevance of the theorem is questionable—the probability of a universe full of monkeys typing a complete work such as Shakespeare's "Hamlet" is so tiny that the chance of it occurring during a period of time hundreds of thousands of orders of magnitude longer than the age of the universe is "extremely" low (but technically not zero).
Variants of the theorem include multiple and even infinitely many typists, and the target text varies between an entire library and a single sentence. The history of these statements can be traced back to Aristotle's "On Generation and Corruption" and Cicero's "De natura deorum" (On the Nature of the Gods), through Blaise Pascal and Jonathan Swift, and finally to modern statements with their iconic simians and typewriters. In the early 20th century, Émile Borel and Arthur Eddington used the theorem to illustrate the timescales implicit in the foundations of statistical mechanics.
Solution.
Direct proof.
There is a straightforward proof of this theorem. As an introduction, recall that if two events are statistically independent, then the probability of both happening equals the product of the probabilities of each one happening independently. For example, if the chance of rain in Moscow on a particular day in the future is 0.4 and the chance of an earthquake in San Francisco on that same day is 0.00003, then the chance of both happening on that day is 0.4 × 0.00003 = 0.000012, assuming that they are indeed independent.
Suppose the typewriter has 50 keys, and the word to be typed is "banana". If the keys are pressed randomly and independently, it means that each key has an equal chance of being pressed. Then, the chance that the first letter typed is 'b' is 1/50, and the chance that the second letter typed is "a" is also 1/50, and so on. Therefore, the chance of the first six letters spelling "banana" is
less than one in 15 billion, but not zero, hence a possible outcome.
From the above, the chance of "not" typing "banana" in a given block of 6 letters is 1 − (1/50)6. Because each block is typed independently, the chance "X""n" of not typing "banana" in any of the first "n" blocks of 6 letters is
As "n" grows, "X""n" gets smaller. For an "n" of a million, "X""n" is roughly 0.9999, but for an "n" of 10 billion "X""n" is roughly 0.53 and for an "n" of 100 billion it is roughly 0.0017. As "n" approaches infinity, the probability "X""n" approaches zero; that is, by making "n" large enough, "X""n" can be made as small as is desired, and the chance of typing "banana" approaches 100%.
The same argument shows why at least one of infinitely many monkeys will produce a text as quickly as it would be produced by a perfectly accurate human typist copying it from the original. In this case "X""n" = (1 − (1/50)6)"n" where "X""n" represents the probability that none of the first "n" monkeys types "banana" correctly on their first try. When we consider 100 billion monkeys, the probability falls to 0.17%, and as the number of monkeys "n" increases, the value of "X""n" – the probability of the monkeys failing to reproduce the given text – approaches zero arbitrarily closely. The limit, for "n" going to infinity, is zero.
Infinite strings.
This can be stated more generally and compactly in terms of strings, which are sequences of characters chosen from some finite alphabet:
Both follow easily from the second Borel–Cantelli lemma. For the second theorem, let "E""k" be the event that the "k"th string begins with the given text. Because this has some fixed nonzero probability "p" of occurring, the "E""k" are independent, and the below sum diverges,
the probability that infinitely many of the "E""k" occur is 1. The first theorem is shown similarly; one can divide the random string into nonoverlapping blocks matching the size of the desired text, and make "E""k" the event where the "k"th block equals the desired string.
Probabilities.
However, for physically meaningful numbers of monkeys typing for physically meaningful lengths of time the results are reversed. If there were as many monkeys as there are atoms in the observable universe typing extremely fast for trillions of times the life of the universe, the probability of the monkeys replicating even a "single page" of Shakespeare is unfathomably minute.
Ignoring punctuation, spacing, and capitalization, a monkey typing letters uniformly at random has a chance of one in 26 of correctly typing the first letter of "Hamlet." It has a chance of one in 676 (26 × 26) of typing the first two letters. Because the probability shrinks exponentially, at 20 letters it already has only a chance of one in 2620 = 19,928,148,895,209,409,152,340,197,376 (almost 2 × 1028). In the case of the entire text of "Hamlet", the probabilities are so vanishingly small as to be inconceivable. The text of Hamlet contains approximately 130,000 letters. Thus there is a probability of one in 3.4 × 10183,946 to get the text right at the first trial. The average number of letters that needs to be typed until the text appears is also 3.4 × 10183,946, or including punctuation, 4.4 × 10360,783.
Even if every proton in the observable universe were a monkey with a typewriter, typing from the Big Bang until the end of the universe (when protons no longer exist), they would still need a ridiculously longer time - more than three hundred and sixty thousand "orders of magnitude" longer - to have even a 1 in 10500 chance of success. To put it another way, for a one in a trillion chance of success, there would need to be 10360,641 universes made of atomic monkeys. As Kittel and Kroemer put it, "The probability of "Hamlet" is therefore zero in any operational sense of an event...", and the statement that the monkeys must eventually succeed "gives a misleading conclusion about very, very large numbers." This is from their textbook on thermodynamics, the field whose statistical foundations motivated the first known expositions of typing monkeys.
In fact there is less than a one in a trillion chance of success that such a universe made of monkeys could type any particular document a mere 79 characters long.
Almost surely.
The probability that an infinite randomly generated string of text will contain a particular finite substring is 1. However, this does not mean the substring's absence is "impossible", despite the absence having a prior probability of 0. For example, the immortal monkey "could" randomly type G as its first letter, G as its second, and G as every single letter thereafter, producing an infinite string of Gs; at no point must the monkey be "compelled" to type anything else. (To assume otherwise implies the gambler's fallacy.) However long a randomly generated finite string is, there is a small but nonzero chance that it will turn out to consist of the same character repeated throughout; this chance approaches zero as the string's length approaches infinity. There is nothing special about such a monotonous sequence except that it is easy to describe; the same fact applies to any nameable specific sequence, such as "RGRGRG" repeated forever, or "a-b-aa-bb-aaa-bbb-...", or "Three, Six, Nine, Twelve…".
If the hypothetical monkey has a typewriter with 90 equally likely keys that include numerals and punctuation, then the first typed keys might be "3.14" (the first three digits of pi) with a probability of (1/90)4, which is 1/65,610,000. Equally probable is any other string of four characters allowed by the typewriter, such as "GGGG", "mATh", or "q%8e". The probability that 100 randomly typed keys will consist of the first 99 digits of pi (including the separator key), or any other "particular" sequence of that length, is much lower: (1/90)100. If the monkey's allotted length of text is infinite, the chance of typing only the digits of pi is 0, which is just as "possible" as typing nothing but Gs (also probability 0).
The same applies to the event of typing a particular version of "Hamlet" followed by endless copies of itself; or "Hamlet" immediately followed by all the digits of pi; these specific strings are equally infinite in length, they are not prohibited by the terms of the thought problem, and they each have a prior probability of 0. In fact, "any" particular infinite sequence the immortal monkey types will have "had" a prior probability of 0, even though the monkey must type something.
This is an extension of the principle that a finite string of random text has a lower and lower probability of "being" a particular string the longer it is (though all specific strings are equally unlikely). This probability approaches 0 as the string approaches infinity. Thus, the probability of the monkey typing an endlessly long string, such as all of the digits of pi in order, on a 90-key keyboard is (1/90)∞ which equals (1/∞) which is essentially 0. At the same time, the probability that the sequence "contains" a particular subsequence (such as the word MONKEY, or the 12th through 999th digits of pi, or a version of the King James Bible) increases as the total string increases. This probability approaches 1 as the total string approaches infinity, and thus the original theorem is correct.
Correspondence between strings and numbers.
In a simplification of the thought experiment, the monkey could have a typewriter with just two keys: 1 and 0. The infinitely long string thusly produced would correspond to the binary digits of a particular real number between 0 and 1. A countably infinite set of possible strings end in infinite repetitions, which means the corresponding real number is rational. Examples include the strings corresponding to one-third (010101…), five-sixths (11010101…) and five-eighths (1100000…). Only a subset of such real number strings (albeit a countably infinite subset) contains the entirety of "Hamlet" (if the text is translated from ASCII to binary).
Meanwhile, there is an "uncountably" infinite set of strings which do not end in such repetition; these correspond to the irrational numbers. These can be sorted into two uncountably infinite subsets: those which contain "Hamlet" and those which do not. However, the "largest" subset of all the real numbers are those which not only contain "Hamlet", but which contain every other possible string of any length, and with equal distribution of such strings. These irrational numbers are called normal. Because almost all numbers are normal, almost all possible strings contain all possible finite substrings. Hence, the probability of the monkey typing a normal number is 1. The same principles apply regardless of the number of keys from which the monkey can choose; a 90-key keyboard can be seen as a generator of numbers written in base 90.
History.
Statistical mechanics.
In one of the forms in which probabilists now know this theorem, with its "dactylographic" [i.e., typewriting] monkeys (French: "singes dactylographes"; the French word "singe" covers both the monkeys and the apes), appeared in Émile Borel's 1913 article "Mécanique Statistique et Irréversibilité" ("Statistical mechanics and irreversibility"), and in his book "Le Hasard" in 1914. His "monkeys" are not actual monkeys; rather, they are a metaphor for an imaginary way to produce a large, random sequence of letters. Borel said that if a million monkeys typed ten hours a day, it was extremely unlikely that their output would exactly equal all the books of the richest libraries of the world; and yet, in comparison, it was even more unlikely that the laws of statistical mechanics would ever be violated, even briefly.
The physicist Arthur Eddington drew on Borel's image further in "The Nature of the Physical World" (1928), writing:
If I let my fingers wander idly over the keys of a typewriter it might happen that my screed made an intelligible sentence. If an army of monkeys were strumming on typewriters they might write all the books in the British Museum. The chance of their doing so is decidedly more favourable than the chance of the molecules returning to one half of the vessel.
These images invite the reader to consider the incredible improbability of a large but finite number of monkeys working for a large but finite amount of time producing a significant work, and compare this with the even greater improbability of certain physical events. Any physical process that is even less likely than such monkeys' success is effectively impossible, and it may safely be said that such a process will never happen. It is clear from the context that Eddington is not suggesting that the probability of this happening is worthy of serious consideration. On the contrary, it was a rhetorical illustration of the fact that below certain levels of probability, the term "improbable" is functionally equivalent to "impossible".
Origins and "The Total Library".
In a 1939 essay entitled "The Total Library", Argentine writer Jorge Luis Borges traced the infinite-monkey concept back to Aristotle's "Metaphysics." Explaining the views of Leucippus, who held that the world arose through the random combination of atoms, Aristotle notes that the atoms themselves are homogeneous and their possible arrangements only differ in shape, position and ordering. In "On Generation and Corruption", the Greek philosopher compares this to the way that a tragedy and a comedy consist of the same "atoms", "i.e.", alphabetic characters. Three centuries later, Cicero's "De natura deorum" ("On the Nature of the Gods") argued against the atomist worldview:
He who believes this may as well believe that if a great quantity of the one-and-twenty letters, composed either of gold or any other matter, were thrown upon the ground, they would fall into such order as legibly to form the "Annals" of Ennius. I doubt whether fortune could make a single verse of them.
Borges follows the history of this argument through Blaise Pascal and Jonathan Swift, then observes that in his own time, the vocabulary had changed. By 1939, the idiom was "that a half-dozen monkeys provided with typewriters would, in a few eternities, produce all the books in the British Museum." (To which Borges adds, "Strictly speaking, one immortal monkey would suffice.") Borges then imagines the contents of the Total Library which this enterprise would produce if carried to its fullest extreme:
Everything would be in its blind volumes. Everything: the detailed history of the future, Aeschylus' "The Egyptians", the exact number of times that the waters of the Ganges have reflected the flight of a falcon, the secret and true nature of Rome, the encyclopedia Novalis would have constructed, my dreams and half-dreams at dawn on August 14, 1934, the proof of Pierre Fermat's theorem, the unwritten chapters of "Edwin Drood", those same chapters translated into the language spoken by the Garamantes, the paradoxes Berkeley invented concerning Time but didn't publish, Urizen's books of iron, the premature epiphanies of Stephen Dedalus, which would be meaningless before a cycle of a thousand years, the Gnostic Gospel of Basilides, the song the sirens sang, the complete catalog of the Library, the proof of the inaccuracy of that catalog. Everything: but for every sensible line or accurate fact there would be millions of meaningless cacophonies, verbal farragoes, and babblings. Everything: but all the generations of mankind could pass before the dizzying shelves—shelves that obliterate the day and on which chaos lies—ever reward them with a tolerable page.
Borges' total library concept was the main theme of his widely read 1941 short story "The Library of Babel", which describes an unimaginably vast library consisting of interlocking hexagonal chambers, together containing every possible volume that could be composed from the letters of the alphabet and some punctuation characters.
Real monkeys.
In 2003, lecturers and students from the University of Plymouth MediaLab Arts course used a £2,000 grant from the Arts Council to study the literary output of real monkeys. They left a computer keyboard in the enclosure of six Celebes Crested Macaques in Paignton Zoo in Devon in England for a month, with a radio link to broadcast the results on a website.
Not only did the monkeys produce nothing but five total pages largely consisting of the letter S, the lead male began by bashing the keyboard with a stone, and the monkeys continued by urinating and defecating on it. Mike Phillips, director of the university's Institute of Digital Arts and Technology (i-DAT), said that the artist-funded project was primarily performance art, and they had learned "an awful lot" from it. He concluded that monkeys "are not random generators. They're more complex than that. ... They were quite interested in the screen, and they saw that when they typed a letter, something happened. There was a level of intention there."
Applications and criticisms.
Evolution.
In his 1931 book "The Mysterious Universe", Eddington's rival James Jeans attributed the monkey parable to a "Huxley", presumably meaning Thomas Henry Huxley. This attribution is incorrect. Today, it is sometimes further reported that Huxley applied the example in a now-legendary debate over Charles Darwin's "On the Origin of Species" with the Anglican Bishop of Oxford, Samuel Wilberforce, held at a meeting of the British Association for the Advancement of Science at Oxford on June 30, 1860. This story suffers not only from a lack of evidence, but the fact that in 1860 the typewriter itself had yet to emerge.
Despite the original mix-up, monkey-and-typewriter arguments are now common in arguments over evolution. For example, Doug Powell argues as a Christian apologist that even if a monkey accidentally types the letters of "Hamlet", it has failed to produce "Hamlet" because it lacked the intention to communicate. His parallel implication is that natural laws could not produce the information content in DNA. A more common argument is represented by Reverend John F. MacArthur, who claims that the genetic mutations necessary to produce a tapeworm from an amoeba are as unlikely as a monkey typing Hamlet's soliloquy, and hence the odds against the evolution of all life are impossible to overcome.
Evolutionary biologist Richard Dawkins employs the typing monkey concept in his book "The Blind Watchmaker" to demonstrate the ability of natural selection to produce biological complexity out of random mutations. In a simulation experiment Dawkins has his weasel program produce the Hamlet phrase "METHINKS IT IS LIKE A WEASEL", starting from a randomly typed parent, by "breeding" subsequent generations and always choosing the closest match from progeny that are copies of the parent, with random mutations. The chance of the target phrase appearing in a single step is extremely small, yet Dawkins showed that it could be produced rapidly (in about 40 generations) using cumulative selection of phrases. The random choices furnish raw material, while cumulative selection imparts information. As Dawkins acknowledges, however, the weasel program is an imperfect analogy for evolution, as "offspring" phrases were selected "according to the criterion of resemblance to a "distant ideal" target." In contrast, Dawkins affirms, evolution has no long-term plans and does not progress toward some distant goal (such as humans). The weasel program is instead meant to illustrate the difference between non-random cumulative selection, and random single-step selection. In terms of the typing monkey analogy, this means that "Romeo and Juliet" could be produced relatively quickly if placed under the constraints of a nonrandom, Darwinian-type selection because the fitness function will tend to preserve in place any letters that happen to match the target text, improving each successive generation of typing monkeys.
A different avenue for exploring the analogy between evolution and an unconstrained monkey lies in the problem that the monkey types only one letter at a time, independently of the other letters. Hugh Petrie argues that a more sophisticated setup is required, in his case not for biological evolution but the evolution of ideas:
In order to get the proper analogy, we would have to equip the monkey with a more complex typewriter. It would have to include whole Elizabethan sentences and thoughts. It would have to include Elizabethan beliefs about human action patterns and the causes, Elizabethan morality and science, and linguistic patterns for expressing these. It would probably even have to include an account of the sorts of experiences which shaped Shakespeare's belief structure as a particular example of an Elizabethan. Then, perhaps, we might allow the monkey to play with such a typewriter and produce variants, but the impossibility of obtaining a Shakespearean play is no longer obvious. What is varied really does encapsulate a great deal of already-achieved knowledge.
James W. Valentine, while admitting that the classic monkey's task is impossible, finds that there is a worthwhile analogy between written English and the metazoan genome in this other sense: both have "combinatorial, hierarchical structures" that greatly constrain the immense number of combinations at the alphabet level.
Literary theory.
R. G. Collingwood argued in 1938 that art cannot be produced by accident, and wrote as a sarcastic aside to his critics,
...some ... have denied this proposition, pointing out that if a monkey played with a typewriter ... he would produce ... the complete text of Shakespeare. Any reader who has nothing to do can amuse himself by calculating how long it would take for the probability to be worth betting on. But the interest of the suggestion lies in the revelation of the mental state of a person who can identify the 'works' of Shakespeare with the series of letters printed on the pages of a book...
Nelson Goodman took the contrary position, illustrating his point along with Catherine Elgin by the example of Borges' "Pierre Menard, Author of the Quixote",
What Menard wrote is simply another inscription of the text. Any of us can do the same, as can printing presses and photocopiers. Indeed, we are told, if infinitely many monkeys ... one would eventually produce a replica of the text. That replica, we maintain, would be as much an instance of the work, "Don Quixote", as Cervantes' manuscript, Menard's manuscript, and each copy of the book that ever has been or will be printed.
In another writing, Goodman elaborates, "That the monkey may be supposed to have produced his copy randomly makes no difference. It is the same text, and it is open to all the same interpretations..." Gérard Genette dismisses Goodman's argument as begging the question.
For Jorge J. E. Gracia, the question of the identity of texts leads to a different question, that of author. If a monkey is capable of typing "Hamlet", despite having no intention of meaning and therefore disqualifying itself as an author, then it appears that texts do not require authors. Possible solutions include saying that whoever finds the text and identifies it as "Hamlet" is the author; or that Shakespeare is the author, the monkey his agent, and the finder merely a user of the text. These solutions have their own difficulties, in that the text appears to have a meaning separate from the other agents: what if the monkey operates before Shakespeare is born, or if Shakespeare is never born, or if no one ever finds the monkey's typescript?
Random document generation.
The theorem concerns a thought experiment which cannot be fully carried out in practice, since it is predicted to require prohibitive amounts of time and resources. Nonetheless, it has inspired efforts in finite random text generation.
One computer program run by Dan Oliver of Scottsdale, Arizona, according to an article in "The New Yorker", came up with a result on August 4, 2004: After the group had worked for 42,162,500,000 billion billion monkey-years, one of the "monkeys" typed, "VALENTINE. Cease toIdor:eFLP0FRjWK78aXzVOwm)-‘;8.t" The first 19 letters of this sequence can be found in "The Two Gentlemen of Verona". Other teams have reproduced 18 characters from "Timon of Athens", 17 from "Troilus and Cressida", and 16 from "Richard II".
A website entitled "The Monkey Shakespeare Simulator", launched on July 1, 2003, contained a Java applet that simulates a large population of monkeys typing randomly, with the stated intention of seeing how long it takes the virtual monkeys to produce a complete Shakespearean play from beginning to end. For example, it produced this partial line from "Henry IV, Part 2", reporting that it took "2,737,850 million billion billion billion monkey-years" to reach 24 matching characters:
Due to processing power limitations, the program uses a probabilistic model (by using a random number generator or RNG) instead of actually generating random text and comparing it to Shakespeare. When the simulator "detects a match" (that is, the RNG generates a certain value or a value within a certain range), the simulator simulates the match by generating matched text.
More sophisticated methods are used in practice for natural language generation. If instead of simply generating random characters one restricts the generator to a meaningful vocabulary and conservatively following grammar rules, like using a context-free grammar, then a random document generated this way can even fool some humans (at least on a cursory reading) as shown in the experiments with SCIgen, snarXiv, and the Postmodernism Generator.
Testing of random number generators.
Questions about the statistics describing how often an ideal monkey is expected to type certain strings translate into practical tests for random number generators; these range from the simple to the "quite sophisticated". Computer science professors George Marsaglia and Arif Zaman report that they used to call one such category of tests "overlapping m-tuple tests" in lecture, since they concern overlapping m-tuples of successive elements in a random sequence. But they found that calling them "monkey tests" helped to motivate the idea with students. They published a report on the class of tests and their results for various RNGs in 1993.
Popular culture.
The infinite monkey theorem and its associated imagery is considered a popular and proverbial illustration of the mathematics of probability, widely known to the general public because of its transmission through popular culture rather than through formal education.
In his 1978 radio play, "The Hitchhiker's Guide to the Galaxy", Douglas Adams invoked the theorem to illustrate the power of the ‘Infinite Improbability Drive’ that powered a spaceship. From Episode 2: "Ford, there’s an infinite number of monkeys outside who want to talk to us about this script for Hamlet they’ve worked out."
A quotation attributed to a 1996 speech by Robert Wilensky stated, "We’ve heard that a million monkeys at a million keyboards could produce the complete works of Shakespeare; now, thanks to the Internet, we know that is not true."
The enduring, widespread popularity of the theorem was noted in the introduction to a 2001 paper, "Monkeys, Typewriters and Networks: The Internet in the Light of the Theory of Accidental Excellence" (Hoffmann & Hofmann, 2001). In 2002, an article in "The Washington Post" said, "Plenty of people have had fun with the famous notion that an infinite number of monkeys with an infinite number of typewriters and an infinite amount of time could eventually write the works of Shakespeare."
 In 2003, the previously mentioned Arts Council funded experiment involving real monkeys and a computer keyboard received widespread press coverage. In 2007, the theorem was listed by "Wired" magazine in a list of eight classic thought experiments.
During one episode of "The Ricky Gervais Show", Karl Pilkington successfully "disproved" the Infinite Monkey theorem by reasoning that you can't have an infinite number of monkeys because there isn't an infinite amount of bananas to feed them. He then doubled down by using the acumen that there isn't a big enough wilderness area available to house the monkeys when they had finished their shifts.

</doc>
<doc id="42518" url="http://en.wikipedia.org/wiki?curid=42518" title="Rollo">
Rollo

Rollo ( 846 – c. 932), also known as Hrolf the Ganger, baptised Robert and so sometimes numbered Robert I to distinguish him from his descendants, was a Norse Viking who was founder and first ruler of the Viking principality which soon became known as Normandy. His descendants were the Dukes of Normandy, and following the Norman conquest of England in 1066, kings of England.
Name.
The name "Rollo" is a Latin translation from the Old Norse name Hrólfr, modern Icelandic name Hrólfur and Scandinavian name Rolf (cf. the latinization of Hrólfr into the similar "Roluo" in the "Gesta Danorum"), but Norman people called him by his popular name "Rou(f)" (see Wace's "Roman de Rou"). Sometimes his name is turned into the Frankish name "Rodolf(us)" or "Radulf(us)" or the French "Raoul", that are derived from it.
Historical evidence.
Started in the late 9th century, the Anglo-Saxon Chronicle is the earliest record of Rollo. However, it does not mention his origins.
Rollo was a powerful Viking leader of contested origin. Dudo of Saint-Quentin, in his "De moribus et actis primorum Normannorum ducum",
tells of a powerful Danish nobleman at loggerheads with the king of Denmark, who had two sons, Gurim and Rollo; upon his death, Rollo was expelled and Gurim killed. Dudo's chronicle, commissioned for Richard I, was finished, sometime after 1015, for Richard II, whose sister, Emma, married the Danish King Cnut, in 1017. William of Jumièges also mentions Rollo's prehistory in his continuation of Dudo's work, "Gesta Normannorum Ducum", but states that he came from the Danish town of Fakse.
Norwegian and Icelandic historians, basing their research on medieval Norwegian and Icelandic sagas, identified Rollo instead with Ganger Hrolf (Hrolf, the Walker), a son of Rognvald Eysteinsson (fl. 865), Earl of Møre in Western Norway. The Latin "Historia Norvegiae", written in Norway at the end of the 12th century, offers the oldest source of this version. This Hrolf fell foul of the Norwegian king Harald Fairhair (c. 850 – c. 932, reigned c. 872 – 930), and became a Jarl in Normandy. The nickname "the Walker", "Ganger" in Norse, came from being so big that no horse could carry him.
Geoffrey of Malaterra, in his "The Deeds of Count Roger of Calabria & Sicily & of Duke Robert Guiscard his brother" claims Rollo "sailed boldly from Norway".
The question of Rollo's origins became a matter of heated dispute between Norwegian and Danish historians of the 19th and early 20th centuries, particularly in the run-up to Normandy's millennium anniversary in 1911. Today, the debate continues.
Claimed Yngling lineage leading to Rollo.
The Yngling "Fairhair dynasty" lineage introduced in "Hversu Noregr byggðist" ("How Norway was settled") and the Orkneyinga and Heimskringla sagas suggests a line of Rollo going back to Fornjót, the primeval "king" who "reigned over" Finland and Kvenland. The claimed line leading to Rollo includes Rognvald Eysteinsson, the founder of the Earldom of Orkney.
Raids along the Seine.
In 885, Rollo was one of the lesser leaders of the Viking fleet which besieged Paris under Sigfred. Legend has it that an emissary was sent by the king to find the chieftain and negotiate terms. When he asked for this information, the Vikings replied that they were all chieftains in their own right. In 886, when Sigfred retreated in return for tribute, Rollo stayed behind and was eventually bought off and sent to harry Burgundy.
Later, he returned to the Seine with his followers (known as Danes, or Norsemen). He invaded the area of northern France now known as Normandy. In 911 the Vikings under Rollo again launched an attack on Paris before laying siege to Chartres. The Bishop of Chartres, Joseaume, made an appeal for help which was answered by Robert, Marquis of Neustria, Richard, Duke of Burgundy and Manasses, Count of Dijon. On 20 July 911, at the Battle of Chartres, Frankish forces defeated Rollo despite the absence of many French barons and also the absence of the French King Charles the Simple.
The Principality of Normandy.
In the Treaty of Saint-Clair-sur-Epte (911) with King Charles, Rollo pledged feudal allegiance to the king, changed his name to the Frankish version, and converted to Christianity, probably with the baptismal name Robert. In return, King Charles granted Rollo land between the Epte and the sea as well as parts of Brittany and according to Dudo of St. Quentin, the hand of the King's daughter, Gisela, although this marriage and Gisela herself are unknown to Frankish sources. He was also the titular ruler of Normandy, centered around the city of Rouen. There exists some argument among historians as to whether Rollo was a "duke" ("dux") or whether his position was equivalent to that of a "count" under Charles.
According to legend, when required to kiss the foot of King Charles, as a condition of the treaty, he refused to perform so great a humiliation, and when Charles extended his foot to Rollo, Rollo ordered one of his warriors to do so in his place. His warrior then lifted Charles' foot up to his mouth causing the king to fall to the ground.
After 911, Rollo stayed true to his word of defending the shores of the Seine river in accordance to the Treaty of Saint-Clair-sur-Epte. However, he also continued attacks on Flanders.
After Charles was deposed by Robert I in 922, Rollo considered his oath to the King of France at an end. It started a period of expansion westwards. Negotiations with French barons ended with Rollo being given Le Mans and Bayeux and continued with the seizure of Bessin in 924. The following year the Normans attacked Picardy.
Rollo began to divide the land between the Epte and Risle rivers among his chieftains and settled there with a "de facto" capital in Rouen. Over time, Rollo's men intermarried with the local women, and became more settled into French Catholic culture as Normans.
Family.
Two spouses are reported for Rollo:
1. Poppa, said by chronicler Dudo of Saint-Quentin to have been a daughter of Count Berenger, captured during a raid at Bayeux. She was his concubine or wife, perhaps by "more danico". They had issue:
2. (traditionally) Gisela of France (d. 919), the daughter of Charles III of France
Death.
Sometime around 927, Rollo passed the fief in Normandy to his son, William Longsword. Rollo may have lived for a few years after that, but certainly died before 933. Even though Rollo had converted to Christianity, some of his prior religious roots surfaced at the end.
Legacy.
Rollo is the great-great-great-grandfather of William the Conqueror. Through William, he is an ancestor of the present-day British royal family, as well as an ancestor of all current European monarchs and a great many claimants to abolished European thrones. A genetic investigation into the remains of Rollo's grandson Richard I and great-grandson Richard II has been announced, with the intention of discerning the origins of the famous Viking warrior.
The "Clameur de Haro" in the Channel Islands is, supposedly, an appeal to Rollo.
Depictions in fiction.
Rollo is the subject of the seventeenth century play Rollo Duke of Normandy written by John Fletcher, Philip Massinger, Ben Jonson, and George Chapman.
A character, played by Clive Standen, based on the historical Rollo is Ragnar Lothbrok's brother in the History Channel television series "Vikings".

</doc>
<doc id="42520" url="http://en.wikipedia.org/wiki?curid=42520" title="255">
255

Year 255 (CCLV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Valerianus and Gallienus (or, less frequently, year 1008 "Ab urbe condita"). The denomination 255 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Science.
</onlyinclude>

</doc>
<doc id="42521" url="http://en.wikipedia.org/wiki?curid=42521" title="Hans Richter (artist)">
Hans Richter (artist)

Hans Richter (April 6, 1888 – February 1, 1976) was a German painter, graphic artist, avant-gardist, film-experimenter and producer. He was born in Berlin into a well-to-do family and died in Minusio, near Locarno, Switzerland.
Germany.
Richter's first contacts with modern art were in 1912 through the "Blaue Reiter" and in 1913 through the "Erster Deutscher Herbstsalon" gallery "Der Sturm", in Berlin. In 1914 he was influenced by cubism. He contributed to the periodical "Die Aktion" in Berlin. His first exhibition was in Munich in 1916, and "Die Aktion" published as a special edition about him. In the same year he was wounded and discharged from the army and went to Zürich and joined the Dada movement.
Richter believed that the artist's duty was to be actively political, opposing war and supporting the revolution. His first abstract works were made in 1917. In 1918, he befriended Viking Eggeling, and the two experimented together with film. Richter was co-founder, in 1919, of the Association of Revolutionary Artists ("Artistes Radicaux") at Zürich. In the same year he created his first "Prélude" (an orchestration of a theme developed in eleven drawings). In 1920 he was a member of the November group in Berlin and contributed to the Dutch periodical "De Stijl".
Throughout his career, he claimed that his 1921 film, "Rhythmus 21", was the first abstract film ever created. This claim is not true: he was preceded by the Italian Futurists Bruno Corra and Arnaldo Ginna between 1911 and 1912 (as they report in the "Futurist Manifesto of Cinema"), as well as by fellow German artist Walter Ruttmann who produced "Lichtspiel Opus 1" in 1920. Nevertheless, Richter's film "Rhythmus 21" is considered an important early abstract film.
About Richter's woodcuts and drawings Michel Seuphor wrote: "Richter's black-and-whites together with those of Arp and Janco, are the most typical works of the Zürich period of Dada." From 1923 to 1926, Richter edited, together with Werner Gräff and Mies van der Rohe, the periodical "G. Material zur elementaren Gestaltung." Richter wrote of his own attitude toward film:
USA.
Richter moved from Switzerland to the United States in 1940 and became an American citizen. He taught in the Institute of Film Techniques at the City College of New York.
While living in New York, Richter directed two feature films, "Dreams That Money Can Buy" (1947) and "" (1957) in collaboration with Max Ernst, Jean Cocteau, Paul Bowles, Fernand Léger, Alexander Calder, Marcel Duchamp, and others, which was partially filmed on the lawn of his summer house in Southbury, Connecticut.
In 1957, he finished a film entitled "Dadascope" with original poems and prose spoken by their creators: Hans Arp, Marcel Duchamp, Raoul Hausmann, Richard Huelsenbeck, and Kurt Schwitters.
After 1958, Richter spent parts of the year in Ascona and Connecticut and returned to painting.
Richter was also the author of a first-hand account of the Dada movement titled "Dada: Art and Anti-Art" which also included his reflections on the emerging Neo-Dada artworks.

</doc>
<doc id="42523" url="http://en.wikipedia.org/wiki?curid=42523" title="322">
322

Year 322 (CCCXXII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Probianus and Iulianus (or, less frequently, year 1075 "Ab urbe condita"). The denomination 322 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Technology.
</onlyinclude>

</doc>
<doc id="42524" url="http://en.wikipedia.org/wiki?curid=42524" title="323">
323

Year 323 (CCCXXIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Severus and Rufinus (or, less frequently, year 1076 "Ab urbe condita"). The denomination 323 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="42525" url="http://en.wikipedia.org/wiki?curid=42525" title="355">
355

Year 355 (CCCLV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Arbitio and Maesius (or, less frequently, year 1108 "Ab urbe condita"). The denomination 355 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="42526" url="http://en.wikipedia.org/wiki?curid=42526" title="Etching">
Etching

Etching is traditionally the process of using strong acid or mordant to cut into the unprotected parts of a metal surface to create a design in intaglio (relief) in the metal. In modern manufacturing, other chemicals may be used on other types of material. As a method of printmaking, it is, along with engraving, the most important technique for old master prints, and remains in wide use today.
Basic method.
In pure etching, a metal (usually copper, zinc or steel) plate is covered with a waxy ground which is resistant to acid. The artist then scratches off the ground with a pointed etching needle where he or she wants a line to appear in the finished piece, so exposing the bare metal. The échoppe, a tool with a slanted oval section, is also used for "swelling" lines. The plate is then dipped in a bath of acid, technically called the "mordant" (French for "biting") or "etchant", or has acid washed over it. The acid "bites" into the metal (it dissolves part of the metal) where it is exposed, leaving behind lines sunk into the plate. The remaining ground is then cleaned off the plate. The plate is inked all over, and then the ink wiped off the surface, leaving only the ink in the etched lines.
The plate is then put through a high-pressure printing press together with a sheet of paper (often moistened to soften it). The paper picks up the ink from the etched lines, making a print. The process can be repeated many times; typically several hundred impressions (copies) could be printed before the plate shows much sign of wear. The work on the plate can also be added to by repeating the whole process; this creates an etching which exists in more than one state.
Etching has often been combined with other intaglio techniques such as engraving (e.g., Rembrandt) or aquatint (e.g., Francisco Goya).
History.
Origin.
Etching by goldsmiths and other metal-workers in order to decorate metal items such as guns, armour, cups and plates has been known in Europe since the Middle Ages at least, and may go back to antiquity. The elaborate decoration of armour, in Germany at least, was an art probably imported from Italy around the end of the 15th century—little earlier than the birth of etching as a printmaking technique. 
The process as applied to printmaking is believed to have been invented by Daniel Hopfer (circa 1470–1536) of Augsburg, Germany. Hopfer was a craftsman who decorated armour in this way, and applied the method to printmaking, using iron plates (many of which still exist). Apart from his prints, there are two proven examples of his work on armour: a shield from 1536 now in the Real Armeria of Madrid and a sword in the Germanisches Nationalmuseum of Nuremberg. An Augsburg horse armour in the German Historical Museum, Berlin, dating to between 1512 and 1515, is decorated with motifs from Hopfer's etchings and woodcuts, but this is no evidence that Hopfer himself worked on it, as his decorative prints were largely produced as patterns for other craftsmen in various media. 
The switch to copper plates was probably made in Italy, and thereafter etching soon came to challenge engraving as the most popular medium for artists in printmaking. Its great advantage was that, unlike engraving which requires special skill in metalworking, etching is relatively easy to learn for an artist trained in drawing.
Prior to 1100 AD, the New World Hohokam independently utilized the technique of acid etching in marine shell designs.
Callot's innovations: échoppe, hard ground, stopping-out.
Jacques Callot (1592–1635) from Nancy in Lorraine (now part of France) made important technical advances in etching technique. He developed the échoppe, a type of etching-needle with a slanting oval section at the end, which enabled etchers to create a swelling line, as engravers were able to do.
Callot also appears to have been responsible for an improved, harder, recipe for the etching ground, using lute-makers' varnish rather than a wax-based formula. This enabled lines to be more deeply bitten, prolonging the life of the plate in printing, and also greatly reducing the risk of "foul-biting", where acid gets through the ground to the plate where it is not intended to, producing spots or blotches on the image. Previously the risk of foul-biting had always been at the back of an etcher's mind, preventing too much time on a single plate that risked being ruined in the biting process. Now etchers could do the highly detailed work that was previously the monopoly of engravers, and Callot made full use of the new possibilities.
Callot also made more extensive and sophisticated use of multiple "stoppings-out" than previous etchers had done. This is the technique of letting the acid bite lightly over the whole plate, then stopping-out those parts of the work which the artist wishes to keep light in tone by covering them with ground before bathing the plate in acid again. He achieved unprecedented subtlety in effects of distance and light and shade by careful control of this process. Most of his prints were relatively small—up to about six inches or 15 cm on their longest dimension, but packed with detail.
One of his followers, the Parisian Abraham Bosse, spread Callot's innovations all over Europe with the first published manual of etching, which was translated into Italian, Dutch, German and English.
The 17th century was the great age of etching, with Rembrandt, Giovanni Benedetto Castiglione and many other masters. In the 18th century, Piranesi, Tiepolo and Daniel Chodowiecki were the best of a smaller number of fine etchers. In the 19th and early 20th century, the Etching revival produced a host of lesser artists, but no really major figures. Etching is still widely practiced today.
Variants.
Aquatint uses acid-resistant resin to achieve tonal effects.
Soft-ground etching uses a special softer ground. The artist places a piece of paper (or cloth etc. in modern uses) over the ground and draws on it. The print resembles a drawing.
Relief etching was invented by William Blake in about 1788, and he has been almost the only artist to use it in its original form. However from 1880–1950 a photo-mechanical ("line-block") variant was the dominant form of commercial printing for images. A similar process to etching, but printed as a relief print, so it is the "white" background areas which are exposed to the acid, and the areas to print "black" which are covered with ground. Blake's exact technique remains controversial. He used the technique to print texts and images together, writing the text and drawing lines with an acid-resistant medium.
Modern technique in detail.
A waxy acid-resist, known as a ground, is applied to a metal plate, most often copper or zinc but steel plate is another medium with different qualities. There are two common types of ground: hard ground and soft ground.
Hard ground can be applied in two ways. Solid hard ground comes in a hard waxy block. To apply hard ground of this variety, the plate to be etched is placed upon a hot-plate (set at 70 degrees C), a kind of metal worktop that is heated up. The plate heats up and the ground is applied by hand, melting onto the plate as it is applied. The ground is spread over the plate as evenly as possible using a roller. Once applied the etching plate is removed from the hot-plate and allowed to cool which hardens the ground.
After the ground has hardened the artist "smokes" the plate, classically with 3 beeswax tapers, applying the flame to the plate to darken the ground and make it easier to see what parts of the plate are exposed. Smoking not only darkens the plate but adds a small amount of wax. Afterwards the artist uses a sharp tool to scratch into the ground, exposing the metal.
The second way to apply hard ground is by liquid hard ground. This comes in a can and is applied with a brush upon the plate to be etched. Exposed to air the hard ground will harden. Some printmakers use
oil/tar based asphaltum or bitumen as hard ground, although often bitumen is used to protect steel plates from rust and copper plates from aging.
Soft ground also comes in liquid form and is allowed to dry but it does not dry hard like hard ground and is impressionable. After the soft ground has dried the printmaker may apply materials such as leaves, objects, hand prints and so on which will penetrate the soft ground and expose the plate underneath.
The ground can also be applied in a fine mist, using powdered rosin or spraypaint. This process is called aquatint, and allows for the creation of tones, shadows, and solid areas of color. 
The design is then drawn (in reverse) with an etching-needle or échoppe. An "echoppe" point can be made from an ordinary tempered steel etching needle, by grinding the point back on a carborundum stone, at a 45–60 degree angle. The "echoppe" works on the same principle that makes a fountain pen's line more attractive than a ballpoint's: The slight swelling variation caused by the natural movement of the hand "warms up" the line, and although hardly noticeable in any individual line, has a very attractive overall effect on the finished plate. It can be drawn with in the same way as an ordinary needle.
The plate is then completely submerged in an acid that eats away at the exposed metal. Ferric chloride may be used for etching copper or zinc plates, whereas nitric acid may be used for etching zinc or steel plates. Typical solutions are 2 parts FeCl3 to 2 parts water and 1 part nitric to 3 parts water. The strength of the acid determines the speed of the etching process.
During the etching process the printmaker uses a bird feather or similar item to wave away bubbles and detritus produced by the dissolving process, from the surface of the plate, or the plate may be periodically lifted from the acid bath. If a bubble is allowed to remain on the plate then it will stop the acid biting into the plate where the bubble touches it. Zinc produces more bubbles much more rapidly than copper and steel and some artists use this to produce interesting round bubble-like circles within their prints for a Milky Way effect.
The detritus is powdery dissolved metal that fills the etched grooves and can also block the acid from biting evenly into the exposed plate surfaces. Another way to remove detritus from a plate is to place the plate to be etched face down within the acid upon plasticine balls or marbles, although the drawback of this technique is the exposure to bubbles and the inability to remove them readily.
For aquatinting a printmaker will often use a test strip of metal about a centimetre to three centimetres wide. The strip will be dipped into the acid for a specific number of minutes or seconds. The metal strip will then be removed and the acid washed off with water. Part of the strip will be covered in ground and then the strip is redipped into the acid and the process repeated. The ground will then be removed from the strip and the strip inked up and printed. This will show the printmaker the different degrees or depths of the etch, and therefore the strength of the ink color, based upon how long the plate is left in the acid.
The plate is removed from the acid and washed over with water to remove the acid. The ground is removed with a solvent such as turpentine. Turpentine is often removed from the plate using methylated spirits since turpentine is greasy and can affect the application of ink and the printing of the plate.
Spit-biting is a process whereby the printmaker will apply acid to a plate with a brush in certain areas of the plate. The plate may be aquatinted for this purpose or exposed directly to the acid. The process is known as "spit"-biting due to the use of saliva once used as a medium to dilute the acid, although gum arabic or water are now commonly used.
A piece of matte board, a plastic "card", or a wad of cloth is often used to push the ink into the incised lines. The surface is wiped clean with a piece of stiff fabric known as "tarlatan" and then wiped with newsprint paper; some printmakers prefer to use the blade part of their hand or palm at the base of their thumb. The wiping leaves ink in the incisions. You may also use a folded piece of organza silk to do the final wipe. If copper or zinc plates are used, then the plate surface is left very clean and therefore white in the print. If steel plate is used, then the plate's natural tooth gives the print a grey background similar to the effects of aquatinting. As a result steel plates do not need aquatinting as gradual exposure of the plate via successive dips into acid will produce the same result.
A damp piece of paper is placed over the plate and it is run through the press.
Nontoxic etching.
Growing concerns about the health effects of acids and solvents led to the development of less toxic etching methods in the late 20th century. An early innovation was the use of floor wax as a hard ground for coating the plate. Others, such as printmakers Mark Zaffron and Keith Howard, developed systems using acrylic polymers as a ground and ferric chloride for etching. The polymers are removed with sodium carbonate (washing soda) solution, rather than solvents. When used for etching, ferric chloride does not produce a corrosive gas, as acids do, thus eliminating another danger of traditional etching.
The traditional aquatint, which uses either powdered rosin or enamel spray paint, is replaced with an airbrush application of the acrylic polymer hard ground. Again, no solvents are needed beyond the soda ash solution, though a ventilation hood is needed due to acrylic particulates from the air brush spray.
The traditional soft ground, requiring solvents for removal from the plate, is replaced with water-based relief printing ink. The ink receives impressions like traditional soft ground, resists the ferric chloride etchant, yet can be cleaned up with warm water and either soda ash solution or ammonia.
Anodic etching has been used in industrial processes for over a century. The etching power is a source of direct current. The item to be etched (anode) is connected to its positive pole. A receiver plate (cathode) is connected to its negative pole. Both, spaced slightly apart, are immersed in a suitable aqueous solution of a suitable electrolyte. The current pushes the metal out from the anode into solution and deposits it as metal on the cathode. Shortly before 1990, two groups working independently developed different ways of applying it to creating intaglio printing plates. 
In the patented Electroetch system, invented by Marion and Omri Behr, in contrast to certain nontoxic etching methods, an etched plate can be reworked as often as the artist desires The system uses voltages below 2 volts which exposes the uneven metal crystals in the etched areas resulting in superior ink retention and printed image appearance of quality equivalent to traditional acid methods. With polarity reversed the low voltage provides a simpler method of making mezzotint plates as well as the "steel facing" copper plates.
Some of the earliest printmaking workshops experimenting with, developing and promoting nontoxic techniques include Grafisk Eksperimentarium, in Copenhagen, Denmark, Edinburgh Printmakers, in Scotland, and New Grounds Print Workshop, in Albuquerque, New Mexico.
Photo-etching.
Light sensitive polymer plates allow for photorealistic etchings. A photo-sensitive coating is applied to the plate by either the plate supplier or the artist. Light is projected onto the plate as a negative image to expose it. Photopolymer plates are either washed in hot water or under other chemicals according to the plate manufacturers' instructions. Areas of the photo-etch image may be stopped-out before etching to exclude them from the final image on the plate, or removed or lightened by scraping and burnishing once the plate has been etched. Once the photo-etching process is complete, the plate can be worked further as a normal intaglio plate, using drypoint, further etching, engraving, etc. The final result is an intaglio plate which is printed like any other.
Types of metal plates.
Copper is a traditional metal, and is still preferred, for etching, as it bites evenly, holds texture well, and does not distort the colour of the ink when wiped. Zinc is cheaper than copper, so preferable for beginners, but it does not bite as cleanly as copper, and it alters some colours of ink. Steel is growing in popularity as an etching substrate. Prices of copper and zinc have steered steel to an acceptable alternative. The line quality of steel is less fine than copper but finer than zinc. Steel has a natural and rich aquatint.
The type of metal used for the plate impacts the number of prints the plate will produce. The firm pressure of the printing press slowly rubs out the finer details of the image with every pass through. With relatively soft copper, for example, the etching details will begin to wear very quickly, some copper plates show extreme wear after only ten prints. Steel, on the other hand, is incredibly durable. This wearing out of the image over time is one of the reasons prints created early in a numbered series tend to be valued more highly. The total number of prints an artist would like to produce are taken into account when choosing the metal.
Industrial uses.
Etching is also used in the manufacturing of printed circuit boards and semiconductor devices, and in the preparation of metallic specimens for microscopic observation.
Controlling the acid's effects.
Hard grounds.
There are many ways for the printmaker to control the acid's effects. Most typically, the surface of the plate is covered in a hard, waxy 'ground' that resists acid. The printmaker then scratches through the ground with a sharp point, exposing lines of metal that are attacked by the acid.
Aquatint.
Aquatint is a variation in which particulate resin is evenly distributed on the plate, then heated to form a screen ground of uniform but less than perfect density. After etching, any exposed surface will result in a roughened (i.e., darkened) surface. Areas that are to be light in the final print are protected by varnishing between acid baths. Successive turns of varnishing and placing the plate in acid create areas of tone difficult or impossible to achieve by drawing through a wax ground.
Sugar lift.
Here designs in a syrupy solution of sugar or Camp Coffee are painted onto the metal surface prior to it being coated in a liquid etching ground or 'stop out' varnish. When later the plate is placed in hot water the sugar dissolves and lifts off leaving the image. The plate can then be etched.
Spit bite.
A mixture of nitric acid and Gum Arabic (or almost never – saliva) which can be dripped, spattered or painted onto a metal surface giving interesting results. A mixture of nitric acid and rosin can also be used.
Printing.
Printing the plate is done by covering the surface with ink, then rubbing the ink off the surface with "tarlatan" cloth or newsprint, leaving ink in the roughened areas and lines. Damp paper is placed on the plate, and both are run through a printing press; the pressure forces the paper into contact with the ink, transferring the image ("c.f.", chine-collé). Unfortunately, the pressure also subtly degrades the image in the plate, smoothing the roughened areas and closing the lines; a copper plate is good for, at most, a few hundred printings of a strongly etched imaged before the degradation is considered too great by the artist. At that point, the artist can manually restore the plate by re-etching it, essentially putting ground back on and retracing their lines; alternatively, plates can be electro-plated before printing with a harder metal to preserve the surface. Zinc is also used, because as a softer metal, etching times are shorter; however, that softness also leads to faster degradation of the image in the press.
Faults.
"Foul-bite" or "over-biting" is common in etching, and is the effect of minuscule amounts of acid leaking through the ground to create minor pitting and burning on the surface. This incidental roughening may be removed by smoothing and polishing the surface, but artists often leave faux-bite, or deliberately court it by handling the plate roughly, because it is viewed as a desirable mark of the process.
"Etchings" euphemism.
The phrase "Want to come up and see my etchings?" is a romantic euphemism by which a person entices someone to come back to their place with an offer to look at something artistic, but with ulterior motives. The phrase is a corruption of some phrases in a novel by Horatio Alger, Jr. called "The Erie Train Boy", which was first published in 1891. Alger was an immensely popular author in the 19th century—especially with young people—and his books were widely quoted. In chapter XXII of the book, a woman writes to her boyfriend, "I have a new collection of etchings that I want to show you. Won't you name an evening when you will call, as I want to be certain to be at home when you really do come." The boyfriend then writes back "I shall no doubt find pleasure in examining the etchings which you hold out as an inducement to call."
This was referenced in a 1929 James Thurber cartoon in which a man tells a woman in a building lobby: "You wait here and I'll bring the etchings down". It was also referenced in Dashiell Hammett's 1934 novel "The Thin Man", in which the narrator answers his wife asking him about a lady he had wandered off with by saying: "She just wanted to show me some French etchings."
The phrase was given new popularity in 1937: in a well publicized case, violinist David Rubinoff was accused of inviting a young woman to his hotel room to view some French etchings, but instead seducing her.
As early as 1895, Hjalmar Söderberg used the reference in his "decadent" début novel "Delusions" (swe: "Förvillelser)", when he lets the dandy Johannes Hall lure the main character's younger sister Greta into his room under the pretence that they browse through his etchings and engravings (e.g., "Die Sünde" by Franz Stuck).

</doc>
<doc id="42527" url="http://en.wikipedia.org/wiki?curid=42527" title="421">
421

Year 421 (CDXXI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Agricola and Eustathius (or, less frequently, year 1174 "Ab urbe condita"). The denomination 421 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Persia.
</onlyinclude>

</doc>
<doc id="42528" url="http://en.wikipedia.org/wiki?curid=42528" title="Screen printing">
Screen printing

Screen printing is a printing technique whereby a mesh is used to transfer ink onto a substrate, except in areas made impermeable to the ink by a blocking stencil. A blade or squeegee is moved across the screen to fill the open mesh apertures with ink, and a reverse stroke then causes the screen to touch the substrate momentarily along a line of contact. This causes the ink to wet the substrate and be pulled out of the mesh apertures as the screen springs back after the blade has passed.
Basically, it is the process of using a mesh-based stencil to apply ink onto a substrate, whether it be T-shirts, posters, stickers, vinyl, wood, or other material.
Screen printing is also a stencil method of print making in which a design is imposed on a screen of polyester or other fine mesh, with blank areas coated with an impermeable substance. Ink is forced into the mesh openings by the fill blade or squeegee and by wetting the substrate, transferred onto the printing surface during the squeegee stroke. As the screen rebounds away from the substrate the ink remains on the substrate. It is also known as silk-screen, screen, serigraphy, and serigraph printing. One color is printed at a time, so several screens can be used to produce a multicoloured image or design.
Etymology.
There are various terms used for what is essentially the same technique. Traditionally the process was called "screen printing" or "silkscreen printing" because silk was used in the process prior to the invention of polyester mesh. Currently, synthetic threads are commonly used in the screen printing process. The most popular mesh in general use is made of polyester. There are special-use mesh materials of nylon and stainless steel available to the screen printer. There are also different types of mesh size which will determine the outcome and look of the finished design on the material.
History.
Screen printing is a form of stencilling that first appeared in a recognizable form in China during the Song Dynasty (960–1279 AD). It was then adapted by other Asian countries like Japan, and was furthered by creating newer methods.
Screen printing was largely introduced to Western Europe from Asia sometime in the late 18th century, but did not gain large acceptance or use in Europe until silk mesh was more available for trade from the east and a profitable outlet for the medium discovered.
Early in the 1910s, several printers experimenting with photo-reactive chemicals used the well-known actinic light–activated cross linking or hardening traits of potassium, sodium or ammonium chromate and dichromate chemicals with glues and gelatin compounds. Roy Beck, Charles Peter and Edward Owens studied and experimented with chromic acid salt sensitized emulsions for photo-reactive stencils. This trio of developers would prove to revolutionize the commercial screen printing industry by introducing photo-imaged stencils to the industry, though the acceptance of this method would take many years. Commercial screen printing now uses sensitizers far safer and less toxic than bichromates. Currently there are large selections of pre-sensitized and "user mixed" sensitized emulsion chemicals for creating photo-reactive stencils.
A group of artists who later formed the National Serigraphic Society coined the word Serigraphy in the 1930s to differentiate the artistic application of screen printing from the industrial use of the process. "Serigraphy" is a compound word formed from Latin "sēricum" (silk) and Greek "graphein" (to write or draw).
The Printers' National Environmental Assistance Center says "Screenprinting is arguably the most versatile of all printing processes." Since rudimentary screenprinting materials are so affordable and readily available, it has been used frequently in underground settings and subcultures, and the non-professional look of such DIY culture screenprints have become a significant cultural aesthetic seen on movie posters, record album covers, flyers, shirts, commercial fonts in advertising, in artwork and elsewhere.
1960s to present.
Credit is generally given to the artist Andy Warhol for popularising screen printing as an artistic technique, identified as serigraphy, in the United States. Warhol is particularly identified with his 1962 depiction of actress Marilyn Monroe screen printed in garish colours. Sister Mary Corita Kent, gained international fame for her vibrant serigraphs during the 1960s and 1970s. Her works were rainbow colored, contained words that were both political and fostered peace and love and caring.
American entrepreneur, artist and inventor Michael Vasilantone started to use, develop, and sell a rotary multicolour garment screen printing machine in 1960. Vasilantone later filed for patent on his invention in 1967 granted number 3,427,964 on February 18, 1969. The original rotary machine was manufactured to print logos and team information on bowling garments but soon directed to the new fad of printing on T-shirts. The Vasilantone patent was licensed by multiple manufacturers, the resulting production and boom in printed T-shirts made the rotary "garment" screen printing machine the most popular device for screen printing in the industry. Screen printing on garments currently accounts for over half of the screen printing activity in the United States.
In June 1986, Marc Tartaglia, Marc Tartaglia Jr. and Michael Tartaglia created a silk screening device which is defined in its US Patent Document as, "Multi-coloured designs are applied on a plurality of textile fabric or sheet materials with a silk screen printer having seven platens arranged in two horizontal rows below a longitudinal heater which is movable across either row." This invention received the patent number 4,671,174 on June 9, 1987, however the patent no longer exists.
Graphic screenprinting is widely used today to create many mass or large batch produced graphics, such as posters or display stands. Full colour prints can be created by printing in CMYK (cyan, magenta, yellow and black ('key')).
Screen printing lends itself well to printing on canvas. Andy Warhol, Rob Ryan, Blexbolex, Arthur Okamura, Robert Rauschenberg, Roy Lichtenstein, Harry Gottlieb, and many other artists have used screen printing as an expression of creativity and artistic vision.
Printing technique.
A screen is made of a piece of mesh stretched over a frame. A stencil is formed by blocking off parts of the screen in the negative image of the design to be printed; that is, the open spaces are where the ink will appear on the substrate.
Before printing occurs, the frame and screen must undergo the pre-press process, in which an emulsion is 'scooped' across the mesh and the 'exposure unit' burns away the unnecessary emulsion leaving behind a clean area in the mesh with the identical shape as the desired image. The surface to be printed (commonly referred to as a pallet) is coated with a wide 'pallet tape'. This serves to protect the 'pallet' from any unwanted ink leaking through the screen and potentially staining the 'pallet' or transferring unwanted ink onto the next substrate. Next, the screen and frame are lined with a tape. The type of tape used in for this purpose often depends upon the ink that is to be printed onto the substrate. These aggressive tapes are generally used for UV and water-based inks due to the inks' lower viscosities. The last process in the 'pre-press' is blocking out any unwanted 'pin-holes' in the emulsion. If these holes are left in the emulsion, the ink will continue through and leave unwanted marks. To block out these holes, materials such as tapes, speciality emulsions and 'block-out pens' may be used effectively.
The screen is placed atop a substrate. Ink is placed on top of the screen, and a floodbar is used to push the ink through the holes in the mesh. The operator begins with the fill bar at the rear of the screen and behind a reservoir of ink. The operator lifts the screen to prevent contact with the substrate and then using a slight amount of downward force pulls the fill bar to the front of the screen. This effectively fills the mesh openings with ink and moves the ink reservoir to the front of the screen. The operator then uses a squeegee (rubber blade) to move the mesh down to the substrate and pushes the squeegee to the rear of the screen. The ink that is in the mesh opening is pumped or squeezed by capillary action to the substrate in a controlled and prescribed amount, i.e. the wet ink deposit is proportional to the thickness of the mesh and or stencil. As the squeegee moves toward the rear of the screen the tension of the mesh pulls the mesh up away from the substrate (called snap-off) leaving the ink upon the substrate surface.
There are three common types of screen printing presses. The 'flat-bed', 'cylinder', and the most widely used type, the 'rotary'.
Textile items printed with multicoloured designs often use a wet on wet technique, or colours dried while on the press, while graphic items are allowed to dry between colours that are then printed with another screen and often in a different colour after the product is re-aligned on the press.
Most screens are ready for re-coating at this stage, but sometimes screens will have to undergo a further step in the reclaiming process called dehazing. This additional step removes haze or "ghost images" left behind in the screen once the emulsion has been removed. Ghost images tend to faintly outline the open areas of previous stencils, hence the name. They are the result of ink residue trapped in the mesh, often in the knuckles of the mesh (the points where threads cross).
While the public thinks of garments in conjunction with screen printing, the technique is used on tens of thousands of items, including decals, clock and watch faces, balloons, and many other products. The technique has even been adapted for more advanced uses, such as laying down conductors and resistors in multi-layer circuits using thin ceramic layers as the substrate.
Stencilling techniques.
A method of stencilling that has increased in popularity over the past years is the photo emulsion technique:
Another advantage of screen printing is that large quantities can be produced rapidly with new automatic presses, up to 1800 shirts in 1 hour. The current speed loading record is 1805 shirts printed in one hour, documented on 18 February 2005. Maddie Sikorski of the New Buffalo Shirt Factory in Clarence, New York (USA) set this record at the Image Wear Expo in Orlando, Florida, USA, using a 12-colour M&R Formula Press and an M&R Passport Automatic Textile Unloader. The world speed record represents a speed that is over four times the typical average speed for manual loading of shirts for automated screen printing.
Versatility.
Screen printing is more versatile than traditional printing techniques. The surface does not have to be printed under pressure, unlike etching or lithography, and it does not have to be planar. Different inks can be used to work with a variety of materials, such as textiles, ceramics, wood, paper, glass, metal, and plastic. As a result, screen printing is used in many different industries, including:
Semiconducting material.
In screen printing on wafer-based solar photovoltaic (PV) cells, the mesh and buses of silver are printed on the front; furthermore, the buses of silver are printed on the back. Subsequently, aluminum paste is dispensed over the whole surface of the back for passivation and surface reflection. One of the parameters that can vary and can be controlled in screen printing is the thickness of the print. This makes it useful for some of the techniques of printing solar cells, electronics etc.
One of the most critical processes to maintain high yield. Solar wafers are becoming thinner and larger, so careful printing is required to maintain a lower breakage rate. On the other hand, high throughput at the printing stage improves the throughput of the whole cell production line.
Screen printing press.
To print multiple copies of the screen design on garments in an efficient manner, amateur and professional printers usually use a screen printing press. Many companies offer simple to sophisticated printing presses. Most of these presses are manual. A few that are industrial-grade-automatic printers require minimal manual labor and increase production significantly.
Rotary screen printing.
A development of screen printing with flat screens from 1963 was to wrap the screen around to form a tube, with the ink supply and squeegee inside the tube. The resulting roller rotates at the same speed as the web in a roll-to-roll machine. The benefits are high output rates and long rolls of product. This is the only way to make high-build fully patterned printing/coating as a continuous process, and has been widely used for manufacturing textured wallpapers.

</doc>
<doc id="42529" url="http://en.wikipedia.org/wiki?curid=42529" title="Ben K. Green">
Ben K. Green

Ben K. Green (1912 – 1974) was an author who wrote about horses and the post-World War I American West. His books consist of anecdotes drawn from his own experiences in the Southwestern United States.
He was born in Cumby, Texas and before he was twenty years old had successfully earned a living trading horses and mules and raising cattle and sheep. The common trading practice-- "cheat or be cheated"—is reflected in his stories, told using the language and humor of the area and not excluding himself from either outcome.
It is often said that he studied at Cornell University and in England but Cornell University has no record of this, and he did not ever become a certified or licensed doctor of veterinary medicine according to records from the Texas State Board of Veterinary Medical Examiners. He was persuaded to settle in Fort Stockton, Texas and practiced in the entire Trans-Pecos Region. A large part of his work involved identifying plants which grew in that alkali soil and contained substances poisonous to horses, cattle, sheep, and hogs (lechuguilla, yellowweed, pinguey, locoweed).

</doc>
<doc id="42531" url="http://en.wikipedia.org/wiki?curid=42531" title="922">
922

Year 922 (CMXXII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="42532" url="http://en.wikipedia.org/wiki?curid=42532" title="Printmaking">
Printmaking

Printmaking is the process of making artworks by printing, normally on paper. Printmaking normally covers only the process of creating prints that have an element of originality, rather than just being a photographic reproduction of a painting. Except in the case of monotyping, the process is capable of producing multiples of a same piece, which is called a print. Each print produced is not considered a "copy" but rather is considered an "original". This is because typically each print varies to an extent due to variables intrinsic to the printmaking process, and also because the imagery of a print is typically not simply a reproduction of another work but rather is often a unique image designed from the start to be expressed in a particular printmaking technique. A print may be known as an impression. Printmaking (other than monotyping) is not chosen only for its ability to produce multiple impressions, but rather for the unique qualities that each of the printmaking processes lends itself to.
Prints are created by transferring ink from a matrix or through a prepared screen to a sheet of paper or other material. Common types of matrices include: metal plates, usually copper or zinc, or polymer plates for engraving or etching; stone, aluminum, or polymer for lithography; blocks of wood for woodcuts and wood engravings; and linoleum for linocuts. Screens made of silk or synthetic fabrics are used for the screenprinting process. Other types of matrix substrates and related processes are discussed below. 
Multiple impressions printed from the same matrix form an edition. Since the late 19th century, artists have generally signed individual impressions from an edition and often number the impressions to form a limited edition; the matrix is then destroyed so that no more prints can be produced. Prints may also be printed in book form, such as illustrated books or artist's books.
Techniques.
Overview.
Printmaking techniques are generally divided into the following basic categories: 
Other types of printmaking techniques outside these groups include collagraphy, viscosity printing, and foil imaging. Collagraphy is a printmaking technique in which textured material is adhered to the printing matrix. This texture is transferred to the paper during the printing process. Contemporary printmaking may include digital printing, photographic mediums, or a combination of digital, photographic, and traditional processes.
Many of these techniques can also be combined, especially within the same family. For example Rembrandt's prints are usually referred to as "etchings" for convenience, but very often include work in engraving and drypoint as well, and sometimes have no etching at all.
Woodcut.
Artists using this technique include
Albrecht Dürer,
Ernst Ludwig Kirchner,
Dulah Marie Evans,
Hiroshige,
Hokusai,
Gustave Baumann, 
Hannah Tompkins, 
Hussein El Gebaly
Carlos Alvarado Lang
Woodcut, a type of relief print, is the earliest printmaking technique, and the only one traditionally used in the Far East. It was probably first developed as a means of printing patterns on cloth, and by the 5th century was used in China for printing text and images on paper. Woodcuts of images on paper developed around 1400 in Europe, and slightly later in Japan. These are the two areas where woodcut has been most extensively used purely as a process for making images without text.
The artist draws a design on a plank of wood, or on paper which is transferred to the wood. Traditionally the artist then handed the work to a specialist cutter, who then uses sharp tools to carve away the parts of the block that will not receive ink. The surface of the block is then inked with the use of a brayer, and then a sheet of paper, perhaps slightly damp, is placed over the block. The block is then rubbed with a baren or spoon, or is run through a printing press. If in color, separate blocks can be used for each color, or a technique called reduction printing can be used. 
Reduction printing is a name used to describe the process of using one block to print several layers of color on one print. This usually involves cutting a small amount of the block away, and then printing the block many times over on different sheets before washing the block, cutting more away and printing the next color on top. This allows the previous color to show through. This process can be repeated many times over. The advantages of this process is that only one block is needed, and that different components of an intricate design will line up perfectly. The disadvantage is that once the artist moves on to the next layer, no more prints can be made. 
Another variation of woodcut printmaking is the cukil technique, made famous by the Taring Padi underground community in Java, Indonesia. Taring Padi Posters usually resemble intricately printed cartoon posters embedded with political messages. Images—usually resembling a visually complex scenario—are carved unto a wooden surface called cukilan, then smothered with printer's ink before pressing it unto media such as paper or canvas.
Engraving.
The process was developed in Germany in the 1430s from the engraving used by goldsmiths to decorate metalwork. Engravers use a hardened steel tool called a burin to cut the design into the surface of a metal plate, traditionally made of copper. Engraving using a burin is generally a difficult skill to learn. 
Gravers come in a variety of shapes and sizes that yield different line types. The burin produces a unique and recognizable quality of line that is characterized by its steady, deliberate appearance and clean edges. Other tools such as mezzotint rockers, roulettes (a tool with a fine-toothed wheel) and burnishers (a tool used for making an object smooth or shiny by rubbing) are used for texturing effects.
To make a print, the engraved plate is inked all over, then the ink is wiped off the surface, leaving only ink in the engraved lines. The plate is then put through a high-pressure printing press together with a sheet of paper (often moistened to soften it). The paper picks up the ink from the engraved lines, making a print. The process can be repeated many times; typically several hundred impressions (copies) could be printed before the printing plate shows much sign of wear, except when drypoint, which gives much shallower lines, is used. 
In the 20th century, true engraving was revived as a serious art form by artists including Stanley William Hayter whose Studio 17 in Paris and New York City became the magnet for such artists as Pablo Picasso, Alberto Giacometti, Mauricio Lasansky and Joan Miró.
Etching.
Etching is part of the intaglio family (along with engraving, drypoint, mezzotint, and aquatint.) The process is believed to have been invented by Daniel Hopfer (circa 1470-1536) of Augsburg, Germany, who decorated armor in this way, and applied the method to printmaking. Etching soon came to challenge engraving as the most popular printmaking medium. Its great advantage was that, unlike engraving which requires special skill in metalworking, etching is relatively easy to learn for an artist trained in drawing.
Etching prints are generally linear and often contain fine detail and contours. Lines can vary from smooth to sketchy. An etching is opposite of a woodcut in that the raised portions of an etching remain blank while the crevices hold ink. In pure etching, a metal (usually copper, zinc or steel) plate is covered with a waxy or acrylic ground. The artist then draws through the ground with a pointed etching needle. The exposed metal lines are then etched by dipping the plate in a bath of etchant (e.g. nitric acid or ferric chloride). The etchant "bites" into the exposed metal, leaving behind lines in the plate. The remaining ground is then cleaned off the plate, and the printing process is then just the same as for engraving.
Artists using this technique include Albrecht Dürer, Rembrandt, Francisco Goya, Whistler, Otto Dix, James Ensor, Edward Hopper, Käthe Kollwitz, Pablo Picasso, Cy Twombly, Lucas van Leyden, Carlos Alvarado Lang.
Mezzotint.
An intaglio variant of engraving in which the image is formed from subtle gradations of light and shade. Mezzotint—from the Italian mezzo ("half") and tinta ("tone")—is a "dark manner" form of printmaking, which requires artists to work from dark to light. To create a mezzotint, the surface of a copper printing plate is roughened evenly all over with the aid of a tool known as a rocker; the image is then formed by smoothing the surface with a tool known as a burnisher. When inked, the roughened areas of the plate will hold more ink and print more darkly, while smoother areas of the plate hold less or no ink, and will print more lightly or not at all. It is, however, possible to create the image by only roughening the plate selectively, so working from light to dark.
Mezzotint is known for the luxurious quality of its tones: first, because an evenly, finely roughened surface holds a lot of ink, allowing deep solid colors to be printed; secondly because the process of smoothing the texture with burin, burnisher and scraper allows fine gradations in tone to be developed.
The mezzotint printmaking method was invented by Ludwig von Siegen (1609–1680). The process was used widely in England from the mid-eighteenth century, to reproduce oil paintings and portraits.
Aquatint.
A technique used in Intaglio etchings. Like etching, aquatint technique involves the application of acid to make marks in a metal plate. Where the etching technique uses a needle to make lines that retain ink, aquatint relies on powdered rosin which is acid resistant in the ground to create a tonal effect. The rosin is applied in a light dusting by a fan booth, the rosin is then cooked until set on the plate. At this time the rosin can be burnished or scratched out to affect its tonal qualities. The tonal variation is controlled by the level of acid exposure over large areas, and thus the image is shaped by large sections at a time.
Goya used aquatint for most of his prints.
Drypoint.
A variant of engraving, done with a sharp point, rather than a v-shaped burin. While engraved lines are very smooth and hard-edged, drypoint scratching leaves a rough burr at the edges of each line. This burr gives drypoint prints a characteristically soft, and sometimes blurry, line quality. Because the pressure of printing quickly destroys the burr, drypoint is useful only for very small editions; as few as ten or twenty impressions. To counter this, and allow for longer print runs, electro-plating (here called steelfacing) has been used since the nineteenth century to harden the surface of a plate.
The technique appears to have been invented by the Housebook Master, a south German fifteenth-century artist, all of whose prints are in drypoint only. Among the most famous artists of the old master print: Albrecht Dürer produced 3 drypoints before abandoning the technique; Rembrandt used it frequently, but usually in conjunction with etching and engraving.
Lithography.
Artists using this technique include
Honoré Daumier,
Vincent van Gogh,
George Bellows,
Pierre Bonnard,
Edvard Munch,
Emil Nolde,
Pablo Picasso,
Odilon Redon,
Henri de Toulouse-Lautrec,
Salvador Dalí,
M. C. Escher,
Willem de Kooning,
Joan Miró,
Stow Wengenroth
Lithography is a technique invented in 1798 by Alois Senefelder and based on the chemical repulsion of oil and water.
A porous surface, normally limestone, is used; the image is drawn on the limestone with a greasy medium.
Acid is applied, transferring the grease to the limestone, leaving the image 'burned' into the surface. Gum arabic, a water soluble substance, is then applied, sealing the surface of the stone not covered with the drawing medium.
The stone is wetted, with water staying only on the surface not covered in grease-based residue of the drawing; the stone is then 'rolled up', meaning oil ink is applied with a roller covering the entire surface; since water repels the oil in the ink, the ink adheres only to the greasy parts, perfectly inking the image.
A sheet of dry paper is placed on the surface, and the image is transferred to the paper by the pressure of the printing press. Lithography is known for its ability to capture fine gradations in shading and very small detail.
A variant is photo-lithography, in which the image is captured by photographic processes on metal plates; printing is carried out in the same way.
Screenprinting.
Artists using this technique include
Josef Albers,
Ralston Crawford,
Gene Davis.
Robert Indiana,
Roy Lichtenstein,
Julian Opie,
Bridget Riley,
Edward Ruscha,
Andy Warhol, and
Carlos Alvarado Lang.
Screenprinting (occasionally known as "silkscreen", or "serigraphy") creates prints by using a fabric stencil technique; ink is simply pushed through the stencil against the surface of the paper, most often with the aid of a squeegee. Generally, the technique uses a natural or synthetic 'mesh' fabric stretched tightly across a rectangular 'frame,' much like a stretched canvas. The fabric can be silk, nylon monofilament, multifilament polyester, or even stainless steel (). While commercial screenprinting often requires high-tech, mechanical apparatuses and calibrated materials, printmakers value it for the "Do It Yourself" approach, and the low technical requirements, high quality results. The essential tools required are a squeegee, a mesh fabric, a frame, and a stencil. Unlike many other printmaking processes, a printing press is not required, as screenprinting is essentially stencil printing.
Screenprinting may be adapted to printing on a variety of materials, from paper, cloth, and canvas to rubber, glass, and metal. Artists have used the technique to print on bottles, on slabs of granite, directly onto walls, and to reproduce images on textiles which would distort under pressure from printing presses.
Monotype.
Monotyping is a type of printmaking made by drawing or painting on a smooth, non-absorbent surface. The surface, or matrix, was historically a copper etching plate, but in contemporary work it can vary from zinc or glass to acrylic glass. The image is then transferred onto a sheet of paper by pressing the two together, usually using a printing-press. Monotypes can also be created by inking an entire surface and then, using brushes or rags, removing ink to create a subtractive image, e.g. creating lights from a field of opaque color. The inks used may be oil based or water based. With oil based inks, the paper may be dry, in which case the image has more contrast, or the paper may be damp, in which case the image has a 10 percent greater range of tones.
Unlike monoprinting, monotyping produces a unique print, or monotype, because most of the ink is removed during the initial pressing. Although subsequent reprintings are sometimes possible, they differ greatly from the first print and are generally considered inferior. A second print from the original plate is called a "ghost print" or "cognate". Stencils, watercolor, solvents, brushes, and other tools are often used to embellish a monotype print. Monotypes are often spontaneously executed and with no preliminary sketch.
Monotypes are the most painterly method among the printmaking techniques, a unique print that is essentially a printed painting. The principal characteristic of this medium is found in its spontaneity and its combination of printmaking, painting, and drawing media.
Monoprint.
Monoprinting is a form of printmaking that uses a matrix such as a woodblock, litho stone, or copper plate, but produces impressions that are unique. Multiple unique impressions printed from a single matrix are sometimes known as a variable edition. There are many techniques used in monoprinting, including collagraph, collage, hand-painted additions, and a form of tracing by which thick ink is laid down on a table, paper is placed on the ink, and the back of the paper is drawn on, transferring the ink to the paper. Monoprints can also be made by altering the type, color, and viscosity of the ink used to create different prints. Traditional printmaking techniques, such as lithography, woodcut, and intaglio, can be used to make monoprints.
Digital prints.
Artists using this technique include
Istvan Horkay, Ralph Goings, Enrique Chagoya
Digital prints refers to images printed using a digital printer instead of a traditional printing press. These images can be printed to a variety of substrates including paper, cloth, or plastic canvas. Accurate color reproduction and the type of ink used (see below) are key to distinguishing high quality from low quality digital prints. Metallics (silvers, golds) are particularly difficult to reproduce accurately because they reflect light back to digital scanners. High quality digital prints typically are reproduced with very high-resolution data files with very high-precision printers. The substrate used has an effect on the final colors and cannot be ignored when selecting a color palette.
Pigment-based vs dye-based inks.
Unlike pigment, dyes dissolve when mixed into a liquid. Dyes are organic (not mineral). Although most are synthetic, derived from petroleum, they can be made from vegetable or animal sources. Dyes are well suited for textiles where the liquid dye penetrates and chemically bonds to the fiber. Because of the deep penetration, more layers of material must lose their color before the fading is apparent. Dyes, however, are not suitable for the relatively thin layers of ink laid out on the surface of a print.
Pigment is a finely ground, particulate substance which, when mixed or ground into a liquid to make ink or paint, does not dissolve, but remains dispersed or suspended in the liquid. Pigments are categorized as either inorganic (mineral) or organic (synthetic).
A pigment, such as red iron oxide (rust) is simply an oxidized form of iron. One could leave iron, lead, or gold in the sun for a million years and they would never change color or change into another substance. In contrast, man-made synthetic and vegetable water-soluble dyes can fade rapidly, often within one to six months.
Giclée.
Giclée (pron.: /ʒiːˈkleɪ/ zhee-KLAY or /dʒiːˈkleɪ/), is a neologism coined in 1991 by printmaker Jack Duganne for digital prints made on inkjet printers. It is based on the French word gicleur, which means "nozzle". Today fine art prints produced on ink-jet machines using the CcMmYK color model are generally called "Giclée".
Foil imaging.
In art, foil imaging is a printmaking technique made using the Iowa Foil Printer, developed by Virginia A. Myers from the commercial foil stamping process. This uses gold leaf and acrylic foil in the printmaking process.
Color.
Printmakers apply color to their prints in many different ways. Some coloring techniques include positive surface roll, negative surface roll, and A la poupée. Often color in printmaking that involves etching, screenprinting, woodcut, or linocut is applied by either using separate plates, blocks or screens or by using a reductionist approach. In multiple plate color techniques, a number of plates, screens or blocks are produced, each providing a different color. Each separate plate, screen, or block will be inked up in a different color and applied in a particular sequence to produce the entire picture. On average about 3 to 4 plates are produced, but there are occasions where a printmaker may use up to seven plates. Every application of another plate of color will interact with the color already applied to the paper, and this must be kept in mind when producing the separation of colors. The lightest colors are often applied first, and then darker colors successively until the darkest.
The reductionist approach to producing color is to start with a lino or wood block that is either blank or with a simple etching. Upon each printing of color the printmaker will then further cut into the lino or woodblock removing more material and then apply another color and reprint. Each successive removal of lino or wood from the block will expose the already printed color to the viewer of the print. Picasso is often cited as the inventor of reduction printmaking, although there is evidence of this method in use 25 years before Picasso's linocuts.
The subtractive color concept is also used in offset or digital print and is present in bitmap or vectorial software in CMYK or other color spaces.
Registration.
In printmaking processes requiring more than one application of ink or other medium, the problem exists as to how to line up properly areas of an image to receive ink in each application. The most obvious example of this would be a multi-color image in which each color is applied in a separate step. The lining up of the results of each step in a multistep printmaking process is called "registration." Proper registration results in the various components of an image being in their proper place. But, for artistic reasons, improper registration is not necessarily the ruination of an image. 
This can vary considerably from process to process. It generally involves placing the substrate, generally paper, in correct alignment with the printmaking element that will be supplying it with coloration.
Protective printmaking equipment.
Protective clothing is very important for printmakers who engage in etching and lithography (closed toed shoes and long pants). In the past, many printmakers did not live far past 35 to 40 years of age because of their exposure to various acids, solvents, particles, and vapors inherent in the printmaking process. 
Whereas in the past printmakers put their plates in and out of acid baths with their bare hands, today printmakers use rubber gloves. They also wear industrial respirators for protection from caustic vapors. Most acid baths are built with ventilation hoods above them.
Often, an emergency cold shower or eye wash station is nearby in case of acid spillages, as well as soda ash—which neutralizes most acids. Some printmakers wear goggles when dealing with acid.
Protective respirators and masks should have particle filters, particularly for aquatinting. As a part of the aquatinting process, a printmaker is often exposed to rosin powder. Rosin is a serious health hazard, especially to printmakers who, in the past, simply used to hold their breath using an aquatinting booth.
Barrier cream is often used upon a printmaker's hands both when putting them inside the protective gloves and if using their hands to wipe plates (wipe ink into the grooves of the plate and remove excess).
Sterile plasters and bandages should always be available to treat cuts and scrapes. For example, zinc plates can be extremely sharp when their edges are not beveled.
External links.
History of printmaking; glossaries
Printmaking organizations

</doc>
<doc id="42537" url="http://en.wikipedia.org/wiki?curid=42537" title="Curl (programming language)">
Curl (programming language)

Curl is a reflective object-oriented programming language for interactive web applications whose goal is to provide a smoother transition between formatting and programming. It makes it possible to embed complex objects in simple documents without needing to switch between programming languages or development platforms.The Curl implementation initially consisted of just an interpreter, but a compiler was later added.
Curl combines text markup (as in HTML), scripting (as in JavaScript), and heavy-duty computing (as in Java, C#, or C++) within one unified framework. It is used in a range of internal enterprise, B2B, and B2C applications.
Curl programs may be compiled into Curl applets, that are viewed using the Curl RTE, a runtime environment with a plugin for web browsers. Currently, it is supported on Microsoft Windows, Linux, and Mac OS X. Curl supports , which is a web deployed applet which runs on the user's desktop independent of a browser window much as in Silverlight 3 and Adobe AIR. 
Architecture.
The Curl language attempts to address a long-standing problem: the different building blocks that make up any modern web document most often require wildly different methods of implementation: different languages, different tools, different frameworks, often completely different teams. The final — and often most difficult — hurdle has been getting all of these blocks to communicate with each other in a consistent manner. Curl attempts to side-step these problems by providing a consistent syntactic and semantic interface at all levels of web content creation: from simple HTML to complex object-oriented programming. 
Curl is a markup language like HTML—that is, plain text is shown as text; at the same time, Curl includes an object-oriented programming language that supports multiple inheritance. Curl applications are not required to observe the separation of information, style, and behavior that HTML, Cascading Style Sheets (CSS), and JavaScript have imposed, although that style of programming can be used in Curl if desired.
While the Curl language can be used as an HTML replacement for presenting formatted text, its abilities range all the way to those of a compiled, strongly typed, object-oriented system programming language. Both the authoring (HTML-level) and programming constructs of Curl can be extended in user code. The language is designed so Curl applications can be compiled to native code of the client machine by a just-in-time compiler and run at high speed. Curl applets can also be written so that they will run off-line when disconnected from the network (). In fact, the is an application written in Curl.
Syntax.
A simple Curl applet for HelloWorld might be
This code will run if the user has at least one of the Curl versions 7.0 or 8.0 installed.
Curl provides both macros and text-procedures in addition to anonymous procedures and named methods.
An alternative using the text-procedure "paragraph" would be:
Recently this style of layout has been adopted by "builders" in the Groovy language for the JVM, but is also familiar to users of CSS or Tcl/Tk. Most features for web applications now implemented through combinations of JavaScript libraries + HTML + CSS are already found within the Curl language, including features usually associated with Prototype + script.aculo.us such as accordion panes.
Curl sets callbacks in the manner also adopted by Groovy:
Curl comments use the vertical bar in several variations. The simplest is as follows:
Curl as lightweight markup.
Because Curl provides both for user-defined text procedures and stylesheets, Curl can be used readily as domain-specific lightweight markup. A major advantage over plain text HTML markup is that the text encoding can be set as, e.g., utf-8, and text entered in a Unicode-enabled editor without any escaping of characters (like JavaScript, Curl is Unicode friendly.) A poetry example would be:
which can initially be implemented by defining the poem and stanza markup as paragraph text formats. Stanza could be further refined to include a hidden navigation anchor for page navigation using the Curl {destination} which is itself a text procedure.
The same markup can be used for different results, as one can style text to be visible in one context and invisible in another. Curl also permits top-level file inclusion so that a source text in markup can be included in different parent files. In education, for example, one could create a source file of test questions, and include it in both a student and a teacher version of the text.

</doc>
