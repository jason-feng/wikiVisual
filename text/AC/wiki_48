<doc id="32071" url="http://en.wikipedia.org/wiki?curid=32071" title="USS Liberty incident">
USS Liberty incident

The USS "Liberty" incident was an attack on a United States Navy technical research ship, USS "Liberty", by Israeli Air Force jet fighter aircraft and Israeli Navy motor torpedo boats, on 8 June 1967, during the Six-Day War. The combined air and sea attack killed 34 crew members (naval officers, seamen, two Marines, and one civilian), wounded 171 crew members, and severely damaged the ship. At the time, the ship was in international waters north of the Sinai Peninsula, about 25.5 nmi northwest from the Egyptian city of Arish.
Israel apologized for the attack, saying that the USS "Liberty" had been attacked in error after being mistaken for an Egyptian ship. Both the Israeli and U.S. governments conducted inquiries and issued reports that concluded the attack was a mistake due to Israeli confusion about the ship's identity, though others, including survivors of the attack, have rejected these conclusions and maintain that the attack was deliberate.
In May 1968, the Israeli government paid US$3,323,500 (US$ million 2015) in compensation to the families of the 34 men killed in the attack. In March 1969, Israel paid a further $3,566,457 to the men who had been wounded. On 18 December 1980, it agreed to pay $6 million as settlement for the final U.S. bill of $17,132,709 for material damage to the "Liberty" herself plus 13 years' interest.
USS "Liberty".
USS "Liberty" was originally the 7725 LT (light) civilian cargo vessel "Simmons Victory", a mass-produced, standard-design Victory Ship, the follow-on series to the famous Liberty Ships, which supplied the United Kingdom and Allied troops with cargo. it was acquired by the United States Navy, converted to an Auxiliary Technical Research Ship (AGTR), and began her first deployment in 1965, to waters off the west coast of Africa. it carried out several more operations during the next two years.
Attack on the "Liberty".
Events leading to the attack.
During the Six-Day War between Israel and several Arab nations, the United States of America maintained a neutral country status. Several days before the war began, the USS "Liberty" was ordered to proceed to the eastern Mediterranean area to perform a signals intelligence collection mission in international waters near the north coast of Sinai, Egypt. After the war erupted, due to concerns about her safety as she approached her patrol area, several messages were sent to "Liberty" to increase her allowable closest point of approach (CPA) to Egypt's and Israel's coasts from 12.5 and, respectively, to 20 and, and then later to 100 nmi for both countries. Unfortunately, due to ineffective message handling and routing, the CPA change messages were not received until after the attack.
According to Israeli sources, at the start of the war on 5 June, General Yitzhak Rabin (then IDF Chief of Staff) informed Commander Ernest Carl Castle, the American Naval Attaché in Tel Aviv, that Israel would defend its coast with every means at its disposal, including sinking unidentified ships. Also, he asked the U.S. to keep its ships away from Israel's shore or at least inform Israel of their exact position.
American sources said that no inquiry about ships in the area was made until after the "Liberty" attack ended. In a message sent from U.S. Secretary of State Dean Rusk to U.S. Ambassador Walworth Barbour, in Tel Aviv, Israel, Rusk asked for "urgent confirmation" of Israel's statement. Barbour responded: "No request for info on U.S. ships operating off Sinai was made until after "Liberty" incident." Further, Barbour stated: "Had Israelis made such an inquiry it would have been forwarded immediately to the chief of naval operations and other high naval commands and repeated to dept [Department of State]."
With the outbreak of war, Captain William L. McGonagle of the "Liberty" immediately asked Vice Admiral William I. Martin at the United States Sixth Fleet headquarters to send a destroyer to accompany the "Liberty" and serve as its armed escort and as an auxiliary communications center. The following day, 6 June, Admiral Martin replied: ""Liberty" is a clearly marked United States ship in international waters, not a participant in the conflict and not a reasonable subject for attack by any nation. Request denied." He promised, however, that in the unlikely event of an inadvertent attack, jet fighters from the Sixth Fleet would be overhead in ten minutes.
Meanwhile, on 6 June, at the United Nations, in response to United Arab Republic complaints that the United States was supporting Israel in the conflict, U.S. Ambassador Arthur Goldberg said to the Security Council that aircraft of the Sixth Fleet were several hundred miles from the conflict, indicating that elements of the Sixth Fleet itself were far from the conflict. When the statement was made this was the case, since "Liberty", now assigned to the Sixth Fleet, was in the central Mediterranean Sea, passing between Libya and Crete; but she would ultimately steam to about 13 nmi north of the Sinai Peninsula.
On the night of 7 June Washington time, early morning on 8 June, 01:10Z or 3:10 am local time, the Pentagon issued an order to Sixth Fleet headquarters to tell the "Liberty" to come no closer than 100 nmi to Israel, Syria, or the Sinai coast (Oren, p. 263).:5, 58 (Exhibit N)
According to the Naval Court of Inquiry:23 ff, 111 ff and National Security Agency official history, the order to withdraw was not sent on the radio frequency that USS "Liberty" monitored for her orders until 15:25 Zulu, several hours after the attack, due to a long series of administrative and message routing problems. The Navy said a large volume of unrelated high-precedence traffic, including intelligence intercepts related to the conflict, were being handled at the time; and that this combined with a shortage of qualified Radiomen contributed to delayed sending of the withdrawal message.:111 ff
Visual contact.
Official testimony combined with "Liberty's" deck log say that throughout the morning of the attack, 8 June, the ship was overflown, at various times and locations, by Israeli Air Force (IAF) aircraft. The primary aircraft type was the Nord Noratlas, in addition to two unidentified delta-wing jets at about 9:00 am Sinai time (GMT+2). "Liberty" crewmembers say that one of the Noratlas aircraft flew so close to "Liberty" that noise from its propellers rattled the ship's deck plating, and that the pilots and crewmembers waved to each other. It was later reported, based on information from Israel Defense Forces sources, that the over-flights were coincidental, and that the aircraft were hunting for Egyptian submarines previously spotted near the coast.
At about 5:45 am Sinai time, a ship-sighting report was initially received at Israeli Central Coastal Command (CCC) about "Liberty", identified by an aerial naval observer as "apparently a destroyer, sailing 70 miles west of Gaza." The vessel's location was marked on a CCC Control Table, using a red marker, indicating an unidentified vessel. At about 6:00 am, the aerial naval observer reported that the ship appeared like a U.S. Navy supply ship; the red marker was replaced with a green marker to indicate a neutral vessel, at about 9:00 am. At that same time, an Israeli jet fighter pilot reported that a ship 20 miles north of Arish had fired at his aircraft after he tried to identify the vessel. Israeli naval command dispatched two destroyers to investigate, but they were returned to their previous positions at 9:40 am after doubts emerged during the pilot's debriefing. After the naval observer's Noratlas landed and he was debriefed, the ship he saw was further identified as the USS "Liberty", based on its "GTR-5" hull markings. USS "Liberty's" marker was removed from CCC's Control Table at 11:00 am, due to its positional information being considered stale.
At 11:24 am, Israeli Chief of Naval Operations received a report that Arish was being shelled from the sea. An inquiry into the source of the report was ordered to determine its validity. The report came from an Air Support Officer in Arish. Additionally, at 11:27 am Israeli Supreme Command Head of Operations received a report stating that a ship had been shelling Arish, but the shells had fallen short. (Investigative journalist James Bamford points out that "Liberty" had only four .50 caliber machine guns mounted on her decks and, thus, could not have shelled the coast.
) The Head of Operations ordered that the report be verified, and determine whether or not Israeli Navy vessels were off the coast of Arish. At 11:45 am, another report arrived at Supreme Command saying two ships were approaching the Arish coast.
The shelling and ships reports were passed from Supreme Command to Fleet Operations Control Center. The Chief of Naval Operations took them seriously, and at 12:05 pm torpedo boat Division 914 was ordered to patrol in the direction of Arish.
Division 914, codenamed "Pagoda", was under the command of Commander Moshe Oren. It consisted of three torpedo boats numbered: T-203, T-204 and T-206. At 12:15 pm, Division 914 received orders to patrol a position 20 miles north of Arish. As Commander Oren headed toward Arish, he was informed by Naval Operations of the reported shelling of Arish and told that IAF aircraft would be dispatched to the area after the target had been detected.
Chief of Staff Yitzhak Rabin was concerned that the supposed Egyptian shelling was the prelude to an amphibious landing that could outflank Israeli forces. Rabin reiterated the standing order to sink any unidentified ships in the area, but advised caution, as Soviet vessels were reportedly operating nearby.
At 1:41 pm, the torpedo boats detected an unknown vessel 20 miles northwest of Arish and 14 miles off the coast of Bardawil. The ship's speed was estimated on their radars. The Combat Information Center officer on T-204, Ensign Aharon Yifrah, reported to the boat's captain, Commander Moshe Oren, that the target had been detected at a range of 22 miles, that her speed had been tracked for a few minutes, after which he had determined that the target was moving westward at a speed of 30 knots. These data were forwarded to the Fleet Operations Control Center.
The speed of the target was significant because it indicated that the target was a combat vessel. Moreover, Israeli forces had standing orders to fire on any unknown vessels sailing in the area at over 20 knots, a speed which, at the time, could only be attained by warships. The Chief of Naval Operations asked the torpedo boats to double-check their calculations. Yifrah twice recalculated and confirmed his assessment. A few minutes later, Commander Oren reported that the target, now 17 miles from his position, was moving at a speed of 28 knots on a different heading. Bamford, however, points out that the "Liberty"'s top speed was far below 28 knots. His sources say that at the time of the attack the "Liberty" was following its signal-intercept mission course along the northern Sinai coast, at about 5 knots speed.
The data on the ship's speed, together with its direction, indicated that it was an Egyptian destroyer fleeing toward port after shelling Arish. The torpedo boats gave chase, but did not expect to overtake their target before it reached Egypt. Commander Oren requested that the Israeli Air Force dispatch aircraft to intercept. At 1:48 pm, the Chief of Naval Operations requested dispatch of fighter aircraft to the ship's location.
The IAF dispatched two Mirage III fighter jets that arrived at "Liberty" at about 2:00 pm. The formation leader, Captain Iftach Spector, attempted to identify the ship. He communicated via radio to one of the torpedo boats his observation that the ship appeared like a military ship with one smokestack and one mast. Also, he communicated, in effect, that the ship appeared to him like a destroyer or another type of small ship. In a post-attack statement, the pilots said they saw no distinguishable markings or flag on the ship.
At this point, a recorded exchange took place between a command headquarters weapons systems officer, one of the air controllers, and the chief air controller questioning a possible American presence. Immediately after the exchange, at 1:57 pm, the chief air controller, Lieutenant-Colonel Shmuel Kislev, cleared the Mirages to attack.
Air and sea attacks.
After being cleared to attack, the Mirages dived on the ship and attacked with 30-mm cannons and rockets. The attack came a few minutes after the crew completed a chemical attack drill, with Captain McGonagle on the command bridge. The crew was in "stand-down mode", with their helmets and life jackets removed, except battle readiness "modified condition three" was set which meant that the ship's four .50 caliber machine guns were manned and ammunition ready for loading and firing. Eight crewmen were either killed immediately or died later, and 75 were wounded. Among the wounded was McGonagle, who was hit in the right thigh and arm. During the attack, antennas were severed, gas drums caught fire, and the ship's flag was knocked down. McGonagle sent an urgent request for help to the Sixth Fleet, "Under attack by unidentified jet aircraft, require immediate assistance."
The Mirages left after expending their ammunition, and were replaced by two Dassault Mysteres armed with napalm bombs. The Mysteres released their payloads over the ship and strafed it with their cannons. Much of the ship's superstructure caught fire. The Mysteres were readying to attack again when the Israeli Navy, alerted by the absence of return fire, warned Kislev that the target could be Israeli. Kislev told the pilots not to attack if there was any doubt about identification, and the Israeli Navy quickly contacted all of its vessels in the area. The Israeli Navy found that none of its vessels were under fire, and the aircraft were cleared to attack. However, Kislev was still disturbed by a lack of return fire, and requested one last attempt to identify the ship. Captain Yossi Zuk, leader of the Mystere formation, made an attempt at identification while strafing the ship. He reported seeing no flag, but saw the ship's GTR-5 marking. Kislev immediately ordered the attack stopped. Kislev guessed that the ship was American.
The fact that the ship had Latin alphabet markings led Chief of Staff Rabin to fear that the ship was Soviet. Though Egyptian warships were known to disguise their identities with Western markings, they usually displayed Arabic letters and numbers only. Rabin ordered the torpedo boats to remain at a safe distance from the ship, and sent in two Hornet (Aérospatiale Super Frelon) helicopters to search for survivors. These radio communications were recorded by Israel. The order also was recorded in the torpedo boat's log, although Commander Oren alleged not to have received it. The order to cease fire was given at 2:20 pm, twenty-four minutes before the torpedo boats arrived at the "Liberty"'s position. At 2:35 pm, "Liberty" was hit by a torpedo launched from one of the torpedo boats.
During the interval, crewmen aboard the "Liberty" hoisted a large American flag to be clearly identified. During the early part of the air attack and before the torpedo boats were visually sighted, "Liberty" sent a distress message that was received by Sixth Fleet aircraft carrier USS "Saratoga". Aircraft carrier USS "America" dispatched eight aircraft. The carrier had been in the middle of strategic exercises. Vice-Admiral William I. Martin recalled the aircraft minutes later.
McGonagle testified at the naval court of inquiry that during "the latter moments of the air attack, it was noted that three high speed boats were approaching the ship from the northeast on a relative bearing of approximately 135 [degrees] at a distance of about 15 [nautical] miles. The ship at the time was still on [westward] course 283 [degrees] true, speed unknown, but believed to be in excess of five knots.":38 McGonagle testified that he "believed that the time of initial sighting of the torpedo boats ... was about 14:20 [2:20 pm]", and that the "boats appeared to be in a wedge type formation with the center boat the lead point of the wedge. Estimated speed of the boats was about 27 to," and that it "appeared that they were approaching the ship in a torpedo launch attitude.":38
When the torpedo boats arrived, Commander Oren could see that the ship could not be the destroyer that had supposedly shelled Arish or any ship capable of 30 kn speed. Oren believed it was a slower-moving vessel that had either serviced the destroyer or evacuated enemy soldiers from the beach. He ordered the squadron not to attack pending better identification "although this was difficult due to the billowing clouds of smoke that enveloped the vessel; only her bow, part of her bridge and the tip of her mast could be discerned." At 6,000 meters, T-204 paused and signalled "AA" – "identify yourself." Due to damaged equipment, McGonagle could only reply with "AA" using a handheld Aldis lamp. Oren recalled receiving a similar response from the "Ibrahim el Awal", an Egyptian destroyer captured by Israel during the Suez Crisis, and was convinced that he was facing an enemy ship.
He consulted an Israeli identification guide to Arab fleets and concluded the ship was the Egyptian supply ship "El Quseir", based on observing its deckline, midship bridge and smokestack. The captain of boat T203 reached the same conclusion independently. The boats organized into battle formation, but did not attack.
As the torpedo boats rapidly approached, Captain McGonagle ordered a sailor to proceed to machine gun Mount 51 and open fire.:38 However, he noticed that the boats appeared to be flying an Israeli flag, and "realized that there was a possibility of the aircraft having been Israeli and the attack had been conducted in error.":39 Captain McGonagle ordered the man at gun mount 51 to hold fire, but a short burst was fired at the torpedo boats before the man was able to understand the order.:39 McGonagle observed that machine gun Mount 53 began firing at the center torpedo boat at about the same time gun mount 51 fired, and that its fire was "extremely effective and blanketed the area and the center torpedo boat.":39 Machine gun mount 53 was located on the starboard amidships side, behind the pilot house.:16 McGonagle could not see or "get to mount 53 from the starboard wing of the bridge.":39 So, he "sent Mr. Lucas around the port side of the bridge, around to the skylights, to see if he could tell [Seaman] Quintero, whom [he] believed to be the gunner on Machine gun 53, to hold fire.":39
Ensign Lucas "reported back in a few minutes in effect that he saw no one at mount 53.":39 Lucas, who had left the command bridge during the air attack and returned to assist Captain McGonagle immediately before a torpedo hit the ship,:14 believed that the gunfire sound was likely from ammunition cooking off, due to a nearby fire.:16 Prior to this time, after a torpedo hit the ship, Lucas had granted a request from Quintero to fire at the torpedo boats before heat from a nearby fire chased him from gun mount 53.:26,27 (McGonagle later testified, at the Court of Inquiry, that this was likely the "extremely effective" firing event he had observed.:49)
After coming under fire, Commander Oren repeatedly requested permission from naval headquarters to return fire, and chief naval controller Izzy Rahav finally approved. Shelling by the torpedo boats killed "Liberty's" helmsman. The torpedo boats then launched five torpedoes at the "Liberty". At 1235Z (2:35 local time) a torpedo hit "Liberty" on the starboard side forward of the superstructure, creating a 40 ft wide hole in what had been a former cargo hold converted to the ship's research spaces and killing 25 servicemen, almost all of them from the intelligence section, and wounding dozens. It has been said the torpedo hit a major hull frame that absorbed much of the energy; crew members reported that if the torpedo had missed the frame the "Liberty" would have split in two. Russian linguist and U.S. Marine Corps Staff Sergeant Bryce Lockwood later commented: "I would never deny that it was God that kept the "Liberty" afloat!". The other four torpedoes missed the ship.
The torpedo boats then closed in and strafed the ship's hull with their cannons and machine guns. According to some crewmen, the torpedo boats fired at damage control parties and sailors preparing life rafts for launch. (See disputed details below.) A life raft which floated from the ship was picked up by T-203 and found to bear US Navy markings. T-204 then circled the "Liberty", and Oren spotted the designation GTR-5, but saw no flag. It took until 3:30 pm to establish the ship's identity. Shortly before the "Liberty"'s identity was confirmed, the "Saratoga" launched eight aircraft armed with conventional weapons towards the "Liberty". After the ship's identity was confirmed, the General Staff was notified and an apology was sent to naval attaché Castle. The aircraft approaching the "Liberty" were recalled to the "Saratoga".
Aftermath of the attack.
According to transcripts of intercepted radio communications, published by the U.S. National Security Agency (NSA), at about 2:30 pm, near the beginning of the torpedo boat attack, two IAF helicopters were dispatched to "Liberty"'s location. The helicopters arrived at about 3:10 pm, about 35 minutes after a torpedo hit the ship. After arriving, one of the helicopter pilots was asked, by his ground-based controller, to verify that the ship was flying an American flag. The helicopters conducted a brief search for crew members of the ship who may have fallen overboard during the air attack. No one was found. The helicopters left the ship at about 3:20 pm.
At about 4 pm, two hours after the attack began, Israel informed the U.S. embassy in Tel Aviv that its military forces had mistakenly attacked a U.S. Navy ship. When the ship was "confirmed to be American" the torpedo boats returned at about 4:40 pm to offer help; it was refused by the "Liberty". Later, Israel provided a helicopter to fly U.S. naval attaché Commander Castle to the ship. (pp. 32,34)
In Washington, President Lyndon B. Johnson had received word from the Joint Chiefs of Staff that the "Liberty" had been torpedoed by an unknown vessel at 9:50 am eastern time. Johnson assumed that the Soviets were involved, and hotlined Moscow with news of the attack and the dispatch of jets from the "Saratoga". He chose not to make any public statements and delegated this task to Phil G. Goulding, who was an Assistant Secretary of Defense for Public Affairs at a time.
Soon afterward, the Israelis said that they had mistakenly attacked the ship. The Johnson administration conveyed "strong dismay" to Israeli ambassador Avraham Harman. Meanwhile, apologies were soon sent by Israeli Prime Minister Levi Eshkol, Foreign Minister Abba Eban, and chargé d'affaires Efraim Evron. Within 48 hours, Israel offered to compensate the victims and their families.
Though the "Liberty" was severely damaged, with a 39 ft wide by 24 ft high (12 m x 7.3 m) hole and a twisted keel, her crew kept her afloat, and she was able to leave the area under her own power. The "Liberty" was later met by the destroyers USS "Davis" and USS "Massey", and the cruiser USS "Little Rock". Medical personnel were transferred to the "Liberty", and it was escorted to Malta, where it was given interim repairs. After these were completed in July 1967, "Liberty" returned to the U.S. She was decommissioned in June 1968 and struck from the Naval Vessel Register. "Liberty" was transferred to United States Maritime Administration (MARAD) in December 1970 and sold for scrap in 1973.
From the start, the response to Israeli statements of mistaken identity ranged between frank disbelief and unquestioning acceptance within the administration in Washington. A communication to the Israeli Ambassador on 10 June, by Secretary Rusk stated, among other things: "At the time of the attack, the "USS Liberty" was flying the American flag and its identification was clearly indicated in large white letters and numerals on its hull. ... Experience demonstrates that both the flag and the identification number of the vessel were readily visible from the air... Accordingly, there is every reason to believe that the "USS Liberty" was identified, or at least her nationality determined, by Israeli aircraft approximately one hour before the attack. ... The subsequent attack by the torpedo boats, substantially after the vessel was or should have been identified by Israeli military forces, manifests the same reckless disregard for human life."
George Lenczowski notes: "It was significant that, in contrast to his secretary of state, President Johnson fully accepted the Israeli version of the tragic incident." He notes that Johnson himself only included one small paragraph about the "Liberty" in his autobiography, in which he accepted the Israeli explanation of "error", but also minimized the whole affair and distorted the actual number of dead and wounded, by lowering them from 34 to 10 and 171 to 100, respectively. Lenczowski further states: “It seems Johnson was more interested in avoiding a possible confrontation with the Soviet Union, ...than in restraining Israel.”
McGonagle received the Medal of Honor, the highest U.S. medal, for his actions. The Medal of Honor is generally presented by the President of the United States in the White House, but this time it was awarded at the Washington Navy Yard by the Secretary of the Navy in an unpublicized ceremony, breaking with established tradition.
Other "Liberty" sailors received decorations for their actions during and after the attack, but most of the award citations omitted mention of Israel as the perpetrator. In 2009, however, a Silver Star awarded to crewmember Terry Halbardier, who braved machine-gun and cannon fire to repair a damaged antenna that restored the ship's communications, in the award citation named Israel as the attacker.
Investigations of the attack.
U.S. government investigations.
American inquiries, memoranda, records of testimony, and various reports involving or mentioning the "Liberty" attack include, but are not limited to, the following:
The U.S. Naval Court of Inquiry record contains testimony by fourteen "Liberty" crew members and five subject matter experts; exhibits of attack damage photographs, various messages and memorandums; and findings of fact. The testimony record reveals "a shallow investigation, plagued by myriad disagreements between the captain and his crew." As to culpability, ""It was not the responsibility of the court to rule on the culpability of the attackers, and no evidence was heard from the attacking nation", the court concluded that "available evidence combines to indicate ... (that the attack was) a case of mistaken identity."" Additionally, the Court found that "heroism displayed by the Commanding Officer, officers and men of the "Liberty" was exceptional."
The Joint Chief of Staff's Report contains findings of fact related only to communication system failures associated with the "Liberty" attack. It was not concerned with matters of culpability, nor does it contain statements thereof.
The CIA Memoranda consist of two documents: one dated June 13, 1967, and the other dated June 21, 1967. The June 13 memorandum is an "account of circumstances of the attack ... compiled from all available sources." The June 21 memorandum is a point-by-point analysis of Israeli inquiry findings of fact. It concludes: "The attack was not made in malice toward the U.S. and was by mistake, but the failure of the IDF Headquarters and the attacking aircraft to identify the "Liberty" and the subsequent attack by torpedo boats were both incongruous and indicative of gross negligence."
The Clark Clifford Report consists of a review of "all available information on the subject" and "deals with the question of Israeli culpability", according to its transmittal memorandum. The report concludes: "The unprovoked attack on the "Liberty" constitutes a flagrant act of gross negligence for which the Israeli Government should be held completely responsible, and the Israeli military personnel involved should be punished."
The Senate Foreign Relations Committee Testimony contains, as an aside matter during hearings concerning a foreign aid authorization bill, questions and statements from several senators and responses from then Secretary of Defense, Robert McNamara, about the "Liberty" attack. For the most part, the senators were dismayed about the attack, as expressed by Senator Bourke B. Hickenlooper: "From what I have read I can't tolerate for one minute that this [attack] was an accident." Also, there was concern about obtaining more information about the attack, as expressed by Committee chairman J. William Fulbright: "We asked for [the attack investigation report] about two weeks ago and have not received it yet from Secretary Rusk. ... By the time we get to it we will be on some other subject." Secretary McNamara promised fast delivery of the investigation report ("... you will have it in four hours."), and concluded his remarks by saying: "I simply want to emphasize that the investigative report does not show any evidence of a conscious intent to attack a U.S. vessel."
The House Armed Services Committee investigation report is titled, "Review of Department of Defense Worldwide Communications". It was not an investigation focused on the "Liberty" attack; although, the committee's report contains a section that describes communications flow involved with the "Liberty" incident.
The NSA History Report is, as its name connotes, a historical report that cited the U.S. Naval Court of Inquiry record, various military and government messages and memorandum, and personal interviews for its content. The report ends with a section entitled, "Unanswered Questions", and provides no conclusion regarding culpability.
The "Liberty" Veterans Association (composed of veterans from the ship) states that U.S. congressional investigations and other U.S. investigations were not actually investigations into the attack, but rather reports using evidence only from the U.S. Navy Court of Inquiry, or investigations unrelated to culpability that involved issues such as communications. In their view, the U.S. Navy Court of Inquiry is the only actual investigation on the incident to date. They say it was hastily conducted, in only 10 days, even though the court's president, Rear Admiral Isaac Kidd, said that it would take six months to conduct properly. The inquiry's terms of reference were limited to whether any shortcomings on the part of the Liberty's crew had contributed to the injuries and deaths that resulted from the attack. According to the Navy Court of Inquiry's record of proceedings, four days were spent hearing testimony: two days for fourteen survivors of the attack and several U.S. Navy expert witnesses, and two partial days for two expert U.S. Navy witnesses. No testimony was heard from Israeli personnel involved.
The National Archives in College Park, Maryland includes in its files on casualties from the "Liberty" copies of the original telegrams the Navy sent out to family members. The telegrams called the attack accidental. The telegrams were sent out June 9, the day before the Navy Court of Inquiry convened.
Israeli government investigations.
Two subsequent Israeli inquiry reports and an historical report concluded the attack was conducted because "Liberty" was confused with an Egyptian vessel and because of failures in communications between Israel and the U.S. The three Israeli reports were:
In the historical report, it was acknowledged that IDF naval headquarters knew at least three hours before the attack that the ship was "an electromagnetic audio-surveillance ship of the U.S. Navy" but concluded that this information had simply "gotten lost, never passed along to the ground controllers who directed the air attack nor to the crews of the three Israeli torpedo boats."
The Israeli government said that three crucial errors were made: the refreshing of the status board (removing the ship's classification as American, so that the later shift did not see it identified), the erroneous identification of the ship as an Egyptian vessel, and the lack of notification from the returning aircraft informing Israeli headquarters of markings on the front of the hull (markings that would not be found on an Egyptian ship). As a common root of these problems, Israel blamed the combination of alarm and fatigue experienced by the Israeli forces at that point of the war when pilots were severely overworked.
After conducting his own fact-finding inquiry and reviewing evidence, Judge Yerushalmi's decision was: "I have not discovered any deviation from the standard of reasonable conduct which would justify committal of anyone for trial." In other words, he found no negligence by any IDF member associated with the attack.
Ongoing controversy and unresolved questions.
Some intelligence and military officials dispute Israel's explanation.
Dean Rusk, U.S. Secretary of State at the time of the incident, wrote: I was never satisfied with the Israeli explanation. Their sustained attack to disable and sink "Liberty" precluded an assault by accident or some trigger-happy local commander. Through diplomatic channels we refused to accept their explanations. I didn't believe them then, and I don't believe them to this day. The attack was outrageous.
Retired naval Lieutenant Commander James Ennes, a junior officer (and off-going Officer of the Deck) on "Liberty"‍ '​s bridge at the time of the attack, authored a book titled "Assault on the Liberty" describing the incident during the Six Day War in June 1967 and saying, among other things, that the attack was deliberate. Ennes and Joe Meadors, also survivors of the attack, run a website about the incident. Meadors states that the classification of the attack as deliberate is the official policy of the USS "Liberty" Veterans Association, to which survivors and other former crew members belong. Other survivors run several additional websites. Citing Ennes's book, Lenczowski notes: "Liberty"‍ '​s personnel received firm orders not to say anything to anybody about the attack, and the naval inquiry was conducted in such a way as to earn it the name of "coverup".
In 2002, Captain Ward Boston, JAGC, U.S. Navy, senior counsel for the Court of Inquiry, said that the Court of Inquiry's findings were intended to cover up what was a deliberate attack by Israel on a ship that the Israelis knew to be American. In 2004, in response to the publication of A. Jay Cristol's book "The Liberty Incident", which Boston said was an "insidious attempt to whitewash the facts", Boston prepared and signed an affidavit in which he said that Admiral Kidd had told him that the government ordered Kidd to falsely report that the attack was a mistake, and that Boston and Kidd both believed the attack was deliberate. On the issue Boston wrote, in part: The evidence was clear. Both Admiral Kidd and I believed with certainty that this attack, which killed 34 American sailors and injured 172 others, was a deliberate effort to sink an American ship and murder its entire crew. Each evening, after hearing testimony all day, we often spoke our private thoughts concerning what we had seen and heard. I recall Admiral Kidd repeatedly referring to the Israeli forces responsible for the attack as 'murderous bastards.' It was our shared belief, based on the documentary evidence and testimony we received first hand, that the Israeli attack was planned and deliberate, and could not possibly have been an accident.
Cristol wrote about Boston's professional qualifications and integrity, on page 149 of his book: Boston brought two special assets in addition to his skill as a Navy lawyer. He had been a naval aviator in World War II and therefore had insight beyond that of one qualified only in the law. Also, Kidd knew him as a man of integrity. On an earlier matter Boston had been willing to bump heads with Kidd when Boston felt it was more important to do the right thing than to curry favor with the senior who would write his fitness report.
Cristol believes that Boston is not telling the truth about Kidd's views and any pressure from the U.S. government. Cristol, who also served as an officer of the U.S. Navy's Judge Advocate General, suggests that Boston was responsible in part for the original conclusions of the Court of Inquiry and, that by later declaring that they were false, Boston has admitted to "lying under oath." Cristol also notes that Boston's statements about pressure on Kidd were hearsay, and that Kidd was not alive to confirm or deny them. He also notes that Boston did not maintain, prior to his affidavit and comments related to it, that Kidd spoke of such instructions to Boston or to others. Finally, Cristol provides a handwritten 1991 letter from Admiral Kidd that, according to Cristol, "suggest that Ward Boston has either a faulty memory or a vivid imagination".
The Anti-Defamation League supports Cristol's opinion: ... according to his own account, Boston's evidence of a cover-up derives not from his own part in the investigation but solely on alleged conversations with Admiral Kidd, who purportedly told him he was forced to find that the attack was unintentional. Kidd died in 1999 and there is no way to verify Boston's statements. However, Cristol argues that the 'documentary record' strongly indicated that Kidd 'supported the validity of the findings of the Court of Inquiry to his dying day.'
According to James Ennes, however, Admiral Kidd urged Ennes and his group to keep pressing for an open congressional probe.
The following arguments, found in official reports or other sources, were published to support that the attack was due to mistaken identity:
Several books and the BBC documentary "USS "Liberty": Dead in the Water" argued that "Liberty" was attacked in order to prevent the U.S. from knowing about the forthcoming attack in the Golan Heights, which would violate a cease-fire to which Israel's government had agreed. However, Syria did not accept the cease fire until 9 June, after the attack on "Liberty." Russian author Joseph Daichman, in his book "History of the Mossad", states Israel was justified in attacking the "Liberty". Israel knew that American radio signals were intercepted by the Soviet Union and that the Soviets would certainly inform Egypt of the fact that, by moving troops to the Golan Heights, Israel had left the Egyptian border undefended.
Lenczowski notes that while the Israeli decision to "attack and destroy" the ship "may appear puzzling", the explanation seems to be found in "Liberty"‍ '​s nature and its task to monitor communications on both sides in the war zone. He writes, "Israel clearly did not want the U.S. government to know too much about its dispositions for attacking Syria, initially planned for 8 June, but postponed for 24 hours. It should be pointed out that the attack on "Liberty" occurred on 8 June, whereas on 9 June at 3 am, Syria announced its acceptance of the cease-fire. Despite this, at 7 am, that is, four hours later, Israel's minister of defense, Moshe Dayan, "gave the order to go into action against Syria." He further writes that timely knowledge of this decision and preparatory moves toward it "might have frustrated Israeli designs for the conquest of Syria's Golan Heights" and, in the sense of Ennes's accusations, provides "a plausible thesis that Israel deliberately decided to incapacitate the signals-collecting American ship and leave no one alive to tell the story of the attack."
U.S. Ambassador to Israel, Barbour, had reported on the day of the "Liberty" attack that he "would not be surprised" by an Israeli attack on Syria, and the IDF Intelligence chief told a White House aide then in Israel that "there still remained the Syria problem and perhaps it would be necessary to give Syria a blow."
The 1981 book "Weapons" by Russell Warren Howe says that "Liberty" was accompanied by the Polaris ballistic missile-armed "Lafayette"-class submarine USS "Andrew Jackson", which filmed the entire episode through its periscope but was unable to provide assistance. According to Howe: "Two hundred feet below the ship, on a parallel course, was its 'shadow'—the Polaris strategic submarine "Andrew Jackson", whose job was to take out all the Israeli long-range missile sites in the Negev if Tel Aviv decided to attack Cairo, Damascus or Baghdad. This was in order that Moscow would not have to perform this task itself and thus trigger World War Three."
James Bamford, a former ABC News producer, in his 2001 book "Body of Secrets", says Israel deliberately attacked "Liberty" to prevent the discovery of what he described as war crimes, including the killing of Egyptian prisoners of war by the IDF that he alleges was taking place around the same time in the nearby town of El-Arish. However according to CAMERA his claim that 400 were executed has been cast into doubt since reporters present in the town claimed that there had in fact been a large battle and this was the main cause of casualties. Bamford also claimed that eyewitness Gabi Bron had claimed he saw 150 people executed by Israeli troops at El-Arish. However Gabi Bron claimed to have only seen 5 people executed by Israeli troops.
The press release for the BBC documentary film "Dead in the Water" states that new recorded and other evidence suggests the attack was a "daring ploy by Israel to fake an Egyptian attack" to give America a reason to enter the war against Egypt. Convinced that the attack was real, President of the United States Lyndon B. Johnson launched allegedly nuclear-armed aircraft targeted against Cairo from a U.S. aircraft carrier in the Mediterranean. The aircraft were recalled only just in time, when it was clear the "Liberty" had not sunk and that Israel had carried out the attack. An information source for the aircraft being nuclear-armed, James Ennes, later stated:
Although America could not send conventionally armed jets, reports still come in that four jet bombers were catapulted from the carrier America with nuclear bombs aboard. Even today there is no official confirmation of that launch and much high-level denial. A nuclear launch has been strongly denied by Secretary McNamara, Admiral Martin (now deceased), Admiral Geis (deceased), Admiral Moorer, and America’s skipper, Admiral David Engen (deceased) and others. Yet eyewitness reports persist. Clearly no such launch could have been intended for offensive purposes. Surely nuclear weapons would not have been used in defense of the USS Liberty.
It is clear that I was mistaken about the aircraft involved, as F4s do not carry nuclear weapons. Others tell me that the aircraft that were launched carried Bullpup missiles, which might easily be mistaken for nuclear bombs. And we learned much later that the USS America was involved in a nuclear weapons loading drill at the very time the ship learned of the attack on the Liberty and that this drill is one factor that delayed America's response to our call for help. It is also possible that those were the weapons seen by our sources.
Also confusing this issue is an oral history report from the American Embassy in Cairo, now in the LBJ Library, which notes that the Embassy received an urgent message from Washington warning that Cairo was about to be bombed by US forces, presumably in mistaken retaliation for the USS Liberty attack. That strange message was never explained or cancelled. 
The video also provides hearsay evidence of a covert alliance of U.S. and Israel intelligence agencies.
Admiral Thomas H. Moorer, former Chairman of the Joint Chiefs of Staff and a critic of the official United States Government version of events, chaired a non-governmental investigation into the attack on the USS "Liberty" in 2003. The committee, which included former U.S. ambassador to Saudi Arabia James E. Akins, held Israel to be culpable and suggested several theories for Israel's possible motives, including the desire to blame Egypt and bring the U.S. into the Six Day War.
NSA tapes and recent developments.
Within an hour of learning that the "Liberty" had been torpedoed, the director of NSA, LTG Marshall S. Carter, sent a message to all intercept sites requesting a special search of all communications that might reflect the attack or reaction. No communications were available. However, one of the airborne platforms, a U.S. Navy EC-121 aircraft that flew near the attacks from 2:30 pm to 3:27 pm, Sinai time (1230 to 1327 Z), had collected voice conversations between two Israeli helicopter pilots and the control tower at Hatzor Airfield following the attack on the "Liberty".
On 2 July 2003, the National Security Agency released copies of the recordings made by the EC-121 and the resultant translations and summaries. These revelations were elicited as part of a Freedom of Information Act lawsuit by Florida bankruptcy judge and retired naval aviator Jay Cristol. Two linguists who were aboard the EC-121 when the recordings were made, however, said separately that at least two additional tapes were made that have been excluded from the NSA releases up to and including a 8 June 2007, release.
English transcripts of the released tapes indicate that Israel still spoke of hitting an Egyptian supply ship even after the attack had stopped. After the attack, the rescue helicopters are heard relaying several urgent requests that the rescuers ask the first survivor pulled out of the water what his nationality is, and discussing whether the survivors from the attacked ship will speak Arabic.
A summary report of the NSA-translated tapes indicates that at 1234Z Hatzor air control began directing two Israeli Air Force helicopters to an Egyptian warship, to rescue its crew: "This ship has now been identified as Egyptian." The helicopters arrived near the ship at about 1303Z: "I see a big vessel, near it are three small vessels..." At 1308Z, Hatzor air control indicated concern about the nationality of the ship's crew: "The first matter to clarify is to find out what their nationality is." At 1310Z, one of the helicopter pilots asked the nearby torpedo boats' Division Commander about the meaning of the ship's hull number: "GTR5 is written on it. Does this mean something?" The response was: "Negative, it doesn't mean anything." At 1312Z, one of the helicopter pilots was asked by air control: "Did you clearly identify an American flag?" No answer appears in the transcript, but the air controller then says: "We request that you make another pass and check once more if this is really an American flag." Again, no response appears in the transcript. At about 1314Z, the helicopters were directed to return home.
The NSA reported that there had been no radio intercepts of the attack made by the "Liberty" herself, nor had there been any radio intercepts made by the U.S. submarine USS "Amberjack".
On 10 October 2003, "The Jerusalem Post" ran an interview with Yiftah Spector, one of the pilots who participated in the attack, and thought to be the lead pilot of the first wave of aircraft. Spector said the ship was assumed to be Egyptian, stating that: "I circled it twice and it did not fire on me. My assumption was that it was likely to open fire at me and nevertheless I slowed down and I looked and there was positively no flag." The interview also contains the transcripts of the Israeli communications about the "Liberty". The journalist who transcribed the tapes for that article, Arieh O'Sullivan, later confirmed that "the Israeli Air Force tapes he listened to contained blank spaces."
The "Liberty"‍ '​s survivors contradict Spector. According to subsequently declassified NSA documents: "Every official interview of numerous "Liberty" crewmen gave consistent evidence that indeed the "Liberty" was flying an American flag—and, further, the weather conditions were ideal to ensure its easy observance and identification."
On 8 June 2005, the USS "Liberty" Veterans Association filed a "Report of War Crimes Committed Against the U.S. Military, June 8, 1967" with the Department of Defense (DoD). They say requires the Department of Defense to conduct a thorough investigation of the allegations contained in their report. DoD has responded that a new investigation will not be conducted since a Navy Court of Inquiry already investigated the facts and circumstances surrounding the attack.
As of 2006, the National Security Agency (NSA) has yet to declassify "boxes and boxes" of "Liberty" documents. Numerous requests under both declassification directives and the Freedom of Information Act are pending in various agencies including the NSA, Central Intelligence Agency, and Defense Intelligence Agency. "On 8 June 2007, the National Security Agency released hundreds of additional declassified documents
on the Israeli attack on the USS "Liberty", a communications interception vessel, on 8 June 1967."
On 2 October 2007, "The Chicago Tribune" published a special report into the attack, containing numerous previously unreported quotes from former military personnel with first-hand knowledge of the incident. Many of these quotes directly contradict the U.S. National Security Agency's position that it never intercepted the communications of the attacking Israeli pilots, saying that not only did transcripts of those communications exist, but also that it showed the Israelis knew they were attacking an American naval vessel.
Two diplomatic cables written by Avraham Harman, Israel's ambassador in Washington, to Abba Eban Israel's minister of foreign affairs, have been declassified by Israel and obtained from the Israel State Archive. The first cable, sent five days after the attack, informs Eban that a U.S. informant told him (Harman) that there was "clear proof that from a certain stage the pilot discovered the identity of the ship and continued the attack anyway." The second cable, sent three days later, added that the White House is "very angry" because "the Americans probably have findings showing that our pilots indeed knew that the ship was American."
Documents of the Israeli General Staff meetings, declassified in October 2008, show no discussion of a planned attack on an American ship.
On 30 October 2014, Al Jazeera English broadcast a documentary film containing recent first-hand accounts by several survivors of the incident.
Details in dispute.
Many of the events surrounding the attack are the subject of controversy:
External links.
Sources saying attack was deliberate.
Survivors of the attack
Sources other than survivors

</doc>
<doc id="32073" url="http://en.wikipedia.org/wiki?curid=32073" title="USB">
USB

Universal Serial Bus (USB) is an industry standard developed in the mid-1990s that defines the cables, connectors and communications protocols used in a bus for connection, communication, and power supply between computers and electronic devices.
USB was designed to standardize the connection of computer peripherals (including keyboards, pointing devices, digital cameras, printers, portable media players, disk drives and network adapters) to personal computers, both to communicate and to supply electric power. It has become commonplace on other devices, such as smartphones, PDAs and video game consoles. USB has effectively replaced a variety of earlier interfaces, such as serial and parallel ports, as well as separate power chargers for portable devices.
Overview.
In general, there are three basic kinds or sizes related to the USB connectors and types of established connection: the older "standard" size, in its USB 1.1/2.0 and USB 3.0 variants (for example, on USB flash drives), the "mini" size (primarily for the B connector end, such as on many cameras), and the "micro" size, in its USB 1.1/2.0 and USB 3.0 variants (for example, on most modern cellphones).
Unlike other data cables (Ethernet, HDMI etc.), each end of a USB cable uses a different "kind" of connector; an A-type or a B-type. This kind of design was chosen to prevent electrical overloads and damaged equipment, as only the A-type socket provides power. There are cables with A-type connectors on both ends, but they should be used carefully. Therefore, in general, each of the different "sizes" requires four different connectors; USB cables have the A-type and B-type plugs, and the corresponding receptacles are on the computer or electronic device. In common practice, the A-type connector is usually the full size, and the B-type side can vary as needed.
The mini and micro sizes also allow for a reversible AB-type receptacle, which can accept either an A-type or a B-type plug. This scheme, known as "USB On-The-Go", allows one receptacle to perform its double duty in space-constrained applications.
Counter-intuitively, the "micro" size is the most durable from the point of designed insertion lifetime. The standard and mini connectors were designed for less than daily connections, with a design lifetime of 1,500 insertion/removal cycles. (Improved mini-B connectors have reached 5,000-cycle lifetimes.) Micro connectors were designed with frequent charging of portable devices in mind; not only is design lifetime of the connector improved to 10,000 cycles, but it was also redesigned to place the flexible contacts, which wear out sooner, on the easily replaced cable, while the more durable rigid contacts are located in the micro-USB receptacles. Likewise, the springy part of the retention mechanism (parts that provide required gripping force) were also moved into plugs on the cable side.
USB connections also come in five data transfer modes: Low Speed, Full Speed, High Speed, SuperSpeed, and SuperSpeed+. High Speed is only supported by specifically designed USB 2.0 High Speed interfaces (that is, USB 2.0 controllers without the High Speed designation do not support it), as well as by USB 3.0 and newer interfaces. SuperSpeed is supported only by USB 3.0 and newer interfaces, and requires a connector and cable with extra pins and wires, usually distinguishable by the blue inserts in connectors.
History.
A group of seven companies began the development of USB in 1994: Compaq, DEC, IBM, Intel, Microsoft, NEC, and Nortel. The goal was to make it fundamentally easier to connect external devices to PCs by replacing the multitude of connectors at the back of PCs, addressing the usability issues of existing interfaces, and simplifying software configuration of all devices connected to USB, as well as permitting greater data rates for external devices. A team including Ajay Bhatt worked on the standard at Intel; the first integrated circuits supporting USB were produced by Intel in 1995.
The original USB 1.0 specification, which was introduced in January 1996, defined data transfer rates of 1.5 Mbit/s "Low Speed" and 12 Mbit/s "Full Speed". The first widely used version of USB was 1.1, which was released in September 1998. The 12 Mbit/s data rate was intended for higher-speed devices such as disk drives, and the lower 1.5 Mbit/s rate for low data rate devices such as joysticks.
The USB 2.0 specification was released in April 2000 and was ratified by the USB Implementers Forum (USB-IF) at the end of 2001. Hewlett-Packard, Intel, Lucent Technologies (now Alcatel-Lucent), NEC and Philips jointly led the initiative to develop a higher data transfer rate, with the resulting specification achieving 480 Mbit/s, a 40-times increase over the original USB 1.1 specification.
The USB 3.0 specification was published on 12 November 2008. Its main goals were to increase the data transfer rate (up to 5 Gbit/s), decrease power consumption, increase power output, and be backward compatible with USB 2.0. USB 3.0 includes a new, higher speed bus called SuperSpeed in parallel with the USB 2.0 bus. For this reason, the new version is also called SuperSpeed. The first USB 3.0 equipped devices were presented in January 2010.
s of 2008[ [update]], approximately six billion USB ports and interfaces were in the global marketplace, and about two billion were being sold each year.
In December 2014, USB-IF submitted USB 3.1, USB Power Delivery 2.0 and USB type-C specifications to the IEC (TC 100 – Audio, video and multimedia systems and equipment) for inclusion in the international standard IEC 62680 "Universal Serial Bus interfaces for data and power", which is currently based on USB 2.0.
Version history.
Prereleases.
The USB standard evolved through several versions before its official release in 1996:
USB 1.x.
Released in January 1996, USB 1.0 specified data rates of 1.5 Mbit/s ("Low Bandwidth" or "Low Speed") and 12 Mbit/s ("Full Bandwidth" or "Full Speed"). It did not allow for extension cables or pass-through monitors, due to timing and power limitations. Few USB devices made it to the market until USB 1.1 was released in August 1998, fixing problems identified in 1.0, mostly related to using hubs. USB 1.1 was the earliest revision that was widely adopted.
USB 2.0.
USB 2.0 was released in April 2000, adding a higher maximum signaling rate of 480 Mbit/s called "High Speed", in addition to the USB 1.x "Full Speed" signaling rate of 12 Mbit/s. Due to bus access constraints, the effective throughput of the "High Speed" signaling rate is limited to 35 MB/s or 280 Mbit/s.
Further modifications to the USB specification have been made via Engineering Change Notices (ECN). The most important of these ECNs are included into the USB 2.0 specification package available from USB.org:
USB 3.0.
USB 3.0 standard was released in November 2008, defining a new "SuperSpeed" mode. A USB 3.0 port, usually colored blue, is backward compatible with USB 2.0 devices and cables.
The USB 3.0 Promoter Group announced on 17 November 2008 that the specification of version 3.0 had been completed and had made the transition to the USB Implementers Forum (USB-IF), the managing body of USB specifications. This move effectively opened the specification to hardware developers for implementation in products.
The new "SuperSpeed" bus provides a fourth transfer mode with a data signaling rate of 5.0 Gbit/s, in addition to the modes supported by earlier versions. The payload throughput is 4 Gbit/s (due to the overhead induced by used 8b/10b encoding), and the specification considers it reasonable to achieve around 3.2 Gbit/s (0.4 GB/s or 400 MB/s), which should increase with future hardware advances. Communication is full-duplex in SuperSpeed transfer mode; in the modes supported previously, by 1.x and 2.0, communication is half-duplex, with direction controlled by the host.
As with previous USB versions, USB 3.0 ports come in low-power and high-power variants, providing 150 mA and 900 mA respectively, while simultaneously transmitting data at SuperSpeed rates. Additionally, there is a Battery Charging Specification (Version 1.2 – December 2010), which increases the power handling capability to 1.5 A but does "not" allow concurrent data transmission. The Battery Charging Specification requires that the physical ports themselves be capable of handling 5 A of current but limits the maximum current drawn to 1.5 A.
USB 3.1.
A January 2013 press release from the USB group revealed plans to update USB 3.0 to 10 Gbit/s. The group ended up creating a new USB version, USB 3.1, which was released on 31 July 2013, introducing a faster transfer mode called "SuperSpeed USB 10 Gbit/s", putting it on par with a single first-generation Thunderbolt channel. The new mode's logo features a "Superspeed+" caption (stylized as "SUPERSPEED+"). The USB 3.1 standard increases the data signaling rate to 10 Gbit/s in the "USB 3.1 Gen2" mode, double that of USB 3.0 (referred to as "USB 3.1 Gen1") and reduces line encoding overhead to just 3% by changing the encoding scheme to 128b/132b. The first USB 3.1 implementation demonstrated transfer speeds of 7.2 Gbit/s.
The USB 3.1 standard is backward compatible with USB 3.0 and USB 2.0.
USB Type-C.
Developed at roughly the same time as, but distinct from, the USB 3.1 specification, the USB Type-C Specification 1.0 defines a new small reversible-plug connector for USB devices. The type-C plug connects to both hosts and devices, replacing various type-B and type-A connectors and cables with a standard meant to be future-proof, similar to Apple Lightning and Thunderbolt. The 24-pin double-sided connector provides four power/ground pairs, two differential pairs for USB 2.0 data bus (though only one pair is implemented in a type-C cable), four pairs for high-speed data bus, two "sideband use" pins, and two configuration pins for cable orientation detection, dedicated biphase mark code (BMC) configuration data channel, and VCONN +5 V power for active cables. Type-A and type-B adaptors/cables will be required for older devices in order to plug into type-C hosts; adaptors/cables with a type-C receptacle are not allowed.
Full-featured USB type-C cables are active, electronically marked cables that contain a chip with an ID function based on the configuration data channel and vendor-defined messages (VDMs) from the USB Power Delivery 2.0 specification. USB type-C devices also support power currents of 1.5 A and 3.0 A over the 5 V power bus in addition to baseline 900 mA; devices can either negotiate increased USB current through the configuration line, or they can support the full Power Delivery specification using both BMC-coded configuration line and legacy BFSK-coded VBUS line.
Alternate Mode dedicates some of the physical wires in the type-C cable for direct device-to-host transmission of alternate data protocols. The four high-speed lanes, two sideband pins, and—for dock, detachable device and permanent cable applications only—two USB 2.0 pins and one configuration pin can be used for Alternate Mode transmission. The modes are configured using VDMs through the configuration channel. As of December 2014, Alt Mode implementations include DisplayPort 1.3 and MHL 3.0; other serial protocols like PCI Express and Base-T Ethernet are possible.
Among the first devices to accommodate a Type-C cable are the Nokia N1 tablet, Apple's 2015 MacBook (which has only a single USB 3.1 gen1 port), and Google's second Chromebook Pixel. The first smartphone that accommodated a USB Type-C cable is from Chinese company LeTV. Other devices use type-A plugs for USB 3.1 ports.
System design.
The design architecture of USB is asymmetrical in its topology, consisting of a host, a multitude of downstream USB ports, and multiple peripheral devices connected in a tiered-star topology. Additional USB hubs may be included in the tiers, allowing branching into a tree structure with up to five tier levels. A USB host may implement multiple host controllers and each host controller may provide one or more USB ports. Up to 127 devices, including hub devices if present, may be connected to a single host controller. USB devices are linked in series through hubs. One hub—built into the host controller—is the root hub.
A physical USB device may consist of several logical sub-devices that are referred to as "device functions". A single device may provide several functions, for example, a webcam (video device function) with a built-in microphone (audio device function). This kind of device is called a "composite device". An alternative to this is "compound device," in which the host assigns each logical device a distinctive address and all logical devices connect to a built-in hub that connects to the physical USB cable.
USB device communication is based on "pipes" (logical channels). A pipe is a connection from the host controller to a logical entity, found on a device, and named an "endpoint". Because pipes correspond 1-to-1 to endpoints, the terms are sometimes used interchangeably. A USB device could have up to 32 endpoints (16 IN, 16 OUT), though it's rare to have so many. An endpoint is defined and numbered by the device during initialization (the period after physical connection called "enumeration") and so is relatively permanent, whereas a pipe may be opened and closed.
There are two types of pipe: stream and message. A message pipe is bi-directional and is used for "control" transfers. Message pipes are typically used for short, simple commands to the device, and a status response, used, for example, by the bus control pipe number 0. A stream pipe is a uni-directional pipe connected to a uni-directional endpoint that transfers data using an "isochronous", "interrupt", or "bulk" transfer:
An endpoint of a pipe is addressable with a tuple "(device_address, endpoint_number)" as specified in a TOKEN packet that the host sends when it wants to start a data transfer session. If the direction of the data transfer is from the host to the endpoint, an OUT packet (a specialization of a TOKEN packet) having the desired device address and endpoint number is sent by the host. If the direction of the data transfer is from the device to the host, the host sends an IN packet instead. If the destination endpoint is a uni-directional endpoint whose manufacturer's designated direction does not match the TOKEN packet (e.g., the manufacturer's designated direction is IN while the TOKEN packet is an OUT packet), the TOKEN packet is ignored. Otherwise, it is accepted and the data transaction can start. A bi-directional endpoint, on the other hand, accepts both IN and OUT packets.
Endpoints are grouped into "interfaces" and each interface is associated with a single device function. An exception to this is endpoint zero, which is used for device configuration and is not associated with any interface. A single device function composed of independently controlled interfaces is called a "composite device". A composite device only has a single device address because the host only assigns a device address to a function.
When a USB device is first connected to a USB host, the USB device enumeration process is started. The enumeration starts by sending a reset signal to the USB device. The data rate of the USB device is determined during the reset signaling. After reset, the USB device's information is read by the host and the device is assigned a unique 7-bit address. If the device is supported by the host, the device drivers needed for communicating with the device are loaded and the device is set to a configured state. If the USB host is restarted, the enumeration process is repeated for all connected devices.
The host controller directs traffic flow to devices, so no USB device can transfer any data on the bus without an explicit request from the host controller. In USB 2.0, the host controller polls the bus for traffic, usually in a round-robin fashion. The throughput of each USB port is determined by the slower speed of either the USB port or the USB device connected to the port.
High-speed USB 2.0 hubs contain devices called transaction translators that convert between high-speed USB 2.0 buses and full and low speed buses. When a high-speed USB 2.0 hub is plugged into a high-speed USB host or hub, it operates in high-speed mode. The USB hub then uses either one transaction translator per hub to create a full/low-speed bus routed to all full and low speed devices on the hub, or uses one transaction translator per port to create an isolated full/low-speed bus per port on the hub.
Because there are two separate controllers in each USB 3.0 host, USB 3.0 devices transmit and receive at USB 3.0 data rates regardless of USB 2.0 or earlier devices connected to that host. Operating data rates for earlier devices are set in the legacy manner.
Device classes.
The functionality of USB devices is defined by class codes, communicated to the USB host to affect the loading of suitable software driver modules for each connected device. This provides for adaptability and device independence of the host to support new devices from different manufacturers.
Device classes include:
USB mass storage / USB drive.
USB implements connections to storage devices using a set of standards called the USB mass storage device class (MSC or UMS). This was at first intended for traditional magnetic and optical drives and has been extended to support flash drives. It has also been extended to support a wide variety of novel devices as many systems can be controlled with the familiar metaphor of file manipulation within directories. The process of making a novel device look like a familiar device is also known as extension. The ability to boot a write-locked SD card with a USB adapter is particularly advantageous for maintaining the integrity and non-corruptible, pristine state of the booting medium.
Though most post-Summer 2004 computers can boot from USB mass storage devices, USB is not intended as a primary bus for a computer's internal storage. Buses such as Parallel ATA (PATA or IDE), Serial ATA (SATA), or SCSI fulfill that role in PC class computers. However, USB has one important advantage, in that it is possible to install and remove devices without rebooting the computer (hot-swapping), making it useful for mobile peripherals, including drives of various kinds.
Firstly conceived and still used today for optical storage devices (CD-RW drives, DVD drives, etc.), several manufacturers offer external portable USB hard disk drives, or empty enclosures for disk drives. These offer performance comparable to internal drives, limited by the current number and types of attached USB devices, and by the upper limit of the USB interface (in practice about 30 MB/s for USB 2.0 and potentially 400 MB/s or more for USB 3.0). These external drives typically include a "translating device" that bridges between a drive's interface to a USB interface port. Functionally, the drive appears to the user much like an internal drive. Other competing standards for external drive connectivity include eSATA, ExpressCard (now at version 2.0), FireWire (IEEE 1394), and most recently Thunderbolt.
Another use for USB mass storage devices is the portable execution of software applications (such as web browsers and VoIP clients) with no need to install them on the host computer.
Media Transfer Protocol.
Media Transfer Protocol (MTP) was designed by Microsoft to give higher-level access to a device's filesystem than USB mass storage, at the level of files rather than disk blocks. It also has optional DRM features. MTP was designed for use with portable media players, but it has since been adopted as the primary storage access protocol of the Android operating system from the version 4.1 Jelly Bean as well as Windows Phone 8 (Windows Phone 7 devices had used the Zune protocol which was an evolution of MTP). The primary reason for this is that MTP does not require exclusive access to the storage device the way UMS does, alleviating potential problems should an Android program request the storage while it is attached to a computer. The main drawback is that MTP is not as well supported outside of Windows operating systems.
Human interface devices.
Joysticks, keypads, tablets and other human-interface devices (HIDs) are also progressively migrating from MIDI, and PC game port connectors to USB.
USB mice and keyboards can usually be used with older computers that have PS/2 connectors with the aid of a small USB-to-PS/2 adapter. For mice and keyboards with dual-protocol support, an adaptor that contains no logic circuitry may be used: the hardware in the USB keyboard or mouse is designed to detect whether it is connected to a USB or PS/2 port, and communicate using the appropriate protocol. Converters also exist that connect PS/2 keyboards and mice (usually one of each) to a USB port. These devices present two HID endpoints to the system and use a microcontroller to perform bidirectional data translation between the two standards.
Device Firmware Upgrade.
"Device Firmware Upgrade" (DFU) is a vendor- and device-independent mechanism for upgrading the firmware of USB devices with improved versions provided by their manufacturers, offering (for example) a way for firmware bugfixes to be deployed. During the firmware upgrade operation, USB devices change their operating mode effectively becoming a PROM programmer. Any class of USB device can implement this capability by following the official DFU specifications.
In addition to its intended legitimate purposes, DFU can also be exploited by uploading maliciously crafted firmwares that cause USB devices to spoof various other device types; one such exploiting approach is known as BadUSB.
Connectors and plugs.
Connector properties.
The connectors the USB committee specifies support a number of USB's underlying goals, and reflect lessons learned from the many connectors the computer industry has used. The connector mounted on the host or device is called the "receptacle", and the connector attached to the cable is called the "plug". The official USB specification documents also periodically define the term "male" to represent the plug, and "female" to represent the receptacle.
Usability and orientation.
By design, it is difficult to insert a USB plug into its receptacle incorrectly. The USB specification states that the required USB icon must be embossed on the "topside" of the USB plug, which "...provides easy user recognition and facilitates alignment during the mating process." The specification also shows that the "recommended" "Manufacturer's logo" ("engraved" on the diagram but not specified in the text) is on the opposite side of the USB icon. The specification further states, "The USB Icon is also located adjacent to each receptacle. Receptacles should be oriented to allow the icon on the plug to be visible during the mating process." However, the specification does not consider the height of the device compared to the eye level height of the user, so the side of the cable that is "visible" when mated to a computer on a desk can depend on whether the user is standing or kneeling.
While it would have been better for usability if the cable could be plugged in with either side up, the original design left this out to make manufacturing as inexpensive as possible. Ajay Bhatt, who was involved in the original USB design team, is working on a new design to make the cable insertable either side up. The new reversible "type-C" plug is an addition to the USB 3.1 specification; it is much smaller than the current USB 3.0 micro-B connector
Only moderate force is needed to insert or remove a USB cable. USB cables and small USB devices are held in place by the gripping force from the receptacle (without need of the screws, clips, or thumb-turns other connectors have required).
Power-use topology.
The standard connectors were deliberately intended to enforce the directed topology of a USB network: type A connectors on host devices that supply power and type B connectors on target devices that draw power. This is intended to prevent users from accidentally connecting two USB power supplies to each other, which could lead to short circuits and dangerously high currents, circuit failures, or even fire. USB does not support cyclic networks and the standard connectors from incompatible USB devices are themselves incompatible.
However, some of this directed topology is lost with the advent of multi-purpose USB connections (such as USB On-The-Go in smartphones, and USB-powered Wi-Fi routers), which require A-to-A, B-to-B, and sometimes Y/splitter cables. See the USB On-The-Go connectors section below, for a more detailed summary description.
Durability.
The standard connectors were designed to be robust. Because USB is hot-pluggable, the connectors would be used more frequently, and perhaps with less care, than other connectors. Many previous connector designs were fragile, specifying embedded component pins or other delicate parts that were vulnerable to bending or breaking. The electrical contacts in a USB connector are protected by an adjacent plastic tongue, and the entire connecting assembly is usually protected by an enclosing metal sheath.
The connector construction always ensures that the external sheath on the plug makes contact with its counterpart in the receptacle before any of the four connectors within make electrical contact. The external metallic sheath is typically connected to system ground, thus dissipating damaging static charges. This enclosure design also provides a degree of protection from electromagnetic interference to the USB signal while it travels through the mated connector pair (the only location when the otherwise twisted data pair travels in parallel). In addition, because of the required sizes of the power and common connections, they are made after the system ground but before the data connections. This type of staged make-break timing allows for electrically safe hot-swapping.
The newer micro-USB receptacles are designed for up to 10,000 cycles of insertion and removal between the receptacle and plug, compared to 1,500 for the standard USB and 5,000 for the mini-USB receptacle. To accomplish this, a locking device was added and the leaf-spring was moved from the jack to the plug, so that the most-stressed part is on the cable side of the connection. This change was made so that the connector on the less expensive cable would bear the most wear instead of the more expensive micro-USB device.
Compatibility.
The USB standard specifies relatively loose tolerances for compliant USB connectors to minimize physical incompatibilities in connectors from different vendors. To address a weakness present in some other connector standards, the USB specification also defines limits to the size of a connecting device in the area around its plug. This was done to prevent a device from blocking adjacent ports due to the size of the cable strain relief mechanism (usually molding integral with the cable outer insulation) at the connector. Compliant devices must either fit within the size restrictions or support a compliant extension cable that does.
In general, USB cables have only plugs on their ends, while hosts and devices have only receptacles. Hosts almost universally have type-A receptacles, while devices have one or another type-B variety. Type-A plugs mate only with type-A receptacles, and the same applies to their type-B counterparts; they are deliberately physically incompatible. However, an extension to the USB standard specification called USB On-The-Go (OTG) allows a single port to act as either a host or a device, what is selectable by the end of the cable that plugs into the receptacle on the OTG-enabled unit. Even after the cable is hooked up and the units are communicating, the two units may "swap" ends under program control. This capability is meant for units such as PDAs in which the USB link might connect to a PC's host port as a device in one instance, yet connect as a host itself to a keyboard and mouse device in another instance.
USB 3.0 connectors.
Type-A plugs and receptacles from both USB 3.0 and USB 2.0 are designed to interoperate. Type-B plugs and receptacles in USB 3.0 are somewhat larger than those in USB 2.0; thus, USB 2.0 type-B plugs can fit into USB 3.0 type-B receptacles, while the opposite is not possible.
Connector types.
There are several types of USB connector, including some that have been added while the specification progressed. The original USB specification detailed standard-A and standard-B plugs and receptacles; the B connector was necessary so that cabling could be plug ended at both ends and still prevent users from connecting one computer receptacle to another. The first engineering change notice to the USB 2.0 specification added mini-B plugs and receptacles.
The data pins in the standard-A plug are actually recessed in the plug compared to the outside power pins. This permits the power pins to connect first, preventing data errors by allowing the device to power up first and then establish the data connection. Also, some devices operate in different modes depending on whether the data connection is made.
To reliably enable a charge-only feature, modern USB accessory peripherals now include charging cables that provide power connections to the host port but no data connections, and both home and vehicle charging docks are available that supply power from a converter device and do not include a host device and data pins, allowing any capable USB device to charge or operate from a standard USB cable.
Standard connectors.
The USB 2.0 standard-A type of USB plug is a flattened rectangle that inserts into a "downstream-port" receptacle on the USB host, or a hub, and carries both power and data. This plug is frequently seen on cables that are permanently attached to a device, such as one connecting a keyboard or mouse to the computer via USB connection.
USB connections eventually wear out as the connection loosens through repeated plugging and unplugging. The lifetime of a USB-A male connector is approximately 1,500 connect/disconnect cycles.
A standard-B plug—&#X200B;which has a square shape with beveled exterior corners—&#X200B;typically plugs into an "upstream receptacle" on a device that uses a removable cable, e.g., a printer. On some devices, the type-B receptacle has no data connections, being used solely for accepting power from the upstream device. This two-connector-type scheme (A/B) prevents a user from accidentally creating an electrical loop.
Maximum allowed size of the "overmold boot" (which is part of the connector used for its handling) is 16 by 8 mm for the standard-A plug type, while for the type B it is 11.5 by 10.5 mm.
Mini and micro connectors.
Various connectors have been used for smaller devices such as digital cameras, smartphones, and tablet computers. These include the now-deprecated (i.e. de-certified but standardized) mini-A and mini-AB connectors; mini-B connectors are still supported, but are not OTG-compliant (On The Go, used in mobile devices). The mini-B USB connector was standard for transferring data to and from the early smartphones and PDAs. Both mini-A and mini-B plugs are approximately 3 by 7 mm; the mini-A connector and the mini-AB receptacle connector were deprecated on 23 May 2007.
The micro-USB connector was announced by the USB-IF on 4 January 2007. Micro-USB plugs have a similar width to mini-USB, but approximately half the thickness, enabling their integration into thinner portable devices. The micro-A connector is 6.85 by 1.8 mm with a maximum overmold boot size of 11.7 by 8.5 mm, while the micro-B connector is 6.85 by 1.8 mm with a maximum overmold size of 10.6 by 8.5 mm.
The thinner micro connectors are intended to replace the mini connectors in new devices including smartphones, personal digital assistants, and cameras. While some of the devices and cables still use the older mini variant, the newer micro connectors are widely adopted, and as of 2010[ [update]] they are the most widely used. 
The micro plug design is rated for at least 10,000 connect-disconnect cycles, which is more than the mini plug design. The micro connector is also designed to reduce the mechanical wear on the device; instead the easier-to-replace cable is designed to bear the mechanical wear of connection and disconnection. The "Universal Serial Bus Micro-USB Cables and Connectors Specification" details the mechanical characteristics of micro-A plugs, micro-AB receptacles (which accept both micro-A and micro-B plugs), and micro-B plugs and receptacles, along with a standard-A receptacle to micro-A plug adapter.
The cellular phone carrier group Open Mobile Terminal Platform (OMTP) in 2007 endorsed micro-USB as the standard connector for data and power on mobile devices In addition, on 22 October 2009 the International Telecommunication Union (ITU) has also announced that it had embraced micro-USB as the "Universal Charging Solution" its "energy-efficient one-charger-fits-all new mobile phone solution", and added: "Based on the Micro-USB interface, UCS chargers also include a 4-star or higher efficiency rating—&#X200B;up to three times more energy-efficient than an unrated charger."
The European Standardisation Bodies CEN, CENELEC and ETSI (independent of the OMTP/GSMA proposal) defined a common External Power Supply (EPS) for use with smartphones sold in the EU based on micro-USB. 14 of the world's largest mobile phone manufacturers signed the EU's common EPS Memorandum of Understanding (MoU). Apple, one of the original MoU signers, makes micro-USB adapters available – as permitted in the Common EPS MoU – for its iPhones equipped with Apple's proprietary 30 pin dock connector or (later) "Lightning" connector.
USB On-The-Go connectors.
All current USB On-The-Go (OTG) devices are required to have one, and only one, USB connector: a micro-AB receptacle. Non-OTG compliant devices are not allowed to use the micro-AB receptacle, due to power supply shorting hazards on the VBUS line. The micro-AB receptacle is capable of accepting both micro-A and micro-B plugs, attached to any of the legal cables and adapters as defined in revision 1.01 of the micro-USB specification. Prior to the development of micro-USB, USB On-The-Go devices were required to use mini-AB receptacles to perform the equivalent job.
To enable type-AB receptacles to distinguish which end of a cable is plugged in, mini and micro plugs have an "ID" pin in addition to the four contacts found in standard-size USB connectors. This ID pin is connected to GND in type-A plugs, and left unconnected in type-B plugs. Typically, a pull-up resistor in the device is used to detect the presence or absence of an ID connection.
The OTG device with the A-plug inserted is called the A-device and is responsible for powering the USB interface when required and by default assumes the role of host. The OTG device with the B-plug inserted is called the B-device and by default assumes the role of peripheral. An OTG device with no plug inserted defaults to acting as a B-device. If an application on the B-device requires the role of host, then the Host Negotiation Protocol (HNP) is used to temporarily transfer the host role to the B-device.
OTG devices attached either to a peripheral-only B-device or a standard/embedded host have their role fixed by the cable, since in these scenarios it is only possible to attach the cable one way.
Host and device interface receptacles.
A pre-USB 3.0 connector (receptacles and plugs) mating matrix is displayed below. As a note, the assignment of functions (VCC, D+, D−, GND and ID) to pin numbers marked below is mostly consistent, with the exception of mini and micro connectors. When compared to standard-sized connectors (type-A and type-B), mini and micro connectors have their GND connections moved from pin #4 to pin #5, while their pin #4 serves as an ID pin for the On-The-Go host/client identification.
Cable plugs (USB 1.x/2.0).
USB cables exist with various combinations of plugs on each end of the cable, as displayed below. Notes from the section above apply here as well.
Cable plugs (USB 3.0).
USB 3.0 introduced new standard and micro-sized type A and type B plugs and receptacles. The 3.0 receptacles are backward-compatible with the corresponding pre-3.0 plugs. See the micro-B cable plug photo on the right. The micro-B 3.0 plug effectively consists of a standard USB 1.x/2.0 micro-B cable plug, with an additional five-pin plug "stacked" to the side of it. In this way, USB 3.0 micro-A host connectors can achieve backward compatibility with the USB 1.x/2.0 micro-B cable plugs.
Pinouts.
USB is a serial bus, using four shielded wires for the USB 2.0 variant: two for power (VBUS and GND), and two for differential data signals (labelled as D+ and D− in pinouts). Non-Return-to-Zero Inverted (NRZI) encoding scheme is used for transferring data, with a sync field to synchronise the host and receiver clocks. D+ and D− signals are transmitted on a twisted pair, providing half-duplex data transfers for USB 2.0.
USB 3.0 provides two additional twisted pairs (four wires, SSTx+, SSTx−, SSRx+ and SSRx−), providing full-duplex data transfers at "super-speed", which makes it similar to Serial ATA or single-lane PCI Express.
Proprietary connectors and formats.
Manufacturers of personal electronic devices might not include a USB standard connector on their product for technical or marketing reasons. Some manufacturers provide proprietary cables that permit their devices to physically connect to a USB standard port. Full functionality of proprietary ports and cables with USB standard ports is not assured; for example, some devices only use the USB connection for battery charging and do not implement any data transfer functions.
Colors.
USB ports and connectors are often color-coded to distinguish their different functions and USB versions. These colors are not part of the USB specification and can vary between manufacturers; for example, USB 3.0 specification mandates appropriate color-coding while it only recommends blue inserts for standard-A USB 3.0 connectors and plugs.
Cabling.
The data cables for USB 1.x and USB 2.x use a twisted pair to reduce noise and crosstalk. USB 3.0 cables contain twice as many wires as USB 2.x to support SuperSpeed data transmission, and are thus larger in diameter.
The USB 1.1 standard specifies that a standard cable can have a maximum length of 5 meters with devices operating at Full Speed (12 Mbit/s), and a maximum length of 3 meters with devices operating at Low Speed (1.5 Mbit/s).
USB 2.0 provides for a maximum cable length of 5 meters for devices running at Hi Speed (480 Mbit/s). The primary reason for this limit is the maximum allowed round-trip delay of about 1.5 μs. If USB host commands are unanswered by the USB device within the allowed time, the host considers the command lost. When adding USB device response time, delays from the maximum number of hubs added to the delays from connecting cables, the maximum acceptable delay per cable amounts to 26 ns. The USB 2.0 specification requires that cable delay be less than 5.2 ns per meter (192 000 km/s, which is close to the maximum achievable transmission speed for standard copper wire).
The USB 3.0 standard does not directly specify a maximum cable length, requiring only that all cables meet an electrical specification: for copper cabling with AWG 26 wires the maximum practical length is 3 m.
Power.
The USB 1.x and 2.0 specifications provide a 5 V supply on a single wire to power connected USB devices. The specification provides for no more than 5.25 V and no less than 4.75 V (5 V ± 5%) between the positive and negative bus power lines (VBUS voltage). For USB 3.0, the voltage supplied by low-powered hub ports is 4.45–5.25 V.
A unit load is defined as 100 mA in USB 1.x and 2.0, and 150 mA in USB 3.0. A device may draw a maximum of five unit loads (500 mA) from a port in USB 1.x and 2.0, or six unit loads (900 mA) in USB 3.0. There are two types of device: low-power and high-power. A low-power device (such as a USB HID) draws at most one-unit load, with minimum operating voltage of 4.4 V in USB 2.0, and 4 V in USB 3.0. A high-power device draws, at most, the maximum number of unit loads the standard permits. Every device functions initially as low-power (including high-power functions during their low-power enumeration phases), but may request high-power, and get it if available on the providing bus.
Some devices, such as high-speed external disk drives, require more than 500 mA of current and therefore may have power issues if powered from just one USB 2.0 port: erratic function, failure to function, or overloading/damaging the port. Such devices may come with an external power source or a Y-shaped cable that has two USB connectors (one for power and data, the other for power only) to plug into a computer. With such a cable, a device can draw power from two USB ports simultaneously. However, USB compliance specification states that "use of a 'Y' cable (a cable with two A-plugs) is prohibited on any USB peripheral", meaning that "if a USB peripheral requires more power than allowed by the USB specification to which it is designed, then it must be self-powered."
A bus-powered hub initializes itself at one-unit load and transitions to maximum unit loads after it completes hub configuration. Any device connected to the hub draws one-unit load regardless of the current draw of devices connected to other ports of the hub (i.e., one device connected on a four-port hub draws only one-unit load despite the fact that more unit loads are being supplied to the hub).
A self-powered hub supplies maximum supported unit loads to any device connected to it. In addition, the "VBUS" presents one-unit load upstream for communication if parts of the Hub are powered down.
Charging ports.
The "USB Battery Charging Specification Revision 1.1" (released in 2007) defines a new type of USB port, called the "charging port". Contrary to the "standard downstream port", for which current draw by a connected portable device can exceed 100 mA only after digital negotiation with the host or hub, a charging port can supply currents between 500 mA and 1.5 A without the digital negotiation. A charging port supplies up to 500 mA at 5 V, up to the rated current at 3.6 V or more, and drops its output voltage if the portable device attempts to draw more than the rated current. The charger port may shut down if the load is too high.
Two types of charging port exist: the "charging downstream port" (CDP), supporting data transfers as well, and the "dedicated charging port" (DCP), without data support. A portable device can recognize the type of USB port; on a dedicated charging port, the D+ and D− pins are shorted with a resistance not exceeding 200 ohms, while charging downstream ports provide additional detection logic so their presence can be determined by attached devices.
With charging downstream ports, current passing through the thin ground wire may interfere with high-speed data signals; therefore, current draw may not exceed 900 mA during high-speed data transfer. A dedicated charge port may have a rated current between 500 and 1,500 mA. For all charging ports, there is maximum current of 5 A, as long as the connector can handle the current (standard USB 2.0 A-connectors are rated at 1.5 A).
Before the battery charging specification was defined, there was no standardized way for the portable device to inquire how much current was available. For example, Apple's iPod and iPhone chargers indicate the available current by voltages on the D− and D+ lines. When D+ = D− = 2.0 V, the device may pull up to 500 mA. When D+ = 2.0 V and D− = 2.8 V, the device may pull up to 1 A of current. When D+ = 2.8 V and D− = 2.0 V, the device may pull up to 2 A of current.
Dedicated charging ports can be found on USB power adapters that convert utility power or another power source (e.g., a car's electrical system) to run attached devices and battery packs. On a host (such as a laptop computer) with both standard and charging USB ports, the charging ports should be labeled as such.
To support simultaneous charge and data communication, even if the communication port does not support charging a demanding device, so-called "accessory charging adapters (ACA)" are introduced. By using an accessory charging adapter, a device providing a single USB port can be attached to both a charger, and another USB device at the same time.
The "USB Battery Charging Specification Revision 1.2" (released in 2010) makes clear that there are safety limits to the rated current at 5 A coming from USB 2.0. On the other hand, several changes are made and limits are increasing including allowing 1.5 A on charging downstream ports for unconfigured devices, allowing high speed communication while having a current up to 1.5 A, and allowing a maximum current of 5 A. Also, revision 1.2 removes support for USB ports type detection via resistive detection mechanisms.
USB Power Delivery.
In July 2012, the USB Promoters Group announced the finalization of the USB Power Delivery ("PD") specification, an extension that specifies using certified "PD aware" USB cables with standard USB type A and B connectors to deliver increased power (more than 7.5W) to devices with larger power demand. Devices can request higher currents and supply voltages from compliant hosts – up to 2 A at 5 V (for a power consumption of up to 10 W), and optionally up to 3 A or 5 A at either 12 V (36 W or 60 W) or 20 V (60 W or 100 W). In all cases, both host-to-device and device-to-host configurations are supported.
The intent is to permit uniformly charging laptops, tablets, USB-powered disks and similarly higher power consumer electronics, as a natural extension of existing European and Chinese mobile telephone charging standards. This may also affect the way electric power used for small devices is transmitted and used in both residential and public buildings.
The Power Delivery specification defines six fixed power profiles for the power sources. PD-aware devices implement a flexible power management scheme by interfacing with the power source through a bidirectional data channel and requesting a certain level of electrical power, variable up to 5 A and 20 V depending on supported profile. The power configuration protocol uses a 24 MHz BFSK-coded transmission channel on the VBUS line.
The USB Power Delivery revision 2.0 specification has been released as part of the USB 3.1 suite. It covers the type-C cable and connector with four power/ground pairs and a separate configuration channel, which now hosts a DC coupled low-frequency BMC-coded data channel that reduces the possibilities for RF interference. Power Delivery protocols have been updated to facilitate type-C features such as cable ID function, Alternate Mode negotiation, increased VBUS currents, and VCONN-powered accessories.
Sleep-and-charge ports.
Sleep-and-charge USB ports can be used to charge electronic devices even when the computer is switched off. Normally, when a computer is powered off the USB ports are powered down, preventing phones and other devices from charging. Sleep-and-charge USB ports remain powered even when the computer is off. On laptops, charging devices from the USB port when it is not being powered from AC drains the laptop battery faster; most laptops have a facility to stop charging if their own battery charge level gets too low.
Sleep-and-charge USB ports may be found colored differently than regular ports, mostly red or yellow, though that is not always the case.
On Dell and Toshiba laptops, the port is marked with the standard USB symbol with an added lightning bolt icon on the right side. Dell calls this feature "PowerShare", while Toshiba calls it "USB Sleep-and-Charge". On Acer Inc. and Packard Bell laptops, sleep-and-charge USB ports are marked with a non-standard symbol (the letters "USB" over a drawing of a battery); the feature is simply called "Power-off USB". On some laptops such as Dell and Apple MacBook models, it is possible to plug a device in, close the laptop (putting it into sleep mode) and have the device continue to charge.
Mobile device charger standards.
In China.
s of 14 2007[ [update]], all new mobile phones applying for a license in China are required to use a USB port as a power port for battery charging. This was the first standard to use the convention of shorting D+ and D-.
OMTP/GSMA Universal Charging Solution.
In September 2007, the Open Mobile Terminal Platform group (a forum of mobile network operators and manufacturers such as Nokia, Samsung, Motorola, Sony Ericsson and LG) announced that its members had agreed on micro-USB as the future common connector for mobile devices.
The GSM Association (GSMA) followed suit on 17 February 2009, and on 22 April 2009, this was further endorsed by the CTIA – The Wireless Association, with the International Telecommunication Union (ITU) announcing on 22 October 2009 that it had also embraced the Universal Charging Solution as its "energy-efficient one-charger-fits-all new mobile phone solution", and added: "Based on the Micro-USB interface, UCS chargers will also include a 4-star or higher efficiency rating—up to three times more energy-efficient than an unrated charger."
EU Smartphone Power Supply Standard.
In June 2009, many of the world's largest mobile phone manufacturers signed an EC-sponsored Memorandum of Understanding (MoU), agreeing to make most data-enabled mobile phones marketed in the European Union compatible with a common External Power Supply (EPS). The EU's common EPS specification (EN 62684:2010) references the USB Battery Charging standard and is similar to the GSMA/OMTP and Chinese charging solutions. In January 2011, the International Electrotechnical Commission (IEC) released its version of the (EU's) common EPS standard as IEC 62684:2011.
Non-standard devices.
Some USB devices require more power than is permitted by the specifications for a single port. This is common for external hard and optical disc drives, and generally for devices with motors or lamps. Such devices can use an external power supply, which is allowed by the standard, or use a dual-input USB cable, one input of which is used for power and data transfer, the other solely for power, which makes the device a non-standard USB device. Some USB ports and external hubs can, in practice, supply more power to USB devices than required by the specification but a standard-compliant device may not depend on this.
In addition to limiting the total average power used by the device, the USB specification limits the inrush current (i.e., that used to charge decoupling and filter capacitors) when the device is first connected. Otherwise, connecting a device could cause problems with the host's internal power. USB devices are also required to automatically enter ultra low-power suspend mode when the USB host is suspended. Nevertheless, many USB host interfaces do not cut off the power supply to USB devices when they are suspended.
Some non-standard USB devices use the 5 V power supply without participating in a proper USB network, which negotiates power draw with the host interface. These are usually called "USB decorations". Examples include USB-powered keyboard lights, fans, mug coolers and heaters, battery chargers, miniature vacuum cleaners, and even miniature lava lamps. In most cases, these items contain no digital circuitry, and thus are not standard compliant USB devices. This may cause problems with some computers, such as drawing too much current and damaging circuitry. Prior to the Battery Charging Specification, the USB specification required that devices connect in a low-power mode (100 mA maximum) and communicate their current requirements to the host, which then permits the device to switch into high-power mode.
Some devices, when plugged into charging ports, draw even more power (10 watts or 2.1 amperes) than the Battery Charging Specification allows. The iPad and MiFi 2200 are two such devices.
Barnes & Noble NOOK Color devices also require a special charger that runs at 1.9 amperes.
PoweredUSB.
PoweredUSB is a proprietary extension that adds four additional pins supplying up to 6 A at 5 V, 12 V, or 24 V. It is commonly used in point of sale systems to power peripherals such as barcode readers, credit card terminals, and printers.
Signaling.
USB allows the following signaling rates (the terms "speed" and "bandwidth" are used interchangeably, while "high-" is alternatively written as "hi-"):
USB signals are transmitted using differential signaling on a twisted-pair data cable with 90 Ω ±15% characteristic impedance.
A USB connection is always between a host or hub at the "A" connector end, and a device or hub's "upstream" port at the other end. Originally, this was a "B" connector, preventing erroneous loop connections, but additional upstream connectors were specified, and some cable vendors designed and sold cables that permitted erroneous connections (and potential damage to circuitry). USB interconnections are not as fool-proof or as simple as originally intended.
The host includes 15 kΩ pull-down resistors on each data line. When no device is connected, this pulls both data lines low into the so-called "single-ended zero" state (SE0 in the USB documentation), and indicates a reset or disconnected connection.
A USB device pulls one of the data lines high with a 1.5 kΩ resistor. This overpowers one of the pull-down resistors in the host and leaves the data lines in an idle state called "J". For USB 1.x, the choice of data line indicates of what signal rates the device is capable; full-bandwidth devices pull D+ high, while low-bandwidth devices pull D− high. The "k" state is just the opposite polarity to the "j" state.
USB data is transmitted by toggling the data lines between the J state and the opposite K state. USB encodes data using the NRZI line coding; a 0 bit is transmitted by toggling the data lines from J to K or vice versa, while a 1 bit is transmitted by leaving the data lines as-is. To ensure a minimum density of signal transitions remains in the bitstream, USB uses bit stuffing; an extra 0 bit is inserted into the data stream after any appearance of six consecutive 1 bits. Seven consecutive received 1 bits is always an error. USB 3.0 has introduced additional data transmission encodings.
A USB packet begins with an 8-bit synchronization sequence '00000001'. That is, after the initial idle state J, the data lines toggle KJKJKJKK. The final 1 bit (repeated K state) marks the end of the sync pattern and the beginning of the USB frame. For high bandwidth USB, the packet begins with a 32-bit synchronization sequence.
A USB packet's end, called EOP (end-of-packet), is indicated by the transmitter driving 2 bit times of SE0 (D+ and D− both below max) and 1 bit time of J state. After this, the transmitter ceases to drive the D+/D− lines and the aforementioned pull up resistors hold it in the J (idle) state. Sometimes skew due to hubs can add as much as one bit time before the SE0 of the end of packet. This extra bit can also result in a "bit stuff violation" if the six bits before it in the CRC are '1's. This bit should be ignored by receiver.
A USB bus is reset using a prolonged (10 to 20 milliseconds) SE0 signal.
USB 2.0 devices use a special protocol during reset, called "chirping", to negotiate the high bandwidth mode with the host/hub. A device that is HS capable first connects as an FS device (D+ pulled high), but upon receiving a USB RESET (both D+ and D− driven LOW by host for 10 to 20 ms) it pulls the D− line high, known as chirp K. This indicates to the host that the device is high bandwidth. If the host/hub is also HS capable, it chirps (returns alternating J and K states on D− and D+ lines) letting the device know that the hub operates at high bandwidth. The device has to receive at least three sets of KJ chirps before it changes to high bandwidth terminations and begins high bandwidth signaling. Because USB 3.0 uses wiring separate and additional to that used by USB 2.0 and USB 1.x, such bandwidth negotiation is not required.
Clock tolerance is 480.00 Mbit/s ±500 ppm, 12.000 Mbit/s ±2500 ppm, 1.50 Mbit/s ±15000 ppm.
Though high bandwidth devices are commonly referred to as "USB 2.0" and advertised as "up to 480 Mbit/s", not all USB 2.0 devices are high bandwidth. The USB-IF certifies devices and provides licenses to use special marketing logos for either "basic bandwidth" (low and full) or high bandwidth after passing a compliance test and paying a licensing fee. All devices are tested according to the latest specification, so recently compliant low bandwidth devices are also 2.0 devices.
USB 3 uses tinned copper stranded AWG-28 cables with impedance for its high-speed differential pairs and linear feedback shift register and 8b/10b encoding sent with a voltage of 1 V nominal with a 100 mV receiver threshold; the receiver uses equalization. SSC clock and 300 ppm precision is used. Packet headers are protected with CRC-16, while data payload is protected with CRC-32.
Power up to 3.6 W may be used. One unit load in superspeed mode is equal to 150 mA.
Transmission rates.
The theoretical maximum data rate in USB 2.0 is 480 Mbit/s (60 MB/s) per controller and is shared amongst all attached devices. Some chipset manufacturers overcome this bottleneck by providing multiple USB 2.0 controllers within the southbridge.
According to routine testing performed by CNet, write operations to typical Hi-Speed (USB 2.0) hard drives can sustain rates of 25–30 MB/s, while read operations are at 30–42 MB/s; this is 70% of the total available bus bandwidth. For USB 3.0, typical write speed is 70–90 MB/s, while read speed is 90–110 MB/s. Mask Tests, also known as Eye Diagram Tests, are used to determine the quality of a signal in the time domain. They are defined in the referenced document as part of the electrical test description for the high-speed (HS) mode at 480 Mbit/s.
According to a USB-IF chairman, "at least 10 to 15 percent of the stated peak 60 MB/s (480 Mbit/s) of Hi-Speed USB goes to overhead—the communication protocol between the card and the peripheral. Overhead is a component of all connectivity standards". Tables illustrating the transfer limits are shown in Chapter 5 of the USB spec.
For isochronous devices like audio streams, the bandwidth is constant, and reserved exclusively for a given device. The bus bandwidth therefore only has an effect on the number of channels that can be sent at a time, not the "speed" or latency of the transmission.
Latency.
For USB1 low-speed (1.5 Mbit/s) and full-speed (12 Mbit/s) devices the shortest time for a transaction in one direction is 1 ms. USB2 high-speed (480 Mbit/s) uses transactions within each micro frame (125 µs) where using 1-byte interrupt packet results in a minimal response time of 940 ns. 4-byte interrupt packet results in 984 ns.
Communication.
During USB communication data is transmitted as packets. Initially, all packets are sent from the host, via the root hub and possibly more hubs, to devices. Some of those packets direct a device to send some packets in reply.
After the sync field, all packets are made of 8-bit bytes, transmitted least-significant bit first. The first byte is a packet identifier (PID) byte. The PID is actually 4 bits; the byte consists of the 4-bit PID followed by its bitwise complement. This redundancy helps detect errors. (Note also that a PID byte contains at most four consecutive 1 bits, and thus never needs bit-stuffing, even when combined with the final 1 bit in the sync byte. However, trailing 1 bits in the PID may require bit-stuffing within the first few bits of the payload.)
Packets come in three basic types, each with a different format and CRC (cyclic redundancy check):
Handshake packets.
Handshake packets consist of only a single PID byte, and are generally sent in response to data packets. Error detection is provided by transmitting four bits that represent the packet type twice, in a single PID byte using complemented form. Three basic types are "ACK", indicating that data was successfully received, "NAK", indicating that the data cannot be received and should be retried, and "STALL", indicating that the device has an error condition and cannot transfer data until some corrective action (such as device initialization) occurs.
USB 2.0 added two additional handshake packets: "NYET" and "ERR". NYET indicates that a split transaction is not yet complete, while ERR handshake indicates that a split transaction failed. A second use for a NYET packet is to tell the host that the device has accepted a data packet, but cannot accept any more due to full buffers. This allows a host to switch to sending small PING tokens to inquire about the device's readiness, rather than sending an entire unwanted DATA packet just to elicit a NAK.
The only handshake packet the USB host may generate is ACK. If it is not ready to receive data, it should not instruct a device to send.
Token packets.
Token packets consist of a PID byte followed by two payload bytes: 11 bits of address and a five-bit CRC. Tokens are only sent by the host, never a device.
"IN" and "OUT" tokens contain a seven-bit device number and four-bit function number (for multifunction devices) and command the device to transmit DATAx packets, or receive the following DATAx packets, respectively. An IN token expects a response from a device. The response may be a NAK or STALL response, or a DATAx frame. In the latter case, the host issues an ACK handshake if appropriate. An OUT token is followed immediately by a DATAx frame. The device responds with ACK, NAK, NYET, or STALL, as appropriate.
"SETUP" operates much like an OUT token, but is used for initial device setup. It is followed by an eight-byte DATA0 frame with a standardized format.
Every millisecond (12000 full-bandwidth bit times), the USB host transmits a special "SOF" (start of frame) token, containing an 11-bit incrementing frame number in place of a device address. This is used to synchronize isochronous and interrupt data transfers. High-bandwidth USB 2.0 devices receive seven additional SOF tokens per frame, each introducing a 125 µs "microframe" (60000 high-bandwidth bit times each).
USB 2.0 added "PING" token, which asks a device if it is ready to receive an OUT/DATA packet pair. PING is usually sent by a host when polling a device that most recently responded with NAK or NYET. This avoids the need to send a large data packet to a device that the host suspects to be unwilling to accept it. The device responds with ACK, NAK or STALL, as appropriate.
USB 2.0 also added a larger three-byte "SPLIT" token with a seven-bit hub number, 12 bits of control flags, and a five-bit CRC. This is used to perform split transactions. Rather than tie up the high-bandwidth USB bus sending data to a slower USB device, the nearest high-bandwidth capable hub receives a SPLIT token followed by one or two USB packets at high bandwidth, performs the data transfer at full or low bandwidth, and provides the response at high bandwidth when prompted by a second SPLIT token.
Data packets.
A data packet consists of the PID followed by 0–1,024 bytes of data payload (up to 1,024 bytes for high-speed devices, up to 64 bytes for full-speed devices, and at most eight bytes for low-speed devices), and a 16-bit CRC.
There are two basic forms of data packet, "DATA0" and "DATA1". A data packet must always be preceded by an address token, and is usually followed by a handshake token from the receiver back to the transmitter. The two packet types provide the 1-bit sequence number required by Stop-and-wait ARQ. If a USB host does not receive a response (such as an ACK) for data it has transmitted, it does not know if the data was received or not; the data might have been lost in transit, or it might have been received but the handshake response was lost.
To solve this problem, the device keeps track of the type of DATAx packet it last accepted. If it receives another DATAx packet of the same type, it is acknowledged but ignored as a duplicate. Only a DATAx packet of the opposite type is actually received.
If the data is corrupted while transmitted or received, the CRC check fails. When this happens, the receiver does not generate an ACK, which makes the sender resend the packet.
When a device is reset with a SETUP packet, it expects an 8-byte DATA0 packet next.
USB 2.0 added "DATA2" and "MDATA" packet types as well. They are used only by high-bandwidth devices doing high-bandwidth isochronous transfers that must transfer more than 1024 bits per 125 µs microframe (8,192 kB/s).
PRE packet.
Low-bandwidth devices are supported with a special PID value, "PRE". This marks the beginning of a low-bandwidth packet, and is used by hubs that normally do not send full-bandwidth packets to low-bandwidth devices. Since all PID bytes include four 0 bits, they leave the bus in the full-bandwidth K state, which is the same as the low-bandwidth J state. It is followed by a brief pause, during which hubs enable their low-bandwidth outputs, already idling in the J state. Then a low-bandwidth packet follows, beginning with a sync sequence and PID byte, and ending with a brief period of SE0. Full-bandwidth devices other than hubs can simply ignore the PRE packet and its low-bandwidth contents, until the final SE0 indicates that a new packet follows.
Comparisons with other connection methods.
FireWire.
At first, USB was considered a complement to IEEE 1394 (FireWire) technology, which was designed as a high-bandwidth serial bus that efficiently interconnects peripherals such as disk drives, audio interfaces, and video equipment. In the initial design, USB operated at a far lower data rate and used less sophisticated hardware. It was suitable for small peripherals such as keyboards and pointing devices.
The most significant technical differences between FireWire and USB include:
These and other differences reflect the differing design goals of the two buses: USB was designed for simplicity and low cost, while FireWire was designed for high performance, particularly in time-sensitive applications such as audio and video. Although similar in theoretical maximum transfer rate, FireWire 400 is faster than USB 2.0 Hi-Bandwidth in real-use, especially in high-bandwidth use such as external hard-drives. The newer FireWire 800 standard is twice as fast as FireWire 400 and faster than USB 2.0 Hi-Bandwidth both theoretically and practically. However, Firewire's speed advantages rely on low-level techniques such as direct memory access (DMA), which in turn have created opportunities for security exploits such as the DMA attack.
The chipset and drivers used to implement USB and FireWire have a crucial impact on how much of the bandwidth prescribed by the specification is achieved in the real world, along with compatibility with peripherals.
Ethernet.
The IEEE 802.3af Power over Ethernet (PoE) standard specifies a more elaborate power negotiation scheme than powered USB. It operates at 48 V DC and can supply more power (up to 12.95 W, PoE+ 25.5 W) over a cable up to 100 meters compared to USB 2.0, which provides 2.5 W with a maximum cable length of 5 meters. This has made PoE popular for VoIP telephones, security cameras, wireless access points and other networked devices within buildings. However, USB is cheaper than PoE provided that the distance is short, and power demand is low.
Ethernet standards require electrical isolation between the networked device (computer, phone, etc.) and the network cable up to 1500 V AC or 2250 V DC for 60 seconds. USB has no such requirement as it was designed for peripherals closely associated with a host computer, and in fact it connects the peripheral and host grounds. This gives Ethernet a significant safety advantage over USB with peripherals such as cable and DSL modems connected to external wiring that can assume hazardous voltages under certain fault conditions.
MIDI.
Digital musical instruments are another example where USB is competitive in low-cost devices. However Power over Ethernet and the MIDI plug standard have an advantage in high-end devices that may have long cables. USB can cause ground loop problems between equipment, because it connects ground references on both transceivers. By contrast, the MIDI plug standard and Ethernet have built-in isolation to or more.
eSATA/eSATAp.
The eSATA connector is a more robust SATA connector, intended for connection to external hard drives and SSDs. eSATA's transfer rate (up to 6 Gbit/s) is similar to that of USB 3.0 (up to 5 Gbit/s on current devices; 10 Gbit/s speeds via USB 3.1, announced on 31 July 2013). A device connected by eSATA appears as an ordinary SATA device, giving both full performance and full compatibility associated with internal drives.
eSATA does not supply power to external devices. This is an increasing disadvantage compared to USB. Even though USB 3.0's 4.5 W is sometimes insufficient to power external hard drives, technology is advancing and external drives gradually need less power, diminishing the eSATA advantage. eSATAp (power over eSATA; aka ESATA/USB) is a connector introduced in 2009 that supplies power to attached devices using a new, backward compatible, connector. On a notebook eSATAp usually supplies only 5 V to power a 2.5-inch HDD/SSD; on a desktop workstation it can additionally supply 12 V to power larger devices including 3.5-inch HDD/SSD and 5.25-inch optical drives.
eSATAp support can be added to a desktop machine in the form of a bracket connecting to motherboard SATA, power, and USB resources.
eSATA, like USB, supports hot plugging, although this might be limited by OS drivers and device firmware.
Thunderbolt.
Thunderbolt combines PCI Express and Mini DisplayPort into a new serial data interface. Current Thunderbolt implementations have two channels, each with a transfer speed of 10 Gbit/s, resulting in an aggregate unidirectional bandwidth of 20 Gbit/s.
Interoperability.
Various protocol converters that convert USB data signals to and from other communications standards.
Related standards.
The USB Implementers Forum is working on a wireless networking standard based on the USB protocol. Wireless USB is intended as a cable-replacement technology, and uses ultra-wideband wireless technology for data rates of up to 480 Mbit/s.
USB 2.0 High Speed Inter Chip (HSIC) is a chip-to-chip variant of USB 2.0 that eliminates the conventional analog transceivers found in normal USB. It was adopted as a standard by the USB Implementers Forum in 2007. The HSIC physical layer uses about 50% less power and 75% less board area compared to traditional USB 2.0. HSIC uses two signals at 1.2 V and has a throughput of 480 Mbit/s using 240 MHz DDR signaling. Maximum PCB trace length for HSIC is 10 cm. It does not have low enough latency to support RAM memory sharing between two chips.

</doc>
<doc id="32077" url="http://en.wikipedia.org/wiki?curid=32077" title="United States presidential election, 1996">
United States presidential election, 1996

 Bill Clinton
Bill Clinton
The United States presidential election of 1996 was the 53rd quadrennial presidential election. It was held on Tuesday, November 5, 1996. The contest was between the Democratic national ticket of President Bill Clinton from Arkansas and Vice President Al Gore from Tennessee and the Republican national ticket of former Senator Bob Dole of Kansas for President and former Housing Secretary Jack Kemp from New York for Vice President. Businessman Ross Perot ran as candidate for the Reform Party with economist Pat Choate as his running mate; he received less media attention and was excluded from the presidential debates and, while still obtaining substantial results for a third-party candidate, by U.S. standards, did not renew his success of the 1992 election.
President Clinton's chances of winning were initially considered slim in the middle of his term as his party had lost both the House and the Senate in 1994 for the first time in decades; he had reneged on promises to cut taxes in order to reduce the deficit, enacted a Federal assault weapons ban, and had a failed healthcare reform initiative. He was able to regain ground as the economy began to recover from the early 1990s recession with a relatively stable world stage. He went on to win re-election with a substantial margin in the popular vote and electoral college. Despite Dole's defeat, the Republican Party was able to maintain a majority in both the House of Representatives and the Senate.
Background.
In 1995, the Republican Party was riding high on the significant gains made in the 1994 mid-term elections. In those races, the Republicans, led by whip Newt Gingrich, captured the majority of seats in the House for the first time in forty years and the majority of seats in the Senate for the first time in eight years. Gingrich became Speaker of the House, while Bob Dole elevated to Senate Majority leader.
The Republicans of the 104th Congress pursued an ambitious agenda, highlighted by their Contract with America, but were often forced to compromise with President Clinton, who wielded veto power. A budget impasse between Congress and the Clinton Administration eventually resulted in a government shutdown. Clinton, meanwhile, was praised for signing the GOP's welfare reform and other notable bills, but was forced to abandon his own health care plan.
Nominations.
Democratic Party nomination.
Democratic Candidates
Candidates gallery.
With the advantage of incumbency, Bill Clinton's path to renomination by the Democratic Party was uneventful. At the 1996 Democratic National Convention, Clinton and incumbent Vice President Al Gore were renominated with token opposition. Incarcerated fringe candidate Lyndon LaRouche won a few Arkansas delegates who were barred from the convention. Jimmy Griffin, former Mayor of Buffalo, New York, mounted a brief campaign but withdrew after a poor showing in the New Hampshire primary. Former Pennsylvania governor Bob Casey contemplated a challenge to Clinton, but health problems forced Casey to abandon a bid.
Clinton easily won primaries nationwide, with margins consistently higher than 80%.
Republican Party nomination.
Republican Candidates
Candidates gallery.
A number of Republican candidates entered the field to challenge the incumbent Democratic President, Bill Clinton.
The fragmented field of candidates debated issues such as a flat tax and other tax cut proposals, and a return to supply-side economic policies popularized by Ronald Reagan. More attention was drawn to the race by the budget stalemate in 1995 between the Congress and the President, which caused temporary shutdowns and slowdowns in many areas of federal government service.
Former U.S. Army General Colin Powell was widely courted as a potential Republican nominee. However, on November 8, 1995, Powell announced that he would not seek the nomination. Former Secretary of Defense and future Vice President of the United States Dick Cheney was touted by many as a possible candidate for the presidency, but he declared his intentions not to run in early 1995. Former and future Defense Secretary Donald Rumsfeld formed a presidential campaign exploratory committee, but declined to formally enter the race.
Primaries and convention.
Ahead of the 1996 primary contest, Senate majority leader and former vice-presidential nominee Bob Dole was seen as the most likely winner. However, Steve Forbes finished first in Delaware and Arizona while paleoconservative firebrand Pat Buchanan managed early victories in Alaska and Louisiana, in addition to a strong second place in the Iowa caucuses and a surprising victory in the small but key New Hampshire primary. Buchanan's New Hampshire win alarmed the Republican "establishment" sufficiently as to provoke prominent Republicans to quickly coalesce around Dole, and Dole won every primary starting with North and South Dakota. Dole resigned his Senate seat on June 11 and the Republican National Convention formally nominated Dole on August 15, 1996 for President.
Popular primaries vote
Convention tally:
Former Congressman and Housing Secretary Jack Kemp was nominated by acclamation for Vice President, the following day.
Third Parties and Independents.
Reform Party nomination.
Reform candidates:
The United States Reform Party had great difficulty in finding a candidate willing to run in the general election. Lowell Weicker, Tim Penny, David Boren and Richard Lamm were among those who toyed with the notion of seeking its presidential nomination, though all but Lamm decided against it; Lamm had himself come close to withdrawing his name from consideration.
Ultimately, the Reform Party nominated its founder Ross Perot of Texas in its first election as an official political party. Although Perot easily won the nomination, his victory at the party's national convention led to a schism as supporters of Lamm accused him of rigging the vote to prevent them from casting their ballots. This faction walked out of the national convention and eventually formed their own group, the American Reform Party, and attempted to convince Lamm to run as an Independent in the general election; Lamm declined, pointing out a promise he made before running that he would respect the Party's final decision.
Economist Pat Choate was nominated for Vice President.
Libertarian Party nomination.
Libertarian candidates:
The Libertarian Party nominated free-market writer and investment analyst, Harry Browne of Tennessee, and selected Jo Jorgensen of South Carolina as his running-mate. Browne and Jorgensen drew 485,798 votes (0.51% of the popular vote).
Natural Law Party Nomination.
Natural Law candidate:
The Natural Law Party for a second time nominated scientist and researcher John Hagelin for President and Mike Tompkins for Vice President. The party platform included preventive health care, sustainable agriculture and renewable energy technologies. During his campaigns, Hagelin favored abortion rights without public financing, campaign finance law reform, improved gun control, a flat tax, the eradication of PACs, a ban on soft money contributions, and school vouchers.
Hagelin and Tompkins drew 113,671 votes (0.12% of the popular vote).
U.S. Taxpayers' Party Nomination.
U.S. Taxpayers' candidates:
The U.S. Taxpayers Party had run its first presidential ticket in 1992, it being head by Howard Phillips who had failed to find any prominent conservative willing to take the mantle. In 1996 the situation ultimately proved the same, though Pat Buchanan for a time was widely speculated to be planning on bolting to the Taxpayers' Party should the expected Republican nominee, Senator Bob Dole, name a Pro-Choice running-mate. When Jack Kemp, who is Pro-Life, was tapped for the position Buchanan agreed to endorse the Republican ticket. Again, Phillips found himself at a temporary post that was made permanent, with Herbert Titus being nominated for the Vice Presidency.
Phillips and Titus drew 182,820 votes (0.19% of the popular vote).
Green Party Nomination.
Green candidate:
The Green Party of the United States – Ralph Nader of Connecticut was drafted as a candidate for President of the United States on the Green Party ticket. He was not formally nominated by the Green Party USA, which was, at the time, the largest national Green group; instead he was nominated independently by various state Green parties (in some areas, he appeared on the ballot as an independent). Nader vowed to spend only $5,000 in his election campaign (to avoid having to file a financial statement with the FEC). Winona LaDuke, and Native American activist and economist from Wisconsin was named as his running-mate.
Nader and LaDuke drew 685,128 votes (0.71% of the popular vote).
Workers World Party Nomination.
Workers World candidate:
The Workers World Party nominated Monica Moorehead for President. Gloria La Riva, who has been on every ticket since 1984, was nominated for Vice President.
Moorehead and La Riva drew 29,083 votes (0.03% of the national popular vote).
Socialist Workers Party Nomination.
Workers World candidate:
The Socialist Workers Party nominated James Harris for President. Laura Garza was nominated for Vice President.
Harris and Garza drew 8,476 votes (0.01% of the national popular vote).
Other nominations.
The Peace and Freedom Party, largely based in California, nominated Marsha Feinland for the Presidency, while nominating Kate McClatchy for the Vice Presidency. Feinland and McClatchy received 25,332 votes "(0.03% of the National Vote)"
Ballot Access: California (54 Electoral)
<br>
The Socialist Equality Party nominated Jerry White for the Presidency and nominated Fred Mazelis for the Vice Presidency. White and Mazelis received 2,438 votes.
Ballot Access: Michigan, Minnesota, New Jersey (43 Electoral)
<br>
Charles E. Collins ran in the general election as an Independent after failing to attain the Republican or Constitution Party nominations for President. Rosemary Giumarra was his running mate. A group known as C.U.R.E. "(Constitutionally Unified Republic for Everyone)" also endorsed their candidacy. Collins and Giumarra received 8,941 votes "(0.01% of the National Vote)"
Ballot Access: Arkansas, Colorado, Mississippi, Tennessee, Washington (36 Electoral)
<br>Write-In Access: Arizona, California, Georgia, Idaho, Indiana, Kansas, Maryland, Missouri, Montana, Utah
<br>
The Socialist Party USA nominated Mary Cal Hollis of Colorado and Eric Chester of Massachusetts. Hollis and Chester received 4,765 votes.
Ballot Access: Arkansas, Colorado, Oregon, Vermont, Wisconsin (35 Electoral)
<br>Write-In Access: Florida, Indiana, Maryland, Massachusetts, Montana, Texas, Utah
<br>
The Prohibition Party nominated Earl Dodge and Rachel Bubar Kelly. Dodge and Kelly received 1,298 votes.
Ballot Access: Arkansas, Colorado, Tennessee, Utah (30 Electoral)
<br>Write-In Access: Illinois, Massachusetts
<br>
The Grassroots Party nominated Dennis Peron. Peron received 5,378 votes.
Ballot Access: Minnesota, Vermont (13 Electoral)
<br>
The American Party nominated Diane Beall Templin and Gary Van Horn. Templin and Van Horn received 1,847 votes.
Ballot Access: Colorado, Utah (13 Electoral)
<br>
Steve Michael ran as an Independent under the banner of the AIDS Cure Party, with Anne Northrup as his running mate. Michael and Northrup received 408 votes.
Ballot Access: Tennessee (11 Electoral)
<br>
The Independent Party of Utah nominated Alma Peter Crane and Connie Chandler. Crane and Chandler received 1,101 votes.
Ballot Access: Utah (5 Electoral)
General election.
Campaign.
Without meaningful primary opposition, Clinton was able to focus on the general election early, while Dole was forced to move to the right and spend his campaign reserves fighting off challengers. Political adviser Dick Morris urged Clinton to raise huge sums of campaign funds via soft money for an unprecedented early TV blitz of swing states promoting Clinton's agenda and record. As a result, Clinton could run a campaign through the summer defining his opponent as an aged conservative far from the mainstream before Dole was in a position to respond. Compared to the 50-year-old Clinton, then 73-year-old Dole appeared especially old and frail, as illustrated by an embarrassing fall off a stage during a campaign event. Dole further enhanced this contrast on September 18 when he made a reference to a no-hitter thrown the day before by Hideo Nomo of the "Brooklyn Dodgers", a team that had left Brooklyn for Los Angeles four decades earlier. A few days later Dole would make a joke about the remark saying "And I'd like to congratulate the St. Louis Cardinals on winning the N.L. Central. Notice I said the St. Louis Cardinals not the St. Louis Browns." (The Browns had left St. Louis after the 1954 season to become the Baltimore Orioles.)
With respect to the issues, Dole promised a 15% across-the-board reduction in income tax rates and made former Congressman and supply side advocate Jack Kemp his running mate. Bill Clinton framed the narrative against Dole early, painting him as a mere clone of unpopular House Speaker Newt Gingrich, warning America that Bob Dole would work in concert with the Republican Congress to slash popular social programs, like Medicare and Social Security, dubbed by Clinton as "Dole-Gingrich". Bob Dole's tax-cut plan found itself under attack from the White House, who said it would "blow a hole in the deficit" which had been cut nearly in half during his opponent's term.
Throughout the run-up to the general election, Clinton maintained comfortable leads in the polls over Dole and Perot. The televised debates featured only Dole and Clinton, locking out Perot and the other minor candidates from the discussion. Perot, who had been allowed to participate in the 1992 debates, would eventually take his case to court, seeking damages from not being in the debate, as well as citing unfair coverage from the major media outlets.
Throughout this campaign, Clinton was always leading in the polls, generally by large margins.
Campaign donations controversy.
In late September 1995, questions arose regarding the Democratic National Committee's fund-raising practices. In February the following year, China's alleged role in the campaign finance controversy first gained public attention after the "Washington Post" published a story stating that a U.S. Department of Justice investigation had discovered evidence that agents of China sought to direct contributions from foreign sources to the DNC before the 1996 presidential campaign. The paper wrote that intelligence information had showed the Chinese Embassy in Washington, D.C. was used for coordinating contributions to the DNC in violation of U.S. law forbidding non-American citizens from giving monetary donations to U.S. politicians and political parties. Seventeen people were eventually convicted for fraud or for funneling Asian funds into the U.S. elections.
One of the more notable events learned involved Vice President Al Gore and a fund-raising event held at Hsi Lai Temple in Hacienda Heights, California. The Temple event was organized by DNC fund-raisers John Huang and Maria Hsia. It is illegal under U.S. law for religious organizations to donate money to politicians or political groups due to their tax-exempt status. The U.S. Justice Department alleged Hsia facilitated $100,000 in illegal contributions to the 1996 Clinton-Gore re-election campaign through her efforts at the Temple. Hsia was eventually convicted by a jury in March 2000. The DNC eventually returned the money donated by the Temple's monks and nuns. Twelve nuns and employees of the Temple refused to answer questions by pleading the Fifth Amendment when they were subpoenaed to testify before Congress in 1997.
Results.
On election day, President Clinton won a decisive victory over Dole, becoming the first Democrat to win presidential reelection since Franklin Roosevelt. At age 50 years and 2 months, he also became the youngest person to win re-election to the office. In the popular vote, he outpolled Dole by over 8.2 million votes. The Electoral College map did not change much from the previous election, with the Democratic incumbent winning 379 votes to the Republican ticket's 159. In the West, Dole managed to narrowly win Colorado and Montana (both had voted for Clinton in 1992), while Clinton became the first Democrat to win the state of Arizona since Harry Truman in 1948. In the South, Clinton took Florida-a state which he failed to win in 1992– from the Republicans in exchange for the less electoral-vote-rich Georgia. The election helped to cement Democratic Presidential prospects in states including California, Vermont, Maine, Illinois, New Jersey, Pennsylvania, Michigan, Delaware, and Connecticut; all went on to vote Democratic in subsequent Presidential elections, having voted Republican in the three prior to 1992. Those states also voted for Richard Nixon in the 1972 landslide. 1996 marked the first time that Vermont voted for a Democrat in two successive elections.
Reform Party nominee Ross Perot won approximately 8% of the popular vote. His vote total was less than half of his performance in 1992. The 1996 national exit poll showed that just as in 1992, Reform Party nominee Ross Perot's supporters drew from Clinton and Dole equally. In polls directed at Perot voters as to who would be a second choice, Clinton consistently held substantial leads. Perot's best showing was in states that tended to strongly favor either Clinton (such as Maine) or Dole (particularly Montana, though the margin of victory there was much closer). Perot once again received his lowest amount of support in the South.
Although Clinton is a native of Arkansas, and his running mate hailed from Tennessee, the Democratic ticket carried just four of the eleven states of the American South. This tied Clinton's 1992 run for the weakest performance by a winning Democratic presidential candidate in the region before 2000 (in terms of states won). Clinton's performance seems to have been part of a broader decline in support for the Democratic Party in the South. In the 2000 and 2004 elections, the Democrats would fail to carry even one of the Southern states, contributing to their defeat both times. This completed the Republican takeover of the American South, a region in which Democrats had held a near monopoly from 1880 to 1948. However, in 2008, the Democrats were able to win three Southern States, but that was still worse than Clinton's performances in both 1992 and 1996. This was the last election in which a third-party candidate carried over 3% of the national popular vote. Since 1984, no winning Presidential candidate has surpassed Bill Clinton's 8.5 percentage popular vote margin, or his 220 electoral vote margin since 1988. Also note that no Democratic Presidential candidate has surpassed Clinton's 8.5 percentage popular vote margin since 1940 (except 1964), and no Democratic Presidential candidate has surpassed his electoral vote margin since 1964.
The election was also notable for the fact that for the first time in U.S. history the winner was elected without winning the male vote and the third time in U.S. history that a candidate was elected President twice without receiving an absolute majority of the popular vote in either election (Grover Cleveland and Woodrow Wilson are the others, although all three won pluralities [i.e. the most votes]).
Clinton was the first Democrat to win re-election to the presidency since Franklin D. Roosevelt, and the first Southern Democrat to win re-election since Andrew Jackson in 1832.
This was the last time the following states voted Democratic: Arizona, Arkansas, Tennessee, Louisiana, Kentucky, West Virginia and Missouri as of the 2012 election.
Official Source (Popular Vote): 
Source (popular and electoral vote): 
unofficial
Secondary Source (Popular Vote): Leip, David. . "" ().
Voting age population: 196,498,000
Percent of voting age population casting a vote for President: 49.00%
(a) "In New York, the Clinton vote was a fusion of the Democratic and Liberal slates. There, Clinton obtained 3,649,630 votes on the Democratic ticket and 106,547 votes on the Liberal ticket."
(b) "In New York, the Dole vote was a fusion of the Republican, Conservative, and Freedom slates. There, Dole obtained 1,738,707 votes on the Republican ticket, 183,392 votes on the Conservative ticket, and 11,393 votes on the Freedom ticket."
(c) "In South Carolina, the Perot vote was a fusion of the Reform and Patriot slates. There, Perot obtained 27,464 votes on the Reform ticket and 36,913 votes on the Patriot ticket."
(d) "On the California, Indiana, Iowa, Kansas, Louisiana, Maine, Maryland, Missouri, Montana, Oregon, South Dakota, Tennessee, and Texas election ballots, James Campbell of California, Perot's former boss at IBM, was listed as a stand-in Vice-Presidential candidate until Perot decided on Pat Choate as his choice for Vice President." 
(e) "The Green Party vice presidential candidate varied from state to state. Winona LaDuke was his vice presidential candidate in eighteen of the twenty-two states where he appeared on the ballot. Anne Goeke was Nader's running mate in Iowa and Vermont. Madelyn Hoffman was his running mate in New Jersey. Muriel Tillinghast was his running mate in New York."
(f) "Candidates receiving less than 0.05% of the total popular vote."
Results by state.
Close states.
States where the margin of victory was under 5% (117 electoral votes):
States where the margin of victory was between 5% and 10% (143 electoral votes):
Voter demographics.
Source: Voter News Service exit poll, reported in "The New York Times", November 10, 1996, 28.
Polling controversy.
Some post-election debate focused on the alleged flaws in the pre-election polls, almost all of which overstated Clinton's lead over Dole, some by a substantial margin. For example, a CBS/New York Times poll overstated Clinton's lead by 10 points despite having an error margin of 2.4%. The odds against this sort of error occurring were 15,000:1. A less extreme example was a Pew poll which overstated Clinton's lead by 5 points, the chances of this happening were 10:1 against. Gerald Wasserman, having examined eight pre-election polls, argued that pure chance would produce such a skewed result in favor of Clinton only once in 4,900 elections. However, because Clinton won the election by a comfortable margin, there was no major reaction towards the inaccuracy of the polls. The polls were also less inaccurate than the overwhelming majority of those taken in 1948, which predicted that losing candidate Thomas Dewey would beat President Harry Truman by a comfortable margin, and in 1980, which predicted that Reagan would win without a landslide victory.

</doc>
<doc id="32078" url="http://en.wikipedia.org/wiki?curid=32078" title="Whig Party (United States)">
Whig Party (United States)

The Whig Party was a political party active in the middle of the 19th century in the United States of America. Four Presidents of the United States were members of the Whig Party. Considered integral to the Second Party System and operating from the early 1830s to the mid-1850s, the party was formed in opposition to the policies of President Andrew Jackson and his Democratic Party. In particular, the Whigs supported the supremacy of Congress over the Presidency and favored a program of modernization and economic protectionism. This name was chosen to echo the American Whigs of 1776, who fought for independence, and because "Whig" was then a widely recognized label of choice for people who identified as opposing tyranny.
The Whig Party nominated for president such national political luminaries as Daniel Webster and their preeminent leader, Henry Clay of Kentucky. The Whig Party also nominated for president war hero generals William Henry Harrison, Zachary Taylor, and Winfield Scott in 1840, 1848 and 1852 respectively.
In its two decades of existence, the Whig Party had two of its candidates, William Henry Harrison and Zachary Taylor, elected President. Both died in office. John Tyler succeeded to the Presidency after Harrison's death, but was expelled from the party. Millard Fillmore, who became President after Taylor's death, was the last Whig to hold the nation's highest office.
The party was ultimately destroyed by the question of whether to allow the expansion of slavery to the territories. With deep fissures in the party on this question, the anti-slavery faction prevented the nomination for a full-term of its own incumbent, President Fillmore, in the 1852 presidential election; instead, the party nominated General Winfield Scott. Most Whig party leaders eventually quit politics (as Abraham Lincoln did temporarily) or changed parties. The northern voter base mostly joined the new Republican Party. By the 1856 presidential election, the party was defunct. In the South, the party vanished, but Whig ideology as a policy orientation persisted for decades and played a major role in shaping the modernizing policies of the state governments during Reconstruction.
Origins.
The name "Whig" was derived from a common term that Patriots used to refer to themselves during the American Revolution. It indicated hostility to the British Sovereign, and despite the identical name, it was not directly derived from the British Whig party.
The American Whigs were modernizers who saw President Andrew Jackson as "a dangerous man on horseback" with a "reactionary opposition" to the forces of social, economic, and moral modernization. Most of the founders of the Whig party had supported Jeffersonian democracy and the Democratic-Republican Party. The Democratic-Republicans who formed the Whig party, led by Henry Clay and John Quincy Adams, drew on a Jeffersonian tradition of compromise and balance in government, national unity, territorial expansion, and support for a national transportation network and domestic manufacturing. Casting their enemy as "King Andrew", they sought to identify themselves as modern-day opponents of governmental overreaching.
Despite the apparent unity of Jefferson's Democratic-Republicans from 1800 to 1824, the American people ultimately preferred partisan opposition to popular political agreement. As Jackson purged his opponents, vetoed internal improvements, and killed the Second Bank of the United States, alarmed local elites fought back. In 1831, Henry Clay re-entered the Senate and started planning a new party. He defended national rather than sectional interests. Clay's plan for distributing the proceeds from the sale of lands among the states in the public domain was intended to serve the nation by providing the states with funds for building roads and canals, which would stimulate growth and knit the sections together. His Jacksonian opponents, however, distrusted the federal government and opposed all federal aid for internal improvements and they again frustrated Clay's plan. Jacksonians promoted opposition to the National Bank and internal improvements and support of egalitarian democracy, state power, and hard money.
The "Tariff of Abominations" of 1828 had outraged Southern feelings; the South's leaders held that the high duties on foreign imports gave an advantage to the North (where the factories were located). Clay's own high tariff schedule of 1832 further disturbed them, as did his stubborn defense of high duties as necessary to his "American System". Clay however moved to pass the Compromise of 1833, which met Southern complaints by a gradual reduction of the rates on imports to a maximum of twenty percent. Controlling the Senate for a while, Whigs passed a censure motion denouncing Jackson's arrogant assumption of executive power in the face of the true will of the people as represented by Congress.
Clay ran as a Whig against Jackson in 1832, but carried only 49 electoral votes against Jackson's 219. Clay and his Whig allies failed in repeated attempts to continue the Second Bank of the United States, which Jackson denounced as a monopoly and from which he abruptly removed all government deposits. Clay was the unquestioned leader of the Whig party nationwide and in Washington, but he was vulnerable to Jacksonian allegations that he associated with the upper class at a time when white males without property had the right to vote and wanted someone more like themselves. The Whigs nominated a war hero in 1840—and emphasized that William Henry Harrison had given up the high life to live in a log cabin on the frontier. Harrison won.
Party structure.
The Whigs suffered greatly from factionalism throughout their existence, as well as weak party loyalty that stood in contrast to the strong party discipline that was the hallmark of a tight Democratic Party organization. One strength of the Whigs, however, was a superb network of newspapers; their leading editor was Horace Greeley of the powerful "New York Tribune".
In the 1840s Whigs won 49 percent of gubernatorial elections, with strong bases in the manufacturing Northeast and in the border states. The trend over time, however, was for the Democratic vote to grow faster and for the Whigs to lose more and more marginal states and districts. After the close 1844 contest, the Democratic advantage widened and the Whigs could win the White House only if the Democrats split. This was partly because of the increased political importance of the western states, which generally voted for Democrats, and Irish Catholic and German immigrants, who voted heavily for the Democrats.
The Whigs appealed to voters in every socio-economic category but proved especially attractive to the professional and business classes: doctors, lawyers, merchants, ministers, bankers, storekeepers, factory owners, commercially oriented farmers and large-scale planters. In general, commercial and manufacturing towns and cities voted Whig, save for strongly Democratic precincts in Irish Catholic and German immigrant communities; the Democrats often sharpened their appeal to the poor by ridiculing the Whigs' aristocratic pretensions. Protestant religious revivals also injected a moralistic element into the Whig ranks.
Whig issues.
The Whigs celebrated Clay's vision of the "American System" that promoted rapid economic and industrial growth in the United States. Whigs demanded government support for a more modern, market-oriented economy, in which skill, expertise and bank credit would count for more than physical strength or land ownership. Whigs sought to promote faster industrialization through high tariffs, a business-oriented money supply based on a national bank and a vigorous program of government funded "internal improvements" (what we now call infrastructure projects), especially expansion of the road and canal systems. To modernize the inner America, the Whigs helped create public schools, private colleges, charities, and cultural institutions. Many were pietistic Protestant reformers who called for public schools to teach moral values and proposed prohibition to end the liquor problem.
The Democrats harkened to the Jeffersonian ideal of an egalitarian agricultural society, advising that traditional farm life bred republican simplicity, while modernization threatened to create a politically powerful caste of rich aristocrats who threatened to subvert democracy. In general the Democrats enacted their policies at the national level, while the Whigs succeeded in passing modernization projects in most states.
Education.
Arguing that universal public education was the best way to turn the nation's unruly children into disciplined, judicious republican citizens, Horace Mann (1796–1859) won widespread approval from modernizers, especially among fellow Whigs, for building public schools. Indeed, most states adopted one version or another of the system he established in Massachusetts, especially the program for "normal schools" to train professional teachers.
1836–1840.
In the 1836 elections, the party was not yet sufficiently organized to run one nationwide candidate; instead William Henry Harrison was its candidate in the northern and border states, Hugh Lawson White ran in the South, and Daniel Webster ran in his home state of Massachusetts. Whigs hoped that their three candidates would amass enough Electoral College votes among them to deny a majority to Martin Van Buren. That would move the election to the House of Representatives, allowing the ascendant Whigs to select their most popular man as president. The Whigs came only a few thousand votes short of victory in Pennsylvania, vindicating their strategy, but failed nonetheless.
In late 1839, the Whigs held their first national convention and nominated William Henry Harrison as their presidential candidate. In March 1840, Harrison pledged to serve only one term as President if elected, a pledge which reflected popular support for a Constitutional limit to Presidential terms among many in the Whig Party. Harrison went on to victory in 1840, defeating Van Buren's re-election bid largely as a result of the Panic of 1837 and subsequent depression. Harrison served only 31 days and became the first President to die in office. He was succeeded by John Tyler, a Virginian and states' rights absolutist. Tyler vetoed the Whig economic legislation and was expelled from the Whig party in September 1841. The Whigs' internal disunity and the nation's increasing prosperity made the party's activist economic program seem less necessary and led to a disastrous showing in the 1842 Congressional election.
A brief golden age.
The central issue in the 1840s was expansion, with proponents of "Manifest Destiny" arguing in favor of aggressive westward expansion even at the risk of war with Mexico (over the annexation of Texas) and Britain (over control of Oregon). Howe argues that, "Nevertheless American imperialism did not represent an American consensus; it provoked bitter dissent within the national polity." That is, most Democrats strongly supported Manifest Destiny and most Whigs strongly opposed it.
Faragher's analysis of the political polarization between the parties is that:
By 1844, the Whigs began their recovery by nominating Henry Clay, who lost to Democrat James K. Polk in a closely contested race, with Polk's policy of western expansion (particularly the annexation of Texas) and free trade triumphing over Clay's protectionism and caution over the Texas question. The Whigs, both northern and southern, strongly opposed expansion into Texas, which they (including Whig Congressman Abraham Lincoln) saw as an unprincipled land grab. In 1848, the Whigs, seeing no hope of success by nominating Clay, nominated General Zachary Taylor, a Mexican-American War hero. They stopped criticizing the war and adopted only a very vague platform. Taylor defeated Democratic candidate Lewis Cass and the anti-slavery Free Soil Party, who had nominated former President Martin Van Buren. Van Buren's candidacy split the Democratic vote in New York, throwing that state to the Whigs; at the same time, however, the Free Soilers probably cost the Whigs several Midwestern states.
Compromise of 1850.
Taylor was firmly opposed to the Compromise of 1850 and committed to the admission of California as a free state and had proclaimed that he would take military action to prevent secession. In July 1850, Taylor died; Vice President Millard Fillmore, a long-time Whig, became President, and he helped push the Compromise through Congress in the hopes of ending the controversies over slavery. The Compromise of 1850 had been first proposed by the Whig Henry Clay of Kentucky.
The Whigs were unable to deal with the slavery issue after 1850. Their southern leaders nearly all owned slaves. The northeastern Whigs, led by Daniel Webster, represented businessmen who loved national unity and a national market but cared little about slavery one way or another. However many Whig voters in the North thought that slavery was incompatible with a free-labor, free-market economy and supported the Wilmot Proviso, which did not pass Congress but would have stopped the expansion of slavery. No one discovered a compromise that would keep the party united. Furthermore, the burgeoning economy made full-time careers in business or law much more attractive than politics for ambitious young Whigs. Thus the Whig Party leader in Illinois, Abraham Lincoln, simply abandoned politics after 1849.
Death throes, 1852–1856.
When new issues of nativism, prohibition and anti-slavery burst on the scene in the mid-1850s, few looked to the quickly disintegrating Whig party for answers. In the north most ex-Whigs joined the new Republican party, and in the South, they flocked to a new short-lived "American" party.
The election of 1852 marked the beginning of the end for the Whigs. The deaths of Henry Clay and Daniel Webster that year severely weakened the party. The Compromise of 1850 fractured the Whigs along pro- and anti-slavery lines, with the anti-slavery faction having enough power to deny Fillmore the party's nomination in 1852. The Whig Party's 1852 convention in New York City saw the historic meeting between Alvan E. Bovay and "The New York Tribune"'s Horace Greeley, a meeting which led to correspondence between the men as the early Republican Party meetings in 1854 began to take place. Attempting to repeat their earlier successes, the Whigs nominated popular General Winfield Scott, who lost decisively to the Democrats' Franklin Pierce. The Democrats won the election by a large margin: Pierce won 27 of the 31 states including Scott's home state of New Jersey. Whig Representative Lewis D. Campbell of Ohio was particularly distraught by the defeat, exclaiming, "We are slain. The party is dead—dead—dead!" Increasingly politicians realized that the party was a loser. Abraham Lincoln, one of its leaders in Illinois, for example, ceased his Whig activities and attended to his law business.
In 1854, the Kansas–Nebraska Act, which opened the new territories to slavery, was passed. Southern Whigs generally supported the Act while Northern Whigs remained strongly opposed. Most remaining Northern Whigs, like Lincoln, joined the new Republican Party and strongly attacked the Act, appealing to widespread northern outrage over the repeal of the Missouri Compromise. Other Whigs joined the Know-Nothing Party, attracted by its nativist crusades against so-called "corrupt" Irish and German immigrants. In the South, the Whig party vanished, but as Thomas Alexander has shown, Whiggism as a modernizing policy orientation persisted for decades. Historians estimate that, in the South in 1856, former Whig Fillmore retained 86 percent of the 1852 Whig voters when he ran as the American Party candidate. He won only 13% of the northern vote, though that was just enough to tip Pennsylvania out of the Republican column. The future in the North, most observers thought at the time, was Republican. Scant prospects for the shrunken old party seemed extant, and after 1856 virtually no Whig organization remained at the regional level. Some Whigs and others adopted the mantle of the "Opposition Party" for several years and enjoyed some individual electoral successes.
Legacy.
In 1860, many former Whigs who had not joined the Republicans regrouped as the Constitutional Union Party, which nominated only a national ticket. It had considerable strength in the border states, which feared the onset of civil war. John Bell finished third in the electoral college.
During the Lincoln Administration (1861–65), ex-Whigs dominated the Republican Party and enacted much of their so-called "American System". Later their Southern colleagues dominated the White response to Reconstruction. In the long run, America adopted Whiggish economic policies coupled with a Democratic strong presidency.
In the South during the latter part of the American Civil War and during the Reconstruction Era, many former Whigs tried to regroup in the South, calling themselves "Conservatives" and hoping to reconnect with the ex-Whigs in the North. These were merged into the Democratic Party in the South, but they continued to promote modernization policies such as large-scale railroad construction and the founding of public schools.
In today's discourse in American politics, the Whig Party is often cited as an example of a political party that lost its followers and its reason for being, as by the expression "going the way of the Whigs." However, the Whig program for "internal improvements" or infrastructure spending is now enshrined as an important role of government by nearly all political leaders, especially during economic downturns.
The True Whig Party—named in direct emulation of the American Whig party—was the dominant force in the politics of Liberia for more than a century.
Namesakes.
Occasionally small groups form parties that take the Whig name. They seldom last long or elect anyone. 
In 2006, the Florida Whig Party was formed and fielded one candidate for congress in state elections of 2010. It disbanded in 2012.
In 2008, a group of veterans formed the Modern Whig Party. It presently has two members elected to a school board and a local position.
The 'Quincy Herald-Whig', a daily newspaper published as of 2014 in western Illinois, is a direct descendant of a 19th-century Whig party news sheet, the "Quincy Whig".
See also :Stephen Simpson, editor of the "Philadelphia Whig", a 19th-century newspaper devoted to the Whig cause.
Presidents from the Whig Party.
Presidents of the United States, dates in office
Additionally, John Quincy Adams, elected President as a Democratic-Republican, later became a National Republican and then a Whig after he was elected to the House of Representatives in 1831.
Presidents Abraham Lincoln, Rutherford B. Hayes, Chester A. Arthur, and Benjamin Harrison were Whigs before switching to the Republican Party, from which they were elected to office.
Bibliography.
</dl>

</doc>
<doc id="32080" url="http://en.wikipedia.org/wiki?curid=32080" title="Democratic-Republican Party">
Democratic-Republican Party

The term Democratic-Republican Party is the name used primarily by modern political scientists for the first "Republican Party" (as it called itself at the time), also known as the Jeffersonian Republicans. Historians usually use "Republican Party". It was the second political party in the United States, and was organized by then United States Secretary of State Thomas Jefferson and his friend and compatriot James Madison, (then serving in the House of Representatives) in 1791-93, to oppose the Federalist Party run by Secretary of the Treasury Alexander Hamilton. The new party controlled the Presidency and Congress, and most states, from 1801 to 1825, during the First Party System. Starting about 1791 one faction in Congress, many of whom had been opposed to the new Constitution, began calling themselves Republicans in the Second United States Congress. People at the time used the name Republican in mentioning the Republican Party of this period and the first two decades of the 19th Century. The Republican Party split after the 1824 presidential election into two parties: the Democratic Party and the short-lived National Republican Party (later succeeded by the Whig Party).
The organization formed first as an "Anti-Administration" secret meeting in the national capital (Philadelphia) to oppose the programs of Secretary of the Treasury Alexander Hamilton. Jefferson needed to have a nationwide party to challenge the Federalists, a nation-wide party organized by Hamilton. Foreign affairs took a leading role in 1794-95 as the Republicans vigorously opposed the Jay Treaty with Britain, which was then at war with France. Republicans saw France as more democratic after its revolution, while Britain represented the hated monarchy. The party denounced many of Hamilton's measures (especially the national bank) as unconstitutional.
The party was strongest in the South and weakest in the Northeast. It demanded states' rights as expressed by the "Principles of 1798" articulated in the Kentucky and Virginia Resolutions that would allow states to nullify a federal law. Above all the party stood for the primacy of the yeoman farmers. Republicans were deeply committed to the principles of republicanism, which they feared were threatened by the supposed monarchical tendencies of the Hamiltonians/Federalists. The party came to power in 1801 with the election of Jefferson in the 1800 presidential election. The Federalists — too elitist to appeal to most people — faded away, and totally collapsed after 1815. The Republicans, despite internal divisions, dominated the First Party System until partisanship itself withered away during the Era of Good Feelings after 1816.
The party selected its presidential candidates in a caucus of members of Congress. They included Thomas Jefferson (nominated 1796; elected 1800-1, 1804), James Madison (1808, 1812), and James Monroe (1816, 1820). By 1824, the caucus system had practically collapsed. After 1800, the party dominated Congress and most state governments outside New England. By 1824, the party was split 4 ways and lacked a center, as the First Party System collapsed. The emergence of the Second Party System in the 1830s saw a realignment of old factions. One remnant followed Andrew Jackson and Martin Van Buren into the new Democratic Party by 1828. That party still exists. Another remnant led by John Quincy Adams and Henry Clay formed the National Republicans in 1828; it morphed into the Whig Party by 1835.
Founding.
Congressman James Madison started the party among Representatives in Philadelphia (then the national capital) as the "Republican party"; then he, Jefferson, and others reached out to include state and local leaders around the country, especially New York and the South. The precise date of founding is disputed, but 1791 is a reasonable estimate; some time by 1792 is certain. The new party set up newspapers that made withering critiques of Hamiltonianism, extolled the yeoman farmer, argued for strict construction of the Constitution, favored the French Revolution, strongly opposed Great Britain, and called for stronger state governments than the Federalist Party was proposing.
Presidential elections of 1792 and 1796.
The elections of 1792 were the first ones to be contested on anything resembling a partisan basis. In most states the congressional elections were recognized, as Jefferson strategist John Beckley put it, as a "struggle between the Treasury department and the republican interest". In New York, the candidates for governor were John Jay, a Federalist, and incumbent George Clinton, who was allied with Jefferson and the Republicans. Four states' electors voted for Clinton and one (Kentucky) for Jefferson for Vice President in opposition to incumbent John Adams as well as casting their votes for President Washington. (Before 1804 electors cast two votes together without differentiation as to which office was to be filled by which candidate.)
In the 1796 election, the party made its first bid for the presidency with Jefferson as its presidential candidate and Aaron Burr as its vice presidential candidate. Jefferson came in second in the electoral college (at the time, its balloting could not distinguish between president and vice president) and became vice president. He would become a consistent and strong opponent of the policies of the John Adams administration. Jefferson and Madison were deeply upset by the unconstitutionality of the Alien and Sedition Acts of 1798; they secretly wrote the Kentucky and Virginia Resolutions, which called on state legislatures to nullify unconstitutional laws. The other states, however, did not follow suit and several rejected the notion that states could nullify federal law. The Republican critique of federalism became wrapped in the slogan of "Principles of 1798", which became the hallmark of the party. The most important of these principles were states' rights, opposition to a strong national government, distrust of the federal courts, and opposition to the navy and the national bank. The party saw itself as a champion of republicanism and denounced the Federalists as supporters of monarchy and aristocracy.
The party itself originally coalesced around Jefferson, who diligently maintained extensive correspondence with like-minded Republican leaders throughout the country. Washington frequently decried the growing sense of "party" emerging from the internal battles among Jefferson, Madison, Hamilton, Adams and others in his administration. As warfare in Europe increased, the two factions increasingly made foreign policy the central political issue of the day. The Republicans wanted to maintain the 1777 alliance with France, which had overthrown the monarchy and aristocracy and become a republic. Even though Britain was by far America's leading trading partner, Republicans feared that increased trade would undermine republicanism. The Republicans distrusted Hamilton's national bank and rejected his premise that a national debt was good for the country; Republicans said they were both forms of corruption. They strongly distrusted the elitism of Hamilton's circle, denouncing it as "aristocratic"; and they called for states' rights lest the Federalists centralize ever more power in the national governments.
The intense debate over the Jay Treaty in 1794–95, transformed those opposed to Hamilton's policies from a loose movement into a true political party. To fight the treaty the Jeffersonians "established coordination in activity between leaders at the capital, and leaders, actives and popular followings in the states, counties and towns." However, they were defeated when Washington mobilized public opinion in favor of the treaty.
Strength in Congress over time.
Historians have used statistical techniques to estimate the party breakdown in Congress. Many Congressmen were hard to classify in the first few years, but after 1796 there was less uncertainty.
The affiliation of many Congress-men in the earliest years is an assignment by later historians; these were slowly coalescing groups with initially considerable independent thinking and voting; Cunningham noted that only about a quarter of the House of Representatives, up till 1794, voted with Madison as much as two-thirds of the time, and another quarter against him two-thirds of the time, leaving almost half as fairly independent. Albert Gallatin recalled only two caucuses on legislative policy between 1795 and 1801, one over appropriations for Jay's Treaty, the other over the Quasi-War, and in neither case did the party decide to vote unanimously.
Organizational strategy.
The new party invented some of the campaign and organizational techniques which were later adopted by the Federalists and became standard American practice. It was especially effective in building a network of newspapers in major cities to broadcast its statements and editorialize its policies. Fisher Ames, a leading Federalist, used the term "Jacobin" to link members of Jefferson's party to the radicals of the French Revolution. He blamed the newspapers for electing Jefferson; they were, he wrote, "an overmatch for any Government... The Jacobins owe their triumph to the unceasing use of this engine; not so much to skill in use of it as by repetition."
As one historian explained, "It was the good fortune of the Republicans to have within their ranks a number of highly gifted political manipulators and propagandists. Some of them had the ability... to not only see and analyze the problem at hand but to present it in a succinct fashion; in short, to fabricate the apt phrase, to coin the compelling slogan and appeal to the electorate on any given issue in language it could understand." Outstanding propagandists included editor William Duane (1760-1835), and party leaders Albert Gallatin, Thomas Cooper and Jefferson himself.
Just as important was effective party organization of the sort that John J. Beckley pioneered. In 1796, he managed the Jefferson campaign in Pennsylvania, blanketing the state with agents who passed out 30,000 hand-written tickets, naming all 15 electors (printed tickets were not allowed). He told one agent, "In a few days a select republican friend from the City will call upon you with a parcel of tickets to be distributed in your County. Any assistance and advice you can furnish him with, as to suitable districts & characters, will I am sure be rendered." Beckley was the first American professional campaign manager, and his techniques were quickly adopted in other states.
The emergence of the new organizational strategies can be seen in the politics of Connecticut around 1806, which have been well documented by Cunningham. The Federalists dominated Connecticut, so the Republicans had to work harder to win. In 1806, the state leadership sent town leaders instructions for the forthcoming elections. Every town manager was told by state leaders "to appoint a district manager in each district or section of his town, obtaining from each an assurance that he will faithfully do his duty." Then the town manager was instructed to compile lists and total the number of taxpayers and the number of eligible voters, find out how many favored the Republicans and how many the Federalists, and to count the number of supporters of each party who were not eligible to vote but who might qualify (by age or taxes) at the next election. These highly detailed returns were to be sent to the county manager and in turn were compiled and sent to the state manager. Using these lists of potential voters, the managers were told to get all eligible people to town meetings and help the young men qualify to vote. The state manager was responsible for supplying party newspapers to each town for distribution by town and district managers. This highly coordinated "get-out-the-vote" drive would be familiar to modern political campaigners, but was the first of its kind in world history.
Revolution of 1800.
The party's electors secured a majority in the 1800 election, but an equal number of electors cast votes for Jefferson and Aaron Burr. The tie sent the election to the House, and Federalists there blocked any choice. Finally Hamilton, believing that Burr would be a poor choice for president, intervened, letting Jefferson win (a move that would result in the collapse of the Federalist Party and Hamilton's death, four years later, at the hands of Burr in a pistol duel). Starting in 1800 in what Jefferson called the "Revolution of 1800", the party took control of the presidency and both houses of Congress, beginning a quarter century of control of those institutions. A faction called "Old Republicans" opposed the nationalism that grew popular after 1815; they were stunned when party leaders started a Second Bank of the United States in 1816.
The first official Republican Congressional Caucus meeting took place at Marache's boarding house on May 11, 1800 in Philadelphia. The January 26, 1799 letter Thomas Jefferson wrote to Elbridge Gerry became the party's platform.
In the Senate chamber on February 25, 1804, a "Convention of Republican members of both houses of Congress" met. Senator Stephen Bradley presided, a Committee on Presidential Electors was formed and it was resolved that Thomas Jefferson be nominated for President and George Clinton be nominated Vice President.
The party held a convention by the same name on January 23, 1808, again in the Senate chamber at 6:00 pm on a Saturday. Senator Stephen Bradley, who was the President "pro tempore" of the Senate, again served as President of the convention with Representative Richard Johnson as the Secretary. A Committee on Correspondence was formed, James Madison was nominated for President, and George Clinton was re-nominated for Vice President.
Legislative issues were handled by the Committee of the Whole, and the elected Speaker of the House of Representatives and floor leaders, who at that time were the Chairman for the Committee on Ways and Means of the House of Representatives and Chairman for the Committee on Finance of the Senate.
The state legislatures often instructed Members of Congress how to vote on specific issues. More exactly, they "instructed" the Senators (who were elected by the legislatures), and "requested" the Representatives (who were elected by the people.) On rare occasions a Senator resigned rather than follow instructions.
The opposition Federalist Party, suffering from a lack of leadership after the death of Hamilton and the retirement of John Adams, quickly declined; it revived briefly in opposition to the War of 1812, but the extremism of its Hartford Convention of 1815 utterly destroyed it as a political force.
National debt.
Jefferson and Albert Gallatin focused on the danger that the public debt, unless it was paid off, would be a threat to republican values. They were appalled that Hamilton was increasing the national debt and using it to solidify his Federalist base. Gallatin was the Republican Party's chief expert on fiscal issues and as Treasury Secretary under Jefferson and Madison worked hard to lower taxes and lower the debt, while at the same time paying cash for the Louisiana Purchase and funding the War of 1812. Burrows says of Gallatin:
Monroe and Adams, 1816–1828.
In rapidly expanding western states, the Federalists had few supporters. Every state had a distinct political geography that shaped party membership. In Pennsylvania, the Republicans were weakest around Philadelphia and strongest in Scots-Irish settlements in the west. Members came from all social classes, but came predominantly from the poor, subsistence farmers, mechanics and tradesmen. After the War of 1812, partisanship subsided across the young republic—people called it the Era of Good Feelings. James Monroe narrowly won the party's nomination for President in Congress over William Crawford in 1816 and defeated Federalist Rufus King in the general election.
In the early years of the party, the key central organization grew out of caucuses of Congressional leaders in Washington. However, the key battles to choose electors occurred in the states, not in the caucus. In many cases, legislatures still chose electors; in others, the election of electors was heavily influenced by local parties that were heavily controlled by relatively small groups of officials. Without a significant Federalist opposition, the need for party unity was greatly diminished and the party's organization faded away.
James Monroe ran under the party's banner in the 1820 election and built support by consensus. Monroe faced no serious rival and was nearly unanimously elected by the electoral college. The party's historic domination by the Virginian delegation faded as New York and Pennsylvania became more important. In the 1824 election, most of the party in Congress boycotted the caucus; only a small rump group backed William Crawford. The Crawford faction included most "Old Republicans"—those who remained committed to states' rights and the Principles of 1798 and were distrustful of the nationalizing program promoted by Henry Clay and John C. Calhoun.
Thomas Jefferson wrote on the state of party politics in the early 1820s:
An opinion prevails that there is no longer any distinction, that the republicans & Federalists are completely amalgamated but it is not so. The amalgamation is of name only, not of principle. All indeed call themselves by the name of Republicans, because that of Federalists was extinguished in the battle of New Orleans. But the truth is that finding that monarchy is a desperate wish in this country, they rally to the point which they think next best, a consolidated government. Their aim is now therefore to break down the rights reserved by the constitution to the states as a bulwark against that consolidation, the fear of which produced the whole of the opposition to the constitution at its birth. Hence new Republicans in Congress, preaching the doctrines of the old Federalists, and the new nick-names of Ultras and Radicals. But I trust they will fail under the new, as the old name, and that the friends of the real constitution and union will prevail against consolidation, as they have done against monarchism. I scarcely know myself which is most to be deprecated, a consolidation, or dissolution of the states. The horrors of both are beyond the reach of human foresight.
In the aftermath of the disputed 1824 presidential election, the separate factions took on many characteristics of parties in their own right. Adams' supporters, in league with Clay, favored modernization, banks, industrial development, and federal spending for roads and other internal improvements, which the Old Republicans and the Jackson men usually opposed. Writing in his personal journal on December 13, 1826, President Adams noted the difficulty he faced in attempting to be nonpartisan in appointing men to office:
And it is upon the occasion of appointments to office that all the wormwood and the gall of the old party hatred ooze out. Not a vacancy to any office occurs but there is a distinguished federalist started and pushed home as a candidate to fill it—always well qualified, sometimes in an eminent degree, and yet so obnoxious to the Republican party that he cannot be appointed without exciting a vehement clamor against him and against the Administration. It becomes thus impossible to fill any appointment without offending one-half the community—the federalists, if their associate is overlooked; the Republicans, if he is preferred.
Presidential electors were now all chosen by direct election, except in South Carolina, where the state legislatures chose them. White manhood suffrage was the norm throughout the West and in most of the East as well. The voters thus were much more powerful, and to win their votes required complex party organization. Under the leadership of Martin Van Buren, a firm believer in political organization, the Jacksonians built strong state and local organizations throughout the country. The Old Republicans, or "Radicals", mostly supported Jackson and joined with supporters of incumbent Vice President Calhoun in an alliance. President Adams was defeated by Andrew Jackson in the election of 1828.
Republican Party name.
Political parties were new in the United States, and people were not accustomed to having formal names for them. There was no single, official name for the party. Party members generally called themselves "Republicans" and voted for what they called the "Republican Party", "republican ticket", or "republican interest". Jefferson and Madison often used the terms "republican" and "Republican party" in their letters. The 1804 Convention of Republican members of Congress that renominated Jefferson described itself as a "regular republican caucus". The name Democratic-Republican was used by contemporaries only occasionally.
The term "republican" was in widespread usage from the 1770s to describe the type government the break-away colonies wanted to form: a Republic of three separate branches of government derived from some principles and structure from ancient Republics; especially the emphasis on civic duty and the opposition to corruption, elitism, aristocracy and monarchy. The word is used in the U.S. Constitution.
Legacy.
A split appeared in the then Republican party during the 1824 elections (at the end of the Monroe administration). When the election was thrown to the House of Representatives, Henry Clay backed John Quincy Adams to deny the presidency to Andrew Jackson, a longtime political rival. Jackson defeated Adams in 1828, and in the next election, the first Democratic national convention took place in Baltimore, Maryland on May 21–23, 1832. It nominated Andrew Jackson for a second term, and he went on to win the presidency.
The Adams/Clay alliance became the basis of the National Republican Party, a rival to the Jackson's Democracy. This party favored a higher tariff in order to protect U.S. manufacturers, as well as public works, especially roads. Many former members of the defunct Federalist Party, including Daniel Webster, joined the party. After Clay's defeat by Jackson in the 1832 presidential election, the National Republicans were absorbed into the Whig Party, a diverse group of Jackson opponents. Taking a leaf from the Jacksonians, the Whigs tended to nominate non-ideological war heroes as their presidential candidates. The Whig party fell apart in the 1850s over the question of whether to allow the expansion of slavery into new territories.
The modern Republican Party formed in 1854 to oppose the expansion of slavery. Many former Whig party leaders (such as Abraham Lincoln - modern Republican Party supporters still sometimes refer to themselves as "the party of Lincoln") and former Free Soil Party leaders joined the newly formed anti-slavery party. The party sought to combine Jefferson's ideals of liberty and equality with Clay's program of using an active government to modernize the economy.
Presidents.
Four United States Presidents were elected following a process that selected them as a national nominee of the Democratic-Republican party:
References.
Bibliography

</doc>
<doc id="32082" url="http://en.wikipedia.org/wiki?curid=32082" title="Ulvophyceae">
Ulvophyceae

The Ulvophyceae or ulvophytes are a class of green algae, distinguished mainly on the basis of ultrastructural morphology, life cycle and molecular phylogenetic data. The sea lettuce, "Ulva", belongs here. Other well-known members include "Caulerpa" and "Acetabularia". "Monostroma kuroshiensis", the well-known edible green algae cultivated worldwide and is the most expensive among green algae, belongs to this class.
The Ulvophytes are diverse in their morphology and their habitat. Most are seaweeds such as those listed above. Others, such as "Rhizoclonium", "Pithophora" and some species of "Cladophora" live in fresh water and in some areas are considered weeds.
Evolution.
The origin and early diversification of the Ulvophyceae likely took place in the late Neoproterozoic. Although most contemporary ulvophytes are marine macroalgae (seaweeds), ancestral ulvophytes may have been freshwater, unicellular green algae. Molecular phylogenetic evidence suggests that macroscopic growth was achieved independently in the various major lineages of Ulvophyceae (Ulvales-Ulotrichales, Trentepohliales, Cladophorales, Bryopsidales and Dasycladales).
Current hypothesis on relationships among the main clades of Ulvophyceae are shown below.

</doc>
<doc id="32086" url="http://en.wikipedia.org/wiki?curid=32086" title="Federalist Party">
Federalist Party

The Federalist Party was the first American political party, from the early 1790s to 1816, the era of the First Party System, with remnants lasting into the 1820s. The Federalists controlled the federal government until 1801. Between 1789–1797 it was built mainly with the support of bankers and businessmen in order to support Alexander Hamilton's fiscal policies. These supporters grew into the Federalist Party committed to a fiscally sound and nationalistic government. The United States' only Federalist president was John Adams; although George Washington was broadly sympathetic to the Federalist program, he remained an independent during his entire presidency. The remaining fragments of Washington's longer, never-delivered draft first inaugural address suggest his agreement with arguments in the "Federalist Papers" on the need for a strong central government.
The Federalist policies called for a national bank, tariffs, and good relations with Britain as expressed in the Jay Treaty negotiated in 1794. Hamilton developed the concept of implied powers, and successfully argued the adoption of that interpretation of the United States Constitution. Led by Thomas Jefferson, the Democratic-Republicans, their political opponents, denounced most of the Federalist policies, especially the bank and implied powers, and vehemently attacked the Jay Treaty as a sell-out of republican values to the British monarchy. The Jay Treaty passed, and indeed the Federalists won most of the major legislative battles in the 1790s. They held a strong base in the nation's cities and in New England. The Democratic-Republicans, with their base in the rural South, won the hard-fought election of 1800; the Federalists never returned to power. They recovered some strength by intense opposition to the War of 1812; they practically vanished during the Era of Good Feelings that followed the end of the war in 1815.
The Federalists left a lasting imprint as they fashioned a strong new government with a sound financial base, and (in the person of Chief Justice John Marshall) decisively shaped Supreme Court policies for another three decades.
Rise.
On taking office in 1789 President Washington nominated New York lawyer Alexander Hamilton to the office of Secretary of the Treasury. Hamilton wanted a strong national government with financial credibility. Hamilton proposed the ambitious Hamiltonian economic program that involved assumption of the state debts incurred during the American Revolution, creating a national debt and the means to pay it off, and setting up a national bank. James Madison, Hamilton's ally in the fight to ratify the United States Constitution, who would later be joined by Thomas Jefferson, opposed Hamilton's program. Political parties had not been anticipated when the Constitution was drafted in 1787 and ratified in 1788, even though both Hamilton and Madison played major roles. Parties were considered to be divisive and harmful to republicanism. No similar parties existed anywhere in the world.
By 1790 Hamilton started building a nationwide coalition. Realizing the need for vocal political support in the states, he formed connections with like-minded nationalists and used his network of treasury agents to link together friends of the government, especially merchants and bankers, in the new nation's dozen major cities. His attempts to manage politics in the national capital to get his plans through Congress, then, "brought strong responses across the country. In the process, what began as a capital faction soon assumed status as a national faction and then, finally, as the new Federalist party." The Federalist Party supported Hamilton's vision of a strong centralized government, and agreed with his proposals for a national bank and heavy government subsidies. In foreign affairs, they supported neutrality in the war between France and Great Britain.
The majority of the founding fathers were originally federalists. Alexander Hamilton, James Madison, Thomas Jefferson and many others can all be considered federalists. These federalists felt that the Articles of Confederation had been too weak to sustain a working government and had decided that a new form of government was needed. When Alexander Hamilton was made Secretary of the Treasury and came up with the idea of funding the debt he created a split in the original federalist group. James Madison greatly disagreed with Hamilton, not just on this issue but on many others as well; he and John Beckley created the Anti-Federalist faction. These men would eventually become the Republicans under Thomas Jefferson.
By 1792-94 newspapers started calling Hamilton supporters "Federalists" and their opponents "Democrats," "Republicans," "Jeffersonians" (people who supported Thomas Jefferson, the 3rd president), or "Democratic-Republicans." Jefferson's supporters usually called themselves "Republicans" and their party the "Republican Party." The Federalist party became popular with businessmen and New Englanders; Republicans were mostly farmers who opposed a strong central government . The Congregationalists and the Episcopalians supported the Federalists, and other minority denominations tended toward the Republican camp. Cities were usually Federalist; frontier regions were heavily Republican. These are generalizations; there are special cases: the
Presbyterians of upland North Carolina, who had immigrated just before the Revolution, and often been Tories, became Federalists. Catholics in Maryland were generally Federalists.
The state networks of both parties began to operate in 1794 or 1795. Patronage now became a factor. The winner-take-all election system opened a wide gap between winners, who got all the patronage, and losers, who got none. Hamilton had over 2000 Treasury jobs to dispense, while Jefferson had one part-time job in the State Department, which he gave to journalist Philip Freneau to attack the Federalists. In New York, however, George Clinton won the election for governor and used the vast state patronage fund to help the Republican cause.
Washington tried and failed to moderate the feud between his two top cabinet members. He was re-elected without opposition in 1792. The Democratic-Republicans nominated New York's Governor Clinton to replace Federalist John Adams as vice president, but Adams won. The balance of power in Congress was close, with some members still undecided between the parties. In early 1793, Jefferson secretly prepared resolutions introduced by William Branch Giles, Congressman from Virginia, designed to repudiate Hamilton and weaken the Washington Administration. Hamilton defended his administration of the nation's complicated financial affairs, which none of his critics could decipher until the arrival in Congress of the Republican Albert Gallatin in 1793.
Federalists counterattacked by claiming the Hamiltonian program had restored national prosperity, as shown in one 1792 anonymous newspaper essay:
To what physical, moral, or political energy shall this flourishing state of things be ascribed? There is but one answer to these inquiries: Public credit is restored and established. The general government, by uniting and calling into action the pecuniary resources of the states, has created a new capital stock of several millions of dollars, which, with that before existing, is directed into every branch of business, giving life and vigor to industry in its infinitely diversified operation. The enemies of the general government, the funding act and the National Bank may bellow tyranny, aristocracy, and speculators through the Union and repeat the clamorous din as long as they please; but the actual state of agriculture and commerce, the peace, the contentment and satisfaction of the great mass of people, give the lie to their assertions.
Jefferson wrote on February 12, 1798:
The term "Federalist" was considered by some to be misleading. Merrill Jensen, in his book "The American Revolution Within America", writes:
Party strength in Congress.
Many Congressmen were very hard to classify in the first few years, but after 1796 there was more certainty,
Source: Kenneth C. Martis, "The Historical Atlas of Political Parties in the United States Congress, 1789–1989" (1989); the numbers are estimates by historians.
The affiliation of many Congressmen in the earliest years is an assignment by later historians. The parties were slowly coalescing groups; at first there were many independents. Cunningham noted that only about a quarter of the House of Representatives, up until 1794, voted with Madison as much as two-thirds of the time, and another quarter against him two-thirds of the time, leaving almost half as fairly independent.
Effects of foreign affairs.
International affairs — the French Revolution and the subsequent war between royalist Britain and republican France — decisively shaped American politics in 1793–1800, and threatened to entangle the nation in wars that "mortally threatened its very existence." The French revolutionaries guillotined King Louis XVI in January 1793, leading the British to declare war to restore the monarchy. The King had been decisive in helping America achieve independence. Now he was dead and many of the pro-American aristocrats in France were exiled or executed. Federalists warned that American republicans threatened to replicate the horrors of the French Revolution, and successfully mobilized most conservatives and many clergymen. The Republicans, some of whom had been strong Francophiles, responded with support, even through the Reign of Terror, when thousands were guillotined, though it was at this point that many began backing away from their pro-France leanings. Many of those executed had been friends of the United States, such as the Comte D'Estaing, whose fleet had fought alongside the Americans in the Revolution. (Lafayette had already fled into exile, and Thomas Paine went to prison in France.) The Republicans denounced Hamilton, Adams, and even Washington as friends of Britain, as secret monarchists, and as enemies of the republican values. The level of rhetoric reached a fever pitch.
Paris in 1793 sent a new minister, Edmond Charles Genêt (known as "Citizen Genêt"), who systematically mobilized pro-French sentiment and encouraged Americans to support France's war against Britain and Spain. Genêt funded local Democratic-Republican Societies that attacked Federalists. He hoped for a favorable new treaty and for repayment of the debts owed to France. Acting aggressively, Genêt outfitted privateers that sailed with American crews under a French flag and attacked British shipping. He tried to organize expeditions of Americans to invade Spanish Louisiana and Spanish Florida. When Secretary of State Jefferson told Genêt he was pushing American friendship past the limit, Genêt threatened to go over the government's head and rouse public opinion on behalf of France. Even Jefferson agreed this was blatant foreign interference in domestic politics. Genêt's extremism seriously embarrassed the Jeffersonians and cooled popular support for promoting the French Revolution and getting involved in its wars. Recalled to Paris for execution, Genêt kept his head and instead went to New York, where he became a citizen and married the daughter of Governor Clinton. Jefferson left office, ending the coalition cabinet and allowing the Federalists to dominate.
The Jay Treaty in 1794–95 was the effort by Washington and Hamilton to resolve numerous difficulties with Britain. Some of these issues dated to the Revolution, such as boundaries, debts owed in each direction, and the continued presence of British forts in the Northwest Territory. In addition America hoped to open markets in the British Caribbean and end disputes stemming from the naval war between Britain and France. Most of all the goal was to avert a war with Britain — a war opposed by the Federalists, that some historians claim the Jeffersonians wanted.
As a neutral party, the United States argued, it had the right to carry goods anywhere it wanted. The British nevertheless seized American ships carrying goods from the French West Indies. The Federalists favored Britain in the war, and by far most of America's foreign trade was with Britain; hence a new treaty was called for. The British agreed to evacuate the western forts, open their West Indies ports to American ships, allow small vessels to trade with the French West Indies, and set up a commission that would adjudicate American claims against Britain for seized ships, and British claims against Americans for debts incurred before 1775. One possible alternative was war with Britain, a war that America was ill-prepared to fight.
The Republicans wanted to pressure Britain to the brink of war (and assumed that America could defeat a weak Britain). Therefore they denounced the Jay Treaty as an insult to American prestige, a repudiation of the French alliance of 1777, and a severe shock to Southern planters who owed those old debts, and who were never to collect for the lost slaves the British captured. Republicans protested against the treaty, but the Federalists controlled the Senate and they ratified it by exactly the necessary ⅔ vote, 20–10, in 1795. The pendulum of public opinion swung toward the Republicans after the Treaty fight, and in the South the Federalists lost most of the support they had among planters.
Whiskey rebellion.
The excise tax of 1791 caused grumbling from the frontier including threats of tax resistance. Corn, the chief crop on the frontier, was too bulky to ship over the mountains to market, unless it was first distilled into whiskey. This was profitable, as the United States population consumed, "per capita", relatively large quantities of liquor. After the excise tax, the backwoodsmen complained the tax fell on them rather than on the consumers. Cash poor, they were outraged that they had been singled out to pay off the "financiers and speculators" back East, and to salary the federal revenue officers who began to swarm the hills looking for illegal stills.
Insurgents in western Pennsylvania shut the courts and hounded federal officials, but Jeffersonian leader Albert Gallatin mobilized the western moderates, and thus forestalled a serious outbreak. Washington, seeing the need to assert federal supremacy, called out 13,000 state militia, and marched toward Washington, Pennsylvania, to suppress this Whiskey Rebellion. The rebellion evaporated in late 1794 as Washington approached, personally leading the army (only two sitting Presidents have directly led American military forces, Washington during the Whiskey Rebellion and Madison in an attempt to save the White House during the War of 1812). The rebels dispersed and there was no fighting. Federalists were relieved that the new government proved capable of overcoming rebellion, while Republicans, with Gallatin their new hero, argued there never was a real rebellion and the whole episode was manipulated in order to accustom Americans to a standing army.
Angry petitions flowed in from three dozen Democratic-Republican Societies created by Citizen Genêt. Washington attacked the societies as illegitimate; many disbanded. Federalists now ridiculed Republicans as "democrats" (meaning in favor of mob rule) or "Jacobins" (a reference to The Terror in France).
Washington refused to run for a third term, establishing a two-term precedent that was to stand until 1940 and eventually to be enshrined in the Constitution as the 22nd Amendment. Washington warned in his Farewell Address against involvement in European wars, and lamented the rising North-South sectionalism and party spirit in politics that threatened national unity. The party spirit, he lamented:
serves always to distract the Public Councils, and enfeeble the Public Administration. It agitates the Community with ill-founded jealousies and false alarms; kindles the animosity of one part against another, foments occasionally riot and insurrection. It opens the door to foreign influence and corruption, which find a facilitated access to the government itself through the channels of party passions. Thus the policy and the will of one country are subjected to the policy and will of another.
Washington never considered himself a member of any party. However, his personal beliefs were generally federalist, as were the policies of his administration.
Newspaper editors at war.
To strengthen their coalitions and hammer away constantly at the opposition, both parties sponsored newspapers in the capital (Philadelphia) and other major cities. On the Republican side, Philip Freneau and Benjamin Franklin Bache blasted the administration with all the scurrility at their command. Bache in particular targeted Washington himself as the front man for monarchy who must be exposed. To Bache, Washington was a cowardly general and a money-hungry baron who saw the Revolution as a means to advance his fortune and fame, Adams was a failed diplomat who never forgave the French their love of Benjamin Franklin and who craved a crown for himself and his descendants, and Alexander Hamilton was the most inveterate monarchist of them all.
The Federalists, with twice as many newspapers at their command, slashed back with equal vituperation; John Fenno and "Peter Porcupine" (William Cobbett) were their nastiest pensmen, and Noah Webster their most learned; Hamilton subsidized the Federalist editors, wrote for their papers, and in 1801 established his own paper, the "New York Evening Post." Though his reputation waned considerably following his death, Joseph Dennie ran three of the most popular and influential newspapers of the period, "The Farmer's Weekly Museum", the "Gazette of the United States" and "Port Folio".
Adams administration, 1797–1801.
Hamilton distrusted Vice President Adams — who felt the same way about Hamilton — but was unable to block his claims to the succession. The election of 1796 was the first partisan affair in the nation's history, and one of the more scurrilous in terms of newspaper attacks. Adams swept New England and Jefferson the South, with the middle states leaning to Adams. Thus Adams was the winner by a margin of three electoral votes, and Jefferson, as the runner-up, became Vice President under the system set out in the Constitution prior to the ratification of the 12th Amendment.
Foreign affairs continued to be the central concern of American politics, for the war raging in Europe threatened to drag in the United States. The new President was a loner, who made decisions without consulting Hamilton or other High Federalists. Benjamin Franklin once quipped that Adams was a man always honest, often brilliant, and sometimes mad. Adams was popular among the Federalist rank and file, but had neglected to build state or local political bases of his own, and neglected to take control of his own cabinet. As a result his cabinet answered more to Hamilton than to himself.
Alien and Sedition Acts.
After an American delegation was insulted in Paris in the XYZ affair (1797), public opinion ran strongly against the French. An undeclared "Quasi-War" with France from 1798 to 1800, saw each side attacking and capturing the other's shipping. It was called "quasi" because there was no declaration of war, but escalation was a serious threat. The Federalists, at the peak of their popularity, took advantage by preparing for an invasion by the French Army.
To silence Administration critics, the Federalists passed the Alien and Sedition Acts in 1798. The Alien Act empowered the President to deport such aliens as he declared to be dangerous. The Sedition Act made it a crime to print false, scandalous, and malicious criticisms of the federal government, but it conspicuously failed to criminalize criticism of Vice President Thomas Jefferson. Several Democratic-Republican newspaper editors were convicted under the Act and fined or jailed, and three Democratic-Republican newspapers were shut down. During this period, Jefferson and Madison secretly wrote the Kentucky and Virginia Resolutions passed by the two states' legislatures, that declared the Alien and Sedition Acts unconstitutional, and insisted the states had the power to nullify federal laws.
Undaunted, the Federalists created a navy, with new frigates, and a large new army, with Washington in nominal command and Hamilton in actual command. To pay for it all they raised taxes on land, houses and slaves, leading to serious unrest. In one part of Pennsylvania the Fries' Rebellion broke out, with people refusing to pay the new taxes. John Fries was sentenced to death for treason, but received a pardon from Adams. In the elections of 1798 the Federalists did very well, but this issue started hurting the Federalists in 1799.
Early in 1799, Adams decided to free himself from Hamilton's overbearing influence, stunning the country and throwing his party into disarray by announcing a new peace mission to France. The mission eventually succeeded, the "Quasi-War" ended, and the new army was largely disbanded. Hamiltonians called Adams a failure, while Adams fired Hamilton's supporters still in the cabinet.
Hamilton and Adams intensely disliked one another, and the Federalists split between supporters of Hamilton ("High Federalists") and supporters of Adams. Hamilton became embittered over his loss of political influence and wrote a scathing criticism of Adams' performance as President of the United States in an effort to throw Federalist support to Charles Cotesworth Pinckney; inadvertently this split the Federalists and helped give the victory to Jefferson.
Election of 1800.
Adams' peace moves proved popular with the Federalist rank and file, and he seemed to stand a good chance of re-election in 1800. If the Three-Fifths Compromise had not been enacted, he most likely would have won reelection since many Federalist legislatures removed the right to select electors from their constituents in fear of a Democratic victory. Jefferson was again the opponent and Federalists pulled out all stops in warning that he was a dangerous revolutionary, hostile to religion, who would weaken the government, damage the economy, and get into war with Britain. Many believed that if Jefferson won the election it would be the end of the newly formed United States. The Republicans crusaded against the Alien and Sedition laws, and the new taxes, and proved highly effective in mobilizing popular discontent.
The election hinged on New York: its electors were selected by the legislature, and given the balance of north and south, they would decide the presidential election. Aaron Burr brilliantly organized his forces in New York City in the spring elections for the state legislature. By a few hundred votes he carried the city—and thus the state legislature—and guaranteed the election of a Democratic-Republican President. As a reward he was selected by the Republican caucus in Congress as their vice presidential candidate. Hamilton, knowing the election was lost anyway, went public with a sharp attack on Adams that further divided and weakened the Federalists.
Members of the Republican party planned to vote evenly for Jefferson and Burr because they did not want for it to seem as if their party was divided. The party took the meaning literally and Jefferson and Burr tied in the election with 73 electoral votes. This sent the election to the House of Representatives to break the tie. The Federalists had enough weight in the House to swing the election in either direction. Many would rather have seen Burr in the office over Jefferson, but Hamilton, who had a strong dislike of Burr, threw his political weight behind Jefferson. During the election neither Jefferson nor Burr attempted to swing the election in the House of Representatives. Jefferson remained at Monticello to oversee the laying of bricks to a section of his home. Jefferson allowed for his political beliefs and other ideologies to filter out through letters to his contacts. Thanks to Hamilton's support Jefferson would win the election and Burr would become his Vice President. Many Federalists held to the belief that this was the end of the United States and that the experiment they had begun had ended in failure. (This unintended complication led directly to the proposal and ratification of the 12th Amendment.) "We are all republicans—we are all federalists," proclaimed Jefferson in his inaugural address. This election marked the first time power had been transferred between opposing political parties, an act that occurred, remarkably, without bloodshed. Though there had been strong words and disagreements, contrary to the Federalists fears, there was no war and no ending of one government system to let in a new one. His patronage policy was to let the Federalists disappear through attrition. Those Federalists such as John Quincy Adams (John Adams' own son) and Rufus King willing to work with him were rewarded with senior diplomatic posts, but there was no punishment of the opposition.
Jefferson had a very successful first term, typified by the Louisiana Purchase, which was ironically supported by Hamilton but opposed by most Federalists at the time as unconstitutional. Shortly before Hamilton's death, some Federalist leaders (see Essex Junto) began courting Jefferson's Vice-President and Hamilton's nemesis Aaron Burr in an attempt to swing New York into an independent confederation with the New England states, which along with New York were supposed to secede from the United States after Burr's election to Governor. However, Hamilton's influence cost Burr the governorship of New York, a key in the Essex Junto's plan, just as Hamilton's influence had cost Burr the Presidency nearly 4 years before. Hamilton's thwarting of Aaron Burr's ambitions for the second time was too much for Burr to bear. Hamilton had known of the Essex Junto (whom Hamilton now regarded as apostate Federalists), and Burr's plans and opposed them vehemently. This opposition by Hamilton would lead to his fatal duel with Burr in July 1804.
The thoroughly disorganized Federalists hardly offered any opposition to Jefferson's reelection in 1804, after his successful first term (by this point, the Federalists were now largely without a strong leader after the untimely death of Alexander Hamilton and with Aaron Burr now a fugitive of the law). In New England and in some districts in the middle states the Federalists clung to power, but the tendency from 1800 to 1812 was steady slippage almost everywhere, as the Republicans perfected their organization and the Federalists tried to play catch-up. Some younger leaders tried to emulate the Democratic-Republican tactics, but their overall disdain of democracy along with the upper class bias of the party leadership eroded public support. In the South, the Federalists steadily lost ground everywhere.
Federalists in opposition.
Jefferson administration.
The Federalists continued for several years to be a major political party in New England and the Northeast, but never regained control of the Presidency or the Congress. With the death of Washington and Hamilton (the latter killed by Burr in a duel), and the retirement of Adams, the Federalists were left without a strong leader, beyond John Marshall, whose appointment to the Supreme Court made him incapable of running for further office. A few younger leaders did appear, notably Daniel Webster. Federalist policies favored factories, banking, and trade over agriculture, and thus became unpopular in the growing Western states. They were increasingly seen as aristocratic and unsympathetic to democracy. In the South the party had lingering support in Maryland, but elsewhere was crippled by 1800 and faded away by 1808.
Massachusetts and Connecticut were the party strongholds. Historian Richard J. Purcell explains how well organized the party was in Connecticut:
It was only necessary to perfect the working methods of the organized body of office-holders who made up the nucleus of the party. There were the state officers, the assistants, and a large majority of the Assembly. In every county there was a sheriff with his deputies. All of the state, county, and town judges were potential and generally active workers. Every town had several justices of the peace, school directors and, in Federalist towns, all the town officers who were ready to carry on the party's work. Every parish had a "standing agent," whose anathemas were said to convince at least ten voting deacons. Militia officers, state's attorneys, lawyers, professors and schoolteachers were in the van of this "conscript army." In all, about a thousand or eleven hundred dependent officer-holders were described as the inner ring which could always be depended upon for their own and enough more votes within their control to decide an election. This was the Federalist machine.
After 1800 the major Federalist role came in the judiciary. Although Jefferson managed to repeal the Judiciary Act of 1801 and thus dismiss many Federalist judges, their effort to impeach Supreme Court Justice Samuel Chase in 1804 failed. Led by the last great Federalist, John Marshall as Chief Justice from 1801 to 1835, the Supreme Court carved out a unique and powerful role as the protector of the Constitution and promoter of nationalism.
President Jefferson imposed an embargo on Britain in 1807; the Embargo Act of 1807 prevented all American ships from sailing to a foreign port. The idea was that the British were so dependent on American supplies that they would come to terms. For 15 months the Embargo wrecked American export businesses, largely based in the Boston-New York region, causing a sharp depression in the Northeast. Evasion was common and Jefferson and Treasury Secretary Gallatin responded with tightened police controls more severe than anything the Federalists had ever proposed. Public opinion was highly negative, and a surge of support breathed fresh life into the Federalist party. The Republicans (slowly assuming the name "Democratic-Republicans") nominated Madison for the presidency in 1808. Federalists, meeting in the first-ever national convention, considered the option of nominating Vice President George Clinton as their own candidate, but balked at working with him and again chose Charles Cotesworth Pinckney, their 1804 candidate. Madison lost New England but swept the rest of the country and carried a Republican Congress. Madison dropped the Embargo, opened up trade again, and offered a carrot and stick approach. If either France or Britain agreed to stop their violations of American neutrality, the U.S. would cut off trade with the other country. Tricked by Napoleon into believing France had acceded to his demands, Madison turned his wrath on Britain, and the War of 1812 began.
Madison administration.
Thus the nation was at war during the 1812 presidential election, and war was the burning issue. Opposition to the war was strong in traditional federalist strongholds in New England and New York, where the party made a comeback in the elections of 1812 and 1814. In their second national convention, in 1812, the Federalists, now the peace party, nominated DeWitt Clinton, the dissident Republican mayor of New York City, and an articulate opponent of the war. Madison ran for reelection promising a relentless war against Britain and an honorable peace. Clinton, denouncing Madison's weak leadership and incompetent preparations for war, could count on New England and New York. To win he needed the middle states and there the campaign was fought out. Those states were competitive and had the best-developed local parties and most elaborate campaign techniques, including nominating conventions and formal party platforms. The Tammany Society in New York City highly favored Madison; the Federalists finally adopted the club idea in 1808. Their Washington Benevolent Societies were semi-secret membership organizations which played a critical role in every northern state; they held meetings and rallies and mobilized Federalist votes. New Jersey went for Clinton, but Madison carried Pennsylvania and thus was reelected with 59% of the Electoral votes. However the Federalists gained 14 seats in Congress.
Opposition to the War of 1812.
The War of 1812 went poorly for the Americans for two years. Even though Britain was concentrating its military efforts on its war with Napoleon, the United States still failed to make any headway on land, and was effectively blockaded at sea by the Royal Navy. The British raided and burned Washington, D.C. in 1814 and sent a force to capture New Orleans.
The war was especially unpopular in New England: the New England economy was highly dependent on trade, and the British blockade threatened to destroy it entirely. In 1814, the British Navy finally managed to enforce their blockade on the New England coast, so the Federalists of New England sent delegates to the Hartford Convention in December 1814.
During the proceedings of the Hartford Convention, secession from the Union was discussed, though the resulting report listed a set of grievances against the Democratic-Republican federal government and proposed a set of Constitutional amendments to address these grievances. They demanded financial assistance from Washington to compensate for lost trade and proposed constitutional amendments requiring a two-thirds vote in Congress before an embargo could be imposed, new states admitted, or war declared. It also indicated that if these proposals were ignored, then another convention should be called and given "such powers and instructions as the exigency of a crisis may require". The Federalist Massachusetts Governor had already secretly sent word to England to broker a separate peace accord. Three Massachusetts "ambassadors" were sent to Washington to negotiate on the basis of this report.
By the time the Federalist "ambassadors" got to Washington, the war was over and news of Andrew Jackson's stunning victory in the Battle of New Orleans had raised American morale immensely. The "ambassadors" hastened back to Massachusetts, but not before they had done fatal damage to the Federalist Party. The Federalists were thereafter associated with the disloyalty and parochialism of the Hartford Convention, and destroyed as a political force. They fielded their last presidential candidate (Rufus King) in 1816, and their last serious vice-presidential candidate (Richard Stockton) in 1820. With its passing partisan hatreds and newspaper feuds on the decline, the nation entered the "Era of Good Feelings", marked by the absence of all but one political party. After the dissolution of the final Federalist congressional caucus in 1825, the last traces of Federalist activity came in Delaware and Massachusetts state politics in the late 1820s, where in 1829 Harrison Gray Otis was elected Mayor of Boston, the last significant Federalist office holder in the United States. As late as 1828 the party won control of the Delaware state legislature, and as late as 1830 the Federalists controlled the Massachusetts Senate.
Interpretations.
Intellectually, Federalists were profoundly devoted to liberty. As Samuel Eliot Morison explained, they believed that liberty is inseparable from union, that men are essentially unequal, that vox populi [voice of the people] is seldom if ever vox Dei [the voice of God], and that sinister outside influences are busy undermining American integrity. Oxford-trained British historian Patrick Allitt concludes that Federalists promoted many positions that would form the baseline for later American conservatism, including the rule of law under the Constitution, republican government, peaceful change through elections, judicial supremacy, stable national finances, credible and active diplomacy, and protection of wealth.
The Federalists were dominated by businessmen and merchants in the major cities who supported a strong national government. The party was closely linked to the modernizing, urbanizing, financial policies of Alexander Hamilton. These policies included the funding of the national debt and also assumption of state debts incurred during the Revolutionary War, the incorporation of a national Bank of the United States, the support of manufactures and industrial development, and the use of a tariff to fund the Treasury. In foreign affairs, the Federalists opposed the French Revolution, engaged in the "Quasi War" (an undeclared naval war) with France in 1798–99, sought good relations with Britain and sought a strong army and navy. Ideologically the controversy between Republicans and Federalists stemmed from a difference of principle and style. In terms of style the Federalists distrusted the public, thought the elite should be in charge, and favored national power over state power. Republicans distrusted Britain, bankers, merchants and did not want a powerful national government. The Federalists, notably Hamilton, were distrustful of "the people," the French, and the Republicans. In the end, the nation synthesized the two positions, adopting representative democracy and a strong nation state. Just as importantly, American politics by the 1820s accepted the two-party system whereby rival parties stake their claims before the electorate, and the winner takes control of majorities in state legislatures and the Congress, and gains governorships and the presidency.
As time went on, the Federalists lost appeal with the average voter and were generally not equal to the tasks of party organization; hence, they grew steadily weaker as the political triumphs of the Republican Party grew. For economic and philosophical reasons, the Federalists tended to be pro-British – the United States engaged in more trade with Great Britain than with any other country – and vociferously opposed Jefferson's Embargo Act of 1807 and the seemingly deliberate provocation of war with Britain by the Madison Administration. During "Mr. Madison's War", as they called it, the Federalists made a temporary comeback. However they lost all their gains and more during the patriotic euphoria that followed the war. The membership was aging rapidly, but a few young men from New England did join the cause, most notably Daniel Webster.
After 1816 the Federalists had no national power base apart from John Marshall's Supreme Court. They had some local support in New England, New York, eastern Pennsylvania, Maryland and Delaware. After the collapse of the Republican Party in the course of the 1824 presidential election, most surviving Federalists (including Daniel Webster) joined former Republicans like Henry Clay to form the National Republican Party, which was soon combined with other anti-Jackson groups to form the Whig Party in 1833. Some former Federalists like James Buchanan, Louis McLane and Roger B. Taney became Jacksonian Democrats.
The "Old Republicans," led by John Randolph of Roanoke, refused to form a coalition with the Federalists and instead set up a separate opposition since Jefferson, Madison, Gallatin, Monroe, John C. Calhoun and Clay had in effect adopted Federalist principles of implied powers to purchase the Louisiana Territory, and after the failures and lessons of the War of 1812, raised tariffs to protect factories, chartered the Second national bank, promoted a strong army and navy and promoted internal improvements. All these measures were opposed to the strict construction of the constitution, which was the formal basis of the republicans; but the drift of the party to support them could not be checked. It was aided by the supreme court, whose influence as a nationalizing factor now first became apparent. The whole change reconciled the federalists to their absorption into the republican party. Indeed, they claimed, with considerable show of justice, that the absorption was in the other direction: that the republicans had recanted; and that the "Washington-Monroe policy," as they termed it after 1820, was all that federalists had ever desired.
The name "Federalist" came increasingly to be used in political rhetoric as a term of abuse, and was denied by the Whigs, who pointed out that their leader Henry Clay was the Republican party leader in Congress during the 1810s.
<br>

</doc>
<doc id="32087" url="http://en.wikipedia.org/wiki?curid=32087" title="United States Army">
United States Army

The United States Army (USA) is the largest branch of the Armed Forces of the United States that performs land-based military operations; and is one of the seven Uniformed services of the United States. As the largest and senior branch of the U.S. military, the modern U.S. Army has its roots in the Continental Army, which was formed (14 June 1775) to fight the American Revolutionary War (1775–83)—before the U.S. was established as a country. After the Revolutionary War, the Congress of the Confederation created the United States Army on 3 June 1784, to replace the disbanded Continental Army. The United States Army considers itself descended from the Continental Army, and dates its institutional inception from the origin of that armed force in 1775.
As a uniformed military service, the Army is part of the Department of the Army, which is one of the three military departments of the Department of Defense. The U.S. Army is headed by a civilian officer, the Secretary of the Army, and by a chief military officer, the Chief of Staff of the Army. The ranking officer of the U.S. Army is the Chairman of the Joint Chiefs of Staff. In the fiscal year 2011, the Regular Army (USA) reported a strength of 546,057 soldiers; the Army National Guard (ARNG) reported 358,078 soldiers, and the United States Army Reserve (USAR) reported 201,166 soldiers; the combined-component strength of the U.S. Army was 1,105,301 soldiers. As a branch of the armed forces, the mission of the U.S. Army is "to fight and win our Nation's wars, by providing prompt, sustained, land dominance, across the full range of military operations and the spectrum of conflict, in support of combatant commanders."
Mission.
The United States Army serves as the land-based branch of the U.S. Armed Forces. defines the purpose of the army as:
History.
Origins.
The Continental Army was created on 14 June 1775 by the Continental Congress as a unified army for the colonies to fight Great Britain, with George Washington appointed as its commander. The army was initially led by men who had served in the British Army or colonial militias and who brought much of British military heritage with them. As the Revolutionary War progressed, French aid, resources, and military thinking influenced the new army. A number of European soldiers came on their own to help, such as Friedrich Wilhelm von Steuben, who taught the army Prussian tactics and organizational skills.
The army fought numerous pitched battles and in the South 1780–81 sometimes used the Fabian strategy and hit-and-run tactics, hitting where the enemy was weakest, to wear down the British forces. Washington led victories against the British at Trenton and Princeton, but lost a series of battles around New York City in 1776 and Philadelphia in 1777. With a decisive victory at Yorktown, and the help of the French, the Continental Army prevailed against the British.
After the war, though, the Continental Army was quickly given land certificates and disbanded in a reflection of the republican distrust of standing armies. State militias became the new nation's sole ground army, with the exception of a regiment to guard the Western Frontier and one battery of artillery guarding West Point's arsenal. However, because of continuing conflict with Native Americans, it was soon realized that it was necessary to field a trained standing army. The Regular Army was at first very small, and after General St. Clair's defeat at the Battle of the Wabash, the Regular Army was reorganized as the Legion of the United States, which was established in 1791 and renamed the "United States Army" in 1796.
19th century.
The War of 1812, the second and last American war against the United Kingdom, was less successful for the U.S. than the Revolution and Northwest Indian War against natives had been, though it ended on a high note for Americans also. After the taking control of Lake Erie in 1813, the Americans were able to seize parts of western Upper Canada, Burn York and Defeat Tecumseh, which caused his Indian Confederacy to collapse. Following ending victories in the province of Upper Canada, which dubbed the U.S. Army "Regulars, by God!", British troops were able to capture and burn Washington. The regular army, however, proved they were professional and capable of defeating the British army during the invasions of Plattsburgh and Baltimore, prompting British agreement on the previously rejected terms of a status quo ante bellum. Two weeks after a treaty was signed (but not ratified), Andrew Jackson defeated the British in the Battle of New Orleans and became a national hero. Per the treaty both sides returned to the status quo with no victor.
The army's major campaign against the Indians was fought in Florida against Seminoles. It took long wars (1818–58) to finally defeat the Seminoles and move them to Oklahoma. The usual strategy in Indian wars was to seize control of the Indians winter food supply, but that was no use in Florida where there was no winter. The second strategy was to form alliances with other Indian tribes, but that too was useless because the Seminoles had destroyed all the other Indians when they entered Florida in the late eighteenth century.
The U.S. Army fought and won the Mexican–American War (1846–1848), which was a defining event for both countries. The U.S. victory resulted in acquisition of territory that eventually became all or parts of the states of California, Nevada, Utah, Colorado, Arizona, Wyoming and New Mexico.
The American Civil War was the most costly war for the U.S. in terms of casualties. After most slave states, located in the southern U.S., formed the Confederate States of America, C.S. troops led by former U.S. Army officers, mobilized a very large fraction of Southern white manpower. Forces of the United States (the "Union" or "the North") formed a large new volunteer army.
For the first two years Confederate forces did well in set battles but lost control of the border states. The Confederates had the advantage of defending a very large country in an area where disease caused twice as many deaths as combat. The Union pursued a strategy of seizing the coastline, blockading the ports, and taking control of the river systems. By 1863 the Confederacy was being strangled. Its eastern armies fought well, but the western armies were defeated one after another until the Union forces captured New Orleans in 1862 along with the Tennessee River. In the famous Vicksburg Campaign of 1862–65, Ulysses Grant seized the Mississippi River and cut off the Southwest. Grant took command of Union forces in 1864 and after a series of battles with very heavy casualties, he had Lee under siege in Richmond as William T. Sherman captured Atlanta and marched through Georgia and the Carolinas. Lee lost his Confederate capital in April 1865 and was captured at Appomattox Court House; the other Confederate armies quickly surrendered.
The war remains the deadliest conflict in American history, resulting in the deaths of 620,000 soldiers. Based on 1860 census figures, 8% of all white males aged 13 to 43 died in the war, including 6.4% in the North and 18% in the South.
Following the Civil War, the U.S. Army had the mission of containing western tribes of Native Americans on their reservations. There were many forts set up, and several campaigns.
The key battles of the Spanish–American War of 1898 were fought by the Navy. Using mostly new volunteers, the US Army defeated Spain in land campaigns in Cuba and played the central role in suppressing a rebellion in the Philippines.
20th century.
Starting in 1910, the army began acquiring fixed-wing aircraft. In 1910, Mexico was having a civil war, peasant rebels fighting government soldiers. The army was deployed to American towns near the border to ensure safety to lives and property. In 1916, Pancho Villa, a major rebel leader, attacked Columbus, New Mexico, prompting a U.S. intervention in Mexico until 7 February 1917. They fought the rebels and the Mexican federal troops until 1918. The United States joined World War I in 1917 on the side of Britain, France, Russia, Italy and other allies. U.S. troops were sent to the front and were involved in the push that finally broke through the German lines. With the armistice in November 1918, the army once again decreased its forces.
The U.S. joined World War II after the Japanese attack on Pearl Harbor. On the European front, U.S. Army troops formed a significant portion of the forces that captured North Africa and Sicily. On D-Day and in the subsequent liberation of Europe and defeat of Nazi Germany, millions of U.S. Army troops played a central role. In the Pacific, U.S. Army soldiers participated alongside U.S. Marines in capturing the Pacific Islands from Japanese control. Following the Axis surrenders in May (Germany) and August (Japan) of 1945, army troops were deployed to Japan and Germany to occupy the two defeated nations. Two years after World War II, the Army Air Forces separated from the army to become the United States Air Force in September 1947 after decades of attempting to separate. Also, in 1948, the army was desegregated by order of President Harry S. Truman.
The end of World War II set the stage for the East–West confrontation known as the Cold War. With the outbreak of the Korean War, concerns over the defense of Western Europe rose. Two corps, V and VII, were reactivated under Seventh United States Army in 1950 and American strength in Europe rose from one division to four. Hundreds of thousands of U.S. troops remained stationed in West Germany, with others in Belgium, the Netherlands and the United Kingdom, until the 1990s in anticipation of a possible Soviet attack.
During the Cold War, American troops and their allies fought Communist forces in Korea and Vietnam. The Korean War began in 1950, when the Soviets walked out of a U.N. Security meeting, removing their possible veto. Under a United Nations umbrella, hundreds of thousands of U.S. troops fought to prevent the takeover of South Korea by North Korea, and later, to invade the northern nation. After repeated advances and retreats by both sides, and the PRC People's Volunteer Army's entry into the war, the returned the peninsula to the status quo in 1953.
The Vietnam War is often regarded as a low point for the army due to the use of drafted personnel, the unpopularity of the war with the American public, and frustrating restrictions placed on the military by American political leaders. While American forces had been stationed in the Republic of Vietnam since 1959, in intelligence & advising/training roles, they did not deploy in large numbers until 1965, after the Gulf of Tonkin Incident. American forces effectively established and maintained control of the "traditional" battlefield, however they struggled to counter the guerrilla hit and run tactics of the communist Viet Cong and the North Vietnamese Army. On a tactical level, American soldiers (and the U.S. military as a whole) did not lose a sizable battle.
During the 1960s the Department of Defense continued to scrutinize the reserve forces and to question the number of divisions and brigades as well as the redundancy of maintaining two reserve components, the Army National Guard and the Army Reserve. In 1967 Secretary of Defense Robert McNamara decided that 15 combat divisions in the Army National Guard were unnecessary and cut the number to 8 divisions (1 mechanized infantry, 2 armored, and 5 infantry), but increased the number of brigades from 7 to 18 (1 airborne, 1 armored, 2 mechanized infantry, and 14 infantry). The loss of the divisions did not set well with the states. Their objections included the inadequate maneuver element mix for those that remained and the end to the practice of rotating divisional commands among the states that supported them. Under the proposal, the remaining division commanders were to reside in the state of the division base. No reduction, however, in total Army National Guard strength was to take place, which convinced the governors to accept the plan. The states reorganized their forces accordingly between 1 December 1967 and 1 May 1968.
The Total Force Policy was adopted by Chief of Staff of the Army General Creighton Abrams in the aftermath of the Vietnam War and involves treating the three components of the army – the Regular Army, the Army National Guard and the Army Reserve as a single force. Believing that no U.S. president should be able to take the United States (and more specifically the U.S. Army) to war without the support of the American people, General Abrams intertwined the structure of the three components of the army in such a way as to make extended operations impossible, without the involvement of both the Army National Guard and the Army Reserve.
The 1980s was mostly a decade of reorganization. The army converted to an all-volunteer force with greater emphasis on training and technology. The Goldwater-Nichols Act of 1986 created unified combatant commands bringing the army together with the other four military services under unified, geographically organized command structures. The army also played a role in the invasions of Grenada in 1983 (Operation Urgent Fury) and Panama in 1989 (Operation Just Cause).
By 1989 Germany was nearing reunification and the Cold War was coming to a close. Army leadership reacted by starting to plan for a reduction in strength. By November 1989 Pentagon briefers were laying out plans to reduce army end strength by 23%, from 750,000 to 580,000. A number of incentives such as early retirement were used. In 1990 Iraq invaded its smaller neighbor, Kuwait, and U.S. land forces, quickly deployed to assure the protection of Saudi Arabia. In January 1991 Operation Desert Storm commenced, a U.S.-led coalition which deployed over 500,000 troops, the bulk of them from U.S. Army formations, to drive out Iraqi forces. The campaign ended in total victory, as Western coalition forces routed the Iraqi Army, organized along Soviet lines, in just one hundred hours.
After Operation Desert Storm, the army did not see major combat operations for the remainder of the 1990s but did participate in a number of peacekeeping activities. In 1990 the Department of Defense issued guidance for "rebalancing" after a review of the Total Force Policy, but in 2004, Air War College scholars concluded the guidance would reverse the Total Force Policy which is an "essential ingredient to the successful application of military force."
21st century.
On September 11, 2001, 53 Army civilians (47 employees and six contractors) and 22 soldiers were among the 125 victims killed in the Pentagon in a terrorist attack when American Airlines Flight 77 commandeered by five Al-Qaeda hijackers slammed into the western side of the building, as part of the September 11 attacks. Lieutenant General Timothy Maude was the highest-ranking military official killed at the Pentagon, and the most senior U.S. Army officer killed by foreign action since the death of Lieutenant General Simon B. Buckner, Jr. on June 18, 1945, in the Battle of Okinawa during World War II. 
In response to the September 11 attacks, and as part of the Global War on Terror, U.S. and NATO forces invaded Afghanistan in October 2001, displacing the Taliban government. The U.S. Army also led the combined U.S. and allied invasion of Iraq in 2003. In the following years the mission changed from conflict between regular militaries to counterinsurgency, resulting in the deaths of more than 4,000 U.S service members (as of March 2008) and injuries to thousands more. 23,813 insurgents were killed in Iraq between 2003–2011.
The army's chief modernization plan was the FCS program. Many systems were canceled and the remaining were swept into the BCT modernization program. In response to Budget sequestration in 2013 the army is planned to shrink to a size not seen since the WWII buildup. The 2015 expenditure for Army research, development and acquisition changed from $32 billion projected in 2012 for FY15, to $21 billion for FY15 expected in 2014.
Organization.
Army components.
The task of organizing the U.S. Army commenced in 1775. In the first one hundred years of its existence, the United States Army was maintained as a small peacetime force to man permanent forts and perform other non-wartime duties such as engineering and construction works. During times of war, the U.S. Army was augmented by the much larger United States Volunteers which were raised independently by various state governments. States also maintained full-time militias which could also be called into the service of the army.
By the twentieth century, the U.S. Army had mobilized the U.S. Volunteers on four separate occasions during each of the major wars of the nineteenth century. During World War I, the "National Army" was organized to fight the conflict, replacing the concept of U.S. Volunteers. It was demobilized at the end of World War I, and was replaced by the Regular Army, the Organized Reserve Corps, and the State Militias. In the 1920s and 1930s, the "career" soldiers were known as the "Regular Army" with the "Enlisted Reserve Corps" and "Officer Reserve Corps" augmented to fill vacancies when needed.
In 1941, the "Army of the United States" was founded to fight World War II. The Regular Army, Army of the United States, the National Guard, and Officer/Enlisted Reserve Corps (ORC and ERC) existed simultaneously. After World War II, the ORC and ERC were combined into the United States Army Reserve. The Army of the United States was re-established for the Korean War and Vietnam War and was demobilized upon the suspension of the draft.
Currently, the army is divided into the Regular Army, the Army Reserve, and the Army National Guard. The army is also divided into major branches such as Air Defense Artillery, Infantry, Aviation, Signal Corps, Corps of Engineers, and Armor. Before 1903 members of the National Guard were considered state soldiers unless federalized (i.e., activated) by the President. Since the Militia Act of 1903 all National Guard soldiers have held dual status: as National Guardsmen under the authority of the governor of their state or territory and, when activated, as a reserve of the U.S. Army under the authority of the President.
Since the adoption of the total force policy, in the aftermath of the Vietnam War, reserve component soldiers have taken a more active role in U.S. military operations. For example, Reserve and Guard units took part in the Gulf War, peacekeeping in Kosovo, Afghanistan, and the 2003 invasion of Iraq.
Army commands and army service component commands.
 Headquarters, United States Department of the Army (HQDA):
Source: U.S. Army organization
Structure.
The United States Army is made up of three components: the active component, the Regular Army; and two reserve components, the Army National Guard and the Army Reserve. Both reserve components are primarily composed of part-time soldiers who train once a month, known as battle assemblies or unit training assemblies (UTAs), and conduct two to three weeks of annual training each year. Both the Regular Army and the Army Reserve are organized under Title 10 of the United States Code, while the National Guard is organized under Title 32. While the Army National Guard is organized, trained and equipped as a component of the U.S. Army, when it is not in federal service it is under the command of individual state and territorial governors; the District of Columbia National Guard, however, reports to the U.S. President, not the district's mayor, even when not federalized. Any or all of the National Guard can be federalized by presidential order and against the governor's wishes.
The army is led by a civilian Secretary of the Army, who has the statutory authority to conduct all the affairs of the army under the authority, direction and control of the Secretary of Defense. The Chief of Staff of the Army, who is the highest-ranked military officer in the army, serves as the principal military adviser and executive agent for the Secretary of the Army, i.e., its service chief; and as a member of the Joint Chiefs of Staff, a body composed of the service chiefs from each of the four military services belonging to the Department of Defense who advise the President of the United States, the Secretary of Defense, and the National Security Council on operational military matters, under the guidance of the Chairman and Vice Chairman of the Joint Chiefs of Staff. In 1986, the Goldwater–Nichols Act mandated that operational control of the services follows a chain of command from the President to the Secretary of Defense directly to the unified combatant commanders, who have control of all armed forces units in their geographic or function area of responsibility. Thus, the secretaries of the military departments (and their respective service chiefs underneath them) only have the responsibility to organize, train and equip their service components. The army provides trained forces to the combatant commanders for use as directed by the Secretary of Defense.
Through 2013, the army is shifting to six geographical commands that will line up with the six geographical unified combatant commands (COCOM):
The army is also changing its base unit from divisions to brigades. Division lineage will be retained, but the divisional headquarters will be able to command any brigade, not just brigades that carry their divisional lineage. The central part of this plan is that each brigade will be modular, i.e., all brigades of the same type will be exactly the same, and thus any brigade can be commanded by any division. As specified before the 2013 end-strength re-definitions, the three major types of ground combat brigades are:
In addition, there are combat support and service support modular brigades. Combat support brigades include aviation (CAB) brigades, which will come in heavy and light varieties, fires (artillery) brigades (now transforms to division artillery), and battlefield surveillance brigades. Combat service support brigades include sustainment brigades and come in several varieties and serve the standard support role in an army.
Regular combat maneuver organizations.
The U.S. Army currently consists of 10 active divisions as well as several independent units. The force is in the process of contracting after several years of growth. In June 2013, the Army announced plans to downsize to 32 active combat brigade teams by 2015 to match a reduction in active duty strength to 490,000 soldiers. Army Chief of Staff Raymond Odierno has projected that by 2018 the Army will eventually shrink to "450,000 in the active component, 335,000 in the National Guard and 195,000 in U.S. Army Reserve."
Within the Army National Guard and United States Army Reserve there are a further eight divisions, over fifteen maneuver brigades, additional combat support and combat service support brigades, and independent cavalry, infantry, artillery, aviation, engineer, and support battalions. The Army Reserve in particular provides virtually all psychological operations and civil affairs units.
 United States Army Forces Command (FORSCOM):
For a description of US Army tactical organizational structure, see: a US context, and also a global context.
Special operations forces.
 United States Army Special Operations Command (Airborne) (USASOC):
Personnel.
These are the U.S. Army ranks authorized for use today and their equivalent NATO designations. Although no living officer currently holds the rank of General of the Army, it is still authorized by Congress for use in wartime.
Commissioned officers.
There are several paths to becoming a commissioned officer including the United States Military Academy, Reserve Officers' Training Corps, and Officer Candidate School. Regardless of which road an officer takes, the insignia are the same. Certain professions, including physicians, pharmacists, nurses, lawyers, and chaplains are commissioned directly into the army and are designated by insignia unique to their staff community.
Most army commissioned officers are promoted based on an "up or out" system. The Defense Officer Personnel Management Act of 1980 establishes rules for timing of promotions and limits the number of officers that can serve at any given time.
Army regulations call for addressing all personnel with the rank of general as 'General (last name)' regardless of the number of stars. Likewise, both colonels and lieutenant colonels are addressed as 'Colonel (last name)' and first and second lieutenants as 'Lieutenant (last name).'
Warrant officers.
Warrant officers are single track, specialty officers with subject matter expertise in a particular area. They are initially appointed as warrant officers (in the rank of WO1) by the Secretary of the Army, but receive their commission upon promotion to chief warrant officer two (CW2).
By regulation, warrant officers are addressed as 'Mr. (last name)' or 'Ms. (last name).' However, many personnel address warrant officers as 'Chief (last name)'. Enlisted soldiers say "sir" or "ma'am" when addressing them.
Enlisted personnel.
Sergeants and corporals are referred to as NCOs, short for non-commissioned officers. This distinguishes corporals from the more numerous specialists, who have the same pay grade but do not exercise leadership responsibilities.
Privates (E1 and E2) and privates first class (E3) are addressed as 'Private (last name)', specialists as 'Specialist (last name)', corporals as 'Corporal (last name)', and sergeants, staff sergeants, sergeants first class, and master sergeants all as 'Sergeant (last name).' First sergeants are addressed as 'First Sergeant (last name)', sergeants major are addressed as 'Sergeant Major (last name)' and command sergeants major are addressed as 'Command Sergeant Major (last name)'.
Training.
Training in the U.S. Army is generally divided into two categories – individual and collective. Basic training consists of 10 weeks for most recruits followed by Advanced Individualized Training (AIT) where they receive training for their military occupational specialties (MOS). Some individuals MOSs range anywhere from 14–20 weeks of One Station Unit Training (OSUT), which combines Basic Training and AIT. The length of AIT school varies by the MOS The length of time spent in AIT depends on the MOS of the soldier, and some highly technical MOS training may require many months (e.g., foreign language translators). Depending on the needs of the army, Basic Combat Training for combat arms soldiers is conducted at a number of locations, but two of the longest-running are the Armor School and the Infantry School, both at Fort Benning, Georgia.
Following their basic and advanced training at the individual-level, soldiers may choose to continue their training and apply for an "additional skill identifier" (ASI). The ASI allows the army to take a wide ranging MOS and focus it into a more specific MOS. For example, a combat medic, whose duties are to provide pre-hospital emergency treatment, may receive ASI training to become a cardiovascular specialist, a dialysis specialist, or even a licensed practical nurse. For commissioned officers, ASI training includes pre-commissioning training either at USMA, or via ROTC, or by completing OCS. After commissioning, officers undergo branch specific training at the Basic Officer Leaders Course, (formerly called Officer Basic Course), which varies in time and location according their future assignments. Further career development is available through the Army Correspondence Course Program.
Collective training at the unit level takes place at the unit's assigned station, but the most intensive training at higher echelons is conducted at the three combat training centers (CTC); the National Training Center (NTC) at Fort Irwin, California, the Joint Readiness Training Center (JRTC) at Fort Polk, Louisiana, and the Joint Multinational Training Center (JMRC) at the in Hohenfels, Germany. ARFORGEN is the Army Force Generation process approved in 2006 to meet the need to continuously replenish forces for deployment, at unit level, and for other echelons as required by the mission. Individual-level replenishment still requires training at a unit level, which is conducted at the continental US (CONUS) replacement center at Fort Bliss, in New Mexico and Texas, before their individual deployment.
Equipment.
Weapons.
The army employs various individual weapons to provide light firepower at short ranges. The most common weapons used by the army are the compact variant of the M16 rifle, the M4 carbine, as well as the 7.62x51 mm variant of the FN SCAR for Army Rangers. The primary sidearm in the U.S. Army is the 9 mm M9 pistol but M11 pistol is also used and M9 pistol is to be replaced by M11 pistol through the Modular Handgun System program.
Many units are supplemented with a variety of specialized weapons, including the M249 SAW (Squad Automatic Weapon), to provide suppressive fire at the fire-team level. Indirect fire is provided by the M203 grenade launcher. The M1014 Joint Service Combat Shotgun or the Mossberg 590 Shotgun are used for door breaching and close-quarters combat. The M14EBR is used by designated marksmen, and the M107 Long Range Sniper Rifle, the M2010 Enhanced Sniper Rifle, and the M110 Semi-Automatic Sniper Rifle are used by snipers. Hand grenades, such as the M67 fragmentation grenade and M18 smoke grenade, are also used.
The army employs various crew-served weapons to provide heavy firepower at ranges exceeding that of individual weapons.
The M240 is the US Army's standard Medium Machine Gun. The M2 heavy machine gun is generally used as a vehicle-mounted machine gun. In the same way, the 40 mm MK 19 grenade machine gun is mainly used by motorized units.
The US Army uses three types of mortar for indirect fire support when heavier artillery may not be appropriate or available. The smallest of these is the 60 mm M224, normally assigned at the infantry company level. At the next higher echelon, infantry battalions are typically supported by a section of 81 mm M252 mortars. The largest mortar in the army's inventory is the 120 mm M120/M121, usually employed by mechanized units.
Fire support for light infantry units is provided by towed howitzers, including the 105 mm M119A1 and the 155 mm M777 (which will replace the M198).
The US Army utilizes a variety of direct-fire rockets and missiles to provide infantry with an Anti-Armor Capability. The AT4 is an unguided projectile that can destroy armor and bunkers at ranges up to 500 meters. The FIM-92 Stinger is a shoulder-launched, heat seeking anti-aircraft missile. The FGM-148 Javelin and BGM-71 TOW are anti-tank guided missiles.
Vehicles.
The army's most common vehicle is the High Mobility Multipurpose Wheeled Vehicle (HMMWV), commonly called the Humvee, which is capable of serving as a cargo/troop carrier, weapons platform, and ambulance, among many other roles. While they operate a wide variety of combat support vehicles, one of the most common types centers on the family of HEMTT vehicles. The M1A2 Abrams is the army's main battle tank, while the M2A3 Bradley is the standard infantry fighting vehicle. Other vehicles include the Stryker, and the M113 armored personnel carrier, and multiple types of Mine Resistant Ambush Protected (MRAP) vehicles.
The Pentagon bought 25,000 MRAP vehicles since 2007 in 25 variants through rapid acquisition with no long-term plans for the platforms. The Army plans to divest 7,456 vehicles and retain 8,585. Of the total number of vehicles the Army will keep, 5,036 will be put in storage, 1,073 will be used for training, and the remainder will be spread across the active force. The Oshkosh M-ATV will be kept the most at 5,681 vehicles, as it is smaller and lighter than other MRAPs for off-road mobility. The other most retained vehicle will be the Navistar MaxxPro Dash with 2,633 vehicles, plus 301 Maxxpro ambulances. Thousands of other MRAPs like the Cougar, BAE Caiman, and larger MaxxPros will be disposed of.
The U.S. Army's principal artillery weapons are the M109A6 Paladin self-propelled howitzer and the M270 Multiple Launch Rocket System (MLRS), both mounted on tracked platforms and assigned to heavy mechanized units.
While the U.S. Army operates a few fixed-wing aircraft, it mainly operates several types of rotary-wing aircraft. These include the AH-64 Apache attack helicopter, the OH-58D Kiowa Warrior armed reconnaissance/light attack helicopter, the UH-60 Black Hawk utility tactical transport helicopter, and the CH-47 Chinook heavy-lift transport helicopter. Restructuring plans call for reduction of 750 aircraft and from 7 to 4 types.
Fixed wing aircraft used by the US Army are for non-front line combat and light transport roles. The army relies on the United States Air Force for airlift capabilities.
Uniforms.
The Army Combat Uniform, or ACU, currently features a digital Universal Camouflage Pattern (UCP) and is designed for use in woodland, desert, and urban environments. However, Soldiers operating in Afghanistan are being issued a fire-resistant ACU with the "MultiCam" pattern, officially known as Operation Enduring Freedom Camouflage Pattern or "OCP".
The standard garrison service uniform is known as Army Greens or Class-As and has been worn by all officers and enlisted personnel since its introduction in 1956 when it replaced earlier olive drab (OD) and khaki (and tan worsted or TW) uniforms worn between the 1950s and 1985. The Army Blue uniform, dating back to the mid-19th century, is currently the Army's formal dress uniform, but in 2013, it replaced the Army Green, and in 2014 it will replace the Army White uniform (a uniform similar to the Army Green uniform, but worn in tropical postings) and will become the new Army Service Uniform, which will function as both a garrison uniform (when worn with a white shirt and necktie) and a dress uniform (when worn with a white shirt and either a necktie for parades or a bow tie for after six or black tie events).
Berets.
The Army black beret (having been permanently replaced with the patrol cap) is no longer worn with the new ACU for garrison duty. After years of complaints that it wasn't suited well for most work conditions, Army Chief of Staff General Martin Dempsey eliminated it for wear with the ACU in June 2011. Soldiers may still wear colored berets who are currently in an airborne unit (maroon beret), Rangers (tan beret), and Special Forces (green beret) and may wear it with the Army Service Uniform for non-ceremonial functions. Unit commanders may still direct the wear of patrol caps in these units in training environments or motor pools.
Tents.
The army has relied heavily on tents to provide the various facilities needed while on deployment. The most common tent uses for the military are as temporary barracks (sleeping quarters), DFAC buildings (dining facilities), forward operating bases (FOBs), after action review (AAR), tactical operations center (TOC), morale, welfare, and recreation (MWR) facilities, and security checkpoints. Furthermore, most of these tents are set up and operated through the support of Natick Soldier Systems Center.
The U.S. Army is beginning to use a more modern tent called the deployable rapid assembly shelter or DRASH. In 2008, DRASH became part of the Army's Standard Integrated Command Post System.
3D printing.
In November 2012 the United States Army developed a tactical 3D printing capability to allow it to rapidly manufacture critical components on the battlefield. 
External links.
 

</doc>
<doc id="32090" url="http://en.wikipedia.org/wiki?curid=32090" title="United States Air Force">
United States Air Force

The United States Air Force (USAF) is the aerial warfare service branch of the United States Armed Forces and one of the seven American uniformed services. Initially part of the United States Army, the USAF was formed as a separate branch of the military on 18 September 1947 under the National Security Act of 1947. It is the most recent branch of the U.S. military to be formed, and is the largest and one of the world's most technologically advanced air forces. The USAF articulates its core functions as Nuclear Deterrence Operations, Special Operations, Air Superiority, Global Integrated ISR, Space Superiority, Command and Control, Cyberspace Superiority, Personnel Recovery, Global Precision Attack, Building Partnerships, Rapid Global Mobility and Agile Combat Support.
The U.S. Air Force is a military service within the Department of the Air Force, one of the three military departments of the Department of Defense. The USAF is headed by the civilian Secretary of the Air Force, who is appointed by the President with the advice and consent of the Senate. The highest-ranking military officer in the Department of the Air Force is the Chief of Staff of the Air Force who exercises supervision over Air Force units, and serves as a member of the Joint Chiefs of Staff. Air Force combat forces and mobility forces are assigned, as directed by the Secretary of Defense, to the Combatant Commanders, and neither the Secretary of the Air Force nor the Chief of Staff have operational command authority over them.
The U.S. Air Force provides air support for surface forces and aids in the recovery of troops in the field. s of 2012[ [update]], the service operates more than 5,638 military aircraft, 450 ICBMs and 63 military satellites. It has a $140 billion budget with 309,339 active duty personnel, 185,522 civilian personnel, 71,400 Air Force Reserve personnel, and 106,700 Air National Guard personnel.
Mission, vision, and functions.
Missions.
According to the National Security Act of 1947 (61 "Stat". 502), which created the USAF:
§8062 of Title 10 US Code defines the purpose of the USAF as:
The stated mission of the USAF today is to "fly, fight, and win in air, space, and cyberspace".
Vision.
"The United States Air Force will be a trusted and reliable joint partner with our sister services known for integrity in all of our activities, including supporting the joint mission first and foremost. We will provide compelling air, space, and cyber capabilities for use by the combatant commanders. We will excel as stewards of all Air Force resources in service to the American people, while providing precise and reliable Global Vigilance, Reach and Power for the nation".
Core functions.
Recently, the Air Force refined its understanding of the core duties and responsibilities it performs as a Military Service Branch, streamlining what previously were six distinctive capabilities and seventeen operational functions into twelve core functions to be used across the doctrine, organization, training, equipment, leadership, and education, personnel, and facilities spectrum. These core functions express the ways in which the Air Force is particularly and appropriately suited to contribute to national security, but they do not necessarily express every aspect of what the Air Force contributes to the nation. It should be emphasized that the core functions, by themselves, are not doctrinal constructs.
Nuclear Deterrence Operations.
The purpose of Nuclear Deterrence Operations (NDO) is to operate, maintain, and secure nuclear forces to achieve an assured capability to deter an adversary from taking action against vital US interests. In the event deterrence fails, the US should be able to appropriately respond with nuclear options. The sub-elements of this function are:
Assure/Dissuade/Deter is a mission set derived from the Air Force's readiness to carry out the nuclear strike operations mission as well as from specific actions taken to assure allies as a part of extended deterrence. Dissuading others from acquiring or proliferating WMD, and the means to deliver them, contributes to promoting security and is also an integral part of this mission. Moreover, different deterrence strategies are required to deter various adversaries, whether they are a nation state, or non-state/transnational actor. The Air Force maintains and presents credible deterrent capabilities through successful visible demonstrations and exercises which assure allies, dissuade proliferation, deter potential adversaries from actions that threaten US national security or the populations and deployed military forces of the US, its allies and friends.
Nuclear strike is the ability of nuclear forces to rapidly and accurately strike targets which the enemy holds dear in a devastating manner. If a crisis occurs, rapid generation and, if necessary, deployment of nuclear strike capabilities will demonstrate US resolve and may prompt an adversary to alter the course of action deemed threatening to our national interest. Should deterrence fail, the President may authorize a precise, tailored response to terminate the conflict at the lowest possible level and lead to a rapid cessation of hostilities. Post-conflict, regeneration of a credible nuclear deterrent capability will deter further aggression. The Air Force may present a credible force posture in either the Continental United States, within a theater of operations, or both to effectively deter the range of potential adversaries envisioned in the 21st century. This requires the ability to engage targets globally using a variety of methods; therefore, the Air Force should possess the ability to induct, train, assign, educate and exercise individuals and units to rapidly and effectively execute missions that support US NDO objectives. Finally, the Air Force regularly exercises and evaluates all aspects of nuclear operations to ensure high levels of performance.
Nuclear surety ensures the safety, security and effectiveness of nuclear operations. Because of their political and military importance, destructive power, and the potential consequences of an accident or unauthorized act, nuclear weapons and nuclear weapon systems require special consideration and protection against risks and threats inherent in their peacetime and wartime environments. The Air Force, in conjunction with other entities within the Departments of Defense or Energy, achieves a high standard of protection through a stringent nuclear surety program. This program applies to materiel, personnel, and procedures that contribute to the safety, security, and control of nuclear weapons, thus assuring no nuclear accidents, incidents, loss, or unauthorized or accidental use (a Broken Arrow incident). The Air Force continues to pursue safe, secure and effective nuclear weapons consistent with operational requirements. Adversaries, allies, and the American people must be highly confident of the Air Force's ability to secure nuclear weapons from accidents, theft, loss, and accidental or unauthorized use. This day-to-day commitment to precise and reliable nuclear operations is the cornerstone of the credibility of the NDO mission. Positive nuclear command, control, communications; effective nuclear weapons security; and robust combat support are essential to the overall NDO function.
Air Superiority.
Air Superiority is "that degree of dominance in the air battle of one force over another which permits the conduct of operations by the former and its related land, sea, air, and special operations forces at a given time and place without prohibitive interference by the opposing force" (JP 1-02).
Offensive Counterair (OCA) is defined as "offensive operations to destroy, disrupt, or neutralize enemy aircraft, missiles, launch platforms, and their supporting structures and systems both before and after launch, but as close to their source as possible" (JP 1-02). OCA is the preferred method of countering air and missile threats, since it attempts to defeat the enemy closer to its source and typically enjoys the initiative. OCA comprises attack operations, sweep, escort, and suppression/destruction of enemy air defense.
Defensive Counterair (DCA) is defined as "all the defensive measures designed to detect, identify, intercept, and destroy or negate enemy forces attempting to penetrate or attack through friendly airspace" (JP 1-02). A major goal of DCA operations, in concert with OCA operations, is to provide an area from which forces can operate, secure from air and missile threats. The DCA mission comprises both active and passive defense measures. Active defense is "the employment of limited offensive action and counterattacks to deny a contested area or position to the enemy" (JP 1-02). It includes both ballistic missile defense and air breathing threat defense, and encompasses point defense, area defense, and high value airborne asset defense. Passive defense is "measures taken to reduce the probability of and to minimize the effects of damage caused by hostile action without the intention of taking the initiative" (JP 1-02). It includes detection and warning; chemical, biological, radiological, and nuclear defense; camouflage, concealment, and deception; hardening; reconstitution; dispersion; redundancy; and mobility, counter-measures, and stealth.
Airspace control is "a process used to increase operational effectiveness by promoting the safe, efficient, and flexible use of airspace" (JP 1-02). It promotes the safe, efficient, and flexible use of airspace, mitigates the risk of fratricide, enhances both offensive and defensive operations, and permits greater agility of air operations as a whole. It both deconflicts and facilitates integration of joint air operations.
Space Superiority.
Space superiority is "the degree of dominance in space of one force over another that permits the conduct of operations by the former and its related land, sea, air, space, and special operations forces at a given time and place without prohibitive interference by the opposing force" (JP 1-02). Space superiority may be localized in time and space, or it may be broad and enduring. Space superiority provides freedom of action in space for friendly forces and, when directed, denies the same freedom to the adversary.
Space Force Enhancement is defined as the "combat support operations and force-multiplying capabilities delivered from space systems to improve the effectiveness of military forces as well as support other intelligence, civil, and commercial users. This mission area includes: intelligence, surveillance, and reconnaissance; integrated tactical warning and attack assessment; command, control, and communications; positioning, navigation, and timing; and environmental monitoring" (JP 1-02).
Space Force Application is defined as "combat operations in, through, and from space to influence the course and outcome of conflict. This mission area includes ballistic missile defense and force projection" (JP 1-02).
Space Control is defined as "operations to ensure freedom of action in space for the US and its allies and, when directed, deny an adversary freedom of action in space. This mission area includes: operations conducted to protect friendly space capabilities from attack, interference, or unintentional hazards (defensive space control); operations to deny an adversary's use of space capabilities (offensive space control); and the requisite current and predictive knowledge of the space environment and the operational environment upon which space operations depend (space situational awareness)" (JP 1-02).
Space Support is defined as "operations to deploy and sustain military and intelligence systems in space. This mission area includes: launching and deploying space vehicles; maintaining and sustaining spacecraft on-orbit, rendezvous and proximity operations; disposing of (including de-orbiting and recovering) space capabilities; and reconstitution of space forces, if required" (JP 1-02).
Cyberspace Superiority.
Cyberspace Superiority is "the operational advantage in, through, and from cyberspace to conduct operations at a given time and in a given domain without prohibitive interference" (AFDD 3-12, Cyberspace Operations).
Cyberspace Force Application is combat operations in, through, and from cyberspace to achieve military objectives and influence the course and outcome of conflict by taking decisive actions against approved targets. It will incorporate computer network attack (CNA), computer network exploitation (CNE), and may involve aspects of influence operations. It is highly dependent on ISR, fused all-source intelligence, sophisticated attribution activities, situational awareness, and responsive C2.
This is the passive, active, and dynamic employment of capabilities to respond to imminent or on-going actions against Air Force or Air Force-protected networks, the Air Force's portion of the Global Information Grid, or expeditionary communications assigned to the Air Force. Cyberspace defense incorporates CNE, computer network defense (CND), and CNA techniques and may be a contributor to influence operations. It is highly dependent upon ISR, fused all-source intelligence, automated indications and warning, sophisticated attribution/characterization, situational awareness, assessment, and responsive C2.
Cyberspace Support is foundational, continuous, or responsive operations ensuring information integrity and availability in, through, and from Air Force-controlled infrastructure and its interconnected analog and digital portion of the battle space. Inherent in this mission is the ability to establish, extend, secure, protect, and defend in order to sustain assigned networks and missions. This includes protection measures against supply chain components plus critical C2 networks/communications links and nuclear C2 networks. The cyberspace support mission incorporates CNE and CND techniques. It incorporates all elements of Air Force Network Operations, information transport, enterprise management, and information assurance, and is dependent on ISR and all-source intelligence.
Command and Control.
Command and control is "the exercise of authority and direction by a properly designated commander over assigned and attached forces in the accomplishment of the mission. Command and control functions are performed through an arrangement of personnel, equipment, communications, facilities, and procedures employed by a commander in planning, directing, coordinating, and controlling forces and operations in the accomplishment of the mission" (JP 1-02). This core function includes all of the C2-related capabilities and activities associated with air, space, cyberspace, nuclear, and agile combat support operations to achieve strategic, operational, and tactical objectives.
At the Strategic Level Command and Control, the US determines national or multinational security objectives and guidance, and develops and uses national resources to accomplish these objectives. These national objectives in turn provide the direction for developing overall military objectives, which are used to develop the objectives and strategy for each theater.
At the Operational Level Command and Control, campaigns and major operations are planned, conducted, sustained, and assessed to accomplish strategic goals within theaters or areas of operations. These activities imply a broader dimension of time or space than do tactics; they provide the means by which tactical successes are exploited to achieve strategic and operational objectives.
Tactical Level Command and Control is where individual battles and engagements are fought. The tactical level of war deals with how forces are employed, and the specifics of how engagements are conducted and targets attacked. The goal of tactical level C2 is to achieve commander's intent and desired effects by gaining and keeping offensive initiative.
Global Integrated ISR.
Global Integrated Intelligence, Surveillance, and Reconnaissance (ISR) is the synchronization and integration of the planning and operation of sensors, assets, and processing, exploitation, dissemination systems across the globe to conduct current and future operations.
Planning and Directing is "the determination of intelligence requirements, development of appropriate intelligence architecture, preparation of a collection plan, and issuance of orders and requests to information collection agencies" (JP 2-01, Joint and National Intelligence Support to Military Operations). These activities enable the synchronization and integration of collection, processing, exploitation, analysis, and dissemination activities/resources to meet information requirements of national and military decision makers.
Collection is "the acquisition of information and the provision of this information to processing elements" (JP 2-01). It provides the ability to obtain required information to satisfy intelligence needs (via use of sources and methods in all domains). Collection activities span the Range of Military Operations (ROMO).
Processing and exploitation is "the conversion of collected information into forms suitable to the production of intelligence" (JP 2-01). It provides the ability, across the ROMO, to transform, extract, and make available collected information suitable for further analysis or action.
Analysis and production is "the conversion of processed information into intelligence through the integration, evaluation, analysis, and interpretation of all source data and the preparation of intelligence products in support of known or anticipated user requirements" (JP 2-01). It provides the ability to integrate, evaluate, and interpret information from available sources to create a finished intelligence product for presentation or dissemination to enable increased situational awareness.
Dissemination and Integration is "the delivery of intelligence to users in a suitable form and the application of the intelligence to appropriate missions, tasks, and functions" (JP 2-01). It provides the ability to present information and intelligence products across the ROMO enabling understanding of the operational environment to military and national decision makers.
Global Precision Attack.
Global Precision Attack is the ability to hold at risk or strike rapidly and persistently, with a wide range of munitions, any target and to create swift, decisive, and precise effects across multiple domains.
Strategic Attack is defined as "offensive action specifically selected to achieve national strategic objectives. These attacks seek to weaken the adversary's ability or will to engage in conflict, and may achieve strategic objectives without necessarily having to achieve operational objectives as a precondition" (AFDD 3–70, Strategic Attack).
Air Interdiction is defined as "air operations conducted to divert, disrupt, delay, or destroy the enemy's military potential before it can be brought to bear effectively against friendly forces, or to otherwise achieve JFC objectives. Air lnterdiction is conducted at such distance from friendly forces that detailed integration of each air mission with the fire and movement of friendly forces is not required" (AFDD 3-03, Counterland Operations).
Close Air Support is defined as "air action by fixed- and rotary-winged aircraft against hostile targets that are in close proximity to friendly forces and which require detailed integration of each air mission with the fire and movement of those forces" (JP 1-02). This can be as a pre-planned event or on demand from an alert posture (ground or airborne). It can be conducted across the ROMO. Today the USAF believes that it accomplishes the CAS mission "better than anyone" actually does.
Special Operations.
Special Operations are "operations conducted in hostile, denied, or politically sensitive environments to achieve military, diplomatic, informational, and/or economic objectives employing military capabilities for which there is no broad conventional force requirement. These operations may require covert, clandestine, or low-visibility capabilities. Special operations are applicable across the ROMO. They can be conducted independently or in conjunction with operations of conventional forces or other government agencies and may include operations through, with, or by indigenous or surrogate forces. Special operations differ from conventional operations in degree of physical and political risk, operational techniques, mode of employment, independence from friendly support, and dependence on detailed operational intelligence and indigenous assets" (JP 1-02).
Agile Combat Support is the capability to effectively create, prepare, deploy, employ, sustain, and protect Air Force Special Operations Command (AFSOC) Airmen, assets, and capabilities throughout the ROMO at a chosen initiative, speed, and tempo.
Aviation Foreign Internal Defense operations directly execute US security and foreign policy as lead airpower elements that shape the battlefield and conduct stability operations to enable global reach and strike. This is accomplished by applying the mission set (assess, train, advise, and assist foreign aviation forces) across a continuum of operating venues described as indirect assistance, direct assistance (not including combat) and combat operations.
Battlefield Air Operations is a unique set of combat proven capabilities (combat control, pararescue, combat weather, and tactical air control party) provided by regular and reserve component special operations forces (SOF) Battlefield Airmen who integrate, synchronize, and control manned and unmanned capabilities to achieve tactical, operational, and strategic objectives.
Command and Control is the exercise of the commander's authority and direction over assigned and attached forces by trained, organized, and equipped C2 elements. Operational C2 elements consist of personnel and equipment with specialized capability to plan, direct, coordinate, and control forces in the conduct of joint/combined special operations.
Information Operations is the integrated employment of the capabilities of influence operations, electronic warfare operations, and network warfare operations, in concert with specified integrated control enablers, to influence, disrupt, corrupt, or usurp adversarial human and automated decision making while protecting one's own.
Intelligence, Surveillance, and Reconnaissance is the synchronization and integration of platforms and sensors with the planning and direction, collection, processing and exploitation, analysis, and production and dissemination processes. These activities provide actionable intelligence, weather, environmental awareness, and prediction across all SOF command echelons.
Military Information Support Operations are planned operations to convey selected information and indicators to foreign audiences to influence their emotions, motives, objective reasoning, and ultimately the behavior of foreign governments, organizations, groups, and individuals. The purpose of military information support operations is to induce or reinforce foreign attitudes and behavior favorable to the originator's objectives.
Precision Strike provides CCDRs with an integrated capability to find, fix, track, target, engage, and assess targets using a single weapons system or a combination of systems. This includes close air support, air interdiction, and armed reconnaissance missions.
Specialized Air Mobility is the conduct of rapid, global infiltration, exfiltration, and resupply of personnel, equipment, and materiel using specialized systems and tactics. These missions may be clandestine, low visibility, or overt and through hostile, denied, or politically sensitive airspace.
Specialized Refueling is the conduct of rapid, global refueling using specialized systems and tactics. This includes aerial refueling of vertical lift aircraft and ground refueling during forward arming and refueling point operations. These missions may be clandestine, low visibility, or overt and in hostile, denied, or politically sensitive environments.
Rapid Global Mobility.
Rapid Global Mobility is the timely deployment, employment, sustainment, augmentation, and redeployment of military forces and capabilities across the ROMO. It provides joint military forces the capability to move from place to place while retaining the ability to fulfill their primary mission. Rapid Global Mobility is essential to virtually every military operation, allowing forces to reach foreign or domestic destinations quickly, thus seizing the initiative through speed and surprise.
Airlift is "operations to transport and deliver forces and materiel through the air in support of strategic, operational, or tactical objectives" (AFDD 3–17, Air Mobility Operations). The rapid and flexible options afforded by airlift allow military forces and national leaders the ability to respond and operate in a variety of situations and time frames. The global reach capability of airlift provides the ability to apply US power worldwide by delivering forces to crisis locations. It serves as a US presence that demonstrates resolve and compassion in humanitarian crisis.
Air Refueling is "the refueling of an aircraft in flight by another aircraft" (JP 1-02). Air refueling extends presence, increases range, and serves as a force multiplier. It allows air assets to more rapidly reach any trouble spot around the world with less dependence on forward staging bases or overflight/landing clearances. Air refueling significantly expands the options available to a commander by increasing the range, payload, persistence, and flexibility of receiver aircraft.
Aeromedical Evacuation is "the movement of patients under medical supervision to and between medical treatment facilities by air transportation" (JP 1-02). JP 4-02, Health Service Support, further defines it as "the fixed wing movement of regulated casualties to and between medical treatment facilities, using organic and/or contracted mobility airframes, with aircrew trained explicitly for this mission." Aeromedical evacuation forces can operate as far forward as fixed-wing aircraft are able to conduct airland operations.
Personnel Recovery.
Personnel Recovery (PR) is defined as "the sum of military, diplomatic, and civil efforts to prepare for and execute the recovery and reintegration of isolated personnel" (JP 1-02). It is the ability of the US government and its international partners to effect the recovery of isolated personnel across the ROMO and return those personnel to duty. PR also enhances the development of an effective, global capacity to protect and recover isolated personnel wherever they are placed at risk; deny an adversary's ability to exploit a nation through propaganda; and develop joint, interagency, and international capabilities that contribute to crisis response and regional stability.
Combat Search and Rescue is "the tactics, techniques, and procedures performed by forces to effect the recovery of isolated personnel during combat" (JP 1-02). Combat search and rescue is the primary Air Force recovery method utilized to conduct PR taskings.
Civil Search and Rescue is "the use of aircraft, surface craft, submarines, and specialized rescue teams and equipment to search for and rescue distressed persons on land or at sea in a permissive environment" (JP 1-02).
Disaster Response can be described as the capability to support and assist US government agencies and embassies during national and international disasters with rapidly deployable and flexible air/ground rescue forces.
Humanitarian Assistance Operations are "programs conducted to relieve or reduce the results of natural or manmade disasters or other endemic conditions such as human pain, disease, hunger, or privation that might present a serious threat to life or that can result in great damage to or loss of property. Humanitarian assistance provided by US forces is limited in scope and duration. The assistance provided is designed to supplement or complement the efforts of the host nation civil authorities or agencies that may have the primary responsibility for providing humanitarian assistance" (JP 1-02).
Medical evacuation refers to dedicated medical evacuation platforms staffed and equipped to provide en route medical care using predesignated tactical and logistic aircraft, boats, ships, and other watercraft temporarily equipped and staffed with medical attendants for en route care. Casualty evacuation involves the unregulated movement of casualties aboard ships, land vehicles, or aircraft (JP 4-02, Health Service Support).
Agile Combat Support.
Agile Combat Support (ACS) is the ability to field, protect, and sustain Air Force forces across the ROMO to achieve joint effects.
Ready the Total Force includes organizing, training, and equipping forces; establishing quality of life and maintaining core security; and fielding and planning for the use of operational and support forces to meet global mission requirements.
Prepare the Battlespace includes assessing, planning, and posturing for rapid employment; prepositioning resources and conditioning specific theaters and/or contingency locations in a manner to meet closure timing; and establishing sustainment levels for potential operations.
Position the Total Force includes preparing to deploy, deploying, receiving, and bedding down tailored and prioritized forces; establishing initial operations and support cadres in a joint operations area; distributing pre-positioned resources; establishing initial reachback connectivity; securing operating locations; and preparing for mission operations.
Protecting the Total Force key focus areas include personnel, critical assets, and information. These areas are the persistent detection and understanding of threats in the operational environment and the timely dissemination of accurate decisions, warnings and taskings to protect against attacks and/or threats.
Employ Combat Support Forces includes engaging support forces in support of mission operations; initializing, launching, recovering, and regenerating operational elements; executing support through supporting-supported relationships; and commencing reachback operations to strategic levels of support.
Sustain the Total Force includes producing assured capacities and levels of support; accomplishing the long term mastery of an operational environment (peacetime and wartime) requiring persistent and effective materiel and personnel support through both local and reachback processes.
Recover the Total Force includes preparing forces to remain in place, redeploy, relocate, and be reconstituted to prescribed levels of readiness; restoring operating locations and/or environments to planned conditions; protecting the dynamic levels of force structure; and ensuring Air Force mission elements can be effectively applied at the direction of national leadership.
Building Partnerships.
Building Partnerships is described as airmen interacting with international airmen and other relevant actors to develop, guide, and sustain relationships for mutual benefit and security. Building Partnerships is about interacting with others and is therefore an inherently inter-personal and cross-cultural undertaking. Through both words and deeds, the majority of interaction is devoted to building trust-based relationships for mutual benefit. It includes both foreign partners as well as domestic partners and emphasizes collaboration with foreign governments, militaries and populations as well as US government departments, agencies, industry, and NGOs. To better facilitate partnering efforts, Airmen should be competent in the relevant language, region, and culture.
Communicate refers to developing and presenting information to domestic audiences to improve understanding. It is also the ability to develop and present information to foreign adversary audiences to affect their perceptions, will, behavior and capabilities in order to further US national security and/or shared global security interests.
Shape refers to conducting activities to affect the perceptions, will, behavior, and capabilities of partners, military forces, and relevant populations to further U.S. national security or shared global security interests.
History.
The U.S. War Department created the first antecedent of the U.S. Air Force in 1907, which through a succession of changes of organization, titles, and missions advanced toward eventual separation 40 years later. In World War II, almost 68,000 U.S airmen died helping to win the war; only the infantry suffered more enlisted casualties. In practice, the U.S. Army Air Forces (USAAF) was virtually independent of the Army during World War II, but officials wanted formal independence. The National Security Act of 1947 was signed on on 26 July 1947 by President Harry S Truman, which established the Department of the Air Force, but it was not not until 18 September 1947, when the first secretary of the Air Force, W. Stuart Symington was sworn into office that the Air Force was officially formed.
The act created the "National Military Establishment" (renamed Department of Defense in 1949), which was composed of three subordinate Military Departments, namely the Department of the Army, the Department of the Navy, and the newly created Department of the Air Force. Prior to 1947, the responsibility for military aviation was shared between the Army (for land-based operations), the Navy (for sea-based operations from aircraft carriers and amphibious aircraft), and the Marine Corps (for close air support of infantry operations). The 1940s proved to be important in other ways as well. In 1947, Captain Chuck Yeager broke the sound barrier in his X-1 rocket-powered aircraft, beginning a new era of aeronautics in America.
The predecessor organizations in the Army of today's Air Force are:
Recent history.
During the early 2000s, the USAF fumbled several high profile aircraft procurement projects, such as the missteps on the KC-X program. Winslow Wheeler has written that this pattern represents "failures of intellect and – much more importantly – ethics." As a result the USAF fleet is setting new records for average aircraft age and needs to replace its fleets of fighters, bombers, airborne tankers, and airborne warning aircraft, in an age of restrictive defense budgets. Finally in the midst of scandal and failure in maintaining its nuclear arsenal, the civilian and military leaders of the air force were replaced in 2008.
Since 2005, the USAF has placed a strong focus on the improvement of Basic Military Training (BMT) for enlisted personnel. While the intense training has become longer, it also has shifted to include a deployment phase. This deployment phase, now called the BEAST, places the trainees in a surreal environment that they may experience once they deploy. While the trainees do tackle the massive obstacle courses along with the BEAST, the other portions include defending and protecting their base of operations, forming a structure of leadership, directing search and recovery, and basic self aid buddy care. During this event, the Military Training Instructors (MTI) act as mentors and enemy forces in a deployment exercise.
In 2007, the USAF undertook a Reduction-in-Force (RIF). Because of budget constraints, the USAF planned to reduce the service's size from 360,000 active duty personnel to 316,000. The size of the active duty force in 2007 was roughly 64% of that of what the USAF was at the end of the first Gulf War in 1991. However, the reduction was ended at approximately 330,000 personnel in 2008 in order to meet the demand signal of combatant commanders and associated mission requirements. These same constraints have seen a sharp reduction in flight hours for crew training since 2005 and the Deputy Chief of Staff for Manpower and Personnel directing Airmen's Time Assessments.
On 5 June 2008, Secretary of Defense Robert Gates, accepted the resignations of both the Secretary of the Air Force, Michael Wynne, and the Chief of Staff of the United States Air Force, General T. Michael Moseley. Gates in effect fired both men for "systemic issues associated with declining Air Force nuclear mission focus and performance." This followed an investigation into two embarrassing incidents involving mishandling of nuclear weapons: specifically a nuclear weapons incident aboard a B-52 flight between Minot AFB and Barksdale AFB, and an accidental shipment of nuclear weapons components to Taiwan. The resignations were also the culmination of disputes between the Air Force leadership, populated primarily by non-nuclear background fighter pilots, versus Gates. To put more emphasis on nuclear assets, the USAF established the nuclear-focused Air Force Global Strike Command on 24 October 2008.
On 26 June 2009, the USAF released a force structure plan that cut fighter aircraft and shifted resources to better support nuclear, irregular and information warfare. On 23 July 2009, The USAF released their Unmanned Aerial System (UAS) Flight Plan, detailing Air Force UAS plans through 2047. One third of the planes that the USAF planned to buy in the future were to be unmanned.
In 2011, the Air Force disallowed the wear of so-called "Friday Name Tags" by aircrew personnel on flight suits and flight jackets per the new dress and appearance standards. This has been a tradition regarding call signs that dated to World War I.
Conflicts.
The United States has been involved in many wars, conflicts and operations using military air operations. Air combat operations before, and since the official conception of the USAF include:
In addition since the USAF dwarfs all allied air forces, it often provides support for allied forces in conflicts to which the United States is otherwise not involved, for example the 2013 French campaign in Mali.
Humanitarian operations.
The USAF has also taken part in numerous humanitarian operations. Some of the more major ones include the following:
Budget sequestration.
Due to the Budget sequestration in 2013, the USAF was forced to ground many of its squadrons. The Commander of Air Combat Command, General Mike Hostage indicated that the USAF must reduce its F-15 and F-16 fleets and eliminate platforms like the A-10 in order to focus on a fifth-generation jet fighter future. In response to squadron groundings and flight time reductions, many Air Force pilots have opted to resign from active duty and enter the Air Force Reserve and Air National Guard while pursuing careers in the commercial airlines where they can find flight hours on more modern aircraft.
Specific concerns include a compounded inability for the Air Force to replace its aging fleet, and an overall reduction of strength and readiness. The USAF attempted to make these adjustments by primarily cutting the Air National Guard and Air Force Reserve aircraft fleets and their associated manpower, but Congress reversed this initiative and the majority of the lost manpower will come from the active forces. However, Congress did allow for $208 million of reprogramming from fleet modernization to enable some portion of the third of the grounded fleet to resume operations.
Organization.
Administrative organization.
The Department of the Air Force is one of three military departments within the Department of Defense, and is managed by the civilian Secretary of the Air Force, under the authority, direction, and control of the Secretary of Defense. The senior officials in the Office of the Secretary are the Under Secretary of the Air Force, four Assistant Secretaries of the Air Force and the General Counsel, all of whom are appointed by the President with the advice and consent of the Senate. The senior uniformed leadership in the Air Staff is made up of the Chief of Staff of the Air Force and the Vice Chief of Staff of the Air Force.
The directly subordinate commands and units are named Field Operating Agency (FOA), Direct Reporting Unit (DRU), and the currently unused "Separate Operating Agency".
The Major Command (MAJCOM) is the superior hierarchical level of command. Including the Air Force Reserve Command, as of 30 September 2006, USAF has ten major commands. The Numbered Air Force (NAF) is a level of command directly under the MAJCOM, followed by Operational Command "(now unused)", Air Division "(also now unused)", Wing, Group, Squadron, and Flight.
Major Commands (Force Structure).
The major components of the U.S. Air Force, as of 30 September 2006, are the following:
The USAF, including its Air Reserve Component (e.g., Air Force Reserve + Air National Guard), possesses a total of 302 flying squadrons.
Operational organization.
The organizational structure as shown above is responsible for the peacetime organization, equipping, and training of aerospace units for operational missions. When required to support operational missions, the Secretary of Defense (SECDEF) directs the Secretary of the Air Force (SECAF) to execute a Change in Operational Control (CHOP) of these units from their administrative alignment to the operational command of a Regional Combatant Commander (CCDR). In the case of AFSPC, AFSOC, PACAF, and USAFE units, forces are normally employed in-place under their existing CCDR. Likewise, AMC forces operating in support roles retain their componency to USTRANSCOM unless chopped to a Regional CCDR.
Aerospace Expeditionary Task Force.
"Chopped" units are referred to as "forces". The top-level structure of these forces is the Air and Space Expeditionary Task Force (AETF). The AETF is the Air Force presentation of forces to a CCDR for the employment of Air Power. Each CCDR is supported by a standing Component Numbered Air Force (C-NAF) to provide planning and execution of aerospace forces in support of CCDR requirements. Each C-NAF consists of a Commander, Air Force Forces (COMAFFOR) and AFFOR/A-staff, and an Air Operations Center (AOC). As needed to support multiple Joint Force Commanders (JFC) in the COCOM's Area of Responsibility (AOR), the C-NAF may deploy Air Component Coordinate Elements (ACCE) to liaise with the JFC. If the Air Force possesses the preponderance of air forces in a JFC's area of operations, the COMAFFOR will also serve as the Joint Forces Air Component Commander (JFACC).
Commander, Air Force Forces.
The Commander, Air Force Forces (COMAFFOR) is the senior USAF officer responsible for the employment of air power in support of JFC objectives. The COMAFFOR has a special staff and an A-Staff to ensure assigned or attached forces are properly organized, equipped, and trained to support the operational mission.
Air Operations Center.
The Air Operations Center (AOC) is the JFACC's Command and Control (C2) center. Several AOCs have been established throughout the Air Force world-wide. These centers are responsible for planning and executing air power missions in support of JFC objectives.
Air Expeditionary Wings/Groups/Squadrons.
The AETF generates air power to support COCOM objectives from Air Expeditionary Wings (AEW) or Air Expeditionary Groups (AEG). These units are responsible for receiving combat forces from Air Force MAJCOMs, preparing these forces for operational missions, launching and recovering these forces, and eventually returning forces to the MAJCOMs. Theater Air Control Systems control employment of forces during these missions.
Personnel.
The classification of any USAF job for officers or enlisted airmen is the Air Force Specialty Code (AFSC).
AFSCs range from officer specialties such as pilot, combat systems officer, missile launch officer, intelligence officer, aircraft maintenance officer, judge advocate general (JAG), medical doctor, nurse or other fields, to various enlisted specialties. The latter range from flight combat operations such as a gunner, to working in a dining facility to ensure that members are properly fed. There are additional occupational fields such as computer specialties, mechanic specialties, enlisted aircrew, communication systems, cyberspace operations, avionics technicians, medical specialties, civil engineering, public affairs, hospitality, law, drug counseling, mail operations, security forces, and search and rescue specialties.
Beyond combat flight crew personnel, perhaps the most dangerous USAF jobs are Explosive Ordnance Disposal (EOD), Combat rescue officer, Pararescue, Security Forces, Combat Control, Combat Weather, Tactical Air Control Party, and AFOSI agents, who deploy with infantry and special operations units who disarm bombs, rescue downed or isolated personnel, call in air strikes and set up landing zones in forward locations. Most of these are enlisted positions augmented by a smaller number of commissioned officers. Other career fields that have seen increasing exposure to combat include civil engineers, vehicle operators, and Air Force Office of Special Investigations (AFOSI) personnel.
Nearly all enlisted career fields are "entry level", meaning that the USAF provides all training. Some enlistees are able to choose a particular field, or at least a field before actually joining, while others are assigned an AFSC at Basic Military Training (BMT). After BMT, new enlisted airmen attend a technical training school where they learn their particular AFSC. Second Air Force, a part of Air Education and Training Command, is responsible for nearly all enlisted technical training.
Training programs vary in length; for example, 3M0X1 (Services) has 31 days of tech school training, while 3E8X1 (Explosive Ordnance Disposal) is one year of training with a preliminary school and a main school consisting of over 10 separate divisions, sometimes taking students close to two years to complete. Officer technical training conducted by Second Air Force can also vary by AFSC, while flight training for aeronautically-rated officers conducted by AETC's Nineteenth Air Force can last well in excess of one year.
USAF rank is divided between enlisted airmen, non-commissioned officers, and commissioned officers, and ranges from the enlisted Airman Basic (E-1) to the commissioned officer rank of General (O-10). Enlisted promotions are granted based on a combination of test scores, years of experience, and selection board approval while officer promotions are based on time-in-grade and a promotion selection board. process Promotions among enlisted personnel and non-commissioned officers are generally designated by increasing numbers of insignia chevrons. Commissioned officer rank is designated by bars, oak leaves, a silver eagle, and anywhere from one to four stars (one to five stars in war-time).
Commissioned officers.
The commissioned officer ranks of the USAF are divided into three categories: company grade officers, field grade officers, and general officers. Company grade officers are those officers in pay grades O-1 to O-3, while field grade officers are those in pay grades O-4 to O-6, and general officers are those in pay grades of O-7 and above.
Air Force officer promotions are governed by the Defense Officer Personnel Management Act of 1980 and its companion Reserve Officer Personnel Management Act (ROPMA) for officers in the Air Force Reserve and the Air National Guard. DOPMA also establishes limits on the number of officers that can serve at any given time in the Air Force. Currently, promotion from second lieutenant to first lieutenant is virtually guaranteed after two years of satisfactory service. The promotion from first lieutenant to captain is competitive after successfully completing another two years of service, with a selection rate varying between 99% and 100%. Promotion to major through major general is through a formal selection board process, while promotions to lieutenant general and general are contingent upon nomination to specific general officer positions and subject to U.S. Senate approval.
During the board process an officer's record is reviewed by a selection board at the Air Force Personnel Center at Randolph Air Force Base in San Antonio, Texas. At the 10 to 11 year mark, captains will take part in a selection board to major. If not selected, they will meet a follow-on board to determine if they will be allowed to remain in the Air Force. Promotion from major to lieutenant colonel is similar and occurs approximately between the thirteen year (for officers who were promoted to major early "below the zone") and the fifteen year mark, where a certain percentage of majors will be selected below zone (i.e., "early"), in zone (i.e., "on time") or above zone (i.e., "late") for promotion to lieutenant colonel. This process will repeat at the 16 year mark (for officers previously promoted early to major and lieutenant colonel) to the 21 year mark for promotion to full colonel.
The Air Force has the largest ratio of general officers to total strength of all of the U.S. armed forces and this ratio has continued to increase even as the force has shrunk from its Cold War highs.
Warrant officers.
Although provision is made in Title 10 of the United States Code for the Secretary of the Air Force to appoint warrant officers, the Air Force does not currently use warrant officer grades, and is the only one of the U.S. Armed Services not to do so. The Air Force inherited warrant officer ranks from the Army at its inception in 1947, but their place in the Air Force structure was never made clear. When the Congress authorized the creation of two new senior enlisted ranks in 1958, Air Force officials privately concluded that these two new "super grades" could fill all Air Force needs then performed at the warrant officer level, although this was not publicly acknowledged until years later. The Air Force stopped appointing warrant officers in 1959, the same year the first promotions were made to the new top enlisted grade, Chief Master Sergeant. Most of the existing Air Force warrant officers entered the commissioned officer ranks during the 1960s, but small numbers continued to exist in the warrant officer grades for the next 21 years.
The last active duty Air Force warrant officer, CWO4 James H. Long, retired in 1980 and the last Air Force Reserve warrant officer, CWO4 Bob Barrow, retired in 1992. Upon his retirement, he was honorarily promoted to CWO5, the only person in the Air Force ever to hold this grade. Barrow died in April 2008. Since Barrow's retirement, the Air Force warrant officer ranks, while still authorized by law, are not used.
Enlisted airmen.
Enlisted members of the USAF have pay grades from E-1 (entry level) to E-9 (senior enlisted). While all USAF military personnel are referred to as "Airmen", the term also refers to the pay grades of E-1 through E-4, which are below the level of non-commissioned officers (NCOs). Above the pay grade of E-4 (i.e., pay grades E-5 through E-9) all ranks fall into the category of NCO and are further subdivided into "NCOs" (pay grades E-5 and E-6) and "Senior NCOs" (pay grades E-7 through E-9); the term "Junior NCO" is sometimes used to refer to staff sergeants and technical sergeants (pay grades E-5 and E-6).
The USAF is the only branch of the U.S. military where NCO status is achieved when an airman reaches the pay grade of E-5. In all other branches, NCO status is generally achieved at the pay grade of E-4 (e.g., a Corporal in the Army and Marine Corps, Petty Officer Third Class in the Navy and Coast Guard). The Air Force mirrored the Army from 1976 to 1991 with an E-4 being either a Senior Airman wearing three stripes without a star or a Sergeant (referred to as "Buck Sergeant"), which was noted by the presence of the central star and considered an NCO. Despite not being an NCO, a Senior Airman who has completed Airman Leadership School can be a supervisor according to the AFI 36-2618.
Uniforms.
The first USAF dress uniform, in 1947, was dubbed and patented "Uxbridge Blue" after "Uxbridge 1683 Blue", developed at the former "Bachman-Uxbridge Worsted Company". The current Service Dress Uniform, which was adopted in 1993 and standardized in 1995, consists of a three-button, pocketless coat, similar to that of a men's "sport jacket" (with silver "U.S." pins on the lapels, with a silver ring surrounding on those of enlisted members), matching trousers, and either a service cap or flight cap, all in Shade 1620, "Air Force Blue" (a darker purplish-blue). This is worn with a light blue shirt (Shade 1550) and Shade 1620 herringbone patterned necktie. Enlisted members wear sleeve insignia on both the jacket and shirt, while officers wear metal rank insignia pinned onto the coat, and Air Force Blue slide-on epaulet loops on the shirt. USAF personnel assigned to Base Honor Guard duties wear, for certain occasions, a modified version of the standard service dress uniform, but with silver trim on the sleeves and trousers, with the addition of a ceremonial belt (if necessary), wheel cap with silver trim and Hap Arnold Device, and a silver aiguillette placed on the left shoulder seam and all devices and accoutrement.
The Airman Battle Uniform (ABU) became the sole authorized utility uniform (except the flight suit for air, missile and space crews) of the USAF on 1 November 2011. The ABU replaced the Battle Dress Uniform (BDU) previously worn by all U.S. military forces.
Awards and badges.
In addition to basic uniform clothing, various badges are used by the USAF to indicate a billet assignment or qualification-level for a given assignment. Badges can also be used as merit-based or service-based awards. Over time, various badges have been discontinued and are no longer distributed. Authorized badges include the Shields of USAF Fire Protection, and Security Forces, and the Missile Badge (or "pocket rocket"), which is earned after working in a missile system maintenance or missile operations capacity for at least one year.
Training.
All non-prior service "enlisted Airmen" attend Basic Military Training (BMT) at Lackland Air Force Base in San Antonio, Texas for 7 1/2 weeks. The Air Force accepts the basic training programs of other U.S. military branches in lieu of BMT for airmen who enlist having completed prior service in the U.S. Army, Navy, Marine Corps or Coast Guard.
"Officers" may be commissioned upon graduation from the United States Air Force Academy, upon graduation from another college or university through the Air Force Reserve Officer Training Corps (AFROTC) program, or through the Air Force Officer Training School (OTS). OTS, previously located at Lackland AFB, Texas until 1993 and located at Maxwell Air Force Base in Montgomery, Alabama since 1993, in turn encompasses two separate commissioning programs: Basic Officer Training (BOT), which is for line-officer candidates of the active-duty Air Force and the U.S. Air Force Reserve; and the Academy of Military Science (AMS), which is for line-officer candidates of the Air National Guard. (The term "line officer" derives from the concept of the line of battle and refers to an officer whose role falls somewhere within the "Line of the Air", meaning combat or combat-support operations within the scope of legitimate combatants as defined by the Geneva Conventions.)
The Air Force also provides Commissioned Officer Training (COT) for officers of all three components who are direct-commissioned to "non-line positions" due to their credentials in medicine, law, religion, biological sciences, or healthcare administration. Originally viewed as a "knife and fork school" that covered little beyond basic wear of the uniform, COT in recent years has been fully integrated into the OTS program and today encompasses extensive coursework as well as field exercises in leadership, confidence, fitness, and deployed-environment operations.
Air Force Fitness Test.
The US Air Force Fitness Test (AFFT) is designed to test the abdominal circumference, muscular strength/endurance and cardiovascular respiratory fitness of airmen in the USAF. As part of the "Fit to Fight" program, the USAF adopted a more stringent physical fitness assessment; the new fitness program was put into effect on 1 June 2010. The annual ergo-cycle test which the USAF had used for several years had been replaced in 2004. In the AFFT, Airmen are given a score based on performance consisting of four components: waist circumference, the sit-up, the push-up, and a 1.5 mi run. Airmen can potentially earn a score of 100, with the run counting as 60%, waist circumference as 20%, and both strength test counting as 10% each. A passing score is 75 points. Effective 1 July 2010, the AFFT is administered by the base Fitness Assessment Cell (FAC), and is required twice a year. Personnel may test once a year if he or she earns a score above a 90%. Additionally, only meeting the minimum standards on each one of these test will not get you a passing score of 75%, and failing any one component will result in a failure for the entire test.
Aircraft inventory.
The U.S. Air Force has over 5,638 aircraft in service as of September 2012. Until 1962, the Army and Air Force maintained one system of aircraft naming, while the U.S. Navy maintained a separate system. In 1962, these were unified into a single system heavily reflecting the Army/Air Force method. For more complete information on the workings of this system, refer to United States Department of Defense aerospace vehicle designation. The various aircraft of the Air Force include:
A – Ground attack.
The ground-attack aircraft of the USAF are designed to attack targets on the ground and are often deployed as close air support for, and in proximity to, U.S. ground forces. The proximity to friendly forces require precision strikes from these aircraft that are not possible with bomber aircraft listed below. They are typically deployed as close air support to ground forces, their role is tactical rather than strategic, operating at the front of the battle rather than against targets deeper in the enemy's rear.
The A-10 had been projected to be retired by 2019 and replaced by the F-35, but the A-10 fleet might possibly be retained through upgrades until at least 2028. The AC-130J is currently under development and is scheduled to replace all current AC-130 variants. The AC-130W's are former MC-130W Combat Spear aircraft.
B – Strategic bombers.
In the US Air Force, the distinction between bombers, fighters that are actually fighter-bombers, and attack aircraft has become blurred. Many attack aircraft, even ones that look like fighters, are optimized to drop bombs, with very little ability to engage in aerial combat. Many fighter aircraft, such as the F-16, are often used as 'bomb trucks', despite being designed for aerial combat. Perhaps the one meaningful distinction at present is the question of range: a bomber is generally a long-range aircraft capable of striking targets deep within enemy territory, whereas fighter bombers and attack aircraft are limited to 'theater' missions in and around the immediate area of battlefield combat. Even that distinction is muddied by the availability of aerial refueling, which greatly increases the potential radius of combat operations. The US, Russia, and the People's Republic of China operate strategic bombers.
The service's B-2A aircraft entered service in the 1990s, its B-1B aircraft in the 1980s and its current B-52H aircraft in the early 1960s. The B-52 Stratofortress airframe design is over 60 years old and the B-52H aircraft currently in the active inventory were all built between 1960 and 1962. The B-52H is scheduled to remain in service for another 30 years, which would keep the airframe in service for nearly 90 years, an unprecedented length of service for any aircraft. Plans for successors to the current strategic bomber force remain only paper projects, and political and funding pressures suggest that they are likely to remain paper-bound for the foreseeable future.
C – Cargo transport.
The Air Force can provide rapid global mobility, which lies at the heart of U.S. strategy in this environment—without the capability to project forces, there is no conventional deterrent. As U.S. forces stationed overseas continue to decline, global interests remain, making the unique mobility capabilities of the USAF even more in demand. Air mobility is a national asset of growing importance for responding to emergencies and protecting American interests around the globe.
Cargo and transport aircraft are typically used to deliver troops, weapons and other military equipment by a variety of methods to any area of military operations around the world, usually outside of the commercial flight routes in uncontrolled airspace. The workhorses of the USAF Air Mobility Command are the C-130 Hercules, C-17 Globemaster III, and C-5 Galaxy. These aircraft are largely defined in terms of their range capability as strategic airlift (C-5), strategic/tactical (C-17), and tactical (C-130) airlift to reflect the needs of the land forces they most often support. The CV-22 is used by the Air Force for the U.S. Special Operations Command (USSOCOM). It conducts long-range, special operations missions, and is equipped with extra fuel tanks and terrain-following radar. Some aircraft serve specialized transportation roles such as executive/embassy support (C-12), Antarctic Support (LC-130H), and USSOCOM support (C-27J, C-145A, and C-146A). The WC-130H aircraft are former weather reconnaissance aircraft, now reverted to the transport mission.
Although most of the US Air Force's cargo aircraft were specially designed with the Air Force in mind, some aircraft such as the C-12 Huron (Beechcraft Super King Air) and C-146 (Dornier 328) are militarized conversions of existing civilian aircraft.
E – Special electronic missions.
The purpose of electronic warfare is to deny the opponent an advantage in the EMS and ensure friendly, unimpeded access to the EM spectrum portion of the information environment. Electronic warfare aircraft are used to keep airspaces friendly, and send critical information to anyone who needs it. They are often called "The Eye in the Sky." The roles of the aircraft vary greatly among the different variants to include Electronic Warfare/Jamming (EC-130H), Psychological Operations/Communications (EC-130J), Airborne Early Warning and Control (E-3), Airborne Command Post (E-4B), ground targeting radar (E-8C), range control (E-9A), and communications relay (E-11A)
F – Fighter.
The fighter aircraft of the USAF are small, fast, and maneuverable military aircraft primarily used for air-to-air combat. Many of these fighters have secondary ground-attack capabilities, and some are dual-roled as fighter-bombers (e.g., the F-16 Fighting Falcon); the term "fighter" is also sometimes used colloquially for dedicated ground-attack aircraft. Other missions include interception of bombers and other fighters, reconnaissance, and patrol. The F-16 is currently used by the USAF Air Demonstration squadron, the Thunderbirds, while a small number of both man-rated and non-man-rated F-4 Phantom II are retained as QF-4 aircraft for use as Full Scale Aerial Targets (FSAT) or as part of the USAF Heritage Flight program. These extant QF-4 aircraft are being replaced in the FSAT role by early model F-16 aircraft converted to QF-16 configuration. The USAF has 2,025 fighters in service as of September 2012.
H – Search and rescue.
These aircraft are used for search and rescue and combat search and rescue on land or sea. The HC-130N/P aircraft are being replaced by newer HC-130J models. HH-60U are replacement aircraft for "G" models that have been lost in combat operations or accidents. New HH-60W helicopters are under development to replace both the "G" and "U" model Pave Hawks.
K – Tanker.
The USAF's aerial refueling aircraft are derivatives of civilian jets. The USAF aircraft are equipped primarily for providing the fuel via a tail-mounted refueling boom, and can be equipped with "probe and drogue" refueling systems. Air-to-air refueling is extensively used in large-scale operations and also used in normal operations; fighters, bombers, and cargo aircraft rely heavily on the lesser-known "tanker" aircraft. This makes these aircraft an essential part of the Air Force's global mobility and the U.S. force projection. The KC-46A Pegasus is currently undergoing testing projected to start fielding in 2016.
M – Multi-mission.
Specialized multi-mission aircraft provide support for global special operations missions. These aircraft conduct infiltration, exfiltration, resupply, and refueling for SOF teams from improvised or otherwise short runways. The MC-130J is currently being fielded to replace "H" and "P" models used by U.S. Special Operations Command. The MC-12W is used in the Intelligence, Surveillance, and Reconnaissance (ISR) role.
Initial generations of RPAs were primarily surveillance aircraft, but some were fitted with weaponry (such as the MQ-1 Predator, which used AGM-114 Hellfire air-to-ground missiles). An armed RPA is known as an unmanned combat air vehicle (UCAV).
O – Observation.
These aircraft are modified to observe (through visual or other means) and report tactical information concerning composition and disposition of forces. The OC-135 is specifically designed to support the Treaty on Open Skies by observing bases and operations of party members under the 2002 signed treaty.
R – Reconnaissance.
The reconnaissance aircraft of the USAF are used for monitoring enemy activity, originally carrying no armament. Although the U-2 is designated as a 'utility' aircraft, it is a reconnaissance platform. The roles of the aircraft vary greatly among the different variants to include general monitoring (RC-26B), Ballistic missile monitoring (RC-135S), Electronic Intelligence gathering (RC-135U), Signal Intelligence gathering (RC-135V/W), and high altitude surveillance (U-2)
Several unmanned remotely controlled reconnaissance aircraft (RPAs), have been developed and deployed. Recently, the RPAs have been seen to offer the possibility of cheaper, more capable fighting machines that can be used without risk to aircrews.
T – Trainer.
The Air Force's trainer aircraft are used to train pilots, combat systems officers, and other aircrew in their duties.
TG - Trainer Gliders.
Several gliders are used by the USAF, primarily used for cadet flying training at the U.S. Air Force Academy.
U – Utility.
Utility aircraft are used basically for what they are needed for at the time. For example, a Huey may be used to transport personnel around a large base or launch site, while it can also be used for evacuation. These aircraft are all around use aircraft.
V – VIP staff transport.
These aircraft are used for the transportation of Very Important Persons (VIPs). Notable people include the President, Vice President, Cabinet secretaries, government officials (e.g., senators and representatives), the Joint Chiefs of Staff, and other key personnel.
W – Weather reconnaissance.
These aircraft are used to study meteorological events such as hurricanes and typhoons.
Culture.
The culture of the United States Air Force is primarily driven by pilots and so the pilots of various aircraft types have driven its priorities over the years. At first there was a focus on bombers (driven originally by the Bomber Mafia), followed by a focus on fighters (Fighter Mafia and following).
In response to the 2007 United States Air Force nuclear weapons incident, Secretary of Defense Robert Gates accepted in June 2009 the resignations of Secretary of the Air Force Michael Wynne and the Chief of Staff of the Air Force General T. Michael Moseley. Moseley's successor, General Norton A. Schwartz, a former tactical airlift and special operations pilot was the first officer appointed to that position who did not have a background as a fighter or bomber pilot. The Washington Post reported in 2010 that General Schwartz began to dismantle the rigid class system of the USAF, particularly in the officer corps.
In 2014, following morale and testing/cheating scandals in the Air Force's missile launch officer officer community, Secretary of the Air Force Deborah Lee James admitted that there remained a "systemic problem" in the USAF's management of the nuclear mission.
Daniel L. Magruder, Jr defines USAF culture as a combination of the rigorous application of advanced technology, individualism and progressive airpower theory. Major General Charles J. Dunlap, Jr. adds that the U.S. Air Force's culture also includes an egalitarianism bred from officers perceiving themselves as their service's principal "warriors" working with small groups of enlisted airmen either as the service crew or the onboard crew of their aircraft. Air Force officers have never felt they needed the formal social "distance" from their enlisted force that is common in the other U.S. armed services. Although the paradigm is changing, for most of its history, the Air Force, completely unlike its sister services, has been an organization in which mostly its officers fought, not its enlisted force, the latter being primarily a rear echelon support force. When the enlisted force did go into harm's way, such as members of multi-crewed aircraft, the close comradeship of shared risk in tight quarters created traditions that shaped a somewhat different kind of officer/enlisted relationship than exists elsewhere in the military.
Cultural and career issues in the U.S. Air Force have been cited as one of the reasons for the shortfall in needed UAV operators. In spite of an urgent need for UAVs or drones to provide round the clock coverage for American troops during the Iraq War, the USAF did not establish a new career field for piloting them until the last year of that war and in 2014 changed its RPA training syllabus again, in the face of large aircraft losses in training, and in response to a GAO report critical of handling of drone programs. Paul Scharre has reported that the cultural divide between the USAF and US Army has kept both services from adopting each other's drone handing innovations.
Many of the U.S. Air Force's formal and informal traditions are an amalgamation of those taken from the Royal Air Force (e.g., dining-ins/mess nights) or the experiences of its predecessor organizations such as the U.S. Army Air Service, U.S. Army Air Corps and the U.S. Army Air Forces. Some of these traditions range from "Friday Name Tags" in flying units to an annual "Mustache Month." The use of "challenge coins" is a recent innovation that was adopted from the U.S. Army while another cultural tradition unique to the Air Force is the "roof stomp", practiced by Air Force members to welcome a new commander or to commemorate another event, such as a retirement.
Slogans and creeds.
The United States Air Force has had numerous recruiting slogans including "No One Comes Close" and "Uno Ab Alto" ("One From On High"). For many years, the U.S. Air Force used "Aim High" as its recruiting slogan; more recently, they have used "Cross into the Blue", "We've been waiting for you" and "Do Something Amazing", "Above All", and the newest one, as of 7 October 2010, considered a call and response, "Aim high" followed with the response, "Fly-Fight-Win" Each wing, group, or squadron usually has its own slogan(s). Information and logos can usually be found on the wing, group, or squadron websites.
The Air Force Core Values are: "Integrity first", "Service before self", "Excellence in all we do". The Airman's Creed is a statement introduced in early 2007 to summarize the culture of the Air Force.
To help further knowledge of their mission and functions, the Air Force has also produced videos, such as "Setting the Conditions for Victory" and "How We Fight", to outline the Air Force role in the war on terrorism and how the service succeeds in its domains of air, space, and cyberspace. The Above All campaign continues to support the message of "air, space and cyberspace" dominance.
References.
References to U.S. Army predecessors of today's U.S. Air Force are cited under their respective articles.

</doc>
<doc id="32092" url="http://en.wikipedia.org/wiki?curid=32092" title="Cape Breton University">
Cape Breton University

 
Cape Breton University (CBU), formerly known as the "University College of Cape Breton" (UCCB), is a Canadian university in Nova Scotia's Cape Breton Regional Municipality. Located near Sydney, CBU is the only post-secondary degree-granting institution on Cape Breton Island. The university is enabled by the "Cape Breton University Act" passed by the Nova Scotia House of Assembly. Prior to this, CBU was enabled by the "University College of Cape Breton Act" (amended). The University College of Cape Breton's Coat of Arms were registered with the Canadian Heraldic Authority on May 27, 1995.
CBU is an ordinary (full) member of the Association of Universities and Colleges of Canada (AUCC), the Association of Canadian Community Colleges (ACCC) and Association of Atlantic Universities (AAU), as well as an Associate Member of the Association of Commonwealth Universities (ACU).
History.
CBU traces its roots to 1951 when the St. Francis Xavier University Sydney Campus was opened as a satellite campus of St. Francis Xavier University. Also referred to informally as "St. Francis Xavier Junior College" or "Xavier Junior College" (XJC) and colloquially as "Little X", the St. Francis Xavier University Sydney Campus was situated in Sydney's central business district and saw several buildings opened as a result of growth during its first decade of operation.
While working as librarian at Xavier Junior College, Mother St. Margaret of Scotland (Sister Margaret Beaton) recognized that documents of historical significance to Cape Breton Island were being lost. In 1957 Sister Beaton responded to this challenge and established Cape Bretoniana.
The Nova Scotia Eastern Institute of Technology (NSEIT) opened in 1968 on Grand Lake Road (Trunk 4) several kilometres east of the Sydney city limits. This institution focused on business technology and trades and its development was largely enabled by federal and provincial funding at a time when the coal and steel industries in Industrial Cape Breton were facing serious financial challenges.
In the early 1970s, the provincial and federal governments, as well as the local community, recognized the need for developing an institution of higher learning in the economically challenged Industrial Cape Breton region. With assistance from the Cape Breton Development Corporation, St. Francis Xavier University Sydney Campus and NSEIT were merged into the College of Cape Breton (CCB) in June 1974.
In 1980, the former NSEIT campus on Grand Lake Road was expanded as the institution consolidated at this location. The Government of Nova Scotia granted CCB a charter for granting university degrees in 1982 which saw the institution rename itself as the University College of Cape Breton (UCCB). UCCB united diverse education streams such as the liberal arts and sciences with technological and vocational diploma programs.
In 2004, UCCB undertook several studies on how to better position the institution locally, regionally and nationally. One recommendation arising out of these studies was to rename the institution to remove the reference to "college", in recognition of its transformation over the past two decades into primarily a university level institution. This process led to UCCB transferring its trades and technology programs to the Nova Scotia Community College (NSCC) which operated its "Marconi Campus" (the former NSEIT) which is co-located on the Grand Lake Road campus.
On September 23, 2004 the university's board of governors voted unanimously to rename the institution Breton University, however the proposed name received opposition from a number of groups in the institution and local community over the removal of the word "Cape" from the proposed new name, thus the name Cape Breton University was adopted instead. The name change became official through the "University College of Cape Breton Act (amended)" which received Royal Assent on May 19, 2005.
Library and Archives.
The , housed at CBU, is the second largest public archive in Nova Scotia. The Beaton Institute operates as a regional archive from and about Cape Breton Island's history, society, politics, economy, health, people, places, and events. The collection includes paper records, photographs, film, video, audio materials, books, maps, plans, and microfilms.
CBU's library is located adjacent to the Campus Center, along with the main cafeteria, Art Gallery 1, and Boardmore Theatre. In 2011, CBU's library had renovations completed, removing the clutter on the first floor and creating a new seating area.
Campus.
The original CBU campus structures were built in the 1960s. A major expansion was undertaken for the 1987 Canada Winter Games which saw extensive sports facilities built at the campus. During the 1990s over $20 million were spent on several campus expansions that saw residences, a Culture and Heritage Centre, and various academic and research facilities constructed.<ref name="http://www.cbu.ca/about/fast-facts">http://www.cbu.ca/about/fast-facts</ref> The Culture and Heritage Centre includes the Great Hall, the Art Gallery, the Folklore Department, and the Beaton Institute.
The university continued to expand with major campus additions initiated in 2009. As a collaborative player, CBU became a lead partner in the establishment of the Cape Breton Health Recreation Complex. The $10 million project is a newly opened health and recreation community facility situated on the CBU campus. It provides CBU students and the community with access to a track and field operation and year round indoor soccer facilities as well as a fitness centre.
CBU is growing in terms or residence and enhanced food services through the construction of Harriss Hall, a new student residence and dining hall, in September 2010, giving the campus a total of four residences. Harriss Hall is also the new location for residence mail services, replacing MacDonald, and holds the office of the Residence Life Coordinator. With this new addition, the residence halls now offer meal service and living space for over 550 students. The four residences on campus include Cabot Residence, MacDonald Residence, Harriss Hall, and Alumni Hall. MacDonald offers single and double rooms, Harriss offers single suites, Cabot offers four-bedroom apartments, and Alumni offers five-bedroom apartments along with two-bedroom dorms.
The establishment of the Verschuren Centre for Sustainability in Energy & Environment (CSEE) is a major part of CBU’s commitment to growth in research, specifically in efforts to balance needs for new sources of energy and increasing environmental sustainability. With public and private investment, construction on the CSEE began in 2010. Additionally,in 2012, the new Shannon School of Business building opened and became the new home of the Shannon School of Business faculty and programs.
Academics.
Overview
Cape Breton University serves more than 3,300 full-time and part-time students from local, regional and national locations. CBU is also the academic home of several hundred international students representing more than 50 countries.
Virtually all Cape Breton University degree, diploma and certificate programs offer a transition-to-work component through co-op education, work placements, internships and work-study programs.
Faculties, Programs, & Affiliated Colleges
School of Arts and Social Sciences.
Dean: Dr. Arja Vainio-Matilla
Bachelor of Arts (BA) and Bachelor of Arts Community Studies (BACS) degrees in:
Minor only:
Diplomas:
Certificates:
School of Professional Studies.
Dean: Dr. Jane Lewis (interim)
Undergraduate Degrees: 
Graduate Degrees, Diplomas, and Certificates:
Professional Degrees:
Shannon School of Business.
Dean: Dr. David Rae
Masters of Business Administration in Community Economic Development (MBACED) with specializations in:
Bachelor of Business Administration (BBA) with majors in:
Additional concentrations include:
Certificates:
Bacheor of Hospitality and Tourism Management (BHTM) also affiliated with the School of Business.
School of Science and Technology.
Dean: Dr. David McCorquodale
Bachelor of Science (Bsc) degrees in:
Minor only:
Bachelor of Science Community Studies (BsCS) degrees with concentrations in:
Bachelor of Engineering (BEng) Transfer Degrees (with Dalhousie) include:
Bachelor of Engineering Technology (BET) Degrees in:
Certificates:
Unama'ki College.
Principal: Stephen Augustine, MA
"In 2010, Unama’ki College was founded as an offshoot of the school specializing in Mi’kmaq history, culture and education." As of 2013, "it has some 250 aboriginal students. Its library holds 1,500 books on aboriginal issues and 7,000 documents."
The College includes the following facilities:
The Department of Indigenous Studies offers the following disciplines:
Scholarships & Bursaries.
The Government of Canada sponsors an Aboriginal Bursaries Search Tool that lists over 680 scholarships, bursaries, and other incentives offered by governments, universities, and industry to support Aboriginal post-secondary participation. Cape Breton University scholarships for Aboriginal, First Nations and Métis students include: Earth Tech/CBCL Award – Entrance Award; Verschuren Family Entrance Scholarship; Wood, Walker Foundation Aboriginal Awards Entrance Scholarship; Bank of Montreal Aboriginal Business Administration Student Scholarship 
Research.
CBU is a small comprehensive university that performs over $3 million in externally funded research and employed over 65 students as researchers in 2011. The Office of Research and Graduate Studies publishes two annual research publication titled Research Matters, as well as a separate student Research Matters magazine. Research chairs at CBU include:
Additionally, Dr. Bruce Hatcher is the Research Chair in Marine Ecosystem Management and the Director of the Bras D'Or Institute.
Currently, CBU offers two graduate programs (Master of Business Administration in Community Economic Development and Masters of Education in Information Technology) with two additional graduate programs in development (Social Justice and Heritage Management).
Students' Union.
The Cape Breton University Students' Union provides services such as the Emergency Bursary Fund, funding and management of societies, health and dental plans, Women’s Centre, Pride and Ally Centre, Capers Helping Capers: The Orange Initiative, The Pit (campus bar), Caper Convenience (store), and free legal service. The CBUSU's main focus is advocacy on behalf of its members, and it is also the largest employer of students on the CBU campus.
Newspaper.
The is a newspaper owned collectively by the students of Cape Breton University and published by the Publishing Board of the Caper Times. It prints 2,000 copies on a fortnightly basis and is distributed on campus and to 25 points across the Cape Breton Regional Municipality and southern Victoria County. The newspaper has been autonomous from the Cape Breton University Students' Union since March 1, 2013. It is a member of the Canadian University Press. The newspaper also publishes an electronic monthly newsletter, CampusLink, which is tailored specifically for Cape Breton University students and faculty. The current Chairperson of the Publishing Board is Sarah Hines and the current Editor-in-Chief is Jill Ellsworth.
Athletics.
CBU is represented in the Atlantic University Sport (AUS) association by the Cape Breton University Capers. Men's teams include basketball and soccer, while women's teams include basketball, soccer and volleyball teams. All sports teams wear uniforms with the Caper logo and mascot along with the school color (orange).
Clubs and Societies.
The CBU Students' Union list includes the following societies:
Notable alumni.
Of the over 15,000+ CBU alumni across the world, some prominent grads include:
References.
All facts, unless otherwise stated, are from Cape Breton University's official website.

</doc>
<doc id="32094" url="http://en.wikipedia.org/wiki?curid=32094" title="University of New Brunswick">
University of New Brunswick

The University of New Brunswick (UNB) is a public university with campuses located in Fredericton and Saint John, New Brunswick. It is the oldest English language university in Canada. It is one of four schools that claim the title of oldest public university in North America (the University of Georgia, the University of North Carolina at Chapel Hill, and The College of William and Mary also claim this title). UNB was founded by a group of seven Loyalists who left the United States after the American Revolution.
UNB has two main campuses: the original campus, founded in 1785 in Fredericton, and a smaller campus which opened in Saint John in 1964. In addition, there are two small satellite health sciences campuses located in Moncton and Bathurst, New Brunswick, and two offices in the Caribbean and in Beijing. UNB offers over 75 degrees in fourteen faculties at the undergraduate and graduate levels with a total student enrollment of approximately 11,400 between the two principal campuses. In the fall of 2010, UNB partnered with Dalhousie University and the government of New Brunswick to open the first English-language medical school in the province at the Saint John campus.
History.
Founding and charters.
In 1783, Loyalist settlers began to build upon the ruins of a former Acadian village called Ste-Anne-des-Pays-Bas. The new settlement was named Frederick's Town in honour of Prince Frederick, son of King George III and uncle of Queen Victoria.
Initially modeled on the Anglican ideals of older, European institutions, the University of New Brunswick was founded in 1785 as the Academy of Liberal Arts and Sciences. The petition requesting the establishment of the school, titled "The Founders' Petition of 1785," was addressed to Governor Thomas Carleton and was signed by seven Loyalist men: William Paine, William Wanton, George Sproule, Zephaniah Kingsley, Sr., John Coffin, Ward Chipman, and Adino Paddock.
 To his Excellency Thomas Carleton Esquire Governor Captain General, and Commander in Chief, of the Province of New Brunswick, and the territories thereunto belonging, Vice Admiral Chancellor &c &c &c: —
By an 1800 provincial charter, signed by Jonathan Odell, the Academy of Liberal Arts and Sciences became the College of New Brunswick. The College was succeeded by King's College, which was granted by royal charter in December 1827. King's College operated under the control of the Church of England until 1859, when it was made non-sectarian by an act of the provincial legislature that transformed the College into the University of New Brunswick. In 1866, Mary Kingsley Tibbits became the first regularly admitted female student of UNB.
20th/21st centuries.
In 1906, UNB established a bicameral system of university government consisting of a senate responsible for academic policy, and a board of governors exercising exclusive control over financial policy and other matters. The president, appointed by the board, was to provide a link between the two bodies and to provide institutional leadership. By 1967, the University of New Brunswick had two faculties: Arts and Applied Science. It awarded the degrees of Bachelor of Arts, Bachelor of Science, Master of Arts, and Doctor of Science. The latter was awarded only in the fields of civil engineering, electrical engineering, and forestry. At this time, the university had 156 male students, 21 female students, and only eleven academic staff, who were all male.
In the 1960s, University policies changed in response to social pressure and the belief that higher education was a key to social justice and economic productivity for individuals and for society. In 1964, a second, smaller campus was established in Saint John, New Brunswick. The growth of the UNBSJ campus is particularly notable, for the campus began with only 96 students spread throughout various buildings in Saint John's central business district. In 1968, UNBSJ moved to its new home at Tucker Park.
The Association of University of New Brunswick Teachers (AUNBT) was established in 1954; in 1979, this association became the bargaining agent for all full-time academic staff, and in 2008, it achieved certification for contract academic staff.
Relocation of the Faculty of Law.
In 1959, the Faculty of Law moved from Saint John to Fredericton following a report on the status of legal education in Canada by Professor Maxwell Cohen from McGill University. In his report, Cohen stated that the Saint John Law School was only "nominally a faculty of UNB". This prompted Lord Beaverbrook, as Chancellor, and UNB President Colin B. Mackay, to permanently move the Saint John Law School to the UNB Fredericton campus, despite the Dean's objections.
Polytechnic controversy.
In the fall of 2007, a report commissioned by the provincial government recommended that UNBSJ and the New Brunswick Community College be reformed and consolidated into a new polytechnic post-secondary institute. The proposal immediately came under heavy criticism and led to the several organised protests. Under heavy fire from the public, the Graham government eventually announced that it would set aside the possibility of UNB Saint John losing its status as a university and would refer the report to a working group for further study. The government would go on to announce in January that UNBSJ would retain its liberal arts program and its association with UNB and the working group reported back to government in May, with its findings and government's response being made public in June.
Campuses.
Currently UNBF has approximately 9,000 students while UNBSJ has 3,000, although UNBSJ is growing at a faster rate. Both campuses have undergone significant expansion over the years, and many University buildings have received funding from Lord Beaverbrook and other prominent industrialists and philanthropists. UNB's largest expansion coincided with the baby boom, when its Fredericton campus tripled in size.
Fredericton.
The UNB Fredericton campus is located on a hill overlooking the Saint John River. The campus is well known for its colourful fall foliage, Georgian style red-brick buildings, and a very steep hill. UNB Fredericton has shared the "College Hill" with St. Thomas University (STU) since 1964, when the former St. Thomas College moved from Chatham, NB (now Miramichi). While the universities share some infrastructure, they remain separate institutions.
Architecture.
Architect G. Ernest Fairweather designed several of the campus buildings, including the Old Civil Engineering Building (1900) and the Gymnasium (1906). In addition, several of the stained glass windows in the Convocation Hall were created by Robert McCausland Limited.
UNBF's War Memorial Hall (usually referred to as Memorial Hall), originally built as a science building in 1924, honours the 35 UNB Alumni who died in World War I.
UNBF's Brigadier Milton F. Gregg, V.C., Centre for the Study of War and Society (usually referred to as The Gregg Centre) was created in 2006.
The Richard J. Currie Center, a five-storey 139,000-square-foot building, was constructed in 2013.
National Historic Sites.
Two buildings on the Fredericton campus have been designated National Historic Sites of Canada: the 1827 Sir Howard Douglas Hall (the Old Arts Building), and the 1851 William Brydone Jack Observatory.
Saint John.
The UNB Saint John campus (UNBSJ) is located in Tucker Park in the Millidgeville neighbourhood, several kilometres north of the city's central business district, and offers spectacular views of the Kennebecasis River and Grand Bay. New Brunswick's largest health care facility, Saint John Regional Hospital, is located adjacent to the UNBSJ campus. In 2010, a new medical school, a joint project between Dalhousie University, UNBSJ, and the Regional Hospital, took in its first class.
The Saint John campus has undergone expansion over the years and is the fastest growing component of the UNB system with many new buildings constructed between the 1970s and the first decade of the 21st century. A trend in recent years has been a growth in the number of international students.
Notable differences from its parent campus in Fredericton lay in the campus culture. While UNB Fredericton has a substantial amount of students living in its on-campus residences, this is not the case for UNBSJ. The majority of students do not live within walking distance of the campus due to its remote location, so unlike Fredericton, Saint John is predominantly a "commuter campus".
Architecture.
On April 1, 2010, construction began on the Hans W. Klohn Commons, one of the most environmentally friendly buildings in Atlantic Canada. The building features an electric elevator that produces power for the commons. The building is part of the Tucker Park enhancement project, which will include the refurbishment of the Canada Games Stadium, the new Dalhousie Medicine New Brunswick facility, and the New Brunswick Community College’s Allied Health building.
Sustainability.
The University of New Brunswick has attempted to reduce its environmental impact through installing a natural gas burning microturbine at the Central Heating Plant that produces 100 kW of electricity for the university.
Heat energy, a result of this process, is used to contribute to the overall heating of the campus to increase its overall energy efficiency. In addition, all produce and dairy products used within its dining services are obtained from local farmers and local producers; the campus offers grass-fed beef, fair trade coffee, and dining locations offer biodegradable to-go containers. UNB recycles electronics in addition to traditional materials and operates a move-out materials collection program. The university adheres to a green purchasing policy and has reduced greenhouse gas emissions 26 percent since 1990; they have also decreased water consumption since 2005 through the adoption of new technologies. With these efforts to create a more sustainable campus, the University of New Brunswick received an overall "B+" grade in the 2011 College Sustainability Report Card put out by the Sustainable Endowment’s Institute.
Research and academics.
UNB is the seat of 16 Canada Research Chairs and is home to more than 60 research centers and institutes. It conducts about seventy five percent of all university research in the province. Between 2004 and 2009, the university's research revenue increased by 77 per cent: the highest increase among Canadian comprehensive universities.
Reputation.
In 2013, "Maclean's" magazine ranked UNB 4th nationally in its evaluation of the top fifteen comprehensive universities in Canada. For several years running, UNB's libraries have been ranked in the top spot nationally in terms of the percentage of the overall budget devoted to libraries and in terms of holdings per student.
In 2008, the "National Post" and the "Ottawa Citizen" recognized UNB as being among the top three comprehensive research universities in Canada for the highest percentage growth of research income across a five-year period.
In 2012, UNB's law school was ranked 2nd nationally in elite firm hiring by "Maclean's". According to Canadian Lawyer Magazine, the law school ranks among the top five in Canada.
Poets' Corner.
Because so many of UNB's students, alumni, and professors have produced celebrated poetry, the city of Fredericton has earned the nickname "Poets' Corner." Two of Canada's four Confederation Poets – Sir Charles G.D. Roberts and Bliss Carman – were educated at UNB, as was Francis Joseph Sherman, along with a number of notable 20th- and 21st-century Canadian writers. In 1947, the Historic Sites and Monuments Board of Canada unveiled a "Poet's Corner" monument in honour of Carman, Roberts, and Sherman.
Institute of Biomedical Engineering.
The Institute of Biomedical Engineering (IBME) on the Fredericton campus is one of the leading research institutes in biomedical engineering in Canada. It was founded in 1965 as the Bio-Engineering Institute, making it one of the oldest research institutes to be solely dedicated to the field of biomedical engineering. The institute is also the region's prosthetic fitting centre where amputees are fitted with state-of-the-art intelligent artificial limbs. The institute also carries out research in the field of myoelectric signal processing, biomedical instrumentation and human motion analysis. The IBME also developed the UNB Test of Prosthetic Function which is used by researchers all over the world. Although the institute does not offer degrees in biomedical engineering, students at UNB usually enroll in one of the other faculties of engineering such as electrical or mechanical and pursue their research in biomedical engineering at the IBME.
Canadian Rivers Institute.
The Canadian Rivers Institute was founded in 2000 and is a leading site of river sciences research. The mandate of the CRI is to conduct both multi-disciplinary basic and applied research focusing on rivers from their headwaters to their estuaries, to promote the conservation, protection and sustainable use of water, and to educate professionals, graduate students and the public on water sciences. Members of the CRI conduct research on regional, national and international issues related to rivers and their land-water linkages.
Mi'kmaq-Maliseet Institute.
UNB created its BEd program for First Nations students in 1977 in an effort to help First Nations communities take control of their own schools. In 1981, the Mi'kmaq-Maliseet Institute opened its doors with an expanded mandate to train professionals and improve First Nations access to First Nations education. The Institute provides a variety of services, including research, curriculum development, language education, policy development, children's literacy, and more. In addition, the Institute funds the Mi'kmaq-Maliseet Resource Collection, which contains materials that are immensely valuable to knowledge of First Nations culture, history, and perspective in the region.
Scholarships.
UNB awards over five million dollars in scholarships each year. The most prestigious of these are the Blake-Kirkpatrick, Beaverbrook, and President's scholarships. UNB has a scholarship guarantee in which any admitted student with an average of 80% or higher will receive a guaranteed amount of five hundred dollars.
As a member of the Loran Scholars university consortium, UNB offers a matching tuition waiver as part of a $100,000 undergraduate scholarship to recognize incoming students who demonstrate exemplary character, service and leadership. Five Loran Scholars have studied at UNB over the years. Additionally, it is part of the Schulich Leader Scholarships program, awarding an $80,000 STEM scholarship to an incoming engineering student and a $60,000 scholarship to a science, technology, or mathematics student each year.
Athletics.
UNB Fredericton is represented in Canadian Interuniversity Sport by the UNB Varsity Reds while UNBSJ is represented by the UNBSJ Seawolves. The Varsity Reds compete in the following sports: men's and women's basketball, men's hockey, men's and women's soccer, men's and women's volleyball, and swimming. Men's and women's track & field and cross country have been added as a varsity sport for 2010/2011; this is a joint Fredericton/Saint John Campus program.
In the past, UNBF used different names for each individual sport's team; for instance, the men's swim team was the Beavers, and the hockey team was the Red Devils. The university club teams, which are supported financially by the Student Union as well as by individual members of the teams, do not use the Varsity Reds name and thus continue the tradition of using different nicknames for each sport.
Songs.
Traditional among a number of songs commonly played and sung at various times such as commencement, convocation, and athletic events are: Carmina Universitatis Novi Brunsvici; 'Alma Mater' (1904); and 'UNB Anthem' with words by A.G. Bailey and music by D.V. Start.
Colloquial songs included: "Bombers Away" to celebrate the football team:
Bombers away, my boys
Bombers away,
'Cause when you fight red bombers.
Fight you Bombers, Fight you Bombers,
Fight, Fight, Fight.
Notable alumni.
As of 2012, the University of New Brunswick reports 64,000 living alumni, half of whom live in New Brunswick.
Media.
The university presses, "The Baron" and "The Brunswickan", are members of Canadian University Press. Publishing since 1867, "The Brunswickan" is the oldest official student publication in Canada.
UNB is also home to several notable magazines and journals, such as "The Fiddlehead" and "Studies in Canadian Literature".

</doc>
<doc id="32095" url="http://en.wikipedia.org/wiki?curid=32095" title="University of Sudbury">
University of Sudbury

The University of Sudbury is a Roman Catholic bilingual university in Sudbury, Ontario, Canada which offers courses in French and English. Programs include religious studies, philosophy, Indigenous studies and folklore (entirely in French). It is a federated school of Laurentian University.
The university is a member of L'Association des universités de la francophonie canadienne, a network of academic institutions of the Canadian Francophonie.
History.
The university was founded as the Collège du Sacré-Cœur in 1913 by the Jesuits. Exclusively French after 1916, Sacred Heart College was the centre of education for young Franco-Ontarians for decades since it was the first, and for a long time, the only college in Northern Ontario. In 1957, it changed its name and became the University of Sudbury. In 1960, it formed the Catholic component of Laurentian federation. 
A plaque was erected by Ontario Heritage Foundation, Ministry of Culture, Tourism and Recreation at Notre Dame & Kathleen Streets, Sudbury

</doc>
<doc id="32096" url="http://en.wikipedia.org/wiki?curid=32096" title="University of Prince Edward Island">
University of Prince Edward Island

The University of Prince Edward Island (UPEI) is a public liberal arts university in Charlottetown, Prince Edward Island, Canada, and the sole university in the province. Founded in 1969, the enabling legislation is the "University Act, R.S.P.E.I 2000." 
History.
The university traces its roots back to 1804, when Lt. Governor Edmund Fanning and the Legislative Council of Prince Edward Island called for the establishment of Kent College. By 1820, the first Kent College building, known as "the National School", or James Breading's School was erected. Later succeeded by Central Academy, which received a Royal Charter in 1834. The Colleges were renamed for the Prince of Wales in honour of the future King Edward VII in 1860. The University of Prince Edward Island also traces its roots back to its two earlier predecessor organizations, St. Dunstan's University and Prince of Wales College, founded in 1855 and 1860 respectively. The two institutions were merged in 1969 by the government of Alex Campbell as part of a campaign to integrate the Island's Roman Catholic and Protestant communities, which had previously maintained the two separate institutions of higher learning. Holland College was later created to fill the void left by the merger of Prince of Wales College into the university.
The University of Prince Edward Island is a non-denominational university established in 1969 by the amalgamation of Prince of Wales College (PWC) founded in 1834, and St. Dunstan's University (SDU) founded in 1855. Its predecessor institutions ceased to operate although St. Dunstan's still retains its charter and the lands that were home to Prince of Wales became the campus for Holland College. UPEI is located on the former St. Dunstan's campus.
Legacy.
On 8 May 2004 Canada Post issued 'University of Prince Edward Island, 1804-2004' as part of the Canadian Universities series. The stamp was based on a design by Denis L'Allier and on a photograph by Guy Lavigueur. The 49¢ stamps are perforated 13.5 and were printed by Canadian Bank Note Company, Limited.
Campus.
UPEI's campus, located at the corner of Belvedere and University Avenues in Charlottetown, Prince Edward Island's capital city, is built on 134 acres (54 hectares) of land. The Confederation Trail runs alongside its eastern boundary.
Original SDU buildings in the central quadrangle have been renovated to retain integrity of their exterior aesthetic design while meeting modern standards. Main Building, built in 1854, and Dalton Hall, built between 1917 and 1919, are on the registry of Historic Places of Canada.
The War Memorial Hall (more generally known as Memorial Hall) is a landmark building on the campus of UPEI. Built as a men’s residence building in 1946, Memorial Hall honours alumni who had enlisted and died in the First World War, and in the Second World War.
Over the past three decades, UPEI has experienced significant growth with many new buildings integrated into the campus, including Central Utility Building (1973), Duffy Science Centre, Blanchard Hall (1973), Bernardine Hall, Robertson Library (1975), Atlantic Veterinary College (1986), Chi-Wan Young Sports Centre (1990), Wanda Wyatt Dining Hall (1990), Food Technology Centre, K.C. Irving Chemistry Centre (1997), W.A. Murphy Student Centre (2002), MacLauchlan Arena (2004), Bill and Denise Andrew Hall residence facility (2006), expansions to the Atlantic Veterinary College (2007 and 2009), Regis and Joan Duffy Research Centre (2007), a research and development laboratory which is home to the National Research Council of Canada, Agriculture and Agri-Food Canada, and other partners, and Don and Marion McDougall Hall (2008). The most recent addition is the Health Sciences Building, home to the School of Nursing and Applied Human Sciences programs.
In October 2004, the UPEI administration undertook an official campus plan to improve the aesthetics of modern buildings constructed since the amalgamation which do not enhance the original SDU design, and to take overall campus aesthetics into account for future developments on and adjacent to the campus.
Organization.
The current President is Dr. Alaa Abd-El-Aziz, installed July 1, 2011. The current chancellor is William E. (Bill) Andrew.
Academics.
UPEI offers undergraduate, graduate, and professional programs in four faculties — Arts, Science, Education, and Veterinary Medicine — and two schools — Business and Nursing. Bachelor's degree programs, in many cases including "honours" options, are available in Arts, Science, Business Administration, Education, and Nursing. Co-op programs have been established in Business Administration, Computer Science, Physics, and Dietetics. One new faculty, Veterinary Medicine, and two schools, Business Administration and Nursing, were added as the university expanded.
Master's and Doctoral degree programs were first introduced through the Atlantic Veterinary College and, beginning in 1999, a Master of Science degree was offered through the Faculty of Science. In that same year the first students were admitted to the university's new Master of Education program. As of 2010, in addition to the MEd graduate program, the Faculty of Education offered a PhD in Educational Studies. The university also now offers an MA in Island Studies. Recently the School of Business Administration began offering a Master of Business Administration degree. Since 1998, The Centre for Conflict Resolution Studies has been offering courses leading to a Certificate in Conflict Resolution Studies. The Master of Applied Health Services Research (MAHSR) program is coordinated by the Atlantic Research Training Centre (ARTC).
The Faculty of Education offers two-year post-degree bachelor degrees with specializations in international and Aboriginal education, French immersion and human resources development, as well as a Master of Education (MEd) in leadership in learning.
The Department of Applied Human Sciences has an accredited dietitian program. The university is accredited by a professional organization such as the Dietitians of Canada and the university's graduates may subsequently become registered dieticians.
Rankings.
In Macleans 21st Annual University Ranking (2011-2012), UPEI was ranked in 5th place among all Canadian universities for offering primarily undergraduate education.
Research.
UPEI manages over $18 million in annual research expenditures. The on-campus biosciences and health research facility is used by researchers from UPEI, National Research Council (Canada), and Agriculture and Agri-Foods Canada.
UPEI houses the L.M. Montgomery Institute, founded in 1993, which promotes scholarly inquiry into the life, works, culture, and influence of the Canadian writer, L.M. Montgomery. The collection of novels, manuscripts, texts, letters, photographs, sound recordings and artifacts and other Montgomery ephemera.
Student life.
Athletics.
The UPEI Panthers have nine teams playing in the Atlantic University Sport (AUS) and the Canadian Interuniversity Sport (CIS), including men's and women's ice hockey, soccer, basketball, as well as women's field hockey and rugby union and co-ed swimming.
The UPEI campus provides its students with many athletics amenities typically found on university campuses. The is a public recreation facility located on the campus and includes two hockey rinks (the MacLauchlan Arena as well as a practice rink) as well as two 25-metre swimming pools (a shallow recreational wading pool, and an eight-lane competitive pool with diving boards). In 2009 UPEI inaugurated the UPEI Alumni Canada Games Place which was built in part to host the 2009 Canada Games. It consists of a "class 2" eight-lane 400-metre running track and rugby field that has spectator seating for 1,335.
Residence.
UPEI accommodates 434 students in three residences, Bill and Denise Andrew Hall, Blanchard Hall, and Bernardine Hall. Bill and Denise Andrew Hall has two-room suites with single bedrooms. In Blanchard Hall, each suite has two single bedrooms with a kitchenette and a living room. Bernardine Hall (known as "Bernie" to the students) offers suites with two double bedrooms. Although the hall is co-ed, one floor is female-only.

</doc>
<doc id="32097" url="http://en.wikipedia.org/wiki?curid=32097" title="University of Utah">
University of Utah

The University of Utah (also referred to as the U, the U of U, or Utah) is a public coeducational space-grant research university in Salt Lake City, Utah, United States. As the state's flagship university, the university offers more than 100 undergraduate majors and more than 92 graduate degree programs. Graduate studies include the S.J. Quinney College of Law and the School of Medicine, Utah's only medical school. As of Autumn 2012, there are 24,840 undergraduate students and 7,548 graduate students, for an enrollment total of 32,388; with 83% coming from Utah and 9% coming from foreign countries. Just over 10% of students live on campus.
The university's athletic teams, the Utes, participate in NCAA Division I athletics (FBS for football) as a member of the Pacific-12 Conference. Its football team has received national attention in recent years for winning the 2005 Fiesta Bowl and the 2009 Sugar Bowl.
The university was established in 1850 as the University of Deseret () by the General Assembly of the provisional State of Deseret, making it Utah's oldest institution of higher education. It received its current name in 1892, four years before Utah attained statehood, and moved to its current location in 1900.
History.
A Board of Regents was organized by Brigham Young to establish a university in the Salt Lake Valley. The university was established on February 28, 1850, as the "University of Deseret" by the General Assembly of the provisional State of Deseret, and Orson Spencer was appointed as the first chancellor of the university. Early classes were held in private homes or wherever space could be found. The university closed in 1853 due to lack of funds and lack of feeder schools.
Following years of intermittent classes in the Salt Lake City Council House, the university began to be re-established in 1867 under the direction of David O. Calder, who was followed by John R. Park in 1869. The university moved out of the council house into the Union Academy building in 1876 and into Union Square in 1884. In 1892, the school's name was changed to the University of Utah, and John R. Park began arranging to obtain land belonging to the U.S. Army's Fort Douglas on the east bench of the Salt Lake Valley, where the university moved permanently in 1900. Additional Fort Douglas land has been granted to the university over the years, and the fort was officially closed on October 26, 1991. Upon his death in 1900, Dr. John R. Park bequeathed his entire fortune to the university.
The university grew rapidly in the early 20th century but was involved in an academic freedom controversy in 1915 when Joseph T. Kingsbury recommended that five faculty members be dismissed after a graduation speaker made a speech critical of Utah governor William Spry. One third of the faculty resigned in protest of these dismissals. Some felt that the dismissals were a result of the LDS Church's influence on the university, while others felt that they reflected a more general pattern of repressing religious and political expression that might be deemed offensive. The controversy was largely resolved when Kingsbury resigned in 1916, but university operations were again interrupted by World War I, and later The Great Depression and World War II. Student enrollment dropped to a low of 3,418 during the last year of World War II, but A. Ray Olpin made substantial additions to campus following the war, and enrollment reached 12,000 by the time he retired in 1964. Growth continued throughout the following decades as the university developed into a center for computer, medical, and other research.
During the 2002 Winter Olympics, the university hosted the Olympic Village, a housing complex for the Olympic and Paralympic athletes, as well as the opening and closing ceremonies. Prior to the events, the university received a facelift that included extensive renovations to the Rice–Eccles Stadium, a light rail track leading to downtown Salt Lake City, a new student center known as the Heritage Center, an array of new student housing, and what is now a 180-room campus hotel and conference center.
Campus.
Campus takes up 1534 acre, including the Health Sciences complex, Research Park, and Fort Douglas. It is located on the east bench of the Salt Lake Valley, close to the Wasatch Range and approximately 2 miles east of downtown Salt Lake City.
Most courses take place on the west side of campus, known as lower campus due to its lower elevation. Presidents Circle is a loop of buildings named after past university presidents with a courtyard in the center. Major libraries on lower campus include the J. Willard Marriott Library and the S.J. Quinney Law Library. The primary student activity center is the A. Ray Olpin University Union, and campus fitness centers include the Health, Physical Education, and Recreation Complex (HPER) and the Nielsen Fieldhouse.
Lower campus is also home to most public venues, such as the Rice–Eccles Stadium, the Jon M. Huntsman Center, and the Utah Museum of Fine Arts, a museum with rotating exhibitions and a permanent collection of American, European, African, and Asian art. Venues for performing arts include Kingsbury Hall, used for touring companies and concerts, Pioneer Memorial Theatre, used by the professional Pioneer Theatre Company, David P. Gardner Hall, used by the School of Music and for musical performances, and the Marriott Center for Dance. Red Butte Garden, with formal gardens and natural areas, as well as the new site of the Utah Museum of Natural History, is located on the far east side of campus.
The health sciences complex, at the northeast end of campus, includes the University of Utah Medical Center, Primary Children's Medical Center, the Huntsman Cancer Institute, the Moran Eye Center, and the Spencer Eccles Health Sciences Library. South of the health sciences complex, several university residence halls and apartments are clustered together near Fort Douglas and the Heritage Center, which serves as a student center and cafeteria for this area. In addition, there are 1,115 university apartments for students, staff, and faculty across three apartment complexes on campus. At the southeast end of campus is Research Park, which is home to research companies including ARUP Laboratories, Evans & Sutherland, Sarcos, Idaho Technology, and Myriad Genetics.
Courses are also held at off-campus centers located in Bountiful, Murray, Park City, downtown Salt Lake City, and Sandy.
Student housing.
The University of Utah provides student housing in a 32-building housing complex on campus. The complex consists of seven housing areas: Chapel Glen, Gateway Heights, Sage Point, Officer's Circle, Benchmark Plaza, Shoreline Ridge, and the Donna Garff Marriott Honors Residential Scholars Community. The Donna Garff Marriott Honors Residential Scholars Community, a dormitory for honors students, was completed in fall 2012.
Transportation.
A number of campus shuttles, running on biodiesel and used vegetable oil, circle the campus on six different routes. The Utah Transit Authority (UTA) runs several buses through the university area as well as the TRAX Red Line (light rail), which runs to South Jordan. Riders can travel downtown, to "FrontRunner" (commuter rail), to West Valley, to the Salt Lake City International Airport, or to Sandy by transferring to the TRAX Green or Blue lines. Students and staff can use their university IDs to ride UTA buses, TRAX, and "FrontRunner".
The University has recently unveiled a new plan for a friendlier campus for bicyclers called the "Bicycle Master Plan" which aims to transform the campus into a safer and more accessible place for bicyclers and to promote the increase of bicycle ridership. The plan emphasizes both campus pathways and on-street facilities that connect the core campus area with surrounding neighborhoods. The Bicycle Master Plan gives guidelines for facilities and programs that are within the University's jurisdiction. It also provides recommendations for the University to work with external entities such as UDOT, UTA, and Salt Lake City to improve bicycling conditions in locations that are important to the campus environment, but which are not under the University's direct control.
Sustainability.
The university is ranked 3rd by the EPA for annual green power usage among universities, with 31% of its power coming from wind and solar sources. Other sustainability efforts include a permanent sustainability office, a campus cogeneration plant, building upgrades and energy efficient building standards, behavior modification programs, purchasing local produce, and student groups including a bicycle collective. Sustainability and transportation are also a large part of the university's campus master plan. The Sustainable Endowments Institute gave the university a "B+" in its College Sustainability Report Card 2011, with A's for climate change and energy, food and recycling, student involvement, and transportation.
The expanded recycling program launched on July 1, 2007. Since its launch, the program has continued to grow and refine its procedures to better accommodate a growing campus' needs. Currently there are programs in place for paper, cardboard, aluminum, batteries, printer cartridges, wooden pallets and plastics #1 and #2.
Renewable energy.
On July 7, 2011 the university unveiled its plans to be the first location in the United States to install solar ivy. Unlike rooftop panels, solar ivy panels are small and shaped like ivy so that they can be installed in an attractive arrangement that will scale walls, much like ivy growing over a building's surface. These panels were designed by Sustainably Minded Interactive Technology of New York.
A renewable energy partnership was entered into by the university, Rocky Mountain Power and 3Degrees on September 28, 2011 allowing the purchase of renewable wind power that in its first year will produce 98,233,000 kilowatt-hours of wind energy, which is 36% of the university's total power usage, with plans for an additional two-year renewable energy commitment. The university's first-year renewable energy purchase through Blue Sky and 3Degrees has the combined environmental benefit of taking more than 13,200 cars off the road for one year or planting 1.7 million trees. The university's support for renewable energy is made possible through a student fee-funded sustainability program established in 2005.
The university unveiled the addition of a new solar array system on April 16, 2012 on the rooftop of the Natural History Museum of Utah. This is the second system installed on the university's campus, the other being at the HPER East building. The Natural History Museum of Utah's system is a 330-kilowatt system, while the HPER East system is a 263-kilowatt system. The combined arrays consist of 2,470 Sharp photovoltaic panels covering 40,000 square feet of rooftop space and together they will annually produce 802,240 kilowatt hours
Organization.
The university is part of the Utah System of Higher Education. As of 2009, the university's endowment is US$668 million. The colleges at the university are:
In addition to the departments in these colleges, there are a number of interdisciplinary academic programs.
Academics.
The university offers 72 undergraduate majors, more than 70 minors and certificates, more than 40 teaching majors and minors, and 95 major fields of study at the graduate level. Students at the undergraduate level can also create an individualized major under the direction of the Bachelor of University Studies program and the supervision of a tenure-track faculty member. The university has three semesters a year: spring, summer, and fall. Undergraduate tuition and fees for 2015–2016 were US$8,240 for Utah residents (about 325% the cost of tuition and fees in 2000, $2,534 for 13 credit hours per semester, 2 semesters), and $26,180 for non-residents per 12-credit-hour semester.
The university is classified as a research university with very high research activity by the Carnegie Foundation, with research and training awards for 2010-2011 amounting to US$410,563,908. The university's research expenditures were the 67th highest in the nation in the Center for Measuring University Performance's 2008 report. Additionally, the university was the 58th highest for federal research expenditures, 52nd for National Academy of Sciences membership, 50th for faculty awards, 51st for doctorates awarded, and 42nd for postdoctoral appointees.
Admissions and demographics.
In 2007–2008, the university accepted 94% and admitted 80% of its 16,200 domestic undergraduate applicants; accepted 94% and admitted 66% of its 1,017 international undergraduate applicants; accepted 80% and admitted 44% of its 6,773 domestic graduate applicants; and accepted 70% and admitted 38% of its 1,992 international graduate applicants.
Of admitted freshmen, the average GPA was 3.4 and the average ACT score was 23.5. The university uses an admissions index number that gives equal weight to GPA and ACT/SAT scores. If a freshman applicant's index number is at or above the current cutoff, they are guaranteed admission, assuming the student has or will graduate from an accredited high school, has satisfactorily completed all course requirements, has a cumulative high school GPA of at least 2.6, and has an ACT score of at least 18 or SAT score of at least 860. Special requirements apply to non-accredited high schools.
In 2010, the undergraduate and graduate student body was 30,819, with 23,371 undergraduate students and 7,448 graduate students. 71% of students were full-time, 56% were male and 44% female, 84% were Utah residents, and 6% were foreign students. The student body was 77% white, 6% non-resident alien, 5% Asian, Native Hawaiian, or Pacific Islander, 5% Hispanic, 1% black, and 1% Native American. Ethnicity or citizenship was unknown for 6% of the student body. The university was ranked 20th by The Princeton Review for having the most religious students in the nation in 2009.
Notable programs.
The University of Utah has the only accredited architecture program in Utah, as well as the only medical school. The medical school has made several notable contributions to medicine, such as establishing the first Cerebrovascular Disease Unit west of the Mississippi River in 1970 and administering the world's first permanent artificial heart, the Jarvik-7, to Barney Clark in 1982.
The university has made unique contributions to the study of genetics due in part to long-term genealogy efforts of the LDS Church, which has allowed researchers to trace genetic disorders through several generations. The relative homogeneity of Utah's population also makes it an ideal laboratory for studies of population genetics. The university is home to the Genetic Science Learning Center, a resource which educates the public about genetics through its website.
In March 2012, the university received unanimous approval from the board of trustees to create a new academic college, the College of Dentistry, which is the university's first new college in sixty years. The new college has received funding for a new structure and has started as a debt-free program. The new school will start enrolling students for the fall semester of 2013 and is expected to average the same cost as the university's medical school tuition.
The University of Utah was one of the original four nodes of ARPANET, the world's first packet-switching computer network and embryo of the current worldwide Internet. Notable innovations of engineering faculty and alumni include the first method for representing surface textures in graphical images, the Gouraud shading model, magnetic ink printing technology, the Johnson counter logic circuit, the oldest algebraic mathematics package still in use (REDUCE), the Phong reflection model, the Phong shading method, and the rendering equation. The school has pioneered work in asynchronous circuits, computer animation, computer art, digital music recording, graphical user interfaces, and stack machine architectures. The School of Computing also takes part in the Scientific Computing and Imaging Institute, which continues to make advances in visualization, scientific computing, and image analysis.
The S.J. Quinney College of Law, founded in 1913, was the only law school in Utah until the 1970s.
In August 2012, the University of Utah announced plans to close its Center for American Indian Languages, which has been home to linguists such as Lyle Campbell and Wick Miller. "The College of Humanities instead will concentrate language-preservation efforts on Utah's tribal tongues," according to one article. This closure, said to be for purposes focusing efforts on the language of Utah tribes, "has shocked many in the language conservation world. Linguists, including Ives Goddard of the Smithsonian have expressed serious concern about the negative impact on efforts to preserve indigenous languages throughout the Americas.
The University of Utah College of Pharmacy is 4th in the nation for NIH research grants. The department of Pharmacology and Toxicology within the School of Pharmacy is world renowned for research in epilepsy treatment with their Anticonvulsant Drug Development (ADD) program.
The university is host to the Neal A. Maxwell Lecture Series in Political Theory and Contemporary Politics, a forum for political theorists to share their newest theoretical work.
Athletics.
The university has 7 men's and 11 women's varsity teams. Athletic teams include men's baseball, basketball, football, golf, skiing, swimming/diving, and tennis and women's basketball, cross country, gymnastics, skiing, soccer, softball, swimming/diving, tennis, track and field, and volleyball. The school's sports teams are called the Utes, though some teams have an additional nickname, such as "Runnin' Utes" for the men's basketball team. The university participates in the NCAA's Division I (FBS for football) as part of the Pac-12 Conference. There is a fierce Utah–BYU rivalry, and the Utah–BYU football game, traditionally a season finale, has been called the "Holy War" by national broadcasting commentators. The university fight song is "Utah Man", commonly played at athletic games and other university events. In 1996, Swoop was introduced as the new mascot of the University of Utah. Because of relationships with the local Ute Indians, Utah adopted a new mascot. While still known as the Utes, Utah is now represented by the Red-tailed Hawk known for the use of his tail feathers in Ute head-dresses, and said he "Reflects the soaring spirit of our state and school"
In 2002, the university was one of 20 schools to make the "U.S. News & World Report" College Sports Honor Roll. In 2005, Utah became the first school to produce No. 1 overall draft picks in both the NFL draft and NBA draft for the same year. Alex Smith was picked first overall by the San Francisco 49ers in the 2005 NFL Draft, and Andrew Bogut was picked first overall by the Milwaukee Bucks in the 2005 NBA Draft. The university has won ten NCAA Skiing Championships, most recently in 2003, as well as the 1977 AIAW National Women's Skiing Championship.
Men's basketball.
The men's basketball team won the NCAA title in 1944 and the NIT crown in 1947. Arnie Ferrin, the only four-time All-American in Utah basketball history, played for both the 1944 and 1947 teams. He also went on to help the Minneapolis Lakers win NBA Championships in 1949 and 1951. Wat Misaka, the first person of Asian descent to play in the NBA, also played for Utah during this era.
Utah basketball rose again to national prominence when head coach Rick Majerus took his team, including guard Andre Miller, combo forward Hanno Möttölä, and post player Michael Doleac, to the NCAA Final Four in 1998. After eliminating North Carolina to advance to the final round, Utah lost the championship game to Kentucky, 78–69.
Football.
In 2004–2005, the football team, coached by Urban Meyer and quarterbacked by Alex Smith, along with defensive great Eric Weddle, went 11–0 during the regular season and defeated Pittsburgh 35–7 in the 2005 Fiesta Bowl, becoming the first team from a conference without an automatic Bowl Championship Series (BCS) bid to go to a BCS bowl game. The team ended its perfect 12–0 season ranked 4th in AP polling.
2008–2009 was another undefeated year for the football team, coached by Kyle Whittingham, as they finished the season 13–0 and defeated Alabama 31–17 in the 2009 Sugar Bowl. Utah finished the season 2nd in AP polling, their highest rank ever. At the end of the season, the Utes were the only unbeaten team in the country, with the nation's longest active streak of bowl victories (8).
The Utah Utes moved to the Pac-12 Conference for the start of the 2011–2012 football season. They are in the South Division with University of Colorado, University of Arizona, Arizona State University, UCLA and University of Southern California. Their first game in the Pac-12 was at USC on September 10, 2011, and resulted in a 23–14 Utah loss.
Gymnastics.
The women's gymnastics team, coached by Greg Marsden, the Red Rocks, has won ten national championships, including the 1981 AIAW championship, and placed 2nd nationally eight times. As of 2013, it has qualified for the NCAA championship every year since 1976, the only program to do so. The program has averaged over 11,000 fans per meet 1992–2010 and has been the NCAA gymnastics season attendance champions 16 of these 19 years. In 2010, there was an average of 14,213 fans per meet, the largest crowd being 15,030.
Marching band.
The university marching band, known as the "Pride of Utah", perform at all home football games, as well as some away games and bowl games. They performed at the 2005 BCS Tostitos Fiesta Bowl, the 2009 BCS Allstate Sugar Bowl, and the Inaugural Parade of President Barack Obama.
The band began as a military band in the 1940s. In 1948, university president A. Ray Olpin recruited Ron Gregory from Ohio State University to form a collegiate marching band. Support for the band dwindled in the 60s, and ASUU (the Associated Students of the University of Utah) discontinued its funding in 1969. The band was revived in 1976 after a fund raising effort. under the direction of Gregg I. Hanson As of 2011, the band is under the direction of Dr. Brian Sproul.
Men's rugby club.
In the year of 2012, Utah's men's rugby club got suspended for unspecified alcohol 'incident' for the 2012–2013 rugby year.
Student life.
A large portion of university students live off-campus, as the university is located in a large metropolitan area and has beds for less than 10% of its undergraduate population in residence halls and single student apartments. An additional 1,115 family apartments are available to students, staff, and faculty. One of the university's primary four goals for long-term campus growth is to increase student engagement through the addition of on-campus housing, intramural fields, athletic centers, and a new student activity center.
The current student activity center, the A. Ray Olpin University Union, is a common gathering place for university-wide events such as Crimson Nights, roughly monthly student activity nights; PlazaFest, a fair for campus groups at the start of the school year; and the Grand Kerfuffle, a concert at the end of the school year. The building includes a cafeteria, computer lab, recreational facilities, and a ballroom for special events. The Union also houses the Lowell Bennion Community Service Center and ASUU (the Associated Students of the University of Utah), which is responsible for appropriating funds to student groups and organizations on campus. ASUU holds primary and general elections each year for student representatives, typically with 10–15% of the student population voting.
Due to the large number of LDS Church members at the university, there is an LDS Institute of Religion building near main campus, as well as several LDS student groups and 46 campus wards. Approximately 650 students are part of 6 sororities and 8 fraternities at the university, most of which have chapter houses on "Greek Row" just off campus.
The University of Utah has a dry campus, meaning that alcohol is banned on campus. In 2004, Utah became the first state with a law expressly permitting concealed weapons on public university campuses. The University of Utah tried to uphold its gun ban but the Utah Supreme Court rejected the ban in 2006.
Media.
The university has several public broadcasting affiliations, many of which utilize the Eccles Broadcast Center. These stations include KUED channel 7, a PBS member station and producer of local documentaries; KUEN channel 9, an educational station for teachers and students from the Utah Education Network; KUER 90.1 FM, a public radio affiliate of National Public Radio, American Public Media, and Public Radio International; and K-UTE 1620
"NewsBreak" is the student-run television newscast on campus. During 2011, the program celebrated its 40th anniversary. Broadcasts air every Thursday night at 10 pm during the fall and spring semesters on KUEN.
"The Daily Utah Chronicle", also referred to as the "Chrony", has been the university's independent, student-run paper since 1890. It publishes daily on school days during fall and spring semesters and weekly during summer semester. The paper typically runs between eight and twelve pages, with longer editions for weekend game guides. The paper converted to a broadsheet format in 2003 when the Newspaper Agency Corporation began printing it. The Society of Professional Journalists selected the newspaper as one of three finalists for best all-around daily student newspaper in the nation in both 2007 and 2008. Staff from the "Chronicle" feed into Utah journalism circles, some of them rising to considerable prominence, such as former editor Matt Canham, whose work with "The Salt Lake Tribune" earned him the Don Baker Investigative Reporting Award from the Utah Chapter of the Society of Professional Journalists.
The University of Utah Press, the oldest press in Utah and now part of the J. Willard Marriott Library, publishes books on topics including the outdoors, anthropology and archaeology, linguistics, creative nonfiction, Mesoamerica, Native American studies, and Utah, Mormon, and Western history. The university is also home to a national literary journal, "Quarterly West".
Notable alumni and faculty.
Notable alumni include politicians Rocky Anderson, Bob Bennett, E. Jake Garn, Jon Huntsman, Jr., Karen Morgan, Frank E. Moss, and Karl Rove; recent LDS Church presidents Gordon B. Hinckley and Thomas S. Monson; authors Orson Scott Card, Stephen Covey, and Wallace Stegner; R Adams Cowley, William DeVries, Russell M. Nelson, and Robert Jarvik in medicine; historian Richard Foltz; educators Gordon Gee and Ann Weaver Hart; reporter Martha Raddatz; historian Laurel Thatcher Ulrich; and speed reading innovator Evelyn Nielsen Wood.
Notable science and engineering alumni include Jim Blinn; Jim Clark, founder of Silicon Graphics, Netscape Communications Corporation, myCFO, and Healtheon; Henri Gouraud; John C. Cook who played a crucial role in establishing the field of ground-penetrating radar; Ralph Hartley; Alan Kay; Simon Ramo; and John Warnock, co-founder of Adobe Systems. 
Notable entrepreneur and business leader alumni include Alan Ashton, co-founder of WordPerfect and Thanksgiving Point; Nolan Bushnell, founder of Atari and Chuck E. Cheese; Ed Catmull, co-founder of Pixar; J. Willard Marriott, founder of Marriott International; Robert A. "Bob" McDonald, CEO of Procter & Gamble; and David Neeleman, founder of JetBlue.
In athletics, notable alumni include baseball player Chris Shelton; basketball players Andrew Bogut, Andre Miller and Keith Van Horn; football players Jamal Anderson, Kevin Dyson, Alex Smith, and Steve Smith; and football coach LaVell Edwards.
Notable faculty in science and engineering include David Evans and Ivan Sutherland, founders of Evans and Sutherland; Henry Eyring, known for studying chemical reaction rates; Stephen Jacobsen, founder of Sarcos; Jindřich Kopeček and Sung Wan Kim, pioneers of polymeric drug delivery and gene delivery; Suhas Patil, founder of Cirrus Logic; Stanley Pons, who claimed to have discovered "cold fusion" in 1989; Venkatraman Ramakrishnan, later co-winner of the 2009 Nobel Prize in Chemistry; and Thomas Stockham, founder of Soundstream. In medicine, notable faculty include Mario Capecchi, the co-winner of the 2007 Nobel Prize in Physiology or Medicine; Willem Johan Kolff; and Russell M. Nelson. Biologist Ralph Vary Chamberlin, founding dean of the Medical School, professor, and later historian of the University, was also an alumnus. 

</doc>
<doc id="32098" url="http://en.wikipedia.org/wiki?curid=32098" title="University of Victoria">
University of Victoria

The University of Victoria (UVic or Victoria) is a public research university in Victoria, British Columbia, Canada, located in Saanich and Oak Bay within Greater Victoria, 5.71 km northeast of downtown Victoria, British Columbia. It was founded as Victoria College in 1903 and affiliated with McGill University, which is also credited with the beginnings of the University of British Columbia. A non-denominational institution, it transitioned to its current status as the University of Victoria in 1963. The university's annual enrollment is about 20,000 students. UVic's campus is known for its innovative architecture, beautiful gardens and mild climate.
Academically, the University of Victoria is noted for its programs in Earth and Ocean Sciences, Fine and Performing Arts, Engineering, and Law along with a strong focus on co-operative education. It is the nation's lead institution in the VENUS and NEPTUNE deep-water seafloor observatory projects.
The Victoria Vikes (more commonly known as the "UVic Vikes" or simply the "Vikes") represent the university in the Canadian Interuniversity Sport (CIS) community in a number of competitive sports, as well as through a variety of intercollegiate leagues. The Vikes have especially long and eminent ties to competitive rowing and basketball.
Victoria ranks well in global rankings. In 2014-2015, Times Higher Education World University Rankings ranked UVic 173 in the world, and at seventh place in Canada. It ranked first in Canada in the Times Higher Education’s ranking of schools under 50 years old. UVic was the top-ranked university in Canada without an autonomous medical school in the THE rankings. The university has also been home to more than 40 faculty members who are Fellows of the Royal Society of Canada since it was founded.
History.
The University of Victoria was established on 1 July 1963 in Victoria, British Columbia. Victoria College, which had been established in 1903 as an affiliated college of McGill University, gained autonomy and full degree granting status on March 1, 1963. The non-denominational university had enjoyed 60 years of prior teaching tradition at the university level as Victoria College. This 60 years of history may be viewed conveniently in three distinct stages.
Between the years 1903 and 1915, Victoria College was affiliated with McGill University, offering first- and second-year McGill courses in Arts and Science. Administered locally by the Victoria School Board, the College was an adjunct to Victoria High School and shared its facilities. Both institutions were under the direction of a single Principal: E.B. Paul, 1903–1908; and S.J. Willis, 1908–1915.
The opening in 1915 of the University of British Columbia, established by Act of Legislature in 1908, obliged the college to suspend operations in higher education in Victoria.
University of British Columbia was created in 1908. A single, public provincial university, it was modeled on the American state university, with an emphasis on extension work and applied research. The governance was modeled on the provincial University of Toronto Act of 1906 which established a bicameral system of university government consisting of a senate (faculty), responsible for academic policy, and a board of governors (citizens) exercising exclusive control over financial policy and having formal authority in all other matters. The president, appointed by the board, was to provide a link between the two bodies and to perform institutional leadership.
In 1920, as a result of local demands, Victoria College began the second stage of its development, reborn in affiliation with the University of British Columbia.
Though still administered by the Victoria School Board, the college was now completely separated from Victoria High School, moving in 1921 into the magnificent Dunsmuir mansion known as Craigdarroch Castle. Over the next two decades, under Principals E.B. Paul and P.H. Elliott, Victoria College built a reputation for thorough and scholarly instruction in first- and second-year arts and science. It was also during this period that future author Pierre Berton edited and served as principal cartoonist for the student newsletter, "The Microscope".
Between the years 1921-1944, the enrolment at Victoria College did not very often reach above 250. However, in 1945, 128 servicemen returned from Wold War II. This pushed enrolment up to 400, and in 1946; 600.
The final stage, between the years 1945 and 1963, saw the transition from two year college to university, under Principals J.M. Ewing and W.H. Hickman.
During this period, the college was governed by the Victoria College Council, representative of the parent University of British Columbia, the Greater Victoria School Board, and the provincial Department of Education. Physical changes were many. In 1946 the college was forced by postwar enrollment to move from Craigdarroch to the Lansdowne campus of the Provincial Normal School, the current location of Camosun College's Lansdowne Campus. The Normal School, itself an institution with a long and honourable history, joined Victoria College in 1956 as its Faculty of Education. Late in this transitional period (through the co-operation of the Department of National Defence and the Hudson's Bay Company) the 284 acre (1,1 km²) now 385 acre (1.6 km²) campus at Gordon Head was acquired. Academic expansion was rapid after 1956, until in 1961 the college, still in affiliation with UBC awarded its first bachelor's degrees.
In the early part of this century, professional education expanded beyond the traditional fields of theology, law and medicine. Graduate training based on the German-inspired American model of specialized course work and the completion of a research thesis was introduced.
The policy of university education initiated in the 1960s responded to population pressure and the belief that higher education was a key to social justice and economic productivity for individuals and for society.
The university gained its autonomy in 1963 as the University of Victoria. The University Act of 1963 vested administrative authority in a chancellor elected by the convocation of the university, a board of governors, and a president appointed by the board; academic authority was given to the senate which was representative both of the faculties and of the convocation.
University of Victoria's Arms were registered with the Canadian Heraldic Authority on April 3, 2001. The historical traditions of the university are reflected in the coat of arms, its academic regalia and its house flag. The BA hood is of solid red, a colour that recalls the early affiliation with McGill, as do the martlets in the coat of arms. The BSc hood, of gold, and the BEd hood, of blue, show the colours of the University of British Columbia. Blue and gold have been retained as the official colours of the University of Victoria. The motto at the top of the Arms of the University, in Hebrew characters, is "Let there be Light"; the motto at the bottom, in Latin, is "A Multitude of the Wise is the Health of the World."
Campus and grounds.
The main campus is located in the Gordon Head area of Greater Victoria. With a total area of 403 acre, the campus spans the border between the municipalities of Oak Bay and Saanich. The original campus plan was prepared by the San Francisco architecture and planning firm of Wurster, Bernardi & Emmons. The general concept of the original design is still being followed, with the academic portions of the campus located inside Ring Road, which forms a perfect circle 600 m in diameter. Outside of Ring Road are the parking lots, the Student Union Building, residence buildings, sports facilities, as well as some of the academic facilities that are more self-contained (Law and Theatre for example).
The following is a list of the more prominent buildings on campus:
The university also offers on-campus housing for over 3,200 students. An extensive variety of housing is available, including single and double dormitories, Cluster Housing (apartment-style housing with four people per unit), bachelor and one-bedroom apartments, and family housing. Four buildings in one of the oldest residential complexes at the university are named for Emily Carr, Arthur Currie, Margaret Newton, and David Thompson. Construction on the South Tower Complex was completed in January 2011. The largest residence building in terms of capacity is Ring Road Hall, which holds 294 beds and is split into three wings. The campus has also become increasingly cycling-friendly.
Much of the university estate has been dedicated to nature, notably Finnerty Gardens and Mystic Vale, a 4.4 ha forested ravine. The campus is home to deer, owls, squirrels and many other wild animals native to the area. A large population of domestic rabbits, which likely descended from abandoned house pets from the surrounding community, was a memorable feature of the campus in years past. In May 2010, the university began trapping and euthanizing the rabbits as they had been known to put athletes at risk in the playing fields and cause extensive damage to university grounds. It has been documented that local veterinarians have offered to perform neutering of the male rabbits. As of July 2011, the UVic campus is free of rabbits. 900 rabbits were saved and sent to shelters.
Undergraduate Faculties, Departments, and Schools.
Below is a list of undergraduate faculties, departments, and schools within the University of Victoria system.
UVic also offers a number of interdisciplinary undergraduate programs, including Applied Ethics, Arts of Canada, European Studies, Film Studies, Human Dimensions of Climate Change, Indigenous Studies, Latin American Studies, Social Justice Studies, and Technology and Society.
Peter B. Gustavson School of Business.
The Peter B. Gustavson School of Business, formerly the Faculty of Business, was renamed following a donation by local entrepreneur Peter B. Gustavson. This business school is one of the finest in Canada with a wide range of programs including the BCom, MBA and other business degrees, EQUIS and AACSB accredited.
School of Earth & Ocean Sciences.
The university's School of Earth & Ocean Sciences is the premiere underwater and marine institution in Canada and has produced a large number of influential findings in its history. The School of Earth & Ocean Science also collaborate with the VENUS and NEPTUNE research institutes. In addition to this, the university was a founding member of the Western Canadian Universities Marine Sciences Society; UVic maintains this field station on the west coast of Vancouver Island, which is jointly run by the University of British Columbia, Simon Fraser University, the University of Alberta and the University of Calgary.
School of Public Administration.
The UVic School of Public Administration is Western Canada's leading government management school. The school specializes in its M.A., and PhD. programs but also offers a selective admission minors program. The innovative course structure of these programs has led numerous graduates to pursue careers in finance management, government administration, and local governance.
Law.
The UVic Faculty of Law is consistently ranked highly by the media. It offers a co-op work experience program and an environmental law intensive program, featuring a course at Hakia Beach, BC in association with the Tula Foundation. UVic Law has been deeply involved with many of the Aboriginal, Ecological, and Environmental cases within British Columbia and continues this tradition today.
Engineering.
The Faculty of Engineering admits approximately 400 students into first-year programs each year. Students can specialize in the following disciplines: Biomedical Engineering, Civil Engineering, Computer Engineering, Computer Science, Electrical Engineering, Mechanical Engineering, and Software Engineering.
Faculty of Humanities.
 consists of ten departments (English, French, Germanic and Slavic Studies, Greek and Roman Studies, Hispanic and Italian Studies, History, Linguistics, Pacific and Asian Studies, Philosophy, and Women's Studies), as well as three Programs (Latin American Studies, Medieval Studies, and Religious Studies). The faculty offers certificates, minors, and majors leading to both BA and BSc degrees, as well as MA and PhD degrees. As one of the largest faculties at the University of Victoria, the faculty prides itself on offering outstanding opportunities to study and expand expressions of the human spirit. Languages, narratives, philosophies, histories—the Faculty of Humanities brings these all together in a critical context of analysis, interpretation, research, and communication. Humanities students ask—and answer!—questions about the place and value of the individual in the human community, the function of tradition in times of intense transformation, and how best to give guidance to humanity as it moves into an ever uncertain future.
Graduate Programs.
UVic offers a number of graduate degrees in the following areas:
Academic profile.
Libraries and Museum system.
The University of Victoria Libraries system is the second largest in British Columbia being composed of three 'on-campus' libraries, the William C. Mearns Center for Learning/McPherson Library, the Diana M. Priestly Law Library, and the MacLaurin Curriculum Library. The Library System has undergone significant growth in recent years thanks to the University's investment in library purchases and research. Amongst the highlights in the University of Victoria Archives and Special Collections are priceless items from Imperial Japan, to carbon dated original manuscripts of the Sancti Epiphanii. The collection also boasts extensive histories of colonial Victoria and the Colony of Vancouver Island among other documents. The library's digitization programme is becoming increasingly active in making materials available for scholars and to the wider world. Renovations and new construction over the past decade have resulted in modernized facilities that include special collections classrooms, an innovative Learning Commons and an art gallery. The UVic libraries collection includes extensive digital resources, over 2.0 million books, 2.3 million items in microforms, plus serial subscriptions, sound recordings, music scores, films and videos, and archival materials.
The University of Victoria houses the Education Heritage Museum, which displays educational history artifacts in the main hallway of the MacLaurin building. The collection consists of manuscripts, texts, photographs, audio-visual material, lesson plans, posters, bells, ink bottles, fountain pens, desks, maps, athletic clothing, photographs, and school yearbooks used in kindergarten to grade 12 schools in Canada from the mid-1800s to the 1980s.
The University of Victoria has two art collections (University and Maltwood) which host loan exhibitions, and exhibits of the works of students and faculty in the University Centre Exhibition Gallery. The University Collection, founded in 1953 by Dr. W.H. Hickman, Principal of Victoria College (1953-1963), consists of 6,000 works, mainly by contemporary artists practicing in British Columbia. The Maltwood Art Museum and Gallery, founded through the bequest of English sculptress and antiquarian, Katharine Emma Maltwood, F.R.S.A. (1878-1961), reflects her and her husband John Maltwood's taste. The collection of 12,000 works of fine, decorative and applied arts includes Oriental ceramics, costumes, rugs, seventeenth century English furniture, Canadian paintings and Katherine Maltwood's own sculptures.
Research.
In the 2010 "Re$earch Infosource" ranking of Canada's research universities, UVic topped all other comprehensive universities in Canada in two out of three measures of research performance over the last decade: growth in research income and growth in research intensity.
The University maintains a field station on the west coast of Vancouver Island to conduct marine research. The facility is jointly run by the University of British Columbia, Simon Fraser University, the University of Alberta and the University of Calgary. Undergraduates at the University of Victoria have full access to research and learning at this facility.
In 2011 the university, in collaboration with the provincial government purchased and modified a state of the art ocean vessel capable of launching 'deep sea submersibles' and conducting long range marine biology research expeditions. The 'floating laboratory' is undergoing upgrades and expansions currently and will be in service by late 2011.
The School of Earth & Ocean Sciences is also home to the renowned VENUS and NEPTUNE research institutes responsible for seismic, oceanic and climate change research.
Located in the Greater Victoria area the University's legal centre provides free legal assistance to the disadvantaged as well as dealing with important environmental cases in British Columbia. The UVic Law Center is the only full-time, term clinical program offered by a Canadian law school. The program reflects the faculty's emphasis on integrating legal theory, legal skills, and community service while providing students with unique education and research opportunities.
Located in the Greater Victoria, British Columbia area the Vancouver Island Technology Park is a state of the art, 35 acre commercial research facility. It is the largest university-owned technology centre in BC. The venture allows the university to work with leading technology and biomedical companies while provided students with unparalleled research opportunities. The facility focuses on fuel cell, new media, wireless, and life science/biotechnological research. The UVic Genome BC Proteomics Centre and a number of other research institutes are based out of the research park. The Capital Regional District is a major commercial hub for technology companies.
Admissions.
Admission to the University of Victoria is based on a selective academic system. UVic requires all applicants to submit gross percentage averages to be considered for admission. The University accepts qualified applicants studying under IB programs, AP programs or other international distinctions. The University of Victoria offers scholarships and financial aid to a large number of students.
International exchanges.
The University Of Victoria has partnered with a number of research institutions to provide UVic students with the opportunity to gain research experience abroad. Both UVic undergraduate and graduate students may travel abroad with UVic's many partner universities. This international exchange programs develops the collegial yet international atmosphere at the University of Victoria, and promotes an exchange of information.
Rankings.
"Maclean's Magazine", a major Canadian news magazine, has ranked UVic as one of the top three comprehensive universities in the nation for three consecutive years; it was ranked first for the year . Its Faculty of Law has also ranked first in the country, 8 out of the last 11 years. Currently, it is ranked 4th by "Canadian Lawyer Magazine". University of Victoria's MBA program is consistently ranked among the top 10 of its kind in the nation. UVic is British Columbia's second largest research university, after UBC, and is one of Canada's top 20 research institutions. According to ScienceWatch, UVic is nationally ranked first in geoscience, second in space science and education, and third in engineering and mathematics for the period of 2000–2004. For the year 2013, five departments are ranked in the top 200 in the QS world rankings, with one department (Department of English) ranked in the top 100: Earth and Marine Science, English Literature, Law, Geography, and Philosophy.
Culture and student life.
"The Martlet" student newspaper.
UVic's oldest and most recognized weekly student newspaper, founded in 1948, is "The Martlet". It is distributed all over campus and the Greater Victoria area. The paper is named after the legendary martlet bird, whose inability to land is often seen to symbolize the constant quest for knowledge, learning, and adventure. "The Martlet" is partly funded by student fees.
The University of Victoria Students Society (UVSS).
The University of Victoria Students' Society is a student society which represents the UVic undergraduate student body, plans campus wide events and maintains the Student Union Building. The student society's leadership is elected annually during campus wide undergraduate student elections. As a multi-million dollar organization, the UVSS is among one of the larger student unions which exist in Canada.
The University of Victoria Graduate Student Society (GSS).
The GSS offers services and support for UVic's 3,000 Graduate students. The society's services include the Grad House Restaurant, health and dental plan, funding for grad student events, and reduced-cost membership in the Victoria Car Share Co-operative.
Radio station CFUV.
CFUV is on-campus radio station focusing on the campus and the surrounding community. CFUV serves Greater Victoria at 101.9, and via cable on 104.3, Vancouver Island and many areas in the Lower Mainland and northwestern Washington state.
Greek Life.
The University of Victoria Students' Society does not recognize fraternities or sororities on the basis that they, by definition, seek to exclude portions of the membership.
The university's students have started an unofficial fraternity and two sororities and one non-exclusive, non-profit social-service club. It should be noted that the university students society itself does not recognize the fraternity or the sororities as affiliated with the campus. Although the fraternity and sororities have no affiliation with the University of Victoria itself, they continue to exist with membership growing yearly. The unofficial fraternities and sororities on campus are as follows:
Athletics.
The university is represented by its team the Victoria Vikes, more commonly known as the "UVic Vikes" or simply the "Vikes". Vikes teams participate in the Canada West Universities Athletic Association (CWUAA) (the western division of Canadian Interuniversity Sport [CIS]) and in the National Association of Intercollegiate Athletics (NAIA). Basketball games are played in the 2,500 seat, McKinnon Gymasium. The facility was built in 1975.
The university currently has both men's and women's teams in each of the following sports:
Sports Hall of Fame.
UVic Charter Inductees are:
Canadian Inter-University Sports(CIS) Championships
Men's basketball: 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1997
Women's basketball: 1980, 1981, 1982, 1985, 1987, 1992, 1998, 2000, 2003
Men's cross-country: 1995, 1996, 1997, 1998
Women's cross-country: 1981, 1986, 1987, 1988, 1995, 1999, 2000, 2001, 2002
Women's field hockey: 1985, 1988, 1990, 1992, 1993, 1995, 1996, 1998, 2001, 2003, 2008
Men's soccer: 1976, 1988, 1997, 2004, 2011
Women's soccer: 2005
Canadian University Championship Titles
Men's rugby: 1998, 1999
Men's rowing: 1997, 1998, 1999, 2001, 2009
Women's rowing: 1997, 1998, 1999, 2000, 2001, 2002, 2003
Men's golf: 2003
Traditions.
Fight Song.
Notable among a number of songs commonly played and sung at various events such as commencement and convocation, and athletic games is 'Rack and Ruin' a reminder of the tradition of the founding Victoria College.
"Rack and Ruin,
Blood and Gore,
Victoria College
Evermore!"
Martlet icon.
The martlet and its red colour adorns many parts of the University of Victoria, including the crest, coat of arms, and flag representing the university's previous affiliation to McGill University which also uses the martlet. The legendary martlet bird's inability to land is often seen to symbolize the constant quest for knowledge, learning, and adventure. The oldest student newspaper on campus, "The Martlet", is named after the bird.
UVic Orientation.
UVic Orientation takes place each year for all new students to the school. UVic Orientation includes events, activities, and workshops to help students adjust to university life. The main event of UVic Orientation, which takes place on the day immediately preceding the first day of classes, has gone by a number of names over the years. This event is currently referred to as New Student Welcome, and is UVic's largest Orientation event.
Sport clubs.
UVic has 25 sport clubs that are administered by Vikes Recreation and run by students.
People.
Notable faculty.
Some of the university's noted faculty members, past and present, are:
Notable alumni.
The university has over 88,000 alumni. Listed below are some of UVic's noted alumni:
Asteroid 150145 Uvic.
The asteroid 150145 Uvic was named in the university's honour on 1 June 2007. UVic was the first university in BC to have an asteroid named for it.

</doc>
<doc id="32099" url="http://en.wikipedia.org/wiki?curid=32099" title="University of Manitoba">
University of Manitoba

The University of Manitoba (U of M) is a public university in the province of Manitoba, Canada. Located in Winnipeg, it is a research-intensive post-secondary educational institution. Founded in 1877, it was Western Canada’s first university.
Location.
The University of Manitoba has three main locations: the Bannatyne Campus, the Fort Garry Campus and the William Norrie Centre.
The downtown Bannatyne campus of the university comprises a complex of ten buildings located west of the Health Sciences Centre between McDermot Ave and William Ave in Central Winnipeg. This complex houses the medical and dental instructional units of the university. The Faculty of Dentistry, the Faculty of Medicine, the School of Medical Rehabilitation, and the School of Dental Hygiene are the major health sciences units located on this campus. The Faculty of Pharmacy officially joined the Bannatyne campus with the opening of the 95000 sqft Apotex Centre on October 16, 2008. The Brodie Center is known as the "flagship" which connects all three faculties as well as the Neil John MacLean Health Sciences Library and the Joe Doupe Fitness Centre. It is located on 727 McDermot Avenue.
The main Fort Garry campus (located on the Red River in south Winnipeg) comprises over 60 teaching and research buildings of the University and sits on 233 ha of land. In addition, Smartpark is the location of seven buildings leased to research and development organizations involving university-industry partnerships. The address is 66 Chancellors Circle.
The William Norrie Centre on Selkirk Avenue is the campus for social work education for inner-city residents.
The university operates agricultural research stations near Glenlea and Carman, Manitoba. The Ian N. Morrison Research Farm near Carman is a 406 acre facility located 70 km from Winnipeg, while the Glenlea facility is approximately 1000 acres and located 20 km from Winnipeg.
Aboriginal.
The University of Manitoba provides services to urban Aboriginal people. The University of Manitoba Native Studies summer course brings first-year Aboriginal students to campus before the start of the school year for some campus orientation. Aboriginal Elders are present on campus at University of Manitoba to provide social supports. Tutoring services are available within the University of Manitoba’s Medicine, Engineering and Social Work ACCESS Programs. The university reaches into Aboriginal communities to talk to potential students at a much younger age through Curry Biz Camp, which fosters entrepreneurship among young First Nations and Métis students.
History.
Early History.
The University of Manitoba is a non-denominational university, founded by Alexander Morris, that received a charter on February 28, 1877. It officially opened on June 20, 1877 to confer degrees on students graduating from its three founding colleges: St. Boniface College (Roman Catholic/Francophone), St John's College (Anglican) and Manitoba College (Presbyterian). The University of Manitoba granted its first degrees in 1880. The University was the first to be established in western Canada. Alan Beddoe designed the university coats of arms.
The university has added a number of colleges to its corporate and associative body. In 1882 the Manitoba Medical College, which had been founded by some physicians and surgeons, became a part of the University. Charles Henry Wheeler (architect) designed the Bacteriological Research Building (1897), part of the Manitoba Medical College. George Creeford Browne (architect) designed the Science Building, 1899-1900.
Other colleges followed:
In 1901 the Legislative Assembly of Manitoba changed the University Act so that the university could do its own teaching, and in 1905 a building in downtown Winnipeg became its first teaching facility with a staff of six science professors. The governance was modelled on the provincial University of Toronto Act of 1906 which established a bicameral system of university government consisting of a senate (faculty), responsible for academic policy, and a board of governors (citizens) exercising exclusive control over financial policy and having formal authority in all other matters. The president, appointed by the board, was to provide a link between the two bodies and to perform institutional leadership.
In the early part of the 20th century, professional education expanded beyond the traditional fields of theology, law and medicine. Graduate training based on the German-inspired American model of specialized course work and the completion of a research thesis was introduced.
The Manitoba Medical Alumni Association erected the Medical Corps Memorial, which is dedicated to the memory of the graduates and students of the University of Manitoba Medical College, who laid down their lives during the North West Rebellion (1 name); 1900 South African War (1 name) and 1914 - 1918 The Great War (7 names).
The first school of architecture in western Canada was founded in 1919 at the University of Manitoba.
By 1920, the university was the largest university in the Canadian Prairies and the fifth largest in Canada. It had eight faculties: Arts, Science, Law, Medicine, Engineering, Architecture, Pharmacy, and Agriculture. It awarded the degrees of Bachelor of Arts (BA), Bachelor of Science (BSc), Bachelor of Civil Engineering (BCE), Bachelor of Electrical Engineering (BEE), Bachelor of Mechanical Engineering (BME), Bachelor of Architecture (BArch), Bachelor of Pharmacy (PhmB), Bachelor of Science in Agriculture (BSA), Bachelor of Laws (LLB), Master of Arts (MA), Master of Civil Engineering (MCE), Master of Electrical Engineering (MEE), Doctor of Medicine (MD), and Doctor of Laws (LLD). It had 1,654 male students and 359 female students, and 184 academic staff, including 6 women.
The Faculty of Law was an affiliated college, the Manitoba Law School, which was founded jointly by the university and the Law Society of Manitoba in 1914. In 1920 it had 123 students, including 5 women, and 21 academic staff. It became a full part of the university in 1966.
The university was originally located on Broadway. In 1929, following the addition of more programs, schools, and faculties, the university moved to its permanent site in Fort Garry, Manitoba. The university maintained the Broadway facilities for many years.
The university established an Evening institute in 1936.
St. Andrew's College, which originally trained the ministry for the Ukrainian Orthodox Church of Canada, became an affiliated College in 1981. St. Andrew's College was the first Ukrainian-language college opened by the Orthodox Church in North America. It is home to a large Ukrainian cultural and religious library.
The policy of university education initiated in the 1960s responded to population pressure. In 1967, two of the colleges that had been part of the University of Manitoba were given university status by the provincial government. United College, which had been formed by the merging of Wesley College and Manitoba College, became the University of Winnipeg, and Brandon College became Brandon University.
St. Boniface College and St. John's College, two of the founding colleges of the University, are still part of the University of Manitoba. St. Boniface College is the University's only French language college; it offers instruction in French and facilities for the training of teachers who expect to teach in the French language. St. John's College, which dates back to 1820, offers instruction in Arts and Science and, among other special programs, prepares men and women for the ordained ministry of the Anglican Church.
The University Today.
Thirty-three of the buildings on the Fort Garry campus of the University of Manitoba are used for teaching. Four of these are colleges: St. John's College, St. Paul's College, St. Andrew's College, and University College. The remaining buildings contain laboratories, administrative and service offices, residences, or are the property of research agencies.
The university has an enrolment of approximately 27,000 students - 24,000 undergraduate and 3,000 graduate. The university offers more than 90 degrees, more than 60 at the undergraduate level. Most academic units offer graduate studies programs leading to master’s or doctoral degrees.
In 2007-08, the university acquired more than $150 million in research income. The university holds 48 Canada Research Chairs and is either home to or a partner in 37 research centres, institutes and shared facilities. These centres foster collaborative research and scholarship.
The University of Manitoba is the network leader of ISIS Canada (Intelligent Sensing for Innovative Structures), headquartered in the Faculty of Engineering. ISIS Canada is a National Network of Centres of Excellence (NCE) developing better ways to build, repair and monitor civil structures. The university is a member of 13 other NCEs.
The Centre for Defence and Security Studies at the University of Manitoba has a research, teaching and outreach program designed to advance knowledge, understanding and debate in Canada on defence and security issues. 
Legacy.
On 28 February 2002, Canada Post issued 'University of Manitoba, 1877-2002' as part of the Canadian Universities series. The stamp was based on a design by Steven Slipp, based on photographs by Mike Grandmaison and on an illustration by Bonnie Ross. The 48¢ stamps are perforated 13.5 and were printed by Ashton-Potter Canada Limited.
Academics.
The university has a total enrolment of approximately 26,000 students in 22 faculties. Most academic units offer graduate studies programs leading to master’s or doctoral degrees. In 2014, the University of Manitoba overtook the University of Sherbrooke to be rated second last overall in the Macleans Rankings of Canadian Medical Doctoral Schools.
The colleges are:
The university's faculties:
Museums, libraries and archives.
The Anthropology Laboratory Museum at UofM collects, inventories and displays artifacts including cartographic materials, prints, drawings, and textual records from the Manitoba Region. The Human History collection includes archaeological and ceremonial objects, and weapons. The Natural Sciences artifacts include biological, zooarchaeological, aquatic, Earth Science, Geological and Paleontological Collections.
The university has 19 libraries and one archive:
Human resources.
The academic staff are represented by two unions. The professors are represented by the University of Manitoba Faculty Association, while sessional instructors and teaching assistants are represented by the CUPE Local 3909. Professors at the Faculty of Dentistry are represented by the University of Manitoba Dental Clinical Staff Association.
The support staff are divided among many unions. The support staff and the campus security are represented by the AESES, though the support staff at the Faculty of the Engineering are represented by CUPE Local 1482. All of the outside workers are represented by the CAW Local 3007.
Notable alumni.
Rhodes Scholars.
As of 2010, there have been 96 Rhodes Scholars from the University of Manitoba, more than from any other university in Western Canada.
Athletics.
The university is represented in Canadian Interuniversity Sport by the Manitoba Bisons.
Athletic facilities located on campus include the Max Bell Centre, the Investor's Group Athletic Centre, and Investor's Group Field, which opened in 2013 to replace University Stadium.
Recreation.
The University of Manitoba offers recreational programs year-round, including a swimming program, adult classes and summer programs for children. The university's Frank Kennedy Centre, Max Bell Centre, and Investor's Group Athletic Centre contain indoor tracks, a swimming pool, work-out facilities, and an international ice hockey rink, as well as basketball, volleyball, squash and raquetball courts. Frank Kennedy Centre also hosts dance, combat and gymnastics rooms, and indoor tennis courts.
The main art gallery on campus is "School of Art Gallery".
Student life.
Student Representation.
The students at the university are members of the University of Manitoba Students' Union (UMSU). UMSU represents students at the Board of Governors and Senate, as well as providing programs and support to students.
Greek Organizations.
The National Panhellenic Conference sororities on campus are Alpha Delta Pi, Alpha Gamma Delta, and Alpha Phi. Fraternities on campus include Delta Upsilon, Delta Kappa Epsilon, and Phi Delta Theta. Fraternity Rush and Sorority Recruitment occur during the first weeks of school in September.

</doc>
<doc id="32100" url="http://en.wikipedia.org/wiki?curid=32100" title="Urban exploration">
Urban exploration

Urban exploration (often shortened as urbex or UE) is the exploration of man-made structures, usually abandoned ruins or not usually seen components of the man-made environment. Photography and historical interest/documentation are heavily featured in the hobby and, although it may sometimes involve trespassing onto private property, this is not always the case. Urban exploration is also commonly referred to as infiltration, although some people consider infiltration to be more closely associated with the exploration of active or inhabited sites. It may also be referred to as draining (when exploring drains), urban spelunking, urban rock climbing, urban caving, or building hacking.
The nature of this activity presents various risks, including both physical danger and the possibility of arrest and punishment. Some activities associated with urban exploration may violate local or regional laws and certain broadly interpreted anti-terrorism laws or be considered trespassing or invasion of privacy.
Exploration sites.
Abandonments.
Ventures into abandoned structures are perhaps the most common example of urban exploration. At times, sites are entered first by locals and may suffer from large amounts of graffiti and other acts of vandalism. Although targets of exploration vary from one country to another, high-profile abandonments include amusement parks, grain elevators, factories, power plants, missile silos, fallout shelters, hospitals, asylums, schools, poor houses, and sanatoriums.
In Japan, ruins are known as haikyo (廃虚)
 (literally "abandoned place"), but the term is synonymous with the practice of urban exploration. Haikyo 
 are particularly common in Japan because of its rapid industrialization (e.g., Hashima Island), damage during World War II, the 1980s real estate bubble, and the 2011 Tōhoku earthquake and tsunami.
Many explorers find decay of uninhabited space to be profoundly beautiful, and some are also proficient freelance photographers who document what they see, as is the case with those who document some of the infrastructure of the former USSR.
Abandoned sites are also popular among historians, preservationists, architects, archaeologists, industrial archaeologists, and ghost hunters.
Active buildings.
Another aspect of urban exploration is the practice of exploring active or "in use" buildings which includes gaining access to secured or "member-only" areas, mechanical rooms, roofs, elevator rooms, abandoned floors and other normally unseen parts of working buildings. The term "infiltration" is often associated with the exploration of active structures. People entering restricted areas may be committing trespass and civil prosecution may result.
Catacombs.
Catacombs such as those found in Paris, Rome, Odessa and Naples have been investigated by urban explorers. The Mines of Paris, comprising much of the underground tunnels that are not open to public tourism like the catacombs, have been considered the "Holy Grail" by some due to their extensive nature and history. Explorers of these are known as cataphiles.
Sewers and storm drains.
Entry into storm drains, or "draining", is another common form of urban exploration. Groups devoted to the task have arisen, such as the Cave Clan in Australia. Draining has a specialized set of guidelines, the foremost of which is "When it rains, no drains!" The dangers of becoming entrapped, washed away, or killed increase dramatically during a heavy rainfall.
A small subset of explorers enter sanitary sewers. Sometimes they are the only connection to caves or other subterranean features. Sewers are among the most dangerous locations to explore owing to risk of poisoning by buildups of toxic gas (commonly methane and hydrogen sulfide). There have been numerous fatalities around the world where people are overcome by toxic gas from sewers.
Transit tunnels.
Exploring active and abandoned subway and underground railway tunnels, bores and stations is often considered to be trespassing and can result in civil prosecution. As a result, this type of exploration is rarely publicized. One important exception to this is the abandoned subway of Rochester, New York, the only American city to have an abandoned, formerly used, subway system. (The Cincinnati subway is also abandoned, but was never completed.)
Utility tunnels.
Universities, and other large institutions such as hospitals, often distribute hazardous superheated steam for heating or cooling buildings from a central heating plant. These pipes are generally run through utility tunnels, which are often intended to be accessible solely for the purposes of maintenance. Nevertheless, many of these steam tunnels, especially those on college campuses, often also have a tradition of exploration by students. This practice was once called "vadding" at the Massachusetts Institute of Technology, though students there now refer to it as roof and tunnel hacking.
Some steam tunnels have dirt floors, poor lighting and temperatures upwards of 45 C. Others have concrete floors, bright light, and more moderate temperatures. Most steam tunnels have large intake fans to bring in fresh air and push the hot air out the back, and these fans may start without warning. Most active steam tunnels do not contain airborne asbestos, but proper breathing protection may be required for other respiratory hazards. Experienced explorers are very cautious inside active utility tunnels, since pipes can spew boiling hot water or steam from leaky valves or pressure relief blowoffs. Frequently there are puddles of muddy water on the floor, making slips and falls a special concern near hot pipes.
Steam tunnels have generally been secured more heavily in recent years, due to their frequent use for carrying communications network backbone cables, increased safety and liability concerns, and perceived risk of their use in terrorist activities.
Popularity.
The rise in the popularity of urban exploration can be attributed to its increased media attention. Recent television shows, such as "Urban Explorers" on the Discovery Channel, "MTV's Fear", and the "Ghost Hunting" exploits of The Atlantic Paranormal Society have packaged the hobby for a popular audience. The fictional film "After..." (2006), a hallucinatory thriller set in Moscow's underground subways, features urban explorers caught up in extreme situations. Talks and exhibits on urban exploration have appeared at the fifth and sixth Hackers on Planet Earth Conference, complementing numerous newspaper articles and interviews.
Another source of popular information is "Cities of the Underworld", a documentary series which ran for three seasons on the History Channel, starting in 2007. This series roamed around the world, showing little-known underground structures in remote locales, as well as right under the feet of densely packed city-dwellers.
With the rise in the relative popularity of the hobby due to this increased focus, there has been increasing discussion on whether the extra attention has been beneficial to urban exploration as a whole. The unspoken rule of urban exploring is "take nothing but photographs, leave nothing but footprints", but because of the rising popularity, many individuals who may have other intentions are creating a concern among many property owners.
Philosophical and psychological aspects.
Several writers on urbex have discussed the personal meaning of such acts of "infiltration" — or "invasions". Simon Cornwell, in his discussions of the Cane Hill Cult (in Croydon, South London), has emphasized the element of danger in recording the experiences — physically, emotionally and photographically. This element of danger serves to heighten the existential anxiety of exploration.
Safety and legality.
Urban exploration is a hobby that comes with a number of inherent dangers. For example, storm drains are not designed with human access as their primary use. They can be subject to flash flooding and bad air. There have been a number of deaths in storm water drains, but these are usually during floods, and the victims are normally not urban explorers.
Many old abandoned structures feature hazards such as unstable structures, unsafe floors, broken glass, the presence of unknown chemicals and other harmful substances (most notably asbestos), stray voltage, and entrapment hazards. Other risks include freely roaming guard dogs and hostile squatters. Some abandoned locations may be heavily guarded with motion detectors and active security patrols. Others are more easily accessible and carry less risk of discovery.
Asbestos is a long-term health risk for urban explorers, along with breathing in contaminants from dried bird feces, which can cause a condition known as pigeon-breeder's lung, a form of hypersensitivity pneumonitis. Urban explorers may use dust masks and respirators to alleviate this danger. Some sites are occasionally used by substance abusers for either recreation or waste disposal, and there may be used or infected syringe needles en route, such as those commonly used with heroin.
The growing popularity of the activity has resulted not just in increased attention from explorers, but also from vandals and law enforcement. The illicit aspects of urban exploring, which may include trespassing and breaking and entering, have brought along with them critical articles in mainstream newspapers.
In Australia, the website of the Sydney Cave Clan was shut down by lawyers for the Roads and Traffic Authority of New South Wales, after they raised concerns that the portal could "risk human safety and threaten the security of its infrastructure". Another website belonging to the Bangor Explorers Guild was criticized by the Maine State Police for potentially encouraging behavior that "could get someone hurt or killed." Likewise, the Toronto Transit Commission has also used the Internet to crimp subway tunnel explorations, going as far as to send investigators to various explorers' homes.
Jeff Chapman, who authored "Infiltration", stated that genuine urban explorers "never vandalize, steal or damage anything". The thrill comes from that of "discovery and a few nice pictures". Some explorers will also request permission for entry in advance.
Photographic documentation.
Many urban explorers adhere to the philosophy of cave explorers and outdoors hikers: "Take nothing but pictures. Leave nothing but footprints." Some are photographers who specialize in documenting urban ruins and scenes of industrial decay. Professional photographers working in this field include Seph Lawless, Julia Solis, Andrew L. Moore, and Brandon P. Davis, Other well-known photographers, such as Jan Saudek, use the interiors of abandoned buildings as backdrops for their figurative and portrait works.
In popular culture.
Urban exploration is featured in a number of works, in a variety of media, such as:

</doc>
<doc id="32101" url="http://en.wikipedia.org/wiki?curid=32101" title="Umbriel (moon)">
Umbriel (moon)

Umbriel is a moon of Uranus discovered on October 24, 1851, by William Lassell. It was discovered at the same time as Ariel and named after a character in Alexander Pope's poem "The Rape of the Lock". Umbriel consists mainly of ice with a substantial fraction of rock, and may be differentiated into a rocky core and an icy mantle. The surface is the darkest among Uranian moons, and appears to have been shaped primarily by impacts. However, the presence of canyons suggests early endogenic processes, and the moon may have undergone an early endogenically driven resurfacing event that obliterated its older surface.
Covered by numerous impact craters reaching 210 km in diameter, Umbriel is the second most heavily cratered satellite of Uranus after Oberon. The most prominent surface feature is a ring of bright material on the floor of Wunda crater. This moon, like all moons of Uranus, probably formed from an accretion disk that surrounded the planet just after its formation. The Uranian system has been studied up close only once, by the spacecraft "Voyager 2" in January 1986. It took several images of Umbriel, which allowed mapping of about 40% of the moon’s surface.
Discovery and name.
Umbriel, along with another Uranian satellite, Ariel, was discovered by William Lassell on October 24, 1851. Although William Herschel, the discoverer of Titania and Oberon, claimed at the end of the 18th century that he had observed four additional moons of Uranus, his observations were not confirmed and those four objects are now thought to be spurious.
All of Uranus's moons are named after characters created by William Shakespeare or Alexander Pope. The names of all four satellites of Uranus then known were suggested by John Herschel in 1852 at the request of Lassell. Umbriel is the 'dusky melancholy sprite' in Alexander Pope's "The Rape of the Lock", and the name suggests the Latin "umbra", meaning "shadow". The moon is also designated Uranus II.
Orbit.
Umbriel orbits Uranus at the distance of about 266000 km, being the third farthest from the planet among its five major moons. Umbriel's orbit has a small eccentricity and is inclined very little relative to the equator of Uranus. Its orbital period is around 4.1 Earth days, coincident with its rotational period. In other words, Umbriel is a synchronous or tidally locked satellite, with one face always pointing toward its parent planet. Umbriel's orbit lies completely inside the Uranian magnetosphere. This is important, because the trailing hemispheres of airless satellites orbiting inside a magnetosphere (like Umbriel) are struck by magnetospheric plasma, which co-rotates with the planet. This bombardment may lead to the darkening of the trailing hemispheres, which is actually observed for all Uranian moons except Oberon (see below). Umbriel also serves as a sink of the magnetospheric charged particles, which creates a pronounced dip in energetic particle count near the moon's orbit as observed by "Voyager 2" in 1986.
Because Uranus orbits the Sun almost on its side, and its moons orbit in the planet's equatorial plane, they (including Umbriel) are subject to an extreme seasonal cycle. Both northern and southern poles spend 42 years in complete darkness, and another 42 years in continuous sunlight, with the Sun rising close to the zenith over one of the poles at each solstice. The "Voyager 2" flyby coincided with the southern hemisphere's 1986 summer solstice, when nearly the entire northern hemisphere was unilluminated. Once every 42 years, when Uranus has an equinox and its equatorial plane intersects the Earth, mutual occultations of Uranus's moons become possible. In 2007–2008 a number of such events were observed including two occultations of Titania by Umbriel on August 15 and December 8, 2007 as well as of Ariel by Umbriel on August 19, 2007.
Currently Umbriel is not involved in any orbital resonance with other Uranian satellites. Early in its history, however, it may have been in a 1:3 resonance with Miranda. This would have increased Miranda's orbital eccentricity, contributing to the internal heating and geological activity of that moon, while Umbriel's orbit would have been less affected. Due to Uranus's lower oblateness and smaller size relative to its satellites, its moons can escape more easily from a mean motion resonance than those of Jupiter or Saturn. After Miranda escaped from this resonance (through a mechanism that probably resulted in its anomalously high orbital inclination), its eccentricity would have been damped, turning off the heat source.
Composition and internal structure.
Umbriel is the third largest and fourth most massive of Uranian moons. The moon's density is 1.39 g/cm3, which indicates that it mainly consists of water ice, with a dense non-ice component constituting around 40% of its mass. The latter could be made of rock and carbonaceous material including heavy organic compounds known as tholins. The presence of water ice is supported by infrared spectroscopic observations, which have revealed crystalline water ice on the surface of the moon. Water ice absorption bands are stronger on Umbriel's leading hemisphere than on the trailing hemisphere. The cause of this asymmetry is not known, but it may be related to the bombardment by charged particles from the magnetosphere of Uranus, which is stronger on the trailing hemisphere (due to the plasma's co-rotation). The energetic particles tend to sputter water ice, decompose methane trapped in ice as clathrate hydrate and darken other organics, leaving a dark, carbon-rich residue behind.
Except for water, the only other compound identified on the surface of Umbriel by the infrared spectroscopy is carbon dioxide, which is concentrated mainly on the trailing hemisphere. The origin of the carbon dioxide is not completely clear. It might be produced locally from carbonates or organic materials under the influence of the energetic charged particles coming from the magnetosphere of Uranus or the solar ultraviolet radiation. This hypothesis would explain the asymmetry in its distribution, as the trailing hemisphere is subject to a more intense magnetospheric influence than the leading hemisphere. Another possible source is the outgassing of the primordial CO2 trapped by water ice in Umbriel's interior. The escape of CO2 from the interior may be a result of past geological activity on this moon.
Umbriel may be differentiated into a rocky core surrounded by an icy mantle. If this is the case, the radius of the core (317 km) is about 54% of the radius of the moon, and its mass is around 40% of the moon’s mass—the parameters are dictated by the moon's composition. The pressure in the center of Umbriel is about 0.24 GPa (2.4 kbar). The current state of the icy mantle is unclear, although the existence of a subsurface ocean is considered unlikely.
Surface features.
Umbriel's surface is the darkest of the Uranian moons, and reflects less than half as much light as Ariel, a sister satellite of similar size. Umbriel has a very low Bond albedo of only about 10% as compared to 23% for Ariel. The reflectivity of the moon's surface decreases from 26% at a phase angle of 0° (geometric albedo) to 19% at an angle of about 1°. This phenomenon is called opposition surge. The surface of Umbriel is slightly blue in color, while fresh bright impact deposits (in Wunda crater, for instance) are even bluer. There may be an asymmetry between the leading and trailing hemispheres; the former appears to be redder than the latter. The reddening of the surfaces probably results from space weathering from bombardment by charged particles and micrometeorites over the age of the Solar System. However, the color asymmetry of Umbriel is likely caused by accretion of a reddish material coming from outer parts of the Uranian system, possibly, from irregular satellites, which would occur predominately on the leading hemisphere. The surface of Umbriel is relatively homogeneous—it does not demonstrate strong variation in either albedo or color.
Scientists have so far recognized only one class of geological feature on Umbriel—craters. The surface of Umbriel has far more and larger craters than do Ariel and Titania and shows the least geological activity. In fact, among the Uranian moons only Oberon has more impact craters than Umbriel. The observed crater diameters range from a few kilometers at the low end to 210 kilometers for the largest known crater, Wokolo. All recognized craters on Umbriel have central peaks, but no crater has rays.
Near Umbriel's equator lies the most prominent surface feature: Wunda crater, which has a diameter of about 131 km. Wunda has a large ring of bright material on its floor, which appears to be an impact deposit. Nearby, seen along the terminator, are the craters Vuver and Skynd, which lack bright rims but possess bright central peaks. Study of limb profiles of Umbriel revealed a possible very large impact feature having the diameter of about 400 km and depth of approximately 5 km.
Much like other moons of Uranus, the surface of Umbriel is cut by a system of canyons trending northeast–southwest. They are not, however, officially recognized due to the poor imaging resolution and generally bland appearance of this moon, which hinders geological mapping.
Umbriel's heavily cratered surface has probably been stable since the Late Heavy Bombardment. The only signs of the ancient internal activity are canyons and dark polygons—dark patches with complex shapes measuring from tens to hundreds of kilometers across. The polygons were identified from precise photometry of "Voyager 2"'s images and are distributed more or less uniformly on the surface of Umbriel, trending northeast–southwest. Some polygons correspond to depressions of a few kilometers deep and may have been created during an early episode of tectonic activity. Currently there is no explanation for why Umbriel is so dark and uniform in appearance. Its surface may be covered by a relatively thin layer of dark material (so called "umbral material") excavated by an impact or expelled in an explosive volcanic eruption. Alternatively, Umbriel's crust may be entirely composed of the dark material, which prevented formation of bright features like crater rays. However, the presence of the bright feature within Wunda seems to contradict this hypothesis.
Origin and evolution.
Umbriel is thought to have formed from an accretion disc or subnebula; a disc of gas and dust that either existed around Uranus for some time after its formation or was created by the giant impact that most likely gave Uranus its large obliquity. The precise composition of the subnebula is not known; however, the higher density of Uranian moons compared to the moons of Saturn indicates that it may have been relatively water-poor. Significant amounts of nitrogen and carbon may have been present in the form of carbon monoxide (CO) and molecular nitrogen (N2) instead of ammonia and methane. The moons that formed in such a subnebula would contain less water ice (with CO and N2 trapped as clathrate) and more rock, explaining the higher density.
Umbriel's accretion probably lasted for several thousand years. The impacts that accompanied accretion caused heating of the moon's outer layer. The maximum temperature of around 180 K was reached at the depth of about 3 km. After the end of formation, the subsurface layer cooled, while the interior of Umbriel heated due to decay of radioactive elements present in its rocks. The cooling near-surface layer contracted, while the interior expanded. This caused strong extensional stresses in the moon's crust, which may have led to cracking. This process probably lasted for about 200 million years, implying that any endogenous activity ceased billions of years ago.
The initial accretional heating together with continued decay of radioactive elements may have led to melting of the ice if an antifreeze like ammonia (in the form of ammonia hydrate) or some salt was present. The melting may have led to the separation of ice from rocks and formation of a rocky core surrounded by an icy mantle. A layer of liquid water (ocean) rich in dissolved ammonia may have formed at the core–mantle boundary. The eutectic temperature of this mixture is 176 K. The ocean, however, is likely to have frozen long ago. Among Uranian moons Umbriel was least subjected to endogenic resurfacing processes, although it may like other Uranian moons have experienced a very early resurfacing event.
Exploration.
So far the only close-up images of Umbriel have been from the "Voyager 2" probe, which photographed the moon during its flyby of Uranus in January 1986. Since the closest distance between "Voyager 2" and Umbriel was 325000 km, the best images of this moon have a spatial resolution of about 5.2 km. The images cover about 40% of the surface, but only 20% was photographed with the quality required for geological mapping. At the time of the flyby the southern hemisphere of Umbriel (like those of the other moons) was pointed towards the Sun, so the northern (dark) hemisphere could not be studied. No other spacecraft has ever visited Uranus (and Umbriel), and no mission to Uranus and its moons are planned.

</doc>
<doc id="32104" url="http://en.wikipedia.org/wiki?curid=32104" title="Unabomber (disambiguation)">
Unabomber (disambiguation)

Unabomber may refer to:
People:
Other:

</doc>
<doc id="32108" url="http://en.wikipedia.org/wiki?curid=32108" title="USS Hornet">
USS Hornet

Eight ships of the United States Navy have been named USS "Hornet", after the stinging insect.

</doc>
<doc id="32110" url="http://en.wikipedia.org/wiki?curid=32110" title="Urd (Oh My Goddess!)">
Urd (Oh My Goddess!)

Urd (ウルド, Urudo) is a character in the popular "Oh My Goddess!" manga and anime, voiced by Toma Yumi (冬馬由美). In the series, her character is only loosely based on the deity Urðr from Norse mythology. Visually, her character design shows influences from shoujo and art nouveau.
Creation and conception.
Urd was one of a series of characters created by Kōsuke Fujishima, and is depicted as the older half-sister of Belldandy. Belldandy, Keiichi Morisato, Skuld (Urd and Belldandy's younger sister) and Urd make up the four major characters in "Oh My Goddess!". Urd first appearanced in the manga in chapter 14, "Sexy sister", but she has also been depicted in a novel ("Ah! My Goddess: First End"), three anime series ("Oh My Goddess!" (OVA), "Ah! My Goddess" and "The Adventures of Mini-Goddess") and in "".
As with her fictional sisters, Belldandy and Skuld, Urd has her origins in Norse mythology. Urd is one of the three Norns and represents the past, (the Norse Verdandi representing the present, with Skuld representing the future). Nevertheless, other than her name, Urd (like her "Oh My Goddess!" sisters) has little in common with her Norse namesake.
Unlike the problems with transliteration that were encountered with Belldandy, "Urd" presented no significant difficulties for translators. While Toren Smith determined that "Urtht" would be the more accurate translation of the Old Norse, when translating the manga series into English he acknowledged that "Urd" was an accepted alternate translation, and thus was comfortable using the spelling.
Biography.
Urd is Belldandy's busty older half sister and is the second Goddess to appear to Keiichi. Urd ranks as Goddess second class, management category limited license, similar to her youngest sister Skuld. She is Yggdrasil's System Administrator and Manager.
Although her powers exceed those of her sisters, she was supposedly relegated to "second class" ranking due to her tendency to lie according to her younger sister, Belldandy. Later, the real reason that Urd dropped the first class license examination was revealed to be because she was asked why she wanted to be a first class goddess. When she did not answer and the licensing goddess said "I think it better if you don't," meaning don't become a first class goddess. Many years later, Urd once again took the first-class licensing exam this time examined by Peorth and Belldandy. At one point, Peorth commented that Urd's control and mastery of her own powers, exceeded her own. At the end of this story arc the licensing goddess approved her first-class exam to which Urd surprisingly declined. She explained to Peorth that a first class goddess' prime directive is to protect and bless all things. However, Urd wishes to selectively protect what is most dear to her (this is followed by a page with Urd drawn enveloping her sisters with her black and white wings). She also concluded that there can be use in a Goddess that can lie, which is forbidden to first class goddesses.
Urd has extensive knowledge of potion lore. She checks her cabinet of potions each day and can tell if even a minute amount is missing. Urd recharges her energy by drinking sake and travels via television screens. She bears the emblem of the past. If allowed to wield her full first class power unsealed, Urd could possibly be the most powerful of the Goddesses on Earth. Her power is so great that she unknowingly burned Peorth (a first class Goddess) by merely touching her shoulder to which Peorth stated "It's no wonder the Almighty was cautious about her powers."
Urd fancies herself a Goddess of Love, although the mishaps of using her magical potions and her general lack of restraint tends to complicate, rather than stimulate, Keiichi and Belldandy's love life. She came to Earth to spur Keiichi onward with love potions and deceitful though well-meaning advice, but as punishment for deserting her post and for using her powers on Earth without authorization, The Almighty banished her from Heaven until further notice. That notice of return came after the Terrible Master Urd episode c. chapter 47, but by then she wanted to stay on Earth and everyone helped muck up things so she couldn't go back right away. She and Skuld have since done emergency duty on Yggdrasil in heaven at least twice since then, as of ch 162.
As she demonstrates later in the manga, she can exercise immense control over her powers despite her second-class status. She was able to draw her personal sigil using first-class lightning magic on her first attempt, a task that First Class Goddess Peorth needed numerous attempts to successfully complete.
Urd shares a common father with her younger sisters (Belldandy, Skuld), but has a different mother, the Demon Lord Hild. Their father has yet to be introduce to the series, but it is implied that he is someone of high status. Because of her heritage, Urd is a hybrid of Goddess and Demon, reflected in the half-white, half-black appearance of her Angel, World of Elegance. Urd is the first and only hybrid introduced in the series, and possibly the only hybrid in the Ah! My Goddess universe. Perhaps due to her Demonic heritage, Austrian Polka (in the English manga) or Enka (in the Japanese manga and TV series) instantly puts Urd to sleep and she is unable to awaken until the music ceases. Similarly, the demon Marller dances to rock music, and the two often use these weaknesses against each other.
Keiichi's friends and his sister Megumi are aware of Urd's existence and her relationship with Belldandy and residency at Keiichi's home; however, for the most part they are not aware of her "goddess" status.
For the longest time, she was unable to summon her angel since she was so scared when she first saw it and ordered it never to come out. This was caused by her self-doubt at being a hybrid Goddess/Demon since she equated having pure white wings as the sign of being a true Goddess. She has since gotten over whatever self-doubt that was holding her back and can now once again call her angel at will, much to Skuld's chagrin (she had originally thought that Urd had no angel and wanted to top her eldest sister by being first).
Personality.
Unlike her younger sister Belldandy, Urd is very impulsive and headstrong. Belldandy describes Urd as being very passionate about everything she does. Urd is a great believer in the idea that the 'End justifies the Means', although, as Belldandy puts it: "...she gets so wrapped up in the means that she forgets what the end was." She once stole Sleipnir to get a cure for a sick Belldandy, but spent so much time in the effort to master riding Sleipnir that it took eight days for her to get to the place where the cure was. Another god had fetched the cure six days earlier. Despite such, she usually means well and will do anything to protect her loved ones. Because of her being the oldest, she believes it's also her duty to look after Belldandy and Skuld.
Urd's impulsiveness often makes her act first without fully considering the consequences. She is also a constant meddler, seemingly unable to leave well enough alone. She is also quite short tempered for a goddess, and is rather easy to irritate and anger. Urd is also notable for her tendency to lie, something a goddess supposedly can't do (or, more accurately, it is something a goddess "shouldn't" do, being against the rules). Although she's not a pathological liar, she's more than willing to distort the truth if needed to accomplish an objective. She is also very open (and rather proud) of her sexuality, evidenced by her provocative dress, jibes at the younger Skuld and her slightly comical distress when turned into a child as a result of energy drainage. Her first appearance to Keiichi Morisato was through a semi-pornographic video.
Urd has an interesting love-hate relationship with her youngest sister, Skuld. Both seem to antagonize one another at times, with Urd usually teasing Skuld about her age, bust size, and apparent lack of talent when it comes to magic. However both do care for each other and will come to the other's aid when necessary. Urd and Skuld are commonly seen playing different games at the table in front of the television for rights to watching their favorite shows, although the two of them have stated that simply watching television isn't as fun as competing for the television, they have been joined at times by Belldandy, Keiichi's mother and Peorth. When Keiichi asked Belldandy "Are they best friends or what?" Belldandy replied with a smile and "They're best friends. I almost envy their ability to feel so strongly for each other."
For a goddess, Urd seems to have an amazing tendency to have her plans backfire, usually a result of her impulsive tendency to use raw power to solve a situation. Given her power levels this tends to cause explosions. Quite often, something will happen to louse up whatever scheme she's currently cooked up. Examples including: drinking one of her own love potions, trying to help Belldandy bake a cake and blowing up the kitchen, trying to help Keiichi build a motorbike and blowing up the garage, trying to dispel a number of computer "bugs" and blowing up the house, and so on.
One of Urd's most defining traits is her mixed Goddess-Demon ancestry. Because of this unique heritage, Urd is occasionally uncertain of her status within her world, as her Goddess and Demon personalities are always in conflict inside her. It was this inner conflict that allowed the Lord of Terror to eventually overcome Urd's will at one point. Deep in her heart, she truly wishes to be recognized as a Goddess and, in her earlier years, often looked up to Belldandy as a role model. This has led Urd to quietly deny her demonic heritage, much to the consternation of her mother, Hild.
Yumi Touma has said that it is only in the last of the OAV episodes that Urd can be seen "as an older sister, one that you can depend on."
World of Elegance's Appearances.
Episodes in which World of Elegance has appeared.

</doc>
<doc id="32113" url="http://en.wikipedia.org/wiki?curid=32113" title="Conservative Party (UK)">
Conservative Party (UK)

The Conservative Party, officially the Conservative and Unionist Party, is a centre-right political party in the United Kingdom. It currently stands as the majority party in the House of Commons, after winning 331 seats in the 2015 general elections. Before the dissolution of the previous parliament, it was the largest single party with 303 Members of Parliament, and governed under a coalition with the Liberal Democrats. At the time of the May 2015 election, it was the largest party in local government with 8,296 councillors and the largest party in the House of Commons with 331 seats of the possible 650. 
The Conservative Party was founded in 1834 from the Tory Party—giving rise to the Conservatives' colloquial name of Tories—and was one of two dominant parties in the 19th century, along with the Liberal Party. In the 1920s, the Liberal vote greatly diminished and the Labour Party became the Conservatives' main rivals. Conservative Prime Ministers led governments for 57 years of the 20th century, including Winston Churchill (1940–45, 1951–55) and Margaret Thatcher (1979–90). Thatcher's tenure led to wide-ranging economic liberalisation and saw the Conservatives become the most eurosceptic of the three major parties. The party was returned to government in coalition in 2010 under the more liberal leadership of David Cameron. The Conservative Party then went on to get re-elected to Government, but this time with a majority, at the 2015 General Election, putting them in a much stronger position than they were before in a coalition government, as they no longer need to rely on the support of the Liberal Democrats to get every piece of legislation passed. 
s of 2014[ [update]], the Conservatives are the joint-second largest British party in the European Parliament, with 20 MEPs, who sit with the soft eurosceptic European Conservatives and Reformists (ECR) parliamentary group. The party is a member of the Alliance of European Conservatives and Reformists (AECR) Europarty and the International Democrat Union (IDU).
The party is the third-largest in the Scottish Parliament and second-largest in the Welsh Assembly. They had been formally allied to the Ulster Unionist Party (UUP) as part of the Ulster Conservatives and Unionists arrangement; this electoral pact formally ended with the Northern Ireland Party's relaunch as the NI Conservatives in June 2012, allowing for autonomy on devolved matters, similar to the Welsh Conservatives and the Scottish Conservatives.
History.
Origins in the Whig Party.
The Conservative Party traces its origins to a faction, rooted in the 18th-century Whig Party, that coalesced around William Pitt the Younger (Prime Minister of Great Britain 1783–1801 and 1804–1806). Originally known as "Independent Whigs", "Friends of Mr Pitt", or "Pittites", after Pitt's death the term "Tory" came into use. This was an allusion to the Tories, a political grouping that had existed from 1678, but which had no organisational continuity with the Pittite party. From about 1812 on the name "Tory" was commonly used for the newer party.
The term "Conservative" was suggested as a title for the party by a magazine article by J. Wilson Croker in the "Quarterly Review" in 1830. The name immediately caught on and was officially adopted under the aegis of Sir Robert Peel around 1834. Peel is acknowledged as the founder of the Conservative Party, which he created with the announcement of the Tamworth Manifesto. The term "Conservative Party" rather than Tory was the dominant usage by 1845.
Conservatives and Unionists (1867–1965).
The widening of the electoral franchise in the 19th century forced the Conservative Party to popularise its approach under Lord Derby and Benjamin Disraeli, who carried through their own expansion of the franchise with the Reform Act of 1867. In 1886 the party formed an alliance with Lord Hartington (later the 8th Duke of Devonshire) and Joseph Chamberlain's new Liberal Unionist Party and, under the statesmen Lord Salisbury and Arthur Balfour, held power for all but three of the following twenty years before suffering a heavy defeat in 1906 when it split over the issue of free trade. In 1912, the Liberal Unionists finally merged with the Conservative party. In Ireland, the Irish Unionist Alliance had been formed in 1891 which merged anti-Home Rule Unionists into one political movement. Its MPs took the Conservative whip at Westminster, and in essence formed the Irish wing of the party until 1922.
First World War.
The Conservatives served with the Liberals in an all-party coalition government during World War I, and the coalition continued under the Liberal prime minister David Lloyd George (with half of the Liberals) until 1922. Keohane finds that the Conservatives were bitterly divided before 1914, especially on the issue of Irish Unionism and the experience of three consecutive election losses. However the war pulled the party together, allowing it to emphasise patriotism as it found new leadership and worked out its positions on the Irish question, socialism, electoral reform, and the issue of intervention in the economy. The fresh emphasis on anti-Socialism was its response to the growing strength of the Labour Party. When electoral reform was an issue it worked to protect its base in rural England. It aggressively sought women voters in the 1920s, often relying on patriotic themes.
1920–1945.
In 1922, Bonar Law and Stanley Baldwin led the break-up of the coalition and the Conservatives governed until 1923, when a minority Labour government led by Ramsay MacDonald came to power. The Conservatives regained power in 1924 and remained in power for the full five-year term. They were defeated in 1929 as a minority Labour government took office. In 1931, following the collapse of the Labour minority government, it entered another coalition, which was dominated by the Conservatives with some support from fractions of both the Liberals and Labour party (National Labour and Liberal Nationals). In May 1940 a more balanced coalition was formed, the National Government, which, under the leadership of Winston Churchill, saw the United Kingdom through World War II. However, the party lost the 1945 general election to the resurgent Labour Party.
1945–1963.
Popular dissatisfaction.
In the late 1940s the Conservative Party exploited and incited growing public anger at food rationing, scarcity, controls, austerity, and omnipresent government bureaucracy. They used the dissatisfaction with the socialistic and equalitarian policies of the Labour Party to rally middle-class supporters and build a political comeback that won the 1951 general election. Their appeal was especially effective to housewives, who faced more difficult shopping conditions after the war than during the war.
Modernising the party.
In 1947 the party published its Industrial Charter which marked its acceptance of the "post-war consensus" on the mixed economy and labour rights. David Maxwell Fyfe chaired a committee into Conservative Party organisation that resulted in the Maxwell Fyfe Report (1948–49). The report shifted the balance of electoral funding from the candidate to the party, with the intention of broadening the diversity of MPs. In practice, it may have had the effect of lending more power to constituency parties and making candidates more uniform.
The success of the Conservative party in reorganising itself was validated by its victory in the 1951 election. Churchill, the party leader, brought in a Party Chairman to modernise the creaking institution. Lord Woolton was a successful department store owner and wartime Minister of Food. As Party Chairman 1946–55, he rebuilt the local organisations with an emphasis on membership, money, and a unified national propaganda appeal on critical issues. To broaden the base of potential candidates, the national party provided financial aid to candidates, and assisted the local organisations in raising local money. Lord Woolton emphasized a rhetoric that characterised the opponents as "Socialist" rather than "Labour". The libertarian influence of Professor Friedrich Hayek's 1944 best-seller "Road to Serfdom" was apparent in the younger generation, but that took another quarter century to have a policy impact. By 1951, Labour had worn out its welcome in the middle classes; its factions were bitterly embroiled. Conservatives were ready to govern again.
With a narrow win in the 1951 general election, Churchill was back. Although he was aging rapidly, he had national and global prestige. Apart from rationing, which was ended, most of the welfare state enacted by Labour were accepted by the Conservatives and became part of the "post-war consensus" that would later be satirised as Butskellism, and which lasted until the 1970s. The Conservatives were conciliatory toward unions, but they did de-nationalise the steel and road haulage industries in 1953. During the Conservatives’ 13 years in office, pensions went up by 49% in real terms, sickness and unemployment benefits by 76% in real terms, and supplementary benefits by 46% in real terms. However, family allowances fell by 15% in real terms during that period.
The Party won in 1955 and 1959 with ever larger majorities. Conservative prime ministers Churchill, Anthony Eden, Harold Macmillan and Sir Alec Douglas-Home promoted relatively liberal trade regulations and less state involvement throughout the 1950s and early 1960s. They oversaw a period of economic prosperity, with Macmillan proclaiming during the 1959 General Election that Britain had 'never had it so good'.
In 1958, Geoffrey Howe co-authored the report "A Giant's Strength" published by the Inns of Court Conservative Association. The report argued that the unions had become too powerful and that their legal privileges ought to be curtailed. Ian Macleod discouraged the authors from publicising the report. Macmillan believed that trade union votes had contributed towards the 1951 and 1955 victories and thought that it "would be inexpedient to adopt any policy involving legislation which would alienate this support".
Macmillan's bid to join the European Economic Community in early 1963 was blocked by French President Charles de Gaulle. The period saw the decline of the UK as a prominent world leader, with the loss of practically the entire empire and a laggard economy.
Following controversy over the selections of Harold Macmillan and Sir Alec Douglas-Home via a process of consultation known as the 'Magic Circle', a formal election process was created and the first leadership election was held in 1965. Of the three candidates, Edward Heath won with 150 votes to Reginald Maudling's 133 and Enoch Powell's 15.
Edward Heath.
Edward Heath's 1970–74 government was notable for taking the UK into the EEC, although the right-wing of the party objected to his failure to control the trade unions at a time when a declining British industry saw many strikes, as well as a recession which started in 1973 and lasted for two years.
Since accession to the EU, British membership has been a source of heated debate within the Conservative party.
Heath had come to power in June 1970 and the last possible date for the next general election was not until mid-1975. However a general election was held in February 1974 in a bid to win public support during a national emergency caused by the miners' strike. However, Heath's attempt to win a second term in power at this "snap" election failed, as a deadlock result left no party with an overall majority. The Conservatives had more votes than Labour, who had four more seats. Heath resigned within days, after failing to gain Liberal Party support in order to form a coalition government, paving the way for Harold Wilson and Labour to return to power as a minority government. Heath's hopes of returning to power later in the year were ended when Labour won the October 1974 election with an overall majority of three seats.
Margaret Thatcher.
Loss of power weakened Heath's control over the party and Margaret Thatcher deposed him in the 1975 leadership election. The UK in the 1970s had seen sustained high inflation rates, which were above 20% at the time of the leadership election, subsequently falling to below 10%; unemployment had risen, and over the winter of 1978–79 there was a series of strikes known as the "Winter of Discontent". Thatcher led her party to victory in the 1979 general election with a manifesto which concentrated on the party's philosophy rather than presenting a 'shopping list' of policies.
As prime minister, Thatcher focused on establishing a political ideology that became known as the "New Right" or Thatcherism, based on social and economic ideas from the United States. Thatcher believed that too much social-democratic-oriented government policy was leading to a long-term decline in the British economy. As a result, her government pursued a programme of economic liberalism, adopting a free-market approach to public services based on the sale of publicly owned industries and utilities, as well as a reduction in trade union power. She held the belief that the existing trend of Unions was bringing economic progress to a standstill by enforcing "wildcat" strikes, keeping wages artificially high and forcing unprofitable industries to stay open.
Thatcher led the Conservatives to two further election victories with landslide majorities in 1983 and 1987. She was greatly admired by her supporters for her leadership in the Falklands War of 1982—which coincided with a dramatic boost in her popularity—and for policies such as giving the right to council house tenants to buy their council house at a discount on market value. She was also deeply unpopular in certain sections of society due to unemployment, which reached its highest level since the 1930s, peaking at over 3 million following her economic reforms, and her response to the miners' strike. Unemployment had doubled between 1979 and 1982, largely due to Thatcher's monetarist battle against inflation. At the time of the 1979 election, inflation had been at 9% or under for the previous year, having fallen under Callaghan, then rose to over 20% in the first two years of the Thatcher government, but it had fallen again to 5.8% by the start of 1983 (it continued to be under 7% until 1990). The UK economy benefitted in the first Thatcher term by tax income from North Sea oil coming on stream.
The period of unpopularity of the Conservatives in the early 1980s coincided with a crisis in the Labour Party which now formed the opposition. The Social Democratic Party (SDP) was formed in 1981 and consisted of more than 20 breakaway Labour MPs, who quickly formed the SDP-Liberal Alliance with the Liberal Party. By the turn of 1982, the SDP-Liberal Alliance was ahead of the Conservatives in the opinion polls, but victory in the Falklands war in June that year, along with the recovering British economy, saw the Conservatives returning quickly to the top of the opinion polls and winning the 1983 General Election with a landslide majority, due to a split opposition vote.
Thatcher now faced, arguably, her most serious rival yet after the 1983 election, when Michael Foot resigned as Labour leader and was succeeded by Neil Kinnock. With a new leader at the helm, Labour were clearly determined to topple the Conservatives at the next election and for virtually the entirety of Thatcher's second government it was looking a very serious possibility, as the lead in the opinion polls constantly saw a change in leadership from the Conservatives to Labour, with the Alliance occasionally scraping into first place.
By the time of the election in June 1987 the economy was stronger, with lower inflation and falling unemployment and Thatcher secured her third successive election victory with a second, though smaller, landslide majority.
The introduction of the Community Charge (known by its opponents as the "poll tax") in 1989 is often cited as contributing to her political downfall. The summer of 1989 saw her fall behind Neil Kinnock's Labour in the opinion polls for the first time since 1986, and her party's fall in popularity continued into 1990. By the second half of that year, opinion polls were showing that Labour had a lead of up to 16 points over the Conservatives and they faced a tough 18 months ahead of them if they were to prevent Kinnock's ambition to be prime minister from being realised. At the same time, the economy was sliding into another recession.
Internal party tensions led to a leadership challenge by the Conservative MP Michael Heseltine; and, after months of speculation about her future as prime minister, she resigned on 28 November 1990, making way for a new Conservative leader more likely to win the next general election in the interests of party unity.
John Major.
John Major won the party leadership contest on 27 November 1990, and his appointment led to an almost automatic boost in Conservative fortunes. A MORI poll six days before Mrs Thatcher's resignation had shown the Conservatives to be 11 points behind Labour, but within two months the Conservatives had returned to the top of the opinion polls with a slim lead.
An election had to be held within the next 18 months and the UK economy was sliding into recession, but 1991 was a year of electoral uncertainty as the Conservatives and Labour regularly swapped places at the top of the opinion polls, and Major resisted Neil Kinnock's numerous calls for an immediate election.
The election was finally held on 9 April 1992 and the Conservatives won, even though the economy was still in recession and most of the polls had predicted either a Labour win or a hung parliament. Major's vigorous campaigning, notably his claim that the UK would have higher prices and higher taxes under a Labour government, was seen to have been crucial in his election win (in which he became the first prime minister to attract 14,000,000 votes in a general election), as was a high profile campaign by "The Sun" newspaper against Labour leader Neil Kinnock, who resigned in the aftermath of the election to be succeeded by John Smith. The Party also touched upon the issue of immigration, claiming that under Labour, immigration would rise hugely.
The UK economy was deep in recession by this stage and remained so until the end of the year. The pound sterling was forced out of the European Exchange Rate Mechanism on 16 September 1992, a day thereafter referred to as "Black Wednesday".
Soon after approximately one million householders faced re-possession of their homes during a recession that saw a sharp rise in unemployment, taking it close to 3,000,000. The party subsequently lost much of its reputation for good financial stewardship although the end of the recession was declared in April 1993 bringing economic recovery and a rise in employment.
The party was also plagued by internal division and infighting, mainly over the issue over policy towards the European Union. The party's eurosceptic wing, represented by MPs such as John Redwood, opposed further EU integration, whilst the party's pro-European wing, represented by men such as Chancellor of the Exchequer Kenneth Clarke, was broadly supportive. The issue of the creation of a single currency also inflamed tensions, and these would continue to dog the party until the early 2000s (decade). These divisions gave off an impression of a divided party, which had lost touch with the voters.
Major also had to survive a leadership challenge in 1995 by the Secretary of State for Wales, the aforementioned John Redwood. He survived, but Redwood received 89 votes from MPs, as well as the backing of the "Sun" newspaper, which described the choice as being between "Redwood or Deadwood". This further undermined Major's influence in the Party.
The Conservative government was also increasingly accused in the media of "sleaze". Their support reached its lowest ebb in late 1994, after the death of Labour Party leader John Smith and the election of Tony Blair as his successor, when Labour had up to 60% of the vote in opinion polls and had a lead of some 30 points ahead of the Conservatives. The Labour lead was gradually narrowed over the next two years, as the Conservatives gained some credit for the strong economic recovery and fall in unemployment. But as the 1997 general election loomed, despite their high profile New Labour, New Danger campaign, it was still looking certain that Labour would win.
An effective opposition campaign by the Labour Party culminated in a landslide defeat for the Conservatives in 1997 that was Labour's largest ever parliamentary victory. The 1997 election left the Conservative Party with MPs in just England, all remaining seats in Scotland and Wales having been lost and not a single seat having been gained anywhere.
Back in opposition: William Hague.
John Major resigned as party leader after the Conservatives were voted out of power and was succeeded by William Hague. Though Hague was a strong debater, a Gallup poll for the "Daily Telegraph" found that two-thirds of voters regarded him as "a bit of a wally", for headlines such as his claim that he drank 14 pints (8 litres) (1.75 gallons) of beer in a single day in his youth. He was also criticised for attending the Notting Hill Carnival and for wearing a baseball cap in public in what were seen as poor attempts to appeal to younger voters. Shortly before the 2001 election, Hague was much maligned for a speech in which he predicted that a re-elected Labour government would turn the UK into a "foreign land". The BBC also reported that the Conservative peer Lord Taylor criticised Hague for not removing the whip from John Townend, a Conservative MP, after the latter made a speech in which he said the British were becoming "a mongrel race", although Hague did reject Townend's views.
The 2001 election resulted in a net gain of just one seat for the Conservative Party, just months after the fuel protests of September 2000 had seen the Conservatives briefly take a narrow lead over Labour in the opinion polls.
Having privately set himself a target of 209 seats, matching Labour's performance in 1983 – a target which he missed by 43  – William Hague resigned soon after.
Iain Duncan Smith and Michael Howard.
Iain Duncan Smith (2001–2003) (often known as IDS and by satirists as "the quiet man") is a strong Eurosceptic, but the issue did not define Duncan Smith's leadership, though during his tenure Europe ceased to be an issue of division in the party as it united behind calls for a referendum on the proposed European Union Constitution.
However, before he could lead the party in a general election Duncan Smith lost the vote on a motion of no confidence by MPs who felt that the party would not be returned to government under his leadership. This was despite the Conservative support equalling that of Labour in the months leading up to his departure from the leadership.
Michael Howard then stood for the leadership unopposed on 6 November 2003.
Under Howard in the 2005 general election, the Conservative Party increased their total vote share by around 0.7% (up to 32.4%) and – more significantly – their number of parliamentary seats by 33 (up to 198 seats). This gain accompanied a larger fall in the Labour vote, and the election reduced Labour's majority from 167 to 68 and its share of the vote to 35.2%. The campaign, based on the slogan "Are you thinking what we're thinking?", was designed by Australian pollster Lynton Crosby. The day after the election, on 6 May, Howard announced that he did not feel it was right to continue as leader after defeat in the general election, also saying that he would be too old to lead the party into another campaign and would therefore step down after allowing time for the party to amend its leadership election rules. 
David Cameron (2010–present).
David Cameron won the subsequent leadership campaign. Cameron beat his closest rival, David Davis, by a margin of more than two to one, taking 134,446 votes to 64,398. He then announced his intention to reform and realign the Conservatives, saying they needed to change the way they looked, felt, thought and behaved, advocating a more centre-right stance as opposed to their recent staunchly right-wing platform. Although Cameron's views are probably to the left of the party membership and he has sought to make the Conservative brand more attractive to young, socially liberal voters, he has also expressed his admiration for Margaret Thatcher, describing himself as a "big fan of Thatcher's", though he questions whether that makes him a "Thatcherite". For most of 2006 and the first half of 2007, polls showed leads over Labour for the Conservatives.
Polls became more volatile in the summer of 2007 with the accession of Gordon Brown as Prime Minister although polls gave the Conservatives a lead after October of that year and, by May 2008, with the UK's economy sliding into its first recession since 1992, and a week after local council elections, a YouGov poll commissioned by "The Sun" newspaper was published giving the Conservative Party a 26-point lead over Labour, its largest lead since 1968. The Conservatives gained control of the London mayoralty for the first time in May 2008 after Boris Johnson defeated the Labour incumbent, Ken Livingstone.
The Conservative lead in the opinion polls had been almost unbroken for nearly three years when Britain finally went to the polls on 6 May 2010, though since the turn of 2010 most polls had shown the Conservative lead as less than 10 points wide. The election ended in a hung parliament with the Conservatives having the most seats (306) but being 20 seats short of an overall majority. Following the resignation of Gordon Brown as prime minister and Labour Party leader five days afterwards, David Cameron was named as the country's new prime minister and the Conservatives entered government in a coalition with the Liberal Democrats – the first postwar coalition government.
In May 2014 the Conservatives were soundly defeated in the European parliamentary elections coming in third behind the UK Independence Party and Labour. The UKIP ended with 24 MEPs, Labour 20, and the Conservatives 19. The result was described by UKIP leader Nigel Farage as "disastrous" for Cameron, and the leaders of the other main parties.
In September 2014 the Unionist side, championed by Labour as well as by the Conservative Party and the Liberal Democrats, won in the Scottish Independence referendum by 55% No to 45% Yes on the question "Should Scotland be an independent country". This can be seen as a victory for British Unionism, a core part of traditional Conservative ideology, and also for David Cameron as the incumbent Prime Minister.
In the 2015 general elections, the Conservatives won a majority of seats in the Commons and formed a single-party government under David Cameron. The party increased its national vote share, becoming the first incumbent party to do so since 1900. The result was unexpected and exceeded even the party leadership's expectations, as most polls had predicted a hung parliament. This was also the first general election since 1992 in which the Conservatives had won an overall majority, although the vote share of 36.9 % was lower than the previous four Conservative majority governments under Thatcher and Major.
Policies.
Economic policy.
The party's reputation for economic stewardship was dealt a blow by Black Wednesday in 1992, in which billions of pounds were spent in an effort to keep the pound within the European Exchange Rate Mechanism (ERM) system at an overvalued rate. Combined with the recession of the early 1990s 'Black Wednesday' allowed Tony Blair and then-Shadow Chancellor of the Exchequer Gordon Brown to promise greater economic competence.
One concrete economic policy of recent years has been opposition to the European single currency. Anticipating the growing Euroscepticism within his party, John Major negotiated a British opt-out from the single currency in the 1992 Maastricht Treaty, although several members of Major's cabinet, such as Kenneth Clarke, were personally supportive of EMU participation. Following Major's resignation after the 1997 defeat, each of the four subsequent Conservative leaders, including David Cameron, have positioned the party firmly against the adoption of the euro. This policy is broadly popular with the British electorate.
Following Labour's victory in the 1997 general election, the Conservative Party opposed Labour's decision to grant the Bank of England independent control of interest rates—on the grounds that it would be a prelude to the abolition of the pound sterling and acceptance of the European single currency, and also expressed concern over the removal of monetary policy from democratic control. However, Bank independence was popular amongst the financial community as it helped to keep inflation low. The Conservatives accepted Labour's policy in early 2000.
The Conservative Party under David Cameron has redirected its stance on taxation, still committed to the general principle of reducing direct taxation whilst arguing that the country needs a "dynamic and competitive economy", with the proceeds of any growth shared between both "tax reduction and extra public investment".
In the wake of the Great Recession of 2008–9, the Conservatives had not ruled out raising taxes, and have said it will be difficult to scrap the 50% top rate of income tax. Since coming to power, they have said that the 50% top rate will be dropped to 45% in 2013 and 40% in 2014. They have said how they would prefer to cut a recent rise in national insurance. Furthermore, they have stated that government spending will need to be reduced, and have ringfenced only international aid and the NHS. Details of the cuts to government spending under the Conservative–Liberal coalition can be found in the following article: United Kingdom government austerity programme.
Social policy.
In recent years, 'modernisers' in the party have claimed that the association between social conservatism and the Conservatives (manifest in policies such as tax incentives for married couples, the removal of the link between pensions and earnings, and criticism of public financial support for those who do not work) have played a role in the electoral decline of the party in the 1990s and early 2000s (decade). Since 1997, a debate has continued within the party between 'modernisers' such as Alan Duncan, who believe that the Conservatives should modify their public stances on social issues, and 'traditionalists' such as Liam Fox and Owen Paterson, who believe that the party should remain faithful to its traditional conservative platform. This may have resulted in William Hague's and Michael Howard's pre-election swings to the right in 2001 and 2005, as well as the election of the stop-Kenneth Clarke candidate Iain Duncan Smith in 2001. Iain Duncan Smith, however, remains influential. It has been argued by analysts that his Centre for Social Justice has forced Cameron to the right on many issues, particularly crime and social welfare.
The party has strongly criticised Labour's "state multiculturalism". Shadow Home Secretary Dominic Grieve said in 2008 that multiculturalism had created a "terrible" legacy, a cultural vacuum that has been exploited by "extremists". However conservative critics such as Peter Hitchens assert that Cameron's is an equally multicultural outlook and accuse the Conservative Party of promoting what they see as "Islamic extremists."
Foreign policy.
For much of the 20th century, the Conservative party took a broadly Atlanticist stance in relations with the United States, favouring close ties with the United States and similarly aligned nations such as Canada, Australia and Japan. The Conservatives have generally favoured a diverse range of international alliances, ranging from the North Atlantic Treaty Organization (NATO) to the Commonwealth of Nations.
Close US-British relations have been an element of Conservative foreign policy since World War II. Winston Churchill during his 1951–1955 post-war premiership built up a strong relationship with the Eisenhower Administration in the United States. Harold Macmillan demonstrated a similarly close relationship with the Democratic administration of John F. Kennedy. Though the US–British relationship in foreign affairs has often been termed a 'Special Relationship', a term coined by Sir Winston Churchill, this has often been observed most clearly where leaders in each country are of a similar political stripe. The former Prime Minister Margaret Thatcher built a close relationship with the American President Ronald Reagan in his opposition to the former Soviet Union, but John Major was less successful in his personal contacts with George H. W. Bush and Bill Clinton. Out of power and perceived as largely irrelevant by American politicians, Conservative leaders Hague, Duncan-Smith, and Howard each struggled to forge personal relationships with presidents Bill Clinton and George W. Bush. However, the Republican 2008 presidential candidate, John McCain, spoke at the 2006 Conservative Party Conference.
The Conservatives have proposed a Pan-African Free Trade Area, which it says could help entrepreneurial dynamism of African people. The Conservatives have also pledged to increase aid spending to 0.7% of national income by 2013.
David Cameron had sought to distance himself from former US President Bush and his neoconservative foreign policy, calling for a "rebalancing" of US-UK ties and met Barack Obama during his 2008 European tour. Despite traditional links between the UK Conservatives and US Republicans, and between Labour and the Democrats, London Mayor Boris Johnson, a Conservative, endorsed Obama in the 2008 election.
Beyond relations with the United States, the Commonwealth and the EU, the Conservative Party has generally supported a pro free-trade foreign policy within the mainstream of international affairs. The degree to which Conservative Governments have supported interventionist or non-interventionist presidents in the US has often varied with the personal relations between a US President and the British Prime Minister.
Welfare.
Improving the welfare of Britain's military service personnel is a priority for the Conservative Party. One of their main goals is to repair the Military Covenant and strengthen the ties between the armed forces and government. Policies introduced in 2010 include those to double the operational bonus for troops serving in Afghanistan; to fund higher education for children of those service personnel killed in action; and to properly resource and staff the NHS to deal optimally with the particular needs of the Armed Forces.
Mental health has always been a very important issue for the Conservative Party, particularly when it comes to service personnel. The Party is committed to addressing issues of mental health before they arise with a mental health follow-up telephone service for veterans and personnel who have deployed on operations or to places in support of operations. This is customer-service driven and at the convenience of the veteran. The Conservative Party have also pledged to support greater awareness of the programmes that offer help to armed forces personnel.
Defence.
Afghanistan.
Since the terrorist attacks of 11 September 2001, the Conservative party has supported the coalition military action in Afghanistan. The Conservative Party believes that success in Afghanistan is defined in terms of the Afghans achieving the capability to maintain their own internal and external security. They have repeatedly criticised the former Labour Government for failing to equip British Forces adequately in the earlier days on the campaign—especially highlighting the shortage of helicopters for British Forces resulting from Gordon Brown's £1.4bn cut to the helicopter budget in 2004.
Strategic Defence and Security Review.
The Conservative Party believes that in the 21st century defence and security are interlinked. They have pledged to break away from holding a traditional Strategic Defence Review and have committed to carrying out a more comprehensive Strategic Defence and Security Review (SDSR) immediately upon coming into office. This review will include both defence and homeland security related matters. The Labour Government last conducted a review in 1998. To prevent a long gap in the future they have also pledged to hold regular defence reviews every 4–5 years, and if necessary will put this requirement into legislation. Party officials claim that the SDSR will be a major improvement, and will ensure that Britain maintains generic and flexible capability to adapt to any changing threats. It will be a cross-departmental review that will begin with foreign policy priorities and will bring together all the levers of domestic national security policy with overseas interests and defence priorities.
As well as an SDSR, the Conservative Party pledged in 2010 to undertake a fundamental and far reaching review of the procurement process and how defence equipment is provided in Britain. They have pledged to reform the procurement process, compile a Green Paper on Sovereignty Capability, and publish another Defence Industrial Strategy following on from the Defence Industrial Strategy in 2005. The Conservative Party has said that there will be four aims for British defence procurement: to provide the best possible equipment at the best possible price; to streamline the procurement process to ensure the speedy delivery of equipment to the front line; to support our industry jobs at home by increasing defence exports; to provide defence procurement that underpins strategic relationships abroad and; to provide predictability to the defence industry.
The Conservative Party also pledged to increase Britain's share of the global defence market as Government policy.
Europe and NATO.
The Conservative Party aims to build enhanced bilateral defence relations with key European partners and believes that it is in Britain's national interest to cooperate fully with all its European neighbours. They have pledged to ensure that any EU military capability must supplement and not supplant British national defence and NATO, and that it is not in the British interest to hand over security to any supranational body.
The Conservatives see it as a priority to encourage all members of the European Union to do more in terms of a commitment to European security at home and abroad.
Regarding the defence role of the European Union, the Conservatives pledged to re-examine some of Britain's EU Defence commitments to determine their practicality and utility; specifically, to reassess UK participation provisions like Permanent Structured Cooperation, the European Defence Agency and EU Battlegroups to determine if there is any value in Britain's participation.
The Conservative Party upholds the view that NATO should remain the most important security alliance for United Kingdom. They believe that NATO, which has been the cornerstone of British security for the past 60 years, should continue to have primacy on all issues relating to Europe's defence, and pledged in 2010 to make NATO reform a key strategic priority.
They have also called on the so-called fighting/funding gap to be changed and have called on the creation of a fairer funding mechanism for NATO's expeditionary operations. As well as this, the Conservatives believe that there is scope for expanding NATO's Article V to include new 21st Century threats such as energy and cyber security.
Nuclear weapons.
The 2010 manifesto said the Conservatives will maintain Britain's continuous at sea, independent, submarine based strategic nuclear deterrent based on the Trident missile system.
Health policy.
In 1945, the Conservatives first declared support for universal healthcare. Since entering office in 2010, they have introduced the Health and Social Care Act, constituting the biggest reformation that the NHS has ever undertaken. However, there has been much criticism and protest about the 2010 government's actions on the NHS, focussing on budget cuts and privatisation of services. After a 2013 union protest said by police to have been one of the largest protests seen in Manchester, the general secretary of the Trades Union Congress (TUC) said that austerity was having a devastating effect, with 21,000 NHS jobs lost over the previous three months alone, and that "The NHS is one of Britain's finest achievements and we will not allow ministers to destroy, through cuts and privatisation, what has taken generations to build." The Department of Health responded that there was "absolutely no government policy to privatise NHS services".
Drug policies.
Views on drug legality and policing vary greatly within the conservative party. Some Conservative politicians such as Alan Duncan take the libertarian approach that individual freedom and economic freedom of industry and trade should be respected. Other Conservative politicians, despite being economically liberal, are in favour of full prohibition of the ownership and trade of many drugs. Other Conservatives are in the middle ground, favouring stances such as looser regulation and decriminalisation of some drugs. Legalisation of cannabis for medical uses is favoured by some Conservative politicians, including Boris Johnson.
Education policy.
In education, the Conservatives have pledged to review the National Curriculum, and introduce the English Baccalaureate. The restoration of discipline was also highlighted, as they want it to be easier for pupils to be searched for contraband items, the granting of anonymity to teachers accused by pupils, and the banning of expelled pupils being returned to schools via appeal panels.
In Higher education, the Conservatives have increased tuition fees to £9,000 per year, however have ensured that this will not be paid by anyone until they are earning over £21,000, and that those who "fail" their studies, will not pay anything at all. The Scottish Conservatives also support the re-introduction of tuition fees in Scotland.
Jobs and welfare policy.
One of the Conservatives' key policy areas of 2010, was to reduce the number of people in the UK claiming state benefits, and increase the number of people in the workforce. They have stated that all those in the UK claiming incapacity benefit, will face a review of their cases. Until 1999, Conservatives opposed the creation of the National Minimum Wage, citing that they believed it would cost jobs, and businesses would be reticent to start business in the UK from fear of high labour costs. However the party have since pledged support. They support, and have implemented, the restoration of the link between pensions and earnings, and seek to raise retirement age from 65 to 66.
Energy/climate change policy.
David Cameron brought several 'green' issues to the forefront of his 2010 campaign. These included proposals designed to impose a tax on workplace car parking spaces, a halt to airport growth, a tax on cars with exceptionally poor petrol mileage, and restrictions on car advertising. Many of these policies were implemented in the Coalition - including the 'Green Deal'
Justice and crime policy.
In 2010, the Conservatives campaigned with the conviction to cut the perceived bureaucracy of the modern police force and pledged greater legal protection to people convicted of defending themselves against intruders. They also supported the creation of a UK Bill of Rights to replace the Human Rights Act 1998, but this was vetoed by their coalition partners the Liberal Democrats. Some Conservatives, particularly within the socially conservative Cornerstone Group, support the re-introduction of the death penalty; although the majority of party members oppose it.
European Union policy.
No subject has proved more divisive in the Conservative Party in recent history than the role of the United Kingdom within the European Union. Though the principal architect of the UK's entry into the European Communities (which became the European Union) was Conservative Prime Minister Edward Heath, and both Winston Churchill and Harold Macmillan favoured some form of European union, the bulk of contemporary Conservative opinion is opposed to closer economic and particularly political union with the EU. This is a noticeable shift in British politics, as in the 1960s and 1970s the Conservatives were more pro-Europe than the Labour Party. Divisions on Europe came to the fore under the premiership of Margaret Thatcher (1979–1990) and were cited by several ministers resigning, including Geoffrey Howe, the Deputy Prime Minister, whose resignation triggered the challenge that ended Thatcher's leadership. Under Thatcher's successor, John Major (1990–1997), the slow process of integration within the EU forced party tensions to the surface. A core of Eurosceptic MPs under Major used the small Conservative majority in Parliament to oppose Government policy on the Maastricht Treaty. By doing so they undermined Major's ability to govern.
In recent years the Conservative Party has become more clearly Eurosceptic, as the Labour Government has found itself unwilling to make a positive case for further integration, and Eurosceptic or pro-withdrawal parties such as the United Kingdom Independence Party have made showings in UK elections. But under current EU practices, the degree to which a Conservative Government could implement policy change regarding the EU would depend directly on the willingness of other EU member states to agree to such policies.
In 2009 the Conservative Party actively campaigned against the Lisbon Treaty, which it believes would give away too much sovereignty to Brussels. Shadow Foreign Secretary William Hague stated that, should the Treaty be in force by the time of an incoming Conservative government, he would "not let matters rest there". However, on 14 June 2009 the shadow Business Secretary, Kenneth Clarke, said in an interview to the BBC that the Conservative party would not reopen negotiations on the Lisbon Treaty if the Irish backed it in a new referendum, which they did on 2 October 2009.
If a majority Conservative government is elected for the 2015-2020 parliamentary term, they have pledged an in-out referendum on membership of the European Union after renegotiation. Current proposals have this referendum taking place in 2017.
Union policy.
The Conservatives staunchly support the maintenance of the United Kingdom, and oppose the independence of any of the countries of the United Kingdom: England, Scotland, Wales or Northern Ireland from it. They have had a mixed history on support for Scottish, Welsh and Northern Irish devolution.
In 1968, Edward Heath issued his 'Perth declaration', in support of a Scottish assembly, in the wake of growing nationalism. However, the cause went unanswered during his turbulent premiership, and under Margaret Thatcher and John Major's leadership, the Conservatives vehemently opposed devolution, and campaigned against it in the 1997 devolution referendum. Following the Scottish Parliament's establishment in 1999, they have vowed to support its continued existence, and along with Labour and the Liberal Democrats, they supported the Scotland Bill (2011), granting further devolution of power. They campaigned alongside Labour and the Liberal Democrats against full Scottish Independence in the 2014 Scottish Independence referendum. 
In Wales, the Conservatives campaigned against devolution in the 1997 referendum, however likewise as with Scotland, they have vowed to maintain the Welsh Assembly's continued existence, and in 2011 supported the further devolution of power.
In Northern Ireland, the Conservatives suspended the parliament in 1973 in the wake of the growing Troubles, and made unsuccessful attempts to re-establish it in the same year, and in 1982. They supported the Belfast Agreement negotiated by the Blair government in 1998, and in 2009, negotiated an electoral pact with the declining Ulster Unionist Party, whom it had previously been allied to before 1973.
The party opposed Labour's attempts to devolve power to the northern regions of England in 2004. They declared support for a commission into the West Lothian Question, as to whether or not only English MPs should be able to vote on issues solely affecting English matters following the Scottish Independence Referendum.
The British Constitution.
Traditionally the Conservative Party have been defenders of Britain's unwritten constitution and system of government. The party opposed many of Tony Blair's reforms such as the removal of the hereditary peers, the incorporation of the European Convention on Human Rights into British law, and the 2009 creation of the Supreme Court of the United Kingdom, a function formerly carried out by the House of Lords. Until 2001 most members of the party were against an elected House of Lords; however opinion was later split, shown in the vote on the House of Lords Reform Bill 2012, when 80 backbenchers voted for an 80% elected upper chamber and 110 did not. There was also a split on whether to introduce a British Bill of Rights which would replace the Human Rights Act 1998; David Cameron expressed support, but Ken Clarke described it as "xenophobic and legal nonsense".
Organisation.
Party structure.
In the organisation of the Conservative Party, constituency associations dominate the election of party leaders and the selection of local candidates (although some associations have organised open parliamentary primaries), while the Conservative Campaign Headquarters (CCHQ) leads financing, organisation of elections and drafting of policy. The leader of the parliamentary party forms policy in consultation with his cabinet and administration. This decentralised structure is unusual.
The Conservative Party Board is the party's ultimate decision making body, responsible for all operational matters (including fundraising, membership and candidates) and is made up of representatives from each (voluntary, political and professional) section of the Party. The Party Board meets about once a month and works closely with CCHQ, elected representatives and the voluntary membership mainly through a number of management sub-committees (such as membership, candidates and conferences).
Membership.
The Conservative Party has a membership of paid-up supporters, which, as of September 2014[ [update]], is 150,000. Membership peaked in the mid-1950s at approximately 3 million, before declining steadily through the second half of the 20th century. Despite an initial boost shortly after David Cameron's election as leader in December 2005, membership resumed its decline in 2006 to a lower level than when he was elected. In 2010, the Conservative Party had about 177,000 members according to activist Tim Montgomerie, and in 2013 membership was estimated by the party itself at 134,000. The membership fee for the Conservative Party is £25, or £5 if the member is under the age of 23. From April 2013 people could join Team2015 without being Party members, and take part in political campaigning for the party in the 2015 general election.
Conservative Future.
The Conservative Party maintains a youth wing for members under 30 called Conservative Future. Conservative Future is the largest such youth wing in the United Kingdom, with approximately 20,000 members. It has branches at both universities and at parliamentary constituency level. This reflects Conservative Future's origin as a merger of the Young Conservatives, Conservative Collegiate Forum, and the National Association of Conservative Graduates, brought about in 1998. Young members in Scotland belong to an independent organisation, called Conservative Future Scotland.
Funding.
In the first decade of the 21st century, half the party's funding came from a cluster of just fifty "donor groups", and a third of it from only fifteen. In the year after the 2010 general election, half the Tories' funding came from the financial sector.
In 2004, according to accounts filed with the Electoral Commission, the party had an income of about £20 million and expenditures of about £26 million.
For 2013, the Conservative Party had an income of £25.4 million, of which £749,000 came from membership subscriptions.
International organisations.
The Conservative Party is affiliated to — and plays a leading part in — a number of international organisations. As a global level, the Conservatives are a member of the International Democrat Union, which unites centre-right parties and its European subdivision, the European Democrat Union.
As a European level, the Conservatives are members of the Alliance of European Conservatives and Reformists (AECR), which unites centre-right parties in opposition to a federal European Union. In the European Parliament, the Conservative Party's MEPs sit in the European Conservatives and Reformists (ECR) group, which is affiliated to the AECR. Party leader David Cameron pushed the foundation of the ECR, which was launched in 2009, along with the Czech Civic Democratic Party and the Polish Law and Justice, before which the Conservative Party's MEPs sat in the European Democrats, which had become a subgroup of the European People's Party in the 1990s. Since the 2014 European election, the ECR group has been the third-largest group, with the largest members being the Conservatives (nineteen MEPs), Law and Justice (eighteen MEPs), the Alternative for Germany (seven MEPs), and the Danish People's Party and New Flemish Alliance (four MEPs each).
As of June 2009, Cameron required a further four partners apart from the Polish and Czech supports to qualify for official fraction status in the parliament; the rules state that a caucus needs at least 25 MEPs from at least seven of the 27 EU member states. In forming the caucus, Cameron is reportedly breaking with two decades of co-operation by the UK's Conservative Party with the mainstream European Christian Democrats and conservatives in the European parliament, the European People's Party (EPP) on the grounds that it is dominated by European federalists and supporters of the Lisbon treaty, which is opposed by the Tories. EPP leader Wilfried Martens, former prime minister of Belgium, stated "Cameron's campaign has been to take his party back to the centre in every policy area with one major exception: Europe. [...] I can't understand his tactics. Merkel and Sarkozy will never accept his Euroscepticism."
Party factions.
The Conservative Party has a variety of internal factions or ideologies, including Cameronism, One-nation conservatism, Social conservatism, Thatcherism, Neoconservatism, Hard euroscepticism, Pro-Europeanism, Localism and Green conservatism.
One-nation Conservatives.
One-nation conservatism was the party's dominant ideology in the 20th century until the rise of Thatcherism in the 1970s, and included in its ranks Conservative Prime Ministers such as Stanley Baldwin, Harold Macmillan and Edward Heath. The name itself comes from a famous phrase of Disraeli. The basis of One-Nation Conservatism is a belief in social cohesion, and its adherents support social institutions that maintain harmony between different interest groups, classes, and—more recently—different races or religions. These institutions have typically included the welfare state, the BBC, and local government. Some are also supporters of the European Union, perhaps stemming from an extension of the cohesion principle to the international level, though others are strongly against the EU (such as Sir Peter Tapsell). Prominent One Nation Conservatives in the contemporary party include Kenneth Clarke, Malcolm Rifkind and Damian Green; they are often associated with the Tory Reform Group and the Bow Group. One Nation Conservatives often invoke Edmund Burke and his emphasis on civil society ("little platoons") as the foundations of society, as well as his opposition to radical politics of all types. Ideologically, One Nation Conservatism identifies itself with a broad liberal conservative stance. The 'Red Tory' theory of Phillip Blond is a strand of the 'One Nation' school of thought. Prominent 'Red Tories' include Iain Duncan Smith and Eric Pickles in the Cabinet and Jesse Norman on the backbenches.
Free-market Conservatives.
The second main grouping in the Conservative party is the "free-market wing" of economic liberals who achieved dominance after the election of Margaret Thatcher as party leader in 1975. Their goal was to reduce the role of the government in the economy and to this end they supported cuts in direct taxation, the privatisation of nationalised industries and a reduction in the size and scope of the welfare state. Supporters of the "free-market wing" have been labelled as "Thatcherites". The group has disparate views of social policy: Thatcher herself was socially conservative and a practising Anglican but the free-market wing in the Conservative Party harbour a range of social opinions from the civil libertarian views of Michael Portillo, Daniel Hannan, and David Davis to the traditional conservatism of former party leaders William Hague and Iain Duncan Smith. The Thatcherite wing is also associated with the concept of a "classless society."
Most free-marketeers are also Eurosceptic, perceiving most EU regulations as interference in the free market and/or a threat to British sovereignty. EU centralisation also conflicts with the localist ideals that have grown in prominence within the party in recent years. Rare Thatcherite Europhiles include Leon Brittan. Many take inspiration from Thatcher's Bruges speech in 1988, in which she declared that "we have not successfully rolled back the frontiers of the state in Britain only to see them reimposed at a European level". A number of free-market Conservatives have signed the Better Off Out pledge to leave the EU. Thatcherites and economic liberals in the party also tend to be Atlanticist, identifying strongly with the founding principles of the United States. This was demonstrated with the close friendship between Margaret Thatcher and US President Ronald Reagan.
Thatcher herself claimed philosophical inspiration from the works of Burke and Friedrich Hayek for her defence of liberal economics. Groups associated with this tradition include the No Turning Back Group and Conservative Way Forward, whilst Enoch Powell and Sir Keith Joseph are usually cited as early influences in the movement.
Traditionalist Conservatives.
This socially conservative right-wing grouping is currently associated with the Cornerstone Group (or Faith, Family, Flag), and is the third main tradition within the Conservative Party. The name stems from its support for three British social institutions (though the Church is an English institution): the Church of England, the unitary British state and the family. To this end, they emphasise the country's Anglican heritage, oppose any transfer of power away from the United Kingdom—either downwards to the nations and regions or upwards to the European Union—and seek to place greater emphasis on traditional family structures to repair what they see as a broken society in the UK. They are strong advocates of marriage and believe the Conservative Party should back the institution with tax breaks and have opposed Labour's alleged assault on both traditional family structures and fatherhood. Most oppose high levels of immigration and support the lowering of the current 24 week abortion limit. Some members in the past have expressed support for capital punishment. Prominent MPs from this wing of the party include Andrew Rosindell, Nadine Dorries and Edward Leigh—the latter a prominent Roman Catholic, notable in a faction marked out by its support for the established Church of England. The conservative English philosopher Roger Scruton is a representative of the intellectual wing of the Cornerstone group: his writings rarely touch on economics and instead focus on conservative perspectives concerning political, social, cultural and moral issues.
Relationships between the factions.
Sometimes two groupings have united to oppose the third. Both Thatcherite and Traditionalist Conservatives rebelled over Europe (and in particular Maastricht) during John Major's premiership; and Traditionalist and One Nation MPs united to inflict Margaret Thatcher's only major defeat in Parliament, over Sunday trading.
Not all Conservative MPs can be easily placed within one of the above groupings. For example, John Major was the ostensibly "Thatcherite" candidate during the 1990 leadership election, but he consistently promoted One-Nation Conservatives to the higher reaches of his cabinet during his time as Prime Minister. These included Kenneth Clarke as Chancellor of the Exchequer and Michael Heseltine as Deputy Prime Minister.
Electoral performance.
This chart shows the electoral performance of the Conservative Party in general elections since 1835.

</doc>
<doc id="32117" url="http://en.wikipedia.org/wiki?curid=32117" title="Upper Peninsula of Michigan">
Upper Peninsula of Michigan

The Upper Peninsula of Michigan is the northern of the two major land masses that make up the U.S. state of Michigan. It is commonly referred to as the Upper Peninsula (U.P.) and Upper Michigan. It is also known colloquially as the land "above the Bridge" linking the two peninsulas. The peninsula is bounded on the north by Lake Superior, on the east by the St. Marys River, on the southeast by Lake Michigan and Lake Huron, and on the southwest by Wisconsin.
The Upper Peninsula contains 29% of the land area of Michigan but just 3% of its total population. Residents are frequently called Yoopers (derived from "U.P.-ers") and have a strong regional identity. Large numbers of French Canadian, Finnish, Swedish, Cornish, and Italian immigrants came to the Upper Peninsula, especially the Keweenaw Peninsula, to work in the area's mines and lumber industry. The peninsula includes the only counties in the United States where a plurality of residents claim Finnish ancestry.
Ordered by size, the peninsula's largest cities are Marquette, Sault Ste. Marie, Escanaba, Menominee, Houghton, and Iron Mountain. The land and climate are not very suitable for agriculture because of the long harsh winters. The economy has been based on logging, mining, and tourism. Most mines have closed since the "golden age" from 1890 to 1920. The land is heavily forested and logging remains a major industry .
History.
The first known inhabitants of the Upper Peninsula were tribes speaking Algonquian languages. They arrived roughly around A.D. 800 and subsisted chiefly from fishing. Early tribes included the Menominee, Nocquet, and the Mishinimaki. Étienne Brûlé of France was probably the first European to visit the peninsula, crossing the St. Marys River around 1620 in search of a route to the Far East.
French colonists laid claim to the land in the 17th century, establishing missions and fur trading posts such as Sault Ste. Marie and St. Ignace. Following the end of the French and Indian War (part of the Seven Years' War) in 1763, the territory was ceded to Great Britain. Sault Ste Marie, Michigan is the oldest European settlement in Michigan and the site of Native American settlements for centuries.
American Indian tribes formerly allied with the French were dissatisfied with the British occupation, which brought new territorial policies. Whereas the French cultivated alliances among the Indians, the British postwar approach was to treat the tribes as conquered peoples. In 1763, tribes united in Pontiac's Rebellion to try to drive the British from the area. American Indians captured Fort Michilimackinac, near present-day Mackinaw City, Michigan, then the principal fort of the British in the Michilimackinac region, as well as others and killed hundreds of British. In 1764, they began negotiations with the British which resulted in temporary peace and changes in objectionable British policies.
Although the Upper Peninsula nominally became United States territory with the 1783 Treaty of Paris, the British did not give up control until 1797 under terms of the Jay Treaty. As an American territory, the Upper Peninsula was still dominated by the fur trade. John Jacob Astor founded the American Fur Company on Mackinac Island in 1808; however, the industry began to decline in the 1830s as beaver and other game were overhunted.
When the Michigan Territory was first established in 1805, it included only the Lower Peninsula and the eastern portion of the Upper Peninsula. In 1819, the territory was expanded to include the remainder of the Upper Peninsula, all of Wisconsin, and part of Minnesota (previously included in the Indiana and Illinois Territories). When Michigan was preparing for statehood in the 1830s, the boundaries proposed corresponded to the original territorial boundaries, with some proposals even leaving the Upper Peninsula out entirely. Meanwhile, the territory was involved in a border dispute with the state of Ohio in a conflict known as the Toledo War.
The people of Michigan approved a constitution in May 1835 and elected state officials in late autumn 1835. Although the state government was not yet recognized by the United States Congress, the territorial government effectively ceased to exist. A constitutional convention of the state legislature refused a compromise to accept the full Upper Peninsula in exchange for ceding the Toledo Strip to Ohio. A second convention, hastily convened by Governor Stevens Thomson Mason, consisting primarily of Mason supporters, agreed in December 1836 to accept the U.P. in exchange for the Toledo Strip.
In January 1837, the U.S. Congress admitted Michigan as a state of the Union. At the time, Michigan was considered the losing party in the compromise. The land in the Upper Peninsula was described in a federal report as a "sterile region on the shores of Lake Superior destined by soil and climate to remain forever a wilderness."
This belief changed when rich mineral deposits (primarily copper and iron) were discovered in the 1840s. The Upper Peninsula's mines produced more mineral wealth than the California Gold Rush, especially after shipping was improved by the opening of the Soo Locks in 1855 and docks in Marquette in 1859. The Upper Peninsula supplied 90% of America's copper by the 1860s. It was the largest supplier of iron ore by the 1890s, and production continued to a peak in the 1920s, but sharply declined shortly afterward. The last copper mine closed in 1995, although the majority of mines had closed decades before. Some iron mining continues near Marquette. A copper sulfate mine opened in 2014.
Thousands of Americans and immigrants moved to the area during the mining boom, prompting the federal government to create Fort Wilkins near Copper Harbor to maintain order. The first wave were the Cornish from England, with centuries of mining experience; followed by Irish, Germans, and French Canadians. During the 1890s, Finnish immigrants began settling there in large numbers, forming the population plurality in the North-Western half of the peninsula. In the early 20th century, 75% of the population was foreign-born.
From 1861 to 1865, 90,000 Michigan men fought in the American Civil War, including 1,209 from the Upper Peninsula. Houghton County contributed 460 soldiers, while Marquette County, Michigan sent 265.
Geography.
The Upper Peninsula contains 16377 sqmi, about 29 percent of the land area of the state (exclusive of territorial waters, which constitute about 40% of Michigan's total jurisdictional area). The maximum east–west distance in the Upper Peninsula is about 320 mi, and the maximum north–south distance is about 125 mi. It is bounded on the north by Lake Superior, on the east by St. Mary's River, on the south by Lake Michigan and Lake Huron, and on the west by Wisconsin and (counting the water border on Lake Superior) by Minnesota. It has about 1,700 mi of continuous shoreline with the Great Lakes. There are about 4,300 inland lakes, the largest of which is Lake Gogebic, and 12,000 mi of streams.
The peninsula is divided between the flat, swampy areas in the east, part of the Great Lakes Plain, and the steeper, more rugged western half, called the Superior Upland, part of the Canadian Shield. The rock in the western portion is the result of volcanic eruptions and is estimated to be at least 3.5 billion years old (much older than the eastern portion) and contains the region's ore resources. Banded-iron formations were deposited million years ago; this is the Marquette Range Supergroup. A considerable amount of bedrock is visible. Mount Arvon, the highest point in Michigan, is found in the region, as well as the Porcupine and Huron mountains. All of the higher areas are the remnants of ancient peaks, worn down over millions of years by erosion and glaciers.
The Keweenaw Peninsula is the northernmost part of the peninsula. It projects into Lake Superior and was the site of the first copper boom in the United States, part of a larger region of the peninsula called the Copper Country. Copper Island is its northernmost section.
About one third of the peninsula is government-owned recreational forest land today, including the Ottawa National Forest and Hiawatha National Forest. Although heavily logged in the 19th century, the majority of the land was forested with mature trees by the 1970s.
Wildlife.
The Upper Peninsula contains a large variety of wildlife. Some of the mammals found in the U.P. include shrews, moles, mice, white tailed deer, moose, black bears, cougar, gray and red foxes, wolves, river otters, martens, fishers, muskrats, bobcats, coyotes, snowshoe hares, cotton-tail rabbits, chipmunks, squirrels, raccoons, opossum and bats. There is a large variety of birds, including hawks, osprey, owls, gulls, hummingbirds, chickadees, robins, woodpeckers, warblers, and bald eagles. In terms of reptiles and amphibians, the U.P. has common garter snakes, red bellied snakes, pine snakes, northern water snakes, brown snakes, eastern garter snakes, eastern fox snakes, eastern ribbon back snakes, green snakes, northern ringneck snakes, Eastern Milk Snakes (Mackinac and Marquette counties) and Eastern Hognose snakes (Menominee County only), plus snapping turtles, wood turtles, and painted turtles (the state reptile), green frogs, bullfrogs, northern leopard frogs, and salamanders. Lakes and rivers contain many fish like walleye, muskie, northern pike, trout, salmon, bullhead catfish, and bass. Invasive species like the alewife and sea lamprey can be found in the Great Lakes. The U.P. also contains many shellfish, such as clams, aquatic snails, and crayfish. The American Bird Conservancy and the National Audubon Society have designated several locations as internationally Important Bird Areas.
There is significant controversy over the presence of Eastern Cougars in the U.P. Historically, the last of the species, or subspecies, was extirpated near Newberry in 1906, although there have been sightings of the creatures over the years since. These reports increased in number over the first decade of the 21st century. The Michigan Department of Natural Resources and Environment (DNRE) formed a four-person team to investigate sightings in the state. The biologists with the DNRE currently do not believe that there is a breeding population anywhere in the state, rather that the sighted animals are visitors to the state. As late as January 2007, the DNRE's official position was that no cougars lived in Michigan. Several residents in the state disagree with both current and previous positions on the part of the DNRE. Researchers at Central Michigan University and the Michigan Wildlife Conservancy in 2006 published the findings of a study using DNA analysis of fecal samples taken in the Upper and Lower peninsulas that showed the presence of cougars at the time. These results were disputed in a second journal article in 2007 by other researchers from Eastern Michigan University and the U.S. Forest Service. A citizen's group, the Michigan Citizens for Cougar Recognition (MCCR), independently tracked sightings and in 2009 listed Delta County as the location with the greatest number of reports in the state. The DNRE verified five sets of tracks and two trail camera photos in Delta, Chippewa, Marquette, and Menominee counties since 2008. DNRE officials acknowledge that there are cougars in the UP, but not elsewhere in the state. Critics of the DNRE's position on the species, including the founder of the MCCR, say that the department is attempting to "avoid paying for a cougar management program".
There are also many invasive species that are primarily brought in the ballast water of foreign ships, usually from the ocean bordering Northeastern Asia. This water is dumped directly into the Great Lakes, depositing a variety of fresh and salt water fish and invertebrates, most notably the zebra mussel, "Dreissena polymorpha". There are also many plant species that have been transported to the Great Lakes, including Purple Loosestrife "Lythrum salicaria" and "Phragmites australis", both of which are considered to be a threat to native hydrophyte wetland plants.
The Emerald ash borer was first reported in the U.P. at Brimley State Park, and is considered to be a serious ecological threat to the habitat and economy.
Climate.
The Upper Peninsula has a humid continental climate ("Dfb" in the Köppen climate classification system). The Great Lakes have a great effect on most of the peninsula. Winters tend to be long, cold, and snowy for most of the peninsula, and because of its northern latitude, the daylight hours are short— around 8 hours between sunrise and sunset in the winter. Lake Superior has the greatest effect on the area, especially the northern and western parts. Lake-effect snow causes many areas to get in excess of 100 - of snow per year—especially in the Keweenaw Peninsula and Gogebic County, and to a lesser extent Baraga, Marquette and Alger counties, making the western U.P. a prominent part of the midwestern snow belt.
Records of 390 in of snow or more have been set in many communities in this area. The Keweenaw Peninsula averages more snowfall than almost anywhere in the United States—more than anywhere east of the Mississippi River and the most of all non-mountainous regions of the continental United States. Because of the howling storms across Lake Superior, which cause dramatic amounts of precipitation, it has been said that the lake-effect snow makes the Keweenaw Peninsula the snowiest place east of the Rockies. Herman averages 236 in of snow every year. Lake-effect snow can cause blinding whiteouts in just minutes, and some storms can last for days. Hancock is found frequently on lists of the Snowiest Cities in America.
The banana belt along the Wisconsin border has a more continental climate since most of its weather does not arrive from the lakes. Summers tend to be warmer and winter nights much colder. Coastal communities have temperatures tempered by the Great Lakes. In summer, it might be 10 °F (5 °C) cooler at lakeside than it is inland, and the opposite effect is seen in winter. The area of the Upper Peninsula north of Green Bay though Menominee and Escanaba (and extending west to Iron River) does not have the extreme weather and precipitation found to the north.
Time zones.
Like the entire Lower Peninsula of Michigan, most of the Upper Peninsula observes Eastern Time. However, the four counties bordering Wisconsin are in the Central Time zone.
In 1967, when the Uniform Time Act came into effect, the Upper Peninsula went under year-round CST, with no daylight saving time. In 1973, the majority of the peninsula switched to Eastern Time; only the four western border counties of Gogebic, Iron, Dickinson, and Menominee continue to observe Central Time.
Government.
There are 15 counties in the Upper Peninsula (see map).
State prisons are located in Baraga, Marquette, Munising, Newberry, Marenisco and Kincheloe.
Politics.
Historically, the Upper Peninsula has tended to vote for the United States' Democratic Party thanks to its legacy of mining and historically high union membership. However, as Democrats have shifted toward social liberalism and as union strength in the peninsula has declined, the region has become progressively less receptive to the Democratic party, and has alternately swung toward either party in recent years. Split-ticket voting has become a common practice in the peninsula. In 2012, for example, Democratic U.S. Senator Debbie Stabenow carried every county in the peninsula in her successful 2012 re-election attempt; but in contrast, Republican presidential candidate Mitt Romney carried all but two counties in the concurrent presidential election.
The breakdown of the 2012 presidential election by county was as follows:
All counties in the U.P. are part of Michigan's 1st congressional district. Dan Benishek, a Republican, has been the U.S. Representative for this district since January 2011.
In Michigan's 2010 gubernatorial election Republican Rick Snyder carried every U.P. county but one, Gogebic, on his way to victory over his Democratic opponent, Virg Bernero.
Proposed statehood.
Superior is the name of a longstanding 51st state proposal for the secession of the Upper Peninsula from the rest of Michigan, potentially with various portions of northern Wisconsin. Named after Lake Superior, the idea has gained serious attention at times. Because stronger connections to the rest of the state exist since completion of the Mackinac Bridge, the proposal's future is vague. Several prominent legislators, including local politician Dominic Jacobetti, attempted to gain passage of the bill in the 1970s, with little traction.
Demographics.
The Upper Peninsula remains a predominantly rural region. As of the 2010 census, the region had a population of 311,361.
According to the 2010 census, only 103,211 people live in the 12 towns of at least 4,000 people, covering 96.5 square miles (250 km²). Only 116,548 people live in the 18 towns and villages of at least 2,000 people, which cover 108.5 square miles (320.4 km²)—less than 1% of the peninsula's land area.
The Upper Peninsula is one of the few regions in the United States that experience population decline. Although not every county in the Upper Peninsula has a declining population, this phenomenon does have a significant impact on the social and economic aspects of many of its communities and citizens. Some of the contributing factors to the Upper Peninsula's shifts in population are the boom and bust cycles of the timber and mining industries, as well as the severity of its winters. Some areas in the Upper Peninsula are more prone to declining population than others, with the six westernmost counties being the most dramatic, going from a 1920 level of 153,674 people (representing 59% of the total population of the entire Upper Peninsula) to a 2010 census level of 82,668 persons (dropping to 26.5% of the total Upper Peninsula's population). It is quite common to see abandoned buildings and ruins in this area; there is even a number of ghost towns that are slowly succumbing to the ubiquitous forest.
Generally speaking, the population of the Upper Peninsula grew throughout the 19th century, and then leveled off and even experienced decline during the 20th century, as can readily be seen in the tables below. The data for these tables is from the U.S. Census; A "↑" indicates an increase in population from the previous census, and a "↓" indicates a decrease in population from the previous census.
Economy.
Industries.
The Upper Peninsula is rich in mineral deposits including iron, copper, nickel and silver. Small amounts of gold have also been discovered and mined. In the 19th century, mining dominated the economy, and the U.P. became home to many isolated company towns. For many years, mines in the Keweenaw Peninsula were the world's largest producers of copper (see Copper mining in Michigan). The mines began declining as early as 1913, with most closing temporarily during the Great Depression. Mines reopened during World War II, but almost all quickly closed after the war ended. The last copper mine in the Copper Country was the White Pine mine, which closed in 1995.
From approximately 1870 to 1915, about thirty-two quarries mined Jacobsville Sandstone in the Upper Peninsula, particularly near Marquette and the town of Jacobsville. The sandstone was used in many buildings, both locally and around the United States.
Ever since logging of white pine began in the 1880s, timber has been an important industry. However, the stands of hemlock and hardwood went under-exploited until the mid-twentieth century as selection cutting was practiced in the western reaches of the forest. Because of the highly seasonal climate and the short growing season, agriculture is limited in the Upper Peninsula, though potatoes, strawberries and a few other small fruits are grown.
Tourism has become the main industry in recent decades. In 2005, ShermanTravel, LLC listed the Upper Peninsula as No. 10 in its assessment of all travel destinations worldwide. The article was republished in April 2006 by MSN.com. The peninsula has extensive coastline on the Great Lakes, large tracts of state and national forests, cedar swamps, more than 150 waterfalls, and low population densities. Because of the camping, boating, fishing, snowmobiling, hunting, and hiking opportunities, many Lower Peninsula and Wisconsin families spend their vacations in the U.P. Tourists also go there from Detroit, Chicago, Milwaukee and other metropolitan areas.
Casinos.
American Indian casinos contribute to the tourist attractions and are popular in the U.P. Originally the casinos were simple, one-room affairs. Some of the casinos are now quite elaborate and are being developed as part of resort and conference facilities, including features such as golf courses, pool and spa, dining, and rooms to accommodate guests.
Transportation.
The Upper Peninsula is separated from the Lower by the Straits of Mackinac, five miles (8 km) across at the narrowest, and is connected to it by the Mackinac Bridge at St. Ignace, one of the longest suspension bridges in the world. Until the bridge was completed in 1957, travel between the two peninsulas was difficult and slow (and sometimes even impossible during winter months). In 1881, the Mackinac Transportation Company was established by three railroads, the Michigan Central Railroad, the Grand Rapids and Indiana Railroad, and the Detroit, Mackinac and Marquette Railroad, to operate a railroad car ferry across the Straits. Beginning in 1923, the State of Michigan operated automobile ferries between the two peninsulas. At the busiest times of year the wait was several hours long. In winter, travel was possible over the ice only after the straits had solidly frozen.
Highways.
State Trunkline Highways.
Of the many "M-" prefixed trunklines crisscrossing the U.P., the four longest (in order of length) are,
Airports.
There are 43 airports in the Upper Peninsula. Of these, six airports have commercial passenger service: Gogebic-Iron County Airport north of Ironwood, Houghton County Memorial Airport southwest of Calumet, Ford Airport west of Iron Mountain, Sawyer International Airport south of Marquette, Delta County Airport in Escanaba, and Chippewa County International Airport south of Sault Ste. Marie. There are 19 other public use airports with a hard surface runway. These are used for general aviation and charter. Notably, Mackinac Island, Beaver Island, and Drummond Island are all accessible by airports. There are five public access airports with turf runways and thirteen airports for the private use of their owners. There is only one control tower in the Upper Peninsula, at Sawyer.
Ferries and bridges.
The Eastern Upper Peninsula Transportation Authority operates car ferries in its area. These include ferries for Sugar Island, Neebish Island, and Drummond Island. Three ferry companies run passenger ferries from St. Ignace to Mackinac Island.
The three major bridges in the Upper Peninsula are:
Bus systems.
Despite its rural character, there are public buses in several counties of the Upper Peninsula.
Education.
The Upper Peninsula of Michigan has three state universities (Lake Superior State University in Sault Ste. Marie, Michigan Technological University in Houghton, and Northern Michigan University in Marquette), one private university (Finlandia University located in Hancock, Michigan, on the Keweenaw Peninsula), and five community colleges (Bay Mills Community College in Brimley, Bay de Noc Community College in Escanaba and Iron Mountain, Gogebic Community College in Ironwood, and Keweenaw Bay Ojibwa Community College in Baraga).
Culture.
Early settlers included multiple waves of people from Nordic countries. There are still Swedish- and Finnish-speaking communities in many areas of the Upper Peninsula today. People of Finnish ancestry make up 16% of the peninsula's population. The U.P. is home to the highest concentration of Finns outside Europe and the only counties of the United States where a plurality of residents claim Finnish ancestry. The Finnish sauna and the concept of sisu have been adopted widely by residents of the Upper Peninsula. The television program "Finland Calling", filmed at Marquette station WLUC-TV, is the only Finnish-language television broadcast in the United States; it has aired since March 25, 1962. Finlandia University, America's only college with Finnish roots, is located in Hancock. Street signs in Hancock appear in English and Finnish to celebrate this heritage.
Other sizeable ethnic communities in the Upper Peninsula include French-Canadian, German, Cornish, Italian, and American Indian ancestry.
Upper Peninsula natives speak a dialect influenced by Scandinavian and French-Canadian speech. A popular bumper sticker, a parody of the "Say YES to Michigan" slogan promoted by state tourism officials, shows an outline of the Upper Peninsula and the slogan, "Say ya to da U.P., eh!" The dialect and culture are captured in many songs by Da Yoopers, a comedy music and skit troupe from Ishpeming, Michigan.
Throughout the Upper Peninsula there are newspapers, such as "The Daily News" of Iron Mountain, "The Menominee County Journal" of Stephenson, "The Daily Mining Gazette" of Houghton, "The Daily Press" of Escanaba, and the "Sault Ste. Marie Evening News" that serve the rest of the U.P. "The Mining Journal", based in Marquette, is the only daily newspaper that publishes a Sunday edition, which is distributed across the entire U.P. (the other six days are distributed in its local area only).
The Keweenaw peninsula is home to several ski areas. Mont Ripley, just outside of Houghton, is popular among students of Michigan Technological University (the university actually owns the mountain). Further up the peninsula in the small town of Lac La Belle is Mt. Bohemia. A skiing purist's resort, Bohemia is a self-proclaimed "experts only" mountain, and it does not groom its heavily gladed slopes. Other ski areas are Pine Mountain located in Iron Mountain, Norway Mountain in the town of the same name, and the Porcupine Mountains located in Ontonagon.
Regional identity.
Today, the Upper Peninsula is home to 299,184 people—only about 3% of the state's population— living in almost one-third of the state's land area. Residents are known as Yoopers (from "U.P.ers"), and many consider themselves Yoopers before they consider themselves Michiganders. (People living in the Lower Peninsula are commonly called "trolls" by Upper Peninsula residents, as they live "Under da Bridge".) This regionalism is not only a result of the physical separation of the two peninsulas, but also the history of the state.
Residents of the western Upper Peninsula take on some of the cultural identities of both Wisconsin and Michigan. In terms of sports fandom, residents may support Detroit professional teams or those of Wisconsin – particularly the Green Bay Packers. This is a result of both proximity and the broadcast and print media of the area. The four counties that border Wisconsin are also in the Central Time Zone, unlike the rest of Michigan, which is on Eastern time.
Cuisine.
The Upper Peninsula has a distinctive local cuisine. The pasty (pronounced "pass-tee"), a kind of meat turnover originally brought to the region by Cornish miners, is popular among locals and tourists alike. Pasty varieties include chicken, venison, pork, hamburger, and pizza.
Many restaurants serve potato sausage and "cudighi", a spicy Italian meat.
Finnish immigrants contributed "nisu", a cardamom-flavored sweet bread; "pannukakku", a variant on the pancake with a custard flavor; "viili" (sometimes spelled "fellia"), a stretchy, fermented Finnish milk; and "korppu", hard slices of toasted cinnamon bread, traditionally dipped in coffee. Some Finnish foods such as "juustoa" (squeaky cheese, essentially a cheese curd, like Leipäjuusto) and "sauna makkara" (a ring-bologna sausage) have become so ubiquitous in Upper Peninsula cuisine that they are now commonly found in most grocery stores and supermarkets.
Maple syrup is a highly prized local delicacy. Fresh Great Lakes fish, such as the lake trout, whitefish, and (in the spring) smelt are widely eaten. There is minimal concern about contamination of fish from Lake Superior waters. Smoked fish is also popular. Thimbleberry jam and chokecherry jelly is a treat.

</doc>
<doc id="32120" url="http://en.wikipedia.org/wiki?curid=32120" title="Universal (metaphysics)">
Universal (metaphysics)

In metaphysics, a universal is what particular things have in common, namely characteristics or qualities. In other words, universals are repeatable or recurrent entities that can be instantiated or exemplified by many particular things. For example, suppose there are two chairs in a room, each of which is green. These two chairs both share the quality of "being a chair," as well as greenness or the quality of being green. Metaphysicians call this quality that they share a "universal." There are three major kinds of qualities or characteristics: types or kinds (e.g. mammal), properties (e.g. short, strong), and relations (e.g. father of, next to). These are all different types of universal.
Paradigmatically, universals are "abstract" (e.g. humanity), whereas particulars are "concrete" (e.g. the person of Socrates). However, universals are not necessarily abstract and particulars are not necessarily concrete. For example, one might hold that numbers are particular yet abstract objects. Likewise, some philosophers, such as D.M. Armstrong, consider universals to be concrete.
Most do not consider classes to be universals, although some prominent philosophers do, such as John Bigelow.
Problem of universals.
"The problem of universals" is an ancient problem in metaphysics about whether universals exist. The problem arises from attempts to account for the phenomenon of similarity or attribute agreement among things. For example, live grass and Granny Smith apples are similar or agree in attribute, namely in having the attribute of greenness. The issue is how to account for this sort of agreement in attribute among things. 
There are many philosophical positions regarding universals. Taking "beauty" as an example, three positions are:
Taking a broader view, the main positions are generally considered to classifiable as: realism, nominalism, and idealism (sometimes simply called "anti-realism" with regard to universals). Realists posit the existence of independent, abstract universals to account for attribute agreement. Nominalists deny that universals exist, claiming that they are not necessary to explain attribute agreement. Conceptualists posit that universals exist only in the mind, or when conceptualized, denying the independent existence of universals. Complications which arise include the implications of language use and the complexity of relating language to ontology.
Particular.
A universal may have instances, known as its "particulars". For example, the type "dog" (or "doghood") is a universal, as are the property "red" (or "redness") and the relation "betweenness" (or "being between"). Any particular dog, red thing, or object that is between other things is not a universal, however, but is an "instance" of a universal. That is, a universal type ("doghood"), property ("redness"), or relation ("betweenness") "inheres" in a particular object (a specific dog, red thing, or object between other things).
Platonic Realism.
Platonic realism holds universals to be the referents of general terms, such as the "abstract", nonphysical, non-mental entities to which words like "sameness", "circularity", and "beauty" refer. Particulars are the referents of proper names, like "Phaedo," or of definite descriptions that identify single objects, like the phrase, "that bed over there". Other metaphysical theories may use the terminology of universals to describe physical entities. 
Plato's examples of what we might today call universals included mathematical and geometrical ideas such as a circle and natural numbers as universals. Plato's views on universals did, however, vary across several different discussions. In some cases, Plato spoke as if the perfect circle functioned as the form or blueprint for all copies and for the word definition of "circle". In other discussions, Plato describes particulars as "participating" in the associated universal.
Contemporary realists agree with the thesis that universals are multiply-exemplifiable entities. Examples include by D. M. Armstrong, Nicholas Wolterstorff, Reinhardt Grossmann, Michael Loux. I
Nominalism.
Nominalists hold that universals are not real mind-independent entities but either merely concepts (sometimes called "conceptualism") or merely names. Nominalists typically argue that properties are abstract particulars (like tropes) rather than universals. JP Moreland distinguishes between "extreme" and "moderate" nominalism. Examples of nominalists include medieval philosopher William of Ockham and contemporary philosophers W. V. O. Quine and Wilfred Sellars, D. C. Williams, and Keith Campbell. 
Ness-Ity-Hood Principle.
The Ness-Ity-Hood Principle is used mainly by English-speaking philosophers to generate convenient, concise names for universals or properties. According to the Ness-Ity-Hood Principle, a name for any universal may be formed that is distinctive, "of left-handers" may be formed by taking the predicate "left-handed" and adding "ness", which yields the name "left-handedness". The principle is most helpful in cases where there is not an established or standard name of the universal in ordinary English usage: What is the name of the universal distinctive of chairs? "Chair" in English is used not only as a subject (as in "The chair is broken"), but also as a predicate (as in "That is a chair"). So to generate a name for the universal distinctive of chairs, take the predicate "chair" and add "ness", which yields "chairness".

</doc>
<doc id="32121" url="http://en.wikipedia.org/wiki?curid=32121" title="University of Manchester Institute of Science and Technology">
University of Manchester Institute of Science and Technology

The University of Manchester Institute of Science and Technology (UMIST) was a university based in the centre of the city of Manchester in England. It specialised in technical and scientific subjects and was a major centre for research. On 1 October 2004, it was subsumed by the Victoria University of Manchester (commonly called the University of Manchester) to form a new entity also called The University of Manchester.
UMIST gained its Royal Charter in 1956 and became a fully autonomous university in 1993. Previously its degrees were awarded by the Victoria University of Manchester. The UMIST motto was "Scientia et Labore" (By Knowledge and Work).
Mechanics' Institute (1824–1882).
The foundation of UMIST can be traced to 1824 during the Industrial Revolution when a group of Manchester businessmen and industrialists met in a public house, the "Bridgewater Arms", to establish the "Mechanics' Institute in Manchester", where artisans could learn basic science, particularly mechanics and chemistry. Hundreds of such institutions were founded in towns and cities throughout the country and while many of the fine Victorian buildings built to house them remain, Manchester's alone survived as an independent institution serving some of its original educational aims throughout the 20th century.
The meeting, convened by George William Wood on 7 April 1824,
was attended by prominent members of the science and engineering community, including:
A committee was elected to realise the planned institution, including Wood, Fairbairn, Heywood, Roberts and John Davies and the Institute opened in 1825 with Heywood as chairman.
However, the Institute's intentions were paternal and no democratic control by its students was intended. In 1829, radical Rowland Detrosier led a breakaway group to form the New Mechanics' Institution in Poole Street, a move that had a serious effect on the recruitment and finances of the original institute. Subscriptions and memberships in 1830-31 were an all-time low and only the gradual opening of the board up to election by the members rectified the situation. Detrosier's break-away ultimately rejoined the Institute.
By 1840, the Institute was established with 1,000 subscribers and a library of some 5,500 books. However, the increased popularity had been somewhat at the cost of science education, more and more lectures on non-scientific subjects were occupying its programmes.
The Institute occupied a building on Cooper Street (near the present St Peter's Square) and later moved to its present site on David Street (later renamed Princess Street). This still stands and is a Grade II* listed building.
"The Tech" (1883–1917).
In 1883 secretary of the Institution John Henry Reynolds reorganised the Institution as a Technical School using the schemes and examinations of the City and Guilds of London Institute. A new building was begun in 1895 and opened by the Prime Minister Arthur Balfour in October 1902. On the site previously had been cheap crowded inner-city housing occupied by Irish immigrants.
This is the western end of what was until recently known as the UMIST Main Building, pictured above, a grade II listed building by Spalding and Cross with Renaissance motifs of Burmantofts terracotta. By this time the institution was called the "Manchester Municipal School of Technology" or fondly known as "The Tech". As a project of the Manchester City Council it includes in the decoration many portrayals of the city's coat of arms.
As befits its roots in the early chemical industry of the region the Tech had pioneered Chemical Engineering as an academic subject in Britain, indeed the lectures by George E. Davis in 1888 were highly influential in defining the discipline. Similarly in the 1920s it pioneered academic training in Management, with the formation of a Department of Industrial Administration funded by an endowment from asbestos magnate Sir Samuel Turner. But perhaps a more significant advance was the foundation in 1905 of a "Faculty of Technology", answerable academically to its 'younger sister' the Victoria University of Manchester and awarding BSc and MSc degrees, the beginnings of UMIST as a University and the first technology faculty in the country.
After the recent merger with Victoria University of Manchester the UMIST Main Building was renamed as the "Sackville St. Building".
Establishment as a university (1918–1993).
In 1918, the institution changed name again to "Manchester Municipal College of Technology". By 1949 over 8500 students were enrolled, however most still studying non-degree courses.
The appointment of B. V. Bowden (later Lord Bowden) in 1953 marked the beginning of a phase of expansion. During 1955 and 1956 the Manchester College of Science and Technology achieved independent university status under its own Royal Charter and became separately funded from the University Grants Committee.
By 1966 all non-degree courses were moved to the Manchester Polytechnic which is now known as Manchester Metropolitan University, and in 1966 the name finally changed to the University of Manchester Institute of Science and Technology on the initiative of Acting Principal Frank Morton. UMIST and the Victoria University of Manchester retained close ties for the second half of the 20th century, with UMIST students being awarded, or having the choice of, a University of Manchester degree until full autonomy.
It was in 1992 that Prof Harold Hankins the Principal of UMIST achieved its separate status as a degree-awarding university and thereby became its first Vice-Chancellor.
Until this time UMIST was the Faculty of Technology of the Victoria University of Manchester, an interesting situation because the University of Manchester held its own science and engineering courses. Although academically part of the University, UMIST was financially and administratively independent.
Congregation ceremonies were held at the University of Manchester on Oxford Road, but in 1991 the first congregation ceremony was held in the Great Hall at UMIST itself in the Sackville Street Building.
UMIST students were entitled to use the facilities of the Victoria University, including the John Rylands University Library at the Oxford Road site and sports facilities and social clubs organised by the students' unions. In fact, first year UMIST undergraduates were often placed into Manchester University halls of residence and vice versa.
Student life.
In the late 20th century, student life at UMIST centred on the Barnes Wallis Building, which was the home of the Students' Union (later known as the Students' Association) and Harry's Bar.
A prominent feature of the student calendar from the 1960s onwards was the Bogle Stroll. This was a 55-mile long sponsored walk for charity which was held annually during Rag Week. Each year, hundreds of students followed the circular route which started and finished at the UMIST campus. The tradition continues in The University of Manchester
Achievements and evolution.
During the last quarter of the 20th century UMIST established a reputation as a major research-based university, performing well in the government's Research Assessment Exercise in 2001, and was well placed in various league tables. UMIST has won four Queen's Prizes for Higher and Further Education, two Prince of Wales' Awards for Innovation and two Queen's Award for Export Achievement.
UMIST was instrumental in the founding of what is now the Museum of Science and Industry in Manchester. Famous alumni include Nobel Laureate in nuclear physics Sir John Cockcroft, aeroplane pioneer Sir Arthur Whitten Brown, and designer of the Lancaster bomber Roy Chadwick, while famous academics include mathematicians Louis Joel Mordell, Hanna Neumann, Lewis Fry Richardson and Robin Bullough, and the physicist Henry Lipson.
Other notable alumni include Margaret Beckett, a politician who in 2006 became Foreign Secretary.
The End of UMIST 2004.
UMIST, together with the Victoria University of Manchester ceased to exist on 1 October 2004, when they were combined in a new single University of Manchester. Terry Leahy, CEO of Tesco and alumnus was the last Chancellor of UMIST, and the Vice Chancellor was fittingly a chemical engineer, Prof John Garside.
The merged university undertook a massive expansion and a £350 million capital investment programme in new buildings. Some, such as the Alan Turing Building, house merged departments such as the School of Mathematics. The estates plan, published in 2007, indicates an intention to sell a number of former UMIST teaching buildings, including the Moffat Building, the Maths and Social Sciences Tower, the Morton Building and the Fairbairn Building, as well as formerly UMIST-owned halls of residence including Hardy Farm, Chandos Hall, Wright-Robinson Hall and Weston Hall. The original UMIST Main Building is not included in this list. Covenants restrict it to educational use. No plans have been announced for the sale of any former Victoria University of Manchester buildings. Unions and some ex-UMIST staff and students have reacted angrily to the potential sales.
In the estates strategy for 2010-2020 for the University of Manchester it is stated that essentially all of the former UMIST campus, described as the "area north of the Mancunian Way," is to be disposed of. Only the MIB, which was built in 2006, is exempted, whilst the fate of the former UMIST Main Building is left vague. The Faraday Building will be replaced by student accommodation and it is envisaged that the Engineering Schools will eventually be relocated to new buildings on the site of the present halls of residence in the Grosvenor Place area. This plan will, therefore, encompass the destruction of almost all of UMIST's physical legacy.
In March 2007, the press claimed that the merger had created a debt of £30 million, about 5% of the University's annual turnover, and that the University was aiming to tackle this debt by implementing 400 voluntary redundancies. The University and College Union accused the University of mismanagement and called for a halt to recruitment. Critics use these statistics to support the claim that it was not a merger of equals, that it was effectively a takeover of UMIST by Manchester University and that this was not in UMIST's best interests.
Alumni groups.
Until the late 1980s, UMIST's official alumni organisation was called the Manchester Technology Association, a name which was a relic of UMIST's past incarnation as 'The Tech'. The organisation's name was then updated to become the UMIST Association. It published a glossy magazine for UMIST graduates called "Mainstream".
In 2004, at the time of the university merger, the UMIST Association also merged with its equivalent organisation at the Victoria University of Manchester. This step was taken after minimal consultation with its membership. From that point on, there was no official association specifically for past UMIST students or staff. However, the growth of social networking websites has allowed the development of a number of unofficial UMIST alumni groups in cyberspace, particularly on Facebook. The UMIST Alumni group on LinkedIn has over 5,000 members and has a sub-group for each of UMIST's academic departments.
UMIST Campus.
UMIST moved to its present location just south of Manchester city centre at the end of the 19th century. The Main Building (now called the Sackville Street Building) was purpose-built between 1895 and 1902 by Spalding and Cross. Starting in 1927, plans were drawn up by the architects Bradshaw Gass & Hope for an extension which would approximately double the size of the original building. However, construction was delayed by the war and other factors, so that the extension was not fully completed until 1957.
In the 1960s the institution expanded rapidly to the south, growing from a single large building to an entire campus. Around a dozen modern buildings were constructed on the other side of the railway viaduct from the Main Building. The new edifices were designed by leading Manchester architects and were all built out of concrete. They included the Maths and Social Sciences Tower, the Faraday Building, the Renold Building, and the Barnes Wallis Building, the last two of which faced each other across a bowling green, which later became a landscaped garden.

</doc>
<doc id="32124" url="http://en.wikipedia.org/wiki?curid=32124" title="United Nations Convention to Combat Desertification">
United Nations Convention to Combat Desertification

The United Nations Convention to Combat Desertification in Those Countries Experiencing Serious Drought and/or Desertification, Particularly in Africa (UNCCD) is a Convention to combat desertification and mitigate the effects of drought through national action programs that incorporate long-term strategies supported by international cooperation and partnership arrangements.
The Convention, the only convention stemming from a direct recommendation of the Rio Conference's Agenda 21, was adopted in Paris, France on 17 June 1994 and entered into force in December 1996. It is the first and only internationally legally binding framework set up to address the problem of desertification. The Convention is based on the principles of participation, partnership and decentralization—the backbone of Good Governance and Sustainable Development. It has 196 parties, making it truly global in reach. In 2013, Canada became the first country to announce its intention to withdraw from the convention.
To help publicise the Convention, 2006 was declared "International Year of Deserts and Desertification" but debates have ensued regarding how effective the International Year was in practice.
States Parties.
The UNCCD has been ratified by 195 states plus the European Union. All member states of the UN are parties to convention. The convention does not apply to Aruba, Caribbean Netherlands, Curaçao and Sint Maarten (Kingdom of the Netherlands), or to Gibraltar, the Isle of Man, Guernsey, or Jersey (United Kingdom).
One ratifying state—Canada—has announced its denunciation the convention. The non-UN member states that have ratified the convention are the Cook Islands and Niue. The Holy See and the states with limited recognition are non-parties.
Secretariat.
The permanent Secretariat of the UNCCD was established during the first Conference of the parties (COP 1) held in Rome in 1997. It has been located in Bonn, Germany since January 1999, and moved from its first Bonn address in Haus Carstanjen to the new UN Campus in July 2006.
The functions of the secretariat are to make arrangements for sessions of the Conference of the Parties (COP) and its subsidiary bodies established under the Convention, and to provide them with services as required. One key task of the secretariat is to compile and transmit reports submitted to it.
The secretariat also provides assistance to affected developing country Parties, particularly those in Africa. This is important when compiling information and reports required under the Convention. UNCCD activities are coordinated with the secretariats of other relevant international bodies and conventions, like those of the UN Framework Convention on Climate Change (UNFCCC) and the Convention on Biological Diversity (CBD).
Conference of the Parties.
The Conference of the Parties (COP) oversees the implementation of the Convention. It is established by the Convention as the supreme decision-making body, and it comprises all ratifying governments. The first five sessions of the COP were held annually from 1997 to 2001.
Starting 2001 sessions are held on a biennial basis interchanging with the sessions of the Committee for the Review of the Implementation of the Convention (CRIC), whose first session was held in 2002.
Committee on Science and Technology (CST).
The UN Convention to Combat Desertification has established a Committee on Science and Technology (CST). The CST was established under Article 24 of the Convention as a subsidiary body of the COP, and its mandate and terms of reference were defined and adopted during the first session of the Conference of the Parties in 1997. It is composed of government representatives competent in the fields of expertise relevant to combating desertification and mitigating the effects of drought. The committee identifies priorities for research, and recommends ways of strengthening cooperation among researchers. It is multi-disciplinary and open to the participation of all Parties. It meets in conjunction with the ordinary sessions of the COP.
The CST collects, analyses and reviews relevant data. It also promotes cooperation in the field of combating desertification and mitigating the effects of drought through appropriate sub-regional, regional and national institutions, and in particular by its activities in research and development, which contribute to increased knowledge of the processes leading to desertification and drought as well as their impact.
The Bureau of the CST is composed of the Chairperson and the four Vice Chairpersons. The chairman is elected by the Conference of the Parties at each of its sessions with due regard to ensure geographical distribution and adequate representation of affected Country Parties, particularly those in Africa, who shall not serve for more than two consecutive terms. The Bureau of the CST is responsible for the follow-up of the work of the Committee between sessions of the COP and may benefit from assistance of ad hoc panels established by the COP.
The CST also contributes to distinguishing causal factors, both natural and human, with a view to combating desertification and achieving improved productivity as well as the sustainable use and management of resources.
Under the authority of the CST, a Group of Experts was established by the COP with a specific work programme, to assist in improving the efficiency and effectiveness of the CST. This Group of Experts working under the authority of the CST, provides advice on the areas of drought and desertification.
Group of Experts (GoE).
The Group of Experts plays an important institutional role, providing the CST with information on the current knowledge, the extent and the impact, the possible scenarios and the policy implications on various themes assigned in its work programme. The results of the work performed by the GoE are widely recognized and include dissemination of its results on ongoing activities (benchmarks and indicators, traditional knowledge, early warning systems).
The Group of Experts develops and makes available to all interested people information on appropriate mechanisms for scientific and technological cooperation and articulates research projects, which promote awareness about desertification and drought between countries and stakeholders at the international, regional and national level.
The Group of Experts seeks to build on and use existing work and evidence to produce pertinent synthesis and outputs for the use of the Parties to the Convention and for the broader dissemination to the scientific community. The programme of work and its mandate is pluri-annual in nature, for a maximum of four years.
National, regional and sub-regional programmes.
National Action Programmes (NAP) are one of the key instruments in the implementation of the Convention. They are strengthened by Action Programmes on Sub-regional (SRAP) and Regional (RAP) level. National Action Programmes are developed in the framework of a participative approach involving the local communities and they spell out the practical steps and measures to be taken to combat desertification in specific ecosystems.
References.
 This article incorporates public domain material from the document .
Full text available from 

</doc>
<doc id="32126" url="http://en.wikipedia.org/wiki?curid=32126" title="Uniramia">
Uniramia

Uniramia ("uni" - one, "ramus" - branch, i.e. single-branches) is a group within the arthropods. In the past this group included the Onychophora, which are now considered a separate category. The group is currently used in a narrower sense.
Uniramia is one of three subphyla in Arthropoda classification suggested by Sidnie Manton. This classification divided arthropods into a three-phyla polyphyletic group, with phylum Uniramia including the Hexapoda (insects), Myriapoda (centipedes and millipedes) and the Onychophora (velvetworms). The discovery of fossil lobopods, determined to be intermediate between onychophorans and arthropods led to the splintering of the Lobopoda and Onychophora into separate groups. This redefined the Uniramia as strictly "true" arthropods with exoskeletons and jointed appendages. Uniramians have strictly uniramous appendages.
Systematics can result in rival taxonomies, and this seems to have happened to Uniramia. The name Uniramia was temporarily rejected as a polyphyletic group, but when used now refers to the subphylum consisting of the insects + myriapods. Subphylum Uniramia is characterized by uniramous (single-branching) appendages, one pair of antennae and two pairs of mouthparts (single pairs of mandibles and maxillae). Their body forms and ecologies are diverse. While most unirames are terrestrial, "some are aquatic for part or all of their life cycles." Atelocerata is described as replacing Uniramia in early twentieth-century texts (Heymons, 1901), where it was the preferred name for the category uniting the Hexapoda (insects) + Myriapoda; but depending on the source, the term Atelocerata may have replaced Mandibulata, be an infraphylum beneath Mandibulata, or may no longer be a valid category after closer, cladistics-based genetic study.
The Crustacea were generally considered the closest relatives of the Uniramia, and sometimes these were united as Mandibulata. However, the competing hypothesis — that Crustacea and Hexapoda form a monophyletic group, the Pancrustacea, to which the Myriapoda are the closest relatives — has support from molecular and fossil evidence.

</doc>
<doc id="32127" url="http://en.wikipedia.org/wiki?curid=32127" title="University of Chicago">
University of Chicago

The University of Chicago (U of C, UChicago, or simply Chicago) is a private research university in Chicago, Illinois. The university consists of the College of the University of Chicago, various graduate programs and interdisciplinary committees organized into four divisions, six professional schools, and a school of continuing education. A highly regarded university internationally, beyond traditional academia, Chicago is also well known for its professional schools, which include the Pritzker School of Medicine, the Booth School of Business, the Law School, and the Divinity School. The university enrolls approximately 5,000 students in the College and about 15,000 students overall.
University of Chicago scholars have played a major role in the development of various academic disciplines, including: the Chicago school of economics, the Chicago school of sociology, the law and economics movement in legal analysis, the Chicago school of literary criticism, the Chicago school of religion, the school of political science known as behavioralism. The physics leading to the world's first man-made, self-sustaining nuclear reaction took place here. The university is also home to the University of Chicago Press, the largest university press in the United States.
Founded by the American Baptist Education Society with a donation from oil magnate and philanthropist John D. Rockefeller, the University of Chicago was incorporated in 1890; William Rainey Harper became the university's first president in 1891, and the first classes were held in 1892. Both Harper and future president Robert Maynard Hutchins advocated for Chicago's curriculum to be based upon theoretical and perennial issues rather than applied sciences and commercial utility.
The University of Chicago is home to many prominent alumni. 89 Nobel laureates have been affiliated with the university as visiting professors, students, faculty, or staff, the fourth most of any institution in the world. In addition, Chicago's alumni include 49 Rhodes Scholars, 2 Fields Medalists, 13 National Humanities Medalists and 13 billionaire graduates.
History.
Founding–1910s.
The University of Chicago was created and incorporated as a coeducational, secular institution in 1890 by the American Baptist Education Society and a donation from oil magnate and philanthropist John D. Rockefeller on land donated by Marshall Field. Organized as an independent institution legally, it replaced the first Baptist university of the same name, which had closed in 1886 due to extended financial and leadership problems. William Rainey Harper became the modern university's first president on July 1, 1891, and the university opened for classes on October 1, 1892.
The business school was founded in 1898, and the law school was founded in 1902. Harper died in 1906, and was replaced by a succession of three presidents whose tenures lasted until 1929. During this period, the Oriental Institute was founded to support and interpret archeological work in what was then called the Near East.
In the 1890s, the University of Chicago, fearful that its vast resources would injure smaller schools by drawing away good students, affiliated with several regional colleges and universities: Des Moines College, Kalamazoo College, Butler University, and Stetson University. Under the terms of the affiliation, the schools were required to have courses of study comparable to those at the University, to notify the university early of any contemplated faculty appointments or dismissals, to make no faculty appointment without the university's approval, and to send copies of examinations for suggestions. The University of Chicago agreed to confer a degree on any graduating senior from an affiliated school who made a grade of A for all four years, and on any other graduate who took twelve weeks additional study at the University of Chicago. A student or faculty member of an affiliated school was entitled to free tuition at the University of Chicago, and Chicago students were eligible to attend an affiliated school on the same terms and receive credit for their work. The University of Chicago also agreed to provide affiliated schools with books and scientific apparatus and supplies at cost; special instructors and lecturers without cost except travel expenses; and a copy of every book and journal published by the University of Chicago Press at no cost. The agreement provided that either party could terminate the affiliation on proper notice. Several University of Chicago professors disliked the program, as it involved uncompensated additional labor on their part, and they believed it cheapened the academic reputation of the University. The program passed into history by 1910.
1920s–1980s.
In 1929, the university's fifth president, Robert Maynard Hutchins, took office; the university underwent many changes during his 24-year tenure. Hutchins eliminated varsity football from the university in an attempt to emphasize academics over athletics, instituted the undergraduate college's liberal-arts curriculum known as the Common Core, and organized the university's graduate work into its current four divisions. In 1933, Hutchins proposed an unsuccessful plan to merge the University of Chicago and Northwestern University into a single university. During his term, the University of Chicago Hospitals (now called the University of Chicago Medical Center) finished construction and enrolled its first medical students. Also, the Committee on Social Thought, an institution distinctive of the university, was created.
Money that had been raised during the 1920s and financial backing from the Rockefeller Foundation helped the school to survive through the Great Depression. During World War II, the university made important contributions to the Manhattan Project. The university was the site of the first isolation of plutonium and of the creation of the first artificial, self-sustained nuclear reaction by Enrico Fermi in 1942.
In the early 1950s, student applications declined as a result of increasing crime and poverty in the Hyde Park neighborhood. In response, the university became a major sponsor of a controversial urban renewal project for Hyde Park, which profoundly affected both the neighborhood's architecture and street plan.
The university experienced its share of student unrest during the 1960s, beginning in 1962, when students occupied President George Beadle's office in a protest over the university's off-campus rental policies. After continued turmoil, a university committee in 1967 issued what became known as the Kalven Report. The report, a two-page statement of the university's policy in "social and political action," declared that "To perform its mission in the society, a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures." The report has since been used to justify decisions such as the university's refusal to divest from South Africa in the 1980s and Darfur in the late 2000s.
In 1969, more than 400 students, angry about the dismissal of a popular professor, Marlene Dixon, occupied the Administration Building for two weeks. After the sit-in ended, when Dixon turned down a one-year reappointment, 42 students were expelled and 81 were suspended, the most severe response to student occupations of any American university during the student movement.
In 1978, Hanna Holborn Gray, then the provost and acting president of Yale University, became President of the University of Chicago, a position she held for 15 years.
1990s–2010s.
In 1999, then-President Hugo Sonnenschein announced plans to relax the university's famed core curriculum, reducing the number of required courses from 21 to 15. When "The New York Times", "The Economist", and other major news outlets picked up this story, the university became the focal point of a national debate on education. The changes were ultimately implemented, but the controversy played a role in Sonnenschein's decision to resign in 2000.
In the past decade, the university began a number of multi-million dollar expansion projects. In 2008, the University of Chicago announced plans to establish the Milton Friedman Institute which attracted both support and controversy from faculty members and students. The institute will cost around $200 million and occupy the buildings of the Chicago Theological Seminary. During the same year, investor David G. Booth donated $300 million to the university's Booth School of Business, which is the largest gift in the university's history and the largest gift ever to any business school. In 2009, planning or construction on several new buildings, half of which cost $100 million or more, was underway.
Since 2009, a two-billion dollar campaign has brought substantial expansion to the campus, including the unveiling of the Max Palevsky Residential Commons, the South Campus Residence Hall, the Gerald Ratner Athletics Center, a new hospital, and a new science building. Since 2011, major construction projects have included the Jules and Gwen Knapp Center for Biomedical Discovery, a ten-story medical research center, and further additions to the medical campus of the University of Chicago Medical Center.
 On May 1, 2014, Barack Obama's White House Task Force to Protect Students from Sexual Assault publicly named the University of Chicago as one of many higher education institutions under investigation by the Office of Civil Rights "for possible violations of federal law over the handling of sexual violence and harassment complaints." "Fourth-year Olivia Ortiz filed the original complaint on the claim that the University had mishandled disciplinary procedures after she was sexually assaulted by her then-partner, who has since graduated, over the course of the 2011–2012 academic year. OCR accepted her case in June 2013, based both on the content of Ortiz’s original complaint and on the "Maroon" Sexual Assault Investigative series from fall 2012, which was cited in the original complaint." The complaint was reported originally by the "Chicago Maroon" in a 2012 student newspaper investigation of University of Chicago's history of under reporting and mishandling sexual violence complaints filed by students since 2007. 
Campus.
The campus of the University of Chicago. From the top of Rockefeller Chapel, the Main Quadrangles can be seen on the left (West), the Oriental Institute and the Becker Friedman Institute for Research in Economics can be seen in the center (North), and the Booth School of Business and Laboratory Schools can be seen on the right (East). The panoramic is bounded on both sides by the Midway Plaisance (South).
The main campus of the University of Chicago consists of 211 acre in the Chicago neighborhoods of Hyde Park and Woodlawn, seven miles (11 km) south of downtown Chicago. The northern and southern portions of campus are separated by the Midway Plaisance, a large, linear park created for the 1893 World's Columbian Exposition. In 2011, Travel+Leisure listed the university as one of the most beautiful college campuses in the United States.
The first buildings of the University of Chicago campus, which make up what is now known as the Main Quadrangles, were part of a "master plan" conceived by two University of Chicago trustees and plotted by Chicago architect Henry Ives Cobb. The Main Quadrangles consist of six quadrangles, each surrounded by buildings, bordering one larger quadrangle. The buildings of the Main Quadrangles were designed by Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms in a mixture of the Victorian Gothic and Collegiate Gothic styles, patterned on the colleges of the University of Oxford. (Mitchell Tower, for example, is modeled after Oxford's Magdalen Tower, and the university Commons, Hutchinson Hall, replicates Christ Church Hall.)
After the 1940s, the Gothic style on campus began to give way to modern styles. In 1955, Eero Saarinen was contracted to develop a second master plan, which led to the construction of buildings both north and south of the Midway, including the Laird Bell Law Quadrangle (a complex designed by Saarinen); a series of arts buildings; a building designed by Ludwig Mies van der Rohe for the university's School of Social Service Administration;, a building which is to become the home of the Harris School of Public Policy Studies by Edward Durrell Stone, and the Regenstein Library, the largest building on campus, a brutalist structure designed by Walter Netsch of the Chicago firm Skidmore, Owings & Merrill. Another master plan, designed in 1999 and updated in 2004, produced the Gerald Ratner Athletics Center (2003), the Max Palevsky Residential Commons (2001), South Campus Residence Hall and dining commons (2009), a new children's hospital, and other construction, expansions, and restorations. In 2011, the university completed the glass dome-shaped Joe and Rika Mansueto Library, which provides a grand reading room for the university library and prevents the need for an off-campus book depository.
The site of Chicago Pile-1 is a National Historic Landmark and is marked by the Henry Moore sculpture "Nuclear Energy". Robie House, a Frank Lloyd Wright building acquired by the university in 1963, is also a National Historic Landmark, as is room 405 of the George Herbert Jones Laboratory, where Glenn T. Seaborg and his team were the first to isolate plutonium. Hitchcock Hall, an undergraduate dormitory, is on the National Register of Historic Places.
Satellite campuses.
The University of Chicago also maintains facilities apart from its main campus. The university's Booth School of Business maintains campuses in Singapore, London, and the downtown Streeterville neighborhood of Chicago. The Center in Paris, a campus located on the left bank of the Seine in Paris, hosts various undergraduate and graduate study programs. In fall 2010, the University of Chicago also opened a center in Beijing, near Renmin University's campus in Haidian District. The most recent addition is a center in New Delhi, India, which opened in 2014.
Administration and finances.
The University of Chicago is governed by a board of trustees. The Board of Trustees oversees the long-term development and plans of the university and manages fundraising efforts, and is composed of 50 members including the university President. Directly beneath the President are the Provost, fourteen Vice Presidents (including the Chief Financial Officer, Chief Investment Officer, and Dean of Students of the university), the Directors of Argonne National Laboratory and Fermilab, the Secretary of the university, and the Student Ombudsperson. s of August 2009[ [update]], the Chairman of the Board of Trustees is Andrew Alper, and the President of the university is Robert Zimmer. In December 2013 it was announced that the Director of Argonne National Laboratory, Eric Isaacs, would become Provost.
The university's endowment was the 12th largest among American educational institutions and state university systems in 2013 and as of 2012[ [update]] was valued at $6.571 billion.
Academics.
The academic bodies of the University of Chicago consist of the College, four divisions of graduate research, six professional schools, and the Graham School of Continuing Liberal and Professional Studies (a continuing education school). The university also contains a library system, the University of Chicago Press, the University of Chicago Laboratory Schools, and the University of Chicago Medical Center, and holds ties with a number of independent academic institutions, including Fermilab, Argonne National Laboratory, and the Marine Biological Laboratory. The university is accredited by The Higher Learning Commission of the North Central Association of Colleges and Schools.
The university runs on a quarter system in which the academic year is divided into four terms: Summer (June–August), Autumn (September–December), Winter (January–March), and Spring (April–June). Full-time undergraduate students take three to four courses every quarter for approximately eleven weeks before their quarterly academic breaks. The school year typically begins in late September and ends in mid-June.
Undergraduate college.
The College of the University of Chicago grants Bachelor of Arts and Bachelor of Science degrees in 50 academic majors and 28 minors. The college's academics are divided into five divisions: the Biological Sciences Collegiate Division, the Physical Sciences Collegiate Division, the Social Sciences Collegiate Division, the Humanities Collegiate Division, and the New Collegiate Division. The first four are sections within their corresponding graduate divisions, while the New Collegiate Division administers interdisciplinary majors and studies which do not fit in one of the other four divisions. 
Undergraduate students are required to take a distribution of courses to satisfy the university's core curriculum known as the Common Core. In 2012-2013, the Core classes at Chicago were limited to 17 students, and are generally led by a full-time professor (as opposed to a teaching assistant). As of the 2013–2014 school year, 15 courses and demonstrated proficiency in a foreign language are required under the Core. Undergraduate courses at the University of Chicago are known for their demanding standards, heavy workload and academic difficulty; according to "Uni in the USA", "Among the academic cream of American universities – Harvard, Yale, Princeton, MIT, and the University of Chicago – it is UChicago that can most convincingly claim to provide the most rigorous, intense learning experience."
Graduate schools and committees.
The university graduate schools and committees are divided into four divisions: Biological Sciences, Humanities, Physical Sciences, and Social Sciences. In the autumn quarter of 2014, the university enrolled 3,468 graduate students: 461 in the Biological Sciences Division, 819 in the Humanities Division, 1,024 in the Physical Sciences Division, and 1,164 in the Social Sciences Division.
The university is home to several committees for interdisciplinary scholarship, including the Committee on Social Thought.
Professional schools.
The university contains six professional schools: the Pritzker School of Medicine (which is a part of the Biological Sciences Division), the Booth School of Business, the Law School, the Divinity School, the Harris School of Public Policy Studies, and the School of Social Service Administration (SSA). The total enrollment for these six professional schools was 5,086 students in the 2009 spring quarter: 2,878 students in the business school, 344 in the Divinity School, 452 in the medical school, 269 in the Harris School, 494 in SSA, and 649 in the Law School.
The Law School is accredited by the American Bar Association, the Divinity School is accredited by the Commission on Accrediting of the Association of Theological Schools in the United States and Canada, Pritzker is accredited by the Liaison Committee on Medical Education.
Associated academic institutions.
The university runs a number of academic institutions and programs apart from its undergraduate and postgraduate schools. It operates the University of Chicago Laboratory Schools (a private day school for K-12 students and day care), the Sonia Shankman Orthogenic School (a residential treatment program for those with behavioral and emotional problems), and four public charter schools on the South Side of Chicago administered by the university's Urban Education Institute. In addition, the Hyde Park Day School, a school for students with learning disabilities, maintains a location on the University of Chicago campus. Since 1983, the University of Chicago has maintained the University of Chicago School Mathematics Project, a mathematics program used in urban primary and secondary schools. The university runs a program called the Council on Advanced Studies in the Social Sciences and Humanities, which administers interdisciplinary workshops to provide a forum for graduate students, faculty, and visiting scholars to present scholarly work in progress.
The university also operates the University of Chicago Press, the largest university press in the United States.
Library system.
The University of Chicago Library system encompasses six libraries that contain a total of 9.8 million volumes, the 11th most among library systems in the United States. The University's main library is the Regenstein Library, which contains one of the largest collections of print volumes in the United States. The John Crerar Library contains more than 1.3 million volumes in the biological, medical and physical sciences and collections in general science and the philosophy and history of science, medicine, and technology. The university also operates a number of special libraries, including the D'Angelo Law Library, the Social Service Administration Library, and the Eckhart Library for mathematics and computer science, which closed temporarily for renovation on July 8, 2013. Harper Memorial Library no longer contains any volumes; however it is the only 24 hour study space on campus. 
Research.
In fiscal year 2006, the University of Chicago spent US$305,301,000 on scientific research. It is classified by the Carnegie Foundation for the Advancement of Teaching as an institution with "very high research activity" and is a founding member of the Committee on Institutional Cooperation and the Association of American Universities.
The university operates 12 research institutes and 113 research centers on campus. Among these are the Oriental Institute—a museum and research center for Near Eastern studies owned and operated by the university—and a number of National Resource Centers, including the Center for Middle Eastern Studies. Chicago also operates or is affiliated with a number of research institutions apart from the university proper. The university partially manages Argonne National Laboratory, part of the United States Department of Energy's national laboratory system, and has a joint stake in Fermilab, a nearby particle physics laboratory, as well as a stake in the Apache Point Observatory in Sunspot, New Mexico. Faculty and students at the adjacent Toyota Technological Institute at Chicago collaborate with the university, In 2013, the University announced that it was affiliating the formerly independent Marine Biological Laboratory in Woods Hole, Mass. Although formally unrelated, the National Opinion Research Center is located on Chicago's campus.
The University of Chicago has been the site of some important experiments and academic movements. In economics, the university has played an important role in shaping ideas about the free market and is the namesake of the Chicago school of economics, the school of economic thought supported by Milton Friedman and other economists. The university's sociology department was the first independent sociology department in the United States and gave birth to the Chicago school of sociology. In physics, the university was the site of the Chicago Pile-1 (the first self-sustained man-made nuclear reaction, part of the Manhattan Project), of Robert Millikan's oil-drop experiment that calculated the charge of the electron, and of the development of radiocarbon dating by Willard F. Libby in 1947. The chemical experiment that tested how life originated on early Earth, the Miller–Urey experiment, was conducted at the university. REM sleep was discovered at the university in 1953 by Nathaniel Kleitman and Eugene Aserinsky. 
Arts.
The UChicago Arts program joins academic departments and programs in the Division of the Humanities and the College, as well as professional organizations including the Court Theatre, the Oriental Institute, the Smart Museum of Art, the Renaissance Society, University of Chicago Presents, and student arts organizations. The university has an artist-in-residence program and scholars in performance studies, contemporary art criticism, and film history. It has offered a doctorate in music composition since 1933 and in Cinema & Media studies since 2000, a master of fine arts in visual arts (early 1970s), and a master of arts in the humanities with a creative writing track (2000). It has bachelor’s degree programs in visual arts, music, and art history, and, more recently, Cinema & Media studies (1996) and theater & performance studies (2002). The College’s general education core includes a “dramatic, music, and visual arts” requirement, requiring students to study the history of the arts, stage desire, or begin working with sculpture. Several thousand major and non-major undergraduates enroll annually in creative and performing arts classes. UChicago is often considered the birthplace of improvisational comedy as the Compass Players student comedy troupe evolved into The Second City improv theater troupe in 1959. The Reva and David Logan Center for the Arts opened in October 2012, five years after a $35 million gift from alumnus David Logan and his wife Reva. The center includes spaces for exhibitions, performances, classes, and media production. The Logan Centre was designed by Tod Williams and Billie Tsien. This building is actually entirely glass. The brick is a facade designed to keep the glass safe from the wind. The architects later removed sections of the bricks when pressure arose in the form of complaints that the views of the city were blocked.
People.
There have been 87 Nobel laureates affiliated with the University of Chicago, 17 of whom were pursuing research or on faculty at the university at the time of the award announcement.
In addition, many Chicago alumni and scholars have won the Fulbright awards and 49 have matriculated as Rhodes Scholars.
Student body.
In the fall quarter of 2014, the University of Chicago enrolled 5,792 students in the College, 3,468 students in its four graduate divisions, 5,984 students in its professional schools, and 15,244 students overall. In the 2012 Spring Quarter, international students comprised almost 19% of the overall study body, over 26% of students were domestic ethnic minorities, and about 44% of enrolled students were female. The middle 50% band of SAT scores for the undergraduate class of 2015, excluding the writing section, was 1420–1530, the average MCAT score for entering students in the Pritzker School of Medicine in 2011 was 36, and the median LSAT score for entering students in the Law School in 2011 was 171.
In 2015, the College of the University of Chicago had an acceptance rate of 7.8% for the Class of 2019, the lowest in the college's history.
Alumni.
In 2004, the University of Chicago claimed 133,155 living alumni.
Notable alumni in the field of government and politics include community organizer Saul Alinsky, Obama campaign advisor David Axelrod, Attorney General and federal judge Robert Bork, Attorney General Ramsey Clark, Prohibition agent Eliot Ness, Supreme Court Justice John Paul Stevens, Prime Minister of Canada William Lyon Mackenzie King, United States Senator from Vermont Bernie Sanders, and former World Bank President Paul Wolfowitz.
In business, Microsoft CEO Satya Nadella, Goldman Sachs and MF Global CEO as well as former Governor of New Jersey Jon Corzine, Arley D. Cathey, Bloomberg L.P. CEO Daniel Doctoroff, Credit Suisse CEO Brady Dougan, Morningstar, Inc. founder and CEO Joe Mansueto, Chicago Cubs owner and chairman Thomas S. Ricketts, and NBA commissioner Adam Silver are graduates.
In journalism, notable graduates include "New York Times" columnist David Brooks, "Washington Post" columnist David Broder, "Washington Post" publisher Katharine Graham, investigative journalist Seymour Hersh, "The Progressive" columnist Milton Mayer, statistical analyst Nate Silver, and CBS News correspondent Rebecca Jarvis.
In literature, writers Lauren Oliver, Philip Roth, Studs Terkel, Susan Sontag, and Kurt Vonnegut are graduates.
In the arts and entertainment, composer Philip Glass, dancer and choreographer Katherine Dunham, Bungie video game developer founder Alex Seropian, Serial host Sarah Koenig, and film director Philip Kaufman are graduates.
American Civil Rights Movement leaders Vernon Johns and Myles Horton, Tuskegee Airmen commander Benjamin O. Davis, Jr., and African-American history scholar Carter G. Woodson are all alumni.
In economics, Milton Friedman, Gary Becker, Herbert A. Simon, Paul Samuelson, Thomas Sowell and Eugene Fama are all graduates.
In science, alumni include astronomers Carl Sagan and Edwin Hubble, NASA astronaut John M. Grunsfeld, geneticist James Watson, environmentalist David Suzuki, balloonist Jeannette Piccard, biologists Ernest Everett Just and Lynn Margulis, computer scientist Richard Hamming, lithium-ion battery developer John B. Goodenough, and geochemist Clair Cameron Patterson.
Other prominent alumni include anthropologist Donald Johanson, psychologist John B. Watson, chess grandmaster Samuel Reshevsky, and international relations scholar Samuel P. Huntington. 
Three students from the university have been prosecuted in notable court cases, they include infamous thrill killers Leopold and Loeb, as well as high school science teacher John T. Scopes who was tried in the Scopes Monkey Trial. 
Notable former students who did not graduate include novelist Saul Bellow, film critic Roger Ebert, Oracle Corporation founder and the third richest man in America Larry Ellison, and director, writer and comedian Mike Nichols.
The most famous fictional alumnus of the university is the archaeologist Indiana Jones.
Faculty.
Notable faculty in physics have included A. A. Michelson, Robert A. Millikan, Arthur H. Compton, Enrico Fermi, Edward Teller, Luis Walter Alvarez, Murray Gell-Mann, Maria Goeppert-Mayer, Tsung-Dao Lee, and Subrahmanyan Chandrasekhar. 
In law, the President of the United States of America Barack Obama, Richard Posner, and Nobel laureate in Economics Ronald Coase have served on the faculty.
Philosophers John Dewey, George H. Mead, Hannah Arendt and Bertrand Russell, as well as writers T.S. Eliot, Ralph Ellison and J.M. Coetzee have all served on the faculty. 
Past faculty have also included Egyptologist James Henry Breasted, mathematician Alberto Calderón, economist Friedrich Hayek, meteorologist Ted Fujita, chemists Glenn T. Seaborg and Yuan T. Lee, cancer researchers Charles Brenton Huggins and Janet Rowley, astronomer Gerard Kuiper, linguist Edward Sapir, and the founder of McKinsey & Co., James O. McKinsey.
Current faculty include paleontologists Neil Shubin and Paul Sereno, physicist Yoichiro Nambu, economists Lars Peter Hansen and Steven Levitt, Shakespeare scholar David Bevington, and political scientists John Mearsheimer and Robert Pape.
Athletics.
The University of Chicago hosts 19 varsity sports teams: 10 men's teams and 9 women's teams, all called the Maroons, with 502 students participating in the 2012–2013 school year.
The Maroons compete in the NCAA's Division III as members of the University Athletic Association (UAA). The university was a founding member of the Big Ten Conference and participated in the NCAA Division I Men's Basketball and Football and was a regular participant in the Men's Basketball tournament. In 1935, the University of Chicago reached the Sweet Sixteen. In 1935, Chicago Maroons football player Jay Berwanger became the first winner of the Heisman Trophy. However, the university chose to withdraw from the conference in 1946 after University President Robert Maynard Hutchins de-emphasized varsity athletics in 1939 and dropped football. (In 1969, Chicago reinstated football as a Division III team, resuming playing its home games at the new Stagg Field.)
Student life.
Student organizations.
Students at the University of Chicago run over 400 clubs and organizations known as Recognized Student Organizations (RSOs). These include cultural and religious groups, academic clubs and teams, and common-interest organizations. Notable extracurricular groups include the University of Chicago College Bowl Team, which has won 118 tournaments and 15 national championships, leading both categories internationally. The University's competitive Model United Nations team was the top ranked team in North America in 2013-14 and Fall 2014. Among notable RSOs are the nation's longest continuously running student film society Doc Films, organizing committee for the University of Chicago Scavenger Hunt, the twice-weekly student newspaper "The Chicago Maroon", the alternative weekly student newspaper "South Side Weekly", the nation's second oldest continuously running student improvisational theater troupe "Off-Off Campus", and the university-owned radio station WHPK-FM.
Student Government.
All Recognized Student Organizations, from the University of Chicago Scavenger Hunt to Model UN, in addition to academic teams, sports club, arts groups, and more are funded by The University of Chicago Student Government. Student Government is made up of graduate and undergraduate students elected to represent members from their respective academic unit. It is led by an Executive Committee, chaired by a President with the assistance of two Vice Presidents, one for Administration and the other for Student Life, elected together as a slate by the student body each spring. Its annual budget is greater than $2 million.
Fraternities and sororities.
There are fifteen fraternities and seven sororities at the University of Chicago, as well as one co-ed community service fraternity, Alpha Phi Omega. Four of the sororities are members of the National Panhellenic Conference, and ten of the fraternities form the University of Chicago Interfraternity Council. In 2002, the Associate Director of Student Activities estimated that 8–10 percent of undergraduates were members of fraternities or sororities. The student activities office has used similar figures, stating that one in ten undergraduates participate in Greek life.
Student housing.
On-campus undergraduate students at the University of Chicago participate in a house system in which each student is assigned to one of the university's 11 residence hall buildings and to a smaller community within their residence hall called a "house". There are 38 houses, with an average of 70 students in each house Freshmen are required to participate in the house system, and housing is guaranteed every year thereafter. About 60% of undergraduate students live on campus.
For graduate students, the university owns and operates 28 apartment buildings near campus.
Traditions.
Every May since 1987, the University of Chicago has held the University of Chicago Scavenger Hunt, in which large teams of students compete to obtain notoriously esoteric items from a list. Since 1963, the Festival of the Arts (FOTA) takes over campus for 7–10 days of exhibitions and interactive artistic endeavors. Every January, the university holds a week-long winter festival, Kuviasungnerk/Kangeiko, which include early morning exercise routines and fitness workshops. The university also annually holds a summer carnival and concert called Summer Breeze that hosts outside musicians, and is home to Doc Films, a student film society founded in 1932 that screens films nightly at the university. Since 1946, the university has organized the Latke-Hamantash Debate, which involves humorous discussions about the relative merits and meanings of latkes and hamantashen.
Notes.
</ol>

</doc>
<doc id="32128" url="http://en.wikipedia.org/wiki?curid=32128" title="Uniformitarianism">
Uniformitarianism

Uniformitarianism is the scientific observation that the same natural laws and processes that operate in the universe now have always operated in the universe in the past and apply everywhere in the universe. It has included the gradualistic concept that "the present is the key to the past" and is functioning at the same rates. Uniformitarianism has been a key principle of geology and virtually all fields of science, but naturalism's modern geologists, while accepting that geology has occurred across deep time, no longer hold to a strict gradualism.
Uniformitarianism, coined by William Whewell, was originally proposed in contrast to catastrophism by British naturalists in the late 18th century, starting with the work of the Scottish geologist James Hutton, which was refined by John Playfair and popularised by Charles Lyell's "Principles of Geology" in 1830.
History.
18th century.
The earlier conceptions likely had little influence on 18th-century European geological explanations for the formation of Earth. Abraham Gottlob Werner proposed Neptunism where strata were deposits from shrinking seas precipitated onto primordial rocks such as granite. In 1785 James Hutton proposed an opposing, self-maintaining infinite cycle based on natural history and not on the Biblical record.
The solid parts of the present land appear in general, to have been composed of the productions of the sea, and of other materials similar to those now found upon the shores. Hence we find reason to conclude:<br>
Hence we are led to conclude, that the greater part of our land, if not the whole had been produced by operations natural to this globe; but that in order to make this land a permanent body, resisting the operations of the waters, two things had been required;<br>
Hutton then sought evidence to support his idea that there must have been repeated cycles, each involving deposition on the seabed, uplift with tilting and erosion, and then moving undersea again for further layers to be deposited. At Glen Tilt in the Cairngorm mountains he found granite penetrating metamorphic schists, in a way which indicated to him that the presumed primordial rock had been molten after the strata had formed. He had read about angular unconformities as interpreted by Neptunists, and found an unconformity at Jedburgh where layers of greywacke in the lower layers of the cliff face have been tilted almost vertically before being eroded to form a level plane, under horizontal layers of Old Red Sandstone. In the Spring of 1788 he took a boat trip along the Berwickshire coast with John Playfair and the geologist Sir James Hall, and found a dramatic unconformity showing the same sequence at Siccar Point. Playfair later recalled that "the mind seemed to grow giddy by looking so far into the abyss of time", and Hutton concluded a 1788 paper he presented at the Royal Society of Edinburgh, later rewritten as a book, with the phrase "we find no vestige of a beginning, no prospect of an end."
Both Playfair and Hall wrote their own books on the theory, and for decades there was a robust debate between Hutton's supporters and the Neptunists. Georges Cuvier's paleontological work in the 1790s, which established the reality of extinction, explained this by local catastrophes, after which other fixed species repopulated the affected areas. In Britain, geologists adapted this idea into "diluvial theory" which proposed repeated worldwide annihilation and creation of new fixed species adapted to a changed environment, initially identifying the most recent catastrophe as the biblical flood.
19th century.
From 1830 to 1833 Charles Lyell's multi-volume "Principles of Geology" was published. The work's subtitle was "An attempt to explain the former changes of the Earth's surface by reference to causes now in operation". He drew his explanations from field studies conducted directly before he went to work on the founding geology text, and developed Hutton's idea that the earth was shaped entirely by slow-moving forces still in operation today, acting over a very long period of time. The terms "uniformitarianism" for this idea, and "catastrophism" for the opposing viewpoint, were coined by William Whewell in a review of Lyell's book. "Principles of Geology" was the most influential geological work in the middle of the 19th century.
Lyell's uniformitarianism.
According to Reijer Hooykaas (1963), Lyell's uniformitarianism is a family of four related propositions, not a single idea:
None of these connotations requires another, and they are not all equally inferred by uniformitarians.
Gould explained Lyell's propositions in "Time's Arrow, Time's Cycle" (1987), stating that Lyell conflated two different types of propositions: a pair of methodological assumptions with a pair of substantive hypotheses. The four together make up Lyell's uniformitarianism.
Methodological observations.
The two methodological observations are universally acclaimed by scientists, and embraced by all geologists. Gould claims that these philosophical propositions must be assumed before you can proceed as a scientist doing science. "You cannot go to a rocky outcrop and observe either the constancy of nature's laws or the working of unknown processes. It works the other way around." You first assume these propositions and "then you go to the out crop of rock."
Substantive hypotheses.
The substantive hypotheses were controversial and, in some cases, accepted by few. These hypotheses are judged true or false on empirical grounds through scientific observation and repeated experimental data. This is in contrast with the previous two philosophical assumptions that come before one can do science and so cannot be tested or falsified by science.
20th century.
Stephen Jay Gould's first scientific paper, "Is uniformitarianism necessary?" (1965), reduced these four interpretations to two. He dismissed the first principle, which asserted spatial and temporal invariance of natural laws, as no longer an issue of debate. He rejected the third (uniformity of rate) as an unjustified limitation on scientific inquiry, as it constrains past geologic rates and conditions to those of the present. So, Lyellian uniformitarianism was unnecessary.
Modern Uniformitarianism includes periodic catastrophes.
Uniformitarianism was originally proposed in contrast to catastrophism, which states that the distant past "consisted of epochs of paroxysmal and catastrophic action interposed between periods of comparative tranquility" Especially in the late 19th and early 20th centuries, most geologists took this interpretation to mean that catastrophic events are not important in geologic time; one example of this is the debate of the formation of the Channeled Scablands due to the catastrophic Missoula glacial outburst floods. An important result of this debate and others was the re-clarification that, while the same principles operate in geologic time, catastrophic events that are infrequent on human time-scales can have important consequences in geologic history.
Derek Ager has noted that "geologists do not deny uniformitarianism in its true sense, that is to say, of interpreting the past by means of the processes that are seen going on at the present day, so long as we remember that the periodic catastrophe is one of those processes. Those periodic catastrophes make more showing in the stratigraphical record than we have hitherto assumed."
Even Charles Lyell thought that ordinary geological processes would cause Niagara Falls to move upstream to Lake Erie within 10,000 years, leading to catastrophic flooding of a large part of North America.
Modern geologists do not apply uniformitarianism in the same way as Lyell. They question if rates of processes were uniform through time and only those values measured during the history of geology are to be accepted. The present may not be a long enough key to penetrate the deep lock of the past. Geologic processes may have been active at different rates in the past that humans have not observed. "By force of popularity, uniformity of rate has persisted to our present day. For more than a century, Lyell's rhetoric conflating axiom with hypotheses has descended in unmodified form. Many geologists have been stifled by the belief that proper methodology includes an a priori commitment to gradual change, and by a preference for explaining large-scale phenomena as the concatenation of innumerable tiny changes."
The current consensus is that Earth's history is a slow, gradual process punctuated by occasional natural catastrophic events that have affected Earth and its inhabitants. In practice it is reduced from Lyell's conflation to simply the two philosophical assumptions. This is also known as the principle of geological actualism, which states that all past geological action was like all present geological action. The principle of actualism is the cornerstone of paleoecology.

</doc>
<doc id="32129" url="http://en.wikipedia.org/wiki?curid=32129" title="Universal Decimal Classification">
Universal Decimal Classification

The Universal Decimal Classification (UDC) is a bibliographic and library classification developed by the Belgian bibliographers Paul Otlet and Henri La Fontaine at the end of the 19th century. UDC provides a systematic arrangement of all branches of human knowledge organized as a coherent system in which knowledge fields are related and inter-linked.
Originally based on the Dewey Decimal Classification, the UDC was developed as a new analytico-synthetic classification system with a significantly larger vocabulary and syntax that enables very detailed content indexing and information retrieval in large collections. In its first edition in 1905, the UDC already included many features that were revolutionary in the context of knowledge classifications: tables of generally applicable (aspect-free) concepts - called common auxiliary tables; a series of special auxiliary tables with specific but re-usable attributes in a particular field of knowledge; an expressive notational system with connecting symbols and syntax rules to enable coordination of subjects and the creation of a documentation language proper. Albeit originally designed as an indexing and retrieval system, due to its logical structure and scalability, UDC has become one of the most widely used knowledge organization systems in libraries, where it is used for either shelf arrangement, content indexing or both. UDC codes can describe any type of document or object to any desired level of detail. These can include textual documents and other media such as films, video and sound recordings, illustrations, maps as well as realia such as museum objects.
Since the first edition in French "Manuel du Répertoire bibliographique universel" (1905), UDC has been translated and published in various editions in 40 languages. UDC Summary, an abridged Web version of the scheme is available in over 50 languages. The classification has been modified and extended over the years to cope with increasing output in all areas of human knowledge, and is still under continuous review to take account of new developments.
The application of UDC.
UDC is used in around 150,000 libraries in 130 countries and in many bibliographical services which require detailed content indexing. In a number of countries it is the main classification system for information exchange and is used in all type of libraries: public, school, academic and special libraries.
UDC is also used in national bibliographies of around 30 countries. Examples of large databases indexed by UDC include: 
UDC has traditionally been used for the indexing of scientific articles which was an important source of information of scientific output in the period predating electronic publishing. Collections of research articles in many countries covering decades of scientific output contain UDC codes. Examples of journal articles indexed by UDC:
The design of UDC lends itself to machine readability, and the system has been used both with early automatic mechanical sorting devices, and modern library OPACs. From 1993, a standard version of UDC is maintained and is distributed in a database format: UDC Master Reference File (UDC MRF) which is updated and released annually. The 2011 version of the MRF (released in 2012) contains over 70,000 classes. In the past full printed editions used to have around 220,000 subdivisions.
UDC structure.
Notation.
A notation is a code commonly used in classification schemes to represent a class, i.e. a subject and its position in the hierarchy, to enable mechanical sorting and filing of subjects. UDC uses Arabic numerals arranged decimally. Every number is thought of as a decimal fraction with the initial decimal point omitted, which determines the filing order. An advantage of decimal notational systems is that they are infinitely extensible, and when new subdivisions are introduced, they need not disturb the existing allocation of numbers. For ease of reading, a UDC notation is usually punctuated after every third digit:
In UDC the notation has two features that make the scheme easier to browse and work with: 
Basic features and syntax.
UDC is an analytico-synthetic and faceted classification. It allows an unlimited combination of attributes of a subject and relationships between subjects to be expressed. UDC codes from different tables can be combined to present various aspects of document content and form, e.g. 94(410)"19"(075) History "(main subject)" of United Kingdom "(place)" in 20th century "(time)", a textbook "(document form)". Or: 37:2 Relationship between Education and Religion. Complex UDC expressions can be accurately parsed into constituent elements. 
UDC is also a disciplinary classification covering the entire universe of knowledge. This type of classification can also be described as "aspect" or "perspective", which means that concepts are subsumed and placed under the field in which they are studied. Thus, the same concept can appear in different fields of knowledge. This particular feature is usually implemented in UDC by re-using the same concept in various combinations with the main subject, e.g. a code for language in common auxiliaries of language is used to derive numbers for ethnic grouping, individual languages in linguistics and individual literatures. Or, a code from the auxiliaries of place, e.g. "(410) United Kingdom", uniquely representing the concept of United Kingdom can be used to express "911(410) Regional geography of United Kingdom" and "94(410) History of United Kingdom".
Organization of classes.
Concepts are organized in two kinds of tables in UDC:
Main classes.
The vacant class 4 is the result of a planned schedule expansion. This class was freed by moving linguistics into class 8 in the 1960s to make space for future developments in the rapidly expanding fields of knowledge; primarily natural sciences and technology.
Common auxiliary tables.
"Common auxiliaries" are aspect-free concepts that can be used in combination with any other UDC code from the main classes or with other common auxiliaries. They have unique notational representations that makes them stand out in complex expressions. Common auxiliary numbers always begin with a certain symbol known as a facet indicator, e.g. = (equal sign) always introduces concepts representing the language of a document; (0...) numbers enclosed in parentheses starting with zero always represent a concept designating document form. Thus (075) Textbook and =111 English can be combined to express, e.g.(075)=111 Textbooks in English, and when combined with numbers from the main UDC tables they can be used as follows: 2(075)=111 Religion textbooks in English, 51(075)=111 Mathematics textbooks in English etc.
Connecting signs.
In order to preserve the precise meaning and enable accurate parsing of complex UDC expressions, a number of connecting symbols are made available to relate and extend UDC numbers. These are:
UDC Outline.
Main Tables.
0 Science and knowledge. Organization. Computer science. Information. Documentation. Librarianship. Institution. Publications.
 00 Prolegomena. Fundamentals of knowledge and culture. Propaedeutics
 001 Science and knowledge in general. Organization of intellectual work
 002 Documentation. Books. Writings. Authorship
 003 Writing systems and scripts
 004 Computer science and technology. Computing
 004.2 Computer architecture
 004.3 Computer hardware
 004.4 Software
 004.5 Human-computer interaction
 004.6 Data
 004.7 Computer communication
 004.8 Artificial intelligence
 004.9 Application-oriented computer-based techniques
 005 Management
 005.1 Management Theory
 005.2 Management agents. Mechanisms. Measures
 005.3 Management activities
 005.5 Management operations. Direction
 005.6 Quality management. Total quality management (TQM)
 005.7 Organizational management (OM)
 005.9 Fields of management
 005.92 Records management
 005.93 Plant management. Physical resources management
 005.94 Knowledge management
 005.95/.96 Personnel management. Human Resources management
 006 Standardization of products, operations, weights, measures and time
 007 Activity and organizing. Information. Communication and control theory generally (cybernetics)
 008 Civilization. Culture. Progress 
 01 Bibliography and bibliographies. Catalogues
 02 Librarianship
 030 General reference works (as subject)
 050 Serial publications, periodicals (as subject)
 06 Organizations of a general nature
 069 Museums
 070 Newspapers (as subject). The Press. Outline of journalism
 08 Polygraphies. Collective works (as subject)
 09 Manuscripts. Rare and remarkable works (as subject)
1 Philosophy. Psychology.
 101 Nature and role of philosophy
 11 Metaphysics
 111 General metaphysics. Ontology
 122/129 Special Metaphysics
 13 Philosophy of mind and spirit. Metaphysics of spiritual life
 14 Philosophical systems and points of view
 159.9 Psychology
 159.91 Psychophysiology (physiological psychology). Mental physiology
 159.92 Mental development and capacity. Comparative psychology
 159.93 Sensation. Sensory perception
 159.94 Executive functions
 159.95 Higher mental processes
 159.96 Special mental states and processes
 159.97 Abnormal psychology
 159.98 Applied psychology (psychotechnology) in general
 16 Logic. Epistemology. Theory of knowledge. Methodology of logic
 17 Moral philosophy. Ethics. Practical philosophy
2 Religion. Theology.
 "2-1/-9 Special auxiliary subdivision for religion
 "2-1 Theory and philosophy of religion. Nature of religion. Phenomenon of religion"
 "2-2 Evidences of religion"
 "2-3 Persons in religion"
 "2-4 Religious activities. Religious practice"
 "2-5 Worship broadly. Cult. Rites and ceremonies"
 "2-6 Processes in religion"
 "2-7 Religious organization and administration"
 "2-8 Religions characterised by various properties"
 "2-9 History of the faith, religion, denomination or church"
 21/29 Religious systems. Religions and faiths
 21 Prehistoric and primitive religions
 22 Religions originating in the Far East
 23 Religions originating in Indian sub-continent. Hindu religion in the broad sense
 24 Buddhism
 25 Religions of antiquity. Minor cults and religions
 26 Judaism
 27 Christianity
 28 Islam
 29 Modern spiritual movements
3 Social Sciences.
 303 Methods of the social sciences
 304 Social questions. Social practice. Cultural practice. Way of life (Lebensweise)
 305 Gender studies
 308 Sociography. Descriptive studies of society (both qualitative and quantitative)
 311 Statistics as a science. Statistical theory
 314/316 Society
 314 Demography. Population studies
 316 Sociology
 32 Politics
 33 Economics. Economic science
 34 Law. Jurisprudence
 35 Public administration. Government. Military affairs
 36 Safeguarding the mental and material necessities of life
 37 Education
 39 Cultural anthropology. Ethnography. Customs. Manners. Traditions. Way of life
4 Vacant.
This section is currently vacant.
5 Mathematics. Natural sciences.
 502/504 Environmental science. Conservation of natural resources. Threats to the environment and protection against them
 502 The environment and its protection
 504 Threats to the environment
 51 Mathematics
 510 Fundamental and general considerations of mathematics
 511 Number theory
 512 Algebra
 514 Geometry
 517 Analysis
 519.1 Combinatorial analysis. Graph theory
 519.2 Probability. Mathematical statistics
 519.6 Computational mathematics. Numerical analysis
 519.7 Mathematical cybernetics
 519.8 Operational research (OR): mathematical theories and methods
 52 Astronomy. Astrophysics. Space research. Geodesy
 53 Physics
 531/534 Mechanics
 535 Optics
 536 Heat. Thermodynamics. Statistical physics
 537 Electricity. Magnetism. Electromagnetism
 538.9 Condensed matter physics. Solid state physics
 539 Physical nature of matter
 54 Chemistry. Crystallography. Mineralogy
 542 Practical laboratory chemistry. Preparative and experimental chemistry
 543 Analytical chemistry
 544 Physical chemistry
 546 Inorganic chemistry
 547 Organic chemistry
 548/549 Mineralogical sciences. Crystallography. Mineralogy
 55 Earth Sciences. Geological sciences
 56 Paleontology
 57 Biological sciences in general
 58 Botany
 59 Zoology
6 Applied sciences. Medicine. Technology.
 60 Biotechnology
 61 Medical sciences
 611/612 Human biology
 613 Hygiene generally. Personal health and hygiene
 614 Public health and hygiene. Accident prevention
 615 Pharmacology. Therapeutics. Toxicology
 616 Pathology. Clinical medicine
 617 Surgery. Orthopaedics. Ophthalmology
 618 Gynaecology. Obstetrics
 62 Engineering. Technology in general
 620 Materials testing. Commercial materials. Power stations. Economics of energy
 621 Mechanical engineering in general. Nuclear technology. Electrical engineering. Machinery
 622 Mining
 623 Military engineering
 624 Civil and structural engineering in general
 625 Civil engineering of land transport. Railway engineering. Highway engineering
 626/627 Hydraulic engineering and construction. Water (aquatic) structures
 629 Transport vehicle engineering
 63 Agriculture and related sciences and techniques. Forestry. Farming. Wildlife exploitation
 630 Forestry
 631/635 Farm management. Agronomy. Horticulture
 633/635 Horticulture in general. Specific crops
 636 Animal husbandry and breeding in general. Livestock rearing. Breeding of domestic animals
 64 Home economics. Domestic science. Housekeeping
 65 Communication and transport industries. Accountancy. Business management. Public relations
 654 Telecommunication and telecontrol (organization, services)
 655 Graphic industries. Printing. Publishing. Book trade
 656 Transport and postal services. Traffic organization and control
 657 Accountancy
 658 Business management, administration. Commercial organization
 659 Publicity. Information work. Public relations
 66 Chemical technology. Chemical and related industries
 67 Various industries, trades and crafts
 68 Industries, crafts and trades for finished or assembled articles
 69 Building (construction) trade. Building materials. Building practice and procedure
7 The arts. Recreation. Entertainment. Sport.
 "7.01/.09 Special auxiliary subdivision for the arts"
 "7.01 Theory and philosophy of art. Principles of design, proportion, optical effect"
 "7.02 Art technique. Craftsmanship"
 "7.03 Artistic periods and phases. Schools, styles, influences"
 "7.04 Subjects for artistic representation. Iconography. Iconology"
 "7.05 Applications of art (in industry, trade, the home, everyday life)"
 "7.06 Various questions concerning art"
 "7.07 Occupations and activities associated with the arts and entertainment"
 "7.08 Characteristic features, forms, combinations etc. (in art, entertainment and sport)"
 "7.091 Performance, presentation (in original medium)"
 71 Physical planning. Regional, town and country planning. Landscapes, parks, gardens
 72 Architecture
 73 Plastic arts
 74 Drawing. Design. Applied arts and crafts
 745/749 Industrial and domestic arts and crafts. Applied arts
 75 Painting
 76 Graphic art, printmaking. Graphics
 77 Photography and similar processes
 78 Music
 79 Recreation. Entertainment. Games. Sport
 791 Cinema. Films (motion pictures)
 792 Theatre. Stagecraft. Dramatic performances
 793 Social entertainments and recreations. Art of movement. Dance
 794 Board and table games (of thought, skill and chance)
 796 Sport. Games. Physical exercises
 797 Water sports. Aerial sports
 798 Riding and driving. Horse and other animal sports
 799 Sport fishing. Sport hunting. Shooting and target sports
8 Language. Linguistics. Literature.
 80 General questions relating to both linguistics and literature. Philology
 801 Prosody. Auxiliary sciences and sources of philology
 808 Rhetoric. The effective use of language 
 81 Linguistics and languages
 "81`1/`4 Special auxiliary subdivision for subject fields and facets of linguistics and languages"
 " 81`1 General linguistics"
 "81`2 Theory of signs. Theory of translation. Standardization. Usage. Geographical linguistics"
 "81`3 Mathematical and applied linguistics. Phonetics. Graphemics. Grammar. Semantics. Stylistics"
 "81`4 Text linguistics, Discourse analysis. Typological linguistics"
 "81`42 Text linguistics. Discourse analysis"
 "81`44 Typological linguistics"
 811 Languages
 811.1/.9 All languages natural or artificial
 811.1/.8 Individual natural languages
 811.1/.2 Indo-European languages
 811.21/.22 Indo-Iranian languages
 811.3 Dead languages of unknown affiliation. Caucasian languages
 811.4 Afro-Asiatic, Nilo-Saharan, Congo-Kordofanian, Khoisan languages
 811.5 Ural-Altaic, Palaeo-Siberian, Eskimo-Aleut, Dravidian and Sino-Tibetan languages. Japanese. Korean. Ainu
 811.6 Austro-Asiatic languages. Austronesian languages
 811.7 Indo-Pacific (non-Austronesian) languages. Australian languages
 811.8 American indigenous languages
 811.9 Artificial languages
 82 Literature
 "82-1/-9 Special auxiliary subdivision for literary forms, genres"
 "82-1 Poetry. Poems. Verse"
 "82-2 Drama. Plays"
 "82-3 Fiction. Prose narrative"
 "82-31 Novels. Full-length stories"
 "82-32 Short stories. Novellas"
 "82-4 Essays"
 "82-5 Oratory. Speeches"
 "82-6 Letters. Art of letter-writing. Correspondence. Genuine letters"
 "82-7 Prose satire. Humour, epigram, parody"
 "82-8 Miscellanea. Polygraphies. Selections"
 "82-9 Various other literary forms"
 "82-92 Periodical literature. Writings in serials, journals, reviews"
 "82-94 History as literary genre. Historical writing. Historiography. Chronicles. Annals. Memoirs"
 "82.02/.09 Special auxiliary subdivision for theory, study and technique of literature"
 "82.02 Literary schools, trends and movements"
 "82.09 Literary criticism. Literary studies"
 "82.091 Comparative literary studies. Comparative literature"
 821 Literatures of individual languages and language families
9 Geography. Biography. History.
 902/908 Archaeology. Prehistory. Cultural remains. Area studies
 902 Archaeology
 903 Prehistory. Prehistoric remains, artefacts, antiquities
 904 Cultural remains of historical times
 908 Area studies. Study of a locality
 91 Geography. Exploration of the Earth and of individual countries. Travel. Regional geography
 910 General questions. Geography as a science. Exploration. Travel
 911 General geography. Science of geographical factors (systematic geography). Theoretical geography
 911.2 Physical geography
 911.3 Human geography (cultural geography). Geography of cultural factors
 911.5/.9 Theoretical geography
 912 Nonliterary, nontextual representations of a region
 913 Regional geography
 92 Biographical studies. Genealogy. Heraldry. Flags
 929 Biographical studies
 929.5 Genealogy
 929.6 Heraldry
 929.7 Nobility. Titles. Peerage
 929.9 Flags. Standards. Banners
 93/94 History
 930 Science of history. Historiography
 930.1 History as a science
 930.2 Methodology of history. Ancillary historical sciences
 930.25 Archivistics. Archives (including public and other records)
 930.85 History of civilization. Cultural history
 94 General
Common Auxiliary Tables.
Common auxiliaries of language. Table 1c.
 =1/=9 Languages (natural and artificial)
 =1/=8 Natural languages
 =1/=2 Indo-European languages
 =1 Indo-European languages of Europe
 =11 Germanic languages
 =12 Italic languages
 =13 Romance languages
 =14 Greek (Hellenic)
 =15 Celtic languages
 =16 Slavic languages
 =17 Baltic languages
 =18 Albanian
 =19 Armenian
 =2 Indo-Iranian, Nuristani (Kafiri) and dead Indo-European languages
 =21/=22 Indo-Iranian languages
 =21 Indic languages
 =22 Iranian languages
 =29 Dead Indo-European languages (not listed elsewhere)
 =3 Dead languages of unknown affiliation. Caucasian languages
 =34 Dead languages of unknown affiliation, spoken in the Mediterranean and Near East (except Semitic)
 =35 Caucasian languages
 =4 Afro-Asiatic, Nilo-Saharan, Congo-Kordofanian, Khoisan languages
 =41 Afro-Asiatic (Hamito-Semitic) languages
 =42 Nilo-Saharan languages
 =43 Congo-Kordofanian (Niger-Kordofanian) languages
 =45 Khoisan languages
 =5 Ural-Altaic, Palaeo-Siberian, Eskimo-Aleut, Dravidian and Sino-Tibetan languages. Japanese. Korean. Ainu
 =51 Ural-Altaic languages
 =521 Japanese
 =531 Korean
 =541 Ainu
 =55 Palaeo-Siberian languages
 =56 Eskimo-Aleut languages
 =58 Sino-Tibetan languages
 =6 Austro-Asiatic languages. Austronesian languages
 =61 Austro-Asiatic languages
 =62 Austronesian languages
 =7 Indo-Pacific (non-Austronesian) languages. Australian languages
 =71 Indo-Pacific (non-Austronesian) languages
 =72 Australian languages
 =8 American indigenous languages
 =81 Indigenous languages of Canada, USA and Northern-Central Mexico
 =82 Indigenous languages of western North American Coast, Mexico and Yucatán
 =84/=88 Central and South American indigenous languages
 =84 Ge-Pano-Carib languages. Macro-Chibchan languages
 =85 Andean languages. Equatorial languages
 =86 Chaco languages. Patagonian and Fuegian languages
 =88 Isolated, unclassified Central and South American indigenous languages
 =9 Artificial languages
 =92 Artificial languages for use among human beings. International auxiliary languages (interlanguages)
 =93 Artificial languages used to instruct machines. Programming languages. Computer languages
(0...) Common auxiliaries of form. Table 1d.
 "(0.02/.08) Special auxiliary subdivision for document form"
 "(0.02) Documents according to physical, external form"
 "(0.03) Documents according to method of production"
 "(0.032) Handwritten documents (autograph, holograph copies). Manuscripts. Pictorial documents (drawings, paintings)"
 "(0.034) Machine-readable documents"
 "(0.04) Documents according to stage of production"
 "(0.05) Documents for particular kinds of user"
 "(0.06) Documents according to level of presentation and availability"
 "(0.07) Supplementary matter issued with a document"
 "(0.08) Separately issued supplements or parts of documents"
 (01) Bibliographies
 (02) Books in general
 (03) Reference works
 (04) Non-serial separates. Separata
 (041) Pamphlets. Brochures
 (042) Addresses. Lectures. Speeches
 (043) Theses. Dissertations
 (044) Personal documents. Correspondence. Letters. Circulars
 (045) Articles in serials, collections etc. Contributions
 (046) Newspaper articles
 (047) Reports. Notices. Bulletins
 (048) Bibliographic descriptions. Abstracts. Summaries. Surveys
 (049) Other non-serial separates
 (05) Serial publications. Periodicals
 (06) Documents relating to societies, associations, organizations
 (07) Documents for instruction, teaching, study, training
 (08) Collected and polygraphic works. Forms. Lists. Illustrations. Business publications
 (09) Presentation in historical form. Legal and historical sources
 (091) Presentation in chronological, historical form. Historical presentation in the strict sense
 (092) Biographical presentation
 (093) Historical sources
 (094) Legal sources. Legal documents
(1/9) Common auxiliaries of place. Table 1e.
 (1) Place and space in general. Localization. Orientation
 "(1-0/-9) Special auxiliary subdivision for boundaries and spatial forms of various kinds"
 "(1-0) Zones"
 "(1-1) Orientation. Points of the compass. Relative position"
 "(1-11) East. Eastern"
 "(1-13) South. Southern"
 "(1-14) South-west. South-western"
 "(1-15) West. Western"
 "(1-17) North. Northern"
 "(1-19) Relative location, direction and orientation"
 "(1-2) Lowest administrative units. Localities"
 "(1-5) Dependent or semi-dependent territories"
 "(1-6) States or groupings of states from various points of view"
 "(1-7) Places and areas according to privacy, publicness and other special features"
 "(1-8) Location. Source. Transit. Destination"
 "(1-9) Regionalization according to specialized points of view"
 (100) Universal as to place. International. All countries in general
 (2) Physiographic designation
 (20) Ecosphere
 (21) Surface of the Earth in general. Land areas in particular. Natural zones and regions
 (23) Above sea level. Surface relief. Above ground generally. Mountains
 (24) Below sea level. Underground. Subterranean
 (25) Natural flat ground (at, above or below sea level). The ground in its natural condition, cultivated or inhabited
 (26) Oceans, seas and interconnections
 (28) Inland waters
 (29) The world according to physiographic features
 (3) Places of the ancient and mediaeval world
 (31) Ancient China and Japan
 (32) Ancient Egypt
 (33) Ancient Roman Province of Judaea. The Holy Land. Region of the Israelites
 (34) Ancient India
 (35) Medo-Persia
 (36) Regions of the so-called barbarians
 (37) Italia. Ancient Rome and Italy
 (38) Ancient Greece
 (399) Other regions. Ancient geographical divisions other than those of classical antiquity
 (4/9) Countries and places of the modern world
 (4) Europe
 (5) Asia
 (6) Africa
 (7) North and Central America
 (8) South America
 (9) States and regions of the South Pacific and Australia. Arctic. Antarctic
(=...) Common auxiliaries of human ancestry, ethnic grouping and nationality. Table 1f.
 (=01) Human ancestry groups
 (=011) European Continental Ancestry Group
 (=012) Asian Continental Ancestry Group
 (=013) African Continental Ancestry Group
 (=014) Oceanic Ancestry Group
 (=017) American Native Continental Ancestry Group
 (=1/=8) Linguistic-cultural groups, ethnic groups, peoples [derived from Table 1c]
 (=1:1/9) Peoples associated with particular places
 "e.g. (=111:71) Anglophone population of Canada"
"..." Common auxiliaries of time. Table 1g.
 "0/2" Dates and ranges of time (CE or AD) in conventional Christian (Gregorian) reckoning
 "0" First millennium CE
 "1" Second millennium CE
 "2" Third millennium CE
 "3/7" Time divisions other than dates in Christian (Gregorian) reckoning
 "3" Conventional time divisions and subdivisions: numbered, named, etc.
 "4" Duration. Time-span. Period. Term. Ages and age-groups
 "5" Periodicity. Frequency. Recurrence at specified intervals.
 "6" Geological, archaeological and cultural time divisions
 "61/62" Geological time division
 "63" Archaeological, prehistoric, protohistoric periods and ages
 "67/69" Time reckonings: universal, secular, non-Christian religious
 "67" Universal time reckoning. Before Present
 "68" Secular time reckonings other than universal and the Christian (Gregorian) calendar
 "69" Dates and time units in non-Christian (non-Gregorian) religious time reckonings
 "7" Phenomena in time. Phenomenology of time
-0 Common auxiliaries of general characteristics. Table 1k.
 -02 Common auxiliaries of properties
 -021 Properties of existence
 -022 Properties of magnitude, degree, quantity, number, temporal values, dimension, size
 -023 Properties of shape
 -024 Properties of structure. Properties of position
 -025 Properties of arrangement
 -026 Properties of action and movement
 -027 Operational properties
 -028 Properties of style and presentation
 -029 Properties derived from other main classes
 -03 Common auxiliaries of materials
 -032 Naturally occurring mineral materials
 -033 Manufactured mineral-based materials
 -034 Metals
 -035 Materials of mainly organic origin
 -036 Macromolecular materials. Rubbers and plastics
 -037 Textiles. Fibres. Yarns. Fabrics. Cloth
 -039 Other materials
 -04 Common auxiliaries of relations, processes and operations
 -042 Phase relations
 -043 General processes
 -043.8/.9 Processes of existence
 -045 Processes related to position, arrangement, movement, physical properties, states of matter
 -047/-049 General operations and activities
 -05 Common auxiliaries of persons and personal characteristics
 -051 Persons as agents, doers, practitioners (studying, making, serving etc.)
 -052 Persons as targets, clients, users (studied, served etc.)
 -053 Persons according to age or age-groups
 -054 Persons according to ethnic characteristics, nationality, citizenship etc.
 -055 Persons according to gender and kinship
 -056 Persons according to constitution, health, disposition, hereditary or other traits
 -057 Persons according to occupation, work, livelihood, education
 -058 Persons according to social class, civil status
See also.
Special classifications based on or used in combination with UDC
Other faceted classifications:
Other general bibliographic classifications

</doc>
<doc id="32131" url="http://en.wikipedia.org/wiki?curid=32131" title="Ultima (series)">
Ultima (series)

Ultima is a series of open world fantasy role-playing video games from Origin Systems, Inc. "Ultima" was created by Richard Garriott, a.k.a. Lord British. Several games of the series are considered seminal entries in their genre. Electronic Arts currently holds the brand.
Games.
The main "Ultima" series consists of nine installments (the seventh title is further divided into two parts) grouped into three trilogies, or "Ages": The Age of Darkness ("Ultima I-III"), The Age of Enlightenment ("Ultima IV-VI"), and The Age of Armageddon ("Ultima VII-IX"). The last is also sometimes referred to as "The Guardian Saga" after its chief antagonist. The first trilogy is set in a fantasy world named Sosaria, but during the cataclysmic events of The Age of Darkness, it is sundered and three quarters of it vanish. What is left becomes known as Britannia, a realm ruled by the benevolent Lord British, and is where the later games mostly take place. The protagonist in all the games is a canonically male resident of Earth who is called upon by Lord British to protect Sosaria and, later, Britannia from a number of dangers. Originally, the player character was referred to as "the Stranger", but by the end of "Ultima IV" he becomes universally known as the Avatar.
Main series.
The Age of Darkness: "Ultima I–III".
In (1981), the Stranger is first summoned to Sosaria to defeat the evil wizard Mondain who aims to enslave it. Since Mondain possesses the Gem of Immortality, which makes him invulnerable, the Stranger locates a time machine, travels back in time to kill Mondain before he creates the Gem, and shatters the incomplete artifact.
 (1982) details Mondain's secret student and lover Minax's attempt to avenge him. Minax launches an attack on the Stranger's homeworld of Earth. Her actions cause doorways to open to various times and locations throughout Earth's history, and brings forth legions of monsters to all of them. The Stranger, after obtaining the Quicksword that alone can harm her, locates the evil sorceress at Castle Shadowguard at the origin of time and defeats her.
 (1983) reveals that Mondain and Minax had an offspring, the eponymous Exodus, "neither human, nor machine", according to the later games (it is depicted as a computer at the conclusion of the game, and it appears to be a demonic, self-aware artificial intelligence). Some time after Minax's death, Exodus starts his own attack on Sosaria and the Stranger is summoned once again to destroy it. "Exodus" was the first installment of the series featuring a player party system, which was used in many later games.
The Age of Enlightenment: "Ultima IV–VI".
 (1985) marked a turning point in the series from the traditional "hero vs. villain" plots, instead introducing a complex alignment system based upon the Eight Virtues derived from the combinations of the Three Principles of Love, Truth and Courage. Although Britannia now prospers under Lord British's rule, he fears for his subjects' spiritual well-being and summons the Stranger again to become a spiritual leader of Britannian people by example. Throughout the game, the Stranger's actions determine how close he comes to the ideal. Upon achieving enlightenment in every Virtue, he can reach the Codex of Ultimate Wisdom and becomes the "Avatar", the embodiment of Britannia's virtues.
In (1988), the Avatar returns to Britannia to find that after Lord British had been lost in the Underworld, Lord Blackthorn, who rules in his stead, was corrupted by the Shadowlords and enforces a radically twisted vision of the Virtues, deviating considerably from their original meaning. The Avatar and his companions proceed to rescue the true king, overthrow the tyrant and restore the Virtues in their true form.
 (1990) details the invasion of Britannia by Gargoyles, which the Avatar and his companions have to repel. Over the course of the game it is revealed that the Gargoyles have valid reasons to loathe the Avatar. Exploring the themes of racism and xenophobia, the game tasks the Avatar with understanding and reconciling two seemingly opposing cultures.
The Age of Armageddon: "Ultima VII–IX".
 (1992) sees the Avatar entangled in the plan of an ostensibly virtuous and benevolent organization named the Fellowship (inspired by Scientology) to create a gateway for the evil entity known as the Guardian to enter Britannia. An expansion pack was released named Forge of Virtue that added a newly arisen volcanic island to the map that the Avatar was invited to investigate. The tie-in storyline was limited to this island, where a piece of Exodus (his data storage unit) had resurfaced. To leave the island again, the Avatar had to destroy this remnant of Exodus. In the process of doing so, he also created The Black Sword, an immensely powerful weapon possessed by a demon.
 (1993) was released as the second part of "Ultima VII" because it used the same game engine as Ultima VII. According to interviews, Richard Garriott felt it therefore did not warrant a new number. Production was rushed due to deadlines set to the developers, and the storyline was cut short; remains of the original, longer storyline can be found in the database. Following the Fellowship's defeat, its founder Batlin flees to the Serpent Isle, pursued by the Avatar and companions. Serpent Isle is revealed as another fragment of former Sosaria, and its history which is revealed throughout the game provides many explanations and ties up many loose ends left over from the Age of Darkness era. Magical storms herald the unraveling of the dying world's very fabric, and the game's mood is notably melancholic, including the voluntary sacrificial death of a long-standing companion of the Avatar. By the end of the game, the Avatar is abducted by the Guardian and thrown into another world, which becomes the setting for the next game in the series. The Silver Seed was an expansion pack for "Ultima VII Part 2" where the Avatar travels back in time to plant a silver seed, thus balancing the forces that hold the Serpent Isle together. Like "Forge of Virtue", the expansion contained an isolated sub-quest that was irrelevant to the main game's storyline, but provided the Avatar with a plethora of useful and powerful artifacts.
In (1994), the Avatar finds himself exiled by the Guardian to a world called "Pagan". The Britannic Principles and Virtues are unknown here. Pagan is ruled by the Elemental Titans, god-like servants of the Guardian. The Avatar defeats them with their own magic, ascending to demi-godhood himself, and finally returns to Britannia. A planned expansion pack, "The Lost Vale", was canceled after "Ultima VIII" failed to meet sales expectations.
 (1999), the final installment of the series, sees Britannia conquered and its Virtues corrupted by the Guardian. The Avatar has to cleanse and restore them. The Guardian is revealed to be the evil part of the Avatar himself, expelled from him when he became the Avatar. To stop it, he has to merge with it, destroying himself as a separate entity. The featured a more apocalyptic ending, with the Guardian and Lord British killed, Britannia destroyed, and the Avatar ascending to a higher plane of existence.
Spin-offs and other games.
"" was released in 1980, and is sometimes considered a prequel to the "Ultima" series.
Sierra On-Line also produced "" in 1983. The maze game has little in common with the others, but is highly sought after by collectors due to extreme rarity.
The Worlds of Ultima series is a spin-off of "Ultima VI" using the same game engine, following the Avatar's adventures after the game's conclusion. In (1990), a failed experiment transports the Avatar to the Valley of Eodon, a jungle world populated by thirteen primitive tribes whom he must unite against a common enemy, the insectoid Myrmidex. (1991) takes place after "The Savage Empire" and sees the Avatar travel back in time to the Victorian era and eventually land on Mars to rescue humans stranded on it by accident and to restore the native Martian civilization. The third game, "Ultima: Worlds of Adventure 3: Arthurian Legends", was planned to be set in the times of King Arthur but was canceled in 1993.
The second spin-off series, , consisted of two games. Set after "Ultima VI", (1992) sees the Avatar descending into the Great Stygian Abyss to rescue a Britannian baron's kidnapped daughter and prevent the summoning of a powerful demon. (1993) is set between the two parts of "Ultima VII" and starts with the Guardian trapping Lord British, the Avatar and his companions within an impenetrable barrier in their castle. To free them, the Avatar has to travel through several parallel universes looking for a way to undo the spell.
A group of volunteer programmers created "" in 2006, a remake of "Ultima V" using the "Dungeon Siege" engine. And another group of volunteer programmers created "Ultima VI Project" in 2010, a remake of "Ultima VI" using also the "Dungeon Siege" engine.
Console games.
Console versions of "Ultima" have allowed further exposure to the series, especially in Japan where the games have been bestsellers and were accompanied by several tie-in products including "Ultima" manga.
In most cases, gameplay and graphics have been changed significantly.
"Ultima Online" MMORPG.
Ultima Online (1997), a MMORPG spin-off of the main series, has become an unexpected hit, making it one of the earliest and longest-running successful MMORPGs of all time. Its lore retconned the ending of "Ultima I", stating that when the Stranger shattered the Gem of Immortality, he discovered that it was tied to the world itself, therefore its shards each contained a miniature version of Britannia. The player characters in "Ultima Online" exist on these "shards". Eight expansion packs for "UO" have been released (', ', ', ', ', ', ' and ') . The aging "UO" graphic engine was renewed in 2007 with the official ' client. "Ultima Online 2", later renamed to ' and canceled in 2001, would have introduced steampunk elements to the game world, following Lord British's unsuccessful attempt to merge past, present, and future shards together.
"UO" spawned two sequel efforts that were canceled before release: ' (canceled in 2001, though the game's storyline was published in the Technocrat War trilogy.) and ' (canceled in 2004). (2004) would have continued the story of "Ultima IX". Now merged with the Guardian, the Avatar creates a world of Alucinor inside his mind, where the players were supposed to pursue the Eight Virtues in order to strengthen him and weaken the Guardian. "Ultima X" was developed without participation of the original creator Richard Garriott and he no longer owns the rights to the series. However, he still owns the rights to several of the game characters so it is impossible for either him or Electronic Arts to produce a new "Ultima" title without getting permission from each other.
"Lord of Ultima".
"Lord of Ultima" is a free-to-play browser-based MMORTS released in 2010 by EA Phenomic. It is the first release in the "Ultima" series since "Ultima Online", and also the first title to have no involvement from series creator Garriott or founding company Origin. It has been criticized for having slow-paced gameplay and very weak connections to the Ultima franchise lore.
EA has announced that "Lord of Ultima" will be shut down and taken offline as of May 12, 2014.
"Ultima Forever: Quest for the Avatar".
Announced in summer 2012, "Ultima Forever" is a free-to-play online action role-playing game. In contrast to "Lord of Ultima", "Ultima Forever" returns to the lore of the original game series.
As of August 29, 2014. Ultima Forever's servers were shut down.
Other media.
Several novels were released under the "Ultima" name, including:
In Japan, an "Ultima" soundtrack CD, two kinds of wrist watches, a tape dispenser, a pencil holder, a board game, a jacket, and a beach towel were released. There was also an "Ultima" anime cartoon.
Three manga comics were released in Japan:
Packaging.
"Ultima" game boxes often contained so-called "feelies"; e.g. from "Ultima II" on, every game in the main series came with a cloth map of the game world. Starting with "Ultima IV", small trinkets like pendants, coins and magic stones were found in the boxes. Made of metal or glass, they usually represented an important object also found within the game itself.
Not liking how games were sold in zip lock bags with a few pages printed out for instructions, Richard Garriott insisted "Ultima II" be sold in a box, with a cloth map, and a manual. Sierra was the only company at that time willing to agree to this, and thus he signed with them.
Anti-piracy measures.
In the Atari 8bit version of "Ultima IV" one of the floppy disks had an unformatted track. In its absence the player would lose on every fight, which would not be obvious as a copy protection effect right away as one could assume that this was just due to either lack of experience or proper equipment. The protection mechanism was subtle enough to be overlooked by the German distributor which originally delivered Atari 8bit packages with floppies that were formatted regularly, and thus these paid copies acted like pirated copies, causing players to lose every battle.
In "Ultima V", there were one or two instances where ostensibly insignificant information found in the accompanying booklet were asked by person(s) encountered in the game. The game also used runic script in some places and a special language for spell names, for both of which the necessary translation tables / explanations were provided in the booklet. These can be seen as subtle copy-protection measures, well fitted for the context of history and fantasy so that a casual player didn't take them for copy protection.
"Ultima VI" introduced a more systematic use of copy protection in the form of in-game questions, preventing the player from progressing any further if the questions were answered incorrectly. In "Ultima VII", this practice was continued, although in both games the player had an unlimited number of tries to answer the questions correctly. Answers could be obtained by consulting the manual or cloth map, although the manual released with the "Ultima Collection" contained all copy protection answers for every game.
In "Ultima VII Part 2: Serpent Isle", the copy protection was changed slightly. Players were asked questions at two points in the game, and if they could not answer after two attempts, all NPCs said nothing but altered versions of famous quotes, such as "My kingdom for a hammer!", "Honor thy father and thy hoe, babycakes" and "Oh my, twig, I don't think we're in Britannia anymore". Everything would also be labeled "Oink!", preventing the game from being playable. From Ultima VIII onward, copy protection questions were discontinued.
Common elements.
Setting.
Originally, the world of "Ultima" was made up of four continents. These were Lord British's Realm, ruled by Lord British and the Lost King; The Lands of Danger and Despair, ruled by Lord Shamino and the King of the White Dragon; The Lands of the Dark Unknown, ruled by Lord Olympus and the King of the Black Dragon; and The Lands of the Feudal Lords, ruled by the lords of Castle Rondorin and Castle Barataria.
After the defeat of Mondain and the shattering of his Gem of Immortality in "Ultima I", there was a cataclysm that changed the structure of the world. Three of the four continents seemingly disappeared, leaving only Lord British's realm in the world. This remaining continent was referred from then on as "Sosaria". The Lands of Danger and Despair were later rediscovered as the Serpent Isle, which had been moved to a different dimension or plane, so it seems likely that the other two continents still exist. "Ultima II" shows Castle Barataria on Planet X, suggesting that the Lands of the Feudal Lords became this planet; "Ultima Online: Samurai Empire" posits that the Lands of the Feudal Lords was transformed into the Tokuno Islands by the cataclysm.
After the defeat of Exodus in "Ultima III", Sosaria became Britannia in order to honor its ruler, Lord British. Serpent Isle remained connected with Britannia via a gate in the polar region. The Fellowship leader, Batlin, fled here after the Black Gate was destroyed in "Ultima VII", preventing the Guardian's first invasion. Ninety percent of the island's population was destroyed by evil Banes released by Batlin in a foolish attempt to capture them for his own use in "Ultima VII Part 2".
Virtues.
In Ultima, the player takes the role of the Avatar, who embodies eight virtues. First introduced in , the Three Principles and the Eight Virtues marked a reinvention of the game focus from a traditional role-playing model into an ethically framed one. Each virtue is associated with a party member, one of Britannia's cities, and one of the eight other planets in Britannia's solar system. Each virtue also has a mantra and each principle a word of power that the player must learn. The Eight Virtues explored in "Ultima" are Honesty, Compassion, Valor, Justice, Sacrifice, Honor, Spirituality, and Humility. These Eight Virtues are based on the Three Principles of Truth, Love, and Courage. The Principles are derived from the One True Axiom, the combination of all Truth, all Love, and all Courage, which is Infinity.
The virtues were first introduced in "" (1985), where the goal of the game is to practice them and become a moral exemplar. Virtues and their variations are present in all later installments. Richard Garriott's motives in designing the virtue system were to build on the fact that games were provoking thought in the player, even unintentionally. As a designer, he "wasn't interested in teaching any specific lesson; instead, his next game would be about making people think about the consequences of their actions." The original virtue system in Ultima was partially inspired by the 16 ways of purification which lead to Avatarhood in Hinduism. He also drew on his interpretation of characters from "The Wizard of Oz", with the Scarecrow representing truth, the Tin Woodsman representing love, and the Cowardly Lion representing courage.
The Virtues have become a frequent theme in the Ultima games following "," with many different variants used throughout the series. ' saw Lord Blackthorn turn the virtue system into a rigid and draconian set of laws. The rigid system of Blackthorn unintentionally causes the Virtues to actually achieve their polar opposites, in part due to the influence of the Shadowlords. This shows that the Virtues always come from one's own self, and that codifying ethics into law does not automatically make evil people good. ' confronted the Avatar with the fact that, from another point of view, the Avatar's quests for Virtue may not appear virtuous at all, presenting an alternative set of virtues. In ', an order known as the Fellowship displaced the Virtues with its own seemingly benevolent belief system, casting Britannia into disarray; and in ', the Virtues had been inverted into their opposite anti-virtues.
Ultima's virtue system was considered a new frontier in game design, and has become "an industry standard, especially within role-playing games." The original system from "Ultima IV" has influenced moral systems in games such as "Black & White", "" and the "Fable" series. However, Ultima can only be won by being virtuous, while other games typically offer a choice to be vicious. Mark Hayse specifically praises Ultima's virtue system for its subtlety. The game emphasizes the importance of virtue, but leaves the practice ambiguous with no explicit point values and limited guidance. This makes the virtue system more of a "philosophical journey" than an ordinary game puzzle.
Artificial scripts.
The "Ultima" series of computer games employed several different artificial scripts. The people of Britannia, the fantasy world where the games are set, speak English, and most of the day-to-day things are written in Latin alphabet. However, there still are other scripts, which are used by tradition.
Britannian runes are the most commonly seen script. In many of the games of the series, most of the signs are written in runes, with no actual transcription for them given. The runes are based on Germanic runes, but are slightly different. They are very reminiscent of the Dwarven runes in Tolkien's The Lord of the Rings, which Ultima creator Richard Garriott has stated he has read. The runes have been used since the early games. They gained steadier use in the games proper since ', which was the first game in series to feature a runic font and use it for most of the display of various signs. Earlier games featured runes only in other graphics; for example, in ', visions from meditating use runic letters. The runes are used less in "" and in later games.
Gargish is the language of the gargoyles of Britannia and the language used in spellcasting within the game. The language is complex and flexible, but the vocabulary is prohibitively small, limiting its use. The Gargish language has its own alphabet, although it can also be written in the Latin alphabet. The difference between nouns, verbs, and adjectives is expressed through intonations and gestures. Because of this, written Gargish uses suffixes to denote part of speech, grammatical tense, and grammatical aspect. In some cases, these suffixes are also used as independent words. Gargoyles avoid using pronouns or verb tense unless it is crucial to comprehension; therefore the language is often spoken in the infinitive (e.g., "To say hello"). The Gargish alphabet is featured in ', though it is seen in the games very rarely. ' and onward does not feature anything written in the alphabet, with the sole exception of some books to be found in the gargoyle colony in the underwater city of Ambrosia in "". The Gargish language and alphabet were designed by Herman Miller.
The Ophidian alphabet, featured in "Ultima VII Part Two: Serpent Isle", was used by the ophidian civilization that inhabited the Serpent Isle. It is based on various snake forms. Ophidian lettering was quite difficult to read, so the game included a "Translation" spell that made the letters look like Latin letters.
Reception.
In 1996, "Next Generation" ranked the "Ultima" series as collectively the 55th top game of all time, commenting that "while the graphics and playing style change with the technological leaps of the day, [it] has been the most consistent source roleplaying excitment in history." In 2000, Britannia was included in GameSpot's list of the ten best game worlds, called "the oldest and one of the most historically rich gameworlds."
Impact and legacy.
"Ultima" and "Wizardry" dominated the computer role-playing game industry in the early 1980s; a historian later wrote that "there seemed to be very little oxygen for anyone else; their serious competition during this period was largely limited to one another. Otherwise there were only ... workmanlike derivatives" like "Questron" "that all but advertised themselves as 'games to play while you wait for the next "Ultima" or "Wizardry"‍ '​".
Many innovations of the early "Ultimas" – in particular "" (1983) – eventually became standard among later RPGs, such as the use of tiled graphics and party-based combat, its mix of fantasy and science-fiction elements, and the introduction of time travel as a plot device. In turn, some of these elements were inspired by "Wizardry", specifically the party-based combat. "Exodus" was also revolutionary in its use of a written narrative to convey a larger story than the typically minimal plots that were common at the time. Most video games – including Garriott's own "Ultima I" and "II" and "Akalabeth" – tended to focus primarily on things like combat without venturing much further. In addition, Garriott would introduce in "Ultima IV" a theme that would persist throughout later "Ultimas" – a system of chivalry and code of conduct in which the player, or "Avatar", is tested periodically (in both obvious and unseen ways) and judged according to his or her actions. This system of morals and ethics was unique, in that in other video games players could for the most part act and do as they wished without having to consider the consequences of their actions.
"Ultima III" would go on to be released for many other platforms and influence the development of such RPGs as "Excalibur" and "Dragon Quest"; and many consider the game to be the first modern CRPG.
"Shroud of the Avatar: Forsaken Virtues".
Richard Garriott's new company Portalarium is developing an RPG/MMORPG that Garriott has described as a clear spiritual successor of the "Ultima" series. On March 8, 2013, Portalarium launched a Kickstarter campaign for "". "Forsaken Virtues" is the first of five full-length episodic installments in "Shroud of the Avatar" and will be a "Selective Multiplayer Game" allowing the player to determine his or her level of multiplayer involvement that ranges from MMO to single player offline. Estimated availability of "Forsaken Virtues", is 2015, with Episodes 2 through 5 estimated for subsequent yearly releases. "Ultima Online" project director Starr Long has joined Portalarium as executive producer for "Shroud of the Avatar".
Notes.
</dl>

</doc>
<doc id="32133" url="http://en.wikipedia.org/wiki?curid=32133" title="Urethra">
Urethra

In anatomy, the urethra (from Greek οὐρήθρα – "ourḗthrā") is a tube that connects the urinary bladder to the urinary meatus for the removal of fluids from the body. In male placental mammals, the urethra travels through the penis, and carries semen as well as urine. In female placental mammals, the urethra is shorter and emerges at the female external urethral orifice above the vaginal opening.
Female placental mammals use their urethra only for urinating, but male placental mammals use their urethra for both urination and ejaculation. The external urethral sphincter is a striated muscle that allows voluntary control over urination.
Anatomy.
Female.
In the human female, the urethra is about 1.9 in to 2 in long and exits the body between the clitoris and the vagina, extending from the internal to the external urethral orifice. The meatus is located 28.9 mm below the clitoris. It is placed behind the symphysis pubis, embedded in the anterior wall of the vagina, and its direction is obliquely downward and forward; it is slightly curved with the concavity directed forward. The proximal 2/3rds is lined by transitional epithelium cells while distal 1/3rd is lined by stratified squamous epithelium cells. The urethra consists of three coats: muscular, erectile, and mucous, the muscular layer being a continuation of that of the bladder. Between the superior and inferior fascia of the urogenital diaphragm, the female urethra is surrounded by the Sphincter urethrae (urethral sphincter). Somatic (conscious) innervation of the external urethral sphincter is supplied by the pudendal nerve. The uro-genital sinus may be divided into three component parts. The first of these is the cranial portion which is continuous with the allantois and forms the bladder proper. The pelvic part of the sinus forms the prostatic urethra and epithelium as well as the membranous urethra and bulbo urethral glands in the male and the membranous urethra and part of the vagina in females.
The female urethra is about 4 cm in length.
Male.
See also: .
In the human male, the urethra is about 8 in long and opens at the end of the penis. The urethra provides an exit for urine as well as semen during ejaculation.
The urethra is divided into four parts in men, named after the location:
There is inadequate data for the typical length of the male urethra; however, a study of 109 men showed an average length of 22.3 cm (SD = 2.4 cm), ranging from 15 cm to 29 cm.
Histology.
The epithelium of the urethra starts off as transitional cells as it exits the bladder. Further along the urethra there are pseudostratified columnar and stratified columnar epithelia, then stratified squamous cells near the external urethral orifice.
There are small mucus-secreting urethral glands, that help protect the epithelium from the corrosive urine.
Physiology.
The urethra is the vessel through which urine passes after leaving the bladder.
Sexual physiology.
The male urethra is the conduit for semen during sexual intercourse. It also serves as a passage for urine to flow.
Urine typically contains epithelial cells shed from the urinary tract. Urine cytology evaluates this urinary sediment for the presence of cancerous cells from the lining of the urinary tract, and it is a convenient noninvasive technique for follow-up analysis of patients treated for urinary tract cancers. For this process, urine must be collected in a reliable fashion, and if urine samples are inadequate, the urinary tract can be assessed via instrumentation. In urine cytology, collected urine is examined microscopically. One limitation is the inability to definitively identify low-grade cancer cells and urine cytology is used mostly to identify high-grade tumors.
Clinical significance.
Investigations.
As the urethra is an open vessel with a lumen, investigations of the genitourinary tract may involve the urethra. Endoscopy of the bladder may be conducted by the urethra, called cystoscopy.
Catheterization.
During a hospital stay or surgical procedure, a catheter may be inserted through the urethra to drain urine from the bladder. The length of a male's urethra, and the fact it contains a prominent bend, makes catheterization more difficult. The integrity of the urethra can be determined by a procedure known as retrograde urethrogram.

</doc>
<doc id="32134" url="http://en.wikipedia.org/wiki?curid=32134" title="Urethritis">
Urethritis

Urethritis is inflammation of the urethra. The most common symptom is painful or difficult urination.
Signs and symptoms.
In men, purulent discharge usually indicates a urethritis of gonococcal nature, while clear discharge indicates urethritis of non-gonococcal nature. Urethritis is difficult to diagnose in women because discharge may not be present, however, the symptoms of dysuria and frequency may be present.
Causes.
The disease is classified as either gonococcal urethritis, caused by "Neisseria gonorrhoeae", or non-gonococcal urethritis (NGU), most commonly caused by "Chlamydia trachomatis". NGU, sometimes called non-specific urethritis (NSU), has both infectious and non-infectious causes.
Other causes include:
Diagnosis.
In female patients, urethritis can be caused by pelvic inflamatory disease.
With male patients, the physician examines the penis and testicles for soreness or any swelling. The urethra is visually examined by spreading the urinary meatus apart with two gloved fingers, and examining the opening for redness, discharge and other abnormalities. Next, a cotton swab is inserted 1–4 cm into the urethra and rotated once. To prevent contamination, no lubricant is applied to the swab, which can result in pain or discomfort. The swab is then smeared onto a glass slide and examined under a microscope. A commonly used cut-off for the diagnosis of urethritis is 5 or more granulocytes per High Power Field, but this definition has recently been called into doubt. The physician sometimes performs a digital rectal examination to inspect the prostate gland for swelling or infection.
A urinary tract infection may cause similar symptoms.
Prevention.
Risk of some causes of urethritis can be lessened by avoiding unprotected sexual activity, chemicals that could irritate the urethra; this could include detergents or lotions as well as spermicides or contraceptives, and irritation caused by manual manipulation of the urethra.
Treatment.
A variety of drugs may be prescribed based on the cause of the patient's urethritis. Some examples of medications based on causes include: azithromycin, doxycycline, erythromycin, levofloxacin, metronidazole, ofloxacin, or tinidazole.
Proper perineal hygiene should be stressed. This includes avoiding use of vaginal deodorant sprays and proper wiping after urination and bowel movements. Intercourse should be avoided until symptoms subside.

</doc>
<doc id="32135" url="http://en.wikipedia.org/wiki?curid=32135" title="United States Virgin Islands">
United States Virgin Islands

The Virgin Islands of the United States (commonly called the United States Virgin Islands, U.S. Virgin Islands, American Virgin Islands, or USVI) are a group of islands in the Caribbean that are an insular area of the United States. The islands are geographically part of the Virgin Islands archipelago and are located in the Leeward Islands of the Lesser Antilles.
The U.S. Virgin Islands consist of the main islands of Saint Croix, Saint John, and Saint Thomas, along with the much smaller but historically distinct Water Island, and many other surrounding minor islands. The total land area of the territory is 133.73 sqmi. The territory's capital is Charlotte Amalie on the island of Saint Thomas.
As of the 2010 U.S. Census, the population was 106,405, comprising mostly persons of Afro-Caribbean descent. Tourism is the primary economic activity, although there is a significant rum manufacturing sector. Farming is done on a smaller scale on the island of St. Croix, although it has seen a slow resurgence in recent years.
Formerly the Danish West Indies, they were sold to the United States by Denmark in the Treaty of the Danish West Indies of 1916. They are classified by the UN as a Non-Self-Governing Territory, and are currently an organized, unincorporated United States territory. The U.S. Virgin Islands are organized under the 1954 Revised Organic Act of the Virgin Islands and have since held five constitutional conventions. The last and only proposed Constitution, adopted by the Fifth Constitutional Convention in 2009, was rejected by the U.S. Congress in 2010, which urged the convention to reconvene to address the concerns Congress and the Obama Administration had with the proposed document. The convention reconvened in October 2012 to address these concerns, but was unable to produce a revised Constitution before its October 31 deadline.
History.
The Virgin Islands were originally inhabited by the Ciboney, Carib, and Arawaks. The islands were named by Christopher Columbus on his second voyage in 1493 for Saint Ursula and her virgin followers. Over the next two hundred years, the islands were held by many European powers, including Spain, Great Britain, the Netherlands, France, and Denmark-Norway.
The Danish West India Company settled on Saint Thomas in 1672, on Saint John in 1694, and purchased Saint Croix from France in 1733. The islands became royal Danish colonies in 1754, named the Danish-Westindian islands (Danish: "De dansk-vestindiske øer"). Sugarcane, produced by slave labor, drove the islands' economy during the 18th and early 19th centuries, until the abolition of slavery by Governor Peter von Scholten on July 3, 1848.
The Danish West India and Guinea Company represented the first Europeans to settle the Virgin Islands. They are also credited with naming the island St. John (Danish: Sankt Jan). The Danish crown took full control of Saint John in 1754, along with St. Thomas and St. Croix. Sugar plantations, such as the famous Annaberg Sugar Plantation, were established in great numbers on St. John because of the intense heat and fertile terrain, which provided ideal growing conditions. The establishment of sugar plantations also led to the importation of more slaves from Africa. St. John was the site of one of the first significant slave rebellions in the New World in 1733, when enslaved Akwamu rebels from the Gold Coast took over the island for six months.
The Danish were able to defeat the enslaved Africans with help from the French in Martinique. Instead of allowing themselves to be recaptured, more than a dozen men and women shot themselves before the French forces could capture them. It is estimated that by 1775, slaves outnumbered the Danish settlers by a ratio of 5:1. The indigenous Caribs and Arawaks were also used as slave labor, to the point of wiping out their entire population. Slavery was finally abolished in the Virgin Islands on July 3, 1848.
For the remainder of the period of Danish rule, the islands were not economically viable and significant transfers were made from the Danish state budgets to the authorities in the islands. In 1867 a treaty to sell Saint Thomas and Saint John to the United States was agreed, but the sale was never effected. A number of reforms aimed at reviving the islands' economy were attempted, but none had great success. A second draft treaty to sell the islands to the United States was negotiated in 1902 but was defeated in the upper house of the Danish parliament in a balanced ballot (because the opposition literally carried a 97-year-old life member into the chamber).
The onset of World War I brought the reforms to a close and again left the islands isolated and exposed. During the submarine warfare phases of the First World War, the United States, fearing that the islands might be seized by Germany as a submarine base, again approached Denmark with a view to buying them. After a few months of negotiations, a selling price of $25 million in United States gold coin was agreed (this is equivalent to $<br>{Inflation} - Amount must not have "" prefix: 25.   million in 2015 dollars). At the same time the economics of continued possession weighed heavily on the minds of Danish decision makers, and a consensus in favor of selling emerged in the Danish parliament.
The Treaty of the Danish West Indies was signed in August 1916, with a Danish referendum held in December 1916 to confirm the decision. The deal was finalized on January 17, 1917, when the United States and Denmark exchanged their respective treaty ratifications. The United States took possession of the islands on March 31, 1917 and the territory was renamed the Virgin Islands of the United States. Every year Transfer Day is recognized as a holiday, to celebrate the acquisition of the islands by the United States. U.S. citizenship was granted to the inhabitants of the islands in 1927.
Water Island, a small island to the south of Saint Thomas, was initially administered by the U.S. federal government and did not become a part of the U.S. Virgin Islands territory until 1996, when 50 acre of land was transferred to the territorial government. The remaining 200 acre of the island were purchased from the U.S. Department of the Interior in May 2005 for $10, a transaction which marked the official change in jurisdiction.
Hurricane Hugo struck the Virgin Islands in 1989, causing catastrophic physical and economic damage. The territory was again struck by Hurricane Marilyn in 1995, killing eight people and causing more than $2 billion in damage. The islands were again struck by Hurricanes Bertha, Georges, Lenny, and Omar in 1996, 1998, 1999, and 2008, respectively, but damage was not as severe in those storms.
Geography.
The U.S. Virgin Islands are in the Atlantic Ocean, about 40 mi east of Puerto Rico and immediately west of the British Virgin Islands. They share the Virgin Islands Archipelago with the Spanish Virgin Islands (administered by Puerto Rico) and the British Virgin Islands. The territory consists of four main islands: Saint Thomas, Saint John, Saint Croix, and Water Island, as well as several dozen smaller islands. The main islands have nicknames often used by locals: "Twin City" (St. Croix), "Rock City" (St. Thomas) and "Love City" (St. John). The combined land area of the islands is roughly twice the size of Washington, D.C.
The U.S. Virgin Islands are known for their white sand beaches, including Magens Bay and Trunk Bay, and strategic harbors, including Charlotte Amalie and Christiansted. Most of the islands, including Saint Thomas, are volcanic in origin and hilly. The highest point is Crown Mountain, Saint Thomas (1555 ft).
Saint Croix, the largest of the U.S. Virgin Islands, lies to the south and has a flatter terrain. The National Park Service owns more than half of Saint John, nearly all of Hassel Island, and many acres of coral reef. ("See also" Virgin Islands National Park, Virgin Islands Coral Reef National Monument, Buck Island Reef National Monument, Christiansted National Historic Site, and Salt River Bay National Historical Park and Ecological Preserve.)
The U.S. Virgin Islands lie on the boundary of the North American plate and the Caribbean Plate. Natural hazards include earthquakes and tropical cyclones (including hurricanes).
Climate.
The Islands experience a tropical savanna climate, affected by moderate trade winds.
Politics and government.
The U.S. Virgin Islands are an organized, unincorporated United States territory. Even though they are U.S. citizens, U.S. Virgin Islands residents cannot vote in presidential elections. U.S. Virgin Islands residents, however, are able to vote in presidential primary elections for delegates to the Democratic National Convention and the Republican National Convention. Unlike persons born on the mainland and naturalized citizens who derive their citizenship from the Fourteenth Amendment of the U.S. constitution, those born in the U.S. Virgin Islands derive their U.S. citizenship from Congressional statute.
The main political parties in the U.S. Virgin Islands are the Democratic Party of the Virgin Islands, the Independent Citizens Movement, and the Republican Party of the Virgin Islands. Additional candidates run as independents.
At the national level, the U.S. Virgin Islands elect a delegate to Congress from their at-large congressional district. However, the elected delegate, while able to vote in committee, cannot participate in floor votes. The current House of Representatives delegate is Stacey Plaskett (D).
At the territorial level, 15 senators – seven from the district of Saint Croix, seven from the district of Saint Thomas and Saint John, and one senator at-large who must be a resident of Saint John – are elected for two-year terms to the unicameral Virgin Islands Legislature.
The U.S. Virgin Islands have elected a territorial governor every four years since 1970. Previous governors were appointed by the President of the United States.
The U.S. Virgin Islands have a District Court, Superior Court and the Supreme Court. The District Court is responsible for federal law, while the Superior Court is responsible for U.S. Virgin Islands law at the trial level and the Supreme Court is responsible for appeals from the Superior Court for all appeals filed on or after January 29, 2007. Appeals filed prior to that date are heard by the Appellate Division of the District Court. Appeals from the federal District Court are heard by the United States Court of Appeals for the Third Circuit, located in Philadelphia, Pennsylvania. District Court judges are appointed by the President, while Superior Court and Supreme Court judges are appointed by the Governor.
On Oct 21, 1976, President Gerald Ford signed authorizing the people of the United States Virgin Islands to organize a government pursuant to a constitution, which would be automatically approved if Congress did not act within 60 days. On May 26, 2009 the U.S. Virgin Islands Fifth Constitutional Convention adopted a proposed a Constitution of the Virgin Islands, which was submitted by President Barack Obama to Congress on March 1, 2010. On June 30, 2010, President Obama signed in which Congress urged the constitutional convention to reconvene.
Administrative divisions.
Administratively, the U.S. Virgin Islands are divided into three (3) districts and twenty (20) sub-districts.
While a Danish possession, the Islands were divided into "quarters" (five on St. John and nine on St. Croix) which were further divided into many dozens of "estates". Estate names are still used to write addresses; estates and quarters are used in describing real estate, especially on St. John and St. Croix. More densely populated towns such as Frederiksted and Christiansted on St. Croix were historically referred to as "districts", in contrast to the surrounding plantation land.
Self-determination.
The U.S. Virgin Islands are on the United Nations list of Non-Self-Governing Territories. A 1993 referendum on status attracted only 31.4% turnout, and so its results (in favor of the status quo) were considered void. No further referenda have been scheduled since.
In 2004, the 25th Legislature of the Virgin Islands established the Fifth Constitutional Convention, a constitutional convention gathered in order to draft a new constitution. In June 2009, Governor John de Jongh, Jr. rejected the resulting constitutional draft, saying the document did "violate federal law, fail to defer to federal sovereignty and disregard basic civil rights". A lawsuit filed by members of the Convention to force Governor de Jongh to forward the document to President Barack Obama was ultimately successful. The President of the United States forwarded the proposal to Congress—which then had 60 days to approve or reject the document—in May 2010, along with a report noting concerns raised by the U.S. Department of Justice and restating the issues noted by Governor de Jongh. A U.S. Congressional resolution disapproving of the proposed constitution and requesting that the Fifth Constitutional Convention reconvene to consider changes to address these issues was signed into law by President Obama on June 30, 2010.
Months later, a federal lawsuit was filed in the Federal District Court of the Virgin Islands in 2011. The lawsuit claimed that the United States had to provide U.S. Virgin Islanders with the ability to be represented in Congress and vote for U.S. President. The case is Civil No. 3:11-cv-110, "Charles v. U.S. Federal Elections Commission et al." (3:11-cv-00110-AET-RM). It alleged that racial discrimination present in an all-white and segregated U.S. Congress of 1917 was the impetus to deny the right to vote to a majority non-white constituency. The case was ultimately dismissed and closed on August 16, 2012 by District Judge Anne E. Thompson from the Federal District Court of the Virgin Islands, Division of St. Croix.
Economy.
Tourism is the primary economic activity. The islands normally host 2 million visitors a year, many of whom visit on cruise ships.
The manufacturing sector consists of mainly rum distilling. The agricultural sector is small, with most food being imported. International business and financial services are a small but growing component of the economy. Most energy is also generated from imported oil, leading to electricity costs four to five times higher than the U.S. mainland. The Virgin Islands Water and Power Authority also uses imported energy to operate its desalination facilities to provide fresh water.
Until February 2012, the Hovensa plant located on St. Croix was one of the world's largest petroleum refineries and contributed about 20% of the territory's GDP. It has since been largely shut down and is now operating as no more than an oil storage facility, provoking a local economic crisis.
The U.S. Virgin Islands are located in the Atlantic Standard Time zone and do not participate in daylight saving time. When the mainland United States is on Standard Time, the U.S. Virgin Islands are one hour ahead of Eastern Standard Time. When the mainland United States is on daylight saving time, Eastern Daylight Time is the same as Atlantic Standard Time.
To draw more technology-focused companies and expand this segment of the economy, the government founded and launched University of the Virgin Islands Research and Technology Park in conjunction with private businesses and the University of the Virgin Islands.
The U.S. Virgin Islands are an independent customs territory from the mainland United States and operate largely as a free port. U.S. citizens thus do not have to clear customs when arriving in the U.S. Virgin Islands, but do when traveling to the mainland. Local residents are not subject to U.S. federal income taxes on U.S. Virgin Islands source income; they pay taxes to the territory equal to what their federal taxes would be if they lived in a state.
Demographics.
As of the census 2010, the U.S. Virgin Islands had a population of 106,405 and there are 40,648 households, and 26,636 families residing in the territory. The racial makeup of the U.S. Virgin Islands was:
Many residents can trace their ancestry to other Caribbean islands, especially Puerto Rico and the Lesser Antilles. The territory is largely Afro-Caribbean in origin.
There were 40,648 households out of which 34.7% had children under the age of 18 living with them, 33.2% were married couples living together, 24.9% had a female householder with no husband present, and 34.5% were non-families. 30.2% of all households were made up of individuals and 6.3% had someone living alone who was 65 years of age or older. The average household size was 2.64 and the average family size was 3.34.
In the territory the population was spread out with 31.6% under the age of 18, 8.0% from 18 to 24, 27.1% from 25 to 44, 24.9% from 45 to 64, and 8.4% who were 65 years of age or older. The median age was 33 years. For every 100 females there were 91.4 males. For every 100 females age 18 and over, there were 87.7 males. The annual population growth is −0.12%.
The median income for a household in the territory was $24,704, and the median income for a family was $28,553. Males had a median income of $28,309 versus $22,601 for females. The per capita income for the territory was $13,139. About 28.7% of families and 32.5% of the population were below the poverty line, including 41.7% of those under age 18 and 29.8% of those age 65 or over.
Ethnicity.
Most U.S. Virgin Islanders descend from Africans, who were brought to the Caribbean by Europeans to labor as slaves on sugar plantations. About half of the residents were born in the islands, although many migrated to the U.S. Virgin Islands from other islands in the West Indies, the United States and other countries.
Language.
The official language is English, although Virgin Islands Creole, an English-based creole, locally known as "dialect", is spoken in informal situations. The Virgin Islands Creole spoken on St. Croix, known as "Crucian", is slightly different from that spoken on St. Thomas and St. John. Because the U.S. Virgin Islands are home to thousands of immigrants from across the Caribbean, Spanish and various French creole languages are also widely spoken. As of the 2000 census, 25.3% of persons over the age of five speak a language other than English at home. Spanish is spoken by 16.8% of the population and French is spoken by 6.6%. Danish, once the language of administration and a handful of inhabitants for over a century and a half, virtually ceased to be spoken once Denmark sold the islands, although Danish place names and surnames among natives still remain.
Religion.
As in most Caribbean countries, Christianity is the dominant religion in the U.S. Virgin Islands. Protestantism is most prevalent, reflecting the territory's Danish colonial heritage. There is also a strong Roman Catholic presence. As in other Caribbean islands, Rastafari is also prevalent. There are some Jews living in the territory.
Transportation and communications.
The Henry E. Rohlsen International Airport serves St. Croix and the Cyril E. King International Airport serves St. Thomas and St. John.
The U.S. Virgin Islands is the only U.S. jurisdiction which drives on the left. This was inherited from what was then-current practice on the islands at the time of the 1917 transfer, to limit losses of livestock. However, as most cars being imported from the mainland United States are left-hand drive, the driver sits to the outside of the road, raising traffic safety issues.
As in other U.S. territories, U.S. Virgin Islands mail service is handled by the United States Postal Service, using the two-character state code "VI" for domestic mail delivery.
ZIP codes are in the 008xx range.
s of 2010[ [update]], specifically assigned codes include 00801–00805 (St Thomas),
00820–00824 (Christiansted),
00830–00831 (St John),
00840–00841 (Frederiksted),
and 00850–00851 (Kingshill).
The islands are part of the North American Numbering Plan, using area code 340, and island residents and visitors are able to call toll-free U.S. numbers.
Media.
The islands have a number of AM and FM radio stations (mostly on St. Thomas and St. Croix) broadcasting music, religious, and news programming. (See List of radio stations in U.S. Territories.) Full and low-power television stations are split between St. Thomas and St. Croix. (See List of television stations in the U.S. Virgin Islands.) Newspapers include:
Education.
The Virgin Islands Department of Education serves as the territory's education agency, and has two school districts: St. Thomas-St. John School District and St. Croix School District.
The University of the Virgin Islands provides higher education leading to associate's, bachelor's, and master's degrees, with campuses on St. Thomas and St. Croix.
Holidays.
Virgin Islands government employees are also given administrative leave for St. Croix carnival events in January and St. Thomas carnival events in April/May.

</doc>
<doc id="32137" url="http://en.wikipedia.org/wiki?curid=32137" title="Geography of the United States Virgin Islands">
Geography of the United States Virgin Islands

The U.S. Virgin Islands are a group of several dozen islands and cays located in the Caribbean, about 1100 mi southeast of Florida, 600 mi north of Venezuela, 40 mi east of Puerto Rico, and immediately west and south of the British Virgin Islands.
The U.S. Virgin Islands lie near the boundary of the North American Plate and the Caribbean Plate, roughly 100 mi south of the Puerto Rico Trench and near the Anegada Passage, a key shipping lane. Together with the British Virgin Islands, Vieques, and Culebra, they make up the Virgin Islands archipelago.
The hilly, volcanic islands of Saint Thomas (31 sqmi) and Saint John (20 sqmi) border the North Atlantic Ocean to the north and the Caribbean Sea to the south. The larger island of Saint Croix (84 sqmi) lies 40 mi to the south across the Virgin Islands Trough and is entirely in the Caribbean Sea.
Charlotte Amalie, Saint Thomas is one of the best natural, deepwater harbors in the Caribbean. The U.S. Virgin Islands have many well-known beaches, including Magens Bay (Saint Thomas) and Trunk Bay (Saint John), and coral reefs, including the Virgin Islands Coral Reef National Monument and the Buck Island Reef National Monument. More than half of Saint John and nearly all of Hassel Island are owned by the U.S. National Park Service.
Crown Mountain, on Saint Thomas, is the highest point in the U.S. Virgin Islands. Sea level is the lowest.
Statistics.
Geographic coordinates (capital Charlotte Amalie): 
Map references:
Central America and the Caribbean
Islands:
Saint Croix, Saint Thomas, Saint John, Water Island, many other islands
Area:
Land boundaries:
0 mi (0 km)
Coastline:
117 mi
Maritime claims:
Terrain:
Elevation extremes:
Natural resources:
sun, sand, sea, surf
Land use:
Irrigated land:
1 km²
Natural hazards:
several hurricanes in recent years; frequent and severe droughts and floods; occasional earthquakes; rare tsunamis
Environment—current issues:
lack of natural freshwater resources
Climate.
The U.S. Virgin Islands enjoy a tropical climate, moderated by easterly trade winds and with relatively low humidity. Temperatures vary little throughout the year.
In the capital, Charlotte Amalie, typical daily maximum temperatures are around 91 °F in the summer and 86 °F in the winter. Typical daily minimum temperatures are around 78 °F in the summer and 72 °F in the winter. Water temperatures are around 83 °F in the summer and 79 °F in the winter. Rainfall averages about 38 in per year. Rainfall can be quite variable, but the wettest months on average are September to November and the driest months on average are February and March.
The islands are subject to tropical storms and hurricanes, with the hurricane season running from June to November. In recent history, substantial damage was caused by Hurricane Hugo in 1989 and Hurricane Marilyn in 1995. The islands were also struck by Hurricane Bertha in 1996, Hurricane Georges in 1998, Hurricane Lenny in 1999, Tropical Storm Jeanne in 2004, Hurricane Omar in 2008, Hurricane Earl in 2010, Tropical Storm Otto in 2010, and Tropical Storm Tomas in 2010, but damage was less severe in those storms.

</doc>
<doc id="32138" url="http://en.wikipedia.org/wiki?curid=32138" title="Demographics of the United States Virgin Islands">
Demographics of the United States Virgin Islands

This article is about the demographic features of the population of the United States Virgin Islands, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.
Population.
The population of the US Virgin Islands is 106,405 (2010 census). 20.8% of the population is under 15 (male 11,279/female 10,855), 65.7% between 15 and 64 (male 32,976/female 36,907), and 13.5% over 64 (male 6,612/female 7,776) (2010 census). The median age is 39.2 years (38.5 for males, 39.7 for females) (2010 census).
Health.
The infant mortality rate as of 2010 is 7.4 deaths/1,000 live births: 8.14 deaths/1,000 live births for males and 6.63 deaths/1,000 live births for females. At birth, life expectancy is 79.61 years (76.57 for males, 82.83 for females or girls).
Ethnicity and religion.
As of the 2010 census, the population comprised the following ethnic groups:
17.4% of the population are identified as "Hispanic or Latino".
By place of birth:
In terms of religion:
Language.
As of the 2010 census, languages spoken in the US Virgin Islands were:

</doc>
<doc id="32139" url="http://en.wikipedia.org/wiki?curid=32139" title="Politics of the United States Virgin Islands">
Politics of the United States Virgin Islands

Politics of the United States Virgin Islands takes place in a framework of a presidential representative democratic dependency, whereby the Governor is the head of the local government, and of a multi-party system. The United States Virgin Islands are an unincorporated and organized territory of the United States, administered by the Office of Insular Affairs of the United States Department of the Interior. Executive power is exercised by the local government of the Virgin Islands. The judiciary is independent of the executive and the legislature.
Virgin Islands residents are U.S. citizens but cannot vote in United States presidential election and cannot elect voting members of Congress. However, in the U.S. House of Representatives, they are represented by a delegate, who can vote in congressional committees but not in the House itself. Virgin Islands residents can vote fully in all elections if they become a resident of one of the 50 U.S. states, while residents of one of the 50 states who become residents of the Virgin Islands can no longer vote for President or for voting members of Congress.
A federal lawsuit since 2011 in the District Court of the Virgin Islands and now before the Washington, D.C., Circuit Court is currently pending to provide Virgin Islanders with the fundamental right to be represented in Congress and vote for U.S. President. The federal case is Civil No. 3:11-cv-110, Charles v. U.S. Federal Elections Commission. A similar case was filed in the Superior Court of the Virgin Islands against the local Board of Elections. The cases allege it was racial discrimination present in an all-white and segregated Congress of 1917 that was the impetus to deny the right to vote to a majority non-white constituency. The local case is also pending a decision.
Law.
The Revised Organic Act of the Virgin Islands of 1954 is the current Organic Act defining the government of the United States Virgin Islands, which were acquired by the United States through the Treaty of the Danish West Indies of 1916. It replaced the Organic Act of the Virgin Islands of 1936 and earlier temporary provisions.
It was subsequently amended in 1958 to prohibit political or religious tests, but required a loyalty oath as qualification to any office or public trust. The Virgin Islands Elective Governor Act made the Governor an elected office, and further amendments in 1984 removed the right to indictment for certain crimes and the jurisdiction of the admiralty courts.
There have been several attempts at a constitution. The most recent attempt was the Fifth Constitutional Convention of the U.S. Virgin Islands which passed a proposed constitution in May 2009 but was rejected by Congress in June 2010.
Executive branch.
The governor and the lieutenant governor are elected on the same ticket by popular vote for four-year terms.
Legislative branch.
The Virgin Islands's territorial legislature is the 15-member Legislature of the Virgin Islands. The body is unicameral and comprises seven Senators from the district of Saint Croix, seven Senators from the district of Saint Thomas and Saint John, and one Senator at-large (who must be a resident of Saint John). They are elected for a two-year term to the territorial legislature.
Judicial branch.
The U.S. Virgin Islands has a District Court, a Supreme Court and a Superior Court. Judges on the District Court are appointed by the President for ten year terms. Judges on the Supreme Court and Superior Court are appointed by the governor and confirmed by the legislative body.
Administrative divisions.
There are no first-order administrative divisions as defined by the U.S. Government, but there are three islands at the second order; Saint Croix, Saint John, and Saint Thomas.

</doc>
<doc id="32140" url="http://en.wikipedia.org/wiki?curid=32140" title="Economy of the United States Virgin Islands">
Economy of the United States Virgin Islands

This article is on the economy of the United States Virgin Islands. This territory uses US currency and the fiscal year is 1 October - 30 September.
Economic history.
The islands also receive cross-over subsidies, which generated approximately $100 million for the Virgin Islands in 2008.
With the help of funding from the American Recovery and Reinvestment Act of 2009, the Virgin Islands Next Generation Network (a government-owned subsidiary) is bringing broadband internet access to the territory, in an effort to stimulate the technology sector and business generally.
Tourism.
The tourism industry is the main industry, generating 80% of GDP and employment. The majority of tourists are from the USA and the most common way to get there is by sea. The tourism industry mostly employs those who have migrated to the U.S. Virgin Islands. In 2005, a record of 2.6 million tourists visited.
Manufacturing.
Manufacturing industries developed significantly in the 1970s, especially on St. Croix island. Most industries depend of tax concessions and the financial advantages they derive from being a U.S. territory. An alumina factory processed bauxite until December 2009. The Hovensa oil refinery produced 495000 oilbbl/d, and closed down in February 2012.
Economy overview.
Budget:
Oil
Job market.
 In 2009, it was reported that the unemployment rate was 7.8%. 
YouthNet.
 in collaboration with BIZVI, launched a program called , to help at-risk youth to get back on their career track.

</doc>
<doc id="32141" url="http://en.wikipedia.org/wiki?curid=32141" title="Telecommunications in the United States Virgin Islands">
Telecommunications in the United States Virgin Islands

Communications in the United States Virgin Islands
The following statistics are from the CIA World Factbook, unless otherwise indicated.
Telephone.
Telephones - main lines in use: 74,200 (2008)
Telephones - mobile cellular: 80,300 (2005)
The islands are served by Claro Puerto Rico, and mainland U.S. carriers AT&T Mobility, Sprint Nextel, and T-Mobile USA. Although Verizon Wireless serves nearby Puerto Rico as domestic service, calls from the USVI are considered roaming and are charged nearly two dollars per minute, far more than calls made while roaming in Canada or Europe. Text messages (SMS), however, are treated as domestic, while multimedia messages (MMS) are unavailable for Verizon customers.
Telephone system:
Country code / area code +1-340
Radio.
Radio broadcast stations:
24 radio stations broadcasting (2009)
Radios:
107,000 (2003)
Television.
Television broadcast stations:
about a dozen television broadcast stations including 1 public TV station; multi-channel cable and satellite TV services are available (2009)
Televisions:
68,000 (1997)
Internet.
The U.S. Virgin Islands' country code top-level domain is .vi.
Internet hosts: 8,933 (2010)
Internet users: 30,000 (2008)

</doc>
<doc id="32142" url="http://en.wikipedia.org/wiki?curid=32142" title="Transportation in the United States Virgin Islands">
Transportation in the United States Virgin Islands

The United States Virgin Islands (USVI) is the only place under United States jurisdiction where the rule of the road is to drive on the left. However, virtually all passenger vehicles are left hand drive due to imports of US vehicles.
Roadways.
The USVI have 1257 km of roadways. Island roads tend to be poorly surfaced due to the terrain, and may take sharp turns. Cars drive on the left hand side of the road, but nearly all the automobiles on the island have left side steering columns.
Virgin Islands Transit (VITRAN) public buses run between the main towns and areas of local interest (not tourist destinations). Bus fare is $1 or less. Privately owned "dollar ride" or "dollar run" taxi buses stop at or near many bus stops. They follow a predefined route, but do not follow a regular schedule. It is often possible to get off anywhere along their route. These buses charge a flat rate for the trip, either $1 or $2.
Nearly all taxis are shared taxis, either enclosed vans or open-air "safaris", that go to destinations that are most convenient for tourists (e.g., hotels, beaches, docks, airports, sightseeing tours). They are not metered and are required by law to charge a flat fare that varies by destination. Though less common, private taxis to other destinations can also be negotiated.
There are many car rental agencies which rent cars and jeeps.
Airports.
Two international airports serve the islands:
There are also two seaplane bases:
There are no airports on Saint John or Water Island.
Ports and harbors.
Ports and harbors include:
Cruise ships call on Charlotte Amalie, Havensight, Subbase, Frederiksted, and Cruz Bay.
There are many and frequent inter-island ferries. Cruz Bay, Saint John can be reached from Charlotte Amalie and Red Hook on Saint Thomas. Car barges also run between Cruz Bay and Red Hook. Water Island can be reached from Crown Bay, Saint Thomas. International ferries also run between Saint Thomas, Saint John, and the neighboring British Virgin Islands.
There are numerous marinas and anchorages in the USVI. Vessels entering the islands must proceed directly to a port of entry for clearance before passengers and crew go ashore.
Railways.
The USVI contain no railways although there was formerly a marine railway on Hassel Island.
Customs.
Although a U.S. territory, the USVI are maintained as a "free port" in a separate customs zone. Travelers to the continental United States and Puerto Rico need to pre-clear U.S. customs and present a passport or proof of U.S. citizenship or nationality. The immigration status of non-U.S. citizens may be checked during this process as well.

</doc>
<doc id="32145" url="http://en.wikipedia.org/wiki?curid=32145" title="Universal precautions">
Universal precautions

Universal precautions refers to the practice, in medicine, of avoiding contact with patients' bodily fluids, by means of the wearing of nonporous articles such as medical gloves, goggles, and face shields. The practice was introduced in 1985–88. In 1987, the practice of universal precautions was adjusted by a set of rules known as body substance isolation. In 1996, both practices were replaced by the latest approach known as standard precautions. Use of personal protective equipment is now recommended in all health settings.
Historical significance of universal precautions.
Under universal precautions all patients were considered to be possible carriers of blood-borne pathogens. The guideline recommended wearing gloves when collecting or handling blood and body fluids contaminated with blood, wearing face shields when there was danger of blood splashing on mucous membranes and disposing of all needles and sharp objects in puncture-resistant containers.
Universal precautions were designed for doctors, nurses, patients, and health care support workers who were required to come into contact with patients or bodily fluids. This included staff and others who might not come into direct contact with patients.
Pathogens fall into two broad categories, bloodborne (carried in the body fluids) and airborne.
Use.
Universal precautions were typically practiced in any environment where workers were exposed to bodily fluids, such as:
Bodily fluids that did not require such precautions included:
Universal precautions were the infection control techniques that were recommended following the AIDS outbreak in the 1980s. Every patient was treated as if infected and therefore precautions were taken to minimize risk.
Essentially, universal precautions were good hygiene habits, such as hand washing and the use of gloves and other barriers, correct handling of hypodermic needles and scalpels, and aseptic techniques.
Equipment.
Protective clothing included but was not limited to:
Additional precautions.
Additional precautions were used in addition to universal precautions 
for patients who were known or suspected to have an infectious 
condition, and varied depending on the infection control needed of that 
patient. Additional precautions were not needed for blood-borne 
infections, unless there were complicating factors.
Conditions indicating additional precautions:
Issues of stigma and discrimination.
Research around stigma and discrimination in health-related settings has implicated universal precautions as a means by which health care workers discriminate against patients. Particularly the employment of universal precautions when working with people with HIV and/or hepatitis C has been demonstrated to be inconsistent and implicated with feelings of stigmatization reported by those populations. Health-cased social research reveals that by not applying universal precautions universally, as is the purpose, health professionals are instead making judgements based on an individual's health status. It is speculated that this differential approach to care stems from stigma towards HIV and hepatitis C, rooted largely in fears and misconceptions around transmission and assumptions about patient lifestyle and risk.

</doc>
<doc id="32146" url="http://en.wikipedia.org/wiki?curid=32146" title="Uniform resource identifier">
Uniform resource identifier

In computing, a uniform resource identifier (URI) is a string of characters used to identify a name of a resource. Such identification enables interaction with representations of the resource over a network, typically the World Wide Web, using specific protocols. Schemes specifying a concrete syntax and associated protocols define each URI. The most common form of URI is the uniform resource locator (URL), frequently referred to informally as a "web address." More rarely seen in usage is the uniform resource name (URN), which was designed to complement URLs by providing a mechanism for the identification of resources in particular namespaces.
The relationship between URIs, URLs, and URNs.
A uniform resource name (URN) functions like a person's name, while a uniform resource locator (URL) resembles that person's street address. In other words: the URN defines an item's identity, while the URL provides a method for finding it.
URLs.
A URL is a URI that, in addition to identifying a web resource, specifies the means of acting upon or obtaining the representation, specifying both its primary access mechanism and network location. For example, the URL http://example.org/wiki/Main_Page refers to a resource identified as /wiki/Main_Page whose representation, in the form of HTML and related code, is obtainable via HyperText Transfer Protocol (http) from a network host whose domain name is example.org.
URNs.
A URN is a URI that identifies a resource by name in a particular namespace. A URN can be used to talk about a resource without implying its location or how to access it.
The International Standard Book Number (ISBN) system for uniquely identifying books provides a typical example of the use of URNs. ISBN 0-486-27557-4 cites unambiguously a specific edition of Shakespeare's play "Romeo and Juliet". The URN for that edition would be "urn:isbn:0-486-27557-4. "To gain access to this object and read the book, its location is needed, for which a URL would have to be specified.
Conceptual distinctions.
Technical publications, especially standards produced by the IETF and by the W3C, normally reflect a view outlined in a W3C Recommendation of 2001, which acknowledges the precedence of the term URI rather than endorsing any formal subdivision into URL and URN: "URL is a useful but informal concept: a URL is a type of URI that identifies a resource via a representation of its primary access mechanism (e.g., its network "location"), rather than by some other attributes it may have". A URL is simply a URI that happens to point to a physical resource over a network.
However, in non-technical contexts and in software for the World Wide Web, the term "URL" remains widely used. Additionally, the term "web address" (which has no formal definition) often occurs in non-technical publications as a synonym for a URI that uses the 'http' or 'https' scheme. Such assumptions can lead to confusion, for example when viewing XML source: the normal means of identifying unique XML vocabularies within an XML document is to declare XML namespaces whose names are URIs that begin with 'http' and use the syntax of a genuine domain name followed by a file path, but which have no need to point to any specific file locations that actually exist.
Syntax.
The URI syntax consists of a URI scheme name (such as "codice_1", "codice_2", "codice_3", "codice_4" or "codice_5") followed by a colon character, and then by a scheme-specific part. The specifications that govern the schemes determine the syntax and semantics of the scheme-specific part. However, URI syntax does require all schemes to adhere to a general syntax that (among other things) reserves certain characters for special purposes (without always identifying those purposes).
The URI syntax also enforces restrictions on the scheme-specific part in order to (for example) provide for a degree of consistency when the part has a hierarchical structure.
"Percent-encoding" can add extra information to a URI.
History.
Naming, addressing, and identifying resources.
URIs and URLs have a shared history. In 1994, Tim Berners-Lee’s proposals for HyperText
implicitly introduced the idea of a URL as a short string representing a resource that is the target of a hyperlink. At the time, people referred to it as a 'hypertext name'
or 'document name'.
Over the next three and a half years, as the World Wide Web's core technologies of HTML (the HyperText Markup Language), HTTP, and web browsers developed, a need to distinguish a string that provided an address for a resource from a string that merely named a resource emerged. Although not yet formally defined, the term "Uniform Resource Locator" came to represent the former, and the more contentious "Uniform Resource Name" came to represent the latter.
During the debate over defining URLs and URNs it became evident that the two concepts embodied by the terms were merely aspects of the fundamental, overarching notion of resource "identification". In June 1994, the IETF published Berners-Lee's RFC 1630: the first RFC that (in its non-normative text) acknowledged the existence of URLs and URNs, and, more importantly, defined a formal syntax for "Universal Resource Identifiers" — URL-like strings whose precise syntaxes and semantics depended on their schemes. In addition, this RFC attempted to summarize the syntaxes of URL schemes in use at the time. It also acknowledged, but did not standardize, the existence of relative URLs and fragment identifiers.
Refinement of specifications.
In December 1994, RFC 1738 formally defined relative and absolute URLs, refined the general URL syntax, defined how to resolve relative URLs to absolute form, and better enumerated the URL schemes then in use. The agreed definition and syntax of URNs had to wait until the publication of RFC 2141 in May 1997.
The publication of RFC 2396 in August 1998 saw the URI syntax become a separate specification and most of the parts of RFCs 1630 and 1738 relating to URIs and URLs in general were revised and expanded by the IETF. The new RFC changed the significance of the "U" in "URI": it came to represent "Uniform" rather than "Universal". The sections of RFC 1738 that summarized existing URL schemes migrated into a separate document. IANA keeps a registry of those schemes; RFC 2717 first described the procedure to register them.
In December 1999, RFC 2732 provided a minor update to RFC 2396, allowing URIs to accommodate IPv6 addresses. Some time later, a number of shortcomings discovered in the two specifications led to the development of a number of draft revisions under the title rfc2396bis. This community effort, coordinated by RFC 2396 co-author Roy Fielding, culminated in the publication of RFC 3986 in January 2005. This RFC, as of 2009[ [update]] the current version of the URI syntax recommended for use on the Internet, renders RFC 2396 obsolete. It does not, however, render the details of existing URL schemes obsolete; RFC 1738 continues to govern such schemes except where otherwise superseded – RFC 2616 for example, refines the 'http' scheme. Simultaneously, the IETF published the content of RFC 3986 as the full standard STD 66, reflecting the establishment of the URI generic syntax as an official Internet protocol.
In August 2002, RFC 3305 pointed out that the term 'URL' has, despite its widespread use in the vernacular of the Internet-aware public at large, faded into near obsolescence. It now serves only as a reminder that some URIs act as addresses because they have schemes that imply some kind of network accessibility, regardless of whether systems actually use them for that purpose. As URI-based standards such as Resource Description Framework make evident, resource identification need not suggest the retrieval of resource representations over the Internet, nor need they imply network-based resources at all.
On November 1, 2006, the W3C Technical Architecture Group published 'On Linking Alternative Representations To Enable Discovery And Publishing', a guide to best practices and canonical URIs for publishing multiple versions of a given resource. For example, content might differ by language or by size to adjust for capacity or settings of the device used to access that content.
The Semantic Web uses the HTTP URI scheme to identify both documents and concepts in the real world: this has caused confusion as to how to distinguish the two. The Technical Architecture Group of W3C (TAG) published an e-mail in June 2005 on how to solve this problem. The e-mail became known as the "httpRange-14 resolution".
To expand on this (rather brief) email, W3C published in March 2008 the Interest Group Note "Cool URIs for the Semantic Web". This explains the use of content negotiation and the 303-redirect code in more detail.
URI reference.
A URI reference may take the form of a full URI, or just the scheme-specific portion of one, or even some trailing component thereof – even the empty string. An optional fragment identifier, preceded by #, may be present at the end of a URI reference. The part of the reference before the # indirectly identifies a resource, and the fragment identifier identifies some portion of that resource.
To derive a URI from a URI reference, software converts the URI reference to 'absolute' form by merging it with an absolute 'base' URI according to a fixed algorithm. The system treats the URI reference as relative to the base URI, although in the case of an absolute reference, the base has no relevance. The base URI typically identifies the document containing the URI reference, although this can be overridden by declarations made within the document or as part of an external data transmission protocol. If the base URI includes a fragment identifier, it is ignored during the merging process. If a fragment identifier is present in the URI reference, it is preserved during the merging process.
Web document markup languages frequently use URI references to point to other resources, such as external documents or specific portions of the same logical document.
URI resolution.
To "resolve" a URI means either to convert a relative URI reference to absolute form, or to dereference a URI or URI reference by attempting to obtain a representation of the resource that it identifies. The 'resolver' component in document processing software generally provides both services.
One can regard a URI reference as a same document reference: a reference to the document containing the URI reference itself. Document processing software can efficiently use its current representation of the document to satisfy the resolution of a same document reference without fetching a new representation. This is only a recommendation, and document processing software can alternatively use other mechanisms to determine whether to obtain a new representation.
The current URI specification as of 2009[ [update]], RFC 3986, defines a URI reference as a same document reference if, when resolved to absolute form, it equates exactly to the base URI in effect for the reference. Typically, the base URI is the URI of the document containing the reference. XSLT 1.0, for example, has a codice_14 function that, in effect, implements this functionality. RFC 3986 also formally defines URI equivalence, which can be used to determine that a URI reference, while not identical to the base URI, still represents the same resource and thus can be considered to be a same document reference.
RFC 2396 prescribed a different method for determining same document references; RFC 3986 made RFC 2396 obsolete, but RFC 2396 still serves as the basis of many specifications and implementations. This specification defines a URI reference as a same document reference if it is an empty string or consists of only the # character followed by an optional fragment.
Relation to XML namespaces.
XML has a concept of a namespace, an abstract domain to which a collection of element and attribute names can be assigned. The namespace name (a character string which must adhere to the generic URI syntax) identifies an XML namespace. However, the namespace name is generally not considered to "be" a URI because the 'URI-ness' of strings is, according to the URI specification, based on their intended use, not just their lexical components. A namespace name also does not necessarily imply any of the semantics of URI schemes; a namespace name beginning with 'http:', for example, likely has nothing to do with the HTTP protocol. XML professionals have debated this thoroughly on the xml dev electronic mailing list; some feel that a namespace name could be a URI, since the collection of names comprising a particular namespace could be regarded as a resource that is being identified, and since a version of the 'Namespaces in XML' specification says that the namespace name "is" a URI reference.
But the consensus seems to suggest that a namespace name is just a string that happens to look like a URI, nothing more.
Initially, the namespace name could match the syntax of any non-empty URI reference, but an erratum to the 'Namespaces In XML Recommendation' later deprecated the use of relative URI references. A separate specification, issued for namespaces for XML 1.1, allows IRI references, not just URI references, to serve as the basis for namespace names.
To mitigate confusion that began to arise among newcomers to XML from the use of URIs (particularly HTTP URLs) for namespaces, a descriptive language called RDDL (Resource Directory Description Language) developed, though the specification of RDDL has no official standing and no relevant organization (such as W3C) has considered or approved it. An RDDL document can provide machine- and human-readable information about a particular namespace and about the XML documents that use it. Authors of XML documents were encouraged to put RDDL documents in locations such that if a namespace name in their document somehow becomes de-referenced, then an RDDL document would be obtained, thus satisfying the desire among many developers for a namespace name to point to a network-accessible resource.

</doc>
<doc id="32147" url="http://en.wikipedia.org/wiki?curid=32147" title="Union of International Associations">
Union of International Associations

The Union of International Associations is a non-profit non-governmental organization researching on international organizations, under United Nations mandate, the global civil society and publishing information on international organizations, international meetings, world problems, etc. Headquarters are in Brussels, Belgium. It was founded in 1907 by Henri La Fontaine, the 1913 Nobel Peace Prize laureate, and Paul Otlet, a founding father of what is now called information science.
Its stated goals (taken from its website) include:

</doc>
<doc id="32149" url="http://en.wikipedia.org/wiki?curid=32149" title="Unconsciousness">
Unconsciousness

Unconsciousness is a state which occurs when the ability to maintain an awareness of self and environment is lost. It involves a complete or near-complete lack of responsiveness to people and other environmental stimuli.
Loss of consciousness should "not" be confused with the notion of the psychoanalytic unconscious or cognitive processes (e.g., implicit cognition) that take place outside of awareness, and with altered states of consciousness, such as delirium (when the person is confused and only partially responsive to the environment), normal sleep, hypnosis, and other altered states in which the person responds to stimuli.
Unconsciousness may occur as the result of traumatic brain injury, brain hypoxia (e.g., due to a brain infarction or cardiac arrest), severe poisoning with drugs that depress the activity of the central nervous system (e.g., alcohol and other hypnotic or sedative drugs), severe fatigue, and other causes.
There is a theory that unconsciousness occurs when different regions of the brain inhibit one another.
Law and medicine.
In jurisprudence, unconsciousness may entitle the criminal defendant to the defense of automatism, i.e. a state uncontrollably of one's own actions, an excusing condition that allows a defendant to argue that they should not be held criminally liable for their actions or omissions. In most countries, courts must consider whether unconsciousness in a situation can be accepted as a defense; it can vary from case to case. Hence epileptic seizures, neurological dysfunctions and sleepwalking may be considered acceptable excusing conditions because the loss of control is not foreseeable, but falling asleep (especially while driving or during any other safety-critical activity), may not be because natural sleep rarely overcomes an ordinary person without warning.
In many countries, it is presumed that someone who is less than fully conscious cannot give consent to anything. This can be relevant in cases of sexual behavior, euthanasia or patients giving informed consent with regard to starting or stopping a treatment.
Laws in some countries require that first responders, EMT, or paramedics obtain consent from an injured person who is conscious before they initiate patient care. In most situations where the injured person is deemed unconscious, consent is implied and the emergency service provider is free to provide care.

</doc>
<doc id="32150" url="http://en.wikipedia.org/wiki?curid=32150" title="Quarter (United States coin)">
Quarter (United States coin)

A quarter, short for quarter dollar, is a U.S. coin worth 25 cents, one-fourth of a dollar. It has been produced since 1796. The choice of 1⁄4 as a denomination—as opposed to the 1⁄5 more common elsewhere—originated with the practice of dividing Spanish milled dollars into eight wedge-shaped segments. At one time "two bits" (that is, two "pieces of eight") was a common nickname for a quarter.
Current design.
The current clad version is two layers of cupronickel, 75% copper and 25% nickel, on a core of pure copper. The total composition of the coin is 8.33% nickel, with the remainder copper. It weighs 5.670 grams (0.2000 avoirdupois oz, 1/80th of a pound, 0.1823 troy oz). The diameter is 0.955 inches (24.26 mm), and the width of 0.069 inches (1.75 mm). The coin has a 0.069-inch (1.75-mm) reeded (or milled) edge. Owing to the introduction of the clad quarter in 1965, it was occasionally called a "Johnson Sandwich" after Lyndon B. Johnson, the U.S. President at the time. It currently costs 11.14 cents to produce each coin (as of 2011). The U.S. Mint began producing silver quarters again in 1992 for inclusion in the annual Silver Proof set. Early quarters (before 1828) were slightly larger in diameter and thinner than the current coin.
The current regular issue coin is the George Washington quarter (showing George Washington) on the front. The reverse featured an eagle prior to the 1999 50 State Quarters Program. The Washington quarter was designed by John Flanagan. It was initially issued as a circulating commemorative, but was made a regular issue coin in 1934.
In 1999, the 50 State Quarters program of circulating commemorative quarters began; these have a modified Washington obverse and a different reverse for each state, ending the former Washington quarter's production completely. On January 23, 2007, the House of Representatives passed H.R. 392 extending the state quarter program one year to 2009, to include the District of Columbia and the five U.S. territories large enough to merit non-voting Congressional representatives: Puerto Rico, Guam, American Samoa, the United States Virgin Islands, and the Commonwealth of the Northern Mariana Islands. The bill passed through the Senate and was signed into legislation by President Bush on December 27, 2007.
The typeface used in the state quarter series varies a bit from one state to another, but is generally derived from Albertus.
On June 7, 2006, a bill titled "America's Beautiful National Parks Quarter Dollar Coin Act of 2008" was introduced to the House of Representatives. On December 23, 2008, President George W. Bush signed the bill into law. The America the Beautiful Quarters program began in 2010 and will continue for 12 years.
Silver series.
Non-clad silver quarters weigh 6.25 grams and are composed of 90% silver, 10% copper, with a total silver weight of 0.1808479 troy ounce pure silver. They were issued from 1932 through 1964.
The current rarities for the Washington Quarter silver series are:
Branch Mintmarks are D = Denver, S = San Francisco. 
Coins without mintmarks are all made at the main Mint in Philadelphia.
This listing is for Business strikes, not Proofs
The 1940 Denver Mint, 1936 Denver mint and the 1935 Denver Mint coins, as well as many others in the series, are considerably more valuable than other coins. This is not due to their mintages, but rather because they are harder to find in high grades (a situation referred to as "condition rarity"). Many of these coins are worth only melt value in low grades. Other coins in the above list are expensive because of their extremely low mintages, such as the 1932 Denver and San Francisco issues. The overstruck mintmark issues are also scarce and expensive, especially in the higher grades; even so they may not have the same popularity as overdates found in pre-Washington quarter series.
The 1934 Philadelphia strike appears in two versions: one with a light motto [for "In God We Trust"], which is the same as that used on the 1932 strikings, and the other a heavy motto seen after the dies were reworked. Except in the highest grades, the difference in value between the two is minor.
The Silver Series of Washington Quarters spans from 1932 to 1964; during many years in the series it will appear that certain mints did not mint Washington Quarters for that year. No known examples of quarters were made in 1933, San Francisco abstained in 1934 and 1949, and stopped after 1955, until it resumed in 1968 by way of making proofs. Denver did not make quarters in 1938, and Philadelphia never stopped, except in 1933. Proof examples from 1936 to 1942 and 1950 to 1967 were struck at the Philadelphia Mint; in 1968 proof production was shifted to the San Francisco Mint.
The mint mark on the coin is located on the reverse beneath the wreath on which the eagle is
perched, and will either carry the mint mark "D" for the Denver Mint, "S" for the San Francisco mint, or be blank if minted at the Philadelphia Mint.
Copper-nickel clad series.
The copper-nickel clad series of Washington Quarters started in 1965, and as part of the switch Denver and San Francisco did not stamp their mint marks from 1965 to 1967 in any denomination. During the early 1960s, the Federal government had been flooding the market with silver to keep the price down, and therefore keep U.S. coins' intrinsic values from passing their face values. However, this was causing the level of silver in the U.S. Reserves to reach dangerously low levels. Silver was estimated to only last another 3–5 years at the rate the Mint was manufacturing coins, so the U.S. Congress authorized the Mint to research alternative materials for the silver denominations (dime, quarter dollar, half dollar, and dollar). The material chosen was a 75% copper/ 25% nickel cupronickel alloy (identical to that in the five-cent coin) clad to a core of "commercially pure" (99.5%) copper.
For the first three years of clad production, in lieu of proof sets, specimen sets were specially sold as "Special Mint Sets" minted at the San Francisco mint in 1965, 1966, and 1967 (Deep Cameo versions of these coins are highly valued because of their rarity).
Currently, there are few examples in the clad series that are valued as highly as the silver series but there are certain extraordinary dates or variations. The Deep Cameo versions of proofs from 1965 to 1971 and 1981 Type Two are highly valued because of their scarcity, high grade examples of quarters from certain years of the 1980s (such as 1981–1987) because of scarcity in high grades due to high circulation and in 1982 and 1983 no mint sets were produced making it harder to find mint state examples, and any coin from 1981–1994 graded in MS67 is worth upwards of $1000.
The mint mark on the coin is located on the obverse at the bottom right hemisphere under the supposed date. In 1965–1967 cupro-nickel coins bore no mint mark; quarters minted in 1968–1979 were stamped with a "D" for the Denver mint, an "S" for the San Francisco mint (proof coins only), or blank for Philadelphia. Starting in 1980, the Philadelphia mint was allowed to add its mint mark to all coins except the one-cent piece. Twenty-five-cent pieces minted from 1980 onwards are stamped with "P" for the Philadelphia mint, "D" for the Denver mint, or "S" for San Francisco mint. Until 2012 the "S" mint mark was used only on proof coins, but beginning with the El Yunque (Puerto Rico) design in the America the Beautiful Quarters program, the U.S. Mint began selling (at a premium) uncirculated 40-coin rolls and 100-coin bags of quarters with the San Francisco mint mark. These coins were not included in the 2012 uncirculated sets or the three-coin ATB quarter sets (which consisted of an uncirculated "P" and "D" and proof "S" specimen) and no "S" mint-marked quarters are being released into circulation, so that mintages will be determined solely by direct demand for the "S" mint-marked coins.

</doc>
<doc id="32152" url="http://en.wikipedia.org/wiki?curid=32152" title="Ural Mountains">
Ural Mountains

The Ural Mountains (Russian: Ура́льские го́ры, "Uralskiye gory"; ]; Bashkir: Урал тауҙары), or simply the Urals, are a mountain range that runs approximately from north to south through western Russia, from the coast of the Arctic Ocean to the Ural River and northwestern Kazakhstan. The mountain range forms the natural boundary between Europe and Asia. Vaygach Island and the islands of Novaya Zemlya form a further continuation of the chain to the north into the Arctic.
The mountains lie within the Ural geographical region and significantly overlap with the Ural Federal District and Ural economic region. They are rich in various deposits, including metal ores, coal, precious and semi-precious stones. Since the 18th century the mountains have been a major mineral base of Russia.
Etymology.
As attested by Sigismund von Herberstein, in the 16th century Russians called the range by a variety of names derived from the Russian words for rock (stone) and belt. The modern Russian name for the Urals (Урал, "Ural"), first appearing in the 16th–17th century when the Russian conquest of Siberia was in its heroic phase, was initially applied to its southern parts and gained currency as the name of the entire range during the 18th century. It might have been a borrowing from either Turkic (Bashkir, where the same name is used for the range), or Ob-Ugric. From the 13th century, in Bashkortostan there has been a legend about a hero named Ural. He sacrificed his life for the sake of his people and they poured a stone pile over his grave, which later turned into the Ural Mountains.
History.
As Middle-Eastern merchants traded with the Bashkirs and other people living on the western slopes of the Urals as far North as Great Perm, since at least the 10th century medieval mideastern geographers had been aware of the existence of the mountain range in its entirety, stretching as far as to the Arctic Ocean in the north. The first Russian mention of the mountains to the east of the East European Plain is provided by the Primary Chronicle, when it describes the Novgorodian expedition to the upper reaches of the Pechora in 1096. During the next few centuries Novgorodians engaged in fur trading with the local population and collected tribute from Yugra and Great Perm, slowly expanding southwards. The rivers Chusovaya and Belaya were first mentioned in the chronicles of 1396 and 1468, respectively. In 1430 the town of Solikamsk (Kama Salt) was founded on the Kama at the foothills of the Urals, where salt was produced in open pans. Ivan III of Moscow captured Perm, Pechora and Yugra from the declining Novgorod Republic in 1472. With the excursions of 1483 and 1499–1500 across the Urals Moscow managed to subjugate Yugra completely.
Nevertheless, around that time early 16th century Polish geographer Maciej of Miechów in his influential "Tractatus de duabus Sarmatiis" (1517) argued that there were no mountains in Eastern Europe at all, challenging the point of view of some authors of Classical antiquity, popular during the Renaissance. Only after Sigismund von Herberstein in his Notes on Muscovite Affairs (1549) had reported, following Russian sources, that there are mountains behind the Pechora and identified them with the Ripheans and Hyperboreans of ancient authors, did the existence of the Urals, or at least of its northern part, become firmly established in the Western geography. The Middle and Southern Urals were still largely unavailable and unknown to the Russian or Western European geographers.
In the 1550s, after the Tsardom of Russia had defeated the Khanate of Kazan and proceeded to gradually annex the lands of the Bashkirs, the Russians finally reached the southern part of the mountain chain. In 1574 they founded Ufa. The upper reaches of the Kama and Chusovaya in the Middle Urals, still unexplored, as well as parts of Transuralia still held by the hostile Siberian Khanate, were granted to the Stroganovs by several decrees of the tsar in 1558–1574. The Stroganovs' land provided the staging ground for Yermak's incursion into Siberia. Yermak crossed the Urals from the Chusovaya to the Tagil around 1581. In 1597 Babinov's road was built across the Urals from Solikamsk to the valley of the Tura, where the town of Verkhoturye (Upper Tura) was founded in 1598. Customs was established in Verkhoturye shortly thereafter and the road was made the only legal connection between European Russia and Siberia for a long time. In 1648 the town of Kungur was founded at the western foothills of the Middle Urals. During the 17th century the first deposits of iron and copper ores, mica, gemstones and other minerals were discovered in the Urals.
Iron and copper smelting works emerged. They multiplied particularly quickly during the reign of Peter I of Russia. In 1720–1722 he commissioned Vasily Tatishchev to oversee and develop the mining and smelting works in the Urals. Tatishchev proposed a new copper smelting factory in Yegoshikha, which would eventually become the core of the city of Perm and a new iron smelting factory on the Iset, which would become the largest in the world at the time of construction and give birth to the city of Yekaterinburg. Both factories were actually founded by Tatishchev's successor, Georg Wilhelm de Gennin, in 1723. Tatishchev returned to the Urals on the order of Empress Anna to succeed de Gennin in 1734–1737. Transportation of the output of the smelting works to the markets of European Russia necessitated the construction of the Siberian Route from Yekaterinburg across the Urals to Kungur and Yegoshikha (Perm) and further to Moscow, which was completed in 1763 and rendered Babinov's road obsolete. In 1745 gold was discovered in the Urals at Beryozovskoye and later at other deposits. It has been mined since 1747.
The first railway across the Urals had been built by 1878 and linked Perm to Yekaterinburg via Chusovoy, Kushva and Nizhny Tagil. In 1890 a railway linked Ufa and Chelyabinsk via Zlatoust. In 1896 this section became a part of the Trans-Siberian Railway. In 1909 yet another railway connecting Perm and Yekaterinburg passed through Kungur by the way of the Siberian Route. It has eventually replaced the Ufa – Chelyabinsk section as the main trunk of the Trans-Siberian railway.
The highest peak of the Urals, Mount Narodnaya, (elevation 1,895 m (6,217 ft)) was identified in 1927.
During the Soviet industrialization in the 1930s the city of Magnitogorsk was founded in the southeastern Urals as a center of iron smelting and steelmaking. During the German invasion of the Soviet Union in 1941–1942, the mountains became a key element in Nazi planning for the territories which they expected to conquer in the USSR. Faced with the threat of having a significant part of the Soviet territories occupied by the enemy, the government evacuated many of the industrial enterprises of European Russia and Ukraine to the eastern foothills of the Urals, considered a safe place out of reach of the German bombers and troops. Three giant tank factories were established at the Uralmash in Sverdlovsk (as Yekaterinburg used to be known), Uralvagonzavod in Nizhny Tagil, and Chelyabinsk Tractor Plant in Chelyabinsk. After the war, in 1947–1948, Chum – Labytnangi railway, built with the forced labor of Gulag inmates, crossed the Polar Urals.
The first ample geographic survey of the Ural Mountains was completed in the early 18th century by the Russian historian and geographer Vasily Tatishchev under the orders of Peter I. Earlier, in the 17th century, rich ore deposits were discovered in the mountains and their systematic extraction began in the early 18th century, eventually turning the region into the largest mineral base of Russia.
One of the first scientific descriptions of the mountains was published in 1770–71. Over the next century, the region was studied by scientists from a number of countries, including Russia (geologist Alexander Karpinsky, botanist Porfiry Krylov and zoologist Leonid Sabaneyev), England (geologist Sir Roderick Murchison), France (paleontologist Edouard de Verneuil), and Germany (naturalist Alexander von Humboldt, geologist Alexander Keyserling). In 1845, Murchison, who had according to "Encyclopædia Britannica" "compiled the first geologic map of the Urals in 1841", published "The Geology of Russia in Europe and the Ural Mountains" with de Verneuil and Keyserling.
Mayak, 150 km southeast of Yekaterinburg, was a center of the Soviet nuclear industry and site of the Kyshtym disaster.
Geography and topography.
The Ural Mountains extend about 2500 km from the Kara Sea to the Kazakh Steppe along the northern border of Kazakhstan. Vaygach Island and the island of Novaya Zemlya form a further continuation of the chain on the north. Geographically this range marks the northern part of the border between the continents of Europe and Asia. Its highest peak is Mount Narodnaya, approximately 1895 m in elevation.
By topography and other natural features, the Urals are divided, from north to south, into the Polar (or Arctic), Nether-Polar (or Sub-Arctic), Northern, Central and Southern parts. The Polar Urals extend for about 385 km from Mount Konstantinov Kamen in the north to the Khulga River in the south; they have an area of about 25000 km2 and a strongly dissected relief. The maximum height is 1499 m at Payer Mountain and the average height is 1000 to. The mountains of the Polar Urals have exposed rock with sharp ridges, though flattened or rounded tops are also found.
The Nether-Polar Urals are up to 150 km wider and higher than the Polar Urals. They include the highest peaks of the range: Mount Narodnaya (1895 m), Mount Karpinsky (1878 m) and Manaraga (1662 m). They extend for more than 225 km south to the Shchugor River. The many ridges are sawtooth shaped and dissected by river valleys. Both Polar and Nether-Polar Urals are typically Alpine; they bear traces of Pleistocene glaciation, along with permafrost and extensive modern glaciation, including 143 extant glaciers.
The Northern Urals consist of a series of parallel ridges up to 1000 – in height and longitudinal depressions. They are elongated from north to south and stretch for about 560 km from the Usa River. Most of the tops are flattened, but those of the highest mountains, such as Telposiz, 1617 m and Konzhakovsky Stone, 1569 m have a dissected topography. Intensive weathering has produced vast areas of eroded stone on the mountain slopes and summits of the northern areas.
The Central Urals are the lowest part of the Urals, with smooth mountain tops, the highest mountain being 994 m (Basegi); they extend south from the Ufa River.
The relief of the Southern Urals is more complex, with numerous valleys and parallel ridges directed south-west and meridionally. The range includes the Ilmensky Mountains separated from the main ridges by the Miass River. The maximum height is 1640 m (Mount Yamantau) and the width reaches 250 km. Other notable peaks lie along the Iremel mountain ridge (Bolshoy Iremel and Maly Iremel). The Southern Urals extend some 550 km up to the sharp westward bend of the Ural River and terminate in the wide Mughalzhar Hills.
Geology.
The Urals are among the world's oldest extant mountain ranges. For its age of 250 to 300 million years, the elevation of the mountains is unusually high. They were formed during the Uralian orogeny due to the collision of the eastern edge of the supercontinent Laurussia with the young and rheologically weak continent of Kazakhstania, which now underlies much of Kazakhstan and West Siberia west of the Irtysh, and intervening island arcs. The collision lasted nearly 90 million years in the late Carboniferous – early Triassic. Unlike the other major orogens of the Paleozoic (Appalachians, Caledonides, Variscides), the Urals have not undergone post-orogenic extensional collapse and are unusually well preserved for their age, being underlaid by a pronounced crustal root. East and south of the Urals much of the orogen is buried beneath later Mesozoic and Cenozoic sediments. The adjacent Pay-Khoy to the north is not a part of the Uralian orogen and formed later.
Many deformed and metamorphosed rocks, mostly of Paleozoic period, surface within the Urals. The sedimentary and volcanic layers are folded and broken, and form meridional bands. The sediments to the west of the Ural Mountains are formed by limestone, dolomite and sandstone left from ancient shallow seas. The eastern side is dominated by basalts similar to the rocks of the bottom of the modern oceans.
The western slope of the Ural Mountains has predominantly karst topography, especially in the basin of the Sylva River, which is a tributary of the Chusovaya River. It is composed of severely eroded sedimentary rocks (sandstones and limestones) that are about 350 million years old. There are many caves, karst sinks and underground streams. The karst topography is much less developed on the eastern slopes. They are relatively flat, with some hills and rocky outcrops and contain alternating volcanic and sedimentary layers dated to the middle Paleozoic period. Most high mountains consist of weather-resistant rocks such as quartzite, schist and gabbro that are between 570 and 395 million years old. The river valleys are laid with limestone.
The Ural Mountains contain about 48 species of economically valuable ores and minerals. Eastern regions are rich in chalcopyrite, nickel oxide, gold, platinum, chromite and magnetite ores, as well as in coal (Chelyabinsk Oblast), bauxite, talc, fireclay and abrasives. The Western Urals contain deposits of coal, oil, natural gas (Ishimbay and Krasnokamsk areas) and potassium salts. Both slopes are rich in bituminous coal and lignite, and the largest deposit of bituminous coal is in the north (Pechora field). The specialty of the Urals is precious and semi-precious stones, such as emerald, amethyst, aquamarine, jasper, rhodonite, malachite and diamond. Some of the deposits, such as the magnetite ores at Magnitogorsk, are already nearly depleted.
Rivers and lakes.
Many rivers originate in the Ural Mountains. The western slopes south of the border between the Komi Republic and Perm Krai and the eastern slopes south of approximately 54°30'N drain into the Caspian Sea via the Kama and Ural River basins. The tributaries of the Kama include the Vishera, Chusovaya, and Belaya and originate on both the eastern and western slopes. The rest of the Urals drain into the Arctic Ocean, mainly via the Pechora basin in the west, which includes the Ilych, Shchugor, and the Usa, and via the Ob basin in the east, which includes the Tobol, Tavda, Iset, Tura and Severnaya Sosva. The rivers are frozen for more than half the year. Generally, the western rivers have higher flow volume than the eastern ones, especially in the Northern and Nether-Polar regions. Rivers are slower in the Southern Urals. This is because of low precipitation and the relatively warm climate resulting in less snow and more evaporation.
The mountains contain a number of deep lakes. The eastern slopes of the Southern and Central Urals have most of these, among the largest of which are the Uvildy, Itkul, Turgoyak, and Tavatuy lakes. The lakes found on the western slopes are less numerous and also smaller. Lake Bolshoye Shchuchye, the deepest lake in the Polar Urals, is 136 m deep. Other lakes, too, are found in the glacial valleys of this region. Spas and sanatoriums have been built to take advantage of the medicinal muds found in some of the mountain lakes.
Climate.
The climate of the Urals is continental. The mountain ridges, elongated from north to south, effectively absorb sunlight thereby increasing the temperature. The areas west of the Ural Mountains are 1 – warmer in winter than the eastern regions because the former are warmed by Atlantic winds whereas the eastern slopes are chilled by Siberian air masses. The average January temperatures increase in the western areas from -20 C in the Polar to -15 C in the Southern Urals and the corresponding temperatures in July are 10 C and 20 C. The western areas also receive more rainfall than the eastern ones by 150 – per year. This is because the mountains trap clouds from the Atlantic Ocean. The highest precipitation, approximately 1000 mm, is in the Northern Urals with up to 1000 cm snow. The eastern areas receive from 500 – in the north to 300 – in the south. Maximum precipitation occurs in the summer: the winter is dry because of the Siberian High.
Flora.
The landscapes of the Urals vary with both latitude and longitude and are dominated by forests and steppes. The southern area of the Mughalzhar Hills is a semidesert. Steppes lie mostly in the southern and especially south-eastern Urals. Meadow steppes have developed on the lower parts of mountain slopes and are covered with zigzag and mountain clovers, "Serratula gmelinii", dropwort, meadow-grass and "Bromus inermis", reaching the height of 60–80 cm. Much of the land is cultivated. To the south, the meadow steppes become more sparse, dry and low. The steep gravelly slopes of the mountains and hills of the eastern slopes of the Southern Urals are mostly covered with rocky steppes. River valleys contain willow, poplar and caragana shrubs.
Forest landscapes of the Urals are diverse, especially in the southern part. The western areas are dominated by dark coniferous taiga forests which change to mixed and deciduous forests in the south. The eastern mountain slopes have light coniferous taiga forests. The Northern Urals are dominated by conifers, namely Siberian fir, Siberian pine, Scots pine, Siberian spruce, Norway spruce and Siberian larch, as well as by Silver and downy birches. The forests are much sparser in the Polar Urals. Whereas in other parts of the Ural Mountains they grow up to the heights of 1 km, in the Polar Urals the tree line is at 250–400 m. The polar forests are low and are mixed with swamps, lichens, bogs and shrubs. Dwarf birch, mosses and berries (blueberry, cloudberry, black crowberry, etc.) are abundant. The forests of the Southern Urals are the most diverse in composition: here, together with coniferous forests are also abundant broadleaf tree species such as English oak, Norway maple and elm. The Virgin Komi Forests in the northern Urals are recognized as a World Heritage site.
Fauna.
The Ural forests are inhabited by animals typical of Siberia, such as elk, brown bear, fox, wolf, wolverine, lynx, squirrel and sable (north only). Because of the easy accessibility of the mountains there are no specifically mountainous species. In the Middle Urals, one can see a rare mixture of sable and pine marten named kidus. In the Southern Urals, badger and black polecat are common. Reptiles and amphibians live mostly in the Southern and Central Ural and are represented by the common viper, lizards and grass snakes. Bird species are represented by capercaillie, black grouse, hazel grouse, spotted nutcracker and cuckoos. In summers, the South and Middle Urals are visited by songbirds, such as nightingale and redstart.
The steppes of the Southern Urals are dominated by hares and rodents such as gophers, susliks and jerboa. There are many birds of prey such as lesser kestrel and buzzards. The animals of the Polar Urals are few and are characteristic of the tundra; they include Arctic fox, tundra partridge, lemming and reindeer. The birds of these areas include rough-legged buzzard, snowy owl and rock ptarmigan.
Ecology.
The continuous and intensive economic development of the last centuries has affected the fauna, and wildlife is much diminished around all industrial centers. During World War II, hundreds of factories were evacuated from Western Russia before the German occupation, flooding the Urals with industry. The conservation measures include establishing national wildlife parks. There are nine strict nature reserves in the Urals: the Ilmen, the oldest one, mineralogical reserve founded in 1920 in Chelyabinsk Oblast, Pechora-Ilych in the Komi Republic, Bashkir and its former branch Shulgan-Tash in Bashkortostan, Visim in Sverdlovsk Oblast, South Urals in Bashkortostan, Basegi in Perm Krai, Vishera in Perm Krai and Denezhkin Kamen in Sverdlovsk Oblast.
The area has also been severely damaged by the plutonium-producing facility Mayak opened in Chelyabinsk-40 (later called Chelyabinsk-65, Ozyorsk), in the Southern Urals, after World War II. Its plants went into operation in 1948 and, for the first ten years, dumped unfiltered radioactive waste into the Techa River and Lake Karachay. In 1990, efforts were underway to contain the radiation in one of the lakes, which was estimated at the time to expose visitors to 500 millirem per day. As of 2006, 500 mrem in the natural environment was the upper limit of exposure considered safe for a member of the general public in an entire year (though workplace exposure over a year could exceed that by a factor of 10). Over 23000 km2 of land were contaminated in 1957 from a storage tank explosion, only one of several serious accidents that further polluted the region. The 1957 accident expelled 20 million curies of radioactive material, 90% of which settled into the land immediately around the facility. Although some reactors of Mayak were shut down in 1987 and 1990, the facility keeps producing plutonium.
Cultural significance.
The Urals have been viewed by Russians as a "treasure box" of mineral resources, which were the basis for its extensive industrial development. In addition to iron and copper the Urals were a source of gold, malachite, alexandrite, and other gems such as those used by the court jeweller Fabergé. As Russians in other regions gather mushrooms or berries, Uralians gather mineral specimens and gems. Dmitry Mamin-Sibiryak (1852–1912) Pavel Bazhov (1879–1950), as well as Aleksey Ivanov and Olga Slavnikova, post-Soviet writers, have written of the region.
The region served as a "military stronghold" during Peter the Great's Great Northern War with Sweden, during Stalin's rule when the Magnitogorsk Metallurgical Complex was built and Russian industry relocated to the Urals during the Nazi advance at the beginning of World War II, and as the center of the Soviet nuclear industry during the Cold War. Extreme levels of air, water, and radiological contamination and pollution by industrial wastes resulted. Population exodus resulted, and economic depression at the time of the collapse of the Soviet Union, but in post-Soviet times additional mineral exploration, particularly in the northern Urals, has been productive and the region has attracted industrial investment.

</doc>
<doc id="32157" url="http://en.wikipedia.org/wiki?curid=32157" title="Upwords">
Upwords

Upwords (also known as Scrabble Upwords in the United States and Canada, and Topwords in other countries) is a board game invented by Elliot Rudell and originally published by the Milton Bradley Company, now a division of Hasbro. The game remains under license to Hasbro by Rudell Design, LLC. Upwords is similar to "Scrabble", or "Words With Friends", in that players build words using letter tiles on a gridded gameboard. The notable point of difference is that in Upwords letters can be stacked on top of other letters already on the gameboard to create new words. The higher the stack of letters, the more points are scored. This typically makes words built in later turns of the game more valuable than earlier words, increasing play intensity and adding a level of strategy unique to Upwords.
Unlike Scrabble, which is manufactured in the U.S. and Canada by Hasbro, and elsewhere in the world by Mattel, Upwords is solely controlled by Hasbro worldwide. The game is available in about twenty languages, and there have been national tournaments played in Hungary and Turkey. There is currently an Upwords online tournament league.
Gameplay.
Players draw letter tiles until they each have seven tiles. The first player forms a word with the tiles that covers one or more of the central squares and then draws more tiles to replace those played. Play continues to the left.
Subsequent players may put tiles on the board adjacent to and on top of the tiles already played, as long as all words formed are found in the dictionary being used. For example, if the word CATER is on the board, a player could put a B and E in front of CATER and then put an L on top of the C and a D on top of the R to build BELATED.
Players score one point for every tile in their word, and for each tile "under" their word. If the word is entirely on the first board layer, they instead score two points per letter. When a word is constructed that contains stacked tiles (up to a total of 5 high), point values will increase. This can lead to increased scoring towards the end of the game.
Players are not allowed to pluralize existing words by simply adding an "s" on the end of a word. If a word is pluralized by the addition of an "s", the "s" must also be part of another complete word that was placed on the board. This rule prevents players from capitalizing too much on other players' words without changing them.
Originally, "Upwords" was played on an 8 by 8 square board, with 64 letter tiles. Hasbro Europe later expanded the gameboard to a 10 by 10 matrix and 100 tiles, to accommodate the longer words frequently used in foreign languages such as German and Dutch. The 10 by 10 matrix is currently employed in worldwide versions of the game. The board is purposely smaller (has fewer tile positions) than "Scrabble" to encourage and even force the stacking up of letters upon letters. It does not have special squares such as "triple word scores" and "double letter scores" that require additional scoring calculations.
Other versions.
In the early 1990s, Hasbro licensed electronic marketing rights to Microsoft, briefly making the game available electronically Microsoft no longer has rights to Upwords.
In 2013, Upwords was developed by indie software developers Lonely Star Software, under license from Hasbro. The game was released as a mobile app for iOS devices. On March 27, 2014, Lonely Star released the app for Android platform devices.

</doc>
<doc id="32160" url="http://en.wikipedia.org/wiki?curid=32160" title="University for Peace">
University for Peace

The University for Peace (UPEACE) is an intergovernmental organization with university status, established by treaty in 1980 and having in main campus in Costa Rica. Its stated mission is “to provide humanity with an international institution of higher education for peace with the aim of promoting among all human beings the spirit of understanding, tolerance and peaceful coexistence, to stimulate cooperation among peoples and to help lessen obstacles and threats to world peace and progress, in keeping with the noble aspirations proclaimed in the Charter of the United Nations.” UPEACE current Rector is Dr. Francisco Rojas Aravena 
History.
The creation of the University for Peace was set in motion by a treaty and endorsed by resolution 34/111 of 14 December 1979 of the United Nations General Assembly. By this Resolution, the UN General Assembly established an international commission which, in collaboration with the Government of Costa Rica, was requested to prepare the organization, structure and setting in motion of the University for Peace. Thereafter, by , the UN General Assembly endorsed the treaty establishing the University for Peace by adopting the (UPEACE) along with the . The University has the unique status of not only being a dedicated institution for higher education in Peace and Conflict studies, but also an international treaty body organization mandated by the United Nations General Assembly.
It offers at its main headquarters in San José, Costa Rica, and carries out various activities related to the international peace and security objectives of the United Nations (UN) through centres and offices located in Addis Ababa, Geneva, New York, The Hague, and South Korea, and through partnership arrangements with numerous other institutions worldwide.
Relationship with United Nations.
The University for Peace is not part of the UN system, but has observer status at the UN General Assembly, while maintaining its independence in academic, financial and management matters. The UN Secretary-General is the Honorary President of UPEACE. The UN General Assembly maintains a constant interest in the activities of UPEACE, and in periodic resolutions calls on the UN Secretary-General to report to it on its activities. Accordingly, the UN Secretary-General reports to the General Assembly of the UN periodically on the progress of UPEACE. The Council of the University for Peace is the supreme authority of the University. It is composed of five "ex-officio" members viz. the Rector, two representatives designated by the UN Secretary-General and by the Director-General of the UNESCO, the Rector of the United Nations University, two representatives designated by the Government of the host country and the Chancellor of UPEACE. In addition, the Council comprises ten representatives of the academic community or other persons eminent in the field of peace and security appointed by the Secretary-General of the UN in consultation with the Director-General of the UNESCO.
Accreditation.
The University has "unique world-wide authorization to award academic degrees, recognized by all countries which are members of the General Assembly". This authorization to grant degrees is not equal to accreditation. Its environmental MA programs received official accreditation from SINAES (the national Costa Rican accreditation body) in 2014. Its law MA degrees are in the process of being accredited by SINAES. All other MA programs remain unaccredited. Unfortunately, the recognition of UPEACE degrees at this point is highly dependent on the potential employer, as even the UN Secretariat has been known not to recognize UPEACE degrees of candidates for employment. On the other hand, the fact that UPEACE offers unique MA programs that cannot be found anywhere else in the world means that it is the best and only choice for those who want to study the specific fields of Peace Education; Gender and Peacebuilding; Media, Peace and Conflict Studies; Responsible Management and Sustainable Development; etc. University-wide accreditation was a goal for some time but is currently on hold.
Headquarters and main campus.
The University for Peace has its headquarters in Costa Rica, a country distinguished by a long tradition of democracy. Costa Rica abolished its army in 1948, the former President, H.E. Oscar Arias Sánchez was awarded The Nobel Peace Prize in 1987 and the country continues to develop strong efforts for natural conservation - not to mention the friendly locals. The main campus of the University - the Rodrigo Carazo Campus - is located 30 km Southwest of San Jose, within a natural reserve composed of a secondary forest and the last remnant of primary forest (200 ha) in the Central Valley of Costa Rica. Hence, this protected area is very rich in fauna. It shelters mammals such as monkeys and deer; reptiles; and over 300 species of birds, as well as approximately 100 varieties of trees. The University's installations and protected area make up 303 ha.
The closest town to the mountain on which the University is perched, is Ciudad Colon. Most of the students, staff and faculty members of the University reside in Ciudad Colon, making it one of the most multi-cultural places in the world for its size.
The Rodrigo Carazo campus of the University for Peace is the principal location for the activities of the University. Most of its and its recently announced are administered from this campus. Students coming from several countries study in a highly multi-cultural environment on the campus. The University boasts of a highly accomplished , that comprises a mix of both resident and visiting faculty members. Because of the structure of the programmes and its unique global status, the University has an that enables bringing on board the most highly acclaimed academicians and practitioners from around the world. The University has also started administering , including an online Masters Programme from the main campus.
The University also carries out hands-on training beyond its Masters and Doctoral Programmes aimed at practitioners and policy makers rather than graduate students. The University has established two Centres for this purpose that are located on the main campus. The delivers dynamic training courses to leaders from around the world. The Centre reaches out to nonprofit leaders, business executives, educators at all levels, UN staff, students and other professional audiences. According to the Centre's website, the approach to all its courses is innovative, interactive, and participant-centered, using case-studies and field trips when appropriate. The Centre aims to develop key leadership skills by incorporating the crosscutting themes of Intercultural Communication, Negotiation and Conflict Resolution and Teambuilding.
The University has also established the which was created within the contours of the broader mission of the University to provide humanity with an international institution of higher education for peace and with the aim of promoting among all human beings the spirit of understanding, tolerance and peaceful coexistence, to stimulate cooperation among peoples and to help lessen obstacles and threats to world peace and progress, in keeping with the noble aspirations proclaimed in the Charter of the United Nations. In particular, the work of the UPEACE Human Rights Centre seeks to promote understanding, respect and enjoyment of universal human rights. The Centre carries out this objective through human rights education, training, research, capacity building and awareness raising activities. The website of the UPEACE Human Rights Centre states that the Centre takes a practice based approach to the respect, protection and fulfillment of human rights and promotes the integration of theory and practice. The Centre also takes a multi-disciplinary approach to human rights and attaches equal importance to all human rights. Over the last few years, the UPEACE Human Rights Centre has conducted several training courses for policy makers, staff members of the UN and other inter-governmental organizations, non-governmental organizations, practitioners, academics and civil servants.
The Headquarters and main campus of UPEACE also hosts the International Secretariat of the Earth Charter Initiative, whose stated mission is "to promote the transition to sustainable ways of living and a global society founded on a shared ethical framework that includes respect and care for the community of life, ecological integrity, universal human rights, respect for diversity, economic justice, democracy, and a culture of peace." This mission is carried out using 'The Earth Charter' as the principal guiding framework. The Earth Charter is an international declaration of fundamental values and principles considered useful by its supporters for building a just, sustainable, and peaceful global society in the 21st century. In 2012, the Earth Charter Initiative and UPEACE were jointly awarded the UNESCO Chair on Education for Sustainable Development and the Earth Charter. The work related to this UNESCO Chair will be carried out at the newly constructed 'Earth Charter Center for Education for Sustainable Development' at the UPEACE main campus.
In addition to the activities at the Costa Rica Headquarters Campus, UPEACE works with an increasing number of partners in various parts of the world to ensure that the UPEACE mission is extended to reach as many individuals and institutions as possible.
Around the world.
Africa
As a result of extensive international consultations, which have underlined the importance of according a high priority to activities in Africa, the University for Peace (UPEACE) officially launched its Africa Programme in January 2002.
The University for Peace (UPEACE) established its in 2002 on the basis of extensive consultations in the continent which aimed at developing a programme that responded to the true needs, aspirations and obstacles for education for building peace in Africa. From its inception, the programme focused on the necessity to stimulate and strengthen the capacity in Africa to teach, train and conduct research in areas of peace and conflict studies.
The first five years of the programme focused on the development of curricula and teaching materials and the delivery of a range of short courses, workshops, conferences and seminars in various parts of Africa. Within this period, the programme attracted close to one thousand participants from Academia, Policy makers and civil society organisations.
In a second five-year plan, which came out of a consultative meeting held in March 2007 with partners, the programme will additionally, work with a number of Partner Universities to develop full-fledged Master's degree programmes to be based at African Universities. The principal aim of this endeavour is to further strengthen the African capacity and build a wide expertise for a better understanding of conflicts in Africa, their prevention and the creation of the environment favourable to lasting peace and development in the region.
Europe
In January 2012, UPEACE created a new Centre at The Hague, Netherlands (), which is housed at the Academy Building of the Peace Palace, next to The Hague Academy of International Law. UPEACE The Hague will focus on education and research at the forefront of peace studies, closely cooperating with academic and policy-oriented institutions in The Hague region. UPEACE The Hague will initially advance three fields where it can be innovative and complementary: Peace & Conflict Studies, Water & Peace, and Urban Peace & Security. In addition, UPEACE The Hague will strengthen peace education in The Hague region by organising professional trainings, lectures, seminars, and workshops. Educational and research programmes will be characterised by the interaction between theory and practice, also contributing to policy innovations, and will therefore be appealing to both academics and professionals.
The Geneva Office of UPEACE, established in 2001, has continued to support the development of the overall activities of the University, in particular its regional programmes in Africa and Central Asia. The key focus of work undertaken by the Geneva office is contributing to the development of programme activities of the University in Africa and the Middle East, engaging with the academic community in Geneva to establish joint teaching and training courses on issues of particular relevance to the expertise available within the international community in Geneva and facilitation of relations within Europe and with the United Nations system, national delegations, donor community and academic institutions.
Asia-Pacific
In 2010, the (UPAPC) was established in Seoul, The Republic of Korea. The Centre carries out important activities as a think tank for development studies and provides post-graduate training programmes(Masters) in The Republic of Korea. The Republic of Korea acceded to the International Agreement for the establishment of the University for Peace and Charter of the University for Peace in June 11, 2010.
Asia
The , a Dual Campus Master Programme, is a shared initiative between the Nippon Foundation and the University for Peace, in collaboration with Ateneo de Manila University, which aims to provide students from Japan and other Asian countries with an opportunity to pursue a peace studies post graduate degree with a content-based language-training module. This offers the support for individuals who do not have a proficient command of English to work in this increasingly common international language and to become comfortable in their professional abilities as they gain academic skills. As part of the programme, students have also the opportunity to apply their academic and practical knowledge through a four-month internship at the end of the Master courses.
Affiliated institutions
Article 4 of the Charter of the University for Peace reads: "the University may enter into association or conclude agreements with Governments and intergovernmental and other organizations and institutions in the field of education." The University for Peace signed agreements with the governments of Serbia (formerly Yugoslavia), Colombia and Uruguay to open centres in those three countries. These centres have the necessary legal status to enjoy autonomy and academic freedom, while keeping its humanistic purpose within the framework of both the Charter of the University for Peace and the Charter of the United Nations and the Universal Declaration of Human Rights.
The European Centre for Peace and Development (ECPD) in Belgrade, Serbia; the World Centre for Training and Research in Conflict Resolution (WCCR) in Bogotá, Colombia; and the World Centre for Research for Peace (CMIP) in Montevideo, Uruguay, have developed close links with their respective governments while being key UPEACE partners in areas of common interest. UPEACE keeps operational agreements with them and lends its logos when necessary in order to undertake joint activities within the framework of UPEACE's and the Centres’ mission. These activities, as with other partners, involve the cooperating parties working together at all stages of jointly agreed-upon projects.
Academics.
UPEACE has been offering Master’s Degree Programmes at its Costa Rica campus for students from all parts of the world since its establishment. The following Programmes are being offered during the academic year 2012-2013:
• MA in International Law and the Settlement of Disputes;
• MA in International Law and Human Rights; 
• MA in International Peace Studies; 
• MA in Gender and Peacebuilding; 
• MA in Peace Education; 
• MA in Environmental Security and Governance, with a specialization in Climate Change;
• MA in Media, Peace and Conflict Studies; 
• MA in Sustainable Natural Resources Management;
• MA in Responsible Management and Sustainable Economic Development;
• MA in Sustainable Urban Governance and Peace;
• On-line MA in Sustainable Peace in the Contemporary World.
• Dual MA in Natural Resources and Sustainable Development (with American University, Washington DC); 
• Asia Leaders Programme, a Dual Campus MA in International Peace Studies (with Ateneo de Manila University, The Philippines)
• Dual MA programmes with Hankuk University of Foreign Studies, Seoul, Korea;
• Joint Degree in Peace and Security Studies with the Institute of Peace and Security Studies, Addis Ababa University, Ethiopia
• Dual MA in Peace Studies with the University of Innsbruck
• Joint MA programme in Sustainable Peace through Sports with International University in Monaco
UPEACE offers graduate and advance undergraduate students from other institutions the opportunity to enrol in UPEACE’s Study Abroad Programme (SAP) in three different ways:
• Semester Abroad Programme 
• UPEACE Institute in January
• Undergraduate Credit Building
Apart from its online MA in Sustainable Peace in the Contemporary World, UPEACE also offers a series of individual online courses that can be taken for both academic credits or for certificates.
The University has announced its new "Doctoral Programme in Peace & Conflict Studies" that is expected to commence in Fall of 2012. According to the website of the University for Peace, "this Doctoral Programme is designed to respond to a growing demand for academic and professional training that addresses the complex and multidimensional issues of peace and conflict in societies." The Programme offers a broad range of research foci and specializations including, though not limited to, Environmental Security and Peace, Gender and Peace Building, International Law and Human Rights, International Law and the Settlement of Disputes, International Peace Studies, Media, Peace and Conflict Studies, Natural Resources and Peace, Peace Education, Responsible Management and Sustainable Development, and Sustainable Urban Governance and Peace. The Programme offers two tracks for achieving the doctorate - a research track and a professional track.
Students and alumni.
Students at UPEACE receive a high quality education in a unique atmosphere with a focus on multicultural perspectives, rigorous theory and practical applications. Thousands of students from over have received graduate degrees from UPEACE. UPEACE alumni are working in peace related activities in their home countries and internationally, often in the front lines of conflict situations, for non-governmental organizations, academic and intergovernmental institutions, including the UN system. The University maintains a strong alumni network, all of whom get equipped with the necessary skills to pursue their chosen career paths at UPEACE. UPEACE aims to instill in their students a ‘sense of hope’ that forever ‘changes their lives’ and world vision in order to transform conflicts and promote sustainable peace and security. Notable UPEACE alumni include: Suzanne Hunt (2004) of X-Prize Foundation and Carbon War Room; Dan Juma (2006) former Deputy Director of Kenya Human Rights Commission; Hovig Etyemezian (2005) Director of the UNHCR Office in Mauritania; and Nick Martin (2006) Founder and President of TechChange.
Research.
"" is a free, fully peer reviewed open source academic journal published by the University for Peace. Articles featured in the review cover aspects of peace and violent conflict with a view to informing students, policymakers, non-governmental organizations and other interested parties of relevant analysis, empirical findings, policy options, and areas for further research. A number of interdisciplinary and multicultural papers are published every year, as well as some review articles of books and conference proceedings. Submissions can be sent online.
 is an online forum for informed debate and peace journalism. Drawing on contributions from the students, researchers, and journalists who make up the majority of its wide readership, the PCM offers unique perspectives on current events from around the world.
 is an academic journal focused on African issues related to peace and security and is published by the UPEACE Africa office. The aim of the APCJ peer review process is to be rigorous and free of bias, ensuring that only high-quality, innovative work is published. The interdisciplinary emphasis of APCJ seeks to encourage the building of the field, combining the disciplines of peace and conflict studies, development, and human and social security in Africa.
Outreach.
The U.S. Association for the University for Peace is a 501(c)(3) nonprofit organization established in 2006 to advance the University for Peace and the practice of education for peace in the United States. UPEACE/US projects include DCPEACE, an initiative to empower teachers, youth, and families with the skills and knowledge necessary to effectively serve as peacebuilders in their communities and PeaceRooms, a program that connect classrooms of middle school students from Costa Rica and Washington D.C. through the use of innovative virtual networking technology for the purpose of developing core concepts of global citizenship and peace education.
The UPEACE Sharing Knowledge for Peace Program (SKP) is a distance learning initiative which ensures that those unable to attend courses in Costa Rica or in one of the other UPEACE locations are reached through state-of-the-art dissemination methods.

</doc>
<doc id="32161" url="http://en.wikipedia.org/wiki?curid=32161" title="Urinary tract infection">
Urinary tract infection

A urinary tract infection (UTI) (also known as acute cystitis or bladder infection) is an infection that affects part of the urinary tract. When it affects the lower urinary tract it is known as a simple cystitis (a bladder infection) and when it affects the upper urinary tract it is known as pyelonephritis (a kidney infection). Symptoms from a lower urinary tract include painful urination and either frequent urination or urge to urinate (or both); while the symptoms of pyelonephritis include fever and flank pain in addition to the symptoms of a lower UTI. In some cases, a painful burning sensation in the urethra may be present even when not urinating. In the elderly and the very young, symptoms may be vague or non-specific. The main causal agent of both types is "Escherichia coli", though other bacteria, viruses or fungi may rarely be the cause.
Urinary tract infections occur more commonly in women than men, with half of women having at least one infection at some point in their lives. Recurrences are common. Risk factors include female anatomy, sexual intercourse and family history. Pyelonephritis, if it occurs, usually follows a bladder infection but may also result from a blood-borne infection. Diagnosis in young healthy women can be based on symptoms alone. In those with vague symptoms, diagnosis can be difficult because bacteria may be present without there being an infection. In complicated cases or if treatment has failed, a urine culture may be useful. In those with frequent infections, low dose antibiotics may be taken as a preventative measure.
In uncomplicated cases, urinary tract infections are easily treated with a short course of antibiotics, although resistance to many of the antibiotics used to treat this condition is increasing. In complicated cases, a longer course or intravenous antibiotics may be needed, and if symptoms have not improved in two or three days, further diagnostic testing is needed. In women, urinary tract infections are the most common form of bacterial infection with 10% developing urinary tract infections yearly. In those who have bacteria or white blood cells in their urine but have no symptoms, antibiotics are generally not needed, although pregnant woman are an exception to this recommendation.
Signs and symptoms.
Lower urinary tract infection is also referred to as a bladder infection. The most common symptoms are burning with urination and having to urinate frequently (or an urge to urinate) in the absence of vaginal discharge and significant pain. These symptoms may vary from mild to severe and in healthy women last an average of six days. Some pain above the pubic bone or in the lower back may be present. People experiencing an upper urinary tract infection, or pyelonephritis, may experience flank pain, fever, or nausea and vomiting in addition to the classic symptoms of a lower urinary tract infection. Rarely the urine may appear bloody or contain visible pus in the urine.
Children.
In young children, the only symptom of a urinary tract infection (UTI) may be a fever. Because of the lack of more obvious symptoms, when females under the age of two or uncircumcised males less than a year exhibit a fever, a culture of the urine is recommended by many medical associations. Infants may feed poorly, vomit, sleep more, or show signs of jaundice. In older children, new onset urinary incontinence (loss of bladder control) may occur.
Elderly.
Urinary tract symptoms are frequently lacking in the elderly. The presentations may be vague with incontinence, a change in mental status, or fatigue as the only symptoms, while some present to a health care provider with sepsis, an infection of the blood, as the first symptoms. Diagnosis can be complicated by the fact that many elderly people have preexisting incontinence or dementia.
It is reasonable to obtain a urine culture in those with signs of systemic infection that may be unable to report urinary symptoms, such as when advanced dementia is present. Systemic signs of infection include a fever or increase in temperature of more than 1.1 C from usual, chills, and an increase white blood cell count.
Cause.
"E. coli" is the cause of 80–85% of community-acquired urinary tract infections, with "Staphylococcus saprophyticus" being the cause in 5–10%. Rarely they may be due to viral or fungal infections. Healthcare-associated urinary tract infections (mostly related to urinary catheterization) involve a much broader range of pathogens including: "E. coli" (27%), "Klebsiella" (11%), "Pseudomonas" (11%), the fungal pathogen "Candida albicans" (9%), and "Enterococcus" (7%) among others. Urinary tract infections due to "Staphylococcus aureus" typically occur secondary to blood-borne infections. "Chlamydia trachomatis" and "Mycoplasma genitalium" can infect the urethra but not the bladder. These infections are usually classified as a urethritis rather than urinary tract infection.
Sex.
In young sexually active women, sexual activity is the cause of 75–90% of bladder infections, with the risk of infection related to the frequency of sex. The term "honeymoon cystitis" has been applied to this phenomenon of frequent UTIs during early marriage. In post-menopausal women, sexual activity does not affect the risk of developing a UTI. Spermicide use, independent of sexual frequency, increases the risk of UTIs. Diaphragm use is also associated. Condom use without spermicide or use of birth control pills does not increase the risk of uncomplicated urinary tract infection.
Women are more prone to UTIs than men because, in females, the urethra is much shorter and closer to the anus. As a woman's estrogen levels decrease with menopause, her risk of urinary tract infections increases due to the loss of protective vaginal flora. Additionally, vaginal atrophy that can sometimes occur after menopause is associated with recurrent urinary tract infections.
Chronic prostatitis may cause recurrent urinary tract infections in males. Risk of infections increases as males age. While bacteria is commonly present in the urine of older males this does not appear to affect the risk of urinary tract infections.
Urinary catheters.
Urinary catheterization increases the risk for urinary tract infections. The risk of bacteriuria (bacteria in the urine) is between three to six percent per day and prophylactic antibiotics are not effective in decreasing symptomatic infections. The risk of an associated infection can be decreased by catheterizing only when necessary, using aseptic technique for insertion, and maintaining unobstructed closed drainage of the catheter.
Male scuba divers utilizing condom catheters or the female divers utilizing external catching device for their dry suits are also susceptible to urinary tract infections.
Others.
A predisposition for bladder infections may run in families. Other risk factors include diabetes, being uncircumcised, and having a large prostate. Complicating factors are rather vague and include predisposing anatomic, functional, or metabolic abnormalities. In children UTIs are associated with vesicoureteral reflux (an abnormal movement of urine from the bladder into ureters or kidneys) and constipation.
Persons with spinal cord injury are at increased risk for urinary tract infection in part because of chronic use of catheter, and in part because of voiding dysfunction. It is the most common cause of infection in this population, as well as the most common cause of hospitalization. Additionally, use of cranberry juice or cranberry supplement appears to be ineffective in prevention and treatment in this population.
Pathogenesis.
The bacteria that cause urinary tract infections typically enter the bladder via the urethra. However, infection may also occur via the blood or lymph. It is believed that the bacteria are usually transmitted to the urethra from the bowel, with females at greater risk due to their anatomy. After gaining entry to the bladder, "E. Coli" are able to attach to the bladder wall and form a biofilm that resists the body's immune response.
Diagnosis.
In straightforward cases, a diagnosis may be made and treatment given based on symptoms alone without further laboratory confirmation. In complicated or questionable cases, it may be useful to confirm the diagnosis via urinalysis, looking for the presence of urinary nitrites, white blood cells (leukocytes), or leukocyte esterase. Another test, urine microscopy, looks for the presence of red blood cells, white blood cells, or bacteria. Urine culture is deemed positive if it shows a bacterial colony count of greater than or equal to 103 colony-forming units per mL of a typical urinary tract organism. Antibiotic sensitivity can also be tested with these cultures, making them useful in the selection of antibiotic treatment. However, women with negative cultures may still improve with antibiotic treatment. As symptoms can be vague and without reliable tests for urinary tract infections, diagnosis can be difficult in the elderly.
Classification.
A urinary tract infection may involve only the lower urinary tract, in which case it is known as a bladder infection. Alternatively, it may involve the upper urinary tract, in which case it is known as pyelonephritis. If the urine contains significant bacteria but there are no symptoms, the condition is known as asymptomatic bacteriuria. If a urinary tract infection involves the upper tract, and the person has diabetes mellitus, is pregnant, is male, or immunocompromised, it is considered complicated. Otherwise if a woman is healthy and premenopausal it is considered uncomplicated. In children when a urinary tract infection is associated with a fever, it is deemed to be an upper urinary tract infection.
Children.
To make the diagnosis of a urinary tract infection in children, a positive urinary culture is required. Contamination poses a frequent challenge depending on the method of collection used, thus a cutoff of 105 CFU/mL is used for a "clean-catch" mid stream sample, 104 CFU/mL is used for catheter-obtained specimens, and 102 CFU/mL is used for suprapubic aspirations (a sample drawn directly from the bladder with a needle). The use of "urine bags" to collect samples is discouraged by the World Health Organization due to the high rate of contamination when cultured, and catheterization is preferred in those not toilet trained. Some, such as the American Academy of Pediatrics recommends renal ultrasound and voiding cystourethrogram (watching a person's urethra and urinary bladder with real time x-rays while they urinate) in all children less than two years old who have had a urinary tract infection. However, because there is a lack of effective treatment if problems are found, others such as the National Institute for Health and Care Excellence only recommends routine imaging in those less than six months old or who have unusual findings.
Differential diagnosis.
In women with cervicitis (inflammation of the cervix) or vaginitis (inflammation of the vagina) and in young men with UTI symptoms, a "Chlamydia trachomatis" or "Neisseria gonorrheae" infection may be the cause. These infections are typically classified as a urethritis rather than a urinary tract infection. Vaginitis may also be due to a yeast infection. Interstitial cystitis (chronic pain in the bladder) may be considered for people who experience multiple episodes of UTI symptoms but urine cultures remain negative and not improved with antibiotics. Prostatitis (inflammation of the prostate) may also be considered in the differential diagnosis.
Hemorrhagic cystitis, characterized by blood in the urine, can occur secondary to a number of causes including: infections, radiation therapy, underlying cancer, medications and toxins. Medications that commonly cause this problem include the chemotherapeutic agent cyclophosphamide with rates of 2 to 40%. Eosinophilic cystitis is a rare condition where eosinophiles are present in the bladder wall. Signs and symptoms are similar to a bladder infection. Its cause is not entirely clear; however, it may be linked to food allergies, infections, and medications among others.
Prevention.
A number of measures have not been confirmed to affect UTI frequency including: urinating immediately after intercourse, the type of underwear used, personal hygiene methods used after urinating or defecating, or whether a person typically bathes or showers. There is similarly a lack of evidence surrounding the effect of holding one's urine, tampon use, and douching. In those with frequent urinary tract infections who use spermicide or a diaphragm as a method of contraception, they are advised to use alternative methods. In those with benign prostatic hyperplasia urinating in a sitting position appears to improve bladder emptying which might decrease urinary tract infections in this group.
Using urinary catheters as little and as short of time as possible and appropriate care of the catheter when used prevents infections.
They should be inserted using sterile technique in hospital however non-sterile technique may be appropriate in those who self catheterize. The urinary catheter set up should also be kept sealed. Evidence does not support an important decreased in risk when silver-alloy catheters are used.
Medications.
For those with recurrent infections, taking a short course of antibiotics when each infection occurs is associated with the lowest antibiotic use. A prolonged course of daily antibiotics is also effective. Medications frequently used include nitrofurantoin and trimethoprim/sulfamethoxazole (TMP/SMX). Methenamine is another agent used for this purpose as in the bladder where the acidity is low it produces formaldehyde to which resistance does not develop. Some recommend again prolonged use due to concerns of antibiotic resistance.
In cases where infections are related to intercourse, taking antibiotics afterwards may be useful. In post-menopausal women, topical vaginal estrogen has been found to reduce recurrence. As opposed to topical creams, the use of vaginal estrogen from pessaries has not been as useful as low dose antibiotics. Antibiotics following short term urinary catheterization decreases the subsequent risk of a bladder infection. A number of vaccines are in development as of 2011.
Children.
The evidence that preventative antibiotics decrease urinary tract infections in children is poor. However recurrent UTIs are a rare cause of further kidney problems if there are no underlying abnormalities of the kidneys, resulting in less than a third of a percent (0.33%) of chronic kidney disease in adults. Whether routine circumcisions prevents UTIs has not been well studied as of 2011.
Alternative medicine.
Some research suggests that cranberry (juice or capsules) may decrease the number of UTIs in those with frequent infections. A Cochrane review concluded that the benefit, if it exists, is small. Long-term tolerance is also an issue with gastrointestinal upset occurring in more than 30%. Cranberry juice is thus not currently recommended for this indication. As of 2011, intravaginal probiotics require further study to determine if they are beneficial.
Treatment.
The mainstay of treatment is antibiotics. Phenazopyridine is occasionally prescribed during the first few days in addition to antibiotics to help with the burning and urgency sometimes felt during a bladder infection. However, it is not routinely recommended due to safety concerns with its use, specifically an elevated risk of methemoglobinemia (higher than normal level of methemoglobin in the blood). Acetaminophen (paracetamol) may be used for fevers. There is no good evidence for the use of cranberry products for treating current infections.
Asymptomatic bacteriuria.
Those who have bacteria in the urine but no symptoms should not generally be treated with antibiotics. This includes those who are old, those with spinal cord injuries, and those who have urinary catheters. Pregnancy is an exception and it is recommended that women take 7 days of antibiotics. If not treated it causes up to 30% of mothers to develop pyelonephritis and increases risk of low birth weight and preterm birth. Some also support treatment of those with diabetes mellitus and treatment before urinary tract procedures which will likely cause bleeding.
Uncomplicated.
Uncomplicated infections can be diagnosed and treated based on symptoms alone. Oral antibiotics such as trimethoprim/sulfamethoxazole (TMP/SMX), nitrofurantoin, or fosfomycin typically first line. Cephalosporins, amoxicillin/clavulanic acid, or a fluoroquinolone may also be used. These medications substantially shorten the time to recovery with all being equally effective. A three-day treatment with trimethoprim, TMP/SMX, or a fluoroquinolone is usually sufficient, whereas nitrofurantoin requires 5–7 days. Fosfomycin may be used as a single dose.
With treatment, symptoms should improve within 36 hours. About 50% of people will recover without treatment within a few days or weeks. The Infectious Diseases Society of America does not recommend fluoroquinolones as first treatment due to the concern of generating resistance to this class of medication. Amoxicillin-clavulanate appears less effective than other options. Despite this precaution, some resistance has developed to all of these medications related to their widespread use. Trimethoprim alone is deemed to be equivalent to TMP/SMX in some countries. For simple UTIs, children often respond to a three-day course of antibiotics. Women with recurrent simple UTIs may benefit from self-treatment upon occurrence of symptoms with medical follow-up only if the initial treatment fails.
Complicated.
Complicated UTIs are more difficult to treat and usually requires more aggressive evaluation, treatment and follow-up. It may require identifying and addressing the underlying complication. Increasing antibiotic resistance is causing concern about the future of treating those with complicated and recurrent UTI.
Pyelonephritis.
Pyelonephritis is treated more aggressively than a simple bladder infection using either a longer course of oral antibiotics or intravenous antibiotics. Seven days of the oral fluoroquinolone ciprofloxacin is typically used in areas where the resistance rate is less than 10%. If the local resistance rates are greater than 10%, a dose of intravenous ceftriaxone is often prescribed. Trimethoprim/sulfamethoxazole or amoxicillin/clavulanate orally for 14 days is another reasonable option. In those who exhibit more severe symptoms, admission to a hospital for ongoing antibiotics may be needed. Complications such as urinary obstruction from a kidney stone may be considered if symptoms do not improve following two or three days of treatment.
Epidemiology.
Urinary tract infections are the most frequent bacterial infection in women. They occur most frequently between the ages of 16 and 35 years, with 10% of women getting an infection yearly and 60% having an infection at some point in their lives. Recurrences are common, with nearly half of people getting a second infection within a year. Urinary tract infections occur four times more frequently in females than males. Pyelonephritis occurs between 20–30 times less frequently. They are the most common cause of hospital acquired infections accounting for approximately 40%. Rates of asymptomatic bacteria in the urine increase with age from two to seven percent in women of child bearing age to as high as 50% in elderly women in care homes. Rates of asymptomatic bacteria in the urine among men over 75 are between 7-10%. Asymptomatic bacteria in the urine occurs in 2% to 10% of pregnancies.
Urinary tract infections may affect 10% of people during childhood. Among children urinary tract infections are the most common in uncircumcised males less than three months of age, followed by females less than one year. Estimates of frequency among children however vary widely. In a group of children with a fever, ranging in age between birth and two years, two to 20% were diagnosed with a UTI.
Society and culture.
In the United States, urinary tract infections account for nearly seven million office visits, a million emergency department visits, and one hundred thousand hospitalizations every year. The cost of these infections is significant both in terms of lost time at work and costs of medical care. In the United States the direct cost of treatment is estimated at 1.6 billion USD yearly.
History.
Urinary tract infections have been described since ancient times with the first documented description in the Ebers Papyrus dated to c. 1550 BC. It was described by the Egyptians as "sending forth heat from the bladder". Effective treatment did not occur until the development and availability of antibiotics in the 1930s before which time herbs, bloodletting and rest were recommended.
Pregnancy.
Urinary tract infections are more concerning in pregnancy due to the increased risk of kidney infections. During pregnancy, high progesterone levels elevate the risk of decreased muscle tone of the ureters and bladder, which leads to a greater likelihood of reflux, where urine flows back up the ureters and towards the kidneys. While pregnant women do not have an increased risk of asymptomatic bacteriuria, if bacteriuria is present they do have a 25-40% risk of a kidney infection. Thus if urine testing shows signs of an infection—even in the absence of symptoms—treatment is recommended. Cephalexin or nitrofurantoin are typically used because they are generally considered safe in pregnancy. A kidney infection during pregnancy may result in premature birth or pre-eclampsia (a state of high blood pressure and kidney dysfunction during pregnancy that can lead to seizures).

</doc>
<doc id="32163" url="http://en.wikipedia.org/wiki?curid=32163" title="USS Greeneville (SSN-772)">
USS Greeneville (SSN-772)

USS "Greeneville" (SSN-772), a "Los Angeles"-class submarine and is the only ship of the United States Navy to be named after Greeneville, Tennessee.
History.
The contract to build the ship was awarded to Newport News Shipbuilding and Dry Dock Company in Newport News, Virginia, on 14 December 1988, and her keel was laid down on 28 February 1992. She was launched on 17 September 1994, sponsored by Tipper Gore, and commissioned on 16 February 1996, with Commander Duane B. Hatch in command.
She was named after Greeneville, the home of 17th United States President Andrew Johnson, after local residents, businesses such as Greeneville Metal Manufacturing, which builds submarine components, and government officials began a campaign for a submarine to be named after their town, rather than a large metropolitan area.
The "Greeneville" is probably best known for colliding with a Japanese fishing vessel off the coast of Oahu in February 2001.
Incidents.
The "Ehime Maru" incident.
On 9 February 2001, while conducting an emergency main ballast tank blow off the coast of Oahu while hosting several civilian "distinguished visitors", mainly donors to the Battleship Missouri Memorial, the "Greeneville" struck the 191-foot (58 m) Japanese fishery high school training ship "Ehime Maru" (えひめ丸), causing the fishing boat to sink in less than ten minutes with the death of nine crew members, including four high school students. The commander of the "Greeneville", Commander Scott Waddle, accepted full responsibility for the incident. However, after he faced a court of inquiry, it was decided a full court-martial would be unnecessary and Commander Waddle's request to retire was approved for 1 October 2001 with an honorable discharge.
Saipan incident.
On 27 August 2001, "Greeneville" ran aground while entering port in Saipan on a routine Western Pacific deployment. The boat's underside, rudder, and propulsion train suffered minor damage; repairs required drydocking and a significant delay in the remainder of her deployment. The boat's commanding officer, Commander David Bogdan, was relieved of command, and the navigator and assistant navigator were also removed from their duties. In addition, the navigator and the sub's executive officer, Lieutenant Commander Gerald Pfieffer, were found guilty of "hazarding a vessel" during an admiral's mast, conducted by Rear Admiral Joseph Enright, Commander, Submarine Group Seven.
USS "Ogden" collision.
Then, on 27 January 2002, less than a year after colliding with "Ehime Maru" and five months after running aground, "Greeneville" collided with during a personnel transfer off the coast of Oman, opening a 5 by 18 inch (130 by 460 mm) hole in one of "Ogden"'s fuel tanks and spilling several thousand gallons of fuel. After the collision, both vessels left the area under their own power.
Post-2002 Service.
Following the investigation regarding the collision with the "USS Ogden", Commander Lindsay R. Hankins was permitted to remain in command of the "Greeneville". ADM Thomas Fargo the US Pacific Commander decided the bleeding had to stop some where and he drew the line at Hankins. Despite the fact the "Ogden"'s Commanding Officer was fired, Hankins went on to have a successful command tour with his XO LCDR Mark D. Pyle. Capt. Hankins went on to be awarded the coveted Vice Admiral James Bond Stockdale Award for Inspirational Leadership, the highest honor that can be bestowed upon a Navy commanding officer. LCDR Pyle also went on to have the honor of being bestowed with the John Paul Jones award, which recognizes outstanding leadership.
On 9 July 2004, when Commander Lorin Selby relieved Hankins as commanding officer of "Greeneville", Captain Cecil Haney, Commodore, Submarine Squadron One, stated that "The performance of USS "Greeneville" during Captain Hankins' tour has been nothing but remarkable. It has been marked by top grades in both tactical and engineering readiness. Lee Hankins was handpicked by our leadership for the job as CO of "Greeneville". They got it right." Hankins was selected for promotion to Captain in 2005 and served as Commodore of Submarine Squadron One (COMSUBRON 1) based in Pearl Harbor, Hawaii. Captain Hankins later served as the Chief of Staff for the Commander, Submarine Forces Pacific.
Between 25–27 March 2006, a series of anti-submarine warfare exercises were held in Hawaiian waters that included the "Greeneville"; Carrier Strike Group Nine; the nuclear-powered attack submarines "Seawolf", "Cheyenne", "Tucson", and "Pasadena", as well as land-based P-3 Orion aircraft from patrol squadrons VP-4, VP-9, and VP-47.
In October 2007, "Greeneville" left her home port of Pearl Harbor to conduct a Depot Modernization Period at Portsmouth Naval Shipyard in Kittery, ME. She returned to Pearl Harbor, HI in July 2009. In early 2011, "Greeneville" returned from a Western Pacific deployment under the command of CDR Carullo.
References.
"This article includes information collected from the Naval Vessel Register, which, as a U.S. government publication, is in the public domain."

</doc>
<doc id="32164" url="http://en.wikipedia.org/wiki?curid=32164" title="Unitarianism">
Unitarianism

Unitarianism is a Christian theological movement named for the affirmation that God is one person, in direct contrast to Trinitarianism, which defines God as three persons coexisting consubstantially in one being. Unitarians maintain that Jesus of Nazareth is in some sense the "son" of God (as all humans are children of the Creator), but that he is not the one God himself. Though they may believe that he was inspired by God in his moral teachings, and can be considered a savior, all Unitarians perceive Christ as human rather than divine. Unitarianism is also known for the rejection of several other Western Christian doctrines, including the soteriological doctrines of original sin and predestination, and, in more recent history, biblical inerrancy. While Unitarians in previous centuries accepted the doctrine of punishment in an eternal hell, few do today. In J. Gordon Melton's "Encyclopedia of American Religions" it is classified among "the 'liberal' family of churches".
The Unitarian movement, although not called "Unitarian" initially, began almost simultaneously in Poland-Lithuania and Transylvania in the mid-16th century. Among the adherents were a significant number of Italians. In England, the first Unitarian Church was established in 1774 on Essex Street, London, where today's British Unitarian headquarters are still located. Since the theology was also perceived as deistic, it began to attract many wealthy and educated classes, and it was only at the late second half of 18th century that it started to gain some wider consent within Christendom. In America, it spread first in New England, and the first official acceptance of the Unitarian faith on the part of a congregation in America was by King's Chapel in Boston, from where James Freeman began teaching Unitarian doctrine in 1784, and was appointed rector and revised the Prayer Book according to Unitarian doctrines in 1786.
Terminology.
"Unitarianism" is a proper noun and follows the same English usage as other theologies that have developed within a religious movement (Calvinism, Anabaptism, Adventism, Wesleyanism, Lutheranism, etc.). The term existed shortly before it became the name of a religious movement, and thus occasionally it is used as a common noun that would describe any understanding of Jesus Christ that denies the Trinity or which believes that God is only one person. In that case it would be a nontrinitarian belief system not necessarily associated with the Unitarian religious movement. For example, the Unitarian movement has never accepted the Godhood of Jesus, and therefore does not include those "nontrinitarian" belief systems that do—such as Oneness Pentecostalism, United Pentecostal Church International and the True Jesus Church and the writings of Michael Servetus —and which maintain that Jesus is God as a single person. Although these groups are unitarians in the common sense, they are not in the proper sense. To avoid confusion, this article is about Unitarianism as a religious movement (proper noun). For the generic form of unitarianism (the Christology), see Nontrinitarianism. Recently some religious groups have adopted the 19th-century term "biblical unitarianism" to distinguish their theology from Unitarianism. These likewise have no direct relation to the Unitarian movement.
The term "Unitarian" is sometimes applied today to those who belong to a Unitarian church but who do not hold a Unitarian theological belief. In the past, the vast majority of members of Unitarian churches were Unitarians also in theology. Over time, however, some Unitarians and Unitarian Universalists moved away from the traditional Christian roots of Unitarianism. For example, in the 1890s the American Unitarian Association began to allow non-Christian and non-theistic churches and individuals to be part of their fellowship. As a result, people who held no Unitarian belief began to be called "Unitarians" because they were members of churches that belonged to the American Unitarian Association. After several decades, the non-theistic members outnumbered the theological Unitarians. A similar, though proportionally much smaller, phenomenon has taken place in the Unitarian churches in the United Kingdom, Canada, and other countries, which remain more theistically based. Unitarian theology, therefore, is distinguishable from the belief system of modern Unitarian and Unitarian Universalist churches and fellowships. This article includes information about Unitarianism as a theology and about the development of theologically Unitarian churches. For a more specific discussion of Unitarianism as it evolved into a pluralistic liberal religious movement, see Unitarian Universalism (and its national groups the Unitarian Universalist Association in the United States, the Canadian Unitarian Council in Canada, the General Assembly of Unitarian and Free Christian Churches in the United Kingdom, and the International Council of Unitarians and Universalists).
History.
Unitarianism, both as a theology and as a denominational family of churches, was defined and developed in five countries: Poland, Transylvania, England, Wales and America. Although there were common beliefs among Unitarians in each of these regions, they initially grew independently from each other. Only later did they influence one another and accumulate more similarities.
The "Ecclesia minor" or "Minor Reformed Church of Poland", better known today as the Polish Brethren, was born as the result of a controversy that started on January 22, 1556, when Piotr of Goniądz (Peter Gonesius), a Polish student, spoke out against the doctrine of the Trinity during the general synod of the Reformed (Calvinist) churches of Poland held in the village of Secemin. After nine years of debate, in 1565, the anti-Trinitarians were excluded from the existing synod of the Polish Reformed Church (henceforth the "Ecclesia maior") and they began to hold their own synods as the "Ecclesia minor". Though frequently called "Arians" by those on the outside, the views of Fausto Sozzini became the standard in the church, and these doctrines were quite removed from Arianism. So important was Sozzini to the formulation of their beliefs that those outside Poland usually referred to them as Socinians. The Polish Brethren were disbanded in 1658 by the Sejm (Polish Parliament). They were ordered to convert to Roman Catholicism or leave Poland. Most of them went to Transylvania or Holland, where they embraced the name "Unitarian." Sozzini's grandson Andrzej Wiszowaty Sr. in 1665–1668 published "Bibliotheca Fratrum Polonorum quos Unitarios vocant" ("Library of the Polish Brethren who are called Unitarians" 4 vols. 1665–69).
The Unitarian Church in Transylvania was first recognized by the Edict of Torda, issued by the Transylvanian Diet under Prince John II Sigismund Zápolya (January 1568), and was first led by Ferenc Dávid (a former Calvinist bishop, who had begun preaching the new doctrine in 1566). The term "Unitarian" first appeared as "unitaria religio" in a document of the Diet of Lécfalva, Transylvania, on 25 October 1600, though it was not widely used in Transylvania until 1638, when the formal "recepta Unitaria Religio" was published.
The word "Unitarian" had been circulating in private letters in England, in reference to imported copies of such publications as the "Library of the Polish Brethren who are called Unitarians" (1665). Henry Hedworth was the first to use the word "Unitarian" in print in English (1673), and the word first appears in a title in Stephen Nye's "A brief history of the Unitarians, called also Socinians" (1687). The movement gained popularity in England in the wake of the Enlightenment and began to become a formal denomination in 1774 when Theophilus Lindsey organised meetings with Joseph Priestley, founding the first avowedly Unitarian congregation in the country, at Essex Street Church in London.
The first official acceptance of the Unitarian faith on the part of a congregation in America was by King's Chapel in Boston, which settled James Freeman (1759–1835) in 1782, and revised the Prayer Book into a mild Unitarian liturgy in 1785. In 1800, Joseph Stevens Buckminster became minister of the Brattle Street Church in Boston, where his brilliant sermons, literary activities, and academic attention to the German "New Criticism" helped shape the subsequent growth of Unitarianism in New England. Unitarian Henry Ware (1764–1845) was appointed as the Hollis professor of divinity at Harvard College, in 1805. Harvard Divinity school then shifted from its conservative roots to teach Unitarian theology. See: Harvard & Unitarianism. Buckminster's close associate William Ellery Channing (1780–1842) was settled over the Federal Street Church in Boston, 1803, and in a few years he became the leader of the Unitarian movement. A theological battle with the Congregational Churches resulted in the formation of the American Unitarian Association at Boston in 1825.
Beliefs.
Christology.
Unitarians believe that mainline Christianity does not adhere to strict monotheism but that they do by maintaining that Jesus was a great man and a prophet of God, perhaps even a supernatural being, but not God himself. They believe Jesus did not claim to be God and that his teachings did not suggest the existence of a triune God. Unitarians believe in the moral authority but not necessarily the divinity of Jesus. Their theology is thus opposed to the trinitarian theology of other Christian denominations.
Unitarian Christology can be divided according to whether Jesus is believed to have had a pre-human existence. Both forms maintain that God is one being and one "person" and that Jesus is the (or a) Son of God, but generally not God himself.
In the early 19th century, Unitarian Robert Wallace identified three particular classes of Unitarian doctrines in history: Arians, which believed in a pre-existence of the divine spirit, but maintained that Jesus was created and lived as human only; "Socinians", which, denied his original divinity, but agreed that Christ should be worshipped; and "Strict unitarians", which, believing in an "incommunicable divinity of God", denied both the existence of the Holy Spirit and the worship of "the man Christ." Unitarianism is considered a factor in the decline of classical deism because there were people who increasingly preferred to identify themselves as Unitarians rather than deists. Several tenets of unitarianism overlap with the beliefs of Muwahhid Muslims.
"Socinian" Christology.
The Christology commonly called "Socinian" (after Fausto Sozzini, one of the founders of Unitarian theology) refers to the belief that Jesus Christ began his life when he was born as a human. In other words, the teaching that Jesus pre-existed his human body is rejected. There are various views ranging from the belief that Jesus was simply a human (psilanthropism) who, because of his greatness, was adopted by God as his Son (adoptionism) to the belief that Jesus literally became the son of God when he was conceived by the Holy Spirit (see Virgin birth of Jesus).
This Christology existed in some form or another prior to Sozzini. Theodotus of Byzantium, Artemon and Paul of Samosata denied the pre-existence of Christ. These ideas were continued by Marcellus of Ancyra and his pupil Photinus in the 4th century AD. In the Radical Reformation and Anabaptist movements of the 16th century this idea resurfaced with Sozzini's uncle, Lelio Sozzini. Having influenced the Polish Brethren to a formal declaration of this belief in the Racovian Catechism, Fausto Sozzini involuntarily ended up giving his name to this Christological position, which continued with English Unitarians such as John Biddle, Thomas Belsham, Theophilus Lindsey, Joseph Priestley, and James Martineau. In America, most of the early Unitarians were "Arian" in Christology (see below), but among those who held to a "Socinian" view was James Freeman.
Regarding the virgin birth of Jesus among those who denied the preexistence of Christ, some held to it and others did not. Its denial is sometimes ascribed to the Ebionites; however, Origen ("Contra Celsum" v.61) and Eusebius ("HE" iii.27) both indicate that some Ebionites did accept the virgin birth. On the other hand, Theodotus of Byzantium, Artemon, and Paul of Samosata all accepted the virgin birth. In the early days of Unitarianism, the stories of the virgin birth were accepted by most. The "Chambers Biographical Dictionary" (1897) incorrectly ascribes denial of the virgin birth to Ferenc Dávid, leader of the Transylvanian Unitarians. However, there were a number of Unitarians who questioned the historical accuracy of the Bible (such as Symon Budny, Jacob Palaeologus, Thomas Belsham, and Richard Wright), and this made them question the virgin birth story. Beginning in England and America in the 1830s, and manifesting itself primarily in Transcendentalist Unitarianism, which emerged from the German liberal theology associated primarily with Friedrich Schleiermacher, the psilanthropist view increased in popularity. Its proponents took an intellectual and humanistic approach to religion. They embraced evolutionary concepts, asserted the "inherent goodness of man", and abandoned the doctrine of biblical infallibility, rejecting most of the miraculous events in the Bible (including the virgin birth). Notable examples are James Martineau, Theodore Parker, Ralph Waldo Emerson and Frederic Henry Hedge. Famous American Unitarian William Ellery Channing was a believer in the virgin birth until later in his life, after he had begun his association with the Transcendentalists.
"Arian" Christology.
The Christology commonly called "Arian" holds that Jesus, before his human life, existed as the Logos, a being created by God, who dwelt with God in heaven. There are many varieties of this form of Unitarianism, ranging from the belief that the Son was a divine spirit of the same nature as God before coming to earth, to the belief that he was an angel or other lesser spirit creature of a wholly different nature from God. Not all of these views necessarily were held by Arius, the namesake of this Christology. It is still Nontrinitarian because, according to this belief system, Jesus has always been beneath God, though higher than humans. Arian Christology was not a majority view among Unitarians in Poland, Transylvania or England. It was only with the advent of American Unitarianism that it gained a foothold in the Unitarian movement.
Among early Christian theologians who believed in a pre-existent Jesus who was subordinate to God the Father were Lucian of Antioch, Eusebius of Caesarea, Arius, Eusebius of Nicomedia, Asterius the Sophist, Eunomius, and Ulfilas, as well as Felix, Bishop of Urgell. Proponents of this Christology also associate it (more controversially) with Justin Martyr and Hippolytus of Rome. Antitrinitarian Michael Servetus did not deny the pre-existence of Christ, so he may have believed in it. (In his "Treatise Concerning the Divine Trinity" Servetus taught that the Logos (Word) was the reflection of Christ, and "that reflection of Christ was 'the Word with God" that consisted of God Himself, shining brightly in heaven, "and it was God Himself" and that "the Word was the very essence of God or the manifestation of God's essence, and there was in God no other substance or hypostasis than His Word, in a bright cloud where God then seemed to subsist. And in that very spot the face and personality of Christ shone bright.") Isaac Newton had Arian beliefs as well. Famous 19th-century Arian Unitarians include Andrews Norton and Dr. William Ellery Channing (in his earlier years).
Other beliefs.
Although there is no specific authority on convictions of Unitarian belief aside from rejection of the Trinity, the following beliefs are generally accepted:
Unitarians have liberal views of God, Jesus, the world and purpose of life as revealed through reason, scholarship, science, philosophy, scripture and other prophets and religions. They believe that reason and belief are complementary and that religion and science can co-exist and guide them in their understanding of nature and God. They also do not enforce belief in creeds or dogmatic formulas. Although there is flexibility in the nuances of belief or basic truths for the individual Unitarian Christian, general principles of faith have been recognized as a way to bind the group in some commonality. Adherents generally accept religious pluralism and find value in all teachings, but remain committed to their core belief in Christ's teachings. Unitarians generally value a secular society in which government is kept separate from religious affairs. Most contemporary Unitarian Christians believe that one's personal moral convictions guide one's political activities, and that a secular society is the most viable, just and fair.
Unitarian Christians reject the doctrine of some Christian denominations that God chooses to redeem or save only those certain individuals that accept the creeds of, or affiliate with, a specific church or religion, from a common ruin or corruption of the mass of humanity.
In 1938, "The Christian leader" attributed ""the" religion "of" Jesus, not "a" religion "about" Jesus" to Unitarians, though the phrase was used earlier by Congregationalist Rollin Lynde Hartt in 1924. and earlier still by US President Thomas Jefferson.
Worship.
Worship within the Unitarian tradition accommodates a wide range of understandings of God, while the focus of the service may be simply the celebration of life itself. Each Unitarian congregation is at liberty to devise its own form of worship, though commonly, Unitarians will light their chalice (symbol of faith), have a story for all ages; and include sermons, prayers, hymns and songs. Some will allow attendees to publicly share their recent joys or concerns.
Modern Christian Unitarian organizations.
This section relates to Unitarian churches and organizations today which are still specifically Christian within or outside Unitarian-Universalism, which embraces non-Christian religions.
Hungarian and Transylvanian Unitarian Churches.
The largest Unitarian denomination worldwide today is also the oldest surviving Unitarian denomination (since 1565, first use of the term "Unitarian" 1600); the Unitarian Church of Transylvania (in Romania, which is in union with the Unitarian Church in Hungary). The church in Romania and Hungary still looks to the statement of faith, the "Summa Universae Theologiae Christianae secundum Unitarios" (1787), though today assent to this is not required. The modern Unitarian Church in Hungary (25,000 members) and the Transylvanian Unitarian Church (75,000 members) are affiliated with the International Council of Unitarians and Universalists (ICUU) and claim continuity with the historical Unitarian Christian tradition established by Ferenc Dávid in 1565 in Transylvania under John II Sigismund Zápolya. The Unitarian churches in Hungary and Transylvania are structured and organized along a church hierarchy that includes the election by the synod of a national bishop who serves as superintendent of the Church. Many Hungarian Unitarians embrace the principles of rationalist Unitarianism. Unitarian high schools exist only in Transylvania (Romania), including the John Sigismund Unitarian Academy in Cluj-Napoca (Kolozsvár), and the Berde Mózes Unitárius Gimnázium in Cristuru Secuiesc (Székelykeresztúr); both teach Rationalist Unitarianism.
UCC USA.
The Unitarian Christian Conference USA is a network of congregations and ministers in the United States identifying with the historic Unitarian Christian tradition. The Unitarian Christian Conference USA promotes the concept of the unity of God and the message and example of Jesus of Nazareth as a rational and enriching spiritual path for personal development and a guide for creating a world of justice, peace and human dignity.
UUCF.
The Unitarian Universalist Christian Fellowship (UUCF, founded 1945) predates the consolidation of the American Unitarian Association (AUA) and Universalist Church of America (UCA) into the Unitarian Universalist Association (UUA) in 1961. UUCF continues as a subgroup of UUA serving the Christian members.
ICUU.
Other Unitarian Christian groups are affiliated with the International Council of Unitarians and Universalists (ICUU), founded in 1995. The ICUU tends to contain a majority membership who express specifically Unitarian Christian beliefs, rather than the religious pluralism of the UUA, but nevertheless remain liberal, open-minded and inclusive communities. The ICUU has "full member" groups in the United States, Australia, New Zealand, United Kingdom, Canada, Brazil, Czech Republic, Finland, Germany, Hungary, Indonesia, India, Nigeria, Pakistan, Philippines, Romania, South Africa, and Sri Lanka.
The ICUU includes small "Associate groups", including Congregazione Italiana Cristiano Unitariana, Turin (founded in 2004) and the Bét Dávid Unitarian Association, Oslo (founded 2005).
AUC.
The American Unitarian Conference (AUC) was formed in 2000 and stands between UUA and ICUU in attachment to the Christian element of modern Unitarianism. The American Unitarian Conference is open to non-Christian Unitarians—being particularly popular with non-Christian theists and deists. The AUC has four congregations in the United States.
UCMI / UCEC.
Unitarian Christian Ministries International was a Unitarian ministry incorporated in South Carolina, USA until its dissolution in 2013 when it merged with the Unitarian Christian Emerging Church.
UCA.
The Unitarian Christian Association (UCA, UK) was founded 1991 by Rev. Lancelot Garrard (1904–93) and others to promote specifically Christian ideas within the General Assembly of Unitarian and Free Christian Churches (GAUFCC). Just as the UUCF and ICUU maintain formal links with UUA in America, so the UCA does with the GAUFCC in the UK.
The majority of Unitarian Christian publications are sponsored by an organization and published specifically for their membership. They generally do not serve as a tool for missionary work or encouraging conversions.
Australia.
The Sydney Unitarian Church was founded 1850 under a Reverend Stanley and was a vigorous denomination during the 19th century. The modern church has properties in Adelaide, Sydney and Melbourne, and smaller congregations elsewhere in Australia and New Zealand.
South Africa.
The Unitarian movement in South Africa was founded in 1867 by the Reverend Dawid Faure, member of a well-known Cape family. He encountered advanced liberal religious thought while completing his studies at the University of Leiden in Holland for the ministry of the Dutch Reformed Church in Cape Town. On his return to South Africa he preached a probationary sermon in the Groote Kerk, Cape Town. This led to a public appeal to him to found a community based upon what was called the 'new theology'. The 'new theology' as preached by Dawid Faure was grounded in what he described as "the very essence of religion" - love of God and love of neighbor. 
Biblical Unitarian Movement.
In the mainstream of the Protestant Reformation there is the Biblical Unitarian Movement. Today, biblical Unitarianism (or "Biblical Unitarianism" or "biblical unitarianism") identifies the Christian belief that the Bible teaches God is a singular person—the Father—and that Jesus is a distinct being, his son. A few denominations use this term to describe themselves, clarifying the distinction between them and those churches which, from the late 19th century, evolved into modern British Unitarianism and, primarily in the United States, Unitarian Universalism.
In Italy the Biblical Unitarian Movement powered by the ideas of Sozzini and others is represented today by the churches associated with the Christian Church in Italy. This Movement in Italy claims a strong Christian and biblical soul. From the analysis of documents that you can find on the official site of the CCI, it is clear that the doctrinal position of this Christian confession of faith is therefore akin to the so-called Biblical Unitarian movement and on the other hand, far from that of Unitarian Universalist Association who, although sharing a 16th-century origin, have been influenced by many non-biblical ideas (e.g., Universalism).
The Christian Church in Italy has significant similarities with the Biblical Unitarian movement, although it maintains a cautious position on some doctrinal points. Wilbur wrote about the Unitarian Movement: 
The Christian Church in Italy believes that God is only One Person in direct contrast with the doctrine of the Trinity which defines God as Three coexisting Persons in one Substance (Essence), merged into one being. So CCI adheres to strict monotheism by believing that Jesus was a perfect and holy man, virginally begotten in Mary, the promised Christ (i.e., Messiah), the Son of God, and is now at the right hand of God praying for the whole Church.
The Christian Church in Italy rejects certain traditional Christian doctrines including the soteriological doctrines of original sin and predestination.
The CCI is distinct from other religious movements which exalt Jesus as the only true God, as for example the Oneness Pentecostalism, the United Pentecostal Church International, and the True Jesus Church.
Ecclesiology.
When Unitarianism developed in the 17th century during the Protestant era of the evolution of Christianity, the strongholds in Transylvania, Poland, and eventually Britain and the northeastern parts of the United States were firmly in the congregational tradition. In the Hungarian-speaking territories it adopted a governance system that combined the Synodal and Episcopal models.
For those churches under the congregational model, each church governed itself independently of a hierarchical authority. These small congregations belonged, however, to more formal associations of churches. The American Unitarian Association, formed in 1825, was one of these. Later, in 1961, the American Unitarian Association and the Universalist Church of America merged to form the Unitarian Universalist Association (UUA), which is the largest organization of Unitarians in the US. The UUA is no longer an explicitly Christian organization and does not focus exclusively on the core teachings of Jesus Christ or Christianity.
Several Unitarian organizations still promote Christianity as their central theme. Among them, Unitarian Ministries International, the Unitarian Universalist Christian Fellowship (UUCF, an affiliate of the UUA), the General Assembly of Unitarian and Free Christian Churches (GAUFCC) of the United Kingdom, and the Unitarian Christian Association (UCA, an affiliate of the GAUFCC).
In the US, the newest organization promoting a return to the theistic roots of Unitarianism is the American Unitarian Conference (AUC), formed in 2000. The AUC's stated goal is to formulate and promote classical Unitarian-based, unifying religious convictions, which balance the needs of members with a practical approach to inclusion and progressive free thought.
Interfaith dialogue and relations.
Catholic, Orthodox and Protestant creeds generally insist on Trinitarian belief as an essential aspect of Christianity and basic to a group's continuity of identity with the historical Christian faith. As a result, Unitarians have often been excluded from fellowship with churches that accept the creeds of the Nicene and pre-Chalcedonian churches.
However, occasionally, especially in Protestant history, traditionally Trinitarian groups have accepted Unitarians. Friendliness toward Unitarianism has sometimes gone hand-in-hand with anti-Catholicism. In some cases non-Trinitarian belief has been adopted by some, and tolerated in Christian churches as a "non-essential." This was the case in the English Presbyterian Church, and in the Congregational Church in New England late in the 18th century. The Restoration Movement also attempted to forge a compatible relation between Trinitarians and nontrinitarians, as did the Seventh Day Baptists and various Adventists. The nontrinitarian tendency in this latter group emerged from their original theology and their rejection of Catholic traditions regarding the Trinity.
In some cases, this openness to Unitarianism within traditionally Trinitarian churches has been inspired by a very broad ecumenical motive. Modern liberal Protestant denominations are often accused by Trinitarians within their ranks, and critics outside, of being indifferent to the doctrine, and therefore self-isolated from their respective Trinitarian pasts and heritage. In some cases, it is charged that these Trinitarian denominations are no longer Christian, because of their toleration of unitarian belief among their teachers and in their seminaries.
At a local level, many Unitarian Christian groups (or members) have links with congregations affiliated with the United Church of Christ, Disciples of Christ, and Unity Church; some argue they feel more at home within these denominations than Unitarian Universalism. A small proportion of Unitarian Christians also have links with Progressive Christianity.
Despite the close friendship and shared heritage that exist between adherents of Unitarian Universalism and those of Unitarian Christianity, there is an element within Unitarian Universalism that specifically opposes Unitarian Christian groups, believing them to be exclusive and intolerant of non-Christian thought. Likewise, some Unitarian Christians also believe that Unitarian Universalists are intolerant of Christian thought and tend to marginalize Christians.
Notable Unitarians.
Notable Unitarians include Béla Bartók, the 20th-century composer, Ralph Waldo Emerson and Theodore Parker in theology and ministry, Charles Darwin, Joseph Priestley, John Archibald Wheeler, and Linus Pauling in science, George Boole in mathematics, Susan B. Anthony in civil government, Florence Nightingale in humanitarianism and social justice, John Bowring, and Samuel Taylor Coleridge in literature, Frank Lloyd Wright in the arts, Josiah Wedgwood in industry, Thomas Starr King in ministry and politics, and Charles William Eliot in education. Although raised a Quaker, Ezra Cornell, founder of Cornell University in Ithaca, New York, attended the Unitarian church and was one of the founders of Ithaca's First Unitarian Church. Eramus Darwin Shattuck, a signatory to the Oregon State Constitution, founded the first Unitarian Church in Oregon in 1865.
Eleven Nobel prizes have been awarded to Unitarians: Robert Millikan and John Bardeen (twice) in Physics; Emily Green Balch, Albert Schweitzer, Linus Pauling, and Geoff Levermore for Peace; George Wald and David H. Hubel in Medicine; Linus Pauling in Chemistry; and Herbert A. Simon in Economics.
Four presidents of the United States were Unitarians: John Adams, John Quincy Adams, Millard Fillmore, and William Howard Taft. Adlai Stevenson II, the Democratic presidential nominee in 1952 and 1956, was a Unitarian, and he was the last Unitarian (so far) to be nominated by a major party for president.
British Prime Minister, Neville Chamberlain was raised by his Unitarian statesman father, Joseph Chamberlain. Certainly, in the United Kingdom, Unitarianism – the religion of only a small minority of the country's population – had an enormous impact on Victorian politics, not only in the larger cities – Birmingham, Leeds, Manchester, and Liverpool – but in smaller communities like Leicester where there were so many Unitarian mayors that the Unitarian Chapel was known as the "Mayors' Nest".
In Birmingham, a most impressive Unitarian Church was opened in 1862. The Church of the Messiah, as it was called, was more than the centre of a small sect: it was a cultural and intellectual centre of a whole society, a place where ideas about society were openly and critically discussed. Henry W. Crosskey’s Birmingham Unitarian congregation included: Joseph Chamberlain, as well as Arthur, his younger brother, who was married to Louisa Kenrick; William Kenrick, his brother-in-law, who was married to Mary Chamberlain; and Sir Thomas Martineau, who was the nephew of Harriet Martineau, another outspoken public figure and author of the time. Sir Thomas Martineau (died 1893), was related to the Chamberlain family by marriage; Sir Thomas had married Emily Kenrick, the sister of Florence Chamberlain, née Kenrick. 
These elite British Unitarian families: the Nettlefolds, the Martineaus, the Luptons, the Kitsons and the Kenricks, found a most significant place in the social and political history of Victorian through to mid-20th-century Britain.
Other Unitarians include Sir Tim Berners-Lee, Lancelot Ware, founder of Mensa, Sir Adrian Boult, the conductor, Ray Kurzweil, notable inventor and futurist, and C. Killick Millard, founder of the Dignity in Dying society to support voluntary euthanasia. Ram Mohan Roy an Indian reformer of the 18th century, was a Unitarian who published a book called "Precepts of Jesus".

</doc>
<doc id="32167" url="http://en.wikipedia.org/wiki?curid=32167" title="Ubiquitin">
Ubiquitin

Ubiquitin is a small (8.5 kDa) regulatory protein that has been found in almost all tissues ("ubiquitously") of eukaryotic organisms. It was discovered in 1975 by Goldstein and further characterized throughout the 1970s and 1980s. There are four genes in the human genome that produce ubiquitin: UBB, UBC, UBA52 and RPS27A.
Ubiquitination is a post-translational modification (an addition to a protein after it has been made) where ubiquitin is attached to a substrate protein. The addition of ubiquitin can affect proteins in many ways: It can signal for their degradation via the proteasome, alter their cellular location, affect their activity, and promote or prevent protein interactions. Ubiquitination is carried out in three main steps: activation, conjugation, and ligation, performed by ubiquitin-activating enzymes (E1s), ubiquitin-conjugating enzymes (E2s), and ubiquitin ligases (E3s), respectively. The result of this sequential cascade binds ubiquitin to lysine residues on the protein substrate via an isopeptide bond or to the amino group of the protein's N-terminus via a peptide bond.
The protein modifications can be either a single ubiquitin protein (monoubiquitination) or a chain of ubiquitin (polyubiquitination). The ubiquitination bonds are always formed with one of the seven lysine residues from the ubiquitin molecule. These 'linking' lysines are represented by a "K" (which is the one-letter amino acid notation of lysine) and a number, referring to its position in the ubiquitin molecule. First, a ubiquitin molecule is bonded by its C-terminus to a specific lysine residue (e.g. K48, K29, K63...) on the target protein. Poly-ubiquitination occurs when the C-terminus of another ubiquitin, will be linked again to a lysine residue (for example again K48 or K29) on the previously added ubiquitin molecule, forming a chain. This process repeats several times, leading to the addition of several ubiquitins. Only poly-ubiquitination on defined lysines, mostly on K48 and K29, is related to degradation with the proteasome (referred to as the "molecular kiss of death"), while other polyubiquitinations (e.g. on K63, K11, K6) and monoubiquitinations may regulate processes such as endocytic trafficking, inflammation, translation and DNA repair.
Lysine 48-linked chains have been much-studied. They are the forms of chains that signal proteins to the proteasome, which destroys and recycles proteins. This discovery won the Nobel Prize for chemistry in 2004.
Identification.
Ubiquitin (originally, ubiquitous immunopoietic polypeptide) was first identified in 1975 as an 8.5 kDa protein of unknown function expressed in all eukaryotic cells. The basic functions of ubiquitin and the components of the ubiquitination pathway were elucidated in the early 1980s at the Technion by Aaron Ciechanover, Avram Hershko, and Irwin Rose for which the Nobel Prize in Chemistry was awarded in 2004.
The ubiquitination system was initially characterised as an ATP-dependent proteolytic system present in cellular extracts. A heat-stable polypeptide present in these extracts, ATP-dependent proteolysis factor 1 (APF-1), was found to become covalently attached to the model protein substrate lysozyme in an ATP- and Mg2+-dependent process. Multiple APF-1 molecules were linked to a single substrate molecule by an isopeptide linkage, and conjugates were found to be rapidly degraded with the release of free APF-1. Soon after APF-1-protein conjugation was characterised, APF-1 was identified as ubiquitin. The carboxyl group of the C-terminal glycine residue of ubiquitin (Gly76) was identified as the moiety conjugated to substrate lysine residues.
The protein.
Ubiquitin is a small protein that exists in all eukaryotic cells. It performs its myriad functions through conjugation to a large range of target proteins. A variety of different modifications can occur. The ubiquitin protein itself consists of 76 amino acids and has a molecular mass of about 8.5 kDa. Key features include its C-terminal tail and the 7 lysine residues. It is highly conserved among eukaryotic species: Human and yeast ubiquitin share 96% sequence identity.
Genes.
Ubiquitin is encoded in mammals by 4 different genes. UBA52 and RPS27A genes code for a single copy of ubiquitin fused to the ribosomal proteins L40 and S27a, respectively. The UBB and UBC genes code for polyubiquitin precursor proteins.
Origins.
No ubiquitin and ubiquitination machinery are known to exist in prokaryotes. However, ubiquitin is believed to have descended from prokaryotic proteins similar to ThiS or MoaD. These prokaryotic proteins, despite having little sequence identity (ThiS has 14% identity to ubiquitin), share the same protein fold. These proteins also share sulfur chemistry with ubiquitin. MoaD, which is involved in molybdenum cofactor biosynthesis, interacts with MoeB, which acts like an E1 ubiquitin-activating enzyme for MoaD, strengthening the link between these prokaryotic proteins and the ubiquitin system. A similar system exists for ThiS, with its E1-like enzyme ThiF. It is also believed that the "Saccharomyces cerevisiae" protein Urm-1, a ubiquitin-related modifier, is a "molecular fossil" that connects the evolutionary relation with the prokaryotic ubiquitin-like molecules and ubiquitin.
Ubiquitination.
Ubiquitination (also known as ubiquitylation) is an enzymatic, post-translational modification (PTM) process in which a ubiquitin protein is attached to a substrate protein. This process most commonly binds the last amino acid of ubiquitin (glycine 76) to a lysine residue on the substrate. An isopeptide bond is formed between the carboxylic acid group of the ubiquitin's glycine and the epsilon amino group of the substrate's lysine. Trypsin cleavage of a ubiquitin-conjugated substrate leaves a di-glycine "remnant" that is used to identify the site of ubiquitination. Cases are known in which the amine group of a protein's N-terminus is used for ubiquitination, rather than a lysine residue. In a few rare cases nonlysine residues have been identified as ubiquitination targets, such as cysteine, threonine and serine. The end result of this process is the addition of one ubiquitin molecule (monoubiquitination) or a chain of ubiquitin molecules (polyubiquitination) to the substrate protein.
Ubiquitination requires three types of enzyme: ubiquitin-activating enzymes, ubiquitin-conjugating enzymes, and ubiquitin ligases, known as E1s, E2s, and E3s, respectively. The process consists of three main steps:
In the ubiquitination cascade, E1 can bind with many E2s, which can bind with hundreds of E3s in a hierarchical way. Having levels within the cascade allows tight regulation of the ubiquitination machinery. Other ubiquitin-like proteins (UBLs) are also modified via the E1–E2–E3 cascade, although variations in these systems do exist.
Variety of ubiquitin modifications.
Ubiquitination affects cellular process by regulating the degradation of proteins (via the proteasome and lysosome), coordinating the cellular localisation of proteins, activating and inactivating proteins, and modulating protein-protein interactions. These effects are mediated by different types of substrate ubiquitination, for example the addition of a single ubiquitin molecule (monoubiquitination) or different types of ubiqutin chains (polyubiquitination).
Monoubiquitination.
Monoubiquitination is the addition of one ubiquitin molecule to one substrate protein residue. Multi-monoubiquitination is the addition of one ubiquitin molecule to multiple substrate residues. The monoubiquitination of a protein can have different effects to the polyubiquitination of the same protein. The addition of a single ubiquitin molecule is thought to be required prior to the formation of polyubiquitin chains. Monoubiquitination affects cellular processes such as membrane trafficking, endocytosis and viral budding.
Polyubiquitin chains.
Polyubiquitination is the formation of a ubiquitin chain on a single lysine residue on the substrate protein. Following addition of a single ubiquitin moiety to a protein substrate, further ubiquitin molecules can be added to the first, yielding a polyubiquitin chain. These chains are made by linking the glycine residue of a ubiquitin molecule to a lysine of ubiquitin bound to a substrate. Ubiquitin has seven lysine residues and an N-terminus that may serve as points of ubiquitination; they are K6, K11, K27, K29, K33, K48, and K63. Lysine 48-linked chains were the first identified and are the best-characterised type of ubiquitin chain. K63 chains have also been well-characterised, whereas the function of other lysine chains, mixed chains, branched chains, N-terminal linear chains, and heterologous chains (mixtures of ubiquitin and other ubiquitin-like proteins) remains more unclear.
Lysine 48-linked polyubiquitin chains target proteins for destruction, by a process known as proteolysis. At least four ubiquitin molecules must be attached to a lysine residue on the condemned protein in order for it to be recognised by the 26S proteasome. This is a barrel-shape structure comprising a central proteolytic core made of four ring structures, flanked by two cylinders that selectively allow entry of ubiquitinated proteins. Once inside, the proteins are rapidly degraded into small peptides (usually 3–25 amino acid residues in length). Ubiquitin molecules are cleaved off the protein immediately prior to destruction and are recycled for further use. Although the majority of protein substrates are ubiquitinated, there are examples of non-ubiquitinated proteins targeted to the proteasome. The polyubiquitin chains are recognised by a subunit of the proteasome: S5a/Rpn10. This is achieved by a ubiquitin interacting motif (UIM) found in a hydrophobic patch in the C-terminal region of the S5a/Rpn10 unit.
Lysine 63-linked chains are not associated with proteasomal degradation of the substrate protein. Instead, they allow the coordination of other processes such as endocytic trafficking, inflammation, translation, and DNA repair. In cells, lysine 63-linked chains are bound by the ESCRT-0 complex, which prevents their binding to the proteasome. This complex contains two proteins, Hrs and STAM1, that contain a UIM, which allows it to bind to lysine 63-linked chains.
Less is understood about atypical (non-lysine 48-linked) ubiquitin chains but research is starting to suggest roles for these chains. There is evidence to suggest that atypical chains linked by lysine 6, 11, 27, 29 and N-terminal chains can induce proteasomal degradation.
Branched ubiquitin chains containing multiple linkage types can be formed. The function of these chains is unknown.
Structure of chains.
Differently linked chains have specific effects on the protein to which they are attached, caused by differences in the conformations of the protein chains. Lysine 29-, 33-, 63-linked and N-terminal chains produce fairly linear chains known as open-conformation chains. Lysine 6-, 11-, and 48-linked chains form closed conformations. The ubiquitin molecules in linear chains do not interact with each other, except for the covalent isopeptide bonds linking them together. In contrast, the closed conformation chains have interfaces with interacting residues. Altering the chain conformations exposes and conceals different parts of the ubiquitin protein, and the different linkages are recognized by proteins that are specific for the unique topologies that are intrinsic to the linkage. The proteins that bind ubiquitin have ubiquitin-binding domains (UBDs). The distances between individual ubiquitin units in chains differ between lysine 63- and 48-linked chains. The UBDs exploit this by having small spacers between ubiquitin-interacting motifs that bind lysine 48-linked chains (compact ubiquitin chains) and larger spacers for lysine 63-linked chains. The machinery involved in recognising polyubiquitin chains can also differentiate between the linear lysine 63-linked chains and linear N-terminal chains, demonstrated by the fact that the latter can induce proteasomal degradation of the substrate.
Functions of ubiquitin modification.
The ubiquitination system functions in a wide variety of cellular processes, including:
Membrane proteins.
Multi-monoubiquitination can mark transmembrane proteins (for example, receptors) for removal from membranes (internalisation) and fulfil several signalling roles within the cell. When cell-surface transmembrane molecules are tagged with ubiquitin, the subcellular localization of the protein is altered, often targeting the protein for destruction in lysosomes. This serves as a negative feedback mechanism because often the stimulation of receptors by ligands increases their rate of ubiquitination and internalisation. Like monoubiquitination, lysine 63-linked polyubiquitin chains also has a role in the trafficking some membrane proteins.
Genomic maintenance.
Proliferating cell nuclear antigen (PCNA) is a protein involved in DNA synthesis. Under normal physiological conditions PCNA is sumoylated (a similar post-translational modification to ubiquitination). When DNA is damaged by ultra-violet radiation or chemicals, the SUMO molecule that is attached to a lysine residue is replaced by ubiquitin. Monoubiquitinated PCNA recruits polymerases that can carry out DNA synthesis with damaged DNA; but this is very error-prone, possibly resulting in the synthesis of mutated DNA. Lysine 63-linked polyubiquitination of PCNA allows it to perform a less error-prone mutation bypass known by the template switching pathway.
Ubiquitination of histone H2AX is involved in DNA damage recognition of DNA double-strand breaks. Lysine 63-linked polyubiquitin chains are formed on H2AX histone by the E2/E3 ligase pair, Ubc13-Mms2/RNF168. This K63 chain appears to recruit RAP80, which contains a UIM, and RAP80 then helps localize BRCA1. This pathway will eventually recruit the necessary proteins for homologous recombination repair.
Transcriptional regulation.
Histones can be ubiquitinated and this is usually in the form of monoubiquitination (although polyubiquitinated forms do occur). Histone ubiquitination alters chromatin structure and allows the access of enzymes involved in transcription. Ubiquitin on histones also acts a binding site for proteins that either activate or inhibit transcription and also can induce further post-translational modifications of the protein. These effects can all modulate the transcription of genes.
Deubiquitination.
Deubiquitinating enzymes (DUBs) oppose the role of ubiquination by removing ubiquitin from substrate proteins. They are cysteine proteases that cleave the amide bond between the two proteins. They are highly specific, as are the E3 ligases that attach the ubiquitin, with only a few substrates per enzyme. They can cleave both isopeptide (between ubiquitin and lysine) and peptide bonds (between ubiquitin and the N-terminus). In addition to removing ubiquitin from substrate proteins, DUBs have many other roles within the cell. Ubiquitin is either expressed as multiple copies joined in a chain (polyubiquitin) or attached to ribosomal subunits. DUBs cleave these proteins to produce active ubiquitin. They also recycle ubiquitin that has been bound to small nucleophilic molecules during the ubiquitination process. Monoubiquitin is formed by DUBs that cleave ubiquitin from free polyubiquitin chains that have been previously removed from proteins.
Ubiquitin-binding domains.
Ubiquitin-binding domains (UBDs) are modular protein domains that non-covalently bind to ubiquitin, these motifs control various cellular events. Detailed molecular structures are known for a number of UBDs, binding specificity determines their mechanism of action and regulation, and how it regulates cellular proteins and processes.
Disease associations.
Pathogenesis.
The ubiquitin pathway has been implicated in the pathogenesis of several diseases and genetic disorders:
Diagnostic use.
Immunohistochemistry using antibodies to ubiquitin can identify abnormal accumulations of this protein inside cells, indicating a disease process. These protein accumulations are referred to as inclusion bodies (which is a general term for any microscopically visible collection of abnormal material in a cell). Examples include:
Ubiquitin-like modifiers.
Although ubiquitin is the most-understood post-translation modifier, there is a growing family of ubiquitin-like proteins (UBLs) that modify cellular targets in a pathway that is parallel to, but distinct from, that of ubiquitin. Known UBLs include: small ubiquitin-like modifier (SUMO), ubiquitin cross-reactive protein (UCRP, also known as interferon-stimulated gene-15 ISG15), ubiquitin-related modifier-1 (URM1), neuronal-precursor-cell-expressed developmentally downregulated protein-8 (NEDD8, also called Rub1 in "S. cerevisiae"), human leukocyte antigen F-associated (FAT10), autophagy-8 (ATG8) and -12 (ATG12), Fau ubiquitin-like protein (FUB1), MUB (membrane-anchored UBL), ubiquitin fold-modifier-1 (UFM1) and ubiquitin-like protein-5 (UBL5, which is but known as homologous to ubiquitin-1 [Hub1] in "S. pombe"). Whilst these proteins share only modest primary sequence identity with ubiquitin, they are closely related three-dimensionally. For example, SUMO shares only 18% sequence identity, but they contain the same structural fold. This fold is called "ubiquitin fold" or sometimes called ubiquiton fold. FAT10 and UCRP contain two. This compact globular beta-grasp fold is found in ubiquitin, UBLs, and proteins that comprise a ubiquitin-like domain, e.g. the "S. cerevisiae" spindle pole body duplication protein, Dsk2, and NER protein, Rad23, both contain N-terminal ubiquitin domains.
These related molecules have novel functions and influence diverse biological processes. There is also cross-regulation between the various conjugation pathways, since some proteins can become modified by more than one UBL, and sometimes even at the same lysine residue. For instance, SUMO modification often acts antagonistically to that of ubiquitination and serves to stabilize protein substrates. Proteins conjugated to UBLs are typically not targeted for degradation by the proteasome but rather function in diverse regulatory activities. Attachment of UBLs might, alter substrate conformation, affect the affinity for ligands or other interacting molecules, alter substrate localization, and influence protein stability.
UBLs are structurally similar to ubiquitin and are processed, activated, conjugated, and released from conjugates by enzymatic steps that are similar to the corresponding mechanisms for ubiquitin. UBLs are also translated with C-terminal extensions that are processed to expose the invariant C-terminal LRGG. These modifiers have their own specific E1 (activating), E2 (conjugating) and E3 (ligating) enzymes that conjugate the UBLs to intracellular targets. These conjugates can be reversed by UBL-specific isopeptidases that have similar mechanisms to that of the deubiquitinating enzymes.
Within some species, the recognition and destruction of sperm mitochondria through a mechanism involving ubiquitin is responsible for sperm mitochondria's disposal after fertilization occurs.
Prokaryotic ubiquitin-like protein (Pup).
Recently, a functional analog of ubiquitin has been found in prokaryotes. Prokaryotic ubiquitin-like protein (Pup) serves the same function (targeting proteins for degradations), although the enzymology of ubiquitination and pupylation is different. In contrast to the three-step reaction of ubiquitination, pupylation requires two steps, therefore only two enzymes are involved in pupylation.
Human proteins containing ubiquitin domain.
ANUBL1; BAG1; BAT3/BAG6; C1orf131; DDI1; DDI2; FAU; HERPUD1; HERPUD2;
HOPS; IKBKB; ISG15; LOC391257; MIDN; NEDD8; OASL; PARK2;
RAD23A; RAD23B; RPS27A; SACS; 8U SF3A1; SUMO1; SUMO2; SUMO3;
SUMO4; TMUB1; TMUB2; UBA52; UBB; UBC; UBD; UBFD1;
UBL4; UBL4A; UBL4B; UBL7; UBLCP1; UBQLN1; UBQLN2; UBQLN3;
UBQLN4; UBQLNL; UBTD1; UBTD2; UHRF1; UHRF2;
Prediction of ubiquitination.
Currently available prediction programs are:

</doc>
<doc id="32168" url="http://en.wikipedia.org/wiki?curid=32168" title="Ulfilas">
Ulfilas

Ulfilas[] (Gothic: 𐍅𐌿𐌻𐍆𐌹𐌻𐌰; Wulfila; "Little Wolf"), also "Ulphilas", "Orphila" (ca. 311 – 383), bishop, missionary, and Bible translator, was a Goth of Greek descent from Cappadocia who had spent time inside the Roman Empire at the peak of the Arian controversy.
Biography.
Ulfilas' parents were of non-Gothic Cappadocian Greek origin, but had been enslaved by Goths and Ulfilas may have been born into captivity or made captive when young. Raised as a Goth, he later became proficient in the Greek and Latin languages. Ulfilas converted many among the Goths, preaching an Arian Christianity, which, when they reached the western Mediterranean, set them apart from their Orthodox neighbors and subjects.
Ulfilas was ordained a bishop by Eusebius of Nicomedia and returned to his people to work as a missionary. In 348, to escape religious persecution by a Gothic chief, probably Athanaric he obtained permission from Constantius II to migrate with his flock of converts to Moesia and settle near Nicopolis ad Istrum in modern northern Bulgaria. There, Ulfilas translated the Bible from Greek into the Gothic language. For this he devised the Gothic alphabet. Fragments of his translation have survived, notably the "Codex Argenteus" held since 1648 in the University Library of Uppsala in Sweden. A parchment page of this Bible was found in 1971 in the Speyer Cathedral.
According to Carolus Lundius, Ulfilas created the Gothic alphabet based on the Getae's alphabet, with minor alterations. Carolus is quoting Bonaventura Vulcanius' book, "De literis et lingua Getarum sive Gothorum", (Lyon, 1597) and Johannes Magnus, Gothus, "Historia de omnibus Gothorum Sueonumque regibus", Roma, 1554, a book in which it has been published, for the first time, both the Getic alphabet, and the laws of the Getae legislator Zamolxis.
Historical sources.
There are five primary sources for the study of Ulfilas's life. Two are by Arian authors, three by Catholics.
There are significant differences between the stories presented by the two camps. The Arian sources depict Ulfilas as an Arian from childhood. He was then consecrated as a bishop around 340 and evangelized among the Goths for 7 years during the 340s. He then moved to Moesia (within the Roman Empire) under the protection of the Arian Emperor Constantius II. He later attended several councils and engaged in continuing religious debate. They date his death in 383.
The accounts by the Catholic historians differ in several details, but the general picture is similar. According to them, Ulfilas was an orthodox Christian for most of his early life. He was only converted to Arianism somewhere around 360, and then only because of political pressure from the pro-Arian ecclesiastical and governmental powers. The sources differ in how much they credit Ulfilas with the conversion of the Goths. Socrates Scholasticus gives Ulfilas a minor role, and instead attributes the mass conversion to the Gothic chieftain Fritigern, who adopted Arianism out of gratitude for the military support of the Arian emperor. Sozomen attributes the mass conversion primarily to Ulfilas, though he also acknowledges the role of Fritigern.
For several reasons, modern scholars depend more heavily on the Arian accounts than the Catholic accounts. Auxentius was clearly the closest to Ulfilas, and so presumably had access to more reliable information. The Catholic accounts differ too widely among themselves to present a unified case. Debate continues as to the best reconstruction of Ulfilas's life.
The Creed of Ulfilas.
The creed of Ulfilas, which concludes a letter praising him written by his foster-son and pupil Auxentius of Durostorum (modern Silistra) on the Danube, who became bishop of Milan, distinguishes God the Father ("unbegotten") from God the Son ("only-begotten"), who was begotten before time and who created the world, and the Holy Spirit, proceeding from the Father and the Son:
I, Ulfila, bishop and confessor, have always so believed, and in this, the one true faith, I make the journey to my Lord; I believe in one God the Father, the only unbegotten and invisible, and in his only-begotten son, our Lord and God, the designer and maker of all creation, having none other like him (so that one alone among all beings is God the Father, who is also the God of our God); and in one Holy Spirit, the illuminating and sanctifying power, as Christ said after his resurrection to his apostles: "And behold, I send the promise of my Father upon you; but tarry ye in the city of Jerusalem, until ye be clothed with power from on high" (Luke 24:49) and again "But ye shall receive power, when the Holy Ghost is come upon you" (Acts 1:8); being neither God (the Father) nor our God (Christ), but the minister of Christ ... subject and obedient in all things to the Son; and the Son, subject and obedient in all things to God who is his Father ... (whom) he ordained in the Holy Spirit through his Christ.
Maximinus, a 5th-century Arian theologian, copied Auxentius' letter, among other works, into the margins of one copy of Ambrose's "De Fide"; there are some gaps in the surviving text.
Honours.
Wulfila Glacier on Greenwich Island in the South Shetland Islands, Antarctica is named after Bishop Ulfilas.

</doc>
<doc id="32169" url="http://en.wikipedia.org/wiki?curid=32169" title="Unified Modeling Language">
Unified Modeling Language

The Unified Modeling Language (UML) is a general-purpose modeling language in the field of software engineering, which is designed to provide a standard way to visualize the design of a system.
It was created and developed by Grady Booch, Ivar Jacobson and James Rumbaugh at Rational Software during 1994–95, with further development led by them through 1996.
In 1997 it was adopted as a standard by the Object Management Group (OMG), and has been managed by this organization ever since. In 2005 the Unified Modeling Language was also published by the International Organization for Standardization (ISO) as an approved ISO standard. Since then it has been periodically revised to cover the latest revision of UML.
Overview.
The Unified Modeling Language (UML) offers a way to visualize a system's architectural blueprints in a diagram (see image), including elements such as:
Although originally intended solely for object-oriented design documentation, the Unified Modeling Language (UML) has been extended to cover a larger set of design documentation (as listed above), and been found useful in many contexts.
History.
UML has been evolving since the second half of the 1990s and has its roots in the object-oriented methods developed in the late 1980s and early 1990s. The timeline (see image) shows the highlights of the history of object-oriented modeling methods and notation.
It is originally based on the notations of the Booch method, the Object-modeling technique (OMT) and Object-oriented software engineering (OOSE), which it has integrated into a single language.
Before UML 1.x.
Rational Software Corporation hired James Rumbaugh from General Electric in 1994 and after that the company became the source for two of the most popular object-oriented modeling approaches of the day: Rumbaugh's Object-modeling technique (OMT) and Grady Booch's method. They were soon assisted in their efforts by Ivar Jacobson, the creator of the object-oriented software engineering (OOSE) method, who joined them at Rational in 1995.
Under the technical leadership of those three (Rumbaugh, Jacobson and Booch), a consortium called the UML Partners was organized in 1996 to complete the "Unified Modeling Language (UML)" specification, and propose it to the Object Management Group (OMG) for standardisation. The partnership also contained additional interested parties (for example HP, DEC, IBM and Microsoft). The UML Partners' UML 1.0 draft was proposed to the OMG in January 1997 by the consortium. During the same month the UML Partners formed a group, designed to define the exact meaning of language constructs, chaired by Cris Kobryn and administered by Ed Eykholt, to finalize the specification and integrate it with other standardization efforts. The result of this work, UML 1.1, was submitted to the OMG in August 1997 and adopted by the OMG in November 1997.
UML 1.x.
After the first release a task force was formed to improve the language, which released several minor revisions, 1.3, 1.4, and 1.5.
The standards it produced (as well as the original standard) have been noted as being ambiguous and inconsistent.
UML 2.x.
The UML 2.0 major revision replaced version 1.5 in 2005, which was developed with an enlarged consortium to improve the language further to reflect new experience on usage of its features.
Although UML 2.1 was never released as a formal specification, versions 2.1.1 and 2.1.2 appeared in 2007, followed by UML 2.2 in February 2009. UML 2.3 was formally released in May 2010. UML 2.4.1 was formally released in August 2011. UML 2.5 was released in October 2012 as an "In process" version and has yet to become formally released.
There are four parts to the UML 2.x specification:
The current versions of these standards follow: UML Superstructure version 2.4.1, UML Infrastructure version 2.4.1, OCL version 2.3.1, and UML Diagram Interchange version 1.0. It continues to be updated and improved by the revision task force, who resolve any issues with the language.
Design.
Software development methods.
UML is not a development method by itself; however, it was designed to be compatible with the leading object-oriented software development methods of its time (for example OMT, Booch method, Objectory).
Modeling.
It is important to distinguish between the UML model and the set of diagrams of a system. A diagram is a partial graphic representation of a system's model. The set of diagrams need not completely cover the model and deleting a diagram does not change the model. The model may also contain documentation that drives the model elements and diagrams (such as written use cases).
UML diagrams represent two different views of a system model:
UML models can be exchanged among UML tools by using the XML Metadata Interchange (XMI) interchange format.
Diagrams.
UML 2 has many types of diagrams which are divided into two categories. Some types represent "structural" information, and the rest represent general types of "behavior", including a few that represent different aspects of "interactions". These diagrams can be categorized hierarchically as shown in the following class diagram:
These diagrams may all contain comments or notes explaining usage, constraint, or intent.
Structure diagrams.
Structure diagrams emphasize the things that must be present in the system being modeled. Since structure diagrams represent the structure, they are used extensively in documenting the software architecture of software systems. For example, the component diagram which describes how a software system is split up into components and shows the dependencies among these components.
Behavior diagrams.
Behavior diagrams emphasize what must happen in the system being modeled. Since behavior diagrams illustrate the behavior of a system, they are used extensively to describe the functionality of software systems. As an example, the activity diagram describes the business and operational step-by-step activities of the components in a system.
Interaction diagrams.
Interaction diagrams, a subset of behavior diagrams, emphasize the flow of control and data among the things in the system being modeled. For example, the sequence diagram which shows how objects communicate with each other in terms of a sequence of messages.
Meta modeling.
The Object Management Group (OMG) has developed a metamodeling architecture to define the Unified Modeling Language (UML), called the Meta-Object Facility (MOF). The Meta-Object Facility is designed as a four-layered architecture, as shown in the image at right. It provides a meta-meta model at the top layer, called the M3 layer. This M3-model is the language used by Meta-Object Facility to build metamodels, called M2-models.
The most prominent example of a Layer 2 Meta-Object Facility model is the UML metamodel, the model that describes the UML itself. These M2-models describe elements of the M1-layer, and thus M1-models. These would be, for example, models written in UML. The last layer is the M0-layer or data layer. It is used to describe runtime instances of the system.
The meta-model can be extended using a mechanism which is called stereotyping. This has been criticised as being insufficient/untenable by Brian Henderson-Sellers and Cesar Gonzalez-Perez in "Uses and Abuses of the Stereotype Mechanism in UML 1.x and 2.0".
Adoption.
UML has been found useful in many design contexts, so much so that is has become ubiquitous in its field.
It has been treated, at times, as a design silver bullet, which has led to problems in its usage. Misuse of it includes excessive usage of it (design every little part of the system's code with it, which is unnecessary) and assuming that anyone can design anything with it (even those who haven't programmed).
It is seen to be a large language, with many constructs in it. Some (including Jacobson) feel that there are too many and that this hinders the learning (and therefore usage) of it.
References.
This article is based on material taken from the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the "relicensing" terms of the GFDL, version 1.3 or later.

</doc>
<doc id="32170" url="http://en.wikipedia.org/wiki?curid=32170" title="UML">
UML

UML may stand for:

</doc>
<doc id="32173" url="http://en.wikipedia.org/wiki?curid=32173" title="United States Military Academy">
United States Military Academy

The United States Military Academy at West Point (USMA), also known as West Point, Army, The Academy or simply, The Point, is a four-year coeducational federal service academy located in West Point, New York. The academy, located in Orange County, sits on scenic high ground overlooking the Hudson River, 50 mi north of New York City. The entire central campus is a national landmark and home to scores of historic sites, buildings, and monuments. The majority of the campus's Norman buildings are constructed from gray and black granite. The campus is a popular tourist destination complete with a large visitor center and the oldest museum in the United States Army.
Candidates for admission must both apply directly to the academy and receive a nomination, usually from a member of Congress or Delegate/Resident Commissioner in the case of Washington, D.C., Puerto Rico, Northern Mariana Islands, Guam, American Samoa, and the Virgin Islands. Other nomination sources include the President and Vice President of the United States. Students are officers-in-training and are referred to as "cadets" or collectively as the "United States Corps of Cadets" (USCC). Tuition for cadets is fully funded by the Army in exchange for an active duty service obligation upon graduation. Approximately 1,300 cadets enter the Academy each July, with about 1,000 cadets graduating.
The academic program grants a bachelor of science degree with a curriculum that grades cadets' performance upon a broad academic program, military leadership performance, and mandatory participation in competitive athletics. Cadets are required to adhere to the Cadet Honor Code, which states that "a cadet will not lie, cheat, steal, or tolerate those who do." The academy bases a cadet's leadership experience as a development of all three pillars of performance: academics, physical, and military.
Most graduates are commissioned as second lieutenants in the Army. Foreign cadets are commissioned into the armies of their home countries. Since 1959, cadets have also been eligible to "cross-commission," or request a commission in one of the other armed services, provided they meet that service's eligibility standards. Every year, a very small number of cadets do this, usually in a one-for-one "trade" with a similarly inclined cadet or midshipman at one of the other service academies.
Because of the academy's age and unique mission, its traditions have influenced other institutions. It was the first American college to have an accredited civil-engineering program, the first to have :class rings, and its technical curriculum was a model for later engineering schools. West Point's student body has a unique rank structure and lexicon. All cadets reside on campus and dine together "en masse" on weekdays for breakfast and lunch. The academy fields fifteen men's and nine women's National Collegiate Athletic Association (NCAA) sports teams. Cadets compete in one sport every fall, winter, and spring season at the intramural, club, or intercollegiate level. Its football team was a national power in the early and mid-20th century, winning three national championships. Its alumni and students are collectively referred to as "The Long Gray Line," and its ranks include two Presidents of the United States (as well as the President of the Confederate States of America), presidents of Costa Rica, Nicaragua and of the Philippines, numerous famous generals, and seventy-five Medal of Honor recipients.
History.
Colonial period, founding, and early years.
The Continental Army first occupied West Point, New York, on 27 January 1778; and is the oldest continuously-operating Army post in the United States. Between 1778 and 1780, the Polish engineer and military hero Tadeusz Kościuszko oversaw the construction of the garrison defenses. The Great Hudson River Chain and high ground above the narrow "S" curve in the river enabled the Continental Army to prevent British Royal Navy ships from sailing upriver and thus dividing the Colonies. As commander of the fortifications at West Point, Benedict Arnold committed his act of treason, attempting to sell the fort to the British. After Arnold betrayed the patriot cause, the Army changed the name of the fortifications at West Point, New York, to Fort Clinton. With the peace after the American Revolutionary War left various ordnance and military stores deposited at West Point.
"Cadets" underwent training in artillery and engineering studies at the garrison since 1794. In 1801, shortly after his inauguration as president, Thomas Jefferson directed that plans be set in motion to establish at West Point the United States Military Academy. He selected Jonathan Williams (engineer) to serve as its first superintendent. Congress formally authorized the establishment and funding of the school with the Military Peace Establishment Act of 1802, which Jefferson signed on 16 March. The academy officially commenced operations on 4 July 1802. The academy graduated Joseph Gardner Swift, its first official graduate, in October 1802; he later returned as Superintendent from 1812 to 1814. In its tumultuous early years, the academy featured few standards for admission or length of study. Cadets ranged in age from 10 years to 37 years and attended between 6 months to 6 years. The impending War of 1812 caused the United States Congress to authorize a more formal system of education at the academy and increased the size of the Corps of Cadets to 250.
In 1817, Colonel Sylvanus Thayer became the Superintendent and established the curriculum, elements of which are still in use as of 2015[ [update]]. Thayer instilled strict disciplinary standards, set a standard course of academic study, and emphasized honorable conduct. Known as the "Father of the Military Academy," he is honored with a monument on campus for the profound impact he had upon the academy. Founded as a school of engineering, for the first half of the 19th century, USMA produced graduates who gained recognition for engineering the bulk of the nation's initial railway lines, bridges, harbors and roads. The academy was the only engineering school in the country until the founding of Rensselaer Polytechnic Institute in 1824. It was so successful in its engineering curriculum that it significantly influenced every American engineering school founded prior to the Civil War.
The Mexican–American War brought the academy to prominence as graduates proved themselves in battle for the first time. Future Civil War commanders Ulysses S. Grant and Robert E. Lee first distinguished themselves in battle in Mexico. In all, 452 of 523 graduates who served in the war received battlefield promotions or awards for bravery. The school experienced a rapid modernization during the 1850s, often romanticized by the graduates who led both sides of the Civil War as the "end of the Old West Point era." New barracks brought better heat and gas lighting, while new ordnance and tactics training incorporated new rifle and musket technology and accommodated transportation advances created by the steam engine. With the outbreak of the Civil War, West Point graduates filled the general officer ranks of the rapidly expanding Union and Confederate armies. 294 graduates served as general officers for the Union, and 151 served as general officers for the Confederacy. Of all living graduates at the time of the war, 105 (10%) were killed, and another 151 (15%) were wounded. Nearly every general officer of note from either army during the Civil War was a graduate of West Point and a West Point graduate commanded the forces of one or both sides in every one of the 60 major battles of the war.
After the Civil War.
Immediately following the Civil War, the academy enjoyed unprecedented fame as a result of the role its graduates had played. However, the post-war years were a difficult time for the academy as it struggled to admit and reintegrate cadets from former confederate states. The first cadets from Southern states were re-admitted in 1868, and 1870 saw the admission of the first black cadet, James Webster Smith of South Carolina. Smith endured harsh treatment and was eventually dismissed for academic deficiency under controversial circumstances in 1874. As a result, Henry O. Flipper of Georgia became the first black graduate in 1877, graduating 50th in a class of 76. Two of the most notable graduates during this period were George Washington Goethals from the class of 1880, and John J. Pershing from the class of 1886. Goethals gained prominence as the chief engineer of the Panama Canal, and Pershing would become famous for his exploits against the famed Pancho Villa in Mexico and later for leading American Forces during World War I.
Besides the integration of southern-state and black cadets, the post-war academy also struggled with the issue of hazing. In its first 65 years, hazing was uncommon or non-existent beyond small pranks played upon the incoming freshmen, but took a harsher tone as Civil War veterans began to fill the incoming freshman classes. The upper class cadets saw it as their duty to "teach the plebes their manners." Hazing at the academy entered the national spotlight with the death of former cadet Oscar L. Booz on 3 December 1900. Congressional hearings, which included testimony by Douglas MacArthur, investigated his death and the pattern of systemic hazing of freshmen. When MacArthur returned as superintendent, he made an effort to end the practice of hazing the incoming freshmen by placing Army sergeants in charge of training new cadets during freshman summer. The practice of hazing continued on some levels well into the late 20th century, but is no longer allowed in the present day.
The demand for junior officers during the Spanish–American War caused the class of 1899 to graduate early, and the Philippine–American War did the same for the class of 1901. This increased demand for officers led Congress to increase the size of the Corps of Cadets to 481 cadets in 1900. The period between 1900 and 1915 saw a construction boom as much of West Point's old infrastructure was rebuilt. Many of the academy's most famous graduates graduated during the 15-year period between 1900 and 1915: Douglas MacArthur (1903), Joseph Stilwell (1904), Henry "Hap" Arnold (1907), George S. Patton (1909), Dwight D. Eisenhower, and Omar Bradley (both 1915). The class of 1915 is known as "the class the stars fell on" for the exceptionally high percentage of general officers that rose from that class (59 of 164).
The outbreak of America's involvement in World War I caused a sharp increase in the demand for army officers, and the academy accelerated graduation of all four classes then in attendance to meet this requirement, beginning with the early graduation of the First Class on 20 April 1917, the Second Class in August 1917, and both the Third and Fourth Classes just before the Armistice of 11 November 1918, when only freshman cadets remained (those who had entered in the summer of 1918). In all, wartime contingencies and post-war adjustments resulted in ten classes, varying in length of study from two to four years, within a seven-year period before the regular course of study was fully resumed.
Douglas MacArthur became superintendent in 1919, instituting sweeping reforms to the academic process, including introducing a greater emphasis on history and humanities. He made major changes to the field training regimen and the Cadet Honor Committee was formed under his watch in 1922. MacArthur was a firm supporter of athletics at the academy, as he famously said "Upon the fields of friendly strife are sown the seeds that, upon other fields, on other days, will bear the fruits of victory." West Point was first officially accredited in 1925, and in 1933 began granting bachelor of science degrees to all graduates. In 1935, the academy's authorized strength increased to 1,960 cadets.
World War II and Cold War.
As World War II engulfed Europe, Congress authorized an increase to 2,496 cadets in 1942 and began graduating classes early. The class of 1943 graduated six months early in January 1943, and the next four classes graduated after only three years. To accommodate this accelerated schedule, summer training was formally moved to a recently acquired piece of land southwest of main post. The site would later become Camp Buckner. The academy had its last serious brush with abolition or major reform during the war, when some members of Congress charged that even the accelerated curriculum allowed young men to "hide out" at West Point and avoid combat duty. A proposal was put forth to convert the academy to an officer's training school with a six-month schedule, but this was not adopted. West Point played a prominent role in WWII; four out of five of the five-star generals were alumni and nearly 500 graduates died. Immediately following the war in 1945, Maxwell Taylor (class of 1922) became superintendent. He expanded and modernized the academic program and abolished antiquated courses in fencing and horsemanship.
Unlike previous conflicts, the Korean War did not disrupt class graduation schedules. More than half of the army leadership during the war was composed of academy graduates. As a result, 157 alumni perished in the conflict. Garrison H. Davidson became superintendent in 1956 and instituted several reforms that included refining the admissions process, changing the core curriculum to include electives, and increasing the academic degree standards for academy instructors. The 1960s saw the size of the Corps expand to 4,400 cadets while the barracks and academic support structure grew proportionally. West Point was not immune to the social upheaval of American society during the Vietnam War. The first woman joined the faculty of the all-male institution amidst controversy in 1968. The Army granted its first honorable discharge to a West Point graduate who claimed conscientious objector status in 1971. The academy struggled to fill its incoming classes as its graduates led troops in Southeast Asia, where 333 graduates died.
Modern era.
Following the 1973 Paris Peace Accords that ended American involvement in Vietnam, the strain and stigma of earlier social unrest dissolved and West Point enjoyed surging enrollments. West Point admitted its first 119 female cadets in 1976, after Congress authorized the admission of women to the federal service academies in 1975. Women currently compose approximately 15% of entering new cadets. In 1989, Kristin Baker became the first female First Captain (an effigy of her is now on display in the Museum), the highest ranking senior cadet at the academy. Three other females have been appointed as First Captain: Grace H. Chung in 2003, Stephanie Hightower in 2005, and Lindsey Danilack in 2013. Rebecca Marier became the academy's first female valedictorian in 1995.
In 1985, cadets were formally authorized to declare an academic major; all previous graduates had been awarded a general bachelor of science degree. Five years later there was a major revision of the "Fourth Class System", as the Cadet Leader Development System (CLDS) became the guidance for the development of all four classes. The class of 1990 was the first one that issued a standard and mandatory computer to every member of the class at the beginning of Plebe year, the Zenith 248 SX. The academy was also an early adopter of the Internet in the mid-1990s, and was recognized in 2006 as one of the nation's "most wired" campuses.
At the height of the Cold War in October 1987, President Reagan visited the Academy and delivered a speech about ending the Evil Empire.
During the Gulf War, alumnus General Schwarzkopf was the commander of Allied Forces, and the American senior generals in Iraq, Generals Petraeus and Odierno, and Afghanistan, retired General Stanley McChrystal and General David Rodriguez, are also alumni. Following the September 11 attacks, applications for admission to the academy increased dramatically, security on campus was increased, and the curriculum was revamped to include coursework on terrorism and military drills in civilian environments. One graduate was killed during the 9/11 terrorist attacks and ninety graduates have died during operations in Afghanistan, Iraq, and the ongoing Global War on Terror. The Class of 2005 has been referred to as The Class of 9/11 as the attacks occurred during their first year at the academy, and they graduated 911 students. In 2008 gender-neutral lyrics were incorporated into West Point's "Alma Mater" and "The Corps" — replacing lines like "The men of the Corps" with "The ranks of the Corps." In December 2009, President Barack Obama delivered a major speech in Eisenhower Hall Theater outlining his policy for deploying 30,000 additional troops to Afghanistan as well as setting a timetable for withdrawal. President Obama also provided the commencement address in 2014.
Campus.
The academy is located approximately 50 mi north of New York City on the western bank of the Hudson River. West Point, New York, is incorporated as a federal military reservation in Orange County and is adjacent to Highland Falls. Based on the significance both of the Revolutionary War fort ruins and of the military academy itself, the majority of the academy area was declared a National Historic Landmark in 1960. In 1841, Charles Dickens visited the academy and said "It could not stand on more appropriate ground, and any ground more beautiful can hardly be." One of the most visited and scenic sites on post, Trophy Point, overlooks the Hudson River to the north, and is home to many captured cannon from past wars as well as the Stanford White-designed Battle Monument. Though the entire military reservation encompasses 15974 acre, the academic area of the campus, known as "central area" or "the cadet area", is entirely accessible to cadets or visitors by foot.
In 1902, the Boston architectural firm Cram, Goodhue, and Ferguson was awarded a major construction contract that set the predominantly neogothic architectural style still seen today. Most of the buildings of the central cadet area are in this style, as typified by the Cadet Chapel, completed in 1910. These buildings are nearly all constructed from granite that has a predominantly gray and black hue. The barracks that were built in the 1960s were designed to mimic this style. Other buildings on post, notably the oldest private residences for the faculty, are built in the Federal, Georgian, or English Tudor styles. A few buildings, such as Cullum Hall and the Old Cadet Chapel, are built in the Neoclassical style.
The academy grounds are home to numerous monuments and statues. The central cadet parade ground, the Plain, hosts the largest number, and includes the Washington Monument, Thayer Monument, Eisenhower Monument, MacArthur Monument, Kosciuszko Monument, and Sedgwick Monument. Patton Monument was first dedicated in front of the cadet library in 1950, but in 2004 it was placed in storage to make room for the construction of Jefferson Hall. With the completion of Jefferson Hall, Patton's statue was relocated and unveiled at a temporary location on 15 May 2009, where it will remain until the completion of the renovation of the old cadet library and Bartlett Hall. There is also a statue commemorating brotherhood and friendship from the École Polytechnique in the cadet central area just outside Nininger Hall. The remaining campus area is home to 27 other monuments and memorials.
The West Point Cemetery is the final resting place of many notable graduates and faculty, including George Armstrong Custer, Winfield Scott, William Westmoreland, Earl Blaik, Maggie Dixon, and sixteen Medal of Honor recipients. The cemetery is also the burial place of several recent graduates who have died during the ongoing conflict in Iraq and Afghanistan. Many of the older grave sites have large and ornate grave markers, the largest belonging to Egbert Viele (class of 1847), chief engineer of Brooklyn's Prospect Park. The cemetery is also home to a monument to Revolutionary War heroine Margaret Corbin.
Athletic facilities.
West Point is home to historic athletic facilities like Michie Stadium and Gillis Field House as well as modern facilities such as the Lichtenburg Tennis Center, Anderson Rugby Complex, and the Lou Gross Gymnastics Facility. Michie Stadium recently underwent a significant upgrade in facilities for the football team, and the academy installed a new artificial turf field in the summer of 2008.
West Point Museum.
The visitor's center is just outside the Thayer Gate in the village of Highland Falls and offers the opportunity to arrange for a guided tour. These tours, which are the only way the general public can access the academy grounds, leave the visitor's center several times a day. The West Point Museum is directly adjacent to the visitor's center, in the renovated Olmsted Hall on the grounds of the former Ladycliff College. Originally opened to the public in 1854, the West Point Museum is the oldest military museum in the country. During the summer months, the museum operates access to the Fort Putnam historic site on main post and access to the 282 acre Constitution Island.
One of the most notable items on display at the museum are George Washington's pistols, Napoleon's sword, a dagger carried by Hermann Goering when he was captured, a revolver that belonged to Goering and a silver-plated party book, signed by Charles Lindbergh, Herbert Hoover and Mussolini etc. Arguably, the most prized artifact on display is a gold-plated pistol that belonged to Adolf Hitler.
Administration.
Academy leadership.
The commanding officer at the USMA is the Superintendent. In recent years, the position of Superintendent has been held by a Lieutenant General (three star general). The current Superintendent, Lieutenant General Robert L. Caslen, Jr., took command on 17 July 2013. Earlier in his career, Caslen served as the 70th commandant of Cadets. The academy is a direct reporting unit, and as such, the Superintendent reports directly to the Army Chief of Staff (CSA).
There are two other general officer positions at the academy. Brigadier General John Thomson is the Commandant of Cadets, and Brigadier General Timothy Trainor is the Dean of the Academic Board. There are 13 academic departments at USMA, each with a colonel as the head of department. These 13 tenured colonels comprise the core of the Academic Board. These officers are titled "Professors USMA" or PUSMA. The academy is also overseen by the Board of Visitors (BOV). The BOV is a panel of Senators, Congressional Representatives, and presidential appointees who "shall inquire into the morale and discipline, curriculum, instruction, physical equipment, fiscal affairs, academic methods, and other matters relating to the academy that the board decides to consider." Currently the BOV is chaired by Congressman John Shimkus and is composed of three Senators, five Congressmen, and six presidential appointees.
Admission requirements.
Candidates must be between 17 and 23 years old, unmarried, and with no legal obligation to support a child. Above average high school and/or previous college grades, and strong performance on standardized testing is expected. The interquartile range on the old SAT was 1100–1360 and 68% ranked in the top fifth of their high school class.
To be eligible for appointment, candidates must also undergo a Candidate Fitness Assessment and a complete physical exam. Up to 60 students from foreign countries are present at USMA, educated at the expense of the sponsoring nation, with tuition assistance based on the GNP of their country. Of these foreign cadets the Code of Federal Regulations specifically permits one Filipino cadet designated by the President of the Philippines.
The actual application process consists of two main requirements: candidates apply to USMA for admission and separately provide a nomination. The majority of candidates receive a nomination from their United States Representative or Senator. Some receive a nomination from the Vice President or even the President of the United States.
The nomination process is not political. Applicants do not have to know their congressman to be nominated. The Academy applicant typically provides written essays and letters of recommendation. The applicant then submits to a formal interview. Admission to West Point is selective: 12.75% of applicants were admitted (total of 1292) to the Class of 2012.
Candidates may have previous college experience, but they may not transfer, meaning that regardless of previous college credit, they enter the academy as a fourth class cadet and undergo the entire four-year program. If a candidate is considered academically disqualified and not selected, he or she may receive an offer to attend to the United States Military Academy Preparatory School. Upon graduation from USMAPS, these candidates are appointed to the academy if they receive the recommendation of the USMAPS Commandant and meet medical admission requirements.
The West Point Association of Graduates (WPAOG) also offers scholarship support to people who are qualified but not selected. The scholarships usually cover around $7,000 to civilian universities; the students who receive these scholarships do so under the stipulation that they will be admitted to and attend West Point a year later. Those who do not must repay the AOG. New Mexico Military Institute, Marion Military Institute, Valley Forge Military College and the Greystone Preparatory School at Schreiner University in Kerrville, Texas, are programs that students often attend on the AOG scholarship prior to admission to West Point.
Curriculum.
West Point is a medium-sized, highly residential baccalaureate college, with a full-time, four-year undergraduate program that emphasizes instruction in the arts, sciences, and professions with no graduate program. There are forty-five academic majors, the most popular of which are foreign languages, management information systems, history, economics, and mechanical engineering. West Point is accredited by the Middle States Commission on Higher Education. Military officers compose 75% of the faculty, while civilian professors make up the remaining 25%.
A cadet's class rank, which determines his or her Army branch and assignment upon graduation, is calculated as a combination of academic performance (55%), military leadership performance (30%), and physical fitness and athletic performance (15%).
Academics.
The academy's teaching style forms part of the Thayer system, which was implemented by Sylvanus Thayer during his tour as Superintendent. This form of instruction emphasizes small classes with daily homework, and strives to make students actively responsible for their own learning by completing homework assignments prior to class and bringing the work to class to discuss collaboratively.
The academic program consists of a structured core of thirty-one courses balanced between the arts and sciences. The Academy operates on the semester system, which it labels as "terms" (Term 1 is the fall semester; Term 2 is the spring semester). Although cadets choose their majors in the fall of their sophomore year, all cadets take the same course of instruction until the beginning of their junior year. This core course of instruction consists of mathematics, information technology, chemistry, physics, engineering, history, physical geography, philosophy, leadership and general psychology, English composition and literature, foreign language, political science, international relations, economics, and constitutional law. Some advanced cadets may "validate" out of the base-level classes and take advanced or accelerated courses earlier as freshmen or sophomores. Regardless of major, all cadets graduate with a Bachelor of Science degree.
Military.
As all cadets are commissioned as second lieutenants upon graduation, military and leadership education is nested with academic instruction. Military training and discipline fall under the purview of the Office of the Commandant. Entering freshmen, or fourth class cadets, are referred to as New Cadets, and enter the academy on Reception Day or R-day, which marks the start of cadet basic training (CBT), known colloquially as Beast Barracks, or simply Beast. Most cadets consider Beast to be their most difficult time at the academy because of the transition from civilian to military life. Their second summer, cadets undergo cadet field training (CFT) at nearby Camp Buckner, where they train in more advanced field craft and military skills. During a cadet's third summer, they may serve as instructors for CBT or CFT. Rising Firstie (senior) cadets also spend one-month training at Camp Buckner, where they train for modern tactical situations that they will soon face as new platoon leaders. Cadets also have the opportunity during their second, third and fourth summers to serve in active army units and military schools around the world. The schools include Airborne, Air Assault, Sapper, Pathfinder, etc.
Active duty officers in the rank of captain or major serve as Company Tactical Officers (TAC Officers). The role of the TAC is to mentor, train, and teach the cadets proper standards of good order and discipline and be a good role model. There is one TAC for every cadet company. There is also one senior Non-Commissioned Officer to assist each TAC, known as TAC-NCOs.
The Department of Military Instruction (DMI) is responsible for all military arts and sciences education as well as planning and executing the cadet summer training. Within DMI there is a representative from each of the Army's branches. These "branch reps" serve as proponents for their respective branches and liaise with cadets as they prepare for branch selection and graduation.
Physical.
The Department of Physical Education (DPE) administers the physical program, which includes both physical education classes, physical fitness testing, and competitive athletics. The head of DPE holds the title of Master of the Sword, dating back to the 19th century when DPE taught swordsmanship as part of the curriculum.
All cadets take a prescribed series of physical fitness courses such as military movement (applied gymnastics), boxing (men) or self-defense (women), swimming, and beginning in 2009, advanced combatives. Cadets can also take elective physical activity classes such as scuba, rock climbing, and aerobic fitness.
As with all soldiers in the Army, cadets also must pass the Army Physical Fitness Test twice per year. Additionally, every year, cadets must pass the Indoor Obstacle Course Test (IOCT), which DPE has administered in Hayes Gymnasium since 1944.
Since Douglas MacArthur's tenure as superintendent, every cadet has been required to participate in either an intercollegiate sport, a club sport, or an intramural (referred to as "company athletics") sport each semester.
Moral and ethical training.
Moral and ethical development occurs throughout the entirety of the cadet experience by living under the honor code and through formal leadership programs available at the academy. These include instruction in the values of the military profession through Professional Military Ethics Education (PME2), voluntary religious programs, interaction with staff and faculty role models, and an extensive guest-speaker program. The foundation of the ethical code at West Point is found in the academy's motto, "Duty, Honor, Country."
West Point's Cadet Honor Code reads simply that: "A cadet will not lie, cheat, steal, or tolerate those who do." Cadets accused of violating the Honor Code face an investigative and hearing process. If they are found guilty by a jury of their peers, they face severe consequences ranging from being "turned back" (repeating an academic year) to separation from the academy. Cadets previously enforced an unofficial sanction known as "silencing" by not speaking to cadets accused of violating the honor code, but the practice ended in 1973 after national scrutiny. Also in 1976, 151 junior cadets were found guilty of 'violating the honour code' in their exams.
Cadet life.
Rank and organization.
Cadets are not referred to as freshmen, sophomores, juniors, or seniors. Instead they are officially called fourth class, third class, second class, and first class cadets. Colloquially, freshmen are "plebes", sophomores are "yearlings" or "yuks", juniors are "cows", and seniors are "firsties". Some of the origins of the class names are known, some are not. Plebeians were the lower class of ancient Roman society, while yearling is a euphemism for a year-old animal. The origin of cow is less known. There are a number of theories for the origin of the term "cow"; however the most prevalent and probably accurate one is that cadets in years past had no leave until the end of their yearling year, when they were granted a summer-long furlough. Their return as second classmen was heralded as "the cows coming home."
The Corps of Cadets is officially organized into a brigade. The senior ranking cadet, the Brigade Commander, is known traditionally as the "First Captain". The brigade is organized into four regiments. Within each regiment there are three battalions, each consisting of three companies. Companies are lettered A through I, with a number signifying which regiment it belongs to. For example, there are four "A" companies: A1, A2, A3, and A4. First class cadets hold the leadership positions within the brigade from the First Captain down to platoon leaders within the companies. Leadership responsibility decreases with the lower classes, with second class cadets holding the rank of cadet sergeant, third class cadets holding the rank of cadet corporal, and fourth class cadets as cadet privates.
Life in the corps.
Because of the academy's congressional nomination process, students come from all 50 states, Puerto Rico, the District of Columbia, the Mariana Islands, Guam, American Samoa, and the US Virgin Islands. The academy is also authorized up to 60 international exchange cadets, who undergo the same four-year curriculum as fully integrated members of the Corps of Cadets. Cadets attend the United States Military Academy free of charge, with all tuition and board paid for by the Army in return for a service commitment of five years of active duty and three years of reserve status upon graduation. In addition to a small salary, Cadets receive meals in the dining halls, and have access to the Internet and a phone in their barracks. The student population was 4,487 cadets for the 2007–2008 academic year. The student body is 15.1% female. Ninety-two percent of entering students re-matriculated for a second year; the four-year graduation rate was 80% and the six-year rate was 81%.
All cadets reside on campus for their entire four years in one of the seven barracks buildings. Most cadets are housed with one roommate, but some rooms are designed for three cadets. Cadets are grouped into "companies" identified by alpha-numeric codes. All companies live together in the same barracks area. The academy has the cadets change companies after their freshman or sophomore years. This process is known as scrambling, and the method of scrambling has changed several times in recent years. All 4,000 cadets dine together at breakfast and lunch in the Washington Hall during the weekdays. The cadet fitness center, Arvin Cadet Physical Development Center (usually just called "Arvin" by cadets and faculty), which was rebuilt in 2004, houses extensive physical fitness facilities and equipment for student use.
Each class of cadets elects representatives to serve as class president and fill several administrative positions. They also elect a ring and crest committee, which designs the class's crest, the emblem that signifies their class and it is embossed upon their class rings. Each class crest is required to contain the initials "USMA" and their class motto. The class motto is proposed by the class during cadet basic training and voted on by the class prior to the beginning of their freshman academic year. Class mottos typically have verbiage that rhymes or is phonetically similar with their class year.
Cadets today live and work within the framework of the Cadet Leader Development System (CLDS), which specifies the roles that a cadet plays throughout their four years at the academy. Cadets begin their USMA careers as trainees (new cadets), then advance in rank, starting as CDT Privates (freshmen) and culminating as CDT Officers (seniors). Freshmen have no leadership responsibilities, but have a host of duties to perform as they learn how to follow orders and operate in an environment of rigid rank structure, while seniors have significant leadership responsibilities and significantly more privileges that correspond to their rank.
Activities.
Cadets have a host of extracurricular activities available, most run by the office of the Directorate of Cadet Activities (DCA). DCA sponsors or operates 113 athletic and non-sport clubs. Many cadets join several clubs during their time at the academy and find their time spent with their clubs a welcome respite from the rigors of cadet life. DCA is responsible for a wide range of activities that provide improved quality of life for cadets, including: three cadet-oriented restaurants, the Cadet Store, and the "Howitzer" and "Bugle Notes". "The Howitzer" is the annual yearbook, while "Bugle Notes", also known as the "plebe bible," is the manual of plebe knowledge. Plebe knowledge is a lengthy collection of traditions, songs, poems, anecdotes, and facts about the academy, the army, the "Old Corps", and the rivalry with Navy that all plebes must memorize during cadet basic training. During plebe year, plebes may be asked, and are expected to answer, any inquiry about plebe knowledge asked by upper class cadets. Other knowledge is historical in nature, including information as found in "Bugle Notes". However, some knowledge changes daily, such as "the days" (a running list of the number of days until important academy events), the menu in the mess hall for the day, or the lead stories in "The New York Times".
Each cadet class celebrates at least one special "class weekend" per academic year. Fourth class cadets participate in Plebe Parent Weekend during the first weekend of spring break. In February, third class cadets celebrate the winter season with Yearling Winter Weekend. In late January the second class cadets celebrate 500th Night, marking the remaining 500 days before graduation. First class cadets celebrate three different formal occasions. In late August, first class cadets celebrate Ring Weekend, in February they mark their last 100 days with 100th Night, and in May they have a full week of events culminating in their graduation. All of the "class weekends" involve a formal dinner and social dance, known in old cadet slang as a "hop," held at Eisenhower Hall.
Athletics.
Since 1899, Army's mascot has officially been a mule because the animal symbolizes strength and perseverance. The academy's football team was nicknamed "The Black Knights of the Hudson" due to the black color of its uniforms. This nickname has since been officially shortened to "Black Knights." U.S. sports media use "Army" as a synonym for the academy. "On Brave Old Army Team" is the school's fight song. Army's chief sports rival is the Naval Academy due to its long-standing football rivalry and the intraservice rivalry with the Navy in general. Fourth class cadets verbally greet upper-class cadets and faculty with "Beat Navy," while the tunnel that runs under Washington Road is named the "Beat Navy" tunnel. Army also plays the U.S. Air Force Academy for the Commander-in-Chief's Trophy. In the first half of the 20th century, Army and Notre Dame were football rivals, but that rivalry has since died out.
Football.
Army football began in 1890, when Navy challenged the cadets to a game of the relatively new sport. Navy defeated Army at West Point that year, but Army avenged the loss in Annapolis the following year. The rival academies still clash every December in what is traditionally the last regular-season Division I college-football game. The 2013 football season marked Navy's twelfth consecutive victory over Army, the longest streak in the series since inception. Army's football team reached its pinnacle of success under coach Earl Blaik when Army won consecutive national championships in 1944, 1945 and 1946, and produced three Heisman trophy winners: Doc Blanchard (1945), Glenn Davis (1946) and Pete Dawkins (1958). Past NFL coaches Vince Lombardi and Bill Parcells were Army assistant coaches early in their careers. The football team plays its home games at Michie Stadium, where the playing field is named after Earl Blaik. Cadets' attendance is mandatory at football games and the Corps stands for the duration of the game. At all home games, one of the four regiments marches onto the field in formation before the team takes the field and leads the crowd in traditional Army cheers. From 1992 through 1996, Army won all of the games against Navy for the first time since the legendary days of Blanchard and Davis, and it introduced the fraternal group of players identifying themselves as the Fat Man Club, initiated by the offensive linemen of the Class of 1996. Between the 1998 and 2004 seasons, Army's football program was a member of Conference USA, but has since reverted to its former independent status.
Other sports.
Though football may receive a lot of media attention due to its annual rivalry game, West Point has a long history of athletics in other NCAA sports. Army is a member of the Division I Patriot League in most sports, while its men's ice hockey program competes in Atlantic Hockey. John P. Riley, Jr. was the hockey coach at West Point for more than 35 years. Every year, Army faces the Royal Military College of Canada (RMC) Paladins in the annual West Point Weekend hockey game. This series, conceived in 1923, is the longest-running annual international sporting event in the world.
The men's lacrosse team has won eight national championships and appeared in the NCAA tournament sixteen times. In its early years, lacrosse was used by football players, like the "Lonesome End" Bill Carpenter, to stay in shape during the off-season. The 2005–06 women's basketball team went 20–11 and won the Patriot League tournament. They went to the 2006 NCAA Women's Division I Basketball Tournament as a 15th-ranked seed, where they lost to Tennessee, 102–54. It was the first March Madness tournament appearance for any Army basketball team. The head coach of that team, Maggie Dixon, died soon after the season at only 28 years of age. Bob Knight, formerly the winningest men's basketball coach in NCAA history, began his head coaching career at Army in the late 1960s before moving on to Indiana and Texas Tech. One of Knight's players at Army was Mike Krzyzewski, who later was head coach at Army before moving on to Duke, where he has won five national championships.
Approximately 15% of cadets are members of a club sport team. West Point fields a total of 24 club sports teams that have been very successful in recent years, winning national championships in judo, boxing, orienteering, pistol, triathlon, crew, cycling, and team handball.
The majority of the student body, about 65%, competes in intramural sports, known at the academy as "company athletics." DPE's Competitive Sports committee runs the club and company athletics sports programs and was recently named one of the "15 Most Influential Sports Education Teams in America" by the Institute for International Sport. The fall season sees competition in basketball, flag-football, team handball, soccer, ultimate disc, and wrestling; while the spring season sees competition in combative grappling, floor hockey, orienteering, flicker ball, and swimming. In the spring, each company also fields a team entry into the annual Sandhurst Competition, a military skills event conducted by the Department of Military Instruction.
Traditions.
Due to West Point's age and its unique mission of producing Army officers, it has many time-honored traditions. The list below are some of the traditions unique to or started by the academy.
Cullum number.
The Cullum number is a reference and identification number assigned to each graduate. It was created by brevet Major General George W. Cullum (USMA Class of 1833) who, in 1850, began the monumental work of chronicling the biographies of every graduate. He assigned number one to the first West Point graduate, Joseph Gardner Swift, and then numbered all successive graduates in sequence. Before his death in 1892, General Cullum completed the first three volumes of a work that eventually comprised 10 volumes, entitled "General Cullum’s Biographical Register of the Officers and Graduates of the United States Military Academy, and covering USMA classes from 1802 through 1850". From 1802 through the Class of 1977, graduates were listed by general order of Merit. Beginning with the Class of 1978, graduates were listed alphabetically, and then by date of graduation. Seven graduates have an "A" suffix after their Cullum Number. For various reasons these graduates were omitted from the original class roster, and a suffix letter was added to avoid renumbering the entire class and subsequent classes.
Class ring.
West Point began the collegiate tradition of the class ring, beginning with the class of 1835. The class of 1836 chose no rings, and the class of 1879 had cuff links in lieu of a class ring. Before 1917, cadets could design much of the ring individually, but now only the center stone can be individualized. One side of the ring bears the academy crest, while the other side bears the class crest and the center stone ring bears the words "West Point" and the class year. The academy library has a large collection of cadet rings on display. Senior cadets receive their rings during Ring Weekend in the early fall of their senior year. Immediately after senior cadets return to the barracks after receiving their rings, fourth class cadets take the opportunity to surround senior cadets from their company and ask to touch their rings. After reciting a poem known to cadets as the "Ring Poop", the senior usually grants the freshmen permission to touch the ring. In 2002, the Memorial Class ring donor program began. Donations of class rings are melted and merged. A portion of the original gold is infused with gold from preceding melts to become part of the rings for each 'Firstie' class.
Thayer Award.
West Point is home to the Sylvanus Thayer Award. Given annually by the academy since 1958, the award honors an outstanding citizen whose service and accomplishments in the national interest exemplify the academy's motto, "Duty, Honor, Country." Currently, the award guidelines state that the recipient not be a graduate of the academy. The award has been awarded to many notable American citizens, to include George H. W. Bush, Colin Powell, Tom Brokaw, Sandra Day O'Connor, Henry Kissinger, Ronald Reagan, Barry Goldwater, Carl Vinson, Barbara Jordan, William J. Perry, Bob Hope, and Condoleezza Rice.
Sedgwick's spurs.
A monument to Civil War Union soldier general John Sedgwick stands on the outskirts of the Plain. Sedgwick's bronze statue has spurs with rowels that freely rotate. Legend states that if a cadet is in danger of failing a class, they are to don their full-dress parade uniform the night before the final exam. The cadet visits the statue and spins the rowels at the stroke of midnight. Then the cadet runs back to the barracks as fast as they can. According to legend, if Sedgwick's ghost catches them, they will fail the exam. Otherwise the cadet will pass the exam and the course. Although being out of their rooms after midnight is officially against regulations, violations have been known to be overlooked for the sake of tradition.
Goat-Engineer game.
As part of the run-up to the Navy football game, the Corps of Cadets plays the Goat-Engineer game. First played in 1907, it is a game between the "Goats" (the bottom half of the senior (Firstie) class academically), and the "Engineers" (the top half). The game is played with full pads and helmets using eight-man football rules. The location has changed over the years, with recent venues being Shea Stadium, Michie Stadium, and Daly Field. Legend states that Army will beat Navy if the goats win, and the opposite if the engineers win. In recent years, female cadets have begun playing a flag football contest, so there are now two Goat-Engineer games, played back to back the same night.
Walking the area.
From the earliest days of the academy, one form of punishment for cadets who commit regulatory infractions has been a process officially known as "punishment tours". This process is better known to the cadets as "hours" because as punishment, cadets must walk a specified number of hours in retribution. Cadets are "awarded" punishment tours based upon the severity of the infraction. Being late to class or having an unkempt room may result in as little as 5 hours while more severe misconduct infractions may result in upwards of 60 to 80 hours. In its most traditional form, punishment tours are "walked off" by wearing the dress gray uniform under arms and walking back and forth in a designated area of the cadet barracks courtyard, known as "Central Area." Cadets who get into trouble frequently and spend many weekends "walking off their hours" are known as "area birds." Cadets who walk more than 100 total hours in their career are affectionately known as "Century Men." An alternate form of punishment to walking hours is known as "fatigue tours," where assigned hours may be "worked off" by manual labor, such as cleaning the barracks. Certain cadets whose academics are deficient may also conduct "sitting tours," where they have to "sit hours" in a designated academic room in a controlled study environment, for which they receive half credit towards their reduction of tours. Cadets' uniforms are inspected before their tours begin each day. A small number of cadets may be relieved of their tours that day if their uniforms are exceptionally presentable. Another tradition associated with punishment tours is that any visiting head of state has the authority to grant "amnesty," releasing all cadets with outstanding hours from the remainder of their assigned tours.
Notable alumni.
An unofficial motto of the academy's history department is "Much of the history we teach was made by people we taught." Graduates of the academy refer to themselves as "The Long Gray Line," a phrase taken from the academy's traditional hymn "The Corps." The academy has produced just under 65,000 alumni, including two Presidents of the United States: Ulysses S. Grant and Dwight D. Eisenhower; the president of the Confederate States of America, Jefferson Davis; and three foreign heads of state: Anastasio Somoza Debayle of Nicaragua, Fidel V. Ramos of the Philippines, and José María Figueres of Costa Rica. Alumni currently serving in public office include Senator Jack Reed, Governor of Nebraska David Heineman, and Congressmen Geoff Davis, Brett Guthrie, Mike Pompeo and John Shimkus.
The academy has produced many notable generals during its 212 years. During the Civil War, graduates included John Bell Hood, Stonewall Jackson, Robert E. Lee, Simon Bolivar Buckner, James Longstreet, George G. Meade, Phillip Sheridan, William Tecumseh Sherman, J.E.B. Stuart and Oliver O. Howard George Armstrong Custer graduated last in his class of 1861. The Spanish–American War saw the first combat service of Lt. (later, Brigadier General) John "Gatling Gun" Parker, the first Army officer to employ machine guns in offensive fire support of infantry.
During World War I, the academy produced General of the Armies John J. Pershing. West Point was the alma mater of many notable World War II generals, Henry H. Arnold, Omar Bradley, Mark Wayne Clark, Robert L. Eichelberger, James M. Gavin, Leslie Groves, Douglas MacArthur, George S. Patton, Joseph Stilwell, Maxwell D. Taylor, James Van Fleet, Jonathan Mayhew Wainwright IV, and Simon Bolivar Buckner, Jr. the highest ranking General to be killed in combat during World War II, with many of these graduates also serving in commanding roles in the Korean War. During the Vietnam War, notable graduates general officers included Creighton Abrams, Hal Moore, and William Westmoreland. West Point also produced some famous generals and statesmen of recent note including John Abizaid, Stanley A. McChrystal, Wesley Clark, Alexander Haig, Barry McCaffrey, Norman Schwarzkopf, Jr., Brent Scowcroft, Lloyd Austin, and former Director of the Central Intelligence Agency, retired General David Petraeus.
A total of 74 graduates have been awarded the Medal of Honor.
West Point has produced 18 NASA astronauts, including five who went to the Moon. Other noted alumni include Jim Kimsey, founder of AOL; Bob McDonald, CEO of Procter & Gamble who was later nominated to be the Secretary of Veteran Affairs; Alex Gorsky, CEO of Johnson & Johnson; Keith McLoughlin, President and CEO of Electrolux and Alden Partridge, founder of Norwich University. West Point's contributions to sport include three Heisman Trophy winners: Glenn Davis, Doc Blanchard, and Pete Dawkins. West Point has produced many high government officials, including Brent Scowcroft, the National Security Advisor under Presidents Gerald Ford and George H. W. Bush, and Eric Shinseki, former Secretary of Veterans Affairs under President Barack Obama. West Point graduate Frank Medina organized and led the nationwide campaign that brought the Congressional Gold Medal to the 65th Infantry Regiment, also known as the Borinqueneers.
Among American universities, the academy is fourth on the list of total winners for Rhodes Scholarships, seventh for Marshall Scholarships and fourth on the list of Hertz Fellowships. The official alumni association of West Point is the West Point Association of Graduates (WPAOG or AOG), headquartered at Herbert Hall.
Commemorations.
On May 26, 1937, the U.S. Post Office issued a 5-cent commemorative stamp honoring West Point, which features several of its buildings along with the West Point's motto, "DUTY * HONOR * COUNTRY", inscribed under its name near the top. On the 200th anniversary of West Point's founding the U.S.P.S. released a second stamp of 34-cents in its honor.
Notes.
References used.
</dl>

</doc>
<doc id="32176" url="http://en.wikipedia.org/wiki?curid=32176" title="United States Minor Outlying Islands">
United States Minor Outlying Islands

The United States Minor Outlying Islands, a statistical designation defined by the International Organization for Standardization's ISO 3166-1 code, consist of eight United States insular areas in the Pacific Ocean (Baker Island, Howland Island, Jarvis Island, Johnston Atoll, Kingman Reef, Midway Islands, Palmyra Atoll, and Wake Island) and one in the Caribbean Sea (Navassa Island).
Overview.
Among them, Palmyra Atoll is the only incorporated territory. As of 2008, none of the islands have any permanent residents. The only human population consists of temporarily stationed scientific and military personnel. The 2000 census counted 315 people on Johnston Atoll and one person on Wake Island.
There has been no modern indigenous population, except at the 1940 census. In 1936 a colonization scheme began to settle Americans on Baker, Howland, and Jarvis, but all three islands were evacuated in 1942 as a result of World War II.
The islands are grouped together as a statistical convenience. They are not administered collectively, nor do they share a single cultural or political history beyond being uninhabited islands under the sovereignty of the United States.
They are collectively represented by the ISO 3166-1 alpha-2 code UM. The individual islands have ISO 3166-2 numerical codes, see .
The Internet country code top-level domain (ccTLD) ".um" has historically been assigned to the islands; however, the .um ccTLD was retired in January 2007.
ISO introduced the term "United States Minor Outlying Islands" in 1986. From 1974 until 1986, five of the islands (Baker Island, Howland Island, Jarvis Island, Palmyra Atoll and Kingman Reef) were grouped under the term United States Miscellaneous Pacific Islands, with ISO 3166 code PU. The code of Midway Atoll was MI, the code of Johnston Atoll was JT, and the code of Wake Island was WK. The Pacific islands are surrounded by large Exclusive Economic Zones.
See also Organized incorporated territories, Unincorporated territories and List of territorial disputes in North America.
Airports.
The following is a list of island airports with ICAO (IATA) codes:
Other airports include:
Ports.
Three of the islands are listed with ports in the World Port Index, with World Port Number:
Baker Island, Howland Island and Jarvis Island have a small boat landing place on each. Kingman Reef and Navassa Island have offshore anchorage only.

</doc>
<doc id="32178" url="http://en.wikipedia.org/wiki?curid=32178" title="United Nations Environment Programme">
United Nations Environment Programme

The United Nations Environment Programme (UNEP) is an agency of the United Nations that coordinates its environmental activities, assisting developing countries in implementing environmentally sound policies and practices. It was founded by Maurice Strong, its first director, as a result of the United Nations Conference on the Human Environment in June 1972 and has its headquarters in the Gigiri neighborhood of Nairobi, Kenya. UNEP also has six regional offices and various country offices.
Its activities cover a wide range of issues regarding the atmosphere, marine and terrestrial ecosystems, environmental governance and green economy. It has played a significant role in developing international environmental conventions, promoting environmental science and information and illustrating the way those can be implemented in conjunction with policy, working on the development and implementation of policy with national governments, regional institutions in conjunction with environmental non-governmental organizations (NGOs). UNEP has also been active in funding and implementing environment related development projects.
The winner of Miss Earth beauty pageant serves as the spokesperson of UNEP. 
UNEP has aided in the formulation of guidelines and treaties on issues such as the international trade in potentially harmful chemicals, transboundary air pollution, and contamination of international waterways.
The World Meteorological Organization and UNEP established the Intergovernmental Panel on Climate Change (IPCC) in 1988. UNEP is also one of several Implementing Agencies for the Global Environment Facility (GEF) and the Multilateral Fund for the Implementation of the Montreal Protocol, and it is also a member of the United Nations Development Group.
The International Cyanide Management Code, a program of best practice for the chemical’s use at gold mining operations, was developed under UNEP’s aegis.
Links in other languages:
Executive Director.
UNEP's current Executive Director Achim Steiner succeeded previous director Klaus Töpfer in 2006. Dr Töpfer served two consecutive terms, beginning in February 1998.
On 15 March 2006, the former Secretary-General of the United Nations, Kofi Annan, nominated Achim Steiner, former Director General of the IUCN to the position of Executive Director. The UN General Assembly followed Annan's proposal and elected him.
The position was held for 17 years (1975–1992) by Dr. Mostaza cipote Kamal Tolba, who was instrumental in bringing environmental considerations to the forefront of global thinking and action. Under his leadership, UNEP's most widely acclaimed success—the historic 1987 agreement to protect the ozone layer—the Montreal Protocol was negotiated.
During December 1972, the UN General Assembly unanimously elected Maurice Strong to head UNEP. Also Secretary General of both the 1972 United Nations Conference on the Human Environment, which launched the world environment movement, and the 1992 Earth Summit, Strong has played a critical role is globalizing the environmental movement.
Structure.
UNEP's structure includes seven substantive Divisions:
International years.
The year 2007 was declared (International) Year of the Dolphin by the United Nations and UNEP.
(International) Patron of the Year of the Dolphin was H.S.H. Prince Albert II of Monaco, with Special Ambassador to the cause being Nick Carter, of the Backstreet Boys.
2010 was designated the International Year of Biodiversity and presented an opportunity to enhance knowledge of ecosystems and their services.
In 2011 the UN celebrated the International Year of Forests.
In 2012, the International Year for Sustainable Energy for All. 
2013 has been designated as the International Year of Water Cooperation.
Reports.
UNEP publishes many reports, atlases and newsletters. For instance, the fifth Global Environment Outlook (GEO-5) assessment is a comprehensive report on environment, development and human well-being, providing analysis and information for policy makers and the concerned public. One of many points in the GEO-5 warns that we are living far beyond our means. It notes that the human population is now so large that the amount of resources needed to sustain it exceeds what is available.
In June 2010, a report from UNEP declared that a global shift towards a vegan diet was needed to save the world from hunger, fuel shortages and climate change.
Reform.
Following the publication of Fourth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) in February 2007, a "Paris Call for Action" read out by French President Jacques Chirac and supported by 46 countries, called for the United Nations Environment Programme to be replaced by a new and more powerful "United Nations Environment Organization (UNEO)", also called Global Environment Organisation now supported by French President Nicolas Sarkozy and German Chancellor Angela Merkel, to be modelled on the World Health Organization. The 46 countries included the European Union nations, but notably did not include the United States, Saudi Arabia, Russia, and China, the top four emitters of greenhouse gases.
In December 2012, following the Rio+20 Summit, a decision by the General Assembly of the United Nations to " the UN Environment Programme (UNEP) and establish universal membership of its governing body was confirmed.
Main activities.
UNEP's main activities are related to:
Notable world projects.
UNEP has sponsored the development of solar loan programs, with attractive return rates, to buffer the initial deployment costs and entice consumers to consider and purchase solar PV systems. The most famous example is the solar loan program sponsored by UNEP helping 100,000 people finance solar power systems in India. Success in India's solar program has led to similar projects in other parts of the developing world like Tunisia, Morocco, Indonesia and Mexico.
UNEP sponsors the Marshlands project in the Middle East that helps to protect the largest marshland in the Middle East. In 2001, UNEP alerted the international community to the destruction of the Marshlands when it released satellite images showing that 90 percent of the Marshlands had already been lost. The UNEP "support for Environmental Management of the Iraqi Marshland" commenced in August 2004, in order to manage the Marshland area in an environmentally sound manner.
In order to ensure full participation of global communities, UNEP works in an inclusive fashion that brings on board different societal cohorts. UNEP has a vibrant programme for young people known as Tunza. Within this program are other projects like the AEO for Youth.
Glaciers shrinking.
Glaciers are shrinking at record rates and many could disappear within decades, the U.N. Environment Programme said on March 16, 2008. The scientists measuring the health of almost 30 glaciers around the world found that ice loss reached record levels in 2006. On average, the glaciers shrank by 4.9 feet in 2006, the most recent year for which data are available. The most severe loss was recorded at Norway's Breidalblikkbrea glacier, which shrank 10.2 feet in 2006. Glaciers lost an average of about a foot of ice a year between 1980 and 1999. But since the turn of the millennium the average loss has increased to about 20 inches.
Electric vehicles.
At the fifth Magdeburg Environmental Forum held from 3–4 July 2008, in Magdeburg, Germany, UNEP and car manufacturer Daimler called for the establishment of infrastructure for electric vehicles. At this international conference, 250 high-ranking representatives from ce, politics and non-government organizations discussed solutions for future road transportation under the motto of "Sustainable Mobility–the Post-2012 CO2 Agenda".

</doc>
<doc id="32179" url="http://en.wikipedia.org/wiki?curid=32179" title="United Australia Party">
United Australia Party

The United Australia Party (UAP) was an Australian political party that was founded in 1931 and dissolved in 1945. It was the political successor to the Nationalist Party of Australia (1917–1931) and was succeeded by the Liberal Party of Australia (1945) as the main anti-Labor party. The party was in government in Australia for much of the 1930s, through Australia's recovery from the Great Depression under Joseph Lyons and into the early stages of World War II under Robert Menzies.
History.
Background.
Joseph Lyons began his political career as an Australian Labor Party politician and served as Premier of Tasmania. Lyons was elected to the Australian Federal Parliament in 1929 and served in Prime Minister James Scullin's Labor Cabinet. Lyons became acting Treasurer in 1930 and helped negotiate the government's strategies for dealing with the Great Depression. With Scullin temporarily absent in London, Lyons and acting Prime Minister James Fenton clashed with the Labor Cabinet and Caucus over economic policy, and grappled with the differing proposals of the Premier's Plan, Lang Labor, the Commonwealth Bank and British adviser Otto Niemeyer.
While Health Minister Frank Anstey supported Premier of New South Wales Jack Lang's bid to default on debt repayments, Lyons advocated orthodox fiscal management. When Labor reinstated the more radical Ted Theodore as Treasurer in 1931, Lyons and Fenton resigned from Cabinet.
Foundation.
The UAP was formed in 1931 by Labor dissidents and a conservative coalition as a response to the more radical economic proposals of Labor Party members to deal with the Great Depression in Australia. Lyons and Fenton's opposition to the economic policies of the Scullin Labor Government had attracted the support of prominent Australian conservatives, known as "the Group", whose number included future prime minister Robert Menzies. In parliament on 13 March 1931, though still a member of the ALP, Lyons supported a no confidence motion against the Scullin Labor government. Soon afterward, Lyons, Fenton and four other right-wing Labor MPs--Moses Gabb, Allan Guy, Charles McGrath and John Price—resigned from the ALP in protest of the Scullin government's economic policies. On 7 May, the Nationalist opposition (hitherto led by John Latham), the six Labor dissidents (who had formed the "All for Australia League"), and former Prime Minister Billy Hughes' Australian Party (a group of former Nationalists who had been expelled for crossing the floor and bringing down Stanley Bruce's Nationalist government in 1929), merged to form the UAP. Although the new party was dominated by former Nationalists, Lyons was chosen as the new party's leader, and thus became Leader of the Opposition.
Claiming that the Scullin government was incapable of managing the economy, it offered traditional deflationary economic policies in response to Australia's economic crisis. Though it was basically an upper- and middle-class conservative party, the presence of ex-Labor MPs with working-class backgrounds, most obviously the party leader, Lyons, allowed the party to present a convincing image of national unity transcending class barriers. Its slogan was "All for Australia and the Empire".
A further split, this time of left-wing NSW Labor MPs who supported the unorthodox economic policies of NSW Premier Jack Lang, cost the Scullin government its parliamentary majority. In November 1931, Lang Labor dissidents broke with the Scullin government and joined with the UAP opposition to pass a no-confidence motion, forcing an early election.
Lyons Government.
With the Labor Party split between Scullin's supporters and Langites, and with a very popular leader (Lyons had a genial manner and the common touch), the UAP won the elections in December 1931 in a massive landslide which saw the two wings of the Labor Party cut down to 18 seats between them, and Lyons became Prime Minister in January 1932. The UAP fought the election as part of the traditional non-Labor Coalition with the Country Party of Earle Page. However, the UAP came up only four seats short of a majority in its own right, putting Lyons in a strong enough position to form an exclusively UAP government. In 1934, the UAP lost six seats, forcing Lyons to take the Country Party into his government in a full-fledged Coalition. The Lyons government followed the conservative economic policies it had promised in opposition, and benefited politically from the gradual worldwide economic recovery as the 1930s went on.
Response to Depression.
Lyons favoured the tough economic measures of the "Premiers' Plan", pursued an orthodox fiscal policy and refused to accept NSW Premier Jack Lang's proposals to default on overseas debt repayments. A dramatic episode in Australian history followed Lyons' first electoral victory when NSW Premier Jack Lang refused to pay interest on overseas State debts. The Lyons government stepped in and paid the debts and then passed the Financial Agreement Enforcement Act to recover the money it had paid. In an effort to frustrate this move, Lang ordered State departments to pay all receipts directly to the Treasury instead of into Government bank accounts. The New South Wales Governor, Sir Philip Game, intervened on the basis that Lang had acted illegally in breach of the state Audit Act and sacked the Lang Government, who then suffered a landslide loss at the consequent 1932 state election.
Australia entered the Depression with a debt crisis and a credit crisis. According to author Anne Henderson of the Sydney Institute, Lyons held a steadfast belief in "the need to balance budgets, lower costs to business and restore confidence" and the Lyons period gave Australia "stability and eventual growth" between the drama of the Depression and the outbreak of the Second World War. A lowering of wages was enforced and industry tariff protections maintained, which together with cheaper raw materials during the 1930s saw a shift from agriculture to manufacturing as the chief employer of the Australian economy - a shift which was consolidated by increased investment by the commonwealth government into defence and armaments manufacture. Lyons saw restoration of Australia's exports as the key to economic recovery. A devalued Australian currency assisted in restoring a favourable balance of trade. Tariffs had been a point of difference between the Country Party and United Australia Party. The CP opposed high tariffs because they increased costs for farmers, while the UAP had support among manufacturers who supported tariffs. Lyons was therefore happy to be perceived as "protectionist". Australia agreed to give tariff preference to British Empire goods, following the 1932 Imperial economic conference. The Lyons Government lowered interest rates to stimulate expenditure. Another point of difference was the issue of establishing national unemployment insurance. Debate on this issue became strained with the Country Party opposing the plan. On this issue, deputy leader Robert Menzies and Country Party leader Earle Page would have a public falling out.
According to author Brian Carroll, Lyons had been underestimated when he assumed office in 1932 and as leader he demonstrated: "a combination of honesty, native shrewdness, tact, administrative ability, common sense, good luck and good humour that kept him in the job longer than any previous Prime Minister except Hughes". Lyons was assisted in his campaigning by his politically active wife, Enid Lyons. She had a busy official role from 1932 to 1939 and, following her husband's death, stood for Parliament herself, becoming Australia's first female Member of the House of Representatives, and later first woman in Cabinet, joining the Menzies Cabinet in 1951.
Preparation for war.
Defence issues became increasingly dominant in public affairs with the rise of fascism in Europe and militant Japan in Asia. The UAP largely supported the western powers in their policy of appeasement, however veteran UAP minister Billy Hughes was an exception and he embarrassed the government with his 1935 book "Australia and the War Today" which exposed a lack of preparation in Australia for what Hughes correctly supposed to be a coming war. Hughes was forced to resign, but the Lyons government tripled its defence budget.
On 7 April 1939, with the storm clouds of the Second World War gathering in Europe and the Pacific, Joseph Lyons became the first Prime Minister of Australia to die in office. Driving from Canberra to Sydney, en route to his home in Tasmania for Easter, he suffered a heart attack, dying soon after in hospital in Sydney, on Good Friday. The UAP's Deputy leader, Robert Menzies, had resigned in March, citing the coalition's failure to implement a plan for national insurance. In the absence of a UAP deputy, the Governor-General, Lord Gowrie, appointed Country Party leader Sir Earle Page as his temporary replacement, pending the selection of Lyons' successor by the UAP.
Menzies Government.
Robert Menzies defeated Hughes for the UAP leadership and became Prime Minister on 26 April 1939. Page refused to serve under Menzies, leaving the UAP with a minority government.
In addition to the office of Prime Minister, Menzies served as Treasurer. The First Menzies Ministry included the ageing former Prime Minister Billy Hughes and the young future Prime Minister Harold Holt. Menzies tried and failed to have the issue of national insurance examined by a committee of parliamentarians. Though no longer in formal coalition, his government survived because the Country Party preferred a UAP government to that of a Labor government.
World War II.
The growing threat of war dominated politics through 1939. Menzies supported British policy against Hitler's Germany (negotiate for peace, but prepare for war) and – fearing Japanese intentions in the Pacific – established independent embassies in Tokyo and Washington in order to receive independent advice about developments. Menzies announced Australia's entry into World War Two on 3 September 1939 as a consequence of Nazi Germany's invasion of Poland. Australia was ill-prepared for war. A National Security Act was passed, the recruitment of a volunteer military force for service at home and abroad was announced, the 2nd Australian Imperial Force, and a citizen militia was organised for local defence.
Troubled by Britain's failure to increase defences at Singapore, Menzies was cautious in committing troops to Europe, nevertheless in 1940–41, Australian forces played prominent roles in the fighting in the Mediterranean theatre.
A special War Cabinet was created;– initially composed of Menzies and five senior ministers (RG Casey, GA Street, Senator McLeay, HS Gullet and World War I Prime Minister Billy Hughes). In January 1940, Menzies dispatched potential leadership rival Richard Casey to Washington as Australia's first "Minister to the United States". In a consequent by-election, the UAP suffered a heavy defeat and Menzies re-entered coalition negotiations with the Country Party. In March 1940, troubled negotiations were concluded with the Country Party to re-enter Coalition with the UAP. The replacement of Earl Page as leader by Archie Cameron allowed Menzies to reach accommodation. A new Coalition ministry was formed including a number of country party members.
With the 1940 election looming, Menzies lost his Chief of the General Staff and three loyal ministers in a Royal Australian Airforce crash at Canberra airport. The Labor Party meanwhile experienced a split along pro and anti Communist lines over policy towards the Soviet Union for its co-operation with Nazi Germany in the invasion of Poland. The Communist Party of Australia (CPA) opposed and sought to disrupt Australia's war effort. Menzies banned the CPA after the fall of France in 1940, but by 1941 Stalin was forced to join the allied cause when Hitler reneged on the Pact and invaded the USSR. The USSR came to bear the brunt of the carnage of Hitler's war machine and the Communist Party in Australia lost its early war stigma as a result.
At the general election in September 1940, there was a large swing to Labor and the UAP-Country Party coalition lost its majority, continuing in office only because of the support of two independent MPs, Arthur Coles and Alexander Wilson. The UAP–Country Party coalition and the Labor parties won 36 seats each. Menzies proposed an all party unity government to break the impasse, but the Labor Party under John Curtin refused to join. Curtin agreed instead to take a seat on a newly created Advisory War Council in October 1940. New Country Party leader Arthur Fadden became Treasurer and Menzies unhappily conceded to allow Earle Page back into his ministry.
In January 1941, Menzies flew to Britain to discuss the weakness of Singapore's defences and sat with Winston Churchill's British War Cabinet. En route he inspected Singapore's defences – finding them alarmingly inadequate – and visited Australian troops in the Mid-East. He at times clashed with Churchill in the War Cabinet, and was unable to achieve significant assurances for increased commitment to Singapore's defences, but undertook morale boosting excursions to war affected cities and factories and was well received by the British press and generally raised awareness in Britain of Australia's contribution to its war effort. He Returned to Australia via Canada and the United States - addressing the Canadian parliament and lobbying President Roosevelt for more arms production. After four months, Menzies returned to Australia to face a lack of enthusiasm for his global travels and a war-time minority government under ever increasing strain.
In Menzies's absence, Curtin had co-operated with Fadden in preparing Australia for the expected Pacific War. With the threat of Japan imminent and with the Australian army suffering badly in the Greek and Crete campaigns, Menzies re-organised his ministry and announced multiple multi-party committees to advise on war and economic policy. Government critics however called for an all-party government.
Menzies resignation.
In August, Cabinet decided that Menzies should travel back to Britain to represent Australia in the War Cabinet – but this time the Labor caucus refused to support the plan. Menzies announced to his Cabinet that he thought he should resign and advise the Governor General to invite Curtin to form Government. The Cabinet instead insisted he approach Curtin again to form a war cabinet. Unable to secure Curtin's support, and with an unworkable parliamentary majority, Menzies faced continuing problems with the administration of the war effort and the undermining of his leadership by members of his own coalition. Menzies resigned as Prime Minister and leader of the UAP on 29 August 1941.
Fadden Government.
Although the UAP had been in government for a decade, it was so bereft of leadership that it was forced to turn to Hughes as its new leader. However, Hughes was a month shy of 78 years old, and was deemed too old and too frail to be a wartime Prime Minister. Under the circumstances, a joint UAP–Country Party meeting chose Fadden to be his successor as Prime Minister, even though the Country Party was nominally the junior partner in the coalition. Hughes became Attorney-General and Minister for the Navy in Fadden's cabinet. With Menzies out and the aged Hughes seen as a stop-gap leader, UAP members jostled for position.
Australia marked two years of war on 7 September 1941 with a day of prayer, on which Prime Minister Fadden broadcast to the nation an exhortation to be united in the ‘supreme task of defeating the forces of evil in the world". With the Pacific on the brink of war, Opposition leader John Curtin offered friendship and co-operation to Fadden, but refused to join in an all-party wartime national government.
Coles and Wilson were angered at how Menzies had been treated, and on 3 October voted with the Opposition in the House of Representatives to reject Fadden’s budget. Fadden promptly resigned—to date, the last time a sitting government has been defeated in the House. Under the prodding of Governor-General Lord Gowrie, who wanted to avoid calling an election given the dangerous international situation, Coles and Wilson threw their support to Labor. Gowrie then duly swore Curtin in as Prime Minister on 7 October 1941. Eight weeks later, Japan attacked Pearl Harbor.
Demise of the party.
Having spent all but eight months of its existence prior to 1941 in government, the UAP was ill-prepared for a role in opposition. Curtin proved a popular leader, rallying the nation in the face of the danger of invasion by the Japanese after Japan's entry into the war in December 1941. Even allowing for the advantages a sitting government has in wartime, the Labor government seemed more effective than its predecessor. Fadden and Hughes were unable to get the better of Curtin. By the time the writs were issued for the 1943 federal election, the Coalition had sunk into near paralysis. At the election, the Coalition suffered a massive defeat and was reduced to only 19 seats nationwide, including 12 for the UAP.
After this election defeat Menzies returned to the UAP leadership, and Fadden handed the post of opposition leader to him as well. However, the party and its organisation now seemed moribund. UAP branches tended to become inactive between elections, and its politicians were seen as compromised by their reliance on large donations from business and financial organisations.
Menzies was convinced that the UAP was no longer viable, and a new anti-Labor party needed to be formed to replace it. On 31 August 1945 the UAP was folded into the newly formed Liberal Party of Australia, with Menzies as leader. The Liberal Party went on to become the dominant centre-right party in Australian politics. After an initial loss to Labor at the 1946 election, Menzies led the new non-Labor Coalition of the Liberal and Country parties to victory at the 1949 election against the incumbent Labor government led by Curtin's successor, Ben Chifley. The Coalition stayed in office for a record 23 years.

</doc>
<doc id="32181" url="http://en.wikipedia.org/wiki?curid=32181" title="USS Scorpion">
USS Scorpion

USS Scorpion may refer to:

</doc>
<doc id="32184" url="http://en.wikipedia.org/wiki?curid=32184" title="Joint Intelligence Committee (United Kingdom)">
Joint Intelligence Committee (United Kingdom)

The Joint Intelligence Committee (JIC) is the part of the British Cabinet Office responsible for directing the national intelligence organisations of the United Kingdom on behalf of the Cabinet of the United Kingdom and providing advice to the Cabinet related to security, defence and foreign affairs. It oversees the setting of priorities for the three intelligence and security agencies (Secret Intelligence Service, Security Service, GCHQ), as well as Defence Intelligence, and establishes professional standards for intelligence analysis in government.
Structure.
The JIC is subject to oversight by the Intelligence and Security Committee. The Committee is chaired by a permanent chairman, a member of the Senior Civil Service, and is supported by the Joint Intelligence Organisation which includes an assessments staff. The assessment staff is made up of experienced senior analysts drawn from across government and the military and conducts all-source analysis on subjects of interest to the committee. JIC papers draw input from across the intelligence and security agencies and other related bodies.
Membership comprises the heads of the three collection agencies—the Secret Intelligence Service, Security Service and GCHQ—the Chief of Defence Intelligence, Deputy Chief of Defence Intelligence Staff, the Chief of the Assessment Staff, representatives of the Ministry of Defence, Foreign and Commonwealth Office and other departments, and the Prime Minister's adviser on foreign affairs.
Function.
The JIC has three functions:
Requirements and priorities.
The JIC drafts the annual Requirements and Priorities for collection and analysis, for approval by Ministers. These support the strategic national security objectives of the UK:
History.
The JIC was founded in 1936 as a sub-committee of the Committee of Imperial Defence, the advisory peacetime defence planning agency. During World War II, it became the senior intelligence assessment body in the UK. In 1957 the JIC moved to the Cabinet Office, where its assessments staff prepare draft intelligence assessments for the committee to consider.
Since founding, the Committee's Chair has been as follows:
Foreign involvement.
Ever since World War II, the chief of the London station of the United States Central Intelligence Agency has attended the JIC's weekly meetings. One former US intelligence officer has described this as the "highlight of the job" for the London CIA chief. Resident intelligence chiefs from Australia, Canada, and New Zealand may attend when certain issues are discussed.
Role in the Iraq dossier.
The JIC recently played a controversial role in compiling a dossier in which the UK government set out the threat posed by Iraq's Weapons of Mass Destruction in the run up to war. There were allegations that the dossier was "sexed up" prior to publication in order to bolster the case for military action. Evidence that the wording of the dossier was "strengthened" was presented to the Hutton Inquiry, a judicial review set up to investigate the circumstances leading up to the death of an eminent government weapons expert, David Kelly, who had criticised the wording of the dossier in off-the-record briefings to journalists. Dr. Kelly committed suicide shortly after his identity was confirmed to the media by the government. JIC members John Scarlett and Sir Richard Dearlove (then head of MI6, the Secret Intelligence Service) gave evidence to the Inquiry in which they argued that the words used in the dossier were consistent with their assessment of the intelligence available at the time.
Despite the work of the 1400 strong Iraq Survey Group in post-war Iraq, no evidence of actual WMD capability has so far been uncovered; according to its final report in September 2004. The US and UK Governments both announced investigations into the assessment of WMD intelligence in the run up to war. The British inquiry, headed by Lord Butler of Brockwell, in its report in July 2004, while critical of the British intelligence community, did not recommend that anyone should resign. Similarly, the US Senate Intelligence Committee, while critical of US intelligence officials, did not recommend any resignations in its report, also issued in July 2004.

</doc>
<doc id="32186" url="http://en.wikipedia.org/wiki?curid=32186" title="USS Ohio">
USS Ohio

USS "Ohio" may refer to:

</doc>
<doc id="32187" url="http://en.wikipedia.org/wiki?curid=32187" title="USS Kitty Hawk (CV-63)">
USS Kitty Hawk (CV-63)

The supercarrier USS "Kitty Hawk" (CV-63), formerly CVA-63, is the second naval ship named after Kitty Hawk, North Carolina, the site of the Wright brothers' first powered airplane flight. "Kitty Hawk" was both the first and last active ship of her class, and the last oil fired aircraft carrier in service with the United States Navy.
"Kitty Hawk" was laid down by the New York Shipbuilding Corporation, Camden, New Jersey, 27 December 1956; and launched 21 May 1960, sponsored by Mrs. Camilla F. McElroy, wife of Secretary of Defense Neil H. McElroy; and commissioned 21 April 1961 at Philadelphia Naval Shipyard, Captain William F. Bringle in command.
"Kitty Hawk" was launched by flooding her drydock. A conventional slide down ways was ruled out because of her mass and the risk of impact with the Philadelphia shore on the far side of the Delaware River.
With the decommissioning of "Independence" on 30 September 1998, "Kitty Hawk" became the United States warship with the second longest active status in the Navy – the sailing ship in Boston Harbor is still retained on active Navy status. At the start of 2013, this status had been surpassed by only one other ship, the "Enterprise" prior to her inactivation in 2012. With this title came the distinction of being one of only two aircraft carriers ever to be honored with flying the First Navy Jack. This came to an end with an instruction dated 31 May 2002, where the Secretary of the Navy directed all United States Navy ships to fly this flag in honor of those killed in the 11 September 2001 attacks for the duration of the War on Terrorism.
For 10 years, "Kitty Hawk" was the forward-deployed carrier at Yokosuka Naval Base in Yokosuka, Japan. In October 2008, she was replaced in this role by the "George Washington". "Kitty Hawk" then returned to the United States and had her decommissioning ceremony on 31 January 2009. She was officially decommissioned on 12 May 2009 after almost 49 years of service. "Kitty Hawk" was replaced by the "George H.W. Bush".
1961 to 1964.
Following a shakedown in the Western Atlantic, "Kitty Hawk" departed Naval Station Norfolk, Norfolk, Virginia on 11 August 1961. After a brief stop at Rio de Janeiro, Brazil, where she embarked the Secretary of the Brazilian Navy for a demonstration of exercise at sea with five Brazilian destroyers, the attack carrier rounded Cape Horn on 1 October. She steamed into Valparaíso, Chile on 13 October and then sailed two days later for Peru, arriving in Callao on 20 October where she entertained the President of Peru. At San Diego, Admiral George W. Anderson, Chief of Naval Operations, landed on her deck 18 November to witness antisubmarine demonstrations by "Henry B. Wilson" and "Blueback", a Terrier missile demonstration by "Topeka" and air demonstrations by "Kitty Hawk".
"Kitty Hawk" entered San Francisco Naval Shipyard on 23 November 1961 for alterations. Following operations out of San Diego, she sailed from San Francisco on 13 September 1962. "Kitty Hawk" joined the United States Seventh Fleet on 7 October 1962, relieving "Midway" as the flagship.
After participating in the Philippine Republic Aviation Week Air Show, "Kitty Hawk" steamed out of Manila Harbor on 30 November 1962, and welcomed Admiral Harry D. Felt, Commander in Chief, United States Pacific Fleet, for a demonstration of modern naval weapons on 3 December. The ship visited Hong Kong early in December and returned to Japan, arriving at Yokosuka on 2 January 1963.
In conjunction with Commander, Carrier Division Seven, "Kitty Hawk" carried out several exercises in January and February 1963. On 4 January 1963, Operation Checkertail saw "Kitty Hawk" and three other attack aircraft carriers launch practice airstrikes against the Okinawa Air Defense Command. From 27 January – 2 February 1963, 'Picture Window III' saw 'foreign aircraft' intercepted and visually identified in the Northern Japan area. Though the official ship's papers released in 2011 do not identify the nationality, it is likely that the 'foreign aircraft' in question were from the Soviet Far Eastern Military District or Soviet Naval Aviation. From 16–19 February 1963, Exercise 'Red Wheel,' was conducted around Southern Japan also under the direction of Commander, Carrier Division Seven. It aimed to improve the United States Seventh Fleet's ability to conduct conventional and nuclear warfare while maintaining defense against air and submarine attack. It also aimed to evaluate the capability of 'the HUK [Hunter-Killer] Group' to protect two CVA Task Groups. During these exercises, the ship visited Kobe, Beppu and Iwakuni before returning to San Diego on 2 April 1963.
On 6 June 1963, President John F. Kennedy, with top civilian and military leaders, boarded "Kitty Hawk" to witness a carrier task force weapons demonstration off the California coast. Addressing the men of the task group from "Kitty Hawk", President Kennedy told them that, as in the past, control of the seas still means security, peace and ultimate victory. He later wrote to President and Madame Chiang Kai-Shek who had witnessed a similar demonstration on board "Constellation": "I hope you were impressed as I was, on my visit to "Kitty Hawk", with the great force for peace or war, which these mighty carriers and their accompanying escorts provide, helping to preserve the freedom of distant nations in all parts of the world."
Film director John Frankenheimer filmed shots for the movie "Seven Days in May" on board the vessel in 1963.
Following a series of strike exercises and tactics reaching along the California coast and off Hawaii, "Kitty Hawk" again sailed for the Far East. While approaching Japan, she learned an assassin had shot President Kennedy. Flags were at half mast as she entered Sasebo Harbor on 25 November 1963, the day of the President's funeral and, as senior ship present, she had the sad honor of firing memorial salutes. After cruising the South China Sea and ranging to the Philippines in readiness operations with the 7th Fleet, she returned to San Diego on 20 July 1964.
1965 to 1972.
"Kitty Hawk" overhauled in Puget Sound Naval Shipyard, then trained along the western seaboard. She sailed from San Diego on 19 October 1965, for Hawaii thence to Subic Bay, Philippines, where she prepared for combat operations off the coast of Vietnam.
"Kitty Hawk" was awarded the Presidential Unit Citation for action off Vietnam during the Tet Offensive and the Navy Unit Meritorious ribbon for exceptionally meritorious service from 26 November 1965 – 14 May 1966 while participating in combat operations displayed undaunted spirit, courage, professionalism and dedication to maintain their ship as a fighting unit under the most arduous operating conditions to enable her pilots to destroy vital military targets in North Vietnam despite intense opposition and extremely adverse weather conditions.
Scenes from the 1966 Walt Disney comedy "Lt. Robin Crusoe, U.S.N." were filmed aboard the warship.
"Kitty Hawk" returned to San Diego in June 1966 for overhaul and training until 4 November 1966, when she again deployed to serve in waters of Southeast Asia. "Kitty Hawk" arrived at Yokosuka, Japan on 19 November to relieve "Constellation" as flagship for Rear Admiral David C. Richardson, Commander Task Force 77. On 26 November, "Kitty Hawk" departed Yokosuka for Yankee Station via Subic Bay, and on 5 December, aircraft from "Kitty Hawk" began their around-the-clock missions over North Vietnam. About this time "Kitty Hawk" — already accustomed to celebrities as guests – entertained a number of prominent visitors: William Randolph Hearst, Jr.; Bob Considine; Dr. Billy Graham; Nancy Sinatra and John Steinbeck, among others. She remained in the Far East supporting the U.S. in Southeast Asia until departing Subic Bay on 28 May 1967. Steaming via Japan, the carrier reached San Diego on 19 June and a week later entered the naval shipyard at Long Beach for maintenance. "Kitty Hawk" returned to San Diego on 25 August and began a rigorous training program to prepare her for future action.
On 12 October 1972 during the Vietnam War, "Kitty Hawk" was en route to her station in the Gulf of Tonkin when a racial riot involving more than 200 sailors broke out. According to crew members, the riot began over a grilled-cheese sandwich. Nearly 50 sailors were injured in this widely-publicized incident. This incident resulted in a Congressional inquiry into discipline in the Navy.
1973 to 1977.
From January through July 1973, "Kitty Hawk" changed home ports from San Diego to San Francisco. "Kitty Hawk" moved into dry dock on 14 January 1973, and work began to convert the ship from an attack (CVA) to a multi-mission carrier (CV). The "CV" designation indicated that "Kitty Hawk" was no longer strictly an attack carrier, in that anti-submarine warfare would also become a major role. "Kitty Hawk" became the first Pacific Fleet carrier to carry the multi-purpose "CV" designation. The conversion consisted of adding 10 new helicopter calibrating stations, installing sonar/sonobuoy readout and analysis center and associated equipment, and changing a large portion of the ship's operating procedures. One of the major equipment/space changes in the conversion was the addition of the Anti-Submarine Classification and Analysis Center (ASCAC) in the CIC area. ASCAC worked in close conjunction with the anti-submarine warfare aircraft assigned aboard Carrier Air Wing 11. During the yard period, the Engineering Department underwent a major change in its propulsion plant. The Navy Standard Oil (black oil) fuel system was completely converted to Navy Distillate Fuel. The Air Department added several major changes to the flight deck, including enlarging the jet blast deflectors (JBD) and installing more powerful catapults in order to handle the new Grumman F-14 Tomcat, which "Kitty Hawk" was standing by to receive for its next deployment. Enlarging JBD#1 meant the No. 1 Aircraft Elevator had to be redesigned, making "Kitty Hawk" the only carrier at the time having an aircraft elevator which tracked from the hangar deck to the flight deck angling out 6°. "Kitty Hawk" moved out of dry dock on 28 April 1973, and the next day, on her 12th birthday, was named a Multi-Purpose Aircraft Carrier (CV).
After much needed upgrades and modifications to "Kitty Hawk"‍ '​s systems, she departed Hunters Point navy shipyards in San Francisco to begin "sea trial" exercises and then made a short three-day layover in Pearl Harbor for some crew R&R. She then departed for the China Sea and Southeast Asia for additional maneuvers. However while en route, during repairs to the ship's fuel oil systems in the No. 1 machinery room on December 11, 1973, a flange gasket failed in one of the fuel transfer tubes of JP5 that pass through Number 1 engine room. Jet fuel was sprayed, atomized, and ignited and the ship went to General Quarters for nearly 38 hours. Due to the massive amounts of thick black smoke the crew was ordered topside to flight deck until the fire could be controlled and smoke cleared. Because two and then three of the ship's four propulsion systems had to be shut down during the fire, "Kitty Hawk" began list to about 7 degrees portside and as a result many of the aircraft were moved starboard in an attempt to balance the ship until the fire was finally brought under control and two propulsion systems restored. "Kitty Hawk" was forced off her course and maneuvers and then headed toward the Philippines where she ported in Subic Bay until the ship's damage could be assessed and repairs could be made, but there would be three days of waiting before reaching port. Six enlisted sailors died in the fire: FR Michael Deverich, FR Linn Schambers, FR Kevin Johnson, FA Alan Champine, Samuel Cardenas and FA Joseph Tulipana. Thirty-four sailors were treated for smoke inhalation and several minor injures and one sailor for a broken wrist reported. The bodies of those men who died in the fire were escorted home by members of their respective divisions and it was reported that no official honor guards or military processions were provided for during their memorial services.
As a result of the deaths of the six crew members, on 10 January 1974 an investigation was ordered by Rear Admiral Donald C. Davis, Commander of Carrier Group 1 and Senior Officer on board "Kitty Hawk" designated as his flagship. Although initial reports lay blame to one of the six men who perished in the tragic fire, upon conclusion of the investigation filed by the Department of the Navy, Commander Seventh Fleet, several opinions on causes were noted within the investigation which included but not limited to the Fourth Endorsement on Captain Kenneth L. Shugart, USN. The investigative report of 10 January 1974, section 3, paragraph 3 stated "The replacement of the defective gasket in the strainer cover assembly by Fireman Apprentice Kevin W. Johnson (deceased) reflected, in the words of the investigating officer, poor judgment and unsound maintenance practices." Further "Fireman Apprentice Johnson was therefore negligent in the performance of his duties." However, in consonance with the investigating officer, the opinion is expressed that under the circumstances, the maintenance deficiencies noted herein constitute simple, rather than culpable, negligence."
In light of the efforts made by all six navy personnel, FA Cardenas, Champine and Tulipana, and FR Deverich, Schambers and Johnson assigned to the machinery room on 11 December 1973, who all died during the suppression efforts, "It has administratively been determined each were posthumously awarded the Navy and Marine Corps Medal for their heroic devotion to duty in fighting the fire which is the subject of this investigative report."
"Kitty Hawk" stayed busy throughout the mid-1970s with numerous deployments to the Western Pacific and involvement in a large number of exercises, including RIMPAC in 1973 and 1975. "Kitty Hawk" departed San Diego on 8 March 1976, and on 12 March entered dry dock at Puget Sound Naval Shipyard in Bremerton, Washington, to commence a US$100 million complex overhaul, scheduled to last just more than 12 months. This overhaul configured "Kitty Hawk" to operate with the F-14 and S-3A "Viking" aircraft in a total CV sea control mode. This included adding spaces for storage, ordnance handling and maintenance facilities for the two aircraft. Also included in the work package were more efficient work areas for airframes and a repair facility for ground support equipment and the addition of avionics support capability for the S-3. The ship also replaced the Terrier Surface-to-Air missile system with the NATO Sea Sparrow system, and added elevators and modified weapons magazines to provide an increased capability for handling and stowing the newer, larger air-launched weapons. "Kitty Hawk" completed the overhaul in March 1977, and departed the shipyard 1 April of that year to return to San Diego. After a six-month pre-deployment workup, "Kitty Hawk" departed NAS North Island 25 September 1977 for another WESTPAC and returned 15 May 1978.
1979 to 1998.
In May 1979, the ship teamed with Carrier Air Wing 15 for another WESTPAC deployment. Her duties included search and assistance operations to aid refugees in small boats fleeing the Socialist Republic of Vietnam.
During that deployment, "Kitty Hawk" also offered contingency support off the coast of Korea following the assassination of Republic of Korea President Park Chung Hee. The deployment was then extended two-and-a-half months to support contingency operations in the North Arabian Sea during the Iran hostage crisis. For their actions in the region, "Kitty Hawk" and CVW-15 were awarded the Navy Expeditionary Medal.
"Kitty Hawk" had a cameo appearance in the 1980 movie "The Final Countdown", standing in for "Nimitz". On her way home from her WESTPAC deployment, "Kitty Hawk" was filmed entering Pearl Harbor with the crew manning the rails as the ship passed the USS "Arizona" Memorial. (At the time of the filming, "Nimitz" was still an Atlantic Fleet, vice Pacific Fleet, aircraft carrier.) "Kitty Hawk" returned to San Diego in late February 1980 and was also awarded the Meritorious Unit Commendation and the Naval Air Force Pacific Battle Efficiency "E" Award as the best carrier in the Pacific Fleet.
In April 1981, "Kitty Hawk" left San Diego for her thirteenth deployment to the Western Pacific. Following the cruise, the crew was awarded the Navy Expeditionary Medal and the Humanitarian Service Medal for the rescue of Vietnamese refugees in the South China Sea.
In January 1982, "Kitty Hawk" returned to Bremerton for another year-long overhaul. Following the comprehensive upgrade and a vigorous training period with Carrier Air Wing 2, "Kitty Hawk" deployed in 1984 as the flagship for Battle Group Bravo. "Kitty Hawk" logged more than 62000 mi on this deployment and remained at "Station Gonzo" in the north Arabian Sea for more than 60 consecutive days.
In March 1984, "Kitty Hawk" participated in "Team Spirit" exercises in the Sea of Japan. The Soviet Victor-class nuclear attack submarine "K-314" shadowed the task group. On 21 March 1984, at the end of the Sea of Japan part of the exercise, "K-314" surfaced directly in front of "Kitty Hawk", time was 22:05, too dark and far too close for "Kitty Hawk" to see and avoid the resulting collision, with minor damage to the aircraft carrier, and significant damage to the Soviet submarine. At the time of the accident, "Kitty Hawk" is estimated to have carried several dozen nuclear weapons, and "K-314" probably carried two nuclear torpedoes. "Kitty Hawk" was thereafter considered the first antisubmarine carrier weapon and a red submarine was painted on her island near the bridge but was ordered removed upon return to home port North Island San Diego, CA.
"Kitty Hawk" went to the U.S. Naval Base at Subic Bay in the Philippines for repairs. A piece of one of "K-314"‍ '​s propellers was embedded in "Kitty Hawk"‍ '​s bow, as were some chunks of the Soviet anechoic coating, from scraping along the side of the submarine. The result was something of an "accidental" intelligence coup for the U.S. Navy.
The ship returned to San Diego on 1 August 1984. Seven months later, "Kitty Hawk" was awarded another Battle Efficiency "E" Award.
In July 1985, "Kitty Hawk" and CVW-9 deployed again as flagship for Battle Group Bravo. "Kitty Hawk" and CVW-9 combined to set a standard for operations, completing their second consecutive fatality-free deployment.
CVW-9 crews logged more than 18,000 flight hours and 7,300 arrested landings while "Kitty Hawk" maintained her catapults and arresting gear at 100 percent availability.
In 1986, during pre-cruise exercises, 1 Airman was killed during flight operations when he was struck by an aircraft while checking "elongs" during a launch.
"Kitty Hawk" bid farewell to San Diego on 3 January 1987, as the ship departed her home port of 25 years and set out on a six-month world cruise. During the circumnavigation, "Kitty Hawk" and CVW-9 again showed their commitment to safety by conducting a third fatality-free deployment . "Kitty Hawk" spent 106 consecutive days on station in the Indian Ocean and was again awarded the Navy Expeditionary Medal and the Meritorious Unit Commendation for its service. The world cruise ended at the Philadelphia Naval Shipyard on 3 July. Six months later, "Kitty Hawk" began a Service Life Extension Program (SLEP) overhaul. "Kitty Hawk" emerged from the yards on 2 August 1990. The overhaul was estimated to have added 20 years of service to the ship. The Aircraft Intermediate Maintenance Department was also awarded the Air Forces, US Pacific Fleet Departmental Excellence Award, the Black "E" for this deployment.
With the return of CVW-15 to its decks, "Kitty Hawk" began its second deployment around "the Horn" of South America to her original home port of San Diego on 11 December 1991, performing Gringo-Gaucho with the Argentine Naval Aviation during the transit.
On 1 August 1992, "Kitty Hawk" was appointed as Naval Air Force Pacific's "ready carrier." The ship embarked Commander, Cruiser-Destroyer Group 5; Commander, Destroyer Squadron 17 and CVW-15 for three months of work-ups before deploying to the Western Pacific on 3 November 1992. While on deployment, "Kitty Hawk" spent nine days off the coast of Somalia supporting U.S. Marines and coalition forces involved in Operation Restore Hope. In response to increasing Iraqi violations of United Nations sanctions, the ship rushed to the Persian Gulf on 27 December 1992. Just 17 days later, "Kitty Hawk" led a joint coalition offensive strike against designated targets in southern Iraq.
"Kitty Hawk" set sail on her 17th deployment 24 June 1994, with the goal of providing a stabilizing influence operating in the Western Pacific during a time of great tension in the Far East, particularly concerning North Korea.
In 1995, "Kitty Hawk" embarked airwing transitioned to CVW-11, marking a change to a single F-14 squadron, and 3 F/A-18 squadrons.
"Kitty Hawk" began her 18th deployment, this time with CVW-11, in October 1996. During the six-month underway period, the ship visited ports in the Persian Gulf and Western Pacific. The carrier made a rare visit to Hobart, Tasmania as well as being only the second carrier to ever stop in Manama, Bahrain. "Kitty Hawk" returned to San Diego 11 April 1997, immediately beginning a 15-month, $110 million overhaul, including three months in dry dock in Bremerton, from January to March 1998.
1998 to 2008 (Homeport: Yokosuka).
"Kitty Hawk" departed San Diego on 6 July 1998, to assume new duties as America's only permanently forward-deployed aircraft carrier from "Independence". "Kitty Hawk" also welcomed aboard Carrier Air Wing 5, operating from Naval Air Facility Atsugi, Japan. "Kitty Hawk" arrived at her new operating location of U.S. Fleet Activities Yokosuka, Japan, on 11 August 1998.
With the decommissioning of "Independence" on 30 September 1998, "Kitty Hawk" became the second-oldest active warship in the US Navy and was authorized to fly the First Navy Jack.
"Kitty Hawk" set sail for a planned three-month underway period 2 March 1999, which included Exercise Tandem Thrust off Guam. Following the exercise, the "Kitty Hawk"/CVW-5 team was ordered to the Persian Gulf to enforce the No-Fly Zone over Southern Iraq. CVW-5 pilots flew more than 8,800 sorties in 116 days, including 1,300 combat sorties, dropping more than 20 tons of ordnance. On the return trip to Japan, "Kitty Hawk" made port visits to Perth, Western Australia, and Pattaya, Thailand. "Kitty Hawk" returned to Yokosuka 25 August 1999. She was again underway to the Sea of Japan 22 October to participate in Exercises Foal Eagle and AnnualEx 11G.
On 11 April 2000, "Kitty Hawk" departed Yokosuka, Japan for routine local area operations and to participate in Exercise Cobra Gold with the navies of Singapore and Thailand. "Kitty Hawk" participated in Exercise Foal Eagle in Fall 2000, and deployed again in March 2001 for a Spring underway period with a historic stop. On 22 March, "Kitty Hawk" became the first aircraft carrier to ever moor pier-side in Singapore, as the ship visited the brand new Changi Pier, located at the Republic of Singapore Navy's Changi Naval Base. On 29 April, shortly after a visit to Guam, "Kitty Hawk" celebrated 40 years of active service as the ship and crew sailed south to participate in Exercise Tandem Thrust 2001 with the Australian and Canadian navies. The ship returned to Yokosuka 11 June 2001.
On 17 October 2000, and again in 9 November 2000, "Kitty Hawk" was buzzed by a group of Russian warplanes in the Sea of Japan, which proceeded to take pictures of the reaction on deck. General Anatoly Kornukov, then Russian air force's commander in chief, stated that the Russian warplanes managed to evade "Kitty Hawk"‍ '​s antiaircraft defense system and that "In the pictures, you can clearly see the panic on deck."
In October 2001, "Kitty Hawk" deployed to the North Arabian Sea for the beginning of Operation Enduring Freedom. The ship served as an afloat forward staging base for the 160th Special Operations Aviation Regiment, with a reduced air wing.
In April 2002, "Kitty Hawk" was underway for her scheduled spring training. Along with a Guam port call, the spring underway included port visits to Singapore and Hong Kong, where the crew celebrated "Kitty Hawk"‍ '​s 41st birthday. In the fall of 2002, "Kitty Hawk" was training in the Western Pacific. "Kitty Hawk" and her battle group combined with U.S. Air Force units and elements of the Japan Maritime Self Defense Force to conduct AnnualEx 14G in the waters surrounding Japan. Later, the ship and her crew made a port visit to Hong Kong.
On 11 September 2002, all US Navy ships were ordered to fly the First Navy Jack.
The ship once again departed Yokosuka on 23 January 2003 for a routine training mission, but a short time later, orders were received to transit to the U.S. Central Command area of responsibility to support the Global War on Terrorism and to prepare for future contingencies. "Kitty Hawk" was soon involved in Operations Southern Watch and Iraqi Freedom in the North Persian Gulf. Although the cruise was originally intended to be short, the ship ended up serving 110 continuous days at sea. "Kitty Hawk" returned to Yokosuka on 6 May 2003, immediately entering an extensive dry-dock period, or dry-docking ship's restricted availability (DSRA), that lasted until October of that year.
On 3 July 2005, "Kitty Hawk" pulled in at Sydney, Australia, for shore leave. Later, during the same cruise, "Kitty Hawk" made a port call in Guam for four days. In November 2005, "Kitty Hawk" anchored at Hong Kong, and was there for Thanksgiving. In June 2005, after a six-month ship's restricted availability (SRA) period, the "Kitty Hawk" once again got underway, and was overflown by a Russian Il-38, which is on the Japanese island of Hokkaidō. In August 2006, the carrier pulled into Fremantle, Australia for shore leave. In September 2006, "Kitty Hawk" made the final port call of her Summer deployment at Pattaya, Thailand, after which she returned to her home port of Yokosuka.
In October 2006, "Kitty Hawk" and her escort warships were undergoing exercises near Okinawa, and a Chinese "Song"-class submarine shadowed the group then surfaced within 5 mi of the group on 26 October 2006. It was considered to be quite rare for Chinese subs to operate that far from their home ports on the mainland, though with this incident that may be changing. Reports claim that the submarine had been undetected until it surfaced. In 2009, Timothy J. Keating, commander of the United States Pacific Command, commented on the issue, stating that the carrier was "in a very relaxed posture. If there were some heightened state of tension, we would, believe me, we would not let them get that close."
On 11 January 2007, "Kitty Hawk" entered a scheduled period of maintenance in Yokosuka, her place being taken by "Ronald Reagan" which made an unscheduled deployment three weeks later. This refit is "smaller than the one the ship completed [in 2006]", which took six months.
On 5 July 2007, "Kitty Hawk" pulled in at Sydney, Australia, for six days of shore leave after participating in Exercise Talisman Sabre.
On 21 September 2007, "Kitty Hawk" pulled into Yokosuka, Japan, after a four-month summer deployment.
In November 2007, "Kitty Hawk" and other US Navy ships performed a joint military exercise, in the Bay of Bengal. Other nations that took part in this exercise were Australia, India, Japan and Singapore. Later that month, "Kitty Hawk" was scheduled to dock at Hong Kong for Thanksgiving. However, China denied entry to "Kitty Hawk" and the rest of her carrier group. China then reversed its position based on humanitarian grounds but by that time, "Kitty Hawk" was too far away to dock in time for the holiday. The cause of the Chinese refusal remains unclear.
"Kitty Hawk" was deployed off the coast of China along with two other ships during the Taiwan election on 20 March 2008. After the elections, she entered Hong Kong for the last time.
On 28 May 2008, "Kitty Hawk" departed Japan for the last time. to be replaced in Japan by "George Washington". However, during "George Washington"'s transit of the Pacific Coast of South America en route to the planned turnover with "Kitty Hawk" in Hawaii, a major fire broke out that led to "Washington" diverting to San Diego for repairs. This led to the US Navy retaining "Kitty Hawk" in Hawaii to take part in the RIMPAC 2008 exercises in June and July. On 7 August 2008, "Kitty Hawk" arrived at NAS North Island.
Retirement.
On 1 December 2005, the United States Navy announced that "George Washington" would replace "Kitty Hawk" in 2008 as the forward-deployed carrier in Japan and it would also assume host carrier duties for forward deployed Carrier Air Wing 5.
In March 2007, the Navy announced that Captain Todd Zecchin, the captain responsible during the decommissioning of "John F. Kennedy", had been tasked with overseeing the decommissioning of "Kitty Hawk".
"Kitty Hawk" left Yokosuka on 28 May 2008 to begin the decommissioning process. However on 22 May, a fire seriously damaged "George Washington", causing the ship to go to San Diego for repairs. "Kitty Hawk" participated in the RIMPAC exercise near Hawaii in "George Washington"‍ '​s place. The turnover between the two carriers was postponed and took place in August. After the turnover, "Kitty Hawk" arrived at Bremerton, Washington in September and was informally retired on 31 January 2009. "Kitty Hawk", the USN's last oil-powered aircraft carrier, was finally decommissioned on 12 May 2009.
Plans.
A group based in Wilmington, North Carolina is lobbying to bring the ship to the city after decommissioning and her obligatory time as Ready Reserve Fleet asset in order to serve as a floating museum alongside the battleship "North Carolina". The Navy will maintain "Kitty Hawk" in reserve until 2015, when the "Gerald R. Ford" is commissioned.
In January 2013, a group from Pensacola, Florida, which had originally wanted to obtain "Forrestal", shifted its efforts to "Kitty Hawk", due to that ship's superior condition.
The current campaign to obtain an aircraft carrier as a Pensacola museum follows a controversial campaign in the early 1990s, when a volunteer effort tried to get the . That movement did not succeed, and the "Lexington" now operates as a museum in Corpus Christi, Texas.

</doc>
