<doc id="26945" url="http://en.wikipedia.org/wiki?curid=26945" title="Saint Helena">
Saint Helena

Saint Helena ( ) is a tropical island of volcanic origin in the South Atlantic Ocean, 4000 km east of Rio de Janeiro. It is part of the British Overseas Territory of Saint Helena, Ascension and Tristan da Cunha, which also includes Ascension Island and the islands of Tristan da Cunha. Saint Helena measures about 16 by and has a population of 4,255 (2008 census). It was named after Saint Helena of Constantinople.
The island was uninhabited when discovered by the Portuguese in 1502. One of the most remote islands in the world, it was for centuries an important stopover for ships sailing to Europe from Asia and South Africa. Napoleon was imprisoned there in exile by the British, as were Dinuzulu kaCetshwayo (for leading a Zulu army against British rule) and more than 5,000 Boers taken prisoner during the Second Boer War.
Between 1791 and 1833, Saint Helena became the site of a series of experiments in conservation, reforestation, and attempts to boost rainfall artificially. This environmental intervention was closely linked to the conceptualization of the processes of environmental change and helped establish the roots of environmentalism.
Saint Helena is Britain's second oldest remaining British Overseas Territory, after Bermuda.
History.
Early history (1502–1658).
Most historical accounts state that the island was discovered on 21 May 1502 by the Galician navigator João da Nova sailing at the service of Portugal, and that he named it "Santa Helena" after Helena of Constantinople. Another theory holds that the island found by da Nova was actually Tristan da Cunha, 2430 km to the south, and that Saint Helena was discovered by some of the ships attached to the squadron of Estêvão da Gama expedition on 30 July 1503 (as reported in the account of clerk Thomé Lopes).
The Portuguese found the island uninhabited, with an abundance of trees and fresh water. They imported livestock, fruit trees and vegetables, and built a chapel and one or two houses. Though they formed no permanent settlement, the island was an important rendezvous point and source of food for ships travelling from Asia to Europe, and frequently sick mariners were left on the island to recover, before taking passage on the next ship to call on the island.
Englishman Sir Francis Drake probably located the island on the final leg of his circumnavigation of the world (1577–1580). Further visits by other English explorers followed, and, once Saint Helena’s location was more widely known, English ships of war began to lie in wait in the area to attack Portuguese India carracks on their way home. In developing their Far East trade, the Dutch also began to frequent the island. The Portuguese and Spanish soon gave up regularly calling at the island, partly because they used ports along the West African coast, but also because of attacks on their shipping, the desecration of their chapel and religious icons, destruction of their livestock and destruction of plantations by Dutch and English sailors.
The Dutch Republic formally made claim to Saint Helena in 1633, although there is no evidence that they ever occupied, colonised or fortified it. By 1651, the Dutch had mainly abandoned the island in favour of their colony at the Cape of Good Hope.
East India Company (1658–1815).
In 1657, Oliver Cromwell granted the English East India Company a charter to govern Saint Helena and the following year the Company decided to fortify the island and colonise it with planters. The first governor, Captain John Dutton, arrived in 1659, making Saint Helena one of Britain's oldest colonies outside North America and the Caribbean. A fort and houses were built. After the Restoration of the English monarchy in 1660, the East India Company received a royal charter giving it the sole right to fortify and colonise the island. The fort was renamed James Fort and the town Jamestown, in honour of the Duke of York, later James II of England.
Between January and May 1673 the Dutch East India Company forcibly took the island, before English reinforcements restored English East India Company control. The Company experienced difficulty attracting new immigrants, and sentiments of unrest and rebellion fomented among the inhabitants. Ecological problems, including deforestation, soil erosion, vermin and drought, led Governor Isaac Pyke to suggest in 1715 that the population be moved to Mauritius, but this was not acted upon and the Company continued to subsidise the community because of the island's strategic location. A census in 1723 recorded 1,110 people, including 610 slaves.
Eighteenth-century governors tried to tackle the island's problems by implementing tree plantation, improving fortifications, eliminating corruption, building a hospital, tackling the neglect of crops and livestock, controlling the consumption of alcohol and introducing legal reforms. From about 1770, the island enjoyed a lengthy period of prosperity. Captain James Cook visited the island in 1775 on the final leg of his second circumnavigation of the world. Saint James' Church was erected in Jamestown in 1774 and in 1791–92 Plantation House was built, and has since been the official residence of the Governor.
On leaving the University of Oxford, in 1676, Edmond Halley visited Saint Helena and set up an observatory with a 24 ft aerial telescope with the intention of studying stars from the Southern Hemisphere. The site of this telescope is near Saint Mathew's Church in Hutt's Gate, in the Longwood district. The 680 m high hill there is named for him and is called Halley's Mount.
Throughout this period Saint Helena was an important port of call of the East India Company. East Indiamen would stop there on the return leg of their voyages to India and China. At Saint Helena ships could replenish supplies of water and provisions, and during war time, form convoys that would sail under the protection of vessels of the Royal Navy. Captain James Cook's vessel "HMS Endeavour" anchored and resupplied off the coast of St Helena in May 1771, on her return from the European discovery of Australia and rediscovery of New Zealand.
The importation of slaves was made illegal in 1792. Governor Robert Patton (1802–1807) recommended that the Company import Chinese labour to supplement the rural workforce. The labourers arrived in 1810, and their numbers reached 600 by 1818. Many were allowed to stay, and their descendents became integrated into the population. An 1814 census recorded 3,507 people on the island.
British rule (1815–1821) and Napoleon's exile.
In 1815, the British government selected Saint Helena as the place of detention of Napoleon Bonaparte. He was taken to the island in October 1815, staying at the Briars pavilion on the grounds of the Balcombe family's home until his permanent home, Longwood House, was completed; he died there on 5 May 1821. During this period, Saint Helena remained in the East India Company’s possession, but the British government met additional costs arising from guarding Napoleon. The island was strongly garrisoned with British troops, and naval ships circled the island.
The 1817 census recorded 821 white inhabitants, a garrison of 820 men on the East India Company's payroll, 1,475 men from the King's troops (infantry, engineers etc.) and 352 people as their families, 618 Chinese indentured labourers, 24 Lascars, 500 free blacks and 1,540 slaves; in total, 6,150 people on the island. In addition, the British government had sent a naval squadron under the command of a rear-admiral and consisting of a couple of men o'war and several smaller vessels. These were not counted in the Census, as most of them lived on their ships. Concerning the slaves, Governor Hudson Lowe initiated their emancipation in 1818: from Christmas of that year, every newborn child was considered a free person (though his parents remained slaves until their death).
British East India Company (1821–1834).
After Napoleon's death, the thousands of temporary visitors were soon withdrawn and the East India Company resumed full control of Saint Helena. Between 1815 and 1830, the EIC made available to the government of the island the packet schooner "St Helena", which made multiple trips per year between the island and the Cape carrying passengers both ways, and supplies of wine and provisions back to the island.
Owing to Napoleon's praise of Saint Helena’s coffee during his exile on the island, the product enjoyed a brief popularity in Paris in the years after his death. The importation of slaves was banned in 1792. The phased emancipation of over 800 resident slaves did not take place until 1827, which still was some six years before the British Parliament passed legislation to ban slavery in the colonies.
Crown colony (1834–1981).
Under the provisions of the 1833 India Act, control of Saint Helena was passed from the East India Company to the British Crown, becoming a crown colony. Subsequent administrative cost-cutting triggered the start of a long-term population decline whereby those who could afford to do so tended to leave the island for better opportunities elsewhere. The latter half of the 19th century saw the advent of steam ships not reliant on trade winds, as well as the diversion of Far East trade away from the traditional South Atlantic shipping lanes to a route via the Red Sea (which, prior to the building of the Suez Canal, involved a short overland section). These factors contributed to a decline in the number of ships calling at the island from 1,100 in 1855 to only 288 in 1889.
In 1840, a British naval station established to suppress the African slave trade was based on the island, and between 1840 and 1849 over 15,000 freed slaves, known as "Liberated Africans", were landed there.
In 1858, the French emperor Napoleon III successfully gained the possession, in the name of the French government, of Longwood House and the lands around it, last residence of Napoleon I (who died there in 1821). It is still French property, administered by a French representative and under the authority of the French Ministry of Foreign Affairs.
On 11 April 1898 American Joshua Slocum, on his famous and epic solo round the world voyage arrived at Jamestown. He departed on 20 April 1898 for the final leg of his circumnavigation having been extended hospitality from the governor, his Excellency Sir R A Standale, presented two lectures on his voyage and been invited to Longwood by the French Consular agent.
In 1900 and 1901, over 6,000 Boer prisoners were held on the island, and the population reached its all-time high of 9,850 in 1901.
A local industry manufacturing fibre from New Zealand flax was successfully reestablished in 1907 and generated considerable income during the First World War. Ascension Island was made a dependency of Saint Helena in 1922, and Tristan da Cunha followed in 1938. During World War II, the United States built Wideawake airport on Ascension in 1942, but no military use was made of Saint Helena.
During this period, the island enjoyed increased revenues through the sale of flax, with prices peaking in 1951. However, the industry declined because of transportation costs and competition from synthetic fibres. The decision by the British Post Office to use synthetic fibres for its mailbags was a further blow, contributing to the closure of the island's flax mills in 1965.
From 1958, the Union Castle shipping line gradually reduced its service calls to the island. Curnow Shipping, based in Avonmouth, replaced the Union-Castle Line mailship service in 1977, using the RMS (Royal Mail Ship) "St Helena".
1981 to present.
The British Nationality Act 1981 reclassified Saint Helena and the other Crown colonies as British Dependent Territories. The islanders lost their right of abode in Britain. For the next 20 years, many could find only low-paid work with the island government, and the only available employment outside Saint Helena was on the Falkland Islands and Ascension Island. The Development and Economic Planning Department, which still operates, was formed in 1988 to contribute to raising the living standards of the people of Saint Helena.
In 1989, Prince Andrew launched the replacement RMS "St Helena" to serve the island; the vessel was specially built for the Cardiff–Cape Town route and features a mixed cargo/passenger layout.
The Saint Helena Constitution took effect in 1989 and provided that the island would be governed by a Governor and Commander-in-Chief, and an elected Executive and Legislative Council. In 2002, the British Overseas Territories Act 2002 granted full British citizenship to the islanders, and renamed the Dependent Territories (including Saint Helena) the British Overseas Territories. In 2009, Saint Helena and its two territories received equal status under a new constitution, and the British Overseas Territory was renamed Saint Helena, Ascension and Tristan da Cunha.
The UK government has invested £250 million in the construction of the island's airport. Expected to be fully operational early 2016, it is expected to help the island towards self-sufficiency and encourage economic development, reducing dependence on British government aid. The airport is also expected to kick start the tourism industry, with up to 30,000 visitors expected annually.
Geography.
Located in the South Atlantic Ocean on the Mid-Atlantic Ridge, more than 2000 km from the nearest major landmass, Saint Helena is one of the most remote places in the world. The nearest port on the continent is Namibe in Southern Angola, and the nearest international airport the Quatro de Fevereiro Airport of Angola's capital Luanda; connections to Cape Town in South Africa are used for most shipping needs, such as the mail boat that serves the island, the RMS St Helena. The island is associated with two other isolated islands in the southern Atlantic, also British territories: Ascension Island about 1300 km due northwest in more equatorial waters, and Tristan da Cunha, which is well outside the tropics 2430 km to the south. The island is situated in the Western Hemisphere and has the same longitude as Cornwall in the United Kingdom. Despite its remote location, it is classified as being in West Africa by the United Nations.
The island of Saint Helena has a total area of 122 km2, and is composed largely of rugged terrain of volcanic origin (the last volcanic eruptions occurred about 7 million years ago). Coastal areas are covered in volcanic rock and warmer and drier than the centre. The highest point of the island is Diana's Peak at 818 m. In 1996 it became the island's first national park. Much of the island is covered by New Zealand flax, a legacy of former industry, but there are some original trees augmented by plantations, including those of the Millennium Forest project which was established in 2002 to replant part of the lost Great Wood and is now managed by the Saint Helena National Trust. When the island was discovered, it was covered with unique indigenous vegetation, including a remarkable cabbage tree species. The island's hinterland must have been a dense tropical forest but the coastal areas were probably also quite green. The modern landscape is very different, with widespread bare rock in the lower areas, although inland it is green, mainly due to introduced vegetation. There are no native land mammals, but cattle, cats, dogs, donkeys, goats, mice, rabbits, rats and sheep have been introduced, and native species have been adversely affected as a result. The dramatic change in landscape must be attributed to these introductions. As a result, the string tree ("Acalypha rubrinervis") and the St Helena olive ("Nesiota elliptica") are now extinct, and many of the other endemic plants are threatened with extinction.
There are several rocks and islets off the coast, including: Castle Rock, Speery Island, the Needle, Lower Black Rock, Upper Black Rock (South), Bird Island (Southwest), Black Rock, Thompson's Valley Island, Peaked Island, Egg Island, Lady's Chair, Lighter Rock (West), Long Ledge (Northwest), Shore Island, George Island, Rough Rock Island, Flat Rock (East), the Buoys, Sandy Bay Island, the Chimney, White Bird Island and Frightus Rock (Southeast), all of which are within one kilometre (1 km) of the shore.
The national bird of Saint Helena is the Saint Helena plover, known locally as the Wirebird. It appears on the coat of arms of Saint Helena and on the flag.
Climate.
The climate of Saint Helena is tropical, marine and mild, tempered by the Benguela Current and trade winds that blow almost continuously. The climate varies noticeably across the island. Temperatures in Jamestown, on the north leeward shore, range between 21 - in the summer (January to April) and 17 - during the remainder of the year. The temperatures in the central areas are, on average, 5 - lower. Jamestown also has a very low annual rainfall, while 750 - falls per year on the higher ground and the south coast, where it is also noticeably cloudier. There are weather recording stations in the Longwood and Blue Hill districts.
Biodiversity.
St Helena has long been known for its high proportion of endemic birds and vascular plants. The highland areas contain most of the 400 endemic species recognized to date. Much of the island has been identified by BirdLife International as being important for bird conservation, especially the endemic Saint Helena plover or Wirebird, and for seabirds breeding on the offshore islets and stacks, in the north-east and the south-west Important Bird Areas. On the basis of these endemics and an exceptional range of habitats, Saint Helena is on the United Kingdom's tentative list for future UNESCO World Heritage Sites.
St Helena's biodiversity, however, also includes marine vertebrates, invertebrates (freshwater, terrestrial and marine), fungi (including lichen-forming species), non-vascular plants, seaweeds, and other biological groups. To date, very little is known about these, although more than 200 lichen-forming fungi have been recorded, including 9 endemics, suggesting that many significant discoveries remain to be made.
Administrative divisions.
Saint Helena is divided into eight districts, each with a community centre. The districts also serve as statistical subdivisions. The island is a single electoral area and sends twelve representatives to the Legislative Council.
Politics.
Executive authority in Saint Helena is vested in Queen Elizabeth II and is exercised on her behalf by the Governor of Saint Helena. The Governor is appointed by the Queen on the advice of the British government. Defence and Foreign Affairs remain the responsibility of the United Kingdom.
There are fifteen seats in the Legislative Council of Saint Helena, a unicameral legislature, in addition to a Speaker and a Deputy Speaker. Twelve of the fifteen members are elected in elections held every four years. The three "ex officio" members are the Chief Secretary, Financial Secretary and Attorney General. The Executive Council is presided over by the Governor, and consists of three "ex officio" officers and five elected members of the Legislative Council appointed by the Governor. There is no elected Chief Minister, and the Governor acts as the head of government. In January 2013 it was proposed that the Executive Council would be led by a "Chief Councillor" who would be elected by the members of the Legislative Council and would nominate the other members of the Executive Council. These proposals were put to a referendum on 23 March 2013 where they were defeated by 158 votes to 42 on a 10% turnout.
Both Ascension Island and Tristan da Cunha have an Administrator appointed to represent the Governor of Saint Helena.
One commentator has observed that, notwithstanding the high unemployment resulting from the loss of full passports during 1981–2002, the level of loyalty to the British monarchy by the St Helena population is probably not exceeded in any other part of the world. King George VI is the only reigning monarch to have visited the island. This was in 1947 when the King, accompanied by Queen Elizabeth (later the Queen Mother), Princess Elizabeth (later Queen Elizabeth II) and Princess Margaret were travelling to South Africa. Prince Philip arrived at St Helena in 1957 and then his son Prince Andrew visited as a member of the armed forces in 1984 and his sister the Princess Royal arrived in 2002.
Human rights.
In 2012, the government of St. Helena funded the creation of the St. Helena Human Rights Action Plan 2012-2015. Work is being done under this action plan, including publishing awareness-raising articles in local newspapers, providing support for members of the public with human rights queries, and extending several UN Conventions on human rights to St. Helena.
Child abuse scandal.
In recent years, there have been reports of child abuse in St Helena. Britain’s Foreign and Commonwealth Office (FCO) has been accused of lying to the United Nations about child abuse in St Helena to cover up allegations, including cases of a police officer having raped a four-year-old girl and of a police officer having mutilated a two-year-old.
The British government admits it made an “erroneous” report to the United Nations when it denied that child abuse was rife in St Helena.
Demographics.
Saint Helena was first settled by the English in 1659, and the island has a population of about 4,250 inhabitants, mainly descended from people from Britain – settlers ("planters") and soldiers – and slaves who were brought there from the beginning of settlement – initially from Africa (the Cape Verde Islands, Gold Coast and west coast of Africa are mentioned in early records), then India and Madagascar. Eventually the planters felt there were too many slaves and no more were imported after 1792.
In 1840, St Helena became a provisioning station for the British West Africa Squadron, preventing slavery to Brazil (mainly), and many thousands of slaves were freed on the island. These were all African, and about 500 stayed while the rest were sent on to the West Indies and Cape Town, and eventually to Sierra Leone.
Imported Chinese labourers arrived in 1810, reaching a peak of 618 in 1818, after which numbers were reduced. Only a few older men remained after the British Crown took over the government of the island from the East India Company in 1834. The majority were sent back to China, although records in the Cape suggest that they never got any further than Cape Town. There were also a very few Indian lascars who worked under the harbour master.
The citizens of Saint Helena hold British Overseas Territories citizenship. On 21 May 2002, full British citizenship was restored by the British Overseas Territories Act 2002. See also British nationality law.
During periods of unemployment, there has been a long pattern of emigration from the island since the post-Napoleonic period. The majority of "Saints" emigrated to the UK, South Africa, and in the early years, Australia. The population has steadily declined since the late 1980s and has dropped from 5,157 at the 1998 census to 4,255 in 2008. In the past emigration was characterised by young unaccompanied persons leaving to work on long-term contracts on Ascension and the Falkland Islands, but since "Saints" were re-awarded UK citizenship in 2002, emigration to the UK by a wider range of wage-earners has accelerated due to the prospect of higher wages and better progression prospects.
Religion.
Most residents belong to the Anglican Communion and are members of the Diocese of St Helena, which has its own bishop and includes Ascension Island. The 150th anniversary of the diocese was celebrated in June 2009. Other Christian denominations on the island include: Roman Catholic (since 1852), Salvation Army (since 1884), Baptist (since 1845), and, in more recent times, Seventh-day Adventist (since 1949), New Apostolic, and Jehovah's Witnesses (of which one in 35 residents is a member, the highest ratio of any country). The Baha'i Faith has also been represented on the island since 1954.
Economy.
The island had a monocrop economy until 1966, based on the cultivation and processing of New Zealand flax for rope and string. St Helena's economy is now weak, and is almost entirely sustained by aid from the British government. The public sector dominates the economy, accounting for about 50% of gross domestic product. Inflation was running at 4% in 2005. There have been increases in the cost of fuel, power and all imported goods.
The tourist industry is heavily based on the promotion of Napoleon's imprisonment. A golf course also exists and the possibility for sportfishing tourism is great. Three hotels operate on the island but the arrival of tourists is directly linked to the arrival and departure schedule of the RMS "St Helena". Some 3,200 short-term visitors arrived on the island in 2013.
Saint Helena produces what is said to be the most expensive coffee in the world. It also produces and exports Tungi Spirit, made from the fruit of the prickly or cactus pears, Opuntia ficus-indica ("Tungi" is the local St Helenian name for the plant). Ascension Island, Tristan da Cunha and Saint Helena all issue their own postage stamps which provide a significant income.
Economic statistics.
Quoted at constant 2002 prices, GDP fell from £12 million in 1999/2000 to £11 million in 2005/6. Imports are mainly from the UK and South Africa and amounted to £6.4 million in 2004/5 (quoted on an FOB basis). Exports are much smaller, amounting to £0.2 million in 2004/5. Exports are mainly fish and coffee; Philatelic sales were £0.06 million in 04/05. The limited number of visiting tourists spent about £0.4 million in 2004/05, representing a contribution to GDP of 3%.
Public expenditure rose from £10 million in 2001/02 to £12 million in 2005/06 to £28m in 2012/13 The contribution of UK budgetary aid to total SHG government expenditure rose from £4.6 million in to £6.4 million to £12.1 million over the same period. Wages and salaries represent about 38% of recurrent expenditure.
Unemployment levels are low (31 in 2013, compared to 50 in 2004 and 342 in 1998). Employment is dominated by the public sector, the number of government positions has fallen from 1,142 in 2006 to just over 800 in 2013. St Helena’s private sector employs approximately 45% of the employed labour force and is largely dominated by small and micro businesses with 218 private businesses employing 886 in 2004.
Household survey results suggest the percentage of households spending less than £20 per week on a per capita basis fell from 27% to 8% between 2000 and 2004, implying a decline in income poverty. Nevertheless, 22% of the population claimed social security benefit in 2006/7, most of them aged over 60, a sector that represents 20% of the population.
Banking and currency.
In 1821, Saul Solomon issued a 70,560 copper tokens worth a halfpenny each "Payable at St Helena by Solomon, Dickson and Taylor" – presumably London partners – that circulated alongside the East India Company's local coinage until the Crown took over the Island in 1836. The coin remains readily available to collectors.
Today Saint Helena has its own currency, the Saint Helena pound, which is at parity with the pound sterling. The government of Saint Helena produces its own coinage and banknotes. The Bank of Saint Helena was established on Saint Helena and Ascension Island in 2004. It has branches in Jamestown on Saint Helena, and Georgetown, Ascension Island and it took over the business of the St. Helena government savings bank and Ascension Island Savings Bank.
For more information on currency in the wider region, see the Sterling Currency in the South Atlantic and the Antarctic.
Transport.
Saint Helena is one of the most remote islands in the world, has no commercial airports, and travel to the island is by ship only. A large military airfield is located on Ascension Island, with two Friday flights to RAF Brize Norton, England (as from September 2010). These RAF flights offer a limited number of seats to civilians. The ship RMS "Saint Helena" runs between St Helena and Cape Town, also visiting Ascension Island and Walvis Bay, and occasionally voyaging north to Tenerife and Portland, UK. It berths in James Bay, St Helena approximately thirty times per year. The RMS "Saint Helena" was due for decommissioning in 2010. However, its service life has been extended indefinitely until the airstrip is completed.
After a long period of rumour and consultation, the British government announced plans to construct an airport in Saint Helena in March 2005 and the airport was originally expected to be completed by 2010. However an approved bidder, the Italian firm Impregilo, was not chosen until 2008, and then the project was put on hold in November 2008, allegedly due to new financial pressures brought on by the credit-crunch. By January 2009, construction had not commenced and no final contracts had been signed, and Governor Andrew Gurr departed for London in an attempt to speed up the process and solve the problems.
On 22 July 2010, the British government agreed to help pay for the new airstrip using taxpayer money. In November 2011 a new deal between the British government and South African company Basil Read was signed and now means the airport is scheduled to open in February 2016, with flights to and from South Africa and the U.K. South African airline Comair (South Africa) became in March 2015 the preferred bidder to provide weekly air service between the island and Johannesburg, starting from 2016.
A minibus offers a basic service to carry people around Saint Helena, with most services designed to take people into Jamestown for a few hours on weekdays to conduct their business. Car rental is available for visitors.
Media and communications.
Radio.
Radio St Helena, which started operations on Christmas Day 1967, provided a local radio service that had a range of about 100 km from the island, and also broadcast internationally on shortwave radio (11092.5 kHz) on one day a year. The station presented news, features and music in collaboration with its sister newspaper, the "St Helena Herald". It closed on 25 December 2012 to make way for a new three-channel FM service, also funded by St. Helena Government and run by the South Atlantic Media Services (formerly St. Helena Broadcasting (Guarantee) Corporation).
Saint FM provided a local radio service for the island which was also available on internet radio and relayed in Ascension Island. The station was not government funded. It was launched in January 2005 and closed on 21 December 2012. It broadcast news, features and music in collaboration with its sister newspaper, the "St Helena Independent" (which continues).
Saint FM Community Radio took over the radio channels vacated by Saint FM and launched on 10 March 2013. The station operates as a limited-by-guarantee company owned by its members and is registered as a fund-raising Association. Membership is open to everyone, and grants access to a live audio stream.
Online.
St Helena Online is a not-for-profit internet news service run from the UK by a former print and BBC journalist, working in partnership with Saint FM and the "St Helena Independent".
Television.
Sure South Atlantic Ltd ("Sure") offers television for the island via 17 analogue terrestrial UHF channels, offering a mix of British, US, and South African programming. The channels are from DSTV and include Mnet, SuperSport and BBC channels. The feed signal, from MultiChoice DStv in South Africa, is received by a satellite dish at Bryant's Beacon from Intelsat 7 in the Ku band.
The St Helena Broadcasting Corporation was due to broadcast television in 2014 on channel 1.
Telecommunications.
SURE provide the telecommunications service in the territory through a digital copper-based telephone network including ADSL-broadband service. In August 2011 the first fiber-optic link has been installed on the island, which connects the television receive antennas at Bryant's Beacon to the Cable & Wireless Technical Centre in the Briars. 
A satellite ground station with a 7.6 m satellite dish installed in 1989 at The Briars is the only international connection providing satellite links through Intelsat 707 to Ascension island and the United Kingdom. Since all international telephone and internet communications are relying on this single satellite link both internet and telephone service are subject to sun outages.
Saint Helena has the international calling code +290 which, since 2006, Tristan da Cunha shares. Saint Helena telephone numbers changed from 4 to 5 digits on 1 October 2013 by being prefixed with the digit "2", i.e. 2xxxx, with the range 5xxxx being reserved for mobile numbering, and 8xxx being used for Tristan da Cunha numbers (these still shown as 4 digits).
Mobile telephony is due to start operating on the island by late 2015.
Internet.
Saint Helena has a 10/3.6 Mbit/s internet link via Intelsat 707 provided by SURE. Serving a population of more than 4000, this single satellite link is considered inadequate in terms of bandwidth.
ADSL-broadband service is provided with maximum speeds of up to 1536 KBit/s downstream and 512 KBit/s upstream offered on contract levels from lite £16 per month to gold+ at £190 per month. There are a few public WiFi hotspots in Jamestown, which are also being operated by SURE (formerly Cable & Wireless).
The South Atlantic Express, a 10000 km submarine communications cable connecting Africa to South America, run by the undersea fiber optic provider eFive, will pass St Helena relatively closely. There were no plans to land the cable and install a landing station ashore, which could supply St Helena's population with sufficient bandwidth to fully leverage the benefits of today's Information Society. In January 2012, a group of supporters petitioned the UK government to meet the cost of landing the cable at St Helena. On October 6, 2012, eFive agreed to reroute the cable through St. Helena after a successful lobbying campaign by A Human Right, a San Francisco-based NGA working on initiatives to ensure all people are connected to the internet. Islanders have sought the assistance of the UK Department for International Development and Foreign and Commonwealth Office in funding the £10m required to bridge the connection from a local junction box on the cable to the island. The UK Government have announced that a review of the island's economy would be required before such funding would be agreed to.
Local newspapers.
The island has two local newspapers, both of which are available on the internet. The "St Helena Independent" has been published since November 2005. "The Sentinel" newspaper was introduced in 2012.
Culture and society.
Education.
Education is free and compulsory between the ages of 5 and 16 There are three primary schools – Harford Primary School, Pilling Primary School and St Paul’s Primary School – for pupils from the age of 4 to 11 years and one secondary school – Prince Andrew School – for 11–18 year olds. At the beginning of the academic year 2009/2010 there were 230 primary school students and 286 secondary school students enrolled 
The Education and Employment Directorate also offers tailor-made programmes for special needs students and lifelong learning opportunities developed by the Adult and Vocational Education Service. The directorate provides evening classes for a variety of subjects and encourages distance learning or online correspondence courses. There is also provision of a public library (the oldest in the Southern Hemisphere)and a mobile library service which operates in the rural areas on a weekly basis.
The UK national curriculum is adapted for local use. A range of qualifications are offered – from GCSE, A/S and A2, to Level 3 Diplomas and VRQ qualifications:
Some of the courses are offered by distance learning, others by the island’s Adult and Vocational Centre. There is no tertiary education institution in Saint Helena. However, a number of scholarships are offered for students to study abroad.
Sport.
Sports played on the island include association football, cricket, volleyball, tennis, golf, motocross, shooting sports and yachting. Saint Helena has sent teams to a number of Commonwealth Games. Saint Helena is a member of the International Island Games Association. The Saint Helena cricket team made its debut in international cricket in Division Three of the African region of the World Cricket League in 2011.
The Governor's Cup is a yacht race between Cape Town and Saint Helena island, held every two years in December/January; the most recent event was in December 2010. In Jamestown a timed run takes place up Jacob's Ladder every year, with people coming from all over the world to take part.
Scouting.
There are scouting and guiding groups on Saint Helena and Ascension Island. Scouting was established on Saint Helena island in 1912. Lord and Lady Baden-Powell visited the Scouts on Saint Helena on the return from their 1937 tour of Africa. The visit is described in Lord Baden-Powell's book entitled "African Adventures".
Namesake.
St Helena, the suburb of Melbourne, Victoria, Australia was named after the island.
Further reading.
</dl>

</doc>
<doc id="26948" url="http://en.wikipedia.org/wiki?curid=26948" title="Spinning (textiles)">
Spinning (textiles)

Spinning is a major part of the textile industry. It is part of the textile manufacturing process where three types of fibre are converted into yarn, then fabrics, which undergo finishing processes such as bleaching to become textiles. The textiles are then fabricated into clothes or other products. There are three industrial processes available to spin yarn, and a handicraft community who use hand spinning techniques. Spinning is the twisting together of drawn out strands of fibres to form yarn, though it is colloquially used to describe the process of drawing out, inserting the twist, and winding onto bobbins.
Types of fibre.
Artificial fibres are made by extruding a polymer through a spinneret into a medium where it hardens. Wet spinning (rayon) uses a coagulating medium. In dry spinning (acetate and triacetate), the polymer is contained in a solvent that evaporates in the heated exit chamber. In melt spinning (nylons and polyesters) the extruded polymer is cooled in gas or air and sets. All these fibres will be of great length, often kilometers long.
Natural fibres are either from animals (sheep, goat, rabbit, silk-worm), mineral (asbestos), or from plants (cotton, flax, sisal). These vegetable fibres can come from the seed (cotton), the stem (known as bast fibres: flax, hemp, jute) or the leaf (sisal). Without exception, many processes are needed before a clean even staple is obtained – each with a specific name. With the exception of silk, each of these fibres is short, being only centimetres in length, and each has a rough surface that enables it to bond with similar staples.
Artificial fibres can be processed as long fibres or batched and cut so they can be processed like a natural fibre.
Spinning.
Ring-spinning is the most common spinning method in the world. Other systems include air-jet and open-end spinning. Open-end spinning is done using break or open-end spinning. This is a technique where the staple fibre is blown by air into a rotor and attaches to the tail of formed yarn that is continually being drawn out of the chamber. Other methods of break spinning use needles and electrostatic forces.
The processes to make yarn short-staple yarn (typically spun from fibres from 0.75 to 2.0") are blending, opening, carding, pin-drafting, roving, spinning, and—if desired—plying and dyeing. In long staple spinning, the process may start with stretch-break of tow, a continuous "rope" of synthetic fibre. In open-end and air-jet spinning, the roving operation is eliminated. The spinning frame winds yarn a bobbin. Generally, after this step the yarn is wound to a cone for knitting or weaving.
The pre-industrial techniques of hand spinning with spindle or spinning wheel continue to be practiced as a handicraft or hobby, and enable wool or unusual vegetable and animal staples to be creatively used.
History and economics.
Hand-spinning was a cottage industry in medieval Europe, where the wool spinners (often women and children) would provide enough yarn to service the needs of the men who operated the loom. This would occur in districts favourable to sheep husbandry. The introduction of the flying shuttle upset this balance. The subsequent invention of the spinning jenny water frame redressed the balance but required water power to operate the machinery, and the industry relocated to West Yorkshire where this was available. The nascent cotton industry was located on wetter side of the same hills. The British government was very protective of this technology, restricting its export. By the aftermath of World War I the colonies where the cotton was grown started to purchase and manufacture significant quantities of cotton spinning machinery. The next breakthrough was with the move over to break or open-end spinning, and then the adoption of artificial fibres. By then most production had moved to India and China.
During the industrial revolution, spinners, doffers, and sweepers were employed in spinning mills for the 18th to 20th centuries. Many employees of the mill were children, who were preferred due to their small size and agility.

</doc>
<doc id="26950" url="http://en.wikipedia.org/wiki?curid=26950" title="Republics of the Soviet Union">
Republics of the Soviet Union

The Republics of the Soviet Union or the Union Republics (Russian: союзные республики, "soyuznye respubliki") of the Soviet Union were ethnically based administrative units that were subordinated directly to the Government of the Soviet Union. For most of its history, the Soviet Union was a highly centralized state; the decentralization reforms during the era of "Perestroika" ("Restructuring") and "Glasnost" ("Openness") conducted by Mikhail Gorbachev led to the dissolution of the Soviet Union in 1991.
Overview.
According to the Article 76 of the Constitution of the Soviet Union, a Union Republic was a sovereign Soviet socialist state that had united with other Soviet Republics in the Union of Soviet Socialist Republics. Article 81 of the Constitution stated that "the sovereign rights of Union Republics shall be safeguarded by the USSR".
In the final decades of its existence, the Soviet Union officially consisted of fifteen Soviet Socialist Republics (SSRs). All of them, with the exception of the Russian Federation (until 1990), had their own local party chapters of the All-Union Communist Party.
Outside the territory of the Russian Federation, the republics were constituted mostly in lands that had formerly belonged to the Russian Empire and had been acquired by it between the 1700 Great Northern War and the Anglo-Russian Convention of 1907.
In 1944, amendments to the All-Union Constitution allowed for separate branches of the Red Army for each Soviet Republic. They also allowed for Republic-level commissariats for foreign affairs and defense, allowing them to be recognized as "de jure" independent states in international law. This allowed for two Soviet Republics, Ukraine and Byelorussia, (as well as the USSR as a whole) to join the United Nations General Assembly as founding members in 1945.
All of the former Republics of the Union are now independent countries, with eleven of them (all except the Baltic states and Georgia) being very loosely organized under the heading of the Commonwealth of Independent States.
However, most of the international community did not consider the Baltic countries (Lithuania, Latvia, and Estonia) to have legitimately been part of the USSR. The Baltic states assert that their incorporation into the Soviet Union in 1940 (as the Lithuanian, Latvian, and Estonian SSRs) under the provisions of the 1939 Molotov–Ribbentrop Pact was illegal, and that they therefore remained independent countries under Soviet occupation. Their position is supported by the European Union, the European Court of Human Rights, the United Nations Human Rights Council and the United States. In contrast, the Russian government and state officials maintain that the Soviet annexation of the Baltic states was legitimate.
Constitutionally, the Soviet Union was a federation. In accordance with provisions present in the Constitution (versions adopted in 1924, 1936 and 1977), each republic retained the right to secede from the USSR. Throughout the Cold War, this right was widely considered to be meaningless; however, the corresponding Article 72 of the 1977 Constitution was used in December 1991 to effectively dissolve the Soviet Union, when Russia, Ukraine, and Belarus seceded from the Union.
In practice, the USSR was a highly centralised entity from its creation in 1922 until the mid-1980s when political forces unleashed by reforms undertaken by Mikhail Gorbachev resulted in the loosening of central control and its ultimate dissolution. Under the constitution adopted in 1936 and modified along the way until October 1977, the political foundation of the Soviet Union was formed by the Soviets (Councils) of People's Deputies. These existed at all levels of the administrative hierarchy, with the Soviet Union as a whole under the nominal control of the Supreme Soviet of the USSR, located in Moscow within the Russian Federation.
Along with the state administrative hierarchy, there existed a parallel structure of party organizations, which allowed the Politburo to exercise large amounts of control over the republics. State administrative organs took direction from the parallel party organs, and appointments of all party and state officials required approval of the central organs of the party.
Each republic had its own unique set of state symbols: a flag, a coat of arms, and, with the exception of Russia until 1990, an anthem. Every republic of the Soviet Union also was awarded with the Order of Lenin.
The republics and the dissolution of the Soviet Union.
In the final decades of its existence, the Soviet Union consisted of 15 Soviet Socialist Republics and they were called Soviet republics.
The republics played an important role in the dissolution of the Soviet Union. Under Mikhail Gorbachev, "openness" and "restructuring" were intended to liberalise and open up the Soviet Union. However, they had a number of effects which caused the power of the republics to increase. First, political liberalization allowed the governments within the republics to gain legitimacy by invoking democracy, nationalism or a combination of both. In addition, liberalization led to fractures within the Communist Party which resulted in reduced ability to effectively govern the Union. The rise of nationalist and right-wing movements, notably led in Russia by Boris Yeltsin, in the previously homogeneously Communist political system led to the crumbling of the Union's foundations. With the central role of the Communist Party removed from the constitution, the Communist Party lost its control over the political system and was banned from operating after an attempted coup d'état.
Throughout the unravelling of the Restructuring, the Soviet government attempted to find a new structure which would reflect the increasing power of the republics. These efforts proved unsuccessful, and the republics began to secede from the Union. On 8 December 1991, the remaining republic leaders signed the Belavezha Accords which agreed that the USSR would be dissolved and replaced with a Commonwealth of Independent States. On 25 December, President Gorbachev announced his resignation and turned all executive powers over to Yeltsin. The next day the Council of Republics voted to dissolve the Union. Since then, the republics have been governed independently with some adopting significantly more liberal policies while others, particularly in Central Asia, retain leadership personnel from the Soviet time to this day.
Other Soviet republics of the Soviet Union.
The leader of the People's Republic of Bulgaria, Todor Zhivkov suggested in the early 1960s, that the country should become a Soviet socialist republic of the USSR, but the offer was rejected.
Autonomous Republics of the Soviet Union.
Several of the Union Republics themselves, most notably Russia, were further subdivided into Autonomous Soviet Socialist Republics (ASSRs). Though administratively part of their respective Union Republics, ASSRs were also established based on ethnic/cultural lines.

</doc>
<doc id="26951" url="http://en.wikipedia.org/wiki?curid=26951" title="Systemic scleroderma">
Systemic scleroderma

Systemic sclerosis or systemic scleroderma is an autoimmune or connective tissue disease. It is characterized by thickening of the skin caused by accumulation of collagen, and by injuries to the smallest arteries. There are two overlapping forms. Limited cutaneous scleroderma is limited to the skin on the face, hands and feet. Diffuse cutaneous scleroderma covers more of the skin, and is at risk of progressing to the visceral organs, including the kidneys, heart, lungs and gastrointestinal tract.
Survival is determined by the severity of visceral disease. Prognosis is difficult to predict until the disease differentiates into recognizable subsets. Patients with limited cutaneous scleroderma have a good prognosis, with 10-year survival of 75%, although <10% develop pulmonary arterial hypertension after 10 to 20 years. Patients with diffuse cutaneous scleroderma have a 10-year survival of 55%. Death is most often from pulmonary, heart and kidney involvement, although survival has greatly improved with effective treatment for kidney failure. Immunosuppressive drugs are used, although glucocorticoids have limited application.
Annual incidence is 19 per million, and prevalence is 19-75 per 100,000, with a female:male ratio of 3:1, and 8:1 in mid to late childbearing years. Incidence is twice as high among African Americans, and the Choctaw Native Americans in Oklahoma have the highest prevalence in the world (469/100,000). There is some hereditary association, some suggestion of immune reaction (molecular mimicry) to a virus, and some cases caused by toxins.
Signs and symptoms.
"Diffuse Scleroderma" - affects the skin as well as the heart, lungs, GI tract, and kidneys.
"Limited Scleroderma" - mostly affects the skin of the face, neck and distal elbows and knees and late in the disease causes isolated pulmonary hypertension. CREST syndrome (Calcinosis, Raynaud's phenomenon, Esophageal dysfunction, Sclerodactyly, Telangiectasias) is associated with limited scleroderma.
There is a slight increase in the risk of cancer with systemic sclerosis.
Skin symptoms.
In the skin, systemic sclerosis causes hardening and scarring. The skin may appear tight, reddish or scaly. Blood vessels may also be more visible. Where large areas are affected, fat and muscle wastage may weaken limbs and affect appearance. Also, patients report substantial, even severe and recurrent itching of large skin areas, the source of much affliction as the condition worsens. There is much variation in severity between patients, with some having scleroderma of only a limited area of the skin (such as the fingers) and little involvement of the underlying tissue; while others have progressive skin involvement.
Other organs.
Diffuse scleroderma can cause musculoskeletal, pulmonary, gastrointestinal, renal and other complications. Patients with larger amounts of cutaneous involvement are more likely to have involvement of the internal tissues and organs. Most patients (over 80%) have vascular symptoms and Raynaud's phenomenon, which leads to attacks of discoloration of the hands and feet in response to cold. Raynaud's normally affects the fingers and toes. Systemic scleroderma and Raynaud's can cause painful ulcers on the fingers or toes which are known as digital ulcers. Calcinosis (deposition of calcium in lumps under the skin) is also common in systemic scleroderma, and is often seen near the elbows, knees or other joints.
The first joint symptoms that patients with scleroderma have are typically non specific joint pains, which can lead to arthritis, or cause discomfort in tendons or muscles. Joint mobility, especially of the small joints of the hand, may be restricted by calcinosis or skin thickening. Patients may develop muscle weakness, or myopathy, either from the disease, or its treatments.
Some impairment in lung function is almost universally seen in patients with diffuse scleroderma on pulmonary function testing; however, it does not necessarily cause symptoms, such as shortness of breath. Some patients can develop pulmonary hypertension, or elevation in the pressures of the pulmonary arteries. This can be progressive, and lead to right sided heart failure. The earliest manifestation of this may be a decreased diffusion capacity on pulmonary function testing.
Other pulmonary complications in more advanced disease include aspiration pneumonia, pulmonary hemorrhage and pneumothorax.
Diffuse scleroderma can affect any part of the gastrointestinal tract. The most common manifestation in the esophagus is reflux esophagitis, which may be complicated by peptic stricturing, or benign narrowing of the esophagus. This is best initially treated with proton pump inhibitors for acid suppression, but may require bougie dilatation in the case of stricture.
Scleroderma can decrease motility anywhere in the gastrointestinal tract. The most common source of decreased motility involvement is the esophagus and the lower esophageal sphincter, leading to dysphagia and chest pain. As Scleroderma progresses, esophageal involvement from abnormalities in decreased motility may worsen due to progressive fibrosis (scarring). If this is left untreated, acid from the stomach can back up into the esophagus causing esophagitis, and GERD. Further scarring from acid damage to the lower esophagus many times leads to the development of fibrotic narrowing, also known as strictures which can be treated by dilatation, and Barrett's esophagus. The small intestine can also become involved, leading to bacterial overgrowth and malabsorption, of bile salts, fats, carbohydrates, proteins, and vitamins. The colon can be involved, and can cause pseudo-obstruction or ischemic colitis.
Rarer complications include pneumatosis cystoides intestinalis, or gas pockets in the bowel wall, wide mouthed diverticula in the colon and esophagus, and liver fibrosis. Patients with severe gastrointestinal involvement can become profoundly malnourished.
Scleroderma may also be associated with gastric antral vascular ectasia (GAVE), also known as "watermelon stomach". This is a condition where atypical blood vessels proliferate usually in a radially symmetric pattern around the pylorus of the stomach. GAVE can be a cause of upper gastrointestinal bleeding or iron deficiency anemia in patients with scleroderma.
Renal involvement, in scleroderma, is considered a poor prognostic factor and frequently a cause of death.
The most important clinical complication of scleroderma involving the kidney is "scleroderma renal crisis". Symptoms of scleroderma renal crisis are malignant hypertension (high blood pressure with evidence of acute organ damage), hyperreninemia (high renin levels), azotemia (kidney failure with accumulation of waste products in the blood) and microangiopathic hemolytic anemia (destruction of red blood cells). Apart from the high blood pressure, hematuria (blood in the urine) and proteinuria (protein loss in the urine) may be indicative.
In the past scleroderma renal crisis was almost uniformily fatal. While outcomes have improved significantly with the use of ACE inhibitors the prognosis is often guarded, as a significant number of patients are refractory to treatment and develop renal failure. Approximately 5-10% of all scleroderma patients develop renal crisis at some point in the course of their disease. Patients that have rapid skin involvement have the highest risk of renal complications. It is most common in diffuse cutaneous scleroderma, and is often associated with antibodies against RNA polymerase (in 59% of cases). Many proceed to dialysis, although this can be stopped within three years in about a third of cases. Higher age and (paradoxically) a lower blood pressure at presentation make it more likely that dialysis is needed.
Treatments for scleroderma renal crisis include ACE inhibitors. Prophylactic use of ACE-inhibitors is currently not recommended, as recent data suggest a poorer prognosis in patient treated with these drugs prior to the development of renal crisis. Transplanted kidneys are known to be affected by scleroderma and patients with early onset renal disease (within one year of the scleroderma diagnosis) are thought to have the highest risk for recurrence.
Diagnosis.
Diagnosis is by clinical suspicion, presence of autoantibodies (specifically anti-centromere and anti-scl70/anti-topoisomerase antibodies) and occasionally by biopsy. Of the antibodies, 90% have a detectable anti-nuclear antibody. Anti-centromere antibody is more common in the limited form (80-90%) than in the diffuse form (10%), and anti-scl70 is more common in the diffuse form (30-40%) and in African-American patients (who are more susceptible to the systemic form).
In 1980 the American College of Rheumatology agreed upon diagnostic criteria for scleroderma.
Other conditions may mimic systemic sclerosis by causing hardening of the skin. Diagnostic hints that another disorder is responsible include the absence of Raynaud's phenomenon, a lack of abnormalities in the skin on the hands, a lack of internal organ involvement, and a normal antinuclear antibodies test result.
Causes.
There is no clear obvious cause for scleroderma and systemic sclerosis. Genetic predisposition appears to be limited: genetic concordance is small; still, there often is a familial predisposition for autoimmune disease. Polymorphisms in "COL1A2" and "TGF-β1" may influence severity and development of the disease. There is limited evidence implicating cytomegalovirus (CMV) as the original epitope of the immune reaction, as well as parvovirus B19. Organic solvents and other chemical agents have been linked with scleroderma.
One of the suspected mechanisms behind the autoimmune phenomenon is the existence of microchimerism, i.e. fetal cells circulating in maternal blood, triggering an immune reaction to what is perceived as "foreign" material.
A distinct form of scleroderma and systemic sclerosis may develop in patients with chronic renal failure. This entity, nephrogenic fibrosing dermopathy or nephrogenic systemic fibrosis, has been linked to the exposure to gadolinium-containing radiocontrast.
Bleomycin (a chemotherapeutic agent) and possibly taxane chemotherapy may cause scleroderma, and occupational exposure to solvents has been linked with an increased risk of systemic sclerosis.
Pathophysiology.
The overproduction of collagen is thought to result from an autoimmune dysfunction, in which the immune system would start to attack the kinetochore of the chromosomes. This would lead to genetic malfunction of nearby genes. T cells accumulate in the skin; these are thought to secrete cytokines and other proteins that stimulate collagen deposition. Stimulation of the fibroblast, in particular, seems to be crucial to the disease process, and studies have converged on the potential factors that produce this effect.
A significant player in the process is transforming growth factor (TGFβ). This protein appears to be overproduced, and the fibroblast (possibly in response to other stimuli) also overexpresses the receptor for this mediator. An intracellular pathway (consisting of "SMAD2/SMAD3", "SMAD4" and the inhibitor "SMAD7") is responsible for the secondary messenger system that induces transcription of the proteins and enzymes responsible for collagen deposition. "Sp1" is a transcription factor most closely studied in this context. Apart from TGFβ, connective tissue growth factor (CTGF) has a possible role. Indeed, a common "CTGF" gene polymorphism is present at an increased rate in systemic sclerosis.
Damage to endothelium is an early abnormality in the development of scleroderma, and this too seems to be due to collagen accumulation by fibroblasts, although direct alterations by cytokines, platelet adhesion and a type II hypersensitivity reaction have similarly been implicated. Increased endothelin and decreased vasodilation has been documented.
Jimenez & Derk describe three theories about the development of scleroderma:
Therapy.
There is no cure for scleroderma, though there is treatment for some of the symptoms, including drugs that soften the skin and reduce inflammation. Some patients may benefit from exposure to heat. Holistic care of patient comprising patient education tailored to patient's education level is useful in view of the complex nature of the disease symptoms and progress.
Topical/symptomatic.
Topical treatment for the skin changes of scleroderma do not alter the disease course, but may improve pain and ulceration. 
A range of NSAIDs (nonsteroidal anti-inflammatory drugs) can be used to ease painful symptoms, such as naproxen. There is limited benefit from steroids such as prednisone. Episodes of Raynaud's phenomenon sometimes respond to nifedipine or other calcium channel blockers; severe digital ulceration may respond to prostacyclin analogue iloprost, and the dual endothelin-receptor antagonist bosentan may be beneficial for Raynaud's phenomenon. The skin tightness may be treated systemically with methotrexate and ciclosporin. and the skin thickness treated with penicillamine.
Kidney disease.
Scleroderma renal crisis, the occurrence of acute renal failure and malignant hypertension (very high blood pressure with evidence of organ damage) in people with scleroderma, is effectively treated with drugs from the class of the ACE inhibitors. The benefit of ACE inhibitors extends even to those who have to commence dialysis to treat their kidney disease, and may give sufficient benefit to allow the discontinuation of renal replacement therapy.
Lung disease and pulmonary hypertension.
Active alveolitis is often treated with pulses of cyclophosphamide, often together with a small dose of steroids. The benefit of this intervention is modest.
Pulmonary hypertension may be treated with epoprostenol, bosentan and possibly aerolized iloprost.
Experimental treatments.
Given the difficulty in treating scleroderma, treatments with a smaller evidence base are often tried to control the disease. These include antithymocyte globulin and mycophenolate mofetil; some reports have reported improvements in the skin symptoms as well as delaying the progress of systemic disease, but neither of them have been subjected to large clinical trials.
Autologous hematopoietic stem cell transplantation (HSCT) is based on the assumption that autoimmune diseases like systemic sclerosis occur when the white blood cells of the immune system attack the body. In this treatment, stem cells from the patient's blood are extracted and stored to preserve them. The patient's white blood cells are destroyed with cyclophosphamide and rabbit antibodies against the white blood cells. Then the stored blood is returned to the patient's bloodstream to reconstitute a healthy blood and immune system which will not attack the body. The results of a phase 3 trial, the Autologous Stem Cell Trnsplantation International Scleroderma (ASTIS) trial, with 156 patients were published in 2014. HSCT itself has a high treatment mortality, so in the first year, the survival of patients in the treatment group was lower than the placebo group, but at the end of 10 years, the survival in the treatment group was significantly higher. The authors concluded that HSCT could be effective, if limited to patients who were healthy enough to survive HSCT itself. Therefore, HSCT should be given early in the progression of the disease, before it does damage. Patients with heart disease, and patients who smoked cigarettes, were less likely to survive. Another trial, the Stem Cell Transplant vs. Cyclophosphamide (SCOT) trial, is ongoing.
Epidemiology.
Systemic scleroderma is a rare disease with an annual incidence of 1 to 2 per 100,000 individuals in the United States. The interval of peak onset starts at age 30 to 35 and ends at age 50 to 55.
In the United States, the prevalence of systemic scleroderma is about 50,000, with different studies giving different estimates, usually ranging between 40,000 and 165,000.
Advocacy.
The Juvenile Scleroderma Network is an organization dedicated to provide emotional support and educational information to parents and their children living with juvenile scleroderma, to support pediatric research to identify the cause of and the cure for juvenile scleroderma, and to enhance public awareness.
In the US, the Scleroderma Research Foundation is dedicated to raise awareness of the disease and assist those who are affected. The Scleroderma Research Foundation sponsors research into the condition. Comedian and television presenter Bob Saget, a board member of the SRF, directed the 1996 ABC TV movie For Hope, starring Dana Delany, which depicts a young woman fatally affected by scleroderma; the film was based on the experiences of Saget's sister Gay.

</doc>
<doc id="26952" url="http://en.wikipedia.org/wiki?curid=26952" title="Slave narrative">
Slave narrative

The slave narrative is a literary form that grew out of the written accounts of enslaved Africans in Great Britain and its colonies, including the later United States, Canada, and Caribbean nations. Some six thousand former slaves from North America and the Caribbean gave accounts of their lives during the 18th and 19th centuries, with about 150 narratives published as separate books or pamphlets. In the U.S. during the Great Depression (1930s), more than 2,300 additional oral histories on life during slavery were collected by writers sponsored and published by the Works Progress Administration (WPA) of President Franklin D. Roosevelt's administration. Most of the 26 audio-recorded interviews are held by the Library of Congress.
Some of the earliest memoirs of captivity known in England and the British Isles were written by white Europeans and later Americans captured and sometimes enslaved in North Africa, usually by Barbary pirates. These were part of a broad category of "captivity narratives" by English-speaking Europeans. Beginning in the 18th century, these included accounts by colonists and American settlers in North America and the United States who were captured and held by Native Americans. Several well-known captivity narratives were published before the American Revolution, and they often followed forms established with the narratives of captivity in North Africa. Later North American accounts were by Americans captured by western tribes during 19th-century migrations.
For the Europeans and Americans, the division between captivity as slaves and as prisoners of war was not always clear. A broader name for the genre is "captivity literature". Given the problem of international contemporary slavery in the 20th and 21st centuries, additional slave narratives are being written and published.
North American slave narratives.
Slave narratives by African slaves from North America were first published in England in the 18th century. They soon became the main form of African-American literature in the 19th century. Slave narratives were publicized by abolitionists, who sometimes participated as editors, or writers if slaves were not literate. During the first half of the 19th century, the controversy over slavery in the United States led to impassioned literature on both sides of the issue.
To present the reality of slavery, a number of former slaves, such as Harriet Tubman, Harriet Jacobs and Frederick Douglass, published accounts of their enslavement and their escapes to freedom. Lucy Delaney wrote an account that included the freedom suit waged by her mother in Missouri for their freedom. Eventually some 6,000 former slaves from North America and the Caribbean wrote accounts of their lives, with about 150 of these published as separate books or pamphlets.
Because of the participation of abolitionist editors, influential historians, such as Ulrich B. Phillips in 1929, suggested that, as a class, "their authenticity was doubtful." With increased emphasis on using the slaves' own accounts and the research of broader classes of information, since the late 20th century historians have more often validated the accounts of slaves about their own experiences.
The slave narratives can be broadly categorized into three distinct forms: tales of religious redemption, tales to inspire the abolitionist struggle, and tales of progress. The tales written to inspire the abolitionist struggle are the most famous because they tend to have a strong autobiographical motif, such as in Frederick Douglass' autobiographies and "Incidents in the Life of a Slave Girl" by Harriet Jacobs (1861).
Before the American Civil War, some authors wrote fictional accounts of slavery to create support for abolitionism. The prime example is "Uncle Tom's Cabin" (1852) by Harriet Beecher Stowe. The success of her novel and the social tensions of the time brought a response by white southern writers, such as William Gilmore Simms and Mary Eastman, who published what were called anti-Tom novels. Both kinds of novels were bestsellers in the 1850s.
Tales of religious redemption.
From the 1770s to the 1820s, the slave narratives generally gave an account of a spiritual journey leading to Christian redemption. The authors usually characterized themselves as Africans rather than slaves, as most were born in Africa.
Examples include:
Tales to inspire the abolitionist movement.
From the mid-1820s, writers consciously chose the autobiographical form to generate enthusiasms for the abolitionist movement. Some writers adopted literary techniques, including the use of fictionalized dialogue. Between 1835 and 1865 more than 80 such narratives were published. Recurrent features include: slave auctions, the break-up of families, and frequently two accounts of escapes, one of which is successful. As this was the period of the forced migration of an estimated one million slaves from the Upper South to the Deep South through the internal slave trade, the experiences of auctions and break-up of families were common to many.
Examples include:
Tales of progress.
Following the defeat of the slave states of the Confederate South, the authors had less need to convey the evils of slavery. Some gave a sentimental account of plantation life and ended with the narrator adjusting to the new life of freedom. The emphasis of writers shifted conceptually toward a recounting of individual and racial progress rather than securing freedom.
Examples include:
WPA slave narratives.
During the Great Depression of the 1930s, the New Deal Works Projects Administration (WPA) employed writers and researchers from the Federal Writers' Project to interview and document the stories of African Americans who were former slaves. Most had been children when the Thirteenth Amendment was passed. Produced between 1936 and 1938, the narratives recount the experiences of more than 2,300 former slaves. Some interviews were recorded; 23 of 26 known audio recordings are held by the American Folklife Center of the Library of Congress. The last interview of a former slave was with Fountain Hughes, then 101, in Baltimore, Maryland in 1949. He was a grandson of a slave owned by President Thomas Jefferson at Monticello.
North African slave narratives.
In comparison to North American and Caribbean slave narratives, the North African slave narratives in English were written by British people and Americans captured (often at sea) and enslaved in North Africa in the 18th and early 19th centuries. These narratives have a distinct form in that they highlight the "otherness" of the Muslim slave traders, whereas the African-American slave narratives often call slave traders to account as fellow Christians.
Some captives used their experiences as North African slaves to criticize slavery in the United States, such as William Ray in his book "Horrors of Slavery". Slaves in North Africa suffered from many of the same conditions as their African counterparts in the United States, including hard labor, poor diet, and demeaning treatment. But, unlike those in America, slaves in North Africa could sometimes escape their condition by converting to Islam and adopting North Africa as their home, or in some cases could be ransomed by European powers. The Barbary pirates made a business out of capturing people at sea for ransom. For slaves in North America, religious conversion rarely resulted in freedom, particularly after the 17th century when Virginia and other colonies decided that what was most important was the status of mothers, under the principle of partus sequitur ventrem; children born to slave mothers were born into slavery, regardless of the father or the religion of the mother or children.
Examples include:
Other historical slave narratives.
As slavery has been practised all over the world for millennia, some narratives cover places and times other than these main two. One example is the account given by John R. Jewitt, an English armourer enslaved for years by Maquinna of the Nootka people in the Pacific Northwest. The "Canadian Encyclopedia" calls his memoir a "classic of captivity literature" and it is a rich source of information about the indigenous people of Vancouver Island.
Maria ter Meetelen (1704 in Amsterdam – fl. 1751), was a Dutch writer of an autobiography. Her biography is considered to be a valuable witness statement of the life of a former slave (1748).
Contemporary slave narratives.
A contemporary slave narrative is a recent memoir written by a former slave, or ghost-written on their behalf. Modern areas of the world in which slavery occurs include the Sudan, and two narratives, "Escape from Slavery: The True Story of My Ten Years in Captivity – and My Journey to Freedom in America" (2003) by Francis Bok and Edward Tivnan, and "Slave" by Mende Nazer and Damien Lewis, derive from slavery experiences in the Sudan.
Neo-slave narratives.
A neo-slave narrative is a modern fictional work set in the slavery era by contemporary authors or substantially concerned with depicting the experience or the effects of enslavement in the New World. The works are largely classified as novels, but may pertain to poetical works as well.
Examples include:

</doc>
<doc id="26954" url="http://en.wikipedia.org/wiki?curid=26954" title="Stephen King">
Stephen King

Stephen Edwin King (born September 21, 1947) is an American author of contemporary horror, supernatural fiction, suspense, science fiction, and fantasy. His books have sold more than 350 million copies, many of which have been adapted into feature films, miniseries, television shows, and comic books. King has published 54 novels, including seven under the pen name Richard Bachman and six non-fiction books. He has written nearly 200 short stories, most of which have been collected in book collections. Many of his stories are set in his home state of Maine.
King has received Bram Stoker Awards, World Fantasy Awards, and British Fantasy Society Awards. His novella "The Way Station" (1980) was a Nebula Award novelette nominee. In 2003, the National Book Foundation awarded him the Medal for Distinguished Contribution to American Letters. His short story "The Man in the Black Suit" (1994) received the O. Henry Award. He has also received awards for his contribution to literature for his entire "oeuvre", such as the World Fantasy Award for Life Achievement (2004), the Canadian Booksellers Association Lifetime Achievement Award (2007), and the Grand Master Award from the Mystery Writers of America (2007).
Early life.
Parents.
King's father, Donald Edwin King, who was born circa 1913 in Peru, Indiana, was a merchant seaman; Donald was born under the surname "Pollock", but used the surname "King", under which Stephen was born. King's mother, Nellie Ruth (née Pillsbury; February 3, 1913 – December 28, 1973), was born in Scarborough, Maine. They were married July 23, 1939, in Cumberland County, Maine.
Stephen Edwin King was born September 21, 1947, in Portland, Maine. When King was two years old, his father left the family under the pretense of "going to buy a pack of cigarettes", leaving his mother to raise King and his adopted older brother, David, by herself, sometimes under great financial strain. The family moved to De Pere, Wisconsin, Fort Wayne, Indiana, and Stratford, Connecticut. When King was eleven, the family returned to Durham, Maine, where Ruth King cared for her parents until their deaths. She then became a caregiver in a local residential facility for the mentally challenged. King was raised Methodist and remains religious as an adult.
Early inspirations.
As a child, King apparently witnessed one of his friends being struck and killed by a train, though he has no memory of the event. His family told him that after leaving home to play with the boy, King returned, speechless and seemingly in shock. Only later did the family learn of the friend's death. Some commentators have suggested that this event may have psychologically inspired some of King's darker works, but King makes no mention of it in his memoir "On Writing" (2000).
King related in detail his primary inspiration for writing horror fiction in his non-fiction "Danse Macabre" (1981), in a chapter titled "An Annoying Autobiographical Pause". King compares his uncle's successfully dowsing for water using the bough of an apple branch with the sudden realization of what he wanted to do for a living. That inspiration occurred while browsing through an attic with his elder brother, when King uncovered a paperback version of an H. P. Lovecraft collection of short stories, entitled "The Lurker in the Shadows", that had belonged to his father. The cover art—an illustration of a yellow-green demon hiding within the recesses of a Hellish cavern beneath a tombstone—was, he writes, the moment in his life which "that interior dowsing rod responded to." King told Barnes & Noble Studios during a 2009 interview, "I knew that I'd found home when I read that book."
Education and early career.
King attended Durham Elementary School and graduated from Lisbon Falls High School, in Lisbon Falls, Maine. He displayed an early interest in horror as an avid reader of EC's horror comics, including "Tales from the Crypt" (he later paid tribute to the comics in his screenplay for "Creepshow"). He began writing for fun while still in school, contributing articles to "Dave's Rag", the newspaper his brother published with a mimeograph machine, and later began selling to his friends stories based on movies he had seen (though when discovered by his teachers, he was forced to return the profits). The first of his stories to be independently published was "I Was a Teenage Grave Robber"; it was serialized over four issues (three published and one unpublished) of a fanzine, "Comics Review", in 1965. That story was published the following year in a revised form as "In a Half-World of Terror" in another fanzine, "Stories of Suspense", edited by Marv Wolfman.
From 1966, King studied English at the University of Maine, graduating in 1970 with a Bachelor of Arts in English. In the same year, his daughter Naomi Rachel was born. He wrote a column for the student newspaper, "The Maine Campus", titled "Steve King's Garbage Truck", took part in a writing workshop organized by Burton Hatlen, and took odd jobs to pay for his studies, including one at an industrial laundry. He sold his first professional short story, "The Glass Floor", to "Startling Mystery Stories" in 1967. The Fogler Library at the University of Maine now holds many of King's papers.
After leaving the university, King earned a certificate to teach high school but, unable to find a teaching post immediately, initially supplemented his laboring wage by selling short stories to men's magazines such as "Cavalier". Many of these early stories have been republished in the collection "Night Shift". In 1971, King married Tabitha Spruce, a fellow student at the University of Maine whom he had met at the University's Fogler Library after one of Professor Hatlen's workshops. That fall, King was hired as a teacher at Hampden Academy in Hampden, Maine. He continued to contribute short stories to magazines and worked on ideas for novels. It was during this time that King developed a drinking problem which would plague him for more than a decade.
1970s–1980s work.
In 1973, King's first novel "Carrie" was accepted by publishing house Doubleday. King had thrown an early draft of the novel into the trash after becoming discouraged with his progress writing about a teenage girl with psychic powers. His wife retrieved the manuscript and encouraged him to finish it.:54 His advance for "Carrie" was $2,500; King's paperback rights later earned $400,000. King and his family moved to southern Maine because of his mother's failing health. At this time, he began writing a book titled "Second Coming", later titled "Jerusalem's Lot", before finally changing the title to "Salem's Lot" (published 1975). In a 1987 issue of "The Highway Patrolman" magazine, he stated, "The story seems sort of down home to me. I have a special cold spot in my heart for it!" Soon after "Carrie"‍ '​s release in 1974, King's mother died of uterine cancer. His Aunt Emrine had read the novel to her before she died. King has written of his severe drinking problem at this time, stating that he was drunk delivering the eulogy at his mother's funeral.:69
After his mother's death, King and his family moved to Boulder, Colorado, where King wrote "The Shining" (published 1977). The family returned to western Maine in 1975, where King completed his fourth novel, "The Stand" (published 1978). In 1977, the family, with the addition of Owen Phillip (his third and last child), traveled briefly to England, returning to Maine that fall, where King began teaching creative writing at the University of Maine. He has kept his primary residence in Maine ever since.
In 1985, King wrote his first work for the comic book medium, writing a few pages of the benefit X-Men comic book "Heroes for Hope Starring the X-Men". The book, whose profits were donated to assist with famine relief in Africa, was written by a number of different authors in the comic book field, such as Chris Claremont, Stan Lee, and Alan Moore, as well as authors not primarily associated with that industry, such as Harlan Ellison. The following year, King wrote the introduction to "Batman" No. 400, an anniversary issue in which he expressed his preference for that character over Superman.
"The Dark Tower" books.
In the late 1970s, King began what became a series of interconnected stories about a lone gunslinger, Roland, who pursues the "Man in Black" in an alternate-reality universe that is a cross between J. R. R. Tolkien's Middle-earth and the American Wild West as depicted by Clint Eastwood and Sergio Leone in their spaghetti Westerns. The first of these stories, "", was initially published in five installments by "The Magazine of Fantasy & Science Fiction" under the editorship of Edward L. Ferman, from 1977 to 1981. "The Gunslinger" was continued as an eight-book epic series called "The Dark Tower", which books King wrote and published infrequently over four decades.
In 1982, the fantasy small-press Donald M. Grant (known for publishing the entire canon of Robert E. Howard) printed these stories for the first time together in hardcover form with color and black-and-white illustrations by fantasy artist Michael Whelan, as "The Gunslinger". Each chapter was named for the story previously published in magazine form. King dedicated the hardcover edition to his editor at "F&SF", Ed Ferman, who "took a chance on these stories". The original print run was only 10,000 copies, which was, by this time, a comparatively low run for a first printing of a King novel in hardcover. His 1980 novel, "Firestarter", had an initial print run in trade hardcover of 100,000 copies, and his 1983 novel, "Christine", had a trade hardcover print run of 250,000 copies, both by the much larger publisher Viking. "The Gunslinger"'s initial release was not highly publicized, and only specialty science-fiction and related bookstores carried it on their shelves. The book was generally unavailable in the larger chain stores, except by special order. Rumors spread among avid fans that there was a King book out that few readers knew about, let alone had actually read. When the initial 10,000 copies sold out, Grant printed another 10,000 copies in 1984, but these runs were still far short of the growing demand among fans for this book. Both the first and second printings of "The Gunslinger" garner premium prices on the collectible book market, notably among avid readers and collectors of Stephen King, horror literature, fantasy literature, and American western literature, and fans of Michael Whelan's artwork.
In 1987, King released the second installment, "", in which Roland draws three people from 20th-century United States into his world through magical doors. Grant published "The Drawing of the Three", with illustrations by Phil Hale, in a slightly larger run of 30,000 copies, which was still well below King's typical initial hardcover print run of a new book. "It", published in 1986, had an initial print run of 1,000,000 copies, King's largest to date. King had believed that the "Dark Tower" books would be of interest to only a select group of his fans, and he had resisted releasing it on a larger scale. Finally, in the late 1980s, bowing to pressure from his publishers and fans who were searching for the books (at this point fewer than 50,000 of his millions of readers would have been able to own any of the "Dark Tower" books), King agreed to release "The Gunslinger" and all subsequent "Dark Tower" books in trade paperback and mass-market formats.
In the early 2000s, King revised the original book, "The Gunslinger", because he felt the voice and imagery of the original stories of the late 1970s did not seem to fit the voice of the final installment of 2004; King felt the style of the work had markedly changed during the intervening 27 years. The revised version was published in 2003 by his former hardcover publisher Viking. Grant published its hardcover limited edition of the revised version of "The Gunslinger" along with a prequel story set in the Dark Tower world called "The Little Sisters of Eluria" (originally published in 1998 in the collection "Legends: Short Novels by the Masters of Modern Fantasy") in 2009.
Adaptations.
In October 2005, King signed a deal with Marvel Comics to publish a seven-issue limited series spin-off of the series called "". The series, which focuses on a young Roland Deschain, was plotted by Robin Furth, with dialogue by Peter David, and illustrated by Eisner Award-winning artist Jae Lee. The first issue was published on February 7, 2007, and King, David, Lee, and Marvel Editor-in-Chief Joe Quesada appeared at a midnight signing at a Times Square, New York comic book store to promote it. The work had sold over 200,000 copies by March 2007. The success of "The Gunslinger Born" led to an ongoing miniseries published by Marvel, with Furth and David continuing to collaborate, featuring both adapted material from the "Dark Tower" books and new material approved by King; it also led to a second series of King adaptations in the same format, serializing the events of "The Stand".
Although "The Hollywood Reporter" announced in February 2007 that plans were underway for "Lost" co-creator J. J. Abrams to do an adaptation of King's epic "Dark Tower" series, Abrams stated in a November 2009 interview with MTV that he would not be adapting the series.
Akiva Goldsman, Ron Howard and Brian Grazer will produce a feature film based on "The Dark Tower" series, with Howard slated to direct.
Richard Bachman.
In the late 1970s, early 1980s, King published a handful of short novels—"Rage" (1977), "The Long Walk" (1979), "Roadwork" (1981), "The Running Man" (1982) and "Thinner" (1984)—under the pseudonym Richard Bachman. The idea behind this was to test whether he could replicate his success again and to allay his fears that his popularity was an accident. An alternate explanation was that publishing standards at the time allowed only a single book a year. He picked up the name from the hard rock band Bachman-Turner Overdrive, of which he is a fan.
Richard Bachman was exposed as King's pseudonym by a persistent Washington D.C. bookstore clerk, Steve Brown, who noticed similarities between the works and later located publisher's records at the Library of Congress that named King as the author of one of Bachman's novels. This led to a press release heralding Bachman's "death"—supposedly from "cancer of the pseudonym." King dedicated his 1989 book "The Dark Half", about a pseudonym turning on a writer, to "the deceased Richard Bachman", and in 1996, when the Stephen King novel "Desperation" was released, the companion novel "The Regulators" carried the "Bachman" byline.
In 2006, during a press conference in London, King declared that he had discovered another Bachman novel, titled "Blaze". It was published on June 12, 2007. In fact, the original manuscript had been held at King's alma mater, the University of Maine in Orono, for many years and had been covered by numerous King experts. King completely rewrote the original 1973 manuscript for its publication.
King has used other pseudonyms, such as John Swithen for "The Fifth Quarter".
Car accident and thoughts of retirement.
On June 19, 1999, at about 4:30 pm, King was walking on the shoulder of Route 5, in Lovell, Maine. Driver Bryan Edwin Smith (July 16, 1957 – September 21, 2000), distracted by an unrestrained dog moving in the back of his minivan, struck King, who landed in a depression in the ground about 14 feet from the pavement of Route 5.:206 According to Oxford County Sheriff deputy Matt Baker, King was hit from behind and some witnesses said the driver was not speeding, reckless, or drinking. In his book "On Writing" King states he was heading north, walking against the traffic. Shortly before the accident took place, a woman in a car also heading north passed first King and then the light blue Dodge van. The van was looping from one side of the road to the other and the woman told her passenger she hoped "that guy in the van doesn't hit him (King)".:206
King was conscious enough to give the deputy phone numbers to contact his family, but was in considerable pain. The author was first transported to Northern Cumberland Hospital in Bridgton and then flown by helicopter to Central Maine Medical Center in Lewiston. His injuries—a collapsed right lung, multiple fractures of his right leg, scalp laceration and a broken hip—kept him at CMMC until July 9. His leg bones were so shattered that doctors initially considered amputating his leg, but stabilized the bones in the leg with an external fixator. After five operations in ten days and physical therapy, King resumed work on "On Writing" in July, though his hip was still shattered and he could sit for only about forty minutes before the pain became worse.:216
King's lawyer and two others purchased Smith's van for $1,500, reportedly to prevent it from appearing on eBay. The van was later crushed at a junkyard, much to King's disappointment, as he fantasized about smashing it up. King later mentioned during an interview with "Fresh Air's" Terry Gross that he wanted the vehicle destroyed at a charity event in which individuals would donate money for an opportunity to smash it with a sledgehammer.
During this time, Tabitha King was inspired to redesign his studio. King visited the space while his books and belongings were packed away. What he saw was an image of what his studio would look like if he died, providing a seed for his novel "Lisey's Story" (2006).
In 2002, King announced he would stop writing, apparently motivated in part by frustration with his injuries, which had made sitting uncomfortable and reduced his stamina. He has since resumed writing, but states on his website:
I'm writing but I'm writing at a much slower pace than previously and I think that if I come up with something really, really good, I would be perfectly willing to publish it because that still feels like the final act of the creative process, publishing it so people can read it and you can get feedback and people can talk about it with each other and with you, the writer, but the force of my invention has slowed down a lot over the years and that's as it should be.
2000s work.
In 2000, King published online a serialized horror novel, "The Plant" At first the public presumed that King had abandoned the project because sales were unsuccessful, but King later stated that he had simply run out of stories. The unfinished epistolary novel is still available from King's official site, now free. Also in 2000, he wrote a digital novella, "Riding the Bullet", and has said he sees e-books becoming 50% of the market "probably by 2013 and maybe by 2012". But he also warns: "Here's the thing—people tire of the new toys quickly."
In August 2003, King began writing a column on pop culture appearing in "Entertainment Weekly", usually every third week. The column, called "The Pop of King" (a play on the nickname "The King of Pop" commonly attributed to Michael Jackson).
In 2006, King published an apocalyptic novel, "Cell". The book features a sudden force in which every cell phone user turns into a mindless killer. King noted in the book's introduction that he does not use cell phones.
In 2007, Marvel Comics began publishing comic books based on King's "Dark Tower" series, followed by adaptations of "The Stand" in 2008 and "The Talisman" in 2009.
In 2008, King published both a novel, "Duma Key", and a collection, "Just After Sunset". The latter featured 13 short stories, including a novella, "N.", which was later released as a serialized animated series that could be seen for free, or, for a small fee, could be downloaded in a higher quality; it then was adopted into a limited comic book series.
In 2009, King published "Ur", a novella written exclusively for the launch of the second-generation Amazon Kindle and available only on Amazon.com, and "Throttle", a novella co-written with his son Joe Hill and released later as an audiobook titled "Road Rage", which included Richard Matheson's short story "Duel". On November 10 that year, King's novel "Under the Dome" was published; it is a reworking of an unfinished novel he tried writing twice in the late 1970s and early 1980s, and at 1,074 pages, it is the largest novel he has written since "It" (1986). "Under the Dome" debuted at No. 1 in The New York Times Bestseller List.
2010s work.
On February 16, 2010, King announced on his website that his next book would be a collection of four previously unpublished novellas called "Full Dark, No Stars". In April of that year, King published "Blockade Billy", an original novella issued first by independent small press Cemetery Dance Publications and later released in mass-market paperback by Simon & Schuster. The following month, DC Comics premiered "American Vampire", a monthly comic book series written by King with short-story writer Scott Snyder, and illustrated by Rafael Albuquerque, which represents King's first original comics work. King wrote the background history of the very first American vampire, Skinner Sweet, in the first five-issues story arc. Scott Snyder wrote the story of Pearl.
King's next novel, "11/22/63", was published November 8, 2011, and was nominated for the 2012 World Fantasy Award Best Novel. The eighth "Dark Tower" volume, "", was published in 2012. King's next book was "Joyland", a novel about "an amusement-park serial killer", according to an article in "The Sunday Times", published on April 8, 2012. It was followed by the sequel to "The Shining" (1977), titled "Doctor Sleep", published in September 2013.
During his Chancellor's Speaker Series talk at University of Massachusetts Lowell on December 7, 2012, King indicated that he was writing a crime novel about a retired policeman being taunted by a murderer. With a working title "Mr. Mercedes" and inspired by a true event about a woman driving her car into a McDonalds restaurant, it was originally meant to be a short story just a few pages long. In an interview with "Parade", published May 26, 2013, King confirmed that the novel was "more or less" completed he published it in June 2013. Later, on June 20, 2013, while doing a video chat with fans as part of promoting the upcoming "Under the Dome" TV series, King mentioned he was halfway through writing his next novel, "Revival", which was released November 11, 2014.
King announced in June 2014 that "Mr. Mercedes" is part of a trilogy; the second book, "Finders Keepers", will be released in 2015. On April 22, 2015, it was revealed that King is currently working on the third book of the trilogy and that its working title is "The Suicide Prince".
Collaborations.
With musical artists.
King is a fan of the Ramones, to the extent that he wrote the liner notes for the 2003 Ramones tribute album '. He states that he agreed to write them because he "loved The Ramones from the first time (he) heard them". Furthermore, King has referred to the band several times in his writing, both in his fiction and non-fiction. Non-fiction references include a mention in King's book "Danse Macabre" where he calls the Ramones "an amusing punk-rock band that surfaced some four years ago". He also wrote about them in "On Writing", making reference to "dancing to the Ramones - gabba gabba hey" as one of the reasons he has maintained a good marriage.:41 King included further Ramones references in his fictional work. He quotes the lyrics to the Ramones' debut single "Blitzkrieg Bop" in his novel "Pet Sematary" on numerous occasions, as in the sentence "What is it the Ramones say? Hey-ho, let's go"! In "The Dark Tower" novel ' the Ramones get a further mention by the character Eddie Dean who states that "Roland stage-dives like Joey Ramone". Critics have also noted the Ramones references. "Entertainment Weekly", for example, in their review of "Black House" by King and Peter Straub, note that King's "trademark references" are in evidence, quoting Dee Dee Ramone. In turn, the Ramones have referenced King on their song "It's Not My Place (In the 9 to 5 World)", from their "Pleasant Dreams" album of 1981 in the line: "Ramones are hangin' out in Kokomo / Roger Corman's on a talk show / With Allan Arkush and Stephen King". Further, Dee Dee Ramone wrote the song "Pet Sematary" in King's basement after King handed him a copy of the novel. The song was eventually featured as the title song for the "Pet Sematary" (1989) film and also appeared on the Ramones album "Brain Drain" (1989).
King is a fan of hard rock such as AC/DC and King arranged for their album "Who Made Who" to feature as the score for the King directed film "Maximum Overdrive" in 1986. King has also stated that he likes heavy metal and has named bands like Anthrax, Judas Priest and Metallica as amongst his favourites to write to. In 1988, the band Blue Öyster Cult recorded an updated version of its 1974 song "Astronomy". The single released for radio play featured a narrative intro spoken by King. The Blue Öyster Cult song "(Don't Fear) The Reaper" was also used in the King TV series "The Stand".
King collaborated with Michael Jackson to create "Ghosts" (1996), a 40-minute musical video. King states he was motivated to collaborate as he is "always interested in trying something new, and for (him), writing a minimusical would be new". In 2012 King collaborated with musician Shooter Jennings and his band Hierophant, providing the narration for their album, "Black Ribbons". King played guitar for the rock band Rock Bottom Remainders, several of whose members are authors. Other members include Dave Barry, Ridley Pearson, Scott Turow, Amy Tan, James McBride, Mitch Albom, Roy Blount, Jr., Matt Groening, Kathi Kamen Goldmark, Sam Barry, and Greg Iles. King and the other band members collaborated to release an e-book called "Hard Listening: The Greatest Rock Band Ever (of Authors) Tells All" (June 2013).
With visual artists.
King produced an artist's book with designer Barbara Kruger, "My Pretty Pony" (1988), published in a limited edition of 250 by the Library Fellows of the Whitney Museum of American Art; Alfred A. Knopf later released it in a general trade edition in 1989.
In theater and television.
King wrote a musical play with John Mellencamp, titled "Ghost Brothers of Darkland County" (2012).
With writer.
King has written two novels with horror novelist Peter Straub: "The Talisman" (1984) and a sequel, "Black House" (2001). King has indicated that he and Straub will likely write the third and concluding book in this series, the tale of Jack Sawyer, but has set no time for its completion.
"" (2001), was a paperback tie-in for the King-penned miniseries "Rose Red" (2002). Published under anonymous authorship, the book was written by Ridley Pearson. This spin-off is a rare occasion of another author's being granted permission to write commercial work using characters and story elements invented by King.
King also wrote the nonfiction book, "Faithful" (2004), with novelist and fellow Red Sox fanatic Stewart O'Nan.
"Throttle" (2009), a novella written in collaboration with his son Joe Hill, appears in the anthology "He Is Legend: Celebrating Richard Matheson". Their second novella collaboration, "In the Tall Grass" (2012), was published in two parts in "Esquire".
Analysis.
Writing style.
King's formula for learning to write well is: "Read and write four to six hours a day. If you cannot find the time for that, you can't expect to become a good writer." He sets out each day with a quota of 2000 words and will not stop writing until it is met. He also has a simple definition for talent in writing: "If you wrote something for which someone sent you a check, if you cashed the check and it didn't bounce, and if you then paid the light bill with the money, I consider you talented."
Shortly after his accident, King wrote the first draft of the book "Dreamcatcher" with a notebook and a Waterman fountain pen, which he called "the world's finest word processor."
When asked why he writes, King responds: "The answer to that is fairly simple—there was nothing else I was made to do. I was made to write stories and I love to write stories. That's why I do it. I really can't imagine doing anything else and I can't imagine not doing what I do." He is also often asked why he writes such terrifying stories and he answers with another question: "Why do you assume I have a choice?" According to Jenna Blum, King usually begins the story creation process by imagining a "what if" scenario, such as what would happen if a writer is kidnapped by a sadistic nurse in Colorado.
King often uses authors as characters, or includes mention of fictional books in his stories, novellas and novels, such as Paul Sheldon who is the main character in "Misery" and Jack Torrance in "The Shining". See also List of fictional books in the works of Stephen King for a complete list. In September 2009 it was announced he would serve as a writer for "Fangoria".
Influences.
King has called Richard Matheson "the author who influenced me most as a writer." In a current edition of Matheson's "The Shrinking Man", King is quoted: "A horror story if there ever was one...a great adventure story—it is certainly one of that select handful that I have given to people, envying them the experience of the first reading."
Ray Bradbury is another influence, with King himself stating "without Ray Bradbury, there is no Stephen King."
King refers to H. P. Lovecraft several times in "Danse Macabre". "Gramma", a short story made into a film in the 1980s anthology horror show "The New Twilight Zone", mentions Lovecraft's notorious fictional creation "Necronomicon", also borrowing the names of a number of the fictional monsters mentioned therein. "I Know What You Need" from the 1976 collection "Night Shift", and "'Salem's Lot" also mention the tome. Despite this, in "On Writing", King is critical of Lovecraft's dialogue-writing skills, using passages from "The Colour Out of Space" as particularly poor examples.:143-4 There are also several examples of King's referring to Lovecraftian characters in his work, such as Nyarlathotep and Yog-Sothoth.
King acknowledges the influence of Bram Stoker, particularly on his novel "Salem's Lot", which he envisioned as a retelling of "Dracula". Its related short story "Jerusalem's Lot" is reminiscent of Stoker's "The Lair of the White Worm".
He also gives Joseph Payne Brennan credit for being one of his inspirations; "Joseph Payne Brennan is one of the most effective writers in the horror genre, and he is certainly one of the writers I have patterned my own career upon; one of the writers whom I studied and with whom I kept school."
King has also referenced author Shirley Jackson. "Salem's Lot" opens with a quotation from Jackson's "The Haunting of Hill House", and a character in "" references the Jackson book "We Have Always Lived in the Castle".
King is a fan of John D. MacDonald, and dedicated the novella "Sun Dog" to MacDonald, saying "I miss you, old friend." For his part, MacDonald wrote an admiring preface to "Night Shift", and even had his famous character, Travis McGee, reading "Cujo" in one of the last McGee novels and "Pet Sematary" in the last McGee novel, "The Lonely Silver Rain."
In 1987 King's Philtrum Press published Don Robertson's novel, "The Ideal, Genuine Man". In his forenote to the novel, King wrote, "Don Robertson was and is one of the three writers who influenced me as a young man who was trying to 'become' a novelist (the other two being Richard Matheson and John D. MacDonald)."
Robert A. Heinlein's book "The Door into Summer" is repeatedly mentioned in King's "Wolves of the Calla".
In an interview with King, published in the "USA Weekend" in March 2009, the author stated, "People look on writers that they like as an irreplaceable resource. I do. Elmore Leonard, every day I wake up and – not to be morbid or anything, although morbid is my life to a degree – don't see his obituary in the paper, I think to myself, "Great! He's probably working somewhere. He's gonna produce another book, and I'll have another book to read. Because when he's gone, there's nobody else."
King partly dedicated his book "Cell" to film director George Romero, and wrote an essay for the Elite DVD version of "Night of the Living Dead".
His favorite books are (in order) "The Golden Argosy"; "Adventures of Huckleberry Finn"; "The Satanic Verses"; "McTeague"; "Lord of the Flies"; "Bleak House"; "Nineteen Eighty-Four"; "The Raj Quartet"; "Light in August"; and "Blood Meridian".
Critical response.
Although critical reaction to King's work has been mostly positive, he has occasionally come under fire from academic writers.
Science fiction editors John Clute and Peter Nichols offer a largely favorable appraisal of King, noting his "pungent prose, sharp ear for dialogue, disarmingly laid-back, frank style, along with his passionately fierce denunciation of human stupidity and cruelty (especially to children) [all of which rank] him among the more distinguished 'popular' writers."
In his book "The Philosophy of Horror" (1990), Noël Carroll discusses King's work as an exemplar of modern horror fiction. Analyzing both the narrative structure of King's fiction and King's non-fiction ruminations on the art and craft of writing, Carroll writes that for King, "the horror story is always a contest between the normal and the abnormal such that the normal is reinstated and, therefore, affirmed."
In his analysis of post-World War II horror fiction, "The Modern Weird Tale" (2001), critic S. T. Joshi devotes a chapter to King's work. Joshi argues that King's best-known works (his supernatural novels), are his worst, describing them as mostly bloated, illogical, maudlin and prone to "deus ex machina" endings. Despite these criticisms, Joshi argues that since "Gerald's Game" (1993), King has been tempering the worst of his writing faults, producing books that are leaner, more believable and generally better written. Joshi suggests that King's strengths as a writer include the accessible "everyman" quality of his prose, and his unfailingly insightful observations about the pains and joys of adolescence. Joshi cites two early non-supernatural novels—"Rage" (1977) and "The Running Man" (1982)—as King's best, suggesting both are riveting and well-constructed suspense thrillers, with believable characters.
In 1996, King won an O. Henry Award for his short story "The Man in the Black Suit".
In his short story collection "A Century of Great Suspense Stories", editor Jeffery Deaver noted that King "singlehandedly made popular fiction grow up. While there were many good best-selling writers before him, King, more than anybody since John D. MacDonald, brought reality to genre novels. He has often remarked that "'Salem's Lot" was "Peyton Place meets Dracula." And so it was. The rich characterization, the careful and caring social eye, the interplay of story line and character development announced that writers could take worn themes such as vampirism and make them fresh again. Before King, many popular writers found their efforts to make their books serious blue-penciled by their editors. ‘Stuff like that gets in the way of the story,' they were told. Well, it's stuff like that that has made King so popular, and helped free the popular name from the shackles of simple genre writing. He is a master of masters."
In 2003, King was honored by the National Book Awards with a lifetime achievement award, the Medal of Distinguished Contribution to American Letters. Some in the literary community expressed disapproval of the award: Richard Snyder, the former CEO of Simon & Schuster, described King's work as "non-literature", and critic Harold Bloom denounced the choice:
The decision to give the National Book Foundation's annual award for "distinguished contribution" to Stephen King is extraordinary, another low in the shocking process of dumbing down our cultural life. I've described King in the past as a writer of penny dreadfuls, but perhaps even that is too kind. He shares nothing with Edgar Allan Poe. What he is is an immensely inadequate writer on a sentence-by-sentence, paragraph-by-paragraph, book-by-book basis.
However, others came to King's defense, such as writer Orson Scott Card, who responded:
Let me assure you that King's work most definitely is literature, because it was written to be published and is read with admiration. What Snyder really means is that it is not the literature preferred by the academic-literary elite."
In Roger Ebert's review of the 2004 movie "Secret Window", he stated, "A lot of people were outraged that [King] was honored at the National Book Awards, as if a popular writer could not be taken seriously. But after finding that his book "On Writing" had more useful and observant things to say about the craft than any book since Strunk and White's "The Elements of Style", I have gotten over my own snobbery."
In 2008, King's book "On Writing" was ranked 21st on "Entertainment Weekly" list of "The New Classics: The 100 Best Reads from 1983 to 2008".
Appearances and adaptations in other media.
King and his wife Tabitha own Zone Radio Corp, a radio station group consisting of WZON 103.1 FM and 620 AM.
King has stated that his favorite book-to-film adaptations are "Stand by Me", "The Shawshank Redemption", and "The Mist".
King's first film appearance was in George Romero's "Knightriders" as a buffoonish audience member. His first featured role was in "Creepshow", playing Jordy Verrill, a backwoods redneck who, after touching a fallen meteorite in hopes of selling it, grows moss all over his body. He has since made cameos in several adaptations of his works. He appeared in "Pet Sematary" as a minister at a funeral, in "Thinner" as a pharmacist, in "Rose Red" as a pizza deliveryman, as a news reporter in "The Storm of the Century", in "The Stand" as "Teddy Wieszack," in the "Shining" miniseries as a band member, in "The Langoliers" as Tom Holby and in "Sleepwalkers" as the cemetery caretaker. He has also appeared in "The Golden Years", in "Chappelle's Show" and, along with fellow author Amy Tan, on "The Simpsons" as himself. In addition to acting, King tried his hand at directing with "Maximum Overdrive", in which he also made a cameo appearance as a man using a malfunctioning ATM.
King produced and acted in a television series, "Kingdom Hospital", which is based on the Danish miniseries "Riget" by Lars von Trier. He also co-wrote "The X-Files" season-5 episode "Chinga" with the creator of the series Chris Carter.
King made an appearance as a contestant on "Celebrity Jeopardy!" in 1995, playing to benefit the Bangor Public Library.
King provided the voice of Abraham Lincoln in the audiobook version of "Assassination Vacation".
In 2010, King appeared in a cameo role as a cleaner named Bachman (a reference to his pen name "Richard Bachman") on the FX series "Sons of Anarchy".
The Syfy TV series "Haven" is based on King's novella, "The Colorado Kid".
Political activism.
In April 2008, King spoke out against HB 1423, a bill pending in the Massachusetts state legislature that would restrict or ban the sale of violent video games to anyone under the age of 18. Although King stated that he had no personal interest in video games as a hobby, he criticized the proposed law, which he sees as an attempt by politicians to scapegoat pop culture, and to act as surrogate parents to others' children, which he asserted is usually "disastrous" and "undemocratic." He also saw the law as inconsistent, as it would forbid a 17-year-old, legally able to see ', from buying or renting ', which is violent but less graphic. While conceding that he saw no artistic merit in some violent video games, King also opined that such games reflect the violence that already exists in society, which would not be lessened by such a law, and would be redundant in light of the ratings system that already exists for video games. King argued that such laws allow legislators to ignore the economic divide between the rich and poor, and the easy availability of guns, which he felt were the more legitimate causes of violence. Regarding video games, he later stated that he enjoys playing light gun shooter arcade games such as "Time Crisis".
A controversy emerged on May 5, 2008, when Noel Sheppard posted a clip of King at a Library of Congress reading event on the website NewsBusters. King, talking to high-school students, had said: "If you can read, you can walk into a job later on. If you don't, then you've got the Army, Iraq, I don't know, something like that." The comment was described by the blog as "another in a long line of liberal media members bashing the military," and likened to John Kerry's similar remark from 2006. King responded later that day, saying, "That a right-wing-blog would impugn my patriotism because I said children should learn to read, and could get better jobs by doing so, is beneath contempt...I live in a national guard town, and I support our troops, but I don't support either the war or educational policies that limit the options of young men and women to any one career—military or otherwise." King again defended his comment in an interview with the "Bangor Daily News" on May 8, saying, "I'm not going to apologize for promoting that kids get better education in high school, so they have more options. Those that don't agree with what I'm saying, I'm not going to change their minds." King later expressed regret for the remark, saying that he mispoke. He characterized the comment as originating from a "brain cramp", and the reality of no longer living in the world he grew up in, saying that during the Vietnam War, serving in the military was a great career for some, and for others, a sacrifice of two years of one's life. King added that he does believe that each person should be obligated to some type of government service or altruism.
King's website states that he is a supporter of the Democratic Party. During the 2008 presidential election, King voiced his support for Democratic candidate Barack Obama. King was quoted as calling conservative commentator Glenn Beck "Satan's mentally challenged younger brother."
On March 8, 2011, King spoke at a political rally in Sarasota aimed against Governor Rick Scott (R-FL), voicing his opposition to the Tea Party movement.
On April 30, 2012, King published an article in "The Daily Beast" calling for rich Americans, including himself, to pay more taxes, citing it as "a practical necessity and moral imperative that those who have received much should be obligated to pay ... in the same proportion".
On January 25, 2013, King published an essay titled "Guns" via Amazon.com's Kindle single feature, which discusses the gun debate in the wake of the Sandy Hook Elementary School shooting. King called for gun owners to support a ban on automatic and semi-automatic weapons, writing, "Autos and semi-autos are weapons of mass destruction...When lunatics want to make war on the unarmed and unprepared, these are the weapons they use." The essay became the fifth-bestselling non-fiction title for the Kindle.
Maine politics.
King endorsed Shenna Bellows in the 2014 U.S. Senate election for the seat currently held by Republican Susan Collins.
King is a public critic of Paul LePage, the Republican Governor of Maine, and has referred to LePage as one of the Three Stooges, along with Florida Governor Rick Scott and Wisconsin Governor Scott Walker. He was critical of LePage for incorrectly suggesting in a weekly radio address on March 18, 2015, that King avoided paying Maine income taxes by living out of state for part of the year. The statement was later corrected by the Governor's office but no apology was issued. King said LePage was "full of the stuff that makes the grass grow green" and demanded that LePage "man up and apologize". LePage declined to apologize to King, stating "I never said Stephen King did not pay income taxes. What I said was, Stephen King's not in Maine right now. That's what I said." LePage further told King that he should "make me the villain of your next book and I won’t charge you royalties".
The attention garnered by the LePage criticism has led to efforts to encourage King to run for Governor of Maine in 2018. Bangor city councilor Joe Baldacci posted on his Facebook page that he was starting a Draft Stephen King effort, and Democratic State Rep. Diane Russell launched a petition drive to encourage King to run. His spokeswoman posted to Baldacci's Facebook comment that he would likely decline to run, and King himself stated he would not run or serve on March 23 while still criticizing what he said was the "laziness that made him mad" about not checking his tax payments and that LePage had "a problem finding a comfortable pair of big-boy pants".
Philanthropy.
King has stated that he donates approximately $4 million per year "to libraries, local fire departments that need updated lifesaving equipment (Jaws of Life tools are always a popular request), schools, and a scattering of organisations that underwrite the arts."
The Stephen and Tabitha King Foundation, chaired by the author and his wife, ranks 6th among Maine charities in terms of average annual giving with over $2.8 million in grants per year, according to The Grantsmanship Center.
In November 2011, the STK Foundation donated $70,000 in matched funding via his radio station to help pay the heating bills for families in need in his home town of Bangor, Maine, during the winter.
Personal life.
King and his wife own and occupy three different houses, one in Bangor, Maine, one in Lovell, Maine, and they regularly winter in their waterfront mansion located off the Gulf of Mexico, in Sarasota, Florida. He and Tabitha have three children, Naomi, Joe and Owen, and four grandchildren.
King's addictions to alcohol and other drugs were so serious during the 1980s that, as he acknowledged in "On Writing" in 2000, he can barely remember writing "Cujo".:73 Shortly after the novel's publication, King's family and friends staged an intervention, dumping on the rug in front of him evidence of his addictions taken from his office including beer cans, cigarette butts, grams of cocaine, Xanax, Valium, NyQuil, dextromethorphan (cough medicine) and marijuana. As King related in his memoir, he then sought help, quit all drugs (including alcohol) in the late 1980s, and has remained sober since.:72 The first novel he wrote after becoming sober was "Needful Things".
Tabitha King has published nine of her own novels. Both King's sons are published authors: Owen King published his first collection of stories, "We're All in This Together: A Novella and Stories", in 2005. Joseph Hillstrom King, who writes under the professional name Joe Hill, published a collection of short stories, "20th Century Ghosts", in 2005. His debut novel, "Heart-Shaped Box", was published in 2007 and will be adapted into a feature film by director Neil Jordan. King's daughter Naomi is a Unitarian Universalist Church minister in Plantation, Florida, with her same-sex partner, Rev. Dr. Thandeka.
King is a fan of baseball, and of the Boston Red Sox in particular; he frequently attends the team's home and away games, and occasionally mentions the team in his novels and stories. He helped coach his son Owen's Bangor West team to the Maine Little League Championship in 1989. He recounts this experience in the "New Yorker" essay "Head Down", which appears also in the collection "Nightmares & Dreamscapes". In 1999, King wrote "The Girl Who Loved Tom Gordon," featuring former Red Sox pitcher Tom Gordon as the protagonist's imaginary companion. In 2004, King co-wrote a book titled "" with Stewart O'Nan, recounting the authors' roller-coaster reaction to the Red Sox's 2004 season, a season culminating in the Sox winning the 2004 American League Championship Series and World Series. In the 2005 film "Fever Pitch," about an obsessive Boston Red Sox fan, King tosses out the first pitch of the Sox's opening-day game.
Further reading.
</dl>

</doc>
<doc id="26956" url="http://en.wikipedia.org/wiki?curid=26956" title="Silent film">
Silent film

A silent film is a film with no synchronized recorded sound, especially with no spoken dialogue. In silent films for entertainment the dialogue is transmitted through muted gestures, mime and title cards. The idea of combining motion pictures with recorded sound is nearly as old as film itself, but because of the technical challenges involved, synchronized dialogue was only made practical in the late 1920s with the perfection of the Audion amplifier tube and the introduction of the Vitaphone system. (The term "silent film" is therefore a retronym, that is, a term created to distinguish something retroactively – the descriptor "silent" used before the late 1920s would have been a redundancy.) After the release of "The Jazz Singer" in 1927, "talkies" became more and more commonplace. Within a decade, popular widespread production of silent films had ceased.
A September 2013 report by the United States Library of Congress announced that a total of 70% of American silent films are believed to be completely lost.
Elements (1894 – 1929).
The earliest precursors of film began with image projection through the use of an item known as the magic lantern. This utilized a lens, shutter and persistent light source to project images on glass slides. These slides used were originally painted, but photographs were used later on after the technological advent of photography in the nineteenth century. Interestingly enough, the invention of a practical photography apparatus only precedes cinema by fifty years.
The next significant step towards film creation was the development of an understanding of image movement. Simulations of movement date as far back as to 1828 and only four years after Paul Roget discovered the phenomenon he called Persistence of Vision. Roget showed that when a series of still photographs are shown at a considerable speed in front of one's eye, the photographs merge into one registered image that appears to be moving. This experience was further demonstrated through Roget's introduction of the thaumatrope, a device which spun a disk with an image on its surface at a fairly high rate of speed.
The first projected primary proto-movie was made by Eadweard Muybridge sometime between 1877 and 1880. Muybridge set up a row of cameras along a racetrack and timed image exposures to capture the many stages of a horse's gallop. The oldest surviving film (of the genera called pictorial realism) was created by Louis Le Prince in 1888. It was a two-second film of people walking in "Oakwood streets" garden, entitled "Roundhay Garden Scene". The development of Thomas Edison's Kinetograph, a photographic device that capture sequential images, and his Kinetoscope, a viewing device for these photos, allowed for the creation and exhibition of short films. Edison also made a business of selling Kinetograph and Kinetoscope equipment, which laid the foundation for widespread film production. 
Due to Edison's lack of securing an international copyright on his film inventions, similar devices were "invented" around the world. The Lumière brothers (Louis and Auguste Lumière), for example, created the Cinématographe in France. The Cinématographe proved to be a more portable and practical device than both of Edison's as it combined a camera, film processor and projector in one unit. In contrast to Edison's "peepshow" kinetoscope, the cinematograph allowed simultaneous viewing by multiple parties. Their first film, Sortie de l'usine Lumière de Lyon, shot in 1894, is considered the first true motion picture.
From the very beginnings of film production, the art of motion pictures grew into full maturity in the "silent era" (1894–1929) before silent films were replaced by "talking pictures" in the late 1920s. Many film scholars and buffs argue that the aesthetic quality of cinema decreased for several years until directors, actors, and production staff adapted to the new "talkies".
The visual quality of silent movies—especially those produced in the 1920s—was often high. However, there is a widely held misconception that these films were primitive and barely watchable by modern standards. This misconception comes as a result of silent films being played back at wrong speed and their deteriorated condition. Many silent films exist only in second- or third-generation copies, often copied from already damaged and neglected film stock.
In addition, many prints may suffer from censorship cuts and missing frames and scenes, resulting in what may appear to be poor editing.
Intertitles.
As motion pictures eventually increased in length, a replacement was needed for the in-house interpreter who would explain parts of the film. Because silent films had no synchronized sound for dialogue, onscreen intertitles were used to narrate story points, present key dialogue and sometimes even comment on the action for the cinema audience. The "title writer" became a key professional in silent film and was often separate from the "scenario writer" who created the story. Intertitles (or "titles" as they were generally called at the time) often became graphic elements themselves, featuring illustrations or abstract decoration that commented on the action.
Live music and sound.
Showings of silent films almost always featured live music, starting with the guitarist, at the first public projection of movies by the Lumière Brothers on December 28, 1895 in Paris. This was furthered in 1896 by the first motion picture exhibition in the United States at Koster and Bial's Music Hall in New York City. At this event, Edison set the precedent that all exhibitions should be accompanied by an orchestra. From the beginning, music was recognized as essential, contributing to the atmosphere and giving the audience vital emotional cues. (Musicians sometimes played on film sets during shooting for similar reasons.) However, depending on the size of the exhibition site, musical accompaniment could drastically change in size. Small town and neighborhood movie theatres usually had a pianist. Beginning in the mid-1910s, large city theaters tended to have organists or ensembles of musicians. Massive theater organs were designed to fill a gap between a simple piano soloist and a larger orchestra. Theatre organs had a wide range of special effects; theatrical organs such as the famous "Mighty Wurlitzer" could simulate some orchestral sounds along with a number of percussion effects such as bass drums and cymbals and sound effects ranging from galloping horses to rolling rain.
Film scores for early silent films were either improvised or compiled of classical or theatrical repertory music. Once full features became commonplace, however, music was compiled from photoplay music by the pianist, organist, orchestra conductor or the movie studio itself, which included a cue sheet with the film. These sheets were often lengthy, with detailed notes about effects and moods to watch for. Starting with the mostly original score composed by Joseph Carl Breil for D. W. Griffith's groundbreaking epic "The Birth of a Nation" (USA, 1915) it became relatively common for the biggest-budgeted films to arrive at the exhibiting theater with original, specially composed scores. However, the first designated full blown scores were composed earlier, in 1908, by Camille Saint-Saëns, for "The Assassination of the Duke of Guise", and by Mikhail Ippolitov-Ivanov, for "Stenka Razin".
When organists or pianists used sheet music, they still might add improvisational flourishes to heighten the drama on screen. Even when special effects were not indicated in the score, if an organist was playing a theater organ capable of an unusual sound effect, such as a "galloping horses" effect, it would be used for dramatic horseback chases.
By the height of the silent era, movies were the single largest source of employment for instrumental musicians (at least in America). But the introduction of talkies, which happened simultaneously with the onset of the Great Depression, was devastating to many musicians.
Some countries devised other ways of bringing sound to silent films. The early cinema of Brazil featured "fitas cantatas": filmed operettas with singers performing behind the screen. In Japan, films had not only live music but also the "benshi", a live narrator who provided commentary and character voices. The "benshi" became a central element in Japanese film, as well as providing translation for foreign (mostly American) movies. The popularity of the "benshi" was one reason why silent films persisted well into the 1930s in Japan.
Score restorations from 1980 to the present.
Few film scores survive intact from the silent period, and musicologists are still confronted by questions when they attempt to precisely reconstruct those that remain. Scores used in current reissues or showings of silent films may be: A) complete reconstructions of composed scores, B) scores newly composed for the occasion, C) scores assembled from already existing music libraries, or D) scores improvised on the spot in the manner of the silent era theater pianist or organist.
Interest in the scoring of silent films fell somewhat out of fashion during the 1960s and 1970s. There was a belief in many college film programs and repertory cinemas that audiences should experience silent film as a pure visual medium, undistracted by music. This belief may have been encouraged by the poor quality of the music tracks found on many silent film reprints of the time. Since around 1980, there has been a revival of interest in presenting silent films with quality musical scores, either reworkings of period scores or cue sheets, or composition of appropriate original scores. An early effort in this context was Kevin Brownlow's 1980 restoration of Abel Gance's "Napoléon" (1927), featuring a score by Carl Davis. Brownlow's restoration was later distributed in America re-edited and shortened by Francis Ford Coppola with a live orchestral score composed by his father Carmine Coppola.
In 1984, an edited restoration of "Metropolis" (1927) was released to cinemas with a new rock music score by producer-composer Giorgio Moroder. Although the contemporary score, which included pop songs by Freddie Mercury of Queen, Pat Benatar and Jon Anderson of Yes was controversial, the door had been opened for a new approach to presentation of classic silent films.
Currently, a number of soloists, music ensembles, and orchestras perform traditional and contemporary scores for silent films. The legendary theater organist Gaylord Carter continued to perform and record his original silent film scores until shortly before his death in 2000; some of these scores are available on DVD reissues. Other purveyors of the traditional approach include organists such as Dennis James and pianists such as Neil Brand, Günter Buchwald, Philip C. Carli, Ben Model, and William P. Perry. Other contemporary pianists, such as Stephen Horne and Gabriel Thibaudeau, have taken a more modern approach to scoring.
Orchestral conductors such as Carl Davis and Robert Israel have written and compiled scores for numerous silent films; many of these have been featured in showings on Turner Classic Movies or have been released on DVD. Davis has composed new scores for classic silent dramas such as "The Big Parade" (1925) and "Flesh and the Devil" (1927). Israel has worked mainly in silent comedy, scoring films of Harold Lloyd, Buster Keaton, Charley Chase and others. Timothy Brock has restored many of Charlie Chaplin's scores, in addition to composing new scores. 
Contemporary music ensembles are helping to introduce classic silent films to a wider audience through a broad range of musical styles and approaches. Some performers create new compositions using traditional musical instruments while others add electronic sounds, modern harmonies, rhythms, improvisation and sound design elements to enhance the film watching experience. Among the contemporary ensembles in this category are Un Drame Musical Instantané, Alloy Orchestra, Club Foot Orchestra and Silent Orchestra. Donald Sosin and Joanna Seaton specialize in adding vocals to silent films, particularly where there is onscreen singing that benefits from hearing the actual song being performed. Films in this category include Griffith's "Lady of the Pavements" with Lupe Velez, Carew's "Evangeline" with Dolores del Rio, and Julian's "Phantom of the Opera" with Mary Philbin and Virginia Pearson.
Acting techniques.
Silent film actors emphasized body language and facial expression so that the audience could better understand what an actor was feeling and portraying on screen. Much silent film acting is apt to strike modern-day audiences as simplistic or campy. The melodramatic acting style was in some cases a habit actors transferred from their former stage experience. Vaudeville was an especially popular origin for many American silent film actors. The pervading presence of stage actors in film was the cause of this outburst from director Marshall Neilan in 1917: "The sooner the stage people who have come into pictures get out, the better for the pictures." In other cases, directors such as John Griffith Wray required their actors to deliver larger-than-life expressions for emphasis. As early as 1914, American viewers had begun to make known their preference for greater naturalness on screen.
In any case, the large image size and unprecedented intimacy the actor enjoyed with the audience began to affect acting style, making for more subtlety of expression. Actresses such as Mary Pickford in all her films, Eleonora Duse in the Italian film "Cenere" (1916), Janet Gaynor in "Sunrise", Priscilla Dean in "Outside the Law" and "White Tiger", and Lillian Gish and Greta Garbo in most of their performances made restraint and easy naturalism in acting a virtue. Directors such as Albert Capellani (a French director who also did work in America directing Alla Nazimova films) and Maurice Tourneur insisted on naturalism in their films. Tourneur had been just such a minimalist in his prior stage productions. By the mid-1920s many American silent films had adopted a more naturalistic acting style, though not all actors and directors accepted naturalistic, low-key acting straight away; as late as 1927, films featuring expressionistic acting styles, such as "Metropolis", were still being released. Some viewers liked the flamboyant acting for its escape value, and some countries were later than the United States in embracing naturalistic style in their films. Just as today, a film's success depended upon the setting, the mood, the script, the skills of the director, and the overall talent of the cast.
According to Anton Kaes, a silent film scholar from the University of Wisconsin, American silent cinema began to see a shift in acting techniques between 1913 and 1921, mainly influenced by techniques found in German silent film. This is mainly attributed to the influx of emigrants from the Weimar Republic, "including film directors, producers, cameramen, lighting and stage technicians, as well as actors and actresses."
Projection speed.
Until the standardization of the projection speed of 24 frames per second (fps) for sound films between 1926 and 1930, silent films were shot at variable speeds (or "frame rates") anywhere from 12 to 40 fps, depending on the year and studio. "Standard silent film speed" is often said to be 16 fps as a result of the Lumière brothers' Cinématographe, but industry practice varied considerably; there was no actual standard. William Kennedy Laurie Dickson, an Edison employee, settled on the astonishingly fast 40 frames per second. Additionally, cameramen of the era insisted that their cranking technique was exactly 16 fps, but modern examination of the films shows this to be in error, that they often cranked faster. Unless carefully shown at their intended speeds silent films can appear unnaturally fast or slow. However, some scenes were intentionally undercranked during shooting to accelerate the action—particularly for comedies and action films.
Slow projection of a cellulose nitrate base film carried a risk of fire, as each frame was exposed for a longer time to the intense heat of the projection lamp; but there were other reasons to project a film at a greater pace. Often projectionists received general instructions from the distributors on the musical director's cue sheet as to how fast particular reels or scenes should be projected. In rare instances, usually for larger productions, cue sheets specifically for the projectionist provided a detailed guide to presenting the film. Theaters also—to maximize profit—sometimes varied projection speeds depending on the time of day or popularity of a film, and to fit a film into a prescribed time slot.
All motion-picture film projectors require a moving shutter to block the light whilst the film is moving, otherwise the image is smeared in the direction of the movement. However this shutter causes the image to "flicker", and images with low rates of flicker are very unpleasant to watch. Early studies by Thomas Edison for his Kinetoscope machine determined that any rate below 46 images per second "will strain the eye." and this holds true for projected images under normal cinema conditions also. The solution adopted for the Kinetoscope was to run the film at over 40 frames/sec, but this is expensive on film. However by using projectors with dual- and triple-blade shutters the flicker rate is multiplied two or three times higher than the number of film frames — each frame being flashed two or three times on screen. A three-blade shutter projecting a 16 fps film will slightly surpass Edison's figure, giving the audience 48 images per second. During the silent era projectors were commonly fitted with 3-bladed shutters. Since the introduction of sound with its 24 frame/sec standard speed 2-bladed shutters have become the norm for 35 mm cinema projectors, though three-bladed shutters have remained standard on 16 mm and 8 mm projectors which are frequently used to project amateur footage shot at 16 or 18 frames/sec. A 35 mm film frame rate of 24 fps translates to a film speed of 456 mm per second. One 1000 ft reel requires 11 minutes and 7 seconds to be projected at 24 fps, while a 16 fps projection of the same reel would take 16 minutes and 40 seconds; 304 mm per second.
In the 1950s, many telecine conversions of silent films at grossly incorrect frame rates for broadcast television may have alienated viewers. Film speed is often a vexed issue among scholars and film buffs in the presentation of silents today, especially when it comes to DVD releases of restored films; the 2002 restoration of "Metropolis" (Germany, 1927) may be the most fiercely debated example.
Tinting.
With the lack of natural color processing available, films of the silent era were frequently dipped in dyestuffs and dyed various shades and hues to signal a mood or represent a time of day. Hand tinting dates back to 1895 in the United States with Edison's release of selected hand-tinted prints of "Butterfly Dance". Additionally, experiments in color film started as early as in 1909, although it took a much longer time for color to be adopted by the industry and an effective process to be developed. Blue represented night scenes, yellow or amber meant day. Red represented fire and green represented a mysterious atmosphere. Similarly, toning of film (such as the common silent film generalization of sepia-toning) with special solutions replaced the silver particles in the film stock with salts or dyes of various colors. A combination of tinting and toning could be used as an effect that could be striking.
Some films were hand-tinted, such as "Annabelle Serpentine Dance" (1894), from Edison Studios. In it, Annabelle Whitford, a young dancer from Broadway, is dressed in white veils that appear to change colors as she dances. This technique was designed to capture the effect of the live performances of Loie Fuller, beginning in 1891, in which stage lights with colored gels turned her white flowing dresses and sleeves into artistic movement. Hand coloring was often used in the early "trick" and fantasy films of Europe, especially those by Georges Méliès. Méliès began hand-tinting his work as early as 1897 and the 1899 "Cendrillion" (Cinderella) and 1900 "Jeanne d'Arc" (Joan of Arc) provide early examples of hand-tinted films in which the color was a critical part of the scenography or "mise an scene"; such precise tinting used the workshop of Elisabeth Thuillier in Paris, with teams of female artists adding layers of color to each frame by hand rather than using a more common (and less expensive) process of stenciling. A newly restored version of Méliès' "A Trip to the Moon", originally released in 1902, shows an exuberant use of color designed to add texture and interest to the image.
By the beginning of the 1910s, with the onset of feature-length films, tinting was used as another mood setter, just as commonplace as music. The director D. W. Griffith displayed a constant interest and concern about color, and used tinting as a special effect in many of his films. His 1915 epic, "The Birth of a Nation", used a number of colors, including amber, blue, lavender, and a striking red tint for scenes such as the "burning of Atlanta" and the ride of the Ku Klux Klan at the climax of the picture. Griffith later invented a color system in which colored lights flashed on areas of the screen to achieve a color.
Unfortunately with the development of sound-on-film technology and the industry's acceptance of it, tinting was abandoned altogether. This is because the dyes used in the tinting process interfered with the soundtracks present on film strips. 
Top grossing silent films in the United States.
The following are American films from the silent film era that had earned the highest gross income as of 1932. The amounts given are gross rentals (the distributor's share of the box-office) as opposed to exhibition gross.
During the sound era.
Transition.
Although attempts to create sync-sound motion pictures go back to the Edison lab in 1896, only from the early 1920s were the basic technologies such as vacuum tube amplifiers and high-quality loudspeakers available. The next few years saw a race to design, implement, and market several rival sound-on-disc and sound-on-film sound formats, such as Photokinema (1921), Phonofilm (1923), Vitaphone (1926), Fox Movietone (1927) and RCA Photophone (1928).
Warner Bros was the first studio to accept sound as an element in film production and utilize Vitaphone, a sound-on-disc technology, to do so. Warner Bros The studio then released "The Jazz Singer" in 1927 which marked the first commercially successful sound film, but silent films were still the majority of features released in both 1927 and 1928, along with so-called goat-glanded films: silents with a section of sound film inserted. Thus the modern sound film era may be regarded as coming to dominance beginning in 1929.
For a listing of notable silent era films, see "list of years in film" for the years between the beginning of film and 1928. The following list includes only films produced in the sound era with the specific artistic intention of being silent.
Later homages.
Several filmmakers have paid homage to the comedies of the silent era, including Jacques Tati with his "Les Vacances de Monsieur Hulot" (1953) and Mel Brooks with "Silent Movie" (1976). Taiwanese director Hou Hsiao-Hsien's acclaimed drama "Three Times" (2005) is silent during its middle third, complete with intertitles; Stanley Tucci's "The Impostors" has an opening silent sequence in the style of early silent comedies. Brazilian filmmaker Renato Falcão's "Margarette's Feast" (2003) is silent. Writer / Director Michael Pleckaitis puts his own twist on the genre with "Silent" (2007). While not silent, the "Mr. Bean" television series and movies have used the title character's non-talkative nature to create a similar style of humor. A lesser-known example is Jérôme Savary's "La fille du garde-barrière" (1975), an homage to silent-era films that uses intertitles and blends comedy, drama, and explicit sex scenes (which led to it being refused a cinema certificate by the British Board of Film Classification).
In 1990, Charles Lane directed and starred in "Sidewalk Stories", a low budget salute to sentimental silent comedies particularly Charlie Chaplin's "The Kid".
The German film "Tuvalu" (1999) is mostly silent; the small amount of dialog is an odd mix of European languages, increasing the film's universality. Guy Maddin won awards for his homage to Soviet era silent films with his short "The Heart of the World" after which he made a feature-length silent, "Brand Upon the Brain!" (2006), incorporating live Foley artists, narration and orchestra at select showings. "Shadow of the Vampire" (2000) is a highly fictionalized depiction of the filming of Friedrich Wilhelm Murnau's classic silent vampire movie "Nosferatu" (1922). Werner Herzog honored the same film in his own version, "" (1979).
Some films draw a direct contrast between the silent film era and the era of talkies. "Sunset Boulevard" shows the disconnect between the two eras in the character of Norma Desmond, played by silent film star Gloria Swanson, and "Singin' in the Rain" deals with the period where the people of Hollywood had to face changing from making silents to talkies. Peter Bogdanovich's affectionate 1976 film "Nickelodeon" deals with the turmoil of silent filmmaking in Hollywood during the early 1910s, leading up to the release of D. W. Griffith's epic "The Birth of a Nation" (1915).
In 1999, the Finnish filmmaker Aki Kaurismäki produced "Juha", which captures the style of a silent film, using intertitles in place of spoken dialogue. In India, the film "Pushpak" (1988), starring Kamal Hassan, was a black comedy entirely devoid of dialog. The Australian film "Dr Plonk" (2007), was a silent comedy directed by Rolf de Heer. Stage plays have drawn upon silent film styles and sources. Actor/writers Billy Van Zandt & Jane Milmore staged their Off-Broadway slapstick comedy "Silent Laughter" as a live action tribute to the silent screen era. Geoff Sobelle and Trey Lyford created and starred in "All Wear Bowlers" (2004), which started as an homage to Laurel and Hardy then evolved to incorporate life-sized silent film sequences of Sobelle and Lyford who jump back and forth between live action and the silver screen. The animated film "Fantasia" (1940), which is eight different animation sequences set to music, can be considered a silent film, with only one short scene involving dialogue. The espionage film "The Thief" (1952) has music and sound effects, but no dialogue.
In 2005, the H. P. Lovecraft Historical Society produced a silent film version of Lovecraft's story "The Call of Cthulhu". This film maintained a period-accurate filming style, and was received as both "the best HPL adaptation to date" and, referring to the decision to make it as a silent movie, "a brilliant conceit."
The French film "The Artist" (2011), written and directed by Michel Hazanavicius, plays as a silent film and is set in Hollywood during the silent era. It also includes segments of fictitious silent films starring its protagonists.
The Japanese vampire film "Sanguivorous" (2011) is not only done in the style of a silent film, but even toured with live orchestral accompiment. Eugene Chadbourne has been among those who have played live music for the film.
"Blancanieves" is a 2012 Spanish black-and-white silent fantasy drama film written and directed by Pablo Berger.
The American feature-length silent film "Silent Life" started in 2006, features performances by Isabella Rossellini and Galina Jovovich, mother of Milla Jovovich, will premiere in 2013. The film is based on the life of the silent screen icon Rudolph Valentino, known as the Hollywood's first "Great Lover". After the emergency surgery, Valentino loses his grip of reality and begins to see the recollection of his life in Hollywood from a perspective of a coma - as a silent film shown at a movie palace, the magical portal between life and eternity, between reality and illusion.
"Right There" is a 2013 short film which is an homage to silent film comedies.
The American Theatre Organ Society pays homage to the music of silent films, as well as the theatre organs which played such music. With over 75 local chapters, the organization seeks to preserve and promote theater organs and music, as an art form.
Early studios.
The early studios were located in the New York City area. In December 1908, Edison led the formation of the Motion Picture Patents Company in an attempt to control the industry and shut out smaller producers. The "Edison Trust", as it was nicknamed, was made up of Edison, Biograph, Essanay Studios, Kalem Company, George Kleine Productions, Lubin Studios, Georges Méliès, Pathé, Selig Studios, and Vitagraph Studios, and dominated distribution through the General Film Company. This company dominated the industry as both a vertical and horizontal monopoly and is a contributing factor in studios migration to the West Coast. The Motion Picture Patents Co. and the General Film Co. were found guilty of antitrust violation in October 1915, and were dissolved. Edison Studios were first in West Orange, New Jersey (1892), they were moved to the Bronx, New York (1907). Fox (1909) and Biograph (1906) started in Manhattan, with studios in St George Staten Island. Others films were shot in Fort Lee, New Jersey. The Thanhouser film studio was founded in New Rochelle, New York in 1909 by American theatrical impresario Edwin Thanhouser. The company produced and released 1,086 films between 1910 and 1917, including the first film serial ever, "The Million Dollar Mystery", released in 1914. The first westerns were filmed at Scott's Movie Ranch. Cowboys and Indians galloped across Fred Scott's movie ranch in South Beach, Staten Island, which had a frontier main street, a wide selection of stagecoaches and a 56-foot stockade. The island provided a serviceable stand-in for locations as varied as the Sahara desert and a British cricket pitch. War scenes were shot on the plains of Grasmere, Staten Island. "The Perils of Pauline" and its even more popular sequel "The Exploits of Elaine" were filmed largely on the island. So was the 1906 blockbuster "Life of a Cowboy", by Edwin S. Porter. Companies and filming moved to the west coast around 1911.
Preservation and lost films.
Many early motion pictures are lost because the nitrate film used in that era was extremely unstable and flammable. Additionally, many films were deliberately destroyed because they had little value in the era before home video. It has often been claimed that around 75% of silent films have been lost, though these estimates may be inaccurate due to a lack of numerical data. Major silent films presumed lost include "Saved from the Titanic" (1912), which featured survivors of the disaster; "The Life of General Villa", starring Pancho Villa himself; "The Apostle", the world's first animated feature film (1917); "Cleopatra" (1917); "Gold Diggers" (1923); "Kiss Me Again" (1925); "Arirang" (1926); "Gentlemen Prefer Blondes" (1927); "The Great Gatsby" (1926); and "London After Midnight" (1927). Though most lost silent films will never be recovered, some have been discovered in film archives or private collections. Discovered and preserved versions may be editions made for the home rental market of the 20s and 30s that are discovered in estate sales, etc.
In 1978 in Dawson City, Yukon, a bulldozer uncovered buried reels of nitrate film during excavation of a landfill. Dawson City was once the end of the distribution line for many films. The retired titles were stored at the local library until 1929 when the flammable nitrate was used as landfill in a condemned swimming pool. Stored for 50 years under the permafrost of the Yukon, the films turned out to be extremely well preserved. Included were films by Pearl White, Harold Lloyd, Douglas Fairbanks, and Lon Chaney. These films are now housed at the Library of Congress. The degradation of old film stock can be slowed through proper archiving, and films can be transferred to digital media for preservation. Silent film preservation has been a high priority among film historians.

</doc>
<doc id="26961" url="http://en.wikipedia.org/wiki?curid=26961" title="Shia Islam">
Shia Islam

The Shia (; Arabic: شيعة‎ "Shīʿah"), or the Shiites (), represent the second largest denomination of Islam.
Adherents of Shia Islam are called Shias or the Shi'a as a collective or Shi'i individually. "Shi'a" is the short form of the historic phrase "Shīʻatu ʻAlī" (شيعة علي) meaning "followers", "faction" or "party" of Muhammad's son-in-law and cousin Ali, whom the Shia believe to be Muhammad's successor in the Caliphate. Twelver Shia ("Ithnā'ashariyyah") is the largest branch of Shia Islam, and the term Shia Muslim is often taken to refer to Twelvers by default. s of 2009[ [update]] Shia Muslims constituted 10-13% of the world's Muslim population, Shias comprised 11-14% of the Muslim population in the Middle East-North Africa region, and between 68% and 80% of Shias lived in four countries: Iran, Pakistan, India and Iraq.
Shia Islam is based on the Quran and the message of the Islamic prophet Muhammad attested in hadith recorded by the Shia, and certain books deemed sacred to the Shia (Nahj al-Balagha). Shia consider Ali to have been divinely appointed as the successor to Muhammad, and as the first Imam. The Shia also extend this "Imami" doctrine to Muhammad's family, the "Ahl al-Bayt" ("the People of the House"), and certain individuals among his descendants, known as "Imams", who they believe possess special spiritual and political authority over the community, infallibility, and other divinely-ordained traits. Although there are myriad Shia subsects, modern Shia Islam has been divided into three main groupings: Twelvers, Ismailis and Zaidis.
Etymology.
The word "Shia" (Arabic: شيعة‎ "shīʻah" /ˈʃiːʕa/) means follower and is the short form of the historic phrase "shīʻatu ʻAlī" (شيعة علي /ˈʃiːʕatu ˈʕaliː/), meaning "followers of Ali", "faction of Ali", or "party of Ali". "Shi'a" and "Shiism" are forms used in English, while "Shi'ite" or "Shiite", as well as "Shia", refer to its adherents.
The word Shia means "sect" or "faction". The plural is شِيَع, and the singular is شائع, "Shaih", the word used by Winston Churchill in a discussion of the religious mixture of modern-day Iraq.
Beliefs.
Imamate.
Succession of Ali.
Shia Muslims believe that just as a prophet is appointed by God alone, only God has the prerogative to appoint the successor to his prophet. They believe God chose Ali to be Muhammad's successor, infallible, the first caliph ("khalifa", head of state) of Islam. Muhammad, before his death, designated Ali as his successor.
Ali was Muhammad's first cousin and closest living male relative as well as his son-in-law, having married Muhammad's daughter Fatimah. Ali would eventually become the fourth Muslim (sunni) caliph.
After the Farewell Pilgrimage, Muhammad ordered the gathering of Muslims at the pond of Khumm and it was there that Shia Muslims believe Muhammad nominated Ali to be his successor. The hadith of the pond of Khumm was narrated on 18th of Dhu al-Hijjah of 10 AH in the Islamic calendar (10 March 632 AD) at a place called Ghadir Khumm, located near the city of al-Juhfah, Saudi Arabia. Muhammad there stated:
 Oh people! Reflect on the Quran and comprehend its verses. Look into its clear verses and do not follow its ambiguous parts, for by Allah, none shall be able to explain to you its warnings and its mysteries, nor shall anyone clarify its interpretation, other than the one that I have grasped his hand, brought up beside myself, [and lifted his arm,] the one about whom I inform you that whomever I am his master ("Mawla")), then Ali is his master ("Mawla"); and he is Ali Ibn Abi Talib, my brother, the executor of my will ("Wasiyyi"), whose appointment as your guardian and leader has been sent down to me from Allah, the mighty and the majestic.
 — Muhammad, " from "The Farewell Sermon"
Shia Muslims believe this to be Muhammad's appointment of Ali as his successor.
Ali's caliphate.
When Muhammad died in 632 CE, Ali and Muhammad's closest relatives made the funeral arrangements. While they were preparing his body, Abu Bakr, Umar, and Abu Ubaidah ibn al Jarrah met with the leaders of Medina and elected Abu Bakr as caliph. Ali and his family accepted the appointment for the sake of unity in the early Muslim community. It was not until the murder of the third caliph, Uthman, in 657 CE that the Muslims in Medina in desperation invited Ali to become the fourth caliph as the last source, and he established his capital in Kufah in present-day Iraq.
Ali's rule over the early Muslim community was often contested, and wars were waged against him. As a result, he had to struggle to maintain his power against the groups who betrayed him after giving allegiance to his succession, or those who wished to take his position. This dispute eventually led to the First Fitna, which was the first major civil war within the Islamic Caliphate. The Fitna began as a series of revolts fought against the first imam, Ali ibn Abi Talib, caused by the assassination of his political predecessor, Uthman ibn Affan. While the rebels who accused Uthman of prejudice affirmed Ali's "khilafa" (caliph-hood), they later turned against him and fought him. Ali ruled from 656 CE to 661 CE, when he was assassinated while prostrating in prayer ("sujud"). Ali's main rival Muawiyah then claimed the caliphate.
Imam Hasan ibn Ali.
Upon the death of Ali, his elder son Hasan became leader of the Muslims of Kufa, and after a series of skirmishes between the Kufa Muslims and the army of Muawiyah, Hasan agreed to cede the caliphate to Muawiyah and maintain peace among Muslims upon certain conditions:
Hasan then retired to Medina, where in 50 AH he was poisoned by his wife Ja'da bint al-Ash'ath ibn Qays, after being secretly contacted by Muawiyah who wished to pass the caliphate to his own son Yazid and saw Hasan as an obstacle.
Husayn.
Husayn, Ali's younger son and brother to Hasan, initially resisted calls to lead the Muslims against Muawiyah and reclaim the caliphate. In 680 CE, Muawiyah died and passed the caliphate to his son Yazid. Yazid asked Husayn to swear allegiance ("bay'ah") to him. Ali's faction, having expected the caliphate to return to Ali's line upon Muawiyah's death, saw this as a betrayal of the peace treaty and so Husayn rejected this request for allegiance. There was a groundswell of support in Kufa for Husayn to return there and take his position as caliph and imam, so Husayn collected his family and followers in Medina and set off for Kufa. En route to Kufa, he was blocked by an army of Yazid's men near Karbala (modern Iraq), and Husayn and approximately 72 of his family and followers were killed in the Battle of Karbala.
The Shias regard Husayn as a martyr ("shahid"), and count him as an Imam from the Ahl al-Bayt. They view Husayn as the defender of Islam from annihilation at the hands of Yazid I. Husayn is the last imam following Ali whom all Shiah sub-branches mutually recognise. The Battle of Karbala is often cited as the definitive break between the Shiah and Sunni sects of Islam, and is commemorated each year by Shiah Muslims on the Day of Ashura.
Imamate of the "Ahl al-Bayt".
Most of the early Shia differed only marginally from mainstream Sunnis in their views on political leadership, but it is possible in this sect to see a refinement of Shia doctrine. Early Sunnis traditionally held that the political leader must come from the tribe of Muhammad—namely, the Quraysh tribe. The Zaydis narrowed the political claims of the Ali's supporters, claiming that not just any descendant of Ali would be eligible to lead the Muslim community ("ummah") but only those males directly descended from Muhammad through the union of Ali and Fatimah. But during the Abbasid revolts, other Shia, who came to be known as Imamiyyah (followers of the Imams), followed the theological school of Imam Ja'far al-Sadiq, himself the great great grandson of the Prophet Muhammad's son-in-law Imam Ali . They asserted a more exalted religious role for Imams and insisted that, at any given time, whether in power or not, a single male descendant of Ali and Fatimah was the divinely appointed Imam and the sole authority, in his time, on all matters of faith and law. To those Shia, love of the imams and of their persecuted cause became as important as belief in God's oneness and the mission of Muhammad.
Later most of the Shia, including Twelver and Ismaili, became Imamis. Imami Shia believe that Imams are the spiritual and political successors to Muhammad. Imams are human individuals who not only rule over the community with justice, but also are able to keep and interpret the divine law and its esoteric meaning. The words and deeds of Muhammad and the imams are a guide and model for the community to follow; as a result, they must be free from error and sin, and must be chosen by divine decree, or "nass", through Muhammad.
According to this view, there is always an Imam of the Age, who is the divinely appointed authority on all matters of faith and law in the Muslim community. Ali was the first imam of this line, the rightful successor to Muhammad, followed by male descendants of Muhammad through his daughter Fatimah.
This difference between following either the Ahl al-Bayt (Muhammad's family and descendants) or Caliph Abu Bakr has shaped Shia and non-Shia views on some of the Quranic verses, the hadith (narrations from Muhammad) and other areas of Islam. For instance, the collection of hadith venerated by Shia Muslims is centered on narrations by members of the Ahl al-Bayt and their supporters, while some hadith by narrators not belonging to or supporting the Ahl al-Bayt are not included. Those of Abu Hurairah, for example, Ibn Asakir in his Ta'rikh Kabir and Muttaqi in his Kanzu'l-Umma report that Caliph Umar lashed him, rebuked him, and forbade him to narrate hadith from Muhammad. Umar said: "Because you narrate hadith in large numbers from the Holy Prophet, you are fit only for attributing lies to him. (That is, one expects a wicked man like you to utter only lies about the Holy Prophet.) So you must stop narrating hadith from the Prophet; otherwise, I will send you to the land of Dus." (A clan in Yemen, to which Abu Huraira belonged.) According to Sunnis, Ali was the fourth successor to Abu Bakr, while the Shia maintain that Ali was the first divinely sanctioned "Imam", or successor of Muhammad. The seminal event in Shia history is the martyrdom in 680 CE at the Battle of Karbala of Ali's son Hussein ibn Ali, who led a non-allegiance movement against the defiant caliph (71 of Hussein's followers were killed as well). Hussein came to symbolize resistance to tyranny.
It is believed in Twelver and Ismaili Shia Islam that 'aql, divine wisdom, was the source of the souls of the prophets and imams and gave them esoteric knowledge called "ḥikmah" and that their sufferings were a means of divine grace to their devotees. Although the imam was not the recipient of a divine revelation, he had a close relationship with God, through which God guides him, and the imam in turn guides the people. Imamate, or belief in the divine guide, is a fundamental belief in the Twelver and Ismaili Shia branches and is based on the concept that God would not leave humanity without access to divine guidance.
Imam of the time, last Imam of the Shia.
The Mahdi is the prophesied redeemer of Islam who will rule for seven, nine or nineteen years (according to differing interpretations) before the Day of Judgment and will rid the world of evil. According to Islamic tradition, the Mahdi's tenure will coincide with the Second Coming of Jesus Christ (Isa), who is to assist the Mahdi against the Masih ad-Dajjal (literally, the "false Messiah" or Antichrist). Jesus, who is considered the Masih (Messiah) in Islam, will descend at the point of a white arcade, east of Damascus, dressed in yellow robes with his head anointed. He will then join the Mahdi in his war against the Dajjal, where Jesus will slay Dajjal and unite mankind.
Theology.
The Shia Islamic faith is vast and inclusive of many different groups. Shia theological beliefs and religious practises, such as prayers, slightly differ from the Sunnis'. While all Muslims pray five times daily, Shias have the option of always combining "Dhuhr" with "Asr" and "Maghrib" with "Isha"', as there are three distinct times mentioned in the Quran. The Sunnis tend to combine only under certain circumstances. Shia Islam embodies a completely independent system of religious interpretation and political authority in the Muslim world. The original Shia identity referred to the followers of Imam Ali, and Shia theology was formulated in the 2nd century AH, or after Hijra (8th century CE). The first Shia governments and societies were established by the end of the 3rd century AH/9th century CE. The 4th century AH /10th century CE has been referred to by Louis Massignon as "the Shiite Ismaili century in the history of Islam".
Hadith.
The Shia believe that the status of Ali is supported by numerous hadith, including the Hadith of the pond of Khumm, Hadith of the two weighty things, Hadith of the pen and paper, Hadith of the invitation of the close families, and Hadith of the Twelve Successors. In particular, the Hadith of the Cloak is often quoted to illustrate Muhammad's feeling towards Ali and his family by both Sunni and Shia scholars. Shias prefer hadith attributed to the Ahl al-Bayt and close associates, and have their own separate collection of hadiths.
Profession of faith.
The Shia version of the Shahada, the Islamic profession of faith, differs from that of the Sunni. The Sunni Shahada states "There is no god except God, Muhammad is the messenger of the God", but to this the Shia append "Ali is the Wali (friend or intimate associate) of God", علي ولي الله. This phrase embodies the Shia emphasis on the inheritance of authority through Muhammad's lineage. The three clauses of the Shia Shahada thus address "tawhid" (the unity of God), "nubuwwah" (the prophethood of Muhammad), and "imamah" (imamate, the leadership of the faith).
Infallibility.
"Ismah" is the concept of infallibility or "divinely bestowed freedom from error and sin" in Islam. Muslims believe that Muhammad and other prophets in Islam possessed "ismah". Twelver and Ismaili Shia Muslims also attribute the quality to Imams as well as to Fatimah, daughter of Muhammad, in contrast to the Zaidi, who do not attribute 'ismah to the Imams. Though initially beginning as a political movement, infallibility and sinlessness of the imams later evolved as a distinct belief of (non-Zaidi) Shiism.
According to Shia theologians, infallibility is considered a rational necessary precondition for spiritual and religious guidance. They argue that since God has commanded absolute obedience from these figures they must only order that which is right. The state of infallibility is based on the Shia interpretation of the verse of purification. Thus, they are the most pure ones, the only immaculate ones preserved from, and immune to, all uncleanness. It does not mean that supernatural powers prevent them from committing a sin, but due to the fact that they have absolute belief in God, they refrain from doing anything that is a sin.
They also have a complete knowledge of God's will. They are in possession of all knowledge brought by the angels to the prophets ("nabi") and the messengers ("rasul"). Their knowledge encompasses the totality of all times. They thus act without fault in religious matters. Shias regard Ali as the successor of Muhammad not only ruling over the community in justice, but also interpreting Islamic practices and its esoteric meaning. Hence he was regarded as being free from error and sin (infallible), and appointed by God by divine decree ("nass") to be the first Imam. Ali is known as "perfect man" ("al-insan al-kamil") similar to Muhammad, according to Shia viewpoint.
Occultation.
The Occultation is a belief in some forms of Shia Islam that a messianic figure, a hidden imam known as the Mahdi, will one day return and fill the world with justice. According to the Twelver Shia, the main goal of the Mahdi will be to establish an Islamic state and to apply Islamic laws that were revealed to Muhammad.
Some Shia, such as the Zaidi and Nizari Ismaili, do not believe in the idea of the Occultation. The groups which do believe in it differ as to which lineage of the Imamate is valid, and therefore which individual has gone into occultation. They believe there are many signs that will indicate the time of his return.
Twelver Shia Muslims believe that the Mahdi (the twelfth imam, Muhammad al-Mahdi) is already on Earth, is in occultation and will return at the end of time. Fatimid/ Bohra/ Dawoodi Bohra believe the same but for their 21st Tayyib. Whereas Sunnis believe the future Mahdi has not yet arrived on Earth.
History.
Historians dispute the origin of Shia Islam, with many Western scholars positing that Shiism began as a political faction rather than a truly religious movement. Other scholars disagree, considering this concept of religious-political separation to be an anachronistic application of a Western concept.
Following the Battle of Karbala, as various Shia-affiliated groups diffused in the emerging Islamic world, several nations arose based around a Shia leadership or population.
Safavids.
A major turning point in Shia history was the Safavid dynasty (1501–1736) in Persia. This caused a number of changes in the Muslim world:
With the fall of the Safavids, the state in Persia – including the state system of courts with government-appointed judges (qadis) – became much weaker. This gave the Sharia courts of "mujtahids" an opportunity to fill the legal vacuum and enabled the ulama to assert their judicial authority. The Usuli School also increased in strength at this time.
Community.
Demographics.
One of the lingering problems in estimating the Shia population is that unless the Shia form a significant minority in a Muslim country, the entire population is often listed as Sunni. Shiites are estimated to be 21–35 percent of the Muslim population in South Asia, although the total number is difficult to estimate due to that reason.
It is variously estimated that 10–20% of the world's Muslims are Shia. They may number up to 200 million as of 2009. The Shia majority countries are Iran, Iraq, Azerbaijan, Bahrain. They also form the plurality in Lebanon. Shias constitute 36.3% of entire local population and 38.6% of the local Muslim population of the Middle East.
Shia Muslims constitute 27-35% of the population in Lebanon, and as per some estimates from 35% to over 35-40% of the population in Yemen, 30%-35% of the citizen population in Kuwait (no figures exist for the non-citizen population), over 20% in Turkey, 10–20% of the population in Pakistan, and 10-19% of Afghanistan's population.
Saudi Arabia hosts a number of distinct Shia communities, including the Twelver Baharna in the Eastern Province and Nakhawila of Medina, and the Ismaili Sulaymani and Zaidiyyah of Najran. Estimations put the number of Shiite citizens at 2-4 million, accounting for roughly 15% of the local population.
Significant Shia communities exist in the coastal regions of West Sumatra and Aceh in Indonesia (see Tabuik). The Shia presence is negligible elsewhere in Southeast Asia, where Muslims are predominantly Shafi'i Sunnis. That is, except in Vietnam and Cambodia, where the totality of the small Muslim minority is made up of Shias of Imami persuasion.
A significant Shia minority is present in Nigeria, made up of modern-era converts to a Shia movement centered around Kano and Sokoto states. Several African countries like Kenya, South Africa, Somalia, etc. hold small minority populations of various Shia denominations, primarily descendants of immigrants from South Asia during the colonial period, such as the Khoja.
According to Shia Muslims, one of the lingering problems in estimating Shia population is that unless Shia form a significant minority in a Muslim country, the entire population is often listed as Sunni. The reverse, however, has not held true, which may contribute to imprecise estimates of the size of each sect. For example, the 1926 rise of the House of Saud in Arabia brought official discrimination against Shia.
List of nations for which the Shia population may be estimated.
Figures indicated in the first three columns below are based on the October 2009 demographic study by the Pew Research Center report, "Mapping the Global Muslim Population".
Persecution.
The history of Sunni-Shia relations has often involved violence, dating back to the earliest development of the two competing sects.
At various times Shia groups have faced persecution.
Militarily established and holding control over the Umayyad government, many Sunni rulers perceived the Shia as a threat – to both their political and their religious authority. The Sunni rulers under the Umayyads sought to marginalize the Shia minority, and later the Abbasids turned on their Shia allies and imprisoned, persecuted, and killed them. The persecution of the Shia throughout history by Sunni co-religionists has often been characterized by brutal and genocidal acts. Comprising only about 10–15% of the entire Muslim population, the Shia remain a marginalized community to this day in many Sunni Arab dominant countries without the rights to practice their religion and organize.
In 1514 the Ottoman sultan, Selim I, ordered the massacre of 40,000 Anatolian Shia. According to Jalal Al-e-Ahmad, "Sultan Selim I carried things so far that he announced that the killing of one Shiite had as much otherworldly reward as killing 70 Christians."
In 1801 the Al Saud-Wahhabi armies attacked and sacked Karbala, the Shia shrine in eastern Iraq that commemorates the death of Husayn.
Under Saddam Hussein's regime, 1973 to 2003, in Iraq, Shia Muslims were heavily persecuted.
In March 2011, the Malaysian government declared the Shia a "deviant" sect and banned them from promoting their faith to other Muslims, but left them free to practice it themselves privately.
Holidays.
Shia, celebrate the following annual holidays:
The following days are some of the most important holidays observed by Shia Muslims:
Holy sites.
The holiest sites common to all Muslims are Mecca, Medina and Jerusalem. For Shias, the Imam Husayn Shrine, Al Abbas Mosque in Karbala, and Imam Ali Mosque in Najaf are also highly revered.
Other venerated sites include Wadi-us-Salaam cemetery in Najaf, Al-Baqi' cemetery in Medina, Imam Reza shrine in Mashhad, Kadhimiya Mosque in Kadhimiya, Al-Askari Mosque in Samarra, Sahla Mosque and Great Mosque of Kufa in Kufa and several other sites in the cities of Qom, Susa and Damascus.
Most of the Shia holy places in Saudi Arabia have been destroyed by the warriors of the Ikhwan, the most notable being the tombs of the Imams in the Al-Baqi' cemetery in 1925. In 2006 a bomb destroyed the shrine of Al-Askari Mosque.
Branches.
The Shia belief throughout its history split over the issue of the Imamate. The largest branch are the Twelvers, followed by the Zaidi and Ismaili. All three groups follow a different line of Imamate.
Twelver.
Twelver Shia or the Ithnā'ashariyyah' is the largest branch of Shia Islam, and the term "Shia Muslim" often refers to the Twelvers by default. The term "Twelver" is derived from the doctrine of believing in twelve divinely ordained leaders, known as The Twelve Imams. Twelver Shia are also known as "Imami" or "Ja'fari", originated from the name of the 6th Imam, Ja'far al-Sadiq, who elaborated the twelver jurisprudence.
Twelvers constitute the majority of the population in Iran (90%), Azerbaijan (85%), Bahrain (70%), Iraq (65%), Lebanon (65% of Muslims).
Doctrine.
Twelver doctrine is based on five principles. These five principles known as "Usul ad-Din" are as follow:
More specifically, these principles are known as Usul al-Madhhab (principles of the Shia sect) according to Twelver Shias which differ from Daruriyat al-Din (Necessities of Religion) which are principles in order for one to be a Muslim. The Necessities of Religion do not include Leadership (Imamah) as it is not a requirement in order for one to be recognized as a Muslim. However, this category, according to Twelver scholars like Ayatollah al-Khoei, does include belief in God, Prophethood, the Day of Resurrection and other "necessities" (like belief in angels). In this regard, Twelver Shias draw a distinction in terms of believing in the main principles of Islam on the one hand, and specifically Shia doctrines like Imamah on the other.
Books.
Besides the Qurʾan which is common to all Muslims, the Shiʿah derive guidance from books of traditions ("ḥadīth") attributed to Muḥammad and the twelve imams. Below is a list of some of the most prominent of these books:
The Twelve Imams.
The "Twelve Imams" are the spiritual and political successors to Muhammad for the Twelvers. According to the theology of Twelvers, the successor of Muhammad is an infallible human individual who not only rules over the community with justice but also is able to keep and interpret the divine law and its esoteric meaning. The words and deeds of Muhammad and the imams are a guide and model for the community to follow; as a result, they must be free from error and sin, and Imams must be chosen by divine decree, or "nass", through Muhammad. Each imam was the son of the previous imam, with the exception of Hussein ibn Ali, who was the brother of Hasan ibn Ali. The twelfth and final imam is Muhammad al-Mahdi, who is believed by the Twelvers to be currently alive and in occultation.
Jurisprudence.
The Twelver jurisprudence is called "Ja'fari jurisprudence". In this jurisprudence "Sunnah" is considered to be the oral traditions of Muhammad and their implementation and interpretation by the twelve Imams. There are three schools of Ja'fari jurisprudence: Usuli, Akhbari, and Shaykhi. The Usuli school is by far the largest of the three. Twelver groups that do not follow Ja'fari jurisprudence include Alevi, Bektashi, and Qizilbash.
In Ja'fari jurisprudence, there are ten ancillary pillars, known as "Furu' ad-Din", which are as follows:
According to Twelvers, defining and interpretation of Islamic jurisprudence is the responsibility of Muhammad and the twelve Imams. As the 12th imam is in occultation, it is the duty of clerics to refer to the Islamic literature such as the Quran and hadith and identify legal decisions within the confines of Islamic law to provide means to deal with current issues from an Islamic perspective. In other words, Twelver clerics provide Guardianship of the Islamic Jurisprudence, which was defined by Muhammad and his twelve successors. This process is known as "Ijtihad" and the clerics are known as "Marja"', meaning reference. The labels "Allamah" and "Ayatollah" are in use for Twelver clerics.
Zaidi ("Fiver").
Zaidiyya, Zaidism or Zaydi is the second largest branch of Shia Islam. It is a Shia school named after Zayd ibn Ali. Followers of the Zaidi fiqh are called Zaidis (or occasionally Fivers). However, there is also a group called "Zaidi Wasītīs" who are Twelvers (see below). Zaidis constitute roughly 42–47% of the population of Yemen.
Doctrine.
The Zaydis, Twelvers, and Ismailis all recognize the same first four Imams; however, the Zaidis recognize Zayd ibn Ali as the fifth. After the time of Zayd ibn Ali, the Zaidis recognized that any descendant of Hasan ibn Ali or Hussein ibn Ali could be imam after fulfilling certain conditions. Other well-known Zaidi Imams in history were Yahya ibn Zayd, Muhammad al-Nafs al-Zakiyya and Ibrahim ibn Abdullah. In matters of Islamic jurisprudence, the Zaydis follow Zayd ibn Ali's teachings which are documented in his book "Majmu'l Fiqh" (in Arabic: مجموع الفِقه). Al-Hadi ila'l-Haqq Yahya, founder of the Zaydi state in Yemen, instituted elements of the jurisprudential tradition of the Sunni Muslim jurist Abū Ḥanīfa, and as a result, Zaydi jurisprudence today continues somewhat parallel to that of the Hanafis.
The Zaidi doctrine of Imamah does not presuppose the infallibility of the imam nor that the Imams receive divine guidance. Zaidis also do not believe that the Imamate must pass from father to son but believe it can be held by any Sayyid descended from either Hasan ibn Ali or Hussein ibn Ali (as was the case after the death of Hasan ibn Ali). Historically, Zaidis held that Zayd was the rightful successor of the 4th imam since he led a rebellion against the Umayyads in protest of their tyranny and corruption. Muhammad al-Baqir did not engage in political action, and the followers of Zayd believed that a true imam must fight against corrupt rulers.
Timeline.
The Idrisids (Arabic: الأدارسة‎) were Arab Zaydi Shia dynasty in the western Maghreb ruling from 788 to 985 C.E., named after its first sultan, Idris I.
A Zaydi state was established in Gilan, Deylaman and Tabaristan (northern Iran) in 864 C.E. by the Alavids; it lasted until the death of its leader at the hand of the Samanids in 928 C.E. Roughly forty years later the state was revived in Gilan and survived under Hasanid leaders until 1126 C.E. Afterwards, from the 12th to 13th centuries, the Zaydis of Deylaman, Gilan and Tabaristan then acknowledged the Zaydi Imams of Yemen or rival Zaydi Imams within Iran.
The Buyids were initially Zaidi as well as the Banu Ukhaidhir rulers of al-Yamama in the 9th and 10th centuries. The leader of the Zaydi community took the title of Caliph. As such, the ruler of Yemen was known as the Caliph, al-Hadi Yahya bin al-Hussain bin al-Qasim ar-Rassi Rassids (a descendant of Hasan ibn Ali the son of Ali) who, at Sa'dah, in 893-7 CE, founded the Zaydi Imamate, and this system continued until the middle of the 20th century, when the revolution of 1962 CE deposed the Zaydi Imam. The founding Zaidism of Yemen was of the Jarudiyya group; however, with increasing interaction with Hanafi and Shafi'i rites of Sunni Islam, there was a shift from the Jarudiyya group to the Sulaimaniyya, Tabiriyya, Butriyya or Salihiyya groups. Zaidis form the second dominant religious group in Yemen. Currently, they constitute about 40–45% of the population in Yemen. Ja'faris and Isma'ilis are 2–5%. In Saudi Arabia, it is estimated that there are over 1 million Zaydis (primarily in the western provinces).
Currently the most prominent Zaydi movement is Houthis movement, known by the name of "Shabab Al Mu'mineen" (Believing Youth). They have been the subject of an ongoing campaign against them by the Yemeni Government in which the army has lost 743 men, and thousands of innocent civilians have been killed or displaced by government forces causing a grave humanitarian crisis in north Yemen.
Ismaili ("Sevener").
Ismailis gain their name from their acceptance of Isma'il ibn Jafar as the divinely appointed spiritual successor (Imam) to Ja'far al-Sadiq, wherein they differ from the Twelvers, who accept Musa al-Kadhim, younger brother of Isma'il, as the true Imam.
After the death or Occultation of Muhammad ibn Ismaill in the 8th century, the teachings of Ismailism further transformed into the belief system as it is known today, with an explicit concentration on the deeper, esoteric meaning ("bāṭin") of the faith. With the eventual development of Twelverism into the more literalistic "(zahir)" oriented Akhbari and later Usuli schools of thought, Shiaism developed in two separate directions: the metaphorical Ismailli group focusing on the mystical path and nature of God and the divine manifestation in the personage of the "Imam of the Time" as the "Face of God", with the more literalistic Twelver group focusing on divine law ("sharī'ah") and the deeds and sayings ("sunnah") of Muhammad and his successors (the "Ahlu l-Bayt"), who as A'immah were guides and a light to God.
Though there are several sub-groupings within the Ismailis, the term in today's vernacular generally refers to The Shia Imami Ismaili Muslim (Nizari community), generally known as the Ismailis, who are followers of the Aga Khan and the largest group among the Ismailiyyah. Another community which falls under the Isma'il's are the Dawoodi Bohras, lead by a "Da'i al-Mutlaq" as representative of a hidden imam. While there are many other branches with extremely differing exterior practices, much of the spiritual theology has remained the same since the days of the faith's early Imams. In recent centuries Ismailis have largely been an Indo-Iranian community, but they are found in India, Pakistan, Syria, Palestine, Saudi Arabia, Yemen, China, Jordan, Uzbekistan, Tajikistan, Afghanistan, East Africa and South Africa, and have in recent years emigrated to Europe, Australia, New Zealand, and North America.
Ismaili Imams.
After the death of Isma'il ibn Jafar, many Ismailis believed that one day the messianic Mahdi, whom they believed to be Muhammad ibn Ismail, would return and establish an age of justice. One group included the violent Qarmatians, who had a stronghold in Bahrain. In contrast, some Ismailis believed the Imamate "did" continue, and that the Imams were in occultation and still communicated and taught their followers through a network of dawah "Missionaries".
In 909, Ubayd Allah al-Mahdi Billah, a claimant to the Ismaili Imamate, established the Fatimid Caliphate. During this period, three lineages of imams formed. The first branch, known today as the Druze, began with Al-Hakim bi-Amr Allah. Born in 386 AH (985), he ascended as ruler at the age of eleven. The typical religiously tolerant Fatimid Empire saw much persecution under his reign. When in 411 AH (1021) his mule returned without him, soaked in blood, a religious group that was forming in his lifetime broke off from mainstream Ismailism and did not acknowledge his successor. Later to be known as the Druze, they believe al-Hakim to be the incarnation of God and the prophesied Mahdi who would one day return and bring justice to the world. The faith further split from Ismailism as it developed very unusual doctrines which often class it separately from both Ismailiyyah and Islam.
The second split occurred following the death of Ma'ad al-Mustansir Billah in 487 AH (1094). His rule was the longest of any caliph in any Islamic empire. Upon his passing away, his sons, Nizar the older, and Al-Musta'li, the younger, fought for political and spiritual control of the dynasty. Nizar was defeated and jailed, but according to Nizari tradition, his son escaped to Alamut, where the Iranian Ismaili had accepted his claim. From here on, the Nizari Ismaili community has continued with a present, living Imam.
The Mustaali line split again between the Taiyabi (Dawoodi Bohra is its main branch) and the Hafizi. The former claim that At-Tayyib Abi l-Qasim (son of Al-Amir bi-Ahkami l-Lah) and the imams following him went into a period of anonymity ("Dawr-e-Satr") and appointed a Da'i al-Mutlaq to guide the community, in a similar manner as the Ismaili had lived after the death of Muhammad ibn Ismail. The latter (Hafizi) claimed that the ruling Fatimid Caliph was the Imam, and they died out with the fall of the Fatimid Empire.
Pillars.
Ismailis have categorized their practices which are known as "seven pillars":
The Shahada (profession of faith) of the Shia differs from that of Sunnis due to mention of Ali
Contemporary leadership.
The Nizaris place importance on a scholarly institution because of the existence of a present Imam. The Imam of the Age defines the jurisprudence, and his guidance may differ with Imams previous to him because of different times and circumstances. For Nizari Ismailis, the imam is Karim al-Husayni Aga Khan IV. The Nizari line of Imams has continued to this day as an unending line.
Divine leadership has continued in the Bohra branch through the institution of the "Unrestricted Missionary" Dai. According to Bohra tradition, before the last Imam, At-Tayyib Abi l-Qasim, went into seclusion, his father, the 20th Al-Amir bi-Ahkami l-Lah, had instructed Al-Hurra Al-Malika the Malika (Queen consort) in Yemen to appoint a vicegerent after the seclusion – the "Unrestricted Missionary", who as the Imam's vicegerent has full authority to govern the community in all matters both spiritual and temporal while the lineage of Mustaali-Tayyibi Imams remains in seclusion (Dawr-e-Sitr). The three branches of the Mustaali, the Alavi Bohra, Sulaimani Bohra and Dawoodi Bohra, differ on who the current Unrestricted Missionary is.

</doc>
<doc id="26962" url="http://en.wikipedia.org/wiki?curid=26962" title="Special relativity">
Special relativity

In physics, special relativity (SR, also known as the special theory of relativity or STR) is the generally accepted physical theory regarding the relationship between space and time. It is based on two postulates: (1) that the laws of physics are invariant (i.e. identical) in all inertial systems (non-accelerating frames of reference); and (2) that the speed of light in a vacuum is the same for all observers, regardless of the motion of the light source. It was originally proposed in 1905 by Albert Einstein in the paper "On the Electrodynamics of Moving Bodies". The inconsistency of Newtonian mechanics with Maxwell’s equations of electromagnetism and the inability to discover Earth's motion through a luminiferous aether led to the development of special relativity, which corrects mechanics to handle situations involving motions nearing the speed of light. As of today, special relativity is the most accurate model of motion at any speed. Even so, Newtonian mechanics is still useful (due to its simplicity and high accuracy) as an approximation at small velocities relative to the speed of light.
Special relativity implies a wide range of consequences, which have been experimentally verified, including length contraction, time dilation, relativistic mass, mass–energy equivalence, a universal speed limit, and relativity of simultaneity. It has replaced the conventional notion of an absolute universal time with the notion of a time that is dependent on reference frame and spatial position. Rather than an invariant time interval between two events, there is an invariant spacetime interval. Combined with other laws of physics, the two postulates of special relativity predict the equivalence of mass and energy, as expressed in the mass–energy equivalence formula "E" = "mc"2, where "c" is the speed of light in vacuum.
A defining feature of special relativity is the replacement of the Galilean transformations of Newtonian mechanics with the Lorentz transformations. Time and space cannot be defined separately from each other. Rather space and time are interwoven into a single continuum known as spacetime. Events that occur at the same time for one observer could occur at different times for another.
The theory is "special" in that it only applies the principle of relativity to the special case of inertial reference frames. Einstein published his treatment of the general case – general relativity, where the principle is equipped to handle generalized coordinate transformations and the effects of gravity – in 1915.
As Galilean relativity is now considered an approximation of special relativity that is valid for low speeds, special relativity is considered an approximation of general relativity that is valid for weak gravitational fields, i.e. at a sufficiently small scale and in conditions of free fall. Whereas general relativity incorporates noneuclidean geometry in order to represent gravitational effects as the geometric curvature of spacetime, special relativity is restricted to the flat spacetime known as Minkowski space. A locally Lorentz-invariant frame that abides by special relativity can be defined at sufficiently small scales, even in curved spacetime.
Galileo Galilei had already postulated that there is no absolute and well-defined state of rest (no privileged reference frames), a principle now called Galileo's principle of relativity. Einstein extended this principle so that it accounted for the constant speed of light, a phenomenon that had been recently observed in the Michelson–Morley experiment. He also postulated that it holds for all the laws of physics, including both the laws of mechanics and of electrodynamics.
Postulates.
Einstein discerned two fundamental propositions that seemed to be the most assured, regardless of the exact validity of the (then) known laws of either mechanics or electrodynamics. These propositions were the constancy of the speed of light and the independence of physical laws (especially the constancy of the speed of light) from the choice of inertial system. In his initial presentation of special relativity in 1905 he expressed these postulates as:
The derivation of special relativity depends not only on these two explicit postulates, but also on several tacit assumptions (made in almost all theories of physics), including the isotropy and homogeneity of space and the independence of measuring rods and clocks from their past history.
Following Einstein's original presentation of special relativity in 1905, many different sets of postulates have been proposed in various alternative derivations. However, the most common set of postulates remains those employed by Einstein in his original paper. A more mathematical statement of the Principle of Relativity made later by Einstein, which introduces the concept of simplicity not mentioned above is:
"Special principle of relativity": If a system of coordinates K is chosen so that, in relation to it, physical laws hold good in their simplest form, the "same" laws hold good in relation to any other system of coordinates K' moving in uniform translation relatively to K.
Henri Poincaré provided the mathematical framework for relativity theory by proving that Lorentz transformations are a subset of his Poincaré group of symmetry transformations. Einstein later derived these transformations from his axioms.
Many of Einstein's papers present derivations of the Lorentz transformation based upon these two principles.
Einstein consistently based the derivation of Lorentz invariance (the essential core of special relativity) on just the two basic principles of relativity and light-speed invariance. He wrote:
The insight fundamental for the special theory of relativity is this: The assumptions relativity and light speed invariance are compatible if relations of a new type ("Lorentz transformation") are postulated for the conversion of coordinates and times of events... The universal principle of the special theory of relativity is contained in the postulate: The laws of physics are invariant with respect to Lorentz transformations (for the transition from one inertial system to any other arbitrarily chosen inertial system). This is a restricting principle for natural laws...
Thus many modern treatments of special relativity base it on the single postulate of universal Lorentz covariance, or, equivalently, on the single postulate of Minkowski spacetime.
From the principle of relativity alone without assuming the constancy of the speed of light (i.e. using the isotropy of space and the symmetry implied by the principle of special relativity) one can show that the spacetime transformations between inertial frames are either Euclidean, Galilean, or Lorentzian. In the Lorentzian case, one can then obtain relativistic interval conservation and a certain finite limiting speed. Experiments suggest that this speed is the speed of light in vacuum.
The constancy of the speed of light was motivated by Maxwell's theory of electromagnetism and the lack of evidence for the luminiferous ether. There is conflicting evidence on the extent to which Einstein was influenced by the null result of the Michelson–Morley experiment. In any case, the null result of the Michelson–Morley experiment helped the notion of the constancy of the speed of light gain widespread and rapid acceptance.
Lack of an absolute reference frame.
The principle of relativity, which states that there is no preferred inertial reference frame, dates back to Galileo, and was incorporated into Newtonian physics. However, in the late 19th century, the existence of electromagnetic waves led physicists to suggest that the universe was filled with a substance that they called "aether", which would act as the medium through which these waves, or vibrations travelled. The aether was thought to constitute an absolute reference frame against which speeds could be measured, and could be considered fixed and motionless. Aether supposedly possessed some wonderful properties: it was sufficiently elastic to support electromagnetic waves, and those waves could interact with matter, yet it offered no resistance to bodies passing through it. The results of various experiments, including the Michelson–Morley experiment, indicated that the Earth was always 'stationary' relative to the aether – something that was difficult to explain, since the Earth is in orbit around the Sun. Einstein's solution was to discard the notion of an aether and the absolute state of rest. In relativity, any reference frame moving with uniform motion will observe the same laws of physics. In particular, the speed of light in vacuum is always measured to be "c", even when measured by multiple systems that are moving at different (but constant) velocities.
Reference frames, coordinates and the Lorentz transformation.
Relativity theory depends on "reference frames". The term reference frame as used here is an observational perspective in space which is not undergoing any change in motion (acceleration), from which a position can be measured along 3 spatial axes. In addition, a reference frame has the ability to determine measurements of the time of events using a 'clock' (any reference device with uniform periodicity).
An event is an occurrence that can be assigned a single unique time and location in space relative to a reference frame: it is a "point" in spacetime. Since the speed of light is constant in relativity in each and every reference frame, pulses of light can be used to unambiguously measure distances and refer back the times that events occurred to the clock, even though light takes time to reach the clock after the event has transpired.
For example, the explosion of a firecracker may be considered to be an "event". We can completely specify an event by its four spacetime coordinates: The time of occurrence and its 3-dimensional spatial location define a reference point. Let's call this reference frame "S".
In relativity theory we often want to calculate the position of a point from a different reference point.
Suppose we have a second reference frame "S"′, whose spatial axes and clock exactly coincide with that of "S" at time zero, but it is moving at a constant velocity "v" with respect to "S" along the "x"-axis.
Since there is no absolute reference frame in relativity theory, a concept of 'moving' doesn't strictly exist, as everything is always moving with respect to some other reference frame. Instead, any two frames that move at the same speed in the same direction are said to be "comoving". Therefore "S" and "S"′ are not "comoving".
Define the event to have spacetime coordinates ("t","x","y","z") in system "S" and ("t"′,"x"′,"y"′,"z"′) in "S"′. Then the Lorentz transformation specifies that these coordinates are related in the following way:
where
is the Lorentz factor and "c" is the speed of light in vacuum, and the velocity "v" of "S"′ is parallel to the "x"-axis. The "y" and "z" coordinates are unaffected; only the "x" and "t" coordinates are transformed. These Lorentz transformations form a one-parameter group of linear mappings, that parameter being called rapidity.
There is nothing special about the "x"-axis, the transformation can apply to the "y" or "z" axes, or indeed in any direction, which can be done by directions parallel to the motion (which are warped by the γ factor) and perpendicular; see main article for details.
A quantity invariant under Lorentz transformations is known as a Lorentz scalar.
Writing the Lorentz transformation and its inverse in terms of coordinate differences, where for instance one event has coordinates ("x"1, "t"1) and ("x"′1, "t"′1), another event has coordinates ("x"2, "t"2)and ("x"′2, "t"′2), and the differences are defined as
we get
These effects are not merely appearances; they are explicitly related to our way of measuring "time intervals" between events which occur at the same place in a given coordinate system (called "co-local" events). These time intervals will be "different" in another coordinate system moving with respect to the first, unless the events are also simultaneous. Similarly, these effects also relate to our measured distances between separated but simultaneous events in a given coordinate system of choice. If these events are not co-local, but are separated by distance (space), they will "not" occur at the same "spatial distance" from each other when seen from another moving coordinate system. However, the spacetime interval will be the same for all observers. The underlying reality remains the same. Only our perspective changes.
Consequences derived from the Lorentz transformation.
The consequences of special relativity can be derived from the Lorentz transformation equations. These transformations, and hence special relativity, lead to different physical predictions than those of Newtonian mechanics when relative velocities become comparable to the speed of light. The speed of light is so much larger than anything humans encounter that some of the effects
predicted by relativity are initially counterintuitive.
Relativity of simultaneity.
Two events happening in two different locations that occur simultaneously in the reference frame of one inertial observer, may occur non-simultaneously in the reference frame of another inertial observer (lack of absolute simultaneity).
From the first equation of the Lorentz transformation in terms of coordinate differences
it is clear that two events that are simultaneous in frame "S" (satisfying Δ"t" = 0), are not necessarily simultaneous in another inertial frame "S"′ (satisfying Δ"t"′ = 0). Only if these events are additionally co-local in frame "S" (satisfying Δ"x" = 0), will they be simultaneous in another frame "S"′.
Time dilation.
The time lapse between two events is not invariant from one observer to another, but is dependent on the relative speeds of the observers' reference frames (e.g., the twin paradox which concerns a twin who flies off in a spaceship traveling near the speed of light and returns to discover that his or her twin sibling has aged much more).
Suppose a clock is at rest in the unprimed system S. Two different ticks of this clock are then characterized by Δ"x" = 0. To find the relation between the times between these ticks as measured in both systems, the first equation can be used to find:
This shows that the time (Δ"t"') between the two ticks as seen in the frame in which the clock is moving ("S"′), is "longer" than the time (Δ"t") between these ticks as measured in the rest frame of the clock ("S"). Time dilation explains a number of physical phenomena; for example, the decay rate of muons produced by cosmic rays impinging on the Earth's atmosphere.
Length contraction.
The dimensions (e.g., length) of an object as measured by one observer may be smaller than the results of measurements of the same object made by another observer (e.g., the ladder paradox involves a long ladder traveling near the speed of light and being contained within a smaller garage).
Similarly, suppose a measuring rod is at rest and aligned along the x-axis in the unprimed system "S". In this system, the length of this rod is written as Δ"x". To measure the length of this rod in the system "S"′, in which the clock is moving, the distances "x"′ to the end points of the rod must be measured simultaneously in that system "S"′. In other words, the measurement is characterized by Δ"t"′ = 0, which can be combined with the fourth equation to find the relation between the lengths Δ"x" and Δ"x"′:
This shows that the length (Δ"x"′) of the rod as measured in the frame in which it is moving ("S"′), is "shorter" than its length (Δ"x") in its own rest frame ("S").
Composition of velocities.
Velocities (speeds) do not simply add. If the observer in "S" measures an object moving along the "x" axis at velocity "u", then the observer in the "S"′ system, a frame of reference moving at velocity "v" in the "x" direction with respect to "S", will measure the object moving with velocity "u"′ where (from the Lorentz transformations above):
The other frame "S" will measure:
Notice that if the object were moving at the speed of light in the "S" system (i.e. "u" = "c"), then it would also be moving at the speed of light in the "S"′ system. Also, if both "u" and "v" are small with respect to the speed of light, we will recover the intuitive Galilean transformation of velocities
The usual example given is that of a train (frame "S"′ above) traveling due east with a velocity "v" with respect to the tracks (frame "S"). A child inside the train throws a baseball due east with a velocity "u"′ with respect to the train. In classical physics, an observer at rest on the tracks will measure the velocity of the baseball (due east) as "u" = "u"′ + "v", while in special relativity this is no longer true; instead the velocity of the baseball (due east) is given by the second equation: "u" = ("u"′ + "v")/(1 + "u"′"v"/"c"2). Again, there is nothing special about the "x" or east directions. This formalism applies to any direction by considering parallel and perpendicular motion to the direction of relative velocity "v", see main article for details.
Einstein's addition of colinear velocities is consistent with the Fizeau experiment which determined the speed of light in a fluid moving parallel to the light, but no experiment has ever tested the formula for the general case of non-parallel velocities.
Other consequences.
Thomas rotation.
The orientation of an object (i.e. the alignment of its axes with the observer's axes) may be different for different observers. Unlike other relativistic effects, this effect becomes quite significant at fairly low velocities as can be seen in the spin of moving particles.
Equivalence of mass and energy.
As an object's speed approaches the speed of light from an observer's point of view, its relativistic mass increases thereby making it more and more difficult to accelerate it from within the observer's frame of reference.
The energy content of an object at rest with mass "m" equals "mc"2. Conservation of energy implies that, in any reaction, a decrease of the sum of the masses of particles must be accompanied by an increase in kinetic energies of the particles after the reaction. Similarly, the mass of an object can be increased by taking in kinetic energies.
In addition to the papers referenced above—which give derivations of the Lorentz transformation and describe the foundations of special relativity—Einstein also wrote at least four papers giving heuristic arguments for the equivalence (and transmutability) of mass and energy, for "E" = "mc"2.
Mass–energy equivalence is a consequence of special relativity. The energy and momentum, which are separate in Newtonian mechanics, form a four-vector in relativity, and this relates the time component (the energy) to the space components (the momentum) in a nontrivial way. For an object at rest, the energy–momentum four-vector is ("E", 0, 0, 0): it has a time component which is the energy, and three space components which are zero. By changing frames with a Lorentz transformation in the x direction with a small value of the velocity v, the energy momentum four-vector becomes ("E", "Ev"/"c"2, 0, 0). The momentum is equal to the energy multiplied by the velocity divided by "c"2. As such, the Newtonian mass of an object, which is the ratio of the momentum to the velocity for slow velocities, is equal to "E"/"c"2.
The energy and momentum are properties of matter and radiation, and it is impossible to deduce that they form a four-vector just from the two basic postulates of special relativity by themselves, because these don't talk about matter or radiation, they only talk about space and time. The derivation therefore requires some additional physical reasoning. In his 1905 paper, Einstein used the additional principles that Newtonian mechanics should hold for slow velocities, so that there is one energy scalar and one three-vector momentum at slow velocities, and that the conservation law for energy and momentum is exactly true in relativity. Furthermore, he assumed that the energy of light is transformed by the same Doppler-shift factor as its frequency, which he had previously shown to be true based on Maxwell's equations. The first of Einstein's papers on this subject was "Does the Inertia of a Body Depend upon its Energy Content?" in 1905. Although Einstein's argument in this paper is nearly universally accepted by physicists as correct, even self-evident, many authors over the years have suggested that it is wrong. Other authors suggest that the argument was merely inconclusive because it relied on some implicit assumptions.
Einstein acknowledged the controversy over his derivation in his 1907 survey paper on special relativity. There he notes that it is problematic to rely on Maxwell's equations for the heuristic mass–energy argument. The argument in his 1905 paper can be carried out with the emission of any massless particles, but the Maxwell equations are implicitly used to make it obvious that the emission of light in particular can be achieved only by doing work. To emit electromagnetic waves, all you have to do is shake a charged particle, and this is clearly doing work, so that the emission is of energy.
How far can one travel from the Earth?
Since one can not travel faster than light, one might conclude that a human can never travel farther from Earth than 40 light years if the traveler is active between the age of 20 and 60. One would easily think that a traveler would never be able to reach more than the very few solar systems which exist within the limit of 20–40 light years from the earth. But that would be a mistaken conclusion. Because of time dilation, a hypothetical spaceship can travel thousands of light years during the pilot's 40 active years. If a spaceship could be built that accelerates at a constant 1g, it will after a little less than a year be traveling at almost the speed of light as seen from Earth. Time dilation will increase his life span as seen from the reference system of the Earth, but his lifespan measured by a clock traveling with him will not thereby change. During his journey, people on Earth will experience more time than he does. A 5-year round trip for him will take 6½ Earth years and cover a distance of over 6 light-years. A 20-year round trip for him (5 years accelerating, 5 decelerating, twice each) will land him back on Earth having traveled for 335 Earth years and a distance of 331 light years. A full 40-year trip at 1 g will appear on Earth to last 58,000 years and cover a distance of 55,000 light years. A 40-year trip at 1.1 g will take 148,000 Earth years and cover about 140,000 light years. A one-way 28 year (14 years accelerating, 14 decelerating as measured with the cosmonaut's clock) trip at 1 g acceleration could reach 2,000,000 light-years to the Andromeda Galaxy. This same time dilation is why a muon traveling close to "c" is observed to travel much further than "c" times its half-life (when at rest).
Causality and prohibition of motion faster than light.
In diagram 2 the interval AB is 'time-like'; i.e., there is a frame of reference in which events A and B occur at the same location in space, separated only by occurring at different times. If A precedes B in that frame, then A precedes B in all frames. It is hypothetically possible for matter (or information) to travel from A to B, so there can be a causal relationship (with A the cause and B the effect).
The interval AC in the diagram is 'space-like'; i.e., there is a frame of reference in which events A and C occur simultaneously, separated only in space. There are also frames in which A precedes C (as shown) and frames in which C precedes A. If it were possible for a cause-and-effect relationship to exist between events A and C, then paradoxes of causality would result. For example, if A was the cause, and C the effect, then there would be frames of reference in which the effect preceded the cause. Although this in itself won't give rise to a paradox, one can show that faster than light signals can be sent back into one's own past. A causal paradox can then be constructed by sending the signal if and only if no signal was received previously.
Therefore, if causality is to be preserved, one of the consequences of special relativity is that no information signal or material object can travel faster than light in vacuum. However, some "things" can still move faster than light. For example, the location where the beam of a search light hits the bottom of a cloud can move faster than light when the search light is turned rapidly.
Even without considerations of causality, there are other strong reasons why faster-than-light travel is forbidden by special relativity. For example, if a constant force is applied to an object for a limitless amount of time, then integrating "F" = "dp"/"dt" gives a momentum that grows without bound, but this is simply because formula_13 approaches infinity as formula_14 approaches "c". To an observer who is not accelerating, it appears as though the object's inertia is increasing, so as to produce a smaller acceleration in response to the same force. This behavior is observed in particle accelerators, where each charged particle is accelerated by the electromagnetic force.
Theoretical and experimental tunneling studies carried out by Günter Nimtz and Petrissa Eckle claimed that under special conditions signals may travel faster than light. It was measured that fiber digital signals were traveling up to 5 times c and a zero-time tunneling electron carried the information that the atom is ionized, with photons, phonons and electrons spending zero time in the tunneling barrier. According to Nimtz and Eckle, in this superluminal process only the Einstein causality and the special relativity but not the primitive causality are violated: Superluminal propagation does not result in any kind of time travel. Several scientists have stated not only that Nimtz' interpretations were erroneous, but also that the experiment actually provided a trivial experimental confirmation of the special relativity theory.
Geometry of spacetime.
Comparison between flat Euclidean space and Minkowski space.
Special relativity uses a 'flat' 4-dimensional Minkowski space – an example of a spacetime. Minkowski spacetime appears to be very similar to the standard 3-dimensional Euclidean space, but there is a crucial difference with respect to time.
In 3D space, the differential of distance (line element) "ds" is defined by
where "d"x = ("dx"1, "dx"2, "dx"3) are the differentials of the three spatial dimensions. In Minkowski geometry, there is an extra dimension with coordinate "X"0 derived from time, such that the distance differential fulfills
where "d"X = ("dX"0, "dX"1, "dX"2, "dX"3) are the differentials of the four spacetime dimensions. This suggests a deep theoretical insight: special relativity is simply a rotational symmetry of our spacetime, analogous to the rotational symmetry of Euclidean space (see image right). Just as Euclidean space uses a Euclidean metric, so spacetime uses a Minkowski metric. Basically, special relativity can be stated as the "invariance of any spacetime interval" (that is the 4D distance between any two events) when viewed from "any inertial reference frame". All equations and effects of special relativity can be derived from this rotational symmetry (the Poincaré group) of Minkowski spacetime.
The actual form of "ds" above depends on the metric and on the choices for the "X"0 coordinate.
To make the time coordinate look like the space coordinates, it can be treated as imaginary: "X"0 = "ict" (this is called a Wick rotation).
According to Misner, Thorne and Wheeler (1971, §2.3), ultimately the deeper understanding of both special and general relativity will come from the study of the Minkowski metric (described below) and to take "X"0 = "ct", rather than a "disguised" Euclidean metric using "ict" as the time coordinate.
Some authors use "X"0 = "t", with factors of "c" elsewhere to compensate; for instance, spatial coordinates are divided by "c" or factors of "c"±2 are included in the metric tensor.
These numerous conventions can be superseded by using natural units where "c" = 1. Then space and time have equivalent units, and no factors of "c" appear anywhere.
3D spacetime.
If we reduce the spatial dimensions to 2, so that we can represent the physics in a 3D space
we see that the null geodesics lie along a dual-cone (see image right) defined by the equation;
or simply
 which is the equation of a circle of radius "c dt".
4D spacetime.
If we extend this to three spatial dimensions, the null geodesics are the 4-dimensional cone:
so
This null dual-cone represents the "line of sight" of a point in space. That is, when we look at the stars and say "The light from that star which I am receiving is X years old", we are looking down this line of sight: a null geodesic. We are looking at an event a distance formula_22 away and a time "d/c" in the past. For this reason the null dual cone is also known as the 'light cone'. (The point in the lower left of the picture below represents the star, the origin represents the observer, and the line represents the null geodesic "line of sight".)
The cone in the −"t" region is the information that the point is 'receiving', while the cone in the +"t" section is the information that the point is 'sending'.
The geometry of Minkowski space can be depicted using Minkowski diagrams, which are useful also in understanding many of the thought-experiments in special relativity.
Note that, in 4d spacetime, the concept of the center of mass becomes more complicated, see center of mass (relativistic).
Physics in spacetime.
Transformations of physical quantities between reference frames.
Above, the Lorentz transformation for the time coordinate and three space coordinates illustrates that they are intertwined. This is true more generally: certain pairs of "timelike" and "spacelike" quantities naturally combine on equal footing under the same Lorentz transformation.
The Lorentz transformation in standard configuration above, i.e. for a boost in the "x" direction, can be recast into matrix form as follows:
In Newtonian mechanics, quantities which have magnitude and direction are mathematically described as 3d vectors in Euclidean space, and in general they are parametrized by time. In special relativity, this notion is extended by adding the appropriate timelike quantity to a spacelike vector quantity, and we have 4d vectors, or "four vectors", in Minkowski spacetime. The components of vectors are written using tensor index notation, as this has numerous advantages. The notation makes it clear the equations are manifestly covariant under the Poincaré group, thus bypassing the tedious calculations to check this fact. In constructing such equations, we often find that equations previously thought to be unrelated are, in fact, closely connected being part of the same tensor equation. Recognizing other physical quantities as tensors simplifies their transformation laws. Throughout, upper indices (superscripts) are contravariant indices rather than exponents except when they indicate a square (this is should be clear from the context), and lower indices (subscripts) are covariant indices. For simplicity and consistency with the earlier equations, Cartesian coordinates will be used.
The simplest example of a four-vector is the position of an event in spacetime, which constitutes a timelike component "ct" and spacelike component x = ("x", "y", "z"), in a contravariant position four vector with components:
where we define "X"0 = "ct" so that the time coordinate has the same dimension of distance as the other spatial dimensions; so that space and time are treated equally. Now the transformation of the contravariant components of the position 4-vector can be compactly written as:
where there is an implied summation on "ν" from 0 to 3, and formula_26 is a matrix.
More generally, all contravariant components of a four-vector formula_27 transform from one frame to another frame by a Lorentz transformation:
Examples of other 4-vectors include the four-velocity "U"μ, defined as the derivative of the position 4-vector with respect to proper time:
where the Lorentz factor is:
The relativistic energy formula_31 and relativistic momentum formula_32 of an object are respectively the timelike and spacelike components of a contravariant four momentum vector:
where "m" is the invariant mass.
The four-acceleration is the proper time derivative of 4-velocity:
The transformation rules for "three"-dimensional velocities and accelerations are very awkward; even above in standard configuration the velocity equations are quite complicated owing to their non-linearity. On the other hand, the transformation of "four"-velocity and "four"-acceleration are simpler by means of the Lorentz transformation matrix.
The four-gradient of a scalar field φ transforms covariantly rather than contravariantly:
that is:
only in Cartesian coordinates. It's the covariant derivative which transforms in manifest covariance, in Cartesian coordinates this happens to reduce to the partial derivatives, but not in other coordinates.
More generally, the "co"variant components of a 4-vector transform according to the "inverse" Lorentz transformation:
where formula_38 is the reciprocal matrix of formula_26.
The postulates of special relativity constrain the exact form the Lorentz transformation matrices take.
More generally, most physical quantities are best described as (components of) tensors. So to transform from one frame to another, we use the well-known tensor transformation law
where formula_41 is the reciprocal matrix of formula_42. All tensors transform by this rule.
An example of a four dimensional second order antisymmetric tensor is the relativistic angular momentum, which has six components: three are the classical angular momentum, and the other three are related to the boost of the center of mass of the system. The derivative of the relativistic angular momentum with respect to proper time is the relativistic torque, also second order antisymmetric tensor.
The electromagnetic field tensor is another second order antisymmetric tensor field, with six components: three for the electric field and another three for the magnetic field. There is also the stress–energy tensor for the electromagnetic field, namely the electromagnetic stress–energy tensor.
Metric.
The metric tensor allows one to define the inner product of two vectors, which in turn allows one to assign a magnitude to the vector. Given the four-dimensional nature of spacetime the Minkowski metric "η" has components (valid in any inertial reference frame) which can be arranged in a 4 × 4 matrix:
which is equal to its reciprocal, formula_44, in those frames. Throughout we use the signs as above, different authors use different conventions – see Minkowski metric alternative signs.
The Poincaré group is the most general group of transformations which preserves the Minkowski metric:
and this is the physical symmetry underlying special relativity.
The metric can be used for raising and lowering indices on vectors and tensors. Invariants can be constructed using the metric, the inner product of a 4-vector "T" with another 4-vector "S" is:
Invariant means that it takes the same value in all inertial frames, because it is a scalar (0 rank tensor), and so no Λ appears in its trivial transformation. The magnitude of the 4-vector "T" is the positive square root of the inner product with itself:
One can extend this idea to tensors of higher order, for a second order tensor we can form the invariants:
similarly for higher order tensors. Invariant expressions, particularly inner products of 4-vectors with themselves, provide equations that are useful for calculations, because one doesn't need to perform Lorentz transformations to determine the invariants.
Relativistic kinematics and invariance.
The coordinate differentials transform also contravariantly:
so the squared length of the differential of the position four-vector "dXμ" constructed using
is an invariant. Notice that when the line element "dX2 is negative that √−"dX2 is the differential of proper time, while when "dX2 is positive, √"dX2 is differential of the proper distance.
The 4-velocity "U"μ has an invariant form:
which means all velocity four-vectors have a magnitude of "c". This is an expression of the fact that there is no such thing as being at coordinate rest in relativity: at the least, you are always moving forward through time. Differentiating the above equation by "τ" produces:
So in special relativity, the acceleration four-vector and the velocity four-vector are orthogonal.
Relativistic dynamics and invariance.
The invariant magnitude of the momentum 4-vector generates the energy–momentum relation:
We can work out what this invariant is by first arguing that, since it is a scalar, it doesn't matter in which reference frame we calculate it, and then by transforming to a frame where the total momentum is zero.
We see that the rest energy is an independent invariant. A rest energy can be calculated even for particles and systems in motion, by translating to a frame in which momentum is zero.
The rest energy is related to the mass according to the celebrated equation discussed above:
Note that the mass of systems measured in their center of momentum frame (where total momentum is zero) is given by the total energy of the system in this frame. It may not be equal to the sum of individual system masses measured in other frames.
To use Newton's third law of motion, both forces must be defined as the rate of change of momentum with respect to the same time coordinate. That is, it requires the 3D force defined above. Unfortunately, there is no tensor in 4D which contains the components of the 3D force vector among its components.
If a particle is not traveling at "c", one can transform the 3D force from the particle's co-moving reference frame into the observer's reference frame. This yields a 4-vector called the four-force. It is the rate of change of the above energy momentum four-vector with respect to proper time. The covariant version of the four-force is:
In the rest frame of the object, the time component of the four force is zero unless the "invariant mass" of the object is changing (this requires a non-closed system in which energy/mass is being directly added or removed from the object) in which case it is the negative of that rate of change of mass, times "c". In general, though, the components of the four force are not equal to the components of the three-force, because the three force is defined by the rate of change of momentum with respect to coordinate time, i.e. "dp"/"dt" while the four force is defined by the rate of change of momentum with respect to proper time, i.e. "dp"/"d"τ.
In a continuous medium, the 3D "density of force" combines with the "density of power" to form a covariant 4-vector. The spatial part is the result of dividing the force on a small cell (in 3-space) by the volume of that cell. The time component is −1/"c" times the power transferred to that cell divided by the volume of the cell. This will be used below in the section on electromagnetism.
Relativity and unifying electromagnetism.
Theoretical investigation in classical electromagnetism led to the discovery of wave propagation. Equations generalizing the electromagnetic effects found that finite propagation speed of the E and B fields required certain behaviors on charged particles. The general study of moving charges forms the Liénard–Wiechert potential, which is a step towards special relativity.
The Lorentz transformation of the electric field of a moving charge into a non-moving observer's reference frame results in the appearance of a mathematical term commonly called the magnetic field. Conversely, the "magnetic" field generated by a moving charge disappears and becomes a purely "electrostatic" field in a comoving frame of reference. Maxwell's equations are thus simply an empirical fit to special relativistic effects in a classical model of the Universe. As electric and magnetic fields are reference frame dependent and thus intertwined, one speaks of "electromagnetic" fields. Special relativity provides the transformation rules for how an electromagnetic field in one inertial frame appears in another inertial frame.
Maxwell's equations in the 3D form are already consistent with the physical content of special relativity, although they are easier to manipulate in a manifestly covariant form, i.e. in the language of tensor calculus. See main links for more detail.
Status.
Special relativity in its Minkowski spacetime is accurate only when the absolute value of the gravitational potential is much less than "c"2 in the region of interest. In a strong gravitational field, one must use general relativity. General relativity becomes special relativity at the limit of weak field. At very small scales, such as at the Planck length and below, quantum effects must be taken into consideration resulting in quantum gravity. However, at macroscopic scales and in the absence of strong gravitational fields, special relativity is experimentally tested to extremely high degree of accuracy (10−20)
and thus accepted by the physics community. Experimental results which appear to contradict it are not reproducible and are thus widely believed to be due to experimental errors.
Special relativity is mathematically self-consistent, and it is an organic part of all modern physical theories, most notably quantum field theory, string theory, and general relativity (in the limiting case of negligible gravitational fields).
Newtonian mechanics mathematically follows from special relativity at small velocities (compared to the speed of light) – thus Newtonian mechanics can be considered as a special relativity of slow moving bodies. See classical mechanics for a more detailed discussion.
Several experiments predating Einstein's 1905 paper are now interpreted as evidence for relativity. Of these it is known Einstein was aware of the Fizeau experiment before 1905, and historians have concluded that Einstein was at least aware of the Michelson–Morley experiment as early as 1899 despite claims he made in his later years that it played no role in his development of the theory.
Particle accelerators routinely accelerate and measure the properties of particles moving at near the speed of light, where their behavior is completely consistent with relativity theory and inconsistent with the earlier Newtonian mechanics. These machines would simply not work if they were not engineered according to relativistic principles. In addition, a considerable number of modern experiments have been conducted to test special relativity. Some examples:
Theories of relativity and quantum mechanics.
"Special" relativity can be combined with quantum mechanics to form relativistic quantum mechanics. It is an unsolved problem in physics how "general" relativity and quantum mechanics can be unified; quantum gravity and a "theory of everything", which require such a unification, are active and ongoing areas in theoretical research.
The early Bohr–Sommerfeld atomic model explained the fine structure of alkali metal atoms using both special relativity and the preliminary knowledge on quantum mechanics of the time.
In 1928, Paul Dirac constructed an influential relativistic wave equation, now known as the Dirac equation in his honour, that is fully compatible both with special relativity and with the final version of quantum theory existing after 1926. This equation explained not only the intrinsic angular momentum of the electrons called "spin", it also led to the prediction of the antiparticle of the electron (the positron), and fine structure could only be fully explained with special relativity. It was the first foundation of "relativistic quantum mechanics". In non-relativistic quantum mechanics, spin is phenomenological and cannot be explained.
On the other hand, the existence of antiparticles leads to the conclusion that relativistic quantum mechanics is not enough for a more accurate and complete theory of particle interactions. Instead, a theory of particles interpreted as quantized fields, called "quantum field theory", becomes necessary; in which particles can be created and destroyed throughout space and time.

</doc>
<doc id="26965" url="http://en.wikipedia.org/wiki?curid=26965" title="Stephenson">
Stephenson

Stephenson is a medieval patronymic surname meaning "son of Stephen". The earliest public record is found in the county of Huntingdonshire in 1279. There are variant spellings including Stevenson. People with the surname include:

</doc>
<doc id="26966" url="http://en.wikipedia.org/wiki?curid=26966" title="Sedan">
Sedan

Sedan may refer to:

</doc>
<doc id="26967" url="http://en.wikipedia.org/wiki?curid=26967" title="SUV (disambiguation)">
SUV (disambiguation)

The term SUV normally refers to sport utility vehicles. It can also refer to:

</doc>
<doc id="26968" url="http://en.wikipedia.org/wiki?curid=26968" title="Saab Group">
Saab Group

Saab Group (originally Svenska Aeroplan AB, later SAAB and Saab AB) is a Swedish aerospace and defence company, founded in 1937. From 1947 to 1990 it was the parent company of automobile manufacturer Saab Automobile. Between 1968 and 1995 the company was in a merger with commercial vehicle manufacturer Scania-Vabis, known as Saab-Scania. The two were de-merged in 1995 by the new owners, Investor AB. Despite the demerger, both Saab and Scania share the right to use the griffin logo, which originates from the coat of arms of the Swedish region of Scania.
History.
"Svenska Aeroplan AB (aktiebolag)" (Swedish for "Swedish Aeroplane Company Limited") (SAAB) was founded in 1937 in Trollhättan, with the merger of Svenska Aero AB (SAAB) and Linköping based VASJA the headquarters moved to Linköping. The style "Saab" replaced "SAAB" around 1950.
Originally manufacturing aircraft, the company sought ways in which to diversify its business. In the late 1940s the company began manufacturing cars at its Saab Automobile division was based in Trollhättan. The first car was the Saab 92; full-scale production started December 12, 1949, based on the prototype Ursaab.
In the late 1950s Saab ventured into the computer market with Datasaab. The company was a result partly of the need to make a computer that would be small enough to mount in an aeroplane as navigational equipment. During the 1960s several computers were developed and sold to European countries, for uses such as banking. The aircraft computer (CK 37) was used in 1971 in the Viggen. The company was sold in 1975 to Sperry UNIVAC, while Saab retained its flight computer development.
In May 1965, the company name was changed to Saab AB to reflect its broad range of activities.
In 1968 Saab AB merged with the Swedish lorry, bus and heavy-duty diesel engine manufacturer Scania-Vabis, and became Saab-Scania AB.
In 1990 General Motors bought 51 percent of the car division Saab Automobile, and acquired the rest a decade later.
In 1991 Investor AB completed a leveraged buyout of Saab-Scania AB. Investor AB acquired all the outstanding shares in Saab-Scania for approximately SEK 21 billion. Saab-Scania became a wholly owned subsidiary of Investor AB and the company was de-listed.
In 1995 Saab-Scania was divided by Investor AB into two independent companies, de-merging into Scania AB and Saab AB. The intention by Investor AB was to broaden ownership in the two companies later. Following the sale of 50% of the car division Saab Automobile AB to General Motors, the main reason behind the merger with lorry manufacturer Scania-Vabis in 1968 had disappeared.
Saab Military Aircraft and British Aerospace (now BAE Systems) formed in 1995 the joint venture company Saab-BAe Gripen AB, to manufacture, market and support Gripen internationally. This co-operation was extended in 2001 with the formation of Gripen International for the same purpose.
From 1998 until 2005 the largest shareholder in Saab was the British aerospace company BAE Systems, following its acquisition of a 35% stake from Investor AB by its predecessor, British Aerospace. In January 2005, BAE Systems reduced its shareholding to 20%. Investor AB maintained a 20% share.
16 November 1999, Saab announced its intention is to purchase Celsius AB and the acquisition was concluded by early March 2000. 
In December 2005 Saab joined the Dassault nEUROn project as a major partner.
In October 2008 the company announced its intention to merge its operations with that of Simrad Optronics. The new unit will develop high-tech optronics products and will be headquartered in Norway, although other details of the new arrangement have not been finalized.
In 2010 the company restructured from fifteen business units into five business areas; Aeronautics, Dynamics, Electronic Defence Systems, Security and Defence Solutions, and Support and Services. According to Saab the restructuring was undertaken to become more market and customer oriented.
In March 2010, BAE Systems sold half of its 20% stake in the company to Investor AB, which then became the major shareholder. In June 2011, the British company eventually sold its remaining stake bringing its 16 year involvement in Saab to an end.
As of June 2012, Investor AB owns a 30% stake in the company (39.5% of the voting rights) and is the majority owner.
Aircraft production.
The main focus of aircraft production is fighter aircraft. Saab has been making aircraft since the 1930s, and the jet predecessors of the JAS 39 Gripen were the Tunnan, the Lansen, the Draken and the Viggen. The last civilian models made by Saab were the Saab 340 and Saab 2000. Both were mid-range turboprop-powered passenger planes. The development and the manufacturing of these aircraft takes place in Linköping.
Organization.
Aeronautics.
Aeronautics offers airborne systems, related subsystems, Unmanned Aerial Systems (UAS) and aerostructures. The business area Aeronautics is responsible for airframe structures for JAS 39 Gripen, and whole sections for Airbus, Boeing and NH90; & system development of the JAS 39 Gripen and the Skeldar VTOL UAV. Aeronautics is also partner in the European joint UAV-project Dassault nEUROn, where Saab develop Avionics and is responsible for the overall architecture and design. Marketing and support of the JAS 39 Gripen fighter jet is also included in the Aeronautics business area.
Dynamics.
Dynamics offers ground combat weapons, missile systems, torpedoes, sensor systems, unmanned underwater vehicles and signature management systems, remotely operated vehicles for armed forces as well as civil security applications.
Short range weapons offered include Carl-Gustaf, AT4/AT4 CS, STRIX and MBT LAW. Missile systems offered are RBS 70, RBS 23 and RBS 15.
Electronic Defence Systems.
Saab Electronic Defence Systems offers airborne, ground based and naval radars, including Erieye, ARTHUR and GIRAFFE.
Various self-protection systems are also offered within the business area, such as counter measure dispenser systems, sensors and jammers. The business area also offer display systems, head up displays, monitoring systems and various other avionics related solutions.
Security and Defence Solutions.
The security and defence solutions area develop systems within the civil security sector as well as training and simulation solutions. The offer include Airborne early warning systems and C4ISTAR systems.
The training and simulation operations of the area offer tactical training and live-firing solutions for military and civil security use.
Support and Services.
Support and Services offer maintenance, integrated support solutions, field facilities, logistics and regional aircraft maintenance.
Saab Aircraft Leasing leases and resells Saab aircraft to airlines. It completed 30 transactions in 2010.
Saab Barracuda LLC.
The Saab Barracuda LLC facility in Lillington, North Carolina, manufactures signature management products and provides customized services. Foremost among the camouflage, concealment and deception products is the Ultra Lightweight Camouflage Net System (ULCANS) which provides multi-spectral protection against visual, near infrared, thermal infrared and broadband radar detection. ULCANS is fielded with the U.S. Army and other Department of Defense organizations and is available in both woodland and desert versions. Saab Barracuda is one of only two qualified suppliers of ULCANS in North America, and currently holds a competed $1.76 B contract, along with GMA Cover Corp.
Saab Kockums.
Submarine division Kockums acquisition.
References.
Bibliography.
</dl>

</doc>
<doc id="26970" url="http://en.wikipedia.org/wiki?curid=26970" title="Škoda Auto">
Škoda Auto

Škoda Auto (]), more commonly known as Škoda, is a Czech automobile manufacturer founded in 1895 as Laurin & Klement. It is headquartered in Mladá Boleslav, Bohemia, Czech Republic.
The car manufacturer was acquired by Škoda Works in 1925, and became a wholly owned subsidiary of the Volkswagen Group in 2000, positioned as the entry brand to the group. Its total global sales reached 1.04 million cars in 2014.
History.
The Škoda Works were established as an arms manufacturing plant in 1859. Škoda Auto (and its predecessors) is one of the five oldest companies producing cars and has an unbroken history alongside Tatra, Daimler, Opel and Peugeot.
Laurin and Klement, Slavia.
The origins of what became Škoda Auto go back to the early 1890s when, like many long-established car manufacturers, a company started manufacturing bicycles. Škoda factories were founded in 1869. In 1894, 26-year-old Václav Klement, who was a bookseller in Mladá Boleslav, Bohemia (today's Czech Republic, then part of Austria-Hungary), was unable to obtain spare parts to repair his German bicycle. 
Klement returned his bicycle to the manufacturers, Seidel and Naumann, with a letter, in Czech, asking them to carry out repairs, only to receive a reply, in German, stating: "If you would like an answer to your inquiry, you should try writing in a language we can understand". Not satisfied with the reply and realising the business potential, Klement, despite having no technical experience, decided to start a bicycle repair shop, which he and Václav Laurin opened in 1895 in Mladá Boleslav. Before going into partnership with Klement, Laurin was an established bicycle manufacturer in the nearby town of Turnov. 
In 1898, after moving to their newly built factory, the pair bought a Werner "Motocyclette". Laurin & Klement's first motorcyclette, powered by an engine mounted on the handlebars driving the front wheels, proved dangerous and unreliable—an early accident on it cost Laurin a front tooth. To design a safer machine with its structure around the engine, the pair wrote to German ignition specialist Robert Bosch for advice on a different electromagnetic system. The pair's new motorcycle made its debut in 1899.
In 1900, with a company workforce of 32, local production began and 150 machines were shipped to London for the Hewtson firm. Shortly afterwards, the press credited them as makers of the first motorcycle. The first model, Voiturette A, was a success and the company was established both within Austria-Hungary and internationally. By 1905 the firm was manufacturing automobiles, making it the second oldest car manufacturer in the Czech lands after Tatra.
Škoda.
After World War I the Laurin & Klement company began producing trucks, but in 1924, after running into problems and being affected by a fire on their premises, the company sought a new partner.
Meanwhile "Akciová společnost, dříve Škodovy závody" (Limited Company, formerly the Škoda Works), an arms manufacturer and multi-sector concern which had become one of the largest industrial enterprises in Europe and the largest in Czechoslovakia, started manufacturing cars in cooperation with Hispano-Suiza. Škoda sought to enlarge its non-arms manufacturing base and acquired Laurin & Klement in 1925. Most of the later production took place under Škoda's name.
An assembly line was used for production from 1930 onwards. In the same year a formal spin-off of the car manufacture into a new company, "Akciová společnost pro automobilový průmysl" or abbreviated "ASAP", took place. ASAP remained a wholly owned subsidiary of the Škoda Works and continued to sell cars under the Škoda marque. Apart from the factory in Mladá Boleslav it included also the firm's representation, sales offices and services, as well as a central workshop in Prague. At the time, the car factory in Mladá Boleslav covered an area of 215,000 m2 and employed 3,750 blue-collar and 500 white-collar workers.
After a decline caused by the economic depression, Škoda introduced a new line of cars in the 1930s which significantly differed from its previous products. A new design of chassis with backbone tube and all-around independent suspension was developed under the leadership of chief engineer Vladimír Matouš and modelled on the one first introduced by Hans Ledwinka in Tatra. First used on model Škoda 420 Standard in 1933, it aimed at solving insufficient torsional stiffness of the ladder frame.
The new design of chassis became the basis for models Popular (845-1,089 cc), Rapid (1165–1766 cc), Favorit (1802–2091 cc) and the Superb (2.5–4 l). While in 1933 Škoda had a 14% share of the Czechoslovak car market and occupied third place behind Praga and Tatra, the new line made it a market leader by 1936, with a 39% share in 1938.
During the occupation of Czechoslovakia in World War II the Škoda Works were turned into part of the "Reichswerke Hermann Göring" serving the German war effort by producing components for military terrain vehicles, military planes, other weapon components and cartridge cases. Vehicle output decreased from 7,052 in 1939 to 683 in 1944, of which only 35 were passenger cars. A total of 316 trucks were produced between January and May 1945. The UK and US air forces bombed the Škoda works repeatedly between 1940 and 1945. The final massive air raid took place on 25 April 1945 and resulted in almost the complete destruction of the Škoda armament works and approximately 1,000 dead and injured.
Post World War II.
When, by July 1945, the Mladá Boleslav factory had been reconstructed, production of Škoda's first post-World War II car, the 1101 series began. It was essentially an updated version of the pre-World War II Škoda Popular. In the autumn of 1945, Škoda (along with all other large manufacturers) became part of the communist planned economy, which meant it was separated from the parent company, Škoda Works. In spite of unfavourable political conditions and losing contact with technical development in non-communist countries, Škoda retained a good reputation until the 1960s, producing models such as the Škoda 440 Spartak, 445 Octavia, Felicia and Škoda 1000 MB.
In late 1959, the Škoda Felicia, a compact four-cylinder convertible coupe, was imported into the United States for model year 1960. Its retail price was around US$2,700, for which one could purchase a nicely-equipped V8 domestic car that was larger, more comfortable, and had more luxury and convenience features (gasoline retailed for less than 30 cents per gallon, so fuel economy was not of primary importance in America at that time). Those Felicias that made it to American ownership soon experienced a number of reliability problems, further damaging the car's reputation. The Felicia was therefore a poor seller in the States and leftover cars ended up being hied off at a fraction of the original retail list. Since that time, Škoda automobiles have not been imported into the U.S. for retail sale.
In the late 1980s, Škoda (then named "Automobilové závody, národní podnik" or abbreviated "AZNP") was still manufacturing cars that conceptually dated back to the 1960s. Rear engined models such as the Škoda 105/120, Estelle and Rapid sold steadily and performed well against more modern makes in races such as the RAC Rally in the 1970s and 1980s. They won their class in the RAC rally for 17 years running. They were powered by a 130 bhp, 1289 cc engine. In spite of its dated image and becoming the subject of negative jokes, Škodas remained a common sight on the roads of UK and Western Europe throughout the 1970s and 1980s.
Sport versions of the Estelle and earlier models were produced, using the name "Rapid". Soft-top versions were also available. The Rapid was once described as the "poor man's Porsche", and had significant sales success in the UK during the 1980s.
In 1987 the Favorit was introduced, and was one of a triumvirate of compact Western-influenced front-wheel drive hatchbacks from the three main Eastern Bloc manufacturers around that time, the others being VAZ's Lada Samara and Zastava's Yugo Sana. The Favorit's appearance was the work of the Italian design company Bertone. With some motor technology licensed from western Europe, but still using the Škoda-designed 1289 cc engine, Škoda engineers designed a car comparable to western production. The technological gap was still there, but began closing rapidly. The Favorit was very popular in Czechoslovakia and other Eastern Bloc countries. It also sold well in Western Europe, especially in the UK and Denmark due to its low price and was regarded as solid and reliable. However, it was perceived as having poor value compared with contemporary Western European designs. The Favorit's trim levels were improved and it continued to be sold until the introduction of the Felicia in 1994.
Volkswagen Group subsidiary.
The fall of communism with the Velvet Revolution brought great changes to Czechoslovakia and most industries were subject to privatisation. In the case of Škoda Automobile, the state authorities brought in a strong foreign partner. Volkswagen was chosen by the Czech government on December 9, 1990, and, as a result, on March 28, 1991 a joint-venture partnership agreement with Volkswagen took place, marked by the transfer of a 30% share to the Volkswagen Group on April 16, 1991. By this stage, Skoda was still making its outdated range of rear engine saloons, although it had started production of the Favorit front-wheel drive hatchback in 1988 as an eventual replacement.
In the following years, Škoda became the fourth brand of the German group, as the Volkswagen Group raised its equity share first on December 19, 1994, to 60.3%, followed on December 11, 1995, to 70%.
In the competition for Škoda, Volkswagen was pitted against French car-maker Renault, which lost out because its strategic plan did not include producing high-value models in the Czech factories: Renault proposed to manufacture the Renault Twingo city car in the Škoda factories.
At the time the decision was made, privatisation to a major German company was somewhat controversial. However, it could be argued that the subsequent fortunes of other Eastern-Bloc automobile manufacturers such as Lada, AutoVAZ, and of Škoda Works itself – once "Škoda Auto's" parent company – suggested that Volkswagen's involvement was not necessarily a result of poor judgement.
Backed by Volkswagen Group expertise and investments, the design — both style and engineering — has improved greatly. The 1994 model Felicia was effectively a reskin of the Favorit, but quality and equipment improvements helped, and in the Czech Republic the car was perceived as good value for money and became popular. Sales improved across Europe, including the United Kingdom, where the Felicia was one of the best-ranking cars in customer satisfaction surveys.
Volkswagen AG chairman Ferdinand Piëch personally chose Dirk van Braeckel as head of design, and the subsequent "Octavia" and "Fabia" models made their way to the demanding European Union markets. They are built on common Volkswagen Group floorpans. The Fabia, launched at the end of 1999, formed the basis for the later versions of the Volkswagen Polo and SEAT Ibiza, while the Octavia, launched in 1996, has shared its floorpan with a host of cars, the most popular of which is the Volkswagen Golf.
The perception of Škoda in Western Europe has changed completely since the takeover by VW, in stark comparison with the reputation of the cars throughout the 1980s—often described as "the laughing stock" of the automotive world. As technical development progressed and attractive new models were marketed, Škoda's image was initially slow to improve. In the UK, a major turnabout was achieved with the ironic "It is a Škoda, honest" campaign, which was started in 2000 when the Fabia was launched. In a 2003 advertisement on British television, a new employee on the production line is fitting Škoda badges on the car bonnets. When some attractive looking cars come along he stands back, not fitting the badge, since they look so good they "cannot be Škodas". This market campaign worked by confronting Škoda's image problem head-on—a tactic which marketing professionals regarded as high risk. Before the advertising campaign, it was common to hear tour guides in Bratislava making jokes about Škoda, saying "How do you double the value of a Škoda? Fill up the petrol tank!" By 2005 Škoda was selling over 30,000 cars a year in the UK, a market share of over 1%. For the first time in its UK history, a waiting list developed for deliveries by Škoda. UK owners have consistently ranked the brand at or near the top of customer satisfaction surveys since the late 1990s. In contrast, the Lada and FSO cars it once competed against were withdrawn from the UK market by the end of the 1990s, due to falling sales and stricter emissions regulations, not to mention the failure to develop newer and better designs, while the Yugo-badged Zastava models were withdrawn from the British market in the early part of the decade as a result of sanctions imposed on the then Yugoslavia during its civil war. Dacia, the Romanian carmaker having been bought and developed by Renault also fared well.
Growth strategy.
2010 was a year of important changes for Škoda Auto, in terms of both products and management. On 1 September 2010, Prof. Dr. h.c. Winfried Vahland assumed responsibility for the management of the company, becoming the CEO of Škoda Auto. Under Vahland's leadership, Škoda set forth plans to double the company’s annual sales to at least 1.5 million by 2018 (later known as the ‘Growth Strategy’, Czech: ‘Růstová Strategie’).
At the 2010 Paris Motor Show in September 2010, the company unveiled the Octavia Green E Line. This e-car concept was the forerunner to the e-car test fleet that Škoda released in 2012. The final 1st-generation Octavia (Tour) was produced at the Mladá Boleslav plant in November 2010. The worldwide production of this model exceeded 1.4 million units since its release in 1996. In 2010 for the first time in history, China overtook German sales to become Škoda's largest individual market.
In 2011, Škoda Auto celebrated its 20-year partnership with the Volkswagen Group. More than 75,000 visitors attended an open-house event held in Mladá Boleslav in the April. Earlier that year, the company provided details on its 2018 Growth Strategy: for at least one new or completely revised model to be released every six months. With this in mind, the company redesigned its logo and CI, which was presented at the 2011 Geneva Motor Show. Škoda’s main attraction at the event was the Vision"D" design concept; a forerunner to the future 3rd generation Octavia. Škoda presented the Mission"L" design study at the IAA in Frankfurt am Main in September, which was to become the basis of the company’s forthcoming compact model the European Rapid. 
In the same year, the company started production of the new Rapid model in Pune, India (October 2011), and launched the Citigo at Volkswagen's Bratislava plant (November 2011).
During 2012 Škoda was preparing the introduction of two volume models. The European version of the Rapid premiered at the Paris Motor Show. This car was a successor to the 1st-generation Octavia in terms of its price bracket. The second volume model was the 3rd-generation Octavia, which premiered In December 2012. In the same month, the local production of the Yeti was launched at the Nizhny Novgorod GAZ factory.
In 2012 Škoda introduced an emission-free fleet of Octavia Green E Line e-cars on Czech roads to be used by external partners. Since internal tests on the fleet in late 2011, the e-fleet had driven more than 250,000 km. During the same year, Škoda celebrated several milestones, including fourteen million Škoda cars being produced since 1905 (January), three million Fabias (May), 500,000 Superbs at the Kvasiny plant (June ) and 5 years of Škoda operations in China.
Massive rejuvenation of the model range was a major tune for 2013 at Škoda: The Czech carmaker launched the third-generation Octavia Combi and Octavia RS (both liftback and estate) as well as facelifted Superb and Superb Combi. They were accompanied by brand new members of the Rapid family as the Rapid Spaceback, the first Škoda hatchback car in the compact segment, and the Chinese version of the Rapid. Also the Yeti faced significant changes. With the facelift, two design variants of Škoda 's compact SUV are now available: city-like Yeti and rugged Yeti Outdoor. Moreover, Chinese customers were given the Yeti with prolonged chassis.
Financial Results.
ŠKODA has maintained sound financial stability over recent years. In 2013 the brand achieved sales revenues totalling €10.3 billion (2012: €10.4 billion). Due to the weak economic situation in many European countries and the expansion of the ŠKODA model range, operating profit reached a modest 522 million euros (2012: €712 million). ŠKODA achieved a successful start to 2014: As well as recording the highest number of deliveries to customers in a first quarter ever (247,200; up 12.1%), ŠKODA recorded a significant increase in sales revenue (23.7%) to almost 3 billion euros. Operating profit increased 65.2% to 185 million Euros over the previous year.
Production.
ŠKODA cars are produced in the Czech Republic, China, Russia, India and Slovakia at ŠKODA’s own production facilities or through partnerships within the Volkswagen Group. ŠKODA models are additionally manufactured in Ukraine and Kazakhstan through local partners.
Czech Republic
ŠKODA has three production sites in the Czech Republic. Mladá Boleslav is the carmaker's base with a tradition of industrial production dating back to 1895. Mladá Boleslav is not only home to the brand's headquarters and R&D department, but is also the location of ŠKODA's largest production facility in the world. ŠKODA also produces engines (e.g. EA 211: 1.2 TSI, 1.4 TSI and EA 111: 1.2 MPI, 1.2 TSI) and gearboxes (MQ 100 and MQ 200 manual gearboxes, SQ 100 piloted gearbox) in Mladá Boleslav for use both in ŠKODA models, and also for other brands within the Volkswagen Group. At the company’s Kvasiny plant, ŠKODA builds the Yeti, Superb and Roomster models, while the Vrchlabí plant is dedicated to the production of the 7-gear direct-shift gearbox (DSG).
India
India became the first non-European country where ŠKODA produces cars. The first car produced in the country was the Octavia at the ŠKODA plant in Aurangabad. The Superb followed in 2004, the Fabia in 2008 and the Yeti in 2010. The Volkswagen Group plant in Pune began manufacturing the Rapid in 2011. Production of the Fabia in India was paused in 2013.
China
In China, ŠKODA cars have been built in cooperation with Shanghai Volkswagen (SVW) since 2007. Initially three models were produced, but nowadays six models – the Fabia, Rapid, Rapid Spaceback, Octavia, Yeti and Superb – roll off the SVW production lines in Anting, Yizheng and Ningbo.
The first ŠKODA model produced in China was the Octavia in 2007. It was followed by the Fabia in 2008, and the Superb in 2009. Production of the Rapid was launched in China at the end of 2012. The ŠKODA Yeti was launched in China in 2013, first as an export model, and later as a locally produced vehicle. The production of the Rapid Spaceback began in spring 2014. Since ŠKODA entered the Chinese market, more than one million ŠKODAs have been produced at SVW plants.
Russia
In Russia ŠKODA cars are produced at the production facilities in Kaluga and Nizhny Novgorod. The first locally assembled model was the Octavia in November 2007. The production of Fabia began in 2008 at the Volkswagen Group Russia (VGR) plant in Kaluga, where the Superb is also produced. The Rapid followed at the beginning of 2014. In partnership with VGR and the Russian automobile manufacturer GAZ, the production of the Yeti in Nizhny Novgorod began in 2011, and the new Octavia has also been manufactured at this plant since 2013.
Slovakia
The city car ŠKODA Citigo has been produced at the Volkswagen Group’s Bratislava plant since 2011.
ŠKODA cars – Production statistics
Motorsport.
World Rally Championship.
Following a long history of class victories in lower levels of motorsport, Škoda became a participant in the FIA World Rally Championship in the 1999 season, with World Rally Car models of the Škoda Octavia. Škoda's best result with the Octavia WRC was Armin Schwarz's third place at the 2001 Safari Rally. From mid 2003, the Octavia was replaced by the smaller Škoda Fabia. Škoda used the 2004 season to develop the car further, but did not achieve much success the following season. However, at the season-ending Rally Australia, 1995 world champion Colin McRae was running second before retiring. Škoda then withdrew from the series, and the 2006 season saw Škoda represented by the semi-privateer Red Bull Škoda Team. Jan Kopecký drove the Fabia WRC to fifth place at the Rally Catalunya, and as late as the 2007 Rallye Deutschland the Fabia still achieved a fifth place result, again in the hands of Kopecký. Former works Ford and Citroen driver François Duval also drove a Fabia WRC in 2006 for the privateer First Motorsport team, achieving a sixth place on Rally Catalunya.
Super 2000.
In 2009, Škoda entered the Intercontinental Rally Challenge (IRC) for the first time, using the Fabia S2000, winning three rallies and finishing second in both the drivers and manufacturers championship. In 2010, Škoda's won a total of seven IRC events winning both the manufacturers and driver championship for Juho Hänninen. These achievements were repeated in the following two seasons, with Andreas Mikkelsen as the drivers' champion. In 2013, the Intercontinental Rally Challenge was merged with the European Rally Championship (ERC) and the team gained the drivers' championship title once again for Jan Kopecký. The car was also raced by privateers in several championships, including Red Bull, Barwa, Rene Georges and Rufa in the 2010 Super 2000 World Rally Championship.
Bonneville Speedway.
In August 2011, a special Škoda Octavia vRS set the world record at the Bonneville Speedway and became the fastest car in the world with an up to two-litre engine, when it hit 227 mph. The current fastest production Škoda car is the Škoda Superb 3.6 FSI 4x4, with a top speed of 250 km/h and acceleration from 0 to in 6.5 seconds.

</doc>
<doc id="26971" url="http://en.wikipedia.org/wiki?curid=26971" title="Seat">
Seat

A seat is a place to sit, referring to the area sat upon as opposed to other elements like armrests.
A seat is also known as a bench, a chair, a chaise longue, "chesterfield", a couch, a "davenport" or a "settee".
Types of seat.
The following are examples of different kinds of seat:
Etymology.
The word seat comes from Middle English "sete" and from Old Norse "sæti"; akin to Old English "gesete" seat, "sittan" to sit. The first known use of the word seat is in the 13th century.

</doc>
<doc id="26972" url="http://en.wikipedia.org/wiki?curid=26972" title="Scandinavian Peninsula">
Scandinavian Peninsula

The Scandinavian Peninsula (Finnish: "Skandinavian Niemimaa"; Norwegian: "Skandinaviske Halvøy"; Nynorsk: "Skandinaviske Halvøya"; Swedish: "Skandinaviska Halvön") is a peninsula in Northern Europe, which today covers Norway, Sweden, and most of northern Finland.
The name of the peninsula is derived from the term Scandinavia, the cultural region of Denmark, Norway, and Sweden. That cultural name is in turn derived from the name of Scania, the region at the southern extremity of the peninsula which has during periods been part of Denmark, which is the ancestral home of the Danes, and which is now part of Sweden. The derived term "Scandinavian" also refers to the Germanic peoples who speak North Germanic languages, considered to be a dialect continuum derived from Old Norse. These languages are Danish, Swedish, Norwegian, Faroese, and Icelandic, with the latter two being closest to Old Norse.
The Scandinavian Peninsula is the largest peninsula of Europe, larger than the Balkan, the Iberian and the Italian peninsulas. During the Ice Ages, the sea level of the Atlantic Ocean dropped so much that the Baltic Sea, the Gulf of Bothnia, and the Gulf of Finland disappeared, and the countries now surrounding them, including Germany, Poland, the other Baltic countries and Scandinavia, were directly joined by land.
Geography.
Arguably the largest peninsula in Europe, the Scandinavian Peninsula is approximately 1,850 km long with a width varying approximately from 370 to 805 kilometers (230 to 500 miles). The Scandinavian mountain range generally defines the border between Norway and Sweden. The peninsula is bordered by several bodies of water including:
Its highest elevation was Glittertinden in Norway at 2,470 m above sea level, but since the glacier at its summit partially melted , the highest elevation is at 2,469 m at Galdhøpiggen, also in Norway. These mountains also have the largest glacier on the mainland of Europe, Jostedalsbreen.
About one quarter of the Scandinavian Peninsula lies north of the Arctic Circle, its northernmost point being at Cape Nordkyn, Norway.
The climate across Scandinavia varies from tundra (Köppen: ET) and subarctic (Dfc) in the north, with cool marine west coast climate (Cfc) in northwestern coastal areas reaching just north of Lofoten, to humid continental (Dfb) in the central portion, and marine west coast (Cfb) in the south and southwest.
The region is rich in timber, iron and copper with the best farmland in southern Sweden. Large petroleum and natural-gas deposits have been found off Norway's coast in the North Sea and the Atlantic Ocean.
Much of the population of the Scandinavian Peninsula is naturally concentrated in its southern part, which is also its agricultural region. The largest cities of the peninsula are Stockholm, Sweden; Oslo, Norway; Gothenburg, Sweden; Malmö, Sweden and Bergen, Norway, in that order.
Geology.
The Scandinavian Peninsula occupies part of the Baltic Shield, a stable and large crust segment formed of very old, crystalline metamorphic rocks. Most of the soil covering this substrate was scraped by glaciers during the Ice Ages of antiquity, especially in northern Scandinavia, where the Baltic Shield is closest to the surface of the land. As a consequence of this scouring, the elevation of the land, and the cool-to-cold climate, a relatively small percentage of its land is arable.
The glaciation during the Ice Ages also deepened many of the river valleys, which were invaded by the sea when the ice melted, creating the noteworthy fjords of Norway. In the southern part of the peninsula, the glaciers deposited vast numbers of terminal moraines, configuring a very chaotic landscape. These terminal moraines covered all of what is now Denmark.
Although the Baltic Shield is mostly geologically stable and hence resistant to the influences of other neighboring tectonic formations, the weight of nearly four kilometers of ice during the Ice Ages caused all of the Scandinavian terrain to sink. When the ice sheet disappeared, the shield rose again, a tendency that continues to this day at a rate of about one meter per century. Conversely, the southern part has tended to sink to compensate, causing flooding of the Low Countries and Denmark.
The crystalline substrate of the land and absence of soil in many places have exposed mineral deposits of metal ores, such as those of iron, copper, nickel, zinc, silver, and gold. The very most valuable of these have been the deposits of iron ore in northwestern Sweden. In the 19th century these deposits prompted the building of a railway from northwestern Sweden to the Norwegian seaport of Narvik so that the iron ore could be exported by ship to places like southern Sweden, Germany, Great Britain, and Belgium for smelting into iron and steel. This railway is in a region of Norway and Sweden that otherwise do not have any railways because of the very rugged terrain, mountains, and fjords of that part of Scandinavia.
People.
The first recorded human presence in the southern area of the peninsula and Denmark dates from 12,000 years ago. As the ice sheets from the glaciation retreated, the climate allowed a tundra biome that attracted reindeer hunters. The climate warmed up gradually, favoring the growth of evergreen trees first, and then deciduous forest which brought animals like aurochs. Groups of hunter-fisher-gatherers started to inhabit the area from the Mesolithic (8200 BC), up to the advent of agriculture in the Neolithic (3200 BC).
The northern and central part of the peninsula is partially inhabited by the Sami, often referred to as "Lapps" or "Laplanders," who began to arrive several thousand years after the Scandinavian Peninsula had already been inhabited in the south. In the earliest recorded periods they occupied the arctic and subarctic regions as well as the central part of the peninsula as far south as Dalarna, Sweden. They speak the Sami language, a non-Indo-European language of the Uralic family which is related to Finnish and Estonian. The first inhabitants of the peninsula were the Norwegians on the west coast of Norway, the Danes in what is now southern and western Sweden and southeastern Norway, the Svear in the region around Mälaren as well as a large portion of the present day eastern seacoast of Sweden and the Geats in Västergötland and Östergötland. These peoples spoke closely related dialects of an Indo-European language, Old Norse. Although political boundaries have shifted, descendants of these peoples still are the dominant populations in the peninsula in the early 21st century.
Political development.
Although the Nordic countries look back on more than 1000 years of history as distinct political entities, the international boundaries came late and emerged gradually. It was not until the middle of the 17th century that Sweden had a secure outlet on the Kattegat and control of the south Baltic coast. The Swedish and Norwegian boundaries were finally agreed and marked out in 1751. The Finnish-Norwegian border on the peninsula was established after extensive negotiation in 1809, and the common Norwegian-Russian districts were not partitioned until 1826. Even then the borders were still fluid, with Finland gaining access to the Barents Sea in 1920, but ceding this territory to Russia in 1944.
Denmark, Sweden, and the Russian Empire dominated the political relationships on the Scandinavian Peninsula for centuries, with Iceland, Finland, and Norway only gaining their full independence during the 20th century. The Kingdom of Norway – long held in personal union by Denmark – fell to Sweden after the Napoleonic Wars and only attained full independence in 1905. Having been an autonomous grand duchy within the Russian Empire since 1809, Finland declared independence during the Soviet revolution of Russia in 1917. Iceland declared its independence from Denmark in 1944, while Denmark was under the occupation of Nazi Germany. Iceland was encouraged to do this by the British and American armed forces that were defending Iceland from Nazi invasion.
The Wehrmacht invaded Norway in 1940 and the German Army occupied all of Norway until May 1945. With the acquiescence of the Kingdom of Sweden, German troops moved from northern Norway, across northern Sweden, into Finland, which had become an ally of Nazi Germany. Then, in the spring of 1941, the German Army and the Finnish Army invaded the Soviet Union together. The Republic of Finland had a grievance against the Soviet Union because the Red Army had invaded southeastern Finland in the Winter War and had taken a large area of territory away from Finland.
Sweden remained a neutral country during World War I, World War II, the Korean War, and the Cold War, and it continues its neutral policies as of 2013.
In 1945, Norway, Denmark, and Iceland were founding members of the United Nations. Sweden joined the U.N. soon after. Finland joined during the 1950s. The first Secretary General of the United Nations, Trygve Lie, was a Norwegian citizen. The second Secretary General of the United Nations, Dag Hammarskjöld, was a Swedish citizen. Thus the people of the Scandinavian Peninsula had a strong influence in international affairs during the 20th century.
In 1949, Norway, Denmark, and Iceland became founding members of the North Atlantic Treaty Organization for their defense against Germany, the Soviet Union, and all other potential invaders, and these three countries remain members as of 2011.
Sweden and Finland joined the European Union in 1995. Norway, however, remains outside the Union.

</doc>
<doc id="26973" url="http://en.wikipedia.org/wiki?curid=26973" title="San Francisco Bay">
San Francisco Bay

San Francisco Bay is a shallow estuary that drains water from approximately forty percent of California. Water from the Sacramento and San Joaquin rivers, and from the Sierra Nevada mountains passes through the Bay to the Pacific Ocean. Specifically, both rivers flow into Suisun Bay, which flows through the Carquinez Strait to meet with the Napa River at the entrance to San Pablo Bay, which connects at its south end to San Francisco Bay. However, the entire group of interconnected bays is often called the "San Francisco Bay".
San Francisco Bay is in the U.S. state of California, surrounded by a contiguous region known as the San Francisco Bay Area (often simply "the Bay Area"), dominated by the large cities San Francisco, Oakland, and San Jose. The waterway entrance to San Francisco Bay from the Pacific Ocean is called the Golden Gate. Across the strait spans the Golden Gate Bridge. The bay was designated a Ramsar Wetland of International Importance on February 2, 2013.
Size.
The bay covers somewhere between 400 and 1,600 square miles (1,040 to 4,160 square kilometers), depending on which sub-bays (such as San Pablo Bay), estuaries, wetlands, and so on are included in the measurement. The main part of the Bay measures 3 to 12 miles (5 to 20 km) wide east-to-west and somewhere between 48 mi1 and 60 mi2 north-to-south. It is the largest Pacific estuary in the Americas.
The bay was navigable as far south as San Jose until the 1850s, when hydraulic mining released massive amounts of sediment from the rivers that settled in those parts of the bay that had little or no current. Later, wetlands and inlets were deliberately filled in, reducing the Bay's size since the mid-19th century by as much as one third. Recently, large areas of wetlands have been restored, further confusing the issue of the Bay's size. Despite its value as a waterway and harbor, many thousands of acres of marshy wetlands at the edges of the bay were, for many years, considered wasted space. As a result, soil excavated for building projects or dredged from channels was often dumped onto the wetlands and other parts of the bay as landfill.
From the mid-19th century through the late 20th century, more than a third of the original bay was filled and often built on. The deep, damp soil in these areas is subject to liquefaction during earthquakes, and most of the major damage close to the Bay in the Loma Prieta earthquake of 1989 occurred to structures on these areas.
The Marina District of San Francisco, hard hit by the 1989 earthquake, was built on fill that had been placed there for the Panama-Pacific International Exposition (1915), although liquefaction did not occur on a large scale. In the 1990s, San Francisco International Airport proposed filling in hundreds more acres to extend its overcrowded international runways in exchange for purchasing other parts of the bay and converting them back to wetlands. The idea was, and remains, controversial. (For further details, see the "Bay Fill and Depth Profile" section.)
There are five large islands in San Francisco Bay. Alameda, the largest island, was created when a shipping lane was cut in 1901. It is now predominantly a bedroom community. Angel Island was known as "Ellis Island West" because it served as the entry point for immigrants from East Asia. It is now a state park accessible by ferry. Mountainous Yerba Buena Island is pierced by a tunnel linking the east and west spans of the San Francisco – Oakland Bay Bridge. Attached to the north is the artificial and flat Treasure Island, site of the 1939 Golden Gate International Exposition. From the Second World War until the 1990s, both islands served as military bases and are now being redeveloped. Isolated in the center of the Bay is Alcatraz, the site of the famous federal penitentiary. The federal prison on Alcatraz Island no longer functions, but the complex is a popular tourist site. Despite its name, Mare Island in the northern part of the bay is a peninsula rather than an island.
San Francisco Bay, and the city skyline seen from Marin County in the Golden Gate National Recreation Area.
Geology.
San Francisco Bay is thought to represent a down-warping of the Earth's crust between the San Andreas Fault to the west and the Hayward Fault to the east, though the precise nature of this remains under study. During the last ice age, the basin now filled by the bay was a large linear valley with small hills, similar to most of the valleys of the Coast Ranges. The rivers of the Central Valley ran out to sea through a canyon that is now the Golden Gate. As the great ice sheets melted, sea level rose 300 ft over 4,000 years, and the valley filled with water from the Pacific, becoming a bay. The small hills became islands.
History.
The first recorded European discovery of San Francisco Bay was on November 4, 1769 when Spanish explorer Gaspar de Portolà, unable to find the port of Monterey, California, continued north close to what is now Pacifica and reached the summit of the 1200 ft high Sweeney Ridge, now marked as the place where he first sighted San Francisco Bay. Portolá and his party did not realize what they had discovered, thinking they had arrived at a large arm of what is now called Drakes Bay. At the time, Drakes Bay went by the name "Bahia de San Francisco" and thus both bodies of water became associated with the name. Eventually, the larger, more important body of water fully appropriated the name "San Francisco Bay".
The first European to enter the bay is believed to have been the Spanish explorer Juan de Ayala, who passed through the Golden Gate on August 5, 1775 in his ship the "San Carlos", and moored in a bay of Angel Island now known as Ayala Cove. Ayala continued to explore the Bay area and the expedition's cartographer, José de Cañizares, gathered the information necessary to produce the first map of the San Francisco Bay area. A number of place names survive (anglicized) from that first map, including Point Reyes, Angel Island, Farallon Islands and Alcatraz Island.
The United States seized the region from Mexico during the Mexican-American War (1846–1848). On February 2, 1848 California was annexed to the U.S. with the signing of the Treaty of Guadalupe Hidalgo. A year and a half later, California requested to join the United States on December 3, 1849 and was accepted as the 31st State of the union on September 9, 1850.
The bay became the center of American settlement and commerce in the Far West through most of the remainder of the 19th century. During the California Gold Rush (1848-1855), San Francisco Bay suddenly became one of the world's great seaports, dominating shipping in the American West until the last years of the 19th century. The bay's regional importance increased further when the First Transcontinental Railroad was connected to its western terminus at Alameda on September 6, 1869. The terminus was switched to the Oakland Long Wharf two months later on November 8, 1869.
San Francisco Bay continues to support some of the densest industrial production and urban settlement in the United States. The San Francisco Bay Area is the American West's second-largest urban area with approximately 8 million residents.
Ecology.
Despite its urban and industrial character, San Francisco Bay and the Sacramento-San Joaquin Delta remain perhaps California's most important ecological habitats. California's Dungeness crab, California halibut, and Pacific salmon fisheries rely on the bay as a nursery. The few remaining salt marshes now represent most of California's remaining salt marsh, supporting a number of endangered species and providing key ecosystem services such as filtering pollutants and sediments from the rivers. San Francisco Bay is recognized for protection by the California Bays and Estuaries Policy, with oversight provided by the San Francisco Estuary Partnership.
Most famously, the bay is a key link in the Pacific Flyway. Millions of waterfowl annually use the bay shallows as a refuge. Two endangered species of birds are found here: the California least tern and the California clapper rail. Exposed bay muds provide important feeding areas for shorebirds, but underlying layers of bay mud pose geological hazards for structures near many parts of the bay perimeter. San Francisco Bay provided the nation's first wildlife refuge, Oakland's artificial Lake Merritt, constructed in the 1860s, and America's first urban National Wildlife Refuge, the Don Edwards San Francisco Bay National Wildlife Refuge (SFBNWR) in 1972. The Bay is also plagued by non-native species.
Salt produced from San Francisco Bay is produced in salt evaporation ponds and is shipped throughout the Western United States to bakeries, canneries, fisheries, cheese makers and other food industries and used to de-ice winter highways, clean kidney dialysis machines, for animal nutrition, and in many industries. Many companies have produced salt in the Bay, with the Leslie Salt Company the largest private land owner in the Bay Area in the 1940s.
Low-salinity salt ponds mirror the ecosystem of the bay, with fish and fish-eating birds in abundance. Mid-salinity ponds support dense populations of brine shrimp, which provide a rich food source for millions of shorebirds. Only salt-tolerant micro-algae survive in the high salinity ponds, and impart a deep red color to these ponds from the pigment within the algae protoplasm.
The seasonal range of water temperature in the Bay is from January's 53 °F to September's 60 °F when measured at Fort Point, which is near the southern end of the Golden Gate Bridge and at the entrance to San Francisco Bay.
Industrial, mining, and other uses of mercury have resulted in a widespread distribution in the bay, with uptake in the bay's phytoplankton and contamination of its sportfish. In January 1971, two Standard Oil tankers collided in the bay, creating an 800,000 gallon oil spill disaster, which spurred environmental protection of the bay. In November 2007, a ship named "COSCO Busan" collided with the San Francisco – Oakland Bay Bridge and spilled over 58,000 gallons of bunker fuel, creating the largest oil spill in the region since 1996.
At times, San Francisco Bay is covered in fog.
For the first time in 65 years, Pacific Harbor Porpoise ("Phocoena phocoena") returned to the Bay in 2009. Golden Gate Cetacean Research, a non-profit organization focused on research on cetaceans, has developed a photo-identification database enabling the scientists to identify specific porpoise individuals and is trying to ascertain whether a healthier bay has brought their return. Pacific harbor porpoise range from Point Conception, California to Alaska and across to the Kamchatka Peninsula and Japan. Recent genetic studies show that there is a local stock from San Francisco to the Russian River and that eastern Pacific coastal populations rarely migrate far, unlike western Atlantic Harbor porpoise.
City skyline through the fog, from the Golden Gate National Recreation Area.
Bay fill and depth profile.
San Francisco Bay's profile changed dramatically in the late 19th century and again with the initiation of dredging by the US Army Corps of Engineers in the 20th century. Before about 1860, most bay shores (exception: rocky shores such as those in Carquinez Strait, along Marin shoreline, Point Richmond, Golden Gate area) contained extensive wetlands that graded nearly invisibly from freshwater wetlands to salt marsh and then tidal mudflat. A deep channel ran through the center of the bay, following the ancient drowned river valley.
In the 1860s and continuing into the early 20th century, miners dumped staggering quantities of mud and gravel from hydraulic mining operations into the upper Sacramento and San Joaquin Rivers. GK Gilbert's estimates of debris total more than eight times the amount of rock and dirt moved during construction of the Panama Canal. This material flowed down the rivers, progressively eroding into finer and finer sediment, until it reached the bay system. Here some of it settled, eventually filling in Suisun Bay, San Pablo Bay, and San Francisco Bay, in decreasing order of severity.
By the end of the 19th century, these "slickens" had filled in much of the shallow bay flats, raising the entire bay profile. New marshes were created in some areas.
In the last years of the nineteenth- and first decades of the twentieth-centuries, at the behest of local political officials and following Congressional orders, the US Army Corps began dredging the Sacramento and San Joaquin Rivers and the deep channels of San Francisco Bay. This work has continued without interruption ever since, an enormous federal subsidy of San Francisco Bay shipping. Some of the dredge spoils were initially dumped in the bay shallows (including helping to create Treasure Island on the former shoals to the north of Yerba Buena Island) and used to raise an island in the Sacramento-San Joaquin Delta. The net effect of dredging has been to maintain a narrow deep channel—deeper perhaps than the original bay channel—through a much shallower bay. At the same time, most of the marsh areas have been filled or blocked off from the bay by dikes.
Large ships transiting the bay must follow deep underwater channels that are maintained by frequent dredging as the average depth of the Bay is only as deep as a swimming pool—approximately 12 to. Between Hayward and San Mateo to San Jose it is 12 to. The deepest part of the bay is under and out of the Golden Gate Bridge, at 372 ft.
In the late 1990s, a 12-year harbor-deepening project for the Port of Oakland began; it was largely completed by September 2009. Previously, the bay waters and harbor facilities only allowed for ships with a draft of 46 ft, but dredging activities undertaken by the United States Army Corps of Engineers in partnership with the Port of Oakland succeeded in providing access for vessels with a 50 ft draft. Four dredging companies were employed in the $432 million project, with $244 million paid for with federal funds and $188 million supplied by the Port of Oakland. Some 6000000 yd3 of mud from the dredging was deposited at the western edge of Middle Harbor Shoreline Park to become a 188 acre shallow-water wetlands habitat for marine and shore life. Further dredging followed in 2011, to maintain the navigation channel. This dredging enabled the arrival of the largest container ship ever to enter the San Francisco Bay, the "MSC Fabiola". Bay pilots trained for the visit on a simulator at the California Maritime Academy for over a year. The ship arrived drawing less than its full draft of 50 ft because it held only three-quarters of a load after its stop in Long Beach.
Transportation.
San Francisco Bay was traversed by watercraft since long before the coming of Europeans. Indigenous peoples used canoes to fish and clam along the shoreline. The era of sail brought ships that connected the area to the rest of the world—and served as early ferries and freighters within the Bay and between the Bay and inland ports, such as Sacramento and Stockton. These were gradually replaced by steam-powered vessels starting in the late 19th century. Several shipyards were early established around the Bay, augmented during wartime. (e.g., the "Kaiser Shipyards")
San Francisco Bay is spanned by eight bridges, all dedicated to vehicle traffic.
The Transbay Tube, an underwater tube that BART runs through, runs from Oakland to San Francisco. Prior to the bridges and, later, the Transbay Tube, transbay transportation was dominated by fleets of ferryboats operated by the Southern Pacific Railroad and the Key System transit company. However, in recent decades, ferries have returned, primarily serving commuters from Marin County, relieving the traffic bottleneck of the Golden Gate Bridge. ("See article" Ferries of San Francisco Bay).
The Bay also continues to serve as a major international shipping port, served by a large container facility operated by the Port of Oakland, and two smaller facilities in Richmond and San Francisco. 
Recreation.
San Francisco Bay is a mecca for sailors (boats, as well as windsurfing and kitesurfing), due to consistent strong westerly/northwesterly thermally-generated winds (Beaufort force 6 (15-25 knots) is common on summer afternoons) and protection from large open ocean swells. Yachting and yacht racing are popular pastimes and the San Francisco Bay Area is home to many of the world's top sailors. A shoreline bicycle and pedestrian trail known as the San Francisco Bay Trail encircles the edge of the bay. The San Francisco Bay Area Water Trail, a growing network of launching and landing sites around the Bay for non-motorized small boat users (such as kayakers) is being developed. Parks and protected areas around the bay include Eden Landing Ecological Reserve, Hayward Regional Shoreline, Don Edwards San Francisco Bay National Wildlife Refuge, Hayward Shoreline Interpretive Center, Crown Memorial State Beach, Eastshore State Park, Point Isabel Regional Shoreline, Brooks Island Regional Shoreline, and César Chávez Park.
The San Francisco Bay Area Water Trail is a planned system of designated trailheads designed to improve non-motorized small boat access to the bay. The California Coastal Conservancy approved funding in March 2011 to begin implementation of the water trail.
San Francisco Bay panorama with a view of sailboats, kite boarders, and the Crissy Field Beach.
See also.
People

</doc>
<doc id="26974" url="http://en.wikipedia.org/wiki?curid=26974" title="San Francisco Peninsula">
San Francisco Peninsula

The San Francisco Peninsula is a peninsula in the San Francisco Bay Area that separates San Francisco Bay from the Pacific Ocean. On its northern tip is the City and County of San Francisco. Its southern base is in Santa Clara County, including the cities of Palo Alto, Los Altos, and Mountain View. Most of the Peninsula is occupied by San Mateo County, between San Francisco and Santa Clara counties, and including the cities and towns of Atherton, Belmont, Brisbane, Burlingame, Colma, Daly City, East Palo Alto, El Granada, Foster City, Hillsborough, Half Moon Bay, La Honda, Menlo Park, Millbrae, Pacifica, Portola Valley, Redwood City, San Bruno, San Carlos, San Mateo, South San Francisco, and Woodside.
Whereas the term "peninsula" technically refers to the entire geographical San Franciscan Peninsula, in local jargon, "The Peninsula" does not include the city of San Francisco.
History.
In 1795, Governor Diego de Borica gave José Darío Argüello a Spanish land grant known as Rancho de las Pulgas. This rancho was the largest grant on the peninsula consisting of 35260 acre.
As a local geographic term, "The Peninsula" is distinct from "The City", and refers to the portion south of San Francisco. The appellation may date to the period, prior to 1856, when the City of San Francisco and the County of San Francisco were separate entities, the latter then coextensive with contemporary San Mateo County and San Francisco City-County. The City-County owns several disjunct properties along the whole of the Peninsula (mostly water pumping stations connected to the Hetch Hetchy Valley on which San Francisco has a permanent leasehold); thus, most of the larger communities in San Mateo County are "de facto" suburbs of San Francisco, with the neighboring communities of Pacifica, Daly City, Broadmoor, Colma, South San Francisco, Half Moon Bay, San Bruno, and Brisbane being immediate suburbs. The remaining suburban area of the Peninsula is on the east side of the Santa Cruz Mountains, along San Francisco Bay; the west and south-central portions of the Peninsula are mostly rural, unincorporated and unorganised areas.
The Peninsula is a part of the Silicon Valley. In Silicon Valley sits some of the largest tech companies in the world with the likes of Google, Yahoo, Facebook and Apple. Over the last decade or so there has been an influx of immigration into the Bay Area from places like India and China to work in the technology industry. There are well over 6,600 tech startups in the Valley and new ones are created every day. 
Boundaries.
The east side of the peninsula is a heavy densely populated and a largely urban area that includes portions of Silicon Valley. It forms a commuter area between San Francisco to the north and San Jose to the south. A number of major thoroughfares run north-south: El Camino Real (SR 82) and US 101 on the east side along the bay, Interstate 280 down the center, Skyline Boulevard (SR 35) along the crest of the Santa Cruz Mountains, and Highway 1 on the west along the Pacific. The Caltrain commuter rail line runs roughly parallel to the El Camino Real (State Route 82) and Highway 101 corridors.
The bridges in the Peninsula include the Dumbarton Bridge, the San Francisco - Oakland Bay Bridge and the San Mateo-Hayward Bridge. 
Along the center line of the Peninsula is the northern half of the Santa Cruz Mountains, formed by the action of plate tectonics along the San Andreas Fault. In the middle of the Peninsula along the fault is the Crystal Springs Reservoir. Just north of the Crystal Springs reservoir is San Andreas Lake after which the famous geologic fault was originally named.
Environmental features.
The San Francisco Peninsula contains a variety of habitats including estuarine, marine, oak woodland, redwood forest, coastal scrub and oak savanna. There are numerous species of wildlife present, especially along the San Francisco Bay estuarine shoreline, San Bruno Mountain, Fitzgerald Marine Reserve and the forests on the Montara Mountain block.
The county is home to several endangered species including the San Francisco garter snake, the Mission blue butterfly and the San Bruno elfin butterfly, all of which are endemic to San Mateo County. The endangered California clapper rail is also found on the shores of San Francisco Bay, in the cities of Belmont and San Mateo.
A number of noteworthy parks and nature preserves are found on the San Francisco Peninsula, including:
Notable structures.
There are a number of well-known structures and complexes on the San Francisco Peninsula:

</doc>
<doc id="26976" url="http://en.wikipedia.org/wiki?curid=26976" title="Silicon Valley">
Silicon Valley

Silicon Valley is a nickname for the southern portion of the San Francisco Bay Area in the United States. It is home to many of the world's largest high-tech corporations, as well as thousands of tech startup companies. The region occupies roughly the same area as the Santa Clara Valley where it is centered, including San Jose and surrounding cities and towns. The term originally referred to the large number of silicon chip innovators and manufacturers in the region, but eventually came to refer to all high tech businesses in the area, and is now generally used as a metonym for the American high-technology economic sector. 
Silicon Valley is a leading hub for high-tech innovation and development, accounting for one-third of all of the venture capital investment in the United States. Geographically, Silicon Valley is generally thought to encompass all of the Santa Clara Valley, the southern half of the Peninsula, and southern portions of the East Bay.
Origin of the term.
The term "Silicon Valley" is attributed to Ralph Vaerst, a local entrepreneur. Its first published use is credited to Don Hoefler, a friend of Vaerst's, who used the phrase as the title of a series of articles in the weekly trade newspaper "Electronic News". The series, entitled "Silicon Valley in the USA", began in the paper's January 11, 1971, issue. The term gained widespread use in the early 1980s, at the time of the introduction of the IBM PC and numerous related hardware and software products to the consumer market. The "Silicon" part of the name refers to the high concentration of companies involved in the making of semiconductors (silicon is used to create most semiconductors commercially) and computer industries that were concentrated in the area. These firms slowly replaced the orchards and related agriculture and food production companies which gave the area its initial nickname — the "Valley of Heart's Delight."
History.
 "Perhaps the strongest thread that runs through the Valley's past and present is the drive to 'play' with novel technology, which, when bolstered by an advanced engineering degree and channeled by astute management, has done much to create the industrial powerhouse we see in the Valley today." (Timothy J. Sturgeon):44
Background.
Stanford University, its affiliates, and graduates have played a major role in the development of this area. Some examples include the work of Lee De Forest with his invention of a pioneering vacuum tube called the Audion and the oscilloscopes of Hewlett-Packard.
A very powerful sense of regional solidarity accompanied the rise of Silicon Valley. From the 1890s, Stanford University's leaders saw its mission as service to the West and shaped the school accordingly. At the same time, the perceived exploitation of the West at the hands of eastern interests fueled booster-like attempts to build self-sufficient indigenous local industry. Thus, regionalism helped align Stanford's interests with those of the area's high-tech firms for the first fifty years of Silicon Valley's development.
During the 1940s and 1950s, Frederick Terman, as Stanford's dean of engineering and provost, encouraged faculty and graduates to start their own companies. He is credited with nurturing Hewlett-Packard, Varian Associates, and other high-tech firms, until what would become Silicon Valley grew up around the Stanford campus. Terman is often called "the father of Silicon Valley".
In 1956 William Shockley, the creator of the transistor, moved from New Jersey to Mountain View, California to start Shockley Semiconductor Laboratory to live closer to his ailing mother in Palo Alto, California. Shockley's work served as the basis for many electronic developments for decades.
During 1955–85, solid state technology research and development at Stanford University followed three waves of industrial innovation made possible by support from private corporations, mainly Bell Telephone Laboratories, Shockley Semiconductor, Fairchild Semiconductor, and Xerox PARC. In 1969, the Stanford Research Institute (now SRI International), operated one of the four original nodes that comprised ARPANET, predecessor to the Internet.
Social roots of the information technology revolution.
Silicon Valley was born when several contributing factors intersected, including a skilled STEM research base housed in area universities, plentiful venture capital, and steady U.S. Department of Defense spending. Stanford University leadership was especially important in the valley's early development. Together these elements formed the basis of its growth and success. It was in Silicon Valley that the silicon-based integrated circuit, the microprocessor, and the microcomputer, among other key technologies, were developed. As of 2013 the region employed about a quarter of a million information technology workers.
Roots in telegraph, radio, commercial and military technology.
The first ship-to-shore wireless telegraph message to be received in the US was from the San Francisco lightship outside the Golden Gate, signaling the return of the American fleet from the Philippines after their victory in the Spanish–American War. The ship had been outfitted with a wireless telegraph transmitter by a local newspaper, so that they could prepare a celebration on the return of the American sailors.
Local historian Clyde Arbuckle states in "Clyde Arbuckle's History of San Jose" that "California first heard the click of a telegraph key on September 11, 1853. It marked completion of an enterprise begun by a couple of San Francisco Merchants' Exchange members named George Sweeney and Theodore E. Baugh…" He says, "In 1849, the gentleman established a wigwag telegraph station a top a high hill overlooking Portsmouth Squares for signaling arriving ships… The operator at the first station caught these signals by telescope and relayed them to the Merchant's Echange for the waiting business community." Arbuckle points to the historic significance the Merchants Exchange Building (San Francisco) and Telegraph Hill, San Francisco when he goes on to say "The first station gave the name "Telegraph" to the hill on which it was located. Its was known as the Inner Station; the second, as the Outer Station. Both used their primitive mode of communication until Messrs. Sweeney and Baugh connected the Outer Station directly with the Merchants's Exchange by electric telegraph Wire."
According to Arbuckle (p. 380-381) Sweeney and Baugh's line was strictly an intra-city, San Francisco based service; that is until California State Telegraph Company enfranchised on May 3, 1852; whereas, O.E. Allen and C. Burnham led the way to "build a line from San Francisco to Marysville via San Jose, Stockton, and Sacramento." Delays to construction occurred until September 1853; but, "…San Jose became the first station on the line when the wire arrived here on October 15. The line was completed when [James] Gamble's northbound crew met a similar crew working southward from Marysville on October 24."
The Bay Area had long been a major site of United States Navy research and technology. In 1909, Charles Herrold started the first radio station in the United States with regularly scheduled programming in San Jose. Later that year, Stanford University graduate Cyril Elwell purchased the U.S. patents for Poulsen arc radio transmission technology and founded the Federal Telegraph Corporation (FTC) in Palo Alto. Over the next decade, the FTC created the world's first global radio communication system, and signed a contract with the Navy in 1912.
In 1933, Air Base Sunnyvale, California, was commissioned by the United States Government for use as a Naval Air Station (NAS) to house the airship USS Macon in Hangar One. The station was renamed NAS Moffett Field, and between 1933 and 1947, U.S. Navy blimps were based there. A number of technology firms had set up shop in the area around Moffett Field to serve the Navy. When the Navy gave up its airship ambitions and moved most of its west coast operations to San Diego, the National Advisory Committee for Aeronautics (NACA, forerunner of NASA) took over portions of Moffett Field for aeronautics research. Many of the original companies stayed, while new ones moved in. The immediate area was soon filled with aerospace firms, such as Lockheed.
Ham radio.
The Bay area was an early center of ham radio with about 10% of the operators in the United States. William Eitel, Jack McCullough, and Charles Litton, who together pioneered vacuum tube manufacturing in the Bay Area, were hobbyists with training in technology gained locally who participated in development of shortwave radio by the ham radio hobby. High frequency, and especially, Very high frequency, VHF, transmission in the 10 meter band, required higher quality power tubes than were manufactured by the consortium of RCA, Western Electric, General Electric, Westinghouse which controlled vacuum tube manufacture. Litton, founder of Litton Industries, pioneered manufacturing techniques which resulted in award of wartime contracts to manufacture transmitting tubes for radar to Eitel-McCullough, a San Bruno firm, which manufactured power-grid tubes for radio amateurs and aircraft radio equipment.
U.S. response to Sputnik.
On October 4, 1957 the Soviet Union launched the first space satellite, Sputnik, which sparked fear that the Soviet Union was pulling ahead technologically. After President Eisenhower signed the National Aeronautics and Space Act (NASA), he turned to Fairchild Semiconductor, then the only company in the world that was able to make transistors. The president funded Fairchild's project, which was highly successful.
Welfare capitalism.
A union organizing drive in 1939-40 at Eitel-McCullough by the strong Bay Area labor movement was fought off by adoption of a strategy of welfare capitalism which included pensions and other generous benefits, profit sharing, and such extras as a medical clinic and a cafeteria. An atmosphere of cooperation and collaboration was established, Successes have been few and far between for union organizing drives by UE and others in subsequent years.
Stanford Industrial Park.
After World War II, universities were experiencing enormous demand due to returning students. To address the financial demands of Stanford's growth requirements, and to provide local employment opportunities for graduating students, Frederick Terman proposed the leasing of Stanford's lands for use as an office park, named the Stanford Industrial Park (later Stanford Research Park). Leases were limited to high technology companies. Its first tenant was Varian Associates, founded by Stanford alumni in the 1930s to build military radar components. However, Terman also found venture capital for civilian technology start-ups. One of the major success stories was Hewlett-Packard. Founded in Packard's garage by Stanford graduates William Hewlett and David Packard, Hewlett-Packard moved its offices into the Stanford Research Park shortly after 1953. In 1954, Stanford created the Honors Cooperative Program to allow full-time employees of the companies to pursue graduate degrees from the University on a part-time basis. The initial companies signed five-year agreements in which they would pay double the tuition for each student in order to cover the costs. Hewlett-Packard has become the largest personal computer manufacturer in the world, and transformed the home printing market when it released the first thermal drop-on-demand ink jet printer in 1984. Other early tenants included Eastman Kodak, General Electric, and Lockheed.
The silicon transistor.
In 1953, William Shockley left Bell Labs in a disagreement over the handling of the invention of the transistor. After returning to California Institute of Technology for a short while, Shockley moved to Mountain View, California, in 1956, and founded Shockley Semiconductor Laboratory. Unlike many other researchers who used germanium as the semiconductor material, Shockley believed that silicon was the better material for making transistors. Shockley intended to replace the current transistor with a new three-element design (today known as the Shockley diode), but the design was considerably more difficult to build than the "simple" transistor. In 1957, Shockley decided to end research on the silicon transistor. As a result of Shockley's abusive management style, eight engineers left the company to form Fairchild Semiconductor; Shockley referred to them as the "traitorous eight". Two of the original employees of Fairchild Semiconductor, Robert Noyce and Gordon Moore, would go on to found Intel.
Computer networking.
April 23, 1963 J.C.R. Licklider, the first director of the Information Processing Techniques Office (IPTO) at the The Pentagon's ARPA issued an office memorandum rescheduling a meeting in Palo Alto addressed to "Members and Affiliates of the Intergalactic Computer Network". regarding his vision of a computer network which he “imagined as an electronic commons open to all, ‘the main and essential medium of informational interaction for governments, institutions, corporations, and individuals.’” As head of IPTO from 1962 to 1964, “Licklider initiated three of the most important developments in information technology: the creation of computer science departments at several major universities, time-sharing, and networking.” By the late 1960s, his promotion of the concept had inspired a primitive version of his vision called ARPANET, which expanded into a network of networks in the 1970s that became the Internet.
Immigration reform.
The Immigration and Nationality Act of 1965 and other factors such as the mass exodus by Vietnamese boat people resulted in significant immigration, particularly by Asians, Latinas, and Portuguese, to Silicon Valley where they contributed to both the high-tech and production workforce. The Asian-American population in Santa Clara County rose from 43,000 in 1970 to 430,000 in 2000. During the same period the Latino population grew to 24% in the county and 30% in San Jose. The African-American population in the county remained steady but grew slightly to about 5%. Expansion of the H-1B visa in 1990 also played a role.
Chips.
In April 1974 Intel released the Intel 8080, a "computer on a chip," "the first truly usable microprocessor." A microprocessor incorporates the functions of a computer's central processing unit (CPU) on a single integrated circuit (IC),
Law firms.
The rise of Silicon Valley was also bolstered by the development of appropriate legal infrastructure to support the rapid formation, funding, and expansion of high-tech companies, as well as the development of a critical mass of litigators and judges experienced in resolving disputes between such firms. From the early 1980s onward, many national (and later international) law firms opened offices in San Francisco and Palo Alto in order to provide Silicon Valley startups with legal services. Furthermore, California law has a number of quirks which help entrepreneurs establish startups at the expense of established firms, such as a nearly absolute ban on non-compete clauses in employment agreements.
Homebrew Computer Club.
The Homebrew Computer Club was an informal group of electronic enthusiasts and technically minded hobbyists who gathered to trade parts, circuits, and information pertaining to DIY construction of computing devices. It was started by Gordon French and Fred Moore who met at the Community Computer Center in Menlo Park. They both were interested in maintaining a regular, open forum for people to get together to work on making computers more accessible to everyone.
The first meeting was held as of March 1975 at French's garage in Menlo Park, San Mateo County, California; which was on occasion of the arrival of the MITS Altair microcomputer, the first unit sent to the area for review by People's Computer Company. Steve Wozniak and Steve Jobs credit that first meeting with inspiring them to design the original Apple I and (successor) Apple II computers. As a result, the first preview of the Apple I was given at the Homebrew Computer Club. Subsequent meetings were held at an auditorium at the Stanford Linear Accelerator Center.
Venture capital firms.
By the early 1970s, there were many semiconductor companies in the area, computer firms using their devices, and programming and service companies serving both. Industrial space was plentiful and housing was still inexpensive. The growth was fueled by the emergence of the venture capital industry on Sand Hill Road, beginning with Kleiner Perkins in 1972; the availability of venture capital exploded after the successful $1.3 billion IPO of Apple Computer in December 1980.
Media.
In 1980 "Intelligent Machines Journal", a hobbyist journal, changed its name to "InfoWorld," and, with offices in Palo Alto, began covering the explosive emergence of the microcomputer industry in the valley.
Software.
Although semiconductors are still a major component of the area's economy, Silicon Valley has been most famous in recent years for innovations in software and Internet services. Silicon Valley has significantly influenced computer operating systems, software, and user interfaces.
Using money from NASA, the US Air Force, and ARPA, Doug Engelbart invented the mouse and hypertext-based collaboration tools in the mid-1960s and 1970s while at Stanford Research Institute (now SRI International), first publicly demonstrated in 1968 in what is now known as The Mother of All Demos. Engelbart's Augmentation Research Center at SRI was also involved in launching the ARPANET (precursor to the Internet) and starting the Network Information Center (now InterNIC). Xerox hired some of Engelbart's best researchers beginning in the early 1970s. In turn, in the 1970s and 1980s, Xerox's Palo Alto Research Center (PARC) played a pivotal role in object-oriented programming, graphical user interfaces (GUIs), Ethernet, PostScript, and laser printers.
While Xerox marketed equipment using its technologies, for the most part its technologies flourished elsewhere. The diaspora of Xerox inventions led directly to 3Com and Adobe Systems, and indirectly to Cisco, Apple Computer, and Microsoft. Apple's Macintosh GUI was largely a result of Steve Jobs' visit to PARC and the subsequent hiring of key personnel. Cisco's impetus stemmed from the need to route a variety of protocols over Stanford's campus Ethernet.
1995, the internet.
In 1995 the internet was opened to commercial use and the initial wave of internet startups, Amazon.com, eBay, and the predecessor to Craigs list began operations.
Internet bubble.
Silicon Valley is generally considered to have been the center of the dot-com bubble, which started in the mid-1990s and collapsed after the NASDAQ stock market began to decline dramatically in April 2000. During the bubble era, real estate prices reached unprecedented levels. For a brief time, Sand Hill Road was home to the most expensive commercial real estate in the world, and the booming economy resulted in severe traffic congestion.
After the dot-com crash, Silicon Valley continues to maintain its status as one of the top research and development centers in the world. A 2006 "The Wall Street Journal" story found that 12 of the 20 most inventive towns in America were in California, and 10 of those were in Silicon Valley. San Jose led the list with 3,867 utility patents filed in 2005, and number two was Sunnyvale, at 1,881 utility patents.
Economy.
According to a 2008 study by AeA in 2006, Silicon Valley was the third largest high-tech center (cybercity) in the United States, behind the New York metropolitan area and Washington metropolitan area, with 225,300 high-tech jobs. The Bay Area as a whole however, of which Silicon Valley is a part, would rank first with 387,000 high-tech jobs. Silicon Valley has the highest concentration of high-tech workers of any metropolitan area, with 285.9 out of every 1,000 private-sector workers. Silicon Valley has the highest average high-tech salary at $144,800. Largely a result of the high technology sector, the San Jose-Sunnyvale-Santa Clara, CA Metropolitan Statistical Area has the most millionaires and the most billionaires in the United States per capita.
The region is the biggest high-tech manufacturing center in the United States. The unemployment rate of the region was 9.4% in January 2009, up from 7.8% in the previous month. Silicon Valley received 41% of all U.S. venture investment in 2011, and 46% in 2012.
Manufacture of transistors is, or was, the core industry in Silicon Valley. The production workforce was for the most part composed of Asian and Latina female immigrants who were paid low wages and worked in hazardous conditions due to the chemicals used in the manufacture of integrated circuits. Technical, engineering, design, and administrative staffs were in large part male and well compensated.
Many more jobs are created in Silicon Valley then there are houses built. Housing prices are extremely high, far out of the range of production workers.
Notable companies.
Thousands of high technology companies are headquartered in Silicon Valley. Among those, the following are in the Fortune 1000:
Additional notable companies headquartered (or with a significant presence) in Silicon Valley include (some defunct or subsumed):
Silicon Valley is also home to the high-tech superstore retail chain Fry's Electronics.
Demographics.
Depending on what geographic regions are included in the meaning of the term, the population of Silicon Valley is between 3.5 and 4 million. A 1999 study by AnnaLee Saxenian for the Public Policy Institute of California reported that a third of Silicon Valley scientists and engineers were immigrants and that nearly a quarter of Silicon Valley's high-technology firms since 1980 were run by Chinese (17 percent) or Indian CEOs (7 percent).
Gender and race.
In November 2006, the University of California at Davis released a report analyzing business leadership by women within the state. The report showed that although 103 of the 400 largest public companies headquartered in California were located in Santa Clara County (the most of all counties), only 8.8% of Silicon Valley companies had women CEOs.:4,7 This was the lowest percentage in the state. (San Francisco County had 19.2% and Marin County had 18.5%.)
Silicon Valley tech leadership positions are occupied almost exclusively by men. This is also represented in the number of new companies founded by women as well as the number of women-lead startups that receive venture capital funding. Wadhwa said he believes that a contributing factor is a lack of parental encouragement to study science and engineering. He also cited a lack of women role models and noted that most famous tech leaders — like Bill Gates, Steve Jobs, and Mark Zuckerberg — are men.
In 2014, tech companies Google, Yahoo!, Facebook, Apple, and others, released corporate transparency reports that offered detailed employee breakdowns. In May, Google said 17% of its tech employees worldwide were women, and, in the U.S., only 1% of its tech workers were black and 2% were Hispanic. June 2014 brought reports from Yahoo! and Facebook. Yahoo! said that 15% of its tech jobs were held by women, and that only 2% of its tech employees were black and 4% Hispanic. Facebook reported that 15% of its tech workforce was female, and that only 3% was Hispanic and 1% was black. In August, Apple reported that 80% of its global tech staff was male and that, in the U.S., 54% of its tech jobs were staffed by white people and 23% by Asians. Soon after, "USA Today" published an article about Silicon Valley's lack of tech-industry diversity, pointing out that it is largely white or Asian, and male. "Blacks and Hispanics are largely absent," it reported, "and women are underrepresented in Silicon Valley — from giant companies to start-ups to venture capital firms." Civil rights activist Jesse Jackson said of improving diversity in the tech industry, "This is the next step in the civil rights movement."
As of October 2014, some high-profile Silicon Valley firms were working actively to prepare and recruit women. "Bloomberg" reported that Apple, Facebook, Google, and Microsoft attended the 20th annual Grace Hopper Celebration of Women in Computing conference to actively recruit and potentially hire female engineers and technology experts. The same month, the second annual Platform Summit was held to discuss increasing racial and gender diversity in tech. As of April 2015 experienced women were engaged in creation of venture capital firms which leveraged women's perspectives in funding of startups.
Sexism.
After UC Davis published its "Study of California Women Business Leaders" in November 2006, some "San Jose Mercury News" readers dismissed the possibility that sexism contributed in making Silicon Valley's leadership gender gap the highest in the state. A January 2015 issue of "Newsweek" magazine featured an article detailing reports of sexism and misogyny in Silicon Valley. The article's author, Nina Burleigh, asked, "Where were all these offended people when women like Heidi Roizen published accounts of having a venture capitalist stick her hand in his pants under a table while a deal was being discussed?"
A 2012 lawsuit, Pao v. Kleiner Perkins, was filed in San Francisco County Superior Court by executive Ellen Pao for gender discrimination against her employer, Kleiner Perkins Caufield & Byers. The case went to trial in February 2015. On March 27, 2015 the jury found in favor of Kleiner Perkins on all counts. Nevertheless, the case, which had wide press coverage, resulted in major advances in consciousness of gender discrimination on the part of venture capital and technology firms and their women employees. Two other cases have been filed against Silicon Valley firms Facebook and Twitter.
Municipalities.
The following Santa Clara County cities are actually located in the Santa Clara Valley and based on that status are traditionally considered to be in Silicon Valley (in alphabetical order):
In 2015, MIT researchers developed a novel method for measuring which towns are home to startups with higher growth potential. This defines Silicon Valley to center on the municipalities of Menlo Park, Mountain View, Palo Alto, and Sunnyvale.
The following Bay Area cities are (or were) home to various high-tech companies (or related firms like venture capital firms) and have thereby become associated with Silicon Valley:
Media outlets.
Local and national media cover Silicon Valley and its companies. CNN, "The Wall Street Journal", and Bloomberg News operate Silicon Valley bureaus out of Palo Alto. Public broadcaster KQED (TV) and KQED-FM, as well as the Bay Area's local ABC station KGO-TV, operate bureaus in San Jose. KNTV, NBC's local Bay Area affiliate "NBC Bay Area", is located in San Jose. Produced from this location is the nationally distributed TV Show "Tech Now" as well as the CNBC Silicon Valley bureau. San Jose-based media serving Silicon Valley include the "San Jose Mercury News" daily and the "Metro Silicon Valley" weekly. Specialty media include "El Observador" and the "San Jose / Silicon Valley Business Journal". Most of the Bay Area's other major TV stations, newspapers, and media operate in San Francisco or Oakland. Patch.com operates , and others, providing local news, discussion and events for residents of Silicon Valley.
See also.
Silicon Mountain
See also: the categories , , and .
Further reading.
</dl>

</doc>
<doc id="26977" url="http://en.wikipedia.org/wiki?curid=26977" title="Stanford University">
Stanford University

Stanford University (officially Leland Stanford Junior University) is a private research university in Stanford, California, and one of the world's most prestigious institutions, with the highest undergraduate selectivity and the top position in numerous surveys and measures in the United States.
Stanford was founded in 1885 by Leland Stanford, former governor of and U.S. senator from California and leading railroad tycoon, and his wife, Jane Lathrop Stanford, in memory of their only child, Leland Stanford, Jr., who had died of typhoid fever at age 15 the previous year. Stanford was opened on October 1, 1891 as a coeducational and non-denominational institution. Tuition was free until 1920. The university struggled financially after Leland Stanford's 1893 death and after much of the campus was damaged by the 1906 San Francisco earthquake. Following World War II, Provost Frederick Terman supported faculty and graduates' entrepreneurialism to build self-sufficient local industry in what would later be known as Silicon Valley. By 1970, Stanford was home to a linear accelerator, and was one of the original four ARPANET nodes (precursor to the Internet).
Stanford is located in northern Silicon Valley near Palo Alto, California. The University's academic departments are organized into seven schools, with several other holdings, such as laboratories and nature reserves, located outside the main campus. Its 8180 acre campus is one of the largest in the United States. The University is also one of the top fundraising institutions in the country, becoming the first school to raise more than a billion dollars in a year. The university's nominal cost is high, but there are financial aid packages based on family income; for undergraduates admitted in 2015, families with an annual income below $125,000 pay no tuition, and families with an annual income below $65,000 pay nothing for tuition, room, or board.
Students compete in 36 varsity sports, and the University is one of two private institutions in the Division I FBS Pacific-12 Conference. It has gained 106 NCAA team championships, the second-most for a university, 465 individual championships, the most in Division I, and has won the NACDA Directors' Cup, recognizing the university with the best overall athletic team achievement, every year since 1994-1995.
Stanford faculty and alumni have founded many companies including Google, Hewlett-Packard, Nike, Sun Microsystems, and Yahoo!, and companies founded by Stanford alumni generate more than $2.7 trillion in annual revenue, equivalent to the 10th-largest economy in the world. Fifty-nine Nobel laureates have been affiliated with the University, and it is the alma mater of 30 living billionaires and 17 astronauts. Stanford has produced a total of 18 Turing Award laureates. It is also one of the leading producers of members of the United States Congress.
History.
Origins and early years (1885–1906).
The university officially opened on October 1, 1891 to 555 students. On the university's opening day, Founding President David Starr Jordan (1851–1931) said to Stanford's Pioneer Class: "[Stanford] is hallowed by no traditions; it is hampered by none. Its finger posts all point forward." However, much preceded the opening and continued for several years until the death of the last Founder, Jane Stanford, in 1905 and the destruction of the 1906 earthquake.
Foundation.
Stanford was founded by Leland Stanford, a railroad magnate, U.S. senator, and former California governor, together with his wife, Jane Lathrop Stanford. It is named in honor of their only child, Leland Stanford, Jr., who died in 1884 from typhoid fever just before his 16th birthday. His parents decided to dedicate a university to their only son, and Leland Stanford told his wife, "The children of California shall be our children." The Stanfords visited Harvard's president, Charles Eliot, and asked whether he should establish a university, technical school or museum. Eliot replied that he should found a university and an endowment of $5 million would suffice (in 1884 dollars; about $ today).
The university's Founding Grant of Endowment from the Stanfords was issued in November 1885. Besides defining the operational structure of the university, it made several specific stipulations:
"The Trustees ... shall have the power and it shall be their duty:
Though the trustees are in overall charge of the university, Leland and Jane Stanford as Founders retained great control until their deaths.
Despite the duty to have a co-educational institution in 1899 Jane Stanford, the remaining Founder, added to the Founding Grant the legal requirement that "the number of women attending the University as students shall at no time ever exceed five hundred". She feared the large numbers of women entering would lead the school to become "the Vassar of the West" and felt that would not be an appropriate memorial for her son. In 1933 the requirement was reinterpreted by the trustees to specify an undergraduate male:female ratio of 3:1. The "Stanford ratio" of 3:1 remained in place until the early 1960s. By the late 1960s the "ratio" was about 2:1 for undergraduates, but much more skewed at the graduate level, except in the humanities. In 1973 the University trustees successfully petitioned the courts to have the restriction formally removed. As of 2014 the undergraduate enrollment is split nearly evenly between the sexes (47.2% women, 52.8% men), though males outnumber females (38.2% women, 61.8% men) at the graduate level. In the same petition they also removed the prohibition of sectarian worship on campus (previous only non-denominational Christian worship in Stanford Memorial Church was permitted).
Physical layout.
The Stanfords chose their country estate, Palo Alto Stock Farm, in northern Santa Clara County as the site of the university, so that the University is often called "the Farm" to this day.
The campus master plan (1886-1914) was designed by Frederick Law Olmsted and later his sons. The Main Quad was designed by Charles Allerton Coolidge and his colleagues, and by Leland Stanford himself. The cornerstone was laid on May 14, 1887, which would have been Leland Stanford Junior's nineteenth birthday.
In the summer of 1886, when the campus was first being planned, Stanford brought the president of Massachusetts Institute of Technology, Francis Amasa Walker, and prominent Boston architect Frederick Law Olmsted westward for consultations. Olmsted worked out the general concept for the campus and its buildings, rejecting a hillside site in favor of the more practical flatlands. 
The Boston firm of Shepley, Rutan, and Coolidge were hired in the Autumn and Charles Allerton Coolidge then developed this concept in the style of his late mentor, Henry Hobson Richardson. The Richardsonian Romanesque style, characterized by rectangular stone buildings linked by arcades of half-circle arches, was merged with the Californian Mission Revival style desired by the Stanfords. However by 1889, Leland Stanford severed the connection with Olmsted and Coolidge and their work was continued by others.
The red tile roofs and solid sandstone masonry are distinctly Californian in appearance and famously complementary to the bright blue skies common to the region, and most of the more recent campus buildings have followed the Quad's pattern of buff colored walls, red roofs, and arcades, giving Stanford its distinctive "look".
Early faculty and administration.
In Spring 1891, the Stanfords offered the presidency of their new university to the president of Cornell University, Andrew White, but he declined and recommended David Starr Jordan, the 40-year-old president of Indiana University Bloomington. Jordan's educational philosophy was a good fit with the Stanfords' vision of a non-sectarian, co-educational school with a liberal arts curriculum, and he accepted the offer. Jordan arrived at Stanford in June 1891 and immediately set about recruiting faculty for the university's planned October opening. With such a short time frame he drew heavily on his own acquaintance in academia; of the fifteen original professors, most came either from Indiana University or his alma mater Cornell. The 1891 founding professors included Robert Allardice in mathematics, Douglas Houghton Campbell in botany, Charles Henry Gilbert in zoology, George Elliott Howard in history, Oliver Peebles Jenkins in physiology and histology, Charles David Marx in civil engineering, Fernando Sanford in physics, and John Maxson Stillman in chemistry. The total initial teaching staff numbered about 35 including instructors and lecturers. For the second (1892–93) school year, Jordan was able to add 29 additional professors including Frank Angell (psychology), Leander M. Hoskins (mechanical engineering), William Henry Hudson (English), Walter Miller (classics), George C. Price (zoology), and Arly B. Show (history). Most of these two founding groups of professors remained at Stanford until their retirement and were referred to as the "Old Guard".
Edward Alsworth Ross gained fame as a founding father of American sociology; in 1900 Jane Stanford fired him for radicalism and racism, unleashing a major academic freedom case.
Early finances.
When Leland Stanford died in 1893, the continued existence of the university was in jeopardy. A $15 million government lawsuit against Stanford's estate, combined with the Panic of 1893, made it extremely difficult to meet expenses. Most of the Board of Trustees advised that the University be closed temporarily until finances could be sorted out. However, Jane Stanford insisted that the university remain in operation. When the lawsuit was finally dropped in 1895, a university holiday was declared. Stanford alumnus George E. Crothers became a close adviser to Jane Stanford following his graduation from Stanford's law school in 1896. Working with his brother Thomas (also a Stanford graduate and a lawyer), Crothers identified and corrected numerous major legal defects in the terms of the university's founding grant and successfully lobbied for an amendment to the California state constitution granting Stanford an exemption from taxation on its educational property—a change which allowed Jane Stanford to donate her stock holdings to the university.
Jane Stanford's actions were sometimes eccentric. In 1897, she directed the board of trustees "that the students be taught that everyone born on earth has a soul germ, and that on its development depends much in life here and everything in Life Eternal". She forbade students from sketching nude models in life-drawing class, banned automobiles from campus, and did not allow a hospital to be constructed so that people would not form an impression that Stanford was unhealthy. Between 1899 and 1905, she spent $3 million on a grand construction scheme building lavish memorials to the Stanford family, while university faculty and self-supporting students were living in poverty.
However, overall, Jane Stanford contributed significantly to the university. Faced with the possibility of financial ruin for the institution, she took charge of financial, administrative, and development matters at the university 1893–1905. For the next several years, she paid salaries out of her personal resources, even pawning her jewelry to keep the university going. In 1901, she transferred $30 million in assets, nearly all her remaining wealth, to the university; upon her death in 1905, she left the university nearly $4 million of her remaining $7 million. In total, the Stanfords donated around $40 million in assets to the university, over $1 billion in 2010 dollars.
Post-founders (1906–1941).
The year after Jane Stanford's death, the 1906 San Francisco earthquake damaged parts of the campus and caused new financial and structural problems, though only two people on campus were killed. Some of the early construction, especially from the second phase between Leland Stanford's death in 1893 and Jane Stanford's death in 1905, was destroyed by the earthquake. The university retains the Quad, part of the Museum, the old Chemistry Building (which is not in use, has been boarded up since 1986, and was subsequently damaged in the 1989 Loma Prieta earthquake), and Encina Hall (then the men's undergraduate dormitory). The earthquake destroyed parts of the Main Quad, including the original iteration of Memorial Church and the gate that first marked the entrance of the school, as well as a partially built main library. Rebuilding on a somewhat less grandiose scale began immediately.
In 1908 the university acquired the already existing Cooper Medical College in San Francisco and it became the Stanford University Department (later School) of Medicine though it remained in San Francisco until the late 1950s. For the full story see History of Stanford Medicine.
Jordan, the first president, stepped down in 1913 and was succeeded for two years by John Casper Branner. Branner was followed by Ray Lyman Wilbur, who was president from 1916 until 1943, except when he took leave to serve as Secretary of the Interior under President Herbert Hoover. Hoover along with his wife, Lou Henry Hoover, were among the first graduates of Stanford. Herbert Hoover was also a trustee of the university. The house they had built on campus as their own residence, Lou Henry Hoover House, became the University president's house after the death of Lou Henry Hoover in 1944.
World War II and late 20th century.
After Ray Lyman Wilbur retired in 1943 in the midst of World War II, Donald Tresidder, president of the Board of Trustees, took over as president until his unexpected death in early 1948. In 1949 Wallace Sterling became president (1949-1968) and he oversaw the rise of Stanford as a regional university to one of the most prestigious universities in the United States. He was succeeded by Kenneth Pitzer from Rice University who lasted only 19 months having stepped in just as the university entered its most tumultuous period of student protests. Richard Lyman, former provost, was president from 1971 until 1980; Donald Kennedy also a former provost was president from 1980 until 1992 when he resigned during the midst of a controversy over finances with the U.S. Government. The Board of Trustees brought in an outsider, Gerhard Casper, from the University of Chicago who was president until 2000.
High tech.
A powerful sense of regional solidarity accompanied the rise of Silicon Valley. From the 1890s, the university's leaders saw its mission as service to the West and shaped the school accordingly. At the same time, the perceived exploitation of the West at the hands of eastern interests fueled booster-like attempts to build self-sufficient indigenous local industry. Thus, regionalism helped align Stanford's interests with those of the area's high-tech firms for the first fifty years of Silicon Valley's development. The distinctive regional ethos of the West during the first half of the 20th century is an ingredient of Silicon Valley's already prepared environment, an ingredient that would-be replicators ignore at their peril.
During the 1940s and 1950s, Frederick Terman, as dean of engineering and later as provost, encouraged faculty and graduates to start their own companies. He is credited with nurturing Hewlett-Packard, Varian Associates, and other high-tech firms, until what would become Silicon Valley grew up around the Stanford campus. Terman is often called "the father of Silicon Valley." Terman encouraged William B. Shockley, co-inventor of the transistor, to return to his hometown of Palo Alto. In 1956 he established the Shockley Transistor Laboratory.
 The spark that set off the explosive boom of "Silicon startups" in Stanford Industrial Park was a personal dispute in 1957 between employees of Shockley Semiconductor and the company's namesake and founder, Nobel laureate and co-inventor of the transistor William Shockley... (His employees) formed Fairchild Semiconductor immediately following their departure...
After several years, Fairchild gained its footing, becoming a formidable presence in this sector. Its founders began to leave to start companies based on their own, latest ideas and were followed on this path by their own former leading employees... The process gained momentum and what had once began in a Stanford's research park became a veritable startup avalanche... Thus, over the course of just 20 years, a mere eight of Shockley's former employees gave forth 65 new enterprises, which then went on to do the same...
Biology.
The biological sciences department evolved rapidly from 1946 to 1972 as its research focus changed, due to the Cold War and other historically significant conditions external to academia. Stanford science went through three phases of experimental direction during that time. In the early 1950s the department remained fixed in the classical independent and self-directed research mode, shunning interdisciplinary collaboration and excessive government funding. Between the 1950s and mid-1960s biological research shifted focus to the molecular level. Then, from the late 1960s onward, Stanford's goal became applying research and findings toward humanistic ends. Each phase was preempted by larger social issues, such as the escalation of the Cold War, the launch of Sputnik, and public concern over medical abuses.
Physics.
In 1962 through 1970, negotiations took place between the Cambridge Electron Accelerator Laboratory (shared by Harvard and the Massachusetts Institute of Technology), the Stanford Linear Accelerator Center, and the US Atomic Energy Commission over the proposed 1970 construction of the Stanford Positron Electron Asymmetric Ring (SPEAR). It would be the first US electron-positron colliding beam storage ring. Paris (2001) explores the competition and cooperation between the two university laboratories and presents diagrams of the proposed facilities, charts detailing location factors, and the parameters of different project proposals between 1967 and 1970. Several rings were built in Europe during the five years that it took to obtain funding for the project, but the extensive project revisions resulted in a superior design that was quickly constructed and paved the way for Nobel Prizes in 1976 for Burton Richter and in 1995 for Martin Perl.
During 1955–85, solid state technology research and development at Stanford University followed three waves of industrial innovation made possible by support from private corporations, mainly Bell Telephone Laboratories, Shockley Semiconductor, Fairchild Semiconductor, and Xerox PARC. In 1969 the Stanford Research Institute operated one of the four original nodes that comprised ARPANET, predecessor to the Internet.
Civil rights.
Though Stanford has never officially prohibited the admission of black students, people of Asian descent, or Native Americans, it did not treat them equally with those considered as White. Discrimination also existed against non-Christians. (The first Black graduate was Ernest Houston Johnson in 1895 who received a degree in economics.)
In 1957 the Board of Trustees adopted a policy stating:
"The University is opposed to discriminatory racial and religious clauses and practices. Insofar as such clauses or practices presently exist, the University will work actively with student groups to eliminate them at the earliest possible date"
Though this was relatively easy for the housing the university directly controlled, it had to work with the fraternities which invite their own membership (no sororities existed on campus at this time). In 1960, the Alpha Tau Omega chapter had its national charter revoked after refusing to retract the pledging of four Jewish students.
And in 1962 Sigma Nu (Beta Chi chapter) seceded from the national organization over the national organization's continuing refusal to drop bans on "Negros and Orientals".
As of late 1962 only the Kappa Alpha fraternity still officially discriminated due the national organization's rules. However in April 1965 the local Sigma Chi chapter pledged Kenneth M. Washington and was suspended allegedly for violating rules on rituals.
Though Sigma Chi officially had removed its no whites policy in 1961 it had then instituted requirements that all members had to be approved by a national committee and that pledges be socially acceptable to other members anywhere. President Sterling then sent a letter to the presidents of all universities with Sigma Chi chapters supporting the local chapter and pointing out that University recognition of racially discriminatory groups could violate the Civil Rights Act of 1964. The suspension continued until Kenneth Washington's poor grades required him to resign anyway from the chapter. In November 1966 the Stanford chapter unanimously severed ties with the national fraternity.
The university started actively recruiting minorities in the 1960s. The minorities started organizing and "in five years, students founded the six major community organizations: the Black Student Union (BSU) in 1967, the Asian American Students’ Association (AASA) and the Movimiento Estudiantil Chicano de Aztlan (MEChA) in 1969, the Stanford American Indian Organization (SAIO) in 1970, the Gay People’s Union in 1971 and the Women’s Collective in 1972."
Government expenses controversy.
In the early 1990s, Stanford was investigated by the U.S. government over allegations that the university had inappropriately billed the government several million dollars for housing, personal expenses, travel, entertainment, fundraising and other activities unrelated to research, including a yacht and an elaborate wedding ceremony. The scandal eventually led to the resignation of Stanford President Donald Kennedy in 1992. In an agreement with the Office of Naval Research, Stanford refunded $1.35 million to the government for billing which occurred in the years 1981 and 1992. Additionally, the government reduced Stanford's annual research budget by $23 million in the year following the settlement.
21st century.
Since 2000, Stanford has expanded dramatically. In February 2012, Stanford announced the conclusion of the Stanford Challenge. In a period of five years, Stanford raised $6.2 billion, exceeding its initial goal by $2 billion, making it the most successful university fundraising campaign in history. The funds will go towards 103 new endowed faculty appointments, 360 graduate student research fellowships, scholarships and financial aid, and the construction or renovation of 38 campus buildings. It enabled the construction of the world's largest facility dedicated exclusively to stem cell research, an entirely new campus for the business school, added dramatically to the law school, a brand-new engineering quad, created a new art and art history building, an on-campus concert hall, a new art museum, and a planned expansion of the medical school, among others. In 2012, Stanford opened the Stanford Center at Peking University, a just-under 400000 sqft, three-story research center in the Peking University campus. The ceremony featured remarks by U.S. Ambassador to China Gary Locke and Stanford President John Hennessy. Stanford became the first American university to have its own building on a major Chinese university campus.
Other Stanford programs underwent notable expansion as well, such as the Stanford in Washington Program's creation of the Stanford in Washington Art Gallery in Woodley Park, Washington, D.C., and the Stanford in Florence program's move to Palazzo Capponi, a 15th-century Renaissance palace. The university completed the James H. Clark Center for interdisciplinary research in engineering and medicine in 2003, named for benefactor, co-founder of Netscape, Silicon Graphics and WebMD, and former professor of electrical engineering James H. Clark.
In 2011, Stanford created the first PhD program in stem cell science in the United States. The program is housed at Stanford Medical School.
Undergraduate admission selectivity also increased, with the acceptance rate dropping from 13% for the class of 2004 to 5.07% for the class of 2018. Stanford's reputation, competitive admissions, and strong legacy of entrepreneurship have contributed to the East-West rivalry between Stanford and such institutions as Harvard University, Princeton University and Yale University.
Campus.
Main campus.
Stanford University is located on an 8180 acre campus on the San Francisco Peninsula, in the northwest part of the Santa Clara Valley (Silicon Valley) approximately 37 mi southeast of San Francisco and approximately 20 mi northwest of San Jose. In 2008, 60% of this land remained undeveloped. The main campus is adjacent to Palo Alto, bounded by El Camino Real, Stanford Avenue, Junipero Serra Boulevard, and Sand Hill Road. The university also operates at several more remote locations (see below).
Stanford's main campus is a census-designated place within unincorporated Santa Clara County, although some of the university land (including the Stanford Shopping Center and the Stanford Research Park) is within the city limits of Palo Alto. The campus also includes much land in unincorporated San Mateo County (including the SLAC National Accelerator Laboratory and the Jasper Ridge Biological Preserve), as well as in the city limits of Menlo Park (Stanford Hills neighborhood), Woodside, and Portola Valley. The United States Postal Service has assigned Stanford two ZIP codes: 94305 for campus mail and 94309 for P.O. box mail. It lies within area code 650.
The university campus was listed by "Travel + Leisure" in September 2011 as one of the most beautiful campuses in the United States and by MSN as one of the most beautiful college campuses in the world.
Other campuses.
Stanford currently operates or intends to operate in various locations outside of its main campus.
On the founding grant but away from the main campus:
Off the founding grant:
Locations in development:
"Lake Lagunita in early spring; the Dish, a large radio telescope and local landmark, is visible in the Stanford owned foothills behind the lake and is the high point of a popular campus jogging and walking trail."
Faculty residences.
One of the benefits of being a Stanford faculty member is the "Faculty Ghetto", where faculty members can live within walking or biking distance of campus. The Faculty Ghetto is composed of land owned entirely by Stanford. Similar to a condominium, the houses can be bought and sold but the land under the houses is rented on a 99-year lease. Houses in the "Ghetto" appreciate and depreciate, but not as rapidly as overall Silicon Valley values. However, it remains an expensive area in which to own property, and the average price of single-family homes on campus is actually higher than in Palo Alto. Stanford itself enjoys the rapid capital gains of Silicon Valley landowners, although by the terms of its founding the university cannot sell the land.
Landmarks.
Contemporary campus landmarks include the Main Quad and Memorial Church, the Cantor Center for Visual Arts and art gallery, the Stanford Mausoleum and the Angel of Grief, Hoover Tower, the Rodin sculpture garden, the Papua New Guinea Sculpture Garden, the Arizona Cactus Garden, the Stanford University Arboretum, Green Library and the Dish. Frank Lloyd Wright's 1937 Hanna–Honeycomb House and the 1919 Lou Henry Hoover House are both listed on the National Historic Register. Previous landmarks included Meyer Library, which has since been demolished. As of March 2015, the old library grounds are intended to be converted to an open green space park. As of 2014, Stanford opened a new meditation center, Windhover Contemplation Center, open to students and faculty.
Administration and organization.
Stanford University is a tax-exempt corporate trust owned and governed by a privately appointed 34-member Board of Trustees. Trustees serve five-year terms (not more than two consecutive terms) and meet five times annually. A new trustee is chosen by the remaining Trustees by ballot. The Stanford trustees also oversee the Stanford Research Park, the Stanford Shopping Center, the Cantor Center for Visual Arts, Stanford University Medical Center, and many associated medical facilities (including the Lucile Packard Children's Hospital).
The Board appoints a President to serve as the chief executive officer of the university and prescribe the duties of professors and course of study, manage financial and business affairs, and appoint nine vice presidents. John L. Hennessy was appointed the 10th President of the University in October 2000. The Provost is the chief academic and budget officer, to whom the deans of each of the seven schools report. John Etchemendy was named the 12th Provost in September 2000.
The University is currently organized into seven academic schools. The schools of Humanities and Sciences (27 departments), Engineering (9 departments), and Earth Sciences (4 departments) have both graduate and undergraduate programs while the Schools of Law, Medicine, Education and Business have graduate programs only. The powers and authority of the faculty are vested in the Academic Council, which is made up of tenure and non-tenure line faculty, research faculty, senior fellows in some policy centers and institutes, the president of the university, and some other academic administrators, but most matters are handled by the Faculty Senate, made up of 55 elected representatives of the faculty.
The Associated Students of Stanford University (ASSU) is the student government for Stanford University and all registered students are members. Its elected leadership consists of the Undergraduate Senate elected by the undergraduate students, the Graduate Student Council elected by the graduate students, and the President and Vice President elected as a ticket by the entire student body.
Stanford is the beneficiary of a special clause in the California Constitution, which explicitly exempts Stanford property from taxation so long as the property is used for educational purposes.
Endowment and fundraising.
The university's endowment, managed by the Stanford Management Company, was valued at $17.2 billion in 2008 and had achieved an annualized rate of return of 15.1% since 1998. The endowment fell 25% in 2009 as a result of the late-2000s recession, but posted gains of 14.4% in 2010 and 22.4% in 2011, when it was valued at $16.5 billion.
Stanford has been the top fundraising university in the United States for several years. It raised $911 million in 2006, $832 million in 2007, $785 million in 2008, $640 million in 2009, $599 million in 2010, $709 million in 2011, and $1.035 billion in 2012, becoming the first school to raise more than a billion dollars in a year. In 2013 and 2014 it raised $932 million and $928 million.
In 2006, President Hennessy launched a five-year campaign called the Stanford Challenge, which reached its $4.3 billion fundraising goal in 2009, two years ahead of time, but continued fundraising for the duration of the campaign. It concluded on December 31, 2011, having raised a total of $6.23 billion and breaking the previous campaign fundraising record of $3.88 billion held by Yale. Specifically, the campaign raised $253.7 million for undergraduate financial aid, as well as $2.33 billion for its initiative in "Seeking Solutions" to global problems, $1.61 billion for "Educating Leaders" by improving K-12 education, and $2.11 billion for "Foundation of Excellence" aimed at providing academic support for Stanford students and faculty. Funds supported 366 new fellowships for graduate students, 139 new endowed chairs for faculty, and 38 new or renovated buildings. Over 10,000 volunteers helped in raising 560,000 gifts from more than 166,000 donors.
Academics.
Teaching and learning.
Stanford University is a large, highly residential research university with a slight majority of enrollments coming from graduate and professional students. It follows a quarter system with Autumn quarter usually starting in late September and Spring Quarter ending in early June. The full-time, four-year undergraduate program has an arts and sciences focus with high graduate student coexistence. Stanford University is accredited by the 
Western Association of Schools and Colleges. Its most recent undergraduate admit rate (for the class of 2018) further dropped to 5.07%, the lowest in the University's history.
Full-time undergraduate tuition was $42,690 for 2013–2014. Stanford's admission process is need-blind for US citizens and permanent residents; while it is not need-blind for international students, 64% are on need-based aid, with an average aid package of $31,411. In 2012/13, the university awarded $126 million in need-based financial aid to 3,485 students, with an average aid package of $40,460. Eighty percent of students receive some form of financial aid. Stanford's no-loan policy waives tuition, room, and board for most families with incomes below $60,000, and most families with incomes below $100,000 are not required to pay tuition (those with incomes up to $150,000 may have tuition significantly reduced). 17% of students receive Pell Grants, a common measure of low-income students at a college.
Research centers and institutes.
The Stanford Office of the Vice Provost and Dean of Research oversees more than eighteen independent laboratories, centers, and institutes.
Other Stanford-affiliated institutions include the SLAC National Accelerator Laboratory (originally the Stanford Linear Accelerator Center), the Stanford Research Institute (a now independent institution which originated at the university), the Hoover Institution on War, Revolution and Peace (a major public policy think tank that attracts visiting scholars from around the world), and the Hasso Plattner Institute of Design (a multidisciplinary design school in cooperation with the Hasso Plattner Institute of University of Potsdam that integrates product design, engineering, and business management education). Unable to locate a copy in any of its libraries, the Soviet Union was obliged to ask the Hoover Institution for a microfilm copy of its original edition of the first issue of "Pravda" (dated March 5, 1917).
Stanford is home to the papers of Martin Luther King, Jr. at the Martin Luther King, Jr. Research and Education Institute. It also runs the John S. Knight Fellowship for Professional Journalists and the Center for Ocean Solutions, which brings together marine science and policy to address challenges facing the ocean.
Libraries and digital resources.
The Stanford University Libraries and Academic Information Resources (SULAIR) hold a collection of more than 9.3 million volumes, nearly 300,000 rare or special books, 1.5 million e-books, 2.5 million audiovisual materials, 77,000 serials, nearly 6 million microform holdings, and thousands of other digital resources, making it one of the largest and most diverse academic library systems in the world.
The main library in the SU library system is Green Library, which also contains various meeting and conference rooms, study spaces, and reading rooms. Meyer Library, a 24-hour library slated for demolition in 2015, holds various student-accessible media resources and houses one of the largest East Asia collections, whose 540,000 volumes are being transported to an interim location while a new library is rebuilt.
Arts.
Stanford University is home to the Cantor Center for Visual Arts museum with 24 galleries, sculpture gardens, terraces, and a courtyard first established in 1891 by Jane and Leland Stanford as a memorial to their only child. Notably, the Center possesses the largest collection of Rodin works outside of Paris, France. The Thomas Welton Stanford Gallery, built in 1917, serves as a teaching resource for the Department of Art & Art History as well as an exhibition venue. There are also a large number of outdoor art installations throughout the campus, primarily sculptures, but some murals as well. The Papua New Guinea Sculpture Garden near Roble Hall features handmade wood carvings and "totem poles."
Stanford has a thriving artistic and musical community. Extracurricular activities include theater groups such as Ram's Head Theatrical Society, and the Stanford Shakespeare Society, award-winning a cappella music groups such as the Mendicants, Counterpoint, the Stanford Fleet Street Singers, Harmonics, Mixed Company, Testimony, Talisman, Everyday People, Raagapella, and a group dedicated to performing the works of Gilbert and Sullivan, the Stanford Savoyards. Beyond these, the music department sponsors many ensembles including five choirs, the Stanford Symphony Orchestra, Stanford Taiko, and the Stanford Wind Ensemble.
Stanford's dance community is one of the most vibrant in the country, with an active dance division in the Drama Department and over 30 different dance-related student groups, including the Stanford Band's Dollie dance troupe. Perhaps most distinctive of all is its social and vintage dance community, cultivated by dance historian Richard Powers and enjoyed by hundreds of students and thousands of alumni. Stanford hosts monthly informal dances (called Jammix) and large quarterly dance events, including Ragtime Ball (fall), the Stanford Viennese Ball (winter), and Big Dance (spring). Stanford also boasts a student-run swing performance troupe called Swingtime and several alumni performance groups, including Decadance and the Academy of Danse Libre.
The creative writing program brings young writers to campus via the Stegner Fellowships and other graduate scholarship programs. "This Boy's Life" author Tobias Wolff teaches writing to undergraduates and graduate students. Knight Journalism Fellows are invited to spend a year at the campus taking seminars and courses of their choice. The Stanford Spoken Word Collective, an extracurricular writing and performance group, also serves as the school's poetry slam team.
Stanford also hosts various publishing courses for professionals. The Stanford Professional Publishing Course, which was offered on campus since the late 1970s, brought together international publishing professionals to discuss changing business models in magazine and book publishing. It ended in 2009, although the tradition has continued at Yale with the Yale Publishing Course that began in 2010. Videos from the Stanford Professional Publishing Courses are still made available on their website.
Reputation and rankings.
Stanford occupies the number one position in numerous domestic college ranking measures, leading "Slate" to dub Stanford "the Harvard of the 21st century," and "The New York Times" to conclude that "Stanford University has become America’s 'it' school, by measures that Harvard once dominated." From polls done by "The Princeton Review" in 2010, 2013 and 2014, Stanford is the most commonly named "dream college" for both students and parents (and in 2011 for students), while a 2003 Gallup poll found that Stanford was tied as the second-most prestigious university in the eyes of the general public.
The Times Higher Education "World Reputation Rankings" placed it third in 2014, while the Academic Ranking of World Universities ("ARWU"), in particular, has ranked Stanford second in the world for many years.
Student life.
Student body.
Stanford enrolled 7,061 undergraduate and 11,075 graduate students as of October 2013, and women comprised 47% of undergraduates and 41% of professional and graduate students. In the same academic year, the freshman retention rate was 99%.
As for comparison, Stanford awarded 1,715 undergraduate degrees, 2,278 Master's degrees, 764 doctoral degrees, and 366 professional degrees in the 2011–2012 school year. The four-year graduation rate in the class of 2011 is 76%, and the six-year rate is 96%. The relatively low four-year graduation rate is a function of the university's coterminal degree (or "coterm") program, which allows students to earn a Master's degree as an extension of their undergraduate program.
As of 2010, fifteen percent of undergraduates are first-generation students.
Dormitories and student housing.
Eighty-nine percent of undergraduate students live in on-campus university housing. First-year students are required to live on campus, and all undergraduates are guaranteed housing for all four undergraduate years. According to the Stanford Housing Assignments Office, undergraduates live in 80 different houses, including dormitories, co-ops, row houses, fraternities and sororities. At Manzanita Park, 118 mobile homes were installed as "temporary" housing from 1969 to 1991, but it is now the site of modern dorms Castano, Kimball, and Lantana. Most student residences are located just outside the campus core, within ten minutes (on foot or bike) of most classrooms and libraries. Some are for freshmen only; others give priority to sophomores, others to both freshmen and sophomores; some are for upperclass students only, and some are open to all four classes. Most residences are co-ed; seven are all-male fraternities, three are all-female sororities, and there is also one all-female non-sorority house, Roth House. In most residences, men and women live on the same floor, but a few dorms are configured for men and women to live on separate floors (single-gender floors), including all Wilbur dorms except for Arroyo and Okada. Beginning in 2009–10, the University's housing plan anticipates that all freshmen desiring to live in all-freshman dorms will be accommodated. In the 2009–10 year, almost two-thirds of freshmen will be housed in Stern and Wilbur Halls. The one-third who requested four-class housing will be located in other dormitories throughout campus, including Florence Moore (FloMo). Stanford hosts incoming freshmen in freshmen dorms with upperclass residence assistants. In April 2008, Stanford unveiled a new pilot plan to test out gender-neutral housing in five campus residences, allowing males and females to live in the same room. This was after concerted student pressure, as well as the institution of similar policies at peer institutions such as Wesleyan, Oberlin, Clark, Dartmouth, Brown, and UPenn.
Several residences are considered theme houses. The Academic, Language and Culture Houses include EAST (Education And Society Theme), Hammarskjöld (International Theme), Haus Mitteleuropa (Central European Theme), La Casa Italiana (Italian Language and Culture), La Maison Française (French Language and Culture House), Slavianskii Dom (Slavic/East European Theme House), Storey (Human Biology Theme House), and Yost (Spanish Language and Culture). Cross-Cultural Theme Houses include Casa Zapata (Chicano/Latino Theme in Stern Hall), Muwekma-tah-ruk (American Indian/Alaska Native, and Native Hawaiian Theme), Okada (Asian-American Theme in Wilbur Hall), and Ujamaa (Black/African-American Theme in Lagunita Court). Focus Houses include Freshman-Sophomore College (Academic Focus), Branner Hall (Community Service), Kimball (Arts & Performing Arts), Crothers (Global Citizenship), and Toyon (Sophomore Priority). Theme houses predating the current "theme" classification system are Columbae (Social Change Through Nonviolence, since 1970), and Synergy (Exploring Alternatives, since 1972).
Another famous style of housing at Stanford is the co-ops. These houses feature cooperative living, where residents and eating associates each contribute work to keep the house running, such as cooking meals or cleaning shared spaces. These shares spaces have unique themes around which their community is centered. Many co-ops are hubs of music, art and philosophy. The co-ops on campus are Chi Theta Chi, Columbae, Enchanted Broccoli Forest (EBF), Hammarskjöld (which is also the International Theme House), Kairos, Terra (the unofficial LGBT house), and Synergy.
At any time, around 50 percent of the graduate population lives on campus. Now that construction has concluded on the new Munger graduate residence, this percentage has probably increased. First-year graduate students are guaranteed housing.
Athletics.
Stanford currently has 36 varsity sports (18 female, 15 male, one coed), 19 club sports and 37 intramural sports—about 800 students participate in intercollegiate sports with an offer of about 300 athletic scholarships. The sports teams are now officially referred to as the "Stanford Cardinal", which is a "mascot" name adopted in 1972 after the abandonment of the previous "Indians" owing to racial insensitivity complained by Native American students, referring to the deep red color, not the cardinal bird. It is a member of the Pacific-12 Conference and the Mountain Pacific Sports Federation with the participation in the inter-collegiate NCAA's Division I FBS.
Its traditional sports rival is Berkeley, the neighbor to the north in the East Bay. The winner of the annual "Big Game" between the Cal and Cardinal football teams gains custody of the Stanford Axe. The first "Big Game", played at Haight Street Park in San Francisco on March 19, 1892, established football on the west coast. Stanford won 14 to 10 in front of 8,000 spectators. Stanford's football team played in the first Rose Bowl in 1902. However, the violence of the sport at the time, coupled with the post-game rioting of drunken spectators, led San Francisco to bar further "Big Games" in the city in 1905. In 1906, David Starr Jordan banned football from Stanford. The 1906–1914 "Big Game" contests featured rugby instead of football. Stanford football was resumed in 1919.
Stanford has had at least one NCAA team champion every year since the 1976–77 school year and has earned 106 NCAA national team titles since its establishment, second most behind the UCLA Bruins, and 467 individual National championships, the most by any university. Stanford has won the award for the top-ranked collegiate athletic program — the NACDA Directors' Cup, formerly known as the Sears Cup - annually for the past twenty years. Stanford athletes have won medals in every Olympic Games since 1912, winning 244 Olympic medals total, 129 of them gold. In the 2008 Summer Olympics, Stanford won more Olympic medals than any other university in the United States. Stanford athletes won 16 medals at the 2012 Summer Games—12 gold, 2 silver and 2 bronze.
Religious life.
Students and staff at Stanford are of many different religions. The Stanford Office for Religious Life's mission is "to guide, nurture and enhance spiritual, religious and ethical life within the Stanford University community" by promoting enriching dialogue, meaningful ritual, and enduring friendships among people of all religious backgrounds. It is headed by a dean with the assistance of a senior associate dean and an associate dean. 
Stanford Memorial Church, located in the center of campus, has a Sunday University Public Worship service (UPW) usually in the "Protestant Ecumenical Christian" tradition where the Memorial Church Choir sings and a sermon is preached usually by one of the Stanford deans for Religious Life. UPW sometimes has multifaith services. In addition the church is used by the Catholic community and by some of the other Christian denominations at Stanford. Weddings happen most Saturdays and the university has for over 20 years allowed blessings of same-gender relationships and now legal weddings.
In addition to the church, the Office for Religious Life has a Center for Inter-Religious Community, Learning and Experiences (CIRCLE) located on the third floor of Old Union. It offers a common room, an interfaith sanctuary, a seminar room, a student lounge area and a reading room, as well as offices housing a number of Stanford Associated Religions (SAR) member groups and the Senior Associate Dean and Associate Dean for Religious Life. Most though not all religious student groups belong to SAR. The SAR directory includes organizations that serve atheist, Baha'i, Buddhist, Christian, Hindu, Islam, Jewish, and Sikh groups, though these groups vary year by year.
The Windhover Contemplation Center is the most recent addition to spiritual and religious life at Stanford. Windhover's purpose is to provide spiritual sanctuary for students and staff in the midst of their demanding course and work schedules. The center displays the "Windhover" paintings by Nathan Olivera, the late Stanford professor and artist. Windhover was dedicated to the campus on October 8, 2014. 
Some religions have a larger and more formal presence on campus in addition to the student groups; these include the Catholic Community at Stanford and Hillel at Stanford.
Greek life.
Fraternities and sororities have been active on the Stanford campus since 1891, when the University first opened. In 1944, University President Donald Tresidder banned all Stanford sororities due to extreme competition. However, following Title IX, the Board of Trustees lifted the 33-year ban on sororities in 1977. Stanford is now home to 29 Greek organizations, including 13 sororities and 16 fraternities, representing 13% of undergraduates. In contrast to many universities, nine of the ten housed Greek organizations live in University-owned houses, the exception being Sigma Chi, which owns its own house (but not the land) on The Row. Six chapters are members of the African American Fraternal and Sororal Association, 11 chapters are members of the Interfraternity Council, 6 chapters belong to the Intersorority Council, and 6 chapters belong to the Multicultural Greek Council.
Student groups.
Stanford offers its students the opportunity to engage in over 650 student organizations. Groups are often, though not always, partially funded by the University via allocations directed by the student government organization, the ASSU. These funds include "special fees", which are decided by a Spring Quarter vote by the student body. Groups span from Athletic/Recreational (see section on Athletics), Careers/Pre-professional, Community Service, Ethnic/Cultural, Fraternities/Sororities, Health/Counseling, Media/Publications, Music/Dance/Creative Arts (see section on Arts), Political/Social Awareness to Religious/Philosophical.
Among publications the "Stanford Daily" is the daily newspaper serving Stanford University. Now an independent organization (to protect both it and the university from potential conflicts of interest) though located on campus, it has been published since the University was founded in 1892. The student-run radio station, KZSU Stanford 90.1 FM, features freeform music programming, sports commentary, and news segments; it started in 1947 as an AM radio station. Literary magazines such as the Leland Quarterly provide creative outlets.
Business oriented groups run from the immediately useful "SUpost.com", an online marketplace for Stanford students and alumni, in partnership with Stanford Student Enterprises (SSE) to the Stanford Pre-Business Association which is the largest business-focused undergraduate organization. The latter plays an instrumental role in establishing an active link between the industry, alumni, and student communities. For students seeking hands-on business experience, Stanford Marketing is the premier practical training-focused pre-professional organization that seeks to educate students through research and strategy based consulting projects with Fortune 500 clients, as well as in-depth workshops led by industry leaders and professors in the Stanford Graduate School of Business. Due to its broad appeal, membership is often very selective, with applicants having to go through an extensive application process with several rounds of interviews. There are also groups that have a more narrow focus. One such example is Stanford Finance, which is aimed at mentoring students who want to enter a career in finance, through mentors and internships. The Business Association of Stanford Entrepreneurial Students (BASES), is one of the largest professional organizations in Silicon Valley, with over 5,000 members. Its goal is to support the next generation of entrepreneurs. Stanford Women In Business (SWIB) is an on-campus business organization consisting of over a board of 40 and 100 active members. Each year, SWIB organizes over 25 events and workshops, hosts a winter and spring conference, and provides mentorship and spring quarter internships. StartX is a non-profit startup accelerator for student and faculty-led startups that over 12% of the study body has applied to. It is staffed primarily by students.
Other groups include (but are not limited to):
People.
Notable faculty and staff.
As of late 2014, Stanford has 2,118 tenure-line faculty, senior fellows, center fellows, and medical center faculty.
Award laureates and scholars.
Stanford's current community of scholars includes:
Stanford's faculty and former faculty includes 31 Nobel laureates, as well as 19 recipients (22 if visiting professors and consulting professors included) of the Turing Award, the so-called "Nobel Prize in computer science", comprising one third of the awards given in its 44-year history. The university has 27 ACM fellows. It is also affiliated with 4 Gödel Prize winners, 4 Knuth Prize recipients, 10 IJCAI Computers and Thought Award winners, and about 15 Grace Murray Hopper Award winners for their work in the foundations of computer science.
Government and politics.
Professors who have served in government include Former Secretary of State Condoleezza Rice, Former Secretary of Energy and Former Director of Lawrence Berkeley National Laboratory Steven Chu, Former Secretary of Defense William Perry, Former US Ambassador to Afghanistan Lt. General Karl Eikenberry, current US Ambassador to Russia Michael McFaul, Former Chair of the Council of Economic Advisors Edward Lazear and Former director of policy planning for the US State Dept. Stephen D. Krasner. George Schultz, Former Secretary of State, Secretary of Labor and Secretary of the Treasury, is a fellow at the Hoover Institution and lectures at the Stanford Graduate School of Business. Former President of Peru Alejandro Toledo was a distinguished lecturer from 2007–2009. Siegfried Hecker, director emeritus of Los Alamos National Laboratory, makes frequent visits to North Korea to inspect their nuclear weapons facilities, and co-teaches a class on national security with William Perry. Tenzin Tethong, former prime minister of the Central Tibetan Administration, chairs the university's Tibetan Studies Initiative, and was a candidate for Prime Minister of the Tibetan Government in Exile. Former US President Benjamin Harrison was a founding professor at Stanford Law School.
The Freeman Spogli Institute for International Studies is also home to political theorist Francis Fukuyama, and founding editor of the Journal of Democracy and advisor to the Coalition Provisional Authority in Iraq, Larry Diamond.
Humanities and social sciences.
Professor and social psychologist Philip Zimbardo oversaw the Stanford Prison Experiment, and psychologist Lewis Terman developed the Stanford-Binet IQ Test. Albert Bandura conducted the Bobo doll experiment, contributing to social learning theory. Tobias Wolff, best known for his memoir "This Boy's Life", is a member of the creative writing faculty. Philosophy Professor Joshua Cohen is a scholar in political science, philosophy, and ethics. History Professor Jack N. Rakove won the Pulitzer Prize for his book on the history of the constitution, the subject of a course he teaches at Stanford. Professor Carl Neumann Degler also won the Pulitzer Prize for History.
In 2012, it was announced that Alexander Nemerov, art historian and chair of the History of Art Department at Yale University, would join the Stanford faculty as part of the University's efforts to increase its presence in the arts.
The economics department and the Hoover Institution have also been home to more than nine Nobel Prize winners in economics, including Kenneth Arrow, Milton Friedman and Gary Becker. Chair of the economics department Jonathan Levin won the 2011 John Bates Clark Medal, awarded to the leading economist under 40. Economist John B. Taylor served as the Under Secretary of the Treasury for International affairs, and developed the Taylor Rule. Professor Caroline Hoxby is a leading education economist and directs of the Economics of Education Program for the National Bureau of Economic Research. She is married to fellow Rhodes Scholar and Stanford English Professor Blair Hoxby.
Notable alumni.
Stanford alumni have started many companies and, according to "Forbes", has produced the second highest number of billionaires of all universities. Companies founded by Stanford alumni include Hewlett-Packard (William Hewlett and David Packard), Cisco Systems (Sandra Lerner and Leonard Bosack), Nvidia (Jen-Hsun Huang), SGI, VMware, MIPS Technologies, Yahoo! (Chih-Yuan Yang and David Filo), Google (Sergey Brin and Lawrence Page), Wipro Technologies (Azim Premji), Nike (Phil Knight), Gap (Doris F. Fisher), Palantir Technologies (Joe Lonsdale and Stephen Cohen), PayPal (Peter Thiel and Elon Musk), Logitech, Instagram, Snapchat, and Sun Microsystems (Vinod Khosla). Other companies and organizations founded or co-founded by Stanford alumni include the Special Olympics, LinkedIn (Reid Hoffman), Netflix (Reed Hastings), Yammer (David O. Sacks), Varian Associates, Pandora Radio, Electronic Arts, Trader Joe's, Dolby Laboratories, Capital One, Renren, TechCrunch, IDEO, Kiva, Acumen, Victoria's Secret, Firefox, Match.com, WhatsApp (Brian Acton) and Participant Media.
Stanford alumni have also founded financial institutions such as the brokerage firm Charles Schwab (Charles R. Schwab), venture capital funds Benchmark, Draper Fisher Jurvetson (Tim Draper and Steve Jurvetson), Khosla Ventures (Vinod Khosla), and Formation 8 (Joe Lonsdale), private equity funds TPG Capital (James Coulter), Bain Capital (Mitt Romney), Hellman & Friedman and Friedman Fleischer & Lowe (Tully Friedman), and Crestview Partners, and hedge funds Farallon Capital (Tom Steyer) and D.E. Shaw & Co. (David E. Shaw). Many leading venture capitalists are Stanford alumni, including Jim Breyer, Reid Hoffman, Peter Thiel, Vinod Khosla, Keith Rabois, Roelof Botha, Brook Byers, Jim Goetz, Bob Kagle, and Peter Fenton, as are financiers Sid Bass and Richard Rainwater and hedge fund manager Andreas Halvorsen.
Stanford-educated executives include former Microsoft CEO Steve Ballmer, General Motors CEO Mary Barra, Yahoo CEO and president Marissa Mayer, eBay president Jeffrey Skoll, Time Warner CEO Jeffrey Bewkes, Google CEO Larry Page, Anheuser-Busch InBev CEO Carlos Brito, Broadcom president and CEO Scott McGregor, NetSuite CEO Zach Nelson, CEMEX chairman and CEO Lorenzo Zambrano, Bank of America Merrill Lynch COO Thomas Montag, Morgan Stanley CFO Ruth Porat, Reliance Industries chairman and managing director Mukesh Ambani, Godrej Industries managing director Nadir Godrej, Dan Siroker founder and CEO of Optimizely, and Infosys CEO and managing director Vishal Sikka.
Former Japanese Prime Ministers Yukio Hatoyama and Taro Aso, former U.S. President Herbert Hoover, former U.S. Secretary of State Warren Christopher, former Israeli Prime Minister Ehud Barak, former Peruvian President Alejandro Toledo, former President of Guatemala Jorge Serrano Elias, current President of the Maldives Mohammed Waheed Hassan, former Vice President of Iran Mohammad-Reza Aref, former Honduras President Ricardo Maduro, King Philippe of Belgium, former United States Senate president pro tempore Carl Hayden, former Arizona governor, supreme court chief justice, and United States Senate Majority Leader Ernest McFarland, and the current U.S. Secretary of Commerce Penny Pritzker are alumni. U.S. President John F. Kennedy attended Stanford without graduating, as did the 2012 Republican presidential nominee and former governor of Massachusetts, Mitt Romney. Former Ghanaian President John Atta Mills earned his J.D. as a Fulbright Scholar at Stanford Law School. U.S. Supreme Court Justices Anthony Kennedy and Stephen Breyer and former Justices Sandra Day O'Connor and William Rehnquist are also alumni. Other alumni in politics include UN Ambassador Susan Rice, former Secretary of Defense and current Stanford professor William Perry, former US Ambassador to Afghanistan Karl Eikenberry, former U.S. Ambassador to Mexico Carlos Pascual, Eileen Donahoe, United States Ambassador to the United Nations Human Rights Council, William Kennard, U.S. Ambassador to the European Union, Michael McFaul, US Ambassador to Russia, and current US Senators Dianne Feinstein, Max Baucus, Jeff Bingaman, Jeff Merkley, Ron Wyden and Cory Booker, and Representatives Xavier Becerra, Judy Biggert, Zoe Lofgren, Adam Schiff, Jim Sensenbrenner, and David Wu. Former U.S. Senators Frank Church (Idaho) and Kent Conrad (North Dakota) also attended Stanford. Chelsea Clinton attended Stanford while her father was President, and met her future husband while attending.
Eighteen Stanford graduates including Sally Ride and Mae Jemison have served as astronauts. Jeff Cooper, Richard D. Hearney, and Charles A. Ott, Jr. had notable military careers.
NBA guards Landry Fields and Brevin Knight, NBA centers Brook Lopez, Robin Lopez and Rich Kelley, NFL quarterbacks Frankie Albert, John Brodie, Jim Plunkett, John Elway and Andrew Luck, NFL receivers James Lofton, Tony Hill, Gene Washington, Gordon Banks, Ed McCaffrey, Chris Walsh and Doug Baldwin, NFL offensive linemen Pat Donovan, Bruno Banducci, Bob Whitfield, Blaine Nye, NFL running backs Ernie Nevers, Darrin Nelson, Hugh Gallarneau, Jon Ritchie, Scott Laidlaw, NFL defensive backs John Lynch, Richard Sherman, Benny Barnes, NFL defensive lineman Paul Wiggin, NFL linebacker David Wyman, runner Ryan Hall, MLB starting pitcher Mike Mussina, MLB outfielders Sam Fuld and Carlos Quentin, MLB infielder Jed Lowrie, MLB catcher Bruce Robinson, Grand Slam winning tennis players John McEnroe (did not graduate) (singles and doubles), Roscoe Tanner (singles), and Bob and Mike Bryan (doubles), professional golfers Michelle Wie, Tom Watson and Tiger Woods (did not graduate), former New Zealand Football and Queens Park Rangers Defender Ryan Nelsen, Olympic swimmers Jenny Thompson, Summer Sanders and Pablo Morales, Olympic figure skater Debi Thomas, Olympic gymnast Amy Chow, Olympic and World Cup soccer players Julie Foudy, Sarah Rafanelli, Kelley O'Hara, Christen Press, Nicole Barnhart, and Rachel Buehler, Olympic water polo players Tony Azevedo and Brenda Villa, Olympic softball player Jessica Mendoza, Olympic volleyball player Kerri Walsh, Olympic volleyball player Logan Tom, and Heisman finalist Toby Gerhart are alumni.
In the field of entertainment, Sigourney Weaver, Ted Koppel, Ben Savage, Tablo and Rachel Maddow are graduates. Jay Roach, director of the "Austin Powers" and "Meet the Parents" films and "Game Change" is an alum. Actor Jack Palance attended and left just one credit short of graduation; the University later awarded him a drama degree. Reese Witherspoon attended Stanford for one year before starting her film career. Actress Jennifer Connelly dropped out to resume her acting career. Alexander Payne wrote and directed such films as "Sideways", "The Descendants", and "About Schmidt". Alum David Chase, a seven-time Emmy Award winner, is the creator and writer of "The Sopranos".
John Steinbeck, author of "Of Mice and Men" and "The Grapes of Wrath", attended Stanford for five years but did not receive a degree. Ken Kesey studied creative writing at Stanford, and began the manuscript of "One Flew Over the Cuckoo's Nest" while attending. Larry McMurtry, author of "Lonesome Dove", studied for two years at Stanford on the Stegner Fellowship. Michael Cunningham author of "The Hours" attended as did Jeffrey Eugenides, who wrote "Middlesex" and "The Virgin Suicides". N. Scott Momaday is credited as a leader in bringing Native American fiction into mainstream American literature. U.S. Poet Laureates Robert Pinsky and Robert Hass were classmates while attaining their Ph.D.s at Stanford, and another Poet Laureate, Philip Levine, studied poetry at Stanford. Author Marta Acosta also attended Stanford.
Yale Presidents Peter Salovey and Rick Levin and former Harvard President Derek Bok each earned a bachelor's degree at Stanford, and MIT President L. Rafael Reif and former Caltech President Jean-Lou Chameau earned their PhDs there. Harvard Provost Alan M. Garber earned his M.D. from Stanford Medical School. Other alumni who became university leaders include former University of California system President Clark Kerr, former Johns Hopkins President William Brody, former Brown University President Vartan Gregorian, former Nanyang Technological University President Su Guaning, National Taiwan University President Lee Si-Chen, Occidental College President Jonathan Veitch, and Boston College President William P. Leahy.
Eight Stanford alumni have won the Nobel Prize. As of 2013, 112 Stanford students have been named Rhodes Scholars.

</doc>
<doc id="26979" url="http://en.wikipedia.org/wiki?curid=26979" title="Substance">
Substance

Substance may refer to:

</doc>
<doc id="26980" url="http://en.wikipedia.org/wiki?curid=26980" title="Sun Microsystems">
Sun Microsystems

Sun Microsystems, Inc. was a company that sold :computers, computer components, :computer software, and :information technology services and that created the Java programming language and the Network File System (NFS). Sun significantly evolved several key computing technologies, among them Unix, RISC processors, thin client computing, and virtualized computing. Sun was founded on February 24, 1982. At its height, Sun headquarters were in Santa Clara, California (part of Silicon Valley), on the former west campus of the Agnews Developmental Center.
On January 27, 2010, Sun was acquired by Oracle Corporation for US $7.4 billion, based on an agreement signed on April 20, 2009. The following month, Sun Microsystems, Inc. was merged with Oracle USA, Inc. to become Oracle America, Inc.
Sun products included computer servers and workstations built on its own RISC-based SPARC processor architecture as well as on x86-based AMD's Opteron and Intel's Xeon processors; storage systems; and a suite of software products including the Solaris operating system, developer tools, Web infrastructure software, and identity management applications. Other technologies include the Java platform, MySQL, and NFS. Sun was a proponent of open systems in general and Unix in particular, and a major contributor to open source software. Sun's main manufacturing facilities were located in Hillsboro, Oregon, and Linlithgow, Scotland.
History.
The initial design for what became Sun's first Unix workstation, the Sun-1, was conceived by Andy Bechtolsheim when he was a graduate student at Stanford University in Palo Alto, California. Bechtolsheim originally designed the SUN workstation for the Stanford University Network communications project as a personal CAD workstation. It was designed around the Motorola 68000 processor with an advanced memory management unit (MMU) to support the Unix operating system with virtual memory support. He built the first ones from spare parts obtained from Stanford's Department of Computer Science and Silicon Valley supply houses.
On February 24, 1982, Vinod Khosla, Andy Bechtolsheim, and Scott McNealy, all Stanford graduate students, founded "Sun Microsystems". Bill Joy of Berkeley, a primary developer of the Berkeley Software Distribution (BSD), joined soon after and is counted as one of the original founders. The Sun name is derived from the initials of the Stanford University Network. Sun was profitable from its first quarter in July 1982.
By 1983 Sun was known for producing 68000-based systems with high-quality graphics that were the only computers other than DEC's VAX to run 4.2BSD. It licensed the computer design to other manufacturers, which typically used it to build Multibus-based systems running Unix from UniSoft. Sun's initial public offering was in 1986 under the stock symbol "SUNW", for "Sun Workstations" (later "Sun Worldwide"). The symbol was changed in 2007 to "JAVA"; Sun stated that the brand awareness associated with its Java platform better represented the company's current strategy.
Sun's logo, which features four interleaved copies of the word "sun", was designed by professor Vaughan Pratt, also of Stanford. The initial version of the logo was orange and had the sides oriented horizontally and vertically, but it was subsequently rotated to stand on one corner and re-colored purple, and later blue.
The "Bubble" and its aftermath.
In the dot-com bubble, Sun began making much more money, and its shares rose dramatically. It also began spending much more, hiring workers and building itself out. Some of this was because of genuine demand, but much was from web start-up companies anticipating business that would never happen. In 2000, the bubble burst. Sales in Sun's important hardware division went into free-fall as customers closed shop and auctioned off high-end servers.
Several quarters of steep losses led to executive departures, rounds of layoffs, and other cost cutting. In December 2001, the stock fell to the 1998, pre-bubble level of about $100. But it kept falling, faster than many other tech companies. A year later it had dipped below $10 (a tenth of what it was even in 1990) but bounced back to $20. In mid-2004, Sun closed their Newark, California factory and consolidated all manufacturing to Hillsboro, Oregon. In 2006, that factory also closed.
Post-crash focus.
In 2004, Sun canceled two major processor projects which emphasized high instruction level parallelism and operating frequency. Instead, the company chose to concentrate on processors optimized for multi-threading and multiprocessing, such as the UltraSPARC T1 processor (codenamed "Niagara"). The company also announced a collaboration with Fujitsu to use the Japanese company's processor chips in mid-range and high-end Sun servers. These servers were announced on April 17, 2007 as the M-Series, part of the SPARC Enterprise series.
In February 2005, Sun announced the Sun Grid, a grid computing deployment on which it offered utility computing services priced at US$1 per CPU/hour for processing and per GB/month for storage. This offering built upon an existing 3,000-CPU server farm used for internal R&D for over 10 years, which Sun marketed as being able to achieve 97% utilization. In August 2005, the first commercial use of this grid was announced for financial risk simulations which was later launched as its first software as a service product.
In January 2005, Sun reported a net profit of $19 million for fiscal 2005 second quarter, for the first time in three years. This was followed by net loss of $9 million on GAAP basis for the third quarter 2005, as reported on April 14, 2005. In January 2007, Sun reported a net GAAP profit of $126 million on revenue of $3.337 billion for its fiscal second quarter. Shortly following that news, it was announced that Kohlberg Kravis Roberts (KKR) would invest $700 million in the company.
Sun had engineering groups in Bangalore, Beijing, Dublin, Grenoble, Hamburg, Prague, St. Petersburg, Tel Aviv, Tokyo, and Trondheim.
In 2007–2008, Sun posted revenue of $13.8 billion and had $2 billion in cash. First-quarter 2008 losses were $1.68 billion; revenue fell 7% to $12.99 billion. Sun's stock lost 80% of its value November 2007 to November 2008, reducing the company's market value to $3 billion. With falling sales to large corporate clients, Sun announced plans to lay off 5,000 to 6,000 workers, or 15–18% of its work force. It expected to save $700 million to $800 million a year as a result of the moves, while also taking up to $600 million in charges.
Major stockholders.
As of May 11, 2009, the following shareholders held over 100,000 common shares of Sun: and at $9.40 per share offered by Oracle they received the amounts indicated when the acquisition closed.
Hardware.
For the first decade of Sun's history, the company positioned its products as technical workstations, competing successfully as a low-cost vendor during the Workstation Wars of the 1980s. It then shifted its hardware product line to emphasize servers and storage.
High-level telecom control systems such as Operational Support Systems service predominantly used Sun equipment. This use is due mainly to the company basing its products around a mature and very stable version of the Unix operating system and the support service that Sun provides.
Motorola-based systems.
Sun originally used Motorola 68000 family central processing units for the Sun-1 through Sun-3 computer series. The Sun-1 employed a 68000 CPU, the Sun-2 series, a 68010. The Sun-3 series was based on the 68020, with the later Sun-3x using the 68030.
SPARC-based systems.
In 1987, the company began using "SPARC", a RISC processor architecture of its own design, in its computer systems, starting with the Sun-4 line. SPARC was initially a 32-bit architecture (SPARC V7) until the introduction of the SPARC V9 architecture in 1995, which added 64-bit extensions.
Sun has developed several generations of SPARC-based computer systems, including the SPARCstation, Ultra and Sun Blade series of workstations, and the SPARCserver, Netra, Enterprise and Sun Fire line of servers.
In the early 1990s the company began to extend its product line to include large-scale symmetric multiprocessing servers, starting with the four-processor SPARCserver 600MP. This was followed by the 8-processor SPARCserver 1000 and 20-processor SPARCcenter 2000, which were based on work done in conjunction with Xerox PARC. In 1995 the company introduced Sun Ultra series machines that were equipped with the first 64-bit implementation of SPARC processors (UltraSPARC). In the late 1990s the transformation of product line in favor of large 64-bit SMP systems was accelerated by the acquisition of Cray Business Systems Division from Silicon Graphics. Their 32-bit, 64-processor Cray Superserver 6400, related to the SPARCcenter, led to the 64-bit Sun Enterprise 10000 high-end server (otherwise known as "Starfire").
In September 2004 Sun made available systems with UltraSPARC IV which was the first multi-core SPARC processor. It was followed by UltraSPARC IV+ in September 2005 and its revisions with higher clock speeds in 2007. These CPUs were used in the most powerful, enterprise class high-end CC-NUMA servers developed by Sun, such as Sun Fire E25K.
In November 2005 Sun launched the UltraSPARC T1, notable for its ability to concurrently run 32 threads of execution on 8 processor cores. Its intent was to drive more efficient use of CPU resources, which is of particular importance in data centers, where there is an increasing need to reduce power and air conditioning demands, much of which comes from the heat generated by CPUs. The T1 was followed in 2007 by the UltraSPARC T2, which extended the number of threads per core from 4 to 8. Sun has open sourced the design specifications of both the T1 and T2 processors via the OpenSPARC project.
In 2006, Sun has also ventured into the "blade server" (high density rack-mounted systems) market with the Sun Blade (distinct from the Sun Blade workstation).
In April 2007 Sun released the SPARC Enterprise server products, jointly designed by Sun and Fujitsu and based on Fujitsu SPARC64 VI and later processors. The "M-class" SPARC Enterprise systems include high-end reliability and availability features. Later T-series servers have also been badged SPARC Enterprise rather than Sun Fire.
In April 2008 Sun released servers with UltraSPARC T2 Plus, which is an SMP capable version of UltraSPARC T2, available in 2 or 4 processor configurations. It was the first CoolThreads CPU with multi-processor capability and it made possible to build standard rack-mounted servers that could simultaneously process up to massive 256 CPU threads in hardware (Sun SPARC Enterprise T5440), which is considered a record in the industry.
Since 2010, all further development of Sun machines based on SPARC architecture (including new SPARC T-Series servers, SPARC T3 and T4 chips) is done as a part of Oracle Corporation hardware division.
x86-based systems.
In the late 1980s, Sun also marketed an Intel 80386-based machine, the Sun386i; this was designed to be a hybrid system, running SunOS but at the same time supporting DOS applications. This only remained on the market for a brief time. A follow-up "486i" upgrade was announced but only a few prototype units were ever manufactured.
Sun's brief first foray into x86 systems ended in the early 1990s, as it decided to concentrate on SPARC and retire the last Motorola systems and 386i products, a move dubbed by McNealy as "all the wood behind one arrowhead". Even so, Sun kept its hand in the x86 world, as a release of Solaris for PC compatibles began shipping in 1993.
In 1997 Sun acquired Diba, Inc., followed later by the acquisition of Cobalt Networks in 2000, with the aim of building "network appliances" (single function computers meant for consumers). Sun also marketed a "network computer" (a term popularized and eventually trademarked by Oracle); the JavaStation was a diskless system designed to run Java applications.
Although none of these business initiatives were particularly successful, the Cobalt purchase gave Sun a toehold for its return to the x86 hardware market. In 2002, Sun introduced its first general purpose x86 system, the LX50, based in part on previous Cobalt system expertise. This was also Sun's first system announced to support Linux as well as Solaris.
In 2003, Sun announced a strategic alliance with AMD to produce x86/x64 servers based on AMD's Opteron processor; this was followed shortly by Sun's acquisition of Kealia, a startup founded by original Sun founder Andy Bechtolsheim, which had been focusing on high-performance AMD-based servers.
The following year, Sun launched the Opteron-based Sun Fire V20z and V40z servers, and the Java Workstation W1100z and W2100z workstations.
On September 12, 2005, Sun unveiled a new range of Opteron-based servers: the Sun Fire X2100, X4100 and X4200 servers. These were designed from scratch by a team led by Bechtolsheim to address heat and power consumption issues commonly faced in data centers. In July 2006, the Sun Fire X4500 and X4600 systems were introduced, extending a line of x64 systems that support not only Solaris, but also Linux and Microsoft Windows.
On January 22, 2007, Sun announced a broad strategic alliance with Intel. Intel endorsed Solaris as a mainstream operating system and as its mission critical Unix for its Xeon processor-based systems, and contributed engineering resources to OpenSolaris. Sun began using the Intel Xeon processor in its x64 server line, starting with the Sun Blade X6250 server module introduced in June 2007.
On May 5, 2008, AMD announced its Operating System Research Center (OSRC) expanded its focus to include optimization to Sun's OpenSolaris and xVM virtualization products for AMD based processors.
Software.
Although Sun was initially known as a hardware company, its software history began with its founding in 1982; co-founder Bill Joy was one of the leading Unix developers of the time, having contributed the vi editor, the C shell, and significant work developing TCP/IP and the BSD Unix OS. Sun later developed software such as the Java programming language and acquired software such as StarOffice, VirtualBox and MySQL.
Sun used community-based and open-source licensing of its major technologies, and for its support of its products with other open source technologies. GNOME-based desktop software called Java Desktop System (originally code-named "Madhatter") was first distributed as a Linux implementation then offered as part of the Solaris operating system. Sun supported its Java Enterprise System (a middleware stack) on Linux. It released the source code for Solaris under the open-source Common Development and Distribution License, via the OpenSolaris community. Sun's positioning includes a commitment to indemnify users of some software from intellectual property disputes concerning that software. It offers support services on a variety of pricing bases, including per-employee and per-socket.
A 2006 report prepared for the EU by UNU-MERIT stated that Sun was the largest corporate contributor to open source movements in the world. According to this report, Sun's open source contributions exceed the combined total of the next five largest commercial contributors.
Operating systems.
Sun is best known for its Unix systems, which have a reputation for system stability and a consistent design philosophy.
Sun's first workstation shipped with UniSoft V7 Unix. Later in 1982 Sun began providing SunOS, a customized 4.1BSD Unix, as the operating system for its workstations.
In the late 1980s, AT&T tapped Sun to help them develop the next release of their branded UNIX, and in 1988 announced they would purchase up to a 20% stake in Sun. UNIX System V Release 4 (SVR4) was jointly developed by AT&T and Sun; Sun used SVR4 as the foundation for Solaris 2.x, which became the successor to SunOS 4.1.x (later retrospectively named Solaris 1.x). By the mid-1990s, the ensuing Unix wars had largely subsided, AT&T had sold off their Unix interests, and the relationship between the two companies was significantly reduced.
From 1992 Sun also sold Interactive Unix, an operating system it acquired when it bought Interactive Systems Corporation from Eastman Kodak Company. This was a popular Unix variant for the PC platform and a major competitor to market leader SCO UNIX. Sun's focus on Interactive Unix diminished in favor of Solaris on both SPARC and x86 systems; it was dropped as a product in 2001.
Sun dropped the Solaris 2.x version numbering scheme after the Solaris 2.6 release (1997); the following version was branded Solaris 7. This was the first 64-bit release, intended for the new UltraSPARC CPUs based on the SPARC V9 architecture. Within the next four years, the successors Solaris 8 and Solaris 9 were released in 2000 and 2002 respectively.
Following several years of difficult competition and loss of server market share to competitors' Linux-based systems, Sun began to include Linux as part of its strategy in 2002. Sun supported both Red Hat Enterprise Linux and SUSE Linux Enterprise Server on its x64 systems; companies such as Canonical Ltd., Wind River Systems and MontaVista also supported their versions of Linux on Sun's SPARC-based systems.
In 2004, after having cultivated a reputation as one of Microsoft's most vocal antagonists, Sun entered into a joint relationship with them, resolving various legal entanglements between the two companies and receiving US$1.95 billion in settlement payments from them. Sun supported Microsoft Windows on its x64 systems, and announced other collaborative agreements with Microsoft, including plans to support each other's virtualization environments.
In 2005, the company released Solaris 10. The new version included a large number of enhancements to the operating system, as well as very novel features, previously unseen in the industry. Solaris 10 update releases continued through the next 8 years, the last release from Sun Microsystems being Solaris 10 10/09. The following updates were released by Oracle under the new license agreement; the final release is Solaris 10 1/13.
Previously, Sun offered a separate variant of Solaris called Trusted Solaris, which included augmented security features such as multilevel security and a least privilege access model. Solaris 10 included many of the same capabilities as Trusted Solaris at the time of its initial release; Solaris 10 11/06 included Solaris Trusted Extensions, which give it the remaining capabilities needed to make it the functional successor to Trusted Solaris.
Following acquisition of Sun, Oracle Corporation continued to develop Solaris operating system, and released Oracle Solaris 11 in November 2011.
Java platform.
The Java platform was developed at Sun in the early 1990s with the objective of allowing programs to function regardless of the device they were used on, sparking the slogan "Write once, run anywhere" (WORA). While this objective was not entirely achieved (prompting the riposte "Write once, debug everywhere"), Java is regarded as being largely hardware- and operating system-independent.
Java was initially promoted as a platform for client-side "applets" running inside web browsers. Early examples of Java applications were the HotJava web browser and the HotJava Views suite. However, since then Java has been more successful on the server side of the Internet.
The platform consists of three major parts: the Java programming language, the Java Virtual Machine (JVM), and several Java Application Programming Interfaces (APIs). The design of the Java platform is controlled by the vendor and user community through the Java Community Process (JCP).
Java is an object-oriented programming language. Since its introduction in late 1995, it became one of the world's most popular programming languages.
Java programs are compiled to byte code, which can be executed by any JVM, regardless of the environment.
The Java APIs provide an extensive set of library routines. These APIs evolved into the "Standard Edition" (Java SE), which provides basic infrastructure and GUI functionality; the "Enterprise Edition" (Java EE), aimed at large software companies implementing enterprise-class application servers; and the "Micro Edition" (Java ME), used to build software for devices with limited resources, such as mobile devices.
On November 13, 2006, Sun announced it would be licensing its Java implementation under the GNU General Public License; it released its Java compiler and JVM at that time.
In February 2009 Sun entered a battle with Microsoft and Adobe Systems, which promoted rival platforms to build software applications for the Internet. JavaFX was a development platform for music, video and other applications that builds on the Java programming language.
Office suite.
In 1999, Sun acquired the German software company StarDivision and with it the office suite StarOffice, which Sun later released as OpenOffice.org under both GNU LGPL and the SISSL (Sun Industry Standards Source License). OpenOffice.org supported Microsoft Office file formats (though not perfectly), was available on many platforms (primarily Linux, Microsoft Windows, Mac OS X, and Solaris) and was used in the open source community.
The principal differences between StarOffice and OpenOffice.org were that StarOffice was supported by Sun, was available as either a single-user retail box kit or as per-user blocks of licensing for the enterprise, and included a wider range of fonts and document templates and a commercial quality spellchecker. StarOffice also contained commercially licensed functions and add-ons; in OpenOffice.org these were either replaced by open-source or free variants, or are not present at all. Both packages had native support for the OpenDocument format.
Virtualization and datacenter automation software.
In 2007, Sun announced the Sun xVM virtualization and datacenter automation product suite for commodity hardware. Sun also acquired VirtualBox in 2008. Earlier virtualization technologies from Sun like "Dynamic System Domains" and "Dynamic Reconfiguration" were specifically designed for high-end SPARC servers, and Logical Domains only supports the UltraSPARC T1/T2/T2 Plus server platforms. Sun marketed "Sun Ops Center" provisioning software for datacenter automation.
On the client side, Sun offered virtual desktop solutions. Desktop environments and applications could be hosted in a datacenter, with users accessing these environments from a wide range of client devices, including Microsoft Windows PCs, Sun Ray virtual display clients, Apple Macintoshes, PDAs or any combination of supported devices. A variety of networks were supported, from LAN to WAN or the public Internet. Virtual desktop products included Sun Ray Server Software, Sun Secure Global Desktop and Sun Virtual Desktop Infrastructure.
Database management systems.
Sun acquired MySQL AB, the developer of the MySQL database in 2008 for US$1 billion. CEO Jonathan Schwartz mentioned in his blog that optimizing the performance of MySQL was one of the priorities of the acquisition. In February 2008, Sun began to publish results of the MySQL performance optimization work. Sun contributed to the PostgreSQL project. On the Java platform, Sun contributed to and supported Java DB.
Other software.
Sun offered other software products for software development and infrastructure services. Many were developed in house; others came from acquisitions, including Tarantella, Waveset Technologies, SeeBeyond, and Vaau. Sun acquired many of the Netscape non-browser software products as part a deal involving Netscape's merger with AOL. These software products were initially offered under the "iPlanet" brand; once the Sun-Netscape alliance ended, they were re-branded as "Sun ONE" (Sun Open Network Environment), and then the "Sun Java System".
Sun's middleware product was branded as the "Java Enterprise System" (or JES), and marketed for web and application serving, communication, calendaring, directory, identity management and service-oriented architecture. Sun's Open ESB and other software suites were available free of charge on systems running Solaris, Red Hat Enterprise Linux, HP-UX, and Windows, with support available optionally.
Sun developed data center management software products, which included the "Solaris Cluster" high availability software, and a grid management package called "Sun Grid Engine" and firewall software such as SunScreen.
For Network Equipment Providers and telecommunications customers, Sun developed the Sun Netra High-Availability Suite.
Sun produced compilers and development tools under the "Sun Studio" brand, for building and developing Solaris and Linux applications.
Sun entered the software as a service (SaaS) market with zembly, a social cloud-based computing platform and Project Kenai, an open-source project hosting service.
Storage.
Sun sold its own storage systems to complement its system offerings; it has also made several storage-related acquisitions.
On June 2, 2005, Sun announced it would purchase Storage Technology Corporation (StorageTek) for US$4.1 billion in cash, or $37.00 per share, a deal completed in August 2005.
In 2006, Sun introduced the Sun StorageTek 5800 System, the first application-aware programmable storage solution. In 2008, Sun contributed the source code of the StorageTek 5800 System under the BSD license.
Sun announced the Sun Open Storage platform in 2008 built with open source technologies.
In late 2008 Sun announced the Sun Storage 7000 Unified Storage systems (codenamed Amber Road). Transparent placement of data in the systems' solid-state drives (SSD) and conventional hard drives was managed by ZFS to take advantage of the speed of SSDs and the economy of conventional hard disks.
Other storage products included Sun Fire X4500 storage server and SAM-QFS filesystem and storage management software.
HPC solutions.
Sun marketed the Sun Constellation System for High-Performance Computing (HPC). Even before the introduction of the Sun Constellation System in 2007, Sun's products were in use in many of the TOP500 systems and supercomputing centers:
The "Sun HPC ClusterTools" product was a set of Message Passing Interface (MPI) libraries and tools for running parallel jobs on Solaris HPC clusters. Beginning with version 7.0, Sun switched from its own implementation of MPI to Open MPI, and donated engineering resources to the Open MPI project.
Sun was a participant in the OpenMP language committee. Sun Studio compilers and tools implemented the OpenMP specification for shared memory parallelization.
In 2006, Sun built the "TSUBAME supercomputer", which was until June 2008 the fastest supercomputer in Asia. Sun built "Ranger" at the Texas Advanced Computing Center (TACC) in 2007. Ranger had a peak performance of over 500 TFLOPS, and was the 6th most powerful supercomputer on the TOP500 list in November 2008.
Sun announced an OpenSolaris distribution that integrated many of Sun's HPC products and other 3rd-party solutions.
Staff.
Notable Sun employees included John Gilmore, Josh Weiss, Whitfield Diffie, Radia Perlman, Marc Tremblay, and Charitha Jayasuriya. Sun was an early advocate of Unix-based networked computing, promoting TCP/IP and especially NFS, as reflected in the company's motto "The Network Is The Computer", coined by John Gage. James Gosling led the team which developed the Java programming language. Jon Bosak led the creation of the XML specification at W3C.
Sun staff published articles on the company's blog site. Staff were encouraged to use the site to blog on any aspect of their work or personal life, with few restrictions placed on staff, other than commercially confidential material. Jonathan I. Schwartz was one of the first CEOs of large companies to regularly blog; his postings were frequently quoted and analyzed in the press. In 2005, Sun Microsystems was one of the first Fortune 500 companies that instituted a formal Social Media program.
Acquisition by Oracle.
Sun was sold to Oracle Corporation in 2009.
Sun's staff were asked to share anecdotes about their experiences at Sun. A web site containing videos, stories, and photographs from 27 years at Sun was made available on September 2, 2009.
In October, Sun announced a second round of thousands of employees to be laid off, blamed partially on delays in approval of the merger.
The transaction completed in early 2010.
In January 2011 Oracle agreed to pay $46 million to settle charges that it submitted false claims to US federal government agencies and paid "kickbacks" to systems integrators.
In February 2011 Sun's former Menlo Park, California campus of about 1000000 ft2 was sold, and it was announced that it would become headquarters for Facebook.
The sprawling facility built around an enclosed courtyard had been nicknamed "Sun Quentin". On September 1, 2011, Sun India legally became part of Oracle. It had been delayed due to legal issues in Indian court.

</doc>
<doc id="26981" url="http://en.wikipedia.org/wiki?curid=26981" title="Solaris">
Solaris

Solaris may refer to:

</doc>
<doc id="26983" url="http://en.wikipedia.org/wiki?curid=26983" title="Saladin">
Saladin

Ṣalāḥ ad-Dīn Yūsuf ibn Ayyūb (Kurdish: سەلاحەدینی ئەییووبی/Selahedînê Eyûbî;
Arabic: صلاح الدين يوسف بن أيوب‎) (1137/1138 – 4 March 1193), better known in the Western world as Saladin, was the first Sultan of Egypt and Syria and the founder of the Ayyubid dynasty. A Muslim of Kurdish origin, Saladin led the Muslim opposition to the European Crusaders in the Levant. At the height of his power, his sultanate included Egypt, Syria, Mesopotamia, Hejaz, Yemen and other parts of North Africa.
Originally sent to Fatimid Egypt by his Zengid lord Nur ad-Din in 1163, Saladin climbed the ranks of the Fatimid government by virtue of his military successes against Crusader assaults on its territory and his personal closeness to the caliph al-Adid. When Saladin's uncle Shirkuh died in 1169, al-Adid appointed Saladin vizier, a rare nomination of a Sunni Muslim to such an important position in the Shia Muslim-led caliphate. During his term as vizier Saladin began to undermine the Fatimid establishment, and following al-Adid's death in 1171 he took over the government and realigned the country's allegiance with the Baghdad-based Abbasid Caliphate. In the following years, he led forays against the Crusaders in Palestine, ordered the successful conquest of Yemen and staved off pro-Fatimid rebellions in Upper Egypt.
Not long after the death of Nur ad-Din in 1174, Saladin personally led the conquest of Syria, peacefully entering Damascus at the request of its ruler. By mid-1175, Saladin had conquered Hama and Homs, inviting the animosity of his former Zengid lords, who had been the official rulers of Syria. Soon after, he defeated the Zengid army in battle and was thereafter proclaimed the "Sultan of Egypt and Syria" by the Abbasid caliph al-Mustadi. He made further conquests in northern Syria and Jazira, escaping two attempts on his life by the Assassins, before returning to Egypt in 1177 to address issues there. By 1182, Saladin completed the conquest of Syria after capturing Aleppo, but ultimately failed to take over the Zengid stronghold of Mosul.
Under Saladin's personal leadership, the Ayyubid army defeated the Crusaders at the decisive Battle of Hattin in 1187, leading the way to the Muslims' re-capture of Palestine from the Crusaders who had conquered it 88 years earlier. Though the Crusader Kingdom of Jerusalem would continue to exist for an extended period, its defeat at Hattin marked a turning point in its conflict with the Muslim powers of the region. Saladin has become a prominent figure in Muslim, Arab, Turk and Kurdish culture. In 1193 he died in Damascus, having given much of his wealth to his subjects. Saladin is buried in a mausoleum adjacent to the Umayyad Mosque.
Early life.
Saladin was born in Tikrit. His personal name was "Yusuf"; "Salah ad-Din" is a "laqab", a descriptive epithet, meaning "Righteousness of the Faith." His family was of Kurdish ancestry, and had originated from the city of Dvin in medieval Armenia. He was maternal grandson of Nur ad-Din. The Rawadid tribe he hailed from had been partially assimilated into the Arabic-speaking world by this time. In 1132 the defeated army of the Imad ad-Din Zengi, the Lord of Mosul, found their retreat blocked by the Tigris River opposite the Tikrit fortress where Saladin's father, Najm ad-Din Ayyub served as the warden. Ayyub provided ferries for the army and gave them refuge in Tikrit. Mujahed al-Din Bihruz, a former Greek slave who had been appointed the military governor of northern Mesopotamia for his service to the Seljuks had reprimanded Ayyub for giving Zengi refuge and in 1137, banished Ayyub from Tikrit after his brother Asad al-Din Shirkuh killed a friend of Bihruz in an honour killing. According to Baha ad-Din ibn Shaddad, Saladin was born the same night his family left Tikrit. In 1139, Ayyub and his family moved to Mosul where Imad ad-Din Zengi acknowledged his debt and appointed Ayyub commander of his fortress in Baalbek. After the death of Zengi in 1146, his son, Nur ad-Din, became the regent of Aleppo and the leader of the Zengids.
Saladin, who now lived in Damascus, was reported to have a particular fondness of the city, but information on his early childhood is scarce. About education, Saladin wrote "children are brought up in the way in which their elders were brought up." According to one of his biographers, al-Wahrani, Saladin was able to answer questions on Euclid, the Almagest, arithmetic, and law, but this was an academic ideal and it was study of the Qur'an and the "sciences of religion" that linked him to his contemporaries. Several sources claim that during his studies he was more interested in religion than joining the military.<ref name="Who2 Biography: Saladin, Sultan/Military Leader"></ref> Another factor which may have affected his interest in religion was that during the First Crusade, Jerusalem was taken in a surprise attack by the Christians. In addition to Islam, Saladin had a knowledge of the genealogies, biographies, and histories of the Arabs, as well as the bloodlines of Arabian horses. More significantly, he knew the "Hamasah" of Abu Tammam by heart. He also spoke Kurdish, and likely Turkish as well.
Early expeditions.
Saladin's military career began under the tutelage of his uncle Asad al-Din Shirkuh, an important military commander under Nur ad-Din, Emir of Damascus and Aleppo, member of the Turkic Zengid dynasty and the most influential teacher of Saladin. In 1163, the vizier to the Fatimid caliph al-Adid, Shawar, had been driven out of Egypt by rival Dirgham, a member of the powerful Banu Ruzzaik tribe. He asked for military backing from Nur ad-Din, who complied and in 1164, sent Shirkuh to aid Shawar in his expedition against Dirgham. Saladin, at age 26, went along with them. After Shawar was successfully reinstated as vizier, he demanded that Shirkuh withdraw his army from Egypt for a sum of 30,000 dinars, but he refused insisting it was Nur ad-Din's will that he remain. Saladin's role in this expedition was minor, and it is known that he was ordered by Shirkuh to collect stores from Bilbais prior to its siege by a combined force of Crusaders and Shawar's troops.
After the sacking of Bilbais, the Crusader-Egyptian force and Shirkuh's army were to engage in a battle on the desert border of the River Nile, just west of Giza. Saladin played a major role, commanding the right wing of the Zengid army (Muslim Dynasty of Oghuz Turk origin), while a force of Kurds commanded the left, and Shirkuh stationed in the center. Muslim sources at the time, however, put Saladin in the "baggage of the centre" with orders to lure the enemy into a trap by staging a false retreat. The Crusader force enjoyed early success against Shirkuh's troops, but the terrain was too steep and sandy for their horses, and commander Hugh of Caesarea was captured while attacking Saladin's unit. After scattered fighting in little valleys to the south of the main position, the Zengid central force returned to the offensive; Saladin joined in from the rear.
The battle ended in a Zengid victory, and Saladin is credited to have helped Shirkuh in one of the "most remarkable victories in recorded history", according to Ibn al-Athir, although more of Shirkuh's men were killed and the battle is considered by most sources as not a total victory. Saladin and Shirkuh moved towards Alexandria where they were welcomed, given money, arms and provided a base. Faced by a superior Crusader-Egyptian force who attempted to besiege the city, Shirkuh split his army. He and the bulk of his force withdrew from Alexandria, while Saladin was left with the task of guarding the city.
In Egypt.
Emir of Egypt.
Shirkuh engaged in a power struggle over Egypt with Shawar and Amalric I of the Kingdom of Jerusalem, in which Shawar requested Amalric's assistance. In 1169, Shawar was reportedly assassinated by Saladin, and Shirkuh died later that year. Nur ad-Din chose a successor for Shirkuh, but al-Adid appointed Saladin to replace Shawar as vizier.
The reasoning behind the Shia caliph al-Adid's selection of Saladin, a Sunni, varies. Ibn al-Athir claims that the caliph chose him after being told by his advisers that "there is no one weaker or younger" than Saladin, and "not one of the emirs obeyed him or served him." However, according to this version, after some bargaining, he was eventually accepted by the majority of "emirs". Al-Adid's advisers were also suspected of attempting to split the Syria-based Zengid ranks. Al-Wahrani wrote that Saladin was selected because of the reputation of his family in their "generosity and military prowess." Imad ad-Din wrote that after the brief mourning period of Shirkuh, during which "opinions differed", the Zengid "emirs" decided upon Saladin and forced the caliph to "invest him as vizier." Although positions were complicated by rival Muslim leaders, the bulk of the Syrian rulers supported Saladin because of his role in the Egyptian expedition, in which he gained a record of military qualifications.
Inaugurated as Emir on 26 March, Saladin repented "wine-drinking and turned from frivolity to assume the dress of religion." Having gained more power and independence than ever before in his career, he still faced the issue of ultimate loyalty between al-Adid and Nur ad-Din.
Later in the year, a group of Egyptian soldiers and "emirs" attempted to assassinate Saladin, but having already known of their intentions, thanks to his intelligence chief Ali bin Safyan, he had the chief conspirator, Naji, Mu'tamin al-Khilafa—the civilian controller of the Fatimid Palace—arrested and killed. The day after, 50,000 black African soldiers from the regiments of the Fatimid army opposed to Saladin's rule along with a number of Egyptian "emirs" and commoners staged a revolt. By 23 August, Saladin had decisively quelled the uprising, and never again had to face a military challenge from Cairo.
Towards the end of 1169, Saladin, with reinforcements from Nur ad-Din defeated a massive Crusader-Byzantine force near Damietta. Afterward, in the spring of 1170, Nur ad-Din sent Saladin's father to Egypt in compliance with Saladin's request, as well as encouragement from the Baghdad-based Abbasid caliph, al-Mustanjid, who aimed to pressure Saladin in deposing his rival caliph, al-Adid. Saladin himself had been strengthening his hold on Egypt and widening his support base there. He began granting his family members high-ranking positions in the region; he ordered the construction of a college for the Maliki branch of Sunni Islam in the city, as well as one for the Shafi'i denomination to which he belonged in al-Fustat.
After establishing himself in Egypt, Saladin launched a campaign against the Crusaders, besieging Darum in 1170. Amalric withdrew his Templar garrison from Gaza to assist him in defending Darum, but Saladin evaded their force and fell on Gaza instead. He destroyed the town built outside the city's castle and killed most of its inhabitants after they were refused entry into the castle. It is unclear exactly when, but during that same year, he attacked and captured the Crusader castle of Eilat, built on an island off the head of the Gulf of Aqaba. It did not pose a threat to the passage of the Muslim navy, but could harass smaller parties of Muslim ships and Saladin decided to clear it from his path.
Sultan of Egypt.
According to Imad ad-Din, Nur ad-Din wrote to Saladin in June 1171, telling him to reestablish the Abbasid caliphate in Egypt, which Saladin coordinated two months later after additional encouragement by Najm ad-Din al-Khabushani, the Shafi'i "faqih", who vehemently opposed Shia rule in the country. Several Egyptian "emirs" were thus killed, but al-Adid was told that they were killed for rebelling against him. He then fell ill, or was poisoned according to one account. While ill, he asked Saladin to pay him a visit to request that he take care of his young children, but Saladin refused, fearing treachery against the Abbasids, and is said to have regretted his action after realizing what al-Adid had wanted. He died on September 13 and five days later, the Abbasid "khutba" was pronounced in Cairo and al-Fustat, proclaiming al-Mustadi as caliph.
On 25 September, Saladin left Cairo to take part in a joint attack on Kerak and Montreal, the desert castles of the Kingdom of Jerusalem, with Nur ad-Din who would attack from Syria. Prior to arriving at Montreal, Saladin however withdrew back to Cairo as he received the reports that in his absence the Crusader Leaders had increased their support to the traitors inside Egypt to attack Saladin from within and lessen his power especially the Fatimid who started plotting to restore their past glory. Because of this,Nur ad-Din went on alone.
During the summer of 1173, a Nubian army along with a contingent of Armenian refugees were reported on the Egyptian border, preparing for a siege against Aswan. The "emir" of the city had requested Saladin's assistance and was given reinforcements under Turan-Shah—Saladin's brother. Consequently, the Nubians departed, but returned in 1173 and were again driven off. This time Egyptian forces advanced from Aswan and captured the Nubian town of Ibrim. Saladin sent a gift to Nur ad-Din who had been his friend and teacher, 60,000 dinars, "wonderful manufactured goods", some jewels, an ass of the finest breed, and an elephant. While transporting these goods to Damascus, Saladin took the opportunity to ravage the Crusader countryside. He did not press an attack against the desert castles, but attempted to drive out the Muslim Bedouins who lived in Crusader territory with the aim of depriving the Franks of guides.
On 31 July 1173, Saladin's father Ayyub was wounded in a horse-riding accident, ultimately causing his death on 9 August. In 1174, Saladin sent Turan-Shah to conquer Yemen to allocate it and its port Aden to the territories of the Ayyubid Dynasty.
Acquisition of Syria.
Capture of Damascus.
In the March of 1174, Nur ad-Din returned to Baghdad in the wake of an intense earthquake which many historians claim was one of the most destructive ones in history.He was a "ruler of the people" and so he returned the moment he heard of the calamity.Also some of his enemies were taking advantage of his absence and this may have played a role in his decision to return.During the next weeks all of his attention was focussed on his people to the extent that he ignored the danger to himself from the traitors and Hassan bin Sabah's Group who were supported by Crusaders. At the end of April 1174 the first hint of trouble started as Nur ad-Din complained of pain in his throat after being poisoned. Despite the best efforts of his physicians his health deteriorated until he died on 15 May 1174. Nur ad-Din's power was handed to his eleven-year-old son as-Salih Ismail al-Malik by a group of powerful nobles who wanted to control his empire. His death left Saladin without a powerful ally in his war against Crusaders and in a letter to as-Salih, he promised to fight against his enemies even if they claimed to be muslims unless he and his supporters refrained from allying themselves with Crusaders against Nur ad-Din's policies.
In the wake of Nur ad-Din's death, Saladin faced a difficult decision; he could move his army against the Crusaders from Egypt or wait until invited by as-Salih in Syria to come to his aid and launch a war from there. He could also take it upon himself to annex Syria before it could possibly fall into the hands of a rival, but feared that attacking a land that formerly belonged to his master—which is forbidden in the Islamic principles he followed—could portray him as hypocritical and thus, unsuitable for leading the war against the Crusaders. Saladin saw that in order to acquire Syria, he either needed an invitation from as-Salih or warn him that potential anarchy could rise danger from the Crusaders.
When as-Salih was removed to Aleppo in August, Gumushtigin, the "emir" of the city and a captain of Nur ad-Din's veterans assumed guardianship over him. The "emir" prepared to unseat all of his rivals in Syria and al-Jazira, beginning with Damascus. In this emergency, the "emir" of Damascus appealed to Saif al-Din (a cousin of Gumushtigin) of Mosul for assistance against Aleppo, but he refused, forcing the Syrians to request the aid of Saladin who complied. Saladin rode across the desert with 700 picked horsemen, passing through al-Kerak then reaching Bosra and according to him, was joined by ""emirs", soldiers, and Bedouins—the emotions of their hearts to be seen on their faces." On 23 November, he arrived in Damascus amid general acclamations and rested at his father's old home there, until the gates of the Citadel of Damascus were opened to him four days later. He installed himself in the castle and received the homage and salutations of the citizens.
Leaving his brother Tughtigin as Governor of Damascus, Saladin proceeded to reduce other cities that had belonged to Nur al-Din, but were now practically independent. His army conquered Hamah with relative ease, but avoided attacking Homs because of the strength of its citadel. Saladin moved north towards Aleppo, besieging it on December 30 after Gumushtigin refused to abdicate his throne. As-Salih, fearing capture by Saladin, came out of his palace and appealed to the inhabitants not to surrender him and the city to the invading force. One of Saladin's chroniclers claimed "the people came under his spell."
Gumushtigin requested from Rashid ad-Din Sinan, grand-master of the Assassins of Syria, who were already at odds with Saladin since he replaced the Fatimids of Egypt, to assassinate Saladin in his camp. On 11 May 1175 a group of thirteen Assassins easily gained admission into Saladin's camp, but were detected immediately before they carried out their attack by Nasih al-Din Khumartekin of Abu Qubays. One was killed by a general of Saladin and the others were slain while trying to escape. To deter Saladin's progress, Raymond of Tripoli gathered his forces by Nahr al-Kabir where they were well placed for an attack on Muslim territory. Saladin later moved toward Homs instead, but retreated after being told a relief force was being sent to the city by Saif al-Din.
Meanwhile, Saladin's rivals in Syria and Jazira waged a propaganda war against him, claiming he had "forgotten his own condition [servant of Nur ad-Din]" and showed no gratitude for his old master by besieging his son, rising "in rebellion against his Lord." Saladin aimed to counter this propaganda by ending the siege, claiming he was defending Islam from the Crusaders; his army returned to Hama to engage a Crusader force there. The Crusaders withdrew beforehand and Saladin proclaimed it "a victory opening the gates of men's hearts." Soon after, Saladin entered Homs and captured its citadel in March 1175, after stubborn resistance from its defenders.
Saladin's successes alarmed Saif al-Din. As head of the Zengids, including Gumushtigin, he regarded Syria and Mesopotamia as his family estate and was angered when Saladin attempted to usurp his dynasty's holdings. Saif al-Din mustered a large army and dispatched it to Aleppo whose defenders anxiously had awaited them. The combined forces of Mosul and Aleppo marched against Saladin in Hama. Heavily outnumbered, Saladin initially attempted to make terms with the Zengids by abandoning all conquests north of the Damascus province, but they refused, insisting he return to Egypt. Seeing that confrontation was unavoidable, Saladin prepared for battle, taking up a superior position on the hills by the gorge of the Orontes River. On 13 April 1175, the Zengid troops marched to attack his forces, but soon found themselves surrounded by Saladin's Ayyubid veterans who crushed them. The battle ended in a decisive victory for Saladin who pursued the Zengid fugitives to the gates of Aleppo, forcing as-Salih's advisers to recognize Saladin's control of the provinces of Damascus, Homs and Hama, as well as a number of towns outside Aleppo such as Ma'arat al-Numan.
After his victory against the Zengids, Saladin proclaimed himself king and suppressed the name of as-Salih in Friday prayers and Islamic coinage. From then on, he ordered prayers in all the mosques of Syria and Egypt as the sovereign king and he issued at the Cairo mint gold coins bearing his official title—"al-Malik an-Nasir Yusuf Ayyub, ala ghaya" "the King Strong to Aid, Joseph son of Job; exalted be the standard." The Abbasid caliph in Baghdad graciously welcomed Saladin's assumption of power and declared him "Sultan of Egypt and Syria." The Battle of Hama did not end the contest for power between the Ayyubids and the Zengids, with the final confrontation occurring in the spring of 1176. Saladin had gathered massive reinforcements from Egypt while Saif al-Din was levying troops among the minor states of Diyarbakir and al-Jazira. When Saladin crossed the Orontes, leaving Hama, the sun was eclipsed. He viewed this as an omen, but he continued his march north. He reached the Sultan's Mound, c. 25 km from Aleppo, where his forces encountered Saif al-Din's army. A hand-to-hand fight ensued and the Zengids managed to plow Saladin's left wing, driving it before him, when Saladin himself charged at the head of the Zengid guard. The Zengid forces panicked and most of Saif al-Din's officers ended up being killed or captured—Saif al-Din narrowly escaped. The Zengid army's camp, horses, baggage, tents and stores were seized by the Ayyubids. The Zengid prisoners of war, however, were given gifts and freed. All of the booty from the Ayyubid victory was accorded to the army, Saladin not keeping anything himself.
He continued towards Aleppo which still closed its gates to him, halting before the city. On the way, his army took Buza'a, then captured Manbij. From there they headed west to besiege the fortress of A'zaz on 15 May. Several days later, while Saladin was resting in one of his captain's tents, an assassin rushed forward at him and struck at his head with a knife. The cap of his head armour was not penetrated and he managed to grip the assassin's hand—the dagger only slashing his gambeson—and the assailant was soon killed. Saladin was unnerved at the attempt on his life, which he accused Gumushtugin and the Assassins of plotting, and so increased his efforts in the siege.
A'zaz capitulated on 21 June, and Saladin then hurried his forces to Aleppo to punish Gumushtigin. His assaults were again resisted, but he managed to secure not only a truce, but a mutual alliance with Aleppo, in which Gumushtigin and as-Salih were allowed to continue their hold on the city and in return, they recognized Saladin as the sovereign over all of the dominions he conquered. The "emirs" of Mardin and Keyfa, the Muslim allies of Aleppo, also recognised Saladin as the King of Syria. When the treaty was concluded, the younger sister of as-Salih came to Saladin and requested the return of the Fortress of A'zaz; he complied and escorted her back to the gates of Aleppo with numerous presents.
Dispute with the Assassins.
Saladin had by now agreed truces with his Zengid rivals and the Kingdom of Jerusalem (latter occurred in the summer of 1175), but faced a threat from the Ismaili sect known then as the "Assassins" led by Rashid ad-Din Sinan. Based in the an-Nusayriyah Mountains, they commanded nine fortresses, all built on high elevations. As soon as he dispatched the bulk of his troops to Egypt, Saladin led his army into the an-Nusayriyah range in August 1176. He retreated the same month, after laying waste to the countryside, but failing to conquer any of the forts. Most Muslim historians claim that Saladin's uncle, the governor of Hama, mediated a peace agreement between him and Sinan.
Assassins feared him when he attacked their hideout. He had his guards supplied with link lights and had chalk and cinders strewed around his tent outside Masyaf—which he was besieging—to detect any footsteps by the Assassins. According to this version, one night Saladin's guards noticed a spark glowing down the hill of Masyaf and then vanishing among the Ayyubid tents. Presently, Saladin awoke to find a figure leaving the tent. He saw that the lamps were displaced and beside his bed laid hot scones of the shape peculiar to the Assassins with a note at the top pinned by a poisoned dagger. The note threatened that he would be killed if he didn't withdraw from his assault. Saladin gave a loud cry, exclaiming that Sinan himself was the figure that had left the tent.
Another version claims that Saladin hastily withdrew his troops from Masyaf because they were urgently needed to fend off a Crusader force in the vicinity of Mount Lebanon. Assassins sought to form an alliance with him, consequently depriving the Crusaders of a potent ally against him. Viewing the expulsion of the Crusaders as a mutual benefit and priority, Saladin and Sinan maintained cooperative relations afterwards, the latter dispatching contingents of his forces to bolster Saladin's army in a number of decisive subsequent battlefronts.
Return to Cairo and forays in Outremer.
After leaving the an-Nusayriyah Mountains, Saladin returned to Damascus and had his Syrian soldiers return home. He left Turan Shah in command of Syria and left for Egypt with only his personal followers, reaching Cairo on 22 September. Having been absent roughly two years, he had much to organize and supervise in Egypt, namely fortifying and reconstructing Cairo. The city walls were repaired and their extensions laid out, while the construction of the Cairo Citadel was commenced. The 280 ft deep Bir Yusuf ("Joseph's Well") was built on Saladin's orders. The chief public work he commissioned outside of Cairo was the large bridge at Giza, which was intended to form an outwork of defense against a potential Moorish invasion.
Saladin remained in Cairo supervising its improvements, building colleges such as the Madrasa of the Sword Makers and ordering the internal administration of the country. In November 1177, he set out upon a raid into Palestine; the Crusaders had recently forayed into the territory of Damascus, so Saladin saw the truce as no longer worth preserving. The Christians sent a large portion of their army to besiege the fortress of Harim north of Aleppo, so southern Palestine bore few defenders. Saladin found the situation ripe and marched to Ascalon, which he referred to as the "Bride of Syria." William of Tyre recorded that the Ayyubid army consisted of soldiers, of which 8,000 were elite forces and were black soldiers from Sudan. This army proceeded to raid the countryside, sack Ramla and Lod, and dispersed themselves as far as the Gates of Jerusalem.
Battles and truce with Baldwin.
The Ayyubids allowed King Baldwin to enter Ascalon with his Gaza-based Templars without taking any precautions against a sudden attack. Although the Crusader force consisted of only 375 knights, Saladin hesitated to ambush them because of the presence of highly skilled generals. On 25 November, while the greater part of the Ayyubid army was absent, Saladin and his men were surprised near Ramla in the battle of Montgisard. Before they could form up, the Templar force hacked the Ayyubid army down. Initially, Saladin attempted to organize his men into battle order, but as his bodyguards were being killed, he saw that defeat was inevitable and so with a small remnant of his troops mounted a swift camel, riding all the way to the territories of Egypt.
Undiscouraged by his defeat at Tell Jezer, Saladin was prepared to fight the Crusaders once again. In the spring of 1178, he was encamped under the walls of Homs, and a few skirmishes occurred between his generals and the Crusader army. His forces in Hama won a victory over their enemy and brought the spoils, together with many prisoners of war, to Saladin who ordered the captives to be beheaded for "plundering and laying waste the lands of the Faithful." He spent the rest of the year in Syria without a confrontation with his enemies.
Saladin's intelligence services reported to him that the Crusaders were planning a raid into Syria. He ordered one of his generals, Farrukh-Shah, to guard the Damascus frontier with a thousand of his men to watch for an attack, then to retire, avoiding battle, and to light warning beacons on the hills, after which Saladin would march out. In April 1179, the Crusaders led by King Baldwin expected no resistance and waited to launch a surprise attack on Muslim herders grazing their herds and flocks east of the Golan Heights. Baldwin advanced too rashly in pursuit of Farrukh-Shah's force, which was concentrated southeast of Quneitra and was subsequently defeated by the Ayyubids. With this victory, Saladin decided to call in more troops from Egypt; he requested al-Adil to dispatch 1,500 horsemen.
In the summer of 1179, King Baldwin had set up an outpost on the road to Damascus and aimed to fortify a passage over the Jordan River, known as Jacob's Ford, that commanded the approach to the Banias plain (the plain was divided by the Muslims and the Christians). Saladin had offered 100,000 gold pieces for Baldwin to abandon the project, which was peculiarly offensive to the Muslims, but to no avail. He then resolved to destroy the fortress, called Chastellet and manned by the Templars, moving his headquarters to Banias. As the Crusaders hurried down to attack the Muslim forces, they fell into disorder, with the infantry falling behind. Despite early success, they pursued the Muslims far enough to become scattered, and Saladin took advantage by rallying his troops and charged at the Crusaders. The engagement ended in a decisive Ayyubid victory, and many high-ranking knights were captured. Saladin then moved to besiege the fortress, which fell on 30 August 1179.
In the spring of 1180, while Saladin was in the area of Safad, anxious to commence a vigorous campaign against the Kingdom of Jerusalem, King Baldwin sent messengers to him with proposals of peace. Because droughts and bad harvests hampered his commissariat, Saladin agreed to a truce. Raymond of Tripoli denounced the truce but was compelled to accept after an Ayyubid raid on his territory in May and upon the appearance of Saladin's naval fleet off the port of Tartus.
Domestic affairs.
In June 1180, Saladin hosted a reception for Nur al-Din Muhammad, the Artuqid "emir" of Keyfa, at Geuk Su, in which he presented him and his brother Abu Bakr presents, valued at over 100,000 dinars according to Imad al-Din. This was intended to cement an alliance with the Artuqids and to impress other "emirs" in Mesopotamia and Anatolia. Previously, Saladin offered to mediate relations between Nur al-Din and Kilij Arslan II—the Seljuk Sultan of Rum—after the two came into conflict. The latter demanded Nur al-Din return the lands given to him as a dowry for marrying his daughter when he received reports that she was being abused and used by him to gain Seljuk territory. Nur al-Din requested Saladin mediate the issue but Arslan refused.
After Nur al-Din and Saladin met at Geuk Su, the top Seljuk "emir", Ikhtiyar al-Din al-Hasan, confirmed Arslan's submission, after which an agreement was drawn up. Saladin was later enraged when he received a message from Arslan accusing Nur al-Din of more abuses against his daughter. He threatened to attack the city of Malatya, saying, "it is two days march for me and I shall not dismount [my horse] until I am in the city." Alarmed at the threat, the Seljuks pushed for negotiations. Saladin felt that Arslan was correct to care for his daughter, but Nur al-Din had taken refuge with him, and therefore he could not betray his trust. It was finally agreed that Arslan's daughter would be sent away for a year and if Nur al-Din failed to comply, Saladin would move to abandon his support for him.
Leaving Farrukh-Shah in charge of Syria, Saladin returned to Cairo at the beginning of 1181. According to Abu Shama, he intended to spend the fast of Ramadan in Egypt and then make the "hajj" pilgrimage to Mecca in the summer. For an unknown reason he apparently changed his plans regarding the pilgrimage and was seen inspecting the Nile River banks in June. He was again embroiled with the Bedouin; he removed two-thirds of their fiefs to use as compensation for the fief-holders at Fayyum. The Bedouin were also accused of trading with the Crusaders and consequently, their grain was confiscated and they were forced to migrate westward. Later, Ayyubid warships were waged against Bedouin river pirates who were plundering the shores of Lake Tanis.
In the summer of 1181, Saladin's former palace administrator Qara-Qush led a force to arrest Majd al-Din—a former deputy of Turan-Shah in the Yemeni town of Zabid—while he was entertaining Imad ad-Din at his estate in Cairo. Saladin's intimates accused Majd al-Din of misappropriating the revenues of Zabid, but Saladin himself believed there was no evidence to back the allegations. He had Majd al-Din released in return for a payment of 80,000 dinars. In addition, other sums were to be paid to Saladin's brothers al-Adil and Taj al-Muluk Buri. The controversial detainment of Majd al-Din was a part of the larger discontent associated with the aftermath of Turan-Shah's departure from Yemen. Although his deputies continued to send him revenues from the province, centralized authority was lacking and internal quarrel arose between Izz al-Din Uthman of Aden and Hittan of Zabid. Saladin wrote in a letter to al-Adil: "this Yemen is a treasure house ... We conquered it, but up to this day we have had no return and no advantage from it. There have been only innumerable expenses, the sending out of troops ... and expectations which did not produce what was hoped for in the end."
Imperial expansions.
Conquest of Mesopotamian hinterland.
Saif al-Din had died earlier in June 1181 and his brother Izz al-Din inherited leadership of Mosul. On December 4, the crown-prince of the Zengids, as-Salih, died in Aleppo. Prior to his death, he had his chief officers swear an oath of loyalty to Izz al-Din, as he was the only Zengid ruler strong enough to oppose Saladin. Izz al-Din was welcomed in Aleppo, but possessing it and Mosul put too great of a strain on his abilities. He thus, handed Aleppo to his brother Imad al-Din Zangi, in exchange for Sinjar. Saladin offered no opposition to these transactions in order to respect the treaty he previously made with the Zengids.
On May 11, 1182, Saladin along with half of the Egyptian Ayyubid army and numerous non-combatants left Cairo for Syria. On the evening before he departed, he sat with his companions and the tutor of one of his sons quoted a line of poetry: "enjoy the scent of the ox-eye plant of Najd, for after this evening it will come no more." Saladin took this as an evil omen and he never saw Egypt again. Knowing that Crusader forces were massed upon the frontier to intercept him, he took the desert route across the Sinai Peninsula to Ailah at the head of the Gulf of Aqaba. Meeting no opposition, Saladin ravaged the countryside of Montreal, whilst Baldwin's forces watched on, refusing to intervene. He arrived in Damascus in June to learn that Farrukh-Shah had attacked the Galilee, sacking Daburiyya and capturing Habis Jaldek, a fortress of great importance to the Crusaders. In July, Saladin dispatched Farrukh-Shah to attack Kawkab al-Hawa. Later, in August, the Ayyubids launched a naval and ground assault to capture Beirut; Saladin led his army in the Bekaa Valley. The assault was leaning towards failure and Saladin abandoned the operation to focus on issues in Mesopotamia.
Kukbary (Gökböri), the "emir" of Harran, invited Saladin to occupy the Jazira region, making up northern Mesopotamia. He complied and the truce between him and the Zengids officially ended in September 1182. Prior to his march to Jazira, tensions had grown between the Zengid rulers of the region, primarily concerning their unwillingness to pay deference to Mosul. Before he crossed the Euphrates, Saladin besieged Aleppo for three days, signaling that the truce was over.
Once he reached Bira, near the river, he was joined by Kukbary and Nur al-Din of Hisn Kayfa and the combined forces captured the cities of Jazira, one after the other. First, Edessa fell, followed by Saruj, then ar-Raqqah, Karkesiya and Nusaybin. Ar-Raqqah was an important crossing point and held by Qutb al-Din Inal, who had lost Manbij to Saladin in 1176. Upon seeing the large size of Saladin's army, he made little effort to resist and surrendered on the condition that he would retain his property. Saladin promptly impressed the inhabitants of the town by publishing a decree that ordered a number of taxes to be canceled and erased all mention of them from treasury records, stating "the most miserable rulers are those whose purses are fat and their people thin." From ar-Raqqah, he moved to conquer al-Fudain, al-Husain, Maksim, Durain, 'Araban, and Khabur—all of which swore allegiance to him.
Saladin proceeded to take Nusaybin which offered no resistance. A medium-sized town, Nusaybin was not of great importance, but it was located in a strategic position between Mardin and Mosul and within easy reach of Diyarbakir. In the midst of these victories, Saladin received word that the Crusaders were raiding the villages of Damascus. He replied "Let them... whilst they knock down villages, we are taking cities; when we come back, we shall have all the more strength to fight them." Meanwhile, in Aleppo, the "emir" of the city Zangi raided Saladin's cities to the north and east, such as Balis, Manbij, Saruj, Buza'a, al-Karzain. He also destroyed his own citadel at A'zaz to prevent it from being used by the Ayyubids if they were to conquer it.
Possession of Aleppo.
Saladin turned his attention from Mosul to Aleppo, sending his brother Taj al-Muluk Buri to capture Tell Khalid, 130 km northeast of the city. A siege was set, but the governor of Tell Khalid surrendered upon the arrival of Saladin himself on May 17 before a siege could take place. According to Imad ad-Din, after Tell Khalid, Saladin took a detour northwards to Ain Tab, but he gained possession of it when his army turned towards it, allowing to quickly move backward another c. 100 km towards Aleppo. On May 21, he camped outside the city, positioning himself east of the Citadel of Aleppo, while his forces encircles the suburb of Banaqusa to the northeast and Bab Janan to the west. He stationed his men dangerously close to the city, hoping for an early success.
Zangi did not offer long resistance. He was unpopular with his subjects and wished to return to his Sinjar, the city he governed previously. An exchange was negotiated where Zangi would hand over Aleppo to Saladin in return for the restoration of his control of Sinjar, Nusaybin, and ar-Raqqa. Zangi would hold these territories as Saladin's vassals on terms of military service. On June 12, Aleppo was formally placed in Ayyubid hands. The people of Aleppo had not known about these negotiations and were taken by surprise when Saladin's standard was hoisted over the citadel. Two "emir"s, including an old friend of Saladin, Izz al-Din Jurduk, welcomed and pledged their service to him. Saladin replaced the Hanafi courts with Shafi'i administration, despite a promise he would not interfere in the religious leadership of the city. Although he was short of money, Saladin also allowed the departing Zangi to take all the stores of the citadel that he could travel with and to sell the remainder—which Saladin purchased himself. In spite of his earlier hesitation to go through with the exchange, he had no doubts about his success, stating that Aleppo was "the key to the lands" and "this city is the eye of Syria and the citadel is its pupil." For Saladin, the capture of the city marked the end of over eight years of waiting since he told Farrukh-Shah that "we have only to do the milking and Aleppo will be ours".
After spending one night in Aleppo's citadel, Saladin marched to Harim, near the Crusader-held Antioch. The city was held by Surhak, a "minor "mamluk"." Saladin offered him the city of Busra and property in Damascus in exchange for Harim, but when Surhak asked for more, his own garrison in Harim forced him out. He was arrested by Saladin's deputy Taqi al-Din on allegations that he was planning to cede Harim to Bohemond III of Antioch. When Saladin received its surrender, he proceeded to arrange the defense of Harim from the Crusaders. He reported to the caliph and his own subordinates in Yemen and Baalbek that was going to attack the Armenians. Before he could move, however, there were a number of administrative details to be settled. Saladin agreed to a truce with Bohemond in return for Muslim prisoners being held by him and then he gave A'zaz to Alam ad-Din Suleiman and Aleppo to Saif al-Din al-Yazkuj—the former was an "emir" of Aleppo who joined Saladin and the latter was a former "mamluk" of Shirkuh who helped rescue him from the assassination attempt at A'zaz.
Fight for Mosul.
As Saladin approached Mosul, he faced the issue of taking over a large city and justifying the action. The Zengids of Mosul appealed to an-Nasir, the Abbasid caliph at Baghdad whose vizier favored them. An-Nasir sent Badr al-Badr (a high-ranking religious figure) to mediate between the two sides. Saladin arrived at the city on 10 November 1182. Izz al-Din would not accept his terms because he considered them disingenuous and extensive, and Saladin immediately laid siege to the heavily fortified city.
After several minor skirmishes and a stalemate in the siege that was initiated by the caliph, Saladin intended to find a way to withdraw without damage to his reputation while still keeping up some military pressure. He decided to attack Sinjar, which was held by Izz al-Din's brother Sharaf al-Din. It fell after a 15-day siege on December 30. Saladin's commanders and soldiers broke their discipline, plundering the city; Saladin only managed to protect the governor and his officers by sending them to Mosul. After establishing a garrison at Sinjar, he awaited a coalition assembled by Izz al-Din consisting of his forces, those from Aleppo, Mardin, and Armenia. Saladin and his army met the coalition at Harran in February 1183, but on hearing of his approach, the latter sent messengers to Saladin asking for peace. Each force returned to their cities and al-Fadil wrote: "They [Izz al-Din's coalition] advanced like men, like women they vanished." 
On 2 March, al-Adil from Egypt wrote to Saladin that the Crusaders had struck the "heart of Islam." Raynald de Châtillon had sent ships to the Gulf of Aqaba to raid towns and villages off the coast of the Red Sea. It was not an attempt to extend the Crusader influence into that sea or to capture its trade routes, but merely a piratical move. Nonetheless, Imad al-Din writes the raid was alarming to the Muslims because they were not accustomed to attacks on that sea, and Ibn al-Athir adds that the inhabitants had no experience with the Crusaders either as fighters or traders.
Ibn Jubair was told that sixteen Muslim ships were burnt by the Crusaders who then captured a pilgrim ship and caravan at Aidab. He also reported they intended to attack Medina and remove Muhammad's body. Al-Maqrizi added to the rumor by claiming Muhammad's tomb was going to be relocated to Crusader territory so Muslims would make pilgrimages there. Fortunately for Saladin, al-Adil had his warships moved from Fustat and Alexandria to the Red Sea under the command of an Armenian mercenary Lu'lu. They broke the Crusader blockade, destroyed most of their ships, and pursued and captured those who anchored and fled into the desert. The surviving Crusaders, numbered at 170, were ordered to be killed by Saladin in various Muslim cities.
From the point of view of Saladin, in terms of territory, the war against Mosul was going well, but he still failed to achieve his objectives and his army was shrinking; Taqi al-Din took his men back to Hama, while Nasir al-Din Muhammad and his forces had left. This encouraged Izz al-Din and his allies to take the offensive. The previous coalition regrouped at Harzam some 140 km from Harran. In early April, without waiting for Nasir al-Din, Saladin and Taqi al-Din commenced their advance against the coalition, marching eastward to Ras al-Ein unhindered. By late April, after three days of "actual fighting", according to Saladin, the Ayyubids had captured Amid. He handed the city to Nur al-Din Muhammad together with its stores, which consisted of 80,000 candles, a tower full of arrowheads, and 1,040,000 books. In return for a diploma granting him the city, Nur al-Din swore allegiance to Saladin, promising to follow him in every expedition in the war against the Crusaders, and repairing damage done to the city. The fall of Amid, in addition to territory, convinced Il-Ghazi of Mardin to enter the service of Saladin, weakening Izz al-Din's coalition.
Saladin attempted to gain the Caliph an-Nasir's support against Izz al-Din by sending him a letter requesting a document that would give him legal justification for taking over Mosul and its territories. Saladin aimed to persuade the caliph claiming that while he conquered Egypt and Yemen under the flag of the Abbasids, the Zengids of Mosul openly supported the Seljuks (rivals of the caliphate) and only came to the caliph when in need. He also accused Izz al-Din's forces of disrupting the Muslim "Holy War" against the Crusaders, stating "they are not content not to fight, but they prevent those who can." Saladin defended his own conduct claiming that he had come to Syria to fight the Crusaders, end the heresy of the Assassins, and stop the wrong-doing of the Muslims. He also promised that if Mosul was given to him, it would lead to the capture of Jerusalem, Constantinople, Georgia, and the lands of the Almohads in the Maghreb, "until the word of God is supreme and the Abbasid caliphate has wiped the world clean, turning the churches into mosques." Saladin stressed that all this would happen by the will of God, and instead of asking for financial or military support from the caliph, he would capture and give the caliph the territories of Tikrit, Daquq, Khuzestan, Kish Island, and Oman.
Wars against Crusaders.
On 29 September 1182, Saladin crossed the Jordan River to attack Beisan, which was found to be empty. The next day his forces sacked and burned the town and moved westwards. They intercepted Crusader reinforcements from Karak and Shaubak along the Nablus road and took a number of prisoners. Meanwhile, the main Crusader force under Guy of Lusignan moved from Sepphoris to al-Fula. Saladin sent out 500 skirmishers to harass their forces, and he himself marched to Ain Jalut. When the Crusader force—reckoned to be the largest the kingdom ever produced from its own resources, but still outmatched by the Muslims—advanced, the Ayyubids unexpectedly moved down the stream of Ain Jalut. After a few Ayyubid raids—including attacks on Zir'in, Forbelet, and Mount Tabor—the Crusaders still were not tempted to attack their main force, and Saladin led his men back across the river once provisions and supplies ran low.
Crusader attacks provoked further responses by Saladin. Raynald of Châtillon, in particular, harassed Muslim trading and pilgrimage routes with a fleet on the Red Sea, a water route that Saladin needed to keep open. In response, Saladin built a fleet of 30 galleys to attack Beirut in 1182. Raynald threatened to attack the holy cities of Mecca and Medina. In retaliation, Saladin twice besieged Kerak, Raynald's fortress in Oultrejordain, in 1183 and 1184. Raynald responded by looting a caravan of pilgrims on the Hajj in 1185. According to the later 13th-century "Old French Continuation of William of Tyre", Raynald captured Saladin's sister in a raid on a caravan; this claim is not attested in contemporary sources, Muslim or Frankish, however, instead stating that Raynald had attacked a preceding caravan, and Saladin set guards to ensure the safety of his sister and her son, who came to no harm.
Following the failure of his Kerak sieges, Saladin temporarily turned his attention back to another long-term project and resumed attacks on the territory of ʻIzz ad-Dīn (Masʻūd ibn Mawdūd ibn Zangi), around Mosul, which he had begun with some success in 1182. However, since then, Masʻūd had allied himself with the powerful governor of Azerbaijan and Jibal, who in 1185 began moving his troops across the Zagros Mountains, causing Saladin to hesitate in his attacks. The defenders of Mosul, when they became aware that help was on the way, increased their efforts, and Saladin subsequently fell ill, so in March 1186 a peace treaty was signed.
In July 1187 Saladin captured most of the Kingdom of Jerusalem. On July 4, 1187, at the Battle of Hattin, he faced the combined forces of Guy of Lusignan, King Consort of Jerusalem, and Raymond III of Tripoli. In this battle alone the Crusader force was largely annihilated by Saladin's determined army. It was a major disaster for the Crusaders and a turning point in the history of the Crusades. Saladin captured Raynald and was personally responsible for his execution in retaliation for his attacks against Muslim caravans. The members of these caravans had, in vain, besought his mercy by reciting the truce between the Muslims and the Crusaders, but Raynald ignored this and insulted the Islamic prophet, Muhammad, before murdering and torturing a number of them. Upon hearing this, Saladin swore an oath to personally execute Raynald. Guy of Lusignan was also captured. Seeing the execution of Raynald, he feared he would be next. However, his life was spared by Saladin, who said of Raynald, "[i]t is not the wont of kings, to kill kings; but that man had transgressed all bounds, and therefore did I treat him thus." 
Capture of Jerusalem.
Saladin had captured almost every Crusader city. Saladin preferred to take Jerusalem without bloodshed and offered generous terms, but those inside refused to leave their holy city, vowing to destroy it in a fight to the death rather than see it handed over peacefully. Jerusalem capitulated to his forces on Friday, 2 October 1187, after a siege. When the siege had started, Saladin was unwilling to promise terms of quarter to the Frankish inhabitants of Jerusalem. Balian of Ibelin threatened to kill every Muslim hostage, estimated at 5,000, and to destroy Islam's holy shrines of the Dome of the Rock and the al-Aqsa Mosque if such quarter were not provided. Saladin consulted his council and the terms were accepted. The agreement was read out through the streets of Jerusalem so that everyone might within forty days provide for himself and pay to Saladin the agreed tribute for his freedom. An unusually low ransom for the times (around $50 today) was to be paid for each Frank in the city, whether man, woman, or child, but Saladin, against the wishes of his treasurers, allowed many families who could not afford the ransom to leave. Patriarch Heraclius of Jerusalem organised and contributed to a collection that paid the ransoms for about 18,000 of the poorer citizens, leaving another 15,000 to be enslaved. Saladin's brother al-Adil "asked Saladin for a thousand of them for his own use and then released them on the spot." Most of the foot soldiers were sold into slavery. Upon the capture of Jerusalem, Saladin summoned the Jews and permitted them to resettle in the city. In particular, the residents of Ashkelon, a large Jewish settlement, responded to his request.
Tyre, on the coast of modern-day Lebanon, was the last major Crusader city that was not captured by Muslim forces. Strategically, it would have made more sense for Saladin to capture Tyre before Jerusalem; Saladin, however, chose to pursue Jerusalem first because of the importance of the city to Islam. Tyre was commanded by Conrad of Montferrat, who strengthened its defences and withstood two sieges by Saladin. In 1188, at Tortosa, Saladin released Guy of Lusignan and returned him to his wife, Queen Sibylla of Jerusalem. They went first to Tripoli, then to Antioch. In 1189, they sought to reclaim Tyre for their kingdom but were refused admission by Conrad, who did not recognize Guy as king. Guy then set about besieging Acre.
Saladin was on friendly terms with Queen Tamar of Georgia. Saladin's biographer Bahā' ad-Dīn ibn Šaddād reports that, after Saladin's conquest of Jerusalem, the Georgian Queen sent envoys to the sultan to request the return of confiscated possessions of the Georgian monasteries in Jerusalem. Saladin's response is not recorded, but the queen's efforts seem to have been successful as Jacques de Vitry, the Bishop of Acre, reports the Georgians were, in contrast to the other Christian pilgrims, allowed a free passage into the city with their banners unfurled. Ibn Šaddād furthermore claims that Queen Tamar outbid the Byzantine emperor in her efforts to obtain the relics of the True Cross, offering 200,000 gold pieces to Saladin who had taken the relics as booty at the battle of Hattin, but to no avail.
Third Crusade.
It is equally true that his generosity, his piety, devoid of fanaticism, that flower of liberality and courtesy which had been the model of our old chroniclers, won him no less popularity in Frankish Syria than in the lands of Islam.
"René Grousset (writer)"
Hattin and the fall of Jerusalem prompted the Third Crusade (1189–1192), financed in England by a special "Saladin tithe". Richard the Lionheart, King of England led Guy's siege of Acre, conquered the city and executed 3,000 Muslim prisoners, including women and children. Bahā' ad-Dīn wrote:The motives of this massacre are differently told; according to some, the captives were slain by way of reprisal for the death of those Christians whom the Musulmans had slain. Others again say that the king of England, on deciding to attempt the conquest of Ascalon, thought it unwise to leave so many prisoners in the town after his departure. God alone knows what the real reason was.
The armies of Saladin engaged in combat with the army of King Richard at the Battle of Arsuf on 7 September 1191, at which Saladin's forces,less in number, suffered heavy losses and were forced to withdraw. After the battle of Arsuf, Richard moved his forces towards Ascalon. Anticipating Richard's next move, Saladin emptied the city and camped a few miles away. When Richard arrived at the city, he was stunned to see it abandoned and the towers demolished. The next day when Richard was preparing to retreat to Jaffa, Saladin attacked his army. After a furious battle, Richard managed to save some of his troops and retreated to Ascalon. This was the last major battle between the two forces. All military attempts and battles made by Richard the Lionheart to retake Jerusalem were defeated and failed. Richard only had 2,000 fit soldiers and 50 fit knights to use in battle. With such a small force, he could not expect or hope to take Jerusalem although he got near enough to see the Holy City. Saladin's relationship with Richard was complicated despite their military rivalry. At Arsuf, when Richard lost his horse, Saladin sent him two replacements. Richard proposed that his sister, Joan of England, Queen of Sicily, should marry Saladin's brother and that Jerusalem could be their wedding gift. However, the two men never met face to face and communication was either written or by messenger. As leaders of their respective factions, the two men came to an agreement in the Treaty of Ramla in 1192, whereby Jerusalem would remain in Muslim hands but would be open to Christian pilgrimages. The treaty reduced the Latin Kingdom to a strip along the coast from Tyre to Jaffa.
Death.
Saladin died of a fever on 4 March 1193, at Damascus, not long after King Richard's departure. In Saladin’s possession at the time of his death were one piece of gold and forty pieces of silver. He had given away his great wealth to his poor subjects, leaving nothing to pay for his funeral. He was buried in a mausoleum in the garden outside the Umayyad Mosque in Damascus, Syria. Seven centuries later, Emperor Wilhelm II of Germany donated a new marble sarcophagus to the mausoleum. The original sarcophagus was not replaced, however. Instead, the mausoleum, which is open to visitors, now has two sarcophagi: the marble one placed on the side and the original wooden one, which covers Saladin's tomb. (Muslims are buried in a simple shroud, so if there are any sarcophagi present, they are usually used for covering the top of the Islamic burials.) 
Family.
According to Imad al-Din, Saladin had fathered five sons before he left Egypt in 1174. Saladin's oldest son, al-Afdal, was born in 1170, and Uthman was born in 1172 to Shamsa who accompanied Saladin to Syria. Saladin had a third son named, Az-Zahir Ghazi, who later became Lord of Aleppo. Al-Afdal's mother bore Saladin another child in 1177. A letter preserved by Qalqashandi records that a twelfth son was born in May 1178, while on Imad al-Din's list, he appears as Saladin's seventh son. Mas'ud was born in 1175 and Yaq'ub in 1176, the latter to Shamsa.
Recognition and legacy.
Western world.
Saladin achieved a great reputation in Europe as a chivalrous knight due to his fierce struggle against the crusaders and his generousity. Although Saladin faded into history after the Middle Ages, he appears in a sympathetic light in Gotthold Ephraim Lessing's play "Nathan the Wise" (1779) and in Sir Walter Scott's novel "The Talisman" (1825). The contemporary view of Saladin originates mainly from these texts. According to Jonathan Riley-Smith, Scott's portrayal of Saladin was that of a "modern [19th Century] liberal European gentlemen, beside whom medieval Westerners would always have made a poor showing." Despite the Crusaders' slaughter when they originally conquered Jerusalem in 1099, Saladin granted amnesty and free passage to all common Catholics and even to the defeated Christian army, as long as they were able to pay the aforementioned ransom (the Greek Orthodox Christians were treated even better, because they often opposed the western Crusaders). An interesting view of Saladin and the world in which he lived is provided by Tariq Ali's novel "The Book of Saladin".
Notwithstanding the differences in beliefs, the Muslim Saladin was respected by Christian lords, Richard especially. Richard once praised Saladin as a great prince, saying that he was without doubt the greatest and most powerful leader in the Islamic world. Saladin in turn stated that there was not a more honorable Christian lord than Richard. After the treaty, Saladin and Richard sent each other many gifts as tokens of respect but never met face to face. In April 1191, a Frankish woman's three-month-old baby had been stolen from her camp and had been sold on the market. The Franks urged her to approach Saladin herself with her grievance. According to Bahā' al-Dīn, Saladin used his own money to buy the child back:
He gave it to the mother and she took it; with tears streaming down her face, and hugged the baby to her chest. The people were watching her and weeping and I (Ibn Shaddad) was standing amongst them. She suckled it for some time and then Saladin ordered a horse to be fetched for her and she went back to camp.
At the end of World War I British Commander General Edmund Allenby had succeeded in capturing Damascus from Turkish troops. According to some sources, after his triumphal entry into the city, Allenby raised his sword in salute to the famous statue of Saladin and proudly declared, "Today the wars of the Crusaders are completed." This quotation was incorrectly attributed to Allenby, and throughout his life he vehemently protested against his conquest of Palestine in 1917 having been called a "Crusade." In 1933 Allenby reiterated this stance by saying: "The importance of Jerusalem lay in its strategic importance, there was no religious impulse in this campaign." The British press continued to celebrate his victory over the Ottoman Empire by printing cartoons of Richard the Lionheart looking down on Jerusalem from the heavens with the caption reading "At last my dream has come true."
Muslim world.
In 1898 German Emperor Wilhelm II visited Saladin's tomb to pay his respects. The visit, coupled with anti-imperialist sentiments, led nationalist Arabs to reinvent the image of Saladin and portray him as a hero of the struggle against the West. The image of Saladin they used was the romantic one created by Walter Scott and other Europeans in the West at the time, conveniently ignoring Saladin's Kurdish ethnicity. It replaced Saladin's reputation as a figure who had been largely forgotten in the Muslim world, eclipsed by more successful figures such as Baybars of Egypt.
Modern Arab states have sought to commemorate Saladin through various measures, often based on the image created of him in the 19th-century west. governorate centered around Tikrit and Samarra in modern-day Iraq, Salah ad Din Governorate, is named after him, as is Salahaddin University in Arbil, the largest city of Iraqi Kurdistan. A suburb community of Arbil, Masif Salahaddin, is also named after him.
Few structures associated with Saladin survive within modern cities. Saladin first fortified the Citadel of Cairo (1175–1183), which had been a domed pleasure pavilion with a fine view in more peaceful times. In Syria, even the smallest city is centred on a defensible citadel, and Saladin introduced this essential feature to Egypt.
Although the Ayyubid dynasty that he founded would only outlive him by 57 years, the legacy of Saladin within the Arab World continues to this day. With the rise of Arab nationalism in the 20th Century, particularly with regard to the Arab-Israeli conflict, Saladin's heroism and leadership gained a new significance. Saladin's recapture of Palestine from the European Crusaders is considered an inspiration for modern-day Arabs' opposition to Zionism. Moreover, the glory and comparative unity of the Arab World under Saladin was seen as the perfect symbol for the new unity sought by Arab nationalists, such as Gamal Abdel Nasser. For this reason, the Eagle of Saladin became the symbol of revolutionary Egypt, and was subsequently adopted by several other Arab states (the United Arab Republic, Iraq, Libya, the partially recognised State of Palestine, and Yemen).
Notes.
114.

</doc>
<doc id="26984" url="http://en.wikipedia.org/wiki?curid=26984" title="Sophocles">
Sophocles

Sophocles (; Greek: Σοφοκλῆς, "Sophoklēs", ]; 497/6 – winter 406/5 BC) is one of three ancient Greek tragedians whose plays have survived. His first plays were written later than those of Aeschylus, and earlier than or contemporary with those of Euripides. According to the "Suda", a 10th-century encyclopedia, Sophocles wrote 123 plays during the course of his life, but only seven have survived in a complete form: "Ajax", "Antigone", "The Women of Trachis", "Oedipus the King", "Electra", "Philoctetes" and "Oedipus at Colonus". For almost 50 years, Sophocles was the most-fêted playwright in the dramatic competitions of the city-state of Athens that took place during the religious festivals of the Lenaea and the Dionysia. He competed in around 30 competitions, won perhaps 24, and was never judged lower than second place. Aeschylus won 14 competitions, and was sometimes defeated by Sophocles, while Euripides won only 4 competitions.
The most famous tragedies of Sophocles feature Oedipus and also Antigone: they are generally known as the Theban plays, although each play was actually a part of a different tetralogy, the other members of which are now lost. Sophocles influenced the development of the drama, most importantly by adding a third actor, thereby reducing the importance of the chorus in the presentation of the plot. He also developed his characters to a greater extent than earlier playwrights such as Aeschylus.
Life.
Sophocles, the son of Sophilus, was a wealthy member of the rural "deme" (small community) of Colonus Hippius in Attica, which was to become a setting for one of his plays, and he was probably born there. He was born a few years before the Battle of Marathon in 490 BC: the exact year is unclear, although 497/6 is the most likely. Sophocles was born into a wealthy family (his father was an armour manufacturer) and was highly educated. Sophocles' first artistic triumph was in 468 BC, when he took first prize in the Dionysia theatre competition over the reigning master of Athenian drama, Aeschylus. According to Plutarch, the victory came under unusual circumstances. Instead of following the usual custom of choosing judges by lot, the archon asked Cimon and the other "strategoi" present to decide the victor of the contest. Plutarch further contends that following this loss Aeschylus soon left for Sicily. Although Plutarch says that this was Sophocles' first production, it is now thought that his first production was probably in 470 BC. "Triptolemus" was probably one of the plays that Sophocles presented at this festival.
In 480 BC Sophocles was chosen to lead the paean (a choral chant to a god), celebrating the Greek victory over the Persians at the Battle of Salamis. Early in his career, the politician Cimon might have been one of his patrons, although if he was, there was no ill will borne by Pericles, Cimon's rival, when Cimon was ostracized in 461 BC. In 443/2 he served as one of the "Hellenotamiai", or treasurers of Athena, helping to manage the finances of the city during the political ascendancy of Pericles. According to the "Vita Sophoclis", in 441 BC he was elected one of ten strategoi, high executive officials that commanded the armed forces, as a junior colleague of Pericles, and he served in the Athenian campaign against Samos; he was supposed to have been elected to this position as the result of his production of "Antigone".
In 420 BC, he welcomed and set up an altar for the image of Asclepius at his house, when the deity was introduced to Athens. For this, he was given the posthumous epithet "Dexion" (receiver) by the Athenians. He was also elected, in 413 BC, one of the commissioners ("probouloi") who responded to the catastrophic destruction of the Athenian expeditionary force in Sicily during the Peloponnesian War.
Sophocles died at the age of ninety or ninety-one in the winter of 406/5 BC, having seen within his lifetime both the Greek triumph in the Persian Wars and the bloodletting of the Peloponnesian War. As with many famous men in classical antiquity, his death inspired a number of apocryphal stories. The most famous is the suggestion that he died from the strain of trying to recite a long sentence from his "Antigone" without pausing to take a breath. Another account suggests he choked while eating grapes at the Anthesteria festival in Athens. A third holds that he died of happiness after winning his final victory at the City Dionysia. A few months later, a comic poet, in a play titled "The Muses", wrote this eulogy: "Blessed is Sophocles, who had a long life, was a man both happy and talented, and the writer of many good tragedies; and he ended his life well without suffering any misfortune." According to some accounts, however, his own sons tried to have him declared incompetent near the end of his life; he is said to have refuted their charge in court by reading from his as yet unproduced "Oedipus at Colonus". One of his sons, Iophon, and a grandson, also called Sophocles, also became playwrights.
Works and legacy.
Among Sophocles' earliest innovations was the addition of a third actor, which further reduced the role of the chorus and created greater opportunity for character development and conflict between characters. Aeschylus, who dominated Athenian playwriting during Sophocles' early career, followed suit and adopted the third character into his own work towards the end of his life. Aristotle credits Sophocles with the introduction of "skenographia", or scenery-painting. It was not until after the death of the old master Aeschylus in 456 BC that Sophocles became the pre-eminent playwright in Athens.
Thereafter, Sophocles emerged victorious in dramatic competitions at 18 Dionysia and 6 Lenaia festivals. In addition to innovations in dramatic structure, Sophocles' work is also known for its deeper development of characters than earlier playwrights. His reputation was such that foreign rulers invited him to attend their courts, although unlike Aeschylus who died in Sicily, or Euripides who spent time in Macedon, Sophocles never accepted any of these invitations. Aristotle used Sophocles' "Oedipus the King" in his "Poetics" (c. 335 BC) as an example of the highest achievement in tragedy, which suggests the high esteem in which his work was held by later Greeks.
Only two of the seven surviving plays can be dated securely: "Philoctetes" (409 BC) and "Oedipus at Colonus" (401 BC, staged after Sophocles' death by his grandson). Of the others, "Electra" shows stylistic similarities to these two plays, which suggests that it was probably written in the latter part of his career. "Ajax", "Antigone" and "The Trachiniae" are generally thought to be among his early works, again based on stylistic elements, with "Oedipus the King" coming in Sophocles' middle period. Most of Sophocles' plays show an undercurrent of early fatalism and the beginnings of Socratic logic as a mainstay for the long tradition of Greek tragedy.
Theban plays.
The Theban plays consist of three plays: "Oedipus the King" (also called "Oedipus Tyrannus" or by its Latin title "Oedipus Rex"), "Oedipus at Colonus" and "Antigone". All three plays concern the fate of Thebes during and after the reign of King Oedipus. They have often been published under a single cover. Sophocles, however, wrote the three plays for separate festival competitions, many years apart. Not only are the Theban plays not a true trilogy (three plays presented as a continuous narrative) but they are not even an intentional series and contain some inconsistencies among them. He also wrote other plays having to do with Thebes, such as the "Epigoni", of which only fragments have survived.
Subjects.
Each of the plays relates to the tale of the mythological Oedipus, who killed his father and married his mother without knowledge that they were his parents. His family is fated to be doomed for three generations.
In "Oedipus the King", Oedipus is the protagonist. Oedipus' infanticide is planned by his parents, Laius and Jocasta, to avert him fulfilling a prophecy; in truth, the servant entrusted with the infanticide passes the infant on through a series of intermediaries to a childless couple, who adopt him not knowing his history. Oedipus eventually learns of the Delphic Oracle's prophecy of him, that he would kill his father and marry his mother; Oedipus attempts to flee his fate without harming his parents (at this point, he does not know that he is adopted). Oedipus meets a man at a crossroads accompanied by servants; Oedipus and the man fought, and Oedipus killed the man. (This man was his father, Laius, not that anyone apart from the gods knew this at the time). He becomes the ruler of Thebes after solving the riddle of the sphinx and in the process, marries the widowed Queen, his mother Jocasta. Thus the stage is set for horror. When the truth comes out, following from another true but confusing prophecy from Delphi, Jocasta commits suicide, Oedipus blinds himself and leaves Thebes, and the children are left to sort out the consequences themselves (which provides the grounds for the later parts of the cycle of plays).
In "Oedipus at Colonus", the banished Oedipus and his daughter Antigone arrive at the town of Colonus where they encounter Theseus, King of Athens. Oedipus dies and strife begins between his sons Polyneices and Eteocles.
In "Antigone", the protagonist is Oedipus' daughter, Antigone. She is faced with the choice of allowing her brother Polyneices' body to remain unburied, outside the city walls, exposed to the ravages of wild animals, or to bury him and face death. The king of the land, Creon, has forbidden the burial of Polyneices for he was a traitor to the city. Antigone decides to bury his body and face the consequences of her actions. Creon sentences her to death. Eventually, Creon is convinced to free Antigone from her punishment, but his decision comes too late and Antigone commits suicide. Her suicide triggers the suicide of two others close to King Creon: his son, Haemon, who was to wed Antigone, and his wife, Eurydice, who commits suicide after losing her only surviving son.
Composition and inconsistencies.
The plays were written across thirty-six years of Sophocles' career and were not composed in chronological order, but instead were written in the order "Antigone", "Oedipus the King", and "Oedipus at Colonus". Nor were they composed as a "trilogy" - a group of plays to be performed together, but are the remaining parts of three different groups of plays. As a result, there are some inconsistencies: notably, Creon is the undisputed king at the end of "Oedipus the King" and, in consultation with Apollo, single-handedly makes the decision to expel Oedipus from Thebes. Creon is also instructed to look after Oedipus' daughters Antigone and Ismene at the end of "Oedipus the King". By contrast, in the other plays there is some struggle with Oedipus' sons Eteocles and Polynices in regard to the succession. In "Oedipus at Colonus", Sophocles attempts to work these inconsistencies into a coherent whole: Ismene explains that, in light of their tainted family lineage, her brothers were at first willing to cede the throne to Creon. Nevertheless, they eventually decided to take charge of the monarchy, with each brother disputing the other's right to succeed. In addition to being in a clearly more powerful position in "Oedipus at Colonus," Eteocles and Polynices are also culpable: they consent <l. 429, Theodoridis, tr.> to their father's going to exile, which is one of his bitterest charges against them.
Other plays.
In addition to the three Theban plays, there are four surviving plays by Sophocles: "Ajax", "The Women of Trachis", "Electra", and "Philoctetes", the last of which won first prize in the year 409BC in which it competed.
"Ajax" focuses on the proud hero of the Trojan War, Telamonian Ajax, who is driven to treachery and eventually suicide. Ajax becomes gravely upset when Achilles’ armor is presented to Odysseus instead of himself. Despite their enmity toward him, Odysseus persuades the kings Menelaus and Agamemnon to grant Ajax a proper burial.
"The Women of Trachis" (named for the Trachinian women who make up the chorus) dramatizes Deianeira's accidentally killing Heracles after he had completed his famous twelve labors. Tricked into thinking it is a love charm, Deianeira applies poison to an article of Heracles' clothing; this poisoned robe causes Heracles to die an excruciating death. Upon learning the truth, Deianeira commits suicide.
"Electra" corresponds roughly to the plot of Aeschylus' "Libation Bearers". It details how Electra and Orestes' avenge their father Agamemnon's murder by Clytemnestra and Aegisthus.
"Philoctetes" retells the story of Philoctetes, an archer who had been abandoned on Lemnos by the rest of the Greek fleet while on the way to Troy. After learning that they cannot win the Trojan War without Philoctetes' bow, the Greeks send Odysseus and Neoptolemus to retrieve him; due to the Greeks' earlier treachery, however, Philoctetes refuses to rejoin the army. It is only Heracles' deus ex machina appearance that persuades Philoctetes to go to Troy.
Fragmentary plays.
Although the list of over 120 titles of plays associated with Sophocles are known and presented below, little is known of the precise dating of most of them. "Philoctetes" is known to have been written in 409BC, and "Oedipus Colonus" is known to have only been performed posthumously in 401BC at the initiation of the grandson of Sophocles. The convention for writing plays for the Greek festivals was to submit them in tetralogies of three tragedies along with one satyr play. Along with the unknown precise dating of the vast majority of over 120 titles of plays, it is also largely unknown as to which plays were grouped together as specific tetralogies. It is, however, known that the three plays known in the modern era as the Theban plays were never performed together in Sophocles' own lifetime, since the second play "Oedipus Colonus" only was performed posthumously in 401BC for the first time after Sophocles' death.
Fragments of "Ichneutae" ("Tracking Satyrs") were discovered in Egypt in 1907. These amount to about half of the play, making it the best preserved satyr play after Euripides' "Cyclops", which survives in its entirety. Fragments of the "Epigoni" were discovered in April 2005 by classicists at Oxford University with the help of infrared technology previously used for satellite imaging. The tragedy tells the story of the second siege of Thebes. A number of other Sophoclean works have survived only in fragments, including:
Sophocles' view of his own work.
There is a passage of Plutarch's tract "De Profectibus in Virtute 7 " in which Sophocles discusses his own growth as a writer. A likely source of this material for Plutarch was the "Epidemiae" of Ion of Chios, a book that recorded many conversations of Sophocles. This book is a likely candidate to have contained Sophocles' discourse on his own development because Ion was a friend of Sophocles, and the book is known to have been used by Plutarch. Though some interpretations of Plutarch's words suggest that Sophocles says that he imitated Aeschylus, the translation does not fit grammatically, nor does the interpretation that Sophocles said that he was making fun of Aeschylus' works. C. M. Bowra argues for the following translation of the line:
"After practising to the full the bigness of Aeschylus, then the painful ingenuity of my own invention, now in the third stage I am changing to the kind of diction which is most expressive of character and best."
Here Sophocles says that he has completed a stage of Aeschylus' work, meaning that he went through a phase of imitating Aeschylus' style but is finished with that. Sophocles' opinion of Aeschylus was mixed. He certainly respected him enough to imitate his work early on in his career, but he had reservations about Aeschylus' style, and thus did not keep his imitation up. Sophocles' first stage, in which he imitated Aeschylus, is marked by "Aeschylean pomp in the language". Sophocles' second stage was entirely his own. He introduced new ways of evoking feeling out of an audience, as in his "Ajax", when Ajax is mocked by Athene, then the stage is emptied so that he may commit suicide alone. Sophocles mentions a third stage, distinct from the other two, in his discussion of his development. The third stage pays more heed to diction. His characters spoke in a way that was more natural to them and more expressive of their individual character feelings.

</doc>
<doc id="26985" url="http://en.wikipedia.org/wiki?curid=26985" title="Salinity">
Salinity

Salinity is the saltiness or dissolved salt content of a body of water (see also soil salinity).
Salinity is an important factor in determining many aspects of the chemistry
of natural waters and of biological processes within it, and is a thermodynamic state variable that, along with temperature and pressure, governs physical characteristics like the density and heat capacity of the water.
A contour line of constant salinity is called a isohalíne – or sometimes isohale.
Definitions.
Salinity in rivers, lakes, and the ocean is conceptually simple, but technically challenging to define and measure precisely. Conceptually the salinity is the quantity of dissolved salt content of the water. Salts are compounds like sodium chloride, magnesium sulfate, potassium nitrate, and sodium bicarbonate which dissolve into ions. The concentration of dissolved chloride ions is sometimes referred to as chlorinity. Operationally, dissolved matter is defined as that which can pass through a very fine filter (historically a filter with a pore size of 0.45 μm, but nowadays usually 0.2 μm). Salinity can be expressed in the form of a mass fraction, i.e. the mass of the dissolved material in a unit mass of solution. 
Seawater typically has a salinity of around 35 g/kg, although lower values are typical near coasts where rivers enter the ocean. Rivers and lakes can have a wide range of salinities, from less than 0.01 g/kg to a few g/kg, although there are many places where higher salinities are found. The Dead Sea has a salinity of more than 200 g/kg.
Whatever pore size is used in the definition, the resulting salinity value of a given sample of natural water will not vary by more than a few %. Physical oceanographers working in the abyssal ocean, however, are often concerned with precision and intercomparability of measurements by different researchers, at different times, to almost five significant digits. A bottled seawater product known as IAPSO Standard Seawater is used by oceanographers to standardize their measurements with enough precision to meet this requirement.
Composition.
Measurement and definition difficulties arise because natural waters contain a complex mixture of many different elements from different sources (not all from dissolved salts) in different molecular forms. The chemical properties of some of these forms depend on temperature and pressure. Many of these forms are difficult to measure with high accuracy, and in any case complete chemical analysis is not practical when analyzing multiple samples. Different practical definitions of salinity result from different attempts to account for these problems, to different levels of precision, while still remaining reasonably easy to use.
For practical reasons salinity is usually related to the sum of masses of a subset of these dissolved chemical constituents (so-called "solution salinity"), rather than to the unknown mass of salts that gave rise to this composition (an exception is when artificial seawater is created). For many purposes this sum can be limited to a set of eight major ions in natural waters, although for seawater at highest precision an additional seven minor ions are also included. The major ions dominate the inorganic composition of most (but by no means all) natural waters. Exceptions include some pit lakes and waters from some hydrothermal springs.
The concentrations of dissolved gases like oxygen and nitrogen are not usually included in descriptions of salinity. However, carbon dioxide gas, which when dissolved is partially converted into carbonates and bicarbonates, is often included. Silicon in the form of silicic acid, which usually appears as a neutral molecule in the pH range of most natural waters, may also be included for some purposes (e.g., when salinity/density relationships are being investigated).
Seawater.
The term 'salinity' is, for oceanographers, usually associated with one of a set of specific measurement techniques. As the dominant techniques evolve, so do different descriptions of salinity. The distinctions between these different descriptions are important to physical oceanographers but are obscure and confusing to nonspecialists.
Salinities were largely measured using titration-based techniques before the 1980s. Titration with silver nitrate could be used to determine the concentration of halide ions (mainly chlorine and bromine) to give a chlorinity. The chlorinity was then multiplied by a factor to account for all other constituents. The resulting 'Knudsen salinities' are expressed in units of parts per thousand (ppt or ‰).
The use of electrical conductivity measurements to estimate the ionic content of seawater led to the development of the so-called "practical salinity scale 1978" (PSS-78). Salinities measured using PSS-78 do not have units. The 'unit' of PSU (denoting "practical salinity unit") is sometimes added to PSS-78 measurements, however this is officially discouraged.
In 2010 a new standard for the properties of seawater was introduced, the so-called "thermodynamic equation of seawater 2010" (TEOS-10). This standard includes a new scale, the so-called "reference composition salinity scale". Absolute salinities on this scale are expressed as a mass fraction, in grams per kilogram of solution. Salinities on this scale are determined by combining electrical conductivity measurements with other information that can account for regional changes in the composition of seawater. They can also be determined by making direct density measurements.
A sample of seawater from most locations with a chlorinity of 19.37 ppt will have a Knudsen salinity of 35.00 ppt, a PSS-78 practical salinity of about 35.0, and a TEOS-10 absolute salinity of about 35.2 g/kg. The electrical conductivity of this water at a temperature of 15 °C is 42.9 mS/cm.
Lakes and rivers.
Limnologists and chemists often define salinity in terms of mass of salt per unit volume, expressed in units of mg per litre or g per litre. It is implied, although often not stated, that this value applies accurately only at some reference temperature. Values presented in this way are typically accurate to of the order of 1%. Limnologists also use electrical conductivity, or "reference conductivity", as a proxy for salinity called. This measurement may be corrected for temperature effects, and is usually expressed in units of μS/cm.
A river or lake water with a salinity of around 70 mg/L will typically have a specific conductivity at 25 °C of between 80 and 130 μS/cm. The actual conductivity usually changes by about 2% per degree Celsius, so the measured conductivity at 5 °C might only be in the range of 50–80 μS/cm.
Direct density measurements are also used to estimate salinities, particularly in highly saline lakes. Sometimes density at a specific temperature is used as a proxy for salinity. At other times an empirical salinity/density relationship developed for a particular body of water is used to estimate the salinity of samples from a measured density.
Systems of classification of water bodies based upon salinity.
Marine waters are those of the ocean, another term for which is "euhaline seas". The salinity of euhaline seas is 30 to 35. "Brackish seas" or waters have salinity in the range of 0.5 to 29 and "metahaline seas" from 36 to 40. These waters are all regarded as "thalassic" because their salinity is derived from the ocean and defined as "homoiohaline" if salinity does not vary much over time (essentially constant). The table on the right, modified from Por (1972), follows the "Venice system" (1959).
In contrast to homoiohaline environments are certain "poikilohaline" environments (which may also be "thalassic") in which the salinity variation is biologically significant. "Poikilohaline" water salinities may range anywhere from 0.5 to greater than 300. The important characteristic is that these waters tend to vary in salinity over some biologically meaningful range seasonally or on some other roughly comparable time scale. Put simply, these are bodies of water with quite variable salinity.
Highly saline water, from which salts crystallize (or are about to), is referred to as brine.
Environmental considerations.
Salinity is an ecological factor of considerable importance, influencing the types of organisms that live in a body of water. As well, salinity influences the kinds of plants that will grow either in a water body, or on land fed by a water (or by a groundwater). A plant adapted to saline conditions is called a halophyte. A halophyte which is tolerant to residual sodium carbonate salinity are called glasswort or saltwort or barilla plants. Organisms (mostly bacteria) that can live in very salty conditions are classified as extremophiles, or halophiles specifically. An organism that can withstand a wide range of salinities is euryhaline.
Salt is expensive to remove from water, and salt content is an important factor in water use (such as potability).
The degree of salinity in oceans is a driver of the world's ocean circulation, where density changes due to both salinity changes and temperature changes at the surface of the ocean produce changes in buoyancy, which cause the sinking and rising of water masses. Changes in the salinity of the oceans are thought to contribute to global changes in carbon dioxide as more saline waters are less soluble to carbon dioxide. In addition, during glacial periods, the hydrography is such that a possible cause of reduced circulation is the production of stratified oceans. Hence it is difficult in this case to subduct water through the thermohaline circulation.

</doc>
<doc id="26987" url="http://en.wikipedia.org/wiki?curid=26987" title="Saxifragales">
Saxifragales

The Saxifragales are an order of flowering plants. Their closest relatives are a large eudicot group known as the rosids by the definition of rosids given in the APG II classification system. Some authors define the rosids more widely, including Saxifragales as their most basal group. Saxifragales is one of the eight groups that compose the core eudicots. The others are Gunnerales, Dilleniaceae, rosids, Santalales, Berberidopsidales, Caryophyllales, and asterids.
Saxifragales have an extensive fossil record. The extant members are apparently remnants of a formerly diverse and widespread order.
The Saxifragales order, as it is now understood, is based upon the results of molecular phylogenetic studies of DNA sequences. It is not part of any of the classification systems based on plant morphology. The group is much in need of comparative anatomical study, especially in light of the recent expansion of the family Peridiscaceae to include "Medusandra", a genus that before 2009 had usually not been placed in Saxifragales.
The order is divided into suprafamilial groups as shown on the phylogenetic tree below. These groups are informal and are not understood to have any particular taxonomic rank.
Families.
Saxifragales contain about 2470 species. These are distributed into 15 families, or into 12 families if Haloragaceae "sensu lato" is recognized as a family consisting of Haloragaceae "sensu stricto", "Penthorum", "Tetracarpaea", and "Aphanopetalum". About 95% of the species are in five families: Crassulaceae (1400), Saxifragaceae (500), Grossulariaceae (150 - 200), Haloragaceae (150), and Hamamelidaceae (100). Most of the families are monogeneric. The number of genera in each family is:
Some authors do not recognize "Choristylis" as a separate genus from "Itea". Similarly, some authors sink "Liquidambar" and "Semiliquidambar" into "Altingia". Thus Altingiaceae and Iteaceae are monogeneric in some classifications.
History.
Within the Saxifragales is a suprafamilial group known as the Saxifragaceae alliance. It comprises four families: Pterostemonaceae, Iteaceae, Grossulariaceae, and Saxifragaceae. These have long been known to be related to each other, but the circumscription of Saxifragaceae has changed dramatically. It is now a much smaller family than it had been. Crassulaceae and Tetracarpaeaceae have long been associated with Saxifragaceae. "Penthorum" has usually been associated with Crassulaceae, but sometimes with Saxifragaceae.
Two members of the core Saxifragales had sometimes been placed near Saxifragaceae, but usually elsewhere. "Aphanopetalum" was often placed in Cunoniaceae, a family in Oxalidales, even though there were good reasons to put it in Saxifragales. "Aphanopetalum" is now excluded from Cunoniaceae. Haloragaceae was often thought to be a family in Myrtales, but it is no longer included in that order.
Cercidiphyllaceae had for a long time been associated with Hamamelidaceae and Trochodendraceae and was often thought to be closer to the latter. Cercidiphyllaceae is now known to be a member of the woody clade of Saxifragales, along with Hamamelidaceae, Altingiaceae, and Daphniphyllaceae, but Trochodendraceae is in the basal eudicot order Trochodendrales. Altingiaceae was usually not separated from Hamamelidaceae until phylogenetic studies showed that its inclusion might make Hamamelidaceae paraphyletic. The recognition of Altingiaceae as a separate family received strong statistical support in 2008.
"Daphniphyllum" was always thought to have an anomalous combination of characters and it was placed in several different orders before molecular phylogenetic analysis showed it to belong to Saxifragales.
Paeoniaceae possesses many unique features and its taxonomic position was for a long time controversial. The idea has long persisted that "Paeonia" belongs in Ranunculales, close to "Glaucidium". Paeoniaceae has been shown unequivocally to belong in Saxifragales, while "Glaucidium" is in the family Ranunculaceae.
The family Peridiscaceae underwent radical shifting and recircumscription from 2003 to 2009. Originally, it consisted of two closely related genera, "Peridiscus" and "Whittonia". The APG II system placed the family in Malpighiales, based on a DNA sequence for the "rbcL" gene from "Whittonia". This sequence turned out to be not from "Whittonia", but from other plants whose DNA had contaminated the sample. After Peridiscaceae was finally placed in Saxifragales, it was expanded to include "Soyauxia" in 2007, and expanded again to include "Medusandra" in 2009.
Phylogeny.
The phylogeny shown below is based on the one published by Shuguang Jian and coauthors in 2008. All branches have 100% maximum likelihood bootstrap support except where labeled with bootstrap percentage. Monogeneric families are represented by genus names.

</doc>
<doc id="26988" url="http://en.wikipedia.org/wiki?curid=26988" title="CLIÉ">
CLIÉ

The Sony CLIÉ was a series of personal digital assistants running the Palm Operating System developed and marketed by Sony from 2000 to 2005. The devices introduced many new features to the PDA market, such as a jog-wheel interface, high-resolution displays, and Sony technologies like Memory Stick slots and ATRAC3 audio playback. Most models were designed and manufactured in Japan. The name is an acronym for "creativity, lifestyle, innovation, emotion" though formerly "communication, link, information and entertainment". It was initially an attempt at a new coinage term, though it means "tool" in the Jèrriais language.
The CLIÉ handhelds were distinguished from other Palm OS models by their emphasis on multimedia capabilities, including photo, video, and audio playback, long before any other Palm OS PDAs had such capabilities. Later models have been credited with spurring competition in the previously stagnant Palm market, closing many of the gaps that existed between Palm OS PDAs and those powered by Microsoft's Windows Mobile operating system, particularly on the multimedia front, but also with Sony's proprietary application launcher interface.
Closure of handheld line.
In the summer of 2004, Sony announced that new CLIÉs would, from then on, be manufactured and available only in Japan, and in the spring of 2005, Sony announced the total termination of its CLIÉ line of products. The last models to be released worldwide were the PEG-TJ27, PEG-TJ37, and PEG-TH55. The last model released in Japan was the PEG-VZ90. Soon after the closure of the CLIÉ line, Sony stopped providing original installation drivers, including Sony's version of Palm Desktop for the CLIÉ, which are necessary for Hotsyncing with the PC and otherwise taking advantage of the handhelds' many features for which a PC may be required. Several CLIÉ fans took it upon themselves to offer these drivers freely for download at http://www.sonyclie.org .
Models.
CLIÉ handhelds were released in series, usually with a few models released in each series. In later years, multiple series would be in production at the same time.
Macintosh support.
Officially, the CLIÉ line did not support the Mac OS, and Sony never provided any software with the handhelds for Mac OS. However, as a Palm OS device, every CLIÉ handheld was inherently capable of HotSync operations with a Mac OS computer. This allowed for the synchronization of the basic PIM functions, as well as for the installation of new software, though this inherent capability was unusable because the Mac HotSync software would not recognize the handheld. PalmSource, however, silently added the capability to recognize older CLIÉ devices when providing new versions of its Palm Desktop software for Mac. This was necessary for those who could synchronize only via USB.
The CLIÉ user community soon that these "updates" were simply a matter of adding a few lines to the USB-detection property-list file. Since then, detailed have been posted online for those who want to synchronize their CLIÉ handhelds. No modifications are required for Bluetooth synchronization, but Wi-Fi synchronization is impossible because the Mac OS HotSync software does not support network synchronization. Some workarounds for the multimedia features also exist. For those who desire stronger Mac OS/CLIÉ integration, the product made by the company is also available. This does make unencrypted Wi-Fi synchronization possible but a bug in the CLIÉ network stack reverses IP addresses which means that the Macintosh involved needs a palindromic IP address such as 10.0.0.10.

</doc>
<doc id="26989" url="http://en.wikipedia.org/wiki?curid=26989" title="Sony">
Sony

Sony Corporation (ソニー株式会社, Sonī Kabushiki Gaisha), commonly referred to as Sony, is a Japanese multinational conglomerate corporation headquartered in Kōnan Minato, Tokyo, Japan. Its diversified business is primarily focused on the electronics (TV, gaming consoles, refrigerators), game, entertainment and financial services sectors. The company is one of the leading manufacturers of electronic products for the consumer and professional markets. Sony is ranked 105th on the 2014 list of Fortune Global 500.
Sony Corporation is the electronics business unit and the parent company of the Sony Group, which is engaged in business through its four operating segments – electronics (including video games, network services and medical business), motion pictures, music and financial services. These make Sony one of the most comprehensive entertainment companies in the world. Sony's principal business operations include Sony Corporation (Sony Electronics in the U.S.), Sony Pictures Entertainment, Sony Computer Entertainment, Sony Music Entertainment, Sony Mobile Communications (formerly Sony Ericsson), and Sony Financial. Sony is among the Worldwide Top 20 Semiconductor Sales Leaders and as of 2013, the fourth-largest television manufacturer in the world, after Samsung Electronics, LG Electronics and TCL.
The Sony Group (ソニー・グループ, Sonī Gurūpu) is a Japan-based corporate group primarily focused on the Electronics (such as AV/IT products and components), Game (such as the PlayStation), Entertainment (such as motion pictures and music), and Financial Services (such as insurance and banking) sectors. The group consists of Sony Corporation (holding and electronics), Sony Computer Entertainment (games), Sony Pictures Entertainment (motion pictures), Sony Music Entertainment (music), Sony/ATV Music Publishing (music publishing), Sony Financial Holdings (financial services) and others.
Its founders Akio Morita and Masaru Ibuka derived the name from "sonus", the Latin word for sound, and also from the English slang word "sonny", since they considered themselves to be "sonny boys", a loan word into Japanese which in the early 1950s connoted smart and presentable young men. The company's current slogan is "BE MOVED". Their former slogans were "make.believe" (2009–2014) and "like.no.other" (2005–2014).
History.
Tokyo Tsushin Kogyo.
Sony began in the wake of World War II. In 1946, Masaru Ibuka started an electronics shop in a department store building in Tokyo. The company had $530 in capital and a total of eight employees. In the following year he was joined by his colleague, Akio Morita, and they founded a company called "Tokyo Tsushin Kogyo" (Tokyo Telecommunications Engineering Corporation). The company built Japan's first tape recorder, called the Type-G. In 1958 the company changed its name to "Sony".
Sony name change.
When Tokyo Tsushin Kogyo was looking for a romanized name to use to market themselves, they strongly considered using their initials, TTK. The primary reason they did not is that the railway company Tokyo Kyuko was known as TTK. The company occasionally used the acronym "Totsuko" in Japan, but during his visit to the United States, Morita discovered that Americans had trouble pronouncing that name. Another early name that was tried out for a while was "Tokyo Teletech" until Akio Morita discovered that there was an American company already using Teletech as a brand name.
The name "Sony" was chosen for the brand as a mix of two words. One was the Latin word ""Sonus", which is the root of sonic and sound, and the other was "Sonny"", a familiar term used in 1950s America to call a boy. The first Sony-branded product, the TR-55 transistor radio, appeared in 1955 but the company name did not change to Sony until January 1958.
At the time of the change, it was extremely unusual for a Japanese company to use Roman letters to spell its name instead of writing it in kanji. The move was not without opposition: TTK's principal bank at the time, Mitsui, had strong feelings about the name. They pushed for a name such as Sony Electronic Industries, or Sony Teletech. Akio Morita was firm, however, as he did not want the company name tied to any particular industry. Eventually, both Ibuka and Mitsui Bank's chairman gave their approval.
Globalization.
According to Schiffer, Sony's TR-63 radio "cracked open the U.S. market and launched the new industry of consumer microelectronics." By the mid-1950s, American teens had begun buying portable transistor radios in huge numbers, helping to propel the fledgling industry from an estimated 100,000 units in 1955 to 5 million units by the end of 1968.
Sony co-founder Akio Morita founded Sony Corporation of America in 1960. In the process, he was struck by the mobility of employees between American companies, which was unheard of in Japan at that time. When he returned to Japan, he encouraged experienced, middle-aged employees of other companies to reevaluate their careers and consider joining Sony. The company filled many positions in this manner, and inspired other Japanese companies to do the same. Moreover, Sony played a major role in the development of Japan as a powerful exporter during the 1960s, 1970s, and 1980s. It also helped to significantly improve American perceptions of "made in Japan" products. Known for its production quality, Sony was able to charge above-market prices for its consumer electronics and resisted lowering prices.
In 1971, Masaru Ibuka handed the position of president over to his co-founder Akio Morita. Sony began a life insurance company in 1979, one of its many peripheral businesses. Amid a global recession in the early 1980s, electronics sales dropped and the company was forced to cut prices. Sony's profits fell sharply. "It's over for Sony," one analyst concluded. "The company's best days are behind it." Around that time, Norio Ohga took up the role of president. He encouraged the development of the Compact Disc in the 1970s and 1980s, and of the PlayStation in the early 1990s. Ohga went on to purchase CBS Records in 1988 and Columbia Pictures in 1989, greatly expanding Sony's media presence. Ohga would succeed Morita as chief executive officer in 1989.
Under the vision of co-founder Akio Morita and his successors, the company had aggressively expanded into new businesses. Part of its motivation for doing so was the pursuit of "convergence," linking film, music, and digital electronics via the Internet. This expansion proved unrewarding and unprofitable, threatening Sony's ability to charge a premium on its products as well as its brand name. In 2005, Howard Stringer replaced Nobuyuki Idei as chief executive officer, marking the first time that a foreigner had run a major Japanese electronics firm. Stringer helped to reinvigorate the company's struggling media businesses, encouraging blockbusters such as "Spider-Man" while cutting 9,000 jobs. He hoped to sell off peripheral business and focus the company again on electronics. Furthermore, he aimed to increase cooperation between business units, which he described as "silos" operating in isolation from one another. In a bid to provide a unified brand for its global operations, Sony introduced a slogan known as "make.believe" in 2009.
Despite some successes, the company faced continued struggles in the mid- to late-2000s. In 2012, Kazuo Hirai was promoted to president and CEO, replacing Sir Howard Stringer. Shortly thereafter, Hirai outlined his company-wide initiative, named "One Sony" to revive Sony from years of financial losses and bureaucratic management structure, which proved difficult for former CEO Stringer to accomplish, partly due to differences in business culture and native languages between Stringer and some of Sony's Japanese divisions and subsidiaries. Hirai outlined three major areas of focus for Sony's electronics business, which include imaging technology, gaming and mobile technology, as well as a focus on reducing the major losses from the television business.
In February 2014, Sony announced the sale of its Vaio PC division to a new corporation owned by investment fund Japan Industrial Partners and spinning its TV division into its own corporation as to make it more nimble to turn the unit around from past losses totaling $7.8 billion over a decade. Later that month, they announced that they would be closing 20 stores. In April, the company announced that they would be selling 9.5 million shares in Square Enix (roughly 8.2 percent of the game company's total shares) in a deal worth approximately $48 million. In May 2014 the company announced it was forming two joint ventures with Shanghai Oriental Pearl Group to manufacture and market Sony's PlayStation games consoles and associated software in China.
In February 2015, Sony announced that it may spin-off its audio and video business as a separate company by October. Kazuo Hirai also said that Sony would focus on its most profitable businesses, such as PlayStation and film and television production, and that it may seek to spin-off or close other under-performing divisions.
Formats and technologies.
Sony has historically been notable for creating its own in-house standards for new recording and storage technologies, instead of adopting those of other manufacturers and standards bodies. Sony (either alone or with partners) has introduced several of the most popular recording formats, including the floppy disk, Compact Disc, and Blu-ray Disc.
Video recording.
The company launched the Betamax videocassette recording format in 1975. Sony became embroiled in the infamous videotape format war of the early 1980s, when Sony was marketing the Betamax system for video cassette recorders against the VHS format developed by JVC. In the end, VHS gained critical mass in the marketbase and became the worldwide standard for consumer VCRs.
While Betamax is for all practical purposes an obsolete format, a professional-oriented component video format called Betacam that was derived from Betamax is still used today, especially in the television industry, although far less so in recent years with the introduction of digital and high definition.
In 1985, Sony launched their Handycam products and the Video8 format. Video8 and the follow-on hi-band Hi8 format became popular in the consumer camcorder market. In 1987 Sony launched the 4 mm DAT or Digital Audio Tape as a new digital audio tape standard.
Audio recording.
In 1979 the Walkman brand was introduced, in the form of the world's first portable music player using the compact cassette format. Sony introduced the MiniDisc format in 1992 as an alternative to Philips DCC or Digital Compact Cassette and as a successor to the compact cassette. Since the introduction of MiniDisc, Sony has attempted to promote its own audio compression technologies under the ATRAC brand, against the more widely used MP3. Until late 2004, Sony's Network Walkman line of digital portable music players did not support the MP3 de facto standard natively.
In 2004, Sony built upon the MiniDisc format by releasing Hi-MD. Hi-MD allows the playback and recording of audio on newly introduced 1 GB Hi-MD discs in addition to playback and recording on regular MiniDiscs. In addition to saving audio on the discs, Hi-MD allows the storage of computer files such as documents, videos and photos.
Audio encoding.
In 1993, Sony challenged the industry standard Dolby Digital 5.1 surround sound format with a newer and more advanced proprietary motion picture digital audio format called SDDS (Sony Dynamic Digital Sound). This format employed eight channels (7.1) of audio opposed to just six used in Dolby Digital 5.1 at the time. Ultimately, SDDS has been vastly overshadowed by the preferred DTS (Digital Theatre System) and Dolby Digital standards in the motion picture industry. SDDS was solely developed for use in the theatre circuit; Sony never intended to develop a home theatre version of SDDS.
Sony and Philips jointly developed the Sony-Philips digital interface format (S/PDIF) and the high-fidelity audio system SACD. The latter has since been entrenched in a format war with DVD-Audio. At present, neither has gained a major foothold with the general public. CDs are preferred by consumers because of ubiquitous presence of CD drives in consumer devices.
Optical storage.
In 1983, Sony followed their counterpart Philips to the Compact Disc (CD). In addition to developing consumer-based recording media, after the launch of the CD Sony began development of commercially based recording media. In 1986 they launched Write-Once optical discs (WO) and in 1988 launched Magneto-optical discs which were around 125MB size for the specific use of archival data storage. In 1984, Sony launched the Discman series which extended their Walkman brand to portable CD products.
In the early 1990s, two high-density optical storage standards were being developed: one was the MultiMedia Compact Disc (MMCD), backed by Philips and Sony, and the other was the Super Density disc (SD), supported by Toshiba and many others. Philips and Sony abandoned their MMCD format and agreed upon Toshiba's SD format with only one modification. The unified disc format was called DVD and was introduced in 1997.
Sony was one of the leading developers of the Blu-ray Disc optical disc format, the newest standard for disc-based content delivery. The first Blu-ray players became commercially available in 2006. The format emerged as the standard for HD media over the competing format, Toshiba's HD DVD, after a two-year-long high definition optical disc format war.
Disk storage.
In 1983 Sony introduced 90 mm micro diskettes (better known as 3.5 in floppy disks), which it had developed at a time when there were 4" floppy disks, and a lot of variations from different companies, to replace the then on-going 5.25" floppy disks. Sony had great success and the format became dominant. 3.5" floppy disks gradually became obsolete as they were replaced by current media formats.
Flash memory.
Sony launched in 1998 their Memory Stick format, flash memory cards for use in Sony lines of digital cameras and portable music players. It has seen little support outside of Sony's own products, with Secure Digital cards (SD) commanding considerably greater popularity. Sony has made updates to the Memory Stick format with Memory Stick Duo and Memory Stick Micro.
Business units.
Sony offers a number of products in a variety of product lines around the world. Sony has developed a music playing robot called Rolly, dog-shaped robots called AIBO and a humanoid robot called QRIO.
As of 1 April 2012, Sony is organized into the following business segments: Imaging Products & Solutions (IP&S), Game, Mobile Products & Communications (MP&C), Home Entertainment & Sound (HE&S), Devices, Pictures, Music, Financial Services and All Other. The network and medical businesses are included in the All Other.
Electronics.
Sony Corporation.
Sony Corporation is the electronics business unit and the parent company of the Sony Group. It primarily conducts strategic business planning of the group, research and development (R&D), planning, designing and marketing for electronics products. Its subsidiaries such as Sony EMCS Corporation (6 plants in Japan), Sony Semiconductor Corporation (7 plants in Japan) and its subsidiaries outside Japan (Brazil, China, UK (Wales), India, Malaysia, Singapore, South Korea, Thailand, Ireland and United States) are responsible for manufacturing as well as product engineering (Sony EMCS is also responsible for customer service operations). In 2012, Sony rolled most of its consumer content services (including video, music, and gaming) into the Sony Entertainment Network.
Audio.
Sony produced the world's first portable music player, the Walkman in 1979. This line fostered a fundamental change in music listening habits by allowing people to carry music with them and listen to music through lightweight headphones. Walkman originally referred to portable audio cassette players. The company now uses the Walkman brand to market its portable audio and video players as well as a line of former Sony Ericsson mobile phones.
Sony utilized a related brand, Discman, to refer to its CD players. It dropped this name in the late 1990s.
Computing.
Sony produced computers (MSX home computers and NEWS workstations) during the 1980s, exclusively for sale in the Japanese market. The company withdrew from the computer business around 1990. Sony entered again into the global computer market under the new VAIO brand, began in 1996. Short for "Video Audio Integrated Operation", the line was the first computer brand to highlight visual-audio features.
Sony faced considerable controversy when some of its laptop batteries exploded and caught fire in 2006, resulting in the largest computer-related recall to that point in history.
In a bid to join the tablet computer market, the company launched its Sony Tablet line of Android tablets in 2011. Since 2012, Sony's Android products have been marketed under the Xperia brand used for its smartphones.
On 4 February 2014, Sony announced that it will sell its VAIO PC business due to poor sales and Japanese company Japan Industrial Partners (JIP) will purchase the VAIO brand, with the deal finalized by the end of March 2014. Sony maintains a minority stake in the new, independent company.
Photography.
Sony offers a wide range of digital cameras. Point-and-shoot models adopt the Cyber-shot name, while digital single-lens reflex models are branded using Alpha.
The first Cyber-shot was introduced in 1996. At the time, digital cameras were a relative novelty. Sony's market share of the digital camera market fell from a high of 20% to 9% by 2005.
Sony entered the market for digital single-lens reflex cameras in 2006 when it acquired the camera business of Konica Minolta. Sony rebranded the company's line of cameras as its Alpha line. Sony is the world's third largest manufacturer of the cameras, behind Canon and Nikon respectively.
Video.
In 1968 Sony introduced the Trinitron brand name for its lines of aperture grille cathode ray tube televisions and (later) computer monitors. Sony stopped production of Trinitron for most markets, but continued producing sets for markets such as Pakistan, Bangladesh and China. Sony discontinued its series of Trinitron computer monitors in 2005. The company discontinued the last Trinitron-based television set in the USA in early 2007. The end of Trinitron marked the end of Sony's analog television sets and monitors.
Sony used the LCD WEGA name for its LCD TVs until summer 2005. The company then introduced the BRAVIA name. BRAVIA is an in house brand owned by Sony which produces high-definition LCD televisions, projection TVs and front projectors, home cinemas and the BRAVIA home theatre range. All Sony high-definition flat-panel LCD televisions in North America have carried the logo for BRAVIA since 2005. Sony is the third-largest maker of televisions in the world. s of 2012[ [update]], Sony's television business has been unprofitable for eight years.
In December 2011, Sony agreed to sell all stake in an LCD joint venture with Samsung Electronics for about $940 million. On 28 March 2012, Sony Corporation and Sharp Corporation announced that they have agreed to further amend the joint venture agreement originally executed by the parties in July 2009, as amended in April 2011, for the establishment and operation of Sharp Display Products Corporation ("SDP"), a joint venture to produce and sell large-sized LCD panels and modules.
Sony also sells a range of DVD players. It has shifted its focus in recent years to promoting the Blu-ray format, including discs and players.
Semiconductor and components.
Sony produces a wide range of semiconductors and electronic components including image sensors, image processor (BIONZ), laser diodes, system LSIs, mixed-signal LSIs, OLED panels, etc. The company has a strong presence in the image sensor market. Sony-manufactured CCD and CMOS image sensors are widely used in digital cameras, tablet computers and smartphones.
Medical-related business.
Sony has targeted medical, healthcare and biotechnology business as a growth sector in the future. The company acquired iCyt Mission Technology, Inc. (renamed Sony Biotechnology Inc. in 2012), a manufacture of flow cytometers, in 2010 and Micronics, Inc., a developer of microfluidics-based diagnostic tools, in 2011.
In 2012, Sony announced that it will acquire all shares of So-net Entertainment Corporation, which is the majority shareholder of M3, Inc., an operator of portal sites (m3.com, MR-kun, MDLinx and MEDI:GATE) for healthcare professionals.
On 28 September 2012, Olympus and Sony announced that the two companies will establish a joint venture to develop new surgical endoscopes with 4K resolution (or higher) and 3D capability. Sony Olympus Medical Solutions Inc. (Sony 51%, Olympus 49%) was established on 16 April 2013.
On 28 February 2014, Sony, M3 and Illumina established a joint venture called P5, Inc. to provide a genome analysis service for research institutions and enterprises in Japan.
Sony Mobile Communications.
Sony Mobile Communications Inc. (formerly Sony Ericsson) is a multinational mobile phone manufacturing company headquartered in Tokyo, Japan and a wholly owned subsidiary of Sony Corporation.
In 2001, Sony entered into a joint venture with Swedish telecommunications company Ericsson, forming Sony Ericsson. Initial sales were rocky, and the company posted losses in 2001 and 2002. However, SMC reached a profit in 2003. Sony Ericsson distinguished itself with multimedia-capable mobile phones, which included features such as cameras. These were unusual for the time. Despite their innovations, SMC faced intense competition from Apple's iPhone, released in 2007. From 2008 to 2010, amid a global recession, SMC slashed its workforce by several thousand. Sony acquired Ericsson's share of the venture in 2012 for over US$1 billion. In 2009, SMC was the fourth-largest mobile phone manufacturer in the world (after Nokia, Samsung and LG). By 2010, its market share had fallen to sixth place. Sony Mobile Communications now focuses exclusively on the smartphone market under the Xperia name.
Sony Computer Entertainment.
Sony Computer Entertainment is best known for producing the popular line of PlayStation consoles. The line grew out of a failed partnership with Nintendo. Originally, Nintendo requested for Sony to develop an add-on for its console that would play Compact Discs. In 1991 Sony announced the add-on, as well as a dedicated console known as the "Play Station". However, a disagreement over software licensing for the console caused the partnership to fall through. Sony then continued the project independently.
Launched in 1994, the first PlayStation gained 61% of global console sales and broke Nintendo's long-standing lead in the market. Sony followed up with the PlayStation 2 in 2000, which was even more successful. The console has become the most successful of all time, selling over 150 million units as of 2011[ [update]]. Sony released the PlayStation 3, a high-definition console, in 2006. It was the first console to use the Blu-ray format, although its expensive Cell processor made it considerably more expensive than competitors Xbox 360 and Wii. Early on, poor sales performance resulted in significant losses for the company, pushing it to sell the console at a loss. The PlayStation 3 sold generally more poorly than its competitors in the early years of its release but managed to overtake the Xbox 360 in global sales later on. It later introduced the PlayStation Move, an accessory that allows players to control video games using motion gestures.
Sony extended the brand to the portable games market in 2005 with the PlayStation Portable (PSP). The console has sold reasonably, but has taken a second place to a rival handheld, the Nintendo DS. Sony developed the Universal Media Disc (UMD) optical disc medium for use on the PlayStation Portable. Early on, the format was used for movies, but it has since lost major studio support. Sony released a disc-less version of its PlayStation Portable, the PSP Go. The company went on to release its second portable video game system, PlayStation Vita, in 2011 and 2012. Sony launched its fourth console, the PlayStation 4, on 15 November 2013, which as of March 1 2015 has sold 20.2 million units.
On 18 March 2014, at GDC, President of Sony Computer Entertainment Worldwide Studios Shuhei Yoshida announced their new virtual reality technology dubbed Project Morpheus for PlayStation 4. The headset, still in prototype form, will bring VR gaming and non-gaming software to the company's new console.
Sony Creative Software.
Sony develops consumer software for digital video (Sony Vegas Pro and Movie Studio), audio (Sound Forge), music production (ACID Pro), DVD production and Blu-ray Disc authoring (DVD Architect Pro). Sony Sound Series is a collection of royalty-free loops and samples.
Electric vehicles and batteries.
In 2014, Sony participated within NRG Energy eVgo Ready for Electric Vehicle (REV) program, for EV charging parking lots.
Sony is in the business of electric vehicle lithium-ion batteries.
IT giants such as Google (driverless car) and Apple (iCar/Project Titan) are working on electric vehicles and self driving cars, competing with Tesla; Sony is entering into this field by investing $842,000 in the ZMP company.
Entertainment.
Sony Pictures Entertainment.
Sony Pictures Entertainment, Inc. (SPE) is the television and film production/distribution unit of Sony. With 12.5% box office market share in 2011, the company was ranked third among movie studios. Its group sales in 2010 were US$7.2 billion. The company has produced many notable movie franchises, including "Spider-Man", "The Karate Kid", and "Men in Black". It has also produced the popular television game shows "Jeopardy!" and "Wheel of Fortune".
Sony entered the television and film production market when it acquired Columbia Pictures Entertainment in 1989 for $3.4 billion. Columbia lives on in the Columbia TriStar Motion Picture Group, a subsidiary of SPE which in turn owns Columbia Pictures and TriStar Pictures. SPE's television division is known as Sony Pictures Television.
For the first several years of its existence, Sony Pictures Entertainment performed poorly, leading many to suspect the company would sell off the division. Sony Pictures Entertainment encountered controversy in the early 2000s. In July 2000, a marketing executive working for Sony Corporation created a fictitious film critic, David Manning, who gave consistently good reviews for releases from Sony subsidiary Columbia Pictures that generally received poor reviews amongst real critics. Sony later pulled the ads, suspended Manning's creator and his supervisor and paid fines to the state of Connecticut and to fans who saw the reviewed films in the US. In 2006 Sony started using ARccOS Protection on some of their film DVDs, but later issued a recall.
Sony Music Entertainment.
Sony Music Entertainment (also known as SME or Sony Music) is the second-largest global recorded music company of the "big four" record companies and is controlled by Sony Corporation of America, the United States subsidiary of Japan's "Sony". The company owns full or partial rights to the catalogues of Michael Jackson, The Beatles, Usher, Eminem, Akon, and others.
In one of its largest-ever acquisitions, Sony purchased CBS Record Group in 1987 for US$2 billion. In the process, Sony gained the rights to the catalogue of Michael Jackson, considered by the "Guinness Book of World Records" to be the most successful entertainer of all time. The acquisition of CBS Records provided the foundation for the formation of Sony Music Entertainment, which Sony established in 1991.
In 2004, Sony entered into a joint venture with Bertelsmann AG, merging Sony Music Entertainment with Bertelsmann Music Group to create Sony BMG. In 2005, Sony BMG faced a copy protection scandal, because its music CDs had installed malware on users' computers that was posing a security risk to affected customers. In 2007, the company acquired Famous Music for US$370 million, gaining the rights to the catalogues of Eminem and Akon, among others.
Sony bought out Bertelsmann's share in the company and formed a new Sony Music Entertainment in 2008. Since then, the company has undergone management changes. In January 1988, Sony acquired CBS Records and the 50% of CBS/Sony Group. In March 1988, four wholly owned subsidiaries were folded into CBS/Sony Group and the company was renamed as Sony Music Entertainment Japan Inc.
Sony/ATV Music Publishing.
Besides its record label, Sony operates other music businesses. In 1995, Sony purchased a 50% stake in ATV Music Publishing, forming Sony/ATV Music Publishing. At the time, the publishing company was the second-largest of its kind in the world. The company owns much of the publishing rights to the catalogue of The Beatles. Sony purchased digital music recognition company Gracenote for US$260 million in 2008.
Finance.
Sony Financial Services.
Sony Financial Holdings is a holding company for Sony's financial services business. It owns and oversees the operation of Sony Life (in Japan and the Philippines), Sony Assurance, Sony Bank and Sony Bank Securities. The company is headquartered in Tokyo, Japan.
Sony Financial accounts for half of Sony's global earnings. The unit proved the most profitable of Sony's businesses in fiscal year 2006, earning $1.7 billion in profit. Sony Financial's low fees have aided the unit's popularity while threatening Sony's premium brand name.
Corporate information.
Finances.
Sony is one of Japan's largest corporations by revenue. It had revenues of ¥6.493 trillion in 2012. It also maintains large reserves of cash, with ¥895 billion on hand as of 2012. In May 2012, Sony shares were valued at about $15 billion.
The company was immensely profitable throughout the 1990s and early 2000s, in part because of the success of its new PlayStation line. The company encountered financial difficulty in the mid- to late-2000s due to a number of factors: the global financial crisis, increased competition for PlayStation, and the devastating Japanese earthquake of 2011. The company faced three consecutive years of losses leading up to 2011. While noting the negative effects of intervening circumstances such as natural disasters and fluctuating currency exchange rates, the "Financial Times" criticized the company for its "lack of resilience" and "inability to gauge the economy." The newspaper voiced skepticism about Sony's revitalization efforts, given a lack of tangible results.
In September 2000 Sony had a market capitalization of $100 billion; but by December 2011 it had plunged to $18 billion, reflecting falling prospects for Sony but also reflecting grossly inflated share prices of the 'dot.com' years. Net worth, as measured by stockholder equity, has steadily grown from $17.9 billion in March 2002 to $35.6 billion through December 2011. Earnings yield (inverse of the price to earnings ratio) has never been more than 5% and usually much less; thus Sony has always traded in over-priced ranges with the exception of the 2009 market bottom.
In April 2012, Sony announced that it would reduce its workforce by 10,000 (6% of its employee base) as part of CEO Hirai's effort to get the company back into the black. This came after a loss of 520 billion yen (roughly US$6.36 billion) for fiscal 2012, the worst since the company was founded. Accumulation loss for the past four years was 919.32 billion-yen. Sony plans to increase its marketing expenses by 30% in 2012.
1,000 of the jobs cut come from the company's mobile phone unit's workforce. 700 jobs will be cut in the 2012–2013 fiscal year and the remaining 300 in the following fiscal year.
On 9 December 2008, Sony Corporation announced that it would be cutting 8,000 jobs, dropping 8,000 contractors and reducing its global manufacturing sites by 10% to save $1.1 billion per year.
In January 2013, Sony announced it was selling its US headquarters building for $1.1 billion to a consortium led by real estate developer The Chetrit Group.
On 28 January 2014, Moody's Investors Services dropped Sony's credit rating to Ba1—"judged to have speculative elements and a significant credit risk"—saying that the company's "profitability is likely to remain weak and volatile."
On 6 February 2014, Sony announced it would trim as many as 5,000 jobs as it attempts to sell its PC business and focus on mobile and tablets.
Environmental record.
In November 2011, Sony was ranked 9th (jointly with Panasonic) in Greenpeace's Guide to Greener Electronics. This chart grades major electronics companies on their environmental work. The company scored 3.6/10, incurring a penalty point for comments it has made in opposition to energy efficiency standards in California. It also risks a further penalty point in future editions for being a member of trade associations that have commented against energy efficiency standards. Together with Philips, Sony receives the highest score for energy policy advocacy after calling on the EU to adopt an unconditional 30% reduction target for greenhouse gas emissions by 2020. Meanwhile, it receives full marks for the efficiency of its products. In 2007, Sony ranked 14th on the Greenpeace guide. Sony fell from its earlier 11th-place ranking due to Greenpeace's claims that Sony had double standards in their waste policies.
Since 1976, Sony has had an Environmental Conference. Sony's policies address their effects on global warming, the environment, and resources. They are taking steps to reduce the amount of greenhouse gases that they put out as well as regulating the products they get from their suppliers in a process that they call "green procurement". Sony has said that they have signed on to have about 75 percent of their Sony Building running on geothermal power. The "Sony Take Back Recycling Program" allow consumers to recycle the electronics products that they buy from Sony by taking them to eCycle (Recycling) drop-off points around the U.S. The company has also developed a biobattery that runs on sugars and carbohydrates that works similarly to the way living creatures work. This is the most powerful small biobattery to date.
In 2000, Sony faced criticism for a document entitled "NGO Strategy" that was leaked to the press. The document involved the company's surveillance of environmental activists in an attempt to plan how to counter their movements. It specifically mentioned environmental groups that were trying to pass laws that held electronics-producing companies responsible for the cleanup of the toxic chemicals contained in their merchandise.
Community Engagement.
"EYE SEE project"
Sony Corporation is actively involved in the EYE SEE project conducted by UNICEF. EYE SEE digital photography workshops have been run for children in Argentina, Tunisia, Mali, South Africa, Ethiopia, Madagascar, Rwanda, Liberia and Pakistan.
"South Africa Mobile Library Project"
Sony assists The South Africa Primary Education Support Initiative (SAPESI) through financial donations and children book donations to the South Africa Mobile Library Project.
"The Sony Canada Charitable Foundation"
The Sony Canada Charitable Foundation (SCCF) is a non-profit organization which supports three key charities; the Make-A-Wish Canada, the United Way of Canada and the EarthDay and ECOKIDS program.
"Sony Foundation" and "You Can"
After the floods of 2011 and Victorian bushfires, Sony Music released benefit albums with money raised going to the Sony Foundation.
You Can is the youth cancer program of Sony Foundation.
"Open Planet Ideas Crowdsourcing Project"
Sony launched its Open Planet Ideas Crowdsourcing Project, in partnership with the World Wildlife Fund and the design group, IDEO.
"Street Football Stadium Project"
On the occasion of the 2014 World Cup in Brazil, Sony partnered with streetfootballworld and launched the Street Football Stadium Project to support football-based educational programmes in local communities across Latin America and Brazil.

</doc>
<doc id="26990" url="http://en.wikipedia.org/wiki?curid=26990" title="Social psychology">
Social psychology

In psychology, social psychology is the scientific study of how people's thoughts, feelings, and behaviors are influenced by the actual, imagined, or implied presence of others. In this definition, "scientific" refers to the empirical method of investigation. The terms "thoughts", "feelings", and "behaviors" include all psychological variables that are measurable in a human being. The statement that others' presence may be "imagined" or "implied" suggests that we are prone to social influence even when no other people are present, such as when watching television, or following internalized cultural norms.
Social psychologists typically explain human behavior as a result of the interaction of mental states and immediate social situations. 
Social psychologists therefore deal with the factors that lead us to behave in a given way in the presence of others, and look at the conditions under which certain behavior/actions and feelings occur. Social psychology is concerned with the way these feelings, thoughts, beliefs, intentions and goals are constructed and how such psychological factors, in turn, influence our interactions with others.
Social psychology is a discipline that bridges the gap between psychology and sociology. During the years immediately following World War II, there was frequent collaboration between psychologists and sociologists. However, the two disciplines have become increasingly specialized and isolated from each other in recent years, with sociologists focusing on "macro variables" (e.g., social structure) to a much greater extent. Nevertheless, sociological approaches to social psychology remain an important counterpart to psychological research in this area.
In addition to the split between psychology and sociology, there has been a somewhat less pronounced difference in emphasis between American social psychologists and European social psychologists. As a broad generalization, American researchers traditionally have focused more on the individual, whereas Europeans have paid more attention to group level phenomena (see group dynamics).
History.
Although there were some older treatises about social psychology such as those by Islamic philosopher Al-Farabi (Alpharabius), the discipline of social psychology, as its modern day definition, began in the United States at the dawn of the 20th century. However, the discipline had already developed a significant foundation. Following the 18th century, those in the emerging field of social psychology were concerned with developing concrete explanations for different aspects of human nature. They desired to discover concrete cause and effect relationships that explained the social interactions in the world around them. In order to do so, they believed that the scientific method, an empirically based scientific measure, could be applied to human behavior.
The first published study in this area was an experiment in 1898 by Norman Triplett on the phenomenon of social facilitation. During the 1930s, many Gestalt psychologists, most notably Kurt Lewin, fled to the United States from Nazi Germany. They were instrumental in developing the field as something separate from the behavioral and psychoanalytic schools that were dominant during that time, and social psychology has always maintained the legacy of their interests in perception and cognition. Attitudes and small group phenomena were the most commonly studied topics in this era.
During World War II, social psychologists studied persuasion and propaganda for the U.S. military. After the war, researchers became interested in a variety of social problems, including gender issues and racial prejudice. Most notable, revealing, and contentious of them all were the Stanley Milgram shock experiments on obedience to authority. In the sixties, there was growing interest in new topics, such as cognitive dissonance, bystander intervention, and aggression. By the 1970s, however, social psychology in America had reached a crisis. There was heated debate over the ethics of laboratory experimentation, whether or not attitudes really predicted behavior, and how much science could be done in a cultural context. This was also the time when a radical situationist approach challenged the relevance of self and personality in psychology.
Social psychology reached a more mature level in both theories and methods during the 1980s and 1990s. Careful ethical standards now regulate research. Pluralistic and multicultural perspectives have emerged. Modern researchers are interested in many phenomena, but attribution, social cognition, and the self-concept are perhaps the greatest areas of growth in recent years. Social psychologists have also maintained their applied interests with contributions in health, environmental, and legal psychology.
Intrapersonal phenomena.
Attitudes.
In social psychology, attitudes are defined as learned, global evaluations of a person, object, place, or issue that influence thought and action. Put more simply, attitudes are basic expressions of approval or disapproval, favorability or unfavorability, or as Bem put it, likes and dislikes. Examples would include liking chocolate ice cream, or endorsing the values of a particular political party.
Social psychologists have studied attitude formation, the structure of attitudes, attitude change, the function of attitudes, and the relationship between attitudes and behavior. Because people are influenced by the situation, general attitudes are not always good predictors of specific behavior. For example, for a variety of reasons, a person may value the environment but not recycle a can on a particular day.
In recent times, research on attitudes has examined the distinction between traditional, self-reported attitude measures and "implicit" or unconscious attitudes. For example, experiments using the Implicit Association Test have found that people often demonstrate implicit bias against other races, even when their explicit responses reveal equal mindedness. One study found that explicit attitudes correlate with verbal behavior in interracial interactions, whereas implicit attitudes correlate with nonverbal behavior.
One hypothesis on how attitudes are formed, first advanced by Abraham Tesser in 1983, is that strong likes and dislikes are rooted in our genetic make-up. Tesser speculates that individuals are disposed to hold certain strong attitudes as a result of inborn physical, sensory, and cognitive skills, temperament, and personality traits. Whatever disposition nature elects to give us, our most treasured attitudes are often formed as a result of exposure to attitude objects; our history of rewards and punishments; the attitude that our parents, friends, and enemies express; the social and cultural context in which we live; and other types of experiences we have. Obviously, attitudes are formed through the basic process of learning. Numerous studies have shown that people can form strong positive and negative attitudes toward neutral objects that are in some way linked to emotionally charged stimuli.:185–186
Attitudes are also involved in several other areas of the discipline, such as conformity, interpersonal attraction, social perception, and prejudice.
Persuasion.
The topic of persuasion has received a great deal of attention in recent years. Persuasion is an active method of influence that attempts to guide people toward the adoption of an attitude, idea, or behavior by rational or emotive means. Persuasion relies on "appeals" rather than strong pressure or coercion. Numerous variables have been found to influence the persuasion process; these are normally presented in five major categories: "who" said "what" to "whom" and "how".
Dual-process theories of persuasion (such as the elaboration likelihood model) maintain that the persuasive process is mediated by two separate routes; central and peripheral. The central route of persuasion is more fact-based and results in longer lasting change, but requires motivation to process. The peripheral route is more superficial and results in shorter lasting change, but does not require as much motivation to process. An example of a peripheral route of persuasion might be a politician using a flag lapel pin, smiling, and wearing a crisp, clean shirt. Notice that this does not require motivation to be persuasive, but should not last as long as persuasion based on the central route. If that politician were to outline exactly what they believed, and their previous voting record, this would be using the central route, and would result in longer lasting change, but would require a good deal of motivation to process.
Social cognition.
Social cognition is a growing area of social psychology that studies how people perceive, think about, and remember information about others. Much research rests on the assertion that people think about (other) people differently from non-social targets. This assertion is supported by the social cognitive deficits exhibited by people with Williams syndrome and autism. Person perception is the study of how people form impressions of others. The study of how people form beliefs about each other while interacting is known as interpersonal perception.
A major research topic in social cognition is attribution. Attributions are the explanations we make for people's behavior, either our own behavior or the behavior of others. We can ascribe the locus of a behavior to either internal or external factors. An "internal", or dispositional, attribution assigns behavior to causes related to inner traits such as personality, disposition, character or ability. An "external", or situational, attribution involves situational elements, such as the weather.:111 A second element, attribution, ascribes the cause of behavior to either stable or unstable factors. Finally, we also attribute causes of behavior to either controllable or uncontrollable factors.
Numerous biases in the attribution process have been discovered. For instance, the fundamental attribution error is the tendency to make dispositional attributions for behavior, overestimating the influence of personality and underestimating the influence of situations.:724 The actor-observer difference is a refinement of this bias, the tendency to make dispositional attributions for other people's behavior and situational attributions for our own.:107 The self-serving bias is the tendency to attribute dispositional causes for successes, and situational causes for failure, particularly when self-esteem is threatened. This leads to assuming one's successes are from innate traits, and one's failures are due to situations, including other people.:109 Other ways people protect their self-esteem are by believing in a just world, blaming victims for their suffering, and making defensive attributions, which explain our behavior in ways which defend us from feelings of vulnerability and mortality.:111 Researchers have found that mildly depressed individuals often lack this bias and actually have more realistic perceptions of reality (as measured by the opinions of others).
Heuristics are cognitive short cuts. Instead of weighing all the evidence when making a decision, people rely on heuristics to save time and energy. The availability heuristic occurs when people estimate the probability of an outcome based on how easy that outcome is to imagine. As such, vivid or highly memorable possibilities will be perceived as more likely than those that are harder to picture or are difficult to understand, resulting in a corresponding cognitive bias. The representativeness heuristic is a shortcut people use to categorize something based on how similar it is to a prototype they know of.:63 Numerous other biases have been found by social cognition researchers. The hindsight bias is a false memory of having predicted events, or an exaggeration of actual predictions, after becoming aware of the outcome. The confirmation bias is a type of bias leading to the tendency to search for, or interpret information in a way that confirms one's preconceptions.
Another key concept in social cognition is the assumption that reality is too complex to easily discern. As a result, we tend to see the world according to simplified schemas or images of reality. Schemas are generalized mental representations that organize knowledge and guide information processing. Schemas often operate automatically and unintentionally, and can lead to biases in perception and memory. Expectations from schemas may lead us to see something that is not there. One experiment found that people are more likely to misperceive a weapon in the hands of a black man than a white man. This type of schema is actually a stereotype, a generalized set of beliefs about a particular group of people (when incorrect, an ultimate attribution error). Stereotypes are often related to negative or preferential attitudes (prejudice) and behavior (discrimination). Schemas for behaviors (e.g., going to a restaurant, doing laundry) are known as "scripts".
Self-concept.
Self-concept is a term referring to the whole sum of beliefs that people have about themselves. However, what specifically does self-concept consist of? According to Hazel Markus (1977), the self-concept is made up of cognitive molecules called self-schemas – beliefs that people have about themselves that guide the processing of self-reliant information. For example, an athlete at a university would have multiple selves that would process different information pertinent to each self: the student would be one "self," who would process information pertinent to a student (taking notes in class, completing a homework assignment, etc.); the athlete would be the "self" who processes information about things related to being an athlete (recognizing an incoming pass, aiming a shot, etc.). These "selves" are part of one's identity and the self-reliant information is the information that relies on the proper "self" to process and react on it. If a "self" is not part of one's identity, then it is much more difficult for one to react. For example, a civilian may not know how to handle a hostile threat as a trained Marine would. The Marine contains a "self" that would enable him/her to process the information about the hostile threat and react accordingly, whereas a civilian may not contain that self, disabling them from properly processing the information from the hostile threat and, furthermore, debilitating them from acting accordingly. Self-schemas are to an individual’s total self–concept as a hypothesis is to a theory, or a book is to a library. A good example is the body weight self-schema; people who regard themselves as over or underweight, or for those whom body image is a significant self-concept aspect, are considered "schematics" with respect to weight. For these people a range of otherwise mundane events – grocery shopping, new clothes, eating out, or going to the beach – can trigger thoughts about the self. In contrast, people who do not regard their weight as an important part of their lives are "a-schematic" on that attribute.
It is rather clear that the self is a special object of our attention. Whether one is mentally focused on a memory, a conversation, a foul smell, the song that is stuck in one's head, or this sentence, consciousness is like a spotlight. This spotlight can shine on only one object at a time, but it can switch rapidly from one object to another and process the information out of awareness. In this spotlight the self is front and center: things relating to the self have the spotlight more often.
The self's ABCs are affect, behavior, and cognition. An affective (or emotional) question: How do people evaluate themselves, enhance their self-image, and maintain a secure sense of identity? A behavioral question: How do people regulate their own actions and present themselves to others according to interpersonal demands? A cognitive question: How do individuals become themselves, build a self-concept, and uphold a stable sense of identity?:53
Affective forecasting is the process of predicting how one would feel in response to future emotional events. Studies done by Timothy Wilson and Daniel Gilbert in 2003 have shown that people overestimate the strength of reaction to anticipated positive and negative life events that they actually feel when the event does occur.
There are many theories on the perception of our own behavior. Daryl Bem's (1972) self-perception theory claims that when internal cues are difficult to interpret, people gain self-insight by observing their own behavior. Leon Festinger's 1954 social comparison theory is that people evaluate their own abilities and opinions by comparing themselves to others when they are uncertain of their own ability or opinions. There is also the facial feedback hypothesis: that changes in facial expression can lead to corresponding changes in emotion.:56
The fields of social psychology and personality have merged over the years, and social psychologists have developed an interest in self-related phenomena. In contrast with traditional personality theory, however, social psychologists place a greater emphasis on cognitions than on traits. Much research focuses on the self-concept, which is a person's understanding of his or her self. The self-concept is often divided into a cognitive component, known as the "self-schema", and an evaluative component, the "self-esteem". The need to maintain a healthy self-esteem is recognized as a central human motivation in the field of social psychology.
Self-efficacy beliefs are associated with the self-schema. These are expectations that performance on some task will be effective and successful. Social psychologists also study such self-related processes as self-control and self-presentation.
People develop their self-concepts by varied means, including introspection, feedback from others, self-perception, and social comparison. By comparison to relevant others, people gain information about themselves, and they make inferences that are relevant to self-esteem. Social comparisons can be either "upward" or "downward," that is, comparisons to people who are either higher in status or ability, or lower in status or ability. Downward comparisons are often made in order to elevate self-esteem.
Self-perception is a specialized form of attribution that involves making inferences about oneself after observing one's own behavior. Psychologists have found that too many extrinsic rewards (e.g. money) tend to reduce intrinsic motivation through the self-perception process, a phenomenon known as overjustification. People's attention is directed to the reward and they lose interest in the task when the reward is no longer offered. This is an important exception to reinforcement theory.
Interpersonal phenomena.
Social influence.
Social influence is an overarching term given to describe the persuasive effects people have on each other. It is seen as a fundamental value in social psychology and overlaps considerably with research on attitudes and persuasion. The three main areas of social influence include: conformity, compliance, and obedience. Social influence is also closely related to the study of group dynamics, as most principles of influence are strongest when they take place in social groups.
The first major area of social influence is conformity. Conformity is defined as the tendency to act or think like other members of a group. The identity of members within a group, i.e. status, similarity, expertise, as well as cohesion, prior commitment, and accountability to the group help to determine the level of conformity of an individual. Individual variation among group members plays a key role in the dynamic of how willing people will be to conform.:27 Conformity is usually viewed as a negative tendency in American culture, but a certain amount of conformity is adaptive in some situations, as is nonconformity in other situations.:15
The second major area of social influence research is compliance. Compliance refers to any change in behavior that is due to a request or suggestion from another person. The Foot-in-the-door technique is a compliance method in which the persuader requests a small favor and then follows up with requesting a larger favor, e.g., asking for the time and then asking for ten dollars. A related trick is the Bait and switch.
The third major form of social influence is obedience; this is a change in behavior that is the result of a direct order or command from another person. Obedience as a form of compliance was dramatically highlighted by the Milgram study, wherein people were ready to administer shocks to a person in distress on a researcher's command.:41
An unusual kind of social influence is the self-fulfilling prophecy. This is a prediction that, in being made, actually causes itself to become true. For example, in the stock market, if it is widely believed that a crash is imminent, investors may lose confidence, sell most of their stock, and thus actually cause the crash. Similarly, people may expect hostility in others and actually induce this hostility by their own behavior.:18
Group dynamics.
A group can be defined as two or more individuals that are connected to each another by social relationships. Groups tend to interact, influence each other, and share a common identity. They have a number of emergent qualities that distinguish them from aggregates:
Temporary groups and aggregates share few or none of these features, and do not qualify as true social groups. People waiting in line to get on a bus, for example, do not constitute a group.
Groups are important not only because they offer social support, resources, and a feeling of belonging, but because they supplement an individual's self-concept. To a large extent, humans define themselves by the group memberships which form their social identity. The shared social identity of individuals within a group influences intergroup behavior, the way in which groups behave towards and perceive each other. These perceptions and behaviors in turn define the social identity of individuals within the interacting groups. The tendency to define oneself by membership in a group may lead to intergroup discrimination, which involves favorable perceptions and behaviors directed towards the in-group, but negative perceptions and behaviors directed towards the out-group. On the other hand, such discrimination and segregation may sometimes exist partly to facilitate a diversity which strengthens society. Intergroup discrimination leads to prejudice and stereotyping, while the processes of social facilitation and group polarization encourage extreme behaviors towards the out-group.
Groups often moderate and improve decision making, and are frequently relied upon for these benefits, such as in committees and juries. A number of group biases, however, can interfere with effective decision making. For example, group polarization, formerly known as the "risky shift," occurs when people polarize their views in a more extreme direction after group discussion. More problematic is the phenomenon of groupthink. This is a collective thinking defect that is characterized by a premature consensus or an incorrect assumption of consensus, caused by members of a group failing to promote views which are not consistent with the views of other members. Groupthink occurs in a variety of situations, including isolation of a group and the presence of a highly directive leader. Janis offered the 1961 Bay of Pigs Invasion as a historical case of groupthink.
Groups also affect performance and productivity. Social facilitation, for example, is a tendency to work harder and faster in the presence of others. Social facilitation increases the "dominant response"‍ '​s likelihood, which tends to improve performance on simple tasks and reduce it on complex tasks. In contrast, social loafing is the tendency of individuals to slack off when working in a group. Social loafing is common when the task is considered unimportant and individual contributions are not easy to see.
Social psychologists study group-related (collective) phenomena such as the behavior of crowds. An important concept in this area is deindividuation, a reduced state of self-awareness that can be caused by feelings of anonymity. Deindividuation is associated with uninhibited and sometimes dangerous behavior. It is common in crowds and mobs, but it can also be caused by a disguise, a uniform, alcohol, dark environments, or online anonymity.
Interpersonal attraction.
A major area in the study of people's relations to each other is interpersonal attraction. This refers to all forces that lead people to like each other, establish relationships, and (in some cases) fall in love. Several general principles of attraction have been discovered by social psychologists, but many still continue to experiment and do research to find out more. One of the most important factors in interpersonal attraction is how similar two particular people are. The more similar two people are in general attitudes, backgrounds, environments, worldviews, and other traits, the more probable an attraction is possible.
Physical attractiveness is an important element of romantic relationships, particularly in the early stages characterized by high levels of passion. Later on, similarity and other compatibility factors become more important, and the type of love people experience shifts from "passionate" to "companionate". Robert Sternberg has suggested that there are actually three components of love: intimacy, passion, and commitment. When two (or more) people experience all three, they are said to be in a state of consummate love.
According to social exchange theory, relationships are based on rational choice and cost-benefit analysis. If one partner's costs begin to outweigh his or her benefits, that person may leave the relationship, especially if there are good alternatives available. This theory is similar to the minimax principle proposed by mathematicians and economists (despite the fact that human relationships are not zero-sum games). With time, long term relationships tend to become communal rather than simply based on exchange.
Research.
Methods.
Social psychology is an empirical science that attempts to answer questions about human behavior by testing hypotheses, both in the laboratory and in the field. Careful attention to sampling, research design, and statistical analysis is important; results are published in peer reviewed journals such as the "Journal of Experimental Social Psychology", "Personality and Social Psychology Bulletin" and the "Journal of Personality and Social Psychology". Social psychology studies also appear in general science journals such as "Psychological Science" and "Science".
Experimental methods involve the researcher altering a variable in the environment and measuring the effect on another variable. An example would be allowing two groups of children to play violent or nonviolent videogames, and then observing their subsequent level of aggression during free-play period. A valid experiment is controlled and uses random assignment.
Correlational methods examine the statistical association between two naturally occurring variables. For example, one could correlate the amount of violent television children watch at home with the number of violent incidents the children participate in at school. Note that this study would "not" prove that violent TV causes aggression in children: it is quite possible that aggressive children choose to watch more violent TV.
Observational methods are purely descriptive and include naturalistic observation, "contrived" observation, participant observation, and archival analysis. These are less common in social psychology but are sometimes used when first investigating a phenomenon. An example would be to unobtrusively observe children on a playground (with a videocamera, perhaps) and record the number and types of aggressive actions displayed.
Whenever possible, social psychologists rely on controlled experimentation. Controlled experiments require the manipulation of one or more independent variables in order to examine the effect on a dependent variable. Experiments are useful in social psychology because they are high in internal validity, meaning that they are free from the influence of confounding or extraneous variables, and so are more likely to accurately indicate a causal relationship. However, the small samples used in controlled experiments are typically low in external validity, or the degree to which the results can be generalized to the larger population. There is usually a trade-off between experimental control (internal validity) and being able to generalize to the population (external validity).
Because it is usually impossible to test everyone, research tends to be conducted on a sample of persons from the wider population. Social psychologists frequently use survey research when they are interested in results that are high in external validity. Surveys use various forms of random sampling to obtain a sample of respondents that are representative of a population. This type of research is usually descriptive or correlational because there is no experimental control over variables. However, new statistical methods like structural equation modeling are being used to test for potential causal relationships in this type of data.
Regardless of which method is used, it is important to evaluate the research hypothesis using the results, either confirming or rejecting the original prediction. Social psychologists use statistics and probability testing to judge their results; these define a significant finding as less than 5% likely to be due to chance. Replications are important, to ensure that the result is valid and not due to chance, or some feature of a particular sample. False positive conclusions, often resulting from the pressure to publish or the author's own confirmation bias, are a hazard in the field.
Ethics.
The goal of social psychology is to understand cognition and behavior as they naturally occur in a social context, but the very act of observing people can influence and alter their behavior. For this reason, many social psychology experiments utilize deception to conceal or distort certain aspects of the study. Deception may include false cover stories, false participants (known as confederates or stooges), false feedback given to the participants, and so on.
The practice of deception has been challenged by some psychologists who maintain that deception under any circumstances is unethical, and that other research strategies (e.g., role-playing) should be used instead. Unfortunately, research has shown that role-playing studies do not produce the same results as deception studies and this has cast doubt on their validity. In addition to deception, experimenters have at times put people into potentially uncomfortable or embarrassing situations (e.g., the Milgram experiment and Stanford prison experiment), and this has also been criticized for ethical reasons.
To protect the rights and well-being of research participants, and at the same time discover meaningful results and insights into human behavior, virtually all social psychology research must pass an ethical review process. At most colleges and universities, this is conducted by an ethics committee or Institutional Review Board. This group examines the proposed research to make sure that no harm is likely to be done to the participants, and that the study's benefits outweigh any possible risks or discomforts to people taking part in the study.
Furthermore, a process of informed consent is often used to make sure that volunteers know what will happen in the experiment and understand that they are allowed to quit the experiment at any time. A debriefing is typically done at the experiment's conclusion in order to reveal any deceptions used and generally make sure that the participants are unharmed by the procedures. Today, most research in social psychology involves no more risk of harm than can be expected from routine psychological testing or normal daily activities.
Replication Crisis.
Social psychology has recently found itself at the center of a "replication crisis" due to some research findings proving difficult to replicate. Replication failures are not unique to social psychology and are found in all fields of science. However, several factors have combined to put social psychology at the center of the current controversy.
Firstly, questionable researcher practices (QRP) have been identified as common in the field. Such practices, while not intentionally fraudulent, involve converting undesired statistical outcomes into desired outcomes via the manipulation of statistical analyses, sample size or data management, typically to convert non-significant findings into significant ones. Some studies have suggested that at least mild versions of QRP are highly prevalent. One of the critics of Daryl Bem in the feeling the future controversy has suggested that the evidence for precognition in this study could (at least in part) be attributed to QRP.
Secondly, social psychology has found itself at the center of several recent scandals involving outright fraudulent research. Most notably the admitted data fabrication by Diederik Stapel as well as allegations against others. However, most scholars acknowledge that fraud is, perhaps, the lesser contribution to replication crises.
Third, several effects in social psychology have been found to be difficult to replicate even before the current replication crisis. For example the scientific journal Judgment and Decision Making has published several studies over the years that fail to provide support for the unconscious thought theory. Replications appear particularly difficult when research trials are pre-registered and conducted by research groups not highly invested in the theory under questioning.
These three elements together have resulted in renewed attention for replication supported by Kahneman. Scrutiny of many effects have shown that several core beliefs are hard to replicate. A recent special edition of the journal Social Psychology focused on replication studies and a number of previously held beliefs were found to be difficult to replicate. A 2012 special edition of the journal Perspectives on Psychological Science also focused on issues ranging from publication bias to null-aversion that contribute to the replication crises in psychology
It is important to note that this replication crisis does not mean that social psychology is unscientific. Rather this process is a healthy if sometimes acrimonious part of the scientific process in which old ideas or those that cannot withstand careful scrutiny are pruned. The consequence is that some areas of social psychology once considered solid, such as social priming, have come under increased scrutiny due to failed replications
Famous experiments.
The Asch conformity experiments demonstrated the power of conformity in small groups with a line estimation task that was designed to be extremely easy. On over a third of the trials, participants conformed to the majority, even though the majority judgment was clearly wrong. Seventy-five percent of the participants conformed at least once during the experiment.
Muzafer Sherif's Robbers' Cave Experiment divided boys into two competing groups to explore how much hostility and aggression would emerge. Sherif's explanation of the results became known as realistic group conflict theory, because the intergroup conflict was induced through competition over resources. Inducing cooperation and superordinate goals later reversed this effect.
In Leon Festinger's cognitive dissonance experiment, participants were asked to perform a boring task. They were divided into 2 groups and given two different pay scales. At the study's end, some participants were paid $1 to say that they enjoyed the task and another group of participants was paid $20 to say the same lie. The first group ($1) later reported liking the task better than the second group ($20). Festinger's explanation was that for people in the first group being paid only $1 is not sufficient incentive for lying and those who were paid $1 experienced dissonance. They could only overcome that dissonance by justifying their lies by changing their previously unfavorable attitudes about the task. Being paid $20 provides a reason for the doing the boring task, therefore no dissonance.
One of the most notable experiments in social psychology was the Milgram experiment, which studied how far people would go to obey an authority figure. Following the events of The Holocaust in World War II, the experiment showed that (most) normal American citizens were capable of following orders from an authority even when they believed they were causing an innocent person to suffer.
Albert Bandura's Bobo doll experiment demonstrated how aggression is learned by imitation. This set of studies fueled debates regarding media violence which continue to be waged among scholars.
In the Stanford prison study, by Philip Zimbardo, a simulated exercise between student prisoners and guards showed how far people would follow an adopted role. In just a few days, the "guards" became brutal and cruel, and the prisoners became miserable and compliant. This was initially argued to be an important demonstration of the power of the immediate social situation and its capacity to overwhelm normal personality traits. However, to this day, it remains a matter of contention what conclusions may be drawn from this study. For example, it has been pointed out that participant self-selection may have affected the participants' behaviour, and that the participants' personality influenced their reactions in a variety of ways, including how long they chose to remain in the study. One of the most concerted empirical revisitations of the themes raised by Zimbardo came with the 2002 BBC prison study.

</doc>
<doc id="26992" url="http://en.wikipedia.org/wiki?curid=26992" title="Suleiman the Magnificent">
Suleiman the Magnificent

Suleiman I (Ottoman Turkish: سلطان سليمان اول‎, Turkish: "I. Süleyman or Kanunî Sultan Süleyman"), known as “the Magnificent” in the West and “Kanuni” (the Lawgiver) in the East, (6 November 1494 – 7 September 1566) was the Caliph of Islam and the tenth and longest-reigning Sultan of the Ottoman Empire, from 1520 to his death in 1566.
Suleiman became a prominent monarch of 16th-century Europe, presiding over the apex of the Ottoman Empire's military, political and economic power. Suleiman personally led Ottoman armies in conquering the Christian strongholds of Belgrade, Rhodes, as well as most of Hungary before his conquests were checked at the Siege of Vienna in 1529. He annexed much of the Middle East in his conflict with the Safavids and large areas of North Africa as far west as Algeria. Under his rule, the Ottoman fleet dominated the seas from the Mediterranean to the Red Sea and through the Persian Gulf.
At the helm of an expanding empire, Suleiman personally instituted major legislative changes relating to society, education, taxation, and criminal law. His canonical law (or the "Kanuns") fixed the form of the empire for centuries after his death. Not only was Suleiman a distinguished poet and goldsmith; he also became a great patron of culture, overseeing the "Golden" age of the Ottoman Empire in its artistic, literary and architectural development.
Breaking with Ottoman tradition, Suleiman married Roxelana, a former Christian girl converted to Islam from his harem, who became subsequently known and influential as Hürrem Sultan. Their son, Selim II, succeeded Suleiman following his death in 1566 after 46 years of rule. Suleiman's previous heir apparent, Mustafa, had been strangled to death 13 years prior at the sultan's order. His other son Bayezid had been killed by his support and Selim's order in 1561 with four of his sons.
Alternative names and titles.
Suleiman was known as Ottoman Turkish: سلطان سليمان اول‎, "Sultān Suleimān-i evvel" or السلطان سليمان القانونى‎‎, "Kānūnī Sultān Suleimān", Modern Turkish: "I. Süleyman" (]) or "Kanunî Sultan Süleyman"; and in the East, as "The Lawgiver" (Turkish: "Kanuni"; Arabic: القانونى‎‎, "al‐Qānūnī") where "evvel" means "the first" and "kanuni" means "lawgiver" for his complete reconstruction of the Ottoman legal system.
Early life.
Suleiman was born in Trabzon along the east coast of the Black Sea, probably on 6 November 1494. His mother was Ayşe Hafsa Sultan or Hafsa Sultan, who died in 1534. At the age of seven, he was sent to study science, history, literature, theology, and military tactics in the schools of the Topkapı Palace in Constantinople (modern Istanbul). As a young man, he befriended Pargalı Ibrahim, a slave who later became one of his most trusted advisers. From the age of seventeen, he was appointed as the governor of first Kaffa (Theodosia), then Sarukhan (Manisa) with a brief tenure at Adrianople (now Edirne). Upon the death of his father, Selim I (1465–1520), Suleiman entered Constantinople and ascended to the throne as the tenth Ottoman Sultan. An early description of Suleiman, a few weeks following his accession, was provided by the Venetian envoy Bartolomeo Contarini: "He is twenty-six years of age, tall, but wiry, and of a delicate complexion. His neck is a little too long, his face thin, and his nose aquiline. He has a shade of a mustache and a small beard; nevertheless he has a pleasant mien, though his skin tends to be a light pallor. He is said to be a wise Lord, fond of study, and all men hope for good from his rule." Some historians claim that in his youth Suleiman had an admiration for Alexander the Great. He was influenced by Alexander's vision of building a world empire that would encompass the east and the west, and this created a drive for his subsequent military campaigns in Asia and in Africa, as well as in Europe.
Military campaigns.
Conquests in Europe.
Upon succeeding his father, Suleiman began a series of military conquests, eventually suppressing a revolt led by the Ottoman-appointed governor of Damascus in 1521. Suleiman soon made preparations for the conquest of Belgrade from the Kingdom of Hungary—something his great-grandfather Mehmed II had failed to achieve. Its capture was vital in removing the Hungarians and Croats who, following the defeats of the Serbs, Bulgarians and the Byzantines, remained the only formidable force who could block further Ottoman gains in Europe. Suleiman encircled Belgrade and began a series of heavy bombardments from an island in the Danube. Belgrade, with a garrison of only 700 men, and receiving no aid from Hungary, fell in August 1521.
The fall of Christendom's major strongholds spread fear across Europe. As the ambassador of the Holy Roman Empire to Constantinople was to note, "The capture of Belgrade was at the origin of the dramatic events which engulfed Hungary. It led to the death of King Louis, the capture of Buda, the occupation of Transylvania, the ruin of a flourishing kingdom and the fear of neighboring nations that they would suffer the same fate..."
The road to Hungary and Austria lay open, but Suleiman turned his attention instead to the Eastern Mediterranean island of Rhodes, the home base of the Knights Hospitaller. In the summer of 1522, taking advantage of the large Navy he inherited from his father, Suleiman dispatched an armada of some 400 ships towards Rhodes, while personally leading an army of 100,000 across Asia Minor to a point opposite the island itself. Here Suleiman built a large fortification, Marmaris Castle, that served as a base for the Ottoman Navy. Following the brutal five-month Siege of Rhodes (1522), Rhodes capitulated and Suleiman allowed the Knights of Rhodes to depart. (The Knights of Rhodes eventually formed a new base in Malta.)
As relations between Hungary and the Ottoman Empire deteriorated, Suleiman resumed his campaign in Eastern Europe and on 29 August 1526, he defeated Louis II of Hungary (1506–26) at the Battle of Mohács. In its wake, Hungarian resistance collapsed and the Ottoman Empire became the preeminent power in Eastern Europe. Upon encountering the lifeless body of King Louis, Suleiman is said to have lamented: "I came indeed in arms against him; but it was not my wish that he should be thus cut off before he scarcely tasted the sweets of life and royalty." While Suleiman was campaigning in Hungary, Turkmen tribes in central Anatolia revolted under the leadership of Kalender Çelebi.
Some Hungarian nobles proposed that Ferdinand, who was ruler of neighboring Austria and tied to Louis II's family by marriage, be King of Hungary, citing previous agreements that the Habsburgs would take the Hungarian throne if Louis died without heirs. 
However, other nobles turned to the nobleman John Zápolya, who was being supported by Suleiman. Under Charles V and his brother Ferdinand I, the Habsburgs reoccupied Buda and took possession of Hungary. As a result, in 1529, Suleiman marched through the valley of the Danube and regained control of Buda; in the following autumn his forces laid siege to Vienna. This was to be the Ottoman Empire's most ambitious expedition and the apogee of its drive to the West. With a reinforced garrison of 16,000  men, the Austrians inflicted the first defeat on Suleiman, sowing the seeds of a bitter Ottoman-Habsburg rivalry which lasted until the 20th century. His second attempt to conquer Vienna failed in 1532, with Ottoman forces delayed by the siege of Güns, failing to reach Vienna. In both cases, the Ottoman army was plagued by bad weather (forcing them to leave behind essential siege equipment) and was hobbled by overstretched supply lines.
By the 1540s a renewal of the conflict in Hungary presented Suleiman with the opportunity to avenge the defeat suffered at Vienna.
In 1541 the Habsburgs once again engaged in conflict with the Ottomans, by attempting to lay siege to Buda. With their efforts repulsed, and more Habsburg fortresses captured by the Ottomans in two consecutive campaigns in 1541 and in 1544 as a result, Ferdinand and his brother Charles V were forced to conclude a humiliating five-year treaty with Suleiman. Ferdinand renounced his claim to the Kingdom of Hungary and was forced to pay a fixed yearly sum to the Sultan for the Hungarian lands he continued to control. Of more symbolic importance, the treaty referred to Charles V not as 'Emperor', but as the 'King of Spain', leading Suleiman to identify as the true 'Caesar'.
With his main European rivals subdued, Suleiman ensured that the Ottoman Empire had a powerful role in the political landscape of Europe for some years to come.
Ottoman–Safavid War.
As Suleiman stabilized his European frontiers, he now turned his attention to the ever present threat posed by the Shi'a Safavid dynasty of Persia. Two events in particular were to precipitate a recurrence of tensions. First, Shah Tahmasp had the Baghdad governor loyal to Suleiman killed and replaced with an adherent of the Shah, and second, the governor of Bitlis had defected and sworn allegiance to the Safavids. As a result, in 1533, Suleiman ordered his Grand Vizier Pargalı Ibrahim Pasha to lead an army into eastern Asia Minor where he retook Bitlis and occupied Tabriz without resistance. Having joined Ibrahim in 1534, Suleiman made a push towards Persia, only to find the Shah sacrificing territory instead of facing a pitched battle, resorting to harassment of the Ottoman army as it proceeded along the harsh interior. When in the following year Suleiman and Ibrahim made a grand entrance into Baghdad, its commander surrendered the city, thereby confirming Suleiman as the leader of the Sunni Islamic world and the legitimate successor to the Sunni Abbasid Caliphs. Moreover, the fact Suleiman restored the grave of Sunni imam Abu Hanifa also strengthened his credentials and claim to the caliphate. 
Attempting to defeat the Shah once and for all, Suleiman embarked upon a second campaign in 1548–1549. As in the previous attempt, Tahmasp avoided confrontation with the Ottoman army and instead chose to retreat, using scorched earth tactics in the process and exposing the Ottoman army to the harsh winter of the Caucasus. Suleiman abandoned the campaign with temporary Ottoman gains in Tabriz and the Urmia region, a lasting presence in the province of Van, control of the western half of Azerbaijan and some forts in Georgia.
In 1553 Suleiman began his third and final campaign against the Shah. Having initially lost territories in Erzurum to the Shah's son, Suleiman retaliated by recapturing Erzurum, crossing the Upper Euphrates and laying waste to parts of Persia. The Shah's army continued its strategy of avoiding the Ottomans, leading to a stalemate from which neither army made any significant gain. In 1554, a settlement was signed which was to conclude Suleiman's Asian campaigns. Part of the treaty included and confirmed the return of Tabriz, but secured Baghdad, lower Mesopotamia, the mouths of the river Euphrates and Tigris, as well as part of the Persian Gulf. The Shah also promised to cease all raids into Ottoman territory.
Campaigns in the Indian Ocean.
Ottoman ships had been sailing in the Indian Ocean since the year 1518. Ottoman Admirals such as Hadim Suleiman Pasha, Seydi Ali Reis and Kurtoğlu Hızır Reis are known to have voyaged to the Mughal imperial ports of Thatta, Surat and Janjira. The Mughal Emperor Akbar, himself is known to have exchanged six documents with Suleiman the Magnificent.
In the Indian Ocean, Suleiman led several naval campaigns against the Portuguese in an attempt to remove them and reestablish trade with India. Aden in Yemen was captured by the Ottomans in 1538, in order to provide an Ottoman base for raids against Portuguese possessions on the western coast of modern Pakistan and India. Sailing on to India, the Ottomans failed against the Portuguese at the Siege of Diu in September 1538, but then returned to Aden where they fortified the city with 100 pieces of artillery. From this base, Sulayman Pasha managed to take control of the whole country of Yemen, also taking Sanaa. Aden rose against the Ottomans however and invited the Portuguese instead, so that the Portuguese were in control of the city until its seizure by Piri Reis in the Capture of Aden (1548).
With its strong control of the Red Sea, Suleiman successfully managed to dispute control of the Indian trade routes to the Portuguese and maintained a significant level of trade with the Mughal Empire of South Asia throughout the 16th century. His admiral Piri Reis led an Ottoman fleet in the Indian Ocean, achieving the Capture of Muscat in 1552.
From 1526 till 1543, Suileman stationed over 900 Turkish soldiers to fight alongside the Somali Adal Sultanate lead by Ahmad ibn Ibrahim al-Ghazi during the Conquest of Abyssinia. In 1559, after the first Ajuran-Portuguese war the Ottoman Empire would later absorb the weakened Adal Sultanate into its domain. This expansion fathered Ottoman rule in Somalia and the Horn of Africa. This also increased its influence in the Indian Ocean to compete with the Portuguese with its close ally the Ajuran Empire.
In 1564, Suleiman received an embassy from Aceh (modern Indonesia), requesting Ottoman support against the Portuguese. As a result an Ottoman expedition to Aceh was launched, which was able to provide extensive military support to the Acehnese.
The discovery of new maritime trade routes by Western European states allowed them to avoid the Ottoman trade monopoly. The Portuguese discovery of the Cape of Good Hope in 1488 initiated a series of Ottoman-Portuguese naval wars in the Indian Ocean throughout the 16th century. The Ajuran Empire allied with the Ottomans defied the Portuguese economic monopoly in the Indian Ocean by employing a new coinage which followed the Ottoman pattern, thus proclaiming an attitude of economic independence in regard to the Portuguese.
Mediterranean and North Africa.
Having consolidated his conquests on land, Suleiman was greeted with the news that the fortress of Koroni in Morea (the modern Peloponnese) had been lost to Charles V's admiral, Andrea Doria. The presence of the Spanish in the Eastern Mediterranean concerned Suleiman, who saw it as an early indication of Charles V's intention to rival Ottoman dominance in the region. Recognizing the need to reassert the navy's preeminence in the Mediterranean, Suleiman appointed an exceptional naval commander in the form of Khair ad Din, known to Europeans as Barbarossa. Once appointed admiral-in-chief, Barbarossa was charged with rebuilding the Ottoman fleet, to such an extent that the Ottoman navy equaled in number those of all other Mediterranean countries put together. In 1535 Charles V won an important victory against the Ottomans at Tunis, which together with the war against Venice the following year, led Suleiman to accept proposals from Francis I of France to form an alliance against Charles. In 1538, the Spanish fleet was defeated by Barbarossa at the Battle of Preveza, securing the eastern Mediterranean for the Turks for 33 years until the defeat at the Battle of Lepanto in 1571.
East of Morocco, huge territories in North Africa were annexed. The Barbary States of Tripolitania, Tunisia, and Algeria became autonomous provinces of the Empire, serving as the leading edge of Suleiman's conflict with Charles V, whose attempt to drive out the Turks failed in 1541. The piracy carried on thereafter by the Barbary pirates of North Africa can be seen in the context of the wars against Spain. For a short period Ottoman expansion secured naval dominance in the Mediterranean. 
In 1542, facing a common Habsburg enemy, Francis I sought to renew the Franco-Ottoman alliance. As a result, Suleiman dispatched 100 galleys under Barbarossa to assist the French in the western Mediterranean. Barbarossa pillaged the coast of Naples and Sicily before reaching France where Francis made Toulon the Ottoman admiral's naval headquarters. The same campaign had seen Barbarossa attack and capture Nice in 1543. By 1544, a peace between Francis I and Charles V had put a temporary end to the alliance between France and the Ottoman Empire.
Elsewhere in the Mediterranean, when the Knights Hospitallers were re-established as the Knights of Malta in 1530, their actions against Muslim navies quickly drew the ire of the Ottomans who assembled another massive army in order to dislodge the Knights from Malta. The Ottomans invaded in 1565, undertaking the Great Siege of Malta, which began on 18 May and lasted until 8 September, and is portrayed vividly in the frescoes of Matteo Perez d'Aleccio in the Hall of St. Michael and St. George. At first it seemed that this would be a repeat of the battle on Rhodes, with most of Malta's cities destroyed and half the Knights killed in battle; but a relief force from Spain entered the battle, resulting in the loss of 30,000 Ottoman troops and the victory of the local Maltese citizenry.
Administrative reforms.
While Sultan Suleiman was known as "the Magnificent" in the West, he was always "Kanuni" Suleiman or "The Lawgiver" (قانونی) to his own Ottoman subjects. As the historian Lord Kinross notes, "Not only was he a great military campaigner, a man of the sword, as his father and great-grandfather had been before him. He differed from them in the extent to which he was also a man of the pen. He was a great legislator, standing out in the eyes of his people as a high-minded sovereign and a magnanimous exponent of justice". The overriding law of the empire was the Shari'ah, or Sacred Law, which as the divine law of Islam was outside of the Sultan's powers to change. Yet an area of distinct law known as the "Kanuns" (قانون, canonical legislation) was dependent on Suleiman's will alone, covering areas such as criminal law, land tenure and taxation. He collected all the judgments that had been issued by the nine Ottoman Sultans who preceded him. After eliminating duplications and choosing between contradictory statements, he issued a single legal code, all the while being careful not to violate the basic laws of Islam. It was within this framework that Suleiman, supported by his Grand Mufti Ebussuud, sought to reform the legislation to adapt to a rapidly changing empire. When the Kanun laws attained their final form, the code of laws became known as the "kanun‐i Osmani" (قانون عثمانی), or the "Ottoman laws". Suleiman's legal code was to last more than three hundred years.
Suleiman gave particular attention to the plight of the rayas, Christian subjects who worked the land of the Sipahis. His Kanune Raya, or "Code of the Rayas", reformed the law governing levies and taxes to be paid by the rayas, raising their status above serfdom to the extent that Christian serfs would migrate to Turkish territories to benefit from the reforms. The Sultan also played a role in protecting the Jewish subjects of his empire for centuries to come. In late 1553 or 1554, on the suggestion of his favorite doctor and dentist, the Spanish Jew Moses Hamon, the Sultan issued a "firman" (فرمان) formally denouncing blood libels against the Jews. Furthermore, Suleiman enacted new criminal and police legislation, prescribing a set of fines for specific offenses, as well as reducing the instances requiring death or mutilation. In the area of taxation, taxes were levied on various goods and produce, including animals, mines, profits of trade, and import-export duties. In addition to taxes, officials who had fallen into disrepute were likely to have their land and property confiscated by the Sultan.
Education was another important area for the Sultan. Schools attached to mosques and funded by religious foundations provided a largely free education to Muslim boys in advance of the Christian countries of the time. In his capital, Suleiman increased the number of "mektebs" (مكتب, primary schools) to fourteen, teaching boys to read and write as well as the principles of Islam. Young men wishing further education could proceed to one of eight "medreses" (مدرسه, colleges), whose studies included grammar, metaphysics, philosophy, astronomy, and astrology. Higher "medreses" provided education of university status, whose graduates became "imams" (امام) or teachers. Educational centers were often one of many buildings surrounding the courtyards of mosques, others included libraries, refectories, fountains, soup kitchens and hospitals for the benefit of the public.
Cultural achievements.
Under Suleiman's patronage, the Ottoman Empire entered the golden age of its cultural development. Hundreds of imperial artistic societies (called the اهل حرف "Ehl-i Hiref", "Community of the Talented") were administered at the Imperial seat, the Topkapı Palace. After an apprenticeship, artists and craftsmen could advance in rank within their field and were paid commensurate wages in quarterly annual installments. Payroll registers that survive testify to the breadth of Suleiman's patronage of the arts, the earliest of documents dating from 1526 list 40 societies with over 600 members. The "Ehl-i Hiref" attracted the empire's most talented artisans to the Sultan's court, both from the Islamic world and recently conquered territories in Europe, resulting in a blend of Arabic, Turkish and European cultures. Artisans in service of the court included painters, book binders, furriers, jewellers and goldsmiths. Whereas previous rulers had been influenced by Persian culture (Suleiman's father, Selim I, wrote poetry in Persian), Suleiman's patronage of the arts had seen the Ottoman Empire assert its own artistic legacy.
Suleiman himself was an accomplished poet, writing in Persian and Turkish under the takhallus (nom de plume) "Muhibbi" (محبی, "Lover"). Some of Suleiman's verses have become Turkish proverbs, such as the well-known "Everyone aims at the same meaning, but many are the versions of the story". When his young son Mehmed died in 1543, he composed a moving chronogram to commemorate the year: "Peerless among princes, my Sultan Mehmed". In addition to Suleiman's own work, many great talents enlivened the literary world during Suleiman's rule, including Fuzuli and Baki. The literary historian E. J. W. Gibb observed that "at no time, even in Turkey, was greater encouragement given to poetry than during the reign of this Sultan". Suleiman's most famous verse is:
The people think of wealth and power as the greatest fate,
But in this world a spell of health is the best state.
What men call sovereignty is a worldly strife and constant war;
Worship of God is the highest throne, the happiest of all estates.
Suleiman also became renowned for sponsoring a series of monumental architectural developments within his empire. The Sultan sought to turn Constantinople into the center of Islamic civilization by a series of projects, including bridges, mosques, palaces and various charitable and social establishments. The greatest of these were built by the Sultan's chief architect, Mimar Sinan, under whom Ottoman architecture reached its zenith. Sinan became responsible for over three hundred monuments throughout the empire, including his two masterpieces, the Süleymaniye and Selimiye mosques—the latter built in Adrianople (now Edirne) in the reign of Suleiman's son Selim II. Suleiman also restored the Dome of the Rock in Jerusalem and the Jerusalem city walls (which are the current walls of the Old City of Jerusalem), renovated the Kaaba in Mecca, and constructed a complex in Damascus.
Personal life.
Consorts and progeny.
Suleiman had three known consorts:
Suleiman had nine children with his three consorts:
Relationship with Hürrem Sultan.
Suleiman was infatuated with Hürrem Sultan, a harem girl from Ruthenia, then part of Poland. In the West foreign diplomats, taking notice of the palace gossip about her, called her "Russelazie" or "Roxelana", referring to her Ruthenian (Ukrainian) origins. The daughter of an Orthodox priest, she was captured by Tatars from Crimea, sold as a slave in Constantinople, and eventually rose through the ranks of the Harem to become Suleiman's favorite. Breaking with two centuries of Ottoman tradition, a former concubine had thus become the legal wife of the Sultan, much to the astonishment of observers in the palace and the city. He also allowed Hürrem Sultan to remain with him at court for the rest of her life, breaking another tradition—that when imperial heirs came of age, they would be sent along with the imperial concubine who bore them to govern remote provinces of the Empire, never to return unless their progeny succeeded to the throne.
Under his pen name, Muhibbi, Sultan Suleiman composed this poem for Hürrem Sultan:
"Throne of my lonely niche, my wealth, my love, my moonlight.
My most sincere friend, my confidant, my very existence, my Sultan, my one and only love.
The most beautiful among the beautiful...
My springtime, my merry faced love, my daytime, my sweetheart, laughing leaf...
My plants, my sweet, my rose, the one only who does not distress me in this room...
My Constantinople, my Caraman, the earth of my Anatolia
My Badakhshan, my Baghdad and Khorasan
My woman of the beautiful hair, my love of the slanted brow, my love of eyes full of misery ...
I'll sing your praises always
I, lover of the tormented heart, Muhibbi of the eyes full of tears, I am happy."
Pargalı Ibrahim Pasha.
Pargalı Ibrahim Pasha was the boyhood friend of Suleiman. Ibrahim was originally a Christian from Parga, (Epirus), and when he was young was educated at the Palace School under the devshirme system. Suleiman made him the royal falconer, then promoted him to first officer of the Royal Bedchamber. Ibrahim Pasha rose to Grand Vizier in 1523 and commander-in-chief of all the armies. Suleiman also conferred upon Ibrahim Pasha the honor of "beylerbey" of Rumelia, granting Ibrahim authority over all Turkish territories in Europe, as well as command of troops residing within them in times of war. According to a 17th-century chronicler, Ibrahim had asked Suleiman not to promote him to such high positions, fearing for his safety; to which Suleiman replied that under his reign no matter what the circumstance, Ibrahim would never be put to death.
Yet Ibrahim eventually fell from grace with the Sultan. During his thirteen years as Grand Vizier, his rapid rise to power and vast accumulation of wealth had made Ibrahim many enemies among the Sultan's court. Reports had reached the Sultan of Ibrahim's impudence during a campaign against the Persian Safavid empire: in particular his adoption of the title "serasker sultan" (سرعسكر سلطان) was seen as a grave affront to Suleiman.
Suleiman's suspicion of Ibrahim was worsened by a quarrel between the latter and the finance secretary ("defterdar") Iskender Çelebi. The dispute ended in the disgrace of Çelebi on charges of intrigue, with Ibrahim convincing Suleiman to sentence the "defterdar" to death. Before his death however, Çelebi's last words were to accuse Ibrahim of conspiracy against the Sultan. These dying words convinced Suleiman of Ibrahim's disloyalty, and on 15 March 1536 Ibrahim was executed.
Succession.
Sultan Suleiman's two wives (Hürrem and Mahidevran) had borne him seven sons, four of whom survived past the 1550s. They were Mustafa, Selim, Bayezid, and Cihangir. Of these, only Mustafa, the eldest, was not Hürrem Sultan's son, but rather Mahidevran Sultan's, and therefore preceded Hürrem's children in the order of succession. Hürrem was aware that should Mustafa become Sultan her own children would be strangled. Yet Mustafa was recognized as the most talented of all the brothers and was supported by Pargalı İbrahim Pasha, who was by this time Suleiman's Grand Vizier. The Austrian ambassador Busbecq would note "Suleiman has among his children a son called Mustafa, marvelously well educated and prudent and of an age to rule, since he is 24 or 25 years old; may God never allow a Barbary of such strength to come near us", going on to talk of Mustafa's "remarkable natural gifts".
Hürrem is usually held at least partly responsible for the intrigues in nominating a successor. Although she was Suleiman's wife, she exercised no official public role. This did not, however, prevent Hürrem from wielding powerful political influence. Since the Empire lacked, until the reign of Ahmed I, any formal means of nominating a successor, successions usually involved the death of competing princes in order to avert civil unrest and rebellions. In attempting to avoid the execution of her sons, Hürrem used her influence to eliminate those who supported Mustafa's accession to the throne.
Thus in power struggles apparently instigated by Hürrem, Suleiman had Ibrahim murdered and replaced with her sympathetic son-in-law, Rüstem Pasha. By 1552, when the campaign against Persia had begun with Rüstem appointed commander-in-chief of the expedition, intrigues against Mustafa began. Rüstem sent one of Suleiman's most trusted men to report that since Suleiman was not at the head of the army, the soldiers thought the time had come to put a younger prince on the throne; at the same time he spread rumors that Mustafa had proved receptive to the idea. Angered by what he came to believe were Mustafa's plans to claim the throne, the following summer upon return from his campaign in Persia, Suleiman summoned him to his tent in the Ereğli valley, stating he would "be able to clear himself of the crimes he was accused of and would have nothing to fear if he came".
Mustafa was confronted with a choice: either he appeared before his father at the risk of being killed; or, if he refused to attend, he would be accused of betrayal. In the end, Mustafa chose to enter his father's tent, confident that the support of the army would protect him. Busbecq, who claims to have received an account from an eyewitness, describes Mustafa's final moments. As Mustafa entered his father's tent, Suleiman's eunuchs attacked Mustafa, with the young prince putting up a brave defence. Suleiman, separated from the struggle only by the linen hangings of the tent, peered through the chamber of his tent and "directed fierce and threatening glances upon the mutes, and by menacing gestures sternly rebuked their hesitation. Thereupon, the mutes in their alarm, redoubling their efforts, hurled Mustafa to the ground and, throwing the bowstring round his neck, strangled him."
Cihangir is said to have died of grief a few months after the news of his half-brother's murder. The two surviving brothers, Selim and Bayezid, were given command in different parts of the empire. Within a few years, however, civil war broke out between the brothers, each supported by his loyal forces. With the aid of his father's army, Selim defeated Bayezid in Konya in 1559, leading the latter to seek refuge with the Safavids along with his four sons. Following diplomatic exchanges, the Sultan demanded from the Safavid Shah that Bayezid be either extradited or executed. In return for large amounts of gold, the Shah allowed a Turkish executioner to strangle Bayezid and his four sons in 1561, clearing the path for Selim's succession to the throne seven years later. On 7 September 1566, Suleiman, who had set out from Constantinople to command an expedition to Hungary, died before an Ottoman victory at the Battle of Szigetvár in Hungary.
Legacy.
At the time of Suleiman's death, the Ottoman Empire was one of the world's foremost powers. Suleiman's conquests had brought under the control of the Empire the major Muslim cities (Mecca, Medina, Jerusalem, Damascus, Cairo, and Baghdad), many Balkan provinces (reaching present day Croatia and Austria), and most of North Africa. His expansion into Europe had given the Ottoman Turks a powerful presence in the European balance of power. Indeed, such was the perceived threat of the Ottoman Empire under the reign of Suleiman that Austria's ambassador Busbecq warned of Europe's imminent conquest: "On [the Turks'] side are the resources of a mighty empire, strength unimpaired, habituation to victory, endurance of toil, unity, discipline, frugality and watchfulness... Can we doubt what the result will be?...When the Turks have settled with Persia, they will fly at our throats supported by the might of the whole East; how unprepared we are I dare not say."
Even thirty years after his death "Sultan Solyman" was quoted by the English playwright William Shakespeare as a military prodigy in "The Merchant of Venice" (Act 2, Scene 1).
Suleiman's legacy was not, however, merely in the military field. The French traveler Jean de Thévenot a century later bears witness to the "strong agricultural base of the country, the well being of the peasantry, the abundance of staple foods, and the pre-eminence of organization in Suleiman's government". The administrative and legal reforms which earned him the name Law Giver ensured the Empire's survival long after his death, an achievement which "took many generations of decadent heirs to undo".
Through his personal patronage, Suleiman also presided over the Golden Age of the Ottoman Empire, representing the pinnacle of the Ottoman Turks' cultural achievement in the realm of architecture, literature, art, theology and philosophy. Today the skyline of the Bosphorus, and of many cities in modern Turkey and the former Ottoman provinces, are still adorned with the architectural works of Mimar Sinan. One of these, the Süleymaniye Mosque, is the final resting place of Suleiman and Hürrem Sultan: they are buried in separate domed mausoleums attached to the mosque.
References.
</dl>
</dl>
Further reading.
</dl>

</doc>
<doc id="26994" url="http://en.wikipedia.org/wiki?curid=26994" title="Scotland">
Scotland

Scotland (; Scots: ]; Scottish Gaelic: "Alba" ]) is a country that is part of the United Kingdom and covers the northern third of the island of Great Britain. It shares a border with England to the south, and is otherwise surrounded by the Atlantic Ocean, with the North Sea to the east and the North Channel and Irish Sea to the south-west. In addition to the mainland, the country is made up of more than 790 islands, including the Northern Isles and the Hebrides.
Edinburgh, the country's capital and second-largest city, was the hub of the Scottish Enlightenment of the 18th century, which transformed Scotland into one of the commercial, intellectual, and industrial powerhouses of Europe. Glasgow, Scotland's largest city, was once one of the world's leading industrial cities and now lies at the centre of the Greater Glasgow conurbation. Scottish waters consist of a large sector of the North Atlantic and the North Sea, containing the largest oil reserves in the European Union. This has given Aberdeen, the third-largest city in Scotland, the title of Europe's oil capital.
The Kingdom of Scotland emerged as an independent sovereign state in the Early Middle Ages and continued to exist until 1707. By inheritance in 1603, King James VI of Scotland became King of England and King of Ireland, thus forming a personal union of the three kingdoms. Scotland subsequently entered into a political union with England on 1 May 1707 to create the new Kingdom of Great Britain. The union also created a new Parliament of Great Britain, which succeeded both the Parliament of Scotland and the Parliament of England. The Treaty of Union was agreed in 1706 and enacted by the twin Acts of Union 1707 passed by the Parliaments of both countries, despite some popular opposition and anti-union riots in Edinburgh, Glasgow, and elsewhere. Great Britain itself subsequently entered into a political union with Ireland on 1 January 1801 to create the United Kingdom of Great Britain and Ireland.
Scotland's legal system has remained separate from those of England and Wales and Northern Ireland, and Scotland constitutes a distinct jurisdiction in public and private law. The continued existence of legal, educational and religious institutions distinct from those in the remainder of the UK have all contributed to the continuation of Scottish culture and national identity since the 1707 union. Following a referendum in 1997, a Scottish Parliament was re-established, this time as a devolved legislature with authority over many areas of home affairs. The Scottish National Party, which supports Scottish independence, won an overall majority in the 2011 general election. An independence referendum held on 18 September 2014 rejected independence by a majority of 55% to 45% on an 85% voter turnout.
Scotland is a member nation of the British–Irish Council, and the British–Irish Parliamentary Assembly. Scotland is represented in the European Union and the European Parliament with six MEPs.
Etymology.
"Scotland" comes from "Scoti", the Latin name for the Gaels. The Late Latin word "Scotia" ("land of the Gaels") was initially used to refer to Ireland. By the 11th century at the latest, "Scotia" was being used to refer to (Gaelic-speaking) Scotland north of the river Forth, alongside "Albania" or "Albany", both derived from the Gaelic "Alba". The use of the words "Scots" and "Scotland" to encompass all of what is now Scotland became common in the Late Middle Ages.
History.
Early history.
Repeated glaciations, which covered the entire land mass of modern Scotland, destroyed any traces of human habitation that may have existed before the Mesolithic period. It is believed the first post-glacial groups of hunter-gatherers arrived in Scotland around 12,800 years ago, as the ice sheet retreated after the last glaciation.
Groups of settlers began building the first known permanent houses on Scottish soil around 9,500 years ago, and the first villages around 6,000 years ago. The well-preserved village of Skara Brae on the mainland of Orkney dates from this period. Neolithic habitation, burial and ritual sites are particularly common and well preserved in the Northern Isles and Western Isles, where a lack of trees led to most structures being built of local stone.
The 2009 discovery in Scotland of a 4000-year-old tomb with burial treasures at Forteviot, near Perth, the capital of a Pictish Kingdom in the 8th and 9th centuries AD, is unrivalled anywhere in Britain. It contains the remains of an early Bronze Age ruler laid out on white quartz pebbles and birch bark. It was also discovered for the first time early Bronze Age people placed flowers in their graves.
Scotland may have been part of a Late Bronze Age maritime trading culture called the Atlantic Bronze Age, which included other Celtic nations, and the areas that became England, France, Spain, and Portugal.
In the winter of 1850, a severe storm hit Scotland, causing widespread damage and over 200 deaths. In the Bay of Skaill, the storm stripped the earth from a large irregular knoll, known as "Skerrabra". When the storm cleared, local villagers found the outline of a village, consisting of a number of small houses without roofs. William Watt of Skaill, the local laird, began an amateur excavation of the site, but after uncovering four houses, the work was abandoned in 1868. The site remained undisturbed until 1913, when during a single weekend the site was plundered by a party with shovels who took away an unknown quantity of artefacts. In 1924, another storm swept away part of one of the houses and it was determined the site should be made secure and more seriously investigated. The job was given to University of Edinburgh's Professor Vere Gordon Childe who travelled to Skara Brae for the first time in mid-1927.
Roman influence.
The written protohistory of Scotland began with the arrival of the Roman Empire in southern and central Great Britain, when the Romans occupied what is now England and Wales, administering it as a province called "Britannia". Roman invasions and occupations of southern Scotland were a series of brief interludes.
According to the Roman historian Tacitus, the Caledonians "turned to armed resistance on a large scale", attacking Roman forts and skirmishing with their legions. In a surprise night-attack, the Caledonians very nearly wiped out the whole 9th Legion until it was saved by Agricola's cavalry.
In AD 83–84, the General Gnaeus Julius Agricola defeated the Caledonians at the Battle of Mons Graupius. Tacitus wrote that, before the battle, the Caledonian leader, Calgacus, gave a rousing speech in which he called his people the "last of the free" and accused the Romans of "making the world a desert and calling it peace" (freely translated). After the Roman victory, Roman forts were briefly set along the Gask Ridge close to the Highland line (only Cawdor near Inverness is known to have been constructed beyond that line). Three years after the battle, the Roman armies had withdrawn to the Southern Uplands.
The Romans erected Hadrian's Wall to control tribes on both sides of the wall so the "Limes Britannicus" became the northern border of the Roman Empire; although the army held the Antonine Wall in the Central Lowlands for two short periods – the last of these during the time of Emperor Septimius Severus from 208 until 210.
The Roman military occupation of a significant part of what is now northern Scotland lasted only about 40 years; although their influence on the southern section of the country, occupied by Brythonic tribes such as the Votadini and Damnonii, would still have been considerable between the first and fifth centuries. The Welsh term Hen Ogledd ("Old North") is used by scholars to describe what is now the North of England and the South of Scotland during its habitation by Brittonic-speaking people around AD 500 to 800. According to writings from the 9th and 10th centuries, the Gaelic kingdom of Dál Riata was founded in the 6th century in western Scotland. The 'traditional' view is that settlers from Ireland founded the kingdom, bringing Gaelic language and culture with them. However, recently some archaeologists have argued against this view, saying there is no archaeological or placename evidence for a migration or a takeover by a small group of elites.
Middle Ages.
The Kingdom of the Picts (based in Fortriu by the 6th century) was the state that eventually became known as "Alba" or "Scotland". The development of "Pictland", according to the historical model developed by Peter Heather, was a natural response to Roman imperialism. Another view places emphasis on the Battle of Dun Nechtain, and the reign of Bridei m. Beli (671–693), with another period of consolidation in the reign of Óengus mac Fergusa (732–761).
The Kingdom of the Picts as it was in the early 8th century, when Bede was writing, was largely the same as the kingdom of the Scots in the reign of Alexander I (1107–1124). However, by the tenth century, the Pictish kingdom was dominated by what we can recognise as Gaelic culture, and had developed a traditional story of an Irish conquest around the ancestor of the contemporary royal dynasty, Cináed mac Ailpín (Kenneth MacAlpin).
From a base of territory in eastern Scotland north of the River Forth and south of the River Oykel, the kingdom acquired control of the lands lying to the north and south. By the 12th century, the kings of Alba had added to their territories the English-speaking land in the south-east and attained overlordship of Gaelic-speaking Galloway and Norse-speaking Caithness; by the end of the 13th century, the kingdom had assumed approximately its modern borders. However, processes of cultural and economic change beginning in the 12th century ensured Scotland looked very different in the later Middle Ages.
The push for this change was the reign of David I and the Davidian Revolution. Feudalism, government reorganisation and the first legally recognised towns (called burghs) began in this period. These institutions and the immigration of French and Anglo-French knights and churchmen facilitated cultural osmosis, whereby the culture and language of the low-lying and coastal parts of the kingdom's original territory in the east became, like the newly acquired south-east, English-speaking, while the rest of the country retained the Gaelic language, apart from the Northern Isles of Orkney and Shetland, which remained under Norse rule until 1468. The Scottish state entered a largely successful and stable period between the 12th and 14th centuries, there was relative peace with England, trade and educational links were well developed with the Continent and at the height of this cultural flowering John Duns Scotus was one of Europe's most important and influential philosophers.
The death of Alexander III in March 1286, followed by that of his granddaughter Margaret, Maid of Norway, broke the centuries-old succession line of Scotland's kings and shattered the 200-year golden age that began with David I. Edward I of England was asked to arbitrate between claimants for the Scottish crown, and he organised a process known as the Great Cause to identify the most legitimate claimant. John Balliol was pronounced king in the Great Hall of Berwick Castle on 17 November 1292 and inaugurated at Scone on 30 November, St. Andrew's Day. Edward I, who had coerced recognition as Lord Paramount of Scotland, the feudal superior of the realm, steadily undermined John's authority. In 1294, Balliol and other Scottish lords refused Edward's demands to serve in his army against the French. Instead the Scottish parliament sent envoys to France to negotiate an alliance. Scotland and France sealed a treaty on 23 October 1295, known as the Auld Alliance (1295–1560). War ensued and King John was deposed by Edward who took personal control of Scotland. Andrew Moray and William Wallace initially emerged as the principal leaders of the resistance to English rule in what became known as the Wars of Scottish Independence (1296–1328).
The nature of the struggle changed significantly when Robert the Bruce, Earl of Carrick, killed his rival John Comyn on 10 February 1306 at Greyfriars Kirk in Dumfries. He was crowned king (as Robert I) less than seven weeks later. Robert I battled to restore Scottish Independence as King for over 20 years, beginning by winning Scotland back from the Norman English invaders piece by piece. Victory at the Battle of Bannockburn in 1314 proved the Scots had regained control of their kingdom. In 1315, Edward Bruce, brother of the King, was briefly appointed High King of Ireland during an ultimately unsuccessful Scottish invasion of Ireland aimed at strengthening Scotland's position in its wars against England. In 1320 the world's first documented declaration of independence, the Declaration of Arbroath, won the support of Pope John XXII, leading to the legal recognition of Scottish sovereignty by the English Crown.
However, war with England continued for several decades after the death of Bruce. A civil war between the Bruce dynasty and their long-term Comyn-Balliol rivals lasted until the middle of the 14th century. Although the Bruce dynasty was successful, David II's lack of an heir allowed his half-nephew Robert II to come to the throne and establish the Stewart Dynasty. The Stewarts ruled Scotland for the remainder of the Middle Ages. The country they ruled experienced greater prosperity from the end of the 14th century through the Scottish Renaissance to the Reformation. This was despite continual warfare with England, the increasing division between Highlands and Lowlands, and a large number of royal minorities.
This period was the height of the Franco-Scottish alliance. The Scots Guard – la Garde Écossaise – was founded in 1418 by Charles VII of France. The Scots soldiers of the Garde Écossaise fought alongside Joan of Arc against England during the Hundred Years War. In March 1421, a Franco-Scots force under John Stewart, 2nd Earl of Buchan, and Gilbert de Lafayette, defeated a larger English army at the Battle of Baugé. Three years later, at the Battle of Verneuil, the French and Scots lost around 7000 men. The Scottish intervention contributed to France's victory in the war.
Early modern era.
In 1502, James IV of Scotland signed the Treaty of Perpetual Peace with Henry VII of England. He also married Henry's daughter, Margaret Tudor, setting the stage for the Union of the Crowns. For Henry, the marriage into one of Europe's most established monarchies gave legitimacy to the new Tudor royal line. A decade later, James made the fateful decision to invade England in support of France under the terms of the Auld Alliance. He was the last British monarch to die in battle, at the Battle of Flodden. Within a generation the Auld Alliance was ended by the Treaty of Edinburgh. France agreed to withdraw all land and naval forces. In the same year, 1560, John Knox realised his goal of seeing Scotland become a Protestant nation and the Scottish parliament revoke papal authority in Scotland. Mary, Queen of Scots, a Catholic and former queen of France, was forced to abdicate in 1567.
In 1603, James VI, King of Scots inherited the thrones of the Kingdom of England and the Kingdom of Ireland, and became King James I of England and Ireland, and left Edinburgh for London. With the exception of a short period under the Protectorate, Scotland remained a separate state, but there was considerable conflict between the crown and the Covenanters over the form of church government. The Glorious Revolution of 1688–89 saw the overthrow of the King James VII of Scotland and II of England by the English Parliament in favour of William and Mary. As late as the 1690s, Scotland experienced famine, which reduced the population of parts of the country by at least 20 per cent.
In 1698, the Scots attempted an ambitious project to secure a trading colony on the Isthmus of Panama. Almost every Scottish landowner who had money to spare is said to have invested in the Darien scheme. Its failure bankrupted these landowners, but not the burghs. Nevertheless, the nobles' bankruptcy, along with the threat of an English invasion, played a leading role in convincing the Scots elite to back a union with England.
On 22 July 1706, the Treaty of Union was agreed between representatives of the Scots Parliament and the Parliament of England and the following year twin Acts of Union were passed by both parliaments to create the united Kingdom of Great Britain with effect from 1 May 1707.
18th century.
With trade tariffs with England now abolished, trade blossomed, especially with Colonial America. The clippers belonging to the Glasgow Tobacco Lords were the fastest ships on the route to Virginia. Until the American War of Independence in 1776, Glasgow was the world's premier tobacco port, dominating world trade. The disparity between the wealth of the merchant classes of the Scottish Lowlands and the ancient clans of the Scottish Highlands grew, amplifying centuries of division.
The deposed Jacobite Stuart claimants had remained popular in the Highlands and north-east, particularly amongst non-Presbyterians, including Roman Catholics and Episcopalian Protestants. However, two major Jacobite Risings launched in 1715 and 1745 failed to remove the House of Hanover from the British throne. The threat of the Jacobite movement to the United Kingdom and its monarchs effectively ended at the Battle of Culloden, Great Britain's last pitched battle. This defeat paved the way for large-scale removals of the indigenous populations of the Highlands and Islands, known as the Highland Clearances.
The Scottish Enlightenment and the Industrial Revolution made Scotland into an intellectual, commercial and industrial powerhouse–so much so Voltaire said "We look to Scotland for all our ideas of civilisation." With the demise of Jacobitism and the advent of the Union, thousands of Scots, mainly Lowlanders, took up numerous positions of power in politics, civil service, the army and navy, trade, economics, colonial enterprises and other areas across the nascent British Empire. Historian Neil Davidson notes "after 1746 there was an entirely new level of participation by Scots in political life, particularly outside Scotland." Davidson also states "far from being 'peripheral' to the British economy, Scotland – or more precisely, the Lowlands – lay at its core."
19th century.
The Scottish Reform Act 1832 increased the number of Scottish MPs and widened the franchise to include more of the middle classes. From the mid-century there were increasing calls for Home Rule for Scotland and the post of Secretary of State for Scotland was revived. Towards the end of the century Prime Ministers of Scottish descent included William E. Gladstone, and the Earl of Rosebery. In the later 19th century the growing importance of the working classes was marked by Keir Hardie's success in the Mid Lanarkshire by-election, 1888, leading to the foundation of the Scottish Labour Party, which was absorbed into the Independent Labour Party in 1895, with Hardie as its first leader.
Glasgow became one of the largest cities in the world, and known as "the Second City of the Empire" after London. After 1860 the Clydeside shipyards specialised in steamships made of iron (after 1870, made of steel), which rapidly replaced the wooden sailing vessels of both the merchant fleets and the battle fleets of the world. It became the world's pre-eminent shipbuilding centre. The industrial developments, while they brought work and wealth, were so rapid that housing, town-planning, and provision for public health did not keep pace with them, and for a time living conditions in some of the towns and cities were notoriously bad, with overcrowding, high infant mortality, and growing rates of tuberculosis.
While the Scottish Enlightenment is traditionally considered to have concluded toward the end of the 18th century, disproportionately large Scottish contributions to British science and letters continued for another 50 years or more, thanks to such figures as the physicists James Clerk Maxwell and Lord Kelvin, and the engineers and inventors James Watt and William Murdoch, whose work was critical to the technological developments of the Industrial Revolution throughout Britain. In literature the most successful figure of the mid-19th century was Walter Scott. His first prose work, Waverley in 1814, is often called the first historical novel. It launched a highly successful career that probably more than any other helped define and popularise Scottish cultural identity. In the late 19th century, a number of Scottish-born authors achieved international reputations, such as Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald. Scotland also played a major part in the development of art and architecture. The Glasgow School, which developed in the late 19th century, and flourished in the early 20th century, produced a distinctive blend of influences including the Celtic Revival the Arts and Crafts Movement, and Japonisme, which found favour throughout the modern art world of continental Europe and helped define the Art Nouveau style. Proponents included architect and artist Charles Rennie Mackintosh.
This period saw a process of rehabilitation for Highland culture. In the 1820s, as part of the Romantic revival, tartan and the kilt were adopted by members of the social elite, not just in Scotland, but across Europe, prompted by the popularity of Macpherson's Ossian cycle and then Walter Scott's Waverley novels. However, the Highlands remained very poor and traditional. The desire to improve agriculture and profits led to the Highland Clearances, in which much of the population of the Highlands suffered forced displacement as lands were enclosed, principally so that they could be used for sheep farming. The clearances followed patterns of agricultural change throughout Britain, but were particularly notorious as a result of the late timing, the lack of legal protection for year-by-year tenants under Scots law, the abruptness of the change from the traditional clan system, and the brutality of many evictions. One result was a continuous exodus from the land—to the cities, or further afield to England, Canada, America or Australia. The population of Scotland grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. Even with the development of industry there were not enough good jobs. As a result, during the period 1841–1931, about 2 million Scots migrated to North America and Australia, and another 750,000 Scots relocated to England.
After prolonged years of struggle in the Kirk, in 1834 the Evangelicals gained control of the General Assembly and passed the Veto Act, which allowed congregations to reject unwanted "intrusive" presentations to livings by patrons. The following "Ten Years' Conflict" of legal and political wrangling ended in defeat for the non-intrusionists in the civil courts. The result was a schism from the church by some of the non-intrusionists led by Dr Thomas Chalmers, known as the Great Disruption of 1843. Roughly a third of the clergy, mainly from the North and Highlands, formed the separate Free Church of Scotland. In the late 19th century growing divisions between fundamentalist Calvinists and theological liberals resulted in a further split in the Free Church as the rigid Calvinists broke away to form the Free Presbyterian Church in 1893. Catholic Emancipation in 1829 and the influx of large numbers of Irish immigrants, particularly after the famine years of the late 1840s, mainly to the growing lowland centres like Glasgow, led to a transformation in the fortunes of Catholicism. In 1878, despite opposition, a Roman Catholic ecclesiastical hierarchy was restored to the country, and Catholicism became a significant denomination within Scotland.
Industrialisation, urbanisation and the Disruption of 1843 all undermined the tradition of parish schools. From 1830 the state began to fund buildings with grants; then from 1846 it was funding schools by direct sponsorship; and in 1872 Scotland moved to a system like that in England of state-sponsored largely free schools, run by local school boards. The historic University of Glasgow became a leader in British higher education by providing the educational needs of youth from the urban and commercial classes, as opposed to the upper class. The University of St Andrews pioneered the admission of women to Scottish universities. From 1892 Scottish universities could admit and graduate women and the numbers of women at Scottish universities steadily increased until the early 20th century.
Early 20th century.
Scotland played a major role in the British effort in the First World War. It especially provided manpower, ships, machinery, fish and money. With a population of 4.8 million in 1911, Scotland sent over half a million men to the war, of whom over a quarter died in combat or from disease, and 150,000 were seriously wounded. Field Marshal Sir Douglas Haig was Britain's commander on the Western Front.
The war saw the emergence of a radical movement called "Red Clydeside" led by militant trades unionists. Formerly a Liberal stronghold, the industrial districts switched to Labour by 1922, with a base among the Irish Catholic working class districts. Women were especially active in building neighbourhood solidarity on housing issues. However, the "Reds" operated within the Labour Party and had little influence in Parliament and the mood changed to passive despair by the late 1920s.
The shipbuilding industry expanded by a third and expected renewed prosperity, but instead a serious depression hit the economy by 1922 and it did not fully recover until 1939. The interwar years were marked by economic stagnation in rural and urban areas, and high unemployment. Indeed, the war brought with it deep social, cultural, economic, and political dislocations. Thoughtful Scots pondered their declension, as the main social indicators such as poor health, bad housing, and long-term mass unemployment, pointed to terminal social and economic stagnation at best, or even a downward spiral. Service abroad on behalf of the Empire lost its allure to ambitious young people, who left Scotland permanently. The heavy dependence on obsolescent heavy industry and mining was a central problem, and no one offered workable solutions. The despair reflected what Finlay (1994) describes as a widespread sense of hopelessness that prepared local business and political leaders to accept a new orthodoxy of centralised government economic planning when it arrived during the Second World War.
The Second World War brought renewed prosperity, despite extensive bombing of cities by the Luftwaffe. It saw the invention of radar by Robert Watson-Watt, which was invaluable in the Battle of Britain as was the leadership at RAF Fighter Command of Air Chief Marshal Sir Hugh Dowding.
Since 1945.
After 1945, Scotland's economic situation became progressively worse due to overseas competition, inefficient industry, and industrial disputes. Only in recent decades has the country enjoyed something of a cultural and economic renaissance. Economic factors contributing to this recovery include a resurgent financial services industry, electronics manufacturing, (see Silicon Glen), and the North Sea oil and gas industry. The introduction in 1989 by Margaret Thatcher's government of the Community Charge (widely known as the Poll Tax) one year before the rest of the United Kingdom, contributed to a growing movement for a return to direct Scottish control over domestic affairs. Following a referendum on devolution proposals in 1997, the Scotland Act 1998 was passed by the United Kingdom Parliament to establish a devolved Scottish Parliament and Scottish Government with responsibility for most laws specific to Scotland.
Government and politics.
Scotland's head of state is the monarch of the United Kingdom, currently Queen Elizabeth II (since 1952). The regnal numbering "Elizabeth II" caused controversy around the time of the Queen's coronation because there had never been an Elizabeth I in Scotland. A legal action, MacCormick v. Lord Advocate (1953 SC 396), was brought to contest the right of the Queen to entitle herself "Elizabeth II" within Scotland, arguing that this was a breach of Article 1 of the Treaty of Union. The Crown won the case. It was decided that future British monarchs would be numbered according to either their English or their Scottish predecessors, whichever number is higher. For instance any future King James would be styled James VIII—since the last Scottish King James was James VII (also James II of England, etc.)—while the next King Henry would be King Henry IX throughout the UK even though there have been no Scottish kings of that name.
Scotland has limited self-government within the United Kingdom, as well as representation in the UK Parliament. Executive and legislative powers respectively have been devolved to the Scottish Government and the Scottish Parliament at Holyrood in Edinburgh since 1999. The UK Parliament retains control over reserved matters specified in the Scotland Act 1998, including UK taxes, social security, defence, international relations and broadcasting. The Scottish Parliament has legislative authority for all other areas relating to Scotland, as well as a limited power to vary income tax.
The Scottish Parliament can give legislative consent over devolved matters back to the UK Parliament by passing a Legislative Consent Motion if United Kingdom-wide legislation is considered more appropriate for a certain issue. The programmes of legislation enacted by the Scottish Parliament have seen a divergence in the provision of public services compared to the rest of the UK. For instance, university education and care services for the elderly are free at point of use in Scotland, while fees are paid in the rest of the UK. Scotland was the first country in the UK to ban smoking in enclosed public places.
The Scottish Parliament is a unicameral legislature with 129 members (MSPs): 73 of them represent individual constituencies and are elected on a first past the post system; the other 56 are elected in eight different electoral regions by the additional member system. MSPs serve for a four-year period (exceptionally five years from 2011–16). The Queen appoints one Member of the Scottish Parliament, nominated by the Parliament, to be First Minister. Other ministers are appointed by the First Minister and serve at his/her discretion. Together they make up the Scottish Government, the executive arm of the devolved government.
In the 2011 election, the Scottish National Party (SNP) formed a majority government after winning 69 seats out of 129. This was the first majority government since the modern post-devolution Scottish Parliament was established in 1999. The leader of the SNP, Alex Salmond, continued as First Minister until 2014. The Labour Party continued as the largest opposition party, with the Conservative Party, the Liberal Democrats, and the Green Party also represented in the Parliament. As of 29 September 2014, there are also three independent MSPs sitting in parliament. On 19 November 2014, Nicola Sturgeon became First Minister of Scotland, the first woman to hold the office. The next Scottish Parliament general election is due to be held on 5 May 2016. 
Scotland is represented in the British House of Commons by 59 MPs elected from territory-based Scottish constituencies. The next United Kingdom general election is due to be held in May 2015. The Scotland Office represents the UK government in Scotland on reserved matters and represents Scottish interests within the UK government. The Scotland Office is led by the Secretary of State for Scotland, who sits in the Cabinet of the United Kingdom; the current incumbent is Alistair Carmichael.
Constitutional changes.
A policy of devolution had been advocated by the three main UK parties with varying enthusiasm during recent history. The late Labour leader John Smith described the revival of a Scottish parliament as the "settled will of the Scottish people". The devolved Scottish Parliament was created after a referendum in 1997 found majority support for both creating the Parliament and granting it limited powers to vary income tax. The constitutional status of Scotland is nonetheless subject to ongoing debate.
The Scottish National Party (SNP), which supports Scottish independence, was first elected to form the Scottish Government in 2007. The new government established a "National Conversation" on constitutional issues, proposing a number of options such as increasing the powers of the Scottish Parliament, federalism, or a referendum on Scottish independence from the United Kingdom. In rejecting the last option, the three main opposition parties in the Scottish Parliament created a commission to investigate the distribution of powers between devolved Scottish and UK-wide bodies. The Scotland Act 2012, based on proposals by the commission, is currently in the process of devolving additional powers to the Scottish Parliament.
In August 2009 the SNP proposed a bill to hold a referendum on independence in November 2010. Opposition from all other major parties led to an expected defeat. After the 2011 elections gave the SNP an overall majority in the Scottish Parliament, a referendum on independence for Scotland was held on 18 September 2014. The referendum rejected independence by a majority of 55% to 45%. During the campaign, the three main parties in the UK Parliament pledged to extend the powers of the Scottish Parliament; an all-party commission chaired by Lord Smith of Kelvin has been formed.
Administrative subdivisions.
Historical subdivisions of Scotland included the mormaerdom, stewartry, earldom, burgh, parish, county and regions and districts. Some of these names are still sometimes used as geographical descriptors.
Modern Scotland is subdivided in various ways depending on the purpose. In local government, there have been 32 single-tier council areas since 1996, whose councils are responsible for the provision of all local government services. Community councils are informal organisations that represent specific sub-divisions of a council area.
In the Scottish Parliament, there are 73 constituencies and eight regions. For the Parliament of the United Kingdom, there are 59 constituencies. Until 2013 the Scottish fire brigades and police forces were based on a system of regions introduced in 1975. For healthcare and postal districts, and a number of other governmental and non-governmental organisations such as the churches, there are other long-standing methods of subdividing Scotland for the purposes of administration.
City status in the United Kingdom is conferred by letters patent. There are seven cities in Scotland: Aberdeen, Dundee, Edinburgh, Glasgow, Inverness, Stirling and Perth.
Law and criminal justice.
Scots law has a basis derived from Roman law, combining features of both uncodified civil law, dating back to the "Corpus Juris Civilis", and common law with medieval sources. The terms of the Treaty of Union with England in 1707 guaranteed the continued existence of a separate legal system in Scotland from that of England and Wales. Prior to 1611, there were several regional law systems in Scotland, most notably Udal law in Orkney and Shetland, based on old Norse law. Various other systems derived from common Celtic or Brehon laws survived in the Highlands until the 1800s.
Scots law provides for three types of courts responsible for the administration of justice: civil, criminal and heraldic. The supreme civil court is the Court of Session, although civil appeals can be taken to the Supreme Court of the United Kingdom (or before 1 October 2009, the House of Lords). The High Court of Justiciary is the supreme criminal court in Scotland. The Court of Session is housed at Parliament House, in Edinburgh, which was the home of the pre-Union Parliament of Scotland with the High Court of Justiciary and the Supreme Court of Appeal currently located at the Lawnmarket. The sheriff court is the main criminal and civil court, hearing most cases. There are 49 sheriff courts throughout the country. District courts were introduced in 1975 for minor offences and small claims. These were gradually replaced by Justice of the Peace Courts from 2008 to 2010. The Court of the Lord Lyon regulates heraldry.
For many decades the Scots legal system was unique for being the only legal system without a parliament. This ended with the advent of the Scottish Parliament, which legislates for Scotland. Many features within the system have been preserved. Within criminal law, the Scots legal system is unique in having three possible verdicts: "guilty", "not guilty" and "not proven". Both "not guilty" and "not proven" result in an acquittal, typically with no possibility of retrial in accordance with the rule of double jeopardy. There is however the possibility of a retrial where new evidence emerges at a later date that might have proven conclusive in the earlier trial at first instance, where the person acquitted subsequently admits the offence or where it can be proved that the acquittal was tainted by an attempt to pervert the course of justice – see the provisions of the Double Jeopardy (Scotland) Act 2011. Many laws differ between Scotland and the other parts of the United Kingdom, and many terms differ for certain legal concepts. Manslaughter, in England and Wales, is broadly similar to culpable homicide in Scotland, and arson is called wilful fire raising. Indeed, some acts considered crimes in England and Wales, such as forgery, are not so in Scotland. Procedure also differs. Scots juries, sitting in criminal cases, consist of fifteen, rather than twelve jurors, as is more common in English-speaking countries.
The Scottish Prison Service (SPS) manages the prisons in Scotland, which collectively house over 8,500 prisoners. The Cabinet Secretary for Justice is responsible for the Scottish Prison Service within the Scottish Government.
Geography and natural history.
The mainland of Scotland comprises the northern third of the land mass of the island of Great Britain, which lies off the north-west coast of Continental Europe. The total area is 78772 km2, comparable to the size of the Czech Republic. Scotland's only land border is with England, and runs for 96 km between the basin of the River Tweed on the east coast and the Solway Firth in the west. The Atlantic Ocean borders the west coast and the North Sea is to the east. The island of Ireland lies only 30 km from the south-western peninsula of Kintyre; Norway is 305 km to the east and the Faroes, 270 km to the north.
The territorial extent of Scotland is generally that established by the 1237 Treaty of York between Scotland and the Kingdom of England and the 1266 Treaty of Perth between Scotland and Norway. Important exceptions include the Isle of Man, which having been lost to England in the 14th century is now a crown dependency outside of the United Kingdom; the island groups Orkney and Shetland, which were acquired from Norway in 1472; and Berwick-upon-Tweed, lost to England in 1482.
The geographical centre of Scotland lies a few miles from the village of Newtonmore in Badenoch. Rising to 1344 m above sea level, Scotland's highest point is the summit of Ben Nevis, in Lochaber, while Scotland's longest river, the River Tay, flows for a distance of 190 km.
Geology and geomorphology.
The whole of Scotland was covered by ice sheets during the Pleistocene ice ages and the landscape is much affected by glaciation. From a geological perspective, the country has three main sub-divisions.
The Highlands and Islands lie to the north and west of the Highland Boundary Fault, which runs from Arran to Stonehaven. This part of Scotland largely comprises ancient rocks from the Cambrian and Precambrian, which were uplifted during the later Caledonian Orogeny. It is interspersed with igneous intrusions of a more recent age, remnants of which formed mountain massifs such as the Cairngorms and Skye Cuillins.
A significant exception to the above are the fossil-bearing beds of Old Red Sandstones found principally along the Moray Firth coast. The Highlands are generally mountainous and the highest elevations in the British Isles are found here. Scotland has over 790 islands divided into four main groups: Shetland, Orkney, and the Inner Hebrides and Outer Hebrides. There are numerous bodies of freshwater including Loch Lomond and Loch Ness. Some parts of the coastline consist of machair, a low lying dune pasture land.
The Central Lowlands is a rift valley mainly comprising Paleozoic formations. Many of these sediments have economic significance for it is here that the coal and iron bearing rocks that fuelled Scotland's industrial revolution are found. This area has also experienced intense volcanism, Arthur's Seat in Edinburgh being the remnant of a once much larger volcano. This area is relatively low-lying, although even here hills such as the Ochils and Campsie Fells are rarely far from view.
The Southern Uplands are a range of hills almost 200 km long, interspersed with broad valleys. They lie south of a second fault line (the Southern Uplands fault) that runs from Girvan to Dunbar. The geological foundations largely comprise Silurian deposits laid down some 4–500 million years ago. The high point of the Southern Uplands is Merrick with an elevation of 843 m. The Southern Uplands is home to the UK's highest village, Wanlockhead (430 m above sea level).
Climate.
The climate of Scotland is temperate and oceanic, and tends to be very changeable. As it is warmed by the Gulf Stream from the Atlantic, it has much milder winters (but cooler, wetter summers) than areas on similar latitudes, such as Labrador, southern Scandinavia, the Moscow region in Russia, and the Kamchatka Peninsula on the opposite side of Eurasia. However, temperatures are generally lower than in the rest of the UK, with the coldest ever UK temperature of -27.2 °C recorded at Braemar in the Grampian Mountains, on 11 February 1895. Winter maxima average 6 °C in the Lowlands, with summer maxima averaging 18 °C. The highest temperature recorded was 32.9 °C at Greycrook, Scottish Borders on 9 August 2003.
The west of Scotland is usually warmer than the east, owing to the influence of Atlantic ocean currents and the colder surface temperatures of the North Sea. Tiree, in the Inner Hebrides, is one of the sunniest places in the country: it had more than 300 hours of sunshine in May 1975. Rainfall varies widely across Scotland. The western highlands of Scotland are the wettest, with annual rainfall in a few places exceeding 3000 mm. In comparison, much of lowland Scotland receives less than 800 mm annually. Heavy snowfall is not common in the lowlands, but becomes more common with altitude. Braemar has an average of 59 snow days per year, while many coastal areas average fewer than 10 days of lying snow per year.
Flora and fauna.
Scotland's wildlife is typical of the north west of Europe, although several of the larger mammals such as the lynx, brown bear, wolf, elk and walrus were hunted to extinction in historic times. There are important populations of seals and internationally significant nesting grounds for a variety of seabirds such as gannets. The golden eagle is something of a national icon.
On the high mountain tops species including ptarmigan, mountain hare and stoat can be seen in their white colour phase during winter months. Remnants of the native Scots pine forest exist and within these areas the Scottish crossbill, the UK's only endemic bird species and vertebrate, can be found alongside capercaillie, wildcat, red squirrel and pine marten. In recent years various animals have been re-introduced, including the white-tailed sea eagle in 1975, the red kite in the 1980s, and more recently there have been experimental projects involving the beaver and wild boar. Today, much of the remaining native Caledonian Forest lies within the Cairngorms National Park and remnants of the forest remain at 84 locations across Scotland. On the west coast, remnants of ancient Celtic Rainforest still remain, particularly on the Taynish peninsula in Argyll, these forests are particularly rare due to high rates of deforestation throughout Scottish history.
The flora of the country is varied incorporating both deciduous and coniferous woodland and moorland and tundra species. However, large scale commercial tree planting and the management of upland moorland habitat for the grazing of sheep and commercial field sport activities impacts upon the distribution of indigenous plants and animals. The UK's tallest tree is a grand fir planted beside Loch Fyne, Argyll in the 1870s, and the Fortingall Yew may be 5,000 years old and is probably the oldest living thing in Europe. Although the number of native vascular plants is low by world standards, Scotland's substantial bryophyte flora is of global importance.
Economy and infrastructure.
Scotland has a western style open mixed economy closely linked with the rest of Europe and the wider world. Traditionally, the Scottish economy has been dominated by heavy industry underpinned by shipbuilding in Glasgow, coal mining and steel industries. Petroleum related industries associated with the extraction of North Sea oil have also been important employers from the 1970s, especially in the north east of Scotland.
De-industrialisation during the 1970s and 1980s saw a shift from a manufacturing focus towards a more service-oriented economy. Edinburgh is the financial services centre of Scotland, with many large finance firms based there, including: Lloyds Banking Group (owners of HBOS); the Government owned Royal Bank of Scotland and Standard Life. Edinburgh was ranked 15th in the list of world financial centres in 2007, but fell to 37th in 2012, following damage to its reputation, and in 2014 was ranked 64th.
In 2012, total Scottish exports (excluding intra-UK trade) were estimated to be £26 billion, of which 59% (£15.4 billion) were attributable to manufacturing. Scotland's primary exports include whisky, electronics and financial services. The United States, Netherlands, Germany, France and Norway constitute the country's major export markets. Scotland's Gross Domestic Product (GDP), including oil and gas produced in Scottish waters, was estimated at £150 billion for the calendar year 2012. If Scotland became independent, it would hold 95% of the UK's current oil and gas reserves if they were split geographically using a median line from the English-Scottish border. If the reserves were split by population, that figure would be reduced to 9%. Scotland also has renewable energy potential, especially in tidal energy and offshore wind.
Whisky is probably the best known of Scotland's manufactured products. Exports increased by 87% in the decade to 2012 and were valued at £4.3 billion in 2013, which was 85% of Scotland's food and drink exports. It supports around 10,000 jobs directly and 25,000 indirectly. It may contribute £400-682 million to Scotland, rather than several billion pounds, as more than 80% of whisky produced is owned by non-Scottish companies. Tourism is also widely recognised as a key contributor to the Scottish economy. A briefing published in 2002 by the Scottish Parliament Information Centre (SPICe) for the Scottish Parliament's Enterprise and Life Long Learning Committee stated that tourism accounted for up to 5% of GDP and 7.5% of employment.
In February 2012, the Centre for Economics and Business Research concluded that "Scotland receives no net subsidy" from the UK, as greater per capita tax generation in Scotland balanced out greater per capita public spending. More recent data, from 2012–13, show that Scotland generated 9.1% (£53.1bn; this included a geographical share of North Sea oil revenue – without it, the figures were 8.2% and £47.6bn) of the UK's tax revenues and received 9.3% (£65.2bn) of spending. Scotland's public spending deficit in 2012–13 was £12bn, a £3.5bn increase on the previous year; over the same period, the UK's deficit decreased by £2.6bn. Over the past thirty years, Scotland contributed a relative budget surplus of almost £20billion to the UK economy.
In the first quarter of 2014, the Scottish economy grew by 1.0%, above the 0.8% recorded for the UK. It also expanded by a further 0.9% in the second quarter of the year, this time the same rate as that of the UK. As of October 2014, Scotland outperforms the UK as a whole in all three labour market indicators. The Scottish unemployment rate of 5.5% is below the UK rate of 6.0%, the Scottish employment rate of 73.9% is higher than the UK figure of 73.0% and the rate of economic inactivity is 21.7% in Scotland but 22.2% in the UK.
Currency.
Although the Bank of England is the central bank for the UK, three Scottish clearing banks still issue their own Sterling banknotes: the Bank of Scotland; the Royal Bank of Scotland; and the Clydesdale Bank. The value of the Scottish banknotes in circulation in 2013 was £3.8 billion, underwritten by the Bank of England.
Transport.
Scotland has five main international airports (Glasgow, Edinburgh, Aberdeen, Prestwick and Inverness), which together serve 150 international destinations with a wide variety of scheduled and chartered flights. GIP operates Edinburgh airport and BAA operates (Aberdeen and Glasgow International), while Highland and Islands Airports operates 11 regional airports, including Inverness, which serve the more remote locations. Infratil operates Prestwick.
The Scottish motorways and major trunk roads are managed by Transport Scotland. The remainder of the road network is managed by the Scottish local authorities in each of their areas. Regular ferry services operate between the Scottish mainland and many islands. These ferries are mostly run by Caledonian MacBrayne, but some are operated by local councils. Other ferry routes, served by multiple companies, connect to Northern Ireland, Belgium, Norway, the Faroe Islands and also Iceland. Network Rail Infrastructure Limited owns and operates the fixed infrastructure assets of the railway system in Scotland, while the Scottish Government retains overall responsibility for rail strategy and funding in Scotland. Scotland's rail network has around 340 railway stations and 3000 kilometres of track. Over 62 million passenger journeys are made each year.
Scotland's rail network is managed by Transport Scotland. The East Coast and West Coast main railway lines connect the major cities and towns of Scotland with each other and with the rail network in England. Domestic rail services within Scotland are operated by ScotRail. During the time of British Rail the West Coast Main Line from London Euston to Glasgow Central was electrified in the early 1970s, followed by the East Coast Main Line in the late 1980s. British Rail created the ScotRail brand. When British Rail existed, many railway lines in Strathclyde were electrified. Strathclyde Passenger Transport Executive was at the forefront with the acclaimed "largest electrified rail network outside London". Some parts of the network are electrified, but there are no electrified lines in the Highlands, Angus, Aberdeenshire, the cities of Dundee or Aberdeen, or Perth & Kinross, and none of the islands has a rail link (although the railheads at Kyle of Lochalsh and Mallaig principally serve the islands).
In addition, Glasgow has had a small integrated subway system since 1896. Completely gutted and modernised between 1977 and 1980, its 15 stations serve just under 40,000 passengers per day. There are plans to extensively refurbish the system in time for the 2014 Commonwealth Games.
The East Coast Main Line crosses the Firth of Forth by the Forth Bridge. Completed in 1890, this cantilever bridge has been described as "the one internationally recognised Scottish landmark".
Demographics.
The population of Scotland at the 2001 Census was 5,062,011. This rose to 5,295,400, the highest ever, at the 2011 Census.
In the 2011 Census, 62% of Scotland's population stated their national identity as 'Scottish only', 18% as 'Scottish and British', 8% as 'British only', and 4% chose other national identities.
Although Edinburgh is the capital of Scotland, the largest city is Glasgow, which has just over 584,000 inhabitants. The Greater Glasgow conurbation, with a population of almost 1.2 million, is home to nearly a quarter of Scotland's population. The Central Belt is where most of the main towns and cities are located, including Glasgow, Edinburgh, Dundee and Perth. Scotland's only major city outside the Central Belt is Aberdeen.
In general, only the more accessible and larger islands retain inhabited. Currently, fewer than 90 remain inhabited. The Southern Uplands are essentially rural in nature and dominated by agriculture and forestry. Because of housing problems in Glasgow and Edinburgh, five new towns were created between 1947 and 1966. They are East Kilbride, Glenrothes, Livingston, Cumbernauld, and Irvine.
Immigration since World War II has given Glasgow, Edinburgh and Dundee small South Asian communities. In 2011, there were an estimated 49,000 ethnically Pakistani people living in Scotland, making them the largest non-White ethnic group. Since the Enlargement of the European Union more people from Central and Eastern Europe have moved to Scotland, and the 2011 census indicated that 61,000 Poles live there.
Scotland has three officially recognised languages: English, Scots, and Scottish Gaelic. Almost all Scots speak Scottish English. The 2011 census indicated that 63% of the population had "no skills in Scots". Others speak Highland English. Gaelic is mostly spoken in the Western Isles, where a large proportion of people still speak it; however, nationally its use is confined to just 1% of the population. The number of Gaelic speakers in Scotland dropped from 250,000 in 1881 to 60,000 in 2008.
There are many more people with Scottish ancestry living abroad than the total population of Scotland. In the 2000 Census, 9.2 million Americans self-reported some degree of Scottish descent. Ulster's Protestant population is mainly of lowland Scottish descent, and it is estimated that there are more than 27 million descendants of the Scots-Irish migration now living in the US. In Canada, the Scottish-Canadian community accounts for 4.7 million people. About 20% of the original European settler population of New Zealand came from Scotland.
In August 2012, the Scottish population reached an all time high of 5.25 million people. The reasons given were that, in Scotland, births were outnumbering the number of deaths, and immigrants were moving to Scotland from overseas. In 2011, 43,700 people moved from Wales, Northern Ireland or England to live in Scotland.
The total fertility rate (TFR) in Scotland is below the replacement rate of 2.1 (the TFR was 1.73 in 2011). The majority of births today are to unmarried women (51.3% of births were outside of marriage in 2012).
Education.
The Scottish education system has always remained distinct from the rest of United Kingdom, with a characteristic emphasis on a broad education. In the 15th century, the Humanist emphasis on education cumulated with the passing of the Education Act 1496, which decreed that all sons of barons and freeholders of substance should attend grammar schools to learn "perfyct Latyne", resulting in an increase in literacy among a male and wealthy elite. In the Reformation the 1560 "First Book of Discipline" set out a plan for a school in every parish, but this proved financially impossible. In 1616 an act in Privy council commanded every parish to establish a school. By the late seventeenth century there was a largely complete network of parish schools in the lowlands, but in the Highlands basic education was still lacking in many areas. Education remained a matter for the church rather than the state until the Education Act (1872).
The "Curriculum for Excellence" provides the curricular framework for children and young people from age 3 to 18. All 3- and 4-year-old children in Scotland are entitled to a free nursery place. Formal primary education begins at approximately 5 years old and lasts for 7 years (P1–P7); today, children in Scotland study Standard Grades, or Intermediate qualifications between the ages of 14 and 16. These are being phased out and replaced by the National Qualifications of the Curriculum for Excellence. The school leaving age is 16, after which students may choose to remain at school and study for Access, Intermediate or Higher Grade and Advanced Higher qualifications. A small number of students at certain private, independent schools may follow the English system and study towards GCSEs and A and AS-Levels instead.
There are fifteen Scottish universities, some of which are amongst the oldest in the world. These include the University of St Andrews, the University of Glasgow, the University of Aberdeen, the University of Edinburgh and the University of Dundee —many of which are ranked amongst the best in the UK. Proportionally, Scotland has more universities in QS' World University Rankings' top 100 than any other nation in the world. The country produces 1% of the world's published research with less than 0.1% of the world's population, and higher education institutions account for 9% of Scotland's service sector exports. Scotland's University Courts are the only bodies in Scotland authorised to award degrees.
Scotland's Universities are complemented in the provision of Further and Higher Education by 43 Colleges. Colleges offer National Certificates, Higher National Certificates and Higher National Diplomas. These Group Awards, alongside Scottish Vocational Qualifications, aim to ensure Scotland's population has the appropriate skills and knowledge to meet workplace needs.
In 2014, research reported by the Office for National Statistics found that Scotland was the most highly educated country in Europe and among the most well-educated in the world in terms of tertiary education attainment, with roughly 40% of people in Scotland aged 16–64 educated to NVQ level 4 and above. Based on the original data for EU statistical regions, all four Scottish regions ranked significantly above the European average for completion of tertiary-level education by 25–64-year-olds.
Religion.
Just over half (54%) of the Scottish population reported being a Christian while nearly 37% reported not having a religion in a 2011 census.
Since the Scottish Reformation of 1560, the national church (the Church of Scotland, also known as The Kirk) has been Protestant and Reformed in theology. Since 1689 it has had a Presbyterian system of church government, and enjoys independence from the state. About 12% of the population are currently members of the Church of Scotland, with 40% claiming affinity. The Church operates a territorial parish structure, with every community in Scotland having a local congregation.
Scotland also has a significant Roman Catholic population, 19% claiming that faith, particularly in the west. After the Reformation, Roman Catholicism in Scotland continued in the Highlands and some western islands like Uist and Barra, and it was strengthened during the 19th century by immigration from Ireland. Other Christian denominations in Scotland include the Free Church of Scotland, various other Presbyterian offshoots, and the Scottish Episcopal Church.
Islam is the largest non-Christian religion (estimated at around 40,000, which is less than 0.9% of the population), and there are also significant Jewish, Hindu and Sikh communities, especially in Glasgow. The Samyé Ling monastery near Eskdalemuir, which celebrated its 40th anniversary in 2007, is the first Buddhist monastery in western Europe.
Health care.
Healthcare in Scotland is mainly provided by NHS Scotland, Scotland's public health care system. This was founded by the National Health Service (Scotland) Act 1947 (later repealed by the National Health Service (Scotland) Act 1978) that took effect on 5 July 1948 to coincide with the launch of the NHS in England and Wales. However, even prior to 1948, half of Scotland's landmass was already covered by state funded health care, provided by the Highlands and Islands Medical Service. Healthcare policy and funding is the responsibility of the Scottish Government's Health Directorates. The current Cabinet Secretary for Health and Wellbeing is Alex Neil and the Director-General (DG) Health and chief executive, NHS Scotland is Paul Gray.
In 2008, the NHS in Scotland had around 158,000 staff including more than 47,500 nurses, midwives and health visitors and over 3,800 consultants. In addition, there are also more than 12,000 doctors, family practitioners and allied health professionals, including dentists, opticians and community pharmacists, who operate as independent contractors providing a range of services within the NHS in return for fees and allowances. These fees and allowances were removed in May 2010, and prescriptions are entirely free, although dentists and opticians may charge if the patient's household earns over a certain amount, about £30,000 per annum.
Life expectancy for those born in Scotland between 2010 and 2012 is 76.5 years for males and 80.7 years for females. This is the lowest of any of the four countries of the UK.
Military.
Of the money spent on UK defence, about £3.3 billion can be attributed to Scotland as of 2013. Although Scotland has a long military tradition predating the Treaty of Union with England, its armed forces now form part of the British Armed Forces, with the notable exception of the Atholl Highlanders, Europe's only legal private army. In 2006, the infantry regiments of the Scottish Division were amalgamated to form the Royal Regiment of Scotland. Other distinctively Scottish regiments in the British Army include the Scots Guards, the Royal Scots Dragoon Guards and the Scottish Transport Regiment, a Territorial Army Regiment of the Royal Logistic Corps.
Because of their topography and perceived remoteness, parts of Scotland have housed many sensitive defence establishments, with mixed public feelings. Between 1960 and 1991, the Holy Loch was a base for the US fleet of Polaris ballistic missile submarines. Today, Her Majesty's Naval Base Clyde, 25 mi north west of Glasgow, is the base for the four Trident-armed "Vanguard" class ballistic missile submarines that comprise the UK's nuclear deterrent. Scapa Flow was the major Fleet base for the Royal Navy until 1956.
Two frontline Royal Air Force bases are also located in Scotland. These are RAF Leuchars and RAF Lossiemouth, the last of which is the most northerly air defence fighter base in the United Kingdom. A third, RAF Kinloss will close as an RAF unit in 2013–14. RAF Leuchars is due to be turned into an army barracks, ending the RAF's connection in Fife.
The only open-air live depleted uranium weapons test range in the British Isles is located near Dundrennan. As a result, over 7000 potentially toxic munitions lie on the seabed of the Solway Firth.
Culture.
Scottish music is a significant aspect of the nation's culture, with both traditional and modern influences. A famous traditional Scottish instrument is the Great Highland Bagpipe, a wind instrument consisting of three drones and a melody pipe (called the chanter), which are fed continuously by a reservoir of air in a bag. Bagpipe bands, featuring bagpipes and various types of drums, and showcasing Scottish music styles while creating new ones, have spread throughout the world. The clàrsach (harp), fiddle and accordion are also traditional Scottish instruments, the latter two heavily featured in Scottish country dance bands. Today, there are many successful Scottish bands and individual artists in varying styles including Annie Lennox, Amy Macdonald, Runrig, Boards of Canada, Cocteau Twins, Deacon Blue, Franz Ferdinand, Susan Boyle, Emeli Sande, Texas, The View, The Fratellis, Twin Atlantic and Biffy Clyro. Other Scottish musicians include Shirley Manson, Paolo Nutini and Calvin Harris.
Scotland has a literary heritage dating back to the early Middle Ages. The earliest extant literature composed in what is now Scotland was in Brythonic speech in the 6th century, but is preserved as part of Welsh literature. Later medieval literature included works in Latin, Gaelic, Old English and French. The first surviving major text in Early Scots is the 14th-century poet John Barbour's epic "Brus", focusing on the life of Robert I, and was soon followed by a series of vernacular romances and prose works. In the 16th century the crown's patronage helped the development of Scots drama and poetry, but the accession of James VI to the English throne removed a major centre of literary patronage and Scots was sidelined as a literary language. Interest in Scots literature was revived in the 18th century by figures including James Macpherson, whose Ossian Cycle made him the first Scottish poet to gain an international reputation and was a major influence on the European Enlightenment. It was also a major influence on Robert Burns, whom many consider the national poet, and Walter Scott, whose Waverley Novels did much to define Scottish identity in the 19th century. Towards the end of the Victorian era a number of Scottish-born authors achieved international reputations as writers in English, including Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald. In the 20th century the Scottish Renaissance saw a surge of literary activity and attempts to reclaim the Scots language as a medium for serious literature. Members of the movement were followed by a new generation of post-war poets including Edwin Morgan, who would be appointed the first Scots Makar by the inaugural Scottish government in 2004. From the 1980s Scottish literature enjoyed another major revival, particularly associated with a group of writers including Irvine Welsh. Scottish poets who emerged in the same period included Carol Ann Duffy, who, in May 2009, was the first Scot named UK Poet Laureate.
Television in Scotland is largely the same as UK-wide broadcasts, however the national broadcaster is BBC Scotland, a constituent part of the British Broadcasting Corporation, the publicly funded broadcaster of the United Kingdom. It runs three national television stations, and the national radio stations, "BBC Radio Scotland" and "BBC Radio nan Gaidheal", amongst others. Scotland also has some programming in the Gaelic language. BBC Alba is the national Gaelic-language channel. The main Scottish commercial television station is STV. National newspapers such as the "Daily Record", "The Herald", and "The Scotsman" are all produced in Scotland. Important regional dailies include the Evening News in Edinburgh "The Courier" in Dundee in the east, and "The Press and Journal" serving Aberdeen and the north. Scotland is represented at the Celtic Media Festival, which showcases film and television from the Celtic countries. Scottish entrants have won many awards since the festival began in 1980.
As one of the Celtic nations, Scotland and Scottish culture is represented at interceltic events at home and over the world. Scotland hosts several music festivals including Celtic Connections (Glasgow), and the Hebridean Celtic Festival (Stornoway). Festivals celebrating Celtic culture, such as Festival Interceltique de Lorient (Brittany), the Pan Celtic Festival (Ireland), and the National Celtic Festival (Portarlington, Australia), feature elements of Scottish culture such as language, music and dance.
Sport.
Sport is an important element in Scottish culture, with the country hosting many of its own national sporting competitions. It enjoys independent representation at many international sporting events including the FIFA World Cup, the Rugby Union World Cup, the Rugby League World Cup, the Cricket World Cup and the Commonwealth Games, but not at the Olympic Games where Scottish athletes are part of the Great Britain team. Scotland has its own national governing bodies, such as the Scottish Football Association (the second oldest national football association in the world) and the Scottish Rugby Union. Variations of football have been played in Scotland for centuries, with the earliest reference dating back to 1424. Association football is the most popular sport and the Scottish Cup is the world's oldest national trophy.
Scotland contested the first ever international football game in 1872 against England. The match took place at Hamilton Crescent, Glasgow, home of the West of Scotland Cricket Club. Scottish clubs have been successful in European competitions with Celtic winning the European Cup in 1967, Rangers and Aberdeen winning the UEFA Cup Winners' Cup in 1972 and 1983 respectively, and Aberdeen also winning the UEFA Super Cup in 1983. Dundee United have also made it to a European final, reaching the UEFA Cup Final in 1987, but losing on aggregate 2-1 to IFK Göteborg.
With the modern game of golf originating in 15th century Scotland, the country is promoted as the home of golf. To many golfers the Old Course in the Fife town of St. Andrews, an ancient links course dating to before 1574, is considered a site of pilgrimage. The world's oldest golf tournament, and golf's first major, is The Open Championship, which was first played on 17 October 1860 at Prestwick Golf Club, in Ayrshire, Scotland, with Scottish golfers winning the earliest majors. There are many other famous golf courses in Scotland, including Carnoustie, Gleneagles, Muirfield, and Royal Troon. Other distinctive features of the national sporting culture include the Highland games, curling and shinty. In boxing, Scotland has had 13 world champions, including Ken Buchanan, Benny Lynch and Jim Watt.
Scotland has competed at every Commonwealth Games since 1930 and has won 356 medals in total—91 Gold, 104 Silver and 161 Bronze. Edinburgh played host to the Commonwealth Games in 1970 and 1986, and most recently Glasgow in 2014.
National symbols.
The image of St. Andrew, martyred while bound to an X-shaped cross, first appeared in the Kingdom of Scotland during the reign of William I. Following the death of King Alexander III in 1286 an image of Andrew was used on the seal of the Guardians of Scotland who assumed control of the kingdom during the subsequent interregnum. Use of a simplified symbol associated with Saint Andrew, the saltire, has its origins in the late 14th century; the Parliament of Scotland decreeing in 1385 that Scottish soldiers should wear a white Saint Andrew's Cross on the front and back of their tunics. Use of a blue background for the Saint Andrew's Cross is said to date from at least the 15th century. Since 1606 the saltire has also formed part of the design of the Union Flag. There are numerous other symbols and symbolic artefacts, both official and unofficial, including the thistle, the nation's floral emblem (celebrated in the song, The Thistle o' Scotland), the Declaration of Arbroath, incorporating a statement of political independence made on 6 April 1320, the textile pattern tartan that often signifies a particular Scottish clan and the royal Lion Rampant flag. Highlanders can thank James Graham, 3rd Duke of Montrose, for the repeal in 1782 of the Act of 1747 prohibiting the wearing of tartans.
Although there is no official national anthem of Scotland, "Flower of Scotland" is played on special occasions and sporting events such as football and rugby matches involving the Scotland national teams and since 2010 is also played at the Commonwealth Games after it was voted the overwhelming favourite by participating Scottish athletes. Other currently less popular candidates for the National Anthem of Scotland include "Scotland the Brave", "Highland Cathedral", "Scots Wha Hae" and "A Man's A Man for A' That".
St Andrew's Day, 30 November, is the national day, although Burns' Night tends to be more widely observed, particularly outside Scotland. In 2006, the Scottish Parliament passed the St. Andrew's Day Bank Holiday (Scotland) Act 2007, designating the day an official bank holiday.Tartan Day is a recent innovation from Canada.
The national animal of Scotland is the unicorn, which has been a Scottish heraldic symbol since the 12th century.
Further reading.
</dl>
Specialized monographs.
</dl>

</doc>
<doc id="26995" url="http://en.wikipedia.org/wiki?curid=26995" title="Shire">
Shire

A shire is a traditional term for a division of land, found in the United Kingdom and Australia. The word derives from the Old English "scir", itself a derivative of the Proto-Germanic "skizo" (cf. Old High German "scira"), meaning care or official charge.
In Britain, "shire" is the original term for what is usually known now as a "county"; the word "county" having been introduced at the Norman Conquest of England. The two are nearly synonymous. Although in modern British usage counties are referred to as "shires" mainly in poetic contexts, terms such as Shire Hall remain common. Shire also remains a common part of many county names.
In some rural parts of Australia, a shire is a local government area; however, in Australia it is not synonymous with a "county", which is a lands administrative division. Individually, or as a suffix in Scotland and in the far northeast of England, the word is pronounced . As a suffix in an English or Welsh place name, it is in most regions pronounced , or sometimes . (In south-east England the is dropped in accordance with normal regional phonology, so that (for instance) "Berkshire" becomes .)
Origins.
The system was first used in Wessex from the beginning of Anglo-Saxon settlement, and spread to most of the rest of England in the tenth century, along with West Saxon political control. In Domesday (1086) the city of York was divided into shires. The first shires of Scotland were created in English-settled areas such as Lothian and the Borders, in the ninth century. King David I more consistently created shires and appointed sheriffs across lowland "shores" of Scotland.
The shire in early days was governed by an "Ealdorman" and in the later Anglo-Saxon period by royal official known as a "shire reeve" or sheriff. The shires were divided into hundreds or wapentakes, although other less common sub-divisions existed. An alternative name for a shire was a "sheriffdom" until sheriff court reforms separated the two concepts. In Scotland the word "county" was not adopted for the shires. Although "county" appears in some texts, "shire" was the normal name until counties for statutory purposes were created in the nineteenth century.
Shire county.
The phrase "shire county" applies, unofficially, to non-metropolitan counties in England, specifically those that are not unitary local authority areas.
Shire names in the United Kingdom.
"Shire" also refers, in a narrower sense, to ancient counties with names that ended in "shire". These counties are typically (though not always) named after their county town.
The suffix "-shire" is attached to most of the names of English, Scottish and Welsh counties. It tends not to be found in the names of shires that were pre-existing divisions. Essex, Kent, and Sussex, for example, have never borne a "-shire", as each represents a former Anglo-Saxon kingdom. Similarly Cornwall was a British kingdom before it became an English county. The term 'shire' is not used in the names of the six traditional counties of Northern Ireland.
Shire names in England.
Shires in England bearing the "-shire" suffix include:
Bedfordshire, Berkshire, Buckinghamshire, Cambridgeshire, Cheshire, Derbyshire, Gloucestershire, Hampshire, Herefordshire, Hertfordshire, Huntingdonshire, Lancashire, Lincolnshire, Leicestershire, Northamptonshire, Nottinghamshire, Oxfordshire, Shropshire, Staffordshire, Warwickshire, Wiltshire, Worcestershire, and Yorkshire. These counties, on their historical boundaries, cover a little more than half the area of England. The counties that do not use "-shire" are mainly in three areas, in the south-east, south-west and far north of England.
Yorkshire no longer exists as a unit of local government in England. Some of the successor modern counties formed by its breakup (North Yorkshire, South Yorkshire and West Yorkshire) however retain the old county name as a component. (East Yorkshire has a more complicated signification.)
The county of Devon is also known as Devonshire, although this is not an official name and is not often used outside the county. The counties of Dorset, Rutland and Somerset were occasionally Dorsetshire, Rutlandshire and Somersetshire, but these usages are now considered archaic.
Hexhamshire was a county in the north-east of England from the early 12th century until 1572, when it was incorporated into Northumberland.
Shire names in Scotland.
In Scotland, barely affected by the Norman conquest of England, the word "shire" prevailed over "county" until the 19th century. Earliest sources have the same usage of the "-shire" suffix as in England (though in Scots this was oftenmost "schyr"). Later the "Shire" appears as a separate word.
"Shire" names in Scotland include Aberdeenshire, Ayrshire, Banffshire, Berwickshire, Clackmannanshire, Cromartyshire, Dumfriesshire, Dunbartonshire, Inverness-shire, Kincardineshire, Kinross-shire, Kirkcudbrightshire, Lanarkshire, Morayshire, Nairnshire, Peeblesshire, Perthshire, Renfrewshire, Ross-shire, Roxburghshire, Selkirkshire, Stirlingshire, and Wigtownshire. 
In Scotland four shires have alternative names with the "-shire" suffix: Angus (Forfarshire), East Lothian (Haddingtonshire), Midlothian (Edinburghshire) and West Lothian (Linlithgowshire).
Sutherland is occasionally still referred to as Sutherlandshire. Similarly, Argyllshire, Buteshire, Caithness-shire and Fifeshire are sometimes found. Also, Morayshire was previously called Elginshire. There is currently much debate about whether Argyllshire was ever really used.
Shire names in Wales.
Shires in Wales bearing the "-shire" suffix include:
Brecknockshire (or Breconshire), Caernarfonshire, Cardiganshire, Carmarthenshire, Denbighshire, Flintshire, Monmouthshire, Montgomeryshire, Pembrokeshire, and Radnorshire.
In Wales, the counties of Merioneth and Glamorgan are occasionally referred to with the "shire" suffix. The only traditional Welsh county that never takes "shire" is Anglesey—in English: in Welsh it is referred to as 'Sir Fon'.
Non-county "shires".
The suffix –"shire" could be a generalised term referring to a district. It did not acquire the strong association with county until later.
Other than these, the term was used for several other districts. Bedlingtonshire, Craikshire, Norhamshire and Islandshire were exclaves of County Durham, which were incorporated into Northumberland or Yorkshire in 1844. The suffix was also used for many hundreds, wapentakes and liberties such as Allertonshire, Blackburnshire, Halfshire, Howdenshire, Leylandshire, Powdershire, Pydarshire, Richmondshire, Riponshire, Salfordshire, Triggshire, Tynemouthshire, West Derbyshire and Wivelshire, counties corporate such as Hullshire, and other districts such as Applebyshire, Bamburghshire, Bunkleshire, Carlisleshire, Coldinghamshire, Coxwoldshire, Cravenshire, Hallamshire, Mashamshire and Yetholmshire.
Non-county shires were very common in Scotland. Kinross-shire and Clackmannanshire are arguably survivals from such districts. Non-county "shires" in Scotland include Bunkleshire, Coldinghamshire and Yetholmshire.
Richmondshire is today the name of a local government district of North Yorkshire.
Shires in Australia.
"Shire" is the most common word in Australia for rural local government areas (LGAs). The states of New South Wales, Victoria, Queensland and Western Australia use the term "Shire" for this unit.
In contrast, South Australia uses district and region for its rural LGA units, while Tasmania uses municipality.
Shires are generally functionally indistinguishable from towns, borough, municipalities, or cities.
Three LGAs in outer metropolitan Sydney and four in outer metropolitan Melbourne have populations exceeding that of towns or municipalities, but retain significant bushlands and/or semi-rural areas, and most have continued to use "Shire" in the their titles—possibly due to community demand or popularity; or for financial and socio-political gain—whilst others have dropped "Shire" from their titles. These "city-shires" are:
Sydney:
Melbourne:
Shires in the United States.
In 1634, eight "shires" were created in the Virginia Colony by order of Charles I, King of England. They were renamed as counties only a few years later. They were:
As of 2013 six of the original eight Shires of Virginia are considered to be still extant whilst two have consolidated with a neighbouring city. Most of their boundaries have changed in the intervening centuries.
Before the Province of New York was granted county subdivisions and a greater royal presence in 1683, the early ducal colony consisted of York Shire, as well as Albany and Ulster, after the three titles held by Prince James: Duke of York, Duke of Albany, Earl of Ulster. While these were basically renamed Dutch core settlements, they were quickly converted to English purposes, while the Dutch remained within the colony, as opposed to later practice of the Acadian Expulsion. Further Anglo-Dutch synthesis occurred when James enacted the Dominion of New England and later when William III of England took over through the Glorious Revolution.
A few New England states and commonwealths (namely Vermont, Massachusetts, and Maine), still use the term "shire town" for their county seats, although they use the term county, rather than shire.

</doc>
<doc id="26997" url="http://en.wikipedia.org/wiki?curid=26997" title="Scientist">
Scientist

A scientist, in a broad sense, is one engaging in a systematic activity to acquire knowledge. In a more restricted sense, a scientist may refer to an individual who uses the scientific method. The person may be an expert in one or more areas of science. This article focuses on the more restricted use of the word. Scientists perform research toward a more comprehensive understanding of nature, including physical, mathematical and social realms.
Philosophy is a distinct activity that is not generally considered science. Philosophers aim to provide a comprehensive understanding of intangible aspects of reality and experience that cannot be physically measured.
Scientists are also distinct from engineers, those who design, build and maintain devices for particular situations. When science is done with a goal toward practical utility, it is called applied science. An applied scientist may not be designing something in particular, but rather is conducting research with the aim of developing new technologies and practical methods. When science is done with an inclusion of intangible aspects of reality it is called "natural philosophy".
Description.
Science and technology have continually modified human existence through the engineering process. As a profession the scientist of today is widely recognized. Scientists include theoreticians who mainly develop new models to explain existing data and predict new results, and experimentalists who mainly test models by making measurements — though in practice the division between these activities is not clear-cut, and many scientists perform both tasks.
Law and Mathematics are often grouped with the sciences. Some of the greatest physicists have also been creative mathematicians and lawyers. There is a continuum from the most theoretical to the most empirical scientists with no distinct boundaries. In terms of personality, interests, training and professional activity, there is little difference between applied mathematicians and theoretical physicists.
Scientists can be motivated in several ways. Many have a desire to understand why the world is as we see it and how it came to be. They exhibit a strong curiosity about reality. Other motivations are recognition by their peers and prestige, or the desire to apply scientific knowledge for the benefit of people's health, the nations, the world, nature or industries (academic scientist and industrial scientist). Scientists tend to be less motivated by direct financial reward for their work than other careers. As a result, scientific researchers often accept lower average salaries when compared with many other professions which require a similar amount of training and qualification.
Demography.
The number of scientists is vastly different from country to country. For instance, there are only 4 full-time scientists per 10,000 workers in India while this number is 79 for the United States. The numbers (per 10,000 workers) for selected countries are as follows:
Historical development and etymology of the term.
Until the late 19th or early 20th century, scientists were called "natural philosophers" or "men of science".
English philosopher and historian of science William Whewell coined the term "scientist" in 1833, and it was first published in Whewell's anonymous 1834 review of Mary Somerville's "On the Connexion of the Physical Sciences" published in the "Quarterly Review". Whewell's suggestion of the term was partly satirical, a response to changing conceptions of science itself in which natural knowledge was increasingly seen as distinct from other forms of knowledge. Whewell wrote of "an increasing proclivity of separation and dismemberment" in the sciences; while highly specific terms proliferated—chemist, mathematician, naturalist—the broad term "philosopher" was no longer satisfactory to group together those who pursued science, without the caveats of "natural" or "experimental" philosopher. Members of the British Association for the Advancement of Science had been complaining about the lack of a good term at recent meetings, Whewell reported in his review; alluding to himself, he noted that "some ingenious gentleman proposed that, by analogy with "artist", they might form [the word] "scientist", and added that there could be no scruple in making free with this term since we already have such words as "economist", and "atheist"—but this was not generally palatable". Scientists are the people who ask a question about a phenomenon and proceed to systematically go about answering the question themselves. They are by nature curious, creative and well organized. They need to have the ability to observe something and see in it some of the properties other people overlook.
Whewell proposed the word again more seriously (and not anonymously) in his 1840 "The Philosophy of the Inductive Sciences":
As we cannot use physician for a cultivator of physics, I have called him a physicist. We need very much a name to describe a cultivator of science in general. I should incline to call him a Scientist. Thus we might say, that as an Artist is a Musician, Painter, or Poet, a Scientist is a Mathematician, Physicist, or Naturalist.
He also proposed the term "physicist" at the same time, as a counterpart to the French word "physicien". Neither term gained wide acceptance until decades later; "scientist" became a common term in the late 19th century in the United States and around the turn of the 20th century in Great Britain. By the twentieth century, the modern notion of science as a special brand of information about the world, practiced by a distinct group and pursued through a unique method, was essentially in place.
The social roles of "scientists", and their predecessors before the emergence of modern scientific disciplines, have evolved considerably over time. Scientists of different eras (and before them, natural philosophers, mathematicians, natural historians, natural theologians, engineers, and other who contributed to the development of science) have had widely different places in society, and the social norms, ethical values, and epistemic virtues associated with scientists—and expected of them—have changed over time as well. Accordingly, many different historical figures can be identified as early scientists, depending on which elements of modern science are taken to be essential. 
Some historians point to the 17th century as the period when science in a recognizably modern form developed (what is popularly called the Scientific Revolution). It wasn't until the 19th century that sufficient socioeconomic changes occurred for scientists to emerge as a major profession.
Ancient and medieval science.
Knowledge about nature in Classical Antiquity was pursued by many kinds of scholars. Greek contributions to science—including works of geometry and mathematical astronomy, early accounts of biological processes and catalogs of plants and animals, and theories of knowledge and learning—were produced by philosophers and physicians, as well as practitioners of various trades. These roles, and their associations with scientific knowledge, spread with the Roman Empire and, with the spread of Christianity, became closely linked to religious institutions in most of Europe. Astrology and astronomy became an important area of knowledge, and the role of astronomer/astrologer developed with the support of political and religious patronage. By the time of the medieval university system, knowledge was divided into the "trivium"—philosophy, including natural philosophy—and the "quadrivium"—mathematics, including astronomy. Hence, the medieval analogs of scientists were often either philosophers or mathematicians. Knowledge of plants and animals was broadly the province of physicians.
Science in medieval Islam generated some new modes of developing natural knowledge, although still within the bounds of existing social roles such as philosopher and mathematician. Many proto-scientists from the Islamic Golden Age and medieval and Renaissance Europe are considered polymaths, in part because of the lack of anything corresponding to modern scientific disciplines. Many of these early polymaths were also religious priests and theologians: for example, Alhazen and al-Biruni were mutakallimiin; the physician Avicenna was a hafiz; the physician Ibn al-Nafis was a hafiz, muhaddith and ulema; the botanist Otto Brunfels was a theologian and historian of Protestantism; the astronomer and physician Nicolaus Copernicus was a priest.
Historical scientists.
Descartes was not only a pioneer of analytic geometry but formulated a theory of mechanics and advanced ideas about the origins of animal movement and perception. Vision interested the physicists Young and Helmholtz, who also studied optics, hearing and music. Newton extended Descartes' mathematics by inventing calculus (contemporaneously with Leibniz). He provided a comprehensive formulation of classical mechanics and investigated light and optics. Fourier founded a new branch of mathematics — infinite, periodic series — studied heat flow and infrared radiation, and discovered the greenhouse effect. Von Neumann, Turing, Khinchin, Markov and Wiener, all mathematicians, made major contributions to science and probability theory, including the ideas behind computers, and some of the foundations of statistical mechanics and quantum mechanics. Many mathematically inclined scientists, including Galileo, were also musicians.
In the late 19th century, Louis Pasteur, an organic chemist, discovered that microorganisms can cause disease. A few years earlier, Oliver Wendell Holmes, Sr., the American physician, poet and essayist, noted that sepsis in women following childbirth was spread by the hands of medics, four years before Semmelweis in Europe. There are many compelling stories in medicine and biology, such as the development of ideas about the circulation of blood from Galen to Harvey. The flowering of genetics and molecular biology in the 20th century is replete with famous names. Ramón y Cajal won the Nobel Prize in 1906 for his remarkable observations in neuroanatomy.
Some see a dichotomy between experimental sciences and purely "observational" sciences such as astronomy, meteorology, oceanography and seismology. But astronomers have done basic research in optics, developed charge-coupled devices, and in recent decades have sent space probes to study other planets in addition to using the Hubble Telescope to probe the origins of the Universe some 14 billion years ago. Microwave spectroscopy has now identified dozens of organic molecules in interstellar space, requiring laboratory experimentation and computer simulation to confirm the observational data and starting a new branch of chemistry. Computer modeling and numerical methods are techniques required of students in every field of quantitative science.
Women in science.
The percent of women entering into science are usually intertwined with engineering stats but the combination of the percentages shows the low numbers that are involved. The number of science and engineering doctorates awarded to women rose from a mere 7 percent in 1970 to 34 percent in 1985 and in engineering alone the numbers of bachelor's degrees awarded to women rose from only 385 in 1975 to more than 11000 in 1985.
The inequality prevails into the professional setting in ways such as starting position inequality and income inequality. According to Eisenhart and Finkel women experiences, even when they have equal qualifications, are that they start in lower-positions while men are granted tenure track positions. This later predicts an inequality of tenures positions as scientist in universities, "as of 1989, 65 percent of men and only 40 percent of women held tenured positions." Income conflicts occur when median annual salaries for full-time employed civilian scientists, "salary for men is $48,000, and that for women is $42,000."
Types of scientists.
Those considering science as a career often look to the frontiers. These include cosmology and biology, especially molecular biology and the human genome project. Other areas of active research include the exploration of matter at the scale of elementary particles as described by high-energy physics, and materials science, which seeks to discover and design new materials. Although there have been remarkable discoveries with regard to brain function and neurotransmitters, the nature of the mind and human thought still remains unknown.

</doc>
<doc id="27000" url="http://en.wikipedia.org/wiki?curid=27000" title="Smog">
Smog

Smog is a type of air pollutant. The word "smog" was made in the early 20th century as a portmanteau of the words smoke and fog to refer to smoky fog. The word was then intended to refer to what was sometimes known as pea soup fog, a familiar and serious problem in London from the 19th century to the mid 20th century. This kind of smog is caused by the burning of large amounts of coal within a city; this smog contains soot particulates from smoke, sulfur dioxide and other components.
Modern smog, as found for example in Los Angeles, is a type of air pollution derived from vehicular emission from internal combustion engines and industrial fumes that react in the atmosphere with sunlight to form secondary pollutants that also combine with the primary emissions to form photochemical smog. In certain other cities, such as Delhi, smog severity is often aggravated by stubble burning in neighboring agricultural areas. The atmospheric pollution levels of Los Angeles, Beijing, Delhi, Mexico City and other cities are increased by inversion that traps pollution close to the ground. It is usually highly toxic to humans and can cause severe sickness, shortened life or death.
Etymology.
Coinage of the term "smog" is generally attributed to Dr. Henry Antoine Des Voeux in his 1905 paper, "Fog and Smoke" for a meeting of the Public Health Congress. The July 26, 1905 edition of the London newspaper "Daily Graphic" quoted Des Voeux, "He said it required no science to see that there was something produced in great cities which was not found in the country, and that was smoky fog, or what was known as 'smog.'" The following day the newspaper stated that "Dr. Des Voeux did a public service in coining a new word for the London fog." "Smog" also appears in a January 19, 1893, "Los Angeles Times" article and is attributed to "a witty English writer."
Causes.
Coal.
Coal fires, used to heat individual buildings or in a power-producing plant, can emit significant clouds of smoke that contributes to smog. Air pollution from this source has been reported in England since the Middle Ages. London, in particular, was notorious up through the mid-20th century for its coal-caused smogs, which were nicknamed 'pea-soupers.' Air pollution of this type is still a problem in areas that generate significant smoke from burning coal, as witnessed by the 2013 autumnal smog in Harbin, China, which closed roads, schools, and the airport.
Transportation emissions.
Traffic emissions – such as from trucks, buses, and automobiles – also contribute. Airborne by-products from vehicle exhaust systems cause air pollution and are a major ingredient in the creation of smog in some large cities.
The major culprits from transportation sources are carbon monoxide (CO), nitrogen oxides (NO and NOx), volatile organic compounds, sulfur dioxide, and hydrocarbons. These molecules react with sunlight, heat, ammonia, moisture, and other compounds to form the noxious vapors, ground level ozone, and particles that comprise smog.
Photochemical smog.
Photochemical smog was first described in the 1950s. It is the chemical reaction of sunlight, nitrogen oxides and volatile organic compounds in the atmosphere, which leaves airborne particles and ground-level ozone. This noxious mixture of air pollutants can include the following:
All of these harsh chemicals are usually highly reactive and oxidizing. Photochemical smog is therefore considered to be a problem of modern industrialization. It is present in all modern cities, but it is more common in cities with sunny, warm, dry climates and a large number of motor vehicles. Because it travels with the wind, it can affect sparsely populated areas as well.
Natural causes.
An erupting volcano can also emit high levels of sulphur dioxide along with a large quantity of particulate matter; two key components to the creation of smog. However, the smog created as a result of a volcanic eruption is often known as vog to distinguish it as a natural occurrence.
The radiocarbon content of some plant life has been linked to the distribution of smog in some areas. For example, the creosote bush in the Los Angeles area has been shown to have an effect on smog distribution that is more than fossil fuel combustion alone.
Health effects.
Smog is a serious problem in many cities and continues to harm human health. Ground-level ozone, sulfur dioxide, nitrogen dioxide and carbon monoxide are especially harmful for senior citizens, children, and people with heart and lung conditions such as emphysema, bronchitis, and asthma. It can inflame breathing passages, decrease the lungs' working capacity, cause shortness of breath, pain when inhaling deeply, wheezing, and coughing. It can cause eye and nose irritation and it dries out the protective membranes of the nose and throat and interferes with the body's ability to fight infection, increasing susceptibility to illness. Hospital admissions and respiratory deaths often increase during periods when ozone levels are high.
Levels of unhealthy exposure.
The U.S. EPA has developed an Air Quality Index to help explain air pollution levels to the general public. 8 hour average ozone concentrations of 85 to 104 ppbv are described as "Unhealthy for Sensitive Groups", 105 ppbv to 124 ppbv as "unhealthy" and 125 ppb to 404 ppb as "very unhealthy". The "very unhealthy" range for some other pollutants are: 355 μg m−3 - 424 μg m−3 for PM10; 15.5 ppm - 30.4ppm for CO and 0.65 ppm - 1.24 ppm for NO2.
Premature deaths due to cancer and respiratory disease.
The Ontario Medical Association announced that smog is responsible for an estimated 9,500 premature deaths in the province each year.
A 20-year American Cancer Society study found that cumulative exposure also increases the likelihood of premature death from a respiratory disease, implying the 8-hour standard may be insufficient.
Smog and the risk of certain birth defects.
A study examining 806 women who had babies with birth defects between 1997 and 2006, and 849 women who had healthy babies, found that smog in the San Joaquin Valley area of California was linked to two types of neural tube defects: spina bifida (a condition involving, among other manifestations, certain malformations of the spinal column), and anencephaly (the underdevelopment or absence of part or all of the brain, which if not fatal usually results in profound impairment).
Smog and low birth weight.
According to a study published in The Lancet, even a very small (5 μg) change in PM2.5 exposure was associated with an increase (18%) in risk of a low birth weight at delivery, and this relationship held even below the current accepted safe levels.
Areas affected.
Smog can form in almost any climate where industries or cities release large amounts of air pollution, such as smoke or gases. However, it is worse during periods of warmer, sunnier weather when the upper air is warm enough to inhibit vertical circulation. It is especially prevalent in geologic basins encircled by hills or mountains. It often stays for an extended period of time over densely populated cities or urban areas, and can build up to dangerous levels.
Delhi, India.
Delhi is the most polluted city in the world and according to one estimate, air pollution causes the death of about 10,500 people in Delhi every year. During 2013-14, peak levels of fine particulate matter (PM) in Delhi increased by about 44%, primarily due to high vehicular and industrial emissions, construction work and crop burning in adjoining states. Delhi has the highest level of the airborne particulate matter, PM2.5 considered most harmful to health, with 153 micrograms. Rising air pollution level has significantly increased lung-related ailments (especially asthma and lung cancer) among Delhi's children and women. The dense smog in Delhi during winter season results in major air and rail traffic disruptions every year. According to Indian meteorologists, the average maximum temperature in Delhi during winters has declined notably since 1998 due to rising air pollution.
Environmentalists have criticised the Delhi government for not doing enough to curb air pollution and to inform people about air quality issues. Most of Delhi's residents are unaware of alarming levels of air pollution in the city and the health risks associated with it. Since the mid-1990s, Delhi has undertaken some measures to curb air pollution – Delhi has the third highest quantity of trees among Indian cities and the Delhi Transport Corporation operates the world's largest fleet of environmentally friendly compressed natural gas (CNG) buses. In 1996, the Centre for Science and Environment (CSE) started a public interest litigation in the Supreme Court of India that ordered the conversion of Delhi's fleet of buses and taxis to run on CNG and banned the use of leaded petrol in 1998. In 2003, Delhi won the United States Department of Energy's first 'Clean Cities International Partner of the Year' award for its "bold efforts to curb air pollution and support alternative fuel initiatives". The Delhi Metro has also been credited for significantly reducing air pollutants in the city.
However, according several authors, most of these gains have been lost, especially due to stubble burning, rise in market share of diesel cars and a considerable decline in bus ridership. According to CSE and System of Air Quality Weather Forecasting and Research (SAFAR), burning of agricultural waste in nearby Punjab, Haryana and Uttar Pradesh regions results in severe intensification of smog over Delhi. The state government of adjoining Uttar Pradesh is considering imposing a ban on crop burning to reduce pollution in Delhi NCR and an environmental panel has appealed to India's Supreme Court to impose a 30% cess on diesel cars.
United Kingdom.
London.
In 1306, concerns over air pollution were sufficient for Edward I to (briefly) ban coal fires in London. In 1661, John Evelyn's "Fumifugium" suggested burning fragrant wood instead of mineral coal, which he believed would reduce coughing. The the same year describes how the smoke "does our lungs and spirits choke, Our hanging spoil, and rust our iron."
Severe episodes of smog continued in the 19th and 20th centuries, mainly in the winter, and were nicknamed "pea-soupers". The Great Smog of 1952 darkened the streets of London and killed approximately 4,000 people in the short time of 4 days (a further 8,000 died from its effects in the following weeks and months). Initially a flu epidemic was blamed for the loss of life.
In 1956 the Clean Air Act started legally enforcing smokeless zones in the capital. There were areas where no soft coal was allowed to be burned in homes or in businesses, only coke, which produces no smoke. Because of the smokeless zones, reduced levels of sooty particulates made the intense and persistent London smog a thing of the past.
It was after this that the great clean-up of London began. One by one, historical buildings which, during the previous two centuries had gradually completely blackened externally, had their stone facades cleaned and restored to their original appearance. Victorian buildings whose appearance changed dramatically after cleaning included the British Museum of Natural History. A more recent example was the Palace of Westminster, which was cleaned in the 1980s. A notable exception to the restoration trend was 10 Downing Street, whose bricks upon cleaning in the late 1950s proved to be naturally "yellow"; the smog-derived black colour of the façade was considered so iconic that the bricks were painted black to preserve the image. Smog caused by traffic pollution, however, does still occur in modern London.
Other areas.
Other areas of the United Kingdom were affected by smog, especially heavily industrialised areas.
The cities of Glasgow and Edinburgh, in Scotland, suffered smoke-laden fogs in 1909. Des Voeux, commonly credited with creating the "smog" moniker, presented a paper in 1911 to the Manchester Conference of the Smoke Abatement League of Great Britain about the fogs and resulting deaths.
One Birmingham resident described near black-out conditions in the 1900s before the Clean Air Act, with visibility so poor that cyclists had to dismount and walk in order to stay on the road.
Mexico City, Mexico.
Due to its location in a highland "bowl", cold air sinks down onto the urban area of Mexico City, trapping industrial and vehicle pollution underneath, and turning it into the most infamously smog-plagued city of Latin America. Within one generation, the city has changed from being known for some of the cleanest air of the world into one with some of the worst pollution, with pollutants like nitrogen dioxide being double or even triple international standards.
Santiago, Chile.
Similar to Mexico City, the air pollution of Santiago valley, located between the Andes and the Chilean Coast Range, turn it into the most infamously smog-plagued city of South America. Other aggravates of the situation reside in its high latitude (31 degrees South) and dry weather during most of the year.
Tehran, Iran.
In December 2005, schools and public offices had to close in Tehran, Iran and 1600 people were taken to hospital, in a severe smog blamed largely on unfiltered car exhaust.
United States.
Smog was brought to the attention of the general US public in 1933 with the publication of the book "Stop That Smoke", by Henry Obermeyer, a New York public utility official, in which he pointed out the effect on human life and even the destruction of 3000 acre of a farmer's spinach crop. Since then, the United States Environmental Protection Agency has designated over 300 U.S. counties to be non-attainment areas for one or more pollutants tracked as part of the National Ambient Air Quality Standards. These areas are largely clustered around large metropolitan areas, with the largest contiguous non-attainment zones in California and the Northeast. Various U.S. and Canadian government agencies collaborate to produce real-time air quality maps and forecasts.
Los Angeles and the San Joaquin Valley.
Because of their locations in low basins surrounded by mountains, Los Angeles and the San Joaquin Valley are notorious for their smog. The millions of vehicles in these regions combined with the additional effects of the San Francisco Bay and Los Angeles/Long Beach port complexes frequently contribute to further air pollution. While strict regulations by numerous California government agencies overseeing this problem have decreased the number of Stage 1 smog alerts from several hundred annually to just a few, these geologically predisposed entrapment zones collect pollution levels from cars, trucks and fixed sources which still exceeds health standards and is a pressing issue for the more than 25 million people who live there.
Ulaanbaatar, Mongolia.
In the late 1990s, massive immigration to Ulaanbaatar from the countryside began. An estimated 150,000 households, mainly living in traditional Mongolian gers on the outskirts of Ulaanbaatar, burn wood and coal (some poor families burn even car tires and trash) to heat themselves during the harsh winter, which lasts from October to April, since these outskirts are not connected to the city's central heating system. A temporary solution to decrease smog was proposed in the form of stoves with improved efficiency, although with no visible results. 
Coal-fired ger stoves release high levels of ash and other particulate matter (PM). When inhaled, these particles can settle in the lungs and respiratory tract and cause health problems. At two to 10 times above Mongolian and international air quality standards, Ulaanbaatar's PM rates are among the worst in the world, according to a December 2009 World Bank report. The Asian Development Bank (ADB) estimates that health costs related to this air pollution account for as much as 4 percent of Mongolia's GDP.
Southeast Asia.
Smog is a regular problem in Southeast Asia caused by land and forest fires in Indonesia, especially Sumatra and Kalimantan, although the term haze is preferred in describing the problem. Farmers and plantation owners are usually responsible for the fires, which they use to clear tracts of land for further plantings. Those fires mainly affect Brunei, Indonesia, Philippines, Malaysia, Singapore and Thailand, and occasionally Guam and Saipan. The economic losses of the fires in 1997 have been estimated at more than US$9 billion. This includes damages in agriculture production, destruction of forest lands, health, transportation, tourism, and other economic endeavours. Not included are social, environmental, and psychological problems and long-term health effects. The second-latest bout of haze to occur in Malaysia, Singapore and the Malacca Straits is in October 2006, and was caused by smoke from fires in Indonesia being blown across the Straits of Malacca by south-westerly winds. A similar haze has occurred in June 2013, with the PSI setting a new record in Singapore on June 21 at 12pm with a reading of 401, which is in the "Hazardous" range.
The Association of Southeast Asian Nations (ASEAN) reacted. In 2002, the Agreement on Transboundary Haze Pollution was signed between all ASEAN nations. ASEAN formed a Regional Haze Action Plan (RHAP) and established a co-ordination and support unit (CSU). RHAP, with the help of Canada, established a monitoring and warning system for forest/vegetation fires and implemented a Fire Danger Rating System (FDRS). The Malaysian Meteorological Department (MMD) has issued a daily rating of fire danger since September 2003. Indonesia has been ineffective at enforcing legal policies on errant farmers.
Pollution index.
The severity of smog is often measured using automated optical instruments such as Nephelometers, as haze is associated with visibility and traffic control in ports. Haze however can also be an indication of poor air quality though this is often better reflected using accurate purpose built air indexes such as the American Air Quality Index, the Malaysian API (Air Pollution Index) and the Singaporean Pollutant Standards Index.
In hazy conditions, it is likely that the index will report the suspended particulate level. The disclosure of the responsible pollutant is mandated in some jurisdictions.
The Malaysian API does not have a capped value; hence its most hazardous readings can go above 500. Above 500, a state of emergency is declared in the affected area. Usually, this means that non-essential government services are suspended, and all ports in the affected area are closed. There may also be prohibitions on private sector commercial and industrial activities in the affected area excluding the food sector. So far, state of emergency rulings due to hazardous API levels were applied to the Malaysian towns of Port Klang, Kuala Selangor and the state of Sarawak during the 2005 Malaysian haze and the 1997 Southeast Asian haze.

</doc>
<doc id="27001" url="http://en.wikipedia.org/wiki?curid=27001" title="Smoke">
Smoke

Smoke is a collection of airborne solid and liquid particulates and gases emitted when a material undergoes combustion or pyrolysis, together with the quantity of air that is entrained or otherwise mixed into the mass. It is commonly an unwanted by-product of fires (including stoves, candles, oil lamps, and fireplaces), but may also be used for pest control (fumigation), communication (smoke signals), defensive and offensive capabilities in the military (smoke-screen), cooking, or smoking (tobacco, cannabis, etc.). Smoke is used in rituals, when incense, sage, or resin is burned to produce a smell for spiritual purposes. Smoke is sometimes used as a flavoring agent, and preservative for various foodstuffs. Smoke is also a component of internal combustion engine exhaust gas, particularly diesel exhaust.
Smoke inhalation is the primary cause of death in victims of indoor fires. The smoke kills by a combination of thermal damage, poisoning and pulmonary irritation caused by carbon monoxide, hydrogen cyanide and other combustion products.
Smoke particles are an aerosol (or mist) of solid particles and liquid droplets that are close to the ideal range of sizes for Mie scattering of visible light. This effect has been likened to three-dimensional textured privacy glass — a smoke cloud does not obstruct an image, but thoroughly scrambles it.
Chemical composition.
The composition of smoke depends on the nature of the burning fuel and the conditions of combustion.
Fires with high availability of oxygen burn at a high temperature and with small amount of smoke produced; the particles are mostly composed of ash, or with large temperature differences, of condensed aerosol of water. High temperature also leads to production of nitrogen oxides. Sulfur content yields sulfur dioxide, or in case of incomplete combustion, hydrogen sulfide. Carbon and hydrogen are almost completely oxidized to carbon dioxide and water. Fires burning with lack of oxygen produce a significantly wider palette of compounds, many of them toxic. Partial oxidation of carbon produces carbon monoxide, nitrogen-containing materials can yield hydrogen cyanide, ammonia, and nitrogen oxides. Hydrogen gas can be produced instead of water. Content of halogens such as chlorine (e.g. in polyvinyl chloride or brominated flame retardants) may lead to production of e.g. hydrogen chloride, phosgene, dioxin, and chloromethane, bromomethane and other halocarbons. Hydrogen fluoride can be formed from fluorocarbons, whether fluoropolymers subjected to fire or halocarbon fire suppression agents. Phosphorus and antimony oxides and their reaction products can be formed from some fire retardant additives, increasing smoke toxicity and corrosivity. Pyrolysis of polychlorinated biphenyls (PCB), e.g. from burning older transformer oil, and to lower degree also of other chlorine-containing materials, can produce 2,3,7,8-tetrachlorodibenzodioxin, a potent carcinogen, and other polychlorinated dibenzodioxins. Pyrolysis of fluoropolymers, e.g. teflon, in presence of oxygen yields carbonyl fluoride (which hydrolyzes readily to HF and CO2); other compounds may be formed as well, e.g. carbon tetrafluoride, hexafluoropropylene, and highly toxic perfluoroisobutene (PFIB).
Pyrolysis of burning material, especially incomplete combustion or smoldering without adequate oxygen supply, also results in production of a large amount of hydrocarbons, both aliphatic (methane, ethane, ethylene, acetylene) and aromatic (benzene and its derivates, polycyclic aromatic hydrocarbons; e.g. benzo[a]pyrene, studied as a carcinogen, or retene), terpenes. Heterocyclic compounds may be also present. Heavier hydrocarbons may condense as tar; smoke with significant tar content is yellow to brown. Presence of such smoke, soot, and/or brown oily deposits during a fire indicates a possible hazardous situation, as the atmosphere may be saturated with combustible pyrolysis products with concentration above the upper flammability limit, and sudden inrush of air can cause flashover or backdraft.
Presence of sulfur can lead to formation of e.g. hydrogen sulfide, carbonyl sulfide, sulfur dioxide, carbon disulfide, and thiols; especially thiols tend to get adsorbed on surfaces and produce a lingering odor even long after the fire. Partial oxidation of the released hydrocarbons yields in a wide palette of other compounds: aldehydes (e.g. formaldehyde, acrolein, and furfural), ketones, alcohols (often aromatic, e.g. phenol, guaiacol, syringol, catechol, and cresols), carboxylic acids (formic acid, acetic acid, etc.).
The visible particulate matter in such smokes is most commonly composed of carbon (soot). Other particulates may be composed of drops of condensed tar, or solid particles of ash. The presence of metals in the fuel yields particles of metal oxides. Particles of inorganic salts may also be formed, e.g. ammonium sulfate, ammonium nitrate, or sodium chloride. Inorganic salts present on the surface of the soot particles may make them hydrophilic. Many organic compounds, typically the aromatic hydrocarbons, may be also adsorbed on the surface of the solid particles. Metal oxides can be present when metal-containing fuels are burned, e.g. solid rocket fuels containing aluminium. Depleted uranium projectiles after impacting the target ignite, producing particles of uranium oxides. Magnetic particles, spherules of magnetite-like ferrous ferric oxide, are present in coal smoke; their increase in deposits after 1860 marks the beginning of the Industrial Revolution. (Magnetic iron oxide nanoparticles can be also produced in the smoke from meteorites burning in the atmosphere.) Magnetic remanence, recorded in the iron oxide particles, indicates the strength of Earth's magnetic field when they were cooled beyond their Curie temperature; this can be used to distinguish magnetic particles of terrestrial and meteoric origin. Fly ash is composed mainly of silica and calcium oxide. Cenospheres are present in smoke from liquid hydrocarbon fuels. Minute metal particles produced by abrasion can be present in engine smokes. Amorphous silica particles are present in smokes from burning silicones; small proportion of silicon nitride particles can be formed in fires with insufficient oxygen. The silica particles have about 10 nm size, clumped to 70-100 nm aggregates and further agglomerated to chains. Radioactive particles may be present due to traces of uranium, thorium, or other radionuclides in the fuel; hot particles can be present in case of fires during nuclear accidents (e.g. Chernobyl disaster) or nuclear war.
Smoke particulates, like other aerosols, are categorized into three modes based on particle size:
Most of the smoke material is primarily in coarse particles. Those undergo rapid dry precipitation, and the smoke damage in more distant areas outside of the room where the fire occurs is therefore primarily mediated by the smaller particles.
Aerosol of particles beyond visible size is an early indicator of materials in a preignition stage of a fire.
Burning of hydrogen-rich fuel produces water; this results in smoke containing droplets of water vapor. In absence of other color sources (nitrogen oxides, particulates...), such smoke is white and cloud-like.
Smoke emissions may contain characteristic trace elements. Vanadium is present in emissions from oil fired power plants and refineries; oil plants also emit some nickel. Coal combustion produces emissions containing aluminium, arsenic, chromium, cobalt, copper, iron, mercury, selenium, and uranium.
Traces of vanadium in high-temperature combustion products form droplets of molten vanadates. These attack the passivation layers on metals and cause high temperature corrosion, which is a concern especially for internal combustion engines. Molten sulfate and lead particulates also have such effect.
Some components of smoke are characteristic of the combustion source. Guaiacol and its derivatives are products of pyrolysis of lignin and are characteristic of wood smoke; other markers are syringol and derivates, and other methoxy phenols. Retene, a product of pyrolysis of conifer trees, is an indicator of forest fires. Levoglucosan is a pyrolysis product of cellulose. Hardwood vs softwood smokes differ in the ratio of guaiacols/syringols. Markers for vehicle exhaust include polycyclic aromatic hydrocarbons, hopanes, steranes, and specific nitroarenes (e.g. 1-nitropyrene). The ratio of hopanes and steranes to elemental carbon can be used to distinguish between emissions of gasoline and diesel engines.
Many compounds can be associated with particulates; whether by being adsorbed on their surfaces, or by being dissolved in liquid droplets. Hydrogen chloride is well absorbed in the soot particles.
Inert particulate matter can be disturbed and entrained into the smoke. Of particular concern are particles of asbestos.
Deposited hot particles of radioactive fallout and bioaccumulated radioisotopes can be reintroduced into the atmosphere by wildfires and forest fires; this is a concern in e.g. the Zone of alienation containing contaminants from the Chernobyl disaster.
Polymers are a significant source of smoke. Aromatic side groups, e.g. in polystyrene, enhance generation of smoke. Aromatic groups integrated in the polymer backbone produce less smoke, likely due to significant charring. Aliphatic polymers tend to generate the least smoke, and are non-self-extinguishing. However presence of additives can significantly increase smoke formation. Phosphorus-based and halogen-based flame retardants decrease production of smoke. Higher degree of cross-linking between the polymer chains has such effect too.
Visible and invisible particles of combustion.
The naked eye detects particle sizes greater than 7 µm (micrometres). Visible particles emitted from a fire are referred to as smoke. Invisible particles are generally referred to as gas or fumes. This is best illustrated when toasting bread in a toaster. As the bread heats up, the products of combustion increase in size. The fumes initially produced are invisible but become visible if the toast is burnt.
An ionization chamber type smoke detector is technically a product of combustion detector, not a smoke detector. Ionization chamber type smoke detectors detect particles of combustion that are invisible to the naked eye. This explains why they may frequently false alarm from the fumes emitted from the red-hot heating elements of a toaster, before the presence of visible smoke, yet they may fail to activate in the early, low-heat smoldering stage of a fire.
Smoke from a typical house fire contains hundreds of different chemicals and fumes. As a result, the damage caused by the smoke can often exceed that caused by the actual heat of the fire. In addition to the physical damage caused by the smoke of a fire – which manifests itself in the form of stains – is the often even harder to eliminate problem of a smoky odor. Just as there are contractors that specialize in rebuilding/repairing homes that have been damaged by fire and smoke, fabric restoration companies specialize in restoring fabrics that have been damaged in a fire.
Dangers of smoke.
Smoke from oxygen-deprived fires contains a significant concentration of compounds that are flammable. A cloud of smoke, in contact with atmospheric oxygen, therefore has the potential of being ignited – either by another open flame in the area, or by its own temperature. This leads to effects like backdraft and flashover. Smoke inhalation is also a danger of smoke that can cause serious injury and death.
Many compounds of smoke from fires are highly toxic and/or irritating. The most dangerous is carbon monoxide leading to carbon monoxide poisoning, sometimes with the additive effects of hydrogen cyanide and phosgene. Smoke inhalation can therefore quickly lead to incapacitation and loss of consciousness. Sulfur oxides, hydrogen chloride and hydrogen fluoride in contact with moisture form sulfuric, hydrochloric and hydrofluoric acid, which are corrosive to both lungs and materials. When asleep the nose does not sense smoke nor does the brain, but the body will wake up if the lungs become enveloped in smoke and the brain will be stimulated and the person will be awoken. This does not work if the person is incapacitated or under the influence of drugs and/or alcohol.
Cigarette smoke is a major modifiable risk factor for lung disease, heart disease, and many cancers.
Smoke can obscure visibility, impeding occupant exiting from fire areas. In fact, the poor visibility due to the smoke that was in the Worcester Cold Storage Warehouse fire in Worcester, Massachusetts was the exact reason why the trapped rescue firefighters couldn't evacuate the building in time. Because of the striking similarity that each floor shared, the dense smoke caused the firefighters to become disoriented.
Smoke corrosion.
Smoke contains a wide variety of chemicals, many of them aggressive in nature. Examples are hydrochloric acid and hydrobromic acid, produced from halogen-containing plastics and fire retardants, hydrofluoric acid released by pyrolysis of fluorocarbon fire suppression agents, sulfuric acid from burning of sulfur-containing materials, nitric acid from high-temperature fires where nitrous oxide gets formed, phosphoric acid and antimony compounds from P and Sb based fire retardants, and many others. Such corrosion is not significant for structural materials, but delicate structures, especially microelectronics, are strongly affected. Corrosion of circuit board traces, penetration of aggressive chemicals through the casings of parts, and other effects can cause an immediate or gradual deterioration of parameters or even premature (and often delayed, as the corrosion can progress over long time) failure of equipment subjected to smoke. Many smoke components are also electrically conductive; deposition of a conductive layer on the circuits can cause crosstalks and other deteriorations of the operating parameters or even cause short circuits and total failures. Electrical contacts can be affected by corrosion of surfaces, and by deposition of soot and other conductive particles or nonconductive layers on or across the contacts. Deposited particles may adversely affect the performance of optoelectronics by absorbing or scattering the light beams.
Corrosivity of smoke produced by materials is characterized by the corrosion index (CI), defined as material loss rate (angstrom/minute) per amount of material gasified products (grams) per volume of air (m3). It is measured by exposing strips of metal to flow of combustion products in a test tunnel. Polymers containing halogen and hydrogen (polyvinyl chloride, polyolefins with halogenated additives, etc.) have the highest CI as the corrosive acids are formed directly with water produced by the combustion, polymers containing halogen only (e.g. polytetrafluoroethylene) have lower CI as the formation of acid is limited to reactions with airborne humidity, and halogen-free materials (polyolefins, wood) have the lowest CI. However, some halogen-free materials can also release significant amount of corrosive products.
Smoke damage to electronic equipment can be significantly more extensive than the fire itself. Cable fires are of special concern; low smoke zero halogen materials are preferable for cable insulation.
When smoke comes into contact with the surface of any substance or structure, the chemicals contained in it are transferred to it. The corrosive properties of the chemicals cause the substance or structure to decompose at a rapid rate. Certain materials or structures absorb these chemicals, which is why clothing, unsealed surfaces, potable water, piping, wood, etc., are replaced in most cases of structural fires.
Secondhand smoke inhalation.
Secondhand smoke is the combination of both sidestream and mainstream smoke emissions. These emissions contain more than 50 carcinogenic chemicals. According to the Surgeon General's latest report on the subject, "Short exposures to secondhand smoke can cause blood platelets to become stickier, damage the lining of blood vessels, decrease coronary flow velocity reserves, and reduce heart variability, potentially increasing the risk of a heart attack". The American Cancer Society lists "heart disease, lung infections, increased asthma attacks, middle ear infections, and low birth weight" as ramifications of smoker's emission 
Measurement.
As early as the 15th century Leonardo da Vinci commented at length on the difficulty of assessing smoke, and distinguished between black smoke (carbonized particles) and white 'smoke' which is not a smoke at all but merely a suspension of harmless water particulates.
Smoke from heating appliances is commonly measured in one of the following ways:
In-line capture. A smoke sample is simply sucked through a filter which is weighed before and after the test and the mass of smoke found. This is the simplest and probably the most accurate method, but can only be used where the smoke concentration is slight, as the filter can quickly become blocked.
The ASTM smoke pump is a simple and widely-used method of in-line capture where a measured volume of smoke is pulled through a filter paper and the dark spot so formed is compared with a standard.
Filter/dilution tunnel. A smoke sample is drawn through a tube where it is diluted with air, the resulting smoke/air mixture is then pulled through a filter and weighed. This is the internationally recognized method of measuring smoke from combustion.
Electrostatic precipitation. The smoke is passed through an array of metal tubes which contain suspended wires. A (huge) electrical potential is applied across the tubes and wires so that the smoke particles become charged and are attracted to the sides of the tubes. This method can over-read by capturing harmless condensates, or under-read due to the insulating effect of the smoke. However, it is the necessary method for assessing volumes of smoke too great to be forced through a filter, i.e., from bituminous coal.
Ringelmann scale. A measure of smoke color. Invented by Professor Maximilian Ringelmann in Paris in 1888, it is essentially a card with squares of black, white and shades of gray which is held up and the comparative grayness of the smoke judged. Highly dependent on light conditions and the skill of the observer it allocates a grayness number from 0 (white) to 5 (black) which has only a passing relationship to the actual quantity of smoke. Nonetheless, the simplicity of the Ringelmann scale means that it has been adopted as a standard in many countries.
Optical scattering. A light beam is passed through the smoke. A light detector is situated at an angle to the light source, typically at 90°, so that it receives only light reflected from passing particles. A measurement is made of the light received which will be higher as the concentration of smoke particles becomes higher.
Optical obscuration. A light beam is passed through the smoke and a detector opposite measures the light. The more smoke particles are present between the two, the less light will be measured.
Combined optical methods. There are various proprietary optical smoke measurement devices such as the 'nephelometer' or the 'aethalometer' which use several different optical methods, including more than one wavelength of light, inside a single instrument and apply an algorithm to give a good estimate of smoke. It has been claimed that these devices can differentiate types of smoke and so their probable source can be inferred, though this is disputed
Inference from carbon monoxide. Smoke is incompletely burned fuel, carbon monoxide is incompletely burned carbon, therefore it has long been assumed that measurement of CO in flue gas (a cheap, simple and very accurate procedure) will provide a good indication of the levels of smoke. Indeed, several jurisdictions use CO measurement as the basis of smoke control. However it is far from clear how accurate the correspondence is.
Medicinal smoke.
Throughout recorded history, humans have used the smoke of medicinal plants to cure illness. A sculpture from Persepolis shows Darius the Great (522–486 BC), the king of Persia, with two censers in front of him for burning Peganum harmala and/or sandalwood Santalum album, which was believed to protect the king from evil and disease. More than 300 plant species in 5 continents are used in smoke form for different diseases. As a method of drug administration, smoking is important as it is a simple, inexpensive, but very effective method of extracting particles containing active agents. More importantly, generating smoke reduces the particle size to a microscopic scale thereby increasing the absorption of its active chemical principles.

</doc>
<doc id="27002" url="http://en.wikipedia.org/wiki?curid=27002" title="Tobacco pipe">
Tobacco pipe

A smoking pipe, often called simply pipe, is a device specifically made to smoke tobacco. It comprises a chamber (the bowl) for the tobacco from which a thin hollow stem (shank) emerges, ending in a mouthpiece (the bit). Pipes can range from very simple machine-made briar models to highly prized hand-made artisanal implements made by renowned pipemakers, which are often very expensive collector's items. Pipe smoking is the oldest known traditional form of tobacco smoking.
The bowls of tobacco pipes are commonly made of briar wood, meerschaum, corncob or clay. Less common are other dense-grained woods such as cherry, olive, maple, mesquite, oak, and bog-wood. Minerals such as catlinite and soapstone have also been used. Pipe bowls are sometimes decorated by carving. 
Unusual, but still noteworthy pipe materials include gourds, as in the famous calabash pipe, and pyrolytic graphite. Metal and glass are uncommon materials for tobacco pipes, but are common for pipes intended for other substances, such as cannabis.
The stem needs a long channel of constant position and diameter running through it for a proper draw, although filter pipes have varying diameters and can be successfully smoked even without filters or adapters. Because it is molded rather than carved, clay may make up the entire pipe or just the bowl, but most other materials have stems made separately and detachable. Stems and bits of tobacco pipes are usually made of moldable materials like vulcanite, lucite, Bakelite, and soft plastic. Less common are stems made of reeds, bamboo, or hollowed out pieces of wood. Expensive pipes once had stems made of amber, though this is rare now.
Tobaccos for smoking in pipes are often carefully treated and blended to achieve flavour nuances not available in other tobacco products. Many of these are blends using staple ingredients of variously cured Burley and Virginia tobaccos which are enhanced by spice tobaccos, among them many Oriental or Balkan varietals, Latakia (a fire-cured spice tobacco of Syrian origin), Perique (uniquely grown in St. James Parish, Louisiana) which is also an old method of fermentation, or blends of Virginia and Burley tobaccos of African, Indian, or South American origins. Traditionally, many U.S. blends are made of American Burley with sweeteners and flavorings added to create an "aromatic" flavor, whereas "English" blends are based on natural Virginia tobaccos enhanced with Oriental and other natural tobaccos. There is a growing tendency towards "natural" tobaccos which derive their aromas from artful blending with selected spice tobaccos only and careful, often historically-based, curing processes.
Types.
Briar.
The majority of pipes sold today, whether hand made or machine made, are fashioned from briar (French: "bruyère"). Briar is a particularly well suited wood for pipe making for a number of reasons. The first and most important characteristic is its natural resistance to fire. The second is its inherent ability to absorb moisture. The burl absorbs water in nature to supply the tree in the dry times and likewise will absorb the moisture that is a byproduct of combustion. Briar is cut from the root burl of the tree heath ("Erica arborea"), which is native to the rocky and sandy soils of the Mediterranean region. Briar burls are cut into two types of blocks; ebauchon and plateaux. Ebauchon is taken from the heart of the burl while plateaux is taken from the outer part of the burl. While both types of blocks can produce pipes of the highest quality, most artisan pipe makers prefer to use plateaux because of its superior graining.
Meerschaum.
Meerschaum (hydrated magnesium silicate), a mineral found in small shallow deposits mainly around the city of Eskişehir in central Turkey, is prized for the properties which allow it to be carved into finely detailed decorative and figural shapes. It has been used since the 17th century and, with clay pipes, represented the most common medium for pipes before the introduction of briar as the material of choice in the 19th century. The word "meerschaum" means "sea foam" in German, alluding to its natural white color and its surprisingly low weight. Meerschaum is a very porous mineral that absorbs elements of the tobacco during the smoking process, and gradually changes color to a golden brown. Old, well-smoked meerschaum pipes are valued by collectors for their distinctive coloring. In selecting a meerschaum pipe it is advisable to verify that the product is indeed carved from a block of meerschaum, and is not made from meerschaum dust collected after carving and mixed with a binder then pressed into a pipe shape. These products are not absorbent, do not color, and lack the smoking quality of the block carved pipe.
Clay.
These are ceramic pipes. Low-quality clay pipes are made by slip casting in a mould. Higher quality pipes are made in a labour-intensive hand shaping process. Traditionally, clay pipes are un-glazed. Clays burn "hot" in comparison to other types of pipes, so they are often difficult for most pipe-smokers to use. Their proponents claim that, unlike other materials, a well-made clay pipe gives a "pure" smoke with no flavour addition from the pipe bowl. In addition to aficionados, reproductions of historical clay styles are used by some re-enactors. Clay pipes were once considered disposable items and the rapidly changing designs in the past are often used as an aid in dating by archaeologists. They were once very popular in Ireland, where they were called a "dúidín"s.
Calabash.
Calabash gourds (usually with meerschaum or porcelain bowls set inside them) have long made prized pipes, but they are labour-intensive and, today, quite expensive. Because of this expense, pipes with bodies made of wood (usually mahogany) instead of gourd, but with the same classic shape, are sold as calabashes. Both wood and gourd pipes are functionally the same (with the important exception that the dried gourd, usually being noticeably lighter, sits more comfortably in the mouth). They consist of a downward curve that ends with an upcurve where the bowl sits. Beneath the bowl is an air chamber which serves to cool, dry, and mellow the smoke. There are also briar pipes being sold as calabashes. These typically do not have an air chamber and are so named only because of their external shape.
A calabash pipe is rather large and easy to recognize as a pipe when used on a stage in dramatic productions. Early portrayers of the character Sherlock Holmes, particularly William Gillette and Basil Rathbone, took advantage of this fact when it was required to portray Holmes smoking. This is why Holmes is stereotypically depicted as favouring a calabash. In fact, most stories, particularly "The Adventure of the Copper Beeches", described him as preferring a long-stemmed cherry-wood churchwarden pipe or a clay pipe.
Corncob.
On the other end of the scale, pipes made from corn cobs are cheap and effective, even if some regard them as inelegant. The cobs are first dried for two years. Then they are hollowed out to make a bowl shape. The bowls are dipped in a plaster-based mixture and varnished or lacquered on the outside. Shanks made from pine wood are then inserted into the bowls. The first and largest manufacturer of corncob pipes is Missouri Meerschaum, located in Washington, Missouri, in the USA. Missouri Meerschaum has produced the pipes since 1869. General Douglas MacArthur, Mark Twain, and Norman Rockwell were perhaps the most famous smokers of this type of pipe, along with the cartoon characters Popeye and Frosty the Snowman.
Corncob pipes remain popular today because they are inexpensive and require no "break-in" period like briar pipes. For these two reasons, corncob pipes are often recommended as a "Beginner's pipe." But their enjoyment is by no means limited to beginners. Corncob pipes are equally valued by both learners and experienced smokers who simply desire a cool, clean smoke. Pipesmokers who wish to sample a wide variety of different tobaccos and blends also might keep a stock of corncobs on hand to permit them to try new flavors without "carryover" from an already-used pipe, or to keep a potentially bad-tasting tobacco from adding its flavor to a more expensive or favored pipe.
Churchwarden.
A churchwarden pipe is a tobacco pipe with a long stem. See Churchwarden pipe
Synthetics.
A variety of other materials may also be used for pipes. The Redmanol corporation manufactured pipes with translucent stems in the 1920s and a series of pipes were manufactured and distributed by the Tar Gard (later Venturi) Corporation of San Francisco from 1965-1975. Marketed under names such as "the pipe," "THE SMOKE" and "Venturi," they used materials such as pyrolytic graphite, phenolic resin, nylon, Bakelite and other synthetics, allowing for higher temperatures in the bowl, reduced tar and aesthetic variations of color and style.
After Venturi stopped making pipes, several companies continue to make pipes from Brylon, a composite of nylon and wood flour, as a cheaper substitute for briar.
Metal.
Metal is an uncommon material for making tobacco pipes, but they are not unknown. The most common form of this is a pipe with a shank made of aluminum, which serves as a heat sink. Mouthpieces are made of vulcanite or lucite. The bowls are removable, though not interchangeable between manufacturers. They are made of varying materials to allow the smoker to try different characteristics or to dedicate particular bowls for particular tobaccos.
Other metal tobacco pipes include the very small Japanese kiseru and Arabian midwakh. Hookahs also may have metal stems, but fall into the general category of water pipes.
Hookahs.
A "hookah", "ghelyan", or "narghile", is a Middle Eastern water pipe that cools the smoke by filtering it through a water chamber. Often ice, cough-drops, milk, or fruit juice is added to the water. Traditionally, the tobacco is mixed with a sweetener, such as honey or molasses. Fruit flavors have also become popular. Modern hookah smokers, especially in the US, smoke "me'assel" "moassel" "molasses" or "shisha" all names for the same wet mixture of tobacco, molasses/honey, glycerine, and often, flavoring. This style of tobacco is smoked in a bowl with foil or a screen (metal or glass) on top of the bowl. More traditional tobaccos are "tombiek" (a dry unflavored tobacco, which the user moistens in water, squeezes out the extra liquid, and places coals directly on top) or "jarak" (more of a paste of tobacco with fruit to flavor the smoke).
Use.
Smoking a pipe requires more apparatus and technique than cigarette or even cigar smoking. In addition to the pipe itself and matches or a lighter, smokers usually require a pipe tool for packing, adjusting, and emptying the tobacco in the bowl, and a regular supply of pipe cleaners.
Tobacco.
Pipe tobacco can be purchased in several forms, which vary both in flavour (leading to many blends and opportunities for smokers to blend their own tobaccos) and in the physical shape and size to which the tobacco has been reduced. Most pipe tobaccos are less mild than cigarette tobacco, substantially more moist and cut much more coarsely. Too finely cut tobacco does not allow enough air to flow through the pipe, and overly dry tobacco burns too quickly with little flavour. Pipe tobacco must be kept in an airtight container, such as a canning jar or sealed tin, to keep from drying out. 
Some pipe tobaccos are cut into long narrow ribbons. Some are pressed into flat cakes which are sliced. Others are tightly wound into long ropes, then sliced into discs. Plug tobacco is maintained in its pressed cake form and sold in small blocks. The plug will be sliced into thin flakes by the smoker and then prepared in a similar fashion to flake tobacco. It is considered that plug tobacco holds its flavor better than rubbed or flake tobacco. Flake tobacco (sliced cakes or ropes) may be prepared in several ways. Generally it is rubbed out with the fingers and palms until it is loose enough to pack. It can also be crumbled or simply folded and stuffed into a pipe. Some people also prefer to dice up very coarse tobaccos before using them, making them easier to pack.
Packing.
In the most common method of packing, tobacco is added to the bowl of the pipe in several batches, each one pressed down until the mixture has a uniform density that optimizes airflow (something that it is difficult to gauge without practice). This can be done with a finger or thumb, but if the tobacco needs to be repacked later, while it is burning, the tamper on a pipe tool is sometimes used. If it needs to be loosened, the reamer, or any similar long pin can be used. A traditional way of packing the pipe is to fill the bowl and then pack gently to about 1/3 full, fill again and pack slightly more firmly to about 2/3 full, and then pack more firmly still to the top.
An alternative packing technique called the Frank method involves lightly dropping tobacco in the pipe, after which a large plug is gingerly pushed into the bowl all at once.
Lighting.
Matches, or separately lit slivers of wood are often considered preferable to lighters because of lower burning temperature. Butane lighters made specifically for pipes 
emit flame sideways or at an angle to make it easier to direct flame into the bowl. Torch-style lighters should never be used to light a pipe because their flames are too hot and can char the rim of the pipe bowl. Matches should be allowed to burn for several seconds to allow the sulfur from the tip to burn away and the match to produce a full flame. A naphtha fueled lighter should also be allowed to burn a few seconds to get rid of stray naphtha vapors that could give a foul taste to the smoke. When a flame has been produced, it is then moved in circles above the rim of the bowl while the smoker puffs to draw the flame down and light the tobacco. Packing method and humidity can affect how often a pipe must be relit.
Burning prevention.
With care, a briar pipe can last a very long time without burning out. However, due to aggressive (hot) smoking, imperfections in the wood, or just bad luck, a hole can be burned in the tobacco chamber of the pipe. There are several methods used to help prevent a wood pipe from burning out. These generally involve coating the chamber with any of a variety of substances, or by gently smoking a new pipe to build up a cake (a mixture of ash, unburned tobacco, oils, sugars, and other residue) on the walls.
These coatings may include honey and water; powdered sugar and water; cigar ash and water; and sour cream, buttermilk, and activated charcoal among many others.
Many modern briar pipes are pre-treated by the manufacturer to resist burning. If smoked correctly, the cake will build up properly on its own. Another technique is to alternate a half-bowl and a full-bowl the first several times the pipe is used to build an even cake. Burley is often recommended to help a new pipe build cake.
The effectiveness of these methods is by no means universally agreed upon.
The caked layer that helps prevent burning through the bottom or sides of a briar wood pipe may damage other pipes, such as meerschaum or clay. As the cake layer heats up, it expands and may cause cracks or breaks in non-briar pipes.
Smoking.
Pipe smoke, like cigar smoke, is usually not inhaled. It is merely brought into the mouth, pumped around oral and nasal cavities to permit absorption of nicotine toward the brain through the mucous membranes, and released. It is normal to have to relight a pipe periodically. If it is smoked too slowly, this will happen more often. If it is smoked too quickly, it can produce excess moisture causing a gurgling sound in the pipe and an uncomfortable sensation on the tongue (referred to as "pipe tongue", or more commonly, "tongue bite").
A pipe cleaner can be used to dry out the bowl and, wetted with alcohol, the inner channel. The bowl of the pipe can also become uncomfortably hot, depending on the material and the rate of smoking. For this reason clay pipes in particular are often held by the stem. Meerschaum pipes are held in a square of chamois leather, with gloves, or else by the stem in order to prevent uneven coloring of the material.
Cleaning.
The ash and the last bits of unburned tobacco, known as dottle, should be cleaned out with a suitable pipe tool. A soft or bristle pipe cleaner, which may be moistened with strong spirits is then run through the airways of the stem and shank to remove any moisture, ash, and other residue before the pipe is allowed to dry. A pipe should be allowed to cool before removing the stem to avoid the possibility of warping it.
A cake of ash eventually develops inside the bowl. This is generally considered desirable for controlling overall heat. However, if it becomes too thick, it may expand faster than the bowl of the pipe itself when heated, cracking the bowl. Before reaching this point, it needs to be scraped down with a reamer. It is generally recommended to keep the cake at approximately the thickness of a U.S. dime (about 1/20th of an inch or 1.5 mm), though sometimes the cake is removed entirely as part of efforts to eliminate flavors or aromas. 
Cake is considered undesirable in meerschaum pipes because it can easily crack the bowl and/or interfere with the mineral's natural porosity. Meerschaum also softens when heated so it is recommended to allow meerschaum pipes to cool before cleaning as people have been known to push pipe cleaners through the walls of heated pipes.
Regardless if a pipe is cleaned after every smoke, over time there is a build up of cake in the bowl and tars in the internals of a smoking pipe. The cake can be controlled by gentle reaming, but a build up of tars in the shank and airway of a pipe is more difficult to deal with. This may require the services of a professional pipe restorer to properly clean and sanitize the pipe.
Sweetening.
When tobacco is burned, oils from adjoining not yet ignited particles vaporize and condense into the existing cake on the walls of the bowl and shank. Over time, these oils can oxidize and turn rancid, causing the pipe to give a sour or bitter smoke. A purported countermeasure involves filling the bowl with kosher salt and carefully wetting it with strong spirits. Many experts feel that it is important to not use iodized salt, as the iodine and other additives may impart an unpleasant flavor. Some people find that regularly wiping out the bowl with spirits is helpful in preventing souring. Commercial pipe-sweetening products are also available.
History.
Pipes have been used since ancient times. Herodotus described Scythians inhaling the fumes of burning leaves in 500 B.C. Romans, and Greeks adopted pipes from their neighbors to the east and they were subsequently used by Germanic, Celtic and Nordic tribes.
As tobacco was not introduced to the Old World until the 16th century, the pipes outside of the Americas were usually used to smoke hashish, a rare and expensive substance outside areas of the Middle East, Central Asia and India, where it was produced.
Native Americans smoked tobacco in pipes long before the arrival of Europeans. The tobacco plant was native to South America but spread into North America before Europeans arrived. Tobacco was introduced to Europe from the Americas in the 16th century and spread around the world rapidly.

</doc>
<doc id="27003" url="http://en.wikipedia.org/wiki?curid=27003" title="Swiss cheese">
Swiss cheese

Swiss cheese is a generic name in North America for several related varieties of cheese, mainly of North American manufacture, which resemble Emmental cheese, a yellow, medium-hard cheese that originated in the area around Emmental, in Switzerland. Some types of Swiss cheese have a distinctive appearance, as the blocks of the cheese are riddled with holes known as "eyes". Swiss cheese without eyes is known as "blind". (The term is applied to cheeses of this style made outside Switzerland, such as Jarlsberg cheese, which originates in Norway).
Production.
Three types of bacteria are used in the production of Emmental cheese: "Streptococcus salivarius" subspecies "thermophilus", "Lactobacillus" ("Lactobacillus helveticus" or "Lactobacillus delbrueckii" subspecies "bulgaricus"), and "Propionibacterium" ("Propionibacterium freudenreichii" subspecies "shermani"). In a late stage of cheese production, the propionibacteria consume the lactic acid excreted by the other bacteria and release acetate, propionic acid, and carbon dioxide gas. The carbon dioxide slowly forms the bubbles that develop the "eyes". The acetate and propionic acid give Swiss its nutty and sweet flavor. Historically, the holes were seen as a sign of imperfection and cheese makers originally tried to avoid them by pressing during production. In modern times, the holes have become an identifier of the cheese. 
In general, the larger the eyes in a Swiss cheese, the more pronounced its flavor because a longer fermentation period gives the bacteria more time to act. This poses a problem, however, because cheese with large eyes does not slice well and comes apart in mechanical slicers. As a result, industry regulators have limited the eye size by which Swiss cheese receives the Grade A stamp. 
Varieties.
Baby Swiss and Lacy Swiss are two varieties of American Swiss cheeses. Both have small holes and a mild flavor. Baby Swiss is made from whole milk, and Lacy Swiss is made from low fat milk. Baby Swiss was developed in the mid-1960s outside of Charm, Ohio, by the Guggisberg Cheese Company, owned by Alfred Guggisberg.

</doc>
<doc id="27004" url="http://en.wikipedia.org/wiki?curid=27004" title="Spontaneous combustion (disambiguation)">
Spontaneous combustion (disambiguation)

Spontaneous combustion is the self-ignition of a mass, for example, a pile of oily rags. Allegedly, humans can also ignite and burn without an obvious cause; this phenomenon is known as spontaneous human combustion.
Spontaneous Combustion is also the name of:

</doc>
<doc id="27005" url="http://en.wikipedia.org/wiki?curid=27005" title="Smoke signal">
Smoke signal

The smoke signal is one of the oldest forms of long-distance communication. It is a form of visual communication used over long distance. In general smoke signals are used to transmit news, signal danger, or gather people to a common area.
History and usage.
In Ancient China, soldiers stationed along the Great Wall would alert each other of impending enemy attack by signaling from tower to tower. In this way, they were able to transmit a message as far away as 750 km in just a few hours.
Polybius, a Greek historian, devised a more complex system of alphabetical smoke signals around 150 BC, which converted Greek alphabetic characters into numeric characters. It enabled messages to be easily signaled by holding sets of torches in pairs. This idea, known as the "Polybius square", also lends itself to cryptography and steganography. This cryptographic concept has been used with Japanese Hiragana and the Germans in the later years of the First World War.
The North American indigenous peoples also communicated via smoke signal. Each tribe had its own signaling system and understanding. A signaler started a fire on an elevation typically using damp grass, which would cause a column of smoke to rise. The grass would be taken off as it dried and another bundle would be placed on the fire. Reputedly the location of the smoke along the incline conveyed a meaning. If it came from halfway up the hill, this would signify all was well, but from the top of the hill it would signify danger.
Smoke signals remain in use today. In Rome, the College of Cardinals uses smoke signals to indicate the selection of a new Pope during a papal conclave. Eligible cardinals conduct a secret ballot until someone receives a vote of two-thirds plus one. The ballots are burned after each vote. Black smoke indicates a failed ballot, while white smoke means a new Pope has been elected.
Examples.
Native Americans.
Lewis and Clark's journals cite several occasions when they adopted the Native American method of setting the plains on fire to communicate the presence of their party or their desire to meet with local tribes.
Yámana.
Yámanas used fire to send messages by smoke signals, for instance if a whale drifted ashore. The large amount of meat required notification of many people, so that it would not decay. They might also have used smoke signals on other occasions, thus it is possible that Magellan saw such fires (which inspired him to name the landscape Tierra del Fuego) but he may have seen the smoke or lights of natural phenomena.
Noon Gun.
Noon Gun time signalling was used to set marine chronometers in Table Bay.
Aboriginal Australians.
Aboriginal Australians in the Western Desert would send up smoke to notify others of their presence, particularly when entering lands which were not their own. 'Putting up a smoke' would often result in nearby individuals or groups replying with their own signals.

</doc>
<doc id="27006" url="http://en.wikipedia.org/wiki?curid=27006" title="Serendipity">
Serendipity

Serendipity means a "fortunate happenstance" or "pleasant surprise". It was coined by Horace Walpole in 1754. In a letter he wrote to a friend Walpole explained an unexpected discovery he had made by reference to a Persian fairy tale, "The Three Princes of Serendip". The princes, he told his correspondent, were “always making discoveries, by accidents and sagacity, of things which they were not in quest of”.
The notion of serendipity is a common occurrence throughout the history of scientific innovation such as Alexander Fleming's accidental discovery of penicillin in 1928 and the invention of the microwave oven by Percy Spencer in 1945, the invention of the Post-it note by Spencer Silver in 1968.
The word has been voted one of the ten English words hardest to translate in June 2004 by a British translation company. However, due to its sociological use, the word has been exported into many other languages.
Etymology.
The first noted use of "serendipity" (meaning pleasant surprise) in the English language was by Horace Walpole (1717–1797). In a letter to Horace Mann (dated 28 January 1754) he said he formed it from the Persian fairy tale "The Three Princes of Serendip", whose heroes "were always making discoveries, by accidents and sagacity, of things they were not in quest of". The name stems from "Serendip", an old name for Sri Lanka (aka Ceylon), from Tamil "Ceralamdivu", Sanskrit "Simhaladvipa" and Persian "Sarandīp" (سرندیپ). Parts of Sri Lanka were under the rule of Tamil kings for extended periods of time in history. Kings of Kerala, India (Cheranadu) were called Ceran Kings and "divu", "tivu" or "dheep" means island, the island belonging to the Chera King was called "Cherandeep", hence "Sarandib" by Arab traders.
The structure of serendipity.
Serendipity is not just a matter of a random event, nor can it be taken simply as a synonym for "a happy accident" (Ferguson, 1999; Khan, 1999), "finding out things without being searching for them" (Austin, 2003), or "a pleasant surprise" (Tolson, 2004) ..
The New Oxford Dictionary of English defines serendipity as the occurrence and development of events by chance in a satisfactory or beneficial way, understanding the chance as any event that takes place in the absence of any obvious project (randomly or accidentally), which is not relevant to any present need, or in which the cause is unknown.
Innovations presented as examples of serendipity have an important characteristic: they were made by individuals able to "see bridges where others saw holes" and connect events creatively, based on the perception of a significant link.
The chance is an event, serendipity a capacity. The Nobel Prize laureate Paul Flory suggests that significant inventions are not mere accidents.
Serendipity and scientific discoveries.
The serendipitous can play an important role in the search for truth, but because of traditional scientific behavior and scientific thinking based on logic and predictability is often ignored in the scientific literature.
Successful researchers can observe the results with a careful attention in the mood to analyze a phenomenon under the most diverse and different perspectives. Question themselves on assumptions that do not fit with the empirical observations. Realizing that serendipitous events can generate important research ideas, these researchers recognize and appreciate the unexpected, encouraging their assistants to observe and discuss unexpected events.
Serendipity can be obtained in groups in that the "critical mass" of multidisciplinary scientists working together in an environment that fosters communication, establishing the idea that the work and the interest of a researcher can be shared with others who may find a new application for a new knowledge.
Serendipity in science and technology.
Various thinkers discuss the role that luck can play in science. One aspect of Walpole's original definition of serendipity, often missed in modern discussions of the word, is the need for an individual to be "sagacious" enough to link together apparently innocuous facts in order to come to a valuable conclusion. Indeed, the scientific method, and the scientists themselves, can be prepared in many other ways to harness luck and make discoveries.
Serendipity and innovation.
Serendipity is typically used incorrectly as a synonym for opportunity, coincidence, luck or providence, a concept that prejudices the appreciation of the term in relation to its contribution to the innovation process.
It is often a misunderstood quality for discovery and innovation. It may become a powerful tool in the contribution of innovative insights that lead to the attainment of entrepreneurial visions.
Understanding the processes of their development and uses allows managers, innovators and researchers as they can use "serendipity" as an important contribution to the competitive success of a given company.
Business and strategy.
M. E. Graebner describes serendipitous value in the context of the acquisition of a business as "windfalls that were not anticipated by the buyer prior to the deal": i.e., unexpected advantages or benefits incurred due to positive synergy effects of the merger.
Ikujiro Nonaka points out that the serendipitous quality of innovation is highly recognized by managers and links the success of Japanese enterprises to their ability to create knowledge not by processing information but rather by "tapping the tacit and often highly subjective insights, intuitions, and hunches of individual employees and making those insights available for testing and use by the company as a whole".
Serendipity is postulated by Napier and Vuong (2013) as a 'strategic advantage' with which a firm can tap its potential creativity.
Serendipity is a key concept in competitive intelligence because it is one of the tools for avoiding blind spots (see Blindspots analysis).
Uses.
Serendipity is used as a sociological method in Anselm L. Strauss' and Barney G. Glaser's Grounded Theory, building on ideas by sociologist Robert K. Merton, who in "Social Theory and Social Structure" (1949) referred to the "serendipity pattern" as the fairly common experience of observing an unanticipated, anomalous and strategic datum which becomes the occasion for developing a new theory or for extending an existing theory. Robert K. Merton also coauthored (with Elinor Barber) "The Travels and Adventures of Serendipity" which traces the origins and uses of the word "serendipity" since it was coined. The book is "a study in sociological semantics and the sociology of science", as the subtitle of the book declares. It further develops the idea of serendipity as scientific "method" (as juxtaposed with purposeful discovery by experiment or retrospective prophecy).
Related terms.
William Boyd coined the term zemblanity to mean somewhat the opposite of serendipity: "making unhappy, unlucky and expected discoveries occurring by design". A zemblanity is, effectively, an "unpleasant unsurprise". It derives from Novaya Zemlya (or Nova Zembla), a cold, barren land with many features opposite to the lush Sri Lanka (Serendip). On this island Willem Barents and his crew were stranded while searching for a new route to the east.
Bahramdipity is derived directly from Bahram Gur as characterized in the "The Three Princes of Serendip". It describes the "suppression" of serendipitous discoveries or research results by powerful individuals.
References.
</dl>

</doc>
<doc id="27007" url="http://en.wikipedia.org/wiki?curid=27007" title="Samuel Morse">
Samuel Morse

Samuel Finley Breese Morse (April 27, 1791 – April 2, 1872) was an American painter and inventor. After having established his reputation as a portrait painter, in his middle age Morse contributed to the invention of a single-wire telegraph system based on European telegraphs. He was a co-developer of the Morse code, and helped to develop the commercial use of telegraphy.
Birth and education.
Samuel F. B. Morse was born in Charlestown, Massachusetts, the first child of the pastor Jedidiah Morse (1761–1826), who was also a geographer, and his wife Elizabeth Ann Finley Breese (1766–1828). His father was a great preacher of the Calvinist faith and supporter of the American Federalist party. He thought it helped preserve Puritan traditions (strict observance of Sabbath, among other things), and believed in the Federalist support of an alliance with Britain and a strong central government. Morse strongly believed in education within a Federalist framework, alongside the instillation of Calvinist virtues, morals and prayers for his first son.
After attending Phillips Academy in Andover, Massachusetts, Samuel Morse went on to Yale College to receive instruction in the subjects of religious philosophy, mathematics and science of horses. While at Yale, he attended lectures on electricity from Benjamin Silliman and Jeremiah Day, and was a member of the Society of Brothers in Unity. He supported himself by painting. In 1810, he graduated from Yale with Phi Beta Kappa honors.
Painting.
Morse expressed some of his Calvinist beliefs in his painting, "Landing of the Pilgrims", through the depiction of simple clothing as well as the people's austere facial features. His image captured the psychology of the Federalists; Calvinists from England brought to North America ideas of religion and government, thus linking the two countries. This work attracted the attention of the notable artist Washington Allston. Allston wanted Morse to accompany him to England to meet the artist Benjamin West. Allston arranged — with Morse's father — a three-year stay for painting study in England. The two men set sail aboard the "Lybia" on July 15, 1811.
In England, Morse perfected his painting techniques under Allston's watchful eye; by the end of 1811, he gained admittance to the Royal Academy. At the Academy, he was moved by the art of the Renaissance and paid close attention to the works of Michelangelo and Raphael. After observing and practicing life drawing and absorbing its anatomical demands, the young artist produced his masterpiece, the "Dying Hercules". (He first made a sculpture as a study for the painting.)
To some, the "Dying Hercules" seemed to represent a political statement against the British and also the American Federalists. The muscles symbolized the strength of the young and vibrant United States versus the British and British-American supporters. During Morse's time in Britain, the Americans and British were engaged in the War of 1812. Both societies were conflicted over loyalties. Anti-Federalist Americans aligned themselves with the French, abhorred the British, and believed a strong central government to be inherently dangerous to democracy.
As the war raged on, Morse's letters to his parents became more anti-Federalist in tone. In one such letter, Morse wrote:
"I assert that the Federalists in the Northern States have done more injury to their country by their violent opposition measures than a French alliance could. Their proceedings are copied into the English papers, read before Parliament, and circulated through their country, and what do they say of them... they call them [Federalists] cowards, a base set, say they are traitors to their country and ought to be hanged like traitors."
Although Jedidiah Morse did not change Samuel's political views, he continued as an influence. Critics believe that the elder Morse's Calvinist ideas are integral to Morse's "Judgment of Jupiter," another significant work completed in England. Jupiter is shown in a cloud, accompanied by his eagle, with his hand spread above the parties and he is pronouncing judgment. Marpessa, with an expression of compunction and shame, is throwing herself into the arms of her husband. Idas, who tenderly loved Marpessa, is eagerly rushing forward to receive her, while Apollo stares with surprise.
Critics have suggested that Jupiter represents God's omnipotence — watching every move that is made. Some call the portrait a moral teaching by Morse on infidelity. Although Marpessa fell victim, she realized that her eternal salvation was important and desisted from her wicked ways. Apollo shows no remorse for what he did, but stands with a puzzled look. Many American paintings throughout the early nineteenth century had religious themes, and Morse was an early exemplar of this. "Judgment of Jupiter" allowed Morse to express his support of Anti-Federalism while maintaining his strong spiritual convictions. Benjamin West sought to present the "Jupiter" at another Royal Academy exhibition, but Morse's time had run out. He left England on August 21, 1815, to return to the United States and begin his full-time career as a painter.
The decade 1815–1825 marked significant growth in Morse's work, as he sought to capture the essence of America's culture and life. He painted the Federalist former President John Adams (1816). The Federalists and Anti-Federalists clashed over Dartmouth College. Morse painted portraits of Francis Brown — the college's president — and Judge Woodward (1817), who was involved in bringing the Dartmouth case before the U.S. Supreme Court.
Morse also sought commissions among the elite of Charleston, South Carolina. Morse's 1818 painting of Mrs. Emma Quash symbolized the opulence of Charleston. The young artist was doing well for himself. Between 1819 and 1821, Morse went through great changes in his life, including a decline in commissions due to the Panic of 1819. Unable to stop the rift within Calvinism, his father was forced to resign from his ministerial position, which he had held for three decades. The new branch that formed was the Congregational Unitarians, Morse considered them to be anti-Federalists, as their beliefs were related to religious salvation.
Although Samuel Morse respected his father's religious opinions, he sympathized with the Unitarians. Among the converts to Unitarianism were the prominent Pickerings of Portsmouth, New Hampshire, whom Morse had painted. Some critics thought his sympathies represented his own anti-Federalism. Morse was commissioned to paint President James Monroe in 1820. He embodied Jeffersonian democracy by favoring the common man over the aristocrat.
Morse had moved to New Haven. His commissions for the "Hall of Congress" (1821) and a portrait of the Marquis de Lafayette (1825) engaged his sense of democratic nationalism. The "Hall of Congress" was designed to capitalize on the success of François-Marius Granet's "The Capuchin Chapel in Rome," which toured the United States extensively throughout the 1820s, attracting audiences willing to pay the 25-cent admission fee.
The artist chose to paint the House of Representatives,in a similar way, with careful attention to architecture and dramatic lighting. He also wished to select a uniquely American topic that would bring glory to the young nation. His subject did just that, showing American democracy in action. He traveled to Washington D.C. to draw the architecture of the new Capitol, and placed eighty individuals within the painting. He chose to portray a night scene, balancing the architecture of the Rotunda with the figures, and using lamplight to highlight the work. Pairs of people, those who stood alone, individuals bent over their desks working, were each painted simply but with faces of character. Morse chose nighttime to convey that Congress’ dedication to the principles of democracy transcended day.
"The Hall of Congress" failed to draw a crowd when exhibited in New York City in 1821. By contrast, John Trumbull’s "Declaration of Independence" had won popular acclaim the previous year. Viewers may have felt that the architecture of "The Hall of Congress" overshadows the individuals, making it hard to appreciate the drama of what was happening.
Morse was honored to paint the Marquis de Lafayette, the leading French supporter of the American Revolution. He felt compelled to paint a grand portrait of the man who helped to establish a free and independent America. He features Lafayette against a magnificent sunset. He has positioned Lafayette to the right of three pedestals: one has a bust of Benjamin Franklin, another of George Washington, and the third seems reserved for Lafayette. A peaceful woodland landscape below him symbolized American tranquility and prosperity as it approached the age of fifty. The developing friendship between Morse and Lafayette, and their discussions of the Revolutionary War, affected the artist after his return to New York City.
In 1826 he helped found the National Academy of Design in New York City. He served as the Academy's President from 1826 to 1845 and again from 1861 to 1862.
From 1830 to 1832, Morse traveled and studied in Europe to improve his painting skills, visiting Italy, Switzerland and France. During his time in Paris, he developed a friendship with the writer James Fennimore Cooper. As a project, he painted miniature copies of 38 of the Louvre's famous paintings on a single canvas (6 ft. x 9 ft), which he entitled "The Gallery of the Louvre." He completed the work upon his return to the United States.
On a subsequent visit to Paris in 1839, Morse met Louis Daguerre. He became interested in the latter's daguerreotype—the first practical means of photography. Morse wrote a letter to the "New York Observer" describing the invention, which was published widely in the American press and provided a broad awareness of the new technology.
Some of Morse's paintings and sculptures are on display at his Locust Grove estate in Poughkeepsie, New York.
Telegraph.
As noted, in 1825 New York City had commissioned Morse to paint a portrait of Lafayette in Washington, DC. While Morse was painting, a horse messenger delivered a letter from his father that read, "Your dear wife is convalescent". The next day he received a letter from his father detailing his wife's sudden death. Morse immediately left Washington for his home at New Haven, leaving the portrait of Lafayette unfinished. By the time he arrived, his wife had already been buried. Heartbroken that for days he was unaware of his wife's failing health and her death, he decided to explore a means of rapid long distance communication.
While returning by ship from Europe in 1832, Morse encountered Charles Thomas Jackson of Boston, a man who was well schooled in electromagnetism. Witnessing various experiments with Jackson's electromagnet, Morse developed the concept of a single-wire telegraph. He set aside his painting, "The Gallery of the Louvre". The original Morse telegraph, submitted with his patent application, is part of the collections of the National Museum of American History at the Smithsonian Institution. In time the Morse code, which he developed, would become the primary language of telegraphy in the world. It is still the standard for rhythmic transmission of data.
Meanwhile, William Cooke and Professor Charles Wheatstone had learned of the Wilhelm Weber and Carl Gauss electromagnetic telegraph in 1833. They had reached the stage of launching a commercial telegraph prior to Morse, despite starting later. In England, Cooke became fascinated by electrical telegraphy in 1836, four years after Morse. Aided by his greater financial resources, Cooke abandoned his primary subject of anatomy and built a small electrical telegraph within three weeks. Wheatstone also was experimenting with telegraphy and (most importantly) understood that a single large battery would not carry a telegraphic signal over long distances. He theorized that numerous small batteries were far more successful and efficient in this task. (Wheatstone was building on the primary research of Joseph Henry, an American physicist). Cooke and Wheatstone formed a partnership and patented the electrical telegraph in May 1837, and within a short time had provided the Great Western Railway with a 13 mi stretch of telegraph. However, within a few years, Cooke and Wheatstone's multiple-wire signaling method would be overtaken by Morse's cheaper method.
In an 1848 letter to a friend, Morse describes how vigorously he fought to be called the sole inventor of the electromagnetic telegraph despite the previous inventions.
I have been so constantly under the necessity of watching the movements of the most unprincipled set of pirates I have ever known, that all my time has been occupied in defense, in putting evidence into something like legal shape that I am the inventor of the Electro-Magnetic Telegraph! Would you have believed it ten years ago that a question could be raised on that subject?—S. Morse.
Relays.
Morse encountered the problem of getting a telegraphic signal to carry over more than a few hundred yards of wire. His breakthrough came from the insights of Professor Leonard Gale, who taught chemistry at New York University (he was a personal friend of Joseph Henry). With Gale's help, Morse introduced extra circuits or relays at frequent intervals, and was soon able to send a message through ten miles (16 km) of wire. This was the great breakthrough he had been seeking. Morse and Gale were soon joined by Alfred Vail, an enthusiastic young man with excellent skills, insights and money.
At the Speedwell Ironworks in Morristown, New Jersey on January 11, 1838, Morse and Vail made the first public demonstration of the electric telegraph. Although Morse and Alfred Vail had done most of the research and development in the ironworks facilities, they chose a nearby factory house as the demonstration site. Without the repeater, the range of the telegraph was limited to two miles (3 km), and the inventors had pulled two miles (3 km) of wires inside the factory house through an elaborate scheme. The first public transmission, with the message, "A patient waiter is no loser", was witnessed by a mostly local crowd.
Morse traveled to Washington, D.C. in 1838 seeking federal sponsorship for a telegraph line but was not successful. He went to Europe, seeking both sponsorship and patents, but in London discovered that Cooke and Wheatstone had already established priority. After his return to the US, Morse finally gained financial backing by Maine congressman Francis Ormand Jonathan Smith.
Federal support.
Morse made his last trip to Washington, D.C., in December 1842, stringing "wires between two committee rooms in the Capitol, and sent messages back and forth" to demonstrate his telegraph system. Congress appropriated $30,000 in 1843 for construction of an experimental 38 mi telegraph line between Washington, D.C., and Baltimore along the right-of-way of the Baltimore and Ohio Railroad. An impressive demonstration occurred on May 1, 1844, when news of the Whig Party's nomination of Henry Clay for U.S. President was telegraphed from the party's convention in Baltimore to the Capitol Building in Washington.
On May 24, 1844, the line was officially opened as Morse sent the now-famous words, "What hath God wrought," from the Supreme Court chamber in the basement of the U.S. Capitol building in Washington, D.C., to the B&O's Mount Clare Station in Baltimore. Annie Ellsworth chose these words from the Bible (Numbers 23:23); her father, U.S. Patent Commissioner Henry Leavitt Ellsworth, had championed Morse's invention and secured early funding for it. His telegraph could transmit thirty characters per minute.
In May 1845 the Magnetic Telegraph Company was formed in order to build telegraph lines from New York City toward Philadelphia, Boston, Buffalo, New York and the Mississippi.
Morse at one time adopted Wheatstone and Carl August von Steinheil's idea of broadcasting an electrical telegraph signal through a body of water or down steel railroad tracks or anything conductive. He went to great lengths to win a lawsuit for the right to be called "inventor of the telegraph", and promoted himself as being an inventor. But, Alfred Vail also played an important role in the development of the Morse code, which was based on earlier codes for the electromagnetic telegraph.
Patent.
Morse received a patent for the telegraph in 1847, at the old Beylerbeyi Palace (the present Beylerbeyi Palace was built in 1861–1865 on the same location) in Istanbul, which was issued by Sultan Abdülmecid, who personally tested the new invention. He was elected an Associate Fellow of the American Academy of Arts and Sciences in 1849. The original patent went to the Breese side of the family after the death of Samuel Morse.
In the 1850s, Morse went to Copenhagen and visited the Thorvaldsens Museum, where the sculptor's grave is in the inner courtyard. He was received by King Frederick VII, who decorated him with the Order of the Dannebrog. Morse expressed his wish to donate his portrait from 1830 to the king. The Thorvaldsen portrait today belongs to Margrethe II of Denmark.
The Morse telegraphic apparatus was officially adopted as the standard for European telegraphy in 1851. Only the United Kingdom (with its extensive overseas empire) kept the needle telegraph of Cooke and Wheatstone.
In 1858, Morse introduced wired communication to Latin America when he established a telegraph system in Puerto Rico, then a Spanish Colony. Morse's oldest daughter, Susan Walker Morse (1821–1885), would often visit her uncle Charles Pickering Walker, who owned the Hacienda Concordia in the town of Guayama. During one of her visits, she met Edward Lind, a Danish merchant who worked in his brother-in-law's Hacienda La Henriqueta in the town of Arroyo. They later married. Lind purchased the Hacienda from his sister when she became a widow. Morse, who often spent his winters at the Hacienda with his daughter and son-in-law, set a two-mile telegraph line connecting his son-in-law's Hacienda to their house in Arroyo. The line was inaugurated on March 1, 1859, in a ceremony flanked by the Spanish and American flags. The first words transmitted by Samuel Morse that day in Puerto Rico were:
"Puerto Rico, beautiful jewel! When you are linked with the other jewels of the Antilles in the necklace of the world's telegraph, yours will not shine less brilliantly in the crown of your Queen!"
There is an argument amongst historians that Morse may have received the idea of a plausible telegraph from Harrison Gray Dyar some eighteen years earlier than his patent.
Political views.
Morse was a leader in the anti-Catholic and anti-immigration movement of the mid-19th century. In 1836, he ran unsuccessfully for mayor of New York under the anti-immigrant Nativist Party's banner, receiving only 1496 votes. When Morse visited Rome, he allegedly refused to take his hat off in the presence of the Pope.
Morse worked to unite Protestants against Catholic institutions (including schools), wanted to forbid Catholics from holding public office, and promoted changing immigration laws to limit immigration from Catholic countries. On this topic, he wrote, "We must first stop the leak in the ship through which muddy waters from without threaten to sink us."
He wrote numerous letters to the New York "Observer" (his brother Sidney was the editor at the time) urging people to fight the perceived Catholic menace. These were widely reprinted in other newspapers. Among other claims, he believed that the Austrian government and Catholic aid organizations were subsidizing Catholic immigration to the United States in order to gain control of the country.
In his "Foreign Conspiracy Against the Liberties of the United States", Morse wrote: 
“Surely American Protestants, freemen, have discernment enough to discover beneath them the cloven foot of this subtle foreign heresy. They will see that Popery is now, what it has ever been, a system of the darkest political intrigue and despotism, cloaking itself to avoid attack under the sacred name of religion. They will be deeply impressed with the truth, that Popery is a political as well as a religious system; that in this respect it differs totally from all other sects, from all other forms of religion in the country.”
In the 1850s, Morse became well known as a defender of slavery, considering it to be sanctioned by God. This was a position held by many Southerners and others. In his treatise "An Argument on the Ethical Position of Slavery," he wrote:
My creed on the subject of slavery is short. Slavery per se is not sin. It is a social condition ordained from the beginning of the world for the wisest purposes, benevolent and disciplinary, by Divine Wisdom. The mere holding of slaves, therefore, is a condition having per se nothing of moral character in it, any more than the being a parent, or employer, or ruler.
Marriages.
Morse married Lucretia Pickering Walker on September 29, 1818, in Concord, New Hampshire. She died on February 7, 1825, shortly after the birth of their third child (Susan b. 1819, Charles b. 1823, James b. 1825). He married his second wife, Sarah Elizabeth Griswold on August 10, 1848 in Utica, New York and had four children (Samuel b. 1849, Cornelia b. 1851, William b. 1853, Edward b. 1857).
Later years.
Litigation over telegraph patent.
In the United States, Morse held his telegraph patent for many years, but it was both ignored and contested. In 1853 "The Telegraph Patent case--O'Reilly v. Morse--" came before the U.S. Supreme Court where, after very lengthy investigation, Chief Justice Roger B. Taney ruled that Morse had been the first to combine the battery, electromagnetism, the electromagnet and the correct battery configuration into a workable practical telegraph. However, in spite of this clear ruling, Morse still received no official recognition from the United States government.
The Supreme Court did not accept all of Morse's claims. The "O'Reilly v. Morse" case has become widely known among patent lawyers because the Supreme Court explicitly denied Morse's claim 8 for any and all use of the electromagnetic force for purposes of transmitting intelligible signals to any distance. 
The Supreme Court sustained, however, Morse's claim to such telecommunication when effectuated by means of Morse's inventive "repeater" apparatus. This was an electrical circuit in which a cascade of many sets comprising a relay and a battery were connected in series, so that when each relay closed, it closed a circuit to cause the next battery to power the succeeding relay, as suggested in the accompanying figure. This caused Morse's signal to pass along the cascade without degrading into noise as its amplitude decreased with the distance traveled. (Each time the amplitude of the signal approaches the noise level, the repeater [in effect, a nonlinear amplifier] boosts the signal amplitude well above the noise level.) 
The Supreme Court thus held that Morse could properly claim a patent monopoly on the system or process of transmitting signals at any distance by means of the repeater circuitry indicated above, but he could not properly claim a monopoly over any and all uses of electromagnetic force to transmit signals. The apparatus limitation in the former type of claim limited the patent monopoly to what Morse taught and gave the world. The lack of that limitation in the latter type of claim (i.e., claim 8) both gave Morse more than was commensurate with what he had contributed to society and discouraged the inventive efforts of others who might come up with different and/or better ways to send signals at a distance using the electromagnetic force.
The problem that Morse faced and how he solved it is discussed in more detail in the article O'Reilly v. Morse. In summary, the solution, as the Supreme Court stated, was the repeater apparatus described in the preceding paragraphs.
The importance of this legal precedent in patent law cannot be overstated, as it became the foundation of the law governing the eligibility of computer program implemented inventions (as well as inventions implementing natural laws) to be granted patents.
Foreign recognition.
Assisted by the American ambassador in Paris, the governments of Europe were approached about their long neglect of Morse while their countries were using his invention. There was a widespread recognition that something must be done, and in 1858 Morse was awarded the sum of 400,000 French francs (equivalent to about $80,000 at the time) by the governments of France, Austria, Belgium, the Netherlands, Piedmont, Russia, Sweden, Tuscany and Turkey, each of which contributed a share according to the number of Morse instruments in use in each country. In 1858, he was also elected a foreign member of the Royal Swedish Academy of Sciences.
Transatlantic cable.
Morse lent his support to Cyrus West Field’s ambitious plan to construct the first transoceanic telegraph line. Morse had experimented with underwater telegraph circuits since 1842. He invested $10,000 in Field’s Atlantic Telegraph Company, took a seat on its board of directors, and was appointed honorary "Electrician". In 1856, Morse traveled to London to help Charles Tilston Bright and Edward Whitehouse test a 2,000-mile-length of spooled cable.
After the first two cable-laying attempts failed, Field reorganized the project, removing Morse from direct involvement. Though the cable broke three times during the third attempt, it was successfully repaired, and the first transatlantic telegraph messages were sent in 1858. The cable failed after just three months of use. Though Field had to wait out the Civil War, the cable laid in 1866 proved more durable, and the era of reliable transatlantic telegraph service had begun.
In addition to the telegraph, Morse invented a marble-cutting machine that could carve three-dimensional sculptures in marble or stone. He could not patent it, however, because of an existing 1820 Thomas Blanchard design.
Last years.
Samuel Morse gave large sums to charity. He also became interested in the relationship of science and religion and provided the funds to establish a lectureship on "the relation of the Bible to the Sciences". Though he was rarely awarded any royalties for the later uses and implementations of his inventions, he was able to live comfortably. 
He died in New York City on April 2, 1872, and was interred at Green-Wood Cemetery in Brooklyn, New York. By the time of his death, his estate was valued at some $500,000 ($ today).
Honors and awards.
Despite honors and financial awards received from foreign countries there was no such recognition in the U.S. until he neared the end of his life, when on June 10, 1871 a bronze statue of Samuel Morse was unveiled in Central Park, New York City. An engraved portrait of Morse appeared on the reverse side of the United States two-dollar bill silver certificate series of 1896. He was depicted along with Robert Fulton. An example can be seen on the website of the Federal Reserve Bank of San Francisco's website in their "American Currency Exhibit":
A blue plaque was erected to commemorate him at 141 Cleveland Street, London, where he lived from 1812 to 1815.
According to his "The New York Times" obituary published on April 3, 1872, Morse received respectively the decoration of the Atiq Nishan-i-Iftikhar (English: Order of Glory) [first medal on wearer's right depicted in photo of Morse with medals], set in diamonds, from Sultan Abdülmecid of Turkey (c.1847), a "golden snuff box containing the Prussian gold medal for scientific merit" from the King of Prussia (1851); the "Great Gold Medal of Arts and Sciences" from the King of Württemberg (1852); and the "Great Golden Medal of Science and Arts" from Emperor of Austria (1855); a cross of Chevalier in the Légion d'honneur from the Emperor of France; the "Cross of a Knight" of the Order of the Dannebrog from the King of Denmark (1856); the Cross of Knight Commander of the Order of Isabella the Catholic, from the Queen of Spain, besides being elected member of innumerable scientific and art societies in this [United States] and other countries. Other awards include Order of the Tower and Sword from the kingdom of Portugal (1860); and Italy conferred on him the insignia of chevalier of the Order of Saints Maurice and Lazarus in 1864. Morse's telegraph was recognized as an IEEE Milestone in 1988.
On April 1, 2012, Google announced the release of "Gmail Tap", an April Fools' Day joke that allowed users to use Morse Code to send text from their mobile phones. Morse's great-great-grandnephew Reed Morse—a Google engineer—was instrumental in the prank, which became a real product.

</doc>
<doc id="27008" url="http://en.wikipedia.org/wiki?curid=27008" title="Ship">
Ship

A ship is a large buoyant watercraft. Ships are generally distinguished from boats based on size, shape and cargo or passenger capacity. Ships are used on lakes, seas, and rivers for a variety of activities, such as the transport of people or goods, fishing, entertainment, public safety, and warfare. Historically, a "ship" was a sailing vessel with at least three square-rigged masts and a full bowsprit.
Ships and boats have developed alongside humanity. In armed conflict and in daily life they have become an integral part of modern commercial and military systems. Fishing boats are used by millions of fishermen throughout the world. Military forces operate vessels for naval warfare and to transport and support forces ashore. Commercial vessels, nearly 35,000 in number, carried 7.4 billion tons of cargo in 2007. As of 2011, there are about 104,304 ships with IMO numbers in the world.
Ships were always a key in history's great explorations and scientific and technological development. Navigators such as Zheng He spread such inventions as the compass and gunpowder. Ships have been used for such purposes as colonization and the slave trade, and have served scientific, cultural, and humanitarian needs. After the 16th century, new crops that had come from and to the Americas via the European seafarers significantly contributed to the world population growth. Ship transport has shaped the world's economy into today's energy-intensive pattern.
Nomenclature.
Ships can usually be distinguished from boats based on size and the ship's ability to operate independently for extended periods. A commonly used rule of thumb is that if one vessel can carry another, the larger of the two is a ship. Dinghies are carried on sailing yachts as small as 35 ft, clearly not ships; this rule of thumb is not foolproof.
In the age of sail, a "ship" was a sailing vessel with at least three square-rigged masts and a full bowsprit; other types of vessel were also defined by their sailplan, e.g. barque, brigantine, etc.
A number of large vessels are usually referred to as boats. Submarines are a prime example. Other types of large vessel which are traditionally called boats are Great Lakes freighters, riverboats, and ferryboats. Though large enough to carry their own boats and heavy cargoes, these vessels are designed for operation on inland or protected coastal waters.
In most maritime traditions ships have individual names, and modern ships may belong to a ship class often named after its first ship. In English, a ship is traditionally referred to as "she", even if named after a man, but this is not universal usage; some journalistic style guides advise using "it" as referring to ships with female pronouns can be seen as offensive and outdated.
History.
Prehistory and antiquity.
The first known vessels date back about 10,000 years ago, but could not be described as ships. The first navigators began to use animal skins or woven fabrics as sails. Affixed to the top of a pole set upright in a boat, these sails gave early ships range. This allowed men to explore widely, allowing for the settlement of Oceania for example (about 3,000 years ago).
By around 3000 BC, Ancient Egyptians knew how to assemble wooden planks into a hull. They used woven straps to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. The Greek historian and geographer Agatharchides had documented ship-faring among the early Egyptians: "During the prosperous period of the Old Kingdom, between the 30th and 25th centuries B. C., the river-routes were kept in order, and Egyptian ships sailed the Red Sea as far as the myrrh-country." Sneferu's ancient cedar wood ship Praise of the Two Lands is the first reference recorded (2613 BC) to a ship being referred to by name.
The ancient Egyptians were perfectly at ease building sailboats. A remarkable example of their shipbuilding skills was the Khufu ship, a vessel 143 ft in length entombed at the foot of the Great Pyramid of Giza around 2500 BC and found intact in 1954.
It is known that ancient Nubia/Axum traded with India, and there is evidence that ships from Northeast Africa may have sailed back and forth between India/Sri Lanka and Nubia trading goods and even to Persia, Himyar and Rome. Aksum was known by the Greeks for having seaports for ships from Greece and Yemen.
Elsewhere in Northeast Africa, the Periplus of the Red Sea reports that Somalis, through their northern ports such as Zeila and Berbera, were trading frankincense and other items with the inhabitants of the Arabian Peninsula well before the arrival of Islam as well as with then Roman-controlled Egypt.
A panel found at Mohenjodaro depicted a sailing craft. Vessels were of many types; their construction is vividly described in the Yukti Kalpa Taru, an ancient Indian text on shipbuilding. This treatise gives a technical exposition on the techniques of shipbuilding. It sets forth minute details about the various types of ships, their sizes, and the materials from which they were built. The Yukti Kalpa Taru sums up in a condensed form all the available information. The Yukti Kalpa Taru gives sufficient information and dates to prove that, in ancient times, Indian shipbuilders had a good knowledge of the materials which were used in building ships. In addition to describing the qualities of the different types of wood and their suitability for shipbuilding, the Yukti Kalpa Taru gives an elaborate classification of ships based on their size.
The oldest discovered sea faring hulled boat is the Egyptian Uluburun shipwreck off the coast of Turkey, dating back to 1300 BC.
The Phoenicians, the first to sail completely around Africa, and Greeks gradually mastered navigation at sea aboard triremes, exploring and colonizing the Mediterranean via ship. Around 340 BC, the Greek navigator Pytheas of Massalia ventured from Greece to Western Europe and Great Britain. In the course of the 2nd century BC, Rome went on to destroy Carthage and subdue the Hellenistic kingdoms of the eastern Mediterranean, achieving complete mastery of the inland sea, that they called "Mare Nostrum". The monsoon wind system of the Indian Ocean was first sailed by Greek navigator Eudoxus of Cyzicus in 118 BC.
In China, by the time of the Zhou Dynasty ship technologies such as stern mounted rudders were developed, and by the Han Dynasty, a well kept naval fleet was an integral part of the military. Ship technology advanced to the point where by the medieval period, water tight compartments were developed.
The Swahili people had various extensive trading ports dotting the coast of medieval East Africa and Great Zimbabwe had extensive trading contacts with Central Africa, and likely also imported goods brought to Africa through the Southeast African shore trade of Kilwa in modern-day Tanzania.
It is known by historians that at its height the Mali Empire built a large naval fleet under Emperor Mansa Musa in the late 13th and early 14th century. Arabic sources describe what some consider to be visits to the New World by a Mali fleet in 1311.
Before the introduction of the compass, celestial navigation was the main method for navigation at sea. In China, early versions of the magnetic compass were being developed and used in navigation between 1040 and 1117. The true mariner's compass, using a pivoting needle in a dry box, was developed in Europe no later than 1300.
Renaissance.
Until the Renaissance, navigational technology remained comparatively primitive. This absence of technology did not prevent some civilizations from becoming sea powers. Examples include the maritime republics of Genoa and Venice, Hanseatic League, and the Byzantine navy. The Vikings used their knarrs to explore North America, trade in the Baltic Sea and plunder many of the coastal regions of Western Europe.
Towards the end of the 14th century, ships like the carrack began to develop towers on the bow and stern. These towers decreased the vessel's stability, and in the 15th century, the caravel, designed by the Portuguese, based on the Arabic "qarib" which could sail closer to the wind, became more widely used. The towers were gradually replaced by the forecastle and sterncastle, as in the carrack "Santa María" of Christopher Columbus. This increased freeboard allowed another innovation: the freeing port, and the artillery associated with it.
In the 16th century, the use of freeboard and freeing ports became widespread on galleons. The English modified their vessels to maximize their firepower and demonstrated the effectiveness of their doctrine, in 1588, by defeating the Spanish Armada.
At this time, ships were developing in Asia in much the same way as Europe. Japan used defensive naval techniques in the Mongol invasions of Japan in 1281. It is likely that the Mongols of the time took advantage of both European and Asian shipbuilding techniques. During the 15th century, China's Ming Dynasty assembled one of the largest and most powerful naval fleet in the world for the diplomatic and power projection voyages of Zheng He. Elsewhere in Japan in the 15th century, one of the world's first iron-clads, "Tekkōsen" (), literally meaning "iron ships", was also developed. In Japan, during the Sengoku era from the fifteenth to 17th century, the great struggle for feudal supremacy was fought, in part, by coastal fleets of several hundred boats, including the atakebune.
During the Age of the Ajuran, the Somali sultanates and republics of Merca, Mogadishu, Barawa, Hobyo and their respective ports flourished, enjoying a lucrative foreign commerce with ships sailing to and coming from Arabia, India, Venetia, Persia, Egypt, Portugal and as far away as China. In the 16th century, Duarte Barbosa noted that many ships from the Kingdom of Cambaya in what is modern-day India sailed to Mogadishu with cloth and spices, for which they in return received gold, wax and ivory. Barbosa also highlighted the abundance of meat, wheat, barley, horses, and fruit on the coastal markets, which generated enormous wealth for the merchants.
Middle Age Swahili Kingdoms are known to have had trade port bullship and trade routes with the Islamic world and Asia and were described by Greek historians as "metropolises". Famous African trade ports such as Mombasa, Zanzibar, and Kilwa were known to Chinese sailors such as Zheng He and medieval Islamic historians such as the Berber Islamic voyager Abu Abdullah ibn Battua. In the 14th century AD, King Abubakari I, the brother of King Mansa Musa of the Mali Empire, is thought to have had a great armada of ships sitting on the coast of West Africa. This is corroborated by ibn Battuta himself who recalls several hundred Malian ships off the coast. This has led to great speculation, with historical evidence, that it is possible that Malian sailors may have reached the coast of Pre-Columbian America under the rule of Abubakari II, nearly two hundred years before Christopher Columbus and that black traders may have been in the Americas before Columbus.
Fifty years before Christopher Columbus, Chinese navigator Zheng He traveled the world at the head of what was for the time a huge armada. The largest of his ships had nine masts, were 130 m long and had a beam of 55 m. His fleet carried 30,000 men aboard 70 vessels, with the goal of bringing glory to the Chinese emperor.
The carrack and then the caravel were developed in Iberia. After Columbus, European exploration rapidly accelerated, and many new trade routes were established. In 1498, by reaching India, Vasco da Gama proved that the access to the Indian Ocean from the Atlantic was possible. These explorations in the Atlantic and Indian Oceans were soon followed by France, England and the Netherlands, who explored the Portuguese and Spanish trade routes into the Pacific Ocean, reaching Australia in 1606 and New Zealand in 1642. In the 17th century Dutch explorers such as Abel Tasman explored the coasts of Australia, while in the 18th century it was British explorer James Cook who mapped much of Polynesia.
Specialization and modernization.
Parallel to the development of warships, ships in service of marine fishery and trade also developed in the period between antiquity and the Renaissance. Still primarily a coastal endeavor, fishing is largely practiced by individuals with little other money using small boats.
Maritime trade was driven by the development of shipping companies with significant financial resources. Canal barges, towed by draft animals on an adjacent towpath, contended with the railway up to and past the early days of the industrial revolution. Flat-bottomed and flexible scow boats also became widely used for transporting small cargoes. Mercantile trade went hand-in-hand with exploration, self-financed by the commercial benefits of exploration.
During the first half of the 18th century, the French Navy began to develop a new type of vessel known as a ship of the line, featuring seventy-four guns. This type of ship became the backbone of all European fighting fleets. These ships were 56 m long and their construction required 2,800 oak trees and 40 km of rope; they carried a crew of about 800 sailors and soldiers.
During the 19th century the Royal Navy enforced a ban on the slave trade, acted to suppress piracy, and continued to map the world. A clipper was a very fast sailing ship of the 19th century. The clipper routes fell into commercial disuse with the introduction of steam ships with better fuel efficiency, and the opening of the Suez and Panama Canals.
Ship designs stayed fairly unchanged until the late 19th century. The industrial revolution, new mechanical methods of propulsion, and the ability to construct ships from metal triggered an explosion in ship design. Factors including the quest for more efficient ships, the end of long running and wasteful maritime conflicts, and the increased financial capacity of industrial powers created an avalanche of more specialized boats and ships. Ships built for entirely new functions, such as firefighting, rescue, and research, also began to appear.
In light of this, classification of vessels by type or function can be difficult. Even using very broad functional classifications such as fishery, trade, military, and exploration fails to classify most of the old ships. This difficulty is increased by the fact that the terms such as sloop and frigate are used by old and new ships alike, and often the modern vessels sometimes have little in common with their predecessors.
Today.
In 2007, the world's fleet included 34,882 commercial vessels with gross tonnage of more than 1,000 tons, totaling 1.04 billion tons. These ships carried 7.4 billion tons of cargo in 2006, a sum that grew by 8% over the previous year. In terms of tonnage, 39% of these ships are tankers, 26% are bulk carriers, 17% container ships and 15% were other types.
In 2002, there were 1,240 warships operating in the world, not counting small vessels such as patrol boats. The United States accounted for 3 million tons worth of these vessels, Russia 1.35 million tons, the United Kingdom 504,660 tons and China 402,830 tons. The 20th century saw many naval engagements during the two world wars, the Cold War, and the rise to power of naval forces of the two blocs. The world's major powers have recently used their naval power in cases such as the United Kingdom in the Falkland Islands and the United States in Iraq.
The size of the world's fishing fleet is more difficult to estimate. The largest of these are counted as commercial vessels, but the smallest are legion. Fishing vessels can be found in most seaside villages in the world. As of 2004, the United Nations Food and Agriculture Organization estimated 4 million fishing vessels were operating worldwide. The same study estimated that the world's 29 million fishermen caught 85800000 t of fish and shellfish that year.
Types of ships.
Because ships are constructed using the principles of naval architecture that require same structural components, their classification is based on their function such as suggested by Paulet and Presles., which requires modification of the components. The categories accepted in general by naval architects are:
Some of these are discussed in the following sections.
Inland and coastal boats.
Many types of boats are designed for inland and coastal waterways. These are the vessels that trade upon the lakes, rivers and canals.
Barges are a prime example of inland vessels. Flat-bottomed boats built to transport heavy goods, most barges are not self-propelled and need to be moved by tugboats towing or towboats pushing them. Barges towed along canals by draft animals on an adjacent towpath contended with the railway in the early industrial revolution but were out competed in the carriage of high value items because of the higher speed, falling costs, and route flexibility of rail transport.
Lake freighters, also called lakers, are cargo vessels that ply the Great Lakes. The most well-known is the , the latest major vessel to be wrecked on the Lakes. These vessels are traditionally called boats, not ships. Visiting ocean-going vessels are called "salties." Because of their additional beam, very large salties are never seen inland of the Saint Lawrence Seaway. Because the smallest of the Soo Locks is larger than any Seaway lock, salties that can pass through the Seaway may travel anywhere in the Great Lakes. Because of their deeper draft, salties may accept partial loads on the Great Lakes, "topping off" when they have exited the Seaway. Similarly, the largest lakers are confined to the Upper Lakes (Superior, Michigan, Huron, Erie) because they are too large to use the Seaway locks, beginning at the Welland Canal that bypasses the Niagara River.
Since the freshwater lakes are less corrosive to ships than the salt water of the oceans, lakers tend to last much longer than ocean freighters. Lakers older than 50 years are not unusual, and as of 2005, all were over 20 years of age.
The "SS St. Marys Challenger", built in 1906 as the "William P Snyder", was the oldest laker still working on the Lakes until its conversion into a barge starting in 2013. Similarly, the "E.M. Ford", built in 1898 as the "Presque Isle", was sailing the lakes 98 years later in 1996. As of 2007 the "Ford" was still afloat as a stationary transfer vessel at a riverside cement silo in Saginaw, Michigan.
Seagoing commercial vessels.
Commercial vessels or merchant ships can be divided into four broad categories: fishing, cargo ships, passenger ships, and special-purpose ships. Modern commercial vessels are typically powered by a single propeller driven by a diesel or, less usually, gas turbine engine., but until the mid-19th century they were predominantly square sail rigged. The fastest vessels may use pump-jet engines. Most commercial vessels have full hull-forms to maximize cargo capacity. Hulls are usually made of steel, although aluminum can be used on faster craft, and fiberglass on the smallest service vessels. Commercial vessels generally have a crew headed by a captain, with deck officers and marine engineers on larger vessels. Special-purpose vessels often have specialized crew if necessary, for example scientists aboard research vessels.
Fishing boats are generally small, often little more than 30 m but up to 100 m for a large tuna or whaling ship. Aboard a fish processing vessel, the catch can be made ready for market and sold more quickly once the ship makes port. Special purpose vessels have special gear. For example, trawlers have winches and arms, stern-trawlers have a rear ramp, and tuna seiners have skiffs. In 2004, 85800000 t of fish were caught in the marine capture fishery. Anchoveta represented the largest single catch at 10700000 t. That year, the top ten marine capture species also included Alaska pollock, Blue whiting, Skipjack tuna, Atlantic herring, Chub mackerel, Japanese anchovy, Chilean jack mackerel, Largehead hairtail, and Yellowfin tuna. Other species including salmon, shrimp, lobster, clams, squid and crab, are also commercially fished. Modern commercial fishermen use many methods. One is fishing by nets, such as purse seine, beach seine, lift nets, gillnets, or entangling nets. Another is trawling, including bottom trawl. Hooks and lines are used in methods like long-line fishing and hand-line fishing. Another method is the use of fishing trap.
Cargo ships transport dry and liquid cargo. Dry cargo can be transported in bulk by bulk carriers, packed directly onto a general cargo ship in break-bulk, packed in intermodal containers as aboard a container ship, or driven aboard as in roll-on roll-off ships. Liquid cargo is generally carried in bulk aboard tankers, such as oil tankers which may include both crude and finished products of oil, chemical tankers which may also carry vegetable oils other than chemicals and LPG/LNG tankers, although smaller shipments may be carried on container ships in tank containers.
Passenger ships range in size from small river ferries to very large cruise ships. This type of vessel includes ferries, which move passengers and vehicles on short trips; ocean liners, which carry passengers from one place to another; and cruise ships, which carry passengers on voyages undertaken for pleasure, visiting several places and with leisure activities on board, often returning them to the port of embarkation. Riverboats and inland ferries are specially designed to carry passengers, cargo, or both in the challenging river environment. Rivers present special hazards to vessels. They usually have varying water flows that alternately lead to high speed water flows or protruding rock hazards. Changing siltation patterns may cause the sudden appearance of shoal waters, and often floating or sunken logs and trees (called snags) can endanger the hulls and propulsion of riverboats. Riverboats are generally of shallow draft, being broad of beam and rather square in plan, with a low freeboard and high topsides. Riverboats can survive with this type of configuration as they do not have to withstand the high winds or large waves that are seen on large lakes, seas, or oceans.
Fishing vessels are a subset of commercial vessels, but generally small in size and often subject to different regulations and classification. They can be categorized by several criteria: architecture, the type of fish they catch, the fishing method used, geographical origin, and technical features such as rigging. As of 2004, the world's fishing fleet consisted of some 4 million vessels. Of these, 1.3 million were decked vessels with enclosed areas and the rest were open vessels. Most decked vessels were mechanized, but two-thirds of the open vessels were traditional craft propelled by sails and oars. More than 60% of all existing large fishing vessels were built in Japan, Peru, the Russian Federation, Spain or the United States of America.
Special purpose vessels.
A weather ship was a ship stationed in the ocean as a platform for surface and upper air meteorological observations for use in marine weather forecasting. Surface weather observations were taken hourly, and four radiosonde releases occurred daily. It was also meant to aid in search and rescue operations and to support transatlantic flights. Proposed as early as 1927 by the aviation community, the establishment of weather ships proved to be so useful during World War II that the International Civil Aviation Organization (ICAO) established a global network of weather ships in 1948, with 13 to be supplied by the United States. This number was eventually negotiated down to nine.
The weather ship crews were normally at sea for three weeks at a time, returning to port for 10 day stretches. Weather ship observations proved to be helpful in wind and wave studies, as they did not avoid weather systems like other ships tended to for safety reasons. They were also helpful in monitoring storms at sea, such as tropical cyclones. The removal of a weather ship became a negative factor in forecasts leading up to the Great Storm of 1987. Beginning in the 1970s, their role became largely superseded by weather buoys due to the ships' significant cost. The agreement of the use of weather ships by the international community ended in 1990. The last weather ship was "Polarfront", known as weather station M ("Mike"), which was put out of operation on 1 January 2010. Weather observations from ships continue from a fleet of voluntary merchant vessels in routine commercial operation.
Naval vessels.
Naval vessels are those used by a navy for military purposes. 
There have been many types of naval vessel. Modern naval vessels can be broken down into three categories: surface warships, submarines, and support and auxiliary vessels.
Modern warships are generally divided into seven main categories: aircraft carriers, cruisers, destroyers, frigates, corvettes, submarines and amphibious assault ships. The distinction between cruisers, destroyers, frigates, and corvettes is not rigorous; the same vessel may be described differently in different navies. Battleships were used during the Second World War and occasionally since then (the last battleships were removed from the U.S. Naval Vessel Register in March 2006), but were made obsolete by the use of carrier-borne aircraft and guided missiles.
Most military submarines are either attack submarines or ballistic missile submarines. Until the end of World War II the primary role of the diesel/electric submarine was anti-ship warfare, inserting and removing covert agents and military forces, and intelligence-gathering. With the development of the homing torpedo, better sonar systems, and nuclear propulsion, submarines also became able to effectively hunt each other. The development of submarine-launched nuclear and cruise missiles gave submarines a substantial and long-ranged ability to attack both land and sea targets with a variety of weapons ranging from cluster munitions to nuclear weapons.
Most navies also include many types of support and auxiliary vessel, such as minesweepers, patrol boats, offshore patrol vessels, replenishment ships, and hospital ships which are designated medical treatment facilities.
Fast combat vessels such as cruisers and destroyers usually have fine hulls to maximize speed and maneuverability. They also usually have advanced marine electronics and communication systems, as well as weapons.
Architecture.
Some components exist in vessels of any size and purpose. Every vessel has a hull of sorts. Every vessel has some sort of propulsion, whether it's a pole, an ox, or a nuclear reactor. Most vessels have some sort of steering system. Other characteristics are common, but not as universal, such as compartments, holds, a superstructure, and equipment such as anchors and winches.
Hull.
For a ship to float, its weight must be less than that of the water displaced by the ship's hull. There are many types of hulls, from logs lashed together to form a raft to the advanced hulls of America's Cup sailboats. A vessel may have a single hull (called a monohull design), two in the case of catamarans, or three in the case of trimarans. Vessels with more than three hulls are rare, but some experiments have been conducted with designs such as pentamarans. Multiple hulls are generally parallel to each other and connected by rigid arms.
Hulls have several elements. The bow is the foremost part of the hull. Many ships feature a bulbous bow. The keel is at the very bottom of the hull, extending the entire length of the ship. The rear part of the hull is known as the stern, and many hulls have a flat back known as a transom. Common hull appendages include propellers for propulsion, rudders for steering, and stabilizers to quell a ship's rolling motion. Other hull features can be related to the vessel's work, such as fishing gear and sonar domes.
Hulls are subject to various hydrostatic and hydrodynamic constraints. The key hydrostatic constraint is that it must be able to support the entire weight of the boat, and maintain stability even with often unevenly distributed weight. Hydrodynamic constraints include the ability to withstand shock waves, weather collisions and groundings.
Older ships and pleasure craft often have or had wooden hulls. Steel is used for most commercial vessels. Aluminium is frequently used for fast vessels, and composite materials are often found in sailboats and pleasure craft. Some ships have been made with concrete hulls.
Propulsion systems.
Propulsion systems for ships fall into three categories: human propulsion, sailing, and mechanical propulsion. Human propulsion includes rowing, which was used even on large galleys. Propulsion by sail generally consists of a sail hoisted on an erect mast, supported by stays and spars and controlled by ropes. Sail systems were the dominant form of propulsion until the 19th century. They are now generally used for recreation and competition, although experimental sail systems, such as the turbosails, rotorsails, and wingsails have been used on larger modern vessels for fuel savings.
Mechanical propulsion systems generally consist of a motor or engine turning a propeller, or less frequently, an impeller or wave propulsion fins. Steam engines were first used for this purpose, but have mostly been replaced by two-stroke or four-stroke diesel engines, outboard motors, and gas turbine engines on faster ships. Nuclear reactors producing steam are used to propel warships and icebreakers, and there have been attempts to utilize them to power commercial vessels (see NS "Savannah").
In addition to traditional fixed and controllable pitch propellers there are many specialized variations, such as contra-rotating and nozzle-style propellers. Most vessels have a single propeller, but some large vessels may have up to four propellers supplemented with transverse thrusters for maneuvring at ports. The propeller is connected to the main engine via a propeller shaft and, in case of medium- and high-speed engines, a reduction gearbox. Some modern vessels have a diesel-electric powertrain in which the propeller is turned by an electric motor powered by the ship's generators.
Steering systems.
For ships with independent propulsion systems for each side, such as manual oars or some paddles, steering systems may not be necessary. In most designs, such as boats propelled by engines or sails, a steering system becomes necessary. The most common is a rudder, a submerged plane located at the rear of the hull. Rudders are rotated to generate a lateral force which turns the boat. Rudders can be rotated by a tiller, manual wheels, or electro-hydraulic systems. Autopilot systems combine mechanical rudders with navigation systems. Ducted propellers are sometimes used for steering.
Some propulsion systems are inherently steering systems. Examples include the outboard motor, the bow thruster, and the Z-drive.
Holds, compartments, and the superstructure.
Larger boats and ships generally have multiple decks and compartments. Separate berthings and heads are found on sailboats over about 25 ft. Fishing boats and cargo ships typically have one or more cargo holds. Most larger vessels have an engine room, a galley, and various compartments for work. Tanks are used to store fuel, engine oil, and fresh water. Ballast tanks are equipped to change a ship's trim and modify its stability.
Superstructures are found above the main deck. On sailboats, these are usually very low. On modern cargo ships, they are almost always located near the ship's stern. On passenger ships and warships, the superstructure generally extends far forward.
Equipment.
Shipboard equipment varies from ship to ship depending on such factors as the ship's era, design, area of operation, and purpose. Some types of equipment that are widely found include:
Design considerations.
Hydrostatics.
Boats and ships are kept on (or slightly above) the water in three ways:
A vessel is in equilibrium when the upwards and downwards forces are of equal magnitude. As a vessel is lowered into the water its weight remains constant but the corresponding weight of water displaced by its hull increases. When the two forces are equal, the boat floats. If weight is evenly distributed throughout the vessel, it floats without trim or heel.
A vessel's stability is considered in both this hydrostatic sense as well as a hydrodynamic sense, when subjected to movement, rolling and pitching, and the action of waves and wind. Stability problems can lead to excessive pitching and rolling, and eventually capsizing and sinking.
Hydrodynamics.
The advance of a vessel through water is resisted by the water. This resistance can be broken down into several components, the main ones being the friction of the water on the hull and wave making resistance. To reduce resistance and therefore increase the speed for a given power, it is necessary to reduce the wetted surface and use submerged hull shapes that produce low amplitude waves. To do so, high-speed vessels are often more slender, with fewer or smaller appendages. The friction of the water is also reduced by regular maintenance of the hull to remove the sea creatures and algae that accumulate there. Antifouling paint is commonly used to assist in this. Advanced designs such as the bulbous bow assist in decreasing wave resistance.
A simple way of considering wave-making resistance is to look at the hull in relation to its wake. At speeds lower than the wave propagation speed, the wave rapidly dissipates to the sides. As the hull approaches the wave propagation speed, however, the wake at the bow begins to build up faster than it can dissipate, and so it grows in amplitude. Since the water is not able to "get out of the way of the hull fast enough", the hull, in essence, has to climb over or push through the bow wave. This results in an exponential increase in resistance with increasing speed.
This hull speed is found by the formula:
formula_1
or, in metric units:
formula_2
where "L" is the length of the waterline in feet or meters.
When the vessel exceeds a speed/length ratio of 0.94, it starts to outrun most of its bow wave, and the hull actually settles slightly in the water as it is now only supported by two wave peaks. As the vessel exceeds a speed/length ratio of 1.34, the hull speed, the wavelength is now longer than the hull, and the stern is no longer supported by the wake, causing the stern to squat, and the bow rise. The hull is now starting to climb its own bow wave, and resistance begins to increase at a very high rate. While it is possible to drive a displacement hull faster than a speed/length ratio of 1.34, it is prohibitively expensive to do so. Most large vessels operate at speed/length ratios well below that level, at speed/length ratios of under 1.0.
For large projects with adequate funding, hydrodynamic resistance can be tested experimentally in a hull testing pool or using tools of computational fluid dynamics.
Vessels are also subject to ocean surface waves and sea swell as well as effects of wind and weather. These movements can be stressful for passengers and equipment, and must be controlled if possible. The rolling movement can be controlled, to an extent, by ballasting or by devices such as fin stabilizers. Pitching movement is more difficult to limit and can be dangerous if the bow submerges in the waves, a phenomenon called pounding. Sometimes, ships must change course or speed to stop violent rolling or pitching.
How it has been convincingly shown in scientific studies of the 21st century, controllability of some vessels decreases dramatically in some cases that are conditioned by effects of the bifurcation memory. This class of vessels includes ships with high manoeuvring capabilities, aircraft and controlled underwater vehicles designed to be unstable in steady-state motion that are interesting in terms of applications. These features must be considered in designing ships and in their control in critical situations.
Lifecycle.
A ship will pass through several stages during its career. The first is usually an initial contract to build the ship, the details of which can vary widely based on relationships between the shipowners, operators, designers and the shipyard. Then, the design phase carried out by a naval architect. Then the ship is constructed in a shipyard. After construction, the vessel is launched and goes into service. Ships end their careers in a number of ways, ranging from shipwrecks to service as a museum ship to the scrapyard.
Design.
A vessel's design starts with a specification, which a naval architect uses to create a project outline, assess required dimensions, and create a basic layout of spaces and a rough displacement. After this initial rough draft, the architect can create an initial hull design, a general profile and an initial overview of the ship's propulsion. At this stage, the designer can iterate on the ship's design, adding detail and refining the design at each stage.
The designer will typically produce an overall plan, a general specification describing the peculiarities of the vessel, and construction blueprints to be used at the building site. Designs for larger or more complex vessels may also include sail plans, electrical schematics, and plumbing and ventilation plans.
As environmental laws are becoming more strict, ship designers need to create their design in such a way that the ship, when it nears its end-of-term, can be disassmbled or disposed easily and that waste is reduced to a minimum.
Construction.
Ship construction takes place in a shipyard, and can last from a few months for a unit produced in series, to several years to reconstruct a wooden boat like the frigate "Hermione", to more than 10 years for an aircraft carrier. During World War II, the need for cargo ships was so urgent that construction time for Liberty Ships went from initially eight months or longer, down to weeks or even days. Builders employed production line and prefabrication techniques such as those used in shipyards today.
Hull materials and vessel size play a large part in determining the method of construction. The hull of a mass-produced fiberglass sailboat is constructed from a mold, while the steel hull of a cargo ship is made from large sections welded together as they are built.
Generally, construction starts with the hull, and on vessels over about 30 m, by the laying of the keel. This is done in a drydock or on land. Once the hull is assembled and painted, it is launched. The last stages, such as raising the superstructure and adding equipment and accommodation, can be done after the vessel is afloat.
Once completed, the vessel is delivered to the customer. Ship launching is often a ceremony of some significance, and is usually when the vessel is formally named. A typical small rowboat can cost under US$100, $1,000 for a small speedboat, tens of thousands of dollars for a cruising sailboat, and about $2,000,000 for a Vendée Globe class sailboat. A 25 m trawler may cost $2.5 million, and a 1,000-person-capacity high-speed passenger ferry can cost in the neighborhood of $50 million. A ship's cost partly depends on its complexity: a small, general cargo ship will cost $20 million, a Panamax-sized bulk carrier around $35 million, a supertanker around $105 million and a large LNG carrier nearly $200 million. The most expensive ships generally are so because of the cost of embedded electronics: a "Seawolf"-class submarine costs around $2 billion, and an aircraft carrier goes for about $3.5 billion.
Repair and conversion.
Ships undergo nearly constant maintenance during their career, whether they be underway, pierside, or in some cases, in periods of reduced operating status between charters or shipping seasons.
Most ships, however, require trips to special facilities such as a drydock at regular intervals. Tasks often done at drydock include removing biological growths on the hull, sandblasting and repainting the hull, and replacing sacrificial anodes used to protect submerged equipment from corrosion. Major repairs to the propulsion and steering systems as well as major electrical systems are also often performed at dry dock.
Vessels that sustain major damage at sea may be repaired at a facility equipped for major repairs, such as a shipyard. Ships may also be converted for a new purpose: oil tankers are often converted into floating production storage and offloading units.
End of service.
Most ocean-going cargo ships have a life expectancy of between 20 and 30 years. A sailboat made of plywood or fiberglass can last between 30 and 40 years. Solid wooden ships can last much longer but require regular maintenance. Carefully maintained steel-hulled yachts can have a lifespan of over 100 years.
As ships age, forces such as corrosion, osmosis, and rotting compromise hull strength, and a vessel becomes too dangerous to sail. At this point, it can be scuttled at sea or scrapped by shipbreakers. Ships can also be used as museum ships, or expended to construct breakwaters or artificial reefs.
Many ships do not make it to the scrapyard, and are lost in fires, collisions, grounding, or sinking at sea. The Allies lost some 5,150 ships during World War II.
Measuring ships.
One can measure ships in terms of overall length, length of the ship at the waterline, beam (breadth), depth (distance between the crown of the weather deck and the top of the keelson), draft (distance between the highest waterline and the bottom of the ship) and tonnage. A number of different tonnage definitions exist and are used when describing merchant ships for the purpose of tolls, taxation, etc.
In Britain until Samuel Plimsoll's Merchant Shipping Act of 1876, ship-owners could load their vessels until their decks were almost awash, resulting in a dangerously unstable condition. Anyone who signed on to such a ship for a voyage and, upon realizing the danger, chose to leave the ship, could end up in jail. Plimsoll, a Member of Parliament, realised the problem and engaged some engineers to derive a fairly simple formula to determine the position of a line on the side of any specific ship's hull which, when it reached the surface of the water during loading of cargo, meant the ship had reached its maximum safe loading level. To this day, that mark, called the "Plimsoll Line", exists on ships' sides, and consists of a circle with a horizontal line through the centre. On the Great Lakes of North America the circle is replaced with a diamond. Because different types of water (summer, fresh, tropical fresh, winter north Atlantic) have different densities, subsequent regulations required painting a group of lines forward of the Plimsoll mark to indicate the safe depth (or freeboard above the surface) to which a specific ship could load in water of various densities. Hence the "ladder" of lines seen forward of the Plimsoll mark to this day. This is called the "freeboard mark" or "load line mark" in the marine industry.
Ship pollution.
Ship pollution is the pollution of air and water by shipping. It is a problem that has been accelerating as trade has become increasingly globalized, posing an increasing threat to the world’s oceans and waterways as globalization continues. It is expected that, “...shipping traffic to and from the USA is projected to double by 2020." Because of increased traffic in ocean ports, pollution from ships also directly affects coastal areas. The pollution produced affects biodiversity, climate, food, and human health. However, the degree to which humans are polluting and how it affects the world is highly debated and has been a hot international topic for the past 30 years.
Oil spills.
Oil spills have devastating effects on the environment. Crude oil contains polycyclic aromatic hydrocarbons (PAHs) which are very difficult to clean up, and last for years in the sediment and marine environment. Marine species constantly exposed to PAHs can exhibit developmental problems, susceptibility to disease, and abnormal reproductive cycles.
By the sheer amount of oil carried, modern oil tankers must be considered something of a threat to the environment. An oil tanker can carry 2 Moilbbl of crude oil, or 84000000 USgal. This is more than six times the amount spilled in the widely known "Exxon Valdez" incident. In this spill, the ship ran aground and dumped 10800000 USgal of oil into the ocean in March 1989. Despite efforts of scientists, managers, and volunteers, over 400,000 seabirds, about 1,000 sea otters, and immense numbers of fish were killed.
The International Tanker Owners Pollution Federation has researched 9,351 accidental spills since 1974. According to this study, most spills result from routine operations such as loading cargo, discharging cargo, and taking on fuel oil. 91% of the operational oil spills were small, resulting in less than 7 tons per spill. Spills resulting from accidents like collisions, groundings, hull failures, and explosions are much larger, with 84% of these involving losses of over 700 tons.
Following the "Exxon Valdez" spill, the United States passed the Oil Pollution Act of 1990 (OPA-90), which included a stipulation that all tankers entering its waters be double-hulled by 2015. Following the sinkings of the "Erika" (1999) and "Prestige" (2002), the European Union passed its own stringent anti-pollution packages (known as Erika I, II, and III), which require all tankers entering its waters to be double-hulled by 2010. The Erika packages are controversial because they introduced the new legal concept of "serious negligence".
Ballast water.
When a large vessel such as a container ship or an oil tanker unloads cargo, seawater is pumped into other compartments in the hull to help stabilize and balance the ship. During loading, this ballast water is pumped out from these compartments.
One of the problems with ballast water transfer is the transport of harmful organisms. Meinesz believes that one of the worst cases of a single invasive species causing harm to an ecosystem can be attributed to a seemingly harmless jellyfish. "Mnemiopsis leidyi", a species of comb jellyfish that inhabits estuaries from the United States to the Valdés peninsula in Argentina along the Atlantic coast, has caused notable damage in the Black Sea. It was first introduced in 1982, and thought to have been transported to the Black Sea in a ship’s ballast water. The population of the jellyfish shot up exponentially and, by 1988, it was wreaking havoc upon the local fishing industry. "The anchovy catch fell from 204000 t in 1984 to 200 t in 1993; sprat from 24600 t in 1984 to 12000 t in 1993; horse mackerel from 4000 t in 1984 to zero in 1993." Now that the jellyfish have exhausted the zooplankton, including fish larvae, their numbers have fallen dramatically, yet they continue to maintain a stranglehold on the ecosystem. Recently the jellyfish have been discovered in the Caspian Sea. Invasive species can take over once occupied areas, facilitate the spread of new diseases, introduce new genetic material, alter landscapes and jeopardize the ability of native species to obtain food. "On land and in the sea, invasive species are responsible for about 137 billion dollars in lost revenue and management costs in the U.S. each year."
Ballast and bilge discharge from ships can also spread human pathogens and other harmful diseases and toxins potentially causing health issues for humans and marine life alike. Discharges into coastal waters, along with other sources of marine pollution, have the potential to be toxic to marine plants, animals, and microorganisms, causing alterations such as changes in growth, disruption of hormone cycles, birth defects, suppression of the immune system, and disorders resulting in cancer, tumors, and genetic abnormalities or even death.
Exhaust emissions.
Exhaust emissions from ships are considered to be a significant source of air pollution. “Seagoing vessels are responsible for an estimated 14 percent of emissions of nitrogen from fossil fuels and 16 percent of the emissions of sulfur from petroleum uses into the atmosphere.” In Europe ships make up a large percentage of the sulfur introduced to the air, “...as much sulfur as all the cars, lorries and factories in Europe put together.” “By 2010, up to 40% of air pollution over land could come from ships.” Sulfur in the air creates acid rain which damages crops and buildings. When inhaled sulfur is known to cause respiratory problems and increase the risk of a heart attack.
Ship breaking.
Ship breaking or ship demolition is a type of ship disposal involving the breaking up of ships for scrap recycling, with the hulls being discarded in ship graveyards. Most ships have a lifespan of a few decades before there is so much wear that refitting and repair becomes uneconomical. Ship breaking allows materials from the ship, especially steel, to be reused.
In addition to steel and other useful materials, however, ships (particularly older vessels) can contain many substances that are banned or considered dangerous in developed countries. Asbestos and polychlorinated biphenyls (PCBs) are typical examples. Asbestos was used heavily in ship construction until it was finally banned in most of the developed world in the mid 1980s. Currently, the costs associated with removing asbestos, along with the potentially expensive insurance and health risks, have meant that ship-breaking in most developed countries is no longer economically viable. Removing the metal for scrap can potentially cost more than the scrap value of the metal itself. In most of the developing world, however, shipyards can operate without the risk of personal injury lawsuits or workers' health claims, meaning many of these shipyards may operate with high health risks. Furthermore, workers are paid very low rates with no overtime or other allowances. Protective equipment is sometimes absent or inadequate. Dangerous vapors and fumes from burning materials can be inhaled, and dusty asbestos-laden areas around such breakdown locations are commonplace.
Aside from the health of the yard workers, in recent years, ship breaking has also become an issue of major environmental concern. Many developing nations, in which ship breaking yards are located, have lax or no environmental law, enabling large quantities of highly toxic materials to escape into the environment and causing serious health problems among ship breakers, the local population and wildlife. Environmental campaign groups such as Greenpeace have made the issue a high priority for their campaigns.
Buoyancy.
A floating boat displaces its weight in water. The material of the boat hull may be denser than water, but if this is the case then it forms only the outer layer. If the boat floats, the mass of the boat (plus contents) "as a whole" divided by the volume "below the waterline" is equal to the density of water (1 kg/l). If weight is added to the boat, the volume below the waterline will increase to keep the weight balance equal, and so the boat sinks a little to compensate.
See also.
Model ships
Lists

</doc>
<doc id="27009" url="http://en.wikipedia.org/wiki?curid=27009" title="Soap opera">
Soap opera

A soap opera, soapie, or soap is a serial drama on television or radio which features related story lines about the lives of multiple characters. The stories usually focus on emotional relationships to the point of melodrama. The term "soap opera" originated from such dramas being typically sponsored by soap manufacturers in the past.
Origin of the genre.
The first series considered to be a "soap opera" was "Painted Dreams", which debuted on October 20, 1930 on Chicago radio station WGN. Early radio series such as "Painted Dreams" were broadcast in weekday daytime slots, usually five days a week, when most of the listeners would be housewives; thus, the shows were aimed at and consumed by a predominantly female audience. In the name, "soap" refers to the soap and detergent commercials originally broadcast during the shows, which were aimed at women who were cleaning their houses at the time of listening or viewing, and "opera" refers to the melodramatic character of the shows.
The first nationally broadcast radio soap opera was "Clara, Lu, and Em", which aired on the NBC Blue Network at 10:30 p.m. Eastern Time on January 27, 1931.
Story and episode structure.
A crucial element that defines the soap opera is the open-ended serial nature of the narrative, with stories spanning several episodes. One of the defining features that makes a television program a soap opera, according to Albert Moran, is "that form of television that works with a continuous open narrative. Each episode ends with a promise that the storyline is to be continued in another episode". In 2012, "Los Angeles Times" columnist Robert Lloyd wrote of daily dramas, "Although melodramatically eventful, soap operas such as this also have a luxury of space that makes them seem more naturalistic; indeed, the economics of the form demand long scenes, and conversations that a 22-episodes-per-season weekly series might dispense with in half a dozen lines of dialogue may be drawn out, as here, for pages. You spend more time even with the minor characters; the apparent villains grow less apparently villainous."
Soap opera storylines run concurrently, intersect and lead into further developments. An individual episode of a soap opera will generally switch between several different concurrent narrative threads that may at times interconnect and affect one another or may run entirely independent of each other. Each episode may feature some of the show's current storylines, but not always all of them. Especially in daytime serials and those that are broadcast each weekday, there is some rotation of both storyline and actors so any given storyline or actor will appear in some but usually not all of a week's worth of episodes. Soap operas rarely bring all the current storylines to a conclusion at the same time. When one storyline ends, there are several other story threads at differing stages of development. Soap opera episodes typically end on some sort of cliffhanger, and the season finale (if a soap incorporates a break between seasons) ends in the same way, only to be resolved when the show returns for the start of a new yearly broadcast.
Evening soap operas and those that air at a rate of one episode per week are more likely to feature the entire cast in each episode, and to represent all current storylines in each episode. Evening soap operas and serials that run for only part of the year tend to bring things to a dramatic end-of-season cliffhanger.
In 1976, "Time" magazine described American daytime television as "TV's richest market," noting the loyalty of the soap opera fan base and the expansion of several half-hour series into hour-long broadcasts in order to maximize ad revenues. The article explained that at that time, many prime time series lost money, while daytime serials earned profits several times more than their production costs. The issue's cover notably featured its first daytime soap stars, Bill Hayes and Susan Seaforth Hayes of "Days of Our Lives", a married couple whose onscreen and real-life romance was widely covered by both the soap opera magazines and the mainstream press at large.
Plots and storylines.
The main characteristics that define soap operas are "an emphasis on family life, personal relationships, sexual dramas, emotional and moral conflicts; some coverage of topical issues; set in familiar domestic interiors with only occasional excursions into new locations". Fitting in with these characteristics, most soap operas follow the lives of a group of characters who live or work in a particular place, or focus on a large extended family. The storylines follow the day-to-day activities and personal relationships of these characters. "Soap narratives, like those of film melodramas, are marked by what Steve Neale has described as 'chance happenings, coincidences, missed meetings, sudden conversions, last-minute rescues and revelations, deus ex machina endings.'" These elements may be found across the gamut of soap operas, from "EastEnders" to "Dallas".
In many soap operas, in particular daytime serials in the United States, the characters are frequently attractive, seductive, glamorous and wealthy. Soap operas from the United Kingdom and Australia tend to focus on more everyday characters and situations, and are frequently set in working class environments. Many of the soaps produced in those two countries explore social realist storylines such as family discord, marriage breakdown or financial problems. Both UK and Australian soap operas feature comedic elements, often by way of affectionate comic stereotypes such as the gossip or the grumpy old man, presented as a sort of comic foil to the emotional turmoil that surrounds them. This diverges from U.S. soap operas where such comedy is rare. UK soap operas frequently make a claim to presenting "reality" or purport to have a "realistic" style. UK soap operas also frequently foreground their geographic location as a key defining feature of the show while depicting and capitalising on the exotic appeal of the stereotypes connected to the location. As examples, "EastEnders" focuses on the tough and grim life in London's east end; while "Coronation Street" invokes Manchester and its characters exhibit the stereotypical characteristic of "Northern straight talking".
Romance, secret relationships, extramarital affairs, and genuine love have been the basis for many soap opera storylines. In U.S. daytime serials, the most popular soap opera characters, and the most popular storylines, often involved a romance of the sort presented in paperback romance novels. Soap opera storylines sometimes weave intricate, convoluted and sometimes confusing tales of characters who have affairs, meet mysterious strangers and fall in love, and who commit adultery, all of which keeps audiences hooked on the unfolding story twists. Crimes such as kidnapping, rape, and even murder may go unpunished if the perpetrator is to be retained in the ongoing story.
Australian and UK soap operas also feature a significant proportion of romance storylines. In Russia, most popular serials explore the "romantic quality" of criminal and/or oligarch life.
In soap opera storylines, previously unknown children, siblings and twins (including the evil variety) of established characters often emerge to upset and reinvigorate the set of relationships examined by the series. Unexpected calamities disrupt weddings, childbirths, and other major life events with unusual frequency.
"If we want to blend an actor back into a show, there's always a way. You can generally find a way to twist and manipulate something. You rarely see a dead body, but hey, even if you do, he or she can always come back to play the evil identical twin."
 – Marlena Laird in 1992, during her time as a line producer and director for "General Hospital".
Much like comic books – another popular form of linear storytelling pioneered in the U.S. during the 20th Century – a character's death is not guaranteed to be permanent. On "The Bold and the Beautiful", Taylor Forrester (Hunter Tylo) was shown to flatline and have a funeral. When Tylo reprised the character in 2005, a retcon explained that Taylor had actually gone into a coma.
Stunts and complex physical action are largely absent, especially from daytime serials. Such story events often take place offscreen and are referred to in dialogue instead of being shown. This is because stunts or action scenes are difficult to adequately depict visually without complex action, multiple takes, and post production editing. When episodes were broadcast live, post production work was impossible. Though all serials have long switched to being taped, extensive post production work and multiple takes, while possible, are not feasible due to the tight taping schedules and low budgets.
United States.
Daytime serials on television.
The first network television soap opera was "Faraway Hill" in 1946. Soap operas became a staple of daytime television in the United States in the early 1950s. Along with game shows, reruns of situation comedies, and talk shows, the soap opera was traditionally a fixture on the daytime schedules of the American broadcast networks. Christina S. Beck argues the significance of soap operas are based on viewers' co-constructing narratives to show how both traditional and online soaps help negotiated the lived experience of people. In 1988, H. Wesley Kenney, who at the time served as the executive producer of "General Hospital", said to "The New York Times":
I think people like stories that continue so they can relate to these people. They become like a family, and the viewer becomes emotionally involved. There seem to be two attitudes by viewers. One, that the stories are similar to what happened to them in real life, or two, thank goodness that isn't me.—H. Wesley Kenney
Many long-running U.S. soap operas established particular environments for their stories. "The Doctors" and "General Hospital", in the beginning, told stories almost exclusively from inside the confines of a hospital. "As the World Turns" dealt heavily with Chris Hughes' law practice and the travails of his wife Nancy who, tired of being "the loyal housewife" in the 1970s, became one of the first older women on the American serials to enter the workforce. "Guiding Light" dealt with Bert Bauer (Charita Bauer) and her alcoholic husband Bill, and their endless marital troubles. When Bert's status shifted to caring mother and town matriarch, her children's marital troubles were showcased. "Search for Tomorrow" mostly told its story through the eyes of Joanne Gardner (Mary Stuart). Even when stories revolved around other characters, Joanne was frequently a key player in their storylines. "Days of our Lives" initially focused on Dr. Tom Horton and his steadfast wife Alice. The show later branched out to focus more on their five children. "The Edge of Night" featured as its central character Mike Karr, a police detective (later an attorney), and largely dealt with organized crime. "The Young and the Restless" first focused on two families, the prosperous Brooks family with four daughters, and the working class Foster family of a single working mother with three children. Its storylines explored realistic problems including cancer, mental illness, poverty and infidelity.
In contrast, "Dark Shadows" (1966–1971) and "Port Charles" (1997–2003) featured supernatural characters and dealt with fantasy and horror storylines. Their characters included vampires, witches, ghosts, goblins and angels.
The American soap opera "Guiding Light" (originally titled "The Guiding Light" until 1975) started as a radio drama in January 1937 and subsequently transferred to television in June 1952. With the exception of several years in the late 1940s when the show's creator Irna Phillips was involved in a dispute with Procter & Gamble, "Guiding Light" was heard or seen nearly every weekday since it began, until 2009 making it the longest story ever told in a broadcast medium.
Originally serials were broadcast as fifteen-minute installments each weekday in daytime slots. In 1956, "As the World Turns" and "The Edge of Night", both produced by Procter & Gamble Productions, debuted as the first half-hour soap operas on the CBS television network. All soap operas broadcast half-hour episodes by the end of the 1960s. With increased popularity in the 1970s, most soap operas had expanded to an hour in length by the end of the decade ("Another World" even expanded to 90 minutes for a short time). More than half of the serials had expanded to one-hour episodes by 1980. As of 2012, three of the four U.S. serials air one hour episodes each weekday; only "The Bold and the Beautiful" airs 30-minute episodes.
Soap operas were originally broadcast live from the studio, creating what many at the time regarded as a feeling similar to that of a stage play. As nearly all soap operas were originated at that time in New York City, a number of soap actors were also accomplished stage actors who performed live theatre during breaks from their soap roles. In the 1960s and 1970s, new serials such as "General Hospital", "Days of our Lives" and "The Young and the Restless" were produced in Los Angeles. Their success made the West Coast a viable alternative to New York-produced soap operas, which were becoming more costly to perform. By the early 1970s, nearly all soap operas had transitioned to being taped. "As the World Turns" and "The Edge of Night" were the last to make the switch, in 1975.
"Port Charles" used the practice of running 13-week "story arcs," in which the main events of the arc are played out and wrapped up over the 13 weeks, although some storylines did continue over more than one arc. According to the 2006 Preview issue of "Soap Opera Digest", it was briefly discussed that all ABC shows might do telenovela arcs, but this was rejected.
Though U.S. daytime soap operas are not generally rerun by their networks, occasionally they are rebroadcast elsewhere. Early episodes of "Dark Shadows" were rerun on PBS member stations in the early 1970s after the show's cancellation, and the entire series (except for a single missing episode) was rerun on the Sci-Fi Channel in the 1990s. After "The Edge of Night"‍ '​s 1984 cancellation, reruns of the show's final five years were shown late nights on USA Network from 1985 to 1989. On January 20, 2000, a digital cable and satellite network dedicated to the genre, SOAPnet, began re-airing soaps that originally aired on ABC, NBC and CBS.
Newer broadcast networks since the late 1980s, such as Fox and cable television networks, have largely eschewed soap operas in their daytime schedules, instead running syndicated programming and reruns. No cable television outlet has produced its own daytime serial, although DirecTV's The 101 Network took over existing serial "Passions", continuing production for one season. Fox, the fourth "major network," carried a short lived daytime soap "Tribes" in 1990. Yet other than this and a couple of pilot attempts, Fox mainly stayed away from daytime soaps, and has not attempted them since their ascension to major-network status in 1994 (it did later attempt a series of daily prime time soaps, which aired on newly created sister network MyNetworkTV, but the experiment was largely a failure).
Due to the masses of episodes produced for a series, release of soap operas to DVD (a popular venue for distribution of current and vintage television series) is considered impractical. With the exception of occasional specials, daytime soap operas are notable by their absence from DVD release schedules (an exception being the supernatural soap opera, "Dark Shadows", which did receive an essentially complete release on both VHS and DVD; the single lost episode #1219 is reconstructed by means of an off-the-air audio recording, still images, and recap material from adjacent episodes).
Performers.
Due to the longevity of these shows, it is not uncommon for a single character to be played by multiple actors. The key character of Mike Karr on "The Edge of Night" was played by three different actors.
Conversely, several actors have remained playing the same character for many years, or decades even. Helen Wagner played Hughes family matriarch Nancy Hughes on American soap "As the World Turns" from its April 2, 1956 debut through her death in May 2010. She is listed in the Guinness Book of World Records as the actor with the longest uninterrupted performance in a single role. A number of performers played roles for twenty years or longer, occasionally on more than one show. Rachel Ames played Audrey Hardy on both "General Hospital" and "Port Charles" from 1964 until 2007, and returned in 2009. Susan Lucci played Erica Kane in "All My Children" from the show's debut in January 1970 until it ended its network television run on ABC on September 23, 2011. Erika Slezak played Victoria Lord #3 on "One Life to Live" from 1971 until the show ended its network television run on ABC on January 13, 2012 and resumed the role in its short-lived online revival on April 29, 2013.
Other actors have played several characters on different shows. Millette Alexander, Bernard Barrow, Doris Belack, David Canary, Judith Chapman, Jordan Charney, Joan Copeland, Nicolas Coster, Jacqueline Courtney, Louis Edmonds, Dan Hamilton, Don Hastings, Vincent Irizarry, Lenore Kasdorf, Teri Keane, Lois Kibbee, John Loprieno, Maeve McGuire, James Mitchell, Christopher Pennock, Gary Pillar, Antony Ponzini, William Prince, Louise Shaffer, and Diana van der Vlis, among many others, have all played multiple soap roles.
Evolution of the daytime serial.
For several decades, most daytime soap operas concentrated on family and marital discord, legal drama and romance. The action rarely left interior settings, and many shows were set in fictional, medium-sized Midwestern towns.
Exterior shots were slowly incorporated into the series "The Edge of Night" and "Dark Shadows". Unlike many earlier serials which were set in fictional towns, "The Best of Everything" and "Ryan's Hope" were set in a real-world location, New York City.
The first exotic location shoot was made by "All My Children", to St. Croix in 1978. Many other soap operas planned lavish storylines after the success of the "All My Children" shoot. Soap operas "Another World" and "Guiding Light" both went to St. Croix in 1980, the former show culminating a long-running storyline between popular characters Mac, Rachel and Janice, and the latter to serve as an exotic setting for Alan Spaulding and Rita Bauer's torrid affair. "Search for Tomorrow" taped for two weeks in Hong Kong in 1981. Later that year, some of the cast and crew ventured to Jamaica to tape a love consummation storyline between the characters of Garth and Kathy.
During the 1980s, perhaps as a reaction to the evening drama series that were gaining high ratings, daytime serials began to incorporate action and adventure storylines, more big-business intrigue, and an increased emphasis on youthful romance.
One of the first and most popular couples was Luke Spencer and Laura Webber on "General Hospital". Luke and Laura helped to attract both male and female fans. Even actress Elizabeth Taylor was a fan and at her own request was given a guest role in Luke and Laura's wedding episode. Luke and Laura's popularity led to other soap producers striving to reproduce this success by attempting to create supercouples of their own.
With increasingly bizarre action storylines coming into vogue, Luke and Laura saved the world from being frozen, brought a mobster down by finding his black book in a Left-Handed Boy Statue, and helped a Princess find her Aztec Treasure in Mexico. Other soap operas attempted similar adventure storylines, often featuring footage shot on location – frequently in exotic locales.
During the 1990s, the mob, action and adventure stories fell out of favor with producers, due to generally declining ratings for daytime soap operas at the time, and the resultant budget cuts. In addition, soap operas were no longer able to go on expensive location shoots overseas as they were able to do in the 1980s. During that decade, soap operas increasingly focused on younger characters and social issues, such as Erica Kane's drug addiction on "All My Children", the re-emergence of Viki Lord's multiple personality disorder on "One Life to Live", and Stuart Chandler dealing with AIDS and death on "All My Children". Other social issues included cancer, homophobia, addiction, abuse, adoption and racism.
Some shows during the 2000s incorporated supernatural and science fiction elements into their storylines. One of the main characters on the earlier soap opera "Dark Shadows" were Barnabas Collins, a vampire, and "One Life to Live" featured an angel named Virgil. Both shows featured characters who travelled to and from the past.
Traditional grammar of daytime serials.
Modern U.S. daytime soap operas largely stay true to the original soap opera format. The duration and format of storylines and the visual grammar employed by U.S. daytime serials set them apart from soap operas in other countries and from evening soap operas. Stylistically, UK and Australian soap operas, which are usually produced for early evening timeslots, fall somewhere in-between U.S. daytime and evening soap operas. Similar to U.S. daytime soap operas, UK and Australian serials are shot on videotape, and the cast and storylines are rotated across the week's episodes so that each cast member will appear in some but not all episodes. UK and Australian soap operas move through storylines at a faster rate than daytime serials, making them closer to U.S. evening soap operas in this regard.
American daytime soap operas feature stylistic elements that set them apart from other shows:
Decline.
Statistics and trends.
Soap opera ratings have significantly fallen in the U.S. since the 2000s. No new major daytime soap opera has been created since "Passions" in 1999, while many have been cancelled. "The Young and the Restless", the highest-rated soap opera from 1988 to the present, had fewer than 5 million daily viewers as of February 2012, a number exceeded by several non-scripted programs such as "Judge Judy". Circulations of soap opera magazines have decreased and some have even ceased publication. SOAPnet, which largely aired soap opera reruns, began to be phased out in 2012 and fully ceased operations the following year. Since January 2012, four daytime soap operas – "General Hospital", "Days of our Lives", "The Young and the Restless" and "The Bold and the Beautiful" – continue to air on the three major networks, down from a total of 12 during the 1990–91 season and a high of 19 in the 1969–70 season. This marks the first time since 1953 that there are only four soap operas on broadcast television.
Several of America's most established soaps ended between 2009 and 2012. The longest-running drama in television and radio history, "Guiding Light", barely reached 2.1 million daily viewers in 2009 and ended on September 18 of that year, after a 72-year run. "As the World Turns" aired its final episode on September 17, 2010 after a 54-year run. "As the World Turns" was the last of 20 soap operas produced by Procter & Gamble, the soap and consumer goods company from which the genre got its name. "As The World Turns" and "Guiding Light" were also among the last of the soaps that originated from New York City. "All My Children", another New York-based soap, moved its production out to Los Angeles in an effort to reduce costs and raise sagging ratings, however, it along with "One Life to Live", each with a four-decade-plus run, were both cancelled in 2011. "All My Children" aired its network finale in September 2011 with "One Life to Live" following suit in January 2012. Both "All My Children" and "One Life to Live" were briefly revived online in 2013, before being canceled again that same year.
Causes.
As women increasingly worked outside of the home, daytime television viewing declined. New generations of potential viewers were not raised watching soap operas with their mothers, leaving the shows' long and complex storylines foreign to younger audiences. Now, as viewers age, ratings continue to drop among young adult women, the demographic group that soap opera advertisers pay the most for. Those who might watch in workplace breakrooms are not counted, as Nielsen does not track television viewing outside the home. The rise of cable and the internet has also provided new sources of entertainment during the day. Part of the genre's decline has even been attributed to audiences' switching to reality television as an alternative source of melodrama.
Daytime programming alternatives such as talk shows, game shows, and court shows cost up to 50% less to produce than scripted dramas, making those formats more profitable and attractive to networks, even if they receive the same or slightly lower ratings than soap operas. A network may even prefer to return a timeslot to its local stations to keeping a soap opera with disappointing ratings on the air, as was the case with "Sunset Beach" and "Port Charles". Compounding the financial pressure on scripted programming in the period from 2007 to 2010 was a decline in advertising, a cause of the late 2000s-early 2010s global recession, which led shows to reduce their budgets and cast sizes.
In addition to the decline comes a shift in demographics. Hispanic viewership has increased as more soap operas began to appear on major Spanish network stations, such as Telemundo and Univision along with other Spanish network channels. Unlike some major network channels that only broadcast soap operas during the daytime it airs both daytime and primetime such as Telemundo. As American soap operas slowly declines some turn to Spanish-speaking soap operas despite the foreign language. However in recent years CC3 became a widely used for translating from Spanish to English thus gaining viewership in the Spanish soap opera, that trend will most likely continue.
The primetime serial.
Serials produced for primetime slots have also found success. The first real prime time soap opera was "Peyton Place" (1964–1969) on ABC. It was based in part on the eponymous 1957 film (which, in turn, was based on the 1956 novel).
The popularity of "Peyton Place" prompted the CBS network to spin-off popular "As the World Turns" character Lisa Miller into her own evening soap opera, "Our Private World" (originally titled "The Woman Lisa" in its planning stages). "Our Private World" was broadcast from May to September 1965. The character of Lisa returned to "As The World Turns" after the series ended.
The structure of "Peyton Place", with its episodic plots and long-running story arcs, set the mold for the primetime serials of the 1980s when the format reached its pinnacle.
The successful primetime serials of the 1980s included "Dallas", "Dynasty", "Knots Landing" and "Falcon Crest". These shows frequently dealt with wealthy families, and their personal and big-business travails. Common characteristics were sumptuous sets and costumes, complex storylines examining business schemes and intrigue, and spectacular disaster cliffhanger situations. Each of these series featured a wealthy, domineering, promiscuous, and passionate antagonist as a key character in the storyline – respectively, J. R. Ewing, Alexis Colby, Abby Cunningham and Angela Channing. These villainous schemers became immensely popular figures that audiences "loved to hate".
Unlike daytime serials, which are shot on video in a studio using the multi-camera setup, these evening series were shot on film using a single camera setup, and featured substantial location-shot footage, often in picturesque locales. "Dallas", its spin-off "Knots Landing", and "Falcon Crest" all initially featured episodes with self-contained stories and specific guest stars who appeared in just that episode. Each story was completely resolved by the end of the episode, and there were no end-of-episode cliffhangers. After the first couple of seasons, all three shows changed their story format to that of a pure soap opera, with interwoven ongoing narratives that ran over several episodes. "Dynasty" featured this format throughout its run.
The soap opera's distinctive open plot structure and complex continuity was increasingly incorporated into American primetime television programs of the period. The first significant drama series to do this was "Hill Street Blues". This series, produced by Steven Bochco, featured many elements borrowed from soap operas, such as an ensemble cast, multi-episode storylines, and extensive character development over the course of the series. It and the later "Cagney & Lacey" overlaid the police series formula with ongoing narratives exploring the personal lives and interpersonal relationships of the regular characters. The success of these series prompted other drama series, such as "St. Elsewhere" and situation comedy series, to incorporate serialized stories and story structure to varying degrees.
The primetime soap operas and drama series of the 1990s, such as "Beverly Hills, 90210", "Melrose Place" and "Dawson's Creek", focused more on younger characters. In the 2000s, ABC began to revitalize the primetime soap opera format with shows such as "Desperate Housewives", "Grey's Anatomy", "Brothers & Sisters", "Ugly Betty", "Private Practice", and more recently "Revenge", "Nashville", "Scandal", and formerly "Ringer", which its sister production company ABC Studios co-produced with CBS Television Studios for The CW. While not soaps in the traditional sense, these shows managed to appeal to wide audiences with their high drama mixed with humor, and are soap operas by definition. These successes led to NBC's launching serials, including "Heroes" and "Friday Night Lights". The upstart MyNetworkTV, a sister network of Fox, launched a line of primetime telenovelas (a genre similar to soap operas in terms of content) upon its launch in September 2006, but discontinued its use of the format in 2007, after disappointing ratings.
On June 13, 2012, a continuation of the 1980s soap opera, "Dallas", premiered on the cable network, TNT. The revived series (which entered its third season in 2014) has delivered solid ratings for the channel. In 2012, Nick at Nite debuted a primetime soap opera, "Hollywood Heights", which aired episodes five nights a week (on Monday through Fridays) in a manner similar to a daytime soap opera, instead of the once-a-week episode output common of other primetime soaps. The series, which was an adaptation of the Mexican telenovela "Alcanzar una estrella", suffered from low ratings (generally receiving less than one million viewers) and was later moved to sister cable channel TeenNick halfway through its run to burn off the remaining episodes.
In 2015, FOX debuted "Empire", a primetime musical soap opera centering on the power struggle between family members within the titular recording company. Created by Lee Daniels and Danny Strong and led by Oscar nominees Terrence Howard and Taraji P. Henson, the drama premiered to high ratings. The show is strongly influenced by other works such as William Shakespeare's "King Lear", James Goldman's "The Lion in Winter" and the 1980s soap opera "Dynasty".
Online serials.
Some web series are soap operas, such as "". In 2013, production company Prospect Park revived "All My Children" and "One Life to Live" for the web, retaining original creator Agnes Nixon as a consultant and keeping many of the same actors (Prospect Park purchased the rights to both series months after their cancellations by ABC in 2011, although it initially suspended plans to relaunch the soaps later that same year due to issues receiving approval from acting and production unions). Each show initially produced four half-hour episodes a week, but quickly cut back to two half-hour episodes each. In the midst of (though not directly related to) a lawsuit between Prospect Park and ABC, the experiment ended that same year, with both shows being canceled again.
United Kingdom.
In the United Kingdom, soap operas are one of the most popular genres, with most being broadcast during prime time. In comparison to U.S. serials which frequently portray romantic storylines in sumptuous and glamorous locales, most UK soap operas focus on more everyday, working-class communities.
The most popular soaps are "Coronation Street", "EastEnders", "Emmerdale", "Hollyoaks", "Doctors", and the Australian produced "Neighbours" and "Home and Away". The first three of these are consistently among the highest-rated shows on British television.
The 1986 Christmas Day episode of "EastEnders" is often referred to as the highest-rated UK soap opera episode ever, with 30.15 million viewers (in 2007, the UK had approximately 54 million television viewers). The figure of 30.15 million was actually a combination of the original broadcast which had just over 19 million viewers, and the Sunday omnibus edition with 10 million viewers. The combined 30.15 million audience figure often sees it attributed as the highest-rated program in UK television for the 1980s, comparable to the records set by the 1970 splashdown of Apollo 13 (28.6 million viewers) and Princess Diana's funeral in 1997 (32.1 million viewers).
"Coronation Street", "Emmerdale" and "EastEnders" are popularly known as the "flagship" soaps, as they are respectively the highest-rated programmes on ITV and the BBC. Poor ratings for a UK flagship serial sometimes brings with it questions about the associated channel. The soaps are so popular they are not routinely scheduled against each other. Episodes of serials have clashed only on isolated occasions when extended episodes have been broadcast.
Origins.
Soap operas in the UK began on radio and consequently were associated with the BBC. It had resisted soaps as antithetical to its quality image, but began broadcasting "Front Line Family" in April 1941 on its North American shortwave service to encourage American intervention on Britain's behalf in World War II. The BBC continues to broadcast the world's longest-running radio soap, "The Archers", which has been running nationally since 1951. It is currently broadcast on BBC Radio 4 and continues to attract over five million listeners, or roughly 25% of the radio listening population of the UK at that time of the evening.
An early television serial was "The Grove Family" on the BBC, which produced 148 episodes from 1954 to 1957. The programme was broadcast live and only a handful of recordings were retained in the archives. The UK's first twice-weekly serial was ITV's "Emergency - Ward 10", which was also the UK's first medical drama, running from 1957 until 1967. Although it was broadcast year-round, its status as a soap opera by today's standards is a subject of dispute.
In the 1960s "Coronation Street" revolutionised UK television and quickly became a British institution. The BBC also produced several serials: "Compact" was about the staff of a women's magazine; "The Newcomers" was about the upheaval caused by a large firm setting up a plant in a small town; "United!" contained 147 episodes and focused on a football team; "199 Park Lane" (1965) was an upper class serial, which ran for only 18 episodes. None of these serials came close to making the same impact as "Coronation Street". Indeed, most of the 1960s BBC serials were largely wiped.
During the 1960s, "Coronation Street"‍ '​s main rival was "Crossroads", a daily serial that began in 1964 and aired on ITV in the early evening. "Crossroads" was set in a Birmingham motel and, although the programme was popular, its purported low technical standard and bad acting were much mocked. By the 1980s, its ratings had begun to decline. Several attempts to revamp the programme through cast changes and, later, expanding the focus from the motel to the surrounding community were unsuccessful. "Crossroads" was cancelled in 1988 (a new version of "Crossroads" was later produced, running from 2001 until 2003).
A later rival to "Coronation Street" was ITV's "Emmerdale Farm" (later renamed "Emmerdale"), which began in 1972 in a daytime slot and was set in rural Yorkshire. Increased viewership resulted in "Emmerdale" being moved to a prime-time slot in the 1980s.
"Pobol y Cwm" ("People of the Valley") is a Welsh language serial that has been produced by the BBC since October 1974, and is the longest-running television soap opera produced by the broadcaster. "Pobol y Cwm" was originally broadcast on BBC Wales television from 1974 to 1982; it was then moved to the Welsh-language television station S4C when it opened in November 1982. The programme was occasionally shown on BBC1 in London during periods of regional optout in the mid- to late 1970s. "Pobol y Cwm" was briefly shown in the rest of the UK in 1994 on BBC2, with English subtitles; it is consistently the most watched programme each week on S4C.
The 1980s.
Daytime soap operas were non-existent until the 1970s because there was virtually no daytime television in the UK. ITV introduced "General Hospital", which later moved to a prime time slot, and Scottish Television had "Take the High Road", which lasted for over twenty years. Later, daytime slots were filled with an influx of older Australian soap operas such as "The Sullivans" (aired on ITV from 1977), "The Young Doctors" (from 1982), "Sons and Daughters" (from 1983), "A Country Practice" (from 1982), "Richmond Hill" (from 1988 to 1989) and eventually, "Neighbours" was acquired by the BBC in 1986, and "Home and Away" aired on ITV beginning in 1989. These achieved significant levels of popularity; "Neighbours" and "Home and Away" were moved to early-evening slots, helping begin the UK soap opera boom in the late 1980s.
The day Channel 4 began operations in 1982 it launched its own soap, the Liverpool-based "Brookside", which would redefine soaps over the next decade. The focus of "Brookside" was different from earlier soap operas in the UK; it was set in a middle-class new-build cul-de-sac, unlike "Coronation Street" and "Emmerdale Farm", which were set in established working-class communities. The characters in "Brookside" were generally either people who had advanced themselves from inner-city council estates, or the upper middle-class who had fallen on hard times. Though "Brookside" was still broadcast in a pre-watershed slot (8.00 p.m. and 8.30 p.m. on weekdays, around 5.00 p.m. for the omnibus on Saturdays), it was more liberal than other soaps of the time: the dialogue regularly included expletives. This stemmed from the overall more liberal policy of the channel during that period. The soap was also heavily politicised. Bobby Grant (Ricky Tomlinson), a militant trade-unionist anti-hero, was the most overtly political character. Storylines were often more sensationalist than on other soaps (throughout the soap's history, there were two armed sieges on the street) and were staged more graphically with violence (particularly, rape) often being featured.
In 1985, the BBC's London-based soap opera "EastEnders" debuted and became a near instant success with viewers and critics alike, with the first episode attracting over 17 million viewers. The Christmas Day 1986 episode was watched by 30.15 million viewers and contained a scene in which divorce papers were served to Angie Watts by her husband Den. Critics talked about the downfall of "Coronation Street", but the programme continued to perform successfully. In 1994, when the two serials were scheduled opposite each other, "Coronation Street" won the slot. For the better part of ten years, "EastEnders" has shared the number one position with "Coronation Street", with varying degrees of difference between the two.
A notable success in pioneering late-night broadcasting, in October 1984, Yorkshire Television began airing the cult Australian soap opera "Prisoner", which originally ran from 1979 to 1986. It was eventually broadcast on all regions of the UK in differing slots, usually around 23:00 (but never before 22:30 in any region), under the title "Prisoner: Cell Block H". It was probably most popular in the Midlands where Central Television consistently broadcast the serial three times a week from 1987 to 1991. Its airing in the UK was staggered, so different regions of the country saw it at a different pace. The programme was immensely successful, regularly achieving 10 million viewers when all regions' ratings per episode were added together. Central bowed to fan pressure to repeat the soap, of which the first 95 episodes aired. Then, rival station Channel 5 also acquired rights to repeat the entire rerun of the programme, starting in 1997. All 692 episodes have since been released on DVD in the UK.
The 1990s.
In 1992, the BBC debuted "Eldorado" to alternate with "EastEnders". The programme was heavily criticised and only lasted one year. Nevertheless soap operas gained increasing prominence on UK television schedules. In 1995, Channel 4 premiered "Hollyoaks", a soap with a youth focus. When Channel 5 launched in March 1997, it debuted the soap opera "Family Affairs", which was formatted as a weekdaily soap, airing Monday through Fridays.
"Brookside"‍ '​s premise evolved during the 1990s, phasing out the politicised stories of the 1980s and shifting the emphasis to controversial and sensationalist stories such as child rape, sibling incest, religious cults and drug addiction, including the infamous 'body under the patio' storyline which ran from 1993 to 1995, and gave the serial its highest ratings ever with 9 million viewers.
"Coronation Street" and "Brookside" began releasing straight-to-video features. The "Coronation Street" releases generally kept the pace and style of conventional programmes episodes with the action set in foreign locations. The "Brookside" releases were set in the programme's usual location, but featured stories with adult content not allowed on television pre-watershed, with these releases given '18' certificates.
A retooling of "Emmerdale Farm" led to the "Farm" being dropped from the programme's title in 1989. In 1993, many of the changes where executed via a plane crash that partially destroyed the village and killed several characters. This attracted criticism as it was broadcast near the fifth anniversary of the Lockerbie bombing. The storyline drew the soap its highest ever viewership at 18 million viewers, and helped massively with the revamp of the programme which became a success and helped grow "Emmerdale"‍ '​s in popularity.
Throughout the 1990s, "Brookside", "Coronation Street", "EastEnders" and "Emmerdale" continued to flourish. Each increased the number of episodes that aired on a weekly basis by at least one, further defining soap operas as the leading genre in British television.
The 2000s.
Since 2000, new soap operas have continued to be developed. Daytime drama "Doctors" began in March 2000, preceding "Neighbours" on BBC1. In 2002, as ratings for the Scottish serial "High Road" (formerly "Take The High Road") continued to decline, BBC Scotland launched "River City", which proved popular and effectively replaced "High Road" when it was cancelled in 2003. The long-running serial "Brookside" ended in November 2003 after 21 years on the air, leaving "Hollyoaks" as Channel 4's flagship serial.
A new version of "Crossroads" featuring a mostly new cast was produced by Carlton Television for ITV in 2001. It did not achieve high ratings and was cancelled in 2003. In 2001, ITV also launched a new early-evening serial entitled "Night and Day". This programme too attracted low viewership and, after being shifted to a late night time slot, was cancelled in 2003. "Family Affairs", which was broadcast opposite the racier "Hollyoaks", never achieved significantly high ratings leading to several dramatic casting revamps and marked changes in style and even location over its run. By 2004, "Family Affairs" had a larger fan base and won its first awards, but was cancelled in late 2005.
In 2008, ITV premiered "The Royal Today", a daily spin-off of popular 1960s drama "The Royal", which had been running in a primetime slot since 2002. Just days later, soap opera parody programmes "Echo Beach" premiered alongside its sister show, the comedy "Moving Wallpaper". Both "Echo Beach" and "The Royal Today" ended after just one series due to low ratings. Radio soap opera "Silver Street" debuted on the BBC Asian Network in 2004. Poor ratings and criticism of the programme led to its cancellation in 2010.
Format.
UK soap operas for many years usually only aired two nights a week. The exception was the original "Crossroads" which began as a weekdaily soap opera in the 1960s, but later had its number of weekly broadcasts reduced. Things started to change in 1989 when "Coronation Street" began airing three times a week. In 1996, it expanded again, to air four episodes a week. "Brookside" premiered in 1982 with two episodes a week. In 1990, it expanded to three episodes a week; the trend was followed by "EastEnders" in 1994 and "Emmerdale" in 1997. "Family Affairs" debuted as a weekdaily soap in 1997, producing five episodes a week throughout its entire run. The imported "Neighbours" screens as five new episodes a week, which are shown once at 1:45 p.m. and repeated at 5:30 p.m. on Channel 5 each weekday.
Currently, "Coronation Street" (which began airing two episodes on Monday nights in 2002) and "Hollyoaks" both produce five episodes a week, while "EastEnders" produces four each week. In 2002, "Brookside" expanded from three half-hour episodes on different weeknights to airing one 90-minute episode each week. In 2004, "Emmerdale" began airing six episodes a week. "Doctors" airs five episodes a week, and is the only soap without a weekend omnibus repeat screening.
Due to a January 2008 overhaul of the ITV network, the Sunday episodes of "Coronation Street" and "Emmerdale" were moved out of their slots. "Coronation Street" added a second episode on Friday evenings at 8:30 p.m. "Emmerdale"‍ '​s Tuesday edition was extended to an hour, putting it in direct competition with rival "EastEnders".
In July 2009, the schedules of these serials were changed again. On 23 July 2009, "Coronation Street" moved from the Wednesday slot it held for 49 years, to Thursday evenings. "Emmerdale" reverted to running just one 30-minute episode on Tuesday evenings and the other 30-minute installment was moved to Thursday evenings.
UK soap operas are shot on videotape in the studio using a multi-camera setup. Since the 1980s, these programmes routinely feature scenes shot outdoors in each episode. This footage is shot on videotape on a purpose-built outdoor set that represents the community that the soap focuses on. During their early years, "Coronation Street" and "Emmerdale" used 16 mm film while scenes were shot on location. Later soap operas such as "Hollyoaks" and "Family Affairs", started filming on high-definition video, a more modern filming process, as opposed to standard videotape, which features better quality and appears to look more like film than videotape.
UK soap operas do not incorporate recap sequences at the beginning of each episode, which would be appropriate for the fact that when an episode ends, it picks up the story during the following episode. However, in 2012, "Hollyoaks" began airing a recap sequence at the beginning of each episode. Soap operas in the UK also lack incidental music (apart from "Hollyoaks"), although "Eastenders" would sometimes feature music which plays over an ending scene if it was dramatic, with an alternative "Eastenders" theme known as "Julia's theme".
Australia.
Australia has had quite a number of well-known soap operas, some of which have gained cult followings in the UK, New Zealand and other countries. The majority of Australian television soap operas are produced for early evening or evening timeslots. They usually produce two or two-and-a-half hours of new material each week, either arranged as four or five half-hour episodes a week, or as two one-hour episodes. Stylistically, these series most closely resemble UK soap operas in that they are nearly always shot on videotape, are mainly recorded in a studio and use a multi-camera setup. The original Australian serials were shot entirely in-studio. During the 1970s occasional filmed inserts were used to incorporate sequences shot outdoors. Outdoor shooting later became commonplace and starting in the late 1970s, it became standard practice for some on-location footage to be featured in each episode of any Australian soap opera, often to capitalise on the attractiveness and exotic nature of these locations for international audiences. Most Australian soap operas focus on a mixed age range of middle-class characters and will regularly feature a range of locations where the various, disparate characters can meet and interact, such as the café, the surf club, the wine bar or the school.
Early serials.
The genre began in Australia, as in other countries, on radio. One such radio serial, "Big Sister", featured actress Thelma Scott in the cast and aired nationally for five years beginning in 1942. Probably the best known Australian radio serial was the long-running Gwen Meredith soap opera "Blue Hills" which ran from 1949 to 1976. With the advent of Australian television in 1956, daytime television serials followed. The first Australian television soap opera "Autumn Affair" (1958), with radio personality and "Blue Hills" star Queenie Ashton making the transition to television. Each episode of this serial ran for 15 minutes and aired each weekday on the Seven Network. The series failed to secure a sponsor and ended in 1959 after 156 episodes. This was followed by "The Story of Peter Grey" (1961), another Seven Network weekday series which aired in a daytime slot, with each episode running for 15 minutes; "The Story of Peter Grey" ran for 164 episodes.
The first successful wave of Australian evening soap operas started in 1967 with "Bellbird", produced by the Australian Broadcasting Corporation. This rural-based serial screened in an early evening slot in 15-minute installments as a lead-in to the evening news. "Bellbird" was a moderate success but built-up a consistent and loyal viewer base, especially in rural areas, and enjoyed a ten-year run. "Motel" (1968) was Australia's first half-hour soap opera; the daytime soap had a short run of 132 episodes.
The 1970s.
The first major soap opera hit in Australia was the sex-melodrama "Number 96", a nighttime series produced by Cash Harmon Television for Network Ten, which debuted March 1972. The program dealt with such topics as homosexuality, adultery, drug use, rape-within-marriage and racism which had rarely been explored on Australian television programs before. The series became famous for its sex scenes and nudity and for its comedic characters, many of whom became cult heroes in Australia. By 1973, "Number 96" had become Australia's highest-rated show. In 1974, the sexed-up antics of "Number 96" prompted the creation of "The Box", which rivaled it in terms of nudity and sexual situations and was scheduled in a nighttime slot. Produced by Crawford Productions, many critics considered "The Box" to be a more slickly produced and better written show than "Number 96". "The Box" also aired on the Ten Network, programmed to run right after "Number 96". For 1974 "Number 96" was again the highest rating show on Australian television, and that year "The Box" occupied the number two spot.
Also in 1974, the Reg Grundy Organisation created its first soap opera, and significantly Australia's first "teen" soap opera, "Class of '74". With its attempts to hint at the sex and sin shown more openly on "Number 96" and "The Box", its high school setting and early evening timeslot, "Class of '74" came under intense scrutiny from the Broadcasting Control Board, who vetted scripts and altered entire storylines.
By 1975, both "Number 96" and "The Box", perhaps as a reaction to declining ratings for both shows, de-emphasised the sex and nudity shifting more towards comedic plots. "Class of '74" was renamed "Class of '75" and also added more slapstick comedy for its second year, but the revamped show's ratings declined, resulting in its cancellation in mid-1975. That year Cash Harmon's newly launched second soap "The Unisexers" failed in its early evening slot and was cancelled after three weeks; the Reg Grundy Organisation's second soap "Until Tomorrow" ran in a daytime slot for 180 episodes.
A feature film version of "Bellbird" entitled "Country Town" was produced in 1971 by two of the show's stars, Gary Gray and Terry McDermott, without production involvement by the Australian Broadcasting Corporation. "Number 96" and "The Box" also released feature film versions, both of which had the same title as the series, released in 1974 and 1975 respectively. As Australian television had broadcast in black and white until 1975, these theatrical releases all had the novelty of being in colour. The film versions of "Number 96" and "The Box" also allowed more explicit nudity than could be shown on television at that time.
In November 1976 "The Young Doctors" debuted on the Nine Network. This Grundy Organization series eschewed the adult drama of "Number 96" and "The Box", focusing more on relationship drama and romance. It became a popular success but received few critical accolades. A week later "The Sullivans", a carefully-produced period serial chronicling the effects of World War II on a Melbourne family, also debuted on Nine. Produced by Crawford Productions, "The Sullivans" became a ratings success, attracted many positive reviews, and won television awards. During this period "Number 96" re-introduced nudity into its episodes, with several much-publicised full-frontal nude scenes, a cast revamp and a new range of shock storylines designed to boost the show's declining ratings. "Bellbird" experienced changes to its broadcast pattern with episodes screening in 60 minute blocks, and later in 30 minute installments.
"Bellbird", "Number 96" and "The Box", which had been experiencing declining ratings, were cancelled in 1977. Various attempts to revamp each of the shows with cast reshuffles or spectacular disaster storylines had proved only temporarily successful. "The Young Doctors" and "The Sullivans" continued to be popular. November 1977 saw the launch of successful soap opera/police procedural series "Cop Shop" (1977–1984) produced by Crawford Productions for Channel Seven. In early December 1977 Channel Ten debuted the Reg Grundy Organisation produced "The Restless Years" (1977–1981), a more standard soap drama focusing on several young school leavers.
The Seven Network, achieving success with "Cop Shop" produced by Crawford Productions, had Crawfords produce "Skyways", a series with a similar format but set in an airport, to compete with the Nine Network's popular talk show "The Don Lane Show". "Skyways", which debuted in July 1979, emphasised adult situations including homosexuality, marriage problems, adultery, prostitution, drug use and smuggling, crime, suicide, political intrigue, and murder, and featured some nudity. Despite this, the program achieved only moderate ratings and was cancelled in mid-1981.
The 1980s.
The Reg Grundy Organisation found major success with the women's-prison drama "Prisoner" (1979–1986) on Network Ten, and melodramatic family saga "Sons and Daughters" (1982–1987) on the Seven Network. Both shows achieved high ratings in their original runs, and unusually, found success in repeats after the programs ended.
Grundy soap "The Young Doctors" and Crawford Productions' "The Sullivans" continued on the Nine Network until late 1982. Thereafter Nine attempted many new replacement soap operas produced by the Reg Grundy Organisation: "Taurus Rising" (1982), "Waterloo Station" (1983), "Starting Out" (1983) and "Possession" (1985), along with "Prime Time" (1986) produced by Crawford Productions. None of these programs were successful and most were cancelled after only a few months. The Reg Grundy Organisation also created "Neighbours", a suburban-based daily serial devised as a sedate family drama with some comedic and lightweight situations, for the Seven Network in 1985.
Produced in Melbourne at the studios of HSV-7, "Neighbours" achieved high ratings in Melbourne, Brisbane and Adelaide, but not in Sydney, where it aired at 5.30 p.m. placing it against the hit dating game show "Perfect Match" on Channel 10. The Seven Network's Sydney station ATN-7 quickly lost interest in "Neighbours" as a result of the low ratings in Sydney. HSV-7 in Melbourne lobbied heavily to keep "Neighbours" on the air, but ATN-7 managed to convince the rest of the network to cancel the show and instead keep ATN-7's own Sydney-based dramas "A Country Practice" and "Sons and Daughters".
After the network cancelled "Neighbours", it was immediately picked up by Channel Ten, which revamped the cast and scripts slightly and aired the series in the 7.00 p.m. slot starting 20 January 1986. It initially attracted low audiences, however after a concerted publicity drive, Ten managed to transform the series into a major success, turning several of its actors into major international stars. The show's popularity eventually declined and it was moved to the 6.30 p.m. slot in 1992. As of 2015 the series airs on Eleven and is Australia's longest-running soap opera.
The success of "Neighbours" in the 1980s prompted the creation of somewhat similar suburban and family or teen-oriented soap operas such as "Home and Away" (1988–present) on Channel Seven and "Richmond Hill" (1988) on Channel Ten. Both proved popular, however "Richmond Hill" emerged as only a moderate success and was cancelled after one year to be replaced on Ten by "E Street" (1989–1993).
Nine continued trying to establish a successful new soap opera, without success. After the failure of family drama "Family and Friends" in 1990, it launched the raunchier and more extreme "Chances" in 1991, which resurrected the sex and melodrama of "Number 96" and "The Box" in an attempt to attract attention. "Chances" achieved only moderate ratings, and was moved to a late-night timeslot. It underwent several revamps that removed much of the original cast, and refocused the storylines to incorporate science-fiction and fantasy elements. The series continued in a late night slot until 1992, when it was cancelled due to low ratings despite the much-discussed fantasy storylines.
Australian soaps internationally.
Several Australian soap operas have also found significant international success. In the UK, starting in the mid-1980s, daytime broadcasts of "The Young Doctors", "The Sullivans", "Sons and Daughters" and "Neighbours" (which itself was subsequently moved to an early-evening slot) achieved significant success. Grundy's "Prisoner" began airing in the United States in 1979 and achieved high ratings in many regions there, however the show ended its run in that country three years into its run. "Prisoner" also aired in late-night timeslots in the UK beginning in the late 1980s, achieving enduring cult success there. The show became so popular in that country that it prompted the creation of two stage plays and a stage musical based on the show, all of which toured the UK, among many other spin-offs. In the late 1990s, Channel 5 repeated "Prisoner" in the UK. Between 1998 and 2005, Channel 5 ran late-night repeats of "Sons and Daughters". During the 1980s, the Australian attempts to emulate big-budget U.S. soap operas such as "Dallas" and "Dynasty" had resulted in the debuts of "Taurus Rising" and "Return to Eden", two slick soap opera dramas with big budgets that were shot entirely on film. Though their middling Australian ratings resulted in the shows running only for a single season, both programs were successfully sold internationally.
Other shows to achieve varying levels of international success include "Richmond Hill", "E Street", "Paradise Beach" (1993–1994), and "Pacific Drive" (1995–1997). Indeed these last two series were designed specifically for international distribution. Channel Seven's "Home and Away", a teen soap developed as a rival to "Neighbours", has also achieved significant and enduring success on UK television.
Teen-oriented serials to the world.
Since 1990, most new Australian serials have been based on the successful "Neighbours" formula of foregrounding youthful attractive casts in appealing locations. An exception to this was the Australian Broadcasting Corporation-produced "Something in the Air", a serial examining a range of characters in a small country town; this series ran from 2000 to 2002.
Attempts to replicate the success of daily teen-oriented serials "Neighbours" and "Home and Away" saw the creation of "Echo Point" (1995) and "Breakers" (1999) on Network Ten. None of these programs emerged as long-running successes and "Neighbours" and "Home and Away" remained the most visible and consistently successful Australian soap operas in production. In their home country, they both attract respectable although not spectacular ratings. By 2004, "Neighbours" was regularly attracting just under a million viewers per episode – a low figure for Australian prime time television. By March 2007, Australian viewership for "Neighbours" had fallen to fewer than 700,000 a night, prompting a revamp of the show's cast and visual presentation, and a de-emphasis on the action-oriented direction that the series had moved in to refocus the show on the family storylines that it is traditionally known for. However, "Neighbours" and "Home and Away" both continue to achieve significant ratings in the UK. This and other lucrative overseas markets, along with Australian broadcasting laws that enforce a minimum amount of domestic drama production on commercial television networks, help ensure that both programs remain in production. Both shows get higher total ratings in the UK than in Australia (the UK has three times the total population of Australia) and the UK channels make a major contribution to the production costs.
It has been suggested that with their emphasis on the younger, attractive and charismatic characters, "Neighbours" and "Home and Away" have found success in the middle ground between glamorous, fantastic U.S. soaps with their wealthy but tragic heroes and the more grim, naturalistic UK soap operas populated by older, unglamorous characters. The casts of "Neighbours" and "Home and Away" are predominantly younger and more attractive than the casts of UK soaps, and without excessive wealth and glamour of the U.S. daytime serial, a middle-ground in which they have found their lucrative niche.
"Neighbours" was carried in the United States on the Oxygen cable channel in March 2004; however it attracted few viewers, perhaps in part due to its scheduling opposite well-established and highly popular U.S. soap operas such as "All My Children" and "The Young and the Restless", and was dropped by the network shortly afterwards due to low ratings.
"headLand" made its debut on Channel Seven in November 2005, the series arose out of a proposed spinoff of "Home and Away" that was to have been produced in conjunction with "Home and Away"‍ '​s UK broadcaster, Five. The idea for the spin-off was scuttled after Five pulled out of the deal, which meant that the show could potentially air on a rival channel in the UK; as such, Five requested that the new show be developed as a standalone series and not be spun off from a series that it owned a stake in. The series premiered in Australia on November 15, 2005, but was not a ratings success and was cancelled two months later on January 23, 2006. The series broadcast on E4 and Channel 4 in the UK.
After losing the UK television rights to "Neighbours" to Five, the BBC commissioned a new serial "Out of the Blue", which was produced in Australia, as its replacement. It debuted as part of BBC One's weekday afternoon schedule on April 28, 2008 but due to viewership that was lower than desired, it was moved to BBC Two on May 19, 2008. The series was cancelled after its first season.
"Neighbours"' continued low ratings in Australia resulted in it being moved to Ten's new digital channel, Eleven on January 11, 2011. However, it continues to achieve reasonable ratings on Channel Five in the United Kingdom, and as of March 2013 still reportedly achieved significant international sales.
New Zealand.
Television.
Pioneering series "" aired over two years (1971–72) and was the NZBC's first continuing drama. It followed the goings-on of a North Island timber town.
"Close to Home" is a New Zealand television soap opera which ran on Television One (Formally NZBC, later becoming Television New Zealand) from 1975 to 1983. At its peak in 1977 nearly one million viewers tuned in twice weekly to watch the series co-created by Michael Noonan and Tony Isaac (who had initially only agreed to make the show on the condition they would get to make "The Governor"). "Gloss" is a television drama series that screened from 1987 to 1990. The series is about a fictional publishing empire run by the Redfern family. Gloss was NZ's answer to US soap "Dynasty", with the Carrington oil scions replaced by the wealthy Redferns and their Auckland magazine empire. It was a starting point for many actors who went on to many productions in New Zealand, Australia and around the world including Temuera Morrison, Miranda Harcourt, Peter Elliott, Lisa Chappell, Danielle Cormack and Kevin Smith. Many of them would go on to star in "Shortland Street" which has been New Zealand's most popular soap since its debut in 1992. It airs on TVNZ 2.
Radio.
Radio New Zealand began airing its first radio soap "You Me Now" in September 2010. It is available for podcast on its website.
Canada.
Relatively few daily soap operas have been produced on English Canadian television, with most Canadian stations and networks that carry soap operas airing those imported from the United States or the United Kingdom. Notable daily soaps that did exist included "Family Passions", "Scarlett Hill", "Strange Paradise", "Metropia", "Train 48" and the international co-production "Foreign Affairs". "Family Passions" was an hour-long program, as is typical of American daytime soaps; all of the others ran half-hour episodes. Unlike American or British soap operas, the most influential of which have run for years or even decades, even daily Canadian soap operas have run for a few seasons at most. Short-run soaps, including "49th & Main" and "North/South", have also aired. Many of these were produced in an effort to comply with Canadian content regulations, which require a percentage of programming on Canadian television to originate from Canada.
Notable prime time soap operas in Canada have included "Riverdale", "House of Pride", "Paradise Falls", "Lance et Compte" ("He Shoots, He Scores"), "Loving Friends and Perfect Couples" and "The City". The "Degrassi" franchise of youth dramas also incorporated some elements of the soap opera format.
On French-language television in Quebec, the "téléroman" has been a popular mainstay of network programming since the 1950s. Notable téléromans have included "Rue des Pignons", "Les Belles Histoires des pays d'en haut", "Diva", "La famille Plouffe", and the soap opera parody "Le Cœur a ses raisons".
India.
India has produced many soap operas. These started in the late 1980s, as more and more people began to purchase television sets. At the beginning of the 21st century, soap operas became an integral part of Indian culture. Indian soap operas mostly concentrate on the conflict between love and arranged marriages occurring in India, and many include conflicts between mothers-in-law and daughters-in-law. Indian serials are produced in the Hindi, Tamil, Punjabi, Marathi, Gujarati, Bengali, Kannada, Telugu, and Malayalam languages.
Many soap operas produced in India are also broadcast overseas in the UK, the United States, and some parts of Europe, South Africa and Australia. They are often mass-produced under large production banners, with companies like Balaji Telefilms running different language versions of the same serial on different television networks or channels.
Europe.
Remakes of Australian serials.
The Australian serial "The Restless Years" was remade in the Netherlands as "Goede tijden, slechte tijden" (which debuted in 1990) and in Germany as "Gute Zeiten, schlechte Zeiten" (which has aired since 1992): both titles translate to "good times, bad times". These remakes still airing, although they have long since diverged from the original Australian storylines. The two shows are the highest-rated soap operas in their respective countries.
A later Australian serial, "Sons and Daughters", has inspired five remakes produced under license from the original producers and based, initially, on original story and character outlines. These are "Verbotene Liebe" (Germany, 1995–present); "Skilda världar" (Sweden, 1996–2002); "Apagorevmeni agapi" (Greece, 1998); "Cuori Rubati" (Italy, 2002–2003) and "Zabranjena ljubav" (Croatia, 2004–2008). Both "The Restless Years" and "Sons and Daughters" were created and produced in Australia by the Reg Grundy Organisation.
Norway.
The Norwegian soap opera "Hotel Cæsar" has aired on TV 2 since 1998, and is the longest-running television drama in Scandinavia. Popular foreign soaps in the country include "Days of Our Lives" (broadcast on TV6), "The Bold and the Beautiful" (TNT) and "Home and Away" (TV 2), all of which are subtitled.
Netherlands.
Serials have included "Goede tijden, slechte tijden" (1990–present), "ONM" (1994–2010) and "Goudkust" (1996–2001). U.S. daytime serials "As The World Turns" and "The Bold and the Beautiful" have aired in the Netherlands; "As the World Turns" began airing in the country in 1990, with Dutch subtitles.
Germany.
In the 1980s, German networks successfully added American daytime and primetime soap operas to their schedule before Das Erste introduced its first self-produced weekly soap with "Lindenstraße", which was seen as a German counterpart to "Coronation Street". Like in other countries, the soap opera met with negative reviews, but eventually proved critics wrong with nearly 13 million viewers tuning in each week. Even though the format proved successful, it was not until 1992 before "Gute Zeiten, schlechte Zeiten" became the first German daily soap opera. Early ratings were bad as were the reviews, but the RTL network was willing to give its first soap opera a chance; ratings would improve, climbing to 7 million viewers by 2002. Not long after "Gute Zeiten, schlechte Zeiten", Das Erste introduced "Marienhof", which aired twice a week.
After successfully creating the first German daily soap, production company Grundy Ufa wanted to produce another soap for RTL. Like "GZSZ", the format was based on an Australian soap opera from Reg Watson. But RTL did not like the plot idea about separated twins who meet each other for the first time after 20 years and fall in love without knowing that they are related. The project was then taken to Das Erste, which commissioned the program, titled "Verbotene Liebe", which premiered on January 2, 1995. With the premiere of "Verbotene Liebe", the network turned "Marienhof" into a daily soap as well. In the meanwhile, RTL debuted the Grundy Ufa-produced "Unter uns" in late 1994.
ZDF started a business venture with Canada and co-produced the short-lived series "Family Passions", starring actors such as Gordon Thomson, Roscoe Born, Dietmar Schönherr and a young Hayden Christensen. The daytime serial premiered on December 5, 1994, lasting 130 episodes. After its cancellation, the network debuted "Jede Menge Leben". Even after a crossover with three soaps, "Freunde fürs Leben", "Forsthaus Falkenau" and "Unser Lehrer Doktor Specht", the soap was canceled after 313 episodes. Sat.1 tried to get into the soap business as well, after successfully airing the Australian soap opera "Neighbours", which was dropped in 1995 due to the talk show phenomenon which took over most of the daytime schedules of German networks. The network first tried to tell a family saga with "So ist das Leben – die Wagenfelds", before failing with "Geliebte Schwestern". RTL II made its own short-lived attempt with "Alle zusammen - jeder für sich".
The teen soap opera "Schloss Einstein" debuted on September 4, 1998, focusing on the life of a group of teenagers at the fictional titular boarding school near Berlin. As of July 2014, the series has produced over 815 episodes during the course of 17 seasons, a milestone in German television programming, and was renewed for an 18th season to debut in 2015.
In 1999, after the lasting success of "Gute Zeiten, schlechte Zeiten", "Marienhof", "Unter uns" and "Verbotene Liebe", ProSieben aired "Mallorca – Suche nach dem Paradies", set on the Spanish island with the same name. After nine months, the network canceled the program due to low viewership and high production costs. Even though ratings had improved, the show ended its run in a morning timeslot. The soap opera became something of a cult classic, as its 200-episode run was repeated several times on free-to-air and pay television.
In 2006, "Alles was zählt" became the last successful daily soap to make its debut, airing as a lead-in to "Gute Zeiten, schlechte Zeiten" and also produced by Grundy Ufa. Since Germany started to produce its own telenovelas, all soap operas faced declines in ratings. "Unter uns" was in danger of cancellation in 2009, but escaped such a fate due to budget cuts imposed by the show's producers and the firing of original cast member Holger Franke, whose firing and the death of his character outraged fans, resulting in a ratings spike in early 2010. After "Unter uns" was saved, Das Erste planned to make changes to its soap lineup. "Marienhof" had to deal with multiple issues in its storytelling, as well as in producing a successful half-hour show. Several changes were made within months, however "Marienhof" was canceled in June 2011. "Verbotene Liebe" was in danger of being canceled as well, but convinced the network to renew it with changes that it made in both 2010 and 2011; the soap was later expanded to an hour after "Marienhof" was canceled, and the network tried to decide on whether to revamp its lineup.
While "Gute Zeiten, schlechte Zeiten", "Unter uns", "Verbotene Liebe" and "Alles was zählt" are currently the only daily soaps on the air, the telenovelas "Sturm der Liebe" and "Rote Rosen" are considered soaps by the press as well, thanks to the changing protagonists every season.
Belgium.
In Belgium, the two major soap operas are "Thuis" ("Home") and "Familie" ("Family"). Soap operas have been very popular in Flanders, the Dutch-speaking part of Belgium. "Familie" debuted in late 1991, and with nearly 5,000 half-hour episodes, it has the highest episode total of any soap in Europe. The highest-rated soap opera is "Thuis", which ahs aired on "één" since late 1995. "Thuis" is often one of the five most-watched Belgian shows and regularly garners over one million viewers (with 6.3 million Flemmings in total).
During the 1990s, foreign soap operas such as "Neighbours" and "The Bold and the Beautiful" were extremely popular, the latter having achieved a cult status in Belgium and airing in the middle of the decade during prime time. Both soaps still air today, along with other foreign soaps such as "Days of Our Lives", Australia's "Home and Away" and Germany's "Sturm der Liebe". Vitaya unsuccessful attempted to air the Dutch soap opera "Goede Tijden, Slechte Tijden" in 2010. Other foreign soaps that previously aired on Belgian television include "The Young and the Restless", "EastEnders" (both on VTM), "Port Charles" (at één, then known as TV1) and "Coronation Street" (on Vitaya). "Santa Barbara" aired during the 1990s on VTM for its entire run.
The only teen soap opera on Belgian television was "Spring" ("Jump" in English), which aired on the youth-oriented Ketnet and produced over 600 15-minute episodes from late 2002 until 2009, when it was cancelled after a steady decline in ratings following the departures of many of its original characters.
Italy.
The most successful soap operas in Italy are the evening series "Un posto al sole" ("A Place Under the Sun"), which had aired on Rai 3 since 1996 whose format is based on Aussie's soap Neighbours and the daytime series "Centovetrine" ("Hundred Shop Windows"), which debuted in 2001 on Canale 5. Several other Italian soaps have been produced such as "Ricominciare" ("Starting Over"), "Cuori rubati" ("Stolen Hearts"), "Vivere" ("Living"), "Sottocasa" ("Downstairs") and "Agrodolce" ("Bittersweet").
The most popular Italian prime-time drama series, "Incantesimo" ("Enchantment"), which ran from 1998 to 2008, became a daytime soap opera for the final two years of its run, airing five days a week on Rai 1.
Ireland.
Television.
In the early years of RTÉ, the network produced several dramas but had not come close to launching a long-running serial. RTÉ's first television soap was "Tolka Row", which was set in urban Dublin. For several years, both "Tolka Row" and "The Riordans" were produced by RTÉ; however, the urban soap was soon dropped in favor of the more popular rural soap opera "The Riordans", which premiered in 1965. Executives from Yorkshire Television visited during on-location shoots for "The Riordans" in the early 1970s and in 1972, debuted "Emmerdale Farm" (now "Emmerdale"), based on the successful format of the Irish soap opera. In the late 1970s, "The Riordans" was controversially dropped. The creator of that series would then go on to produce the second of his "Agri-soap" trilogy "Bracken", starring Gabriel Byrne, whose character had appeared in the last few seasons of "The Riordans". "Braken" was soon replaced by the third "Agri-soap" "Glenroe", which ran until 2001. As RTÉ wanted a drama series for its Sunday night lineup rather than a soap opera, "On Home Ground" (2001–2002), "The Clinic" (2002–2009) and "RAW" (2010–2013) replaced the agri-soaps of the previous decades.
In 1989, RTÉ decided to produce its first Dublin-based soap opera since the 1960s. "Fair City", which is set in the fictional city of Carrickstown, initially aired one night a week during the 1989-90 season, and similar to its rural soaps, much of the footage was filmed on location – in a suburb of Dublin City. In 1992, RTÉ made a major investment into the series by copying the houses used in the on-location shoots for an on-site set in RTÉ's Headquarters in Dublin 4. By the early 1990s, it was airing two nights a week for 35 weeks a year. With competition from the UK soap operas, RTÉ expanded "Fair City" to three nights a week for most of the year and one night a week during the summer in 1996, later expanding to four nights a week and two nights during the summer. Until the early 2000s, the series produced four episodes a week, airing all 52 weeks of the year. "Fair City" airs Sundays, Tuesdays and Thursdays at 8.00 p.m. GMT on RTÉ One; however, after rival network TV3 moved "Coronation Street" to Thursday night, the Wednesday night episode of "Fair City" began airing at 7:30 p.m. each week.
TG4 produce the Irish language soap "Ros na Rún" ("Headland of the Secrets" or "Headland of the Sweethearts"); set in the fictional village of "Ros Na Rún", located outside Galway and near Spiddal, it centres on the domestic and professional lives of the town's residents. It is modeled on an average village in the West of Ireland, but with its own distinct personality – with a diverse population that share secrets, romances and friendships among other things. While the core community has remained the same, the look and feel of "Ros Na Rún" has changed and evolved over the years to incorporate the changing face of rural Ireland. It has an established a place not only in the hearts and minds of the Irish speaking public, but also the wider Irish audience. The programe has dealt with many topics, including domestic violence, infidelity, theft, arson, abortion, homosexuality, adoption, murder, rape, drugs, teen pregnancy and paedophilia. It runs twice a week for 35 weeks of the year, currently airing Tuesday and Thursday nights. "Ros na Rún" is the single largest independent production commissioned in the history of Irish broadcasting. Prior to TG4's launch, it originally aired on RTÉ One in the early 1990s.
Although Ireland has access to international soaps (such as "Coronation Street", "Emmerdale", "EastEnders", "Home and Away", "Hollyoaks" and "Neighbours"), "Fair City" continues to outperform them all, and is Ireland's most popular soap opera, with the show peaking at over 700,000 viewers.
January 2015 "Red Rock" has broadcast on TV3. Red Rock airs twice a week on Wednesday and Thursday nights. The series is base in a fishing village in Dublin. The soaps centres around the local Garda station but also includes stories from the village.
Radio.
RTÉ Radio produced its first radio soap, "Kennedys of Castleross", which ran from April 13, 1955 to 1975. In 1979 RTÉ long running TV soap The Riordans moved to Radio until December 24, 1985. In the mid-1980s, RTÉ debuted a new radio soap, "Harbour Hotel", which ran until the mid-1990s. The network later ran two short-lived radio soaps, "Konvenience Korner" and "Riverrun", which were followed in 2004 by "Driftwood". RTÉ does not run any radio soaps, however RTÉ Radio 1 continues to air radio dramas as part of its nighttime schedule.
France.
France had no real tradition of running daytime dramas; however in 2004, the primetime soap "Plus belle la vie" premiered on public television network France 3. After initially suffering from poor ratings, the show became a huge success and is one of the highest-rated series on the network. Other attempts were made by competitors to create soaps (including "Seconde Chance", "Cinq soeurs" and "Paris 16ème"), but none have achieved much success.
Greece.
In Greece, there have been several soap operas.
ANT1.
An early serial was "Sti skia tou hrimatos" ("Money Shadows"), which ran from 1990 to 1991. September 1991 saw the debut of "Lampsi" ("the Shining"), from creator Nicos Foskolos. The series would become Greece's longest-running soap opera. After the success of "Lampsi" came the short lived "To galazio diamandi" ("Blue Diamond") and "Simphonia siopis" ("Omertà"). "Lampsi" was canceled in June 2005 due to declining ratings. It was replaced by "Erotas" ("Love"), a soap that ran from 2005 to 2008. After that series ended, ANT1 abandoned the soap opera genre and focused on comedy series and weekly dramas.
Greece's second longest-running soap is "Kalimera Zoi" ("Goodmorning Life"), which ran from September 1993 until its cancellation in June 2006 due to low ratings.
MEGA.
Mega Channel began producing soap operas in 1990 with the prime time serial "I Dipsa" ("The Thirst"), which ran for 102 episodes. Other daytime soaps have included "Paralliloi dromoi" (1992–1994) and its successor "Haravgi" ("Daylight", 1994–1995), both of which were cancelled due to low viewership; as well as the serials "Apagorevmeni Agapi" ("Forbidden Love"), which ran from 1998 to 2006; "Gia mia thesi ston Ilio" ("A Spot Under the Sun"), which ran from 1998 to 2002; "Filodoxies" ("Expectations"), which ran from 2002 to 2006; and "Vera Sto Deksi" ("Ring on the Right Hand"), which ran from 2004 to 2006 and proved to be a successful competitor to "Lampsi", causing that show's ratings to decline.
"Ta Mistika Tis Edem" ("Edem Secrets"), which was created by the producers of "Vera Sto Deksi", debuted in 2008 and has eclipsed that show's success. Its ratings place it consistently among the three highest-rated daytime programs.
ERT.
IENED (which was renamed ERT2 in 1982) was responsible for the first Greek soap operas "I Kravgi Ton Likon" and "Megistanes". ERT also produced the long-running soap "O Simvoleografos". Since 2000 and with the introduction of private television, ERT produced additional daily soap operas – which included "Pathos" ("Passion"), "Erotika tis Edem" ("Loving in Eden") and "Ta ftera tou erota" ("The Wings of Love") – however, these failed to achieve high ratings and were canceled shortly after their premiere.
ALPHA.
Alpha produced "Kato apo tin Acropoli" ("Under the Acropolis"), which ran for 2½ years.
Cyprus.
Weekday shows.
The first daytime soap opera produced by a Cyprus channel was LOGOs TV's "Odos Den Ksehno" ("'Don't Forget' Street"), which ran from January to December 1996. It was followed by "To Serial", which also ran for one year from September 1997 to June 1998. CyBC created the third weekdaily soap, "Anemi Tou Pathous" ("Passion Winds"), running from January 2000 to June 2004, which was replaced by "I Platia" ("The Square") from September 2004 to July 2006. "Epikindini Zoni" ran from 2009 to 2010, and was cancelled after 120 episodes. "Vimata Stin Ammo" made its debut in September 2010.
Sigma TV first commissioned the weekdaily comedic soap "Sto Para Pente", which aired from September 1998 to June 2004, and first held the distinction of being the longest weekday show in Cyprus television history, before it was surpassed by "Se Fonto Kokkino", which ran from September 2008 to July 2012. Other Sigma TV weekday shows include "Akti Oniron" (which ran from 1999 to 2001), "Vourate Geitonoi" (which ran from 2001 to 2005, and was the most successful weekdaily series, achieving ratings shares of up to 70% of all television households in the country), "Oi Takkoi" (which ran from 2002 to 2005), "S' Agapo" (which ran from 2001 to 2002), "Vasiliki" (which ran from 2005 to 2006), "Vendetta" (which ran from September 2005 to December 2006), "30 kai Kati" (which ran from 2006 to 2007) and "Mila Mou" (which ran from September 2007 to January 2009).
ANT1 Cyprus aired the soap "I Goitia Tis Amartias" in 2002, which was soon canceled. "Dikse Mou To Filo Sou" followed from 2006 to 2009, along with "Gia Tin Agapi Sou", which ran from 2008 to 2009 and itself was followed by "Panselinos", which has aired since 2009.
Weekly shows.
The longest-running weekly show on Cyprus television is "Istories Tou Horkou" ("Villages Stories", which premiered on CyBC in March 1996 and ran until its cancellation in June 2006; it was revived in September 2010 but was cancelled again in March 2011 due to very low ratings), followed by "Manolis Ke Katina" ("Manolis and Katina", which ran from 1995 to 2004). The most controversial of these series was "To Kafenio" ("The Coffee Shop"), which premiered on CyBC on 1993 as a weekly series, before moving to MEGA Channel Cyprus six years later in 1999 as a weekdaily show and then moved to ANT1 Cyprus on 2000, which canceled the show one year later. There were plans to move the show back to CyBC as a weekly series in 2001, with the original cast, however this plan was never realised. The most successful weekly shows in Cyprus currently are ANT1's "Eleni I Porni" ("Eleni, The Whore"), which premiered in October 2010 and CyBC's "Stin Akri Tu Paradisou" ("At The Heaven's Edge"), which premiered in 2007. The most successful weekdaily soap was "Aigia Fuxia", which aired on ANT1 Cyprus from 2008 to 2010.
Finland.
The only daily Finnish soap opera so far is "Salatut elämät" ("Secret Lives"), which has achieved popularity in Finland since its 1999 debut on MTV3. It focuses on the lives of people along the imaginary Pihlajakatu street in Helsinki. The show has also spawned several Internet spin-off series and a film based on the show that was released in 2012.
Other soap-like shows in Finland are YLE shows "Uusi päivä" (which has aired since 2009) and "Kotikatu" (which ran from 1995 to 2012), however these programs do not adhere to a five-episode-a-week schedule.
Internet and mobile soap opera.
With the advent of internet television and mobile phones, several soap operas have also been produced specifically for these platforms, including "", a spin-off of the established "EastEnders". For those produced only for the mobile phone, episodes may generally consist of about six or seven pictures and accompanying text.
On September 13, 2011, TG4 launched a new 10-part online series titled, "Na Rúin" (an Internet spin-off of "Ros na Rún"). The miniseries took on the theme of a mystery; the viewer had to read Rachel and Lorcán's blogs as well as watch video diaries detailing each character's thoughts to solve the mystery of missing teenage character Ciara.
Parodies.
In motion pictures, the movie "Soapdish", stars Sally Field as an aging soap opera actress on a show called "The Sun Also Sets," who pines over her own neuroses and misfortunes, such as her live-in boyfriend who leaves her to go back to his wife, and the incidents of backstabbing and scheming of other members of the cast, some of which are more interesting than the stories on the program.
On television, several soap opera parodies have been produced:
References.
</dl>

</doc>
<doc id="27010" url="http://en.wikipedia.org/wiki?curid=27010" title="Software engineering">
Software engineering

Software engineering is the study and an application of engineering to the design, development, and maintenance of software.
The Bureau of Labor Statistics' definition is "Research, design, develop, and test operating systems-level software, compilers, and network distribution software for medical, industrial, military, communications, aerospace, business, scientific, and general computing applications."
Typical formal definitions of software engineering are:
History.
When the first digital computers appeared in the early 1940s, the instructions to make them operate were wired into the machine. Practitioners quickly realized that this design was not flexible and came up with the "stored program architecture" or von Neumann architecture. Thus the division between "hardware" and "software" began with abstraction being used to deal with the complexity of computing.
Programming languages started to appear in the 1950s and this was also another major step in abstraction. Major languages such as Fortran, ALGOL, and COBOL were released in the late 1950s to deal with scientific, algorithmic, and business problems respectively. E.W. Dijkstra wrote his seminal paper, "Go To Statement Considered Harmful", in 1968 and David Parnas introduced the key concept of modularity and information hiding in 1972 to help programmers deal with the ever increasing complexity of software systems.
The term "software engineering", coined by Margaret Hamilton, was first used in 1968 as a title for the world's first conference on software engineering, sponsored and facilitated by NATO. The conference was attended by international experts on software who agreed on defining best practices for software grounded in the application of engineering. The result of the conference is a report that defines how software should be developed [i.e., software engineering foundations]. The original report is publicly available.
The discipline of software engineering was created to address poor quality of software, get projects exceeding time and budget under control, and ensure that software is built systematically, rigorously, measurably, on time, on budget, and within specification. Engineering already addresses all these issues, hence the same principles used in engineering can be applied to software. The widespread lack of best practices for software at the time was perceived as a "software crisis".
Barry W. Boehm documented several key advances to the field in his 1981 book, 'Software Engineering Economics'. These include his Constructive Cost Model (COCOMO), which relates software development effort for a program, in man-years T, to "source lines of code" (SLOC). formula_1
The book analyzes sixty-three software projects and concludes the cost of fixing errors escalates as we move the project toward field use. The book also asserts that the key driver of software cost is the capability of the software development team.
In 1984, the Software Engineering Institute (SEI) was established as a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. Watts Humphrey founded the SEI Software Process Program, aimed at understanding and managing the software engineering process. His 1989 book, Managing the Software Process, asserts that the Software Development Process can and should be controlled, measured, and improved. The Process Maturity Levels introduced would become the Capability Maturity Model Integration for Development(CMMi-DEV), which has defined how the US Government evaluates the abilities of a software development team. 
Modern, generally accepted best-practices for software engineering have been collected by the ISO/IEC JTC 1/SC 7 subcommittee and published as the Software Engineering Body of Knowledge (SWEBOK).
Subdisciplines.
Software engineering can be divided into ten subdisciplines. They are:
Education.
Knowledge of computer programming is a prerequisite to becoming a software engineer. In 2004 the IEEE Computer Society produced the SWEBOK, which has been published as ISO/IEC Technical Report 1979:2004, describing the body of knowledge that they recommend to be mastered by a graduate software engineer with four years of experience.
Many software engineers enter the profession by obtaining a university degree or training at a vocational school. One standard international curriculum for undergraduate software engineering degrees was defined by the CCSE, and updated in 2004. A number of universities have Software Engineering degree programs; as of 2010[ [update]], there were 244 Campus programs, 70 Online programs, 230 Masters-level programs, 41 Doctorate-level programs, and 69 Certificate-level programs in the United States.
For practitioners who wish to become proficient and recognized as professional software engineers, the IEEE offers two certifications that extend knowledge above level achieved by an academic degree: "Certified Software Development Associate" and "Certified Software Development Professional".
In addition to university education, many companies sponsor internships for students wishing to pursue careers in information technology. These internships can introduce the student to interesting real-world tasks that typical software engineers encounter every day. Similar experience can be gained through military service in software engineering.
Profession.
Legal requirements for the licensing or certification of professional software engineers vary around the world. In the UK, the British Computer Society licenses software engineers and members of the society can also become Chartered Engineers (CEng), while in some areas of Canada, such as Alberta, British Columbia, Ontario, and Quebec, software engineers can hold the Professional Engineer (P.Eng) designation and/or the Information Systems Professional (I.S.P.) designation. In Canada, there is a legal requirement to have P.Eng when one wants to use the title "engineer" or practice "software engineering".
The United States, starting from 2013 offers an "NCEES" "Professional Engineer" exam for Software Engineering, thereby allowing Software Engineers to be licensed and recognized. Mandatory licensing is currently still largely debated, and perceived as controversial. In some parts of the US such as Texas, the use of the term Engineer is regulated by law and reserved only for use by individuals who have a Professional Engineer license. The IEEE informs the professional engineer license is not required unless the individual would work for public where health of others could be at risk if the engineer was not fully qualified to required standards by the particular state. Professional engineer licenses are specific to the state which has awarded them, and have to be regularly retaken.
The IEEE Computer Society and the ACM, the two main US-based professional organizations of software engineering, publish guides to the profession of software engineering. The IEEE's "Guide to the Software Engineering Body of Knowledge - 2004 Version", or SWEBOK, defines the field and describes the knowledge the IEEE expects a practicing software engineer to have. The most current SWEBOK v3 is an updated version and was released in 2014. The IEEE also promulgates a "Software Engineering Code of Ethics".
Employment.
In 2004, the U. S. Bureau of Labor Statistics counted 760,840 software engineers holding jobs in the U.S.; in the same time period there were some 1.4 million practitioners employed in the U.S. in all other engineering disciplines combined. Due to its relative newness as a field of study, formal education in software engineering is often taught as part of a computer science curriculum, and many software engineers hold computer science degrees and have no engineering background whatsoever.
Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies (civilian or military), and non-profit organizations. Some software engineers work for themselves as freelancers. Some organizations have specialists to perform each of the tasks in the software development process. Other organizations require software engineers to do many or all of them. In large projects, people may specialize in only one role. In small projects, people may fill several or all roles at the same time. Specializations include: in industry (analysts, architects, developers, testers, technical support, middleware analysts, managers) and in academia (educators, researchers).
Most software engineers and programmers work 40 hours a week, but about 15 percent of software engineers and 11 percent of programmers worked more than 50 hours a week in 2008. Injuries in these occupations are rare. However, like other workers who spend long periods in front of a computer terminal typing at a keyboard, engineers and programmers are susceptible to eyestrain, back discomfort, and hand and wrist problems such as carpal tunnel syndrome.
The field's future looks bright according to Money Magazine and Salary.com, which rated Software Engineer as the best job in the United States in 2006. In 2012, software engineering was again ranked as the best job in the United States, this time by CareerCast.com.
Certification.
The Software Engineering Institute offers certifications on specific topics like security, Process improvement and software architecture. Apple, IBM, Microsoft and other companies also sponsor their own certification examinations. Many IT certification programs are oriented toward specific technologies, and managed by the vendors of these technologies. These certification programs are tailored to the institutions that would employ people who use these technologies.
Broader certification of general software engineering skills is available through various professional societies. s of 2006[ [update]], the IEEE had certified over 575 software professionals as a Certified Software Development Professional (CSDP). In 2008 they added an entry-level certification known as the Certified Software Development Associate (CSDA). The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. The ACM examined the possibility of professional certification of software engineers in the late 1990s, but eventually decided that such certification was inappropriate for the professional industrial practice of software engineering.
In the U.K. the British Computer Society has developed a legally recognized professional certification called "Chartered IT Professional (CITP)", available to fully qualified members ("MBCS"). Software engineers may be eligible for membership of the Institution of Engineering and Technology and so qualify for Chartered Engineer status. In Canada the Canadian Information Processing Society has developed a legally recognized professional certification called "Information Systems Professional (ISP)". In Ontario, Canada, Software Engineers who graduate from a "Canadian Engineering Accreditation Board (CEAB)" accredited program, successfully complete PEO's ("Professional Engineers Ontario") Professional Practice Examination (PPE) and have at least 48 months of acceptable engineering experience are eligible to be licensed through the "Professional Engineers Ontario" and can become Professional Engineers P.Eng. The PEO does not recognize any online or distance education however; and does not consider Computer Science programs to be equivalent to software engineering programs despite the tremendous overlap between the two. This has sparked controversy and a certification war. It has also held the number of P.Eng holders for the profession exceptionally low. The vast majority of working professionals in the field hold a degree in CS, not SE. Given the difficult certification path for holders of non-SE degrees, most never bother to pursue the license.
Impact of globalization.
The initial impact of outsourcing, and the relatively lower cost of international human resources in developing third world countries led to a massive migration of software development activities from corporations in North America and Europe to India and later: China, Russia, and other developing countries. This approach had some flaws, mainly the distance / timezone difference that prevented human interaction between clients and developers and the massive job transfer. This had a negative impact on many aspects of the software engineering profession. For example, some students in the developed world avoid education related to software engineering because of the fear of offshore outsourcing (importing software products or services from other countries) and of being displaced by foreign visa workers. Although statistics do not currently show a threat to software engineering itself; a related career, computer programming does appear to have been affected. Nevertheless, the ability to smartly leverage offshore and near-shore resources via the follow-the-sun workflow has improved the overall operational capability of many organizations. When North Americans are leaving work, Asians are just arriving to work. When Asians are leaving work, Europeans are arriving to work. This provides a continuous ability to have human oversight on business-critical processes 24 hours per day, without paying overtime compensation or disrupting a key human resource, sleep patterns.
While global outsourcing has several advantages, global - and generally distributed - development can run into serious difficulties resulting from the distance between developers. This is due to the key elements of this type of distance which have been identified as geographical, temporal, cultural and communication (which includes the use of different languages and dialects of English in different locations). Research has been carried out in the area of global software development over the last 15 years and an extensive body of relevant work published which highlights the benefits and problems associated with the complex activity. As with other aspects of software engineering research is ongoing in this and related areas.
Related fields.
Software engineering is a direct sub-field of engineering and has an overlap with computer science and management science . It is also considered a part of overall systems engineering.
Controversy.
Over definition.
Typical formal definitions of software engineering are:
The term has been used less formally:
Criticism.
Software Engineering sees its practitioners as individuals who follow well-defined engineering approaches to problem-solving. These approaches are specified in various software engineering books and research papers, always with the connotations of predictability, precision, mitigated risk and professionalism. This perspective has led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading the engineering knowledge and maturing the field.
Software Craftsmanship has been proposed by a body of software developers as an alternative that emphasizes the coding skills and accountability of the software developers themselves without professionalism or any prescribed curriculum leading to ad-hoc problem-solving (craftmanship) without engineering (lack of predictability, precision, missing risk mitigation, methods are informal and poorly defined). extends the Agile Software Manifesto and draws a metaphor between modern software development and the apprenticeship model of medieval Europe.
Software engineering extends engineering and draws on the engineering model, i.e. engineering process, engineering project management, engineering requirements, engineering design, engineering construction, and engineering validation. The concept is so new that it is rarely understood, and it is widely misinterpreted, including in software engineering textbooks, papers, and among the communities of programmers and crafters.
One of the core issues in software engineering is that its approaches are not empirical enough because a real-world validation of approaches is usually absent, or very limited and hence software engineering is often misinterpreted as feasible only in a "theoretical environment."
Dijkstra who developed computer languages in the last century refuted the concepts of "software engineering" which was prevalent thirty years ago in the 1980s, arguing that those terms were poor analogies for what
he called the "radical novelty" of computer science:
 A number of these phenomena have been bundled under the name "Software
Engineering". As economics is known as "The Miserable Science", software
engineering should be known as "The Doomed Discipline", doomed because it
cannot even approach its goal since its goal is self-contradictory. Software
engineering, of course, presents itself as another worthy cause, but that is
eyewash: if you carefully read its literature and analyse what its devotees
actually do, you will discover that software engineering has accepted as its
charter "How to program if you cannot."

</doc>
<doc id="27011" url="http://en.wikipedia.org/wiki?curid=27011" title="Software Engineering Institute">
Software Engineering Institute

The Carnegie Mellon Software Engineering Institute (SEI) is a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. SEI also has offices in Arlington, Virginia, and Frankfurt, Germany. The SEI operates with major funding from the U.S. Department of Defense. The SEI also works closely with industry and academia through research collaborations.
The SEI program of work is conducted in several principal areas: acquisition, process management, risk, security, software development, and system design.
Areas of work.
The SEI defines specific initiatives aimed at improving organizations' software engineering capabilities.
Management practices.
Organizations need to effectively manage the acquisition, development, and evolution (ADE) of software-intensive systems. Success in software engineering management practices helps organizations predict and control quality, schedule, cost, cycle time, and productivity. The best-known example of SEI work in management practices is the SEI’s Capability Maturity Model (CMM) for Software (now Capability Maturity Model Integration (CMMI)). The CMMI approach consists of models, appraisal methods, and training courses that have been proven to improve process performance. In 2006, Version 1.2 of the CMMI Product Suite included the release of CMMI for Development. CMMI for Development was the first of three constellations defined in Version 1.2: the others include CMMI for Acquisition and CMMI for Services. The CMMI for Services constellation was released in February 2009. Another management practice developed by CERT, which is part of the SEI, is the Resilience Management Model (CERT-RMM). The CERT-RMM is a capability model for operational resilience management. Version 1.0 of the Resilience Management Model was released in May 2010.
Engineering practices.
SEI work in engineering practices increases the ability of software engineers to analyze, predict, and control selected
functional and non-functional properties of software systems. Key SEI tools and methods include the SEI Architecture Tradeoff Analysis Method (ATAM) method, the SEI Framework for Software Product Line Practice, and the SEI Service Migration and Reuse Technique (SMART).
Acquisition practices.
The goal of SEI work is to improve organizations acquisition processes.
Security.
The SEI is also the home of the CERT/CC (CERT Coordination Center), a federally funded computer security organization. The SEI CERT Program's primary goals are to ensure that appropriate technology and systems-management practices are used to resist attacks on networked systems and to limit damage and ensure continuity of critical services in spite of successful attacks, accidents, or failures. The SEI CERT program is working with US-CERT to produce the Build Security In (BSI) website, which provides guidelines for building security into every phase of the software development lifecycle. The SEI has also conducted research on insider threats and computer forensics. Results of this research and other information now populate the CERT Virtual Training Environment.
Carnegie Mellon, Capability Maturity Model, CMM, CMMI, Architecture Tradeoff Analysis Method, ATAM, and CERT are registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.
SQUARE.
The CERT Coordination Center Program has developed a method to help organizations build security into the early stages of the production life cycle. The Security Quality Requirements Engineering (SQUARE) method consists of nine steps that generate a final deliverable of categorized and prioritized security requirements. Although the SQUARE method could likely be generalized to any large-scale design project, it was designed for use with information technology systems.
SQUARE is listed at DHS National Cyber Security Division Build Security In (BSI) initiative's site.
A web-based tool, released in December 2009, was created to assist teams using the SQUARE method. The tool was extended in 2011 to include support for privacy requirements using P-SQUARE.
Special programs.
SEI Partner Network.
The SEI Partner Network helps the SEI disseminate software engineering best practices. Organizations and individuals in the SEI Partner Network are selected, trained, and licensed by the SEI to deliver authentic SEI services, which include courses, consulting methods, and management processes. The network currently consists of nearly 250 partner organizations worldwide.
Conferences.
The SEI sponsors national and international conferences, workshops, and user-group meetings. Other events cover subjects including acquisition of software-intensive systems, commercial off-the-shelf (COTS)-based systems, network security and survivability, software process research, software product lines, CMMI, and the SEI Team Software Process.
Education and training.
SEI courses help bring state-of-the-art technologies and practices from research and development into widespread use. SEI courses are currently offered at the SEI’s locations in the United States and Europe. In addition, using licensed course materials, SEI Partners train thousands of individuals annually.
Membership program.
The SEI Membership Program helps the software engineering community to network. SEI Members include small business owners, software and systems programmers, CEOs, directors, and managers from both Fortune 500 companies and prominent government organizations in 36 different countries.
Affiliate program.
Through the SEI Affiliate Program, organizations place technical experts with the SEI for periods ranging from 12 months to four years. Affiliates currently are working on projects with the SEI to identify, develop, and demonstrate improved software engineering practices.
Software Process Achievement award program.
In order to recognize outstanding achievement in improving an organization's ability to create and evolve software-dependent systems, the SEI and IEEE Computer Society created the Software Process Achievement Award program. In addition to rewarding excellence, the purpose of this award is to foster continuous advancement in the practice of software engineering and to disseminate insights, experiences, and proven practices throughout the relevant research and practitioner communities.
Research and publications.
The SEI publishes reports that offer new technical information about software engineering topics, whether theoretical or applied. The SEI also publishes books on software engineering for industry, government and military applications and practices.
In addition, the SEI offers public courses, workshops, and conferences in process improvement, software architecture and product lines, and security.
Focus of progressive protests.
SEI has been an occasional site of anti-war movement and peace movement protests, many of which have been organized by Pittsburgh's Thomas Merton Center.

</doc>
<doc id="27012" url="http://en.wikipedia.org/wiki?curid=27012" title="Software crisis">
Software crisis

Software crisis was a term used in the early days of computing science for the difficulty of writing useful and efficient computer programs in the required time. The software crisis was due to the rapid increases in computer power and the complexity of the problems that could be tackled. With the increase in the complexity of the software, many software problems arose because existing methods were neither sufficient nor up to the mark.
The term "software crisis" was coined by some attendees at the first NATO Software Engineering Conference in 1968 at Garmisch, Germany. Edsger Dijkstra's 1972 ACM Turing Award Lecture makes reference to this same problem:
 The major cause of the software crisis is that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming has become an equally gigantic problem.
 — Edsger Dijkstra, "The Humble Programmer (EWD340)", Communications of the ACM
The causes of the software crisis were linked to the overall complexity of hardware and the software development process. The crisis manifested itself in several ways:
The main cause is that improvements in computing power had outpaced the ability of programmers to effectively utilize those capabilities. Various processes and methodologies have been developed over the last few decades to improve software quality management such as procedural programming and object-oriented programming. However software projects that are large, complicated, poorly specified, and involve unfamiliar aspects, are still vulnerable to large, unanticipated problems.

</doc>
<doc id="27013" url="http://en.wikipedia.org/wiki?curid=27013" title="Swedish Academy">
Swedish Academy

The Swedish Academy (Swedish: "Svenska Akademien"), founded in 1786 by King Gustav III, is one of the Royal Academies of Sweden. It is known for making the annual decision on who will be the laureate for the Nobel Prize in Literature, awarded in memory of the donor Alfred Nobel.
History.
The Swedish Academy was founded in 1786 by King Gustav III. Modelled after the Académie française, it has 18 members. The motto of the Academy is "Talent and Taste" ("Snille och Smak" in Swedish). The primary purpose of the Academy is to further the "purity, strength, and sublimity of the Swedish language" ("Svenska Språkets renhet, styrka och höghet") (Walshe, 1965). To that end the Academy publishes two dictionaries.
The first is a one-volume glossary called "Svenska Akademiens ordlista" ("SAOL"). The second is a multi-volume dictionary, edited on principles similar to those of the "Oxford English Dictionary", entitled "Svenska Akademiens ordbok" ("SAOB"). The "SAOL" has reached its 13th edition while the first volume of the "SAOB" was published in 1898 and, as of 2013, work has progressed to words beginning with the letter "U".
The building now known as the Stockholm Stock Exchange Building was built for the bourgeoisie. The bottom floor was used as a trading exchange (this later became the stock exchange) and the upper floor was used for balls, New Year's Eve parties, etc. When the academy was founded, the ballroom was the biggest room in Stockholm that could be heated and thus used in the winter, so the king asked if he could borrow it. 
The academy has had its annual meeting there every year since, attended by members of the Swedish royal family. However, it was not until 1914 the academy gained the right to use the upper floor as their own for all eternity. It is here that the Academy meets and, amongst other business, announces the names of Nobel Prize laureates. The latter makes it arguably one of the most influential literary bodies in the world.
Dag Hammarskjöld's former farm at Backåkra, close to Ystad in southern Sweden, was bought in 1957 as a summer residence by Hammarskjöld, then Secretary-General of the United Nations (1953–1961). The south wing of the farm is reserved as a summer retreat for the 18 members of the Swedish Academy, of which Hammarskjöld was a member.
It is not possible for members of the Academy to resign; membership is for life, although the Academy can decide to exclude members - this happened twice to Gustaf Mauritz Armfelt who was excluded in 1794, re-elected in 1805, and excluded again in 1811. In 1989, Kerstin Ekman and Lars Gyllensten chose to stop participating in the meetings of the Academy, over its refusal to express support for Salman Rushdie when Ayatollah Khomeini condemned him to death for "The Satanic Verses", and in 2005, Knut Ahnlund made the same decision, as a protest against the choice of Elfride Jelinek as the Nobel laureate for 2004.
Awards and prizes.
Since 1901, the Academy has annually decided who will be the laureate for the Nobel Prize in Literature, awarded in memory of the donor Alfred Nobel.
The Swedish Academy annually awards nearly 50 different prizes and scholarships, most of them for domestic Swedish authors. Common to all is that they are awarded without competition and without application. The Dobloug Prize, the largest of these at $40,000, is a literature prize awarded for Swedish and Norwegian fiction.
Current members.
The current permanent secretary of the Academy is Peter Englund, who was preceded by Horace Engdahl. The current members of the Swedish Academy listed by seat number:

</doc>
<doc id="27014" url="http://en.wikipedia.org/wiki?curid=27014" title="Svenska Dagbladet">
Svenska Dagbladet

Svenska Dagbladet (common abbreviation "SvD"; the title translates as "the Swedish daily paper") is a daily newspaper published in Stockholm, Sweden. 
History and profile.
The first issue of "Svenska Dagbladet" appeared on 18 December 1884. Ivar Anderson is among its former editors-in-chief who assumed the post in 1940.
The paper is published in Stockholm and provides coverage of national and international news as well as local coverage of the Greater Stockholm region. Its subscribers are concentrated in the capital, but it is distributed in most of Sweden. During the beginning of the 1900s the paper was one of the right-wing publications in Stockholm.
"Svenska Dagbladet" is owned by Schibsted which purchased it in the late 1990s. The stated position of the editorial page is "independently moderate" ("oberoende moderat"), which means it is independent but adheres to the liberal conservatism of the Moderate Party. On the other hand, the paper is also regarded as conservative.
In November 2000 "Svenska Dagbladet" changed its format from broadsheet to tabloid. In 2005 the paper started a Web portal for business news as a joint venture with "Aftonbladet".
Since 1925 "Svenska Dagbladet" has awarded an individual sportsperson or a team the Svenska Dagbladet Gold Medal at the end of each year.
Circulation.
The circulation of "Svenska Dagbladet" was 185,000 copies in 2003. The paper had a circulation of 187,100 copies on weekdays in 2005. Among Swedish morning newspapers "Svenska Dagbladet" had the third largest circulation with 195,200 copies in 2007 after "Dagens Nyheter" and "Göteborgs-Posten". In 2008 "Svenska Dagbladet" had a circulation of 123,383 copies. The circulation of the paper was 185,600 copies in 2011. It was 159,600 copies in 2012 and 143,400 copies in 2013.

</doc>
<doc id="27016" url="http://en.wikipedia.org/wiki?curid=27016" title="Sture Allén">
Sture Allén

Sture Allén (born 31 December 1928 in Gothenburg) is a Swedish retired professor of computational linguistics at the University of Gothenburg, who was the permanent secretary of the Swedish Academy between 1986 and 1999. He was elected to chair 3 of the Swedish Academy in 1980. He is a member of the Norwegian Academy of Science and Letters.

</doc>
<doc id="27018" url="http://en.wikipedia.org/wiki?curid=27018" title="Stress">
Stress

Stress may refer to: 

</doc>
