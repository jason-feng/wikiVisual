<doc id="37374" url="http://en.wikipedia.org/wiki?curid=37374" title="Lockheed Martin RQ-3 DarkStar">
Lockheed Martin RQ-3 DarkStar

The RQ-3 DarkStar (known as Tier III- or "Tier three minus" during development) is an unmanned aerial vehicle (UAV). Its first flight was on March 29, 1996. The Department of Defense terminated DarkStar in January 1999, after determining the UAV was not aerodynamically stable and was not meeting cost and performance objectives.
Design and development.
The RQ-3 DarkStar was designed as a "high-altitude endurance UAV", and incorporated stealth aircraft technology to make it difficult to detect, which allowed it to operate within heavily defended airspace, unlike the RQ-4 Global Hawk, which is unable to operate except under conditions of air supremacy. The DarkStar was fully autonomous: it could take off, fly to its target, operate its sensors, transmit information, return and land without human intervention. Human operators, however, could change the DarkStar's flight plan and sensor orientation through radio or satellite relay. The RQ-3 carried either an optical sensor or radar, and could send digital information to a satellite while still in flight. It used a single airbreathing jet engine of unknown type for propulsion. 
The first prototype made its first flight on March 29, 1996, but its second flight, on April 22, 1996, ended in a crash shortly after takeoff. A modified, more stable design (the RQ-3A) first flew on June 29, 1998, and made a total of five flights before the program was canceled just prior to the sixth and final flight planned for the airworthiness test phase. Two additional RQ-3As were built, but never made any flights before program cancellation.
Although purportedly terminated on January 28, 1999, it was reported in April 2003 that the RQ-3 was still in development as a black project. The size and capabilities were reported to have increased somewhat. It was further alleged that the first such example had been used in the 2003 invasion of Iraq. There has been no independent confirmation. 
The "R" is the Department of Defense designation for reconnaissance; "Q" means unmanned aircraft system. The "3" refers to it being the third of a series of purpose-built unmanned reconnaissance aircraft systems.
Specifications.
General characteristics
Performance

</doc>
<doc id="37375" url="http://en.wikipedia.org/wiki?curid=37375" title="Northrop Grumman RQ-4 Global Hawk">
Northrop Grumman RQ-4 Global Hawk

The Northrop Grumman RQ-4 Global Hawk is an unmanned (UAV) surveillance aircraft. It was initially designed by Ryan Aeronautical (now part of Northrop Grumman), and known as Tier II+ during development. In role and operational design, the Global Hawk is similar to the Lockheed U-2. The RQ-4 provides a broad overview and systematic surveillance using high-resolution synthetic aperture radar (SAR) and long-range electro-optical/infrared (EO/IR) sensors with long loiter times over target areas. It can survey as much as 40000 sqmi of terrain a day.
The Global Hawk is operated by the United States Air Force and U.S. Navy. It is used as a high-altitude platform covering the spectrum of intelligence collection capability to support forces in worldwide military operations. According to the United States Air Force, the superior surveillance capabilities of the aircraft allow more precise weapons targeting and better protection of friendly forces. Cost overruns led to the original plan to acquire 63 aircraft being cut to 45, and to a 2013 proposal to mothball the 21 Block 30 signal-intelligence variants. Each aircraft was to cost US$60.9 million in 2001, but this had risen to $222.7 million per aircraft (including development costs) by 2013. The U.S. Navy has developed the Global Hawk into the MQ-4C Triton maritime surveillance platform.
Development.
Origins.
The Global Hawk took its first flight on 28 February 1998.
The first seven aircraft were built under the Advanced Concept Technology Demonstration (ACTD) program, sponsored by DARPA, in order to evaluate the design and demonstrate its capabilities. Demand for the RQ-4's abilities was high in the Middle East; thus, the prototype aircraft were actively operated by the U.S. Air Force in the War in Afghanistan. In an unusual move, the aircraft entered initial low-rate production while still in engineering and manufacturing development. Nine production Block 10 aircraft, sometimes referred to as RQ-4A, were produced; of these, two were sold to the US Navy and an additional two were deployed to Iraq to support operations there. The final Block 10 aircraft was delivered on 26 June 2006.
In order to increase the aircraft's capabilities, the airframe was redesigned, with the nose section and wings being stretched. The modified aircraft, designated RQ-4B Block 20, allow it to carry up to 3,000 lb of internal payload. These changes were introduced with the first Block 20 aircraft, the 17th Global Hawk produced, which was rolled out in a ceremony on 25 August 2006. First flight of the Block 20 from the USAF Plant 42 in Palmdale, California to Edwards Air Force Base took place on 1 March 2007. Developmental testing of Block 20 took place in 2008.
United States Navy version.
The United States Navy took delivery of two of the Block 10 aircraft to be used to evaluate maritime surveillance capabilities, designated N-1 (BuNo 166509) and N-2 (BuNo 166510). The initial example was tested in a naval configuration at Edwards Air Force Base for several months, later ferrying to NAS Patuxent River on 28 March 2006 to begin the Global Hawk Maritime Demonstration (GHMD) program. Navy squadron VX-20 was tasked with operating the GHMD system.
The GHMD aircraft flew in the Rim of the Pacific (RIMPAC) exercise for the first time in July 2006. Although RIMPAC operations were in the vicinity of Hawaii, the aircraft was operated from Edwards, requiring flights of approximately 2500 mi each way to the operations area. Four flights were performed, resulting in over 24 hours of persistent maritime surveillance coordinated with "Abraham Lincoln" and "Bonhomme Richard". As a part of the demonstration program, Global Hawk was tasked with maintenance of maritime situational awareness, contact tracking, and imagery support of various exercise operations. In operation, images from Global Hawks were transmitted to NAS Patuxent River for processing before being forwarded to the fleet operations off Hawaii.
Northrop Grumman entered a version of the RQ-4B in the US Navy's Broad Area Maritime Surveillance (BAMS) UAV contract competition. On 22 April 2008, the announcement was made that the Northrop Grumman "RQ-4N" had won the bid, with the Navy awarding a contract worth US$1.16 billion. In September 2010, the RQ-4N was officially designated the "MQ-4C". The Navy MQ-4C differs from the Air Force RQ-4 mainly in its wing. While the Global Hawk remains at high altitude to conduct surveillance, the Triton climbs to 50,000 ft to see a wide area and can drop to 10,000 ft to get further identification of a target. The Triton's wings are specially designed to take the stresses of rapidly decreasing altitude. Though similar in appearance to the Global Hawk's wings, the Triton's internal wing structure is much stronger and has additional features including anti-icing capabilities and impact and lightning strike protection.
Cost increases and procurement.
Development cost overruns placed the Global Hawk at risk of cancellation. In mid-2006, per-unit costs were 25% over baseline estimates, caused by both the need to correct design deficiencies as well as to increase its capabilities. This caused concern over a possible congressional termination of the program if its national security benefits could not be justified. However, in June 2006, the program was restructured. Completion of an operational assessment report by the USAF was delayed from August 2005-November 2007 due to manufacturing and development delays. The operational assessment report was released in March 2007 and production of the 54 air vehicles planned has been extended by two years to 2015.
In February 2011, the USAF reduced its planned purchase of RQ-4 Block 40 aircraft from 22 to 11 in order to cut costs. In June 2011, the U.S. Defense Department's Director, Operational Test and Evaluation (DOT&E) found the RQ-4B "not operationally effective" due to reliability issues. In June 2011, the Global Hawk was certified by the Secretary of Defense as critical to national security following a breach of the Nunn-McCurdy Amendment; the Secretary stated: "The Global Hawk is essential to national security; there are no alternatives to Global Hawk which provide acceptable capability at less cost; Global Hawk costs $220M less per year than the U-2 to operate on a comparable mission; the U-2 cannot simultaneously carry the same sensors as the Global Hawk; and if funding must be reduced, Global Hawk has a higher priority over other programs."
On 26 January 2012, the Pentagon announced plans to end Global Hawk Block 30 procurement as the type was found to be more expensive to operate and with less capable sensors than the existing U-2. Plans to increase procurement of the Block 40 variant were also announced. The Air Force's fiscal year 2013 budget request said it had resolved to divest itself of the Block 30 variant, however, the National Defense Authorization Act for Fiscal Year 2013 mandated operations of the Block 30 fleet through the end of 2014. The USAF plans to procure 45 RQ-4B Global Hawks as of 2013. Just before his release from ACC, Hostage said of the U-2's replacement by the drone that "The combatant commanders are going to suffer for eight years and the best they’re going to get is 90 percent".
From 2010-2013, costs of flying the RQ-4 fell by more than 50%. In 2010, the cost per flight hour was $40,600, with contractor logistic support making up $25,000 per flight hour of this figure. By mid-2013, cost per flight hour dropped to $18,900, contractor logistic support having dropped to $11,000 per flight hour. This was in part due to higher usage, spreading logistics and support costs over a higher number of flight hours.
EuroHawk.
The German Air Force ("Luftwaffe") ordered a variant of the RQ-4B, to be equipped with a customized sensor suite, designated "EuroHawk". The aircraft was based on the RQ-4B Block 20/30/40 and was to be equipped with an EADS-built SIGINT package; it was intended to fulfill Germany's requirement to replace their aging Dassault-Breguet Atlantique electronic surveillance aircraft of the Marineflieger ("German Naval Air Arm"). The EADS sensor package is composed of six wing-mounted pods; reportedly these sensor pods could potentially be used on other platforms, including manned aircraft.
The EuroHawk was officially rolled out on 8 October 2009 and its first flight took place on 29 June 2010. It underwent several months of flight testing at Edwards Air Force Base. On 21 July 2011, the first EuroHawk arrived in Manching, Germany; after which it was scheduled to receive its SIGINT sensor package and undergo further testing and pilot training until the first quarter of 2012. The Luftwaffe planned to station the type with Reconnaissance Wing 51. In 2011 the German ministry of defence was aware of difficulties with the certification for use within the European airspace. During flight trials, problems with the EuroHawk's flight control system were found; the German certification process was also complicated by Northrop Grumman refusing to share technical data on the aircraft with which to perform evaluations.
On 13 May 2013, German media reported that the EuroHawk would not be certifiable under ICAO rules without an anti-collision system; thus preventing any operations within European airspace or the airspace of any ICAO member. The additional cost of certification was reported to be more than €600 million (US$780 million). On 15 May 2013, the German government announced the immediate termination of the program, attributing the cancellation to the certification issue. Reportedly, the additional cost to develop the EuroHawk to the standards needed for certification may not have guaranteed final approval for certification. German defense minister Thomas de Maizière stated EuroHawk was "very important" for Germany in 2012, then referred to the project as being "a horror without end" in his 2013 statement to the Bundestag. The total cost of the project before it was canceled was €562 million. Northrop Grumman and EADS have described reports of flight control problems and high costs for certification as "inaccurate"; they have stated their intention to provide an affordable plan to complete the first EuroHawk's flight testing and produce the remaining four aircraft.
On 8 August 2013, the EuroHawk set an endurance record by flying continuously in European airspace for 25.3 hours, reaching an altitude of 58600 ft. It was the longest flight by an unrefueled UAS weighing more than 30000 lb in European skies. On 5 October 2014, German Minister of Defence Ursula von der Leyen was reportedly considering reactivating the EuroHawk program to test its reconnaissance abilities over a long period at altitudes of up to 20,000 m. Attempting to test the recon system on Airbus aircraft and an Israeli drone as alternate platforms had proven unsuccessful. The Bundeswehr would use it to detect, decrypt, and potentially interfere with enemy communications signals. If tests prove successful, a carrier would be purchased, likely "similar" to the U.S. Global Hawk. Germany is considering installing the EuroHawk's SIGINT payloads onto the U.S. Navy MQ-4C Triton Global Hawk derivative, as the electronic and communications intelligence sensors would be more difficult to place on other substitute aircraft. It already has icing and lightning-strike protection, and was built with certification over civilian airspace in mind, meeting the STANAG 4671 requirements that had ended the EuroHawk program.
Further development.
In January 2014, President Obama signed a budget that included $10 million to study how the U-2's superior sensors could be adapted to the RQ-4. On 29 April 2015, Janes reported that Northrup Grumman had installed U-2 sensors on the RQ-4 using an Universal Payload Adaptor (UPA) to hold a payload amount of 3,000-4,000 lb (1360-1814 kg). The sensors consist of the Optical Bar Camera and Senior Year Electro-Optical Reconnaissance System-2B/C. Successful testing of the system suggests that all RQ-4s could be similarly retrofitted.
Design.
Overview.
The Global Hawk UAV system comprises the RQ-4 air vehicle, which is outfitted with various equipment such as sensor packages and communication systems; and a ground element consisting of a Launch and Recovery Element (LRE), and a Mission Control Element (MCE) with ground communications equipment. Each RQ-4 air vehicle is powered by an Allison Rolls-Royce AE3007H turbofan engine with 7,050 lbf thrust, and carries a payload of 2,000 lb. The fuselage comprises an aluminum, semi-monocoque construction with V-tail; the wings are made of composite materials.
System and ground facilities.
Raytheon's Integrated Sensor Suite (ISS) consists of a synthetic aperture radar (SAR), electro-optical (EO), and thermographic camera (IR) sensors. Either the EO or the IR sensors can operate simultaneously with the SAR. Each sensor provides wide area search imagery and a high-resolution spot mode. The SAR has a ground moving target indicator (GMTI) mode, which can provide a text message providing the moving target's position and velocity. Both SAR and EO/IR imagery are transmitted from the aircraft to the MCE as individual frames, and reassembled during ground processing. An onboard inertial navigation system, supplemented by Global Positioning System updates, comprises the navigational suite. Global Hawk is intended to operate autonomously and "untethered" using a satellite data link (either Ku or Ultra high frequency) for sending data from the aircraft to the MCE. The common data link can also be used for direct down link of imagery when the UAV is within line-of-sight of compatible ground stations.
The ground segment consists of a Mission Control Element (MCE) and Launch and Recovery Element (LRE), provided by Raytheon. The MCE is used for mission planning, command and control, and image processing and dissemination; an LRE for controlling launch and recovery; and associated ground support equipment. (The LRE provides precision Differential GPS corrections for navigational accuracy during takeoff and landings, while precision coded GPS supplemented with an inertial navigation system is used during mission execution.) By having separable elements in the ground segment, the MCE and the LRE can operate in geographically separate locations, and the MCE can be deployed with the supported command's primary exploitation site. Both ground segments are contained in military shelters with external antennas for line-of-sight and satellite communications with the air vehicles.
Sensor packages.
Radar.
The Global Hawk carries the Hughes Integrated Surveillance & Reconnaissance (HISAR) sensor system. HISAR is a lower-cost derivative of the ASARS-2 package that Hughes developed for the Lockheed U-2, it is also fitted in the US Army's RC-7B Airborne Reconnaissance Low Multifunction (ARLM) manned aircraft, and is being sold on the international market. HISAR integrates a SAR-MTI system, along with an optical and an thermography imager. All three sensors are controlled and their outputs filtered by a common processor and transmitted in real time at up to 50 Mbit/s to a ground station. The SAR-MTI system operates in the X band in various operational modes; such as the wide-area MTI mode with a radius of 62 mi, combined SAR-MTI strip mode provides 20 ft resolution over 23 mi wide sections, and a SAR spot mode providing 6 ft resolution over 3.8 mi2.
In July 2006, the US Air Force began testing the Global Hawk Block 30 upgrades in the Benefield Anechoic Facility at Edwards AFB; such as the Advanced Signals Intelligence Payload, an extremely sensitive SIGINT processor. In 2006, a specialist active electronically scanned array radar system, the Multi-Platform Radar Technology Insertion Program, or MP-RTIP, began testing on the Scaled Composites Proteus; one modified Global Hawk shall carry the radar following validation. In 2010, Northrop spoke on the sensor capabilities of the new Block 40 aircraft, including MP-RTIP radar, emphasising surveillance over reconnaissance.
On 14 April 2014, a Block 40 Global Hawk completed the first Maritime Modes program risk reduction flight to enhance the Air Force's maritime surveillance capabilities. Maritime Modes is made up of a Maritime Moving Target Indicator and a Maritime Inverse Synthetic Aperture Radar (MISAR) that function together to provide ISR information on vessels traveling on the water's surface. During the 11.5 hour flight off of the California coast, the MISAR collected data on over 100 items of interest. Maritime Modes is planned to be integrated with the RQ-4B's existing MP-RTIP radar to detect and produce synthetic aperture radar imagery of ground vehicles.
Visible light/infrared.
The visible and infrared imagers share the same gimballed sensor package, and use common optics, providing a telescopic close-up capability. It can be optionally fitted with an auxiliary Signals intelligence package. To improve survivability, the Global Hawk is fitted with a Raytheon developed AN/ALR-89 self-protection suite consisting of the AN/AVR-3 Laser warning receiver, AN/APR-49 Radar warning receiver and a jamming system. An ALE-50 towed decoy also aids in the Global Hawk's deception of enemy air defenses.
Operational history.
U.S. Air Force.
Global Hawk ATCD prototypes were used in the War in Afghanistan and in the Iraq War. Since April 2010, they fly the Northern Route, from Beale AFB over Canada to South-East Asia and back, reducing flight time and improving maintenance. While their data-collection capabilities have been praised, the program lost three prototype aircraft to accidents, more than one quarter of the aircraft used in the wars. The crashes were reported to be due to "technical failures or poor maintenance", with a failure rate per hour flown over 100 times higher than the F-16 fighter. Northrop Grumman stated that it was unfair to compare the failure rates of a mature design to that of a prototype aircraft. In June 2012, a media report described the Global Hawk, the MQ-1 Predator and the MQ-9 Reapers "... the most accident-prone aircraft in the Air Force fleet." On 11 February 2010, the Global Hawks deployed in the Central Command AOR accrued 30,000 combat hours and 1,500 plus sorties.
Initial operational capability was declared for the RQ-4 Block 30 in August 2011. The USAF did not plan to keep the RQ-4B Block 30 in service past 2014 due to the U-2 and other platforms being less expensive in the role; but Congress sought to keep it in service until December 2016. The USAF had 18 RQ-4 Block 30s by the time of the passage of the National Defense Authorization Act for Fiscal Year 2013, which directed a further three RQ-4s to be procured as part of Lot 11; The USAF felt that additional aircraft were "excess to need" and likely become backup or attrition reserve models. Despite the potential retirement of the Block 30 fleet due to low reliability, low mission readiness, and high costs, the USAF released a pre-solicitation notice on 12 September 2013 for Lot 12 aircraft. In planning the USAF's FY 2015 budget, the Pentagon reversed its previous decision, shifting $3 billion from the U-2 to the RQ-4 Block 30, which had become more competitive with the U-2 due to increased flying hours. Factors such as cost per flight hour (CPFH), information gathering rates, mission readiness, adverse weather operational capability, distance to targets, and onboard power still favored the U-2.
After the 2011 Tōhoku earthquake and tsunami, RQ-4s flew 300 hours over the affected areas in Japan. There were also plans to survey the No. 4 reactor at the Fukushima Daiichi Nuclear Power Plant.
By November 2012, Northrop Grumman had delivered 37 Global Hawks to the USAF. As of March 2014, 42 Global Hawks are in use around the world, with 32 in use by the USAF.
The USAF stated that U-2 pilot and altitude advantages allow better functionality in the stormy weather and airspace restrictions of the East Asia region and its altitude and sensor advantages allow it to see further into hostile territory. In October 2013, the U.S. secured basing rights to deploy RQ-4s from Japan, the first time that basing rights for the type had been secured in Northeast Asia. RQ-4s are stationed at Andersen Air Force Base in Guam, but bad weather often curtailed flights. Basing in Japan as opposed to Guam enhances spying capabilities against North Korea by eliminating range as a factor. Two RQ-4s moved from Anderson AFB to Misawa AFB in mid 2014 in the type's first deployment to Japan; they were speculated to have focused on maritime patrol missions. The two RQ-4s successfully performed their missions from Misawa AFB during a six-month deployment, with none cancelled due to poor weather. It was the first time that they had operated out of a civil-military airport, sharing airspace and runways with commercial aircraft safely without additional restrictions, usually taking off and landing during quieter periods of air traffic. Officials only stated that they had operated at "various places around the Pacific."
On 19 September 2013, the RQ-4 Block 40 Global Hawk conducted its first wartime flight from Grand Forks Air Force Base.
In November 2013, an USAF RQ-4 deployed to the Philippines after Typhoon Haiyan to assist in relief efforts. It flew from Andersen Air Force Base in Guam to relay imagery of afflicted areas to response personnel and ground commanders.
In planning for the FY 2015 budget, the U-2 would be retired in favor of the RQ-4, made possible by reductions of RQ-4 operating costs and would be the first time an unmanned aircraft would completely replace a manned aircraft. The Block 40 Global Hawk may have to be retired in FY 2016 if sequestration is not repealed. The U-2 will continue to fly through 2018 without replacement.
In May 2014, a U.S. Global Hawk conducted a surveillance mission over Nigeria as part of the search for the kidnapped Nigerian schoolgirls. The Global Hawk joined MC-12 manned aircraft in the search.
Records.
On 24 April 2001, a Global Hawk flew non-stop from Edwards in the US to RAAF Base Edinburgh in Australia, making history by being the first pilotless aircraft to cross the Pacific Ocean. The flight took 22 hours, and set a world record for absolute distance flown by a UAV, 13219.86 km.
On 22 March 2008, a Global Hawk set the endurance record for full-scale, operational unmanned aircraft UAVs by flying for 33.1 hours at altitudes up to 60,000 feet over Edwards Air Force Base.
From its first flight in 1998 to 9 September 2013, the combined Global Hawk fleet flew 100,000 hours. 88 percent of flights were conducted by USAF RQ-4s, while the remaining hours were flown by NASA Global Hawks, the EuroHawk, the Navy BAMS demonstrator, and the MQ-4C Triton. Approximately 75 percent of flights were in combat zones; RQ-4s flew in operations over Afghanistan, Iraq, and Libya; and supported disaster response efforts in Haiti, Japan, and California.
From 10-16 September 2014, the RQ-4 fleet flew a total of 781 hours, the most hours flown by the type during a single week. 87 percent of flights were made by USAF RQ-4s, with the rest flown by the Navy BAMS-D and NASA hurricane research aircraft.
NASA.
In December 2007, two Global Hawks were transferred from the U.S. Air Force to NASA's Dryden Flight Research Center at Edwards Air Force Base. Initial research activities beginning in the second quarter of 2009 supported NASA's high-altitude, long-duration Earth science missions. The two Global Hawks were the first and sixth aircraft built under the original DARPA Advanced Concept Technology Demonstration program, and were made available to NASA when the Air Force had no further need for them. Northrop Grumman is an operational partner with NASA and will use the aircraft to demonstrate new technologies and to develop new markets for the aircraft, including possible civilian uses.
According to an article in the March 2010 issue of Scientific American (p. 25-27), the Global Hawk aircraft belonging to NASA were in use for testing purposes as of October 2009, with science missions expected to start in March 2010. Initial science applications included measurements of the ozone layer and cross-Pacific transport of air pollutants and aerosols. The author of the Scientific American piece speculates that the aircraft could be used for Antarctic exploration while based in and operated from Chile.
In August–September 2010, one of the two Global Hawks was loaned for NASA's GRIP Mission (Genesis and Rapid Intensification Program). Its long-term on station capabilities and long range made it a suitable aircraft for monitoring the development of Atlantic basin Hurricanes. It was modified to equip weather sensors including Ku-band radar, lightning sensors and dropsondes. It successfully flew into Hurricane Earl off the United States East Coast on 2 September 2010.
NATO.
In 2009, NATO announced that it expects to have a fleet of up to eight Global Hawks by 2012. The aircraft are to be equipped with MP-RTIP radar systems. NATO has budgeted US$1.4 billion (€1 billion) for the project, and a letter of intent has been signed. NATO signed a contract for five Block 40 Global Hawks in May 2012. 12 NATO members are participating in the purchase. On 10 January 2014, Estonia revealed it wanted to participate in NATO Global Hawk usage.
Potential operators.
Australia considered the purchase of a number of Global Hawks for maritime and land surveillance. The Global Hawk was to be assessed against the MQ-9 Mariner in trials in 2007. The Global Hawk aircraft would have operated in conjunction with manned Boeing P-8 Poseidon aircraft by 10 and 11 Squadrons of the RAAF, as a replacement of aging AP-3C Orion aircraft. In the end, the Australian government decided not to proceed and canceled the order. In 2012, a procurement effort for seven UAVs by 2019 was initiated. In May 2013 the Australian government confirmed its interest in acquiring the MQ-4C Triton maritime surveillance variant.
Canada has also been a potential customer, looking at the Global Hawk for maritime and land surveillance as either a replacement for its fleet of CP-140 Aurora patrol aircraft or to supplement manned patrols of remote Arctic and maritime environments, before withdrawing from the joint effort in August 2011. Spain has a similar requirement, and has existing contacts with Northrop Grumman.
On 24 August 2013, Japan announced that the Japan Air Self-Defense Force plans to operate one Global Hawk jointly with the U.S. by 2015. On 21 November 2014, the Japanese Ministry of Defense officially decided to procure the Global Hawk, which beat out the General Atomics Guardian ER; Japan has also been interested in the purchase of three aircraft. 
In 2011, South Korea's Defense Acquisition Program Administration (DAPA) expressed interest in acquiring at least four RQ-4Bs to increase intelligence capabilities following the exchange of the Wartime Operational Control from the U.S. to the Republic of Korea. Officials debated on the topic of the Global Hawks and domestic UAV programs. In September 2011, the US and South Korea discussed aircraft deployments near its land border to view North Korea and the North Korea–China border. In January 2012, DAPA announced that it would not proceed with a purchase due to a price rise from US$442M to US$899M, and that other platforms such as the Global Observer or the Phantom Eye were being investigated. However, in December 2012, South Korea notified Congress of a possible Foreign Military Sale of 4 RQ-4 Block 30 (I) Global Hawks with the Enhanced Integrated Sensor Suite (EISS) at an estimated cost of $1.2 billion. On 5 July 2013, the Korean National Assembly advised the government to re-evaluate the RQ-4 purchase, again citing high costs. On 24 March 2014, DAPA announced its intention to buy four Global Hawks through the FMS program at a cost of 880 billion won ($814.63 million), with the first to be delivered by 2018. On 17 December 2014, Northrop Grumman was awarded a $657 million contract by South Korea for four RQ-4B Block 30 Global Hawks, all are to be delivered by June 2019.
The New Zealand Defence Force is studying the Global Hawk, which has the range to conduct surveillance in the Southern Ocean around Antarctica, and in the Pacific Islands. The acquisition process has not moved beyond an expression of interest.
The Indian Navy has expressed interest in acquiring six to eight MQ-4C Maritime Surveillance Unmanned Aircraft Systems.
Variants.
Autonomous tanker variant.
KQ-X is a proposed autonomous tanker variant. It is currently being tested.
Model 396.
Scaled Composites and Northrop Grumman also offered an armed, 50% smaller version of the RQ-4A, known as the Scaled Composites Model 396, as part of the USAF Hunter-Killer program. The aircraft was rejected in favor of the MQ-9 Reaper.
Specifications (RQ-4B).
"Data from" USAF
References.
"This article contains material that originally came from the web article by Greg Goebel, which exists in the Public Domain."

</doc>
<doc id="37376" url="http://en.wikipedia.org/wiki?curid=37376" title="AAI RQ-2 Pioneer">
AAI RQ-2 Pioneer

The RQ-2 Pioneer is an unmanned aerial vehicle (UAV) that had been utilized by the United States Navy, Marine Corps, and Army, and deployed at sea and on land from 1986 until 2007. Initially tested aboard USS Iowa (BB-61), the RQ-2 Pioneer was placed aboard "Iowa"-class battleships to provide gunnery spotting, its mission evolving into reconnaissance and surveillance, primarily for amphibious forces.
It was developed jointly by AAI Corporation and Israel Aircraft Industries. The program grew out of successful testing and field operation of the Tadiran Mastiff UAV by the American and Israeli militaries.
Essentially, the Pioneer is an upgraded Tadiran Mastiff which was re-engined to accommodate a greater payload by request of the US Navy. To accomplish this, the original "Limbach" two-cylinder two-stroke engine was replaced with a Fichtel & Sachs two-cylinder two-stroke. The Limbach motor utilized a 28 inch propeller from Propeller Engineering and Duplicating, Inc. of San Clemente, California. The newer, more powerful Fichtel & Sachs motor was outfitted with a 29 inch propeller (which spins in the opposite direction) from the Sensenich Propeller Manufacturing Company of Lancaster, Pennsylvania.
Operation.
Launched by rocket assist (shipboard), by catapult, or from a runway, the Pioneer recovers into a net (shipboard) or with arresting gear after flying up to five hours with a 75 lb payload. It flies day or night missions with a gimbaled EO/IR sensor, relaying analog video in real time via a C-band line-of-sight (LOS) data link. Since 1991, Pioneer has flown reconnaissance missions during the Persian Gulf, Somalia (UNOSOM II), Bosnia, Kosovo and Iraq conflicts. In 2005, the Navy operated two Pioneer systems (one for training) and the Marines operated two, each with five or more aircraft. It is also operated by Israel and the Republic of Singapore Air Force. In 2007 Pioneer was retired by the US Navy and was replaced by the Shadow UAV.
Internationally, Pioneer drones are perhaps most remembered for their role in the 1991 Gulf War, when a Pioneer launched by the "Iowa"-class battleship observed Iraqi troops on Failaka Island surrendering shortly after USS "Missouri"‍ '​s attack on their trenchlines. When navy officials offered to transfer a Pioneer to the Smithsonian Institution, curators at the National Air and Space Museum specifically asked for the UAV that Iraqi troops surrendered to during the Gulf War.
The "R" is the Department of Defense designation for reconnaissance; "Q" means unmanned aircraft system. The "2" refers to its being the second of a series of purpose-built unmanned reconnaissance aircraft systems.
TERN.
The concept of using fixed wing surveillance UAVs from surface combatants returned in 2013 with DARPA's TERN project.

</doc>
<doc id="37377" url="http://en.wikipedia.org/wiki?curid=37377" title="IAI RQ-5 Hunter">
IAI RQ-5 Hunter

The IAI RQ-5 Hunter unmanned aerial vehicle (UAV) was originally intended to serve as the United States Army's Short Range UAV system for division and corps commanders. It took off and landed (using arresting gear) on runways. It used a gimbaled EO/IR sensor to relay its video in real time via a second airborne Hunter over a C-band line-of-sight data link. The RQ-5 is based on the Hunter UAV that was developed by Israel Aircraft Industries.
Operational overview.
System acquisition and training started in 1994 but production was cancelled in 1996 due to concerns over program mismanagement. Seven low rate initial production (LRIP) systems of eight aircraft each were acquired, four of which remained in service: one for training and three for doctrine development, exercise, and contingency support. Hunter was to be replaced by the RQ-7 Shadow, but instead of being replaced, the Army's has kept both systems in operation, because the Hunter has significantly larger payload, range, and time-on-station capabilities than the Shadow.
In 1995, A Company, 15th Military Intelligence Battalion (Aerial Exploitation) out of Fort Hood, TX was the first Army field unit equipped with the Hunter. A Company conducted multiple successful training rotations to the National Training Center. Then in March 1999, they were deployed to the Republic of Macedonia in support of NATO operations in Kosovo. During the 7 month operation, the Hunter was flown over 4000 hours. Significant operational success in Kosovo led to resumption of production and technical improvements. Hunter has been used in Iraq and other military operations since then. The system has also been armed with the Viper Strike munitions.
The Army's Unmanned Aircraft Systems Training Battalion at Fort Huachuca, AZ trains soldiers and civilians in the operation and maintenance of the Hunter UAV.
In 2004, the United States Department of Homeland Security, Bureau of Customs and Border Protection, Office of Air and Marine utilized the Hunter under a trial program for border patrol duties. During this program, the Hunter flew 329 flight hours, resulting in 556 detections.
A version armed with the Northrop Grumman GBU-44/B Viper Strike weapon system is known as the MQ-5A/B.
As of October 2012, the U.S. Army has 20 MQ-5B Hunters in service. The Hunter is being slowly replaced by the MQ-1C Grey Eagle. Retirement of the Hunter was expected to be completed in 2013. However, Northrop was awarded a support contract for the Hunter on January 22, 2013. The completion date for the contract is January 14, 2014, so the Hunter UAV is likely to be flying missions into 2014.
On 7 October 2013, the U.S. Army opened a UAS facility at Vilseck Army Airfield in Germany. A letter of agreement between the U.S. and Germany allows the 7th Army Joint Multinational Training Command to use two ‘air bridges’ in the east of the country to train operators, marking the first time a U.S. UAV will fly beyond the limits of military training areas. Two unarmed MQ-5B Hunters will be used solely for training drone operators.
From 1996 to January 2014, the MQ-5B Hunter unmanned aerial system has flown over 100,000 hours with the U.S. Army.
On 14 March 2014, an RQ-5 was reported downed by a Crimean self-defense unit over Russian occupied Ukrainian territory, although Russia did not substantiate the claim and the Pentagon denies it operated such a vehicle over Crimea.
International use.
In 1998 the Belgian Air Force purchased three B-Hunter UAV-systems, each consisting of six aircraft and two ground control stations.
Specifications.
"Data from" </ul>Armament

</doc>
<doc id="37379" url="http://en.wikipedia.org/wiki?curid=37379" title="Relative density">
Relative density

Relative density, or specific gravity, is the ratio of the density (mass of a unit volume) of a substance to the density of a given reference material. Specific gravity usually means relative density with respect to water. The term "relative density" is often preferred in modern scientific usage.
If a substance's relative density is less than one then it is less dense than the reference; if greater than 1 then it is denser than the reference. If the relative density is exactly 1 then the densities are equal; that is, equal volumes of the two substances have the same mass. If the reference material is water then a substance with a relative density (or specific gravity) less than 1 will float in water. For example, an ice cube, with a relative density of about 0.91, will float. A substance with a relative density greater than 1 will sink.
Temperature and pressure must be specified for both the sample and the reference. Pressure is nearly always 1 atm equal to 101.325 kPa. Where it is not, it is more usual to specify the density directly. Temperatures for both sample and reference vary from industry to industry. In British brewing practice the specific gravity as specified above is multiplied by 1000. Specific gravity is commonly used in industry as a simple means of obtaining information about the concentration of solutions of various materials such as brines, sugar solutions (syrups, juices, honeys, brewers wort, must, etc.) and acids.
Basic formulas.
Relative density ("RD") or specific gravity ("SG") is a dimensionless quantity, as it is the ratio of either densities or weights
where "RD" is relative density, "ρsubstance" is the density of the substance being measured, and "ρreference" is the density of the reference. (By convention "ρ", the Greek letter rho, denotes density.)
The reference material can be indicated using subscripts: "RD"substance/reference, which means "the relative density of "substance" with respect to "reference"". If the reference is not explicitly stated then it is normally assumed to be water at 4 °C (or, more precisely, 3.98 °C, which is the temperature at which water reaches its maximum density). In SI units, the density of water is (approximately) 1000 kg/m3 or 1 g/cm3, which makes relative density calculations particularly convenient: the density of the object only needs to be divided by 1000 or 1, depending on the units.
The relative density of gases is often measured with respect to dry air at a temperature of 20 °C and a pressure of 101.325 kPa absolute, which has a density of 1.205 kg/m3. Relative density with respect to air can be obtained by
Where "M" is the molar mass and the approximately equal sign is used because equality pertains only if 1 mol of the gas and 1 mol of air occupy the same volume at a given temperature and pressure i.e. they are both Ideal gases. Ideal behaviour is usually only seen at very low pressure. For example, one mol of an ideal gas occupies 22.414 L at 0 °C and 1 atmosphere whereas carbon dioxide has a molar volume of 22.259 L under those same conditions.
Temperature dependence.
The density of substances varies with temperature and pressure so that it is necessary to specify the temperatures and pressures at which the densities or masses were determined. It is nearly always the case that measurements are made at nominally 1 atmosphere (101.325 kPa the variations caused by changing weather patterns) but as relative density usually refers to highly incompressible aqueous solutions or other incompressible substances (such as petroleum products) variations in density caused by pressure are usually neglected at least where apparent relative density is being measured. For true ("in vacuo") relative density calculations air pressure must be considered (see below). Temperatures are specified by the notation "Ts/Tr)" with "Ts" representing the temperature at which the sample's density was determined and "Tr" the temperature at which the reference (water) density is specified. For example SG (20 °C/4 °C) would be understood to mean that the density of the sample was determined at 20 °C and of the water at 4 °C. Taking into account different sample and reference temperatures we note that while SGH2O = 1.000000 (20 °C/20 °C) it is also the case that RDH2O = 0.998203/0.998840 = 0.998363 (20 °C/4 °C). Here temperature is being specified using the current ITS-90 scale and the densities used here and in the rest of this article are based on that scale. On the previous IPTS-68 scale the densities at 20 °C and 4 °C are, respectively, 0.9982071 and 0.9999720 resulting in an RD (20 °C/4 °C) value for water of 0.9982343.
The temperatures of the two materials may be explicitly stated in the density symbols; for example:
where the superscript indicates the temperature at which the density of the material is measured, and the subscript indicates the temperature of the reference substance to which it is compared.
Uses.
Relative density can also help quantify the buoyancy of a substance in a fluid, or determine the density of an unknown substance from the known density of another. Relative density is often used by geologists and mineralogists to help determine the mineral content of a rock or other sample. Gemologists use it as an aid in the identification of gemstones. Water is preferred as the reference because measurements are then easy to carry out in the field (see below for examples of measurement methods).
As the principal use of relative density measurements in industry is determination of the concentrations of substances in aqueous solutions and these are found in tables of RD vs concentration it is extremely important that the analyst enter the table with the correct form of relative density. For example, in the brewing industry, the Plato table, which lists sucrose concentration by mass against true RD, were originally (20 °C/4 °C) that is based on measurements of the density of sucrose solutions made at laboratory temperature (20 °C) but referenced to the density of water at 4 °C which is very close to the temperature at which water has its maximum density of "ρ"(H2O) equal to 0.999972 g/cm3 (or 62.43 lbm·ft−3). The ASBC table in use today in North America, while it is derived from the original Plato table is for apparent relative density measurements at (20 °C/20 °C) on the IPTS-68 scale where the density of water is 0.9982071 g/cm3. In the sugar, soft drink, honey, fruit juice and related industries sucrose concentration by mass is taken from this work which uses SG (17.5 °C/17.5 °C). As a final example, the British RD units are based on reference and sample temperatures of 60 °F and are thus (15.56 °C/15.56 °C).
Measurement.
Relative density can be calculated directly by measuring the density of a sample and dividing it by the (known) density of the reference substance. The density of the sample is simply its mass divided by its volume. Although mass is easy to measure, the volume of an irregularly shaped sample can be more difficult to ascertain. One method is to put the sample in a water-filled graduated cylinder and read off how much water it displaces. Alternatively the container can be filled to the brim, the sample immersed, and the volume of overflow measured. The surface tension of the water may keep a significant amount of water from overflowing, which is especially problematic for small samples. For this reason it is desirable to use a water container with as small a mouth as possible.
For each substance, the density, "ρ", is given by
When these densities are divided, references to the spring constant, gravity and cross-sectional area simply cancel, leaving
Hydrostatic weighing.
Relative density is more easily and perhaps more accurately measured without measuring volume. Using a spring scale, the sample is weighed first in air and then in water. Relative density (with respect to water) can then be calculated using the following formula:
where
This technique cannot easily be used to measure relative densities less than one, because the sample will then float. "W"water becomes a negative quantity, representing the force needed to keep the sample underwater.
Another practical method uses three measurements. The sample is weighed dry. Then a container filled to the brim with water is weighed, and weighed again with the sample immersed, after the displaced water has overflowed and been removed. Subtracting the last reading from the sum of the first two readings gives the weight of the displaced water. The relative density result is the dry sample weight divided by that of the displaced water. This method works with scales that can't easily accommodate a suspended sample, and also allows for measurement of samples that are less dense than water.
Hydrometer.
The relative density of a liquid can be measured using a hydrometer. This consists of a bulb attached to a stalk of constant cross-sectional area, as shown in the diagram to the right.
First the hydrometer is floated in the reference liquid (shown in light blue), and the displacement (the level of the liquid on the stalk) is marked (blue line). The reference could be any liquid, but in practice it is usually water.
The hydrometer is then floated in a liquid of unknown density (shown in green). The change in displacement, Δ"x", is noted. In the example depicted, the hydrometer has dropped slightly in the green liquid; hence its density is lower than that of the reference liquid. It is, of course, necessary that the hydrometer floats in both liquids.
The application of simple physical principles allows the relative density of the unknown liquid to be calculated from the change in displacement. (In practice the stalk of the hydrometer is pre-marked with graduations to facilitate this measurement.)
In the explanation that follows,
Since the floating hydrometer is in static equilibrium, the downward gravitational force acting upon it must exactly balance the upward buoyancy force. The gravitational force acting on the hydrometer is simply its weight, "mg". From the Archimedes buoyancy principle, the buoyancy force acting on the hydrometer is equal to the weight of liquid displaced. This weight is equal to the mass of liquid displaced multiplied by "g", which in the case of the reference liquid is "ρrefVg". Setting these equal, we have
or just
Exactly the same equation applies when the hydrometer is floating in the liquid being measured, except that the new volume is "V" - "A"Δ"x" (see note above about the sign of Δ"x"). Thus,
Combining (1) and (2) yields
But from (1) we have "V" = "m"/"ρ"ref. Substituting into (3) gives
This equation allows the relative density to be calculated from the change in displacement, the known density of the reference liquid, and the known properties of the hydrometer. If Δ"x" is small then, as a first-order approximation of the geometric series equation (4) can be written as:
This shows that, for small Δ"x", changes in displacement are approximately proportional to changes in relative density.
Pycnometer.
A pycnometer (from Greek: πυκνός (puknos) meaning "dense"), also called pyknometer or specific gravity bottle, is a device used to determine the density of a liquid. A pycnometer is usually made of glass, with a close-fitting ground glass stopper with a capillary tube through it, so that air bubbles may escape from the apparatus. This device enables a liquid's density to be measured accurately by reference to an appropriate working fluid, such as water or mercury, using an analytical balance.
If the flask is weighed empty, full of water, and full of a liquid whose relative density is desired, the relative density of the liquid can easily be calculated. The particle density of a powder, to which the usual method of weighing cannot be applied, can also be determined with a pycnometer. The powder is added to the pycnometer, which is then weighed, giving the weight of the powder sample. The pycnometer is then filled with a liquid of known density, in which the powder is completely insoluble. The weight of the displaced liquid can then be determined, and hence the relative density of the powder.
There is also a gas-based manifestation of a pycnometer known as a "gas pycnometer". It compares the change in pressure caused by a measured change in a closed volume containing a reference (usually a steel sphere of known volume) with the change in pressure caused by the sample under the same conditions. The difference in change of pressure represents the volume of the sample as compared to the reference sphere, and is usually used for solid particulates that may dissolve in the liquid medium of the pycnometer design described above, or for porous materials into which the liquid would not fully penetrate.
When a pycnometer is filled to a specific, but not necessarily accurately known volume, "V" and is placed upon a balance, it will exert a force
where "mb" is the mass of the bottle and "g" the gravitational acceleration at the location at which the measurements are being made. "ρ"a is the density of the air at the ambient pressure and "ρ"b is the density of the material of which the bottle is made (usually glass) so that the second term is the mass of air displaced by the glass of the bottle whose weight, by Archimedes Principle must be subtracted. The bottle is, of course, filled with air but as that air displaces an equal amount of air the weight of that air is canceled by the weight of the air displaced. Now we fill the bottle with the reference fluid e.g. pure water. The force exerted on the pan of the balance becomes:
If we subtract the force measured on the empty bottle from this (or tare the balance before making the water measurement) we obtain.
where the subscript n indicated that this force is net of the force of the empty bottle. The bottle is now emptied, thoroughly dried and refilled with the sample. The force, net of the empty bottle, is now:
where "ρ"s is the density of the sample. The ratio of the sample and water forces is:
This is called the Apparent Relative Density, denoted by subscript A, because it is what we would obtain if we took the ratio of net weighings in air from an analytical balance or used a hydrometer (the stem displaces air). Note that the result does not depend on the calibration of the balance. The only requirement on it is that it read linearly with force. Nor does "RDA" depend on the actual volume of the pycnometer.
Further manipulation and finally substitution of "RDV", the true relative density (the subscript V is used because this is often referred to as the relative density "in vacuo"), for "ρ"s/"ρ"w gives the relationship between apparent and true relative density.
In the usual case we will have measured weights and want the true relative denstiy. This is found from
Since the density of dry air at 101.325 kPa at 20 °C is 0.001205 g/cm3 and that of water is 0.998203 g/cm3 we see that the difference between true and apparent relative densities for a substance with relative density (20 °C/20 °C) of about 1.100 would be 0.000120. Where the relative density of the sample is close to that of water (for example dilute ethanol solutions) the correction is even smaller.
The pycnometer is used in ISO standard: ISO 1183-1:2004, ISO 1014–1985 and ASTM standard: ASTM D854.
Types
Digital density meters.
"Hydrostatic Pressure-based Instruments": This technology relies upon Pascal's Principle which states that the pressure difference between two points within a vertical column of fluid is dependent upon the vertical distance between the two points, the density of the fluid and the gravitational force. This technology is often used for tank gaging applications as a convenient means of liquid level and density measure.
"Vibrating Element Transducers": This type of instrument requires a vibrating element to be placed in contact with the fluid of interest. The resonant frequency of the element is measured and is related to the density of the fluid by a characterization that is dependent upon the design of the element. In modern laboratories precise measurements of relative density are made using oscillating U-tube meters. These are capable of measurement to 5 to 6 places beyond the decimal point and are used in the brewing, distilling, pharmaceutical, petroleum and other industries. The instruments measure the actual mass of fluid contained in a fixed volume at temperatures between 0 and 80 °C but as they are microprocessor based can calculate apparent or true relative density and contain tables relating these to the strengths of common acids, sugar solutions, etc. The vibrating fork immersion probe is another good example of this technology. This technology also includes many coriolis-type mass flow meters which are widely used in chemical and petroleum industry for high accuracy mass flow measurement and can be configured to also output density information based on the resonant frequency of the vibrating flow tubes.
"Ultrasonic Transducer": Ultrasonic waves are passed from a source, through the fluid of interest, and into a detector which measures the acoustic spectroscopy of the waves. Fluid properties such as density and viscosity can be inferred from the spectrum.
"Radiation-based Gauge": Radiation is passed from a source, through the fluid of interest, and into a scintillation detector, or counter. As the fluid density increases, the detected radiation "counts" will decrease. The source is typically the radioactive isotope cesium-137, with a half-life of about 30 years. A key advantage for this technology is that the instrument is not required to be in contact with the fluid—typically the source and detector are mounted on the outside of tanks or piping.
"Buoyant Force Transducer": the buoyancy force produced by a float in a homogeneous liquid is equal to the weight of the liquid that is displaced by the float. Since buoyancy force is linear with respect to the density of the liquid within which the float is submerged, the measure of the buoyancy force yields a measure of the density of the liquid. One commercially available unit claims the instrument is capable of measuring relative density with an accuracy of ± 0.005 RD units. The submersible probe head contains a mathematically characterized spring-float system. When the head is immersed vertically in the liquid, the float moves vertically and the position of the float controls the position of a permanent magnet whose displacement is sensed by a concentric array of Hall-effect linear displacement sensors. The output signals of the sensors are mixed in a dedicated electronics module that provides a single output voltage whose magnitude is a direct linear measure of the quantity to be measured.
Examples.
Substances with a relative density of 1 are neutrally buoyant, those with RD greater than one are denser than water, and so (ignoring surface tension effects) will sink in it, and those with an RD of less than one are less dense than water, and so will float.
Example:

</doc>
<doc id="37381" url="http://en.wikipedia.org/wiki?curid=37381" title="D'Urville Island (New Zealand)">
D'Urville Island (New Zealand)

D'Urville Island is an island in the Marlborough Sounds along the northern coast of the South Island of New Zealand. It was named after the French explorer Jules Dumont d'Urville. With an area of approximately 58 sqmi, it is the eighth-largest island of New Zealand, and has around 52 permanent residents.
Geography.
The island has a convoluted coastline, as is frequently found with islands formed from peaks between sea-drowned valleys. It extends for some 35 kilometres northeast/southwest, and is a little over 10 kilometres wide at its widest point. The eastern coast of the island is relatively smooth, marked mainly by the small D'Urville Peninsula, some halfway along its length. In contrast, the west coast is marked by three large inlets: Port Hardy in the north, Greville Harbour in the centre, and Manuhakapakapa in the south. Numerous smaller islands lie off the coast, notably Stephens Island, which lies 3 km off D'Urville's northernmost point, Cape Stephens. The island's highest point, Attempt Hill (728 m) lies close to the centre of the island, due east of Greville Harbour. Most of the island's residents live close to the more sheltered east coast, with the localities of Patuki and Mukahanga being close to the northern tip of the island.
The Māori name is Rangitoto Ki Te Tonga. The local tribes are Ngāti Koata and Ngāti Kuia.
French Pass.
The island is separated from the mainland by the dangerous French Pass, known to Māori as Te Aumiti, through which water passes at up to 8 kn at each tide. Several vortices occur near this passage. D'Urville investigated the passage for several days in 1827, and damaged his ship passing through it.

</doc>
<doc id="37386" url="http://en.wikipedia.org/wiki?curid=37386" title="R.U.R.">
R.U.R.

R.U.R. is a 1920 science fiction play in the Czech language by Karel Čapek. "R.U.R." stands for "Rosumovi Univerzální Roboti" (Rossum’s Universal Robots). However, the English phrase Rossum’s Universal Robots had been used as the subtitle in the Czech original. It premiered on 25 January 1921 and introduced the word "robot" to the English language and to science fiction as a whole.
"R.U.R." quickly became famous and was influential early in the history of its publication. By 1923, it had been translated into thirty languages.
The play begins in a factory that makes artificial people, called "roboti" (robots), out of synthetic organic matter. They are not exactly robots by the current definition of the term; these creatures are closer to the modern idea of cyborgs, androids or even clones, as they may be mistaken for humans and can think for themselves. They seem happy to work for humans at first, but that changes, and a hostile robot rebellion leads to the extinction of the human race. Čapek later took a different approach to the same theme in "War with the Newts", in which non-humans become a servant class in human society.
"R.U.R" is dark but not without hope, and was successful in its day in both Europe and the United States.
Characters.
Parenthesis indicate differences in translations.
Humans
Robots and Robotesses
Plot.
Act I.
Helena, the daughter of the president of a major industrial power, arrives at the island factory of Rossum's Universal Robots. She meets Domin, the General Manager of R.U.R., who tells her the history of the company:
In 1920 a man named Rossum came to the island to study marine biology, and in 1932 he accidentally discovered a chemical that behaved exactly like protoplasm, except that it did not mind being knocked around. Rossum attempted to make a dog and a man, but failed. His nephew came to see him, and the two argued nonstop, largely because Old Rossum only wanted to create animals to prove that not only was God not necessary but that there was no God at all, and Young Rossum only wanted to make himself rich. Eventually, Young Rossum locked his uncle in a laboratory to play with his monsters and mutants, while Young Rossum built factories and cranked out Robots by the thousands. By the time the play takes place (in the 1950s or 1960s, presumably), Robots are cheap and available all over the world. They have become absolutely necessary because they allow products to be made at a fifth the previous cost.
Helena meets Fabry, Dr. Gall, Alquist, Busman, and Hallemeier, and reveals she is a representative of the League of Humanity, a human rights organization that wishes to "free" the Robots. The managers of the factory find this a ridiculous proposition, since they see Robots as appliances. Helena requests that the Robots be paid so that they can buy things they like, but the Robots do not "like" anything. Helena is eventually convinced that the League Of Humanity is a waste of money. Domin and Helena fall in love and are engaged to be married.
Act II.
Ten years later, Helena and her nurse Nana are talking about current events—particularly the decline in human births. Helena and Domin reminisce about the day they met and summarize the last ten years of world history, which has been shaped by the new worldwide Robot-based economy. Helena meets Dr. Gall's new Robot experiment, Radius, and Dr Gall describes his experimental Robotess, Robot Helena. Both are more advanced, fully featured versions. In secret, Helena burns the formula required to create Robots. The revolt of the Robots reaches Rossum's island as the act ends.
Act III.
The characters sense that the very universality of the Robots presents a danger. Reminiscent of the Tower of Babel, the characters discuss whether creating national Robots who were unable to communicate beyond their language group would have been a good idea. As Robot forces lay siege to the factory, Helena reveals she has burned the formula. The characters lament the end of humanity and defend their actions, despite the fact that their imminent deaths are a direct result of those actions. Busman is killed attempting to negotiate a peace with the Robots, who then storm the factory and kill all the humans except for Alquist, whom the Robots spare because they recognize that "he works with his hands like the Robots."
Epilogue.
Years have passed and all humans had been killed by the robot revolution except for Alquist. He has been working to recreate the formula that Helena destroyed. Because he is not a scientist, he has not made any progress. He has begged the robot government to search for surviving humans, and they have done so. There are none. Officials from the robot government approach Alquist and first order and then beg him to complete the formula, even if it means he will have to kill and dissect other Robots to do so. Alquist yields, agreeing to kill and dissect, which completes the circle of violence begun in Act Two. Alquist is disgusted by it. Robots Primus and Helena develop human feelings and fall in love. Playing a hunch, Alquist threatens to dissect Primus and then Helena; each begs him to take him- or herself and spare the other. Alquist realizes that they are the new Adam and Eve, and gives charge of the world to them.
Robots.
The Robots described in Čapek's play are not robots in the popularly understood sense of an automaton. They are not mechanical devices, but rather biological organisms that may be mistaken for humans. A comic scene at the beginning of the play shows Helena arguing with her future husband, Harry Domin, because she cannot believe his secretary is a robotess:
<poem>
DOMIN: Sulla, let Miss Glory have a look at you.
HELENA: (stands and offers her hand) Pleased to meet you. It must be very hard for you out here, cut off from the rest of the world.
SULLA: I do not know the rest of the world Miss Glory. Please sit down.
HELENA: (sits) Where are you from?
SULLA: From here, the factory
HELENA: Oh, you were born here.
SULLA: Yes I was made here.
HELENA: (startled) What?
DOMIN: (laughing) Sulla isn't a person, Miss Glory, she's a robot.
HELENA: Oh, please forgive me ...
</poem>
In a limited sense, they resemble more modern conceptions of man-made life forms, such as the Replicants in "Blade Runner", and the humanoid Cylons in the re-imagined "Battlestar Galactica," but in Čapek's time there was no conception of modern genetic engineering (DNA's role in heredity was not confirmed until 1952). There are descriptions of kneading-troughs for robot skin, great vats for liver and brains, and a factory for producing bones. Nerve fibers, arteries, and intestines are spun on factory bobbins, while the Robots themselves are assembled like automobiles. Čapek's robots are living biological beings, but they are still "assembled," as opposed to "grown" or "born."
One critic has described Čapek's Robots as epitomizing "the traumatic transformation of modern society by the First World War and the Fordist assembly line."
Origin of the word.
The play introduced the word "Robot", which displaced older words such as "automaton" or "android" in languages around the world. In an article in "Lidové noviny" Karel Čapek named his brother Josef as the true inventor of the word. In its original Czech, "robota" means forced labour of the kind that serfs had to perform on their masters' lands, and is derived from "rab," meaning "slave."
The name "Rossum" is an allusion to the Czech word "rozum," meaning "reason," "wisdom," "intellect" or "common-sense."
 It has been suggested that the allusion might be preserved by translating "Rossum" as "Reason," but only the Majer/Porter
version translates the word as "Reason".
Production history.
The work was published in Prague by Aventinum in 1920, and premiered in that city on 25 January 1921. It was translated from Czech into English by Paul Selver and adapted for the English stage by Nigel Playfair in 1923. Selver's translation abridged the play and eliminated a character, a robot named "Damon". In April 1923 Basil Dean produced "R.U.R." for the Reandean Company at St. Martin's Theatre, London.
The play's American première was at the Garrick Theatre in New York City in October 1922, where it ran for 184 performances, a production in which Spencer Tracy and Pat O'Brien played robots in their Broadway debuts.
It also played in Chicago and Los Angeles during 1923. In the late 1930s, the play was staged in the U.S. by the Federal Theatre Project's Marionette Theatre in New York.
In 1989, a new, unabridged translation by Claudia Novack-Jones restored the elements of the play eliminated by Selver. Another unabridged translation
was produced by Peter Majer and Cathy Porter for Methuen Drama in 1999.
Critical reception.
Reviewing the New York production of "R.U.R.", "The Forum" magazine described the play as "thought-provoking" and "a highly original thriller". John Clute has lauded "R.U.R." as "a play of exorbitant wit and almost demonic energy" and lists the play as one of the "classic titles" of inter-war science fiction.
Luciano Floridi has described the play thus: "Philosophically rich and controversial, "R.U.R." was unanimously acknowledged as a masterpiece from its first appearance, and has become a classic of technologically dystopian literature." Jarka M. Burien called "R.U.R." a "theatrically effective, prototypal
sci-fi melodrama".
On the other hand, Isaac Asimov, author of the "Robot" series of books and creator of the Three Laws of Robotics, stated: "Capek's play is, in my own opinion, a terribly bad one, but it is immortal for that one word. It contributed the word 'robot' not only to English but, through English, to all the languages in which science fiction is now written."
Adaptations.
In April 1935 was the premiere of the film "Loss of Sensation", USSR, screening of "R.U.R.". On 11 February 1938, a thirty-five minute adaptation of a section of the play was broadcast on BBC Television – the first piece of television science-fiction ever to be broadcast. In 1941 BBC radio presented a radio play version, and in 1948, another television adaptation – this time of the entire play, running to ninety minutes – was screened by the BBC. In this version Radius was played by Patrick Troughton who was later the second actor to play The Doctor in "Doctor Who," None of these three productions survive in the BBC's archives. BBC Radio 3 dramatised the play again in 1989, and this version has been released commercially. The Hollywood Theater of the Ear dramatized an unabridged audio version of "R.U.R." which is available on the collection "2000x: Tales of the Next Millennia."
In August 2010, Portuguese multi-media artist Leonel Moura's "R.U.R.: The Birth of the Robot", inspired by the Capek play, was performed at Itaú Cultural in São Paulo, Brazil. It utilized actual robots on stage interacting with the human actors.
An electro-rock musical, "Save The Robots" is based on "R.U.R.", featuring the music of the New York City pop-punk art-rock band Hagatha. This version with book and adaptation by E. Ether, music by Rob Susman, and lyrics by Clark Render was an official selection of the 2014 New York Musical Theatre Festival season.
References.
Notes

</doc>
<doc id="37388" url="http://en.wikipedia.org/wiki?curid=37388" title="Reedy Creek Improvement District">
Reedy Creek Improvement District

The Reedy Creek Improvement District (RCID) is the immediate governing jurisdiction for the land of the Walt Disney World Resort. As of the late 1990s, it comprised an area of 38.6 sqmi within the outer limits of Orange and Osceola counties in Florida. The RCID includes the cities of Bay Lake and Lake Buena Vista, and unincorporated RCID land.
History.
Creation.
After the success of Disneyland in California, Walt Disney began planning a second park on the East Coast. He also disliked the businesses that had sprung up around Disneyland, and therefore wanted control of a much larger area of land for the new project. As a result, Disney used multiple shell companies to buy up land at very low prices from unknowing landowners in the area that would eventually become the district. These company names are listed on the upper story windows of what is now the "Main Street USA" section of Walt Disney World, including Compass East Corporation, Latin-American Development and Management Corporation, Ayefour Corporation (named because of nearby I-4, or Interstate 4), Tomahawk Properties, Incorporated, Reedy Creek Ranch, Incorporated and Bay Lake Properties, Incorporated.
On March 11, 1966, these landowners, all fully owned subsidiaries of what is now The Walt Disney Company, petitioned the Circuit Court of the Ninth Judicial Circuit, which served Orange County, Florida, for the creation of the Reedy Creek Drainage District under Chapter 298 of the Florida Statutes. After a period during which some minor landowners within the boundaries opted out, the Drainage District was incorporated on May 13, 1966, as a public corporation. Among the powers of a Drainage District were the power to condemn and acquire property outside its boundaries "for the public use". It used this power at least once to obtain land for Canal C-1 (Bonnet Creek) through land that is now being developed as the Bonnet Creek Resort, a non-Disney resort.
However, Walt Disney knew that his plans for the land would be easier to carry out with more independence. Among his ideas for his Florida project was his proposed EPCOT, the Experimental Prototype Community of Tomorrow, which was to be a futuristic planned city (and which was also known as Progress City). He envisioned a real working city with both commercial and residential areas, but one that also continued to showcase and test new ideas and concepts for urban living.
Therefore, the Disney Company petitioned the Florida State Legislature for the creation of the Reedy Creek Improvement District, which would have almost total autonomy within its borders. The planned EPCOT city was also emphasized in this lobbying effort. Chapter 67-764 of the Laws of Florida was eventually signed into law by Governor Claude R. Kirk, Jr. on May 12, 1967, creating the District. On the same day, Governor Kirk also signed the incorporation acts for two cities inside the District: Bay Lake (Chapter 67-1104) and Reedy Creek (Chapter 67-1965). (The City of Reedy Creek was renamed to the City of Lake Buena Vista around 1970.)
After Walt Disney died in 1966 before his vision was realized, the Disney Company board decided that it did not want to be in the business of running a city, and abandoned many of his ideas for Progress City. The planned residential areas were never built. Most notably, Richard Foglesong argues in his book, "Married to the Mouse: Walt Disney World and Orlando", that Disney has abused its powers by remaining in complete control of the District.
According to a press conference held in Winter Park, Florida, on February 2, 1967, by Disney Vice President Donn Tatum, the Improvement District and Cities were created to serve "the needs of those residing there", and the company needed its own government to "clarify the District's authority to [provide services] within the District's limits" and because of the public nature of the planned development. The original city boundaries did not cover the whole Improvement District; they may have been intended as the areas where communities would be built for people to live.
In addition, the Disney-controlled town of Celebration, Florida, which was built with many of Walt Disney's original ideas, which have evolved into a form of New Urbanism, was deannexed from Bay Lake and the District to keep its residents from having power over Disney by providing for separate administration of the areas. Celebration lies on unincorporated land within Osceola County, with a thin strip of still-incorporated land separating it from the rest of the county. This strip of land contains canals and other land used by the District.
In January 1990, RCID was granted a $57-million allocation of tax-free state bonds over an agency with plans for an low-income housing development and all additional government applicants in a 6 county region as state distributes the bond proceeds on a first-come order. Disney was criticized for the move with a Republican gubernatorial candidate filed lawsuit filed to stop the RCID from using the funds. Also, one legislator moved that would limit the RCID ability to apply to the program and other talk about stripping Disney of the RCID.
Naming.
Reedy Creek is a natural waterway, the course of which runs mostly through undeveloped territory east of Haines City. Its flow, drainage, and destination have been altered over the years by human development: It crosses Interstate 4 and enters Disney property west of Celebration and passes between Disney's Animal Kingdom and Blizzard Beach, meandering north past the western reaches of the Bay Lake city limits and the Magic Kingdom.
Governance.
A five-member Board of Supervisors governs the District, elected by the landowners of the District. These members, senior employees of The Walt Disney Company, each own undeveloped five-acre (20,235 m²) lots of land within the District, the only land in the District not technically controlled by Disney or used for public road purposes. The only residents of the District, also Disney employees or their immediate family members, live in two small communities, one in each city. In the 2000 census, Bay Lake had 23 residents, all in the community on the north shore of Bay Lake, and Lake Buena Vista had 16 residents, all in the community about a mile north of Downtown Disney. These residents elect the officials of the cities, but since they don't actually own any land, they don't have any power in electing the District Board of Supervisors.
The District headquarters are in a building in Lake Buena Vista, east of Downtown Disney. The District runs the following services, primarily serving Disney:
Disney provides transportation for guests and employees in the form of buses, ferries, and monorails, under the name Disney Transport. In addition, several Lynx public bus routes enter the District, with half-hour service between the Transportation and Ticket Center (and backstage areas at the Magic Kingdom) and Downtown Orlando and Kissimmee, and once-a-day service to more points, intended mainly for cleaning staff. Half-hourly service is provided, via Lynx, to Orlando International Airport (MCO).
Law Enforcement.
Law enforcement from Orange County, Osceola County and the Florida Highway Patrol to police the district. In addition, the Walt Disney Company employs about 800 security staff. While Disney security maintains a fleet of private security Chevrolet Equinoxes equipped with flashing lights, flares, traffic cones, and chalk commonly used by police officers, arrests and citations are issued by the Florida Highway Patrol along with the Orange County and Osceola County sheriffs deputies. 
Disney security personnel are involved with traffic control and may only issue personnel violation notices to Disney, not the general public. Security vans previously had red lightbars, but after public scrutiny following the death of Robb Sipkema, were changed to amber to fall in line with Florida State Statutes.

</doc>
<doc id="37389" url="http://en.wikipedia.org/wiki?curid=37389" title="Walt Disney World">
Walt Disney World

The Walt Disney World Resort, informally known as Walt Disney World or simply Disney World or shortly WDW, is an entertainment complex in Bay Lake, Florida (mailing address is Lake Buena Vista, Florida), near Kissimmee, Florida and is the flagship of Disney's worldwide theme park empire. The resort opened on October 1, 1971 and, is the most visited vacation resort in the world, with an attendance of over 52 million annually.
Disney World is owned and operated by Walt Disney Parks and Resorts, a division of The Walt Disney Company. The property covers 27258 acre, in which it houses 27 themed resort hotels, 9 non–Disney hotels, four theme parks, two water parks, four golf courses, one nine-hole walking golf course for young golfers (no electric carts allowed), two themed miniature golf courses, one camping resort and other entertainment venues. Magic Kingdom was the first and original theme park to open in the complex followed by Epcot, Disney's Hollywood Studios, and Disney's Animal Kingdom, which opened later throughout the 1980s and 1990s.
Designed to supplement Disneyland in Anaheim, California, which had opened in 1955, the complex was developed by Walt Disney in the 1960s. "The Florida Project", as he called it, was originally to be built in hopes of differential in design and scheme from Disneyland with its own diverse set of rides. Walt Disney's original plans also called for the inclusion of an "Experimental Prototype Community of Tomorrow", a planned community that would serve as a test bed for new innovations for city living. After extensive lobbying, the Government of Florida created the Reedy Creek Improvement District, a special government district that essentially gave The Walt Disney Company the standard powers and autonomy of an incorporated city. However, Disney died on December 15, 1966, before construction began. Without the mind of Disney spearheading the construction of Walt Disney World, the Disney Company instead created the resort very similar to Disneyland, just on a much larger scale, along with abandoning his concept of an experimental planned community.
Coincidentally, Disneyland is in Orange County in California and Walt Disney World is in Orange County in Florida.
History.
Planning and construction.
Conception.
In 1959, Walt Disney Productions began looking for land for a second park to supplement Disneyland, which opened in Anaheim, California, in 1955. Market surveys revealed that only 5% of Disneyland's visitors came from east of the Mississippi River, where 75% of the population of the United States lived. Additionally, Walt Disney disliked the businesses that had sprung up around Disneyland and wanted control of a much larger area of land for the new project.
Walt Disney flew over the Orlando-area site (one of many) in November 1963. Seeing the well-developed network of roads, including the planned Interstate 4 and Florida's Turnpike, with McCoy Air Force Base (later Orlando International Airport) to the east, Disney selected a centrally located site near Bay Lake. To avoid a burst of land speculation, Walt Disney World Company used various dummy corporations to acquire 27443 acre of land. In May 1965, some of these major land transactions were recorded a few miles southwest of Orlando in Osceola County. Also, two large tracts totaling $1.5 million were sold, and smaller tracts of flatlands and cattle pastures were purchased by exotic-sounding companies such as the "Latin-American Development and Management Corporation" and the "Reedy Creek Ranch Corporation"; some of these names are now memorialized on a window above Main Street, U.S.A. in the Magic Kingdom. In addition to three huge parcels of land were many smaller parcels, called "outs". Much of the land acquired had been platted into 5 acre lots in 1912 by the Munger Land Company and sold to investors. Most owners were happy to get rid of the land, which was mostly swamp. Another issue was the mineral rights to the land, which were owned by Tufts University. Without the transfer of these rights, Tufts could come in at any time and demand the removal of buildings to obtain minerals. Eventually, Disney's team negotiated a deal with Tufts to buy the mineral rights for $15,000.
Working under a strict cloak of secrecy, real estate agents who did not know the identity of their client began making offers to landowners in southwest Orange and northwest Osceola counties in April 1964, shortly after Walt Disney chose the site for his new theme park. Careful not to let property owners know the extent of their land-buying appetites, the agents quietly negotiated one deal after another, sometimes lining up contracts to buy huge tracts for little more than $100 an acre. Because they knew that recording the first deeds would trigger intense public questioning about what was going on, Disney's representatives waited until they had a large number of parcels locked up through options before filing their paperwork.
Project's secrecy.
Meanwhile, a rumor had popped up in California that Disney had his eye on Orlando. On May 20, an "Orlando Sentinel" article acknowledged the persistent rumor that "the land is being purchased for a second East Coast Disneyland attraction", but the paper discounted the gossip, because Disney had specifically denied it when interviewed during a visit to Cape Kennedy. Disney lied in telling the newspaper he was spending $50 million to expand Disneyland in California and was not interested in another such venture at that time. The first purchases, recorded on May 3, 1965, included one for 8380 acre of swamp and brush from state Senator Irlo Bronson. The deal had been made seven months earlier. The first newspaper account of the large-scale interest in Orange and Osceola county property ran the next day. The May 4 "Orlando Sentinel" story said the transactions "will undoubtedly increase rumors already afloat for the past year to the effect that a new and large industrial complex is about to locate in this area."
Because of the proximity to Cape Kennedy, much early speculation centered on space or aircraft technology, according to anthropologist Stephen M. Fjellman in his 1992 book "Vinyl Leaves: Walt Disney World and America". Carmakers' names, especially Ford, also were mentioned. Speculation during the summer about the identity of the buyer included the Rockefellers, Howard Hughes and NASA's Manned Orbiting Laboratory Project.
One day while Hinson was putting out the Evening Star, Andersen's afternoon paper, he got a phone call from a friend who said he had been in the office of a New York public relations firm and had been told the firm was helping Disney plan a big development near Orlando. This story was quickly suppressed.
Within three weeks of recording the Bronson transaction, Florida Ranch Lands had wrapped up deals with 47 owners. Eventually, the firm negotiated agreements with 51 owners to buy 27443 acre for more than $5 million, an average price of $182 per acre. Disney wanted to announce his ownership of the land and his plans for Walt Disney World on November 15, 1965, but the secret was divulged earlier than that, when, in October 1965, Emily Bavar, editor of the "Sentinel"‍ '​s Florida magazine, was in Anaheim for Disneyland's 10th anniversary celebration. During an interview with Walt Disney, Bavar asked whether he was buying up vast acreage in Central Florida. Disney was caught unawares, and Bavar suspected that the rumor was true. Therefore, on October 21, 1965, a story by Bavar, written in the first person and acknowledging that she was sticking her neck out, predicted Disney would build a new theme park on the huge tract. After piecing together more information from various sources, the paper led its Sunday edition three days later with a story headlined, "We Say: `Mystery Industry' Is Disney".
Disney allowed Governor Haydon Burns to confirm the next day, October 25, that he intended to build "the greatest attraction in the history of Florida" in Central Florida. Disney came in person to Orlando for the formal announcement with Burns on November 15. Disney explained the plans for the site, including Experimental Prototype Community of Tomorrow, (EPCOT), also known as Progress City, was to be a futuristic planned city. He envisioned a working city with commercial and residential areas that also continued to showcase and test new ideas and concepts for urban living.
Roy Disney's oversight of construction.
Walt Disney died from lung cancer on December 15, 1966, before his vision was realized. His brother and business partner, Roy O. Disney, postponed his retirement to oversee construction of the resort's first phase.
On February 2, 1967, Roy O. Disney held a press conference at the Park Theatres in Winter Park, Florida. The role of EPCOT was emphasized in the film that was played. After the film, it was explained that for Disney World, including EPCOT, to succeed, a special district would have to be formed: the Reedy Creek Improvement District with two cities inside it, Bay Lake and Reedy Creek, now Lake Buena Vista. In addition to the standard powers of an incorporated city, which include the issuance of tax-free bonds, the district would have immunity from any current or future county or state land-use laws. The only areas where the district had to submit to the county and state would be property taxes and elevator inspections. The legislation forming the district and the two cities was signed into law by Florida Governor Claude R. Kirk, Jr. on May 12, 1967. The Supreme Court of Florida then ruled in 1968 that the district was allowed to issue tax-exempt bonds for public projects within the district, despite the sole beneficiary being Walt Disney Productions.
The district soon began construction of drainage canals, and Disney built the first roads and the Magic Kingdom. The Contemporary Resort Hotel, the Polynesian Village, and Fort Wilderness were also completed in time for the park's opening on October 1, 1971. The Palm and Magnolia golf courses near Magic Kingdom had opened a few weeks before. At the park's opening, Roy O. Disney dedicated the property and declared that it would be known as "Walt Disney World" in his brother's honor. In his own words: "Everyone has heard of Ford cars. But have they all heard of Henry Ford, who started it all? Walt Disney World is in memory of the man who started it all, so people will know his name as long as Walt Disney World is here." After the dedication, Roy Disney asked Walt's widow, Lillian, what she thought of Walt Disney World. According to biographer Bob Thomas, she responded, "I think Walt would have approved." Roy O. Disney died on December 20, 1971, less than three months after the property opened.
Recent history.
Much of Walt Disney's plans for his Progress City were abandoned after his death, after the company board decided that it did not want to be in the business of running a city. The concept evolved into the resort's second theme park, EPCOT Center (renamed Epcot in 1996), which opened in 1982. While still emulating Walt Disney's original idea of showcasing new technology, it is closer to a world's fair than a "community of tomorrow". Some of the urban planning concepts from the original idea of EPCOT would instead be integrated into the community of Celebration much later. The resort's third theme park, Disney-MGM Studios (renamed Disney's Hollywood Studios in 2008), opened in 1989, and is inspired by show business. The resort's fourth theme park, Disney's Animal Kingdom, opened in 1998.
George Kalogridis was named president of the resort in December 2012, replacing Meg Crofton, who had overseen the site since 2006.
Location.
Despite marketing claims and popular misconceptions, the Florida resort is not within Orlando city limits, but is actually about 21 mi southwest of downtown Orlando, much of it in southwestern Orange County, with the remainder in adjacent Osceola County. The property includes the cities of Lake Buena Vista and Bay Lake which are governed by the Reedy Creek Improvement District. The 27258 acre site is accessible from Central Florida's Interstate 4 via Exits 62B (World Drive), 64B (US 192 West), 65B (Osceola Parkway West), 67B (SR 536 West), and 68 (SR 535 North), and Exit 8 on SR 429, the Western Expressway. At its founding the park occupied approximately 30500 acre. Portions of the property have since been sold or de-annexed, including land now occupied by the Disney-built community of Celebration. Now the park occupies 27258 acre, about the size of San Francisco, or twice the size of Manhattan.
Attractions.
Water parks.
There are also many beaches around the area
Golf and recreation.
Disney's property includes five golf courses. The four 18-hole golf courses are the Palm (4.5 Stars), the Magnolia (4 Stars), Lake Buena Vista (4 Stars) and Osprey Ridge (4.5 Stars). There is also a nine-hole walking course (no electric carts allowed) called Oak Trail, designed for young golfers. The Magnolia and Palm courses played home to the PGA Tour's Children's Miracle Network Hospitals Classic. Arnold Palmer Golf Management manages the Disney golf courses. Additionally, there are two themed miniature golf complexes, each with two courses, Fantasia Gardens and Winter Summerland.
Catch-and-release fishing excursions are offered daily on the resort's lakes. A Florida fishing license is not required, because it occurs on private property. Cane-pole fishing is offered from the docks at Disney's Fort Wilderness Resort and Campground and Disney's Port Orleans Resort.
Additional recreational activities include watercraft rentals, surrey pedal car rentals, and firework cruises that launch from several resort marinas.
Resorts.
Of the thirty-four resorts and hotels on the Walt Disney World property, twenty-eight are owned and operated by Walt Disney Parks and Resorts. These are classified into four categories — Deluxe, Moderate, Value, and Disney Vacation Club Villas — and are located in one of five resort areas: the Magic Kingdom, Epcot, Wide World of Sports, Animal Kingdom, or Downtown Disney resort areas.
While all of the Deluxe resort hotels have achieved a AAA Four Diamond rating, Disney's Grand Floridian Resort & Spa is considered the highest tier flagship luxury resort on the Walt Disney World Resort complex.
Disney's Magical Express.
Guests with a Disney Resort reservation (excluding the Walt Disney World Swan and Dolphin) arriving at Orlando International Airport can be transported to their resort from the airport using the complimentary Disney Magical Express service, which is operated by Mears Destination Services as Walt Disney World is not allowed to transport guests off resort property. Guests can also have their bags picked up and transported for them through a contract with BAGS Incorporated. Mears operates custom motor coaches and luggage is delivered to the guests' rooms by BAGS. Disney Cruise Line buses are also operated by Mears.
Attendance.
Employment.
When the Magic Kingdom opened in 1971, the site employed about 5,500 "cast members". Today Walt Disney World employs more than 66,000 cast members, spending more than $1.2 billion on payroll and $474 million on benefits each year. The largest single-site employer in the United States, Walt Disney World has more than 3,700 job classifications. The resort also sponsors and operates the Walt Disney World College Program, an internship program that offers American college students (CP's) the opportunity to live about 15 mi off-site in four Disney-owned apartment complexes and work at the resort, and thereby provides much of the theme park and resort "front line" cast members. There is also the Walt Disney World International College Program, an internship program that offers international college students (ICP's) from all over the world the same opportunity.
Corporate culture.
Walt Disney World's corporate culture is based in some respects on that of its older sibling Disneyland, of which the most interesting is the use of a unique jargon based on theatrical terminology. This phenomenon is so well known that travel guidebooks have to include lists of common terms and abbreviations. For example, park visitors are always "guests", employees are "cast members," rides are "attractions" or "adventures", cast members costumed as famous Disney characters in a way that does not cover their faces are known as "face characters", jobs are "roles", and public and nonpublic areas are respectively labeled "onstage" and "backstage".
Maintenance.
In a March 30, 2004 article in the "Orlando Sentinel", then-Walt Disney World president Al Weiss gave some insight into how the parks are maintained:
Transportation.
A fleet of Disney-operated buses on property, branded Disney Transport, is complimentary for guests. In 2007, Disney Transport started a guest services upgrade to the buses. SatellGPS systems controlling new public address systems on the buses give safety information, park tips and other general announcements, with music. They are not to be confused with the Disney Cruise Line and Disney's Magical Express buses, which are operated by Mears Transportation. The Walt Disney World Monorail System also provides transportation at Walt Disney World. They operate on three routes that interconnect at the Transportation and Ticket Center (TTC), adjacent to the Magic Kingdom's parking lot. One line provides an express non-stop link from the TTC to the Magic Kingdom, while a second line provides a link from the TTC to Epcot. The third line links the TTC and the Magic Kingdom to the Contemporary, Polynesian, and Grand Floridian resorts. Disney Transport also operates a fleet of watercraft, ranging in size from water taxis up to the ferries that connect the Magic Kingdom to the Transportation and Ticket Center. Additionally, it is also responsible for maintaining the fleet of parking lot trams used for shuttling visitors between the various theme park parking lots and their respective main entrances.
The major roads within the resort (World Drive, Osceola Parkway and Epcot Center Drive) have segments that are built as freeways with full grade-separated interchanges. World Drive enters Walt Disney World from U.S. Route 192 and heads north to the Magic Kingdom Resort Area. Osceola Parkway heads east from the Animal Kingdom Resort Area to Interstate 4. Epcot Center Drive is a freeway for most of its route, running east from World Drive, past the Epcot parking lot to Interstate 4. Buena Vista Drive is a major surface street, running east from the Animal Kingdom Resort Area to Disney's Hollywood Studios, the Epcot Resort Area, and Downtown Disney.
Name and logo.
During the resort's early planning stages, Walt Disney referred to the project as "Project X", "The Florida Project", "Disney World", and "The Disney World". Early visual references used the same medieval font as Disneyland. Walt Disney was very involved in the site selection and project planning in the years before his death. The secretive names were chosen because of the high confidentiality of the project during the initial planning. After Walt Disney's death, Roy O. Disney added the name "Walt" to "Disney World" as a permanent tribute to his brother.
The original Walt Disney World logo featured an over-sized "D" with a Mickey Mouse-shaped globe containing latitude and longitude lines, with the property's name presented in a blocky, modern, sans-serif font. The original logo was retired during the resort's 25th anniversary celebration in 1996 and was replaced with the current logo, which features the "Walt Disney" portion of the logo in the typical Disney corporate signature font and "World" in Times New Roman font. Remnants of the original logo can still be found in many places throughout the resort, including the SpectroMagic title float, on the front car of each monorail, manhole covers, survey markers, and flags flown at several sites across the property. During the resort's 40th anniversary celebration in 2011, the original logo began to reappear on merchandise sold at the resort and can still be found on select items sold at various gift shops and stores at Walt Disney World.
Twin town.
As part of a competition run by Disney for 2010, Walt Disney World has an unofficial twinning (sister city) with Swindon, England, since 2009. Rebecca Warren's submission to the competition granted Swindon to be the twin town of Walt Disney World, which is famous for its intersection with six roundabouts. Warren and the mayor of Swindon were invited to a "twinning" ceremony, where a plaque revealing the connection will be placed.

</doc>
<doc id="37391" url="http://en.wikipedia.org/wiki?curid=37391" title="Raven paradox">
Raven paradox

The raven paradox, also known as Hempel's paradox or Hempel's ravens, is a paradox arising from the question of what constitutes evidence for a statement. Observing objects that are neither black nor ravens may formally increase the likelihood that all ravens are black – even though, intuitively, these observations are unrelated.
This problem was proposed by the logician Carl Gustav Hempel in the 1940s to illustrate a contradiction between inductive logic and intuition.
The paradox.
Hempel describes the paradox in terms of the hypothesis:
In strict logical terms, via contraposition, this statement is equivalent to:
It should be clear that in all circumstances where (2) is true, (1) is also true; and likewise, in all circumstances where (2) is false (i.e. if a world is imagined in which something that was not black, yet was a raven, existed), (1) is also false. This establishes logical equivalence.
Given a general statement such as "all ravens are black", a form of the same statement that refers to a specific observable instance of the general class would typically be considered to constitute evidence for that general statement. For example,
is evidence supporting the hypothesis that "all ravens are black".
The paradox arises when this same process is applied to statement (2). On sighting a green apple, one can observe:
By the same reasoning, this statement is evidence that (2) "everything that is not black is not a raven." But since (as above) this statement is logically equivalent to (1) "all ravens are black", it follows that the sight of a green apple is evidence supporting the notion that all ravens are black. This conclusion seems paradoxical, because it implies that information has been gained about ravens by looking at an apple.
Proposed resolutions.
Nicod's criterion says that only observations of ravens should affect one's view as to whether all ravens are black. Observing more instances of black ravens should support the view, observing white or coloured ravens should contradict it, and observations of non-ravens should not have any influence.
Hempel's equivalence condition states that when a proposition, X, provides evidence in favor of another proposition Y, then X also provides evidence in favor of any proposition that is logically equivalent to Y.
With normal real world expectations, the set of ravens is finite. The set of non black things is either non finite or beyond human enumeration. In order to confirm the statement 'All ravens are black.', it would be necessary to observe all ravens. This is possible. In order to confirm the statement 'All non black things are non ravens.', it would be necessary to examine all non black things. This is not possible. Observing a black raven could be considered a finite amount of confirmatory evidence, but observing a non black non raven would be an infinitesimal amount of evidence.
The paradox shows that Nicod's criterion and Hempel's equivalence condition are not mutually consistent. A resolution to the paradox must reject at least one out of:
A satisfactory resolution should also explain "why" there naively appears to be a paradox. Solutions that accept the paradoxical conclusion can do this by presenting a proposition that we intuitively know to be false but that is easily confused with (PC), while solutions that reject (EC) or (NC) should present a proposition that we intuitively know to be true but that is easily confused with (EC) or (NC).
Accepting non-ravens as relevant.
Although this conclusion of the paradox seems counter-intuitive, some approaches accept that observations of (coloured) non-ravens can in fact constitute valid evidence in support for hypotheses about (the universal blackness of) ravens.
Hempel's resolution.
Hempel himself accepted the paradoxical conclusion, arguing that the reason the result appears paradoxical is that we possess prior information without which the observation of a non-black non-raven would indeed provide evidence that all ravens are black.
He illustrates this with the example of the generalization "All sodium salts burn yellow", and asks us to consider the observation that occurs when somebody holds a piece of pure ice in a colorless flame which does not turn yellow::19–20
 This result would confirm the assertion, "Whatever does not burn yellow is not sodium salt", and consequently, by virtue of the equivalence condition, it would confirm the original formulation. Why does this impress us as paradoxical? The reason becomes clear when we compare the previous situation with the case of an experiment where an object whose chemical constitution is as yet unknown to us is held into a flame and fails to turn it yellow, and where subsequent analysis reveals it to contain no sodium salt. This outcome, we should no doubt agree, is what was to be expected on the basis of the hypothesis ... thus the data here obtained constitute confirming evidence for the hypothesis. ...
In the seemingly paradoxical cases of confirmation, we are often not actually judging the relation of the given evidence, E alone to the hypothesis H ... we tacitly introduce a comparison of H with a body of evidence which consists of E in conjunction with an additional amount of information which we happen to have at our disposal; in our illustration, this information includes the knowledge (1) that the substance used in the experiment is ice, and (2) that ice contains no sodium salt. If we assume this additional information as given, then, of course, the outcome of the experiment can add no strength to the hypothesis under consideration. But if we are careful to avoid this tacit reference to additional knowledge ... the paradoxes vanish.
Standard Bayesian solution.
One of the most popular proposed resolutions is to accept the conclusion that the observation of a green apple provides evidence that all ravens are black but to argue that the amount of confirmation provided is very small, due to the large discrepancy between the number of ravens and the number of non-black objects. According to this resolution, the conclusion appears paradoxical because we intuitively estimate the amount of evidence provided by the observation of a green apple to be zero, when it is in fact non-zero but extremely small.
I J Good's presentation of this argument in 1960 is perhaps the best known, and variations of the argument have been popular ever since, although it had been presented in 1958 and early forms of the argument appeared as early as 1940.
Good's argument involves calculating the weight of evidence provided by the observation of a black raven or a white shoe in favor of the hypothesis that all the ravens in a collection of objects are black. The weight of evidence is the logarithm of the Bayes factor, which in this case is simply the factor by which the odds of the hypothesis changes when the observation is made. The argument goes as follows:
Many of the proponents of this resolution and variants of it have been advocates of Bayesian probability, and it is now commonly called the Bayesian Solution, although, as Chihara observes, "there is no such thing as "the" Bayesian solution. There are many different 'solutions' that Bayesians have put forward using Bayesian techniques." Noteworthy approaches using Bayesian techniques include Earman, Eells, Gibson, Hosiasson-Lindenbaum, Howson and Urbach, Mackie, and Hintikka, who claims that his approach is "more Bayesian than the so-called 'Bayesian solution' of the same paradox". Bayesian approaches that make use of Carnap's theory of inductive inference include Humburg, Maher, and Fitelson et al. Vranas introduced the term "Standard Bayesian Solution" to avoid confusion.
Carnap approach.
Maher accepts the paradoxical conclusion, and refines it:
A non-raven (of whatever color) confirms that all ravens are black because
In order to reach (ii), he appeals to Carnap's theory of inductive probability, which is (from the Bayesian point of view) a way of assigning prior probabilities that naturally implements induction. According to Carnap's theory, the posterior probability, formula_16, that an object, formula_17, will have a predicate, formula_18, after the evidence formula_19 has been observed, is:
where formula_21 is the initial probability that formula_17 has the predicate formula_18; formula_24 is the number of objects that have been examined (according to the available evidence formula_19); formula_26 is the number of examined objects that turned out to have the predicate formula_18, and formula_28 is a constant that measures resistance to generalization.
If formula_28 is close to zero, formula_16 will be very close to one after a single observation of an object that turned out to have the predicate formula_18, while if formula_28 is much larger than formula_24, formula_16 will be very close to formula_21 regardless of the fraction of observed objects that had the predicate formula_18.
Using this Carnapian approach, Maher identifies a proposition which we intuitively (and correctly) know to be false, but which we easily confuse with the paradoxical conclusion. The proposition in question is the proposition that observing non-ravens tells us about the color of ravens. While this is intuitively false and is also false according to Carnap's theory of induction, observing non-ravens (according to that same theory) causes us to reduce our estimate of the total number of ravens, and thereby reduces the estimated number of possible counterexamples to the rule that all ravens are black.
Hence, from the Bayesian-Carnapian point of view, the observation of a non-raven does not tell us anything about the color of ravens, but it tells us about the prevalence of ravens, and supports "All ravens are black" by reducing our estimate of the number of ravens that might not be black.
Role of background knowledge.
Much of the discussion of the paradox in general and the Bayesian approach in particular has centred on the relevance of background knowledge. Surprisingly, Maher shows that, for a large class of possible configurations of background knowledge, the observation of a non-black non-raven provides "exactly the same" amount of confirmation as the observation of a black raven. The configurations of background knowledge that he considers are those that are provided by a "sample proposition", namely a proposition that is a conjunction of atomic propositions, each of which ascribes a single predicate to a single individual, with no two atomic propositions involving the same individual. Thus, a proposition of the form "A is a black raven and B is a white shoe" can be considered a sample proposition by taking "black raven" and "white shoe" to be predicates.
Maher's proof appears to contradict the result of the Bayesian argument, which was that the observation of a non-black non-raven provides much less evidence than the observation of a black raven. The reason is that the background knowledge that Good and others use can not be expressed in the form of a sample proposition – in particular, variants of the standard Bayesian approach often suppose (as Good did in the argument quoted above) that the total numbers of ravens, non-black objects and/or the total number of objects, are known quantities. Maher comments that, "The reason we think there are more non-black things than ravens is because that has been true of the things we have observed to date. Evidence of this kind can be represented by a sample proposition. But ... given any sample proposition as background evidence, a non-black non-raven confirms A just as strongly as a black raven does ... Thus my analysis suggests that this response to the paradox [i.e. the Standard Bayesian one] cannot be correct."
Fitelson et al. examined the conditions under which the observation of a non-black non-raven provides less evidence than the observation of a black raven. They show that, if formula_17 is an object selected at random, formula_38 is the proposition that the object is black, and formula_39 is the proposition that the object is a raven, then the condition:
is sufficient for the observation of a non-black non-raven to provide less evidence than the observation of a black raven. Here, a line over a proposition indicates the logical negation of that proposition.
This condition does not tell us "how large" the difference in the evidence provided is, but a later calculation in the same paper shows that the weight of evidence provided by a black raven exceeds that provided by a non-black non-raven by about formula_41. This is equal to the amount of additional information (in bits, if the base of the logarithm is 2) that is provided when a raven of unknown color is discovered to be black, given the hypothesis that not all ravens are black.
Fitelson et al. explain that:
The authors point out that their analysis is completely consistent with the supposition that a non-black non-raven provides an extremely small amount of evidence although they do not attempt to prove it; they merely calculate the difference between the amount of evidence that a black raven provides and the amount of evidence that a non-black non-raven provides.
Disputing the induction from positive instances.
Some approaches for resolving the paradox focus on the inductive step. They dispute whether observation of a particular instance (such as one black raven) is the kind of evidence that necessarily "increases" confidence in the general hypothesis (such as that ravens are always black).
The red herring.
Good gives an example of background knowledge with respect to which the observation of a black raven "decreases" the probability that all ravens are black:
Good concludes that the white shoe is a "red herring": Sometimes even a black raven can constitute evidence "against" the hypothesis that all ravens are black, so the fact that the observation of a white shoe can support it is not surprising and not worth attention. Nicod's criterion is false, according to Good, and so the paradoxical conclusion does not follow.
Hempel rejected this as a solution to the paradox, insisting that the proposition 'c is a raven and is black' must be considered "by itself and without reference to any other information", and pointing out that it "... was emphasized in section 5.2(b) of my article in "Mind" ... that the very appearance of paradoxicality in cases like that of the white shoe results in part from a failure to observe this maxim."
The question that then arises is whether the paradox is to be understood in the context of absolutely no background information (as Hempel suggests), or in the context of the background information that we actually possess regarding ravens and black objects, or with regard to all possible configurations of background information.
Good had shown that, for some configurations of background knowledge, Nicod's criterion is false (provided that we are willing to equate "inductively support" with "increase the probability of" – see below). The possibility remained that, with respect to our actual configuration of knowledge, which is very different from Good's example, Nicod's criterion might still be true and so we could still reach the paradoxical conclusion. Hempel, on the other hand, insists that it is our background knowledge itself which is the red herring, and that we should consider induction with respect to a condition of perfect ignorance.
Good's baby.
In his proposed resolution, Maher implicitly made use of the fact that the proposition "All ravens are black" is highly probable when it is highly probable that there are no ravens. Good had used this fact before to respond to Hempel's insistence that Nicod's criterion was to be understood to hold in the absence of background information:
This, according to Good, is as close as one can reasonably expect to get to a condition of perfect ignorance, and it appears that Nicod's condition is still false. Maher made Good's argument more precise by using Carnap's theory of induction to formalize the notion that if there is one raven, then it is likely that there are many.
Maher's argument considers a universe of exactly two objects, each of which is very unlikely to be a raven (a one in a thousand chance) and reasonably unlikely to be black (a one in ten chance). Using Carnap's formula for induction, he finds that the probability that all ravens are black decreases from 0.9985 to 0.8995 when it is discovered that one of the two objects is a black raven.
Maher concludes that not only is the paradoxical conclusion true, but that Nicod's criterion is false in the absence of background knowledge (except for the knowledge that the number of objects in the universe is two and that ravens are less likely than black things).
Distinguished predicates.
Quine argued that the solution to the paradox lies in the recognition that certain predicates, which he called natural kinds, have a distinguished status with respect to induction. This can be illustrated with Nelson Goodman's example of the predicate grue. An object is grue if it is blue before (say) 0 and green afterwards. Clearly, we expect objects that were blue before 0 to remain blue afterwards, but we do not expect the objects that were found to be grue before 0 to be blue after 0, since after 0 they would be green. Quine's explanation is that "blue" is a natural kind; a privileged predicate which can be used for induction, while "grue" is not a natural kind and using induction with it leads to error.
This suggests a resolution to the paradox – Nicod's criterion is true for natural kinds, such as "blue" and "black", but is false for artificially contrived predicates, such as "grue" or "non-raven". The paradox arises, according to this resolution, because we implicitly interpret Nicod's criterion as applying to all predicates when in fact it only applies to natural kinds.
Another approach, which favours specific predicates over others, was taken by Hintikka. Hintikka was motivated to find a Bayesian approach to the paradox that did not make use of knowledge about the relative frequencies of ravens and black things. Arguments concerning relative frequencies, he contends, cannot always account for the perceived irrelevance of evidence consisting of observations of objects of type A for the purposes of learning about objects of type not-A.
His argument can be illustrated by rephrasing the paradox using predicates other than "raven" and "black". For example, "All men
are tall" is equivalent to "All short people are women", and so observing that a randomly selected person is a short woman should provide evidence that all men are tall. Despite the fact that we lack background knowledge to indicate that there are dramatically fewer men than short people, we still find ourselves inclined to reject the conclusion. Hintikka's example is: "... a generalization like 'no material bodies are infinitely divisible' seems to be completely unaffected by questions concerning immaterial entities, independently of what one thinks of the relative frequencies of material and immaterial entities in one's universe of discourse."
His solution is to introduce an "order" into the set of predicates. When the logical system is equipped with this order, it is possible to restrict the "scope" of a generalization such as "All ravens are black" so that it applies to ravens only and not to non-black things, since the order privileges ravens over non-black things. As he puts it:
Rejections of Hempel's equivalence condition.
Some approaches for the resolution of the paradox reject Hempel's equivalence condition. That is, they may not consider evidence supporting the statement "all non-black objects are non-ravens" to necessarily support logically-equivalent statements such as "all ravens are black".
Selective confirmation.
Scheffler and Goodman took an approach to the paradox that incorporates
Karl Popper's view that scientific hypotheses are never really confirmed,
only falsified.
The approach begins by noting that the observation of a black raven does not prove that "All ravens are black" but it falsifies the contrary hypothesis, "No ravens are black". A non-black non-raven, on the other hand, is consistent with both "All ravens are black" and with "No ravens are black". As the authors put it:
Selective confirmation violates the equivalence condition since a black raven selectively confirms "All ravens are black" but not "All non-black things are non-ravens".
Probabilistic or non-probabilistic induction.
Scheffler and Goodman's concept of selective confirmation is an example of an interpretation of "provides evidence in favor of", which does not coincide with "increase the probability of". This must be a general feature of all resolutions that reject the equivalence condition, since logically equivalent propositions must always have the same probability.
It is impossible for the observation of a black raven to increase the probability of the proposition "All ravens are black" without causing exactly the same change to the probability that "All non-black things are non-ravens". If an observation inductively supports the former but not the latter, then "inductively support" must refer to something other than changes in the probabilities of propositions. A possible loophole is to interpret "All" as "Nearly all" – "Nearly all ravens are black" is not equivalent to "Nearly all non-black things are non-ravens", and these propositions can have very different probabilities.
This raises the broader question of the relation of probability theory to inductive reasoning. Karl Popper argued that probability theory alone cannot account for induction. His argument involves splitting a hypothesis, formula_47, into a part that is deductively entailed by the evidence, formula_19, and another part. This can be done in two ways.
First, consider the splitting:
where formula_52, formula_53 and formula_54 are probabilistically independent: formula_55 and so on. The condition that is necessary for such a splitting of H and E to be possible is formula_56, that is, that formula_47 is probabilistically supported by formula_19.
Popper's observation is that the part, formula_53, of formula_47 which receives support from formula_19 actually follows deductively from formula_19, while the part of formula_47 that does not follow deductively from formula_19 receives no support at all from formula_19 – that is, formula_66.
Second, the splitting:
separates formula_47 into formula_69, which as Popper says, "is the logically strongest part of formula_47 (or of the content of formula_47) that follows [deductively] from formula_19", and formula_73, which, he says, "contains all of formula_47 that goes beyond formula_19". He continues:
The orthodox approach.
The orthodox Neyman-Pearson theory of hypothesis testing considers how to decide whether to "accept" or "reject" a hypothesis, rather than what probability to assign to the hypothesis. From this point of view, the hypothesis that "All ravens are black" is not accepted "gradually", as its probability increases towards one when more and more observations are made, but is accepted in a single action as the result of evaluating the data that has already been collected. As Neyman and Pearson put it:
According to this approach, it is not necessary to assign any value to the probability of a "hypothesis", although one must certainly take into account the probability of the "data" given the hypothesis, or given a competing hypothesis, when deciding whether to accept or to reject. The acceptance or rejection of a hypothesis carries with it the risk of error.
This contrasts with the Bayesian approach, which requires that the hypothesis be assigned a prior probability, which is revised in the light of the observed data to obtain the final probability of the hypothesis. Within the Bayesian framework there is no risk of error since hypotheses are not accepted or rejected; instead they are assigned probabilities.
An analysis of the paradox from the orthodox point of view has been performed, and leads to, among other insights, a rejection of the equivalence condition:
Rejecting material implication.
The following propositions all imply one another: "Every object is either black or not a raven", "Every Raven is black", and "Every non-black object is a non-raven." They are therefore, by definition, logically equivalent. However, the three propositions have different domains: the first proposition says something about "Every object", while the second says something about "Every raven".
The first proposition is the only one whose domain of quantification is unrestricted ("all objects"), so this is the only one that can be expressed in first order logic. It is logically equivalent to:
and also to
where formula_91 indicates the material conditional, according to which "If formula_52 then formula_53" can be understood to mean "formula_53 or formula_95".
It has been argued by several authors that material implication does not fully capture the meaning of "If formula_52 then formula_53" (see the paradoxes of material implication). "For every object, formula_98, formula_98 is either black or not a raven" is "true" when there are no ravens. It is because of this that "All ravens are black" is regarded as true when there are no ravens. Furthermore, the arguments that Good and Maher used to criticize Nicod's criterion (see Good's Baby, above) relied on this fact – that "All ravens are black" is highly probable when it is highly probable that there are no ravens.
To say that all ravens are black in the absence of any ravens is an empty statement. It refers to nothing. "All ravens are white" is equally relevant and true, if this statement is considered to have any truth or relevance.
Some approaches to the paradox have sought to find other ways of interpreting "If formula_52 then formula_53" and "All formula_52 are formula_53", which would eliminate the perceived equivalence between "All ravens are black" and "All non-black things are non-ravens."
One such approach involves introducing a many-valued logic according to which "If formula_52 then formula_53" has the truth-value formula_106, meaning "Indeterminate" or "Inappropriate" when formula_52 is false. In such a system, contraposition is not automatically allowed: "If formula_52 then formula_53" is not equivalent to "If formula_110 then formula_95". Consequently, "All ravens are black" is not equivalent to "All non-black things are non-ravens".
In this system, when contraposition occurs, the modality of the conditional involved changes from the indicative ("If that piece of butter "has been" heated to 32 C then it "has" melted") to the counterfactual ("If that piece of butter "had been" heated to 32 C then it "would have" melted"). According to this argument, this removes the alleged equivalence that is necessary to conclude that yellow cows can inform us about ravens:
Differing results of accepting the hypotheses.
Several commentators have observed that the propositions "All ravens are black" and "All non-black things are non-ravens" suggest different procedures for testing the hypotheses. E.g. Good writes:
More recently, it has been suggested that "All ravens are black" and "All non-black things are non-ravens" can have different effects when "accepted". The argument considers situations in which the total numbers or prevalences of ravens and black objects are unknown, but estimated. When the hypothesis "All ravens are black" is accepted, according to the argument, the estimated number of black objects increases, while the estimated number of ravens does not change.
It can be illustrated by considering the situation of two people who have identical information regarding ravens and black objects, and who have identical estimates of the numbers of ravens and black objects. For concreteness, suppose that there are 100 objects overall, and, according to the information available to the people involved, each object is just as likely to be a non-raven as it is to be a raven, and just as likely to be black as it is to be non-black:
and the propositions formula_117 are independent for different objects formula_17, formula_3 and so on. Then the estimated number of ravens is 50; the estimated number of black things is 50; the estimated number of black ravens is 25, and the estimated number of non-black ravens (counterexamples to the hypotheses) is 25.
One of the people performs a statistical test (e.g. a Neyman-Pearson test or the comparison of the accumulated weight of evidence to a threshold) of the hypothesis that "All ravens are black", while the other tests the hypothesis that "All non-black objects
are non-ravens". For simplicity, suppose that the evidence used for the test has nothing to do with the collection of 100 objects dealt with here. If the first person accepts the hypothesis that "All ravens are black" then, according to the argument, about 50 objects whose colors were previously in doubt (the ravens) are now thought to be black, while nothing different is thought about the remaining objects (the non-ravens). Consequently, he should estimate the number of black ravens at 50, the number of black non-ravens at 25 and the number of non-black non-ravens at 25. By specifying these changes, this argument "explicitly" restricts the domain of "All ravens are black" to ravens.
On the other hand, if the second person accepts the hypothesis that "All non-black objects are non-ravens", then the approximately 50 non-black objects about which it was uncertain whether each was a raven, will be thought to be non-ravens. At the same time, nothing different will be thought about the approximately 50 remaining objects (the black objects). Consequently, he should estimate the number of black ravens at 25, the number of black non-ravens at 25 and the number of non-black non-ravens at 50. According to this argument, since the two people disagree about their estimates after they have accepted the different hypotheses, accepting "All ravens are black" is not equivalent to accepting "All non-black things are non-ravens"; accepting the former means estimating more things to be black, while accepting the latter involves estimating more things to be non-ravens. Correspondingly, the argument goes, the former requires as evidence ravens that turn out to be black and the latter requires non-black things that turn out to be non-ravens.
Existential presuppositions.
A number of authors have argued that propositions of the form "All formula_52 are formula_53" presuppose that there are objects that are formula_52. This analysis has been applied to the raven paradox:
A modified logic can take account of existential presuppositions using the presuppositional operator, '*'. For example,
can denote "All ravens are black" while indicating that it is ravens and not non-black objects which are presupposed to exist in this example.

</doc>
<doc id="37392" url="http://en.wikipedia.org/wiki?curid=37392" title="Sacramento River">
Sacramento River

The Sacramento River is the principal river of Northern California in the United States, and is the largest river in California. Rising in the Klamath Mountains, the river flows south for 445 mi before reaching the Sacramento–San Joaquin River Delta and San Francisco Bay. The river drains about 27500 sqmi in 19 California counties, mostly within a region bounded by the Coast Ranges and Sierra Nevada known as the Sacramento Valley, but also extending as far as the volcanic plateaus of Northeastern California. Historically, its watershed has reached farther, as far north as south-central Oregon where the now, primarily, endorheic (closed) Goose Lake rarely experiences southerly outflow into the Pit River, the most northerly tributary of the Sacramento.
The Sacramento and its wide natural floodplain were once abundant in fish and other aquatic creatures, notably one of the southernmost large runs of chinook salmon in North America. For about 12,000 years, native peoples have drawn upon the vast natural resources of the watershed, which had one of the densest American Indian populations in California. The river has also been used as a trade and travel route since ancient times. Hundreds of tribes sharing regional customs and traditions inhabited the Sacramento Valley, though they received little disturbance upon the arrival of Europeans in the 1700s. The Spanish explorer Gabriel Moraga named the river "Rio de los Sacramentos" in 1808, later shortened and anglicized into "Sacramento".
In the 19th century the gold find in the Sierra Nevada was the impetus to the California Gold Rush with an enormous population influx. Overland trails such as the California Trail and Siskiyou Trail followed the Sacramento and other tributaries, guiding hundreds of thousands of people to the goldfields and the growing agricultural region of the Sacramento Valley. By the late part of the century, many populous communities had been established along the Sacramento River, chief of which was the city of Sacramento. Intensive agriculture and mining contributed to pollution in the Sacramento, and significant changes to the river's hydrology and environment.
Since the 1950s the watershed have been intensely developed for water supply and the generation of hydroelectric power. Today, large dams impound the river and almost all of its major tributaries. The Sacramento is used heavily for irrigation and serves much of Central and Southern California through the canals of giant state and federal water projects. While now providing water to over half of California's population and supporting one of the most productive agricultural areas in the nation, these changes have left the Sacramento greatly modified from its natural state and have caused the decline of its once-abundant fisheries.
Course.
The Sacramento's source waters rise in the volcanic plateaus and ranges of far northern California as two streams – the Upper Sacramento and Pit. The main stem rises in the shadow of Mount Shasta and flows south through the Klamath Mountains, past Mount Shasta, Dunsmuir and Lakehead for about 72 mi. However, the river's true headwaters lie far to the northeast, as the 315 mi Pit River, which is formed by streams flowing southwest from the Modoc Plateau. The two rivers join in the waters of Lake Shasta, a giant reservoir formed by the Shasta Dam. The upper Sacramento is only the main stem by name: the flow of the Pit into the lake, 4269 cuft/s, is nearly four times that of the Sacramento's 1191 cuft/s.
From the dam the Sacramento winds south through foothills and leaves the mountains near Redding, the first large city on the river's course and second largest on its entire course. Many small and moderate-sized tributaries join the river from both east and west including Clear, Cottonwood, Cow, Thomes, Ash and Battle Creeks. As the river meanders into the Central Valley a large portion of its flow is diverted into a pair of irrigation canals at Red Bluff. The Sacramento continues south, receiving Mill Creek near Tehama, and Stony and Big Chico creeks a bit southwest of Chico. The river then passes Colusa, and receives Butte Creek about 3 mi west of the Sutter Buttes, a group of isolated volcanic hills in the middle of the Sacramento Valley.
Twenty-five miles (40 km) southeast of Colusa near Fremont Landing, the Sacramento incorporates the flow of its largest tributary, the Feather River, which descends from the Sierra Nevada to the northeast. About 10 mi downstream, it flows into the city of Sacramento, California and receives the American River, its second largest tributary. Here the river splits into two: the main stem and the artificial Sacramento Deep Water Ship Channel. Both waterways continue south through the lowlands, eventually to rejoin in the estuary of the Sacramento–San Joaquin River Delta near Rio Vista.
The mouth of the Sacramento is on Suisun Bay near Antioch, where it combines with the San Joaquin River, south of the Montezuma Hills. The Sacramento is nearly a mile (2 km) wide at its mouth. The joined waters then flow west through the tidal marshes of Suisun Bay, the Carquinez Strait, San Pablo Bay and San Francisco Bay, whereupon the river's waters finally join the Pacific in the Golden Gate just to the north of San Francisco.
Discharge.
The Sacramento River's average annual discharge is about 30000 cuft/s, carrying over 22000000 acre.ft of water each year, making it the second largest river on the Pacific coast of the continental United States.
The U.S. Geological Survey has stream gauges on several locations along the Sacramento River. The ones currently in operation are at Delta (near the source at Mount Shasta), at Keswick (near Redding), Colusa (about halfway down the river), Verona, and Freeport. At the Delta gauge, which began operation in 1945, the average annual discharge was 1191 cuft/s. At Keswick, after receiving major tributaries such as the Pit, the river's flow increases to 10120 cuft/s. The Colusa gauge recorded an annual mean of 11640 cuft/s from 1946 to 2009. At Verona, downstream from the Feather River confluence, the Sacramento's flow rises to 17470 cuft/s. The final gauge, at Freeport, sits just downstream of Sacramento; it recorded an average flow of 23490 cuft/s from 1949 to 2009. The USGS also operates many other gauges, including at Sacramento and Rio Vista, but the data recorded at these stations is more spotty.
Sacramento River monthly discharges at Freeport (cfs)
<br>
Watershed.
The largest river in California, the Sacramento River's watershed covers a large portion of the northern portion of the state and is situated almost entirely within California's boundaries, with the historically rare exception of the northernmost Pit River, which once received outflow of the now endorheic (closed) Goose Lake drainage basin in southern Oregon. Almost the entire basin lies between the Sierra Nevada and Cascade Range on the east and the Coast Ranges and Klamath Mountains in the west. The Sacramento's longest tributary, the Pit River, has the distinction of being one of three rivers that cut through the main crest of the Cascades; its headstreams rise on the western extreme of the Basin and Range Province, east of major Cascade volcanoes such as Mount Shasta and Lassen Peak. The other two are the Klamath River and Columbia River.
By discharge, it is the second-largest contiguous U.S. river draining into the Pacific, after only the Columbia River, which has almost seven times the flow of the Sacramento. The Colorado River, which reaches the Gulf of California just south of the US-Mexico border near the southeast part of the state, is far larger than the Sacramento by both length and drainage area but has a slightly smaller flow. After the Colorado and San Joaquin, it has the third-largest drainage basin in California. The Sacramento, when combined with the Pit, is also one of the longest rivers in the United States entirely within one state—after Alaska's Kuskokwim and Texas' Trinity.
The major drainage basins bordering that of the Sacramento are that of the Klamath in the north, the San Joaquin and Mokelumne to the south and the Eel River in the west. The Russian River also lies to the west and the endorheic (closed) Honey Lake and Eagle Lake basins to the north. On the east side are many endorheic watersheds of the Great Basin including the Truckee River and Carson River. Parts of the Sacramento watershed come very close to, but do not extend past, the border of California and Nevada.
The basin's diverse geography ranges from the glacier-carved, snowcapped peaks of the Sierra Nevada to the sea-level (and often lower) marshes and agricultural lands of the Sacramento-San Joaquin Delta. The highest point is Mount Shasta, a stratovolcano that stands 14104 ft high, near the headwaters of the Sacramento River. Subsidence caused by wind erosion and other phenomena slowly caused the land in the delta to sink for years; many of the delta islands would be underwater if not for the maintenance of the levees that keep them dry. Many of the "islands" are now up to 25 ft below the surrounding water. The Sierra Nevada generally decreases in height from south to north—from 10000 to near Lake Tahoe, east of the American River, to just 6000 ft as they merge into the Cascades and Modoc Plateau in the Lassen Peak area; however, on the west side, the Coast Ranges area is the opposite, increasing from 2000 to in the south to just shy of 10000 ft in the north. The volcanic plateaus in the northeast, which comprise relatively flat terrain, typically lie at elevations of 3000 to. Most of the Sacramento Valley is below 300 ft in elevation; in its lower course, the Sacramento River drops only about 1 ft per mile.
Most of the Sacramento River's valley is intensely cultivated, with some 2000000 acre of irrigated farmland. Medium to dense forests occupy most of the mountains, many of which lie on U.S. Forest Service lands. Sparse grasslands and high desert stretch to the north. Along with the agrarian base, the basin is also home to about 2.8 million people, far more than half of whom live within the Sacramento metropolitan area. Other important cities are Chico, Redding, Davis and Woodland. The Sacramento River watershed covers all or most of Shasta, Tehama, Glenn, Butte, Plumas, Yuba, Sutter, Lake and Yolo Counties. It also extends into portions of Siskiyou, Modoc, Lassen, Lake (in Oregon), Sierra, Nevada, Placer, El Dorado, Sacramento, Solano and Contra Costa Counties. The river itself flows through Siskiyou, Shasta, Tehama, Butte, Glenn, Colusa, Sutter, Yolo, Sacramento, Solano and Contra Costa, often forming boundaries between the counties.
The Sacramento River watershed includes large areas of forests such as the Mendocino and Trinity National Forests in the Coast Ranges, Shasta and Lassen National Forests in the southern Cascades and the Plumas, Tahoe and Eldorado National Forests on the western slopes of the Sierra Nevada. The watershed also has Lassen Volcanic National Park, which covers 106000 acre centered around Lassen Peak, the southernmost Cascade volcano. Whiskeytown-Shasta-Trinity National Recreation Area, which is over 200000 acre in size, straddles much of the upper Sacramento and Trinity Rivers, centering around three popular man-made lakes–Shasta Lake, Trinity Lake and Whiskeytown Lake. Many other state parks and recreation areas lie within the watershed.
Geology.
By geologic standards, the Sacramento is a fairly young river; the borders of its watershed began to form only a few million years ago as magma welling up below the Earth's crust pushed up by the Pacific Plate colliding with the North American Plate caused the formation of the Sierra Nevada. Although mountains had existed as early as 100 million years ago in this region (before then the land was probably submerged under the Pacific), they were worn by erosion, and the present-day range only formed about 4 million years ago. The northern part of the Sacramento watershed is more ancient, and was formed by intense volcanic activity over 25 million years ago, resulting in lava flows that covered and created the Modoc Plateau, through which the Pit River flows. Mount Shasta and Lassen Peak are among the numerous Cascade Range volcanoes that still stand in the area.
As the Sierra rose, the ancestors of the Sacramento's east side tributaries and numerous glaciations carved deep canyons in the mountains, depositing massive amounts of silt between the Sierra Nevada and the Pacific, slowly building up the floor of the Sacramento Valley. The Sacramento River did not form until multiple terranes were formed and smashed into the North American Plate from the Pacific Plate about 3 million years ago. The resulting geologic folding pushed up the California Coast Ranges and Klamath Mountains, enclosing the Sacramento Valley and forcing the streams within to flow south instead of west and forming the ancestral Sacramento River. It is believed that the river once had its outlet in Monterey Bay (forming the 300 mi Monterey Submarine Canyon when sea levels were lower during the Ice Ages). While the Coast Ranges are young by geologic standards, only a few million years old, the Klamath Mountains reached their present form some 7.5 million years ago.
The Monterey Bay outlet of the Sacramento and San Joaquin rivers was blocked off about 2 million years ago, and runoff from the Sierra began to transform the Central Valley into a gigantic lake, called Lake Clyde. This lake stretched 500 mi north to south and was at least 1000 ft deep. About 650,000 years ago the lake catastrophically overflowed, draining into San Francisco Bay and creating the Carquinez Strait, the only major break for hundreds of miles in the Coast Ranges. The narrow outlet trapped some of the sediments of the rivers in the Central Valley, forming the Sacramento-San Joaquin Delta. For thousands of years, this inland sea would periodically reform during times of intense flooding, the most recent being the Great Flood of 1862. Dams and canals that control the river now prevent this phenomenon from occurring in most years.
History.
The Sacramento River and its valley were one of the major American Indian population centers of California. The river's abundant flow and the valley's fertile soil and mild climate ensured enough resources for hundreds of groups to share the land. Most of the villages were small. Although it was once commonly believed that the original natives lived as tribes, they actually lived as bands, or family groups as small as twenty to thirty people. The Sacramento Valley was first settled about 12,000 years ago, but permanent villages were not established until about 8,000 years ago. Historians have organized the numerous separate original native groups into several "tribes". These are known as the Shasta, Modoc, and Achomawi/Pit River Tribes of the volcanic plateaus in the north; the Wintu and Hupa in the northern Klamath and Trinity mountains; the Nomlaki, Yuki, Patwin, and Pomo of the Coast Ranges; the Yana, Atsugewi, Maidu, Konkow, and Nisenan in the Sierra and their western foothills; and the Miwok in the south.
Life for Native Americans in the Sacramento Valley was relatively simple and involved little violence. Little agriculture was practiced; most were hunter-gatherers and fishermen. Settlement size ranged from small camps to villages of 30–50 permanent structures. As with tribes in the San Joaquin Valley and throughout much of California, the acorn was a staple food. The historic abundance of live and valley oaks in the Sacramento Valley was capable of supporting a large population. American Indians usually pounded the acorns into flour, which they used to make bread and cakes. Despite the prevalence of acorns in their diet, they also consumed a variety of other foods—wild roots, seeds, berries, and game that included fish, deer, rabbits, and birds. The natural abundance of the Sacramento River and its valley, along with the San Joaquin, probably once supported most of California's original 275,000–300,000 Native Americans.
The first outsiders to see the river were probably the members of a Spanish colonial-exploratory venture to Northern California in 1772, led by Captain Pedro Fages. The group ascended a mountain, likely in the hills north of Suisun Bay, and found themselves looking down at the delta of the Sacramento and San Joaquin Rivers. However, due to their vantage point, neither Fages nor any of his men saw the Sacramento clearly. They assumed that the San Joaquin, coming from the south, was the largest of the merging rivers they saw. In 1808, explorer Gabriel Moraga, on a journey to find suitable sites for the construction of missions, became the first foreigner to see the river clearly. Judging its huge breadth and power he named it "Rio de los Sacramentos", or "River of the Blessed Sacrament". In the following years, two more Spanish expeditions traversed the lower part of the river, the last one in 1817.
The next visitors were Hudson's Bay Company (HBC) fur trappers exploring southwards from the disputed Oregon Country, starting in the 1820s. The first organized expedition, led by Peter Skene Ogden, arrived in the area of Mount Shasta in 1826. By this time, California was under the control of Mexico, although few Mexican settlers had come to what would later become the state, mostly settling in the small "pueblos" and "ranchos" along the south and central coast. The HBC mountain men created the Siskiyou Trail out of several Native American paths that ran through the mountains between Oregon's Willamette Valley and the northern part of the Sacramento Valley. In the years to come, this path, which eventually extended from San Francisco to Portland, Oregon following parts of the Sacramento, Willamette, Klamath, Rogue, and other rivers would become an important trade and travel route.
Although just one of thousands of American emigrants that poured into California over the next few years when California became part of the United States, John Augustus Sutter became one of the most significant settlers of the Sacramento River valley. In 1841, he and his men built a fortress at the confluence of the Sacramento and American Rivers (the latter of which was actually named by him) and he was granted almost 50000 acre of land surrounding the two rivers. Naming it New Helvetia, he created an agricultural empire in the lower Sacramento Valley, attracting hundreds of settlers to the area, and relied on Native American labor to maintain his domain. Sutter had something of a two-faced relationship with the many Native American groups in the area. He was friendly with some of the tribes, and paid their leaders handsomely for supplying workers, but others he seized by force and made them labor in his fields.
Sutter's prosperity, however, indirectly led to his financial demise, and the rise of one of the most significant events in California history. When one of his employees, James W. Marshall was assigned to build a sawmill on the South Fork American River in Sutter's interests, he discovered gold in the headrace. It was not long before the secret slipped out attracting three hundred thousand hopefuls from all over North America, and even the world, to the Sacramento River in search of fortunes, kicking off the California Gold Rush. People flocked to the region by the Oregon Trail-Siskiyou Trail, California Trail, Southern Immigrant Trail and various land and/or sea routes through the Isthmus of Panama and around southern South America by ship. Steamboats traveled busily up and down the Sacramento River carrying miners from San Francisco to the "gold fields".
As the miners expanded their diggings deeper into the Sierra Nevada and Klamath Mountains, Native Americans were pushed off their land and a long series of skirmishes and fights began that continued until intervention by the state and national governments.
The influx of migrants brought foreign diseases like malaria and smallpox, which American Indians had no immunity to. These diseases killed off a large proportion of their population within a few decades of the arrival of Sutter and the following settlers, the start of the gold rush, not to mention the numerous battles fought between the settlers and native bands as well as the forced relocation of some of the tribes to Indian reservations in several places scattered around the Sacramento Valley, mainly in the Coast Ranges. In the early 1850s, several treaties were signed between the U.S. government and the Native Americans involving their relocation onto a reservation in the Sierra foothills; this promise was broken, of course. Therefore in 1863, the tribes from the area surrounding the middle Sacramento and Feather rivers, the Konkow group, were removed and marched forcibly to the Round Valley Indian Reservation near the Eel River. A total of 461 people were forced from their homes, but only 277 made it to the reservation before dying of disease, starvation or exhaustion.
As mining developed from simple methods such as panning and sluicing to a new form of commercialized extraction, hydraulic mining, profits from the petering gold rush made a second leap, earning more profits than those miners in the early years had ever made. The city of Sacramento, founded on the original site of Sutter's fort, began to flourish as the center of an agricultural empire that provided food to feed the thousands of miners working in the hills as well as a place of financial exchange of all the gold that was mined. Sacramento was officially established in 1850 and was recognized as the state capital in 1854. As the economy of the Sacramento Valley grew, the Southern Pacific Railroad established tracks along the river to connect California with Oregon following the ancient path of the Siskiyou Trail, in the 1880s and 1890s. Many parts of the railroad were treacherous, especially in the mountainous areas north of Dunsmuir. It was not long after the city had reached a relatively large population of about 10,000, then the Great Flood of 1862 swept away much of it (and almost everything else along the Sacramento River) and put the rest under water. The flood waters were exacerbated by the sediments washed down by the millions of tons by hydraulic mining, which filled the beds of the Sacramento, Feather and American rivers up to 7 ft in Sacramento and also covered thousands of acres of Central Valley lands. A flood in 1875 covered the city of Marysville and when it subsided the town's streets were filled with debris and rocks washed down from the "hydraulicking" going on upstream.
Repeated floods and increased demand for Sacramento River water saw a plethora of massive changes to the environment beginning in the 20th century. An early project was undertaken to raise the entire city of Sacramento about 11 ft above its original elevation. This, however, was followed by engineering projects to try and stem the flows of water rather than defend against it. The engineering era of the 20th century on the Sacramento thus begun.
Dams and water use.
In the late 19th century through the 20th, California experienced an economic boom that led to the rapid expansion of both agricultural and urban infrastructure. The Central Valley was becoming a heavily developed irrigation farming region, and cities along the state's Pacific coast and the Sacramento and San Joaquin rivers were growing rapidly, requiring ways to manage the river's water to prevent flooding (and resulting economic loss) on one hand, and to ensure a consistent supply of it on the other. The U.S. Army Corps of Engineers and the state of California completed reports as early as the 1870s and 1880s that detailed the geography and water supplies of the Sacramento, Feather, Yuba and Bear rivers.
Back in 1873, Colonel B.S. Alexander of the Army Corps of Engineers had written in his surveys of the Central Valley's hydrology and irrigation systems of a great network of pumps and canals that would take water from the water-rich Sacramento River basin into drought-prone South and Central California, especially the San Joaquin Valley. The Sacramento River is often said to receive "two-thirds to three-quarters of northern California's precipitation though it has only one-third to one-quarter of the land. The San Joaquin River watershed occupies two-thirds to three quarters of northern [central] California's land, but only collects one-third to one-quarter of the precipitation."
During the Great Depression in the 1930s, the first plans for statewide water engineering projects emerged backed by first the Californian, then the United States government. The California State Water Project and Central Valley Project both began their rise to reality during this period. Both began as brainchilds of the state government, but because of lack of funds, the construction work and costs were shifted to the federal U.S. Army Corps of Engineers and U.S. Bureau of Reclamation. As the construction of dams, power plants and canals required immense labor, which was rare in the middle of the Depression, the government authorized Sacramento River dams and other structures as public works projects beginning in 1935.
Construction of Shasta Dam, the main dam on the Sacramento, started in 1938 and was completed in 1945. Capable of absorbing enormous flood flows and storing the water for use in prolonged drought as well as navigation and electricity generation, it gave inhabitants of the Sacramento Valley nearly complete control over the whims of the river. In the following decades, more dams–huge dams hundreds of feet high and capable of storing millions of acre-feet of water–were constructed on the Sacramento's main tributaries: the Pit, Feather and American. Folsom Dam, Oroville Dam and New Bullards Bar Dam, built in the 1950s and '60s for both the State Water Project and the Central Valley Project, are among the most important. With a firm water management system in place, the Sacramento River's flow was thus regulated and a highly controlled regime of irrigation and water diversions was able to begin.
Part of the purpose of constructing dams on the Sacramento was to regulate flows for irrigation agriculture purposes. After the river's flow was under control, two major canals serving the western side of the Sacramento Valley – the Tehama-Colusa and Corning Canals. Both starting at the Red Bluff Diversion Dam on the Sacramento, the two canals are 111 mi and 21 mi long respectively, and divert a total of over 3000 cuft/s from the river to serve some 100019 acre of land. A third major canal, the Sacramento River Deep Water Ship Channel, exists not for irrigation purposes but rather to facilitate navigation of large oceangoing ships from the Delta to the city of Sacramento. Built by the Army Corps of Engineers, the canal is 43 mi long and is maintained to 30 ft deep.
In 1959, construction began on the final link for the Sacramento-San Joaquin River water system, the California Aqueduct. A series of dams, dikes, channels and pump plants was constructed in the Delta to facilitate water flow from the Sacramento into this huge man-made river, which can carry up to 5834 cuft/s of water. From its origin at the Delta the canal runs some 444 mi southwards through the west side of the San Joaquin Valley, providing irrigation water to farmlands along its length. The remainder is then powered over the Tehachapi Mountains via a 3000 ft pump lift. The Aqueduct's waters, which functionally extend the Sacramento River southwards, then run on to serve the enormous populace of California's south, supplying the needs of some 22 million people.
Over the years, several other plans materialized to take water from "other" drainage basins into that of the Sacramento to bolster the river's petering discharge. A successful one was the Trinity River diversion, which sent over 90 percent of the flow of that river into the Sacramento through a tunnel under the Klamath Mountains. Because of resulting ecological destruction and fish kills, less water is diverted today than a few decades ago. Others failed to take root – one of the most notorious, the Klamath Diversion, proposed to send the entire flow of the Klamath River into the Sacramento Valley through a complex system of reservoirs, canals, flumes and tunnels. Similarly, the Dos Rios Dam project would have diverted almost the entire flow of the Eel River to the Sacramento. Both projects were defeated by locals' and environmentalists' opposition, as well as, for the former, staggering costs.
Ecology.
The Sacramento River and its drainage basin were originally abundant in multiple avian and aquatic species, but modern-day development has thinned populations of many species, especially riverine. The river's once-ample stretches of riparian zones and marshes, supported by its wide variations in flow, as well as the wetlands downstream in the Delta, have mostly been replaced by agricultural lands. The Sacramento supports 40–60 species of fish, and 218 types of birds. The basin is relatively abundant in endemic amphibian and fish species. It is surmised that between four and five million years ago, the Sacramento and Snake–Columbia River systems were somehow connected by a series of now-dry wetlands and river channels. Many of the fish in the present-day river are similar to those of the other, indicating a possible link sometime in the past. The Sacramento and San Joaquin also have the southernmost runs of five species of anadromous fish.
Wildlife along the Sacramento has been hurt severely by the heavy usage of Sacramento River water for agriculture and urban areas, and pollution caused by pesticides, nitrates, mine tailings, acid mine drainage and urban runoff. Located along the Pacific Flyway, the sprawling marshlands of the Sacramento Valley were originally an important stop for migratory birds; only a few wetlands remain today, either preserved or artificially constructed. Native bird populations have been declining steadily throughout the 19th, 20th and 21st centuries. Species that were once common but now are gone or endangered include the southwestern willow flycatcher, western yellow-billed cuckoo, least Bell's vireo, and warbling vireo. Another reason for dropping numbers are the introduction of non-native species, such as the "parasitic" cowbird, which steals the nests of other birds to use as its own.
There were once 9 species of amphibians that used the Sacramento River, but some have become extinct and the population of the others are declining drastically due to the loss of their habitat. Amphibians originally thrived in the marshes, sloughs, side-channels and oxbow cutoffs because of their warmer water, abundance of vegetation and nutrients, lower population of predators, and slower current. Encroachment of agricultural and urban land has eliminated most of this habitat. This population once included several species of frogs and salamanders; the foothill yellow-legged frog and western spadefoot are listed as endangered species.
The riparian areas along the Sacramento once totaled more than 500000 acre; today only about 10000 acre remains. Much of it consists of restored stretches, and there is also a significant amount of artificial wetland in the watershed. River control has prevented the Sacramento from its natural flooding, braiding and course-changing patterns, which are important for the maintenance of existing wetlands and the creation of new ones. Since the 1860s, the river has been mostly locked in its channel, which once could shift hundreds of feet or even several miles in a year because of floods. These wetlands originally flooded every winter and spring, but levee construction, agricultural encroachment and the construction of dams upstream have also eliminated the flooding process. Today about 100 mi of the river’s riparian forests are undergoing active restoration.
Anadromous fish.
"The Sacramento River fall chinook stock is the driver of commercial and recreational salmon fisheries off California and most of Oregon."
Pacific Fishery Management Council, 2008
Second only to the Columbia River on the west coast of the United States in Chinook salmon runs, the Sacramento and its tributaries once supported a huge population of this fish. Millions of salmon once swam upstream to spawn in the Sacramento; as recently as 2002 eight hundred thousand fish were observed to return to the river.
Starting in the 20th century, dam construction blocked off hundreds of miles of salmon-spawning streams, such as the upper Feather and American Rivers, and the entirety of the Pit and upper Sacramento rivers. Pollution from farms and urban areas took a heavy toll on the river's environment, and heavy irrigation withdrawals sometimes resulted in massive fish kills. Since 1960, when the big pumps at the head of the California Aqueduct in the Delta began their operation, the outflow of fresh water into the Pacific has been reduced to a trickle leaving the fish confused as to where to go, resulting in many generations dying off because they have not been able to find their way upstream. In 2004, only 200,000 fish were reported to return to the Sacramento; in 2008, a disastrous low of 39,000.
In 1999, five hydroelectric dams on Battle Creek, a major tributary of the Sacramento River, were removed to allow better passage of the fish. Three other dams along the creek were fitted with fish ladders. The river is considered one of the best salmon habitats in the watershed because of its relatively cold water and the availability of ideal habitat such as gravel bars.
By the late 20th and early 21st centuries, the government blamed crashing fish populations on overfishing, especially off the Northern California and Oregon coast, which lie directly adjacent to the migration paths of Sacramento River salmon. This has resulted in a ban on coastal salmon fishing for several years since 2002. The Red Bluff Diversion Dam, although not a large dam and equipped with fish passage facilities, also presents a major barrier. Because of inadequate design, roughly 25–40% of the incoming fish get blocked by the dam each year. The dam has also become a "favorite spot" for predatory fish to congregate, feasting on the salmon that get trapped both above and below the dam. As of 2010, the salmon run has shown slight signs of improvement, probably because of that year's greater precipitation.
In 1995, a gate on the Folsom Dam on the American River broke open, causing the river's flow to rise by some 40000 cuft/s. The water traveled down the Sacramento and washed into the Pacific; the influx of fresh water was such that it confused thousands of anadromous fish to begin migrating up the river, thinking that the river had risen because of late-autumn storms.
Whales.
Marine animals such as whales and sea lions are occasionally found far inland after navigating the river for food or refuge and then losing track of how to get back to the Pacific Ocean. In October 1985 a humpback whale affectionately named "Humphrey the humpbacked whale" by television media traveled 69 mi up the Sacramento River before being rescued. Rescuers downstream broadcast sounds of humpback whales feeding to draw the whale back to the ocean.
On May 14, 2007, onlookers and media spotted two humpback whales traveling the deep waters near Rio Vista. The duo, generally believed to be mother and calf (Delta, the mother and Dawn, her calf), continued to swim upstream to the deep water ship channel near West Sacramento, about 90 mi inland. There was concern because the whales had been injured, perhaps by a boat's propeller or keel, leaving a gash in each whale's skin. The whales were carefully inspected by biologists and injected with antibiotics to help prevent infection. After days of efforts to lure (or frighten) the whales in the direction of the ocean, the whales eventually made their way south into San Francisco Bay, where they lingered for several days. By May 30, 2007, the cow and calf apparently slipped out unnoticed under the Golden Gate Bridge into the Pacific Ocean, likely under cover of night.
Pollution.
For a river of its size, the Sacramento is considered to have fairly clean water. However, pollutants still flow into the river from many of its tributaries and man-made drains or channels. Pesticide runoff, especially DDT, is one of the largest problems faced today, because of the valley's primarily agricultural economy. Increased erosion caused by the removal of riparian vegetation and the runoff of fertilizers into the river have led to occasional algae blooms, though the water is usually cold because of the regulation of dams upstream. Other pollutant sources include urban runoff, mercury and even rocket fuel that was reported to have leaked near the American River from an Aerojet extraction project.
Mercury pollution created by mining and processing activities during the California Gold Rush still has a profound impact on the Sacramento River’s environment. The toxic substance was widely used by miners to separate gold from the surrounding rocks and dirt, and was disposed of by allowing it to evaporate. Most of the mercury was mined in the Coast Ranges to the west of the Sacramento River; mines in these mountains produced roughly 140,000 tons of mercury to serve the Gold Rush. When the gold rush ended, most of the mines were closed but toxic acidic water and chemicals continue to leak from within, into west-side Sacramento tributaries such as Cache Creek and Putah Creek. In the east, mercury that permeated into the ground has contaminated several aquifers that feed rivers such as the Feather, Yuba and American. Even the evaporated mercury posed problems – so much of it was used that significant concentrations still linger in the air in many places. Mercury pollution continues today and will probably continue for decades or centuries into the future.
In July 1991, a train derailed near Dunsmuir, California alongside the Sacramento River. A tank car split open, spilling about 19,500 gallons of the pesticide metam sodium into the river. The chemical formed a stinking, bubbling, green glob that moved 45 mi down the river, killing everything in its path. More than one million fish were killed, including at least 100,000 rainbow trout, and thousands of other aquatic creatures as well as nearby trees. Next, the green glob entered Shasta Lake, California’s largest reservoir. Fortunately, a system of aerating pipes at the bottom of the lake had been set up to dissipate the chemical, reducing it to almost nothing by the 29th, preventing further environmental destruction. The tank car carrying the metam sodium through California was of a type that the National Transportation Safety Board said had “a high incidence of failure” in accidents. Furthermore, the tank car was not labeled, so the train’s crew didn’t know that they were hauling a dangerous chemical.

</doc>
<doc id="37395" url="http://en.wikipedia.org/wiki?curid=37395" title="Celebration, Florida">
Celebration, Florida

Celebration is a census-designated place (CDP) and a master-planned community in Osceola County, Florida, United States, located near Walt Disney World Resort and originally developed by The Walt Disney Company. As part of the Orlando–Kissimmee Metropolitan Statistical Area, Celebration's population was 7,427 at the 2010 census.
Subsequent to founding Celebration, Disney followed its plans to divest most of its control of the town. Several Disney business units continue to occupy the town's office buildings, and two utility companies, Smart City Telecom and Reedy Creek Energy Services, both operated from Walt Disney World, provide services to the town. The town itself remains directly connected to the Walt Disney World resorts via one of its primary streets, World Drive, which begins near the Magic Kingdom.
Downtown Celebration's post office was designed by Michael Graves, the adjacent Welcome Center is by Philip Johnson and the Celebration Health building by Robert A. M. Stern. 
Other nearby buildings are designed by well known architects including: Charles Moore (Preview Center), Graham Gund (Bohemian Hotel), Cesar Pelli (movie theatre), Robert Venturi and Denise Scott Brown (SunTrust Bank).
Response to Celebration has ranged from an early visitor who said it resembled the too-perfect town of ""The Stepford Wives"," to those who see Celebration as an example of unabashed neo-urbanism.
History.
In the early 1990s, the Disney Development Company (DDC) established the Celebration Company to spearhead its development within approximately 4900 acre of land in the southern portion of the Reedy Creek Improvement District. Total investment for the project is estimated at US$2.5 billion.
The master plan was developed by Cooper, Robertson & Partners and Robert A. M. Stern, and the extensive landscape, parks, trails and pathways were designed by the San Francisco firm EDAW (now AECOM). Celebration is planned in an early 20th-century architectural style and is not zoned for high-density residences. Celebration was named the "New Community of the Year" in 2001 by the Urban Land Institute.
The first phase of residential development occurred in the summer of 1996 with Celebration Village, West Village and Lake Evalyn; this was followed by the North Village, South Village, East Village and Aquila Reserve and the final Artisan Park phases. Disney CEO Michael Eisner took an especially keen interest in the development of the new town in the early days, encouraging the executives at Disney Development Company to "make history" and develop a town worthy of the Disney brand and legacy that extended to Walt Disney's vision of an Experimental Prototype Community of Tomorrow (EPCOT). DDC executives collaborated extensively with leaders in education, health and technology in addition to planners and architects to create the vision and operating policies for the town.
Geography.
Celebration is located at (28.320059, −81.540149).
According to the United States Census Bureau, the CDP has a total area of 10.7 sqmi, of which 0.04 sqmi, or 0.28%, is water.
Celebration is under USPS ZIP code 34747, sometimes known as Kissimmee, Florida. This is due to the city's being unincorporated, as Celebration is not a subdivision and is still considered an unincorporated town.
Demographics.
As of the census of 2010, there were 7,427 people, 3,063 households, and 716 families residing in the CDP. The population density was 704.9 people per square mile (99.0/km²). There were 4,566 housing units at an average density of 102.4/sq mi (39.6/km²). The racial makeup of the CDP was 91.0% white (with 81.9% of the population non-Hispanic white), 1.5% black, 3.2% Asian, 2.2% from two or more races and 0.26% Native American. Hispanics or Latinos of any race were 11.2% of the population.
There were 3,063 households, out of which 32.7% had children under the age of 18 living with them, 57.0% were married couples living together, 4.5% had a female householder with no husband present, and 35.0% were non-families. 24.3% of all households were made up of individuals and 3.6% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.96.
The age distribution was 25.6% under the age of 18, and 9.2% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 94.7 males. For every 100 females age 18 and over, there were 93.5 males.
The median income for a household in the CDP was $74,231, and the median income for a family was $92,334. Males had a median income of $51,250 versus $46,650 for females. The per-capita income for the CDP was $39,521, and 4.1% of the population lived below the poverty line.
City life.
Community.
Celebration has a variety of community organizations that maintain the town; "each play a role in the governance of Celebration." There are also seven registered Christian churches, one Hospital Ministry, and one Jewish congregation.
There are parks throughout the town as well as a fire department, post office, schools, a hospital, and a golf course.
Downtown.
Celebration Town Center contains shops, restaurants, and other commercial establishments.
The Celebration Hotel hosted the Tampa Bay Buccaneers during training camp until the 2009 season when the team moved training camp back to Tampa Bay. In autumn, leaf-shaped confetti shoots out of the lamp posts on Market Street to simulate falling leaves. During the holiday season, suds pour out of the lamp posts to replicate snow while Christmas music streams from the sidewalks.
There is a water fountain that comes out from the ground for children to play in located next to the lake, surrounded by palm trees and benches.
Commerce.
The community started with a small number of merchants that the Disney Company selected. There are now more than five hundred registered companies listed as doing business in the shopping plazas, small office complexes, and the Disney World office building park. This community does hold the only Class A office buildings in Osceola County. There is a high number of home businesses.
Villages.
Celebration is separated into areas referred to as "villages." The main village, closest to downtown, is where the first homes were constructed. North Village, closest to U.S. 192, houses the Georgetown Condos as well as Acadia Estate Homes. East Village includes Roseville Corner and Aquila Loop. Lake Evalyn, generally considered its own area of Celebration but not quite its own village, includes a small lake where one can find a multitude of ducks, alligators, and the occasional river otter. South Village houses the Spring Park Loop estate homes and Heritage Hall. Additionally, Siena Condos complete the outer edge of South Village by Celebration Blvd. Mirasol includes condos with concierge service and a day spa. Artisan Park is at the end of Celebration Ave and houses condos, town homes, single-family residences as well as a clubhouse consisting of a pool, gym, and restaurant.
Homes and condominiums are constructed along streets, with garages and garbage pickup done in narrow but paved alleyways behind the homes, keeping the look of home fronts and sidewalks pristine. Utility service is underground.
Transportation.
91% of residents who work outside their homes drive to work.
Most residents do not often drive long distances and there are a high amount of smart cars or low-speed vehicles to travel around the town.
Contrary to its design as a quintessential American town, Celebration does not have any road named Main Street. This is because there was already a Main Street in Osceola County, and street names cannot be duplicated in the county. The two main roads going through the center of the downtown area are named Market Street and Front Street. Other streets in Celebration include:
This is considered the main road in the town. The road stretches from U.S. 192 to Artisan Park where it ends in a traffic circle. Starting from U.S. 192 near the Disney Parks and the Celebration water tower, you can find a small shopping plaza. From there, Celebration Avenue passes the North Village, splits the Celebration golf course, winds through a few down-town shops and schools, and then proceeds into the parks and homes in the newer sections of Celebration.
Celebration Boulevard has two sections. The most public section is an avenue parallel to I-4 that includes many commercial businesses and Celebration High School. The architecture on the street is mostly Celebration Modern style. This style reflects art Streamline Moderne and Art Deco influences with its sleek lines, sparse but effective ornamentation, and ample opportunities for individually expressive special features. The entire street is lined with two rows of Washington Palms. The buildings on the street include sitting areas under the shade of trees and trellises along their frontage. The other section of Celebration Boulevard lies on the other side of the golf course, closer to the Celebration Water Tower in the North Village. Here, Celebration Boulevard is almost completely residential. In addition to the homes perched behind white picket fences, this section of Celebration Boulevard flows past the Georgetown condominiums, the community pool, and soccer fields.
Celebration Place nearly spans the gap between the two sections of Celebration Boulevard, except that its eastern end terminates at the Water Tower Plaza instead of at the entrance to North Village on the other side of State Road 417. Celebration Place is a commercial road.
Health.
The community is home to a 174-bed hospital operated by Florida Hospital that resembles a resort-style facility. Celebration Health has been recently expanded, and also houses a gym, the Fitness Centre. College Gameday host Lee Corso's brother Ralph Corso is a trainer at the fitness centre.
Events.
Celebration hosts many events every year, including community-wide yard sales, an art show, an exotic car festival, an annual Radio Disney Holiday concert, an Oktoberfest Celebration, the "Great American Pie Festival" (televised on The Food Network)
, a "Posh Pooch" festival, and downtown events for the Fall and Christmas seasons when autumn leaves and "snow" (small-scale soap flakes) are released into the Town Center. The community also hosts a large Independence Day fireworks celebration. The town events are organized on the Internet by the Community Calendar. Chris Fowler performed the star spangled banner during Fourth of July celebrations in Celebration in 2006.
Education.
The School District of Osceola County, Florida operates public schools in Celebration. Celebration is zoned to the Celebration School for K-8. Celebration High School, located in the city, serves Celebration for grades 9–12. There are private education options provided by the Montessori School of Celebration (K-8). Private graduate education is available at Stetson University Celebration Campus. There are free classes offered at the community center by clubs for cooking, gardening, art, writing, and technology.
The Osceola Library System operates the West Osceola Branch Library in Celebration.
References.
</dl>

</doc>
<doc id="37397" url="http://en.wikipedia.org/wiki?curid=37397" title="Epcot">
Epcot

Epcot is the second of four theme parks built at Walt Disney World in Bay Lake, Florida, near the city of Orlando. It opened as EPCOT Center on October 1, 1982, and spans 300 acres, more than twice the size of the Magic Kingdom park. It is dedicated to the celebration of human achievement, namely technological innovation and international culture, and is often referred to as a "permanent World's Fair." In 2013, the park hosted approximately 11.22 million guests, making it the fifth most visited theme park in the world.
The park is represented by Spaceship Earth, a geodesic sphere that also serves as an attraction. Epcot was known as EPCOT Center until 1994, when it was later renamed Epcot '94, then Epcot '95 the following year.
Dedication.
To all who come to this place of joy, hope of enterprise and concepts of a future that promises new and exciting benefits for all. May EPCOT Center entertain, inform and inspire and above all, may it instill a new sense of belief and pride in man's ability to shape a world that offers hope to people everywhere in the world.—E. Cardon Walker, October 24, 1982
History.
EPCOT is an acronym for Experimental Prototype Community of Tomorrow; a utopian city of the future planned by Walt Disney, often interchanging "city" and "community." In Walt Disney's words: "EPCOT will take its cue from the new ideas and new technologies that are now emerging from the creative centers of American industry. It will be a community of tomorrow that will never be completed, but will always be introducing, and testing, and demonstrating new materials and new systems. And EPCOT will always be a showcase to the world of the ingenuity and imagination of American free enterprise." His original vision was for a model community which would have been home to twenty thousand residents and a test bed for city planning as well as organization. It was to have been built in the shape of a circle with businesses and commercial areas at its center with community buildings, schools, and recreational complexes around it while residential neighborhoods would line the perimeter. This radial plan concept is strongly influenced by British planner Ebenezer Howard and his Garden Cities of To-morrow. Transportation would have been provided by monorails and PeopleMovers (like that in Magic Kingdom's Tomorrowland.) Automobile traffic would be kept underground, leaving pedestrians safe above ground. The original model of EPCOT can still be seen by passengers riding the Tomorrowland Transit Authority attraction in the Magic Kingdom park; when the PeopleMover enters the showhouse for Stitch's Great Escape!, the remaining portion of the model is visible on the left (when facing forward) behind glass. Walt Disney was not able to obtain funding and permission to start work on his Florida property until he agreed to first build Magic Kingdom. He died nearly five years before Magic Kingdom opened.
After Disney's death, The Walt Disney Company decided that it did not want to be in the business of running a city without Walt's guidance. The model community of Celebration, Florida has been mentioned as a realization of Disney's original vision, but Celebration is based on concepts of new urbanism which is radically different from Disney's modernist and futurist visions. However, the idea of EPCOT was instrumental in prompting the state of Florida to create the Reedy Creek Improvement District (RCID) and the Cities of Bay Lake and Reedy Creek (now Lake Buena Vista), a legislative mechanism allowing the Walt Disney Company to exercise governmental powers over Walt Disney World. Control over the RCID is vested in the landowners of the district, and the promise of an actual city in the district would have meant that the powers of the RCID would have been distributed among the landowners in EPCOT. Because the idea of EPCOT was never implemented, the Disney Corporation remained almost the sole landowner in the district allowing it to maintain control of the RCID and the cities of Bay Lake and Lake Buena Vista; Disney further cemented this control by deannexing Celebration from the RCID.
The original plans for the park showed indecision over the park's purpose. Some Imagineers wanted it to represent the cutting edge of technology, while others wanted it to showcase international cultures and customs. At one point, a model of the futuristic park was pushed together against a model of a World's Fair international theme, and the two were combined. The park was originally named EPCOT Center to reflect the ideals and values of the city. It was constructed for an estimated $800 million to $1.4 billion and took three years to build, at the time the largest construction project on Earth. The parking lot serving the park is 141 acres (including bus area) and can accommodate 11,211 vehicles (grass areas hold additional 500+ vehicles). Before it opened on October 1, 1982, Walt Disney World Ambassador Genie Field introduced E. Cardon Walker, Disney's chairman and CEO, who dedicated EPCOT Center. Walker also presented a family with lifetime passes for the two Walt Disney World theme parks. His remarks were followed by Florida Governor Bob Graham and William Ellinghouse, president of AT&T.
As part of the opening-day ceremony, dancers and band members performed "We've Just Begun to Dream". The Sherman Brothers wrote a song especially for the occasion entitled "The World Showcase March". During the finale, doves and many sets of balloons were released. Performing groups representing countries from all over the world performed in World Showcase. Water was gathered from major rivers across the globe and emptied into the park's fountain of nations ceremonial containers to mark the opening. Located at the front of the park is a plaque bearing Walker's opening-day dedication, as seen above.
Areas.
Epcot is divided into two main themed areas, Future World and World Showcase.
Future World.
Future World consists of a variety of pavilions that explore innovative aspects and applications including technology and science. Future World also serves as the park's main entrance and features the park's iconic landmark, Spaceship Earth, a large geodesic sphere structure which houses a themed attraction inside. Originally, each pavilion of Future World featured a unique circular logo which was featured on park signage and the attractions themselves. The logos, including that of Epcot itself, have been phased out over recent years, but some remnants are still scattered throughout the park; the pavilions are now instead identified by name and recognized by the main attraction(s) housed inside. The various pavilions located in Future World include the following:
Corporate sponsorships.
Each pavilion was initially sponsored by a corporation which helped fund its construction and maintenance in return for the corporation's logos and some marketing elements appearing throughout the pavilion. For example, Universe of Energy was sponsored by Exxon from 1982 to 2004, and The Land was sponsored by Kraft from 1982 to 1993, then Nestlé from 1993 to 2009. Each pavilion contains a private "VIP area" for its sponsor with offices, lounges, and reception areas hidden away from regular park guests. While some pavilions still retain active sponsorships, in recent years several pavilions have lost sponsorships due to lack of interest from partner companies in renewing expiring agreements. After General Electric left Horizons in 1993, it closed for a couple of years, then reopened temporarily while neighboring attractions Universe of Energy and World of Motion were renovated. Horizons closed permanently on January 9, 1999 and was demolished in the summer of 2000 to make room for the opening of Mission: SPACE on October 9, 2003. Metlife sponsored Wonders of Life from 1989 to 2001, until that area was closed. However, the Wonders Of Life pavilion is still mostly intact and is used for both the Flower and Garden Festival and the Food and Wine Festival. Current active sponsorships include the following:
World Showcase.
World Showcase is a large area reminiscent of a permanent world's fair containing eleven pavilions, each themed and dedicated to represent a specific country. The eleven pavilions surround the World Showcase Lagoon, a large man-made lake located in the center of World Showcase with a perimeter of 1.2 mi. In clockwise order, the eleven pavilions are:
Of the eleven pavilions, Norway and Morocco were not present at the park's opening, and were added later. Each pavilion contains themed architecture, landscapes, streetscapes, attractions, shops, and restaurants representing the respective country's culture and cuisine. In an effort to maintain the authenticity of the represented countries, the pavilions are primarily staffed by citizens of the respective countries as part of the Cultural Representative Program through J-1 visa agreements. Some pavilions also contain themed rides, shows, and live entertainment representative of the respective country. The only pavilion that is directly sponsored by the government of its respective country is Morocco, the remaining pavilions are primarily sponsored by private companies with affiliations to the represented countries.
Pavilions for Puerto Rico, Russia, Switzerland, Spain, Venezuela, United Arab Emirates, and Israel have occasionally been rumored as potential future pavilions but have never made it past the planning phases to date. The Israeli, Spanish, and an Equatorial Africa were even announced as coming soon in 1982, but never took off. Instead, a small African themed refreshment shop known as The Outpost currently resides where Equatorial Africa was to be. Israel, five African countries (Eritrea, Ethiopia, Kenya, Namibia, and South Africa), as well as eight other countries (Brazil, Chile, India, Indonesia, Saudi Arabia, Scotland, and Sweden) took part in the Millennium Village during the Millennium Celebration.
Contrary to popular belief, there are currently 9 undeveloped spots for countries around the World Showcase, including the space occupied by The Outpost. These spots are in between most of the countries, with the exceptions of Japan to The American Adventure, The American Adventure to Italy (both due to The American Adventure's reversed forced perspective, which would be ruined by pavilions immediately next to it), and Norway to China (separated only by a service road, they are the only two pavilions right next to each other).
International Gateway (Secondary Park Entrance).
A secondary park gate is located between the France and United Kingdom pavilions known as the International Gateway. The International Gateway is directly accessible to guests staying at nearby Epcot Area Resorts and also guests coming from Disney's Hollywood Studios via "Friendship" taxi boat travel or landscaped pedestrian walkways. The World Showcase usually opens two hours after park opening and remains open later than the Future World section of the park; however, most major attractions in Future World including Test Track, Soarin', Mission Space, The Seas with Nemo and Friends, and Spaceship Earth remain open until park close. Guests entering via this gate prior to the opening of World Showcase are directed by staff to Future World.
Alcohol policy.
Unlike the Magic Kingdom, which up until 2012 did not serve alcohol and now only services on a select limited basis, most stores and restaurants at Epcot, especially in the World Showcase, serve and/or sell a variety of alcoholic beverages including specialty drinks, craft beers, wines, and spirits reflective of the respective countries. The park also hosts the Epcot International Food & Wine Festival, an annual event featuring food and drink samplings from all over the world, along with live entertainment and special exhibits.
The World Showcase Adventure.
Originally based on the Disney Channel animated series "Kim Possible", the World Showcase Adventure is an interactive mobile attraction taking place in several pavilions throughout the World Showcase. The attraction is an electronic scavenger hunt that has guests using special "Kimmunicators" (in actuality, customized cell phones) to help teenage crime-fighters Kim Possible and Ron Stoppable solve a "crime" or disrupt an evil-doer's "plans for global domination." The "Kimmunicator" is able to trigger specific events within the pavilion grounds that provide clues to completing the adventure. Launched in January 2009 and presented by Verizon Wireless, the Adventure is included in park admission. It was succeeded by Agent P's World Showcase Adventure, based on Disney's "Phineas and Ferb", on June 23, 2012.
IllumiNations: Reflections of Earth.
Illuminations: Reflections of Earth is an award-winning show taking place in the World Showcase Lagoon every night at the park's closing time (usually 9:00 pm). It features fireworks, lasers, fire, and water fountains timed to a musical score over the World Showcase Lagoon. A large rotating globe with curved LED screens is the centerpiece of the show and is used to display images of people and places. The current version premiered as part of the park's Millennium Celebration in 2000. The show tells the story of Earth and is divided into three movements titled "Chaos," "Order," and "Meaning." The music has an African tribal sound to it, to emphasize the idea of humanity as a single unified tribe on this planet; the lagoon is surrounded by nineteen large torches signifying the first 19 centuries of the common era, and the show culminates in the globe opening like a lotus blossom to reveal a twentieth torch, representing the now-completed 20th century.
Annual events.
Epcot hosts a number of special events during the year:
"The Official Album of Walt Disney World Epcot Center".
"The Official Album of Walt Disney World Epcot Center" was the official album for EPCOT Center in 1983. It was originally released on LP and audio cassette and is no longer being produced.

</doc>
<doc id="37398" url="http://en.wikipedia.org/wiki?curid=37398" title="The Walt Disney Company">
The Walt Disney Company

The Walt Disney Company, commonly known as Disney, is an American diversified:1 multinational mass media and entertainment conglomerate headquartered at the Walt Disney Studios in Burbank, California. It is the world's second largest broadcasting and cable company in terms of revenue, after Comcast. Disney was founded on October 16, 1923, by Walt Disney and Roy O. Disney as the Disney Brothers Cartoon Studio, and established itself as a leader in the American animation industry before diversifying into live-action film production, television, and theme parks. The company also operated under the names The Walt Disney Studio, then Walt Disney Productions. Taking on its current name in 1986, it expanded its existing operations and also started divisions focused upon theater, radio, music, publishing, and online media. In addition, Disney has since created corporate divisions in order to market more mature content than is typically associated with its flagship family-oriented brands. The company is best known for the products of its film studio, the Walt Disney Studios, which is today one of the largest and best-known studios in American cinema. Disney also owns and operates the ABC broadcast television network; cable television networks such as Disney Channel, ESPN, A+E Networks, and ABC Family; publishing, merchandising, music, and theatre divisions; and owns and licenses 14 theme parks around the world. The company has been a component of the Dow Jones Industrial Average since May 6, 1991. An early and well-known cartoon creation of the company, Mickey Mouse, is a primary symbol of The Walt Disney Company.
Corporate history.
1923–1928: The silent era.
In early 1923, Kansas City, Missouri, animator Walt Disney created a short film entitled "Alice's Wonderland", which featured child actress Virginia Davis interacting with animated characters. After the bankruptcy in 1923 of his previous firm, Laugh-O-Gram Films, Disney moved to Hollywood to join his brother, Roy O. Disney. Film distributor Margaret J. Winkler of M.J. Winkler Productions contacted Disney with plans to distribute a whole series of "Alice Comedies" purchased for $1,500 per reel with Disney as a production partner. Walt and Roy Disney formed Disney Brothers Cartoon Studio that same year. More animated films followed after Alice. In January 1926, with the completion of the Disney studio on Hyperion Street, the Disney Brothers Studio's name was changed to the Walt Disney Studio.
After the demise of the "Alice" comedies, Disney developed an all-cartoon series starring his first original character, Oswald the Lucky Rabbit, which was distributed by Winkler Pictures through Universal Pictures. The distributor owned Oswald, so Disney only made a few hundred dollars. Disney completed 26 "Oswald" shorts before losing the contract in February 1928, due to a legal loophole, when Winkler's husband Charles Mintz took over their distribution company. After failing to take over the Disney Studio, Mintz hired away four of Disney's primary animators (the exception being Ub Iwerks) to start his own animation studio, Snappy Comedies.
1928–1934: Mickey Mouse and Silly Symphonies.
In 1928, to recover from the loss of Oswald the Lucky Rabbit, Disney came up with the idea of a mouse character named Mortimer while on a train headed to California, drawing up a few simple drawings. The mouse was later renamed Mickey Mouse (Disney's wife, Lillian, disliked the sound of 'Mortimer Mouse') and starred in several Disney produced films. Ub Iwerks refined Disney's initial design of Mickey Mouse. Disney's first sound film "Steamboat Willie", a cartoon starring Mickey, was released on November 18, 1928 through Pat Powers' distribution company. It was the first Mickey Mouse sound cartoon released, but the third to be created, behind "Plane Crazy" and "The Gallopin' Gaucho". "Steamboat Willie" was an immediate smash hit, and its initial success was attributed not just to Mickey's appeal as a character, but to the fact that it was the first cartoon to feature synchronized sound. Disney used Pat Powers' Cinephone system, created by Powers using Lee De Forest's Phonofilm system. "Steamboat Willie" premiered at B. S. Moss's Colony Theater in New York City, now The Broadway Theatre. Disney's "Plane Crazy" and "The Galloping Gaucho" were then retrofitted with synchronized sound tracks and re-released successfully in 1929.
Disney continued to produce cartoons with Mickey Mouse and other characters, and began the Silly Symphonies series with Columbia Pictures signing on as Symphonies distributor in August 1929. In September 1929, theater manager Harry Woodin requested permission to start a Mickey Mouse Club which Walt approved. In November, test comics strips were sent to King Features, who requested additional samples to show to the publisher, William Randolph Hearst. On December 16, the Walt Disney Studios partnership was reorganized as a corporation with the name of Walt Disney Productions, Limited with a merchandising division, Walt Disney Enterprises, and two subsidiaries, Disney Film Recording Company, Limited and Liled Realty and Investment Company for real estate holdings. Walt and his wife held 60% (6,000 shares) and Roy owned 40% of WD Productions. On December 30, King Features signed its first newspaper, New York Mirror, to publish the Mickey Mouse comic strip with Walt's permission.
In 1932, Disney signed an exclusive contract with Technicolor (through the end of 1935) to produce cartoons in color, beginning with "Flowers and Trees" (1932). Disney released cartoons through Powers' Celebrity Pictures (1928–1930), Columbia Pictures (1930–1932), and United Artists (1932–1937). The popularity of the Mickey Mouse series allowed Disney to plan for his first feature-length animation.
The feature film "Walt Before Mickey" based on the book by Diane Disney Miller featured these moments in the studio's history.
1934–1945: "Snow White and the Seven Dwarfs" and World War II.
Deciding to push the boundaries of animation even further, Disney began production of his first feature-length animated film in 1934. Taking three years to complete, "Snow White and the Seven Dwarfs", premiered in December 1937 and became highest-grossing film of that time by 1939. "Snow White" was released through RKO Radio Pictures, which had assumed distribution of Disney's product in July 1937, after United Artists attempted to attain future television rights to the Disney shorts.
Using the profits from "Snow White", Disney financed the construction of a new 51 acre studio complex in Burbank, California. The new Walt Disney Studios, in which the company is headquartered to this day, was completed and open for business by the end of 1939. The following year on April 2, Walt Disney Productions had its initial public offering.
The studio continued releasing animated shorts and features, such as "Pinocchio" (1940), "Fantasia" (1940), "Dumbo" (1941), and "Bambi" (1942). After World War II began, box-office profits declined. When the United States entered the war after the attack on Pearl Harbor, many of Disney's animators were drafted into the armed forces. The U.S. and Canadian governments commissioned the studio to produce training and propaganda films. By 1942 90% of its 550 employees were working on war-related films. Films such as the feature "Victory Through Air Power" and the short "Education for Death" (both 1943) were meant to increase public support for the war effort. Even the studio's characters joined the effort, as Donald Duck appeared in a number of comical propaganda shorts, including the Academy Award-winning "Der Fuehrer's Face" (1943).
1946–1954: Post-war and television.
With limited staff and little operating capital during and after the war, Disney's feature films during much of the 1940s were "package films," or collections of shorts, such as "The Three Caballeros" (1944) and "Melody Time" (1948), which performed poorly at the box-office. At the same time, the studio began producing live-action films and documentaries. "Song of the South" (1946) and "So Dear to My Heart" (1948) featured animated segments, while the "True-Life Adventures" series, which included such films as "Seal Island" (1948) and "The Vanishing Prairie" (1954), were also popular. Eight of the films in the series won Academy Awards.
The release of "Cinderella" in 1950 proved that feature-length animation could still succeed in the marketplace. Other releases of the period included "Alice in Wonderland" (1951) and "Peter Pan" (1953), both in production before the war began, and Disney's first all-live action feature, "Treasure Island" (1950). Other early all-live-action Disney films included "The Story of Robin Hood and His Merrie Men" (1952), "The Sword and the Rose" (1953), and "20,000 Leagues Under the Sea" (1954). Disney ended its distribution contract with RKO in 1953, forming its own distribution arm, Buena Vista Distribution.
In December 1950, Walt Disney Productions and The Coca-Cola Company teamed up for Disney's first venture into television, the NBC television network special "An Hour in Wonderland". In October 1954, the ABC network launched Disney's first regular television series, "Disneyland", which would go on to become one of the longest-running primetime series in history. "Disneyland" allowed Disney a platform to introduce new projects and broadcast older ones, and ABC became Disney's partner in the financing and development of Disney's next venture, located in the middle of an orange grove near Anaheim, California. It was the first phase of a long corporate relationship which, although no one could have anticipated it at the time, would culminate four decades later in the Disney company's acquisition of the ABC network, its owned and operated stations, and its numerous cable and publishing ventures.
1955–1965: Disneyland.
In 1954, Walt Disney used his "Disneyland" series to unveil what would become Disneyland, an idea conceived out of a desire for a place where parents and children could both have fun at the same time. On July 18, 1955, Walt Disney opened Disneyland to the general public. On July 17, 1955, Disneyland was previewed with a live television broadcast hosted by Art Linkletter and Ronald Reagan. After a shaky start, Disneyland continued to grow and attract visitors from across the country and around the world. A major expansion in 1959 included the addition of America's first monorail system.
For the 1964 New York World's Fair, Disney prepared four separate attractions for various sponsors, each of which would find its way to Disneyland in one form or another. During this time, Walt Disney was also secretly scouting out new sites for a second Disney theme park. In November 1965, "Disney World" was announced, with plans for theme parks, hotels, and even a model city on thousands of acres of land purchased outside of Orlando, Florida.
Disney continued to focus its talents on television throughout the 1950s. Its weekday afternoon children's television program "The Mickey Mouse Club", featuring its roster of young "Mouseketeers", premiered in 1955 to great success, as did the "Davy Crockett" miniseries, starring Fess Parker and broadcast on the "Disneyland" anthology show. Two years later, the "Zorro" series would prove just as popular, running for two seasons on ABC. Despite such success, Walt Disney Productions invested little into television ventures in the 1960s, with the exception of the long-running anthology series, later known as "The Wonderful World of Disney".
Disney's film studios stayed busy as well. Averaging five or six releases per year during this period. While the production of shorts slowed significantly during the 1950s and 1960s, the studio released a number of popular animated features, like "Lady and the Tramp" (1955), "Sleeping Beauty" (1959) and "One Hundred and One Dalmatians" (1961), which introduced a new xerography process to transfer the drawings to animation cels. Disney's live-action releases were spread across a number of genres, including historical fiction ("Johnny Tremain", 1957), adaptations of children's books ("Pollyanna", 1960) and modern-day comedies ("The Shaggy Dog", 1959). Disney's most successful film of the 1960s was a live action/animated musical adaptation of "Mary Poppins", which was one of the all-time highest grossing movies and received five Academy Awards, including Best Actress for Julie Andrews and Best Song for Robert B. Sherman & Richard M. Sherman for "Chim Chim Cher-ee" .
The theme park design and architectural group became so integral to the Disney studio's operations that the studio bought it on February 5, 1965, along with the WED Enterprises name.
1966–1971: The deaths of Walt and Roy Disney and the opening of Walt Disney World.
On December 15, 1966, Walt Disney died of complications relating to lung cancer, and Roy Disney took over as chairman, CEO, and president of the company. One of his first acts was to rename Disney World as "Walt Disney World" in honor of his brother and his vision.
In 1967, the last two films Walt actively supervised were released, the animated feature "The Jungle Book" and the musical "The Happiest Millionaire". The studio released a number of comedies in the late 1960s, including "The Love Bug" (1969's highest grossing film) and "The Computer Wore Tennis Shoes" (1969), which starred another young Disney discovery, Kurt Russell. The 1970s opened with the release of Disney's first "post-Walt" animated feature, "The Aristocats", followed by a return to fantasy musicals in 1971's "Bedknobs and Broomsticks". "Blackbeard's Ghost" was another successful film during this period.
On October 1, 1971, Walt Disney World opened to the public, with Roy Disney dedicating the facility in person later that month. On December 20, 1971, Roy Disney died of a stroke. He left the company under control of Donn Tatum, Card Walker, and Walt's son-in-law Ron Miller, each trained by Walt and Roy.
1972–1984: Theatrical malaise and new leadership.
While Walt Disney Productions continued releasing family-friendly films throughout the 1970s, such as "Escape to Witch Mountain" (1975) and "Freaky Friday" (1976), the films did not fare as well at the box office as earlier material. However, the animation studio saw success with "Robin Hood" (1973), "The Rescuers" (1977), and "The Fox and the Hound" (1981).
As head of the studio, Miller attempted to make films to drive the profitable teenage market who generally passed on seeing Disney movies. Inspired by the popularity of ', the Disney studio produced the science-fiction adventure "The Black Hole" in 1979 that cost $20 million to make, but was lost in "Star Wars wake. "The Black Hole" was the first Disney production to carry a PG rating in the United States. Disney dabbled in the horror genre with "The Watcher in the Woods", and financed the boldly innovative "Tron"; both films were released to minimal success.
Disney also hired outside producers for film projects, which had never been done before in the studio's history. In 1979, Disney entered a joint venture with Paramount Pictures on the production of the 1980 film adaptation of "Popeye" and "Dragonslayer" (1981); the first time Disney collaborated with another studio. Paramount distributed Disney films in Canada at the time, and it was hoped that Disney's marketing prestige would help sell the two films.
Finally, in 1982, the Disney family sold the naming rights and rail-based attractions to the Disney film studio for 818,461 shares of Disney stock then worth $42.6 million none of which went to Retlaw. Also, Roy E. Disney objected to the overvalued purchase price of the naming right and voted against the purchase as a Disney board director.
The 1983 release of Mickey's Christmas Carol began a string of successful movies, starting with "Never Cry Wolf" and the Ray Bradbury adaptation "Something Wicked This Way Comes". The Walt Productions film division was incorporated on as Walt Disney Pictures. In 1984, Disney CEO Ron Miller created Touchstone Films as a brand for Disney to release more major release motion pictures. Touchstone's first release was the comedy "Splash" (1984), which was a box office success.
With "The Wonderful World of Disney" remaining a prime-time staple, Disney returned to television in the 1970s with syndicated programing such as the anthology series "The Mouse Factory" and a brief revival of the "Mickey Mouse Club". In 1980, Disney launched Walt Disney Home Video to take advantage of the newly emerging videocassette market. On April 18, 1983, The Disney Channel debuted as a subscription-level channel on cable systems nationwide, featuring its large library of classic films and TV series, along with original programming and family-friendly third-party offerings.
Walt Disney World received much of the company's attention through the 1970s and into the 1980s. In 1978, Disney executives announced plans for the second Walt Disney World theme park, EPCOT Center, which would open in October 1982. Inspired by Walt Disney's dream of a futuristic model city, EPCOT Center was built as a "permanent World's Fair", complete with exhibits sponsored by major American corporations, as well as pavilions based on the cultures of other nations. In Japan, the Oriental Land Company partnered with Walt Disney Productions to build the first Disney theme park outside of the United States, Tokyo Disneyland, which opened in April 1983.
Despite the success of the Disney Channel and its new theme park creations, Walt Disney Productions was financially vulnerable. Its film library was valuable, but offered few current successes, and its leadership team was unable to keep up with other studios, particularly the works of Don Bluth, who defected from Disney in 1979.
By the early 1980s, the parks were generating 70% of Disney's income.
In 1984, financier Saul Steinberg's Reliance Group Holdings launched a hostile takeover bid for Walt Disney Productions, with the intent of selling off some of its operations. Disney bought out Reliance's 11.1% stake in the company. However, another shareholder filed suit claiming the deal devaluated Disney's stock and for Disney management to retain their positions. The shareholder lawsuit was settled in 1989 for a total of $45 million from Disney and Reliance.
1984–2005: The Eisner era and the Save Disney campaign.
With the Sid Bass family purchase of 18.7 percent of Disney, Bass and the board brought in Michael Eisner from Paramount Pictures as CEO and Frank Wells from Warner Bros. as president. Eisner emphasized Touchstone Films with "Down and Out in Beverly Hills" (1985) to start leading to increased output with "Ruthless People" (1986), "Outrageous Fortune" (1987), "Pretty Woman" (1990) and additional hits. Eisner used expanding cable and home video markets to sign deals using Disney shows and films with a long-term deal with Showtime Networks for Disney/Touchstone releases through 1996 and entering television with syndication and distribution for TV series as "The Golden Girls" and "Home Improvement". Disney began limited releases of its previous films on video tapes in the late 1980s. Eisner's Disney purchased KHJ, an independent Los Angeles TV station.
Organized in 1985, Silver Screen Partners II, LP financed films for Disney with $193 million. In January 1987, Silver Screen III began financing movies for Disney with $300 million raised, the largest amount raised for a film financing limited partnership by E.F. Hutton. Silver Screen IV was also set up to finance Disney's studios.
Beginning with "Who Framed Roger Rabbit" in 1988, Disney's flagship animation studio enjoyed a series of commercial and critical successes with such films as "The Little Mermaid" (1989), "Beauty and the Beast" (1991), "Aladdin" (1992) and "The Lion King" (1994). In addition, the company successfully entered the field of television animation with a number of lavishly budgeted and acclaimed series such as "Adventures of the Gummi Bears", "Duck Tales", "Chip 'n Dale Rescue Rangers", "Darkwing Duck" and "Gargoyles". Disney moved to first place in box office receipts by 1988 and had increased revenues by 20% every year.
In 1989, Disney signed an agreement-in-principle to acquire The Jim Henson Company (then known as Henson Associates) from its founder, Muppet creator Jim Henson. The deal included Henson's programming library and Muppet characters (excluding the Muppets created for "Sesame Street"), as well as Jim Henson's personal creative services. However, in May 1990, before the deal was completed, Jim Henson passed away, and the two companies broke off merger negotiations the following December.
Named the "Disney Decade" by the company, the executive talent attempted to move the company to new heights in the 1990s with huge changes and accomplishments. In September 1990, The Disney Company arranged for financing up to $200 million by a unit of Nomura Securities for Interscope films made for Disney. On October 23, Disney formed Touchwood Pacific Partners I which would supplant the Silver Screen Partnership series as their movie studios' primary source of funding.
In 1991, hotels, home video distribution, and Disney merchandising became 28 percent of total company revenues with international revenues contributed 22 percent of revenues. The company committed its studios in the first quarter of 1991 to produce 25 films in 1992. However, 1991 saw net income drop by 23% and had no growth for the year, but saw the release of Beauty and the Beast, winner of 2 Academy Awards and top grossing film in the genre. Disney next moved into publishing with Hyperion Books and adult music with Hollywood Records while Disney Imagineering was laying off 400 employees.
Disney also broadened its adult offerings in film when then Disney Studio Chairman Jeffrey Katzenberg acquired Miramax Films in 1993. That same year Disney created the NHL team the Mighty Ducks of Anaheim, named after the 1992 hit film of the same name. Disney purchased a minority stake in the Anaheim Angels baseball team around the same time.
Wells died in a helicopter crash in 1994. Shortly thereafter, Katzenberg resigned and formed DreamWorks SKG because Eisner would not appoint Katzenberg to Wells' now-available post (Katzenberg had also sued over the terms of his contract). Instead, Eisner recruited his friend Michael Ovitz, one of the founders of the Creative Artists Agency, to be President, with minimal involvement from Disney's board of directors (which at the time included Oscar-winning actor Sidney Poitier, the CEO of Hilton Hotels Corporation Stephen Bollenbach, former U.S. Senator George Mitchell, Yale dean Robert A. M. Stern, and Eisner's predecessors Raymond Watson and Card Walker). Ovitz lasted only 14 months and left Disney in December 1996 via a "no fault termination" with a severance package of $38 million in cash and 3 million stock options worth roughly $100 million at the time of Ovitz's departure. The Ovitz episode engendered a long running derivative suit, which finally concluded in June 2006, almost 10 years later. Chancellor William B. Chandler, III of the Delaware Court of Chancery, despite describing Eisner's behavior as falling "far short of what shareholders expect and demand from those entrusted with a fiduciary position..." found in favor of Eisner and the rest of the Disney board because they hadn't violated the letter of the law (namely, the duty of care owed by a corporation's officers and board to its shareholders).
Eisner attempted in 1994 to purchase NBC from GE, but the deal failed due to GE wanting to keep 51% ownership of the network. Disney acquired many other media sources during the decade, including a merger with Capital Cities/ABC in 1995 which brought broadcast network ABC and its assets, including the A&E Television Networks and ESPN networks, into the Disney fold. Eisner felt that the purchase of ABC was an important investment to keep Disney surviving and allowing it to compete with international multimedia conglomerates.
Disney lost a $10.4 million lawsuit in September 1997 to Marsu B.V. over Disney's failure to produce as contracted 13 half-hour Marsupilami cartoon shows. Instead Disney felt other internal "hot properties" deserved the company's attention.
Disney took control of the Anaheim Angels in 1996, and purchased a majority stake in the team in 1998. That same year, Disney began a move into the internet field with the purchase of Starwave and 43 percent of Infoseek. In 1999, Disney purchased the remaining shares of Infoseek and launch the Go Network portal in January. Disney also launched its cruise line with the christening of Disney Magic and a sister ship, Disney Wonder.
As the Katzenberg case dragged on as his contract included a portion of the film revenue from ancillary markets forever. Katzenberg had offered $100 to settle the case but Eisner felt the original claim amount of about half a billion too much, but then the ancillary market clause was found. Disney lawyers tried to indicate a decline situation which reveal the some of the problems in the company. ABC had declining rating and increasing costs while the film segment had two film failures. While neither party revealed the settlement amount, it is estimated at $200 million.
Eisner's controlling style inhibited efficiency and progress according to some critics, while other industry experts indicated that "age compression" theory led to a decline in the company's target market due to youth copying teenage behavior earlier.
2000 brought an increase in revenue of 9% and net income of 39% with ABC and ESPN leading the way and Parks and Resorts marking its sixth consecutive year of growth. However the September 11 attacks led to a complete halt of vacation travel and led to a recession. The recession led to a decrease in ABC revenue. Plus, Eisner had the company make an expensive purchase of Fox Family Worldwide. 2001 was a year of cost cutting laying off 4,000 employees, Disney parks operations decreased, slashing annual live-action film investment, and minimizing Internet operations. While 2002 revenue had a small decrease from 2001 with the cost cutting, net income rose to $1.2 billion with two creative film releases. In 2003, the Studio became the first studio to record over $3 billion in worldwide box office receipts.
Eisner did not want the board to renominate Roy E. Disney, the son of Disney co-founder Roy O. Disney, as a board director citing his age of 72 as a required retirement age. Stanley Gold responded by resigning from the board and requesting the other board members oust Eisner. In 2003, Disney resigned from his positions as the company's vice chairman and chairman of Walt Disney Feature Animation, accusing Eisner of micromanagement, flops with the ABC television network, timidity in the theme park business, turning the Walt Disney Company into a "rapacious, soul-less" company, and refusing to establish a clear succession plan, as well as a string of box-office movie flops starting in the year 2000.
On May 15, 2003, Disney sold their stake in the Anaheim Angels baseball team to Arte Moreno. Disney purchased the rights to The Muppets and the "Bear in the Big Blue House" franchises from The Jim Henson Company on February 17, 2004. The two brands were placed under control of the Muppets Holding Company, LLC, a unit of Disney Consumer Products.
In 2004, Pixar Animation Studios began looking for another distributor after its 12-year contract with Disney ended, due to its strained relationship over issues of control and money with Eisner. Also that year, Comcast Corporation made an unsolicited $54 billion bid to acquire Disney. A couple of high budget movies flopped at the box office. With these difficulties and with some board directors dissatisfied, Eisner ceded the board chairmanship.
On March 3, 2004, at Disney's annual shareholders' meeting, a surprising and unprecedented 45% of Disney's shareholders, predominantly rallied by former board members Roy Disney and Stanley Gold, withheld their proxies to re-elect Eisner to the board. Disney's board then gave the chairmanship position to Mitchell. However, the board did not immediately remove Eisner as chief executive.
In 2005, Disney sold the Mighty Ducks of Anaheim hockey team to Henry and Susan Samueli.
On March 13, 2005, Robert Iger was announced as Eisner successor as CEO. On September 30, Eisner resigned both as an executive and as a member of the board of directors.
2005–present: The Iger era.
On July 8, 2005, Walt Disney's nephew, Roy E. Disney returned to The Walt Disney Company as a consultant and with the new title of Non Voting Director, Emeritus. Walt Disney Parks and Resorts celebrated the 50th anniversary of Disneyland Park on July 17, and opened Hong Kong Disneyland on September 12. Walt Disney Feature Animation released "Chicken Little", the company's first film using 3-D animation. On October 1, Bob Iger replaced Michael Eisner as CEO. Miramax co-founders Bob Weinstein and Harvey Weinstein also departed the company to form their own studio. On July 25, 2005, Disney announced that it was closing DisneyToon Studios Australia in October 2006, after 17 years of existence.
In 2006, Disney acquired Oswald the Lucky Rabbit, Disney’s pre-Mickey silent animation star.
Aware that Disney's relationship with Pixar was wearing thin, President and CEO Robert Iger began negotiations with leadership of Pixar Animation Studios, Steve Jobs and Ed Catmull, regarding possible merger. On January 23, 2006, it was announced that Disney would purchase Pixar in an all-stock transaction worth $7.4 billion. The deal was finalized on May 5; and among noteworthy results was the transition of Pixar's CEO and 50.1% shareholder, Steve Jobs, becoming Disney's largest individual shareholder at 7% and a member of Disney's Board of Directors. Ed Catmull took over as President of Pixar Animation Studios. Former Executive Vice-President of Pixar, John Lasseter, became Chief Creative Officer of Walt Disney Animation Studios, its division DisneyToon Studios, and Pixar Animation Studios, as well assuming the role of Principal Creative Advisor at Walt Disney Imagineering.
In April 2007, the Muppets Holding Company, LLC was renamed The Muppets Studio and placed under new leadership in an effort by Iger to re-brand the division. The re-branding was completed in September 2008, when control of The Muppets Studio was transferred from Disney Consumer Products to the Walt Disney Studios.
After a long time working in the company as a senior executive and large shareholder, Director Emeritus Roy E. Disney died from stomach cancer on December 16, 2009. At the time of his death, he owned roughly 1% of all of Disney which amounted to 16 million shares. He is seen to be the last member of the Disney family to be actively involved in the running of the company and working in the company altogether.
On August 31, 2009, Disney announced a deal to acquire Marvel Entertainment, Inc. for $4.24 billion. The deal was finalized on December 31, 2009 in which Disney acquired full ownership on the company. Disney has stated that their acquisition of Marvel Entertainment will not affect Marvel's products, neither will the nature of any Marvel characters be transformed.
In October 2009, Disney Channel president Rich Ross, hired by Iger, replaced Dick Cook as chairman of the company and, in November, began restructuring the company to focus more on family friendly products. Later in January 2010, Disney decided to shut down Miramax after downsizing Touchstone, but one month later, they instead began selling the Miramax brand and its 700-title film library to Filmyard Holdings. On March 12, ImageMovers Digital, Robert Zemeckis's company which Disney had bought in 2007, was shut down. In April 2010, Lyric Street, Disney's country music label in Nashville, was shut down. In May 2010, the company sold the Power Rangers brand, as well as its 700-episode library, back to Haim Saban. In June, the company canceled Jerry Bruckheimer's film project "Killing Rommel". In January 2011, Disney Interactive Studios was downsized. In November, two ABC stations were sold.
With the release of "Tangled" in 2010, Ed Catmull said that the "princess" genre of films was taking a hiatus until "someone has a fresh take on it ... but we don't have any other musicals or fairytales lined up." He explained that they were looking to get away from the princess era due to the changes in audience composition and preference. However in the Facebook page, Ed Catmull stated that this was just a rumor.
In April 2011, Disney broke ground on Shanghai Disney Resort. Costing $4.4 billion, the resort is slated to open in 2015. Later, in August 2011, Bob Iger stated on a conference call that after the success of the Pixar and Marvel purchases, he and the Walt Disney Company are looking to "buy either new characters or businesses that are capable of creating great characters and great stories." Later, in early February 2012, Disney completed its acquisition of UTV Software Communications, expanding their market further into India and Asia.
On October 30, 2012, Disney announced plans to acquire Lucasfilm, along with plans to produce a in its "Star Wars" franchise for 2015. On December 4, 2012, the Disney-Lucasfilm merger was approved by the Federal Trade Commission, allowing the acquisition to be finalized without dealing with antitrust problems. On December 21, 2012, the deal was completed with the acquisition value amounting to approximately $4.06 billion, and thus Lucasfilm became a wholly owned subsidiary of Disney (which coincidentally reunited Lucasfilm under the same corporate umbrella with its former spin-off and new sibling, Pixar).
On May 29, 2013, Disney set release dates for eight currently untitled animated films through 2018, including four from Disney Animation and four from Pixar Animation.
On March 24, 2014, Disney bought Maker Studios, a YouTube company generating billions of views each year, for over $500 million in order to advertise to viewers in the crucial teenage/young adult demographics.
On May 9, 2014, Disney announced they have reached an agreement with Japan's TV Asahi Corporation to air an English dub of the "Doraemon" anime series on Disney XD.
In July 2014, The Walt Disney Company announced 11 startups that would begin in the company’s accelerator program.
In August 2014, The Walt Disney Company filed three patents for using drones. Patents included using unmanned aerial vehicles (UAV) to lift marionettes in the air, raise mesh screens for floating video projections, and equipping drones with lights to make them part of a new kind of light show.
On February 5, 2015, it was announced that Tom Staggs had been promoted to COO.
Company divisions and subsidiaries.
The Walt Disney Company operates through five primary business units, which it calls "business segments": Studio Entertainment, with the primary business unit The Walt Disney Studios, which includes the company's film, recording label, and theatrical divisions; Parks and Resorts, featuring the company's theme parks, cruise line, and other travel-related assets; Disney Consumer Products, which produces toys, clothing, and other merchandising based upon Disney-owned properties; Media Networks, which includes the company's television properties; and Disney Interactive, which includes Disney's Internet, mobile, social media, virtual worlds, and computer games operations. The first four segments are headed by chairmen, while Disney Interactive is currently headed by a president. Marvel Entertainment is also a direct CEO reporting business, while its financial results are primarily divided between the Studio Entertainment and Consumer Products segments. While Maker Studios is split between Studio Entertainment and Media Networks segments.
Its main entertainment holdings include Walt Disney Studios, Disney Music Group, Disney Theatrical Group, Disney-ABC Television Group, Radio Disney, ESPN Inc., Disney Interactive Media Group, Disney Consumer Products, Disney India Ltd., The Muppets Studio, Pixar Animation Studios, Marvel Entertainment, UTV Software Communications, Lucasfilm and Maker Studios.
Its resorts and diversified related holdings include Walt Disney Parks and Resorts, Disneyland Resort, Walt Disney World Resort, Tokyo Disney Resort, Disneyland Paris, Euro Disney S.C.A., Hong Kong Disneyland Resort, Disney Vacation Club and Disney Cruise Line.
Executive management.
Chairmen of the Board.
Walt Disney dropped his Chairman title in 1960 to focus more on the creative aspects of the company, becoming "executive producer in charge of all production." After a four-year vacancy, Roy O. Disney assumed the chairmanship.
Criticism.
Some of Disney's animated family films have drawn fire for being accused of having sexual references hidden in them, among them "The Little Mermaid" (1989), "Aladdin" (1992), and "The Lion King" (1994). Instances of sexual material hidden in some versions of "The Rescuers" (1977) and "Who Framed Roger Rabbit" (1988) resulted in recalls and modifications of the films to remove such content.
Some religious welfare groups, such as the Catholic League, have opposed films including "Priest" (1994) and "Dogma" (1999). A book called "Growing Up Gay", published by Disney-owned Hyperion and similar publications, as well as the company's extension of benefits to same-sex domestic partners, spurred boycotts of Disney and its advertisers by the Catholic League, the Assemblies of God USA, the American Family Association, and other conservative groups. The boycotts were discontinued by most of these organizations by 2005. In addition to these social controversies, the company has been accused of human rights violations regarding the working conditions in factories that produce their merchandise.

</doc>
<doc id="37399" url="http://en.wikipedia.org/wiki?curid=37399" title="Roland Garros (aviator)">
Roland Garros (aviator)

Roland Garros (]; 6 October 1888 – 5 October 1918) was an early French aviator and a fighter pilot during World War I.
Biography.
Eugène Adrien Roland Georges Garros was born in Saint-Denis, Réunion, and studied at the Lycée Janson de Sailly and HEC Paris. He started his aviation career in 1909 flying a Demoiselle (Dragonfly) monoplane, an aircraft that only flew well with a small lightweight pilot. He gained Ae.C.F. licence no. 147 in July 1910. In 1911 Garros graduated to flying Blériot monoplanes and entered a number of European air races with this type of machine, including the 1911 Paris to Madrid air race and the Circuit of Europe (Paris-London-Paris), in which he came second. In September he established a new world altitude record of 5610 m By 1913 he had switched to flying the faster Morane-Saulnier monoplanes, and gained fame for making the first non-stop flight across the Mediterranean Sea from Fréjus in the south of France to Bizerte in Tunisia. The following year, Garros joined the French army at the outbreak of World War I.
Development of interrupter gear.
In the early stages of the air war in World War I the problem of mounting a forward-firing machine gun on combat aircraft was considered by a number of individuals. The so-called "interrupter gear" did not come into use until Anthony Fokker developed a synchronization device which had a large impact on air combat; however, Garros also had a significant role in the process of achieving this goal.
As a reconnaissance pilot with the Escadrille MS26, Garros visited the Morane-Saulnier Works in December 1914. Saulnier's work on metal deflector wedges attached to propeller blades was taken forward by Garros; he eventually had a workable installation fitted to his Morane-Saulnier Type L aircraft. Garros achieved the first ever shooting-down of an aircraft by a fighter firing through a tractor propeller, on 1 April 1915; two more victories over German aircraft were achieved on 15 and 18 April 1915.
On 18 April 1915, either Garros' fuel line clogged or, by other accounts, his aircraft was downed by ground fire, and he glided to a landing on the German side of the lines. Garros failed to destroy his aircraft completely before being taken prisoner: most significantly, the gun and armoured propeller remained intact. Legend has it that after examining the plane, German aircraft engineers, led by Fokker, designed the improved interrupter gear system. In fact the work on Fokker's system had been going for at least six months before Garros' aircraft fell into their hands. With the advent of the interrupter gear the tables were turned on the Allies, with Fokker's planes shooting down many Allied aircraft, leading to what became known as the Fokker Scourge.
After internment in a POW camp.
Garros finally managed to escape from a POW camp in Germany on 14 February 1918, after several attempts, and rejoined the French army. He settled into Escadrille 26 to pilot a Spad, and claimed two victories on 2 October 1918, one of which was confirmed. On 5 October 1918, he was shot down and killed near Vouziers, Ardennes, a month before the end of the war and one day before his 30th birthday. His adversary was probably German ace Hermann Habich from "Jasta 49".
Garros is erroneously called the world's first fighter ace. In fact, he shot down only four aircraft; the definition of "ace" is five or more victories. The honour of becoming the first ace went to another French airman, Adolphe Pégoud.
Places named after Roland Garros.
A tennis centre, which he attended religiously when he was studying in Paris, was named after him in the 1920s, the "Stade de Roland Garros". The stadium accommodates the French Open, one of tennis' Grand Slam tournaments. Consequently, the tournament is officially called Les internationaux de France de Roland-Garros (the "French Internationals of Roland Garros").
The international airport of La Réunion, Roland Garros Airport, is also named after him.
The place where he landed in Bizerte is actually called place of Roland Garros.
The French car manufacturer Peugeot commissioned a 'Roland Garros' limited edition version of its 205 model in celebration of the tennis tournament that bears his name. The model included special paint and leather interior. Because of the success of this special edition, Peugeot later created Roland Garros editions of its 106, 206, 207, 306, 406, and 806 models.

</doc>
<doc id="37400" url="http://en.wikipedia.org/wiki?curid=37400" title="Mole (unit)">
Mole (unit)

The mole is a unit of measurement used in chemistry to express amounts of a chemical substance, defined as the amount of any substance that contains as many elementary entities (e.g., atoms, molecules, ions, electrons) as there are atoms in 12 grams of pure carbon-12 (12C), the isotope of carbon with relative atomic mass of exactly 12 by definition. This corresponds to the Avogadro constant, which has a value of elementary entities of the substance. It is one of the base units in the International System of Units; it has the unit symbol mol and corresponds with the dimension symbol N.
The mole is widely used in chemistry instead of units of mass or volume as a convenient way to express amounts of reactants or of products of chemical reactions. For example, the chemical equation 2 H2 + O2 → 2 H2O implies that 2 mol of dihydrogen (H2) and 1 mol of dioxygen (O2) react to form 2 mol of water (H2O). The mole may also be used to express the number of atoms, ions, or other elementary entities in a given sample of any substance. The concentration of a solution is commonly expressed by its molarity, defined as the number of moles of the dissolved substance per litre of solution.
The number of molecules in a mole (known as Avogadro's constant) is defined such that the mass of one mole of a substance, expressed in grams, is exactly equal to the substance's mean molecular mass. For example, the mean molecular mass of natural water is about 18.015, so one mole of water is about 18.015 grams. Making use of this equation considerably simplifies many chemical and physical computations.
The term gram-molecule was formerly used for essentially the same concept. The term gram-atom (abbreviated gat.) has been used for a related but distinct concept, namely a quantity of a substance that contains Avogadro's number of "atoms", whether isolated or combined in molecules. Thus, for example, 1 mole of MgB2 is 1 gram-molecule of MgB2 but 3 gram-atoms of MgB2.
In honour of the unit, some chemists celebrate October 23 (a reference to the 1023 part of the Avogadro constant) as "Mole Day". Some also do the same for February 6 and June 2.
Definition and related concepts.
s of 2011[ [update]], the mole is defined by BIPM to be the amount of substance of a system which contains the same number of elementary entities (e.g. atoms, molecules, ions, electrons) as atoms in 0.012 kilograms of carbon-12 (12C), the isotope of carbon with relative atomic mass 12. Thus, by definition, one mole of pure 12C has a mass of "exactly" 12 g. It also follows from the definition that "X" moles of any substance will contain the same number of molecules as "X" moles of any other substance.
The mass per mole of a substance is called its molar mass. Since the standard unit for expressing the mass of molecules or atoms (atomic mass unit or the dalton) is defined as 1/12 of the mass of a 12C atom, it follows that the molar mass of a substance, measured in grams per mole, is exactly equal to its mean molecular or atomic mass, measured in unified atomic mass units or daltons; which is to say, to the substance's mean molecular or relative atomic mass.
The number of elementary entities in a sample of a substance is technically called its (chemical) amount. Therefore, the mole is a convenient unit for that physical quantity. One can determine the chemical amount of a known substance, in moles, by dividing the sample's mass by the substance's molar mass. Other methods include the use of the molar volume or the measurement of electric charge.
The mass of one mole of a substance depends not only on its molecular formula, but also on the proportion of the isotopes of each element present in it. For example, one mole of calcium-40 is ± grams, whereas one mole of calcium-42 is ± grams, and one mole of calcium with the normal isotopic mix is 40.078 ± 0.004 grams.
Since the definition of the gram is not (as of 2011[ [update]]) mathematically tied to that of the atomic mass unit, the number "N""A" of molecules in a mole (Avogadro's number) must be determined experimentally. The value adopted by CODATA in 2010 is "N""A" = ± .
In 2011 the measurement was refined to ± .
We can find number of moles in a given mass (in grams) by
formula_1
History.
The history of the mole is intertwined with that of molecular mass, atomic mass unit, Avogadro's number and related concepts.
The first table of relative atomic mass (atomic weight) was published by John Dalton (1766–1844) in 1805, based on a system in which the relative atomic mass of hydrogen was defined as 1. These relative atomic masses were based on the stoichiometric proportions of chemical reactions and compounds, a fact that greatly aided their acceptance: It was not necessary for a chemist to subscribe to atomic theory (an unproven hypothesis at the time) to make practical use of the tables. This would lead to some confusion between atomic masses (promoted by proponents of atomic theory) and equivalent weights (promoted by its opponents and which sometimes differed from relative atomic masses by an integer factor), which would last throughout much of the nineteenth century.
Jöns Jacob Berzelius (1779–1848) was instrumental in the determination of relative atomic masses to ever-increasing accuracy. He was also the first chemist to use oxygen as the standard to which other masses were referred. Oxygen is a useful standard, as, unlike hydrogen, it forms compounds with most other elements, especially metals. However, he chose to fix the atomic mass of oxygen as 100, an innovation that did not catch on.
Charles Frédéric Gerhardt (1816–56), Henri Victor Regnault (1810–78) and Stanislao Cannizzaro (1826–1910) expanded on Berzelius' works, resolving many of the problems of unknown stoichiometry of compounds, and the use of atomic masses attracted a large consensus by the time of the Karlsruhe Congress (1860). The convention had reverted to defining the atomic mass of hydrogen as 1, although at the level of precision of measurements at that time — relative uncertainties of around 1% — this was numerically equivalent to the later standard of oxygen = 16. However the chemical convenience of having oxygen as the primary atomic mass standard became ever more evident with advances in analytical chemistry and the need for ever more accurate atomic mass determinations.
Developments in mass spectrometry led to the adoption of oxygen-16 as the standard substance, in lieu of natural oxygen. The current definition of the mole, based on carbon-12, was approved during the 1960s. The four different definitions were equivalent to within 1%.
The name "mole" is an 1897 translation of the German unit "Mol", coined by the chemist Wilhelm Ostwald in 1894 from the German word "Molekül" (molecule). However, the related concept of equivalent mass had been in use at least a century earlier.
The mole was made the seventh SI base unit in 1971 by the 14th CGPM.
The mole as a unit.
Since its adoption into the International System of Units in 1971, there have been a number of criticisms of the concept of the mole as a unit like the metre or the second:
In chemistry, it has been known since Proust's law of definite proportions (1794) that knowledge of the mass of each of the components in a chemical system is not sufficient to define the system. Amount of substance can be described as mass divided by Proust's "definite proportions", and contains information that is missing from the measurement of mass alone. As demonstrated by Dalton's law of partial pressures (1803), a measurement of mass is not even necessary to measure the amount of substance (although in practice it is usual). There are many physical relationships between amount of substance and other physical quantities, the most notable one being the ideal gas law (where the relationship was first demonstrated in 1857). The term "mole" was first used in a textbook describing these colligative properties.
Other units called "mole".
Chemical engineers use the concept extensively, but the unit is rather small for industrial use. For convenience in avoiding conversions in the Imperial (or American Customary Units), some engineers adopted the pound-mole (notation lb-mol or lbmol), which is defined as the number of entities in 12 lb of 12C. One lb-mol is equal to .
In the metric system, chemical engineers once used the kilogram-mole (notation kg-mol), which is defined as the number of entities in 12 kg of 12C, and often referred to the mole as the gram-mole (notation g-mol), when dealing with laboratory data.
Late 20th century chemical engineering practice came to use the kilomole (kmol), which is numerically identical to the kilogram-mole, but whose name and symbol adopt the SI convention for standard multiples of metric units - thus kmol means 1000 moles. This is analogous to the use of kg instead of g. The use of kmol is not only for "magnitude convenience" but also makes the equations used for modelling chemical engineering systems coherent. For example, the conversion of a flowrate of kg/s to kmol/s only requires the molecular mass not the factor 1000 unless the basic SI unit of mol/s were to be used. Indeed, the appearance of any conversion factors in a model can cause confusion and is to be avoided; possibly a definition of coherence is the absence of conversion factors in sets of equations developed for modelling.
Concentrations expressed as kmol/m3 are numerically the same as those in mol/dm3 i.e. the molarity conventionally used by chemists for bench measurements; this equality can be convenient for scale-up.
Proposed future definition.
In 2011, the 24th meeting of the General Conference on Weights and Measures (CGPM) agreed a plan for a possible revision of the SI base unit definitions on an as yet undetermined date. This plan, set forward in the meeting's first resolution, included a proposal to redefine the mole in a way that will fix "the Avogadro constant to be equal to exactly 6.022 14X ×1023 when it is expressed in the SI unit mol−1... ... the symbol X in this Draft Resolution represents one or more additional digits to be added to the numerical values ... using values based on the most recent CODATA adjustment".
Related units.
The SI units for molar concentration are mol/m3. However, most chemical literature traditionally uses mol/dm3, or mol dm−3, which is the same as mol/L. These traditional units are often denoted by a capital letter M (pronounced "molar"), sometimes preceded by an SI prefix, for example, millimoles per litre (mmol/L) or millimolar (mM), micromoles/litre (µmol/L) or micromolar (µM), or nanomoles/L (nmol/L) or nanomolar (nM).
The unit's holiday.
October 23 is called Mole Day. It is an informal holiday in honor of the unit among chemists. The date is derived from Avogadro's constant, which is approximately 6.022×1023. It starts at 6:02 a.m. and ends at 6:02 p.m.
Alternatively, some chemists celebrate June 2 or February 6, a reference to the 6.02 part of the constant.

</doc>
<doc id="37401" url="http://en.wikipedia.org/wiki?curid=37401" title="Fertilizer">
Fertilizer

A fertilizer (or fertiliser in British English) is any material of natural or synthetic origin (other than liming materials) that is applied to soils or to plant tissues (usually leaves) to supply one or more plant nutrients essential to the growth of plants. Conservative estimates report 30 to 50% of crop yields are attributed to natural or synthetic commercial fertilizer. Global market value is likely to rise to more than US$185 billion until 2019. The European fertilizer market will grow to earn revenues of approx. €15.3 billion in 2018.
Mechanism.
Fertilizers enhance the growth of plants. This goal is met in two ways, the traditional one being additives that provide nutrients. The second mode by which some fertilizers act is to enhance the effectiveness of the soil by modifying its water retention and aeration. This article, like most on fertilizers, emphasizes the nutritional aspect.
Fertilizers typically provide, in varying proportions:
The nutrients required for healthy plant life are classified according to the elements, but the elements are not used as fertilizers. Instead compounds containing these elements are the basis of fertilizers. The macronutrients are consumed in larger quantities and are present in plant tissue in quantities from 0.15% to 6.0% on a dry matter (DM) (0% moisture) basis. Plants are made up of four main elements: hydrogen, oxygen, carbon, and nitrogen. Carbon, hydrogen and oxygen are widely available as water and carbon dioxide. Although nitrogen makes up most of the atmosphere, it is in a form that is unavailable to plants. Nitrogen is the most important fertilizer since nitrogen is present in proteins, DNA and other components (e.g., chlorophyll). To be nutritious to plants, nitrogen must be made available in a "fixed" form. Only some bacteria and their host plants (notably legumes) can fix atmospheric nitrogen (N2) by converting it to ammonia. Phosphate is required for the production of DNA and ATP, the main energy carrier in cells, as well as certain lipids.
Micronutrients are consumed in smaller quantities and are present in plant tissue on the order of parts-per-million (ppm), ranging from 0.15 to 400 ppm DM, or less than 0.04% DM. These elements are often present at the active sites of enzymes that carry out the plant's metabolism. Because these elements enable catalysts (enzymes) their impact far exceeds their weight percentage.
Classification.
Fertilizers are classified in many ways. They are classified according to whether they provide a single nutrient (say, N, P, or K), in which case they are classified as "straight fertilizers." "Multinutrient fertilizers" (or "complex fertilizers") provide two or more nutrients, for example N and P. Fertilizers are also sometimes classified as inorganic (the topic of most of this article) vs organic. Inorganic fertilizers excludes carbon-containing materials except ureas. Organic fertilizers are usually (recycled) plant- or animal-derived matter. Inorganic are sometimes called synthetic fertilizers since various chemical treatments are required for their manufacture.
Single nutrient ("straight") fertilizers.
The main nitrogen-based straight fertilizer is ammonia or its solutions. Ammonium nitrate (NH4NO3) is also widely used. About 15M tons were produced in 1981, i.e., several kilograms per person. Urea is another popular source of nitrogen, having the advantage that it is a solid and non-explosive, unlike ammonia and ammonium nitrate, respectively. A few percent of the nitrogen fertilizer market (4% in 2007) is met by calcium ammonium nitrate (Ca(NO3)2•NH4NO3•10H2O).
The main straight phosphate fertilizers are the superphosphates. "Single superphosphate" (SSP) consists of 14–18% P2O5, again in the form of Ca(H2PO4)2, but also phosphogypsum (CaSO4 · 2 H2O). Triple superphosphate (TSP) typically consists of 44-48% of P2O5 and no gypsum. A mixture of single superphosphate and triple superphosphate is called double superphosphate. More than 90% of a typical superphosphate fertilizer is water-soluble.
Multinutrient fertilizers.
These fertilizers are the most common. They consist of two or more nutrient components.
Binary (NP, NK, PK) fertilizers.
Major two-component fertilizers provide both nitrogen and phosphorus to the plants. These are called NP fertilizers. The main NP fertilizer are monoammonium phosphate (MAP) and diammonium phosphate (DAP). The active ingredient in MAP is NH4H2PO4. The active ingredient in DAP is (NH4)2HPO4. About 85% of MAP and DAP fertilizers are soluble in water.
NPK fertilizers.
NPK fertilizers are three-component fertilizers providing nitrogen, phosphorus, and potassium.
NPK rating is a rating system describing the amount of nitrogen, phosphorus, and potassium in a fertilizer. NPK ratings consist of three numbers separated by dashes (e.g., 10-10-10 or 16-4-8) describing the chemical content of fertilizers. The first number represents the percentage of nitrogen in the product; the second number, P2O5; the third, K2O. Fertilizers do not actually contain P2O5 or K2O, but the system is a conventional shorthand for the amount of the phosphorus (P) or potassium (K) in a fertilizer. A 50-pound bag of fertilizer labeled 16-4-8 contains 8 pounds of nitrogen (16% of the 50 pounds) an amount of phosphorus and potassium equivalent to that in 2 pounds of P2O5 (4% of 50 pounds) and 4 pounds of K2O (8% of 50 pounds). Most fertilizers are labeled according to this N-P-K convention, though Australian convention, following an N-P-K-S system, adds a fourth number for sulfur.
Micronutrients.
The main micronutrients include sources of iron, manganese, molybdenum, zinc, and copper. As for the macronutrients, these elements are provided as water-soluble salts. Iron presents special problems because it converts to insoluble (bio-unavailable) compounds at moderate soil pH and phosphate concentrations. For this reason, iron is often administered as a chelate complex, e.g. the EDTA derivative. The micronutrient needs depend on the plant. For example, sugar beets appear to require boron, and legumes require cobalt.
Production.
Nitrogen fertilizers.
All nitrogen fertilizers are made from ammonia (NH3), which is sometimes injected into the ground directly. The ammonia is produced by the Haber-Bosch process. In this energy-intensive process, natural gas (CH4) supplies the hydrogen and the nitrogen (N2) is derived from the air. This ammonia is used as a feedstock for all other nitrogen fertilizers, such as anhydrous ammonium nitrate (NH4NO3) and urea (CO(NH2)2). Deposits of sodium nitrate (NaNO3) (Chilean saltpeter) are also found in the Atacama desert in Chile and was one of the original (1830) nitrogen-rich fertilizers used. It is still mined for fertilizer.
Phosphate fertilizers.
All phosphate fertilizers are obtained by extraction from minerals containing the anion PO43−. In rare cases, fields are treated with the crushed mineral, but most often more soluble salts are produced by chemical treatment of phosphate minerals. The most popular phosphate-containing minerals are referred to collectively as phosphate rock. The main minerals are fluorapatite Ca5(PO4)3F (CFA) and hydroxyapatite Ca5(PO4)3OH. These minerals are converted to water-soluble phosphate salts by treatment with sulfuric or phosphoric acids. The large production of sulfuric acid as an industrial chemical is primarily due to its use as cheap acid in processing phosphate rock into phosphate fertilizer. The global primary uses for both sulfur and phosphorus compounds relate to this basic process.
In the nitrophosphate process or Odda process (invented in 1927), phosphate rock with up to a 20% phosphorus (P) content is dissolved with nitric acid (HNO3) to produce a mixture of phosphoric acid (H3PO4) and calcium nitrate (Ca(NO3)2). This mixture can be combined with a potassium fertilizer to produce a "compound fertilizer" with the three macronutrients N, P and K in easily dissolved form.
Potassium fertilizers.
Potash is a mixture of potassium minerals used to make potassium (chemical symbol: K) fertilizers. Potash is soluble in water, so the main effort in producing this nutrient from the ore involves some purification steps; e.g. to remove sodium chloride (NaCl), i.e. common salt. Sometimes potash is referred to as K2O, as a matter of convenience to those describing the potassium content. In fact potash fertilizers are usually potassium chloride, potassium sulfate, potassium carbonate, or potassium nitrate.
Compound fertilizers.
Compound fertilizers, which contain N, P, and K, can often be produced by mixing straight fertilizers. In some cases, chemical reactions occur between the two or more components. For example monoammonium and diammonium phosphates, which provide plants with both N and P, are produced by neutralizing phosphoric acid (from phosphate rock) and ammonia (from a Haber facility):
Organic fertilizers.
The main "organic fertilizers" are, in ranked order, peat, animal wastes, plant wastes from agriculture, and sewage sludge. In terms of volume, peat is the most widely used organic fertilizer. This immature form of coal confers no nutritional value to the plants, but improves the soil by aeration and absorbing water. Animal sources include the products of the slaughter of animals. Bloodmeal, bone meal, hides, hoofs, and horns are typical components. Organic fertilizer usually contain less nutrients, but offer other advantages as well as appealing to environmentally friendly users.
Other elements: calcium, magnesium, and sulfur.
Calcium is supplied as superphosphate or calcium ammonium nitrate solutions.
Application.
Fertilizers are commonly used for growing all crops, with application rates depending on the soil fertility, usually as measured by a soil test and according to the particular crop. Legumes, for example, fix nitrogen from the atmosphere and generally do not require nitrogen fertilizer.
Liquid vs solid.
Fertilizers are applied to crops both as solids and as liquid. About 90% of fertilizers are applied as solids. Solid fertilizer is typically granulated or powdered. Often solids are available as prills, a solid globule. Liquid fertilizers comprise anhydrous ammonia, aqueous solutions of ammonia, aqueous solutions of ammonium nitrate and or urea. These concentrated products may be diluted with water to form a concentrated liquid fertilizer (e.g. UAN). Advantages of liquid fertilizer are its more rapid effect and easier coverage. The addition of fertilizer to irrigation water is called "fertigation".
Slow- and controlled-release fertilizers.
Slow- and controlled-release involve only 0.15% (562,000 tons) of the fertilizer market (1995). Their utility stems from the fact that fertilizers are subject to antagonistic processes. In addition to their providing the nutrition to plants, excess fertilizers can be poisonous to the same plant. Competitive with the uptake by plants is the degradation or loss of the fertilizer. Microbes degrade many fertilizers, e.g. by immobilization or oxidation. Furthermore fertilizers are lost by evaporation or leaching. Most slow-release fertilizers are derivatives of urea, a straight fertilizer providing nitrogen. Isobutylidenediurea ("IBDU") and urea-formaldehyde slowly convert in the soil to free urea, which is rapidly uptaken by plants. IBDU is a single compound with the formula (CH3)2CHCH(NHC(O)NH2)2 whereas the urea-formaldehydes consist of mixtures of the approximate formula (HOCH2NHC(O)NH)nCH2.
Besides being more efficient in the utilization of the applied nutrients, slow-release technologies also reduce the impact on the environment and the contamination of the subsurface water. Slow-release fertilizers (various forms including fertilizer spikes, tabs, etc.) which reduce the problem of "burning" the plants due to excess nitrogen. Polymer coating of fertilizer ingredients gives tablets and spikes a or 'staged nutrient release' (SNR) of fertilizer nutrients.
Controlled release fertilizers are traditional fertilizers encapsulated in a shell that degrades at a specified rate. Sulfur is a typical encapsulation material. Other coated products use thermoplastics (and sometimes ethylene-vinyl acetate and surfactants, etc.) to produce diffusion-controlled release of urea or other fertilizers. "Reactive Layer Coating" can produce thinner, hence cheaper, membrane coatings by applying reactive monomers simultaneously to the soluble particles. "Multicote" is a process applying layers of low-cost fatty acid salts with a paraffin topcoat.
Foliar application.
Foliar fertilizers are applied directly to leaves. The method is almost invariably used to apply water-soluble straight nitrogen fertilizers and used especially for high value crops such as fruits.
Chemicals that affect nitrogen uptake.
Various chemicals are used to enhance the efficiency of nitrogen-based fertilizers. In this way farmers can limit the polluting effects of nitrogen run-off. Nitrification inhibitors (also known as nitrogen stabilizers) suppress the conversion of ammonia into nitrate, an anion that is more prone to leaching. 1-Carbamoyl-3-methylpyrazole (CMP), dicyandiamide, and nitrapyrin (2-chloro-6-trichloromethylpyridine) are popular. Urease inhibitors are used to slow the hydrolytic conversion of urea into ammonia, which is prone to evaporation as well as nitrification. The conversion of urea to ammonia catalyzed by enzymes called ureases. A popular inhibitor of ureases is N-(n-butyl)thiophosphoric triamide (NBPT). 
Overfertilization.
Careful fertilization technologies are important because excess nutrients can be as detrimental. Fertilizer burn can occur when too much fertilizer is applied, resulting in drying out of the leaves and damage or even death of the plant. Fertilizers vary in their tendency to burn roughly in accordance with their salt index.
Statistics.
Data on the per hectare arable land in 2012 are published by The World Bank. For the diagram below values of the European Union (EU) countries have been extracted and are presented as kilograms per hectare. The total consumption of fertilizer in the EU is 15.9 million tons for 105 million hectare arable land area (or 107 million hectare arable land according to another estimate). This figure equates to 151 kg of fertilizers consumed per ha arable land on average for the EU countries. Interestingly, mainly in those countries where fertilizers are consumed a lot also plant growth product are sold more than in others. (See P5 in thumbnail "Pesticide categories" maps on the right.)
Environmental effects.
Water.
Agricultural run-off is a major contributor to the eutrophication of fresh water bodies. For example, in the US, about half of all the lakes are eutrophic. The main contributor to eutrophication is phosphate, which is normally a limiting nutrient; high concentrations promote the growth of cyanobacteria and algae, the demise of which consumes oxygen. Cyanobacteria blooms ('algal blooms') can also produce harmful toxins that can accumulate in the food chain, and can be harmful to humans.
The nitrogen-rich compounds found in fertilizer runoff are the primary cause of serious oxygen depletion in many parts of oceans, especially in coastal zones, lakes and rivers. The resulting lack of dissolved oxygen greatly reduces the ability of these areas to sustain oceanic fauna. The number of oceanic dead zones near inhabited coastlines are increasing. As of 2006, the application of nitrogen fertilizer is being increasingly controlled in northwestern Europe and the United States. If eutrophication "can" be reversed, it may take decades before the accumulated nitrates in groundwater can be broken down by natural processes.
Nitrate pollution.
Only a fraction of the nitrogen-based fertilizers is converted to produce and other plant matter. The remainder accumulates in the soil or lost as run-off. High application rates of nitrogen-containing fertilizers combined with the high water-solubility of nitrate leads to increased runoff into surface water as well as leaching into groundwater, thereby causing groundwater pollution. The excessive use of nitrogen-containing fertilizers (be they synthetic or natural) is particularly damaging, as much of the nitrogen that is not taken up by plants is transformed into nitrate which is easily leached.
Nitrate levels above 10 mg/L (10 ppm) in groundwater can cause 'blue baby syndrome' (acquired methemoglobinemia). The nutrients, especially nitrates, in fertilizers can cause problems for natural habitats and for human health if they are washed off soil into watercourses or leached through soil into groundwater.
Soil.
Acidification.
Nitrogen-containing fertilizers can cause soil acidification when added. This may lead to decreases in nutrient availability which may be offset by liming.
Accumulation of toxic elements.
Cadmium.
The concentration of cadmium in phosphorus-containing fertilizers varies considerably and can be problematic. For example, mono-ammonium phosphate fertilizer may have a cadmium content of as low as 0.14 mg/kg or as high as 50.9 mg/kg. This is because the phosphate rock used in their manufacture can contain as much as 188 mg/kg cadmium (examples are deposits on Nauru and the Christmas islands). Continuous use of high-cadmium fertilizer can contaminate soil (as shown in New Zealand) and plants. Limits to the cadmium content of phosphate fertilizersis has been considered by the European Commission. Producers of phosphorus-containing fertilizers now select phosphate rock based on the cadmium content.
Fluoride.
Phosphate rocks contain high levels of fluoride. Consequently the widespread use of phosphate fertilizers has increased soil fluoride concentrations. It has been found that food contamination from fertilizer is of little concern as plants accumulate little fluoride from the soil; of greater concern is the possibility of fluoride toxicity to livestock that ingest contaminated soils. Also of possible concern are the effects of fluoride on soil microorganisms.
Radioactive elements.
The radioactive content of the fertilizers varies considerably and depends both on their concentrations in the parent mineral and on the fertilizer production process. Uranium-238 concentrations range can range from 7 to 100 pCi/g in phosphate rock and from 1 to 67 pCi/g in phosphate fertilizers. Where high annual rates of phosphorus fertilizer are used, this can result in uranium-238 concentrations in soils and drainange waters that are several times greater than are normally present. However, the impact of these increases on the risk to human health from radinuclide contamination of foods is very small (less than 0.05 mSv/y).
Other metals.
Steel industry wastes, recycled into fertilizers for their high levels of zinc (essential to plant growth), wastes can include the following toxic metals: lead arsenic, cadmium, chromium, and nickel. The most common toxic elements in this type of fertilizer are mercury, lead, and arsenic. These potentially harmful impurities can be removed; however, this significantly increases cost. Highly pure fertilizers are widely available and perhaps best known as the highly water soluble fertilizers containing blue dyes used around households. These highly water soluble fertilizers are used in the plant nursery business and are available in larger packages at significantly less cost than retail quantities. There are also some inexpensive retail granular garden fertilizers made with high purity ingredients.
Trace mineral depletion.
Attention has been addressed to the decreasing concentrations of elements such as iron, zinc, copper and magnesium in many foods over the last 50–60 years. Intensive farming practices, including the use of synthetic fertilizers are frequently suggested as reasons for these declines and organic farming is often suggested as a solution. Although improved crop yields resulting from NPK fertilizers are known to dilute the concentrations of other nutrients in plants, much of the measured decline can be attributed to the use of progressively higher-yielding crop varieties which produce foods with lower mineral concentrations than their less productive ancestors. It is, therefore, unlikely that organic farming or reduced use of fertilizers will solve the problem; foods with high nutrient density are posited to be achieved using older, lower-yielding varieties or the development of new high-yield, nutrient-dense varieties.
Fertilizers are, in fact, more likely to solve trace mineral deficiency problems than cause them: In Western Australia deficiencies of zinc, copper, manganese, iron and molybdenum were identified as limiting the growth of broad-acre crops and pastures in the 1940s and 1950s. Soils in Western Australia are very old, highly weathered and deficient in many of the major nutrients and trace elements. Since this time these trace elements are routinely added to fertilizers used in agriculture in this state. Many other soils around the world are deficient in zinc, leading to deficiency in both plants and humans, and zinc fertilizers are widely used to solve this problem.
Changes in soil biology.
High levels of fertilizer may cause the breakdown of the symbiotic relationships between plant roots and mycorrhizal fungi.
Energy consumption and sustainability.
In the USA in 2004, 317 billion cubic feet of natural gas were consumed in the industrial production of ammonia, less than 1.5% of total U.S. annual consumption of natural gas.
A 2002 report suggested that the production of ammonia consumes about 5% of global natural gas consumption, which is somewhat under 2% of world energy production.
Ammonia is produced from natural gas and air. The cost of natural gas makes up about 90% of the cost of producing ammonia. The increase in price of natural gases over the past decade, along with other factors such as increasing demand, have contributed to an increase in fertilizer price.
Contribution to climate change.
The greenhouse gases carbon dioxide, methane and nitrous oxide are produced during the manufacture of nitrogen fertilizer. The effects can be combined into an equivalent amount of carbon dioxide. The amount varies according to the efficiency of the process. The figure for the United Kingdom is over 2 kilogrammes of carbon dioxide equivalent for each kilogramme of ammonium nitrate. 
Nitrogen fertilizer can be converted by soil bacteria to nitrous oxide, a greenhouse gas.
Atmosphere.
Through the increasing use of nitrogen fertilizer, which was used at a rate of about 110 million tons (of N) per year in 2012, adding to the already existing amount of reactive nitrogen, nitrous oxide (N2O) has become the third most important greenhouse gas after carbon dioxide and methane. It has a global warming potential 296 times larger than an equal mass of carbon dioxide and it also contributes to stratospheric ozone depletion. 
By changing processes and procedures, it is possible to mitigate some, but not all, of these effects on anthropogenic climate change.
Methane emissions from crop fields (notably rice paddy fields) are increased by the application of ammonium-based fertilizers. These emissions contribute to global climate change as methane is a potent greenhouse gas.
Regulation.
In Europe problems with high nitrate concentrations in run-off are being addressed by the European Union's Nitrates Directive. Within Britain, farmers are encouraged to manage their land more sustainably in 'catchment-sensitive farming'. In the US, high concentrations of nitrate and phosphorus in runoff and drainage water are classified as non-point source pollutants due to their diffuse origin; this pollution is regulated at state level. Oregon and Washington, both in the United States, have fertilizer registration programs with on-line databases listing chemical analyses of fertilizers.
History.
Management of soil fertility has been the preoccupation of farmers for thousands of years. Egyptians, Romans, Babylonians, and early Germans all are recorded as using minerals and or manure to enhance the productivity of their farms. The modern science of plant nutrition started in the 19th century and the work of German chemist Justus von Liebig, among others. John Bennet Lawes, an English entrepreneur, began to experiment on the effects of various manures on plants growing in pots in 1837, and a year or two later the experiments were extended to crops in the field. One immediate consequence was that in 1842 he patented a manure formed by treating phosphates with sulphuric acid, and thus was the first to create the artificial manure industry. In the succeeding year he enlisted the services of Joseph Henry Gilbert, with whom he carried on for more than half a century on experiments in raising crops at the Institute of Arable Crops Research.
The Birkeland–Eyde process was one of the competing industrial processes in the beginning of nitrogen based fertilizer production. This process was used to fix atmospheric nitrogen (N2) into nitric acid (HNO3), one of several chemical processes generally referred to as nitrogen fixation. The resultant nitric acid was then used as a source of nitrate (NO3−). A factory based on the process was built in Rjukan and Notodden in Norway, combined with the building of large hydroelectric power facilities.
The 1910s and 1920s witness the rise of the Haber process and the Ostwald process. The Haber process produces ammonia (NH3) from methane (CH4) gas and molecular nitrogen (N2). The ammonia from the Haber process is then converted into nitric acid (HNO3) in the Ostwald process. The development of synthetic fertilizer has significantly supported global population growth — it has been estimated that almost half the people on the Earth are currently fed as a result of synthetic nitrogen fertilizer use.
The use of commercial fertilizers has increased steadily in the last 50 years, rising almost 20-fold to the current rate of 100 million tonnes of nitrogen per year. Without commercial fertilizers it is estimated that about one-third of the food produced now could not be produced. The use of phosphate fertilizers has also increased from 9 million tonnes per year in 1960 to 40 million tonnes per year in 2000. A maize crop yielding 6–9 tonnes of grain per hectare requires 31–50 kg of phosphate fertilizer to be applied, soybean requires 20–25 kg per hectare. Yara International is the world's largest producer of nitrogen based fertilizers.
Controlled-nitrogen-release technologies based on polymers derived from combining urea and formaldehyde were first produced in 1936 and commercialized in 1955. The early product had 60 percent of the total nitrogen cold-water-insoluble, and the unreacted (quick release) less than 15%. Methylene ureas were commercialized in the 1960s and 1970s, having 25 and 60% of the nitrogen cold-water-insoluble, and unreacted urea nitrogen in the range of 15 to 30%.
In the 1960s, the Tennessee Valley Authority National Fertilizer Development Center began developing Sulfur-coated urea; sulfur was used as the principle coating material because of its low cost and its value as a secondary nutrient. Usually there is another wax or polymer which seals the sulfur; the slow release properties depend on the degradation of the secondary sealant by soil microbes as well as mechanical imperfections (cracks, etc.) in the sulfur. They typically provide 6 to 16 weeks of delayed release in turf applications. When a hard polymer is used as the secondary coating, the properties are a cross between diffusion-controlled particles and traditional sulfur-coated.

</doc>
<doc id="37402" url="http://en.wikipedia.org/wiki?curid=37402" title="Chicken">
Chicken

The chicken ("Gallus gallus domesticus") is a domesticated fowl, a subspecies of the red junglefowl. As one of the most common and widespread domestic animals, with a population of more than 24 billion in 2003, there are more chickens in the world than any other species of bird. Humans keep chickens primarily as a source of food, consuming both their meat and their eggs.
The traditional poultry farming view of the domestication of the chicken is stated in "Encyclopædia Britannica" (2007): "Humans first domesticated chickens of Indian origin for the purpose of cockfighting in Asia, Africa, and Europe. Very little formal attention was given to egg or meat production... ", a view which is supported by many archeologists. Recent genetic studies have pointed to multiple maternal origins in Southeast, East, and South Asia, but with the clade found in the Americas, Europe, the Middle East and Africa originating in the Indian subcontinent. From India, the domesticated chicken was imported to Lydia in western Asia Minor, and to Greece by the fifth century BC. Fowl had been known in Egypt since the mid-15th century BC, with the "bird that gives birth every day" having come to Egypt from the land between Syria and Shinar, Babylonia, according to the annals of Thutmose III.
Terminology.
In the UK and Ireland adult male chickens over the age of one year are primarily known as cocks, whereas in America, Australia and Canada they are more commonly called roosters. Males less than a year old are "cockerels". Castrated roosters are called "capons" (surgical and chemical castration are now illegal in some parts of the world). Females over a year old are known as "hens" and younger females as "pullets" although in the egg-laying industry, a pullet becomes a hen when she begins to lay eggs at 16 to 20 weeks of age. In Australia and New Zealand (also sometimes in Britain), there is a generic term "chook" to describe all ages and both sexes. The young are called "chicks" and the meat is called "chicken".
"Chicken" originally referred to chicks, not the species itself. The species as a whole was then called "domestic fowl", or just "fowl". This use of "chicken" survives in the phrase "Hen and Chickens", sometimes used as a British public house or theatre name, and to name groups of one large and many small rocks or islands in the sea (see for example Hen and Chicken Islands).
In the Deep South of the United States chickens are also referred to by the slang term "yardbird".
General biology and habitat.
Chickens are omnivores. In the wild, they often scratch at the soil to search for seeds, insects and even larger animals such as lizards, small snakes or young mice.
Chickens may live for five to ten years, depending on the breed. The world's oldest chicken, a hen, died of heart failure at the age of 16 according to Guinness World Records.
Roosters can usually be differentiated from hens by their striking plumage of long flowing tails and shiny, pointed feathers on their necks ("hackles") and backs ("saddle"), which are typically of brighter, bolder colours than those of females of the same breed. However, in some breeds, such as the Sebright chicken, the rooster has only slightly pointed neck feathers, the same colour as the hen's. The identification can be made by looking at the comb, or eventually from the development of spurs on the male's legs (in a few breeds and in certain hybrids, the male and female chicks may be differentiated by colour). Adult chickens have a fleshy crest on their heads called a comb, or cockscomb, and hanging flaps of skin either side under their beaks called wattles. Collectively, these and other fleshy protuberances on the head and throat are called caruncles. Both the adult male and female have wattles and combs, but in most breeds these are more prominent in males.
A "muff" or "beard" is a mutation found in several chicken breeds which causes extra feathering under the chicken's face, giving the appearance of a beard.
Domestic chickens are not capable of long distance flight, although lighter birds are generally capable of flying for short distances, such as over fences or into trees (where they would naturally roost). Chickens may occasionally fly briefly to explore their surroundings, but generally do so only to flee perceived danger.
Behaviour.
Social behaviour.
Chickens are gregarious birds and live together in flocks. They have a communal approach to the incubation of eggs and raising of young. Individual chickens in a flock will dominate others, establishing a "pecking order", with dominant individuals having priority for food access and nesting locations. Removing hens or roosters from a flock causes a temporary disruption to this social order until a new pecking order is established. Adding hens, especially younger birds, to an existing flock can lead to fighting and injury.
When a rooster finds food, he may call other chickens to eat first. He does this by clucking in a high pitch as well as picking up and dropping the food. This behaviour may also be observed in mother hens to call their chicks and encourage them to eat.
Roosters crowing (a loud and sometimes shrill call) is a territorial signal to other roosters. However, crowing may also result from sudden disturbances within their surroundings. Hens cluck loudly after laying an egg, and also to call their chicks. Chickens also give a low "warning call" when they think they see a predator approaching.
Courtship.
To initiate courting, some roosters may dance in a circle around or near a hen ("a circle dance"), often lowering his wing which is closest to the hen. The dance triggers a response in the hen and when she responds to his "call", the rooster may mount the hen and proceed with the mating.
Nesting and laying behaviour.
Hens will often try to lay in nests that already contain eggs and have been known to move eggs from neighbouring nests into their own. The result of this behaviour is that a flock will use only a few preferred locations, rather than having a different nest for every bird. Hens will often express a preference to lay in the same location. It is not unknown for two (or more) hens to try to share the same nest at the same time. If the nest is small, or one of the hens is particularly determined, this may result in chickens trying to lay on top of each other. There is evidence that individual hens prefer to be either solitary or gregarious nesters. Some farmers use fake eggs made from plastic or stone (or golf balls) to encourage hens to lay in a particular location.
Broodiness.
Under natural conditions, most birds lay only until a clutch is complete, and they will then incubate all the eggs. Many domestic hens will also do this–and are then said to "go broody". The broody hen will stop laying and instead will focus on the incubation of the eggs (a full clutch is usually about 12 eggs). She will "sit" or "set" on the nest, protesting or pecking in defense if disturbed or removed, and she will rarely leave the nest to eat, drink, or dust-bathe. While brooding, the hen maintains the nest at a constant temperature and humidity, as well as turning the eggs regularly during the first part of the incubation. To stimulate broodiness, an owner may place many artificial eggs in the nest, or to stop it they may place the hen in an elevated cage with an open wire floor.
Modern egg-laying breeds rarely go broody, and those that do often stop part-way through the incubation. However, some "utility" (general purpose) breeds, such as the Cochin, Cornish and Silkie, do regularly go broody, and they make excellent mothers, not only for chicken eggs but also for those of other species—even those with much smaller or larger eggs and different incubation periods, such as quail, pheasants, turkeys or geese. Chicken eggs can also be hatched under a broody duck, with varied success.
Hatching and early life.
At the end of the incubation period (about 21 days), the eggs, if fertile, will hatch. Development of the egg starts only when incubation begins, so they all hatch within a day or two of each other, despite perhaps being laid over a period of two weeks or so. Before hatching, the hen can hear the chicks peeping inside the eggs, and will gently cluck to stimulate them to break out of their shells. The chick begins by "pipping"; pecking a breathing hole with its egg tooth towards the blunt end of the egg, usually on the upper side. The chick will then rest for some hours, absorbing the remaining egg yolk and withdrawing the blood supply from the membrane beneath the shell (used earlier for breathing through the shell). It then enlarges the hole, gradually turning round as it goes, and eventually severing the blunt end of the shell completely to make a lid. It crawls out of the remaining shell, and its wet down dries out in the warmth of the nest.
The hen will usually stay on the nest for about two days after the first egg hatches, and during this time the newly hatched chicks live off the egg yolk they absorb just before hatching. Any eggs not fertilized by a rooster will not hatch, and the hen eventually loses interest in these and leaves the nest. After hatching, the hen fiercely guards the chicks, and will brood them when necessary to keep them warm, at first often returning to the nest at night. She leads them to food and water; she will call them to edible items, but seldom feeds them directly. She continues to care for them until they are several weeks old, when she will gradually lose interest and eventually start to lay again.
Embryology.
In 2006, scientists researching the ancestry of birds "turned on" a chicken recessive gene, "talpid2", and found that the embryo jaws initiated formation of teeth, like those found in ancient bird fossils. John Fallon, the overseer of the project, stated that chickens have "...retained the ability to make teeth, under certain conditions... ."
Breeding.
Origins.
The domestic chicken is descended primarily from the red junglefowl ("Gallus gallus") and is scientifically classified as the same species. As such it can and does freely interbreed with populations of red jungle fowl. Recent genetic analysis has revealed that at least the gene for yellow skin was incorporated into domestic birds through hybridization with the grey junglefowl ("G. sonneratii"). The traditional poultry farming view is stated in "Encyclopædia Britannica" (2007): "Humans first domesticated chickens of Indian origin for the purpose of cockfighting in Asia, Africa, and Europe. Very little formal attention was given to egg or meat production... ", a view supported by many archeologists. In the last decade there have been a number of genetic studies. According to one study, a single domestication event occurring in the region of modern Thailand created the modern chicken with minor transitions separating the modern breeds. However, that study was later found to be based on incomplete data, and recent studies point to multiple maternal origins, with the clade found in the Americas, Europe, Middle East, and Africa, originating from the Indian subcontinent, where a large number of unique haplotypes occur. It is postulated that the jungle fowl, known as the "bamboo fowl" in many Southeast Asian languages, is a special pheasant well adapted to take advantage of the large amounts of fruits that are produced during the end of the 50 year bamboo seeding cycle to boost its own reproduction. In domesticating the chicken, humans took advantage of this prolific reproduction of the jungle fowl when exposed to large amount of food.
It has been claimed (based on paleoclimatic assumptions) that chickens were domesticated in Southern China in 6000 BC. However, according to a recent study, "it is not known whether these birds made much contribution to the modern domestic fowl. Chickens from the Harappan culture of the Indus Valley (2500-2100 BC), in what today is Pakistan, may have been the main source of diffusion throughout the world." A northern road spread the chicken to the Tarim basin of central Asia. The chicken reached Europe (Romania, Turkey, Greece, Ukraine) about 3000 BC.
Introduction into Western Europe came far later, about the 1st millennium BC. Phoenicians spread chickens along the Mediterranean coasts, to Iberia. Breeding increased under the Roman Empire, and was reduced in the Middle Ages.
Middle East traces of chicken go back to a little earlier than 2000 BC, in Syria; chicken went southward only in the 1st millennium BC. The chicken reached Egypt for purposes of cock fighting about 1400 BC, and became widely bred only in Ptolemaic Egypt (about 300 BC). Little is known about the chicken's introduction into Africa. Three possible routes of introduction in about the early first millennium AD could have been through the Egyptian Nile Valley, the East Africa Roman-Greek or Indian trade, or from Carthage and the Berbers, across the Sahara. The earliest known remains are from Mali, Nubia, East Coast, and South Africa and date back to the middle of the first millennium AD.
Domestic chicken in the Americas before Western conquest is still an ongoing discussion, but blue-egged chickens, found only in the Americas and Asia, suggest an Asian origin for early American chickens.
A lack of data from Thailand, Russia, the Indian subcontinent, Southeast Asia and Sub-Saharan Africa makes it difficult to lay out a clear map of the spread of chickens in these areas; better description and genetic analysis of local breeds threatened by extinction may also help with research into this area.
South America.
An unusual variety of chicken that has its origins in South America is the araucana, bred in southern Chile by the Mapuche people. Araucanas, some of which are tailless and some of which have tufts of feathers around their ears, lay blue-green eggs. It has long been suggested that they pre-date the arrival of European chickens brought by the Spanish and are evidence of pre-Columbian trans-Pacific contacts between Asian or Pacific Oceanic peoples, particularly the Polynesians, and South America. In 2007, an international team of researchers reported the results of analysis of chicken bones found on the Arauco Peninsula in south-central Chile. Radiocarbon dating suggested that the chickens were Pre-Columbian, and DNA analysis showed that they were related to prehistoric populations of chickens in Polynesia. These results appeared to confirm that the chickens came from Polynesia and that there were transpacific contacts between Polynesia and South America before Columbus's arrival in the Americas.
However, a later report looking at the same specimens concluded:
A published, apparently pre-Columbian, Chilean specimen and six pre-European Polynesian specimens also cluster with the same European/Indian subcontinental/Southeast Asian sequences, providing no support for a Polynesian introduction of chickens to South America. In contrast, sequences from two archaeological sites on Easter Island group with an uncommon haplogroup from Indonesia, Japan, and China and may represent a genetic signature of an early Polynesian dispersal. Modeling of the potential marine carbon contribution to the Chilean archaeological specimen casts further doubt on claims for pre-Columbian chickens, and definitive proof will require further analyses of ancient DNA sequences and radiocarbon and stable isotope data from archaeological excavations within both Chile and Polynesia.
Farming.
More than 50 billion chickens are reared annually as a source of food, for both their meat and their eggs.
The vast majority of poultry are raised in factory farms. According to the Worldwatch Institute, 74 percent of the world's poultry meat, and 68 percent of eggs are produced this way. One alternative to intensive poultry farming is free range farming.
Friction between these two main methods has led to long term issues of ethical consumerism. Opponents of intensive farming argue that it harms the environment, creates human health risks and is inhumane. Advocates of intensive farming say that their highly efficient systems save land and food resources due to increased productivity, stating that the animals are looked after in state-of-the-art environmentally controlled facilities.
In part due to the conditions on intensive poultry farms and recent recalls of large quantities of eggs, there is a growing movement for small scale micro-flocks or 'backyard chickens'. This involves keeping small numbers of hens (usually no more than a dozen), in suburban or urban residential areas to control bugs, utilize chicken waste as fertilizer in small gardens, and of course for the high-quality eggs and meat that are produced.
Reared for meat.
Chickens farmed for meat are called broiler chickens. Chickens will naturally live for 6 or more years, but broiler chickens typically take less than 6 weeks to reach slaughter size. A free range or organic meat chicken will usually be slaughtered at about 14 weeks of age.
Reared for eggs.
Chickens farmed for eggs are called egg-laying hens. In total, the UK alone consumes over 29 million eggs per day. Some hen breeds can produce over 300 eggs per year, with "the highest authenticated rate of egg laying being 371 eggs in 364 days". After 12 months of laying, the commercial hen's egg-laying ability starts to decline to the point where the flock is unviable. Hens, particularly from battery cage systems, are sometimes infirm, have lost a significant amount of their feathers, and their life expectancy has been reduced from around 7 years to less than 2 years. In the UK and Europe, laying hens are then slaughtered and used in processed foods, or sold as "soup hens". In some other countries, flocks are sometimes force moulted, rather than being slaughtered, to reinvigorate egg-laying. This involves complete withdrawal of food (and sometimes water) for 7–14 days or sufficiently long to cause a body weight loss of 25 to 35%, or up to 28 days under experimental conditions which presumably reflect farming practice. This stimulates the hen to lose her feathers, but also reinvigorates egg-production. Some flocks may be force moulted several times. In 2003, more than 75% of all flocks were moulted in the US.
Artificial incubation.
Incubation can successfully occur artificially in machines that provide the correct, controlled environment for the developing chick. The average incubation period for chickens is 21 days but may depend on the temperature and humidity in the incubator. Temperature regulation is the most critical factor for a successful hatch. Variations of more than 1 °C (1.8 °F) from the optimum temperature of 37.5 °C will reduce hatch rates. Humidity is also important because the rate at which eggs lose water by evaporation depends on the ambient relative humidity. Evaporation can be assessed by candling, to view the size of the air sac, or by measuring weight loss. Relative humidity should be increased to around 70% in the last three days of incubation to keep the membrane around the hatching chick from drying out after the chick cracks the shell. Lower humidity is usual in the first 18 days to ensure adequate evaporation. The position of the eggs in the incubator can also influence hatch rates. For best results, eggs should be placed with the pointed ends down and turned regularly (at least three times per day) until one to three days before hatching. If the eggs aren't turned, the embryo inside may stick to the shell and may hatch with physical defects. Adequate ventilation is necessary to provide the embryo with oxygen. Older eggs require increased ventilation.
Many commercial incubators are industrial-sized with shelves holding tens of thousands of eggs at a time, with rotation of the eggs a fully automated process. Home incubators are boxes holding from 6 to 75 eggs; they are usually electrically powered, but in the past some were heated with an oil or paraffin lamp.
As pets.
Chickens are sometimes kept as pets and can be tamed by hand feeding, but roosters can sometimes become aggressive and noisy, although aggression can be curbed with proper handling. Some have advised against keeping them around very young children. Certain breeds, however, such as silkies and many bantam varieties are generally docile and are often recommended as good pets around children with disabilities.
Some people find chickens' behaviour entertaining and educational.
Diseases and ailments.
Chickens are susceptible to several parasites, including lice, mites, ticks, fleas, and intestinal worms, as well as other diseases. Despite the name, they are not affected by chickenpox, which is generally restricted to humans.
Some of the common diseases that affect chickens are shown below:
In religion and mythology.
Since antiquity chickens have been, and still are, a sacred animal in some cultures and deeply embedded within belief systems and religious worship. The term "Persian bird" for the cock appears to been given by the Greeks after Persian contact "because of his great importance and his religious use among the Persians".
In Indonesia the chicken has great significance during the Hindu cremation ceremony. A chicken is considered a channel for evil spirits which may be present during the ceremony. A chicken is tethered by the leg and kept present at the ceremony for its duration to ensure that any evil spirits present go into the chicken and not the family members. The chicken is then taken home and returns to its normal life.
In ancient Greece, the chicken was not normally used for sacrifices, perhaps because it was still considered an exotic animal. Because of its valor, the cock is found as an attribute of Ares, Heracles, and Athena. The alleged last words of Socrates as he died from hemlock poisoning, as recounted by Plato, were "Crito, I owe a cock to Asclepius; will you remember to pay the debt?", signifying that death was a cure for the illness of life.
The Greeks believed that even lions were afraid of roosters. Several of Aesop's Fables reference this belief.
In the New Testament, Jesus prophesied the betrayal by Peter: "Jesus answered, 'I tell you, Peter, before the rooster crows today, you will deny three times that you know me.'" It happened, and Peter cried bitterly. This made the rooster a symbol for both vigilance and betrayal.
Earlier, Jesus compares himself to a mother hen when talking about Jerusalem: "O Jerusalem, Jerusalem, you who kill the prophets and stone those sent to you, how often I have longed to gather your children together, as a hen gathers her chicks under her wings, but you were not willing."
In the sixth century, Pope Gregory I declared the rooster the emblem of Christianity and another Papal enactment of the ninth century by Pope Nicholas I ordered the figure of the rooster to be placed on every church steeple.
In many Central European folk tales, the devil is believed to flee at the first crowing of a rooster.
In traditional Jewish practice, a kosher animal is swung around the head and then slaughtered on the afternoon before Yom Kippur, the Day of Atonement, in a ritual called kapparos; it is now common practice to cradle the bird and move it around the head. A chicken or fish is typically used because it is commonly available (and small enough to hold). The sacrifice of the animal is to receive atonement, for the animal symbolically takes on all the person's sins in kapparos. The meat is then donated to the poor. A woman brings a hen for the ceremony, while a man brings a rooster. Although not a sacrifice in the biblical sense, the death of the animal reminds the penitent sinner that his or her life is in God's hands.
The Talmud speaks of learning "courtesy toward one's mate" from the rooster. This might refer to the fact that when a rooster finds something good to eat, he calls his hens to eat first. The Talmud likewise provides us with the statement "Had the Torah not been given to us, we would have learned modesty from cats, honest toil from ants, chastity from doves and gallantry from cocks," which may be further understood as to that of the gallantry of cocks being taken in the context of a religious instilling vessel of "a girt one of the loins" (Young's Literal Translation) that which is "stately in his stride" and "move with stately bearing" in the Book of Proverbs 30:29-31 as referenced by Michael V. Fox in his "Proverbs" 10-31 where Saʻadiah ben Yosef Gaon (Saadia Gaon) identifies the definitive trait of "A cock girded about the loins" in Proverbs 30:31 (Douay–Rheims Bible) as "the honesty of their behavior and their success", identifying a spiritual purpose of a religious vessel within that religious instilling schema of purpose and use.
The chicken is one of the Zodiac symbols of the Chinese calendar. In Chinese folk religion, a cooked chicken as a religious offering is usually limited to ancestor veneration and worship of village deities. Vegetarian deities such as the Buddha are not recipients of such offerings. Under some observations, an offering of chicken is presented with "serious" prayer (while roasted pork is offered during a joyous celebration). In Confucian Chinese weddings, a chicken can be used as a substitute for one who is seriously ill or not available (e.g., sudden death) to attend the ceremony. A red silk scarf is placed on the chicken's head and a close relative of the absent bride/groom holds the chicken so the ceremony may proceed. However, this practice is rare today.
A cockatrice was supposed to have been born from an egg laid by a rooster, as well as killed by a rooster's call.
In history.
An early domestication of chickens in Southeast Asia is probable, since the word for domestic chicken ("*manuk") is part of the reconstructed Proto-Austronesian language (see Austronesian languages). Chickens, together with dogs and pigs, were the domestic animals of the Lapita culture, the first Neolithic culture of Oceania.
The first pictures of chickens in Europe are found on Corinthian pottery of the 7th century BC. The poet Cratinus (mid-5th century BC, according to the later Greek author Athenaeus) calls the chicken "the Persian alarm". In Aristophanes's comedy "The Birds" (414 BC) a chicken is called "the Median bird", which points to an introduction from the East. Pictures of chickens are found on Greek red figure and black-figure pottery.
In ancient Greece, chickens were still rare and were a rather prestigious food for symposia. Delos seems to have been a center of chicken breeding (Columella, "De Re Rustica" 8.3.4).
The Romans used chickens for oracles, both when flying ("ex avibus", Augury) and when feeding ("auspicium ex tripudiis", Alectryomancy). The hen ("gallina") gave a favourable omen ("auspicium ratum"), when appearing from the left (Cic.,de Div. ii.26), like the crow and the owl.
For the oracle "ex tripudiis" according to Cicero (Cic. de Div. ii.34), any bird could be used in auspice, and shows at one point that any bird could perform the "tripudium" but normally only chickens ("pulli") were consulted. The chickens were cared for by the pullarius, who opened their cage and fed them pulses or a special kind of soft cake when an augury was needed. If the chickens stayed in their cage, made noises ("occinerent"), beat their wings or flew away, the omen was bad; if they ate greedily, the omen was good.
In 249 BC, the Roman general Publius Claudius Pulcher had his "sacred chickens" " thrown overboard when they refused to feed before the battle of Drepana, saying "If they won't eat, perhaps they will drink." He promptly lost the battle against the Carthaginians and 93 Roman ships were sunk. Back in Rome, he was tried for impiety and heavily fined.
In 162 BC, the Lex Faunia forbade fattening hens to conserve grain rations. To get around this, the Romans castrated roosters(capon), which resulted in a doubling of size despite the law that was passed in Rome that forbade the consumption of fattened chickens. It was renewed a number of times, but does not seem to have been successful. Fattening chickens with bread soaked in milk was thought to give especially delicious results. The Roman gourmet Apicius offers 17 recipes for chicken, mainly boiled chicken with a sauce. All parts of the animal are used: the recipes include the stomach, liver, testicles and even the pygostyle (the fatty "tail" of the chicken where the tail feathers attach).
The Roman author Columella gives advice on chicken breeding in his eighth book of his treatise, "De Re Rustica" (On Agriculture). He identified Tanagrian, Rhodic, Chalkidic and Median (commonly misidentified as Melian) breeds, which have an impressive appearance, a quarrelsome nature and were used for cockfighting by the Greeks ("De Re Rustica" 8.3.4). For farming, native (Roman) chickens are to be preferred, or a cross between native hens and Greek cocks ("De Re Rustica" 8.2.13). Dwarf chickens are nice to watch because of their size but have no other advantages.
According to Columella ("De Re Rustica" 8.2.7), the ideal flock consists of 200 birds, which can be supervised by one person if someone is watching for stray animals. White chickens should be avoided as they are not very fertile and are easily caught by eagles or goshawks. One cock should be kept for five hens. In the case of Rhodian and Median cocks that are very heavy and therefore not much inclined to sex, only three hens are kept per cock. The hens of heavy fowls are not much inclined to brood; therefore their eggs are best hatched by normal hens. A hen can hatch no more than 15-23 eggs, depending on the time of year, and supervise no more than 30 hatchlings. Eggs that are long and pointed give more male, rounded eggs mainly female hatchlings ("De Re Rustica" 8.5.11).
Columella also states that chicken coops should face southeast and lie adjacent to the kitchen, as smoke is beneficial for the animals and "poultry never thrive so well as in warmth and smoke" ("De Re Rustica" 8.3.1). Coops should consist of three rooms and possess a hearth. Dry dust or ash should be provided for dust-baths.
According to Columella ("De Re Rustica" 8.4.1), chickens should be fed on barley groats, small chick-peas, millet and wheat bran, if they are cheap. Wheat itself should be avoided as it is harmful to the birds. Boiled ryegrass ("Lolium" sp.) and the leaves and seeds of alfalfa ("Medicago sativa" L.) can be used as well. Grape marc can be used, but only when the hens stop laying eggs, that is, about the middle of November; otherwise eggs are small and few. When feeding grape marc, it should be supplemented with some bran. Hens start to lay eggs after the winter solstice, in warm places around the first of January, in colder areas in the middle of February. Parboiled barley increases their fertility; this should be mixed with alfalfa leaves and seeds, or vetches or millet if alfalfa is not at hand. Free-ranging chickens should receive two cups of barley daily.
Columella advises farmers to slaughter hens that are older than three years, because they no longer produce sufficient eggs.
According to Aldrovandi: Capons were produced by burning "the hind part of the bowels, or loins or spurs" with a hot iron. The wound was treated with potter's chalk.
For the use of poultry and eggs in the kitchens of ancient Rome see Roman eating and drinking.
Chickens were spread by Polynesian seafarers and reached Easter Island in the 12th century AD, where they were the only domestic animal, with the possible exception of the Polynesian rat ("Rattus exulans"). They were housed in extremely solid chicken coops built from stone, which was first reported as such to Linton Palmer in 1868, who also "expressed his doubts about this".
As food.
The meat of the chicken, also called "chicken", is a type of poultry meat. Because of its relatively low cost, chicken is one of the most used meats in the world. Nearly all parts of the bird can be used for food, and the meat can be cooked in many different ways. Popular chicken dishes include roasted chicken, fried chicken, chicken soup, Buffalo wings, tandoori chicken, butter chicken, and chicken rice. Chicken is also a staple of many fast food restaurants.
Eggs.
In 2000, there were 50.4 million tons of eggs produced in the world ("Executive guide to world poultry trends," 2001) and an estimated 53.4 million tons of table eggs were produced during 2002. In 2009, an estimated 62.1 million metric tons of eggs were produced worldwide from a total laying flock of approximately 6.4 billion hens.
Chicken eggs are widely used in many types of dishes, both sweet and savory, including many baked goods. Eggs can be scrambled, fried, hard-boiled, soft-boiled, pickled, and poached. The albumen, or egg white, contains protein but little or no fat, and can be used in cooking separately from the yolk. Egg whites may be aerated or whipped to a light, fluffy consistency and are often used in desserts such as meringues and mousse. Ground egg shells are sometimes used as a food additive to deliver calcium. Hens do not need a male to produce eggs, only to fertilize them. A flock containing only females will still produce eggs; however, the eggs will all be infertile.

</doc>
<doc id="37403" url="http://en.wikipedia.org/wiki?curid=37403" title="Eastern Europe">
Eastern Europe

Eastern Europe is the eastern part of the European continent. There is no consensus as to the precise area it refers to, partly because the term has a wide range of geopolitical, geographical, cultural, and socioeconomic connotations. There are "almost as many definitions of Eastern Europe as there are scholars of the region". A related United Nations paper adds that "every assessment of spatial identities is essentially a social and cultural construct".
One definition describes Eastern Europe as a cultural (and econo-cultural) entity: the region lying in Europe with main characteristics consisting in Byzantine, Orthodox, and some Turco-Islamic influences. Another definition was created during the Cold War and used more or less synonymously with the term "Eastern Bloc". A similar definition names the formerly communist European states outside the Soviet Union as Eastern Europe. Although some view such definitions as outdated or relegating, they are still heard in everyday speech and used for statistical purposes by various supranational organizations.
Definitions.
Several definitions of Eastern Europe exist today, but they often lack precision or are extremely general. These definitions vary both across cultures and among experts, even political scientists, recently becoming more and more imprecise.
Geographical.
The Ural Mountains, Ural River, and the Caucasus Mountains are the geographical land border of the eastern edge of Europe. In the west, however, the cultural and religious boundaries of "Eastern Europe" are subject to considerable overlap and, most importantly, have undergone historical fluctuations, which make a precise definition of the western boundaries of Eastern Europe and the geographical midpoint of Europe somewhat difficult.
International organisations.
European Union.
The Multilingual Thesaurus of the European Union provides entries for "23 EU languages" ( "Bulgarian, Croatian, Czech", Danish, Dutch, English, Estonian, Finnish, French, German, Greek, "Hungarian", Italian, Latvian, Lithuanian, Maltese, "Polish", Portuguese, "Romanian, Slovak, Slovenian", Spanish and Swedish) plus "Serbian". Of these, those in italics are classified as "Eastern Europe" in this source.
Central Intelligence Agency.
CIA defines Eastern Europe as Belarus, Estonia, Latvia, Lithuania, Moldova, Russia (transcontinental), Turkey (transcontinental) and Ukraine.
Political, military and economic.
Historical.
One view of the present boundaries of Eastern Europe came into being during the final stages of World War II. The area eventually came to encompass all the European countries which were under Soviet influence. Countries which had communist governments in the postwar era (1945-1989/1992), and neutral countries were classified by the nature of their political regimes.
The Cold War increased the number of reasons for the division of Europe into two parts along the borders of NATO and Warsaw Pact states. ("See": The Cold War section).
The economic organisation connecting the countries was the Council for Mutual Economic Assistance.
Contemporary.
In recent years, after the fall of the USSR, a few political and economic organisations emerged in the region of Eastern Europe, including the Commonwealth of Independent States (CIS), the Union State.
Cultural.
A competing view excludes from the definition of Eastern Europe states historically and culturally different, constituting part of the so-called Western world. This could potentially refer to various formerly Communist countries of Central Europe and the Baltic states which have different political, religious, cultural, and economic histories from their eastern neighbors e.g. Russia and Ukraine. ("See": Classical antiquity and medieval origins section).
Religious.
The East–West Schism is the break of communion and theology between what are now the Eastern (Orthodox) and Western (Roman Catholic, as well as Protestant) churches which began in the 11th century and lasts until this very day. It divided Christianity in Europe, and consequently the world, into Western Christianity and Eastern Christianity.
Contemporary developments.
The fall of the Iron Curtain brought the end of the East-West division in Europe, but this geopolitical concept is sometimes still used for quick reference by the media.
Baltic states.
Most sources place the Baltic states in Northern Europe whereas the CIA World Factbook places the region in Eastern Europe.
Transcaucasia.
The Caucasus states are rarely included in definitions of Eastern Europe or histories of Eastern Europe. They are located on or near the border of Europe and Asia. They participate in European Union's Eastern Partnership Program and are members of the Council of Europe which specifies that all three are "geographically" in Asia but have "political" and cultural connections to Turkey and Europe; Georgia has sought membership in NATO and EU. The World Factbook and National Geographic Society atlases and the United Nations Statistics Division have always listed and or shown the three states as in Asia.
Other former Soviet states.
Several other former Soviet republics may be considered part of Eastern Europe
Central Europe.
The term "Central Europe" is often used by historians to designate Germany and its eastern neighbors, and thus overlaps with "Eastern Europe." The following countries are often labeled Eastern European by some commentators and as Central European by others.
Southeastern Europe.
Most Southeastern European states did not belong to the Eastern Bloc (save Bulgaria, Romania, and for a short time, Albania) although some of them were represented in the Cominform. Only some of them can be included in the classical former political definition of Eastern Europe. Some can be considered part of Southern Europe. However, most can be characterized as belonging to South-eastern Europe, but some of them may also be included in Central Europe or Eastern Europe.
Disputed states:
History.
Classical antiquity and medieval origins.
Ancient kingdoms of the region included Orontid Armenia Albania, Colchis and Iberia. These kingdoms were either from the start, or later on incorporated into various Iranian empires, including the Achaemenid Persian, Parthian, and Sassanid Persian Empires. Parts of the Balkans and more northern areas were ruled by the Achaemenid Persians as well, including Thrace, Paeonia, Macedon, and most of the Black Sea coastal regions of Romania, Ukraine, and Russia. Owing to the rivalry between Parthian Iran and Rome, and later Byzantium and the Sassanid Persians, the former would invade the region several times, although it was never able to hold the region, unlike the Sassanids who ruled over most of the Caucasus during their entire rule.
The earliest known distinctions between east and west in Europe originate in the history of the Roman Republic. As the Roman domain expanded, a cultural and linguistic division appeared between the mainly Greek-speaking eastern provinces which had formed the highly urbanized Hellenistic civilization. In contrast the western territories largely adopted the Latin language. This cultural and linguistic division was eventually reinforced by the later political east-west division of the Roman Empire.
The division between these two spheres was enhanced during Late Antiquity and the Middle Ages by a number of events. The Western Roman Empire collapsed starting the Early Middle Ages. By contrast, the Eastern Roman Empire, mostly known as the Byzantine Empire, managed to survive and even to thrive for another 1,000 years. The rise of the Frankish Empire in the west, and in particular the Great Schism that formally divided Eastern and Western Christianity, enhanced the cultural and religious distinctiveness between Eastern and Western Europe. Much of Eastern Europe was invaded and occupied by the Mongols.
The conquest of the Byzantine Empire, center of the Eastern Orthodox Church, by the Ottoman Empire in the 15th century, and the gradual fragmentation of the Holy Roman Empire (which had replaced the Frankish empire) led to a change of the importance of Roman Catholic/Protestant vs. Eastern Orthodox concept in Europe. Armour points out that the Cyrillic alphabet use is not a strict determinant for Eastern Europe, where from Croatia to Poland and everywhere in between, the Latin alphabet is used. Greece's status as the cradle of Western civilization and an integral part of the Western world in the political, cultural and economic spheres has led to it being nearly always classified as belonging not to Eastern, but to Southern and/or Western Europe.
Interwar years.
A major result of the First World War was the breakup of the Russian, Austro-Hungarian, and Ottoman empires, as well as partial losses to the German Empire. A surge of ethnic nationalism created a series of new states in Eastern Europe, validated by the Versailles Treaty of 1919. Poland was reconstituted after the partitions of the 1790s had divided it between Germany, Austria, and Russia. New countries included Finland, Estonia, Latvia, Lithuania, Ukraine (which was soon absorbed by the Soviet Union), Czechoslovakia, and Yugoslavia. Austria and Hungary had much reduced boundaries. Romania, Bulgaria, Albania, and Greece likewise were independent. All the countries were heavily rural, with little industry and only a few urban centers. Nationalism was the dominant force but most of the countries had ethnic or religious minorities who felt threatened by majority elements. Nearly all became democratic in the 1920s, but all of them (except Czechoslovakia and Finland) gave up democracy during the depression years of the 1930s, in favor of autocratic or strong-man or single party states. The new states were unable to form stable military alliances, and one by one were too weak to stand up against Nazi Germany or the Soviet Union, which took them over between 1938 and 1945.
World War II and the onset of the Cold War.
Russia, defeated in the First World War, lost territory as the Baltics and Poland made good their independence. The region was the main battlefield in the Second World War (1939–45), with German and Soviet armies sweeping back and forth, with millions of Jews killed by the Nazis, and millions of others killed by disease, starvation, and military action, or executed after being deemed as politically dangerous. During the final stages of WWII the future of Eastern Europe was decided by the overwhelming power of the Soviet Red Army, as it swept the Germans aside. It did not reach Yugoslavia, Albania, and Greece, however. Finland was free but forced to be neutral in the upcoming Cold War. The region fell to Soviet control and Communist governments were imposed. Yugoslavia and Albania had their own Communist regimes; after a civil war the Communists lost in Greece. The Eastern Bloc with the onset of the Cold War in 1947 was mostly behind the Western European countries in economic rebuilding and progress.
Winston Churchill, in his famous "Sinews of Peace" address of March 5, 1946 at Westminster College in Fulton, Missouri, stressed the geopolitical impact of the "iron curtain":
Eastern Bloc during the Cold War to 1989.
The Soviet secret police, the NKVD, working in collaboration with local communists, created secret police forces using leadership trained in Moscow. As soon as the Red Army had expelled the Germans, this new secret police arrived to arrest political enemies according to prepared lists. The national Communists then took power in a normally gradualist manner, backed by the Soviets in many, but not all, cases. They took control of the Interior Ministries, which controlled the local police. They confiscated and redistributed farmland. Next the Soviets and their agents took control of the mass media, especially radio, as well as the education system. Third the communists seized control of or replaced the organizations of civil society, such as church groups, sports, youth groups, trade unions, farmers organizations, and civic organizations. Finally they engaged in large scale ethnic cleansing, moving ethnic minorities far away, often with high loss of life. After a year or two, the communists took control of private businesses and monitored the media and churches. For a while, cooperative non-Communist parties were tolerated. The communists had a natural reservoir of popularity in that they had destroyed Hitler and the Nazi invaders. Their goal was to guarantee long-term working-class solidarity.
Eastern Europe after 1945 usually meant all the European countries liberated and then occupied by the Soviet army. It included the German Democratic Republic (also known as East Germany), formed by the Soviet occupation zone of Germany. All the countries in Eastern Europe adopted communist modes of control. These countries were officially independent from the Soviet Union, but the practical extent of this independence – except in Yugoslavia, Albania, and to some extent Romania – was quite limited.
Under pressure from Stalin these nations rejected grants from the American Marshall plan. Instead they participated in the Molotov Plan which later evolved into the Comecon (Council for Mutual Economic Assistance). When NATO was created in 1949, most countries of Eastern Europe became members of the opposing Warsaw Pact, forming a geopolitical concept that became known as the "Eastern Bloc".
Since 1989.
With the fall of the Iron Curtain in 1989, the political landscape of the Eastern Bloc, and indeed the world, changed. In the German reunification, the Federal Republic of Germany peacefully absorbed the German Democratic Republic in 1990. In 1991, COMECON, the Warsaw Pact, and the Soviet Union were dissolved.
Many European nations which had been part of the Soviet Union regained their independence (Belarus, Moldova, Ukraine, as well as the Baltic States of Latvia, Lithuania, and Estonia).
Czechoslovakia peacefully separated into the Czech Republic and Slovakia in 1993. Many countries of this region joined the European Union, namely Bulgaria, the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Poland, Romania, and Slovakia.
See also.
European geography:

</doc>
<doc id="37404" url="http://en.wikipedia.org/wiki?curid=37404" title="KFC">
KFC

Kentucky Fried Chicken (KFC) is a fast food restaurant chain that specializes in fried chicken and is headquartered in Louisville, Kentucky, in the United States. It is the world's second largest restaurant chain (as measured by sales) after McDonald's, with 18,875 outlets in 118 countries and territories as of December 2013[ [update]]. The company is a subsidiary of Yum! Brands, a restaurant company that also owns the Pizza Hut and Taco Bell chains.
KFC was founded by Harland Sanders, an entrepreneur who began selling fried chicken from his roadside restaurant in Corbin, Kentucky, during the Great Depression. Sanders identified the potential of the restaurant franchising concept, and the first "Kentucky Fried Chicken" franchise opened in Utah in 1952. KFC popularized chicken in the fast food industry, diversifying the market by challenging the established dominance of the hamburger. By branding himself as "Colonel Sanders," Harland became a prominent figure of American cultural history, and his image remains widely used in KFC advertising. However, the company's rapid expansion saw it overwhelm the ageing Sanders, and in 1964 he sold the company to a group of investors led by John Y. Brown, Jr. and Jack C. Massey.
KFC was one of the first fast food chains to expand internationally, opening outlets in Canada, the United Kingdom, Mexico, and Jamaica by the mid-1960s. Throughout the 1970s and 1980s, KFC experienced mixed fortunes domestically, as it went through a series of changes in corporate ownership with little or no experience in the restaurant business. In the early 1970s, KFC was sold to the spirits distributor Heublein, who were taken over by the R.J. Reynolds food and tobacco conglomerate, who sold the chain to PepsiCo. The chain continued to expand overseas however, and in 1987 KFC became the first Western restaurant chain to open in China. The chain has since expanded rapidly in China, which is now the company's single largest market. PepsiCo spun off its restaurants division as Tricon Global Restaurants, which later changed its name to Yum! Brands.
KFC's original product is pressure fried chicken pieces, seasoned with Sanders' recipe of 11 herbs and spices. The constituents of the recipe represent a notable trade secret. Larger portions of fried chicken are served in a cardboard "bucket," which has become a well known feature of the chain since it was first introduced by franchisee Pete Harman in 1957. Since the early 1990s, KFC has expanded its menu to offer other chicken products such as chicken fillet burgers and wraps, as well as salads and side dishes, such as French fries and coleslaw, desserts, and soft drinks, the latter often supplied by PepsiCo. KFC is known for the slogan "finger lickin' good," which has since been replaced by "Nobody does chicken like KFC" and "So good."
History.
Harland Sanders was born in 1890 and raised on a farm outside Henryville, Indiana (near Louisville, Kentucky). When Harland was five years old, his father died, forcing his mother to work at a canning plant. This left Harland, as the eldest son, to care for his two younger siblings. After he reached seven years of age, his mother taught him how to cook. After leaving the family home at the age of 13, Sanders passed through several professions, with mixed success. In 1930, he took over a Shell filling station on US Route 25 just outside North Corbin, Kentucky, a small town on the edge of the Appalachian Mountains. It was here that he first served to travelers the recipes that he had learned as a child: fried chicken and other dishes such as steaks and country ham. After four years of serving from his own dining room table, Sanders purchased the larger filling station on the other side of the road and expanded to six tables. By 1936, this had proven successful enough for Sanders to be given the honorary title of Kentucky colonel by Governor Ruby Laffoon. In 1937 he expanded his restaurant to 142 seats, and added a motel he purchased across the street, naming it Sanders Court & Café.
Sanders was unhappy with the 35 minutes it took to prepare his chicken in an iron frying pan, but he refused to deep fry the chicken, which he believed lowered the quality of the product. If he pre-cooked the chicken in advance of orders, there was sometimes wastage at day's end. In 1939, the first commercial pressure cookers were released onto the market, mostly designed for steaming vegetables. Sanders bought one, and modified it into a pressure fryer, which he then used to fry chicken. The new method reduced production time to be comparable with deep frying, while, in the opinion of Sanders, retaining the quality of pan-fried chicken.
In July 1940, Sanders finalised what came to be known as his "Original Recipe" of 11 herbs and spices. Although he never publicly revealed the recipe, he admitted to the use of salt and pepper, and claimed that the ingredients "stand on everybody's shelf." After being recommissioned as a Kentucky colonel in 1950 by Governor Lawrence Wetherby, Sanders began to dress the part, growing a goatee and wearing a black frock coat (later switched to a white suit), a string tie, and referring to himself as "Colonel." His associates went along with the title change, "jokingly at first and then in earnest," according to biographer Josh Ozersky.
The Sanders Court & Café generally served travelers, so when the route planned in 1955 for Interstate 75 bypassed Corbin, Sanders sold his properties and traveled the US to franchise his chicken recipe to restaurant owners. Independent restaurants would pay four (later five) cents on each chicken as a franchise fee, in exchange for Sanders' "secret blend of herbs and spices" and the right to feature his recipe on their menus and use his name and likeness for promotional purposes. In 1952 he had already successfully franchised his recipe to his friend Pete Harman of South Salt Lake, Utah, the operator of one of the city's largest restaurants.
Don Anderson, a sign painter hired by Harman, coined the name "Kentucky Fried Chicken." For Harman, the addition of KFC was a way of differentiating his restaurant from competitors; a product from Kentucky was exotic, and evoked imagery of Southern hospitality. Harman trademarked the phrase "It's finger lickin' good," which eventually become the company-wide slogan. He also introduced the "bucket meal" in 1957 (14 pieces of chicken, five bread rolls and a pint of gravy in a cardboard bucket). Serving their signature meal in a paper bucket was to become an iconic feature of the company.
By 1963 there were 600 KFC restaurants, making the company the largest fast food operation in the United States. KFC popularized chicken in the fast food industry, diversifying the market by challenging the established dominance of the hamburger.
In 1964, Sanders sold the company to a group of investors led by John Y. Brown Jr. and Jack C. Massey for US$2 million (around US$15 million in 2013). The contract included a lifetime salary for Sanders and the agreement that he would be the company's quality controller and trademark. The chain had reached 3,000 outlets in 48 different countries by 1970. In July 1971, Brown sold the company to the Connecticut-based Heublein, a packaged food and drinks corporation, for US$285 million (around US$1.6 billion in 2013). Sanders died in 1980, his promotional work making him a prominent figure in American cultural history. By the time of his death, there were an estimated 6,000 KFC outlets in 48 different countries worldwide, with $2 billion of sales annually.
In 1982, Heublein was acquired by R. J. Reynolds, the tobacco giant. In July 1986, Reynolds sold KFC to PepsiCo for $850 million (around US$1.8 billion in 2013). PepsiCo made the chain a part of its restaurants division alongside Pizza Hut and Taco Bell. The Chinese market was entered in November 1987, with an outlet in Beijing.
In 1991, the KFC name was officially adopted, although it was already widely known by that initialism. Kyle Craig, president of KFC US, admitted the change was an attempt to distance the chain from the unhealthy connotations of "fried". The early 1990s saw a number of successful major products launched throughout the chain, including spicy "Hot Wings" (launched in 1990), popcorn chicken (1992), and internationally, the "Zinger", a spicy chicken fillet burger (1993). By 1994, KFC had 5,149 outlets in the US, and 9,407 overall, with over 100,000 employees. In August 1997, PepsiCo spun off its restaurants division as a public company valued at US$4.5 billion (around US$6.5 billion in 2013). The new company was named Tricon Global Restaurants, and at the time had 30,000 outlets and annual sales of US$10 billion (around US$14 billion in 2013), making it second in the world only to McDonald's. Tricon was renamed Yum! Brands in May 2002.
Operations.
KFC is a subsidiary of Yum! Brands, one of the largest restaurant companies in the world. KFC had sales of $23 billion in 2013. KFC has its headquarters at 1441 Gardiner Lane, Louisville, Kentucky, in a three-story colonial style building known colloquially as the "White House" due to its resemblance to the US president's home. The headquarters contain executive offices and the company's research and development facilities. KFC is incorporated at 1209 North Orange St, Wilmington, Delaware.
By December 2013, there were 18,875 KFC outlets in 118 countries and territories around the world. There are 4,563 outlets in China, 4,491 in the United States, and 9,821 across the rest of the world. Outlets are owned by franchisees or directly by the company. Eleven percent of outlets are company owned, with the rest operated by franchise holders. Although capital intensive, company ownership allows for faster expansion of the chain.
Most restaurants are furnished with images of the company founder, Colonel Harland Sanders. As well as dine-in and take-out, many stand-alone KFC outlets offer a drive-through option. KFC offers a limited delivery service in a small number of markets. Units include express concessions and kiosks which feature a limited menu and operated in non-traditional locations such as filling stations, convenience stores, stadia, theme parks and colleges, where a full scale outlet would not be practical. Average annual sales per unit was $1.2 million in 2013. Worldwide, the daily average number of food orders at an outlet is 250, with most occurring within a two-hour peak-period.
As chairman and CEO of Yum!, David C. Novak ultimately has foremost responsibility for KFC operations. Sam Su is chairman and CEO of Yum!'s Chinese operations, and Muktesh Pant is the CEO of KFC. Richard T. Carucci is president of Yum!, and Roger Eaton is the COO of Yum! and the president of KFC.
Africa.
The company hopes to expand its African operations, where it is already the regional leader among US fast food chains. The company is slowly expanding across the African continent, opening 70 outlets, but progress has been hampered by sourcing issues, such as a lack of quality suppliers.
Asia.
KFC continues to grow in Asia. In Malaysia there were 579 outlets as of December 2013.
In Sri Lanka, KFC was launched in 1995 at Majestic City. There were 25 KFC restaurants in Sri Lanka as of December 2014.
China.
KFC is the largest restaurant chain in China, with 4,563 outlets. KFC became the first Western fast food company in China after its first outlet opened in Qianmen, Beijing, in November 1987.
Local food items include rice congee and tree fungus salad, with an average of 50 different menu items per store.
In December 2012, the chain faced allegations that some of its suppliers injected antiviral drugs and growth hormones into poultry in ways that violated food safety regulations. This resulted in the chain severing its relationship with 100 suppliers, and agreeing to "actively co-operate" with a government investigation into its use of antibiotics. KFC China sales in January 2013 were down 41 percent against the previous year. To counter sluggish sales, the menu was revamped in 2014.
In July 2014, Chinese authorities closed down the Shanghai operations of the OSI Group, amidst allegations that it had supplied KFC with expired meat. Yum! immediately terminated its contract with the supplier, and stated that the revelation had led to a "significant [and] negative" decline in sales.
India.
In December 2013, there were 361 KFC outlets in India. As well as the standard KFC offerings, the chain sells a chickpea burger, a paneer burger, hot wings with chilli lemon sprinkles and other country-specific products. A major franchise holder is QSR Brands (M) Holdings, which operated 26 outlets as of 2012.
The first Indian KFC was a two-storey outlet on the fashionable Brigade Road in Bangalore in June 1995. According to journalist Michael White, the company could not have chosen a "more difficult venue for its maiden entrée into the country." Bangalore housed the headquarters of the Karnataka Rajya Raitha Sangha, one of the most influential, vocal and anti-foreign investment farmers' associations in the country. The first outlet suffered protests from left wing, anti-globalisation and environmental campaigners, as well as local farmers, who objected to the chain bypassing local producers. Many Indians were concerned about the onslaught of consumerism, the loss of national self-sufficiency, and the disruption of indigenous traditions. The protests came to a head in August 1995, when the Bangalore outlet was repeatedly ransacked. The KFC outlet in Bangalore demanded, and received, a police van permanently parked outside for a year. The outlet was closed on September 13, 1995 by local authorities, who claimed the company used illegally high amounts of monosodium glutamate (MSG) in its food. The outlet re-opened a few hours later as the result of an appeal by KFC to the Karnataka High Court. The company stated the recipe was no different than that used in any other KFC store. Rural activist M. D. Nanjundaswamy claimed KFC would adversely affect the health of the impoverished, by diverting grain from poor people to make the more profitable animal feed. Former environment minister Maneka Gandhi joined the anti-KFC movement. A second outlet opened in Delhi, but was closed by the authorities throughout November, purportedly for health reasons, but more likely to avoid a repetition of the Bangalore incident. The Delhi outlet soon closed permanently.
KFC began to expand outside of Bangalore in 2004, with a localized menu that was the most extensive meat-free menu across the chain's worldwide operations. It introduced a vegetarian menu that included rice meals, wraps and side dishes and, like McDonald's, served eggless mayonnaise and sauces. Unnat Varma, marketing director of KFC India, states "The vegetarian offerings have made the brand more relevant to a larger section of consumers and that is necessary for KFC's growth." KFC also began using Indian spices and cooking techniques to localize its chicken dishes. By 2008–09, KFC operated 34 outlets in India. In 2014, KFC launched the "So Veg, So Good" menu as part of an India-specific promotional strategy focused on enhancing their vegetarian range. Dhruv Kaul, marketing director of KFC India, stated, "The So Veg, So Good menu launch does not mean that we are moving away from our core chicken offerings. It enhances and strengthens our existing vegetarian range and helps broaden the brand's relevance in a diverse country such as India."
Indonesia.
In Indonesia KFC is the largest Western restaurant chain, with 466 outlets as of December 2013. The chain has grown to hold an estimated 32 percent market share, and menu items include spaghetti, wraps and chicken porridge. The master franchisee is PT Fastfood Indonesia.
The first outlet opened in Jakarta in 1979. Salim Group, Indonesia's largest conglomerate, became a major shareholder in 1990, which provided the company with funds for major expansion. Its master franchisee, PT Fastfood Indonesia, was publicly listed on the Indonesian Stock Exchange in 1993.
Japan.
Japan is the third-largest market for KFC after China and the United States with 1,200 outlets.
KFC Japan was formed in 1970 as a joint venture between the American parent and the Japanese Mitsubishi Corporation.
In December 1974, KFC Japan began to promote fried chicken as a Christmas meal. Eating KFC as a Christmas time meal has since become a widely practised custom in Japan.
In December 2007, Mitsubishi assumed majority control of KFC Japan in a JP¥ 14.83 billion transaction.
Europe.
United Kingdom.
As of December 2013, there were 784 KFC outlets in the United Kingdom. British turnover was around £684.5 million in 2013, according to Technomic. About 70 percent of outlets are run by franchisees, with the remainder company owned. The company employs 24,000 people. Around 400 sites are drive-through outlets. Average outlet turnover is between £1 and £1.5 million.
Annual sales amount to 60,000 metric tonnes of chicken, 60 percent of which is purchased from the four largest suppliers in the UK, including Faccenda Group and 2 Sisters Food Group, and delivered fresh to outlets at least three times a week. The remaining 40 percent is sourced from companies in Europe, Thailand (including Charoen Pokphand Foods) and Brazil. All of the Original Recipe chicken is sourced within the UK.
England had the first overseas branch of KFC which opened in Preston, Lancashire in May 1965, and was the first American fast food restaurant chain in the country, pre-dating the arrival of McDonald's, Burger King and Pizza Hut by almost a decade. Ray Allen, an experienced Lancashire caterer, was the first franchisee. The first London branch opened in North Finchley in November 1968. In 1971 there were 31 outlets; by 1975 the chain had grown to 250 outlets. In the late 1970s and throughout the 1980s, KFCs began to introduce seating. KFC opened its first drive through restaurant in the UK in 1984. By 1987 the company had almost 400 outlets.
In May 1997, the "Tower Burger", a fried chicken fillet burger with the addition of a hash brown, was first launched in the United Kingdom. In 2006, the company stopped pre-salting its fries and removed trans fats from its products. In 2012 palm oil was replaced by rapeseed oil in the fryers. Between 2004 and 2014, KFC UK increased its offering of "portable" foods: burgers, wraps and salads. During that period, sales rose from around £500 million to almost £1 billion. In 2012, KFC UK invested £9 million to install ovens in all of its outlets, so that it could offer griddled chicken. In 2013, KFC rolled out Lavazza coffee across all of its UK outlets. As of 2014, KFC UK is trialling serving only halal meat at 96 of its outlets.
North America.
United States.
KFC sales in the United States in 2013 were estimated at $4.22 billion by Technomic.
The basic model for KFC in the United States, not necessarily duplicated elsewhere, is a focus on low prices, a limited menu (29 items on average) and an emphasis on takeout. A "very strong percentage" of sales come from African American customers. Many KFC locations are co-located with either Taco Bell or Pizza Hut, or other Yum! restaurants. When Yum! owned Long John Silver's and A&W Restaurants, these brands were often co-branded with KFC as well. Often these locations behave like a single restaurant, offering one menu with food items from both restaurant brands. In 2003, there were 354 KFC-Taco Bell combines, offering the full KFC menu and Taco Bell items, and 13 units offering the full KFC menu and a limited number of Pizza Hut items. The concept originated in 1991, when a KFC-Taco Bell combination opened in Virginia. Some locations were also opened as combinations of KFC, Taco Bell and Pizza Hut, but this failed to catch on, and Yum! CEO David Novak blamed a lack of franchisee commitment for its lack of success.
Initially, Sanders and KFC used hydrogenated vegetable oil for frying, but in the 1980s the company began to switch to cheaper oils such as palm or soybean. In the 2000s it became apparent that these oils contain relatively high levels of trans fat, which increases the risk of heart disease. By April 2007, the chain had switched to trans fat-free soybean oil in all of its US outlets.
In 2008, Novak credited low US sales as being the result of a lack of new ideas and menu items. The Spring 2009 launch of Kentucky Grilled Chicken only resulted in a temporary halt to the sales decline. In 2010 KFC announced a turnaround plan that included improving restaurant operations, introducing value items and providing healthier menu options. In the same year, "Advertising Age" noted that KFC was losing market share to its smaller chicken restaurant rival, Chick-fil-A. In 2011 Bloomberg News referred to KFC US as "an also-ran to McDonald's Corp." In 2012, "Forbes" magazine described how many of the KFC outlets were "aged and uninviting," and that the chain "hasn't introduced an exciting new food item in ages."
KFC was described in 2012 by "Bloomberg Businessweek" as a "muscular player" in developing regions, specifically Africa, China and India, while noting its falling market share in the US to rivals such as Chick-fil-A and Popeyes. Some analysts speculated that KFC would begin spinning off its ailing US operations. That year, the company began divesting control of company-owned US restaurants to franchised operations, with the intention of reducing overall company ownership from 35 percent to 5 percent.
Oceania.
There are over 600 KFC outlets in Australia, and around 100 in New Zealand. KFC was the first American style fast food chain to open in both countries. In 2013, KFC reported an annual turnover of almost for its Australia and New Zealand operations.
Australia.
Yum! directly operates 160 KFC outlets in Australia. The largest of the 53 independent franchisees in Australia is Collins Foods, which operates 169 stores. KFC's major poultry suppliers in Australia are Inghams, Steggles and Turi Foods.
The first Australian KFC was opened in 1968 in Guildford, a suburb of Sydney. The franchise was owned by a Canadian entrepreneur called Bob Lapointe. Between 1970 and 1971, 75 outlets were opened. This had a major impact on Australian chicken production, which increased by 38 percent during the period. By 1995 there were 452 outlets, and the company employed 12,000 staff. That year, Australia produced 35 percent of KFC's international earnings.
New Zealand.
The first KFC opened in New Zealand in 1971 at Royal Oak, a suburb of Auckland. By 1980 there were 37 outlets. In 1989, PepsiCo acquired the 50 percent stake in KFC New Zealand that it did not already own from the local Goodman Fielder conglomerate. In 1991 New Zealand turnover topped for the first time.
Products.
KFC's core product offering is pressure fried on-the-bone chicken pieces seasoned with the "Original Recipe". The product is typically available in either two or three piece individual servings, or in a family size cardboard bucket, typically holding between 6 and 16 chicken pieces. Poultry is divided into 9 different cuts (2 drumsticks, 2 thighs, 2 wings, 1 keel, and a backbone based breast cut divided into 2 pieces). The product is hand-breaded at individual KFC outlets with wheat flour mixed with seasoning in a two to four minute process. It is then pressure fried for between seven and ten minutes (the timing differs between countries) in oil at 185 degrees celsius. Following this, the chicken is left to stand for 5 minutes in order for it to sufficiently cool before it is placed in the warming oven. It is KFC policy to discard chicken if it has not been sold within 90 minutes, in order to ensure freshness. The frying oil varies regionally, and versions used include sunflower, soybean, rapeseed and palm oil. A KFC executive stated that the taste of the chicken will vary between regions depending on the oil variety used, and whether the chicken has been corn-fed or wheat-fed.
As well as its core chicken on the bone offering, KFC's major products include chicken burgers (including the Zinger and the Tower burgers); wraps ("Twisters" and "Boxmasters"); and a variety of finger foods, including crispy chicken strips and hot wings. Popcorn Chicken is one of the most widely available KFC products, and consists of small pieces of fried chicken. In some locations, chicken nuggets are also sold.
KFC adapts its menu internationally to suit regional tastes, and there are over three hundred KFC menu items worldwide. Some locations, such as the UK and the US, sell grilled chicken. In predominantly Islamic countries, the chicken served is halal. In Asia there is a preference for spicy foods, such as the Zinger chicken burger. Some locations in the US sell fried chicken livers and gizzards. A small number of US outlets offer an all-you-can-eat buffet option with a limited menu.
A number of territories, such as Japan, Jamaica, Trinidad, Barbados, Ecuador and Singapore sell fried seafood products under the "Colonel's Catch" banner. In Jamaica, what was originally a seasonal offering for the Lent period was expanded to a year-round offering from 2010.
Value menu items are sold under the "Streetwise" name in locations such as Canada. Side dishes often include French fries, coleslaw, barbecue baked beans, corn on the cob, mashed potato, bread rolls and American biscuits. Salads include the bean salad, the Caesar salad and the garden salad. In a number of territories, KFC sell onion rings. In Asia, rice based side dishes such as congee are often sold. In Malaysia, chicken meatball soup is sold. In the US and Greece, potato wedges are sold instead of French fries.
McCormick & Company is KFC's largest supplier of sauces, seasonings and marinades, and is a long-term partner in new product development.
Due to the company's previous relationship with PepsiCo, most territories supply PepsiCo products, but exceptional territories include South Africa, the Philippines, Turkey, Romania, Greece and Barbados, which stock drinks supplied by The Coca-Cola Company, and Aruba, which stocks RC Cola from the Cott Corporation. In Peru, the locally popular Inca Kola is sold. In a number of Eastern European locations and Portugal, beer is offered, in addition to soft drinks.
Launched in 2009, the Krusher/Krushem range of frozen beverages containing "real bits" such as Kit Kat, Oreo and strawberry shortcake, is available in over 2,000 outlets. Egg custard tart is a popular dessert worldwide, but other items include ice cream sundaes and tres leches cake in Peru.
In 2012, the "KFC am" breakfast menu began to be rolled out internationally, including such items as pancakes, waffles and porridge, as well as fried chicken.
11 herbs and spices.
Sanders' Original Recipe of "11 herbs and spices" is one of the most famous trade secrets in the catering industry. The recipe is not patented, because patents eventually expire, whereas trade secrets can remain the intellectual property of their holders in perpetuity.
A copy of the recipe, signed by Sanders, is held inside a safe inside a vault in KFC's Louisville headquarters, along with eleven vials containing the herbs and spices. To maintain the secrecy of the recipe, half of it is produced by Griffith Laboratories before it is given to McCormick, who add the second half.
Equipment.
KFC initially used stove-top covered cooking pots to fry its chicken. In the 1960s, the officially recommended model was the L S Hartzog developed "KFC 20-Head Cooker," a large device that cost $16,000. The Hartzog model had no oil filtration system, meaning that filtering had to be done manually, and the pressure fryers occasionally exploded. In 1969, an engineer called Winston Shelton developed the "Collectramatic 519" pressure fryer that would self-filter the oil, and used precision timers and temperature controls. Fred Jeffries, then vice president of purchasing at KFC, claimed that the invention helped fuel the company's rapid expansion and success: "There's no way it could have grown like it did without the Collectramatic. Stores were doing about $200,000 a year in sales on average with the pots but they could never have done the $900,000 a year it became without Win's fryer."
Although a number of franchisees bought the Collectramatic, which had the support of Colonel Sanders from 1970 onwards, John Y. Brown had already signed an exclusive contract to only use the L S Hartzog fryer. Brown warned franchisees that they were in violation of their contract if they used the Collectramatic. Brown held his ground on the issue until he learned that his father, John Y. Brown, Sr., who was a KFC franchisee himself, was also using the Collectramatic. The issue was eventually resolved after Heublein purchased KFC and acquired Hartzog in order to invalidate the contract. The Collectramatic thus became the official pressure fryer for KFC from 1972 onwards.
Winston previously supplied KFC with holding cabinets, but since 2010, these have been supplied by Henny Penny.
Advertising.
Colonel Sanders.
Colonel Sanders was a key component of KFC advertising until his death in 1980. Despite his death, Sanders remains a key symbol of the company as an "international symbol of hospitality."
Modern renditions of the Colonel are sometimes used in post-1980 advertising. In 1994, Henderson Forsythe portrayed the Colonel in a television campaign entitled "The Colonel's Way." From 1998 to 2001 an animated version of the Colonel voiced by Randy Quaid was used for television advertisements. In 2012, a UK advertisement entitled "4000 cooks" featured an actor made up to resemble Sanders.
The ubiquity of Sanders has not prevented KFC from introducing a mascot aimed at children. "Chicky," a young animated chicken, was first introduced in Thailand in the 1990s, and has since been rolled out across a number of markets worldwide, mostly in Asia and South America.
Slogans.
Early official slogans included "North America's Hospitality Dish" (from 1956) and "We fix Sunday dinner seven nights a week" from 1957 until 1967.
The "finger lickin' good" slogan was used from 1956, and went on to become one of the best-known slogans of the twentieth century. The trademark expired in the US in 2006, and was replaced in that market with "Follow your taste" until 2010. In 2011, the "finger lickin' good" slogan was dropped in favor of "So good," to be rolled out worldwide. A Yum! executive said that the new slogan was more holistic, applying to staff and service, as well as food.
"Nobody does chicken like KFC" was first introduced by KFC Australia in 1998, and has continued to be used by the company in some markets.
Logos.
The first KFC logo was introduced in 1952 and featured a "Kentucky Fried Chicken" typeface and a logo of the Colonel. It was designed by the Lippincott & Margulies corporate identity agency. Lippincott & Margulies were hired to redesign it in 1978, and used a similar typeface and a slightly different Sanders logo. The "KFC" initialism logo was designed by Schechter & Luth of New York and was introduced in 1991, and the Colonel's face logo was switched from brown to blue ink.
Landor redesigned the logo in 1997, with a new image of the Colonel. The new Colonel image was more thinly lined, less cartoonish and a more realistic representation of Sanders. In 2006, the Colonel logo was updated by Tesser of San Francisco, replacing his white suit with an apron, bolder colors and a better defined visage. According to Gregg Dedrick, president of KFC's US division, the change, "communicates to customers the realness of Colonel Sanders and the fact that he was a chef."
Television.
United States.
Advertising played a key role at KFC after it was sold by Sanders, and the company began to advertise on US television with a budget of US$4 million in 1966. In order to fund nationwide advertising campaigns, the Kentucky Fried Chicken Advertising Co-Op was established, giving franchisees ten votes and the company three when deciding on budgets and campaigns.
In 1969, KFC hired its first national advertising agency, Leo Burnett. A notable Burnett campaign in 1972 was the "Get a bucket of chicken, have a barrel of fun" jingle, performed by Barry Manilow.
By 1976 KFC was one of the largest advertisers in the US. Young & Rubicam (Y&R) was KFC's agency of record in the US from 1976 until December 2000. From 1978 to 1980 "It's nice to feel so good about a meal" was the slogan. It was chosen because KFC had identified consumer guilt as its core marketing obstacle. Meanwhile, KFC hired the Mingo-Jones agency to target African American audiences. Mingo-Jones coined the "We do chicken right" slogan, which was later adopted across the whole chain from 1981 until 1990. "Nobody's cooking like today's KFC" was used from December 1990 until March 1991.
From 1991 to 1994, the television campaign focused on the fictional town of Lake Edna. When he took over the CEO role at KFC, David Novak ended the campaign, which he derided as "hokey." The campaign was replaced by one with the tagline, "Everybody needs a little KFC," which Novak credited with helping to boost sales at the company.
BBDO took over the KFC US account in December 2000. Its first campaign, featuring Jason Alexander, debuted on television in July 2001. It ran until May 2003 with the tagline, "There's fast food. Then there's KFC." In September 2003, BBDO was replaced by Foote, Cone & Belding. Its first campaign aired in November, but was pulled after less than a month following complaints from the National Advertising Division and the Center for Science in the Public Interest that it advertised the health benefits of eating fried chicken.
International.
In 1994, Ogilvy & Mather became KFC's international agency of record. From 1997 to 1999, Ogilvy & Mather used celebrities such as Ivana Trump, Tara Palmer-Tomkinson and Ulrika Jonsson to endorse KFC products in television advertisements in the UK. After this campaign, the agency simply adapted Y&R's American campaigns, such as the animated Colonel, for a British audience. In late 2002, BBH was appointed KFC's UK agency. In 2003, the "Soul Food" campaign was launched, aiming to capture the young urban market with 1960s and 70s African-American music. By 2005, this believed to have been a failure, and KFC UK's marketing director left the company amid speculation that the US head office was unhappy with the campaign. Marketing subsequently moved towards a more family-orientated line.
Promotional tie-ins and corporate sponsorships.
In 1994, KFC embarked upon its first US nationwide promotional tie in, with the Looney Tunes franchise. Customers could buy a Looney Tunes character 3D mug for $1.99 with each $14.99 Mega Meal that was purchased.
KFC in the US featured a Matchbox promotion in Spring 1995.
Between November 1998 and January 2000, KFC US teamed with Nintendo, Game Freak and 4 Kids Entertainment in a Pokémon tie-in. Pokémon themed promotional days were held, Pokémon Beanie Babies were sold, and Pokémon toys were given away free with children's meals. In 1999, PepsiCo signed a $2 billion agreement with Lucasfilm in order to market Star Wars themed meals in its KFC and Pizza Hut chains.
Since 2010, KFC has sponsored the KFC Yum! Center in Louisville. In Australia, KFC has sponsored the Big Bash League Twenty20 cricket tournament and Twenty20 international matches since 2003.
Controversies and criticism.
Since the turn of the 21st century, fast food has been criticised for its animal welfare record, its links to obesity and its environmental impact. Eric Schlosser's book "Fast Food Nation" (2002) and Morgan Spurlock's film "Super Size Me" (2004) reflected these concerns. Since 2003, People for the Ethical Treatment of Animals (PETA) has protested KFC's choice of poultry suppliers worldwide. The exception is KFC Canada, which signed an agreement pledging to only use "animal friendly" suppliers. PETA have held thousands of demonstrations, sometimes in the home towns of KFC executives, and CEO David Novak was notably soaked in fake blood by a protester. President of KFC's US division Gregg Dedrick said PETA mischaracterized KFC as a poultry producer rather than a purchaser of chickens. In 2008, Yum! stated: "[As] a major purchaser of food products, [Yum!] has the opportunity and responsibility to influence the way animals supplied to us are treated. We take that responsibility very seriously, and we are monitoring our suppliers on an ongoing basis."
In 2006, Greenpeace accused KFC Europe of sourcing the soya bean for its chicken feed from Cargill, which had been accused of clearing large swathes of the Amazon rainforest in order to grow the crop.
In May 2012, Greenpeace accused KFC of sourcing paper pulp for its food packaging from Indonesian rainforest wood. Independent forensic tests showed that some packaging contained more than 50 percent mixed tropical hardwood fiber, sourced from Asia Pulp & Paper (APP). APP said such fiber can be found in recycled paper, or: "It can also come from tree residues that are cleared, after a forest area has become degraded, logged-over or burned, as part of a sustainable development plan. APP has strict policies and practices in place to ensure that only residues from legal plantation development on degraded or logged-over forest areas and sustainable wood fiber enters the production supply chain." KFC said: "From a global perspective, 60 percent of the paper products that Yum! (our parent company) sources are from sustainable sources. Our suppliers are working towards making it 100 percent."
In December 2012, the chain was criticised in China when it was discovered that a number of KFC suppliers had been using growth hormones and an excessive amount of antibiotics on its poultry in ways that violated Chinese law. In February 2013, Yum! CEO David Novak admitted that the scandal had been "longer lasting and more impactful than we ever imagined." The issue is of major concern to Yum!, which earns almost half of its profits from China, largely through the KFC brand. In March 2013, Yum! reported that sales had rebounded in February, but that lower sales in December and January would result in a decline in same-store sales of 20 percent in the first quarter.

</doc>
<doc id="37406" url="http://en.wikipedia.org/wiki?curid=37406" title="Kristiansund">
Kristiansund

Kristiansund ] (historically "Christianssund") is a city and municipality on the western coast of Norway in the "Nordmøre" district of Møre og Romsdal county. It was officially awarded township status in 1742, and it is still the major town for the region. The administrative center of the municipality is the city of Kristiansund. Other settlements in the municipality include the villages of Kvalvåg, Rensvik, and Nedre Frei.
The city of Kristiansund is the largest settlement in the municipality. The 7.91 km2 city has a population (2013) of 18,002 which gives the city a population density of 2276 PD/km2.
General information.
The parish of "Christianssund" was established as a municipality on 1 January 1838 (see formannskapsdistrikt). On 1 January 1897, the Grip archipelago was separated from Kristiansund Municipality to become a separate municipality. On 1 January 1964, Kristiansund Municipality was merged with the tiny Grip Municipality (population: 104) to the northwest and the "Dale" area of Bremsnes Municipality on Nordlandet island (population: 963). The neighboring Frei Municipality was merged with Kristiansund on 1 January 2008 creating a much larger Kristiansund Municipality.
Toponymy.
The city, formerly named "Christianssund", is named after the Danish-Norwegian king Christian VI in 1742. The last element of the name, "sund", means "strait". The old name of the town/village (originally the island Kirkelandet) was "Fosna" or "Fosen" (Old Norse: "fólgsn") which means "hiding place" (here 'hidden port'). It was also often named "Lille Fosen" ("the small Fosen") to distinguish it from the island "Storfosna" ("the big Fosen") in Ørland.
Before 1877, the name was written "Christianssund", from 1877-1888 it was spelled "Kristianssund", and since 1889 it has had its present spelling, "Kristiansund".
Before the introduction of postal codes in Norway in 1968, it was easy to confuse the name "Kristiansund" with Kristiansand in the south. It was therefore obligatory to always add an "N" (for north) to Kristiansund "(Kristiansund N)" and an "S" (for south) to Kristiansand "(Kristiansand S)". This is pretty much still practiced and also occurs in some other contexts than postal addresses.
Coat-of-arms.
The Coat-of-arms is from 1742. It shows a waterfall because the old name of the town ("Fosen") was misinterpreted as "Fossund" (as a compound of "foss" which means waterfall and "sund" which means strait). There are, however, no waterfalls in the municipality.
Another myth concerning the coat-of-arms is that there was a mix up, between Kristiansund's and Molde's intended shield. The Dano-Norwegian government officials in charge of the giving of the coats, had a party to remember the momentous occasion and became too drunk and hungover to remember which was which, and so Molde got the coat with a whale (which are scarce in between the Romsdal fjords) and Kristiansund got the waterfall (since Molde is on the mainland and Kristiansund lies in the open sea, it would be more likely that the waterfall was intended for Molde's mountains and the whales for Kristiansund.)
Churches.
The Church of Norway has three parishes "(sokn)" within the municipality of Kristiansund. It is part of the Ytre Nordmøre deanery in the Diocese of Møre.
St. Eystein Catholic Church is the only Catholic church in Kristiansund.
Geography.
The municipality borders Smøla Municipality and Aure Municipality to the northeast, Tingvoll Municipality to the east, Gjemnes Municipality to the south, and Averøy Municipality to the southwest. The small Grip archipelago is located in the northwestern part of the municipality. The municipality is surrounded by the Freifjorden and Kvernesfjorden with the open sea to the northwest.
Kristiansund is built on four main islands, with many smaller islands. The island of Nordlandet ("North Land", humorously nicknamed "Marokko"), is the second largest island and the site of the local airport, Kristiansund Airport, Kvernberget (IATA code: KSU). Kirkelandet, third in size is made up of two areas "Kirkelandet" and "Gomalandet". In the local dialect, "Kirkelandet" (the "Church Land") is pronounced "Kirklandet", without the middle "e". The smallest island is Innlandet ("Innermost Land"; humorously, "Tahiti"). The largest island in the municipality is Frei which was part of the old Frei Municipality which was merged into Kristiansund on 1 January 2008. The highest point of the municipality is located on Frei island, Freikollen at a height of 629 m.
The island of Grip, located northwest of Kristiansund is also a part of the municipality. It was Norway's smallest municipality, and also one of the most remote until it merged with Kristiansund in 1964. Today the island of Grip holds status as a deserted fishing village, but in the summer season it is a popular tourist attraction due to the very special location and architecture. Grip Stave Church, the second smallest stave church of Norway (Undredal Stave Church is smaller), is also located at Grip. It is also where Grip Lighthouse is located.
Kristiansund is one of the most densely populated cities of Norway, having what is arguably the country's most urban small city centre, due to the relatively small size of the islands on which it is built and the very constricted central harbour/town area of Kirkelandet.
History.
8000 BC–1066.
Many scientists believe that the very first Norwegian lived near the city of Kristiansund. At the end of the last Ice age some areas at the western coast of Norway were ice-free. There was also a lot of food in the sea around Kristiansund at that time, and it is believed that the first settlement arrived in Kristiansund around year 8000 BC.
During the Viking ages there were many important battles around Kristiansund. The most famous one was the Battle of Rastarkalv on the island of Frei, where the Norwegian King Håkon the Good fought against the Eirikssønnene-group. There is now a memorial monument located near Rastakalv (at Nedre Frei, where the battle was fought.
Middle ages.
The island of Grip was an important fishing community during the Middle Ages, and was considered to be the most important municipality in the region at the time. The natural harbour in Lille-fosen, close to where Kristiansund is located today was also frequently used for fishing purposes.
17th to 18th century.
During the 17th century a small settlement developed around the area we know today as Kristiansund harbour. As more and more settlers arrived, the area became an important trading port for fishing and the lumber transportation along the coast. The Dano-Norwegian government established a customs station here, which was controlled by the main trading port in Trondheim.
Dutch sailors brought the knowledge of clipfish production to Kristiansund at the end of the 17th century, and for a number of years the city was the largest exporter of clipfish in Norway, exporting goods mainly to the Mediterranean countries. The city's clipfish production was also part of the reason why it was awarded town status in 1742.
Media.
There are two local TV stations in Kristiansund. The larger one is TVNordvest, (TV North-West) which broadcasts local news from the area around Kristiansund on a daily basis, as well as some other TV shows. The second one is TV Kristiansund, which is more of a culture channel, broadcasting cultural news from Kristiansund, like shows from the city Opera.
The local newspaper of Kristiansund is Tidens Krav, which also functions as a local newspaper for the other municipalities located nearby the city.
Climate.
Kristiansund has a maritime, temperate climate with cool-to-warm summers and relatively short and mild winters. The city structure with the unique natural harbour of the city combined with warm wind from the southwest of the Atlantic Ocean and the Gulf Stream gives Kristiansund a much warmer climate than its latitude would indicate.
Government.
The city council of Kristiansund has 45 representatives. Per Kristian Øyen from the Labor Party (Arbeiderpartiet) was elected in 2007 as the mayor of Kristiansund, succeeding Dagfinn Ripnes. Øyen was reelected in 2011.
2011 election.
After the 2011 election, the following parties have representatives in the municipal council of Kristiansund:
Twin towns.
Kirstiansund is twinned with:
Together the three cities hold a tournament called "Nordiske Dager" ("Nordic Days").
Parks and gardens.
Though fairly small in size, the city of Kristiansund contains many green parks and gardens, frequently used by the city's inhabitants. There are two larger parks near the city centre. The first one is located near Langveien, and was constructed in the aftermath of World War II . The second one is located in Vanndamman. This area used to be part of the city water supply, due to the large amount of small lakes in the area. (hence the name "Vanndamman" (The Water ponds)) The two parks are partly linked together, but the Langveien-park serve more as an urban recreation area due to the short walking distance from the city centre, while the Vanndamman-park is more suitable for outings and jogging.
Transport.
Started in 1876 and still going strong is the "Sundbåt" ("Sound Boat"/"Strait Crossing Boat") shuttle service with a capacity of a few tens of passengers, travelling between the islands. The small motor ferry crosses the harbour from Kirkelandet to Innlandet, then goes on to Nordlandet, to Gomalandet, and back to Kirkelandet, repeating the round trip in half-hour intervals morning to evening on weekdays. The Sundbåt bears the distinction of being "the world's oldest motorized regular public transport system in continuous service".
The road to Kristiansund from the mainland, Norwegian National Road 70 is connected to European Route E39 by the bridge/tunnel system called Krifast. After passing through the underwater Freifjord Tunnel from the central part of Krifast, National Road 70 crosses Frei, and enters Kristiansund over the Omsund Bridge onto Nordlandet. The Nordsund Bridge brings the Rv 70 to Gomalandet and its terminus in downtown at Kirkelandet. Another high bridge, the Sørsund Bridge, leads from Kirkelandet to Innlandet. E39 leads southwest to the town of Molde and northeast via the European route E6 to Trøndelag and the city of Trondheim.
There used to be a car ferry going from Kirkelandet island to neighboring Averøy Municipality to the west, whose people have been commuting to town for many years for work as well as selling agricultural products. The ferry to Averøy connected Kristiansund to Norwegian National Road 64, which continued along the scenic Atlanterhavsvegen to Molde. The ferry was replaced by the 5.7 km long underwater Atlantic Ocean Tunnel in December 2009. Because both tunnels are forbidden for bicyclists, Kristiansund cannot easily be reached by bicycle.
A second car ferry goes from "Seivika" on Nordlandet to Tustna in the northeast (road: "RV 680"), with further road and ferry connections to the islands of Smøla and Hitra, and to Aure Municipality on the mainland.
Besides roads and car ferries and Kristiansund Airport, Kvernberget, connections to/from Kristiansund consist of the traditional coastal express Hurtigruten connecting coastal towns from Bergen in the south to Kirkenes in the north, and the high speed catamaran passenger service Kystekspressen to Trondheim. Another option to get to Kristiansund is to fly with Scandinavian Airlines from several other Norwegian cities.
Commerce and industry.
Kristiansund is known as the major "bacalao" city of Norway. Bacalao is made of salted, dried codfish, and has traditionally been exported in large amounts to Spain, Portugal and Latin America as food suitable during Lent. In recent years Kristiansund has become the major oil and gas city at the mid-northwestern coast. Oil companies like Royal Dutch Shell and Statoil have offices in Kristiansund from where they serve their offshore installations at Haltenbanken (one of the northernmost underwater oil fields in the world).
Due to the city's heavy involvement in fish processing and international shipping, there used to be as many as seven consulates in Kristiansund, mainly to Latin countries. Currently, there are only five left: Britain, Finland, Latvia, the Netherlands, and Portugal.
Culture and sports.
Kristiansund is an important cultural centre in the region of Nordmøre. The city is probably best known for housing Norway's oldest opera, which was established in 1928 by Edvard Bræin. There is an annual opera festival held every February in Kristiansund named The Opera Weeks (Operafestukene). In addition to this, Kristiansund is also host city of Northern Europes largest photo festival, Nordic Light. Even though this is a rather "young" festival, (Est. 2006) it has grown to become one of the most important of its kind in Europe, attracting famous photographers from all around the world, like Don McCullin, Jock Sturges and William Klein. Other smaller festivals held in Kristiansund include The Tahiti Festival and Kristiansund Church, Art and Culture Festival (shortened to the KKKK-festival in Norwegian).
Kristiansund's main football team, Kristiansund BK, is a result of the merger between the two largest football teams in the city, KFK and Clausenengen, which got together so they could make an elite football club in Kristiansund. KBK now plays in the First division in the Norwegian football league.
Other popular sports in Kristiansund include Volleyball, Wrestling, Swimming, Ice skating and Handball.
Notable residents.
The following people are from, or have their roots in, Kristiansund.

</doc>
<doc id="37407" url="http://en.wikipedia.org/wiki?curid=37407" title="Strasbourg">
Strasbourg

Strasbourg (]; Lower Alsatian: "Strossburi", ]; German: "Straßburg", ]) is the capital and principal city of the Alsace region in north eastern France and is the official seat of the European Parliament. Located close to the border with Germany, it is the capital of the Bas-Rhin département. The city and the region of Alsace were historically Alemannic-speaking, which explains the city's Germanic name. In 2006, the city proper had 272,975 inhabitants and its urban community 467,375 inhabitants. With 759,868 inhabitants in 2010, Strasbourg's metropolitan area (only the part of the metropolitan area on French territory) is the ninth largest in France. The transnational Eurodistrict Strasbourg-Ortenau had a population of 884,988 inhabitants in 2008.
Strasbourg is the seat of several European institutions, such as the Council of Europe (with its European Court of Human Rights, its European Directorate for the Quality of Medicines and its European Audiovisual Observatory) and the Eurocorps, as well as the European Parliament and the European Ombudsman of the European Union. The city is also the seat of the Central Commission for Navigation on the Rhine and the International Institute of Human Rights.
Strasbourg's historic city centre, the "Grande Île" (Grand Island), was classified a World Heritage site by UNESCO in 1988, the first time such an honour was placed on an entire city centre. Strasbourg is immersed in the Franco-German culture and although violently disputed throughout history, has been a bridge of unity between France and Germany for centuries, especially through the University of Strasbourg, currently the second largest in France, and the coexistence of Catholic and Protestant culture. The largest Islamic place of worship in France, the Strasbourg Grand Mosque, was inaugurated by French Interior Minister Manuel Valls on 27 September 2012.
Economically, Strasbourg is an important centre of manufacturing and engineering, as well as a hub of road, rail, and river transportation. The port of Strasbourg is the second largest on the Rhine after Duisburg, Germany. In terms of city ranking for innovation, Strasbourg has been ranked the third city in France and 18th globally.
Etymology.
The city's Gallicized name is of Germanic origin and means "Town (at the crossing) of roads". The modern "Stras-" is cognate to the German "Straße" and English "street", all of which are derived from Latin "strata" ("paved road"), while "-bourg" is cognate to the German "Burg" and English "borough", all of which are derived from Proto-Germanic "*burgz" ("hill fort, fortress").
Geography.
Strasbourg is on the Eastern border of France, on the Ill River where it flows into the Rhine on the border with Germany, across from the German town Kehl. The city lies in the Upper Rhine Plain, a major axis of north-south travel, approximately 20 km east of the Vosges Mountains and 25 km west of the Black Forest.
Strasbourg's location in the Rhine valley, sheltered from the dominant winds by the Vosges and Black Forest mountains, results in poor natural ventilation, making Strasbourg one of the most atmospherically polluted cities of France. Nonetheless, the progressive disappearance of heavy industry on both banks of the Rhine, as well as effective measures of traffic regulation in and around the city have reduced air pollution. The "Grand contournement ouest" (GCO) project, programmed since 1999, plans to construct a 24 km long highway connection between the junctions of the A 4 and the A 35 autoroutes in the north and of the A4 and the A352 and A35 autoroutes in the south, meant to divest a significant portion of motorized traffic from the unité urbaine.
Climate.
Strasbourg's climate is classified as Oceanic (Köppen climate classification "Cfb"), with warm, relatively sunny summers and cold, overcast winters. Precipitation is elevated from mid-spring to the end of summer, but remains largely constant throughout the year, totaling 631.4 mm annually. On average, snow falls 30 days per year.
The highest temperature ever recorded was 38.5 °C in August 2003, during the 2003 European heat wave. The lowest temperature ever recorded was -23.4 °C in December 1938.
History.
Prehistory.
The first traces of human occupation in the environs of Strasbourg go back 600,000 years. Neolithic, bronze age and iron age artifacts have been uncovered by archeological excavations. It was permanently settled by proto-Celts around 1300 BC. Towards the end of the third century BC, it developed into a Celtic township with a market called "Argentorate". Drainage works converted the stilthouses to houses built on dry land.
From Romans to Renaissance.
Argentoratum.
The Romans under Nero Claudius Drusus established a military outpost belonging to the "Germania Superior" Roman province at Strasbourg's current location, and named it "Argentoratum". (Hence the town is commonly called "Argentina" in medieval Latin.) The name "Argentoratum" was first mentioned in 12 BC and the city celebrated its 2,000th birthday in 1988. "Argentorate" as the toponym of the Gaulish settlement preceded it before being Latinized, but it is not known by how long. The Roman camp was destroyed by fire and rebuilt six times between the first and the fifth centuries AD: in 70, 97, 235, 355, in the last quarter of the fourth century, and in the early years of the fifth century. It was under Trajan and after the fire of 97 that Argentoratum received its most extended and fortified shape. From the year 90 on, the Legio VIII Augusta was permanently stationed in the Roman camp of Argentoratum. It then included a cavalry section and covered an area of approximately 20 hectares. Other Roman legions temporarily stationed in Argentoratum were the Legio XIV Gemina and the Legio XXI Rapax, the latter during the reign of Nero.
The centre of Argentoratum proper was situated on the Grande Île (Cardo: current "Rue du Dôme", Decumanus: current "Rue des Hallebardes"). The outline of the Roman "castrum" is visible in the street pattern in the Grande Ile. Many Roman artifacts have also been found along the current "Route des Romains", the road that led to Argentoratum, in the suburb of Kœnigshoffen. This was where the largest burial places were situated, as well as the densest concentration of civilian dwelling places and commerces next to the camp. Among the most outstanding finds in Kœnigshoffen were (found in 1911–12) the fragments of a grand Mithraeum that had been shattered by early Christians in the fourth century. From the fourth century, Strasbourg was the seat of the Bishopric of Strasbourg (made an Archbishopric in 1988). Archaeological excavations below the current "Église Saint-Étienne" in 1948 and 1956 unearthed the apse of a church dating back to the late fourth or early fifth century, considered to be the oldest church in Alsace. It is supposed that this was the first seat of the Roman Catholic Diocese of Strasbourg.
The Alemanni fought the Battle of Argentoratum against Rome in 357. They were defeated by Julian, later Emperor of Rome, and their King Chonodomarius was taken prisoner. On 2 January 366, the Alemanni crossed the frozen Rhine in large numbers to invade the Roman Empire. Early in the fifth century, the Alemanni appear to have crossed the Rhine, conquered, and then settled what is today Alsace and a large part of Switzerland.
Imperial city.
</td></tr></table>
In the fifth century Strasbourg was occupied successively by Alemanni, Huns, and Franks. In the ninth century it was commonly known as "Strazburg" in the local language, as documented in 842 by the Oaths of Strasbourg. This trilingual text contains, alongside texts in Latin and Old High German (teudisca lingua), the oldest written variety of Gallo-Romance (lingua romana) clearly distinct from Latin, the ancestor of Old French. The town was also called "Stratisburgum" or "Strateburgus" in Latin, from which later came "Strossburi" in Alsatian and "Straßburg" in Standard German, and then "Strasbourg" in French. The Oaths of Strasbourg is considered as marking the birth of the two countries of France and Germany with the division of the Carolingian Empire.
A major commercial centre, the town came under the control of the Holy Roman Empire in 923, through the homage paid by the Duke of Lorraine to German King Henry I. The early history of Strasbourg consists of a long conflict between its bishop and its citizens. The citizens emerged victorious after the Battle of Oberhausbergen in 1262, when King Philip of Swabia granted the city the status of an Imperial Free City.
Around 1200, Gottfried von Straßburg wrote the Middle High German courtly romance Tristan, which is regarded, alongside Wolfram von Eschenbach's Parzival and the Nibelungenlied, as one of great narrative masterpieces of the German Middle Ages.
A revolution in 1332 resulted in a broad-based city government with participation of the guilds, and Strasbourg declared itself a free republic. The deadly bubonic plague of 1348 was followed on 14 February 1349 by one of the first and worst pogroms in pre-modern history: over a thousand Jews were publicly burnt to death, with the remainder of the Jewish population being expelled from the city. Until the end of the 18th century, Jews were forbidden to remain in town after 10 pm. The time to leave the city was signalled by a municipal herald blowing the "Grüselhorn" (see below, Museums, "Musée historique");. A special tax, the "Pflastergeld" (pavement money), was furthermore to be paid for any horse that a Jew would ride or bring into the city while allowed to.
Construction on Strasbourg Cathedral began in the twelfth century, and it was completed in 1439 (though, of the towers, only the north tower was built), becoming the World's Tallest Building, surpassing the Great Pyramid of Giza. A few years later, Johannes Gutenberg created the first European moveable type printing press in Strasbourg.
In July 1518, an incident known as the Dancing Plague of 1518 struck residents of Strasbourg. Around 400 people were afflicted with dancing mania and danced constantly for weeks, most of them eventually dying from heart attack, stroke or exhaustion.
In the 1520s during the Protestant Reformation, the city, under the political guidance of Jacob Sturm von Sturmeck and the spiritual guidance of Martin Bucer embraced the religious teachings of Martin Luther. Their adherents established a Gymnasium, headed by Johannes Sturm, made into a University in the following century. The city first followed the Tetrapolitan Confession, and then the Augsburg Confession. Protestant iconoclasm caused much destruction to churches and cloisters, notwithstanding that Luther himself opposed such a practice. Strasbourg was a centre of humanist scholarship and early book-printing in the Holy Roman Empire, and its intellectual and political influence contributed much to the establishment of Protestantism as an accepted denomination in the southwest of Germany. (John Calvin spent several years as a political refugee in the city). The Strasbourg Councillor Sturm and guildmaster Matthias represented the city at the Imperial Diet of Speyer (1529), where their protest led to the schism of the Catholic Church and the evolution of Protestantism.
Together with four other free cities, Strasbourg presented the "confessio tetrapolitana" as its Protestant book of faith at the Imperial Diet of Augsburg in 1530, where the slightly different Augsburg Confession was also handed over to Charles V, Holy Roman Emperor.
After the reform of the Imperial constitution in the early sixteenth century and the establishment of Imperial Circles, Strasbourg was part of the Upper Rhenish Circle, a corporation of Imperial estates in the southwest of Holy Roman Empire, mainly responsible for maintaining troops, supervising coining, and ensuring public security.
After the invention of the printing press by Johannes Gutenberg around 1440, the first printing offices outside the inventor's hometown Mainz were established around 1460 in Strasbourg by pioneers Johannes Mentelin and Heinrich Eggestein. Subsequently, the first modern newspaper was published in Strasbourg in 1605, when Johann Carolus received the permission by the City of Strasbourg to print and distribute a weekly journal written in German by reporters from several central European cities.
From Thirty Years' War to First World War.
The Free City of Strasbourg remained neutral during the Thirty Years' War, and retained its status as a Free Imperial City. However, the city was annexed by King Louis XIV of France to extend the borders of his kingdom.
Louis' advisors believed that as long as Strasbourg remained independent, it would endanger the King's newly annexed territories in Alsace, and that to effectively defend these large rural lands a garrison had to be placed in towns such as Strasbourg. Indeed, the bridge over the Rhine at Strasbourg had been used repeatedly by the Imperial (Holy Roman Empire) forces, and three times during the Franco-Dutch War Strasbourg had served as a gateway for Imperial invasions into Alsace. In September 1681 Louis' forces, though lacking a clear casus belli, surrounded the city with overwhelming force. Louis marched into the city on September 30, 1681 and proclaimed its annexation.
This annexation was one of the direct causes of the brief and bloody War of the Reunions whose outcome left the French in possession. The French annexation was recognized by the Treaty of Ryswick (1697).
The official policy of religious intolerance which drove most Protestants from France after the revocation of the Edict of Nantes in 1685 was not applied in Strasbourg and in Alsace, because both had a special status as a "province à l'instar de l'étranger effectif" (a kind of foreign province of the king of France). Strasbourg Cathedral, however, was taken from the Lutherans to be returned to the Catholics as the French authorities tried to promote Catholicism wherever they could. The German Lutheran university persisted until the French Revolution. Famous students were Goethe and Herder.
During a dinner in Strasbourg organized by Mayor Frédéric de Dietrich on 25 April 1792, Claude Joseph Rouget de Lisle composed "La Marseillaise". The same year François Christophe Kellermann, a child of Strasbourg was appointed the head of the Mosel Army. He led his company to victory at the battle of Valmy and saved the young French republic. He was later appointed duke of Valmy by Napoléon in 1808.
During this period Jean-Baptiste Kléber, born in Strasbourg as well, led the French army to win several decisive victories. Nowadays a statue is displayed in the centre of the city, at Place Kléber, and he is still one of the most famous French officers, he was later appointed Marshal of France by Napoléon.
Strasbourg's status as a free city was revoked by the French Revolution. Enragés, most notoriously Eulogius Schneider, ruled the city with an increasingly iron hand. During this time, many churches and cloisters were either destroyed or severely damaged. The cathedral lost hundreds of its statues (later replaced by copies in the 19th century) and in April 1794, there was talk of tearing its spire down, on the grounds that it was against the principle of equality. The tower was saved, however, when in May of the same year citizens of Strasbourg crowned it with a giant tin Phrygian cap. This artifact was later kept in the historical collections of the city until it was destroyed by the Germans in 1870 during the Franco-Prussian war.
In 1805, 1806 and 1809, Napoléon Bonaparte and his first wife, Joséphine stayed in Strasbourg. In 1810, his second wife Marie Louise, Duchess of Parma spent her first night on French soil in the palace. Another royal guest was King Charles X of France in 1828. In 1836, Louis-Napoléon Bonaparte unsuccessfully tried to lead his first Bonapartist coup in Strasbourg.
With the growth of industry and commerce, the city's population tripled in the 19th century to 150,000.
During the Franco-Prussian War and the Siege of Strasbourg, the city was heavily bombarded by the Prussian army. The indiscriminate bombardment of the city was meant to break the morale of the people of Strasbourg. On 24 and 26 August 1870, the Museum of Fine Arts was destroyed by fire, as was the Municipal Library housed in the Gothic former Dominican church, with its unique collection of medieval manuscripts (most famously the Hortus deliciarum), rare Renaissance books, archeological finds and historical artifacts. The gothic cathedral was damaged as well as the medieval church of Temple Neuf, the theater, the city hall, the court of justice and many houses. At the end of the siege 10,000 inhabitants were left without shelter; over 600 died, including 261 civilians, and 3200 were injured, including 1,100 civilians.
In 1871, after the war's end, the city was annexed to the newly established German Empire as part of the Reichsland Elsaß-Lothringen (via the Treaty of Frankfurt). As part of Imperial Germany, Strasbourg was rebuilt and developed on a grand and representative scale (the "Neue Stadt", or "new city"). Historian Rodolphe Reuss and Art historian Wilhelm von Bode were in charge of rebuilding the municipal archives, libraries and museums. The University, founded in 1567 and suppressed during the French Revolution as a stronghold of German sentiment, was reopened in 1872 under the name "Kaiser-Wilhelms-Universität".
A belt of massive fortifications was established around the city, most of which still stand today, renamed after French generals and generally classified as Monuments historiques; most notably "Fort Roon" (now "Fort Desaix") and "Fort Podbielski" (now "Fort Ducrot") in Mundolsheim, "Fort von Moltke" (now "Fort Rapp") in Reichstett, "Fort Bismarck" (now "Fort Kléber") in Wolfisheim, "Fort Kronprinz" (now "Fort Foch") in Niederhausbergen, "Fort Kronprinz von Sachsen" (now "Fort Joffre") in Holtzheim and "Fort Großherzog von Baden" (now " Fort Frère") in Oberhausbergen.
Those forts subsequently served the French army (Fort Podbielski/Ducrot for instance was integrated into the Maginot Line), and were used as POW-camps in 1918 and 1945.
Two garrison churches were also erected for the members of the Imperial German army, the Lutheran "Église Saint-Paul" and the Roman Catholic "Église Saint-Maurice".
1918 to the present.
Following the defeat of the German empire in World War I and the abdication of the German Emperor, some revolutionary insurgents declared Alsace-Lorraine as an independent Republic, without preliminary referendum or vote. On 11 November 1918 (Armistice Day), communist insurgents proclaimed a "soviet government" in Strasbourg, following the example of Kurt Eisner in Munich as well as other German towns. French troops commanded by French general Henri Gouraud entered triumphantly in the city on the 22 November. A major street of the city now bears the name of that date ("Rue du 22 Novembre") which celebrate the entry of the French in the city. Viewing the massive cheering crowd gathered under the balcony of Strasbourg's town hall, French President Raymond Poincaré stated that "the plebiscite is done".
In 1919, following the Treaty of Versailles, the city was annexed by France in accordance with U.S. President Woodrow Wilson's "Fourteen Points" without a referendum. The date of the assignment was retroactively established on Armistice Day. It is doubtful whether a referendum in Strasbourg would have ended in France's favor since the political parties striving for an autonomous Alsace or a connection to France accounted only for a small proportion of votes in the last Reichstag as well as the local elections. The Alsatian autonomists who were pro French won many votes in the more rural parts of the region and others towns since the annexion of the region by the Germans in 1871. The movement started with the first election at the Reichstag, they were called "les députés protestataires", and until the fall of Bismarck in 1890, they were the only deputies elected by the Alsatians sent to the German parliament demanding the return of those territories to France. At the last election in Strasbourg and its periphery, the clear winners were the Social-democrats, the city was the administrative capital of the region, and was inhabited by many Germans appointed by the central government in Berlin and its flourishing economy attracted many Germans. This can explain the difference between the rural vote and the one in Strasbourg. After the war, many Germans left Strasbourg and went back to Germany, some of them were denounced by the locals or expelled by the new appointed authorities. The Saverne Affair was vivid in the memory among the alsatians.
In 1920, Strasbourg became the seat of the Central Commission for Navigation on the Rhine, previously located in Mannheim, one of the oldest European institutions. It moved into the former Imperial Palace.
When the Maginot Line was built, the "Sous-secteur fortifié de Strasbourg" (fortified sub-sector of Strasbourg) was laid out on the city's territory as a part of the "Secteur fortifié du Bas-Rhin", one of the sections of the Line. Blockhouses and casemates were built along the Grand Canal d'Alsace and the Rhine in the Robertsau forest and the port.
Between the German invasion of Poland on 1 September 1939 and the Anglo-French declaration of War against the German Reich on 3 September 1939, the entire city (a total of 120,000 people) was evacuated, like other border towns as well. Until the arrival of the Wehrmacht troops mid-June 1940, the city was, for ten months, completely empty, with the exception of the garrisoned soldiers. The Jews of Strasbourg had been evacuated to Périgueux and Limoges, the University had been evacuated to Clermont-Ferrand.
After the ceasefire following the Fall of France in June 1940, Alsace was annexed to Germany and a rigorous policy of Germanization was imposed upon it by the "Gauleiter" Robert Heinrich Wagner. When, in July 1940, the first evacuees were allowed to return, only residents of Alsatian origin were admitted. The last Jews were deported on 15 July 1940 and the main synagogue, a huge Romanesque revival building that had been a major architectural landmark with its 54-metre-high dome since its completion in 1897, was set ablaze, then razed.
In September 1940 the first Alsatian resistance movement lead by Marcel Weinum called La main noire (The black hand) was created. It was composed by a group of 25 young men aged from 14 to 18 years old who led several attacks against the German occupation. The actions culminated with the attack of the Gauleiter Robert Wagner, the highest commander of Alsace directly under the order of Hitler. In March 1942, Marcel Weinum was prosecuted by the Gestapo and sentenced to be beheaded at the age of 18 in April 1942 in Stuttgart, Germany. His last words will be: "If I have to die, I shall die but with a pure heart".
From 1943 the city was bombarded by Allied aircraft. While the First World War had not notably damaged the city, Anglo-American bombing caused extensive destruction in raids of which at least one was allegedly carried out by mistake. In August 1944, several buildings in the Old Town were damaged by bombs, particularly the Palais Rohan, the Old Customs House ("Ancienne Douane") and the Cathedral. On 23 November 1944, the city was officially liberated by the 2nd French Armoured Division under General Leclerc. He achieved the oath that he made with his soldiers, after the decisive Capture of Kufra. With the Oath of Kuffra, they swore to keep up the fight until the French flag flew over the Cathedral of Strasbourg.
Many people from Strasbourg were incorporated in the German Army against their will, and were sent to the eastern front, those young men and women were called Malgré-nous. Many tried to escape from the incorporation, join the French Resistance, or desert the Wehrmacht but many couldn't because they were running the risk of having their families sent to work or concentration camps by the Germans.
Many of these men, especially those who did not answer the call immediately, were pressured to "volunteer" for service with the SS, often by direct threats on their families.
This threat obliged the majority of them to remain in the German army. After the war, the few that survived were often accused of being traitors or collaborationists, because this tough situation was not known in the rest of France, and they had to face the incomprehension of many. In July 1944, 1500 malgré-nous were released from Soviet captivity and sent to Algiers, where they joined the Free French Forces.
Nowadays history recognizes the suffering of those people, and museums, public discussions and memorials have been built to commemorate this terrible period of history of this part of Eastern France (Alsace and Moselle). Liberation of Strasbourg took place on 23 November 1944.
In 1947, a fire broke out in the Musée des Beaux-Arts and devastated a significant part of the collections. This fire was an indirect consequence of the bombing raids of 1944: because of the destruction inflicted on the Palais Rohan, humidity had infiltrated the building, and moisture had to be fought. This was done with welding torches, and a bad handling of these caused the fire.
In the 1950s and 1960s the city was enlarged by new residential areas meant to solve both the problem of housing shortage due to war damage and that of the strong growth of population due to the baby boom and immigration from North Africa: "Cité Rotterdam" in the North-East, "Quartier de l'Esplanade" in the South-East, "Hautepierre" in the North-West. Between 1995 and 2010, a new district has been built in the same vein, the "Quartier des Poteries", south of Hautepierre.
In 1958, a violent hailstorm destroyed most of the historical greenhouses of the Botanical Garden and many of the stained glass windows of St. Paul's Church.
In 1949, the city was chosen to be the seat of the Council of Europe with its European Court of Human Rights and European Pharmacopoeia. Since 1952, the European Parliament has met in Strasbourg, which was formally designated its official 'seat' at the Edinburgh meeting of the European Council of EU heads of state and government in December 1992. (This position was reconfirmed and given treaty status in the 1997 Treaty of Amsterdam). However, only the (four-day) plenary sessions of the Parliament are held in Strasbourg each month, with all other business being conducted in Brussels and Luxembourg. Those sessions take place in the "Immeuble Louise Weiss", inaugurated in 1999, which houses the largest parliamentary assembly room in Europe and of any democratic institution in the world. Before that, the EP sessions had to take place in the main Council of Europe building, the Palace of Europe, whose unusual inner architecture had become a familiar sight to European TV audiences. In 1992, Strasbourg became the seat of the Franco-German TV channel and movie-production society Arte.
In 2000, an Islamist plot to blow up the cathedral was prevented thanks to the cooperation between French and German police that led to the arrest in late 2000 of a Frankfurt-based group of terrorists.
On 6 July 2001, during an open-air concert in the "Parc de Pourtalès", a single falling Platanus tree killed thirteen people and injured 97. On 27 March 2007, the city was found guilty of neglect over the accident and fined €150,000.
In 2006, after a long and careful restoration, the inner decoration of the "Aubette", made in the 1920s by Hans Arp, Theo van Doesburg, and Sophie Taeuber-Arp and destroyed in the 1930s, was made accessible to the public again. The work of the three artists had been called "the Sistine Chapel of abstract art".
Districts.
Strasbourg is divided into the following districts:
Main sights.
Architecture.
The city is chiefly known for its sandstone Gothic Cathedral with its famous astronomical clock, and for its medieval cityscape of Rhineland black and white timber-framed buildings, particularly in the "Petite-France" district or "Gerberviertel" ("tanners' district") alongside the Ill and in the streets and squares surrounding the cathedral, where the renowned "Maison Kammerzell" stands out.
Notable medieval streets include "Rue Mercière", "Rue des Dentelles", "Rue du Bain aux Plantes", "Rue des Juifs", "Rue des Frères", "Rue des Tonneliers", "Rue du Maroquin", "Rue des Charpentiers", "Rue des Serruriers", "Grand' Rue", "Quai des Bateliers", "Quai Saint-Nicolas" and "Quai Saint-Thomas".
Notable medieval squares include "Place de la Cathédrale", "Place du Marché Gayot", "Place Saint-Étienne", "Place du Marché aux Cochons de Lait" and "Place Benjamin Zix".
In addition to the cathedral, Strasbourg houses several other medieval churches that have survived the many wars and destructions that have plagued the city: the Romanesque "Église Saint-Étienne", partly destroyed in 1944 by Anglo-American bombing raids, the part Romanesque, part Gothic, very large "Église Saint-Thomas" with its Silbermann organ on which Wolfgang Amadeus Mozart and Albert Schweitzer played, the Gothic "Eglise Saint-Pierre-le-Jeune Protestant" with its crypt dating back to the seventh century and its cloister partly from the eleventh century, the Gothic "Église Saint-Guillaume" with its fine early-Renaissance stained glass and furniture, the Gothic "Église Saint-Jean", the part Gothic, part Art Nouveau "Église Sainte-Madeleine", etc.
The Neo-Gothic church "Saint-Pierre-le-Vieux Catholique" (there is also an adjacent church "Saint-Pierre-le-Vieux Protestant") serves as a shrine for several 15th-century wood worked and painted altars coming from other, now destroyed churches and installed there for public display.
Among the numerous secular medieval buildings, the monumental "Ancienne Douane" (old custom-house) stands out.
The German Renaissance has bequeathed the city some noteworthy buildings (especially the current "Chambre de Commerce et d'Industrie", former town hall, on "Place Gutenberg"), as did the French Baroque and Classicism with several "hôtels particuliers" (i.e. palaces), among which the "Palais Rohan" (now housing three museums) is the most spectacular. Other buildings of its kind are the "Hôtel du Préfet", the "Hôtel des Deux-Ponts" and the city-hall "Hôtel de Ville" etc. The largest baroque building of Strasbourg though is the 1720s main building of the "Hôpital civil".
As for French Neo-classicism, it is the Opera House on Place Broglie that most prestigiously represents this style.
Strasbourg also offers high-class eclecticist buildings in its very extended German district, being the main memory of Wilhelmian architecture since most of the major cities in Germany proper suffered intensive damage during World War II. Streets, boulevards and avenues are homogeneous, surprisingly high (up to seven stories) and broad examples of German urban lay-out and of this architectural style that summons and mixes up five centuries of European architecture as well as Neo-Egyptian, Neo-Greek and Neo-Babylonian styles. The former imperial palace "Palais du Rhin", the most political and thus heavily criticized of all German Strasbourg buildings epitomizes the grand scale and stylistic sturdiness of this period. But the two most handsome and ornate buildings of these times are the "École internationale des Pontonniers" (the former "Höhere Mädchenschule", girls college) with its towers, turrets and multiple round and square angles and the "École des Arts décoratifs" with its lavishly ornate façade of painted bricks, woodwork and majolica.
Notable streets of the German district include: "Avenue de la Forêt Noire", "Avenue des Vosges", "Avenue d'Alsace", "Avenue de la Marseillaise", "Avenue de la Liberté", "Boulevard de la Victoire", "Rue Sellénick", "Rue du Général de Castelnau", "Rue du Maréchal Foch", and "Rue du Maréchal Joffre". Notable squares of the German district include: "Place de la République", "Place de l'Université", "Place Brant", and "Place Arnold"
Impressive examples of Prussian military architecture of the 1880s can be found along the newly reopened "Rue du Rempart", displaying large-scale fortifications among which the aptly named "Kriegstor" (war gate).
As for modern and contemporary architecture, Strasbourg possesses some fine Art Nouveau buildings (the huge "Palais des Fêtes", some houses and villas on "Avenue de la Robertsau" and "Rue Sleidan"), good examples of post-World War II functional architecture (the "Cité Rotterdam", for which Le Corbusier did not succeed in the architectural contest) and, in the very extended "Quartier Européen", some spectacular administrative buildings of sometimes utterly large size, among which the European Court of Human Rights building by Richard Rogers is arguably the finest. Other noticeable contemporary buildings are the new Music school "Cité de la Musique et de la Danse", the "Musée d'Art moderne et contemporain" and the "Hôtel du Département" facing it, as well as, in the outskirts, the tramway-station Hoenheim-Nord designed by Zaha Hadid.
The city has many bridges, including the medieval, four-towered "Ponts Couverts".
Next to it is a part of the 17th-century Vauban fortifications, the "Barrage Vauban". Other bridges are the ornate 19th-century "Pont de la Fonderie" (1893, stone) and "Pont d'Auvergne" (1892, iron), as well as architect Marc Mimram's futuristic "Passerelle" over the Rhine, opened in 2004.
The largest square at the centre of the city of Strasbourg is the Place Kléber. Located in the heart of the city's commercial area, it was named after general Jean-Baptiste Kléber, born in Strasbourg in 1753 and assassinated in 1800 in Cairo. In the square is a statue of Kléber, under which is a vault containing his remains. On the north side of the square is the Aubette (Orderly Room), built by Jacques François Blondel, architect of the king, in 1765–1772.
Parks.
Strasbourg features a number of prominent parks, of which several are of cultural and historical interest: the "Parc de l'Orangerie", laid out as a French garden by André le Nôtre and remodeled as an English garden on behalf of Joséphine de Beauharnais, now displaying noteworthy French gardens, a neo-classical castle and a small zoo; the "Parc de la Citadelle", built around impressive remains of the 17th-century fortress erected close to the Rhine by Vauban; the "Parc de Pourtalès", laid out in English style around a baroque castle (heavily restored in the 19th century) that now houses a small three star hotel, and featuring an open-air museum of international contemporary sculpture.
The Jardin botanique de l'Université de Strasbourg (botanical garden) was created under the German administration next to the Observatory of Strasbourg, built in 1881, and still owns some greenhouses of those times. The "Parc des Contades", although the oldest park of the city, was completely remodeled after World War II. The futuristic "Parc des Poteries" is an example of European park-conception in the late 1990s. The "Jardin des deux Rives", spread over Strasbourg and Kehl on both sides of the Rhine, is the most recent (2004) and most extended (60 hectare) park of the agglomeration.
Museums.
For a city of comparatively small size, Strasbourg displays a large quantity and variety of museums:
Fine Art museums.
Unlike most other cities, Strasbourg's collections of European art are divided into several museums according not only to type and area, but also to epoch. Old master paintings from the Germanic Rhenish territories and until 1681 are displayed in the "Musée de l'Œuvre Notre-Dame", old master paintings from all the rest of Europe (including the Dutch Rhenish territories) and until 1871 as well as old master paintings from the Germanic Rhenish territories between 1681 and 1871 are displayed in the "Musée des Beaux-Arts". Old master graphic arts until 1871 is displayed in the "Cabinet des estampes et dessins". Decorative arts until 1681 ("German period") are displayed in the "Musée de l'Œuvre Notre-Dame", decorative arts from 1681 to 1871 ("French period") are displayed in the "Musée des Arts décoratifs". International art (painting, sculpture, graphic arts) and decorative art since 1871 is displayed in the "Musée d'art moderne et contemporain". The latter museum also displays the city's photographic library.
Other museums.
University museums.
The Université de Strasbourg is in charge of a number of permanent public displays of its collections of scientific artefacts and products of all kinds of exploration and research.
Demographics.
The metropolitan area of Strasbourg includes 638,670 inhabitants (2006), while the Eurodistrict has a population of 884,988 inhabitants.
Culture.
Strasbourg is the seat of internationally renowned institutions of music and drama:
Other theatres are the "Théâtre jeune public", the "TAPS Scala", the "Kafteur"... 
Education.
Universities and schools.
Strasbourg, well known as centre of humanism, has a long history of excellence in higher-education, at the crossroads of French and German intellectual traditions. Although Strasbourg had been annexed by the Kingdom of France in 1683, it still remained connected to the German-speaking intellectual world throughout the 18th century and the university attracted numerous students from the Holy Roman Empire, including Goethe, Metternich and Montgelas, who studied law in Strasbourg, among the most prominent. Nowadays, Strasbourg is known to offer among the best university courses in France, after Paris.
Up until January 2009 there were three universities in Strasbourg, with an approximate total of 48,500 students as of 2007 (another 4,500 students are being taught at one of the diverse post-graduate schools):
Since 1 January 2009, those three universities have merged and constitute now the Université de Strasbourg.
Schools part of the Université de Strasbourg include:
Libraries.
The Bibliothèque nationale et universitaire (BNU) is, with its collection of more than 3,000,000 titles, the second largest library in France after the Bibliothèque nationale de France. It was founded by the German administration after the complete destruction of the previous municipal library in 1871 and holds the unique status of being simultaneously a students' and a national library. The Strasbourg municipal library had been marked erroneously as “City Hall” in a French commercial map, which had been captured and used by the German artillery to lay their guns. A librarian from Munich later pointed out “...that the destruction of the precious collection was not the fault of a German artillery officer, who used the French map, but of the slovenly and inaccurate scholarship of a Frenchman.”
The municipal library Bibliothèque municipale de Strasbourg (BMS) administrates a network of ten medium-sized librairies in different areas of the town. A six stories high "Grande bibliothèque", the "Médiathèque André Malraux", was inaugurated on 19 September 2008 and is considered the largest in Eastern France.
Incunabula.
As one of the earliest centers of book-printing in Europe (see above: History), Strasbourg for a long time held a large number of incunabula—documents printed before 1500—in her library as one of her most precious heritages. After the total destruction of this institution in 1870, however, a new collection had to be reassembled from scratch. Today, Strasbourg's different public and institutional libraries again display a sizable total number of incunabula, distributed as follows: "Bibliothèque nationale et universitaire", ca. 2 098 "Médiathèque de la ville et de la communauté urbaine de Strasbourg", 394 "Bibliothèque du Grand Séminaire", 238 "Médiathèque protestante", 94 and "Bibliothèque alsatique du Crédit Mutuel", 5.
Transportation.
Strasbourg has its own airport, serving major domestic destinations as well as international destinations in Europe and northern Africa.
Train services operate from Gare de Strasbourg eastward to Offenburg and Karlsruhe in Germany, westward to Metz and Paris, and southward to Basel. Strasbourg's links with the rest of France have improved due to its recent connection to the TGV network, with the first phase of the TGV "Est" (Paris–Strasbourg) in 2007, the TGV "Rhin-Rhône" (Strasbourg-Lyon) in 2012, and the second phase of the TGV Est (currently planned to open in 2016).
City transportation in Strasbourg is served by a futurist-looking tram system that has been operated since 1994 by the regional transit company Compagnie des Transports Strasbourgeois and as of 2010 consists of 6 lines (A, B, C, D, E and F) adding up to a total of 55.8 km. A former tram system, partly following different routes, had been operating since 1878 but was ultimately dismantled in 1960.
The tram system that now criss-crosses the historic city centre complements walking and biking in it. The centre has been transformed into a pedestrian priority zone that enables and invites walking and biking by making these active modes of transport comfortable, safe and enjoyable. These attributes are accomplished by applying the principle of "filtered permeability" to the existing irregular network of streets. It means that the network adaptations favour active transportation and, selectively, "filter out" the car by reducing the number of streets that run through the centre. While certain streets are discontinuous for cars, they connect to a network of pedestrian and bike paths which permeate the entire centre. In addition, these paths go through public squares and open spaces increasing the enjoyment of the trip (see drawing). This logic of filtering a mode of transport is fully expressed in a comprehensive model for laying out neighbourhoods and districts – the Fused Grid
Being a city next to the Rhine and along some of its most important canals (Marne-Rhine Canal, Grand Canal d'Alsace), while crossed by the Ill, Strasbourg has always been an important centre of fluvial navigation, as is attested by archeological findings as well as the important activity of the "Port autonome de Strasbourg". Water tourism inside the city proper attracts hundreds of thousands of tourists yearly.
With more than 500 km of bicycle paths, biking in the city is convenient. Compagnie des Transports Strasbourgeois operates a cheap bike-sharing scheme named "Vélhop"'.
European role.
Institutions.
Strasbourg is the seat of over twenty international institutions, most famously of the Council of Europe and of the European Parliament, of which it is the official seat. Strasbourg is considered the legislative and democratic capital of the European Union, while Brussels is considered the executive and administrative capital and Luxembourg the judiciary and financial capital. 
Strasbourg is:
Eurodistrict.
France and Germany have created a Eurodistrict straddling the Rhine, combining the Greater Strasbourg and the Ortenau district of Baden-Württemberg, with some common administration. The combined population of this district is 884,988 according to the latest official national statistics.
Sports.
Internationally renowned teams from Strasbourg are the Racing Club de Strasbourg (football), Strasbourg IG (basketball) and the Étoile Noire (ice hockey). The women's tennis Internationaux de Strasbourg is one of the most important French tournaments of its kind outside Roland-Garros.
Notable people.
In chronological order, notable people born in Strasbourg include: Johannes Tauler, Sebastian Brant, Jean Baptiste Kléber, Louis Ramond de Carbonnières, Marie Tussaud, Ludwig I of Bavaria, Charles Frédéric Gerhardt, Louis-Frédéric Schützenberger, Gustave Doré, Émile Waldteufel, Jean/Hans Arp, Charles Münch, Hans Bethe, Maurice Kriegel-Valrimont, Marcel Marceau, Tomi Ungerer, Arsène Wenger, Petit and Matt Pokora.
In chronological order, notable residents of Strasbourg include: Johannes Gutenberg, Hans Baldung, Martin Bucer, John Calvin, Joachim Meyer, Johann Carolus, Johann Wolfgang Goethe, Jakob Michael Reinhold Lenz, Klemens Wenzel von Metternich, Georg Büchner, Louis Pasteur, Ferdinand Braun, Albrecht Kossel, Georg Simmel, Albert Schweitzer, Otto Klemperer, Marc Bloch, Alberto Fujimori, Marjane Satrapi, Paul Ricoeur and Jean-Marie Lehn.
Twin towns and sister cities.
Strasbourg is twinned with:
Strasbourg has cooperative agreements with:

</doc>
<doc id="37408" url="http://en.wikipedia.org/wiki?curid=37408" title="Kingston, Jamaica">
Kingston, Jamaica

Kingston ( or ) is the capital and largest city of Jamaica, located on the southeastern coast of the island. It faces a natural harbour protected by the Palisadoes, a long sand spit which connects the town of Port Royal and the Norman Manley International Airport to the rest of the island. In the Americas, Kingston is the largest predominantly English-speaking city south of the United States.
The local government bodies of the parishes of Kingston and St. Andrew were amalgamated by the Kingston and St. Andrew Corporation Act of 1923, to form the Kingston and St. Andrew Corporation (KSAC). Greater Kingston, or the "Corporate Area" refers to those areas under the KSAC; however, it does not solely refer to Kingston Parish, which only consists of the old downtown and Port Royal. Kingston Parish had a population of 96,052, and St. Andrew parish had a population of 555,828 in 2001. Kingston is only bordered by Saint Andrew to the east, west and north. The geographical border for the parish of Kingston encompasses the following communities, Tivoli Gardens, Denham Town, downtown Kingston, National Heroes Park, Kingston Gardens, Rae Town, Bournemouth Gardens, Norman Gardens, Springfield, Rennock Lodge, Port Royal along with portions of Allman Town, Franklyn Town and Rollington Town.
The city proper is bounded by six miles (6 mi) to the west, Stony Hill to the north, Papine to the northeast and Harbour View to the east, communities in urban and suburban Saint Andrew. Communities in rural St. Andrew such as Gordon Town, Mavis Bank, Lawrence Tavern, Mt. Airy and Bull Bay would not be described as being in Kingston city.
Two parts make up the central area of Kingston: the historic Downtown, and New Kingston. Both are served by Norman Manley International Airport and also by the smaller and primarily domestic Tinson Pen Aerodrome.
History.
Kingston was founded in July 1692 as a place for survivors of the 1692 earthquake that destroyed Port Royal. Before the earthquake, Kingston’s functions were purely agricultural. The earthquake survivors set up a camp on the sea front. Approximately two thousand people died due to mosquito-borne diseases. Initially the people lived in a tented camp on Colonel Barry's "Hog Crawle". The town did not begin to grow until after the further destruction of Port Royal by the Nick Catania Pirate Fleet's fire in 1703. Surveyor John Goffe drew up a plan for the town based on a grid bounded by North, East, West and Harbour Streets. By 1716 it had become the largest town and the centre of trade for Jamaica.
The government sold land to people with the regulation that they purchase no more than the amount of the land that they owned in Port Royal, and only land on the sea front. Gradually wealthy merchants began to move their residences from above their businesses to the farm lands north on the plains of Liguanea.
The first free school, Wolmers's, was founded in 1729 and there was a theatre, first on Harbour Street and then moved in 1774 to North Parade. Both are still in existence. In 1755 the governor, Sir Charles Knowles, had decided to transfer the government offices from Spanish Town to Kingston. It was thought by some to be an unsuitable location for the Assembly in proximity to the moral distractions of Kingston, and the next governor rescinded the Act. However, by 1780 the population of Kingston was 11,000, and the merchants began lobbying for the administrative capital to be transferred from Spanish Town, which was by then eclipsed by the commercial activity in Kingston.
By the end of the 18th century, the city contained more than 3,000 brick buildings. The harbour fostered trade, and played part in several naval wars of the 18th century. Kingston took over the functions of Spanish Town (the capital at the time). These functions included agriculture, commercial, processing, and a main transportation hub to and from Kingston and other sections of the island.
The government passed an act to transfer the government offices to Kingston from Spanish Town, which occurred in 1872. It kept this status when the island was granted independence in 1962.
In 1907, 800 people died in another earthquake known as the 1907 Kingston earthquake, destroying nearly all the historical buildings south of Parade in the city. That was when a restriction of no more than 60 ft was instituted on buildings in the central business district. These three story high buildings were built with reinforced concrete. Construction on King Street in the city was the first area to breach this building code.
During the 1930s, island-wide riots led to the development of trade unions and political parties to represent workers.
The city became home to the Mona campus of the University of the West Indies founded in 1948, with 24 medical students.
Not until the 1960s did major change occur in the development of Kingston’s central business district. The international attention of reggae music at that time coincided with the expansion and development of 95 acre of the Downtown Kingston waterfront area. These developments led to an influx of shops and offices, and the development of a new financial center: New Kingston, which replaced the Knutsford Racetrack. Multi-story buildings and boulevards were placed within that section.
In 1966 Kingston was the host city to the Commonwealth Games.
The western section of the city was not the focus of development, and that area proved to be politically tense. The 1970s saw deteriorating economic conditions that led to recurrent violence and a decline in tourism which later affected the island.
In the 1980 general elections, the democratic socialist People's National Party (PNP) government was voted out, and subsequent governments have been more market-oriented. Within a global urban era, the 1990s saw that Kingston has made efforts to modernize and develop its city structure and functions. Various organizations such as The Kingston Restoration Company, the Urban Development Corporation (UDC), the Port Authority of Jamaica, and the Port Royal Development Company, among others sought to develop the urban structure of the city.
Demographics.
The majority of the population of Kingston is of African descent. Large minority ethnic groups include East Indians and Chinese, who came to the country as indentured servants in the late 19th century. The Chinese occupy important roles in Jamaica's economy especially in the retail markets in Downtown Kingston and the wider metropolitan area. Europeans, mostly descending from immigrants from Germany and Great Britain as well as Christian Syrians and Lebanese form one of the most influential ethnic groups in not only Kingston, but the entire island. Though a minority ethnic group, the Lebanese were able to give Jamaica one of its prime ministers in the form of Edward Philip George Seaga. Multi-racial Jamaicans continue to form the second largest racial group and there is also a small Jewish population in the city.
Religion.
There is a wide variety of Christian churches in the city. Most are Protestant, a legacy of British colonization of the island. The chief denominations are Church of God, Baptist, Anglican, Methodist, Roman Catholic, Seventh-day Adventist, and Pentecostal. Afro-Christian syncretic religions such as the Rastafari movement also have a significant following.
The Shaare Shalom Synagogue serves Kingston's Jewish population. The city also has communities of Buddhists and Muslims. The Islamic Council of Jamaica and the Islamic Education and Dawah Center are both located in Kingston. There are three units of The Church of Jesus Christ of Latter-day Saints in the city.
Economy.
Kingston plays a central role in Jamaica's economy. The vast majority of economic activity takes place within Kingston, and as most government ministries are located in the city, it is a key force in legislation in regards to Jamaica's finances. The high population density of the capital city means that the majority of monetary transactions occur in Kingston - stimulating much of Jamaica's local economy. Many multinational conglomerates and financial institutions are headquartered in and around the Kingston Metropolitan Area. The Jamaican government has expressed a desire and as such, passed legislation to transform Kingston into an International Financial Centre. This IFC will most likely be located along the Kingston waterfront, and be a part of the wider revitalization and gentrification programme for Downtown Kingston.
Air Jamaica is headquartered in Kingston.
Geography and climate.
Kingston is surrounded by the Blue Mountains, Red Hills, Long Mountain and the Kingston Harbour. The city is on the Liguanea Plain, an alluvial plain alongside the Hope River. Kingston experiences frequent earthquakes, including the 1907 earthquake.
Kingston has a tropical climate, specifically a tropical wet-and-dry climate, characterized by a wet season from May to November, which coincides with the hurricane season, and a dry season from December to April. During the dry season, there is not much rainfall, however, cold and stationary fronts occur at this time, and often bring heavy showers, especially in March. Kingston is in the rain shadow of the Blue Mountains; therefore, little to none of the moisture carried by the Northeast Trade Winds falls over Kingston, causing Kingston to be very dry in comparison to Portland and Saint Mary on the windward side of the Blue Mountains. Kingston is on a coastal location, hence it comes under the influence of the sea, though dense urban development can negate this effect. In the 21st century, Kingston has experienced temperatures as high as 36 °C and as low as 14 °C. Between 1895 and 1990, the total average rainfall was recorded at 909.7 mm, the highest monthly average rainfall recorded in October at 181.1 mm, and the lowest monthly average rainfall recorded in March at 22.7 mm.
Parks.
The city of Kingston is home to a number of urban parks which are frequently transformed to accommodate various events and festivities on the Jamaican calendar. The most popular parks include: Emancipation Park, Hope Gardens, Devon House, National Heroes' Park, St William Grant Park and Mandela Park.
Emancipation Park.
The Liguanea Club, a recreational and social club for the upper class in society, located on Knutsford Boulevard, owned over 35 acres of land including the former Liguanea Park now the site of Emancipation Park. The Club gave the land measuring seven acres as a gift to the Jamaican Government.
Several government members argued that the land should be converted into a business district, while others felt a multi-functional entertainment complex should be built on the site. The large financial input needed for either venture, was not forthcoming. In 2002 Cabinet granted approval for the transfer of the land to the National Housing Trust on the condition that a park was built and maintained at that location. The land was transferred for one Jamaican dollar.
The park is well known for the 11 ft. (approximately 3m) high bronze sculpture done by Jamaican artist Laura Facey-Cooper, situated at the Park's main entrance. This prominent sculpture comprises two naked black male and female statues gazing to the skies – symbolic of their triumphant rise from the horrors of slavery. The statue was unveiled in July 2003, in time for the Park's first anniversary which caused an out cry from the Jamaican populace who believed that the blatant nudity and generous bodily proportions of the figures were very inappropriate to depict the freedom of black people.
Hope Gardens.
The Royal Botanical Gardens at Hope, popularly called Hope Gardens serves as a national attraction. The Hope Gardens is a part of the 2000 acres of land making it the largest botanical garden in the English-speaking Caribbean. The land situated by the foothills of the Blue Mountains was originally owned by Major Richard Hope from whom it got its name. Two hundred acres of this land was obtained by the Government of Jamaica in 1880 and was originally established as a plant introduction and crop-testing facility for plants such as pineapple, cocoa, coffee and tobacco. The formal Botanical Gardens were laid out on approximately 60 acres of this land with the assistance of personnel from the Kew Gardens in England.
In the 1950s, the Queen, after visiting the island and being pleased with the state of the gardens, gave permission for it to be called the Royal Botanical Gardens, Hope. The Gardens have many exotic species along with some endemic trees of Jamaica. Over the years, the ravages of hurricanes and other disasters have resulted in the loss of a significant number of species. However, there are still some prominent trees and popular sites to be viewed in the Gardens. At Hope Gardens, visitors can view a number of other features including the Coconut Museum, the Sunken Gardens, the Orchid House, the Lily Pond, the Maze and Palm Avenue.
The Hope Gardens has an adjoining zoo referred to as Hope Gardens Zoo. The gardens and zoo are currently undergoing redevelopment to improve the physical landscape and the animal inventory as a part of Bring Back The Hope campaign.
Transportation.
Road.
The St William Grant Park (Parade) in the heart of downtown Kingston is the starting point for three of Jamaica's four A roads, namely the A1 (Kingston to Lucea), the A3 (Kingston to Saint Ann's Bay) and the A4 (Kingston to Annotto Bay), while the city itself is provided with a dense network of trunk, main, secondary and minor roads. It also consists of the Highway 2000, Jamaica which runs through Portmore, Ocho Rios, and Mandeville
Kingston is served well by a modern bus system, mini buses, and taxis, which operate throughout the city with major hubs at , Cross Roads, Half Way Tree and elsewhere.
Private car ownership levels are high, and like many major urban conurbations Kingston suffers from frequent traffic jams and pollution.
Bus.
In June 1898, the existing mule car service was phased out and a transition to electric trams, initially operated by the West India Electric Company and later by the Jamaica Public Service Company, was undertaken. This transition to the electric tram was completed on 31 March 1899. This service continued to operate, but the inflexibility of a tram service could not keep pace with a growing city, and the tram service ceased to operate on 7 August 1948.
Between 1948 and 1953 a motor bus service was operated by a company called Jamaica Utilities. The government revoked its franchise in 1953.
From 1953 to 1983 the Jamaica Omnibus Service operated a service, which at its peak consisted of over 600 buses and served an area spanning Spanish Town, Border, Mt. James, Bull Bay and Port Royal. It was wound up by the government in 1983 after being nationalized in 1974.
Kingston is served well by a modern bus system, the Jamaica Urban Transit Company (JUTC), mini buses, and taxis, which operate throughout the city with major hubs at , Cross Roads, Half Way Tree and elsewhere.
Rail.
The now disused Kingston railway station served the main line with branches from , , and .
The station opened in 1845 and closed in October 1992 when all passenger traffic on Jamaica's railways abruptly ceased.
Air.
Kingston's international airport is Norman Manley International Airport while Tinson Pen Aerodrome provides domestic services.
Sea.
Historically, the Kingston waterfront was Jamaica's main port with many finger piers at which freighters and passenger liners could dock. More recently, with the containerisation of freight, the port has moved to Newport West.
Law enforcement.
Jamaica's police force, the Jamaica Constabulary Force, is based on Old Hope Road near Liguanea. Smaller police stations, such as Hunt's Bay, Matilda's Corner and Half-Way-Tree, are dispersed across the Corporate Area. The Supreme Court of Jamaica is also located in Kingston. Other courts, such as the Half-Way-Tree Resident Magistrate's Court, Gun Court, Traffic Court and Family Court, make Kingston their home. The Jamaica Defence Force (JDF) has its headquarters at Up Park Camp near New Kingston and Cross Roads. The JDF also operates a major naval base at Port Royal.
Fire Service.
Fire response in Kingston is provided by the Jamaica Fire Brigade, the national fire service. The service operates from fire stations spread throughout the Corporate Area. Currently fire stations are located at 
Media and telecommunications.
The Gleaner Company, the Jamaica Observer and the Sunday Herald, three of Jamaica's large newspaper companies, make their home in Kingston. Several television and radio stations including Television Jamaica (TVJ), CVM TV, RJR 94 FM, TBC Radio 88.5 FM, Hitz 92 FM, FAME 95 FM, LOVE TV, ZIP 103, Kool 97 FM and LOVE FM, are all based in Kingston. Kingston generally has an adequate telecommunications service, administered by either Cable and Wireless or Flow Jamaica. Cellular phone service is also very strong in Kingston, especially since Cable & Wireless(now operating as LIME) & Digicel, Jamaica’s two cellular providers, are all based in the city.
Postal Service.
Postal Services in Kingston and throughout the island are provided by the Postal Corporation of Jamaica, the national post office of Jamaica. Services include domestic and international mail delivery, post office boxes, registered mail, priority mail (local courier), parcel delivery, express mail service (international courier), advertising mail and provision of post office boxes.
Kingston is divided in several postal zones enumerated as follows;
Institutions.
Kingston, as the capital, is the financial, cultural, economic and industrial centre of Jamaica. Many financial institutions are based in Kingston, and the city boasts the largest number of hospitals, schools, universities and cultural attractions of any urban area on the island. Notable Kingston landmarks include the University of the West Indies, Jamaica Defence Force Museum, and Bob Marley Museum.
International relations.
Twin towns – Sister cities.
Kingston is twinned with:

</doc>
<doc id="37409" url="http://en.wikipedia.org/wiki?curid=37409" title="Ravenna">
Ravenna

Ravenna (Romagnol: "Ravêna") is the capital city of the Province of Ravenna, in the Emilia-Romagna region of Italy. It was the capital city of the Western Roman Empire from 402 until that empire collapsed in 476. It then served as the capital of the Kingdom of the Ostrogoths until it was re-conquered in 540 by the Eastern Roman (Byzantine) Empire. Afterwards, the city formed the centre of the Byzantine Exarchate of Ravenna until the invasion of the Franks in 751, after which it became the seat of the Kingdom of the Lombards.
Although an inland city, Ravenna is connected to the Adriatic Sea by the Candiano Canal. It is the location of eight UNESCO World Heritage Sites.
History.
The origin of the name "Ravenna" is unclear, although it is believed the name is Etruscan. Some have speculated that "ravenna" is related to "Rasenna" (later "Rasna"), the term that the Etruscans used for themselves, but there is no agreement on this point.
Ancient era.
The origins of Ravenna are uncertain. The first settlement is variously attributed to (and then has seen the co presence of) the Thessalians, the Etruscans and the Umbrians, afterwards its territory was settled also by the Senones, especially the southern countryside of the city (that wasn't part of the lagoon), the "Ager Decimanus". Ravenna consisted of houses built on piles on a series of small islands in a marshy lagoon – a situation similar to Venice several centuries later. The Romans ignored it during their conquest of the Po River Delta, but later accepted it into the Roman Republic as a federated town in 89 BC. In 49 BC, it was the location where Julius Caesar gathered his forces before crossing the Rubicon. Later, after his battle against Mark Antony in 31 BC, Emperor Augustus founded the military harbor of Classe. This harbor, protected at first by its own walls, was an important station of the Roman Imperial Fleet. Nowadays the city is landlocked, but Ravenna remained an important seaport on the Adriatic until the early Middle Ages. During the German campaigns, Thusnelda, widow of Arminius, and Marbod, King of the Marcomanni, were confined at Ravenna.
Ravenna greatly prospered under Roman rule. Emperor Trajan built a 70 km long aqueduct at the beginning of the 2nd century. During the Marcomannic Wars, Germanic settlers in Ravenna revolted and managed to seize possession of the city. For this reason, Marcus Aurelius decided not only against bringing more barbarians into Italy, but even banished those who had previously been brought there. In AD 402, Emperor Honorius transferred the capital of the Western Roman Empire from Milan to Ravenna. At that time it was home to 50,000 people. The transfer was made partly for defensive purposes: Ravenna was surrounded by swamps and marshes, and was perceived to be easily defensible (although in fact the city fell to opposing forces numerous times in its history); it is also likely that the move to Ravenna was due to the city's port and good sea-borne connections to the Eastern Roman Empire. However, in 409, King Alaric I of the Visigoths simply bypassed Ravenna, and went on to sack Rome in 410 and to take Galla Placidia, daughter of Emperor Theodosius I, hostage. After many vicissitudes, Galla Placidia returned to Ravenna with her son, Emperor Valentinian III and the support of her nephew Theodosius II. Ravenna enjoyed a period of peace, during which time the Christian religion was favoured by the imperial court, and the city gained some of its most famous monuments, including the Orthodox Baptistery, the misnamed Mausoleum of Galla Placidia (she was not really buried there), and San Giovanni Evangelista.
The late 400s saw the dissolution of Roman authority in the west, and the last person to hold the title of emperor in the West was deposed in 476 by the general Odoacer. Odoacer ruled as King of Italy for 13 years, but in 489 the Eastern Emperor Zeno sent the Ostrogoth King Theoderic the Great to re-take the Italian peninsula. After losing the Battle of Verona, Odoacer retreated to Ravenna, where he withstood a siege of three years by Theoderic, until the taking of Rimini deprived Ravenna of supplies. Theoderic took Ravenna in 493, supposedly slew Odoacer with his own hands, and Ravenna became the capital of the Ostrogothic Kingdom of Italy. Theoderic, following his imperial predecessors, also built many splendid buildings in and around Ravenna, including his palace church Sant'Apollinare Nuovo, an Arian cathedral (now Santo Spirito) and Baptistery, and his own Mausoleum just outside the walls.
Theoderic and his followers were Arian Christians, but co-existed peacefully with the Latins, who were largely Orthodox. Ravenna's Orthodox bishops carried out notable building projects, of which the sole surviving one is the Capella Arcivescovile. Theoderic allowed Roman citizens within his kingdom to be subject to Roman law and the Roman judicial system. The Goths, meanwhile, lived under their own laws and customs. In 519, when a mob had burned down the synagogues of Ravenna, Theoderic ordered the town to rebuild them at its own expense.
Theoderic died in 526 and was succeeded by his young grandson Athalaric under the authority of his daughter Amalasunta, but by 535 both were dead and Theoderic's line was represented only by Amalasuntha's daughter Matasuntha. Various Ostrogothic military leaders took the kingship of Italy, but none were as successful as Theoderic had been. Meanwhile, the orthodox Christian Byzantine Emperor Justinian I, opposed both Ostrogoth rule and the Arian variety of Christianity. In 535 his general Belisarius invaded Italy and in 540 conquered Ravenna. After the conquest of Italy was completed in 554, Ravenna became the seat of Byzantine government in Italy.
From 540 to 600, Ravenna's bishops embarked upon a notable building program of churches in Ravenna and in and around the port city of Classe. Surviving monuments include the Basilica of San Vitale and the Basilica of Sant'Apollinare in Classe, as well as the partially surviving San Michele in Africisco.
Exarchate of Ravenna.
Following the conquests of Belisarius for the Emperor Justinian I in the 6th century, Ravenna became the seat of the Byzantine governor of Italy, the Exarch, and was known as the Exarchate of Ravenna. It was at this time that the Ravenna Cosmography was written.
Under Byzantine rule, the archbishop of Ravenna was temporarily granted autocephaly from the Roman Church by the emperor, in 666, but this was soon revoked. Nevertheless, the archbishop of Ravenna held the second place in Italy after the pope, and played an important role in many theological controversies during this period.
Middle Ages and Renaissance.
The Lombards, under King Liutprand, occupied Ravenna in 712, but were forced to return it to the Byzantines. However, in 751 the Lombard king, Aistulf, succeeded in conquering Ravenna, thus ending Byzantine rule in northern Italy.
King Pepin of France attacked the Lombards under orders of Pope Stephen II. Ravenna then gradually came under the direct authority of the popes, although this was contested by the archbishops at various times. Pope Adrian I authorized Charlemagne to take away anything from Ravenna that he liked, and an unknown quantity of Roman columns, mosaics, statues, and other portable items were taken north to enrich his capital of Aachen.
In 1198 Ravenna led a league of Romagna cities against the Emperor, and the Pope was able to subdue it. After the war of 1218 the Traversari family was able to impose its rule in the city, which lasted until 1240. After a short period under an Imperial vicar, Ravenna was returned to the Papal States in 1248 and again to the Traversari until, in 1275, the Da Polenta established their long-lasting seigniory. One of the most illustrious residents of Ravenna at this time was the exiled poet Dante. The last of the Da Polenta, Ostasio III, was ousted by the Republic of Venice in 1440, and the city was annexed to the Venetian territories.
Ravenna was ruled by Venice until 1509, when the area was invaded in the course of the Italian Wars. In 1512, during the Holy League wars, Ravenna was sacked by the French.
After the Venetian withdrawal, Ravenna was again ruled by legates of the Pope as part of the Papal States. The city was damaged in a tremendous flood in May 1636. Over the next 300 years, a network of canals diverted nearby rivers and drained nearby swamps, thus reducing the possibility of flooding and creating a large belt of agricultural land around the city.
Modern age.
Apart from another short occupation by Venice (1527–1529), Ravenna was part of the Papal States until 1796, when it was annexed to the French puppet state of the Cisalpine Republic, (Italian Republic from 1802, and Kingdom of Italy from 1805). It was returned to the Papal States in 1814. Occupied by Piedmontese troops in 1859, Ravenna and the surrounding Romagna area became part of the new unified Kingdom of Italy in 1861. During World War II two troops of the British 27th Lancers entered and occupied Ravenna on 5 December 1944. The town suffered very little damage.
Main sights.
Eight early Christian monuments of Ravenna are inscribed on the World Heritage List. These are
Other attractions include:
Music.
The city annually hosts the Ravenna Festival, one of Italy's prominent classical music gatherings. Opera performances are held at the Teatro Alighieri while concerts take place at the Palazzo Mauro de André as well as in the ancient Basilica of San Vitale and Basilica of Sant'Apollinare in Classe. Chicago Symphony Orchestra music director Riccardo Muti, a longtime resident of the city, regularly participates in the festival, which invites orchestras and other performers from around the world.
Ravenna in Film.
Michelangelo Antonioni filmed his 1964 movie "Red Desert" ("Deserto Rosso") within the industrialised areas of the Pialassa valley within the city limits.
Transport.
Ravenna has an important commercial and tourist port.
Ravenna railway station has direct Trenitalia service to Bologna, Ferrara, Lecce, Milan, Parma, Rimini, Venice and Verona.
Ravenna Airport is located in Ravenna. The nearest commercial airports are those of Forlì, Rimini and Bologna.
Freeways crossing Ravenna include: A14-bis from the hub of Bologna; on the north-south axis of EU routes E45 (from Rome) and E55 (SS-309 "Romea" from Venice); and on the regional Ferrara-Rimini axis of SS-16 (partially called "Adriatica").
Twin towns—Sister cities.
Ravenna is twinned with:
 Chartres, France, since 1957
 Laguna, Brazil
Sports.
The historical Italian football of the city is Ravenna F.C.. Currently it plays in Eccellenza Emilia-Romagna Girone B.
A.P.D. Ribelle 1927 is the Italian football of Castiglione di Ravenna, a fraction of Ravenna and was founded in 1927. Currently it plays in Italy's Serie D after the promotion from Eccellenza Emilia-Romagna Girone B in the 2013-14 season.
The president is Marcello Missiroli and the manager is Enrico Zaccaroni.
Its home ground is "Stadio Massimo Sbrighi" of the fraction with 1,000 seats. The team's colors are white and blue.
The beaches of Ravenna hosted the 2011 FIFA Beach Soccer World Cup, in September 2011.

</doc>
<doc id="37410" url="http://en.wikipedia.org/wiki?curid=37410" title="Dresden">
Dresden

 
Dresden (]; Upper Sorbian: "Drježdźany") is the capital city of the Free State of Saxony in Germany. It is situated in a valley on the River Elbe, near the Czech border. The Dresden conurbation is part of the Saxon Triangle metropolitan area with 2.4 million inhabitants.
Dresden has a long history as the capital and royal residence for the Electors and Kings of Saxony, who for centuries furnished the city with cultural and artistic splendor. The city was known as the Jewel Box, because of its baroque and rococo city center. The controversial British and American bombing of Dresden in World War II towards the end of the war killed approximately 25,000, many of whom were civilians, and destroyed the entire city center. The bombing gutted the city, as it did for other major German cities. After the war restoration work has helped to reconstruct parts of the historic inner city, including the Katholische Hofkirche, the Semper Oper and the Dresdner Frauenkirche as well as the suburbs.
Before and since German reunification in 1990, Dresden was and is a cultural, educational, political and economic center of Germany and Europe. The Dresden University of Technology is one of the 10 largest universities in Germany and part of the German Universities Excellence Initiative.
History.
Although Dresden is a relatively recent city of Germanic origin followed by settlement of Slavic peoples, the area had been settled in the Neolithic era by Linear Pottery culture tribes ca. 7500 BC. Dresden's founding and early growth is associated with the eastward expansion of Germanic peoples, mining in the nearby Ore Mountains, and the establishment of the Margraviate of Meissen. Its name etymologically derives from Old Sorbian "Drežďany", meaning "people of the forest". Dresden later evolved into the capital of Saxony.
Early history.
Around the late 12th century, a Slavic settlement called "Drežďany" had developed on the southern bank. Another settlement existed on the northern bank, but its Slavic name is unclear. It was known as "Antiqua Dresdin" by 1350, and later as Altendresden, both literally "old Dresden". Dietrich, Margrave of Meissen, chose Dresden as his interim residence in 1206, as documented in a record calling the place "Civitas Dresdene".
After 1270, Dresden became the capital of the margraviate. It was restored to the Wettin dynasty in about 1319. From 1485, it was the seat of the dukes of Saxony, and from 1547 the electors as well.
Modern age.
The Elector and ruler of Saxony Frederick Augustus I became King August the Strong of Poland in personal union. He gathered many of the best musicians, architects and painters from all over Europe to Dresden. His reign marked the beginning of Dresden's emergence as a leading European city for technology and art. Dresden suffered heavy destruction in the Seven Years' War (1756–1763), following its capture by Prussian forces, its subsequent re-capture, and a failed Prussian siege in 1760. Friedrich Schiller wrote his Ode to Joy (the literary base of the European anthem) for the Dresden Masonic Lodge in 1785. 
The city of Dresden had a distinctive silhouette, captured in famous paintings by Bernardo Bellotto and by Norwegian painter Johan Christian Dahl.
Between 1806 and 1918 the city was the capital of the Kingdom of Saxony (which was a part of the German Empire from 1871). During the Napoleonic Wars the French emperor made it a base of operations, winning there the famous Battle of Dresden on 27 August 1813. Dresden was a center of the German Revolutions in 1848 with the May Uprising, which cost human lives and damaged the historic town of Dresden. 
During the 19th century the city became a major center of economy, including motor car production, food processing, banking and the manufacture of medical equipment.
In the early 20th century Dresden was particularly well known for its camera works and its cigarette factories. Between 1918 and 1934 Dresden was capital of the first Free State of Saxony. Dresden was a center of European modern art until 1933.
Military history.
During the foundation of the German Empire in 1871, a large military facility called Albertstadt was built. It had a capacity of up to 20,000 military personnel at the beginning of the First World War. The garrison saw only limited use between 1918 and 1934, but was then reactivated in preparation for the Second World War.
Its usefulness was limited by attacks on 17 April 1945 on the railway network (especially towards Bohemia). Soldiers had been deployed as late as March 1945 in the Albertstadt garrison.
The Albertstadt garrison became the headquarters of the Soviet 1st Guards Tank Army in the Group of Soviet Forces in Germany after the war. Apart from the German army officers' school ("Offizierschule des Heeres"), there have been no more military units in Dresden since the army merger during German reunification, and the withdrawal of Soviet forces in 1992. Nowadays, the Bundeswehr operates the Military History Museum of the Federal Republic of Germany in the former Albertstadt garrison.
Second World War.
During the Nazi era from 1933 to 1945, The Jewish community of Dresden was reduced from over 6,000 (7,100 people were persecuted as Jews) to 41. Non-Jews were also targeted, and over 1,300 people were executed by the Nazis at the Münchner Platz, a courthouse in Dresden, including labour leaders, undesirables, resistance fighters and anyone caught listening to foreign radio broadcasts. The bombing stopped prisoners who were busy digging a large hole into which an additional 4,000 prisoners were to be disposed of.
Dresden in the 20th century was a major communications hub and manufacturing center with 127 factories and major workshops and was designated by the German Military as a defensive strongpoint, with which to hinder the Soviet advance. Being the capital of the German state of Saxony, Dresden not only had garrisons but a whole "military borough", the "Albertstadt". This military complex, named after Saxon King Albert, was not specifically targeted in the bombing of Dresden though it was within the expected area of destruction and was extensively damaged.
During the final months of World War II, Dresden harboured some 600,000 refugees, with a total population of 1.2 million. Dresden was attacked seven times between 1944 and 1945, and was occupied by the Red Army after German capitulation.
The bombing of Dresden by the Royal Air Force (RAF) and the United States Army Air Forces (USAAF) between 13 and 15 February 1945 remains controversial. The inner city of Dresden was largely destroyed by 722 RAF and 527 USAAF bombers that dropped 2431 tons of high explosive bombs, and 1475.9 tons of incendiaries. The high explosive bombs damaged buildings and exposed their wooden structures, while the incendiaries ignited them, denying their use by retreating German troops and refugees. Widely quoted Nazi propaganda reports claimed 200,000 deaths however the German Dresden Historians' Commission made up of 13 prominent German historians, in an official 2010 report published after five years of research concluded that casualties numbered between 18,000 and a maximum of 25,000, while right-wing groups continue to claim that up to 500,000 people died. 
The Allies described the operation as the legitimate bombing of a military and industrial target. A report from the British Bomber Command stated the military target was the railway marshaling yard Dresden-Friedrichstadt. Several researchers have argued that the February attacks were disproportionate. Mostly women and children died. When interviewed after the war in 1977, Sir Arthur Harris stood by his decision to carry out the raids, and reaffirmed that it reduced the German military's ability to wage war.
American author Kurt Vonnegut's novel "Slaughterhouse Five" is loosely based on his first-hand experience of the raid as a POW. In remembrance of the victims, the anniversaries of the bombing of Dresden are marked with peace demonstrations, devotions and marches.
The destruction of Dresden allowed Hildebrand Gurlitt, a major Nazi museum director and art dealer, to hide a large collection of artwork worth over a billion dollars that had been stolen during the Nazi era, as he claimed it had been destroyed along with his house which was located in Dresden.
Post-war period.
After the Second World War, Dresden became a major industrial center in the German Democratic Republic (former East Germany) with a great deal of research infrastructure. Many important historic buildings were rebuilt, including the Semper Opera House, the Zwinger Palace and a great many other historic buildings, although the city leaders chose to reconstruct large areas of the city in a "socialist modern" style, partly for economic reasons, but also to break away from the city's past as the royal capital of Saxony and a stronghold of the German bourgeoisie. However, some of the bombed-out ruins of churches, royal buildings and palaces, such as the Gothic Sophienkirche, the Alberttheater and the Wackerbarth-Palais were razed by the Soviet and East German authorities in the 1950s and 1960s instead of being repaired. Compared to West Germany, the majority of historic buildings were saved.
From 1985 to 1990, the KGB stationed Vladimir Putin, the future President of Russia, in Dresden. On 3 October 1989 (the so-called "battle of Dresden"), a convoy of trains carrying East German refugees from Prague passed through Dresden on its way to the Federal Republic of Germany. Local activists and residents joined in the growing civil disobedience movement spreading across the German Democratic Republic by staging demonstrations and demanding the removal of the nondemocratic government.
Post-reunification.
Dresden has experienced dramatic changes since the reunification of Germany in the early 1990s. The city still bears many wounds from the bombing raids of 1945, but it has undergone significant reconstruction in recent decades. Restoration of the Dresden Frauenkirche was completed in 2005, a year before Dresden's 800th anniversary, notably by privately raised funds. The gold cross on the top of the church was funded officially by "the British people and the House of Windsor". The urban renewal process, which includes the reconstruction of the area around the Neumarkt square on which the Frauenkirche is situated, will continue for many decades, but public and government interest remains high, and there are numerous large projects underway—both historic reconstructions and modern plans—that will continue the city's recent architectural renaissance.
Dresden remains a major cultural center of historical memory, owing to the city's destruction in World War II. Each year on 13 February, the anniversary of the British and American fire-bombing raid that destroyed most of the city, tens of thousands of demonstrators gather to commemorate the event. Since reunification, the ceremony has taken on a more neutral and pacifist tone (after being used more politically during the Cold War). Beginning in 1999, white nationalists have organized Neo-Nazi demonstrations in Dresden that have been among the largest in the post-war history of Germany. Each year around the anniversary of the city's destruction, members of the far-right convened in the memory of those who died in the fire-bombing. In 2010, anti-fascists protesters clashed with police in an attempt to prevent the march from taking place. These efforts have been successful in marginalizing the far-right's demonstrations, and have been repeated each year since.
The completion of the reconstructed Dresden Frauenkirche in 2005 marked the first step in rebuilding the Neumarkt area. The areas around the square have been divided into 8 "Quarters", with each being rebuilt as a separate project, the majority of buildings to be rebuilt either to the original structure or at least with a façade similar to the original. Quarter I and the front section of Quarters II, III, IV and V(II) have since been completed, with Quarter VIII currently under construction.
In 2002, torrential rains caused the Elbe to flood 9 m above its normal height, i.e., even higher than the old record height from 1845, damaging many landmarks (See 2002 European flood). The destruction from this "millennium flood" is no longer visible, due to the speed of reconstruction.
The United Nations' cultural organization UNESCO declared the Dresden Elbe Valley to be a World Heritage Site in 2004. After being placed on the list of endangered World Heritage Sites in 2006, the city lost the title in June 2009, due to the construction of the "Waldschlößchenbrücke", making it only the second ever World Heritage Site to be removed from the register. UNESCO stated in 2006 that the bridge would destroy the cultural landscape. The city council's legal moves meant to prevent the bridge from being built failed.
The Dresden Elbe Valley was an internationally recognized site of cultural significance by the UNESCO World Heritage Committee for five years. After being placed on the list of endangered World Heritage Sites in 2006, the city had its status as world heritage site formally removed in June 2009, for the willful breach of the UNESCO World Heritage Convention, due to the construction of a highway bridge across the valley within 2 km of the historic center. It thereby became the first location ever in Europe to lose this status, and the second ever in the world.
Modern Dresen by night
Dresden by day (Brühl's Terrace)
Geography.
Location.
Dresden lies on both banks of the Elbe River, mostly in the Dresden Basin, with the further reaches of the eastern Ore Mountains to the south, the steep slope of the Lusatian granitic crust to the north, and the Elbe Sandstone Mountains to the east at an altitude of about 113 m. Triebenberg is the highest point in Dresden at 384 m.
With a pleasant location and a mild climate on the Elbe, as well as Baroque-style architecture and numerous world-renowned museums and art collections, Dresden has been called "Elbflorenz" (Florence of the Elbe).
The incorporation of neighbouring rural communities over the past 60 years has made Dresden the fourth largest urban district by area in Germany after Berlin, Hamburg, and Cologne.
The nearest German cities are Chemnitz 80 km to the southwest, Leipzig 100 km to the northwest and Berlin 200 km to the north. Prague, Czech Republic is about 150 km to the south and to the east 200 km is the Polish city of Wrocław.
Nature.
Dresden is one of the greenest cities in all of Europe, with 63% of the city being green areas and forests. The Dresden Heath ("Dresdner Heide") to the north is a forest 50 km2 in size. There are four nature reserves. The additional Special Conservation Areas cover 18 km2. The protected gardens, parkways, parks and old graveyards host 110 natural monuments in the city. The Dresden Elbe Valley is a former world heritage site which is focused on the conservation of the cultural landscape in Dresden. One important part of that landscape is the Elbe meadows, which cross the city in a 20 kilometre swath. Saxon Switzerland is an important nearby location.
Climate.
Dresden has an oceanic climate (Cfb), influenced by its inland location, with warm summers and slightly colder winters as compared to the German average. The average temperature in January is 0.1 °C and in July 19.0 °C. The driest months are February, March and April, with precipitation of around 40 mm. The wettest months are July and August, with more than 80 mm per month.
The microclimate in the Elbe valley differs from that on the slopes and in the higher areas. Klotzsche, at 227 metres above sea level, hosts the Dresden weather station. The weather in Klotzsche is 1 to colder than in the inner city.
Flood protection.
Because of its location on the banks of the Elbe, into which some water sources from the Ore Mountains flow, flood protection is important. Large areas are kept free of buildings to provide a flood plain. Two additional trenches, about 50 metres wide, have been built to keep the inner city free of water from the Elbe, by dissipating the water downstream through the inner city's gorge portion. Flood regulation systems like detention basins and water reservoirs are almost all outside the city area.
The Weißeritz, normally a rather small river, suddenly ran directly into the main station of Dresden during the 2002 European floods. This was largely because the river returned to its former route; it had been diverted so that a railway could run along the river bed.
Many locations and areas need to be protected by walls and sheet pilings during floods. A number of districts become waterlogged if the Elbe overflows across some of its former floodplains.
City structuring.
Dresden is a spacious city. Its districts differ in their structure and appearance. Many parts still contain an old village core, while some quarters are almost completely preserved as rural settings. Other characteristic kinds of urban areas are the historic outskirts of the city, and the former suburbs with scattered housing. During the German Democratic Republic, many apartment blocks were built. The original parts of the city are almost all in the districts of Altstadt (Old town) and Neustadt (New town). Growing outside the city walls, the historic outskirts were built in the 18th century. They were planned and constructed on the orders of the Saxon monarchs, which is why the outskirts are often named after sovereigns. From the 19th century the city grew by incorporating other districts. Dresden has been divided into ten districts called "Ortsamtsbereich" and nine former boroughs ("Ortschaften") which have been incorporated.
Demographics.
The population of Dresden grew to 100,000 inhabitants in 1852, making it the third German city to reach that number. The population peaked at 649,252 in 1933, and dropped to 450,000 in 1946 because of World War II, during which large residential areas of the city were destroyed. After large incorporations and city restoration, the population grew to 522,532 again between 1950 and 1983.
Since German reunification, demographic development has been very unsteady. The city has struggled with migration and suburbanization. During the 1990s the population increased to 480,000 because of several incorporations, and decreased to 452,827 in 1998. Between 2000 and 2010, the population grew quickly by more than 45,000 inhabitants (about 9.5%) due to a stabilized economy and re-urbanization. Along with Munich and Potsdam, Dresden is one of the ten fastest-growing cities in Germany, while the population of the surrounding new federal states is still shrinking.
s of 2010[ [update]] the population of the city of Dresden was 523,058, the population of the Dresden agglomeration was 780,561 as of 2008, and as of 2007 the population of the Dresden region, which includes the neighbouring districts of Meißen, Sächsische Schweiz-Osterzgebirge and the western part of the district of Bautzen was 1,143,197. Dresden is one of the few German Cities which has more inhabitants than ever since World War II.
s of 2006[ [update]] about 51.3% of the population was female. s of 2007[ [update]] the mean age of the population was 43 years, which is the lowest among the urban districts in Saxony. s of 31 2013[ [update]] there were 43,707 people with a migration background (8.7% of the city's population), and about half, 25,224 or about 4.7% of all Dresden citizens were foreigners. This percentage is almost the same as in 2006 with 4%.
Governance.
Dresden is one of Germany's 16 political centers and the capital of Saxony. It has institutions of democratic local self-administration that are independent from the capital functions. Some local affairs of Dresden receive national attention.
Dresden hosted some international summits such as the Petersburg Dialogue between Russia and Germany, the European Union's Minister of the Interior conference and the G8 labor ministers conference in recent years.
Municipality and city council.
The city council defines the basic principles of the municipality by decrees and statutes. The council gives orders to the "Bürgermeister" ("Burgomaster" or Mayor) by voting for resolutions and thus has some executive power.
s of 2008[ [update]], there was no stable governing majority on Dresden city council (Stadtrat).
s of 2014[ [update]] the 70 seats of the city council were distributed as follows:
The Supreme Burgomaster is directly elected by the citizens for a term of seven years. Executive functions are normally elected indirectly in Germany. However, the Supreme Burgomaster shares numerous executive rights with the city council. He/She is the executive head of the municipality, and also the ceremonial representative of the city. The main departments of the municipality are managed by seven burgomasters.
Local affairs.
Local affairs in Dresden often center around the urban development of the city and its spaces. Architecture and the design of public places is a controversial subject. Discussions about the Waldschlößchenbrücke, a bridge under construction across the Elbe, received international attention because of its position across the Dresden Elbe Valley World Heritage Site. The city held a public referendum in 2005 on whether to build the bridge, prior to UNESCO expressing doubts about the compatibility between bridge and heritage. Its construction caused loss of World Heritage site status in 2009.
In 2006 Dresden sold its publicly subsidized housing organization, WOBA Dresden GmbH, to the US-based private investment company Fortress Investment Group. The city received 987.1 million euro and paid off its remaining loans, making it the first large city in Germany to become debt-free. Opponents of the sale were concerned about Dresden's loss of control over the subsidized housing market.
Since October 2014, PEGIDA, a xenophobic political movement based in Dresden has been organizing weekly demonstrations against what it perceives as the Islamisation of Europe although the primarily Turkish people Muslims make up only 0.2% of the population of the city. As the number of demonstrators increased to 17,500 on December 22, so has the international media coverage of it.
Twin towns – sister cities.
Along with its twin city Coventry, Dresden was one of the first two cities to twin with a foreign city after World War II. Similar symbolism occurred in 1988, when Dresden twinned with the Dutch city of Rotterdam. The cities became twins after World War II in an act of reconciliation, as they had suffered incisive destructions from bombings. The Coventry Blitz and Rotterdam Blitz bombardments of the German Luftwaffe are also considered to be disproportional. Dresden has had a triangular partnership with Saint Petersburg and Hamburg since 1987. Dresden has 14 twin cities.
 Ostrava, Czech Republic, since 1971
 Strasbourg, France, since 1990
 Salzburg, Austria, since 1991
Culture and architecture.
Carl Maria von Weber and Richard Wagner had a number of their works performed for the first time in Dresden. Other famous artists, such as Ernst Ludwig Kirchner, Otto Dix, Oskar Kokoschka, Richard Strauss, Gottfried Semper and Gret Palucca, were also active in the city. Dresden is also home to several important art collections, world-famous musical ensembles, and significant buildings from various architectural periods, many of which were rebuilt after the destruction of the Second World War.
Entertainment.
The Saxon State Opera descends from the opera company of the former electors and Kings of Saxony. Their first opera house was the Opernhaus am Taschenberg, opened in 1667. The Opernhaus am Zwinger presented opera from 1719 to 1756, when the Seven Years' War began. The later Semperoper was completely destroyed during the bombing of Dresden during the second world war. The opera's reconstruction was completed exactly 40 years later, on 13 February 1985. Its musical ensemble is the "Sächsische Staatskapelle Dresden", founded in 1548. The Dresden State Theatre runs a number of smaller theatres. The Dresden State Operetta is the only independent operetta in Germany. The "Herkuleskeule" (Hercules club) is an important site in German-speaking political cabaret.
There are several choirs in Dresden, the best-known of which is the Dresdner Kreuzchor (Choir of The Holy Cross). It is a boys' choir drawn from pupils of the Kreuzschule, and was founded in the 13th century. The "Dresdner Kapellknaben" are not related to the "Staatskapelle", but to the former "Hofkapelle", the Catholic cathedral, since 1980. The Dresden Philharmonic Orchestra is the orchestra of the city of Dresden.
Throughout the summer, the outdoor concert series "Zwingerkonzerte und Mehr" is held in the "Zwingerhof". Performances include dance and music.
A big event each year in June is the Bunte Republik Neustadt, a culture festival lasting 3 days in the city district of Dresden-Neustadt. Bands play live concerts for free in the streets and people can find all kinds of refreshments and food.
Museums, presentations and collections.
Dresden hosts the "Staatlichen Kunstsammlungen Dresden" (Dresden State Art Collections) which, according to the institution's own statements, place it among the most important museums presently in existence. The art collections consist of twelve museums, of which the "Gemäldegalerie Alte Meister" (Old Masters Gallery) and the "Grünes Gewölbe" (Green Vault)and the "Japanese Palace"(Japanisches Palais)are the most famous. Also known are "Galerie Neue Meister" (New Masters Gallery), "Rüstkammer" (Armoury) with the Turkish Chamber, and the "Museum für Völkerkunde Dresden" (Museum of Ethnology).
Other museums and collections owned by the Free State of Saxony in Dresden are:
The Dresden City Museum is run by the city of Dresden and focused on the city's history. The "Militärhistorisches Museum der Bundeswehr" (Military History Museum) is placed in the former garrison in the Albertstadt.
The book museum of the Saxon State Library presents the famous Dresden Codex.
The "Botanischer Garten Dresden" is a botanical garden in the "Großer Garten" that is maintained by the Dresden University of Technology. Also located in the "Großer Garten" is the Dresden Zoo.
Architecture.
Although Dresden is often said to be a Baroque city, its architecture is influenced by more than one style. Other eras of importance are the Renaissance and Historism, as well as the contemporary styles of Modernism and Postmodernism.
Dresden has some 13 000 listed cultural monuments and eight districts under general preservation orders.
Royal household.
The royal buildings are among the most impressive buildings in Dresden. The Dresden Castle was the seat of the royal household from 1485. The wings of the building have been renewed, built upon and restored many times. Due to this integration of styles, the castle is made up of elements of the Renaissance, Baroque and Classicist styles.
The Zwinger Palace is across the road from the castle. It was built on the old stronghold of the city and was converted to a center for the royal art collections and a place to hold festivals. Its gate by the moat, surmounted by a golden crown, is famous.
Other royal buildings and ensembles:
Sacred buildings.
The Hofkirche was the church of the royal household. Augustus the Strong, who desired to be King of Poland, converted to Catholicism, as Polish kings had to be Catholic. At that time Dresden was strictly Protestant. Augustus the Strong ordered the building of the Hofkirche, the Roman Catholic Cathedral, to establish a sign of Roman Catholic religious importance in Dresden. The church is the cathedral "Sanctissimae Trinitatis" since 1980. The crypt of the Wettin Dynasty is located within the church.
In contrast to the Hofkirche, the Lutheran Frauenkirche was built almost contemporaneously by the citizens of Dresden. It is said to be the greatest cupola building in Central and Northern Europe. The city's historic Kreuzkirche was reconsecrated in 1388.
There are also other churches in Dresden, for example a Russian Orthodox Church in the Südvorstadt district.
Contemporary architecture.
Dresden has been an important site for the development of contemporary architecture for centuries, and this trend has continued into the 20th and 21st centuries.
Historicist buildings made their presence felt on the cityscape until the 1920s sampled by public buildings such as the Staatskanzlei or the City Hall. One of the youngest buildings of that era is the Hygiene Museum, which is designed in an impressively monumental style, but employs plain façades and simple structures. It is often attributed, wrongly, to the Bauhaus school.
Most of the present cityscape of Dresden was built after 1945, a mix of reconstructed or repaired old buildings and new buildings in the modern and postmodern styles. Important buildings erected between 1945 and 1990 are the Centrum-Warenhaus (a large department store) representing the international style, the Kulturpalast, and several smaller and two bigger complexes of Plattenbau housing in Gorbitz, while there is also housing dating from the era of Stalinist architecture.
After 1990 and German reunification, new styles emerged. Important contemporary buildings include the New Synagogue, a postmodern building with few windows, the Transparent Factory, the Saxon State Parliament and the New Terrace, the UFA-Kristallpalast cinema by Coop Himmelb(l)au (one of the biggest buildings of Deconstructivism in Germany), and the Saxon State Library. Daniel Libeskind and Norman Foster both modified existing buildings. Foster roofed the main railway station with translucent Teflon-coated synthetics. Libeskind changed the whole structure of the Bundeswehr Military History Museum Museum by placing a wedge through the historical arsenal building.
Other buildings.
Other buildings include important bridges crossing the Elbe river, the Blaues Wunder bridge and the Augustusbrücke, which is on the site of the oldest bridge in Dresden.
There are about 300 fountains and springs, many of them in parks or squares. The wells serve only a decorative function, since there is a fresh water system in Dresden. Springs and fountains are also elements in contemporary cityspaces.
The most famous sculpture in Dresden is Jean-Joseph Vinache's golden equestrian sculpture of August the Strong called the "Goldener Reiter" (Golden Cavalier) on the Neustädter Markt square. It shows August at the beginning of the Hauptstraße (Main street) on his way to Warsaw, where he was King of Poland in personal union. Another sculpture is the memorial of Martin Luther in front of the Frauenkirche.
Dresden-Hellerau—Germany's first garden city.
The Garden City of Hellerau, at that time a suburb of Dresden, was founded in 1909. In 1911 Heinrich Tessenow built the Hellerau Festspielhaus (festival theatre) and Hellerau became a center of modernism with international standing until the outbreak of World War I.
In 1950, Hellerau was incorporated into the city of Dresden. Today the Hellerau reform architecture is recognized as exemplary. In the 1990s, the garden city of Hellerau became a conservation area.
Living quarters.
Dresden's urban parts are subdivided in rather a lot of city quarters, up to around 100, among them relatively many larger villa quarters dominated by historic multiple dwelling units, especially, but not only along the river, most known are Blasewitz, Loschwitz, Pillnitz and Weißer Hirsch. Also some Art Nouveau living quarters and two bigger quarters typical for communist architecture – but much renovated – can be found. The villa town of Radebeul joins the Dresden city tram system, which is expansive due to the lack of an underground system.
Cinemas and cinematics.
There are several small theaters presenting cult films and low-budget or low-profile films chosen for their cultural value. Dresden also has a few multiplex cinemas, of which the Rundkino is the oldest.
Dresden has been a center for the production of animated films and optical cinematic techniques. 
Sport.
Dresden is home to Dynamo Dresden, which had a tradition in UEFA club competitions up to the early 1990s. Dynamo Dresden won eight titles in the DDR-Oberliga. Currently, the club is a member of the 3rd Liga after some seasons in the Bundesliga and 2. Bundesliga.
In the early 20th century, the city was represented by Dresdner SC, who were one of Germany's most successful clubs in football. Their best performances came during World War II, when they were twice German champions, and twice Cup winners. Dresdner SC is a multisport club. While its football team plays in the sixth-tier Landesliga Sachsen, its volleyball section has a team in the women's Bundesliga. Dresden has a third football team SC Borea Dresden.
ESC Dresdner Eislöwen is an ice hockey club playing in the 2nd Bundesliga again. Dresden Monarchs are an American football team in the German Football League.
Since 1890, horse races have taken place and the Dresdener Rennverein 1890 e.V. are active and one of the big sporting events in Dresden.
Major sporting facilities in Dresden are the Glücksgas Stadium, the Heinz-Steyer-Stadion and the EnergieVerbund Arena for ice hockey.
Infrastructure.
Transport.
The Bundesautobahn 4 (European route E40) crosses Dresden in the northwest from west to east. The Bundesautobahn 17 leaves the A4 in a south-eastern direction. In Dresden it begins to cross the Ore Mountains towards Prague. The Bundesautobahn 13 leaves from the three-point interchange "Dresden-Nord" and goes to Berlin. The A13 and the A17 are on the European route E55. Several Bundesstraße roads crossing or running through Dresden.
There are two main inter-city transit hubs in the railway network in Dresden: Dresden Hauptbahnhof and Dresden-Neustadt railway station. The most important railway lines run to Berlin, Prague, Leipzig and Chemnitz. A commuter train system (Dresden S-Bahn) operates on three lines alongside the long-distance routes.
Dresden Airport is the city's international airport, located at the north-western outskirts of the town. Its infrastructure has been improved with new terminals and a motorway access route.
Dresden has a large tramway network operated by Dresdner Verkehrsbetriebe, the municipal transport company. Because the geological bedrock does not allow the building of underground railways, the tramway is an important form of public transport. The Transport Authority operates twelve lines on a 200 km network. Many of the new low-floor vehicles are up to 45 metres long and produced by Bombardier Transportation in Bautzen. While many of the system's lines are on reserved track (often sown with grass to avoid noise), many tracks still run on the streets, especially in the inner city.
The CarGoTram is a tram that supplies Volkswagen's Transparent Factory, crossing the city. The transparent factory is located not far from the city center next to the city's largest park.
The districts of Loschwitz and Weisser Hirsch are connected by the Dresden Funicular Railway, which was opened on 26 October 1895.
Public utilities.
Dresden is the capital of a German "Land" (federal state). It is home to the Landtag of Saxony and the ministries of the Saxon Government. The controlling Constitutional Court of Saxony is in Leipzig. The highest Saxon court in civil and criminal law, the Higher Regional Court of Saxony, has its home in Dresden.
Most of the Saxon state authorities are located in Dresden. Dresden is home to the Regional Commission of the Dresden Regierungsbezirk, which is a controlling authority for the Saxon Government. It has jurisdiction over eight rural districts, two urban districts and the city of Dresden.
Like many cities in Germany, Dresden is also home to a local court, has a trade corporation and a Chamber of Industry and Trade and many subsidiaries of federal agencies (such as the Federal Labour Office or the Federal Agency for Technical Relief). It hosts some divisions of the German Customs and the eastern Federal Waterways Directorate.
Dresden is home to a military subdistrict command, but no longer has large military units as it did in the past. Dresden is the traditional location for army officer schooling in Germany, today carried out in the Offizierschule des Heeres.
Economy.
Until famous enterprises like Dresdner Bank left Dresden in the communist era to avoid nationalisation, Dresden was one of the most important German cities, an important industrial center of the German Democratic Republic. The period of the GDR until 1990 was characterized by low economic growth in comparison to western German cities. 
In 1990 Dresden had to struggle with the economic collapse of the Soviet Union and the other export markets in Eastern Europe. After reunification enterprises and production sites broke down almost completely as they entered the social market economy, facing competition from the Federal Republic of Germany. After 1990 a completely new legal system and currency system was introduced and infrastructure was largely rebuilt with funds from the Federal Republic of Germany. Dresden as a major urban center has developed much faster and more consistently than most other regions in the former German Democratic Republic, but it still faces many social and economic problems stemming from the collapse of the former system, including high unemployment levels. 
Between 1990 and 2010 the unemployment rate fluctuated between 13% and 15% and is still relatively high, with a low of 8.9% in May 2012. Dresden has raised its GDP per capita to 31,100 euro, close to the GDP per capita of some West German communities (the average of the 50 biggest cities is around 35,000 euro).
Thanks to the presence of public administration centers, a high density of semi-public research institutes and an extension of publicly funded high technology sectors, the proportion of highly qualified workers Dresden is again among the highest in Germany and by European criteria. Dresden regularly ranks among the best ten bigger cities in Germany to live in. 
Enterprises.
Three major sectors dominate Dresden's economy:
Silicon Saxony Saxony's semiconductor industry was built up in 1969. Major enterprises today are AMD's spin-off GLOBALFOUNDRIES, Infineon Technologies, ZMDI and Toppan Photomasks. Their factories attract many suppliers of material and cleanroom technology enterprises to Dresden.
The pharmaceutical sector developed at the end of the 19th century. The 'Sächsisches Serumwerk Dresden' (Saxon Serum Plant, Dresden), owned by GlaxoSmithKline, is a global leader in vaccine production. Another traditional pharmaceuticals producer is Arzneimittelwerke Dresden (Pharmaceutical Works, Dresden).
A third traditional branch is that of mechanical and electrical engineering. Major employers are the Volkswagen Transparent Factory, EADS Elbe Flugzeugwerke (Elbe Aircraft Works), Siemens and Linde-KCA-Dresden. The tourism industry enjoys high revenue and supports many employees. There are around one hundred bigger hotels in Dresden, many of which cater in the upscale range. Dresden still has a shortage of corporate headquarters.
Media.
The media sector is not particularly strong in Dresden. Recently it sometimes benefits from the new interface with informatics so that it can gain transregional meaning beyond the semi-public science and upper culture sectors which often produce their media coverage in-house. The media in Dresden include two major newspapers of regional record: the "Sächsische Zeitung" ("Saxonian Newspaper", circulation around 300,000) and the "Dresdner Neueste Nachrichten" ("Dresden's Latest News", circulation around 50,000). Dresden has a broadcasting center belonging to the Mitteldeutscher Rundfunk. The "Dresdner Druck- und Verlagshaus" (Dresden printing plant and publishing house) produces part of Spiegel's print run, among other newspapers and magazines.
Education and science.
Universities.
Dresden is home to a number of renowned universities, but among German cities it is a more recent location for academic education.
Other universities include the "Hochschule für Kirchenmusik", a school specialising in church music, the "Evangelische Hochschule für Sozialarbeit", an education institution for social work. The "Dresden International University" is a private postgraduate university, founded a few years ago in cooperation with the Dresden University of Technology.
Research institutes.
Dresden hosts many research institutes, some of which have gained an international standing. The domains of most importance are micro- and nanoelectronics, transport and infrastructure systems, material and photonic technology, and bio-engineering. The institutes are well connected among one other as well as with the academic education institutions.
Helmholtz-Zentrum Dresden-Rossendorf is the largest complex of research facilities in Dresden, a short distance outside the urban areas. It focuses on nuclear medicine and physics. As part of the Helmholtz Association it is one of the German Big Science research centers.
The Max Planck Society focuses on fundamental research. In Dresden there are three Max Planck Institutes (MPI); the "MPI of Molecular Cell Biology and Genetics", the "MPI for Chemical Physics of Solids" and the "MPI for the Physics of Complex Systems".
The Fraunhofer Society hosts institutes of applied research that also offer mission-oriented research to enterprises. With eleven institutions or parts of institutes, Dresden is the largest location of the Fraunhofer Society worldwide. The Fraunhofer Society has become an important factor in location decisions and is seen as a useful part of the "knowledge infrastructure".
The Leibniz Community is a union of institutes with science covering fundamental research and applied research. In Dresden there are three Leibniz Institutes. The "Leibniz Institute of Polymer Research" and the "Leibniz Institute for Solid State and Materials Research" are both in the material and high-technology domain, while the "Leibniz Institute for Ecological and Regional Development" is focused on more fundamental research into urban planning. Helmholtz-Zentrum Dresden-Rossendorf was member of the Leibniz Community until the end of 2010.
Higher secondary education.
Dresden has 21 Gymnasien which prepare for a tertiary education, five of which are private. The "Sächsisches Landesgymnasium für Musik" with a focus on music is supported by the State of Saxony, rather than by the city. There are some "Berufliche Gymnasien" which combine vocational education and secondary education and a "Abendgymnasium" which prepares higher education of adults avocational.

</doc>
<doc id="37411" url="http://en.wikipedia.org/wiki?curid=37411" title="Alkaline earth metal">
Alkaline earth metal

The alkaline earth metals are a group of chemical elements in the periodic table with very similar properties. They are all shiny, silvery-white, somewhat reactive metals at standard temperature and pressure and readily lose their two outermost electrons to form cations with charge 2+ and an oxidation state, or oxidation number of +2. In the modern IUPAC nomenclature, the alkaline earth metals comprise the group 2 elements.
The alkaline earth metals are beryllium (Be), magnesium (Mg), calcium (Ca), strontium (Sr), barium (Ba), and radium (Ra). This group lies in the s-block of the periodic table as all alkaline earth metals have their outermost electron in an s-orbital.
All the discovered alkaline earth metals occur in nature. Experiments have been conducted to attempt the synthesis of element 120, which is likely to be the next member of the group, but they have all met with failure. However, element 120 may not be an alkaline earth metal due to relativistic effects, which are predicted to have a large influence on the chemical properties of superheavy elements.
Characteristics.
Chemical.
As with other groups, the members of this family show patterns in their electronic configuration, especially the outermost shells, resulting in trends in chemical behavior:
Most of the chemistry has been observed only for the first five members of the group. The chemistry of radium is not well-established due to its radioactivity; thus, the presentation of its properties here is limited.
The alkaline earth metals are all silver-colored and soft, and have relatively low densities, melting points, and boiling points. In chemical terms, all of the alkaline metals react with the halogens to form the alkaline earth metal halides, all of which being ionic crystalline compounds (except for beryllium chloride, which is covalent). All the alkaline earth metals except beryllium also react with water to form strongly alkaline hydroxides and, thus, should be handled with great care. The heavier alkaline earth metals react more vigorously than the lighter ones. The alkaline metals have the second-lowest first ionization energies in their respective periods of the periodic table because of their somewhat low effective nuclear charges and the ability to attain a full outer shell configuration by losing just two electrons. The second ionization energy of all of the alkaline metals is also somewhat low.
Beryllium is an exception: It does not react with water or steam, and its halides are covalent. If beryllium did form compounds with an ionization state of +2, it would polarize electron clouds that are near it very strongly and would cause extensive orbital overlap, since beryllium has a high charge density. All compounds that include beryllium have a covalent bond. Even the compound beryllium fluoride, which is the most ionic beryllium compound, has a low melting point and a low electrical conductivity when melted.
All the alkaline earth metals have two electrons in their valence shell, so the energetically preferred state of achieving a filled electron shell is to lose two electrons to form doubly charged positive ions.
Compounds and reactions.
The alkaline earth metals all react with the halogens to form ionic halides, such as calcium chloride (CaCl2), as well as reacting with oxygen to form oxides such as strontium oxide (SrO). Calcium, strontium, and barium react with water to produce hydrogen gas and their respective hydroxides, and also undergo transmetalation reactions to exchange ligands.
Physical and atomic.
The table below is a summary of the key physical and atomic properties of the alkaline earth metals.
Nuclear stability.
All of the alkaline earth metals except magnesium and strontium have at least one naturally occurring radioisotope: beryllium-7, beryllium-10, and calcium-41 are trace radioisotopes, calcium-48 and barium-130 have very long half-lives and, thus, occur naturally, and all isotopes of radium are radioactive. Calcium-48 is the lightest nuclide to undergo double beta decay.
The natural radioisotope of calcium, calcium-48, makes up about 0.1874% of natural calcium, and, thus, natural calcium is weakly radioactive. Barium-130 makes up approximately 0.1062% of natural barium, and, thus, barium is weakly radioactive, as well.
History.
Etymology.
The alkaline earth metals are named after their oxides, the "alkaline earths", whose old-fashioned names were beryllia, magnesia, lime, strontia, and baryta. These oxides are basic (alkaline) when combined with water. "Earth" is an old term applied by early chemists to nonmetallic substances that are insoluble in water and resistant to heating—properties shared by these oxides. The realization that these earths were not elements but compounds is attributed to the chemist Antoine Lavoisier. In his "Traité Élémentaire de Chimie" ("Elements of Chemistry") of 1789 he called them salt-forming earth elements. Later, he suggested that the alkaline earths might be metal oxides, but admitted that this was mere conjecture. In 1808, acting on Lavoisier's idea, Humphry Davy became the first to obtain samples of the metals by electrolysis of their molten earths, thus supporting Lavoisier's hypothesis and causing the group to be named the "alkaline earth metals".
Discovery.
The calcium compounds calcite and lime have been known and used since prehistoric times. The same is true for the beryllium compounds beryl and emerald. The other compounds of the alkaline earth metals were discovered starting in the early 15th century. The magnesium compound magnesium sulfate was first discovered in 1618 by a farmer at Epsom in England. Strontium carbonate was discovered in minerals in the Scottish village of Strontian in 1790. The last element is the least abundant: radioactive radium, which was extracted from uraninite in 1898.
All elements except beryllium were isolated by electrolysis of molten compounds. Magnesium, calcium, and strontium were first produced by Humphry Davy in 1808, whereas beryllium was independently isolated by Friedrich Wöhler and Antoine Bussy in 1828 by reacting beryllium compounds with potassium. In 1910, radium was isolated as a pure metal by Curie and André-Louis Debierne also by electrolysis.
Beryllium.
Beryl, a mineral that contains beryllium, has been known since the time of the Ptolemaic dynasty in Egypt. Although it was originally thought that beryl was an aluminium silicate, beryl was later found to contain a then-unknown element when, in 1797, Louis-Nicolas Vauquelin dissolved aluminium hydroxide from beryl in an alkali. In 1828, Friedrich Wöhler and Antoine Bussy independently isolated this new element, beryllium, by the same method, which involved a reaction of beryllium chloride with metallic potassium; this reaction was not able to produce large ingots of beryllium. It was not until 1898, when Paul Lebeau performed an electrolysis of a mixture of beryllium fluoride and sodium fluoride, that large pure samples of beryllium were produced.
Magnesium.
Magnesium was first produced by Sir Humphry Davy in England in 1808 using electrolysis of a mixture of magnesia and mercuric oxide. Antoine Bussy prepared it in coherent form in 1831. Davy’s first suggestion for a name was magnium, but the name magnesium is now used.
Calcium.
Lime has been used as a material for building since 7000 to 14,000 BCE, and kilns used for lime have been dated to 2,500 BCE in Khafaja, Mesopotamia. Calcium as a material has been known since at least the first century, as the ancient Romans were known to have used calcium oxide by preparing it from lime. Calcium sulfate has been known to be able to set broken bones since the tenth century. Calcium itself, however, was not isolated until 1808, when Humphry Davy, in England, used electrolysis on a mixture of lime and mercuric oxide, after hearing that Jöns Jakob Berzelius had prepared a calcium amalgam from the electrolysis of lime in mercury.
Strontium.
In 1790, physician Adair Crawford, who had been working with barium, realized that Strontian ores showed different properties than other supposed ores of barium. Therefore, he concluded that these ores contained new minerals, which were named "strontites" in 1793 by Thomas Charles Hope, a chemistry professor at the University of Glasgow, who confirmed Crawford's discovery. Strontium was eventually isolated in 1808 by Sir Humphry Davy by electrolysis of a mixture of strontium chloride and mercuric oxide. The discovery was announced by Davy on 30 June 1808 at a lecture to the Royal Society.
Barium.
Barite, a mineral containing barium, was first recognized as containing a new element in 1774 by Carl Scheele, although he was able to isolate only barium oxide. Barium oxide was isolated again two years later by Johan Gottlieb Gahn. Later in the 18th century, William Withering noticed a heavy mineral in the Cumberland lead mines, which are now known to contain barium. Barium itself was finally isolated in 1808 when Sir Humphry Davy used electrolysis with molten salts, and Davy named the element "barium", after baryta. Later, Robert Bunsen and Augustus Matthiessen isolated pure barium by electrolysis of a mixture of barium chloride and ammonium chloride.
Radium.
While studying uraninite, on 21 December 1898, Marie and Pierre Curie discovered that, even after uranium had decayed, the material created was still radioactive. The material behaved somewhat similarly to barium compounds, although some properties, such as the color of the flame test and spectral lines, were much different. They announced the discovery of a new element on 26 December 1898 to the French Academy of Sciences. Radium was named in 1899 from the word "radius", meaning "ray", as radium emitted power in the form of rays.
Occurrence.
Beryllium occurs in the earth's crust at a concentration of two to six parts per million (ppm), much of which is in soils, where it has a concentration of six ppm. Beryllium is one of the rarest elements in seawater, even rarer than elements such as scandium, with a concentration of 0.2 parts per trillion. However, in freshwater, beryllium is somewhat more common, with a concentration of 0.1 parts per billion.
Magnesium and calcium are very common in the earth's crust, with calcium the fifth-most-abundant element, and magnesium the eighth. None of the alkaline earth metals are found in their elemental state, but magnesium and calcium are found in many rocks and minerals: magnesium in carnellite, magnesite, and dolomite; and calcium in chalk, limestone, gypsum, and anhydrite.
Strontium is the fifteenth-most-abundant element in the Earth's crust. Most strontium is found in the minerals celestite and strontianite. Barium is slightly less common, much of it in the mineral barite.
Radium, being a decay product of uranium, is found in all uranium-bearing ores. Due to its relatively short half-life, radium from the Earth's early history has decayed, and present-day samples have all come from the much slower decay of uranium.
Production.
Most beryllium is extracted from beryllium hydroxide. One production method is sintering, done by mixing beryl, sodium fluorosilicate, and soda at high temperatures to form sodium fluoroberyllate, aluminium oxide, and silicon dioxide. A solution of sodium fluoroberyllate and sodium hydroxide in water is then used to form beryllium hydroxide by precipitation. Alternatively, in the melt method, powdered beryl is heated to high temperature, cooled with water, then heated again slightly in sulfuric acid, eventually yielding beryllium hydroxide. The beryllium hydroxide from either method then produces beryllium fluoride and beryllium chloride through a somewhat long process. Electrolysis or heating of these compounds can then produce beryllium.
In general, strontium carbonate is extracted from the mineral celestite through two methods: by leaching the celestite with sodium carbonate, or in a more complicated way involving coal.
To produce barium, barite ore is separated from quartz, sometimes by froth flotation methods, resulting in relatively pure barite. Carbon is then used to reduce the baryte into barium sulfide, which is dissolved with other elements to form other compounds, such as barium nitrate. These in turn are thermally decompressed into barium oxide, which eventually yields pure barium after a reaction with aluminium. The most important supplier of barium is China, which produces more than 50% of world supply.
Applications.
Beryllium is used mostly for military applications, but there are other uses of beryllium, as well. In electronics, beryllium is used as a p-type dopant in some semiconductors, and beryllium oxide is used as a high-strength electrical insulator and heat conductor. Due to its light weight and other properties, beryllium is also used in mechanics when stiffness, light weight, and dimensional stability are required at wide temperature ranges.
Magnesium has many different uses. One of its most common uses was in industry, where it has many structural advantages over other materials such as aluminium, although this usage has fallen out of favor recently due to magnesium's flammability. Magnesium is also often alloyed with aluminium or zinc to form materials with more desirable properties than any pure metal. Magnesium has many other uses in industrial applications, such as having a role in the production of iron and steel, and the production of titanium.
Calcium also has many uses. One of its uses is as a reducing agent in the separation of other metals from ore, such as uranium. It is also used in the production of the alloys of many metals, such as aluminium and copper alloys, and is also used to deoxidize alloys as well. Calcium also has a role in the making of cheese, mortars, and cement.
Strontium and barium do not have as many applications as the lighter alkaline earth metals, but still have uses. Strontium carbonate is often used in the manufacturing of red fireworks, and pure strontium is used in the study of neurotransmitter release in neurons. Barium has some use in vacuum tubes to remove gases, and barium sulfate has many uses in the petroleum industry, as well as other industries.
Due to its radioactivity, radium no longer has many applications, but it used to have many. Radium used to be used often in luminous paints, although this use was stopped after workers got sick. As people used to think that radioactivity was a good thing, radium used to be added to drinking water, toothpaste, and many other products, although they are also not used anymore due to their health effects. Radium is no longer even used for its radioactive properties, as there are more powerful and safer emitters than radium.
Biological role and precautions.
Magnesium and calcium are ubiquitous and essential to all known living organisms. They are involved in more than one role, with, for example, magnesium or calcium ion pumps playing a role in some cellular processes, magnesium functioning as the active center in some enzymes, and calcium salts taking a structural role, most notably in bones.
Strontium plays an important role in marine aquatic life, especially hard corals, which use strontium to build their exoskeletons. It and barium have some uses in medicine, for example "barium meals" in radiographic imaging, whilst strontium compounds are employed in some toothpastes. Excessive amounts of strontium-90 are toxic due to its radioactivity and strontium-90 mimics calcium and then can kill.
Beryllium and radium, however, are toxic. Beryllium's low aqueous solubility means it is rarely available to biological systems; it has no known role in living organisms and, when encountered by them, is usually highly toxic. Radium has a low availability and is highly radioactive, making it toxic to life.
Extensions.
The next alkaline earth metal after radium is thought to be element 120, although this may not be true due to relativistic effects. The synthesis of element 120 was first attempted in March 2007, when a team at the Flerov Laboratory of Nuclear Reactions in Dubna bombarded plutonium-244 with iron-58 ions; however, no atoms were produced, leading to a limit of 400 fb for the cross-section at the energy studied. In April 2007, a team at the GSI attempted to create element 120 by bombarding uranium-238 with nickel-64, although no atoms were detected, leading to a limit of 1.6 pb for the reaction. Synthesis was again attempted at higher sensitivities, although no atoms were detected. Other reactions have been tried, although all have been met with failure.
The chemistry of element 120 is predicted to be closer to that of calcium or strontium instead of barium or radium. This is unusual as periodic trends would predict element 120 to be more reactive than barium and radium. This lowered reactivity is due to the expected energies of element 120's valence electrons, increasing element 120's ionization energy and decreasing the metallic and ionic radii.

</doc>
<doc id="37412" url="http://en.wikipedia.org/wiki?curid=37412" title="Gold standard">
Gold standard

A gold standard is a monetary system in which the standard economic unit of account is based on a fixed quantity of gold. Three types can be distinguished: specie, exchange, and bullion. 
Most nations abandoned the gold standard as the basis of their monetary systems at some point in the 20th century, although many hold substantial gold reserves.
An estimated total of 174,100 tonnes of gold have been mined in human history, according to GFMS as of 2012. This is roughly equivalent to 5.6 billion troy ounces or, in terms of volume, about 9261 m3, or a cube 21 m on a side. There are varying estimates on the total volume of gold mined, one of the reason being gold has been mined for over thousands of years. Another reason is that some nations are not particularly open about how much gold is being mined. In addition, it is difficult to account for gold output in illegal mining activities.
World production for 2011 was at 2,700 tonnes. Since the 1950s, annual gold output growth has approximately kept pace with world population growth of around 2x, although far less than world economic growth of some 8x, or some 4x since 1980.
History.
Origin.
The gold specie standard arose from the widespread acceptance of gold as currency. Various commodities have been used as money; typically, the one that loses the least value over time becomes the accepted form. The use of gold as money began thousands of years ago in Asia Minor.
During the early and high Middle Ages, the Byzantine gold solidus, commonly known as the bezant, was used widely throughout Europe and the Mediterranean. However, as the Byzantine Empire's economic influence declined, so too did the use of the bezant. In its place, European territories chose silver as its currency over gold, leading to the development of silver standards.
Silver pennies based on the Roman denarius became the staple coin of Mercia in Great Britain around the time of King Offa, circa CE 757–796. Similar coins, including Italian denari, French deniers, and Spanish dineros circulated in Europe. Spanish explorers discovered silver deposits in Mexico in 1522 and at Potosí in Bolivia in 1545. International trade came to depend on coins such as the Spanish dollar, the Maria Theresa thaler, and later, the United States trade dollar.
In modern times, the British West Indies was one of the first regions to adopt a gold specie standard. Following Queen Anne's proclamation of 1704, the British West Indies gold standard was a "de facto" gold standard based on the Spanish gold doubloon. In 1717, Sir Isaac Newton, the master of the Royal Mint, established a new mint ratio between silver and gold that had the effect of driving silver out of circulation and putting Britain on a gold standard.
A formal gold specie standard was first established in 1821, when Britain adopted it following the introduction of the gold sovereign by the new Royal Mint at Tower Hill in 1816. The United Province of Canada in 1853, Newfoundland in 1865, and the United States and Germany ("de jure") in 1873 adopted gold. The United States used the eagle as its unit, Germany introduced the new gold mark, while Canada adopted a dual system based on both the American gold eagle and the British gold sovereign.
Australia and New Zealand adopted the British gold standard, as did the British West Indies, while Newfoundland was the only British Empire territory to introduce its own gold coin. Royal Mint branches were established in Sydney, Melbourne and Perth for the purpose of minting gold sovereigns from Australia's rich gold deposits.
The gold specie standard came to an end in the United Kingdom and the rest of the British Empire with the outbreak of World War I.
Silver.
From 1750 to 1870, wars within Europe as well as an ongoing trade deficit with China (which sold to Europe but had little use for European goods) drained silver from the economies of Western Europe and the United States. Coins were struck in smaller and smaller numbers, and there was a proliferation of bank and stock notes used as money.
United Kingdom.
In the 1790s, the United Kingdom suffered a silver shortage. It ceased to mint larger silver coins and instead issued "token" silver coins and overstruck foreign coins. With the end of the Napoleonic Wars, the Bank of England began the massive recoinage programme that created standard gold sovereigns, circulating crowns, half-crowns and eventually copper farthings in 1821. The recoinage of silver after a long drought produced a burst of coins. The United Kingdom struck nearly 40 million shillings between 1816 and 1820, 17 million half crowns and 1.3 million silver crowns.
The 1819 Act for the Resumption of Cash Payments set 1823 as the date for resumption of convertibility, which was reached by 1821. Throughout the 1820s, small notes were issued by regional banks. This was restricted in 1826, while the Bank of England was allowed to set up regional branches. In 1833 however, Bank of England notes were made legal tender and redemption by other banks was discouraged. In 1844, the Bank Charter Act established that Bank of England notes were fully backed by gold and they became the legal standard. According to the strict interpretation of the gold standard, this 1844 act marked the establishment of a full gold standard for British money.
United States.
In the 1780s, Thomas Jefferson, Robert Morris and Alexander Hamilton recommended to Congress the value of a decimal system. This system would also apply to monies in the United States. The question was what type of standard: gold, silver or both. The United States adopted a silver standard based on the Spanish milled dollar in 1785.
International.
From 1860 to 1871 various attempts to resurrect bi-metallic standards were made, including one based on the gold and silver franc; however, with the rapid influx of silver from new deposits, the expectation of scarce silver ended.
The interaction between central banking and currency basis formed the primary source of monetary instability during this period. The combination of a restricted supply of notes, a government monopoly on note issuance and indirectly, a central bank and a single unit of value produced economic stability. Deviation from these conditions produced monetary crises.
Devalued notes or leaving silver as a store of value caused economic problems. Governments, demanding specie as payment, could drain the money out of the economy. Economic development expanded need for credit. The need for a solid basis in monetary affairs produced a rapid acceptance of the gold standard in the period that followed.
Japan.
Following Germany's decision after the 1870–1871 Franco-Prussian War to extract reparations to facilitate a move to the gold standard, Japan gained the needed reserves after the Sino-Japanese War of 1894–1895. For Japan, moving to gold was considered vital for gaining access to Western capital markets.
Bimetallic standard.
US: Pre-Civil War.
In 1792, Congress passed the Mint and Coinage Act. It authorized the Federal Government's use of the Bank of the United States to hold its reserves, as well as establish a fixed ratio of gold to the U.S. dollar. Gold and silver coins were legal tender, as was the Spanish Real. In 1792 the market price of gold was about 15 times that of silver. Silver coins left circulation, exported to pay for the debts taken on to finance the American Revolutionary War. In 1806 President Jefferson suspended the minting of silver coins. This resulted in a derivative silver standard, since the Bank of the United States was not required to fully back its currency with reserves. This began a long series of attempts by the United States to create a bi-metallic standard.
The intention was to use gold for large denominations, and silver for smaller denominations. A problem with bimetallic standards was that the metals' absolute and relative market prices changed. The mint ratio (the rate at which the mint was obligated to pay/receive for gold relative to silver) remained fixed at 15 ounces of silver to 1 ounce of gold, whereas the market rate fluctuated from 15.5 to 1 to 16 to 1. With the Coinage Act of 1834, Congress passed an act that changed the mint ratio to approximately 16 to 1. Gold discoveries in California in 1848 and later in Australia lowered the gold price to fall relative to silver; this drove silver money from circulation because it was worth more in the market than as money. Passage of the Independent Treasury Act of 1848 placed the U.S. on a strict hard-money standard. Doing business with the American government required gold or silver coins.
Government accounts were legally separated from the banking system. However, the mint ratio (the fixed exchange rate between gold and silver at the mint) continued to overvalue gold. In 1853, the US reduced the silver weight of coins to keep them in circulation and in 1857 removed legal tender status from foreign coinage. In 1857 the final crisis of the free banking era began as American banks suspended payment in silver, with ripples through the developing international financial system. Due to the inflationary finance measures undertaken to help pay for the US Civil War, the government found it difficult to pay its obligations in gold or silver and suspended payments of obligations not legally specified in specie (gold bonds); this led banks to suspend the conversion of bank liabilities (bank notes and deposits) into specie. In 1862 paper money was made legal tender. It was a fiat money (not convertible on demand at a fixed rate into specie). These notes came to be called "greenbacks".
US: Post-Civil War.
After the Civil War, Congress wanted to reestablish the metallic standard at pre-war rates. The market price of gold in greenbacks was above the pre-War fixed price ($20.67 per ounce of gold) requiring deflation to achieve the pre-War price. This was accomplished by growing the stock of money less rapidly than real output. By 1879 the market price matched the mint price of gold ($20.67 per ounce). The coinage act of 1873 (also known as the Crime of ‘73) demonetized silver. This act removed the 412.5 grain silver dollar from circulation. Subsequently silver was only used in coins worth less than $1 (fractional currency). With the resumption of convertibility on June 30, 1879 the government again paid its debts in gold, accepted greenbacks for customs and redeemed greenbacks on demand in gold. Greenbacks were therefore perfect substitutes for gold coins. During the latter part of the nineteenth century the use of silver and a return to the bimetallic standard were recurrent political issues, raised especially by William Jennings Bryan, the People's Party and the Free Silver movement . In 1900 the gold dollar was declared the standard unit of account and a gold reserve for government issued paper notes was established. Greenbacks, silver certificates, and silver dollars continued to be legal tender, all redeemable in gold.
Fluctuations in the US gold stock, 1862–1877.
The US had a gold stock of 1.9 million ounces (59 t) in 1862. Stocks rose to 2.6 (81 t) in 1866, declined in 1875 to 1.6 million ounces (50 t) and rose to 2.5 million (78 t) in 1878. Net exports did not mirror that pattern. In the decade before the Civil War net exports were roughly constant; postwar they varied erratically around pre-war levels, but fell significantly in 1877 and became negative in 1878 and 1879. The net import of gold meant that the foreign demand for American currency to purchase goods, services, and investments exceeded the corresponding American demands for foreign currencies. In the final years of the greenback period (1862–1879), gold production increased while gold exports decreased. The decrease in gold exports was considered by some to be a result of changing monetary conditions. The demands for gold during this period were as a speculative vehicle, and for its primary use in the foreign exchange markets financing international trade. The major effect of the increase in gold demand by the public and Treasury was to reduce exports of gold and increase the Greenback price of gold relative to purchasing power.
Gold exchange standard.
Towards the end of the 19th century, some silver standard countries began to peg their silver coin units to the gold standards of the United Kingdom or the US. In 1898, British India pegged the silver rupee to the pound sterling at a fixed rate of 1s 4d, while in 1906, the Straits Settlements adopted a gold exchange standard against sterling, fixing the silver Straits dollar at 2s 4d.
Around the start of the 20th century, the Philippines pegged the silver peso/dollar to the U.S. dollar at 50 cents. This move was assisted by the passage of the Philippines Coinage Act by the United States Congress on March 3, 1903. Around the same time Mexico and Japan pegged their currencies to the dollar. When Siam adopted a gold exchange standard in 1908, only China and Hong Kong remained on the silver standard.
When adopting the gold standard, many European nations changed the name of their currency from Daler (Sweden and Denmark) or Gulden (Austria-Hungary) to Crown, since the former names were traditionally associated with silver coins and the latter with gold coins.
Impact of World War I.
Governments with insufficient tax revenue suspended convertibility repeatedly in the 19th century. The real test, however, came in the form of World War I, a test which "it failed utterly" according to economist Richard Lipsey.
By the end of 1913, the classical gold standard was at its peak but World War I caused many countries to suspend or abandon it. According to Lawrence Officer the main cause of the gold standard’s failure to resume its previous position after World War 1 was “the Bank of England's precarious liquidity position and the gold-exchange standard.” A run on sterling caused Britain to impose exchange controls that fatally weakened the standard; convertibility was not legally suspended, but gold prices no longer played the role that they did before. In financing the war and abandoning gold, many of the belligerents suffered drastic inflations. Price levels doubled in the US and Britain, tripled in France and quadrupled in Italy. Exchange rates change less, even though European inflations were more severe than America’s. This meant that the costs of American goods decreased relative to those in Europe. Between August 1914 and spring of 1915, the dollar value of US exports tripled and its trade surplus exceeded $1 billion for the first time. 
Ultimately, the system could not deal quickly enough with the large balance of payments deficits and surpluses; this was previously attributed to downward wage rigidity brought about by the advent of unionized labor, but is now considered as an inherent fault of the system that arose under the pressures of war and rapid technological change. In any case, prices had not reached equilibrium by the time of the Great Depression, which served to kill off the system completely.
For example, Germany had gone off the gold standard in 1914, and could not effectively return to it because War reparations had cost it much of its gold reserves. During the Occupation of the Ruhr the German central bank (Reichsbank) issued enormous sums of non-convertible marks to support workers who were on strike against the French occupation and to buy foreign currency for reparations; this led to the German hyperinflation of the early 1920s and the decimation of the German middle class.
The US did not suspend the gold standard during the war. The newly created Federal Reserve intervened in currency markets and sold bonds to “sterilize” some of the gold imports that would have otherwise increased the stock of money. By 1927 many countries had returned to the gold standard. As a result of World War 1 the United States, which had been a net debtor country, had become a net creditor by 1919.
Gold bullion replaces gold specie as standard.
The gold specie standard ended in the United Kingdom and the rest of the British Empire at the outbreak of World War I. Treasury notes replaced the circulation of gold sovereigns and gold half sovereigns. Legally, the gold specie standard was not repealed. The end of the gold standard was successfully effected by the Bank of England through appeals to patriotism urging citizens not to redeem paper money for gold specie. It was only in 1925, when Britain returned to the gold standard in conjunction with Australia and South Africa that the gold specie standard was officially ended.
The British Gold Standard Act 1925 both introduced the gold bullion standard and simultaneously repealed the gold specie standard. The new standard ended the circulation of gold specie coins. Instead, the law compelled the authorities to sell gold bullion on demand at a fixed price, but only in the form of bars containing approximately four hundred troy ounces (12 kg) of fine gold. John Maynard Keynes argued against the deflationary dangers of resuming the gold standard.
Many other countries followed Britain in returning to the gold standard, this was followed by a period of relative stability but also deflation. This state of affairs lasted until the Great Depression (1929–1939) forced countries off the gold standard. In September 19, 1931, speculative attacks on the pound forced Britain to abandon the gold standard. Loans from American and French Central Banks of £50,000,000 were insufficient and exhausted in a matter of weeks, due to large gold outflows across the Atlantic. The British benefited from this departure. They could now use monetary policy to stimulate the economy. Australia and New Zealand had already left the standard and Canada quickly followed suit.
The interwar partially backed gold standard was inherently unstable, because of the conflict between the expansion of liabilities to foreign central banks and the resulting deterioration in the Bank of England's reserve ratio. France was then attempting to make Paris a world class financial center, and it received large gold flows as well.
In May 1931 a run on Austria's largest commercial bank caused it to fail. The run spread to Germany, where the central bank also collapsed. International financial assistance was too late and in July 1931 Germany adopted exchange controls, followed by Austria in October. The Austrian and German experiences, as well as British budgetary and political difficulties, were among the factors that destroyed confidence in sterling, which occurred in mid-July 1931. Runs ensued and the Bank of England lost much of its reserves.
Depression and World War II.
Great Depression.
Some economic historians, such as Barry Eichengreen, blame the gold standard of the 1920s for prolonging the economic depression which started in 1929 and lasted for about a decade. Adherence to the gold standard prevented the Federal Reserve from expanding the money supply to stimulate the economy, fund insolvent banks and fund government deficits that could "prime the pump" for an expansion. Once off the gold standard, it became free to engage in such money creation. The gold standard limited the flexibility of the central banks' monetary policy by limiting their ability to expand the money supply. In the US, the Federal Reserve was required by law to have gold backing 40% of its demand notes. Others including former Federal Reserve Chairman Ben Bernanke and Nobel Prize-winner Milton Friedman place the blame for the severity and length of the Great Depression at the feet of the Federal Reserve, mostly due to the deliberate tightening of monetary policy even after the gold standard. They blamed the US major economic contraction in 1937 on tightening of monetary policy resulting in higher cost of capital, weaker securities markets, reduced net government contribution to income, the undistributed profits tax and higher labor costs. The money supply peaked in March 1937, with a trough in May 1938.
Higher interest rates intensified the deflationary pressure on the dollar and reduced investment in U.S. banks. Commercial banks converted Federal Reserve Notes to gold in 1931, reducing its gold reserves and forcing a corresponding reduction in the amount of currency in circulation. This speculative attack created a panic in the U.S. banking system. Fearing imminent devaluation many depositors withdrew funds from U.S. banks. As bank runs grew, a reverse multiplier effect caused a contraction in the money supply. Additionally the New York Fed had loaned over $150 million in gold (over 240 tons) to European Central Banks. This transfer contracted the US money supply. The foreign loans became questionable once Britain, Germany, Austria and other European countries went off the gold standard in 1931 and weakened confidence in the dollar.
The forced contraction of the money supply resulted in deflation. Even as nominal interest rates dropped, inflation-adjusted real interest rates remained high, rewarding those who held onto money instead of spending it, further slowing the economy. Recovery in the United States was slower than in Britain, in part due to Congressional reluctance to abandon the gold standard and float the U.S. currency as Britain had done.
In the early 1930s, the Federal Reserve defended the dollar by raising interest rates, trying to increase the demand for dollars. This helped attract international investors who bought foreign assets with gold.
Congress passed the Gold Reserve Act on 30 January 1934; the measure nationalized all gold by ordering Federal Reserve banks to turn over their supply to the U.S. Treasury. In return the banks received gold certificates to be used as reserves against deposits and Federal Reserve notes. The act also authorized the president to devalue the gold dollar. Under this authority the president, on 31 January 1934, changed the value of the dollar from $20.67 to the troy ounce to $35 to the troy ounce, a devaluation of over 40%.
Other factors in the prolongation of the Great Depression include trade wars and the reduction in international trade caused by barriers such as Smoot-Hawley Tariff in the US and the Imperial Preference policies of Great Britain, the failure of central banks to act responsibly, government policies designed to prevent wages from falling, such as the Davis-Bacon Act of 1931, during the deflationary period resulting in production costs dropping slower than sales prices, thereby injuring business profits and increases in taxes to reduce budget deficits and to support new programs such as Social Security. The US top marginal income tax rate went from 25% to 63% in 1932 and to 79% in 1936, while the bottom rate increased over tenfold, from .375% in 1929 to 4% in 1932. The concurrent massive drought resulted in the US Dust Bowl.
The Austrian School claimed that the Great Depression was the result of a credit bust. Alan Greenspan wrote that the bank failures of the 1930s were sparked by Great Britain dropping the gold standard in 1931. This act "tore asunder" any remaining confidence in the banking system. Financial historian Niall Ferguson wrote that what made the Great Depression truly 'great' was the European banking crisis of 1931. According to Fed Chairman Marriner Eccles, the root cause was the concentration of wealth resulting in a stagnating or decreasing standard of living for the poor and middle class. These classes went into debt, producing the credit explosion of the 1920s. Eventually the debt load grew too heavy, resulting in the massive defaults and financial panics of the 1930s.
World War II.
Under the Bretton Woods international monetary agreement of 1944, the gold standard was kept without domestic convertibility. The role of gold was severely constrained, as other countries’ currencies were fixed in terms of the dollar. Many countries kept reserves in gold and settled accounts in gold. Still they preferred to settle balances with other currencies, with the American dollar becoming the favorite. The International Monetary Fund was established to help with the exchange process and assist nations in maintaining fixed rates. Within Bretton Woods adjustment was cushioned through credits that helped countries avoid deflation. Under the old standard, a country with an overvalued currency would lose gold and experience deflation until the currency was again valued correctly. Most countries defined their currencies in terms of dollars, but some countries imposed trading restrictions to protect reserves and exchange rates. Therefore, most countries' currencies were still basically inconvertible. In the late 1950s, the exchange restrictions were dropped and gold became an important element in international financial settlements.
Bretton Woods.
After the Second World War, a system similar to a gold standard and sometimes described as a "gold exchange standard" was established by the Bretton Woods Agreements. Under this system, many countries fixed their exchange rates relative to the U.S. dollar and central banks could exchange dollar holdings into gold at the official exchange rate of $35 per ounce; this option was not available to firms or individuals. All currencies pegged to the dollar thereby had a fixed value in terms of gold.
Starting in the 1959-1969 administration of President Charles de Gaulle and continuing until 1970, France reduced its dollar reserves, exchanging them for gold at the official exchange rate, reducing US economic influence. This, along with the fiscal strain of federal expenditures for the Vietnam War and persistent balance of payments deficits, led U.S. President Richard Nixon to end international convertibility of the U.S. dollar to gold on August 15, 1971 (the "Nixon Shock").
This was meant to be a temporary measure with the gold price of the dollar, and the official rate of exchanges remaining constant. Revaluing currencies was the main purpose of this plan. No official revaluation or redemption occurred. The dollar subsequently floated. In December 1971, the “Smithsonian Agreement” was reached. In this agreement, the dollar was devalued from $35 per troy ounce of gold to $38. Other countries' currencies appreciated. This was the official price of the dollar, and policies to maintain its value relative to other currencies. However, gold convertibility did not resume. In October 1973, the price was raised to $42.22. Once again, the devaluation was insufficient. Within two weeks of the second devaluation the dollar was left to float. The $42.22 par value was made official in September 1973, long after it had been abandoned in practice. In October 1976, the government officially changed the definition of the dollar; references to gold were removed from statutes. From this point, the international monetary system was made of pure fiat money.
Theory.
Commodity money is inconvenient to store and transport in large amounts. Furthermore, it does not allow a government to manipulate the flow of commerce with the same ease that a fiat currency does. As such, commodity money gave way to representative money and gold and other specie were retained as its backing.
Gold was a preferred form of money due to its rarity, durability, divisibility, fungibility and ease of identification, often in conjunction with silver. Silver was typically the main circulating medium, with gold as the monetary reserve. Commodity money was anonymous, as identifying marks can be removed. Commodity money retains its value despite what may happen to the monetary authority. After the fall of South Vietnam, many refugees carried their wealth to the West in gold after the national currency became worthless.
Under commodity standards currency itself has no intrinsic value, but is accepted by traders because it can be redeemed any time for the equivalent specie. A US silver certificate, for example, could be redeemed for an actual piece of silver.
Representative money and the gold standard protect citizens from hyperinflation and other abuses of monetary policy, as were seen in some countries during the Great Depression. Commodity money conversely led to deflation and bank runs.
Countries that left the gold standard earlier than other countries recovered from the Great Depression sooner. For example, Great Britain and the Scandinavian countries, which left the gold standard in 1931, recovered much earlier than France and Belgium, which remained on gold much longer. Countries such as China, which had a silver standard, almost entirely avoided the depression (due to the fact it was then barely integrated into the global economy). The connection between leaving the gold standard and the severity and duration of the depression was consistent for dozens of countries, including developing countries. This may explain why the experience and length of the depression differed between national economies.
Variations.
A "full or 100%-reserve" gold standard exists when the monetary authority holds sufficient gold to convert all the circulating representative money into gold at the promised exchange rate. It is sometimes referred to as the gold specie standard to more easily distinguish it. Opponents of a full standard consider it difficult to implement, saying that the quantity of gold in the world is too small to sustain worldwide economic activity at or near current gold prices; implementation would entail a many-fold increase in the price of gold. Gold standard proponents have said, "Once a money is established, any stock of money becomes compatible with any amount of employment and real income." While prices would necessarily adjust to the supply of gold, the process may involve considerable economic disruption, as was experienced during earlier attempts to maintain gold standards.
In an "international gold-standard system" (which is necessarily based on an internal gold standard in the countries concerned), gold or a currency that is convertible into gold at a fixed price is used to make international payments. Under such a system, when exchange rates rise above or fall below the fixed mint rate by more than the cost of shipping gold, inflows or outflows occur until rates return to the official level. International gold standards often limit which entities have the right to redeem currency for gold.
Advocates.
A return to the gold standard was considered by the US Gold Commission back in 1982, but found only minority support
. In 2001 Malaysian Prime Minister Mahathir bin Mohamad proposed a new currency that would be used initially for international trade among Muslim nations, using the Islamic gold dinar, defined as 4.25 grams of pure (24-carat) gold. Mahathir claimed it would be a stable unit of account and a political symbol of unity between Islamic nations. This would purportedly reduce dependence on the US dollar and establish a non-debt-backed currency in accord with Sharia law that prohibited the charging of interest. s of 2013[ [update]] the global monetary system continued to rely on the US dollar as the main reserve currency.
Former U.S. Federal Reserve Chairman, Alan Greenspan acknowledged he was one of "a small minority" within the central bank that had some positive view on the gold standard. Greenspan once famously argued the case for returning to a 'pure' gold standard in his 1966 paper "Gold and Economic Freedom", in which he described supporters of fiat currencies as "welfare statists" intending to use monetary policy to finance deficit spending. More recently he claimed that by focusing on targeting inflation "central bankers have behaved as though we were on the gold standard", rendering a return to the standard unnecessary.
Similarly, economists like Robert Barro argued that whilst some form of "monetary constitution" is essential for stable, depoliticized monetary policy, the form this constitution takes—for example, a gold standard, some other commodity-based standard, or a fiat currency with fixed rules for determining the quantity of money—is considerably less important.
The gold standard is supported by many followers of the Austrian School of Economics, free-market libertarians and some supply-siders. 
US politics.
In the United States, strict constitutionalists object to the government issuing fiat currency through central banks. Some gold-standard advocates also call for a mandated end to fractional-reserve banking. Many similar alternatives have been suggested, including energy-based currencies, collections of currencies or commodities, with gold as one component.
Former congressman Ron Paul is a long-term, high-profile advocate of a gold standard, but has also expressed support for using a standard based on a basket of commodities that better reflects the state of the economy.
In 2011 the Utah legislature passed a bill to accept federally issued gold and silver coins as legal tender to pay taxes. As Federally issued currency, the coins were already legal tender for taxes, although the market price of their metal content currently exceeds their monetary value. Similar legislation is under consideration in other US states. The bill was initiated by newly elected Republican Party legislators associated with the Tea Party movement and was driven by anxiety over the policies of President Barack Obama.
In 2013, the Arizona Legislature passed SB 1439, which would have made gold and silver coin a legal tender in payment of debt, but the bill was vetoed by the Governor.
Gold as a reserve.
As of 2013, no countries use a gold standard. From 1936 until 2000 the Swiss Franc was based on a 40% gold-reserve. Gold reserves are held in significant quantity by many nations as a means of defending their currency and hedging against the US dollar, which forms the bulk of liquid currency reserves worldwide. Both gold coins and gold bars are traded in liquid markets and serve as a private store of wealth.
In 1999 the European Central Bank and 11 European national banks signed the Washington Agreement on Gold declaring that "gold will remain an important element of global monetary reserves"; the Agreement was later amended and extended.
External links.
Listen to this article ()
This audio file was created from a revision of the "Gold standard" article dated 2007-12-04, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="37413" url="http://en.wikipedia.org/wiki?curid=37413" title="Astrid Lindgren">
Astrid Lindgren

Astrid Anna Emilia Lindgren (born Ericsson); ]; 14 November 1907 – 28 January 2002) was a Swedish writer of fiction and screenplays. She is best known for children's book series featuring Pippi Longstocking, Karlsson-on-the-Roof, and the Six Bullerby Children ("Children of Noisy Village" in the US). As of May 2013, she is the world's 18th most translated author and the third most translated children's books author after H.C. Andersen and the Grimm brothers. Lindgren has sold roughly 144 million books worldwide.
Biography.
Astrid Lindgren grew up in Näs, near Vimmerby, Småland, Sweden, and many of her books are based on her family and childhood memories and landscapes.
Lindgren was the daughter of Samuel August Ericsson and Hanna Jonsson. She had two sisters, Stina and Ingegerd, and a brother, Gunnar Ericsson, who eventually became a member of the Swedish parliament.
Upon finishing school, Lindgren took a job with the a local newspaper in Vimmerby. She had a relationship with the chief editor, who eventually proposed marriage in 1926 after she became pregnant. She declined and moved to Stockholm, learning to become a typist and stenographer (she would later write most of her drafts in stenography). In due time, she gave birth to her son, Lars, in Copenhagen and left him in the care of a foster family.
Although poorly paid, she saved whatever she could and travelled as often as possible to Copenhagen to be with Lars, often just over a weekend, spending most of her time on the train back and forth. Eventually, she managed to bring Lars home, leaving him in the care of her parents until she could afford to raise him in Stockholm.
In 1931, she married her boss, Sture Lindgren (1898–1952). Three years later, in 1934, Lindgren gave birth to her second child, Karin, who became a translator. The character Pippi Longstocking was invented for her daughter to amuse her while she was ill and bed-ridden. Lindgren later related that Karin had suddenly said to her, "Tell me a story about Pippi Longstocking." and the tale was created in response to that remark.
The family moved in 1941 to an apartment on , with a view over Vasaparken, where Lindgren lived until her death in 2002, at the age of 94.
Lindgren was almost blind a few years before her death.
Career.
Lindgren worked as a journalist and secretary before becoming a full-time author. She served as a secretary for the 1933 Swedish Summer Grand Prix.
In 1944 Lindgren won second prize in a competition held by Rabén & Sjögren, a new publishing house, with the novel "Britt-Marie lättar sitt hjärta" ("Britt-Marie unburdens her heart"). A year later she won first prize in the same competition with the chapter book "Pippi Långstrump" ("Pippi Longstocking"), which had been rejected by Bonniers. (Rabén & Sjögren published it with illustrations by Ingrid Vang Nyman, the latter's debut in Sweden.) Since then it has become one of the most beloved children's books in the world and has been translated into 60 languages. While Lindgren almost immediately became a much appreciated writer, the irreverent attitude towards adult authority that is a distinguishing characteristic of many of her characters has occasionally drawn the ire of some conservatives.
The women's magazine "Damernas Värld" sent Lindgren to the USA in 1948 to write short essays. Upon arrival she is said to have been upset by the discrimination against black Americans. A few years later she published the book "Kati in America", a collection of short essays inspired by the trip.
In 1956, the inaugural year of the Deutscher Jugendliteraturpreis, the German-language edition of "Mio, min Mio" ("Mio, My Son") was recognised by one of six special awards. (Sixteen books written by Astrid Lindgren made the Children's Book and Picture Book longlist, 1956–1975, but none won these main prizes.)
In 1958, Lindgren received the second Hans Christian Andersen Medal for the "Rasmus på luffen" ("Rasmus and the Vagabond"), a 1956 novel developed from her screenplay filmed in 1955. The biennial International Board on Books for Young People, now considered the highest lifetime recognition available to creators of children's books, soon came to be called the Little Nobel Prize. Prior to 1962 it cited a single book published during the preceding two years.
On her 90th birthday, she was pronounced Swede of the Year by a radio show.
In its entry on Scandinavian fantasy, "The Encyclopedia of Fantasy" named Lindgren the foremost Swedish contributor to modern children's fantasy. Its entry on Lindgren summed up her work in glowing terms: "her niche in children's fantasy remains both secure and exalted. Her stories and images can never be forgotten."
Politics.
In 1976, a scandal arose in Sweden when Lindgren's marginal tax rate was publicised to have risen to 102%. This was to be known as the "Pomperipossa effect" from a story she published in "Expressen" on 3 March 1976. The publication led to a stormy tax debate. In the parliamentary election later in the same year, the Social Democrat government was voted out for the first time in 44 years, and the Lindgren tax debate was one of several controversies that may have contributed to this result.
Lindgren, however, remained a Social Democrat for the rest of her life.
Lindgren was well known both for her support for children's and animal rights and for her opposition to corporal punishment. In 1994, she received the Right Livelihood Award, "...For her commitment to justice, non-violence and understanding of minorities as well as her love and caring for nature."
Honors and memorials.
In 1967, Rabén & Sjögren established an annual literary prize, the Astrid Lindgren Prize, in connection with her 60th birthday. The prize, SEK 40,000, is awarded to a Swedish language children's author, every year on her birthday in November.
Following Lindgren's death, the government of Sweden instituted the Astrid Lindgren Memorial Award in her memory. The award is the world's largest monetary award for children's and youth literature, in the amount of five million SEK.
The collection of Astrid Lindgren's original manuscripts in Kungliga Biblioteket (the Royal Library), Stockholm, was placed on UNESCO's World heritage list in 2005.
On 6 April 2011, the Bank of Sweden announced that Lindgren's portrait will feature on the 20 kronor banknote, beginning in 2014–15. In the run-up to the announcement of the persons who would feature on the new banknotes, Lindgren's name had been the one most often put forward in the public debate.
"Asteroid Lindgren".
A minor planet, 3204 Lindgren, discovered in 1978 by Soviet astronomer Nikolai Stepanovich Chernykh, was named after her. The name of the Swedish microsatellite Astrid 1, launched on 24 January 1995, was originally selected only as a common Swedish female name, but within a short time it was decided to name the instruments after characters in Astrid Lindgren's books: PIPPI (Prelude in Planetary Particle Imaging), EMIL (Electron Measurements – In-situ and Lightweight), and MIO (Miniature Imaging Optics). Astrid said that maybe people should call her Asteroid Lindgren instead.
"Astrid's Wellspring".
In memory of Astrid Lindgren, a memorial sculpture was created next to her childhood home, named "Källa Astrid" ("Astrid's Wellspring" in English). It is situated at the same place where Astrid Lindgren first heard fairy tales.
It consists of an artistic representation of a young person's head (1.37m high), flattened on top, in the corner of a square pond, and, just above the water, a ring of rosehip thorn (with a single rosehip bud attached to it). The sculpture was initially slightly different in design and intended to be part of a fountain set in the city center, but the people of Vimmerby vehemently opposed the idea. Astrid Lindgren furthermore had stated that she never wanted to be represented as a statue. (However, there is a statue of Lindgren in the city center.) The memorial was sponsored by the culture council of Vimmerby.
Lindgren's childhood home is near the statue and open to the public. Just 100 metres from "Astrid's Wellspring" is a museum in her memory. The author is buried in Vimmerby where the Astrid Lindgren's World theme park is also located. The children's museum Junibacken, Stockholm, was opened in June 1996, with the main theme of the permanent exhibition being devoted to Astrid Lindgren: the heart of the museum is a theme train ride through the world of Astrid Lindgren's novels.
Filmography.
This is a chronological list of feature films based on stories by Astrid Lindgren. There are live action films as well as animated features. Most of the films were made in Sweden, the second largest producer was Russia. Some of the films were made in transnational collaboration.

</doc>
<doc id="37417" url="http://en.wikipedia.org/wiki?curid=37417" title="Mercury (mythology)">
Mercury (mythology)

Mercury (; Latin: "Mercurius"   ) is a major Roman god, being one of the Dii Consentes within the ancient Roman pantheon. He is the patron god of financial gain, commerce, eloquence (and thus poetry), messages/communication (including divination), travelers, boundaries, luck, trickery and thieves; he is also the guide of souls to the underworld.
He was considered the son of Maia and Jupiter in Roman mythology. His name is possibly related to the Latin word "merx" ("merchandise"; compare "merchant", "commerce", etc.), "mercari" ("to trade"), and "merces" ("wages"); another possible connection is the Proto-Indo-European root merĝ- for "boundary, border" (cf. Old English "mearc", Old Norse "mark" and Latin "margō") and Greek οὖρος (by analogy of Arctūrus/Ἀρκτοῦρος), as the "keeper of boundaries," referring to his role as bridge between the upper and lower worlds. In his earliest forms, he appears to have been related to the Etruscan deity Turms, both of which share characteristics with the Greek god Hermes. In Virgil's "Aeneid", Mercury reminds Aeneas of his mission to found the city of Rome. In Ovid's "Fasti", Mercury is assigned to escort the nymph Larunda to the underworld. Mercury, however, fell in love with Larunda and made love to her on the way. Larunda thereby became mother to two children, referred to as the Lares, invisible household gods.
Mercury has influenced the name of many things in a variety of scientific fields, such as the planet Mercury, and the element mercury. The word "mercurial" is commonly used to refer to something or someone erratic, volatile or unstable, derived from Mercury's swift flights from place to place. He is often depicted holding the caduceus in his left hand.
History.
Mercury did not appear among the numinous "di indigetes" of early Roman religion. Rather, he subsumed the earlier Dei Lucrii as Roman religion was syncretized with Greek religion during the time of the Roman Republic, starting around the 4th century BC. From the beginning, Mercury had essentially the same aspects as Hermes, wearing winged shoes (talaria) and a winged hat (petasos), and carrying the caduceus, a herald's staff with two entwined snakes that was Apollo's gift to Hermes. He was often accompanied by a cockerel, herald of the new day, a ram or goat, symbolizing fertility, and a tortoise, referring to Mercury's legendary invention of the lyre from a tortoise shell.
Like Hermes, he was also a god of messages, eloquence and of trade, particularly of the grain trade. Mercury was also considered a god of abundance and commercial success, particularly in Gaul, where he was said to have been particularly revered. He was also, like Hermes, the Romans' psychopomp, leading newly deceased souls to the afterlife. Additionally, Ovid wrote that Mercury carried Morpheus' dreams from the valley of Somnus to sleeping humans.
Archeological evidence from Pompeii suggests that Mercury was among the most popular of Roman gods. The god of commerce was depicted on two early bronze coins of the Roman Republic, the Sextans and the Semuncia.
Syncretism.
When they described the gods of Celtic and Germanic tribes, rather than considering them separate deities, the Romans interpreted them as local manifestations or aspects of their own gods, a cultural trait called the "interpretatio Romana". Mercury in particular was reported as becoming extremely popular among the nations the Roman Empire conquered; Julius Caesar wrote of Mercury being the most popular god in Britain and Gaul, regarded as the inventor of all the arts. This is probably because in the Roman syncretism, Mercury was equated with the Celtic god Lugus, and in this aspect was commonly accompanied by the Celtic goddess Rosmerta. Although Lugus may originally have been a deity of light or the sun (though this is disputed), similar to the Roman Apollo, his importance as a god of trade made him more comparable to Mercury, and Apollo was instead equated with the Celtic deity Belenus.
Romans associated Mercury with the Germanic god Wotan, by "interpretatio Romana"; 1st-century Roman writer Tacitus identifies him as the chief god of the Germanic peoples.
In Celtic areas, Mercury was sometimes portrayed with three heads or faces, and at Tongeren, Belgium, a statuette of Mercury with three phalli was found, with the extra two protruding from his head and replacing his nose; this was probably because the number 3 was considered magical, making such statues good luck and fertility charms. The Romans also made widespread use of small statues of Mercury, probably drawing from the ancient Greek tradition of hermae markers.
Names and epithets.
Mercury is known to the Romans as Mercurius and occasionally in earlier writings as "Merqurius", "Mirqurios" or "Mircurios", had a number of epithets representing different aspects or roles, or representing syncretisms with non-Roman deities. The most common and significant of these epithets included the following:
Mercury's net.
Vulcan created a net out of unbreakable steel so that he could catch Venus, the goddess of love and beauty, and Mars, the god of war, in the act of making love. He was jealous of their relationship, because Venus was his beloved wife. Vulcan managed to catch them but, afterwards, Mercury stole the net from the blacksmith god so that he could catch Chloris, a nymph whom he admired. Chloris was tasked with flying after the sun while it rose and scattering lilies, roses and violets behind it. Mercury lay in wait for at least several days until he caught her wing in the net over an unnamed great river in Ethiopia. Mercury then gave the net to the temple of Anubis at Canopus to protect the sacred spot. In Ludovico Ariosto's "Orlando Furioso", the net is stolen 3,000 years later by Caligorant, who goes on to destroy the temple and the city.
Temple.
Mercury's temple in Rome was situated in the Circus Maximus, between the Aventine and Palatine hills, and was built in 495 BC.
That year saw disturbances at Rome between the patrician senators and the plebeians, which led to a secession of the plebs in the following year. At the completion of its construction, a dispute emerged between the consuls Appius Claudius Sabinus Inregillensis and Publius Servilius Priscus Structus as to which of them should have the honour of dedicating the temple. The senate referred the decision to the popular assembly, and also decreed that whichever was chosen should also exercise additional duties, including presiding over the markets, establish a merchants' guild, and exercising the functions of the pontifex maximus. The people, because of the ongoing public discord, and in order to spite the senate and the consuls, instead awarded the honour of dedicating the temple to the senior military officer of one of the legions named Marcus Laetorius. The senate and the consuls, in particular the conservative Appius, were outraged at this decision, and it inflamed the ongoing situation.
The dedication occurred on 15 May, 495 BC.
The temple was regarded as a fitting place to worship a swift god of trade and travel, since it was a major center of commerce as well as a racetrack. Since it stood between the plebeian stronghold on the Aventine and the patrician center on the Palatine, it also emphasized the role of Mercury as a mediator.
Worship.
Because Mercury was not one of the early deities surviving from the Roman Kingdom, he was not assigned a "flamen" ("priest"), but he did have his own major festival, on May 15, the Mercuralia. During the Mercuralia, merchants sprinkled water from his sacred well near the Porta Capena on their heads.
In Hindu mythology.
Budha (Sanskrit: बुध) or Saumya of Hindu mythology, and not to be confused with the Buddha, is the name for the Hindu god and the planet of Mercury (but not for the chemical element called quicksilver.) Budha is the son of Chandra (the Moon) and his mother is said to be Taraka (or Tara.) Budha is the god of merchandise and protector of merchants; he presides over intersections such as road junctions and the midweek day 'Budhavara' or Wednesday. In modern Hindi, Oriya, Telugu, Bengali, Marathi, Urdu, Kannada and Gujarati, Wednesday is called "Budhavara"; Tamil: "Budhan kizhamai"; Malayalam: "Budhanazhcha"; Thai: "Wan Phut" (วันพุธ).

</doc>
<doc id="37419" url="http://en.wikipedia.org/wiki?curid=37419" title="Porsche 914">
Porsche 914

The Porsche 914 or VW-Porsche 914 was a mid-engined, targa-topped two-seat roadster designed, manufactured and marketed collaboratively by Volkswagen and Porsche from 1969 to 1976.
History.
Development.
By the late 1960s, both Volkswagen and Porsche were in need of new models; Porsche was looking for a replacement for their entry-level 912, and Volkswagen wanted a new range-topping sports coupe to replace the Karmann Ghia. At the time, the majority of Volkswagen's developmental work was handled by Porsche, part of a setup that dated back to Porsche's founding; Volkswagen needed to contract out one last project to Porsche to fulfill the contract, and decided to make this that project. Ferdinand Piëch, who was in charge of research and development at Porsche, was put in charge of the 914 project.
Originally intending to sell the vehicle with a flat four-cylinder engine as a Volkswagen and with a flat six-cylinder engine as a Porsche, Porsche decided during development that having Volkswagen and Porsche models sharing the same body would be risky for business in the American market, and convinced Volkswagen to allow them to sell both versions as Porsches in North America.
On March 1, 1968, the first 914 prototype was presented. However, development became complicated after the death of Volkswagen's chairman, Heinz Nordhoff, on April 12, 1968. His successor, Kurt Lotz, was not connected with the Porsche dynasty and the verbal agreement between Volkswagen and Porsche fell apart.
In Lotz's opinion, Volkswagen had all rights to the model, and no incentive to share it with Porsche if they would not share in tooling expenses. With this decision, the price and marketing concept for the 914 had failed before series production had begun. As a result, the price of the chassis went up considerably, and the 914/6 ended up costing only a bit less than the 911T, Porsche's next lowest price car. The 914/6 sold quite poorly while the much less expensive 914/4 became Porsche's top seller during its model run, outselling the Porsche 911 by a wide margin with over 118,000 units sold worldwide.
Design evolution.
Volkswagen versions originally featured an 80 PS fuel-injected 1.7 L flat-4 engine based on the Volkswagen air-cooled engine. Porsche's 914/6 variant featured a carbureted 110 PS 2.0 L flat-6 engine from the 1969 911T, placed amidships in front of a version of the 1969 911's "901" gearbox configured for a mid-engine car. Karmann manufactured the rolling chassis at their plant, completing Volkswagen production in-house or delivering versions to Porsche for their final assembly.
914/6 models used lower gear ratios and high brake gearing in order to try to overcome the greater weight of the 6 cylinder engine along with higher power output. Suspension, brakes, and handling were otherwise the same. A Volkswagen-Porsche joint venture, Volkswagen of America, handled export to the U.S., where both versions were badged and sold as Porsches, except in California, where they were sold in Volkswagen dealerships. The four-cylinder cars were sold as Volkswagen-Porsches at European Volkswagen dealerships.
Slow sales and rising costs prompted Porsche to discontinue the 914/6 variant in 1972 after producing 3,351 of them; its place in the lineup was filled by a variant powered by a new 100 PS 2.0 L, fuel-injected version of Volkswagen's Type 4 engine in 1973. For 1974, the 1.7 L engine was replaced by a 85 PS 1.8 L, and the new Bosch L-Jetronic fuel injection system was added to American units to help with emissions control. 914 production ended in 1976. The 2.0 L flat-4 engine continued to be used in the 912E, which provided an entry-level model until the 924 was introduced.
The 914 was Motor Trend's Import Car of the Year for 1970. A 914/6 GT piloted by Frenchmen Claude Ballot-Lena and Guy Chasseuil won the GTS class and finished sixth overall at the 1970 24 Hours of Le Mans. Brian Redman used the 914/6 to scout the course in practice runs of the 1970 Targa Florio circuit.
Technical specifications of the standard versions.
The Porsche 914 was produced from 1969 to 1976 the following models:
Prototypes.
Two prototype 914s, dubbed "914/8", were built during 1969. The orange 914/8 was the first constructed, at the instigation of Ferdinand Piëch (then head of the racing department), to prove the concept. Powered by the full-blown, 350 hp (261 kW) 908 [flat-8] racing engine, it was based on a surplus 914 handbuilt development prototype bodyshell (chassis No. 914111), hence the many differences from the standard vehicle (e.g., the quad headlights). The second, silver, road-registered car, powered by a carburetted and detuned 908 race engine making 300 hp (224 kW) was then prepared as a gift to Ferry Porsche on his 60th birthday. Also based on a spare prototype shell (chassis No. 914006), it was much closer to the standard car in detail. By all accounts Ferry didn't like the car very much and it sits in the Porsche Museum. Neither car saw a racetrack except for the purposes of testing. The 914/8 was not considered for production as a regular model. Another factory prototype, a 914/6 (chassis no. 914114) surfaced in the US in 2001. Together with a surviving prototype Sportomatic 914/6 (chassis No. 914120), reputedly in Southern Germany, they form a unique piece of Porsche history.
Porsche 916.
Planned for the 1972 model year, the Porsche 916 program was cancelled after eleven prototypes with aerodynamic front and rear bumpers and either the 2.4 engine from the 911S, or the 2.7 from the Carrera. They were also to have a fixed steel roof, wider wheels, double grilled engine lid, and flared fenders as styled from the 914-6 GT cars. Ventilated disc brakes were fitted to all four wheels, and also a "mid-engined" version of the then-new 915 transmission, giving a conventional shift pattern with one to four in an H and fifth out on a limb. One 916 was built to US specs and on delivery to the US was fitted with air conditioning by the dealer (Brumos).
Technical information.
Model year changes.
Over the seven model years, Porsche made a number of changes to the 914. Some of these changes were cosmetic and others were in response to changing crash protection standards. From 1970 to 1974, the 914 was offered with chrome or painted bumpers. In early 1970, rear bumpers were produced with a straight crease on either side of the license plate indent. Between 1970 and 1972, both front and rear bumpers were smooth without bumper guards. In 1973, bumper guards were added to the front of the car. In 1974, guards were also added to the rear bumper. In 1975 and 1976, the chrome or painted bumpers were replaced with heavy, rubber-covered units.
The headlight surrounds were white from the first 914s to mid-production of 73 and subsequently black. Cars produced up to early 1972 had a fixed passenger seat and a removable passenger footrest. Later cars featured a movable passenger seat. Other interior differences included changing vinyl designs, gauge appearance, and air vent configurations in the dash.
The most significant performance upgrade during the vehicle's lifespan was the introduction of anti roll bars, significantly improving the handling, and a change from the "tail shifter" to the "side shifter" gearbox - improving the otherwise vague long linkage.
Whilst not being as "collectable" as the six cylinder car, the final 2.0L four cylinder cars (in European spec at least) were more than a match in performance for the "six" with similar power, lighter weight, and improvements in many areas where the early cars are weak.
Limited editions.
In 1974, Porsche produced a series of Limited Edition cars for the North American market to commemorate Porsche's victories in the Can Am racing series, and were equipped with unique color schemes and came standard with otherwise optional equipment. The factory is said to have produced about 1,000 of these vehicles, about 50% Bumblebee and 50% Creamsicle. Variants of this series were manufactured and distributed in very limited numbers to European markets and Japan.
The Creamsicle: With a cream color exterior (paint code U2V9), these cars sported Phoenix red trim, including color matched lower valences, bumpers and Mahle wheels. This light ivory color scheme concept carried over from the 1973 911 Carrera RS series.
The Bumblebee: Featuring a black exterior (paint code L041), these cars sported Sunflower yellow trim (paint code L13K). Black body paint color was always an additional cost special option on standard 914 Porsche cars, but was included as a standard component on the black 914 LE cars. All but one photo of the 914 Porsche Can Am prototype cars are Bumblebee cars. The black-based 914 LE color scheme is unique to the 914 LE cars and has no precedent with the Can Am race cars or the 1973 911 Carrera RS series cars. The majority of 914 Limited Editions seem to be Bumblebees.
All 914 LE cars featured a specially designed front spoiler and negative side stripes. Additionally, all Limited Editions were equipped with front and rear anti sway bars, dual horns, leather covered steering wheel, driving lights, black painted rear roll bar trim, Targa bar vinyl delete, and a center console with an oil temperature gauge, clock, and voltmeter.
F1 Safety Car.
The Porsche 914 is renowned for having been Formula One's first Safety Car following its deployment at the 1973 Canadian Grand Prix to help manage the race , which had seen various incidents due to treacherous weather conditions.

</doc>
<doc id="37420" url="http://en.wikipedia.org/wiki?curid=37420" title="East Malaysia">
East Malaysia

East Malaysia ("Malaysia Timur"), also known as Sabah, Sarawak and Labuan ("Sabah, Sarawak dan Labuan") or Malaysian Borneo, is the part of Malaysia located on the island of Borneo. It consists of the Malaysian states of Sabah, Sarawak, and Federal Territory of Labuan. It lies to the east of Peninsular Malaysia (West Malaysia), which is located on the Malay Peninsula. The two are separated by the South China Sea. While East Malaysia is less populated and less developed than West Malaysia, its land mass is larger and it has notably more natural resources, chiefly oil and gas reserves.
History.
Some parts of present-day East Malaysia, especially the coastal regions, were once part of the thalassocracy of the Sultanate of Brunei. However, most parts of the interior region consisted of independent tribal societies.
In 1658, the northern and eastern coasts of Sabah were ceded to the Sultanate of Sulu while the west coast of Sabah and most of Sarawak remained part of Brunei. Beginning in the mid 19th century, Sabah and Sarawak became British protectorates, and, in 1946, they became separate British colonies.
Federation.
Sabah (formerly British North Borneo) and Sarawak were separate British colonies from Malaya, and did not become part of the Federation of Malaya in 1957. However, each voted to become part of the new Federation of Malaysia along with the Federation of Malaya and Singapore in 1963. Previously, there were efforts to unite Brunei, Sabah, and Sarawak under the North Borneo Federation but that failed after the Brunei Revolt occurred.
Sabah and Sarawak retained a higher degree of local government and legislative autonomy than other states in West Malaysia. For example, both states have their own immigration controls, requiring Malaysian citizens from West Malaysia to carry passports or identity cards when visiting East Malaysia.
The islands of Labuan Territory once were part of North Borneo (later Sabah) in 1946 before becoming a Federal Territory in Malaysia on 1984. It was used to establish a centre for offshore finance in 1990.
Since 2010, there has been some speculation and discussion, at least on the ground level, about the possibility of secession from the Federation of Malaysia because of allegations of resource mishandling, illegal processing of immigrants, etc.
Administration.
It has been a source of debate whether the states of Sabah and Sarawak joined the Federation of Malaysia as equal partners with Malaya and Singapore or whether they became merely equal partners of the states of Malaya (Peninsular Malaysia). The consensus seems to be that Sabah and Sarawak are merely states of the federation with a slightly higher degree of autonomy compared to states in Peninsular Malaysia. For example, the East Malaysian states have separate laws regulating the entry of citizens from other states in Malaysia (including the other East Malaysian state), whereas, in Peninsular Malaysia, there are no restrictions on interstate travel or migration, including visitors from East Malaysia. There are also separate land laws governing Sabah and Sarawak, as opposed to the National Land Code, which governs Peninsular Malaysia.
With regard to the administration of justice, the courts in East Malaysia are part of the federal court system in Malaysia. The Constitution of Malaysia provides that there shall be two High Courts of co-ordinate jurisdiction – The High Court in Malaya and the High Court in Sabah and Sarawak (formerly the High Court in Borneo). The current Chief Judge of Sabah and Sarawak is Richard Malanjum from Sabah. His office is the fourth highest in the Malaysian judicial system (behind the Chief Judge of Malaya, President of the Court of Appeal, and Chief Justice of Malaysia).
Politics.
Sarawak, Sabah and Labuan currently holding a total of 57 out 222 seats (25.68%) in the Malaysian parliament with majority of the seats going to the ruling coalition Barisan Nasional ever since the two states hold their first state elections. However, Jeffrey Kitingan from Sabah, who is vocal of East Malaysian rights, is concerned that the number of seats from East Malaysia is under-represented in the Malaysian parliament as compared to the ideal representation of 35% stated in the Cobbold Commission report. After the conclusion of 2013 Malaysian general election, East Malaysia contributed a total of 47 parliamentary seats (35.34%) out of the 133 seats won by the Barisan Nasional coalition following the Barisan dismal performance in Peninsular Malaysia. This has resulted an increase in ministers and deputy ministers allocation for East Malaysia in the Malaysian Cabinet from 11 out of 57 portfolios in 2008 election to 20 out of 61 after the 2013 election. On the basis that East Malaysia should be treated as equal partner as compared to the Peninsular, local lawmakers has urged the federal government since the year 2011 to appoint at least one deputy prime minister from East Malaysia into the federal cabinet. Political parties in Sarawak and Sabah evolved independently of each other. Party switching and party leadership tussle are common in both the states.
Physical geography.
The landscape of East Malaysia is mostly lowland rain forests with areas of mountain rain forest towards the interior regions.
The total area of East Malaysia is 200,565 km2, representing approximately 61% of the total land area of Malaysia and 27% of the total area of Borneo.
East Malaysia contains the five highest mountains in Malaysia, the highest being Mount Kinabalu at 4095 m, which is also the highest mountain in Borneo and the 10th highest mountain peak in Southeast Asia. It also contains the two longest rivers in Malaysia – Rajang River and Kinabatangan River.
Banggi Island in Sabah and Betruit Island in Sarawak are the two largest islands that are located entirely within Malaysia. The largest island is Borneo, which is shared with Indonesia and Brunei. The second largest island is Sebatik Island, in Sabah, which is shared with Indonesia.
Sarawak contains the Mulu Caves within Gunung Mulu National Park. Its Sarawak Chamber is the largest known cave chamber in the world. The Gunung Mulu National Park was declared a UNESCO World Heritage Site in November 2000.
Sabah's attractions include World Heritage Site Kinabalu Park (which includes Mount Kinabalu), and Sipadan Island (a diving and bio-diversity hot-spot).
Geology.
Several oil and gas fields have been discovered offshore, including the Samarang oil field (1972) offshore Sabah, the Baronia oil field (1967) offshore Sarawak, and the Central Luconia natural gas fields (1968), also offshore Sarawak. The Baronia Field is a domal structural trap between two east-west growth faults, which produces from late Miocene sandstones interbedded with siltstones and clays at 2 km depth in 75 m of water.:431 The Samarang Field produces from late Miocene sandtones in an alternating sequence of sandstones, siltstones and clays in an anticline at a depth of about 3 km in water 9–45 m.:431 The Central Luconia Gas Fields produce from middle to late Miocene carbonate platform and pinnacle reefs from 1.25-3.76 km deep and water depths 60-100m.:436–437
Population.
The total population of East Malaysia in 2010 was 5.77 million (3.21 million in Sabah, 2.47 million in Sarawak, and 0.09 million in Labuan), which represents 20.4% of the population of Malaysia. A significant part of the population of East Malaysia today reside in towns and cities. The largest city and urban center is Kuching, which is also the capital of Sarawak and has a population of over 600,000 people. Kota Kinabalu is the second largest, and one of the most important cities in East Malaysia. Kuching, Kota Kinabalu, and Miri are the only three places with city status in East Malaysia. Other important towns include Sandakan and Tawau in Sabah, Sibu and Bintulu in Sarawak, and Victoria in Labuan.
The earliest inhabitants of East Malaysia are the Dayak people and other related ethnic groups such as the Dusun people. These indigenous people form a significant portion, but not the majority, of the population. For hundreds of years, there has been significant migration into East Malaysia and Borneo from many parts of the Malay Archipelago, including Java, the Lesser Sunda Islands, Sulawesi, and Sulu. More recently, there has been immigration from India and China.
The indigenous inhabitants were originally animists. Islamic influence began as early as the 15th century, while Christian influence started in the 19th century.
The indigenous inhabitants are generally partisan and maintain culturally distinct dialects of the Malay language, in addition to their own ethnic languages. Approximately 13% of the population of Sabah, and 26% of the population of Sarawak, is composed of ethnic Chinese Malaysians.
However, the demographics of Sabah has been altered dramatically with the alleged implementation of Project IC in the 1990s. Citizenships are alleged to be granted to immigrants of Indonesia and Philippines in order to keep the UMNO ruling party in power. Royal Commission of Inquiry (RCI) has been conducted from 11 August 2012 to 20 September 2013. The outcome of the investigation was submitted to the prime minister on 19 May 2014. The report was released on 3 December 2014 after 6 months delay. It is stated that Project IC may have existed which is responsible for the sudden spike in the state population. However, the report did not pinpoint anyone who is responsible except for "corrupt officials" who was taking advantage of the system.
Education.
East Malaysia currently has two public universities, namely Universiti Malaysia Sarawak (UNIMAS) and Universiti Malaysia Sabah (UMS). Universiti Teknologi Mara (UiTM) also has branch campuses in both states. Labuan's own institution of higher education is Universiti Malaysia Sabah Labuan International Campus, a branch of Universiti Malaysia Sabah in Sepanggar Bay, Kota Kinabalu. Labuan also has a matriculation college, Kolej Matrikulasi Labuan, the only matriculation college in East Malaysia. Thus, all pre-university students from Sabah, Sarawak, and Labuan must take their courses there.
UCSI University, Sarawak Campus, Tunku Abdul Rahman University College (Sabah campus), International University College Of Technology Twintech (Sabah campus), and Open University Malaysia (Sabah campus) have local private university branch campuses in East Malaysia.
Curtin University Sarawak and Swinburne University of Technology Sarawak Campus are foreign university branch campuses in Sarawak.
There are 4 teacher training colleges (Malay: "Maktab Perguruan") in Sarawak, namely Maktab Perguruan Batu Lintang (Kuching), Maktab Perguruan Rajang (Sibu), Maktab Perguruan Sains Bintulu, and Maktab Perguruan Sarawak (Miri). There are also 4 teacher training colleges in Sabah, namely Maktab Perguruan Kent, Maktab Perguruan Gaya, Maktab Perguruan Keningau, and Maktab Perguruan Tawau.
Transport.
The Pan Borneo Highway connects Sabah, Sarawak, and Brunei. The road has been poorly maintained since it was built. The narrow road is dark at night without any street lights and there are many danger spots, sharp bends, blind spots, potholes, and erosion. However, federal government funds have been allocated for the upgrade of the highway, which will be carried out in stages until completion in 2025.
The major airports in East Malaysia are Kuching International Airport, Labuan International Airport and Kota Kinabalu International Airport. There are frequent air flights by carriers including Malaysia Airlines (MAS) and AirAsia between East Malaysia and Peninsular Malaysia. Other ports of entry to East Malaysia include Sibu Airport, Bintulu Airport, and Miri Airport in Sarawak, Sandakan Airport and Tawau Airport in Sabah. MAS also operates international flights to major cities in East Malaysia.
The rural areas in Borneo can only be accessed by air or river boat. River transport is especially prevalent in Sarawak because there are many large and long rivers, with Rajang River being the most used. Rivers are used by boats and ferries for communications (i.e. mail) and passenger transport between inland areas and coastal towns. Timber is also transported via vessels and log carriers down the rivers of Sarawak.
The Labuan Ferry operates boat express and vehicle ferries from Labuan Island to Sabah, Sarawak and Brunei. The ferries have overtaken the airport as the chief transportation mode for the island.
Security.
The state of Sabah has been subjected to attacks by Moro militants since 1950s and attacks intensify in 1985, 2000, 2013, and 2014. Eastern Sabah Security Zone (ESSZONE) and Eastern Sabah Security Command (ESSCOM) was established on 25 March 2013 to tighten security in the region. On 19 July 2014, 12-hour dusk-to-dawn curfew has been imposed on six Sabah east coast districts and it is still ongoing.

</doc>
<doc id="37421" url="http://en.wikipedia.org/wiki?curid=37421" title="Bowline">
Bowline

The bowline ( or ) is an ancient and simple knot used to form a fixed loop at the end of a rope. It has the virtues of being both easy to tie and untie; most notably, it is easy to untie after being subjected to a load. The bowline is sometimes referred as "King of the knots" because of its importance. It is one of the four basic maritime knots (the other three are figure-eight knot, reef knot and clove hitch).
The structure of the bowline is identical to that of the sheet bend, except the bowline forms a loop in one rope and the sheet bend joins two ropes. Along with the sheet bend and the clove hitch, the bowline is often considered one of the most essential knots.
Although generally considered a reliable knot, its main deficiencies are a tendency to work loose when not under load, to slip when pulled sideways and the bight portion of the knot to capsize in certain circumstances. To address these shortcomings, a number of more secure variations of the bowline have been developed for use in safety-critical applications.
History.
The bowline's name has an earlier meaning, dating to the age of sail. On a square-rigged ship, a bowline (sometimes spelled as two words, "bow line") is a rope that holds the edge of a square sail towards the bow of the ship and into the wind, preventing it from being taken aback. A ship is said to be on a "taut bowline" when these lines are made as taut as possible in order to sail close-hauled to the wind.
The bowline knot is thought to have been first mentioned in John Smith's 1691 work "A Sea Grammar" under the name Boling knot. Smith considered the knot to be strong and secure, saying, "The "Boling knot" is also so firmly made and fastened by the bridles into the cringles of the sails, they will break, or the sail split before it will slip."
Another possible finding was discovered on the rigging of the Ancient Egyptian Pharaoh Khufu's solar ship during an excavation in 1954.
Use.
The bowline is used to make a loop at one end of a line. It is tied with the rope's working end also known as the "tail" or "end". The loop may pass around or through an object during the making of the knot. The knot tightens when loaded at (pulled by) the standing part of the line.
The bowline is commonly used in sailing small craft, for example to fasten a halyard to the head of a sail or to tie a jib sheet to a clew of a jib. The bowline is well known as a rescue knot for such purposes as rescuing people who might have fallen down a hole, or off a cliff onto a ledge. They would put it around themselves and sit on the loop. This makes it easy to heft them up away from danger. The Federal Aviation Administration recommends the bowline knot for tying down light aircraft.
A rope with a bowline retains approximately 2/3 of its strength, with variances depending upon the nature of the rope, as in practice the exact strength depends on a variety of factors.
Tying.
A mnemonic used to teach the tying of the bowline is to imagine the end of the rope as a rabbit, and where the knot will begin on the standing part, a tree trunk. First a loop is made near the end of the rope, which will act as the rabbit's hole. Then the "rabbit" comes up the hole, goes round the tree right to left, then back down the hole. This can be taught to children with the rhyme: "Up through the rabbit hole, round the big tree; down through the rabbit hole and off goes he."
An alternative "lightning method" can also be used; see .
There is a potential with beginners to tie what is known as an Eskimo bowline. This faulty knot stems from an incorrect first step while tying the rabbit hole. If the loop is made backwards so that the bitter end is on the bottom, the resulting knot will be sideways. The final loop of a sideways bowline will slip. This makes it particularly dangerous in the case of an inexperienced sailor, who, in addition to having an insecure knot, is also less familiar with what to do should it come untied on the water.
Security.
As noted above, the simplicity of the bowline makes it a good knot for a general purpose end-of-line loop. However in situations that require additional security, several variants have been developed:
Double bowline.
The double bowline is made by the addition of an extra turn in the formation of the "rabbit hole" before the working end is threaded through.
Water bowline.
Similar to the double bowline, the water bowline is made by forming a clove hitch before the working end is threaded through. It is said to be stronger and also more resistant to jamming than the other variations, especially when wet.
Yosemite bowline.
In this variation the knot's working end is taken round the loop in the direction of the original round turn, then threaded back up through the original round turn before the knot is drawn tight. The Yosemite bowline is often used in climbing.
Other variants.
The cowboy bowline (also called "Dutch bowline"), French bowline, and Portuguese bowline are variations of the bowline, each of which makes one loop. (Names of knots are mostly traditional and may not reflect their origins.) A running bowline can be used to make a noose which draws tighter as tension is placed on the standing part of the rope. The "Birmingham bowline" has two loops; the working part is passed twice around the standing part (the "rabbit" makes two trips out of the hole and around the tree). Other two-loop bowline knots include the Spanish bowline and the bowline on the bight; these can be tied in the middle of a rope without access to the ends. A triple bowline is used to make three loops.

</doc>
<doc id="37422" url="http://en.wikipedia.org/wiki?curid=37422" title="Loop">
Loop

Loop or LOOP may refer to:

</doc>
<doc id="37423" url="http://en.wikipedia.org/wiki?curid=37423" title="Bend">
Bend

Bend may refer to:

</doc>
<doc id="37424" url="http://en.wikipedia.org/wiki?curid=37424" title="Colorimeter">
Colorimeter

For articles on Colorimeter see:

</doc>
<doc id="37425" url="http://en.wikipedia.org/wiki?curid=37425" title="Equilibrium">
Equilibrium

Equilibrium may refer to:

</doc>
<doc id="37426" url="http://en.wikipedia.org/wiki?curid=37426" title="Squeak">
Squeak

The Squeak programming language is a dialect of Smalltalk. It is object-oriented, class-based and reflective.
It was derived directly from Smalltalk-80 by a group at Apple Computer that included some of the original Smalltalk-80 developers. Its development was continued by the same group at Walt Disney Imagineering, where it was intended for use in internal Disney projects.
Squeak is available for many platforms, and programs produced on one platform run bit-identical on all other platforms. The Squeak system includes code for generating a new version of the virtual machine (VM) on which it runs. It also includes a VM simulator written in Squeak itself. For this reason, it is easily ported.
Developers.
Dan Ingalls, an important contributor to the Squeak project, wrote the paper upon which Squeak is built and constructed the architecture for five generations of the Smalltalk language.
Squeak incorporates many of the elements Alan Kay proposed in the Dynabook concept, which he formulated in the 1960s. Kay is an important contributor to the Squeak project.
User-interface frameworks.
Squeak includes a number of user-interface frameworks:
Uses.
Many Squeak contributors collaborate on Open Cobalt, a free and open source virtual world browser and construction toolkit application which is built on Squeak.
Squeak is also used in the es operating system and for implementing the Scratch
programming language for beginning programmers. In May 2011 the OpenQwaq virtual conferencing and collaboration system based on Squeak, an open source release of Teleplace, was announced on the Teleplace blog.
License.
Squeak 4.0 may be downloaded at no cost, including source code, as a prebuilt virtual machine image licensed under the MIT License, with the exception of some of the original Apple code, which is governed by the Apache License.
Originally, Apple actually released Squeak under a license called the "Squeak License." While source code was available and modification permitted, the Squeak License contained an indemnity clause that prevented it from qualifying as true Free and Open Source Software.
In 2006, Apple relicensed Squeak twice. First, in May, Apple used its own Apple Public Source License, which satisfies the Free Software Foundation's concept of a Free Software License and has attained official approval from the Open Source Initiative as an Open Source License. The Apple Public Source License, as it turns out, fails to pass the third standard that Free and Open Source Software licenses are held to: the Debian Free Software Guidelines promulgated by the Debian project, an influential volunteer-run Linux distribution. To enable inclusion of Etoys in the One Laptop Per Child project, a second relicensing was undertaken using the Apache License. At this point, an effort was also made to address the issue of code contributed by members of the Squeak community, which it was not in Apple's power to unilaterally relicense.
For each contribution made under the Squeak License since 1996, a relicensing statement was obtained authorizing distribution under the MIT license, and finally in March 2010, the end result was released as Squeak 4.0, now under combined MIT and Apache licenses.

</doc>
<doc id="37427" url="http://en.wikipedia.org/wiki?curid=37427" title="Le Chatelier's principle">
Le Chatelier's principle

In chemistry, Le Châtelier's principle, also called Chatelier's principle or "The Equilibrium Law", can be used to predict the effect of a change in conditions on a chemical equilibrium. The principle is named after Henry Louis Le Châtelier and sometimes Karl Ferdinand Braun who discovered it independently. It can be stated as:
This principle has a variety of names, depending upon the discipline using it (see homeostasis, a term commonly used in biology). It is common to take Le Châtelier's principle to be a more general observation, roughly stated:
In chemistry, the principle is used to manipulate the outcomes of reversible reactions, often to increase the yield of reactions. In pharmacology, the binding of ligands to the receptor may shift the equilibrium according to Le Châtelier's principle, thereby explaining the diverse phenomena of receptor activation and desensitization. In economics, the principle has been generalized to help explain the price equilibrium of efficient economic systems. In simultaneous equilibrium systems, phenomena that are in apparent contradiction to Le Châtelier's principle can occur; these can be resolved by the theory of response reactions.
Status as a Physical Law.
Le Châtelier's principle describes the qualitative behavior of systems where there is an externally induced, instantaneous change in one parameter of a system; it states that a behavioural shift occurs in the system so as to oppose (partially cancel) the parameter change. The duration of adjustment depends on the strength of the negative feedback to the initial shock. Where a shock initially induces positive feedback (such as thermal runaway), the new equilibrium can be far from the old one, and can take a long time to reach. In some dynamic systems, the end-state cannot be determined from the shock. The principle is typically used to describe closed negative-feedback systems, but applies, in general, to thermodynamically closed and isolated systems in nature, since the second law of thermodynamics ensures that the disequilibrium caused by an instantaneous shock must have a finite half-life. The principle has analogs throughout the entire physical world.
Chemistry.
Effect of change in concentration.
Changing the concentration of a chemical will shift the equilibrium to the side that would reduce that change in concentration. The chemical system will attempt to partially oppose the change affected to the original state of equilibrium. In turn, the rate of reaction, extent and yield of products will be altered corresponding to the impact on the system.
This can be illustrated by the equilibrium of carbon monoxide and hydrogen gas, reacting to form methanol.
Suppose we were to increase the concentration of CO in the system. Using Le Châtelier's principle, we can predict that the amount of methanol will increase, decreasing the total change in CO. If we are to add a species to the overall reaction, the reaction will favor the side opposing the addition of the species. Likewise, the subtraction of a species would cause the reaction to fill the "gap" and favor the side where the species was reduced. This observation is supported by the collision theory. As the concentration of CO is increased, the frequency of successful collisions of that reactant would increase also, allowing for an increase in forward reaction, and generation of the product. Even if a desired product is not thermodynamically favored, the end-product can be obtained if it is continuously removed from the solution.
Effect of change in temperature.
The effect of changing the temperature in the equilibrium can be made clear by a) incorporating heat as either a reactant or a product, and b) assuming that an increase in temperature increases the heat content of a system. When the reaction is exothermic (Δ"H" is negative, puts energy out), heat is included as a product, and, when the reaction is endothermic (Δ"H" is positive, takes energy in), heat is included as a reactant. Hence, whether increasing or decreasing the temperature would favor the forward or the reverse reaction can be determined by applying the same principle as with concentration changes.
Take, for example, the reversible reaction of nitrogen gas with hydrogen gas to form ammonia:
Because this reaction is exothermic, it produces heat:
If the temperature was increased, the heat content of the system would increase, so the system would consume some of that heat by shifting the equilibrium to the left, thereby producing less ammonia. More ammonia would be produced if the reaction was run at a lower temperature, but a lower temperature also lowers the rate of the process, so, in practice (the Haber process) the temperature is set at a compromise value that allows ammonia to be made at a reasonable rate with an equilibrium concentration that is not too unfavorable.
In exothermic reactions, increase in temperature decreases the equilibrium constant, "K", whereas, in endothermic reactions, increase in temperature increases the K value.
Le Chatelier's principle applied to changes in concentration or pressure can be understood by having "K" have a constant value. The effect of temperature on equilibria, however, involves a change in the equilibrium constant. The dependence of "K" on temperature is determined by the sign of Δ"H". The theoretical basis of this dependence is given by the Van 't Hoff equation.
Effect of change in pressure.
Changes in pressure are attributable to changes in volume. The equilibrium concentrations of the products and reactants do not directly depend on the pressure subjected to the system. However, a change in pressure due to a change in volume of the system will shift the equilibrium.
Considering the reaction of nitrogen gas with hydrogen gas to form ammonia:
Note the number of moles of gas on the left-hand side and the number of moles of gas on the right-hand side. When the volume of the system is changed, the partial pressures of the gases change. If we were to decrease pressure by increasing volume, the equilibrium of the above reaction will shift to the left, because the reactant side has greater number of moles than does the product side. The system tries to counteract the decrease in partial pressure of gas molecules by shifting to the side that exerts greater pressure. Similarly, if we were to increase pressure by decreasing volume, the equilibrium shifts to the right, counteracting the pressure increase by shifting to the side with fewer moles of gas that exert less pressure. If the volume is increased because there are more moles of gas on the reactant side, this change is more significant in the denominator of the equilibrium constant expression, causing a shift in equilibrium.
Thus, an increase in system pressure due to decreasing volume causes the reaction to shift to the side with the fewer moles of gas. A decrease in pressure due to increasing volume causes the reaction to shift to the side with more moles of gas. There is no effect on a reaction where the number of moles of gas is the same on each side of the chemical equation.
Effect of adding an inert gas.
An inert gas (or noble gas) such as helium is one that does not react with other elements or compounds. Adding an inert gas into a gas-phase equilibrium at constant volume does not result in a shift. This is because the addition of a non-reactive gas does not change the partial pressures of the other gases in the container. While it is true that the total pressure of the system increases, the total pressure does not have any effect on the equilibrium constant; rather, it is a change in partial pressures that will cause a shift in the equilibrium. If, however, the volume is allowed to increase in the process, the partial pressures of all gases would be decreased resulting in a shift towards the side with the greater number of moles of gas.
Effect of a catalyst.
A catalyst has no effect on the position and composition of an equilibrium. It just speeds up both the forward and backward reactions equally, at the same time.
For example, consider the Haber process for the synthesis of ammonia (NH3):
In the above reaction, iron (Fe) and Molybdenum (Mo) will function as catalysts if present. They will accelerate any reactions, but they do not affect the state of the equilibrium.
Applications in economics.
In economics, a similar concept also named after Le Châtelier was introduced by U.S. economist Paul Samuelson in 1947. There the generalized Le Châtelier principle is for a maximum condition of economic equilibrium: Where all unknowns of a function are independently variable, auxiliary constraints—"just-binding" in leaving initial equilibrium unchanged—reduce the response to a parameter change. Thus, factor-demand and commodity-supply elasticities are hypothesized to be lower in the short run than in the long run because of the fixed-cost constraint in the short run.

</doc>
<doc id="37428" url="http://en.wikipedia.org/wiki?curid=37428" title="Beirut">
Beirut

Beirut (Arabic: بيروت‎ "Bayrūt"; Biblical Hebrew: בְּאֵרוֹת Be'erot; Hebrew: ביירות "Beirut"; Latin: "Berytus"; French: "Beyrouth"; Turkish: "Beyrut"; Armenian: Պէյրութ "Beyrut") is the capital and largest city of Lebanon. As there has been no recent population census, the exact population is unknown; but, in 2007, estimates ranged from slightly more than 1 million to slightly less than 2 million as part of Greater Beirut. Located on a peninsula at the midpoint of Lebanon's Mediterranean coast, Beirut is the country's largest and main seaport. The first mention of this metropolis is found in the ancient Egyptian Tell el Amarna letters dating from the 15th century BC. The city has been inhabited continuously since then. The Beirut River runs south to north on the eastern edge of the city.
Beirut is Lebanon's seat of government and plays a central role in the Lebanese economy, with many banks and corporations based in its Central District, Hamra Street, Rue Verdun and Ashrafieh. Following the destructive Lebanese Civil War, Beirut's cultural landscape underwent major reconstruction. Identified and graded for accountancy, advertising, banking/finance and law, Beirut is ranked as a Beta World City by the Globalization and World Cities Research Network.
Archaeology and prehistory.
Several prehistoric archaeological sites were discovered within the urban area of Beirut, revealing flint tools of sequential periods dating from the Middle Paleolithic and Upper Paleolithic, and through the Neolithic to the Bronze Age.
"Beirut I", or "Minet el Hosn", was listed as "Beyrouth ville" by Louis Burkhalter and said to be on the beach near the Orent and Bassoul hotels on the Avenue des Français in central Beirut. The site was discovered by Lortet in 1894 and discussed by Godefroy Zumoffen in 1900. The flint industry from the site was described as Mousterian and is held by the Museum of Fine Arts of Lyon.
"Beirut II", or "Umm el Khatib", was suggested by Burkhalter to have been north of Tarik el Jedideh, where P.E. Gigues discovered a Copper Age flint industry at around 100 meters above sea level. The site had been built on and destroyed by 1948.
"Beirut III", "Furn esh Shebbak" or "Plateau Tabet", was suggested to have been located on the left bank of the Beirut River. Burkhalter suggested that it was west of the Damascus road, although this determination has been criticized by Lorraine Copeland. P. E. Gigues discovered a series of Neolithic flint tools on the surface along with the remains of a structure suggested to be a hut circle. Auguste Bergy discussed polished axes that were also found at this site, which has now completely disappeared as a result of construction and urbanization of the area.
"Beirut IV", or "Furn esh Shebbak, river banks", was also on the left bank of the river and on either side of the road leading eastwards from the Furn esh Shebbak police station towards the river that marked the city limits. The area was covered in red sand that represented Quaternary river terraces. The site was found by Jesuit Father Dillenseger and published by fellow Jesuits Godefroy Zumoffen, Raoul Describes and Auguste Bergy. Collections from the site were made by Bergy, Describes and another Jesuit, Paul Bovier-Lapierre. A large number of Middle Paleolithic flint tools were found on the surface and in side gullies that drain into the river. They included around 50 varied bifaces accredited to the Acheulean period, some with a lustrous sheen, now held at the Museum of Lebanese Prehistory. Henri Fleisch also found an Emireh point amongst material from the site, which has now disappeared beneath buildings.
"Beirut V", or "Nahr Beirut" (Beirut River), was discovered by Dillenseger and said to be in an orchard of mulberry trees on the left bank of the river, near the river mouth, and to be close to the railway station and bridge to Tripoli. Levallois flints and bones and similar surface material were found amongst brecciated deposits. The area has now been built on.
"Beirut VI", or "Patriarchate", was a site discovered while building on the property of the Lebanese Evangelical School for Girls in the Patriarchate area of Beirut. It was notable for the discovery of a finely styled Canaanean blade javelin suggested to date to the "Néolithique Ancien" or "Néolithique Moyen" periods of Byblos and which is held in the school library.
"Beirut VII", or "Rivoli Cinema" and "Byblos Cinema" sites near the Bourj in the Rue el Arz area, are two sites discovered by Lorraine Copeland and Peter Wescombe in 1964 and examined by Diana Kirkbride and Roger Saidah. One site was behind the parking lot of the Byblos Cinema and showed collapsed walls, pits, floors, charcoal, pottery and flints. The other, overlooking a cliff west of the Rivoli Cinema, was composed of three layers resting on limestone bedrock. Fragments of blades and broad flakes were recovered from the first layer of black soil, above which some Bronze Age pottery was recovered in a layer of grey soil. Pieces of Roman pottery and mosaics were found in the upper layer. Middle Bronze Age tombs were found in this area, and the ancient tell of Beirut is thought to be in the Bourj area.
The Phoenician port of Beirut was located between Rue Foch and Rue Allenby on the north coast. The port or harbor was excavated and reported on several years ago and now lies buried under the city. Another suggested port or dry dock was claimed to have been discovered ~1 km to the west, in 2011 by a team of Lebanese archaeologists from the Directorate General of Antiquities of Lebanese University. Controversy arose on 26 June 2012 when authorization was given by Lebanese Minister of Culture Gaby Layoun for a private company called Venus Towers Real Estate Development Company to destroy the ruins (archaeological site BEY194) in the $500 million construction project of three skyscrapers and a garden behind Hotel Monroe in downtown Beirut. Two later reports by an international committee of archaeologists appointed by Layoun, including Hanz Curver, and an expert report by Ralph Pederson, a member of the institute of Nautical Archaeology and now teaching at Marburg in Germany, dismissed the claims that the trenches were a port, on various criteria. The exact function of site BEY194 may now never be discovered, and the issue raised heated emotions and led to increased coverage on the subject of Lebanese heritage in the press.
History.
Beirut's history goes back more than 5,000 years. According to the "Encyclopædia Britannica", its antiquity is indicated by its name, derived from the Canaanite-Phoenician "be'erot" ("wells"), referring to the underground water table that is still tapped by the local inhabitants for general use. Excavations in the downtown area have unearthed layers of Phoenician, Hellenistic, Roman, Byzantine, Arab, Crusader and Ottoman remains. The first historical reference to Beirut dates from the 14th century BC, when it is mentioned in the cuneiform tablets of the Amarna letters, three letters that Ammunira of "Biruta" (Beirut) sent to the pharaoh of Egypt. Biruta is also referenced in the letters from Rib-Hadda, king of Byblos. The oldest settlement was on an island in the river that progressively silted up. The city was known in antiquity as "Berytus". This name was taken in 1934 for the archaeological journal published by the Faculty of Arts and Sciences at the American University of Beirut.
Hellenistic and Roman period.
In 140 B.C.E the city was destroyed by Diodotus Tryphon in his contest with Antiochus VII Sidetes for the throne of the Macedonian Seleucid monarchy. Beirut was soon rebuilt on a more conventional Hellenistic plan and renamed "Laodicea in Phoenicia" (Greek: Λαοδίκεια ἡ ἐν Φοινίκῃ) or "Laodicea in Canaan" in honor of a Seleucid Laodice. The modern city overlies the ancient one, and little archaeology was carried out until after the end of the civil war in 1991. The post-war salvage excavations (1993-to date) have yielded new insights in the layout and history of Roman Berytus. Public architecture included several bath complexes, colonnaded streets, a circus and theater; residential areas were excavated in the Future Garden of Forgiveness, Martyrs' Square and the Beirut Souks.
Mid-first-century coins from Berytus bear the head of Tyche, goddess of fortune; on the reverse, the city's symbol appears: a dolphin entwines an anchor. This symbol was later taken up by the early printer Aldus Manutius in 15th century Venice.
Beirut was conquered by Pompey in 64 B.C.E The city was assimilated into the Roman Empire, veteran soldiers were sent there, and large building projects were undertaken. Beirut was considered the most Roman city in the eastern provinces of the Roman Empire.
In 14 B.C.E, during the reign of Herod the Great, Berytus became a "colonia" and was named "Colonia Iulia Augusta Felix Berytus". Its law school was widely known; two of Rome's most famous jurists, Papinian and Ulpian, both natives of Phoenicia, taught there under the Severan emperors. When Justinian assembled his "Pandects" in the 6th century, a large part of the corpus of laws was derived from these two jurists, and in 533 Justinian recognized the school as one of the three official law schools of the empire. After the 551 Beirut earthquake the students were transferred to Sidon.
Middle Ages.
Beirut passed into Arab control in 635 Prince Arslan bin al-Mundhir founded the Principality of Sin-el-Fil in Beirut in 759 AD. From this principality developed the later Principality of Mount Lebanon, which was the basis for the establishment of Greater Lebanon, today's Lebanon. As a trading centre of the eastern Mediterranean, Beirut was overshadowed by Acre during the Middle Ages. From 1110 to 1291 it was in the hands of the Crusaders' Kingdom of Jerusalem. John of Ibelin, the Old Lord of Beirut (1179–1236) rebuilt the city after the battles with Saladin and also built the Ibelin family palace in Beirut.
Ottoman rule.
Beirut was controlled by local Druze emirs throughout the Ottoman period. One of them, Fakhr-al-Din II, fortified it early in the 17th century, but the Ottomans reclaimed it in 1763. With the help of Damascus, Beirut successfully broke Acre's monopoly on Syrian maritime trade and for a few years supplanted it as the main trading centre in the region. During the succeeding epoch of rebellion against Ottoman hegemony in Acre under Jezzar Pasha and Abdullah Pasha, Beirut declined to a small town with a population of about 10,000 and was an object of contention between the Ottomans, the local Druze, and the Mamluks.
After Ibrahim Pasha of Egypt captured Acre in 1832, Beirut began its revival.
By the second half of the nineteenth century, Beirut was developing close commercial and political ties with European imperial powers, particularly France. European interests in Lebanese silk and other export products transformed the city into a major port and commercial centre. Meanwhile, Ottoman power in the region continued to decline. Sectarian and religious conflicts, power vacuums, and changes in the political dynamics of the region culminated in the 1860 Lebanon conflict. Beirut became a destination for Maronite Christian refugees fleeing from the worst areas of the fighting on Mount Lebanon and in Damascus. This in turn altered the ethnic composition of Beirut itself, sowing the seeds of future ethnic and religious troubles there and in greater Lebanon. However, Beirut was able to prosper in the meantime. This was again a product of European intervention, and also a general realization amongst the city's residents that commerce, trade, and prosperity depended on domestic stability.
In 1888, Beirut was made capital of a vilayet (governorate) in Syria, including the sanjaks (prefectures) Latakia, Tripoli, Beirut, Acre and Bekaa. By this time, Beirut had grown into a cosmopolitan city and had close links with Europe and the United States. It also became a centre of missionary activity that spawned educational institutions, such as the American University of Beirut. Provided with water from a British company and gas from a French one, silk exports to Europe came to dominate the local economy. After French engineers established a modern harbor in 1894 and a rail link across Lebanon to Damascus and Aleppo in 1907, much of the trade was carried by French ships to Marseille. French influence in the area soon exceeded that of any other European power. The 1911 "Encyclopædia Britannica" reported a population consisting of 36,000 Muslims, 77,000 Christians, 2,500 Jews, 400 Druze and 4,100 foreigners. At the start of the 20th century, Salim Ali Salam was one of the most prominent figures in Beirut, holding numerous public positions including deputy from Beirut to the Ottoman parliament and President of the Municipality of Beirut. Given his modern way of life, the emergence of Salim Ali Salam as a public figure constituted a transformation in terms of the social development of the city.
An aerial panoramic view of Beirut in the last third of the 19th century
Modern era.
After the collapse of the Ottoman Empire following World War I, Beirut, along with the rest of Lebanon, was placed under the French Mandate. Lebanon achieved independence in 1943, and Beirut became the capital city. The city remained a regional intellectual capital, becoming a major tourist destination and a banking haven , especially for the Persian Gulf oil boom.
This era of relative prosperity ended in 1975 when the Lebanese Civil War broke out throughout the country. During most of the war, Beirut was divided between the Muslim west part and the Christian east. The downtown area, previously the home of much of the city's commercial and cultural activity, became a no man's land known as the Green Line. Many inhabitants fled to other countries. About 60,000 people died in the first two years of the war (1975–1976), and much of the city was devastated. A particularly destructive period was the 1978 Syrian siege of Achrafiyeh, the main Christian district of Beirut. Syrian troops relentlessly bombed the eastern quarter of the city, but Christian militias defeated multiple attempts by Syria's elite forces to capture the strategic area in a three-month campaign later known as the Hundred Days' War.
Another destructive chapter was the 1982 Lebanon War, during which most of West Beirut was under siege by Israeli troops. In 1983, French and US barracks were bombed, killing 241 American servicemen, 58 French servicemen, six civilians and the two suicide bombers.
Hezbollah was formed after the 1982 Lebanon War in 1982, and was primarily formed to offer resistance to the Israeli occupation.
Since the end of the war in 1990, the people of Lebanon have been rebuilding Beirut, and by the start of the 2006 Israel-Lebanon conflict the city had somewhat regained its status as a tourist, cultural and intellectual center in the Middle East and as a centre for commerce, fashion, and media. The reconstruction of downtown Beirut has been largely driven by Solidere, a development company established in 1994 by Prime Minister Rafic Hariri. The city has been host to the Asian Club Basketball Championship and the Asian Football Cup and has hosted the Miss Europe pageant eight times, 1960–1964, 1999, 2001–2002.
Rafic Hariri was assassinated in 2005 near the Saint George Hotel in Beirut. A month later about one million people gathered for an opposition rally in Beirut. The Cedar Revolution was the largest rally in Lebanon's history at that time. The last Syrian troops withdrew from Beirut on 26 April 2005, and the two countries established diplomatic relations on 15 October 2008.
During the 2006 Lebanon War, Israeli bombardment caused damage in many parts of Beirut, especially the predominantly Shiite southern suburbs of Beirut.
In May 2008, after the government decided to disband Hezbollah's communications network (a decision it later rescinded), violent clashes broke out briefly between government allies and opposition forces, before control of the city was handed over to the Lebanese Army. After this a national dialogue conference was held in Doha at the invitation of the Prince of Qatar. The conference agreed to appoint a new president of Lebanon and to establish a new national government involving all the political adversaries. As a result of the Doha Agreement, the opposition's camp in the capital was removed.. On 19 October 2012, a car bomb killed eight people in the Beirut's neighbourhood of Achrafiyeh, including Brigadier General Wissam al-Hassan, chief of the Intelligence Bureau of the Internal Security Forces. In addition, 78 others were wounded in the bombing. It was the largest attack in the capital since 2008. On 27 December 2013, a car bomb exploded in the Central District killing at least five people, including the former Lebanese ambassador to the U.S. Mohamad Chatah, and wounding 71 others.
Geography.
Beirut sits on a peninsula extending westward into the Mediterranean Sea about 94 km north of the Lebanon-Israel border. It is flanked by the Lebanon Mountains and has taken on a triangular shape, largely influenced by its situation between and atop two hills: Al-Ashrafieh and Al-Musaytibah. The Beirut Governorate occupies 18 km2, and the city's metropolitan area 67 km2. The coast is rather diverse, with rocky beaches, sandy shores and cliffs situated beside one another.
Climate.
Beirut has a hot-summer Mediterranean climate (Köppen: Csa) characterized by warm days and nights, yet summers can be virtually rainless. Autumn and spring are warm, with rainy winters. August is considered the only really hot muggy month, with a monthly average high temperature of 32 °C, and January and February are the coldest months, with a monthly average low temperature of 11 °C. The prevailing wind during the afternoon and evening is from the west (onshore, blowing in from the Mediterranean); at night it reverses to offshore, blowing from the land out to sea. 
The average annual rainfall is 893 mm, with the majority falling in winter, autumn and spring. Much of the autumn and spring rain falls in heavy downpours on a limited number of days, but in winter it is spread more evenly over a large number of days. Summer receives very little rainfall, if any. Snow is rare, except in the mountainous eastern suburbs, where snowfall is common due to the region's high altitudes.
Quarters and sectors.
Beirut is divided into 12 quarters ("quartiers"):
These quarters are divided into sectors ("secteurs").
Two of the twelve official Palestinian refugee camps in Lebanon are located in the southern suburbs of Beirut: Bourj el-Barajneh and Shatila. There is also one within its municipal boundaries: Mar Elias. Of the fifteen unregistered or unofficial refugee camps, Sabra, which lies adjacent to Shatila, is also located in southern Beirut.
People in Lebanon often use different names for the same geographic locations, and few people rely on official, government-provided street numbers. Instead, historic and commercial landmarks and location codes such as PinLiban are more common.
Demographics.
No population census has been taken in Lebanon since 1932, and estimates of Beirut's population range from as low as 938,940 through 1,303,129 to as high as 2,012,000 as part of Greater Beirut.
Religion.
Beirut is one of the most cosmopolitan and religiously diverse cities of Lebanon and all of the Middle East. The city boasts significant Christian and Muslim communities. There are nine major religious groups in Beirut: Maronite Catholic, Eastern Orthodox, Melkite Catholic, Armenian Apostolic, Armenian Catholic, Protestant, Sunni Muslim, Shia Muslim, Jews, and Druze.
Family matters such as marriage, divorce and inheritance are still handled by the religious authorities representing a person's faith (the Ottoman "millet" system). Calls for civil marriage are unanimously rejected by the religious authorities, but civil marriages held in another country are recognized by Lebanese civil authorities. Until the mid-20th century, Beirut was also home to a Jewish community in the Bab Idriss sector of Zokak el-Blat.
Before the civil war the neighborhoods of Beirut were fairly heterogeneous, but they became largely segregated by religion since the conflict. East Beirut has a mainly Christian population with a small Muslim minority, while West Beirut has a Muslim majority with small minorities of Christians and Druze. Since the end of the civil war, East and West Beirut have begun to see an increase in Muslims and Christians moving into each half. The southern suburbs are populated largely by Shia Muslims, while the eastern and northern suburbs are largely Christian.
The city has six dioceses within its territory. The Maronite Catholic Church has had an episcopal see since 1577, currently under Archbishop Paul Youssef Matar, the Greek Orthodox Church, under Archbishop Elias Audi, the Melkite Greek Catholic Church, under Archbishop Cyril Salim Bustros. It also has the Armenian Catholic Church under the jurisdiction of Nerses Bedros XIX Tarmouni, as well as the Chaldean Catholic Church which has had a presence in the city since 1957. It also has the Syriac Catholic Church under the jurisdiction of Ignatius Joseph III Yonan.
The city is also home to a small number of Latin Rite Roman Catholics in the form of an apostolic vicariate with Archbishop Paul Dahdah, OCD, as the apostolic vicar.
Beirut Central District.
The Beirut Central District (BCD) or Centre Ville is the name given to Beirut’s historical and geographical core by "Solidere", the "vibrant financial, commercial, and administrative hub of the country." It is an area thousand of years old, traditionally a focus of business, finance, culture and leisure. Its reconstruction constitutes one of the most ambitious contemporary urban developments. Due to the devastation incurred on the city center from the Lebanese Civil War, the Beirut Central District underwent a thorough reconstruction and development plan that gave it back its cultural and economic position in the region. Ever since, Beirut Central District has evolved into an integrated business and commercial environment and the focus of the financial activity in the region. That evolution was accompanied with the relocation of international organizations, reoccupation of civic and government buildings, expansion of financial activities, and establishment of regional headquarters and global firms in the city center.
Assessment of the demand for build-up space in the BCD has been done in reference to a number of macro-economic, demographic, and urban planning considerations at a time of marked need for new activity poles in the city, such as Souks, financial, cultural and recreational centers. The district's total area is 4,690,000 square meters, the majority of which is dedicated to residential space (1,924,000 sq meters). The Beirut Central District contains over 60 gardens, squares and open spaces. These spaces comprise landscaped streets, gardens, historical squares, pedestrian areas and sea promenades thus totaling to an area of 96 acres of open spaces.
The central district is Lebanon's prime location for shopping, entertainment, and dining. There are over 100 cafes, restaurants, pubs and nightclubs open in the Beirut Central District, and over 350 retail outlets distributed along its streets and quarters. Beirut Souks alone are home to over 200 stores and a handful of restaurants and cafes. Beirut Souks are the Central District's old medieval market, recently renovated along with the original Hellenistic street grid that characterized the old souks and the area's historical landmarks along long vaulted shopping alleys and arcades. Solidere, the company responsible for the reconstruction and renovation of the district, organizes music and entertainment events all throughout the year like the Beirut Marathon, Fête de la Musique, Beirut Jazz Festival.
Economy.
Beirut's economy is service-oriented with the main growth sectors being banking and tourism.
In an area dominated by authoritarian or militarist regimes, the Lebanese capital was generally regarded as a haven of liberalism, though a precarious one. With its seaport and airport—coupled with Lebanon’s free economic and foreign exchange system, solid gold-backed currency, banking-secrecy law, and favourable interest rates—Beirut became an established banking centre for Arab wealth, much of which was invested in construction, commercial enterprise, and industry (mostly the manufacture of textiles and shoes, food processing, and printing). The economy of Beirut is diverse, including publishing, banking, trade and various industries. During that period, Beirut was the region's financial services center. At the onset of the oil boom starting in the 1960s, Lebanon-based banks were the main recipients of the region's petrodollars.
Beirut is the focal point of the Economy of Lebanon. The capital hosts the headquarters of Banque du Liban, Lebanon's central bank, the Beirut Stock Exchange, the head office of Lebanon's flag-carrier Middle East Airlines, the United Nations Economic and Social Commission for Western Asia, the Union of Arab Banks, and the Union of Arab Stock Exchanges.
Banking and finance.
The Banking System is the backbone of the local economy with a balance sheet of $152 billion at the end of 2012, nearing 3.5 times the GDP estimated at $43 billion by the IMF. Bank deposits also increased in 2012 by 8% to 125 billion dollars, 82 percent of the sector’s assets. "Banks are still attracting deposits because the interest rates offered are higher than the ones in Europe and the United States", says Marwan Mikhael, head of research at BLOM Bank.
Beirut's foreign reserves were still close to an all-time high when they reached $32.5 billion in 2011 and analysts say that the Central Bank can cover nearly 80 percent of the Lebanese currency in the market. This means that the Central Bank can easily cope with any unforeseen crisis in the future thanks to the massive foreign currency reserves.
The Lebanese banking system is endowed with several characteristics that promote the role of Beirut as a regional financial center, in terms of ensuring protection for foreign capital and earnings. The Lebanese currency is fully convertible and can be exchanged freely with any other currency. Moreover, no restrictions are put on the free flow of capital and earnings into and out of the Lebanese economy. The passing of the banking secrecy law in 3 September 1956, subjected all banks established in Lebanon as well as foreign banks' branches to the "secret of the profession". Both article 16 of law No. 282 dated 30 December 1993 and article 12 of decree No. 5451 dated 26 August. 1994, offer exemptions from income tax on all interest and revenues earned on all types of accounts opened in Lebanese banks. On the first of April 1975, decree No. 29 established a free banking zone by granting the Lebanese government the right to exempt non-residents' deposits and liabilities in foreign currency from: the income tax on interest earned, the required reserves imposed by the Banque Du Liban by virtue of article 76 of the Code of Money and Credit, the premium of deposit guarantee imposed on bank deposits to the profit of the National Deposit Guarantee Institution.
Tourism.
The tourism industry in Beirut has been historically important to the local economy and remains to this day to be a major source of revenue for the city, and Lebanon in general. Before the Lebanese Civil War, Beirut was widely regarded as "The Paris of the Middle East," often cited as a financial and business hub where visitors could experience the Levantine Mediterranean culture. Beirut's diverse atmosphere and ancient history make it an important destination which is slowly rebuilding itself after continued turmoil. Although in recent times, certain countries such as the United States frequently place Lebanon and Beirut in particular, within their travel warnings list due to a large number of car bombings and orchestrated political violence.
According to the 2012 tourist statistics, 34% of the tourists in Beirut came from states within the Arab League, 33% came from European countries (mainly France, Germany, and Britain), and 16% from the Americas (about half of which are from the United States).
The largely pedestrianized Beirut Central District is the core of the Beirut tourism scene. The district is a cluster of stone-façade buildings lining arcaded streets and radial alleyways. The architecture of the area is a mix of French Architecture and Venetian Gothic architecture mixed with Arabesque and Ottoman Architecture. The district contains numerous old mosques and crusader churches, as well as uncovered remnants and ruins of the Roman era. The District contains tens of restaurants, cafes and pubs, as well as a wide range of shopping stores mainly in Beirut Souks. High-rise hotels and towers line the district's New Waterfront, marina and seaside promenade.
Another popular tourist destination in Beirut is the Corniche Beirut, a 4.8 km pedestrian promenade that encircles the capital's seafront from the Saint George Bay in the north all the way to Avenue de Paris and Avenue General de Gaulle south of the city. The corniche reaches its maximum height above sea level at Raouché, a high-rise residential neighborhood rising over a giant white limestone cliff and facing the recognizable off-shore Raouché Rocks.
Hamra Street is a long cobblestone street connecting the Beirut Central District with the coastal Raouche area. The street is a large concentration of shopping stores, boutiques, restaurants, banks, street vendors, sidewalk cafes, newspaper kiosks, and a booming nightlife spurred by students from the neighboring American University of Beirut. The AUB campus is another popular visitor destination, composed of a cluster of 19th century red-roofed buildings dispersed on a wooded hillside overlooking the Mediterranean.
Gemmayzeh is Beirut's artistic Bohemian quarter, full of narrow streets and historic buildings from the French era. It is located East of the Beirut Central District, bordering the Saifi Village. The neighborhood is well known for its trendy bars and pubs, cafes, restaurants and lounges; most are directly located on Rue Gouraud, the main thoroughfare that cuts through the middle of the district. In 2004, Travel + Leisure magazine called Gemmayzeh "SoHo by the Sea," due to its colorful and chic cafés amid 1950s apartment buildings and hole-in-the-wall shops.
Beirut is a destination for tourists from both the Arab world and West. In "Travel + Leisure" magazine's World Best Awards 2006, it was ranked 9th best city in the world. That list was voted upon shortly before the 2006 Lebanon War broke out, but in 2008 "The Guardian" listed Beirut as one of its top ten cities in the world. "The New York Times" ranked it at number One on its "44 places to go" list of 2009. 2011 MasterCard Index revealed that Beirut had the second-highest visitor spending levels in the Middle East and Africa, totaling $6.5 billion. Beirut was chosen in 2012 by Condé Nast Traveler as the best city in the Middle East, beating Tel Aviv and Dubai.
Many of the tourists are returning Lebanese expatriates, but many are from Western countries. Approximately 3 million visitors visited in 2010; the previous record was 1.4 million in 1974.
In 2012, San Diego television channel WealthTV will feature Beirut, its culture and its people as a part of the travel series "Uncover".
Like other forms of tourism, medical tourism in Lebanon is on the rise recently. Although visitors from neighboring Arab nations make up the bulk of medical tourism patients here due to its proximity, Beirut is strongly trying to woo more southern Europeans, Asians and North Americans to its land. Its Agency for Investment Development in Lebanon reports that growth in the medical tourism industry is growing by up to 30% a year since 2009. The country’s tourism ministry is working closely with the medical sector and top-class hotels to create an organized, quality medical destination. Major hotel and spa chains work with local clinics, travel agencies and the tourism ministry to create comprehensive healthcare and recuperation packages for foreign visitors. The government is highly involved in this industry and strives to make the process as easy as possible.
Cosmetic surgery is a major component of medical tourism in Lebanon. Most of the foreign patients come for routine operations like plastic surgery, dental or eye Beirut’s hospitals are also capable of performing specialized procedures such as internal bypass surgery and other technical treatments. Its top clinics and hospitals like Sahel General are equipped to handle the full range of surgical procedures. Beirut-based Clemenceau Medical Center (CMC), affiliated with Johns Hopkins International, was ranked one of the world’s top ten best hospitals for medical tourism in 2012.
Government.
Beirut is the capital of Lebanon and its seat of government. The Lebanese Parliament, all the Ministries and most of the public administrations, embassies and consulates are there. The Beirut Governorate is one of six "mohafazat" (plural of "mohafazah", a state governorate). The others are North Lebanon, Mount Lebanon, South Lebanon, Beqaa and Nabatiye.
International organizations.
The city is home to numerous international organizations. The United Nations Economic and Social Commission for Western Asia (ESCWA) is headquartered in downtown Beirut, The Arab Air Carriers Organization (AACO), the Union of Arab Banks and the Union of Arab Stock Exchanges are also headquartered in the city. The International Labour Organization (ILO) and UNESCO (United Nations Educational, Scientific and Cultural Organization) both have regional offices in Beirut covering the Arab world.
Education.
Higher education throughout Lebanon is provided by universities, colleges and technical and vocational institutes.
The American University of Beirut and Université Saint-Joseph (USJ), are the oldest respectively English medium and French medium universities in the country. The Lebanese University is the only public institution for higher education in Beirut. Beirut is also home to the Lebanese American University (LAU), which is also, together with many of its programs, accredited by US bodies and considered lately one of the top universities in the Middle East. LAU also offers an architecture degree equivalent to the French DEA, allowing graduates to practice in the European Union. Beirut is also home to the American University of Science and Technology (AUST), University of Balamand, École Supérieure des Affaires (ESA), Beirut Arab University (BAU), Haigazian University (HU), as well as the Lebanese International University (LIU).
The Directorate General of Higher Education is responsible for managing the university colleges, university institutes and universities in Beirut and nationwide.
Among the private secondary schools in Beirut are Lycee Abdel Kader Grand Lycée Franco-Libanais, Lycée Franco-Libanais Verdun, American Community School, International College, Collège Notre-Dame de Jamhour, Carmel Saint-Joseph, Collège Louise Wegmann, Rawdah High School, Saint Mary's Orthodox College, Collège Notre Dame de Nazareth, Collège du Sacré-Coeur Gemmayzé, Collège Protestant Français, Armenian Evangelical Central High School, German School of Beirut, and the Armenian Hamazkayin Arslanian College.
Transportation.
The city's renovated airport is the Rafic Hariri International Airport, located in the southern suburbs. The Port of Beirut, one of the largest and most commercial in the eastern Mediterranean, is another port of entry. As a final destination, Lebanon can be reached by ferry from Cyprus via the nearby city of Jounieh or by road from Damascus via the Beqaa valley in the east.
Beirut has frequent bus connections to other cities in Lebanon and major cities in Syria such as Homs and its capital Damascus. There are a number of different companies providing public transport in Lebanon. The publicly owned buses are managed by Office des Chemins de Fer et des Transports en Commun (OCFTC – "Railway and Public Transportation Authority"). Buses for northern destinations and Syria leave from Charles Helou Station.
The ministry of transport and public works purchased an extra 250 intra and inter-buses in 2012 to better serve regions outside the capital as well as congestion-choked Beirut, hoping to lessen the use of private cars. 
Beirut has also private buses that are provided by the Lebanese Commuting Company.
Culture.
The culture of Beirut has evolved under the influence of many different peoples and civilizations, such as Greeks, Romans, Arabs, Ottoman Turks and French. The law school in downtown Beirut was one of the world's earliest and was considered to be a leading center of legal studies in the Eastern Roman Empire.
Beirut hosted the Francophonie and Arab League summits in 2002, and in 2007 it hosted the ceremony for the Prix Albert Londres, which rewards outstanding francophone journalists every year. The city also hosted the Jeux de la Francophonie in 2009. In the same year it was proclaimed World Book Capital by UNESCO.
Beirut has also been called the "party capital of the Arab world". Rue Monnot has an international reputation among clubbers, and Rue Gouraud in districts such as Gemmayze and Mar Mikhael have emerged as new hotspots for bar patrons and clubbers, as well as 'The Alleyway' in Hamra Street.
Museums.
The National Museum of Beirut is the principal museum of archaeology in Lebanon. It has about 1,300 exhibits ranging in date from prehistoric times to the medieval Mamluk period. The Archaeological Museum of the American University of Beirut is the third oldest museum in the Middle East, exhibiting a wide range of artifacts from Lebanon and neighboring countries. Sursock Museum was built by the Sursock family at the end of the 19th century as a private villa and then donated to the Lebanese state. It now houses Beirut's most influential and popular art museum. The permanent collection shows a set of Japanese engravings and numerous works of Islamic art, and temporary exhibitions are shown throughout the year. The Robert Mouawad Private Museum near Beirut's Grand Serail exhibits Henri Pharaon's private collection of archaeology and antiques. Planet Discovery is a children’s science museum with interactive experiments, exhibitions, performances, workshops and awareness competitions. The Saint Joseph University opened the Museum of Lebanese Prehistory in 2000, the first prehistory museum in the Arabic Middle East, displaying bones, stone tools and neolithic pottery collected by Jesuits.
Media.
Beirut is a main center for the television, newspaper, and book publishing industries.
Television stations based in Beirut include Télé Liban, LBC, ÓTV (Orange TV), MTV Lebanon, Tele Lumiere (Catholic TV), Future TV, New TV, NBN, ANB and Saudi TV 1 on 33 UHF and MBC 1, MBC 4, MBC Action, Fox, Al Jazeera, Rotana, OSN First, OSN News, Al Yawm and Arabic Series Channel on 45 UHF.
Newspapers include An-Nahar, Al Joumhouria, As-Safir, Al Mustaqbal, Al-Akhbar, Al-Balad, Ad-Diyar, Al Anwar, Al Sharq.
Newspapers and magazines published in French include L'Orient Le Jour (since 1971), La Revue Du Liban, Al Balad-French Version, Al Intiqad, Magazine L'Hebdo and La Commerce Du Levant.
English newspapers published in Beirut are The Daily Star, Executive Magazine (weekly), Beirut Online, Beirut Times (weekly) and Monday Morning.
Sports.
The Lebanese capital hosted the Mediterranean Games in 1959, FIBA Asia Champions Cup in 1999, 2000, 2012, the AFC Asian Cup in 2000, and the FIBA Asia Cup in 2010. Beirut was the host city for the 6th Annual Games of the Jeux de la Francophonie in 2009. Beirut also hosted the Pan Arab Games in 1957, 1997, and will do so again in 2015.
Beirut, with Sidon and Tripoli, hosted the 2000 AFC Asian Cup. There are two stadiums in the city, Camille Chamoun Sports City Stadium and Beirut Municipal Stadium.
Basketball is the most popular sport in Lebanon. Currently, four Beirut teams play in Lebanese Basketball League Division 1: Hekmeh, Sporting Al Riyadi Beirut, Hoops Club and Antranik SC.
Other sports events in Beirut include the annual Beirut Marathon, hip ball, weekly horse racing at the Beirut Hippodrome, and golf and tennis tournaments that take place at Golf Club of Lebanon. Three out of the five teams in the Lebanese rugby league championship are based in Beirut.
Arts and fashion.
There are hundreds of art galleries in Beirut and its suburbs. Every year hundreds of fine art students graduate from universities and institutions. Artist workshops exist all over Lebanon. The inauguration of the Beirut Art Center, a non-profit association, space and platform dedicated to contemporary art in Lebanon, in the Mkalles suburb of Beirut added to the number of exhibition spaces available in the city, with a screening and performance room, mediatheque, bookstore, cafe and terrace. Adjacent to the latter is the Ashkal Alwan Home Workspace, a venue hosting cultural events and educational programs.
A number of international fashion designers have displayed their work in big fashion shows. Most major fashion labels have shops in Beirut's shopping districts, and the city is home to a number of local fashion designers, some of whom like Elie Saab,Yara Farhat, Reem Acra, Zuhair Murad, Georges Chakra, Georges Hobeika, Jean Faris, Nicolas Jebran, Rabih Kayrouz and Abed Mahfouz have achieved international fame.
Twin towns and sister cities.
Beirut is twinned with:
 Lyon, France
Foreign opinion.
Beirut was named the top place to visit by "The New York Times" in 2009, and as one of the ten liveliest cities in the world by Lonely Planet in the same year. According to a 2010 study by the American global consulting firm Mercer comparing high-end items such as upscale residential areas and entertainment venues, Beirut was ranked as the 4th most expensive city in the Middle East and 15th among the Upper Middle Income Countries included in the survey. Beirut came in first place regionally and 10th place internationally in a 2010 study by "EuroCost International" about the rental markets for high quality housing. 2011 MasterCard Index revealed that Beirut had the second-highest visitor spending levels in the Middle East and Africa, totaling $6.5 billion. Beirut was chosen in 2012 by Condé Nast Traveler as the best city in the Middle East.
Condé Nast Reader choice awards 2013 selected Beirut as the 20th best city in the world, with a score of 81.0, tied with Seville, Spain.
On 7 December 2014, Beirut was selected to be among the New 7 Wonders of Cities, along with Doha, Durban, La Paz, Havana, Kuala Lampur and Vigan. The campaign was held by New 7 Wonders.

</doc>
<doc id="37431" url="http://en.wikipedia.org/wiki?curid=37431" title="Solvent">
Solvent

A solvent (from the Latin "solvō", "I loosen, untie, I solve") is a substance that dissolves a solute (a chemically different liquid, solid or gas), resulting in a solution. A solvent is usually a liquid but can also be a solid or a gas. The quantity of solute that can dissolve in a specific volume of solvent varies with temperature. Common uses for organic solvents are in dry cleaning (e.g., tetrachloroethylene), as paint thinners (e.g., toluene, turpentine), as nail polish removers and glue solvents (acetone, methyl acetate, ethyl acetate), in spot removers (e.g., hexane, petrol ether), in detergents (citrus terpenes) and in perfumes (ethanol). Solvents find various applications in chemical, pharmaceutical, oil and gas industries, including in chemical syntheses and purification processes.
The global solvent market is expected to earn revenues of about US$33 billion in 2019. The dynamic economic development in emerging markets like China, India or Brazil will especially continue to boost demand for solvents. Specialists expect the worldwide solvent consumption to increase at an average annual rate of 2.5% over the subsequent years. Accordingly, the growth rate seen during the past eight years will be surpassed.
Solutions and solvation.
When one substance is dissolved into another, a solution is formed. This is opposed to the situation when the compounds are insoluble like sand in water. In a solution, all of the ingredients are uniformly distributed at a molecular level and no residue remains. A solvent-solute mixture consists of a single phase with all solute molecules occurring as "solvates" (solvent-solute complexes), as opposed to separate continuous phases as in suspensions, emulsions and other types of non-solution mixtures. The ability of one compound to be dissolved in another is known as solubility; if this occurs in all proportions, it is called miscibility.
In addition to mixing, the substances in a solution interact with each other at the molecular level. When something is dissolved, molecules of the solvent arrange around molecules of the solute. Heat transfer is involved and entropy is increased making the solution more thermodynamically stable than the solute and solvent separately. This arrangement is mediated by the respective chemical properties of the solvent and solute, such as hydrogen bonding, dipole moment and polarizability. Solvation does not cause a chemical reaction or chemical configuration changes in the solute. However, solvation resembles a coordination complex formation reaction, often with considerable energetics (heat of solvation and entropy of solvation) and is thus far from a neutral process.
Solvent classifications.
Solvents can be broadly classified into two categories: "polar" and "non-polar". Generally, the dielectric constant of the solvent provides a rough measure of a solvent's polarity. The strong polarity of water is indicated, at 0 °C, by a dielectric constant of 88. Solvents with a dielectric constant of less than 15 are generally considered to be nonpolar. The dielectric constant measures the solvent's tendency to partly cancel the field strength of the electric field of a charged particle immersed in it. This reduction is then compared to the field strength of the charged particle in a vacuum. Heuristically, the dielectric constant of a solvent can be thought of as its ability to reduce the solute's effective internal charge. Generally, the dielectric constant of a solvent is an acceptable predictor of the solvent's ability to dissolve common ionic compounds, such as salts.
Other polarity scales.
Dielectric constants are not the only measure of polarity. Because solvents are used by chemists to carry out chemical reactions or observe chemical and biological phenomena, more specific measures of polarity are required. Most of these measures are sensitive to chemical context.
"The Grunwald Winstein mY scale" measures polarity in terms of solvent influence on buildup of positive charge of a solute during a chemical reaction.
"Kosower's Z scale" measures polarity in terms of the influence of the solvent on UV-absorption maxima of a salt, usually pyridinium iodide or the pyridinium zwitterion.
"Donor number and donor acceptor scale" measures polarity in terms of how a solvent interacts with specific substances, like a strong Lewis acid or a strong Lewis base.
The Hildebrand parameter is the square root of cohesive energy density. It can be used with nonpolar compounds, but cannot accommodate complex chemistry.
Reichardt's dye, a solvatochromic dye that changes color in response to polarity, gives a scale of "ET"(30) values. "ET" is the transition energy between the ground state and the lowest excited state in kcal/mol, and (30) identifies the dye. Another, roughly correlated scale ("ET"(33)) can be defined with Nile red.
The polarity, dipole moment, polarizability and hydrogen bonding of a solvent determines what type of compounds it is able to dissolve and with what other solvents or liquid compounds it is miscible. Generally, polar solvents dissolve polar compounds best and non-polar solvents dissolve non-polar compounds best: "like dissolves like". Strongly polar compounds like sugars (e.g., sucrose) or ionic compounds, like inorganic salts (e.g., table salt) dissolve only in very polar solvents like water, while strongly non-polar compounds like oils or waxes dissolve only in very non-polar organic solvents like hexane. Similarly, water and hexane (or vinegar and vegetable oil) are not miscible with each other and will quickly separate into two layers even after being shaken well.
Polarity can be separated to different contributions. For example, the Kamlet-Taft parameters are dipolarity/polarizability ("π*"), hydrogen-bonding acidity ("α") and hydrogen-bonding basicity ("β"). These can be calculated from the wavelength shifts of 3–6 different solvatochromic dyes in the solvent, usually including Reichardt's dye, nitroaniline and diethylnitroaniline. Another option, Hansen's parameters, separate the cohesive energy density into dispersion, polar and hydrogen bonding contributions.
Polar protic and polar aprotic.
Solvents with a relative static permittivity greater than 15 (i.e. polar or polarizable) can be further divided into protic and aprotic. Protic solvents solvate anions (negatively charged solutes) strongly via hydrogen bonding. Water is a protic solvent. Aprotic solvents such as acetone or dichloromethane tend to have large dipole moments (separation of partial positive and partial negative charges within the same molecule) and solvate positively charged species via their negative dipole. In chemical reactions the use of polar protic solvents favors the SN1 reaction mechanism, while polar aprotic solvents favor the SN2 reaction mechanism.
Physical properties of common solvents.
Properties table of common solvents.
The solvents are grouped into non-polar, polar aprotic, and polar protic solvents and ordered by increasing polarity. The polarity is given as the dielectric constant. The properties of solvents that exceed those of water are bolded.
Hansen solubility parameter values.
The Hansen solubility parameter values are based on dispersion bonds (δD), polar bonds (δP) and hydrogen bonds (δH). These contain information about the inter-molecular interactions with other solvents and also with polymers, pigments, nanoparticles, etc. This allows for rational formulations knowing, for example, that there is a good HSP match between a solvent and a polymer. Rational substitutions can also be made for "good" solvents (effective at dissolving the solute) that are "bad" (expensive or hazardous to health or the environment). The following table shows that the intuitions from "non-polar", "polar aprotic" and "polar protic" are put numerically – the "polar" molecules have higher levels of δP and the protic solvents have higher levels of δH. Because numerical values are used, comparisons can be made rationally by comparing numbers. For example, acetonitrile is much more polar than acetone but exhibits slightly less hydrogen bonding.
If, for environmental or other reasons, a solvent or solvent blend is required to replace another of equivalent solvency, the substitution can be made on the basis of the Hansen solubility parameters of each. The values for mixtures are taken as the weighted averages of the values for the neat solvents. This can be calculated by trial-and-error, a spreadsheet of values, or HSP software. A 1:1 mixture of toluene and 1,4 dioxane has δD, δP and δH values of 17.8, 1.6 and 5.5, comparable to those of chloroform at 17.8, 3.1 and 5.7 respectively. Because of the health hazards associated with toluene itself, other mixtures of solvents may be found using a full HSP dataset.
Boiling point.
An important property of solvents is the boiling point. This also determines the speed of evaporation. Small amounts of low-boiling-point solvents like diethyl ether, dichloromethane, or acetone will evaporate in seconds at room temperature, while high-boiling-point solvents like water or dimethyl sulfoxide need higher temperatures, an air flow, or the application of vacuum for fast evaporation.
Density.
Most organic solvents have a lower density than water, which means they are lighter and will form a separate layer on top of water. An important exception: most of the halogenated solvents like dichloromethane or chloroform will sink to the bottom of a container, leaving water as the top layer. This is important to remember when partitioning compounds between solvents and water in a separatory funnel during chemical syntheses.
Often, specific gravity is cited in place of density. Specific gravity is defined as the density of the solvent divided by the density of water at the same temperature. As such, specific gravity is a unitless value. It readily communicates whether a water-insoluble solvent will float (SG < 1.0) or sink (SG > 1.0) when mixed with water.
Health and safety.
Fire.
Most organic solvents are flammable or highly flammable, depending on their volatility. Exceptions are some chlorinated solvents like dichloromethane and chloroform. Mixtures of solvent vapors and air can explode. Solvent vapors are heavier than air; they will sink to the bottom and can travel large distances nearly undiluted. Solvent vapors can also be found in supposedly empty drums and cans, posing a flash fire hazard; hence empty containers of volatile solvents should be stored open and upside down.
Both diethyl ether and carbon disulfide have exceptionally low autoignition temperatures which increase greatly the fire risk associated with these solvents. The autoignition temperature of carbon disulfide is below 100 °C (212 °F), so objects such as steam pipes, light bulbs, hotplates and recently extinguished bunsen burners are able to ignite its vapours.
Explosive peroxide formation.
Ethers like diethyl ether and tetrahydrofuran (THF) can form highly explosive organic peroxides upon exposure to oxygen and light, THF is normally more able to form such peroxides than diethyl ether. One of the most susceptible solvents is diisopropyl ether.
The heteroatom (oxygen) stabilizes the formation of a free radical which is formed by the abstraction of a hydrogen atom by another free radical. The carbon centred free radical thus formed is able to react with an oxygen molecule to form a peroxide compound. A range of tests can be used to detect the presence of a peroxide in an ether; one is to use a combination of iron sulfate and potassium thiocyanate. The peroxide is able to oxidize the Fe2+ ion to an Fe3+ ion which then form a deep red coordination complex with the thiocyanate. In extreme cases the peroxides can form crystalline solids within the vessel of the ether.
Unless the desiccant used can destroy the peroxides, they will concentrate during distillation due to their higher boiling point. When sufficient peroxides have formed, they can form a crystalline and shock sensitive solid precipitate. When this solid is formed at the mouth of the bottle, turning the cap may provide sufficient energy for the peroxide to detonate. Peroxide formation is not a significant problem when solvents are used up quickly; they are more of a problem for laboratories which take years to finish a single bottle. Ethers have to be stored in the dark in closed canisters in the presence of stabilizers like butylated hydroxytoluene (BHT) or over sodium hydroxide.
Peroxides may be removed by washing with acidic iron(II) sulfate, filtering through alumina, or distilling from sodium/benzophenone. Alumina does not destroy the peroxides; it merely traps them. The advantage of using sodium/benzophenone is that moisture and oxygen are removed as well.
Health effects.
General health hazards associated with solvent exposure include toxicity to the nervous system, reproductive damage, liver and kidney damage, respiratory impairment, cancer, and dermatitis.
Many solvents can lead to a sudden loss of consciousness if inhaled in large amounts. Solvents like diethyl ether and chloroform have been used in medicine as anesthetics, sedatives, and hypnotics for a long time. Ethanol (grain alcohol) is a widely used and abused psychoactive drug. Diethyl ether, chloroform, and many other solvents (e.g., from gasoline or glues) are used recreationally in glue sniffing, often with harmful long term health effects like neurotoxicity or cancer. Fraudulent substitution of 1,5-pentanediol for the psychoactive 1,4-butanediol by a subcontractor caused the Bindeez product recall.
If ingested, alcohols (other than ethanol) such as methanol, propanol and ethylene glycol metabolize into toxic aldehydes and acids, which cause potentially fatal metabolic acidosis. Thus, the commonly available alcohol solvent methanol can cause permanent blindness and death if ingested, and is also dangerous because it burns with an invisible flame. The solvent 2-butoxyethanol, used in fracking fluids, can cause hypotension and metabolic acidosis.
Some solvents including chloroform and benzene (an ingredient of gasoline) are carcinogenic. Many others can damage internal organs like the liver, the kidneys, or the brain.
Chronic exposure to organic solvents in the work environment can produce a range of adverse neuropsychiatric effects. For example, occupational exposure to organic solvents has been associated with higher numbers of painters suffering from alcoholism. Ethanol has a synergistic effect when taken in combination with many solvents; for instance, a combination of toluene/benzene and ethanol causes greater nausea/vomiting than either substance alone.
Many solvents are known or suspected to be cataractogenic, greatly increasing the risk of developing cataracts of the lens of the eye. Solvent exposure has also been associated with neurotoxic damage to color vision.
Environmental contamination.
A major pathway to induce health effects arises from spills or leaks of solvents that reach the underlying soil. Since solvents readily migrate substantial distances, the creation of widespread soil contamination is not uncommon; there may be about 5000 sites worldwide that have major subsurface solvent contamination; this is particularly a health risk if aquifers are affected.

</doc>
<doc id="37432" url="http://en.wikipedia.org/wiki?curid=37432" title="Westminster">
Westminster

Westminster () is an area of central London within the City of Westminster on the north bank of the River Thames. Westminster's concentration of visitor attractions and historic landmarks, one of the highest in London, includes the Palace of Westminster, Buckingham Palace, Westminster Abbey and Westminster Cathedral.
Historically the area lay within St Margaret's parish, City & Liberty of Westminster, Middlesex.
The name "Westminster" originated from the informal description of the abbey church and royal peculiar of St Peter's (Westminster Abbey's), literally West of the City of London, indeed until the Reformation there was a reference to the 'East Minster' at Minories (Holy Trinity Priory, Aldgate) east of the City; the abbey was part of the royal palace that had been created here by Edward the Confessor. It has been the home of the permanent institutions of England's government continuously since about 1200 (High Middle Ages' Plantagenet times) and is now the seat British government.
In a government context, "Westminster" often refers to the Parliament of the United Kingdom, which is located in the UNESCO World Heritage Palace of Westminster - also known as the Houses of Parliament. The closest tube stations are Westminster, St James Park on the Jubilee and Circle and District lines.
The area is the centre of UK government, with Parliament in the Palace of Westminster and most of the major Government ministries known as Whitehall, itself the site of the royal palace that replaced that at Westminster.
Within the area is Westminster School, a major public school which grew out of the Abbey, and the long established University of Westminster, attended by over 20,000 students. Bounding Westminster to the north is Green Park, a Royal Park of London.
Demography.
The area has a substantial resident population, indeed most of its listed buildings are residential. A proportion of residents are people of limited means, living in council and Peabody Trust estates in certain streets between Westminster Abbey and Millbank. Hotels, large Victorian homes and barracks exist nearer to Buckingham Palace.
History.
It describes an area no more than 1 mi from Westminster Abbey and Palace of Westminster north of the River Thames. The settlement grew up around the palace and abbey, as a service area to them. The need for a parish church, St Margaret's Westminster for the servants of the palace and of the abbey who could not worship there indicates that it had a large enough population as a small village. It became larger and in the Georgian period became connected through urban ribbon development with the City along the Strand. It did not become a viable local government unit until created as a civil parish. However as a result of Henry VIII's Reformation the Abbey was abolished and established as a Cathedral and that is the source of the origin of the parish being described as 'City' although it was only a fraction of the size of the City of London and the Borough of Southwark at that time. Indeed the Cathedral and diocesan status of the church did not last, from only 1539 to 1556, but the 'city' status was retained for a mere parish within Middlesex. As such it had an MP in 1545 but this was not retained and it was part of the county representation until in 1707 it was given two MPs as a new Parliamentary Borough, centuries after the City and Southwark.
Royal seat.
The historic core of Westminster is the former Thorney Island on which Westminster Abbey was built. The abbey became the traditional venue of the coronation of the kings and queens of England from that of Harold Godwinson.
From about 1200, near the abbey, the Palace of Westminster became the principal royal residence, marked by the transfer of royal treasury and financial records to Westminster from Winchester. Later the palace housed the developing Parliament and England's law courts. Thus London developed two focal points: the City of London (financial/economic) and Westminster (political and cultural).
The monarchy later moved to the St James' Palace and the Palace of Whitehall a little towards the north-east and eventually to Buckingham Palace and other palaces. The main law courts have since moved to the Royal Courts of Justice.
Victorian divide.
Charles Booth's poverty map showing Westminster in 1889 showed the full range of income and capital brackets living in adjacent streets within it; its central western area had become (by 1850) (the) Devil's Acre in the southern flood channel ravine of the Tyburn (stream), yet along Victoria Street and other small streets and squares were the highest colouring of social class in London, yellow/gold. The abject poverty with the clearance of this slum and drainage improvement has been shed from Westminster but there is a typical Central London property distinction within the area which is very acute, epitomised by grandiose 21st century developments, architectural high point listed buildings and nearby social housing (mostly non-council housing) buildings of the Peabody Trust founded by philanthropist George Peabody.
Local government.
The Westminster area formed part of the City and Liberty of Westminster in Middlesex. The ancient parish was St Margaret; after 1727 this became the civil parish of 'St Margaret and St John', the latter a new church required for the increasing population. The area around Westminster Abbey formed the extra-parochial Close of the Collegiate Church of St Peter surrounded by — but not part of — either parish. Until 1900 the local council was the combined vestry of St Margaret and St John (also known as the Westminster District Board of Works from 1855 to 1887), which was based at Westminster City Hall on Caxton Street from 1883. The Liberty of Westminster, governed by the Westminster Court of Burgesses, also included St Martin in the Fields and several other parishes and places. Westminster had its own quarter sessions, but the Middlesex sessions also had jurisdiction. The area was transferred from Middlesex to the County of London in 1889 and the local government of Westminster was reformed in 1900 when the court of burgesses and parish vestries were abolished, to be replaced with a metropolitan borough council. The borough was given city status, allowing it to be known as the City of Westminster and its council as Westminster City Council.
Wider uses of the term.
Thus "Westminster" with its focus in public life from earliest days is casually used as a metonym for Parliament and the political community of the United Kingdom generally (the civil service is similarly referred to by the northern sub-neighbourhood it inhabits, "Whitehall") and "Westminster" is consequently also used in reference to the Westminster system, the parliamentary model of democratic government that has evolved in the United Kingdom and for those other nations, particularly in the Commonwealth of Nations and other parts of the former British Empire that adopted it.
The term "Westminster Village", sometimes used in the context of British politics, does not refer to a geographical area at all; employed especially in the phrase "Westminster Village gossip", it denotes a supposedly close social circle of members of parliament, political journalists, so-called spin doctors and others connected to events in the Palace of Westminster and Government Ministries.
References.
</dl>

</doc>
<doc id="37436" url="http://en.wikipedia.org/wiki?curid=37436" title="Emergence">
Emergence

In philosophy, systems theory, science, and art, emergence is a process whereby larger entities, patterns, and regularities arise through interactions among smaller or simpler entities that themselves do not exhibit such properties.
Emergence is central in theories of integrative levels and of complex systems. For instance, the phenomenon "life" as studied in biology is commonly perceived as an emergent property of interacting molecules as studied in chemistry, whose phenomena reflect interactions among elementary particles, modeled in particle physics, that at such higher mass—via substantial conglomeration—exhibit motion as modeled in gravitational physics. Neurobiological phenomena are often presumed to suffice as the underlying basis of psychological phenomena, whereby economic phenomena are in turn presumed to principally emerge.
In philosophy, emergence typically refers to emergentism. Almost all accounts of emergentism include a form of epistemic or ontological irreducibility to the lower levels.
In philosophy.
In philosophy, emergence is often understood to be a claim about the etiology of a system's properties. An emergent property of a system, in this context, is one that is not a property of any component of that system, but is still a feature of the system as a whole. Nicolai Hartmann, one of the first modern philosophers to write on emergence, termed this "categorial novum" (new category).
Definitions.
This idea of emergence has been around since at least the time of Aristotle.  John Stuart Mill and Julian Huxley are two of many scientists and philosophers who have written on the concept.
The term "emergent" was coined by philosopher G. H. Lewes, who wrote:
"Every resultant is either a sum or a difference of the co-operant forces; their sum, when their directions are the same -- their difference, when their directions are contrary. Further, every resultant is clearly traceable in its components, because these are homogeneous and commensurable. It is otherwise with emergents, when, instead of adding measurable motion to measurable motion, or things of one kind to other individuals of their kind, there is a co-operation of things of unlike kinds. The emergent is unlike its components insofar as these are incommensurable, and it cannot be reduced to their sum or their difference."
Economist Jeffrey Goldstein provided a current definition of emergence in the journal "Emergence". Goldstein initially defined emergence as: "the arising of novel and coherent structures, patterns and properties during the process of self-organization in complex systems".
Goldstein's definition can be further elaborated to describe the qualities of this definition in more detail:
"The common characteristics are: (1) radical novelty (features not previously observed in systems); (2) coherence or correlation (meaning integrated wholes that maintain themselves over some period of time); (3) A global or macro "level" (i.e. there is some property of "wholeness"); (4) it is the product of a dynamical process (it evolves); and (5) it is "ostensive" (it can be perceived). For good measure, Goldstein throws in supervenience."
Systems scientist Peter Corning also says that living systems cannot be reduced to underlying laws of physics:
Rules, or laws, have no causal efficacy; they do not in fact “generate” anything. They serve merely to describe regularities and consistent relationships in nature. These patterns may be very illuminating and important, but the underlying causal agencies must be separately specified (though often they are not). But that aside, the game of chess illustrates ... why any laws or rules of emergence and evolution are insufficient. Even in a chess game, you cannot use the rules to predict “history” — i.e., the course of any given game. Indeed, you cannot even reliably predict the next move in a chess game. Why? Because the “system” involves more than the rules of the game. It also includes the players and their unfolding, moment-by-moment decisions among a very large number of available options at each choice point. The game of chess is inescapably historical, even though it is also constrained and shaped by a set of rules, not to mention the laws of physics. Moreover, and this is a key point, the game of chess is also shaped by teleonomic, cybernetic, feedback-driven influences. It is not simply a self-ordered process; it involves an organized, “purposeful” activity.
Strong and weak emergence.
Usage of the notion "emergence" may generally be subdivided into two perspectives, that of "weak emergence" and "strong emergence". In terms of physical systems, weak emergence is a type of emergence in which the emergent property is amenable to computer simulation. This is opposed to the older notion of strong emergence, in which the emergent property cannot be simulated by a computer.
Some common points between the two notions are that emergence concerns new properties produced as the system grows, which is to say ones which are not shared with its components or prior states. Also, it is assumed that the properties are supervenient rather than metaphysically primitive .
Weak emergence describes new properties arising in systems as a result of the interactions at an elemental level. However, it is stipulated that the properties can be determined by observing or simulating the system, and not by any process of a priori analysis.
Bedau notes that weak emergence is not a universal metaphysical solvent, as weak emergence leads to the conclusion that matter itself contains elements of awareness to it. However, Bedau concludes that adopting this view would provide a precise notion that emergence is involved in consciousness, and second, the notion of weak emergence is metaphysically benign .
Strong emergence describes the direct causal action of a high-level system upon its components; qualities produced this way are irreducible to the system's constituent parts . The whole is greater than the sum of its parts. It follows that no simulation of the system can exist, for such a simulation would itself constitute a reduction of the system to its constituent parts .
However, "the debate about whether or not the whole can be predicted from the properties of the parts misses the point. Wholes produce unique combined effects, but many of these effects may be co-determined by the context and the interactions between the whole and its environment(s)" . In accordance with his Synergism Hypothesis , Corning also stated, "It is the synergistic effects produced by wholes that are the very cause of the evolution of complexity in nature." Novelist Arthur Koestler used the metaphor of Janus (a symbol of the unity underlying complements like open/shut, peace/war) to illustrate how the two perspectives (strong vs. weak or holistic vs. reductionistic) should be treated as non-exclusive, and should work together to address the issues of emergence . Further,
The ability to reduce everything to simple fundamental laws does not imply the ability to start from those laws and reconstruct the universe. The constructionist hypothesis breaks down when confronted with the twin difficulties of scale and complexity. At each level of complexity entirely new properties appear. Psychology is not applied biology, nor is biology applied chemistry. We can now see that the whole becomes not merely more, but very different from the sum of its parts. 
The plausibility of strong emergence is questioned by some as contravening our usual understanding of physics. Mark A. Bedau observes:
Although strong emergence is logically possible, it is uncomfortably like magic. How does an irreducible but supervenient downward causal power arise, since by definition it cannot be due to the aggregation of the micro-level potentialities? Such causal powers would be quite unlike anything within our scientific ken. This not only indicates how they will discomfort reasonable forms of materialism. Their mysteriousness will only heighten the traditional worry that emergence entails illegitimately getting something from nothing.
Meanwhile, others have worked towards developing analytical evidence of strong emergence. In 2009, Gu et al. presented a class of physical systems that exhibits non-computable macroscopic properties. More precisely, if one could compute certain macroscopic properties of these systems from the microscopic description of these systems, they one would be able to solve computational problems known to be undecidable in computer science. They concluded that
Although macroscopic concepts are essential for understanding our world, much of fundamental physics has been devoted to the search for a `theory of everything', a set of equations that perfectly describe the behavior of all fundamental particles. The view that this is the goal of science rests in part on the rationale that such a theory would allow us to derive the behavior of all macroscopic concepts, at least in principle. The evidence we have presented suggests that this view may be overly optimistic. A `theory of everything' is one of many components necessary for complete understanding of the universe, but is not necessarily the only one. The development of macroscopic laws from first principles may involve more than just systematic logic, and could require conjectures suggested by experiments, simulations or insight.
Emergent structures are patterns that emerge via collective actions of many individual entities. To explain such patterns, one might conclude, per Aristotle, that emergent structures are more than the sum of their parts on the assumption that the emergent order will not arise if the various parts simply interact independently of one another. However, there are those who disagree. According to this argument, the interaction of each part with its immediate surroundings causes a complex chain of processes that can lead to order in some form. In fact, some systems in nature are observed to exhibit emergence based upon the interactions of autonomous parts, and some others exhibit emergence that at least at present cannot be reduced in this way.
Objective or subjective quality.
The properties of complexity and organization of any system are considered by Crutchfield to be subjective qualities determined by the observer.
"Defining structure and detecting the emergence of complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analysed in terms of how model-building observers infer from measurements the computational capabilities embedded in non-linear processes. An observer’s notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of raw measurement data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtly, though, on how those resources are organized. The descriptive power of the observer’s chosen (or implicit) computational model class, for example, can be an overwhelming determinant in finding regularity in data."
On the other hand, Peter Corning argues "Must the synergies be perceived/observed in order to qualify as emergent effects, as some theorists claim? Most emphatically not. The synergies associated with emergence are real and measurable, even if nobody is there to observe them." 
In religion, art and humanities.
In religion, emergence grounds expressions of religious naturalism in which a sense of the sacred is perceived in the workings of entirely naturalistic processes by which more complex forms arise or evolve from simpler forms. Examples are detailed in a 2006 essay titled 'The Sacred Emergence of Nature' by Ursula Goodenough and Terrence Deacon and a 2006 essay titled by Stuart Kauffman.
An early argument (1904-5) for the emergence of social formations, in part stemming from religion, can be found in Max Weber's most famous work, "The Protestant Ethic and the Spirit of Capitalism" 
In art, emergence is used to explore the origins of novelty, creativity, and authorship. Some art/literary theorists (Wheeler, 2006; Alexander, 2011 have proposed alternatives to postmodern understandings of "authorship" using the complexity sciences and emergence theory. They contend that artistic selfhood and meaning are emergent, relatively objective phenomena. Michael J. Pearce has used emergence to describe the experience of works of art in relation to contemporary neuroscience.) The concept of emergence has also been applied to the theory of literature and art, history, linguistics, cognitive sciences, etc. by the teachings of Jean-Marie Grassin at the (v. esp.: J. Fontanille, B. Westphal, J. Vion-Dury, éds. L'Émergence—Poétique de l'Émergence, en réponse aux travaux de Jean-Marie Grassin, Bern, Berlin, etc., 2011; and: the article " in the ". 
In international development, concepts of emergence have been used within a theory of social change termed SEED-SCALE to show how standard principles interact to bring forward socio-economic development fitted to cultural values, community economics, and natural environment (local solutions emerging from the larger socio-econo-biosphere). These principles can be implemented utilizing a sequence of standardized tasks that self-assemble in individually specific ways utilizing recursive evaluative criteria.
In postcolonial studies, the term "Emerging Literature" refers to a contemporary body of texts that is gaining momentum in the global literary landscape (v. esp.: J.M. Grassin, ed. "Emerging Literatures", Bern, Berlin, etc. : Peter Lang, 1996). By opposition, "emergent literature" is rather a concept used in the theory of literature.
Emergent properties and processes.
An emergent behavior or emergent property can appear when a number of simple entities (agents) operate in an environment, forming more complex behaviors as a collective. If emergence happens over disparate size scales, then the reason is usually a causal relation across different scales. In other words there is often a form of top-down feedback in systems with emergent properties. The processes from which emergent properties result may occur in either the observed or observing system, and can commonly be identified by their patterns of accumulating change, most generally called 'growth'. Emergent behaviours can occur because of intricate causal relations across different scales and feedback, known as interconnectivity. The emergent property itself may be either very predictable or unpredictable and unprecedented, and represent a new level of the system's evolution. The complex behaviour or properties are not a property of any single such entity, nor can they easily be predicted or deduced from behaviour in the lower-level entities, and might in fact be irreducible to such behavior. The shape and behaviour of a flock of birds or school of fish are good examples of emergent properties.
One reason why emergent behaviour is hard to predict is that the number of interactions between components of a system increases exponentially with the number of components, thus potentially allowing for many new and subtle types of behaviour to emerge.
On the other hand, merely having a large number of interactions is not enough by itself to guarantee emergent behaviour; many of the interactions may be negligible or irrelevant, or may cancel each other out. In some cases, a large number of interactions can in fact work against the emergence of interesting behaviour, by creating a lot of "noise" to drown out any emerging "signal"; the emergent behaviour may need to be temporarily isolated from other interactions before it reaches enough critical mass to be self-supporting. Thus it is not just the sheer number of connections between components which encourages emergence; it is also how these connections are organised. A hierarchical organisation is one example that can generate emergent behaviour (a bureaucracy may behave in a way quite different from that of the individual humans in that bureaucracy); but perhaps more interestingly, emergent behaviour can also arise from more decentralized organisational structures, such as a marketplace. In some cases, the system has to reach a combined threshold of diversity, organisation, and connectivity before emergent behaviour appears.
Unintended consequences and side effects are closely related to emergent properties. Luc Steels writes: "A component has a particular functionality but this is not recognizable as a subfunction of the global functionality. Instead a component implements a behaviour whose side effect contributes to the global functionality [...] Each behaviour has a side effect and the sum of the side effects gives the desired functionality" . In other words, the global or macroscopic functionality of a system with "emergent functionality" is the sum of all "side effects", of all emergent properties and functionalities.
Systems with emergent properties or emergent structures may appear to defy entropic principles and the second law of thermodynamics, because they form and increase order despite the lack of command and central control. This is possible because open systems can extract information and order out of the environment.
Emergence helps to explain why the fallacy of division is a fallacy.
Emergent structures in nature.
Emergent structures can be found in many natural phenomena, from the physical to the biological domain. For example, the shape of weather phenomena such as hurricanes are emergent structures. The development and growth of complex, orderly crystals, as driven by the random motion of water molecules within a conducive natural environment, is another example of an emergent process, where randomness can give rise to complex and deeply attractive, orderly structures.
 However, crystalline structure and hurricanes are said to have a self-organizing phase.
It is useful to distinguish three forms of emergent structures. A "first-order" emergent structure occurs as a result of shape interactions (for example, hydrogen bonds in water molecules lead to surface tension). A "second-order" emergent structure involves shape interactions played out sequentially over time (for example, changing atmospheric conditions as a snowflake falls to the ground build upon and alter its form). Finally, a "third-order" emergent structure is a consequence of shape, time, and heritable instructions. For example, an organism's genetic code sets boundary conditions on the interaction of biological systems in space and time.
Non-living, physical systems.
In physics, emergence is used to describe a property, law, or phenomenon which occurs at macroscopic scales (in space or time) but not at microscopic scales, despite the fact that a macroscopic system can be viewed as a very large ensemble of microscopic systems.
An emergent property need not be more complicated than the underlying non-emergent properties which generate it. For instance, the laws of thermodynamics are remarkably simple, even if the laws which govern the interactions between component particles are complex. The term emergence in physics is thus used not to signify complexity, but rather to distinguish which laws and concepts apply to macroscopic scales, and which ones apply to microscopic scales.
Some examples include:
Temperature is sometimes used as an example of an emergent macroscopic behaviour. In classical dynamics, a "snapshot" of the instantaneous momenta of a large number of particles at equilibrium is sufficient to find the average kinetic energy per degree of freedom which is proportional to the temperature. For a small number of particles the instantaneous momenta at a given time are not statistically sufficient to determine the temperature of the system. However, using the ergodic hypothesis, the temperature can still be obtained to arbitrary precision by further averaging the momenta over a long enough time.
Convection in a liquid or gas is another example of emergent macroscopic behaviour that makes sense only when considering differentials of temperature. Convection cells, particularly Bénard cells, are an example of a self-organizing system (more specifically, a dissipative system) whose structure is determined both by the constraints of the system and by random perturbations: the possible realizations of the shape and size of the cells depends on the temperature gradient as well as the nature of the fluid and shape of the container, but which configurations are actually realized is due to random perturbations (thus these systems exhibit a form of symmetry breaking).
In some theories of particle physics, even such basic structures as mass, space, and time are viewed as emergent phenomena, arising from more fundamental concepts such as the Higgs boson or strings. In some interpretations of quantum mechanics, the perception of a deterministic reality, in which all objects have a definite position, momentum, and so forth, is actually an emergent phenomenon, with the true state of matter being described instead by a wavefunction which need not have a single position or momentum.
Most of the laws of physics themselves as we experience them today appear to have emerged during the course of time making emergence the most fundamental principle in the universe and raising the question of what might be the most fundamental law of physics from which all others emerged. Chemistry can in turn be viewed as an emergent property of the laws of physics. Biology (including biological evolution) can be viewed as an emergent property of the laws of chemistry. Similarly, psychology could be understood as an emergent property of neurobiological laws. Finally, free-market theories understand economy as an emergent feature of psychology.
In Laughlin's book, he explains that for many particle systems, nothing can be calculated exactly from the microscopic equations, and that macroscopic systems are characterised by broken symmetry: the symmetry present in the microscopic equations is not present in the macroscopic system, due to phase transitions. As a result, these macroscopic systems are described in their own terminology, and have properties that do not depend on many microscopic details. This does not mean that the microscopic interactions are irrelevant, but simply that you do not see them anymore — you only see a renormalized effect of them. Laughlin is a pragmatic theoretical physicist: if you cannot, possibly ever, calculate the broken symmetry macroscopic properties from the microscopic equations, then what is the point of talking about reducibility?
Living, biological systems.
Emergence and evolution.
Life is a major source of complexity, and evolution is the major process behind the varying forms of life. In this view, evolution is the process describing the growth of complexity in the natural world and in speaking of the emergence of complex living beings and life-forms, this view refers therefore to processes of sudden changes in evolution.
Life is thought to have emerged in the early RNA world when RNA chains began to express the basic conditions necessary for natural selection to operate as conceived by Darwin: heritability, variation of type, and competition for limited resources. Fitness of an RNA replicator (its per capita rate of increase) would likely be a function of adaptive capacities that were intrinsic (in the sense that they were determined by the nucleotide sequence) and the availability of resources. The three primary adaptive capacities may have been (1) the capacity to replicate with moderate fidelity (giving rise to both heritability and variation of type); (2) the capacity to avoid decay; and (3) the capacity to acquire and process resources. These capacities would have been determined initially by the folded configurations of the RNA replicators (see “Ribozyme”) that, in turn, would be encoded in their individual nucleotide sequences. Competitive success among different replicators would have depended on the relative values of these adaptive capacities.
Regarding causality in evolution Peter Corning observes:
"Synergistic effects of various kinds have played a major causal role in the evolutionary process generally and in the evolution of cooperation and complexity in particular... Natural selection is often portrayed as a “mechanism”, or is personified as a causal agency... In reality, the differential “selection” of a trait, or an adaptation, is a consequence of the functional effects it produces in relation to the survival and reproductive success of a given organism in a given environment. It is these functional effects that are ultimately responsible for the trans-generational continuities and changes in nature." 
Per his definition of emergence, Corning also addresses emergence and evolution:
"[In] evolutionary processes, causation is iterative; effects are also causes. And this is equally true of the synergistic effects produced by emergent systems. In other words, emergence itself... has been the underlying cause of the evolution of emergent phenomena in biological evolution; it is the synergies produced by organized systems that are the key." 
Swarming is a well-known behaviour in many animal species from marching locusts to schooling fish to flocking birds. Emergent structures are a common strategy found in many animal groups: colonies of ants, mounds built by termites, swarms of bees, shoals/schools of fish, flocks of birds, and herds/packs of mammals.
An example to consider in detail is an ant colony. The queen does not give direct orders and does not tell the ants what to do. Instead, each ant reacts to stimuli in the form of chemical scent from larvae, other ants, intruders, food and buildup of waste, and leaves behind a chemical trail, which, in turn, provides a stimulus to other ants. Here each ant is an autonomous unit that reacts depending only on its local environment and the genetically encoded rules for its variety of ant. Despite the lack of centralized decision making, ant colonies exhibit complex behavior and have even been able to demonstrate the ability to solve geometric problems. For example, colonies routinely find the maximum distance from all colony entrances to dispose of dead bodies.
Organization of life.
A broader example of emergent properties in biology is viewed in the biological organisation of life, ranging from the subatomic level to the entire biosphere. For example, individual atoms can be combined to form molecules such as polypeptide chains, which in turn fold and refold to form proteins, which in turn create even more complex structures. These proteins, assuming their functional status from their spatial conformation, interact together and with other molecules to achieve higher biological functions and eventually create an organism. Another example is how cascade phenotype reactions, as detailed in chaos theory, arise from individual genes mutating respective positioning. At the highest level, all the biological communities in the world form the biosphere, where its human participants form societies, and the complex interactions of meta-social systems such as the stock market.
In humanity.
Spontaneous order.
Groups of human beings, left free to each regulate themselves, tend to produce spontaneous order, rather than the meaningless chaos often feared. This has been observed in society at least since Chuang Tzu in ancient China. A classic traffic roundabout is a good example, with cars moving in and out with such effective organization that some modern cities have begun replacing stoplights at problem intersections with traffic circles , and getting better results. Open-source software and Wiki projects form an even more compelling illustration.
Emergent processes or behaviours can be seen in many other places, such as cities, cabal and market-dominant minority phenomena in economics, organizational phenomena in computer simulations and cellular automata. Whenever you have a multitude of individuals interacting with one another, there often comes a moment when disorder gives way to order and something new emerges: a pattern, a decision, a structure, or a change in direction (Miller 2010, 29).
Economics.
The stock market (or any market for that matter) is an example of emergence on a grand scale. As a whole it precisely regulates the relative security prices of companies across the world, yet it has no leader; when no central planning is in place, there is no one entity which controls the workings of the entire market. Agents, or investors, have knowledge of only a limited number of companies within their portfolio, and must follow the regulatory rules of the market and analyse the transactions individually or in large groupings. Trends and patterns emerge which are studied intensively by technical analysts.
World Wide Web and the Internet.
The World Wide Web is a popular example of a decentralized system exhibiting emergent properties. There is no central organization rationing the number of links, yet the number of links pointing to each page follows a power law in which a few pages are linked to many times and most pages are seldom linked to. A related property of the network of links in the World Wide Web is that almost any pair of pages can be connected to each other through a relatively short chain of links. Although relatively well known now, this property was initially unexpected in an unregulated network. It is shared with many other types of networks called small-world networks .
Internet traffic can also exhibit some seemingly emergent properties. In the congestion control mechanism, TCP flows can become globally synchronized at bottlenecks, simultaneously increasing and then decreasing throughput in coordination. Congestion, widely regarded as a nuisance, is possibly an emergent property of the spreading of bottlenecks across a network in high traffic flows which can be considered as a phase transition [see review of related research in ].
Another important example of emergence in web-based systems is social bookmarking (also called collaborative tagging). In social bookmarking systems, users assign tags to resources shared with other users, which gives rise to a type of information organisation that emerges from this crowdsourcing process. Recent research which analyzes empirically the complex dynamics of such systems has shown that consensus on stable distributions and a simple form of shared vocabularies does indeed emerge, even in the absence of a central controlled vocabulary. Some believe that this could be because users who contribute tags all use the same language, and they share similar semantic structures underlying the choice of words. The convergence in social tags may therefore be interpreted as the emergence of structures as people who have similar semantic interpretation collaboratively index online information, a process called semantic imitation.
Open-source software, or Wiki projects such as Wikipedia and Wikivoyage are other impressive examples of emergence. The "zeroeth law of Wikipedia" is often cited by its editors to highlight its apparently surprising and unpredictable quality: "The problem with Wikipedia is that it only works in practice. In theory, it can never work."
Architecture and cities.
Emergent structures appear at many different levels of organization or as spontaneous order. Emergent self-organization appears frequently in cities where no planning or zoning entity predetermines the layout of the city. The interdisciplinary study of emergent behaviors is not generally considered a homogeneous field, but divided across its application or problem domains.
Architects and Landscape Architects may not design all the pathways of a complex of buildings. Instead they might let usage patterns emerge and then place pavement where pathways have become worn in.
The on-course action and vehicle progression of the 2007 Urban Challenge could possibly be regarded as an example of cybernetic emergence. Patterns of road use, indeterministic obstacle clearance times, etc. will work together to form a complex emergent pattern that can not be deterministically planned in advance.
The architectural school of Christopher Alexander takes a deeper approach to emergence attempting to rewrite the process of urban growth itself in order to affect form, establishing a new methodology of planning and design tied to traditional practices, an . Urban emergence has also been linked to theories of urban complexity and urban evolution .
Building ecology is a conceptual framework for understanding architecture and the built environment as the interface between the dynamically interdependent elements of buildings, their occupants, and the larger environment. Rather than viewing buildings as inanimate or static objects, building ecologist Hal Levin views them as interfaces or intersecting domains of living and non-living systems. The microbial ecology of the indoor environment is strongly dependent on the building materials, occupants, contents, environmental context and the indoor and outdoor climate. The strong relationship between atmospheric chemistry and indoor air quality and the chemical reactions occurring indoors. The chemicals may be nutrients, neutral or biocides for the microbial organisms. The microbes produce chemicals that affect the building materials and occupant health and well being. Humans manipulate the ventilation, temperature and humidity to achieve comfort with the concomitant effects on the microbes that populate and evolve.
Eric Bonabeau's attempt to define emergent phenomena is through traffic: "traffic jams are actually very complicated and mysterious. On an individual level, each driver is trying to get somewhere and is following (or breaking) certain rules, some legal (the speed limit) and others societal or personal (slow down to let another driver change into your lane). But a traffic jam is a separate and distinct entity that emerges from those individual behaviors. Gridlock on a highway, for example, can travel backward for no apparent reason, even as the cars are moving forward." He has also likened emergent phenomena to the analysis of market trends and employee behavior.
Computational emergent phenomena have also been utilized in architectural design processes, for example for formal explorations and experiments in digital materiality.
Computer AI.
Some artificially intelligent computer applications utilize emergent behavior for animation. One example is Boids, which mimics the swarming behavior of birds.
Language.
It has been argued that the structure and regularity of language--grammar, or at least language change, is an emergence phenomenon . While each speaker merely tries to reach his or her own communicative goals, he or she uses language in a particular way. If enough speakers behave in that way, language is changed . In a wider sense, the norms of a language, i.e. the linguistic conventions of its speech society, can be seen as a system emerging from long-time participation in communicative problem-solving in various social circumstances. 
Emergent change processes.
Within the field of group facilitation and organization development, there have been a number of new group processes that are designed to maximize emergence and self-organization, by offering a minimal set of effective initial conditions. Examples of these processes include SEED-SCALE, Appreciative Inquiry, Future Search, the World Cafe or Knowledge Cafe, Open Space Technology, and others. (Holman, 2010)

</doc>
<doc id="37438" url="http://en.wikipedia.org/wiki?curid=37438" title="Complex system">
Complex system

A complex system is a damped, driven system (for example, a harmonic oscillator) whose total energy exceeds the threshold for it to perform according to classical mechanics but does not reach the threshold for the system to exhibit properties according to chaos theory.
History.
Although it is arguable that humans have been studying complex systems for thousands of years, the modern scientific study of complex systems is relatively young in comparison to conventional fields of science with simple system assumptions, such as physics and chemistry. The history of the scientific study of these systems follows several different research trends.
In the area of mathematics, arguably the largest contribution to the study of complex systems was the discovery of chaos in deterministic systems, a feature of certain dynamical systems that is strongly related to nonlinearity. The study of neural networks was also integral in advancing the mathematics needed to study complex systems.
The notion of self-organizing systems is tied up to work in nonequilibrium thermodynamics, including that pioneered by chemist and Nobel laureate Ilya Prigogine in his study of dissipative structures.
Types of complex systems.
Chaotic systems.
For a dynamical system to be classified as chaotic, it must have the following properties:
Sensitivity to initial conditions means that each point in such a system is arbitrarily closely approximated by other points with significantly different future trajectories. Thus, an arbitrarily small perturbation of the current trajectory may lead to significantly different future behavior.
Complex adaptive systems.
Complex adaptive systems (CAS) are special cases of complex systems. They are complex in that they are diverse and made up of multiple interconnected elements and adaptive in that they have the capacity to change and learn from experience. Examples of complex adaptive systems include the stock market, social insect and ant colonies, the biosphere and the ecosystem, the brain and the immune system, the cell and the developing embryo, manufacturing businesses and any human social group-based endeavor in a cultural and social system such as political parties or communities. This includes some large-scale online systems, such as collaborative tagging or social bookmarking systems.
Nonlinear system.
The behavior of nonlinear systems is not subject to the principle of superposition while that of linear systems is subject to superposition. Thus, a complex nonlinear system is one whose behavior can't be expressed as a sum of the behaviors of its parts (or of their multiples).
Topics on complex systems.
Features of complex systems.
Complex systems may have the following features:

</doc>
<doc id="37439" url="http://en.wikipedia.org/wiki?curid=37439" title="AAI RQ-7 Shadow">
AAI RQ-7 Shadow

The RQ-7 Shadow unmanned aerial vehicle (UAV) is used by the United States Army, Marine Corps, Australian Army and Swedish Army for reconnaissance, surveillance, target acquisition and battle damage assessment. Launched from a trailer-mounted pneumatic catapult, it is recovered with the aid of arresting gear similar to jets on an aircraft carrier. Its gimbal-mounted, digitally stabilized, liquid nitrogen-cooled electro-optical/infrared (EO/IR) camera relays video in real time via a C-band line-of-sight data link to the ground control station (GCS).
In the US, the Army's 2nd Battalion, 13th Aviation Regiment at Fort Huachuca, AZ, trains soldiers, Marines, and civilians in the operation and maintenance of the Shadow UAV. 
Design.
The RQ-7 Shadow 200 unmanned aerial vehicle is of a high-wing, constant chord pusher configuration with a twin-tailboom empennage and an inverted v-tail elerudder. The aircraft is powered by a 38 bhp AR741-1101 Wankel engine designed and manufactured by UAV Engines Ltd in the United Kingdom. Onboard electrical systems are powered by a GEC/Plessey 28 volt, direct current, 2,000 watt generator. Currently, the primary payload for the aircraft is the Israeli Aircraft Industries POP300 Plug-in Optical Payload which consists of a forward-looking Infrared camera, a daytime TV camera with a selectable near-infrared filter and a laser pointer. The aircraft has fixed tricycle landing gear. Takeoffs are assisted by a trailer-mounted pneumatic launcher which can accelerate the 375 pound aircraft to 70 kn in 50 ft. Landings are guided by a Tactical Automatic Landing System, developed by the Sierra Nevada Corporation, which consists of a ground-based micro-millimeter wavelength radar and a transponder carried on the aircraft. Once on the ground, a tailhook mounted on the aircraft catches an arresting wire connected to two disk brake drums which can stop the aircraft in less than 170 ft.
The aircraft is part of a larger system which currently uses the M1152-series of Humvees for ground transport of all ground and air equipment. A Shadow 200 system consists of four aircraft, three of which are transported in the Air Vehicle Transporter (AVT). The fourth is transported in a specially designed storage container to be used as a spare. The AVT also tows the launcher. The AVT Support Vehicle and trailer contain extra equipment to launch and recover the aircraft, such as the Tactical Automatic Landing System. Maintenance equipment for the aircraft is stored in the Maintenance Section Multifunctional (MSM) vehicle and trailer as well as the M1165 MSM Support Vehicle and its associated trailer. 
Two Humvee-mounted Ground Control Stations (GCS), also part of the Shadow 200 system, control the aircraft in flight. Each station has an associated Ground Data Terminal (GDT), which takes commands generated by the GCS and modulates them into radio waves received by the aircraft in flight. The GDT receives video imagery from the payload, as well as telemetry from the aircraft, and sends this information to the GCS. A trailer, towed by the M1165 GCS support vehicle, carries the GDT and houses a 10 kW Tactical Quiet Generator to provide power for its associated GCS. The Shadow 200 system also includes a Portable Ground Control Station (PGCS) and Portable Ground Data Terminal (PGDT), which are stripped-down versions of the GCS and GDT designed as a backup to the two GCSs.
A fielded Shadow 200 system requires 22 soldiers to operate it. Army modelling indicates that crew workload is highest at takeoff, and second-highest at landing.
Development.
The RQ-7 Shadow is the result of a continued US Army search for an effective battlefield UAV after the cancellation of the RQ-6 Outrider aircraft. AAI Corporation followed up their RQ-2 Pioneer with the Shadow 200, a similar, more refined UAV. In late 1999, the army selected the Shadow 200 to fill the tactical UAV requirement, redesignating it the RQ-7. Army requirements specified a UAV that used a gasoline engine, could carry an electro-optic/infrared imaging sensor turret, and had a minimum range of 31 miles (50 kilometers) with four-hour, on-station endurance. The Shadow 200 offered at least twice that range, powered by a 38 hp rotary engine. The specifications also dictated that UAV would be able to land in an athletic field.
Operational history.
By July 2007, the Shadow platform accumulated 200,000 flight hours, doubling its previous record of 100,000 hours in 13 months. The system then surpassed 300,000 flight hours in April 2008, and by May 2010, the Shadow system had accumulated over 500,000 flight hours. As of 2011, the Shadow had logged over 709,000 hours. The Shadow platform has flown over 37,000 sorties in support of operations in Iraq and Afghanistan by US Army and Army National Guard units. On 6 August 2012, AAI announced that the Shadow had achieved 750,000 flight hours during more than 173,000 missions. More than 900,000 flight hours had been logged by Shadow UAVs by the end of June 2014.
Shadow did not see service in the Afghanistan campaign of 2001–2002, but it did fly operational missions in support of Operation Iraqi Freedom. The operating conditions in Iraq proved hard on the UAVs, with heat and sand leading to engine failures, resulting in a high-priority effort to find fixes with changes in system technology and operating procedures. Shadow UAVs have since flown more than 600,000 combat hours in support of the Wars in Iraq and Afghanistan. 
In 2007, the United States Marine Corps began to transition from the RQ-2 Pioneer to the RQ-7 Shadow. VMU-1, VMU-2 have completed their transition from the RQ-2 to the RQ-7 and ScanEagle while VMU-3 and VMU-4 have been activated as Shadow and ScanEagle elements. VMU-3, was activated on 12 September 2008 and VMU-4 conducted its inaugural flight on 28 September 2010 in Yuma, Arizona. In October 2007, VMU-1 became the first Marine Corps squadron to see combat in Iraq. VMU-2 deployed a Shadow detachment to Afghanistan in 2009, with VMU-3 following in January 2010.
The Navy provided personnel for four Shadow platoons in support of army brigades deployed in Iraq. The first two platoons returned from 6-month tours in Iraq in January and February 2008. The Navy personnel went through the Army's training program at Fort Huachuca, Arizona.
The U.S. Army is considering a plan to reform its aerial scout capabilities by scrapping its fleet of OH-58 Kiowa helicopters from 2015-2019 and replacing them with AH-64 Apache attack helicopters teamed with Shadow and MQ-1C Grey Eagle UAVs. Using unmanned assets to scout ahead would put the pilots of manned aircraft out of reach of potential harm. Reformed combat aviation brigades (CAB) would consist of a battalion of 24 Apaches for attack missions and an armed reconnaissance squadron of another 24 Apaches teamed with three Shadow platoons totaling 12 RQ-7s overall; it would also include a Grey Eagle company. The manned-unmanned teaming of Apaches and UAVs can meet 80 percent of aerial scout requirements.
In early July 2014, the U.S. Army sent RQ-7 Shadows to Baghdad as part of efforts to protect embassy personnel against Islamic State militant attacks. The Shadows were shipped along with Apache attack helicopters, which may be able to use them through manned/unmanned teaming to share information and designate targets.
On 16 March 2015, the 1st Battalion, 501st Aviation Regiment was reflagged the 3rd Squadron, 6th Cavalry Regiment, making it the first of 10 Apache battalions to be converted to a heavy attack reconnaissance squadron by eliminating the Kiowa scout helicopter and having three RQ-7 Shadow platoons organically assigned; the attack battalions will also be aligned with the MQ-1C Gray Eagle company assigned to each division. Moving Shadows from brigade combat team level to the battalions themselves reduces lines of communication, distance issues, and allows operators and pilots to better train and work together. The unit is equipped with the RQ-7BV2 Shadow version, which has new capabilities including encryption of video and control data-links, software that allows interoperability between other UAS platforms, integration of a common control station and control terminal for all Army UAS platforms, and increased endurance to nine hours.
RQ-7 in civilian airspace.
The Shadow system has also received a special airworthiness certificate (experimental) from the Federal Aviation Administration authorizing operations at Benson Municipal Airport, a general aviation facility in southeastern Arizona. This airworthiness certificate is the first issued by the FAA permitting an unmanned aircraft to operate at a public-use airport that serves general aviation, and the first FAA certificate covering the system's technologically sophisticated automated landing system. This is currently the only FAA certification category available to UAS manufacturers.
Variants.
RQ-7A Shadow.
The RQ-7A was the initial version of the Shadow 200 UAV developed by AAI. The first low-rate initial-production systems were delivered to the US Army in 2002 with the first full-scale production systems being delivered in September 2003. The RQ-7A was 11 ft long and had a wingspan of 12 ft with a 327 lb max takeoff weight. The aircraft's endurance ranged between 4 to 5.5 hours depending on mission. The "A" model aircraft also had the AR741-1100 engine which could use either 87 octane automotive gasoline or 100LL aviation fuel. The "A" model also featured IAI's POP200 payload.
RQ-7B Shadow.
Production of Shadow aircraft shifted to a generally improved RQ-7B variant in the summer of 2004. The RQ-7B features new wings increased in length to 14 ft. The new wings are not only more aerodynamically efficient, they are "wet" to increase fuel storage up to 44 liters for an endurance of up to 6 hours. The payload capability has been increased to 45 kg. After reports from Iraq that engines were failing, in 2005, the Army's UAV project manager called for the use of 100LL, an aviation fuel, rather than the conventional 87 octane mogas. Avionics systems have been generally improved, and the new wing is designed to accommodate a communications relay package, which allows the aircraft to act as a relay station. This allows commanders or even the aircraft operators themselves to communicate via radio to the troops on ground in locations that would otherwise be "dead" to radio traffic.
Other incremental improvements to the system include replacing the AR741-1100 engine with the AR741-1101 which increases reliability through the use of dual spark plugs as well as limiting the fuel to 100LL. Also, the older POP200 payload was replaced with the newer POP300 system.
In February 2010, AAI began a fleet update program to improve the Shadow system. The improvements include installing the wiring harnesses and software updates for IAI's POP300D payload which includes a designator for guiding laser-guided bombs. Other improvements in the program will include an electronic fuel injection engine and fuel system to replace the AR741-1101's carburetored engine. The most visible improvement to the system will be a wider wing of 20 ft in span which is designed to increase fuel capacity and allow for mission endurance of almost 9 hours. The new wings will also include hardpoints for external munitions.
Preliminary TCDL testing conducted at Dugway Proving Ground was a success. This led to an estimated fielding date of May 2010 for TCDL.
A joint Army-Marine program is testing IED jamming on a Shadow at MCAS Yuma. Another joint effort is to view a 4x4km ground area from 12,000 feet.
A test version called STTB has been flown in Summer 2011. AAI is developing a bigger version called M2 with a blended wing to include a 3-cylinder 60 hp Lycoming heavy fuel engine, and began flight testing in August 2012. The M2 Shadow is expected to be fielded in 2015. The M2 Shadow has 80 percent commonality with the Shadow 200 but has a different center fuselage giving it greater range and loiter-on-target time with a dual payload capability.
The Army is now proposing the upgraded Shadow 152A, which includes Soldier Radio Waveform software, which allows both the command post and their troops to see the images that the UAV is projecting, as long as they are on the same frequency. It also increases the distance and area of communication.
Armed Shadow.
On 19 April 2010 the Army issued a "solicitation for sources sought" from defense contractors for a munition for the Shadow system with a deadline for proposals due no later than 10 May 2010. Although no specific munition has been chosen yet, some possible munitions include the General Dynamics 81 mm 10-pound air-dropped guided mortar, as well as the QuickMEDS system for delivering medical supplies to remote and stranded troops. The Army subsequently slowed work, and the Marine Corps then took the lead on arming the RQ-7 Shadow. Raytheon has conducted successful flight tests with the Small Tactical Munition, and Lockheed Martin has tested the Shadow Hawk glide weapon from an RQ-7. On 1 November 2012, General Dynamics successfully demonstrated their guided 81 mm Air Dropped Mortar, with three launches at 7,000 ft hitting within seven meters of the target grid.
As of August 2011, the Marine Corps has received official clearance to experiment with armed RQ-7s, and requires AAI to select a precision munition ready for deployment. AAI was awarded $10 million for this in December 2011, and claims a weapon has already been fielded by the Shadow. In 2014, Textron launched the Fury precision weapon from a Shadow 200.
By May 2015, the Marine Corps had run out of funding for weaponizing the RQ-7, and the Army had shown little interest in continuing the effort. The Army's stance is that the Shadow's primary capability is persistent surveillance, while there are many other ways to drop bombs on targets and adding that to the Shadow would add weight and decrease endurance.
Shadow 600.
AAI has also built a scaled-up Pioneer derivative known as the "Shadow 600". It also resembles a Pioneer, except that the outer panels of the wings are distinctively swept back, and it has a stronger Wankel engine, the UAV EL 801, with 52 hp. A number of Shadow 600s are in service in several nations, including Romania.
SR/C Shadow.
AAI, in conjunction with Textron sister company Bell Helicopter, intends to modify two Shadows with a Carter rotor on top for vertical take-off and landing, eliminating the need for the recovery and pneumatic launcher systems, while increasing payload and endurance. s of August 2011[ [update]], it is expected to fly in 2012. AAI also expected to use the SR/C technology for the Shadow Knight, a powered-rotor two-propeller surveillance aircraft for the US Navy MRMUAS program; however, the MRMUAS program was cancelled in 2012.
Incidents and accidents.
On 15 August 2011 a US Air Force C-130 cargo plane collided with a RQ-7 while on approach to FOB Sharana in Paktika Province, Afghanistan. The C-130 made an emergency landing with damage to two engines and one wing, while the RQ-7 was destroyed completely. The collision caused the cargo aircraft to be grounded for several months while being fixed, while the RQ-7 wreckage was never recovered. Early reports indicating that the mishap occurred when the C-130 took off without clearance were incorrect. The investigating board determined that the mishap was largely due to poor local air traffic control training and supervision.
On 3 April 2014 a Pennsylvania National Guard RQ-7 participating in training exercises at Fort Indiantown Gap crashed near an elementary school in Pennsylvania and was then hit by a civilian vehicle destroying the drone. No injuries were reported.
Specifications (200 Family).
"Data from" 
Note: When outfitted with IE (Increased Endurance) Wings, the CRP (Communications Relay Package) and the 1102 engine, endurance time is increased to 9 hours, wing span is increased to approx. 22 ft, and the service ceiling is 18,000 ft (only with authorization).

</doc>
<doc id="37441" url="http://en.wikipedia.org/wiki?curid=37441" title="Nitrous oxide">
Nitrous oxide

Nitrous oxide, commonly known as laughing gas, nitrous, nitro, or NOS is a chemical compound with the formula N2O. It is an oxide of nitrogen. At room temperature, it is a colourless, non-flammable gas, with a slightly sweet odour and taste. It is used in surgery and dentistry for its anaesthetic and analgesic effects. It is known as "laughing gas" due to the euphoric effects of inhaling it, a property that has led to its recreational use as a dissociative anaesthetic. It is also used as an oxidizer in the launching of rockets and in motor racing to increase the power output of engines. At elevated temperatures, nitrous oxide is a powerful oxidizer similar to molecular oxygen.
Nitrous oxide gives rise to nitric oxide (NO) on reaction with oxygen atoms, and this NO in turn reacts with ozone. As a result, it is the main naturally occurring regulator of stratospheric ozone. It is also a major greenhouse gas and air pollutant. Considered over a 100-year period, it has 298 times more impact per unit mass (global-warming potential) than carbon dioxide.
It is on the WHO Model List of Essential Medicines, the most important medications needed in a health system.
Applications.
Rocket motors.
Nitrous oxide can be used as an oxidizer in a rocket motor. This has the advantages over other oxidisers in that it is not only non-toxic, but also, due to its stability at room temperature, easy to store and relatively safe to carry on a flight. As a secondary benefit it can be readily decomposed to form breathing air. Its high density and low storage pressure (when maintained at low temperature) enable it to be highly competitive with stored high-pressure gas systems.
In a 1914 patent, American rocket pioneer Robert Goddard suggested nitrous oxide and gasoline as possible propellants for a liquid-fuelled rocket. Nitrous oxide has been the oxidiser of choice in several hybrid rocket designs (using solid fuel with a liquid or gaseous oxidizer). The combination of nitrous oxide with hydroxyl-terminated polybutadiene fuel has been used by SpaceShipOne and others. It is also notably used in amateur and high power rocketry with various plastics as the fuel.
Nitrous oxide can also be used in a monopropellant rocket. In the presence of a heated catalyst, N2O will decompose exothermically into nitrogen and oxygen, at a temperature of approximately 1070 °F.http://spg-corp.com/nitrous-oxide-safety.html Because of the large heat release, the catalytic action rapidly becomes secondary as thermal autodecomposition becomes dominant. In a vacuum thruster, this can provide a monopropellant specific impulse ("I"sp) of as much as 180 s. While noticeably less than the "I"sp available from hydrazine thrusters (monopropellant or bipropellant with dinitrogen tetroxide), the decreased toxicity makes nitrous oxide an option worth investigating.
Nitrous oxide is said to deflagrate somewhere around 600 C at a pressure of 21 atmospheres. It can also easily be ignited using a combination of the two. At 600  for example, the required ignition energy is only 6 joules, whereas N2O at 130 psi a 2500-joule ignition energy input is insufficient.
Specific impulse ("I"sp) can be improved by blending a hydrocarbon fuel with the nitrous oxide inside the same storage tank, becoming a nitrous oxide fuel blend (NOFB) monopropellant. This storage mixture does not incur the danger of spontaneous ignition, since N2O is chemically stable. When the nitrous oxide decomposes by a heated catalyst, high temperature oxygen is released and rapidly ignites the hydrocarbon fuel-blend. NOFB monopropellants are capable of I greater than 300 seconds, while avoiding the toxicity associated with hypergolic propulsion systems. The low freezing point of NOFB eases thermal management compared to hydrazine and dinitrogen tetroxide—a valuable property for space storable propellants.
Internal combustion engine.
In vehicle racing, nitrous oxide (often referred to as just "nitrous") allows the engine to burn more fuel by providing more oxygen than air alone, resulting in a more powerful combustion. The gas itself is not flammable at a low pressure/temperature, but it delivers more oxygen than atmospheric air by breaking down at elevated temperatures. Therefore, it is often mixed with another fuel that is easier to deflagrate.
Nitrous oxide is stored as a compressed liquid; the evaporation and expansion of liquid nitrous oxide in the intake manifold causes a large drop in intake charge temperature, resulting in a denser charge, further allowing more air/fuel mixture to enter the cylinder. Nitrous oxide is sometimes injected into (or prior to) the intake manifold, whereas other systems directly inject right before the cylinder (direct port injection) to increase power.
The technique was used during World War II by Luftwaffe aircraft with the GM-1 system to boost the power output of aircraft engines. Originally meant to provide the Luftwaffe standard aircraft with superior high-altitude performance, technological considerations limited its use to extremely high altitudes. Accordingly, it was only used by specialized planes like high-altitude reconnaissance aircraft, high-speed bombers, and high-altitude interceptor aircraft.
One of the major problems of using nitrous oxide in a reciprocating engine is that it can produce enough power to damage or destroy the engine. Very large power increases are possible, and if the mechanical structure of the engine is not properly reinforced, the engine may be severely damaged or destroyed during this kind of operation. It is very important with nitrous oxide augmentation of petrol engines to maintain proper operating temperatures and fuel levels to prevent "pre-ignition", or "detonation" (sometimes referred to as "knock"). Most problems that are associated with nitrous do not come from mechanical failure due to the power increases. Since nitrous allows a much denser charge into the cylinder it dramatically increases cylinder pressures. The increased pressure and temperature can cause problems such as melting the piston or valves. It may also crack or warp the piston or head and cause pre-ignition due to uneven heating.
Automotive-grade liquid nitrous oxide differs slightly from medical-grade nitrous oxide. A small amount of sulfur dioxide (SO2) is added to prevent substance abuse. Multiple washes through a base (such as sodium hydroxide) can remove this, decreasing the corrosive properties observed when SO2 is further oxidised during combustion into sulfuric acid, making emissions cleaner.
Aerosol propellant.
The gas is approved for use as a food additive (also known as E942), specifically as an aerosol spray propellant. Its most common uses in this context are in aerosol whipped cream canisters, cooking sprays, and as an inert gas used to displace oxygen, to inhibit bacterial growth, when filling packages of potato chips and other similar snack foods.
The gas is extremely soluble in fatty compounds. In aerosol whipped cream, it is dissolved in the fatty cream until it leaves the can, when it becomes gaseous and thus creates foam. Used in this way, it produces whipped cream four times the volume of the liquid, whereas whipping air into cream only produces twice the volume. If air were used as a propellant, oxygen would accelerate rancidification of the butterfat; nitrous oxide inhibits such degradation. Carbon dioxide cannot be used for whipped cream because it is acidic in water, which would curdle the cream and give it a seltzer-like "sparkling" sensation.
However, the whipped cream produced with nitrous oxide is unstable and will return to a more liquid state within half an hour to one hour. Thus, the method is not suitable for decorating food that will not be immediately served.
Similarly, cooking spray, which is made from various types of oils combined with lecithin (an emulsifier), may use nitrous oxide as a propellant; other propellants used in cooking spray include food-grade alcohol and propane.
Users of nitrous oxide often obtain it from whipped cream dispensers that use nitrous oxide as a propellant (see above section), for recreational use as a euphoria-inducing inhalant drug. It is not harmful in small doses, but risks due to lack of oxygen do exist (see "Recreational use below).
Medicine.
Nitrous oxide has been used for anaesthesia in dentistry since December 1844, where Horace Wells made the first 12–15 dental operations with the gas in Hartford. Its debut as a generally accepted method, however, came in 1863, when Gardner Quincy Colton introduced it more broadly at all the Colton Dental Association clinics, that he founded in New Haven and New York City. The first devices used in dentistry to administer the gas, known as Nitrous Oxide inhalers, were designed in a very simple way with the gas stored and breathed through a breathing bag made of rubber cloth, without a scavenger system and flowmeter, and with no addition of oxygen/air. Today these simple and somewhat unreliable inhalers have been replaced by the more modern relative analgesia machine, which is an automated machine designed to deliver a precisely dosed and breath-actuated flow of nitrous oxide mixed with oxygen, for the patient to inhale safely. The machine used in dentistry is designed as a simplified version of the larger anaesthetic machine used by hospitals, as it doesn't feature the additional anaesthetic vaporiser and medical ventilator. The purpose of the machine allows for a simpler design, as it only delivers a mixture of nitrous oxide and oxygen for the patient to inhale, in order to depress the feeling of pain while keeping the patient in a conscious state.
Relative analgesia machines typically feature a constant-supply flowmeter, which allow the proportion of nitrous oxide and the combined gas flow rate to be individually adjusted. The gas is administered by dentists through a demand-valve inhaler over the nose, which will only release gas when the patient inhales through the nose. Because nitrous oxide is minimally metabolised in humans (with a rate of 0.004%), it retains its potency when exhaled into the room by the patient, and can pose an intoxicating and prolonged exposure hazard to the clinic staff if the room is poorly ventilated. Where nitrous oxide is administered, a continuous-flow fresh-air ventilation system or nitrous scavenger system is used to prevent a waste-gas buildup.
Hospitals administer nitrous oxide as one of the anaesthetic drugs delivered by anaesthetic machines. Nitrous oxide is a weak general anaesthetic, and so is generally not used alone in general anaesthesia. In general anaesthesia it is used as a carrier gas in a 2:1 ratio with oxygen for more powerful general anaesthetic drugs such as sevoflurane or desflurane. It has a minimum alveolar concentration of 105% and a blood/gas partition coefficient of 0.46.
The medical grade gas tanks, with the tradename Entonox and Nitronox contain a mixture with 50%, but this will normally be diluted to a lower percentage upon the operational delivery to the patient. Inhalation of nitrous oxide is frequently used to relieve pain associated with childbirth, trauma, oral surgery, and acute coronary syndrome (includes heart attacks). Its use during labour has been shown to be a safe and effective aid for women wanting to give birth without an epidural. Its use for acute coronary syndrome is of unknown benefit.
In Britain and Canada, Entonox and Nitronox are commonly used by ambulance crews (including unregistered practitioners) as a rapid and highly effective analgesic gas.
Nitrous oxide has been shown to be effective in treating a number of addictions, including alcohol withdrawal.
Nitrous oxide is also gaining interest as a substitute gas for carbon dioxide in laparoscopic surgery. It has been found to be as safe as carbon dioxide with better pain relief.
Recreational use.
Nitrous oxide can cause analgesia, depersonalisation, derealisation, dizziness, euphoria, and some sound distortion. Research has also found that it increases suggestibility and imagination. Inhalation of nitrous oxide for recreational use, with the purpose of causing euphoria and/or slight hallucinations, began as a phenomenon for the British upper class in 1799, known as "laughing gas parties". Until at least 1863, a low availability of equipment to produce the gas, combined with a low usage of the gas for medical purposes, meant it was a relatively rare phenomenon that mainly happened among students at medical universities. When equipment became more widely available for dentistry and hospitals, most countries also restricted the legal access to buy pure nitrous oxide gas cylinders to those sectors. Despite only medical staff and dentists today being legally allowed to buy the pure gas, a Consumers Union report from 1972 found that the use of the gas for recreational purpose was [then] still taking place, based upon reports of its use in Maryland 1971, Vancouver 1972, and a survey made by Dr. Edward J. Lynn of its non-medical use in Michigan 1970.
It was not uncommon [in the interviews] to hear from individuals who had been to parties where a professional (doctor, nurse, scientist, inhalation therapist, researcher) had provided nitrous oxide. There also were those who work in restaurants who used the N2O stored in tanks for the preparation of whip cream. Reports were received from people who used the gas contained in aerosol cans both of food and non-food products. At a recent rock festival nitrous oxide was widely sold for 25 cents a balloon. Contact was made with a "mystical-religious" group that used the gas to accelerate arriving at their transcendental-meditative state of choice. Although a few, more sophisticated users employed nitrous oxide-oxygen mixes with elaborate equipment, most users used balloons or plastic bags. They either held a breath of N2O or rebreathed the gas. There were no adverse effects reported in the more than one hundred individuals surveyed.
In Australia, nitrous oxide bulbs are known as nangs, possibly derived from the sound distortion perceived by consumers.
In the United Kingdom, nitrous oxide is used by almost half a million young people at nightspots, festivals and parties.
Mechanism of action.
The pharmacological mechanism of action of N2O in medicine is not fully known. However, it has been shown to directly modulate a broad range of ligand-gated ion channels, and this likely plays a major role in many of its effects. It moderately blocks NMDA and β2-subunit-containing nACh channels, weakly inhibits AMPA, kainate, GABAC, and 5-HT3 receptors, and slightly potentiates GABAA and glycine receptors. It has also been shown to activate two-pore-domain K+ channels. While N2O affects quite a few ion channels, its anaesthetic, hallucinogenic, and euphoriant effects are likely caused predominantly or fully via inhibition of NMDAR-mediated currents. In addition to its effects on ion channels, N2O may act to imitate nitric oxide (NO) in the central nervous system, and this may be related to its analgesic and anxiolytic properties.
Anxiolytic effect.
In behavioural tests of anxiety, a low dose of N2O is an effective anxiolytic, and this anti-anxiety effect is associated with enhanced activity of GABAA receptors, as it is partially reversed by benzodiazepine receptor antagonists. Mirroring this, animals which have developed tolerance to the anxiolytic effects of benzodiazepines are partially tolerant to N2O. Indeed, in humans given 30% N2O, benzodiazepine receptor antagonists reduced the subjective reports of feeling "high", but did not alter psychomotor performance, in human clinical studies.
Analgesic effect.
The analgesic effects of N2O are linked to the interaction between the endogenous opioid system and the descending noradrenergic system. When animals are given morphine chronically they develop tolerance to its pain-killing effects, and this also renders the animals tolerant to the analgesic effects of N2O. Administration of antibodies which bind and block the activity of some endogenous opioids (not β-endorphin) also block the antinociceptive effects of N2O. Drugs which inhibit the breakdown of endogenous opioids also potentiate the antinociceptive effects of N2O. Several experiments have shown that opioid receptor antagonists applied directly to the brain block the antinociceptive effects of N2O, but these drugs have no effect when injected into the spinal cord.
Conversely, α2-adrenoceptor antagonists block the pain reducing effects of N2O when given directly to the spinal cord, but not when applied directly to the brain. Indeed, α2B-adrenoceptor knockout mice or animals depleted in norepinephrine are nearly completely resistant to the antinociceptive effects of N2O. Apparently N2O-induced release of endogenous opioids causes disinhibition of brain stem noradrenergic neurons, which release norepinephrine into the spinal cord and inhibit pain signalling. Exactly how N2O causes the release of endogenous opioid peptides is still uncertain.
Euphoric effect.
In rats, N2O stimulates the mesolimbic reward pathway via inducing dopamine release and activating dopaminergic neurons in the ventral tegmental area and nucleus accumbens, presumably through antagonisation of NMDA receptors localised in the system. This action has been implicated in its euphoric effects, and notably, appears to augment its analgesic properties as well.
However, it is remarkable that in mice, N2O blocks amphetamine-induced carrier-mediated dopamine release in the nucleus accumbens and behavioural sensitisation, abolishes the conditioned place preference (CPP) of cocaine and morphine, and does not produce reinforcing (or aversive) effects of its own. Studies on CPP of N2O in rats is mixed, consisting of reinforcement, aversion, and no change. In contrast, it is a positive reinforcer in squirrel monkeys, and is well known as a drug of abuse in humans. These discrepancies in response to N2O may reflect species variation or methodological differences. In human clinical studies, N2O was found to produce mixed responses similarly to rats, reflecting high subjective individual variability.
Neurotoxicity and neuroprotection.
Like other NMDA antagonists, N2O was suggested to produce neurotoxicity in the form of Olney's lesions in rodents upon prolonged (several hour) exposure. However, new research has arisen suggesting that Olney's lesions do not occur in humans, and similar drugs like ketamine are now believed not to be acutely neurotoxic. It has been argued that, because N2O has a very short duration under normal circumstances, it is less likely to be neurotoxic than other NMDA antagonists. Indeed, in rodents, short-term exposure results in only mild injury that is rapidly reversible, and permanent neuronal death only occurs after constant and sustained exposure. Nitrous oxide may also cause neurotoxicity after extended exposure because of hypoxia. This is especially true of non-medical formulations such as whipped-cream chargers (also known as "whippets"), which are not necessarily mixed with oxygen.
Additionally, nitrous oxide depletes vitamin B12 levels. This can cause serious neurotoxicity with even acute use if the user has preexisting vitamin B12 deficiency.
Nitrous oxide is also neuroprotective, inhibiting glutamate-induced excitotoxicity.
Safety.
The major safety hazards of nitrous oxide come from the fact that it is a compressed liquefied gas, an asphyxiation risk, and a dissociative anaesthetic. Exposure to nitrous oxide causes short-term decreases in mental performance, audiovisual ability, and manual dexterity. Long-term exposure can cause vitamin B#redirect [[Template:Smallsub]]
[[Category:Superscript and subscript templates]] deficiency, numbness, reproductive side effects (in pregnant females), and other problems (see "Biological").
The National Institute for Occupational Safety and Health recommends that workers' exposure to nitrous oxide should be controlled during the administration of anaesthetic gas in medical, dental, and veterinary operators.
Chemical/physical.
At room temperature (20 °C) the saturated vapour pressure is 58.5 bar, rising up to 72.45 bar at 36.4 C—the critical temperature. The pressure curve is thus unusually sensitive to temperature. Liquid nitrous oxide acts as a good solvent for many organic compounds; liquid mixtures may form shock sensitive explosives.
As with many strong oxidisers, contamination of parts with fuels have been implicated in rocketry accidents, where small quantities of nitrous/fuel mixtures explode due to "water hammer"-like effects (sometimes called "dieseling"—heating due to adiabatic compression of gases can reach decomposition temperatures). Some common building materials such as stainless steel and aluminium can act as fuels with strong oxidisers such as nitrous oxide, as can contaminants, which can ignite due to adiabatic compression.
There have also been accidents where nitrous oxide decomposition in plumbing has led to the explosion of large tanks.
Biological.
Nitrous oxide inactivates the cobalamin form of vitamin B12 by oxidation. Symptoms of vitamin B12 deficiency, including sensory neuropathy, myelopathy, and encephalopathy, can occur within days or weeks of exposure to nitrous oxide anaesthesia in people with subclinical vitamin B12 deficiency. Symptoms are treated with high doses of vitamin B12, but recovery can be slow and incomplete. People with normal vitamin B12 levels have stores to make the effects of nitrous oxide insignificant, unless exposure is repeated and prolonged (nitrous oxide abuse). Vitamin B12 levels should be checked in people with risk factors for vitamin B12 deficiency prior to using nitrous oxide anaesthesia.
A study of workers
and several experimental animal studies indicate that adverse reproductive effects for pregnant females may also result from chronic exposure to nitrous oxide.
Nitrous oxide reductase is an important enzyme which limits the emission of the gas to the atmosphere.
Environmental.
N2O is a greenhouse gas with a large global warming potential (GWP). When compared to carbon dioxide (CO2), N2O has 298 times the ability per molecule of gas to trap heat in the atmosphere. N2O is produced naturally in the soil during the microbial processes of nitrification and denitrification.
The United States of America signed and ratified the United Nations Framework Convention on Climate Change () in 1992, agreeing to inventory and assess the various sources of greenhouse gases that contribute to climate change. The agreement requires parties to "develop, periodically update, publish and make available... national inventories of anthropogenic emissions by sources and removals by sinks of all greenhouse gases not controlled by the Montreal Protocol, using comparable methodologies...". In response to this agreement, the U.S. is obligated to inventory anthropogenic emissions by sources and sinks, of which agriculture is a key contributor. In 2008, agriculture contributed 6.1% of the total U.S. greenhouse gas emissions and cropland contributed nearly 69% of total direct nitrous oxide (N2O) emissions. Additionally, estimated emissions from agricultural soils were 6% higher in 2008 than 1990.
According to 2006 data from the United States Environmental Protection Agency, industrial sources make up only about 20% of all anthropogenic sources, and include the production of nylon, and the burning of fossil fuel in internal combustion engines. Human activity is thought to account for 30%; tropical soils and oceanic release account for 70%. However, a 2008 study by Nobel Laureate Paul Crutzen suggests that the amount of nitrous oxide release attributable to agricultural nitrate fertilizers has been seriously underestimated, most of which would presumably come under soil and oceanic release in the Environmental Protection Agency data. Atmospheric levels have risen by more than 15% since 1750. Nitrous oxide also causes ozone depletion. A new study suggests that N#redirect 
O emission currently is the single most important ozone-depleting substance (ODS) emission and is expected to remain the largest throughout the 21st century.
Production.
Nitrous oxide is most commonly prepared by careful heating of ammonium nitrate, which decomposes into nitrous oxide and water vapour. The addition of various phosphates favours formation of a purer gas at slightly lower temperatures. One of the earliest commercial producers was George Poe in Trenton, New Jersey.
This reaction occurs between 170 and, temperatures where ammonium nitrate is a moderately sensitive explosive and a very powerful oxidizer. Above 240 C the exothermic reaction may accelerate to the point of detonation, so the mixture must be cooled to avoid such a disaster. Superheated steam is used to reach reaction temperature in some turnkey production plants.
Downstream, the hot, corrosive mixture of gases must be cooled to condense the steam, and filtered to remove higher oxides of nitrogen. Ammonium nitrate smoke, as an extremely persistent colloid, will also have to be removed. The cleanup is often done in a train of three gas washes; namely base, acid and base again. Any significant amounts of nitric oxide (NO) may not necessarily be absorbed directly by the base (sodium hydroxide) washes.
The nitric oxide impurity is sometimes chelated out with ferrous sulfate, reduced with iron metal, or oxidised and absorbed in base as a higher oxide. The first base wash may (or may not) react out much of the ammonium nitrate smoke. However, this reaction generates ammonia gas, which may have to be absorbed in the acid wash.
As a byproduct.
The synthesis of adipic acid; one of the two reactants used in nylon manufacture, produces nitrogen oxides including nitric oxides This might become a major commercial source, but will require the removal of higher oxides of nitrogen and organic impurities. Currently much of the gas is decomposed before release for environmental protection.
Other routes.
Heating a mixture of sodium nitrate and ammonium sulphate.
The reaction of urea, nitric acid and sulfuric acid
Direct oxidation of ammonia with a manganese dioxide-bismuth oxide catalyst: cf. Ostwald process.
Reacting Hydroxylammonium chloride with sodium nitrite. If the nitrite is added to the hydroxylamine solution, the only remaining by-product is salt water. However, if the hydroxylamine solution is added to the nitrite solution (nitrite is in excess), then toxic higher oxides of nitrogen are also formed.
Reacting HNO3 with SnCl2 and HCl:
Hyponitrous acid decomposes to N2O and water with a half-life of 16 days at 25 °C at pH 1–3.
Soil.
Of the entire anthropogenic N2O emission (5.7 teragrams N2O-N per year), agricultural soils provide 3.5 teragrams N2O–N per year. Nitrous oxide is produced naturally in the soil during the microbial processes of nitrification, denitrification, nitrifier denitrification and others:
Soil N2O emissions are reported to be controlled by soil chemical and physical properties such as the availability of mineral N, soil pH, organic matter availability, and soil type, and climate related soil properties such as soil temperature and soil water content (e.g., Mosier, 1994; Bouwman, 1996; Beauchamp, 1997; Yamulki et al. 1997; Dobbie and Smith, 2003; Smith et al. 2003; Dalal et al. 2003).
Properties and reactions.
Nitrous oxide is a colourless, non-toxic gas with a faint, sweet odour.
Nitrous oxide supports combustion by releasing the dipolar bonded oxygen radical,[Name?] thus it can relight a glowing splint.
N2O is inert at room temperature and has few reactions. At elevated temperatures, its reactivity increases. For example, nitrous oxide reacts with NaNH2 at 460 K to give NaN3:
The above reaction is actually the route adopted by the commercial chemical industry to produce azide salts, which are used as detonators.
Occurrence.
Nitrous oxide is emitted by bacteria in soils and oceans, and is thus a part of Earth's atmosphere. Agriculture is the main source of human-produced nitrous oxide: cultivating soil, the use of nitrogen fertilisers, and animal waste handling can all stimulate naturally occurring bacteria to produce more nitrous oxide. The livestock sector (primarily cows, chickens, and pigs) produces 65% of human-related nitrous oxide. Industrial sources make up only about 20% of all anthropogenic sources, and include the production of nylon, and the burning of fossil fuel in internal combustion engines. Human activity is thought to account for 30%; tropical soils and oceanic release account for 70%.
Nitrous oxide reacts with ozone in the stratosphere. Nitrous oxide is the main naturally occurring regulator of stratospheric ozone. Nitrous oxide is a major greenhouse gas. Considered over a 100-year period, it has 298 times more impact per unit weight than carbon dioxide. Thus, despite its low concentration, nitrous oxide is the fourth largest contributor to these greenhouse gases. It ranks behind water vapour, carbon dioxide, and methane. Control of nitrous oxide is part of efforts to curb greenhouse gas emissions.
History.
The gas was first synthesised by English natural philosopher and chemist Joseph Priestley in 1772, who called it "phlogisticated nitrous air" (see phlogiston). Priestley published his discovery in the book "Experiments and Observations on Different Kinds of Air (1775)", where he described how to produce the preparation of "nitrous air diminished", by heating iron filings dampened with nitric acid.
Early use.
The first important use of nitrous oxide was made possible by Thomas Beddoes and James Watt, who worked together to publish the book "Considerations on the Medical Use and on the Production of Factitious Airs (1794)". This book was important for two reasons. First, James Watt had invented a novel machine to produce "Factitious Airs" (i.e. nitrous oxide) and a novel "breathing apparatus" to inhale the gas. Second, the book also presented the new medical theories by Thomas Beddoes, that tuberculosis and other lung diseases could be treated by inhalation of "Factitious Airs".
The machine to produce "Factitious Airs" had three parts: A furnace to burn the needed material, a vessel with water where the produced gas passed through in a spiral pipe (for impurities to be "washed off"), and finally the gas cylinder with a gasometer where the gas produced, "air", could be tapped into portable air bags (made of airtight oily silk). The breathing apparatus consisted of one of the portable air bags connected with a tube to a mouthpiece. With this new equipment being engineered and produced by 1794, the way was paved for clinical trials, which began when Thomas Beddoes in 1798 established the "Pneumatic Institution for Relieving Diseases by Medical Airs" in Hotwells (Bristol). In the basement of the building, a large-scale machine was producing the gases under the supervision of a young Humphry Davy, who was encouraged to experiment with new gases for patients to inhale. The first important work of Davy was examination of the nitrous oxide, and the publication of his results in the book: "Researches, Chemical and Philosophical (1800)". In that publication, Davy notes the analgesic effect of nitrous oxide at page 465 and its potential to be used for surgical operations at page 556.
Despite Davy's discovery that inhalation of nitrous oxide could relieve a conscious person from pain, another 44 years elapsed before doctors attempted to use it for anaesthesia. The use of nitrous oxide as a recreational drug at "laughing gas parties", primarily arranged for the British upper class, became an immediate success beginning in 1799. While the effects of the gas generally make the user appear stuporous, dreamy and sedated, some people also "get the giggles" in a state of euphoria, and frequently erupt in laughter.
Anaesthetic use.
The first time nitrous oxide was used as an anaesthetic drug in the treatment of a patient was when dentist Horace Wells, with assistance by Gardner Quincy Colton and John Mankey Riggs, demonstrated insensitivity to pain from a dental extraction on 11 December 1844. In the following weeks, Wells treated the first 12–15 patients with nitrous oxide in Hartford, and according to his own record only failed in two cases. In spite of these convincing results being reported by Wells to the medical society in Boston already in December 1844, this new method was not immediately adopted by other dentists. The reason for this was most likely that Wells, in January 1845 at his first public demonstration to the medical faculty in Boston, had been partly unsuccessful, leaving his colleagues doubtful regarding its efficacy and safety. The method did not come into general use until 1863, when Gardner Quincy Colton successfully started to use it in all his "Colton Dental Association" clinics, that he had just established in New Haven and New York City. Over the following three years, Colton and his associates successfully administered nitrous oxide to more than 25,000 patients. Today, nitrous oxide is used in dentistry as an anxiolytic, as an adjunct to local anaesthetic.
However, nitrous oxide was not found to be a strong enough anaesthetic for use in major surgery in hospital settings. Being a stronger and more potent anaesthetic, sulfuric ether was instead demonstrated and accepted for use in October 1846, along with chloroform in 1847. When Joseph Thomas Clover invented the "gas-ether inhaler" in 1876, it however became a common practice at hospitals to initiate all anaesthetic treatments with a mild flow of nitrous oxide, and then gradually increase the anaesthesia with the stronger ether/chloroform. Clover's gas-ether inhaler was designed to supply the patient with nitrous oxide and ether at the same time, with the exact mixture being controlled by the operator of the device. It remained in use by many hospitals until the 1930s. Although hospitals today are using a more advanced anaesthetic machine, these machines still use the same principle launched with Clover's gas-ether inhaler, to initiate the anaesthesia with nitrous oxide, before the administration of a more powerful anaesthetic.
Legality.
In the United States, possession of nitrous oxide is legal under federal law and is not subject to DEA purview. It is, however, regulated by the Food and Drug Administration under the Food Drug and Cosmetics Act; prosecution is possible under its "misbranding" clauses, prohibiting the sale or distribution of nitrous oxide for the purpose of human consumption.
Many states have laws regulating the possession, sale, and distribution of nitrous oxide. Such laws usually ban distribution to minors or limit the amount of nitrous oxide that may be sold without special license. For example, in the state of California, possession for recreational use is prohibited and qualifies as a misdemeanour.
In New Zealand, the Ministry of Health has warned that nitrous oxide is a prescription medicine, and its sale or possession without a prescription is an offence under the Medicines Act. This statement would seemingly prohibit all non-medicinal uses of the chemical, though it is implied that only recreational use will be legally targeted.
In India, for general anaesthesia purposes, nitrous oxide is available as Nitrous Oxide IP. India's gas cylinder rules (1985) permit the transfer of gas from one cylinder to another for breathing purposes. This law benefits remote hospitals, which would otherwise suffer as a result of India's geographic immensity. Nitrous Oxide IP is transferred from bulk cylinders (17,000 L capacity gas) to smaller pin-indexed valve cylinders (1,800 L of gas), which are then connected to the yoke assembly of Boyle's machines. Because India's Food & Drug Authority (FDA-India) rules state that transferring a drug from one container to another (refilling) is equivalent to manufacturing, anyone found doing so must possess a drug manufacturing license.

</doc>
<doc id="37442" url="http://en.wikipedia.org/wiki?curid=37442" title="Alliant RQ-6 Outrider">
Alliant RQ-6 Outrider

The Alliant RQ-6 Outrider unmanned aerial vehicle (UAV) was designed to provide near-real-time reconnaissance, surveillance, and target acquisition information to United States Marine Corps air/ground task forces, United States Army brigades, and deployed United States Navy units that was small enough for an entire system to be contained on two Humvees and trailer and transported on a single C-130 Hercules cargo aircraft. 
The project began in 1996 and was cancelled in 1999.
The "R" is the Department of Defense designation for reconnaissance; "Q" means unmanned aircraft system. The "6" refers to its being the sixth of a series of purpose-built unmanned aircraft systems.

</doc>
<doc id="37445" url="http://en.wikipedia.org/wiki?curid=37445" title="Kannada">
Kannada

Kannada or , (ಕನ್ನಡ "kannaḍa", ]) or Canarese/Kanarese , is a Dravidian language spoken predominantly by Kannada people in the South Indian state of Karnataka, and by linguistic minorities in the states of Andhra Pradesh, Telangana, Tamil Nadu, Maharashtra, Kerala and Goa. With roughly 40 million native speakers, who are called Kannadigas ("Kannaḍigaru"), Kannada ranks 33rd in the list of most spoken languages in the world. It is one of the scheduled languages of India and the official and administrative language of the state of Karnataka.
The Kannada language is written using the Kannada script, which evolved from the 5th-century Kadamba script. Kannada is attested epigraphically for about one and a half millennia, and literary Old Kannada flourished in the 6th-century Ganga dynasty and during the 9th-century Rashtrakuta Dynasty. Kannada has an unbroken literary history of over a thousand years.
Based on the recommendations of the Committee of Linguistic Experts, appointed by the Ministry of Culture, the Government of India designated Kannada a classical language of India. In July 2011, a center for the study of classical Kannada was established as part of the Central Institute of Indian Languages at Mysore to facilitate research related to the language.
History.
Kannada is a Southern Dravidian language, and according to Dravidian scholar Sanford Steever, its history can be conventionally divided into three periods; Old Kannada ("halegannada") from 450–1200 A.D., Middle Kannada ("Nadugannada") from 1200–1700 A.D., and Modern Kannada from 1700 to the present. Kannada is influenced to an appreciable extent by Sanskrit. Influences of other languages such as Prakrit and Pali can also be found in Kannada language. The scholar Iravatham Mahadevan proved that Kannada was already a language of rich oral tradition earlier than 3rd century B.C., and based on the native Kannada words found in Prakrit and Tamil inscriptions of that period, Kannada must have been spoken by a widespread and stable population. The scholar K.V. Narayana claims that many tribal languages which are now designated as Kannada dialects could be nearer to the earlier form of the language with lesser influence from other languages.
Influence of Sanskrit and Prakrit.
The sources of influence on literary Kannada grammar appear to be three-fold; Pāṇini's grammar, non-Paninian schools of Sanskrit grammar, particularly "Katantra" and "Sakatayana" schools, and Prakrit grammar. Literary Prakrit seemed to have prevailed in Karnataka since ancient times. The vernacular Prakrit speaking people may have come in contact with the Kannada speakers, thus influencing their language, even before Kannada was used for administrative or liturgical purposes. Kannada phonetics, morphology, vocabulary, grammar and syntax show significant influence of these languages.
Some examples of naturalised ("tadbhava") words of Prakrit origin in Kannada are: "baṇṇa" (color) derived from "vaṇṇa", "hunnime" (new moon) from "puṇṇivā". Examples of naturalized Sanskrit words in Kannada are: "varṇa" (color), "arasu" (king) from "rajan", "paurṇimā", and "rāya" from "rāja" (king). Kannada has numerous borrowed ("tatsama") words such as "dina" (day), "kopa" (anger), "surya" (sun), "mukha" (face), "nimiṣa" (minute) and "anna" (rice).
Early epigraphy.
Pre-old Kannada (or "Purava HaleGannada") was the language of Banavasi in the early Common Era, the Satavahana and Kadamba periods and hence has a history of over 2000 years. The Ashoka rock edict found at Brahmagiri (dated to 230 BC) has been suggested to contain words in identifiable Kannada.
A possibly more definite reference to Kannada is found in the 'Charition mime' of the 1st or 2nd century AD. The farce, written by an unknown author was discovered in the early 20th century at Oxyrynchus in Egypt. The play is concerned with a Greek lady named Charition who has been stranded on the coast of a country bordering the Indian Ocean. The king of this region, and his countrymen, sometimes use their own language, and the sentences they spoke include "Koncha madhu patrakke haki" ("lit" having poured a little wine into the cup separately) and "paanam beretti katti madhuvam ber ettuvenu" ("lit" having taken up the cup separately and having covered it, I shall take wine separately). The language employed in the papyrus indicates that the play is set in one of the numerous small ports on the western coast of India, between Karwar and Mangalore.
The written tradition of Kannada begins in the early centuries of common era. The earliest examples of a full-length Kannada language stone inscription ("shilashaasana") containing Brahmi characters with characteristics attributed to those of proto-Kannada in "Hale Kannada" ("lit" Old Kannada) script can be found in the Halmidi inscription, usually dated c. AD 450, indicating that Kannada had become an administrative language at that time. The Halmidi inscription provides invaluable information about the history and culture of Karnataka. The 5th century Tamatekallu inscription of Chitradurga and the Chikkamagaluru inscription of 500 AD are further examples. Recent reports indicate that the Old Kannada "Nishadi" Inscription discovered on the Chandragiri hill, Shravanabelagola, is older than Halmidi inscription by about fifty to hundred years and may belong to the period AD 350–400. The noted archaeologist and art historian S. Settar is of the opinion that an inscription of the Western Ganga King Kongunivarma (c. 350–370) is also older than the Halmidi inscription.
Over 30,000 inscriptions written in the Kannada language have been discovered so far. Prior to the Halmidi inscription, there is an abundance of inscriptions containing Kannada words, phrases and sentences, proving its antiquity. The 543 AD Badami cliff inscription of Pulakesi I is an example of a Sanskrit inscription in old Kannada script.
The earliest copper plates inscribed in Old Kannada script and language, dated to the early 8th century AD, are associated with Alupa King Aluvarasa II from Belmannu (the Dakshina Kannada district), and display the double crested fish, his royal emblem. The oldest well-preserved palm leaf manuscript in "Old Kannada" is that of "Dhavala". It dates to around the 9th century and is preserved in the Jain Bhandar, Mudbidri, Dakshina Kannada district. The manuscript contains 1478 leaves written using ink.
Coins.
Some early Kadamba Dynasty coins bearing the Kannada inscription "Vira" and "Skandha" were found in Satara collectorate. A gold coin bearing three inscriptions of "Sri" and an abbreviated inscription of king Bhagiratha's name called "bhagi" (c. AD 390–420) in old Kannada exists. A Kadamba copper coin dated to the 5th century AD with the inscription "Srimanaragi" in Kannada script was discovered in Banavasi, Uttara Kannada district. Coins with Kannada legends have been discovered spanning the rule of the Western Ganga Dynasty, the Badami Chalukyas, the Alupas, the Western Chalukyas, the Rashtrakutas, the Hoysalas, the Vijayanagar Empire, the Kadamba Dynasty of Banavasi, the Keladi Nayakas and the Mysore Kingdom, the Badami Chalukya coins being a recent discovery. The coins of the Kadambas of Goa are unique in that they have alternate inscription of the king's name in Kannada and Devanagari in triplicate, a few coins of the Kadambas of Hangal are also available.
Literature.
Old Kannada.
The oldest existing record of Kannada poetry in "tripadi" metre is the Kappe Arabhatta record of AD 700. "Kavirajamarga" by King Nripatunga Amoghavarsha I (AD 850) is the earliest existing literary work in Kannada. It is a writing on literary criticism and poetics meant to standardise various written Kannada dialects used in literature in previous centuries. The book makes reference to Kannada works by early writers such as King Durvinita of the 6th century and Ravikirti, the author of the Aihole record of 636 AD. Since the earliest available Kannada work is one on grammar and a guide of sorts to unify existing variants of Kannada grammar and literary styles, it can be safely assumed that literature in Kannada must have started several centuries earlier. An early extant prose work, the "Vaddaradhane" by Shivakotiacharya of AD 900 provides an elaborate description of the life of Bhadrabahu of Shravanabelagola.
Kannada works from earlier centuries mentioned in the Kavirajamarga are not yet traced. Some ancient texts now considered extinct but referenced in later centuries are "Prabhrita" (AD 650) by Syamakundacharya, "Chudamani" (Crest Jewel—AD 650) by Srivaradhadeva, also known as Tumbuluracharya, which is a work of 96,000 verse-measures and a commentary on logic ("Tatwartha-mahashastra"). Other sources date "Chudamani" to the 6th century or earlier. The "Karnateshwara Katha", a eulogy for King Pulakesi II, is said to have belonged to the 7th century; the "Gajastaka", a work on elephant management by King Shivamara II, belonged to the 8th century, and the "Chandraprabha-purana" by Sri Vijaya, a court poet of King Amoghavarsha I, is ascribed to the early 9th century. Tamil Buddhist commentators of the 10th century AD (in the commentary on "Nemrinatham", a Tamil grammatical work) make references that show that Kannada literature must have flourished as early as the AD 4th century.
The late classical period gave birth to several genres of Kannada literature, with new forms of composition coming into use, including "Ragale" (a form of blank verse) and meters like "Sangatya" and "Shatpadi". The works of this period are based on Jain and Hindu principles. Two of the early writers of this period are Harihara and Raghavanka, trailblazers in their own right. Harihara established the "Ragale" form of composition while Raghavanka popularised the "Shatpadi" (six-lined stanza) meter. A famous Jaina writer of the same period is Janna, who expressed Jain religious teachings through his works.
The Vachana Sahitya tradition of the 12th century is purely native and unique in world literature, and the sum of contributions by all sections of society. Vachanas were pithy poems on that period's social, religious and economic conditions. More importantly, they held a mirror to the seed of social revolution, which caused a radical re-examination of the ideas of caste, creed and religion. Some of the important writers of Vachana literature include Basavanna, Allama Prabhu and Akka Mahadevi.
Middle Kannada.
During the period between the 15th and 18th centuries, Hinduism had a great influence on Middle Kannada ("Nadugannada") language and literature. Kumara Vyasa, who wrote the "Karnata Bharata Kathamanjari", was arguably the most influential Kannada writer of this period. His work, entirely composed in the native "Bhamini Shatpadi" (hexa-meter), is a sublime adaptation of the first ten books of the Mahabharata. 
During this period, the Sanskritic influence is present in most abstract, religious, scientific and rhetorical terms. During this period, several Hindi and Marathi words came into Kannada, chiefly relating to feudalism and militia.
Hindu saints of the Vaishnava sect such as Kanakadasa, Purandaradasa, Naraharitirtha, Vyasatirtha, Sripadaraya, Vadirajatirtha, Vijaya Dasa, Jagannatha Dasa, Prasanna Venkatadasa produced devotional poems in this period. Kanakadasa's "Ramadhanya Charite" is a rare work, concerning with the issue of class struggle. This period saw the advent of "Haridasa Sahitya" ("lit" Dasa literature) which made rich contributions to "bhakti" literature and sowed the seeds of Carnatic music. Purandara Dasa is widely considered the "Father of Carnatic music".
Modern Kannada.
The Kannada works produced from the 19th century make a gradual transition and are classified as "Hosagannada" or Modern Kannada. Most notable among the modernists was the poet Nandalike Muddana whose writing may be described as the "Dawn of Modern Kannada", though generally, linguists treat "Indira Bai" or "Saddharma Vijayavu" by Gulvadi Venkata Raya as the first literary works in Modern Kannada. The first modern movable type printing of "Canarese" appears to be the "Canarese Grammar" of Carey printed at Serampore in 1817, and the "Bible in Canarese" of John Hands in 1820. The first novel printed was John Bunyan's "Pilgrim's Progress", along with other texts including "Canarese Proverbs", "The History of Little Henry and his Bearer" by Mary Martha Sherwood, Christian Gottlob Barth's "Bible Stories" and "a Canarese hymn book."
Modern Kannada in the 20th century has been influenced by many movements, notably "Navodaya", "Navya", "Navyottara", "Dalita" and "Bandaya". Contemporary Kannada literature has been highly successful in reaching people of all classes in society. Further, Kannada has produced a number of prolific and renowned poets and writers such as Kuvempu, Bendre, and V K Gokak. Works of Kannada literature have received eight Jnanpith awards, the highest number awarded to any Indian language.
Dialects.
There is also a considerable difference between the spoken and written forms of the language. Spoken Kannada tends to vary from region to region. The written form is more or less consistent throughout Karnataka. The Ethnologue reports "about 20 dialects" of Kannada. Among them are Kundagannada (spoken exclusively in Kundapura), Nadavar-Kannada (spoken by Nadavaru), Havigannada (spoken mainly by Havyaka Brahmins), Are Bhashe (spoken by Gowda community mainly in the Sullia region of Dakshina Kannada), Malenadu Kannada (Sakaleshpur, Coorg, Shimoga, Chikmagalur), Soliga, Gulbarga Kannada, Dharawad Kannada etc. All of these dialects are influenced by their regional and cultural background.
Ethnologue also classifies a group of four languages related to Kannada, which are, besides Kannada proper, Badaga, Holiya and Urali.
Status.
The Director of the Central Institute of Indian Languages, Udaya Narayana Singh, submitted a report in 2006 to the Indian government arguing for Kannada to be made a classical language of India.
In 2008 the Indian government announced that Kannada was to be designated as one of the classical languages of India.
Writing system.
The language uses forty-nine phonemic letters, divided into three groups: "swaragalu" (vowels – thirteen letters); "vyanjanagalu" (consonants – thirty-four letters); and "yogavaahakagalu" (neither vowel nor consonant – two letters: "anusvara" ಂ and "visarga" ಃ). The character set is almost identical to that of other Indian languages. The script itself, derived from Brahmi script, is fairly complicated like most other languages of India owing to the occurrence of various combinations of "half-letters" (glyphs), or symbols that attach to various letters in a manner similar to diacritical marks in the Romance languages. The Kannada script is almost perfectly phonetic, but for the sound of a "half n" (which becomes a half m). The number of written symbols, however, is far more than the forty-nine characters in the alphabet, because different characters can be combined to form "compound" characters "(ottakshara)". Each written symbol in the Kannada script corresponds with one syllable, as opposed to one phoneme in languages like English. The Kannada script is syllabic.
Obsolete Kannada letters.
Kannada literary works employed the letters ಱ (transliterated 'ṟ' or 'rh') and ೞ (transliterated 'ḻ', 'lh' or 'zh'), whose manner of articulation most plausibly could be akin to those in present-day Malayalam and Tamil. The letters dropped out of use in the 12th and 18th centuries, respectively. Later Kannada works replaced 'rh' and 'lh' with ರ (ra) and ಳ (la) respectively.
Another letter (or unclassified "vyanjana" (consonant)) that has become extinct is 'nh' or 'inn'. Likewise, this has its equivalent in Telugu, where it is called "Nakaara pollu". The usage of this consonant was observed until the 1980s in Kannada works from the mostly coastal areas of Karnataka (especially the Dakshina Kannada district). Now, hardly any mainstream works use this consonant. This letter has been replaced by ನ್ (consonant n).
Kannada script evolution.
The image below shows the evolution of Kannada script from prehistoric times to the modern period. The Kannada script evolved in stages:
Proto-Kannada → Pre–Old Kannada → Old Kannada → Modern Kannada.
The Proto-Kannada script has its root in ancient Brahmi and appeared around the 3rd century BC. The Pre-Old-Kannada script appeared around the 4th century AD. Old-Kannada script can be traced to around the 10th century AD, whereas Modern-Kannada script appeared around the 17th century AD.
Dictionary.
Kannada–Kannada dictionary has existed in Kannada along with ancient works of Kannada grammar. The oldest available Kannada dictionary was composed by the poet 'Ranna' called 'Ranna Kanda' in 996 ACE. Other dictionaries are 'Abhidhana Vastukosha' by Nagavarma (1045 ACE), 'Amarakoshada Teeku' by Vittala (1300), 'Abhinavaabhidaana' by Abhinava Mangaraja (1398 ACE) and many more. A Kannada–English dictionary consisting of more than 70,000 words was composed by Ferdinand Kittel.
G. Venkatasubbaiah edited the first modern Kannada–Kannada dictionary, a 9,000-page, 8-volume series published by the Kannada Sahitya Parishat. He also wrote a Kannada–English dictionary and a "kliṣtapadakōśa", a dictionary of difficult words.
Kannada script in computing.
Several transliteration schemes/tools are used to type Kannada characters using a standard keyboard. These include Baraha (based on ITRANS), Pada Software and several internet tools like Google transliteration, Quillpad (predictive transliterator). Nudi, the Government of Karnataka's standard for Kannada Input, is a phonetic layout loosely based on transliteration.
Grammar.
The canonical word order of Kannada is SOV (subject–object–verb) as is the case with Dravidian languages.
Kannada is a highly inflected language with three genders (masculine, feminine, and neuter or common) and two numbers (singular and plural). It is inflected for gender, number and tense, among other things. The most authoritative known book on old Kannada grammar is "Shabdhamanidarpana" by Keshiraja. The first available Kannada book, a treatise on poetics, rhetoric and basic grammar is the "Kavirajamarga".
The most influential account of Kannada grammar is Keshiraja's "Shabdamanidarpana" (c. AD 1260). The earlier grammatical works include portions of "Kavirajamarga" (a treatise on "alańkāra") of the 9th century, and "Kavyavalokana" and "Karnatakabhashabhushana" (both authored by Nagavarma II in the first half of the 12th century).
Compound bases.
Compound bases, called "samāsa" in Kannada, are a set of two or more words compounded together. There are several types of compound bases, based on the rules followed for compounding.
Examples: "tangaaLi", "hemmara", "immadi".
Pronouns.
In many ways the third-person pronoun is more like demonstratives than like the other pronouns. They are pluralized like nouns, whereas the first- and second-person pronouns have different ways to distinguish number.

</doc>
<doc id="37447" url="http://en.wikipedia.org/wiki?curid=37447" title="Latin square">
Latin square

In combinatorics and in experimental design, a Latin square is an "n" × "n" array filled with "n" different symbols, each occurring exactly once in each row and exactly once in each column. Here is an example:
The name "Latin square" was inspired by mathematical papers by Leonhard Euler, who used Latin characters as symbols. Other symbols can be used instead of Latin letters: in the above example, the alphabetic sequence A, B, C can be replaced by the integer sequence 1, 2, 3.
Reduced form.
A Latin square is said to be "reduced" (also, "normalized" or "in standard form") if both its first row and its first column are in their natural order. For example, the above Latin square is not reduced because its first column is A, C, B rather than A, B, C.
We can make any Latin square reduced by permuting (that is, reordering) the rows and columns. Here switching the above matrix's second and third rows yields the following square: 
This Latin square is reduced; both its first row and its first column are alphabetically ordered A, B, C.
Properties.
Orthogonal array representation.
If each entry of an "n" × "n" Latin square is written as a triple ("r","c","s"), where "r" is the row, "c" is the column, and "s" is the symbol, we obtain a set of "n"2 triples called the orthogonal array representation of the square. For example, the orthogonal array representation of the following Latin square is:
where for example the triple (2,3,1) means that in row 2 and column 3 there is the symbol 1. The definition of a Latin square can be written in terms of orthogonal arrays: 
For any Latin square, there are "n"2 triples since choosing any two uniquely determines the third. (Otherwise, an ordered pair would appear more than once in the Latin square.)
The orthogonal array representation shows that rows, columns and symbols play rather similar roles, as will be made clear below.
Equivalence classes of Latin squares.
Many operations on a Latin square produce another Latin square (for example, turning it upside down).
If we permute the rows, permute the columns, and permute the names of the symbols of a Latin square, we obtain a new Latin square said to be "isotopic" to the first. Isotopism is an equivalence relation, so the set of all Latin squares is divided into subsets, called "isotopy classes", such that two squares in the same class are isotopic and two squares in different classes are not isotopic.
Another type of operation is easiest to explain using the orthogonal array representation of the Latin square. If we systematically and consistently reorder the three items in each triple, another orthogonal array (and, thus, another Latin square) is obtained. For example, we can replace each triple ("r","c","s") by ("c","r","s") which corresponds to transposing the square (reflecting about its main diagonal), or we could replace each triple ("r","c","s") by ("c","s","r"), which is a more complicated operation. Altogether there are 6 possibilities including "do nothing", giving us 6 Latin squares called the conjugates (also parastrophes) of the original square.
Finally, we can combine these two equivalence operations: two Latin squares are said to be paratopic, also main class isotopic, if one of them is isotopic to a conjugate of the other. This is again an equivalence relation, with the equivalence classes called main classes, "species", or paratopy classes. Each main class contains up to 6 isotopy classes.
Number.
There is no known easily computable formula for the number "L"("n") of "n" × "n" Latin squares with symbols 1,2...,"n". The most accurate upper and lower bounds known for large "n" are far apart. One classic result is, 
The table below contains all known exact values. It can be seen that the numbers grow exceedingly quickly. For each "n", the number of Latin squares altogether (sequence in OEIS) is "n"! ("n"-1)! times the number of reduced Latin squares (sequence in OEIS).
For each "n", each isotopy class (sequence in OEIS) contains up to ("n"!)3 Latin squares (the exact number varies), while each main class (sequence in OEIS) contains either 1, 2, 3 or 6 isotopy classes.
Examples.
We give one example of a Latin square from each main class up to order 5.
formula_2
formula_3
formula_4
They present, respectively, the multiplication tables of the following groups:
Applications.
Error correcting codes.
Sets of Latin squares that are orthogonal to each other have found an application as error correcting codes in situations where communication is disturbed by more types of noise than simple white noise, such as when attempting to transmit broadband Internet over powerlines.
Firstly, the message is sent by using several frequencies, or channels, a common method that makes the signal less vulnerable to noise at any one specific frequency. A letter in the message to be sent is encoded by sending a series of signals at different frequencies at successive time intervals. In the example below, the letters A to L are encoded by sending signals at four different frequencies, in four time slots. The letter C, for instance, is encoded by first sending at frequency 3, then 4, 1 and 2.
formula_10
The encoding of the twelve letters are formed from three Latin squares that are orthogonal to each other. Now imagine that there's added noise in channels 1 and 2 during the whole transmission. The letter A would then be picked up as:
In other words, in the first slot we receive signals from both frequency 1 and frequency 2; while the third slot has signals from frequencies 1, 2 and 3. Because of the noise, we can no longer tell if the first two slots were 1,1 or 1,2 or 2,1 or 2,2. But the 1,2 case is the only one that yields a sequence matching a letter in the above table, the letter A. 
Similarly, we may imagine a burst of static over all frequencies in the third slot:
Again, we are able to infer from the table of encodings that it must have been the letter A being transmitted. The number of errors this code can spot is one less than the number of time slots. It has also been proved that if the number of frequencies is a prime or a power of a prime, the orthogonal Latin squares produce error detecting codes that are as efficient as possible.
Mathematical puzzles.
The problem of determining if a partially filled square can be completed to form a Latin square is NP-complete.
The popular Sudoku puzzles are a special case of Latin squares; any solution to a Sudoku puzzle is a Latin square.
Sudoku imposes the additional restriction that nine particular 3×3 adjacent subsquares must also contain the digits 1–9 (in the standard version). The more recent KenKen puzzles are also examples of Latin squares.
Boardgames.
Latin squares have been used as the basis for several board games, notably the popular abstract strategy game Kamisado.
Heraldry.
The Latin square also figures in the arms of the Statistical Society of Canada, being specifically mentioned in its blazon. Also, it appears in the logo of the International Biometric Society.

</doc>
<doc id="37448" url="http://en.wikipedia.org/wiki?curid=37448" title="Overhand">
Overhand

Overhand may refer to:

</doc>
<doc id="37449" url="http://en.wikipedia.org/wiki?curid=37449" title="Mariner 9">
Mariner 9

Mariner 9 (Mariner Mars '71 / Mariner-I) was an unmanned NASA space probe that contributed greatly to the exploration of Mars and was part of the Mariner program. Mariner 9 was launched toward Mars on May 30, 1971 from Cape Canaveral Air Force Station and reached the planet on November 14 of the same year, becoming the first spacecraft to orbit another planet — only narrowly beating the Soviets' Mars 2 and Mars 3, which both arrived within a month. After months of dust storms it managed to send back clear pictures of the surface.
Mariner 9 returned 7329 images over the course of its mission, which concluded in October 1972.
Objectives.
Mariner 9 was designed to continue the atmospheric studies begun by Mariner 6 and 7, and to map over 70% of the Martian surface from the lowest altitude (1500 km) and at the highest resolutions (from 1 kilometer per pixel to 100 meters per pixel) of any Mars mission up to that point. An infrared radiometer was included to detect heat sources in search of evidence of volcanic activity. It was to study temporal changes in the Martian atmosphere and surface. Mars' two moons were also to be analyzed. Mariner 9 more than met its objectives.
Achievements.
Mariner 9 was the first spacecraft to orbit another planet. It carried an instrument payload similar to Mariners 6 and 7, but because of the need for a larger propulsion system to control the spacecraft in Martian orbit, it weighed more than Mariners 6 and 7 combined.
When Mariner 9 arrived at Mars on November 14, 1971, planetary scientists were surprised to find the atmosphere was thick with "a planet-wide robe of dust, the largest storm ever observed." The surface was totally obscured. Mariner 9's computer was thus reprogrammed from Earth to delay imaging of the surface for a couple of months until the dust settled. The main surface imaging did not get underway until mid-January 1972. However, surface-obscured images did contribute to the collection of Mars science, including understanding of the existence of several huge high-altitude volcanoes of the Tharsis Bulge that gradually became visible as the dust storm abated. This unexpected situation made a strong case for the desirability of studying a planet from orbit rather than merely flying past.
After 349 days in orbit, Mariner 9 had transmitted 7,329 images, covering 85% of Mars' surface, whereas previous flyby missions had returned less than one thousand images covering only a small portion of the planetary surface. 
The images revealed river beds, craters, massive extinct volcanoes (such as Olympus Mons, the largest known volcano in the Solar System; Mariner 9 led directly to its reclassification from Nix Olympica), canyons (including the Valles Marineris, a system of canyons over about 2500 mi long), evidence of wind and water erosion and deposition, weather fronts, fogs, and more. Mars' small moons, Phobos and Deimos, were also photographed.
The findings from the Mariner 9 mission underpinned the later Viking program.
The enormous Valles Marineris canyon system is named after Mariner 9 in honor of its achievements.
After depleting its supply of attitude control gas, the spacecraft was turned off on October 27, 1972.
Construction.
The ultraviolet spectrometer aboard Mariner 9 was constructed by the Laboratory for Atmospheric and Space Physics at the University of Colorado, Boulder, Colorado. The ultraviolet spectrometer team was led by Professor Charles Barth.
The Infrared Interferometer Spectrometer (IRIS) team was led by Dr. Rudolf A. Hanel from NASA Goddard Spaceflight Center (GSFC). The IRIS instrument was built by Texas Instruments, Dallas, Texas.
The Infrared Radiometer (IRR) team was led by Professor Gerald Neugebauer from the California Institute of Technology (Caltech).
Error-Correction Codes achievements.
To control for errors in the reception of the grayscale image data sent by Mariner 9 (caused by a low signal-to-noise ratio), the data had to be encoded before transmission using a so-called error-correcting code (ECC). Without ECC, noise would have made up roughly a quarter of a received image, while the ECC encoded the data in a redundant way which allowed for the reconstruction of the sent image data at reception.
As the flown hardware was constrained with regards to weight, power consumption, storage and computing power, some considerations had to be put into choosing an error-correcting code, and it was decided to use a Hadamard code for Mariner 9. The data words used during this mission were 6 bits long, which represented 64 grayscale values. Because of limitations of the transmitter, the maximum useful data length was about 30 bits. Instead of using a repetition code, a [32, 6, 16] Hadamard code was used. Errors of up to 7 bits per word could be corrected using this scheme. Compared to a five-repetition code, the error correcting properties of this Hadamard code were much better, yet its rate was comparable. The efficient decoding algorithm was an important factor in the decision to use this code. The circuitry used was called the "Green Machine", which employed the fast Fourier transform, increasing the decoding speed by a factor of three.
Present location.
Mariner 9 remains a derelict satellite in Mars orbit. It is expected to remain in orbit until approximately 2022, when the spacecraft is projected to enter the Martian atmosphere and either burn up or crash into the planet's surface.

</doc>
<doc id="37453" url="http://en.wikipedia.org/wiki?curid=37453" title="Funeral home">
Funeral home

A funeral home, funeral parlor or mortuary, is a business that provides interment and funeral services for the dead and their families. These services may include a
prepared wake and funeral, and the provision of a chapel for the funeral.
Services.
Funeral homes arrange services in accordance with the wishes of surviving friends and families. The funeral home often takes care of the necessary paperwork, permits, and other details, such as making arrangements with the cemetery, and providing obituaries to the news media. 
There are a few common types of services in North America.
A traditional funeral service consists of a viewing (sometimes referred to as a visitation), a funeral service in a place of worship or the funeral home chapel and a graveside committal service. 
Direct cremation consists of the funeral home receiving the corpse, preparing it for the crematory and filing the necessary legal paperwork. 
Direct/immediate burial is the forgoing of a funeral ceremony for a prompt, simple burial.
Moving a corpse between mortuaries involves preparing it for shipment in a coffin strapped into an arbitrary or a combination unit. This is common when it is to be buried in a different locality than where the person died.
When a corpse is brought to a funeral home, it is sometimes embalmed to delay decomposition. The procedure typically involves replacing the blood with a mixture of preservative chemicals and dyes, aspirating the internal organs and setting the facial features. Makeup is used to make the face and hands look more lifelike. If the face or hands were disfigured by accident, illness or decomposition, the embalmer may utilize restorative techniques to make them presentable for an "open casket" service. If this isn't possible, or the family wishes, the funeral home can perform a "closed casket" service.
The funeral home often sets aside one or more large areas for people to gather at a visitation. This area may contain a space to display the body in a casket to visitors who may pay their respects. Funeral and memorial services may also take place at the funeral home. Many funeral homes offer prearrangement options for those who wish to prepare their own funerals.
Several large multi-national corporations in this service field have received exposure from high profile litigation. The Loewen Group, Inc., received a particularly large jury verdict in the State of Mississippi which was later found to be in error as the allegations against Loewen Group proved false. The Canadian-based company then brought suit against the United States alleging violations under N.A.F.T.A.. Houston based Service Corporation International has also had their share of legal troubles with the operations of both their funeral home and cemetery operations.
In 2011, the total funeral homes revenue in the United States was $13.6 billion.

</doc>
<doc id="37454" url="http://en.wikipedia.org/wiki?curid=37454" title="Overhand knot">
Overhand knot

The overhand knot is one of the most fundamental knots and forms the basis of many others including the simple noose, overhand loop, angler's loop, reef knot, fisherman's knot and water knot. The overhand knot is very secure, to the point of jamming badly. It should be used if the knot is intended to be permanent. It is often used to prevent the end of a rope from unraveling.
Tying.
There are a number of ways to tie the Overhand knot.
Heraldry.
In heraldry, the overhand knot is known as a "Stafford knot", due to use first as a heraldic badge by the "Lords of Stafford", then as a general symbol of Staffordshire.
Knot theory.
If the two loose ends of an overhand knot are joined together (without creating additional crossings), this becomes equivalent to the trefoil knot of mathematical knot theory.
Overhand knot in paper-folding.
If a flat ribbon or strip is tightly folded into a flattened overhand knot, it assumes a regular pentagonal shape.

</doc>
<doc id="37457" url="http://en.wikipedia.org/wiki?curid=37457" title="Granny knot">
Granny knot

The granny knot is a binding knot, used to secure a rope or line around an object. It is considered inferior to the reef knot (square knot), which it superficially resembles. Neither of these knots should be used as a bend knot for attaching two ropes together.
Etymology.
Called the "granny's knot" with references going back to at least 1867, the knot was so-called because it is "the natural knot tied by women or landsmen". It has also been suggested that rather than impugning the knot tying skill of grandmothers, the name "granny" may be a corruption of granary after its possible use tying the necks of grain sacks.
Tying.
When attempting to tie a reef knot, it is easy to produce a granny knot accidentally. This is dangerous because the granny knot can slip when heavily loaded. A tightened granny knot can also jam and is often more difficult to untie than the reef knot. It is better to tie a reef knot in nearly all circumstances. One way to distinguish them is that in the reef knot each loop passes completely over, or completely under (not through) the neck of the other.
The reef knot is commonly taught as "left over right, tuck under" then "right over left, tuck under". The granny knot is the first step repeated twice, "left over right, tuck under". This is a very common mistake made by people learning to tie a reef knot.
Heraldry.
In heraldry, the granny knot is known as the Bourchier knot, due to being a heraldic badge of the Bourchier family.

</doc>
<doc id="37459" url="http://en.wikipedia.org/wiki?curid=37459" title="Service Corporation International">
Service Corporation International

Service Corporation International is an American provider of funeral goods and services as well as cemetery property and services. It is headquartered in Neartown, Houston, Texas. SCI operates more than 1500 funeral homes and 400 cemeteries in 43 states, eight Canadian provinces, and Puerto Rico.
Company history.
Robert L. Waltrip, a licensed funeral director who grew up in his family’s funeral business, founded the company in 1962. SCI began as a small network of funeral homes and cemeteries in the Houston area.
As SCI grew its offshore presence, it continued to acquire businesses in North America—a marketplace that, by the late 1990s, had become extremely competitive among companies seeking to buy death care businesses. SCI, Alderwoods Group and Stewart Enterprises emerged from this period as the three largest companies in the industry. On December 31, 1999, SCI owned and operated 3,823 funeral service locations, 525 cemeteries, 198 crematoria and two insurance operations located in 20 countries on five continents.
In 1999, SCI also introduced Dignity Memorial, the first transcontinental brand of death care services and products in North America. By unifying its network of funeral homes and cemeteries under one brand name, SCI believed it could establish recognizable and communicable brand values.
In 2000, poor market conditions forced SCI to reevaluate operations. While foreign operations had once shown promise, nearly 70 percent of SCI’s revenue was generated by operations in the United States and Canada. The company decided to divest many of its offshore businesses, in addition to many North American funeral homes and cemeteries. The UK arm now operates as Dignity plc.
Between 2002 and 2006, SCI reduced its net debt (total debt minus cash) by more than $1.0 billion, increased operating cash flow, and simplified its field management organization to enhance efficiency, performance, and accountability. It also changed business and sales processes, tightened internal controls following the protocols, strengthened corporate governance standards, and established a new training and development system. For its shareholders, SCI returned value through more than $335 million in share repurchases, and it resumed payment of a regular quarterly dividend in early 2005, the first since 1999.
Recent acquisitions.
In 2006, SCI merged with Alderwoods Group, its nearest competitor in terms of size. The Federal Trade Commission (FTC) blocked the merger, citing concerns over consumer choice. After agreeing to divest funeral home and cemetery locations in several markets and end licensing agreements with other funeral homes, the FTC allowed the merger to continue. By 2007, the integration of Alderwoods's locations and operations was complete.
In 2009 SCI put in a bid to purchase Keystone North America for $208 million. The purchase was completed in 2010 and added about 200 locations.
In May 2013 SCI signed a $1.4 billion deal to purchase Stewart Enterprises, the second-largest death care company. In December 2013, the FTC imposed conditions on the acquisition, requiring the two companies to sell 53 funeral homes and 38 cemeteries in 59 local markets, and requiring the merged company to be subject to a ten-year period during which the FTC will review any attempt by the company to acquire funeral or cemetery assets in those local markets.
Brands.
SCI operates the following brands in the United States and Canada:
Business model.
SCI's network of funeral homes consists almost entirely of existing businesses that the company acquired. SCI tends to buy successful funeral homes that are firmly settled and already well known in their community. SCI then retains the funeral home's original name, often along with former owners who are kept on as management. A typical funeral home that is owned by SCI will not contain advertisements or logos for SCI, with the exception, perhaps, of employee pins on staff lapels. As a consequence, most North American consumers are unfamiliar with the company itself. Instead, SCI places strong emphasis on their Dignity Memorial brand. The "Dignity" logo can be seen throughout SCI's funeral homes and cemeteries, on staff, signage, paperwork, vehicles, etc.
Controversies.
Costs.
Writing in an 24 October 2013 issue of "Bloomberg Businessweek", journalist Paul M. Barrett found, despite its lower overhead, SCI has higher prices than independent funeral home operators. Barrett quoted "data compiled" by a "`concierge` funeral planning service" Everest Funeral Package, which found that for "traditional funerals, SCI charges $6,256 on average (excluding casket and cemetery plot), 42 percent more than independents." In reply, SCI points to "overwhelmingly positive responses" on customer surveys, below market wages paid to staff and management, and states "we provides top value" at a variety of funeral price points.
Texas.
In the late 1990s, SCI was involved in a controversy involving alleged violations of Texas State embalming laws. The proceedings took a political slant due to Robert Waltrip’s friendship with the family of then-governor George W. Bush and Waltrip's campaign contributions to various members of the Bush family.
Referred to as "Funeralgate" or "Formaldegate" in the media, the controversy was widely publicized when Eliza May, a director with the Texas Funeral Service Commission (TFSC), was fired while investigating SCI. May alleged in a civil suit that she was fired because she refused to halt her investigation despite pressure to do so from Governor Bush. 
May's lawyers subpoenaed President Bush to testify at the trial, but Texas Judge John K. Dietz threw out the subpoena on the grounds that the then-governor was not in a position to have enough specialized information to require his involvement.
The lawsuit was settled in 2001 for more than $200,000. SCI and the state of Texas were required to jointly pay the decision. On January 23, 2004, the TFSC fined SCI an additional $21,000 for administrative penalties.
Florida.
In 2001, it was reported that employees of the Memorial Gardens cemetery near Ft. Lauderdale, Florida had oversold the cemetery, so bodies were buried in the wrong places, separating husbands from wives; vaults were cracked open by a backhoe; bodies were exhumed, with bones, skulls and shrouds thrown into nearby woods; bodies were stacked on top of each other; and remains were relocated without notifying relatives.
The allegations were particularly appalling to the Jewish cemetery's more religiously observant customers, "The Miami Herald" reported. Traditional Jewish law requires bodies to be buried intact and prohibits disturbing the dead. SCI reached a $14 million agreement (this is where employee bonuses went) with the Florida attorney general's office in 2003 that required it to repair plots and reorganize the cemeteries to ensure all graves were properly marked and the grounds could accommodate all plots sold. SCI also settled a separate class-action lawsuit on behalf of 350 families for $100 million.
Virginia.
On April 26, 2007, the "Washington Post" reported that an SCI cemetery in Alexandria, Virginia, had improperly buried the remains of the stillborn daughter of Nsombi Hale in a grave too shallow (in a grave about 8 inches deep). Nsombi Hale is filing suit against SCI.
After an internal investigation by SCI, attorneys working for SCI denied the charges against the company in a letter to Virginia funeral regulators,
and a few days later, the Post reported that Robert Ranghelli, one of the SCI employees who had corroborated the initial reports of improper handing of corpses, was fired for "(exercising his first amendment rights/speaking with the media" after having been on administrative leave for several months following the initial reports in the newspaper.
On April 5, 2009, "The Washington Post" reported that the National Funeral Home, a facility owned by SCI in the Falls Church area of Fairfax County, Virginia, which also acts as a centralized embalming and dressing station for embalming and body preparation for other nearby SCI-owned operations (Arlington Funeral Home, Danzansky-Goldberg Memorial Chapel and Demaine Funeral Home), was storing naked bodies in various stages of decomposition in conditions described as "disgusting, degrading and humiliating". The story went on to report that as many as 200 bodies were stored on "makeshift gurneys in the garage" and "at least half a dozen veterans destined for the hallowed ground at Arlington National Cemetery were left in their coffins on a garage rack". The "Post" reported that documentation describing these conditions had been reported to the Virginia Board of Funeral Directors and Embalmers.
A few days later, the "Post" reported that family members of a deceased Army veteran whose remains were stored in an unrefrigerated garage at National Funeral Home asked the Fairfax County Commonwealth's Attorney to investigate the actions of National and its parent company, SCI, as crimes.
The "Post" further reported that the family of retired U.S. Army Colonel Andrew DeGraff filed a lawsuit in Fairfax County alleging that SCI mishandled DeGraff's remains. According to the article, an SCI spokesman said that the company is conducting an internal investigation.
California.
On September 14, 2009, a class-action lawsuit was filed against SCI and Eden Memorial Park, a Jewish cemetery managed by SCI in Mission Hills, charging that they were destroying graves to make room for new interments.
The "Los Angeles Times" reported that state officials found no evidence of mass grave disturbances. Russ Heimerich, a spokesman for the state Department of Consumer Affairs, said, "We have not seen any evidence of the kind of massive desecration that [is] being alleged...The kind of activity they're alleging [is] not easily hidden, especially on a willful, large-scale basis." The plaintiff's attorney rejected the findings of the state's investigation. The lawsuit remained ongoing as of late 2009.
Michael Avenatti, the plaintiff’s attorney, said more than 800 families have joined the class action suit. Avenatti claims the state's investigation was shoddy, saying, “Investigators from the state were told by various groundskeepers over a year ago that they had been repeatedly told to throw bones away, and yet for some reason, the state didn’t adequately follow up.”
SCI denied all charges. After the lawsuit was filed, the Consumer Affairs Department reviewed five to six years of the cemetery's annual inspection records and found no indication that graves had been disturbed. According to the "Los Angeles Times" article, "The agency also asked the dozens of families that contacted officials to look for signs of disturbances -- shifted or cracked gravestones or anything else that appeared different from previous visits -- and didn’t receive a single call back, he said".
In January, 2012, the lawsuit against Eden Memorial Park was ruled to be a valid class action in Los Angeles Superior Court, with the trial scheduled to begin in May 2012.
In February 2014, a settlement in the amount of $80M was reached in this case.
Massachusetts.
In 2010, the SCI-owned Stanetsky Chapel, a Jewish funeral home in Brookline, MA, was charged by the State Board of Registration with serious violations of state law and regulations in connection with an incident where a woman was buried in the wrong grave, then disinterred without a legal permit being obtained and reburied in the correct grave with the woman's family not being notified of the mistake and the corrective procedure. As a result, in December 2011, the State Board announced a Consent Agreement and levied the biggest fine in its history, $18,000, against Stanetsky and SCI, and suspended the license of the Stanetsky general manager for a year. Other staff members involved in the incident were subject to punitive actions ranging from additional professional training to license revocation. The incident received widespread local media coverage. The Board's action was also published on the Board's website.
In a case first reported on April 7, 2005, the "Boston Globe" reported J.S. Waterman's & Sons, also owned by SCI, was found by the Board to have accidentally cremated the body of a stillborn infant in 2003. The infant's body was apparently placed on a gurney that held an adult woman's body that was scheduled for cremation. As a result of a civil suit brought by the infant's family, Waterman's was ordered to pay the parents $325,000, with a pending legal claim that the mortuary violated the state's consumer protection law that could triple the damages, the "Boston Globe" reported. The family's lawyer, Gordon T. Walker, said SCI could be hit with additional costs, as there is a pending claim that the company violated the state's consumer protection law. The civil verdict was made in Suffolk Superior Court on March 4. The jury awarded $75,000 because of emotional distress and $250,000 because they found the funeral home was negligent and intentionally inflicted emotional harm.

</doc>
<doc id="37461" url="http://en.wikipedia.org/wiki?curid=37461" title="State of matter">
State of matter

In physics, a state of matter is one of the distinct forms that matter takes on. Four states of matter are observable in everyday life: solid, liquid, gas, and plasma. Many other states are known such as Bose–Einstein condensates and neutron-degenerate matter but these only occur in extreme situations such as ultra cold or ultra dense matter. Other states, such as quark–gluon plasmas, are believed to be possible but remain theoretical for now. For a complete list of all exotic states of matter, see the list of states of matter.
Historically, the distinction is made based on qualitative differences in properties. Matter in the solid state maintains a fixed volume and shape, with component particles (atoms, molecules or ions) close together and fixed into place. Matter in the liquid state maintains a fixed volume, but has a variable shape that adapts to fit its container. Its particles are still close together but move freely. Matter in the gaseous state has both variable volume and shape, adapting both to fit its container. Its particles are neither close together nor fixed in place. Matter in the plasma state has variable volume and shape, but as well as neutral atoms, it contains a significant number of ions and electrons, both of which can move around freely. Plasma is the most common form of visible matter in the universe.
The term phase is sometimes used as a synonym for state of matter, but a system can contain several immiscible phases of the same state of matter. (See Phase (matter) for more discussion of the difference between the two terms.)
The four fundamental states.
Solid.
In a solid the particles (ions, atoms or molecules) are closely packed together. The forces between particles are strong so that the particles cannot move freely but can only vibrate. As a result, a solid has a stable, definite shape, and a definite volume. Solids can only change their shape by force, as when broken or cut.
In crystalline solids, the particles (atoms, molecules, or ions) are packed in a regularly ordered, repeating pattern. There are various different crystal structures, and the same substance can have more than one structure (or solid phase). For example, iron has a body-centred cubic structure at temperatures below 912 °C, and a face-centred cubic structure between 912 and 1394 °C. Ice has fifteen known crystal structures, or fifteen solid phases, which exist at various temperatures and pressures.
Glasses and other non-crystalline, amorphous solids without long-range order are not thermal equilibrium ground states; therefore they are described below as nonclassical states of matter.
Solids can be transformed into liquids by melting, and liquids can be transformed into solids by freezing. Solids can also change directly into gases through the process of sublimation, and gases can likewise change directly into solids through deposition.
Liquid.
A liquid is a nearly incompressible fluid that conforms to the shape of its container but retains a (nearly) constant volume independent of pressure. The volume is definite if the temperature and pressure are constant. When a solid is heated above its melting point, it becomes liquid, given that the pressure is higher than the triple point of the substance. Intermolecular (or interatomic or interionic) forces are still important, but the molecules have enough energy to move relative to each other and the structure is mobile. This means that the shape of a liquid is not definite but is determined by its container. The volume is usually greater than that of the corresponding solid, the best known exception being water, H2O. The highest temperature at which a given liquid can exist is its critical temperature.
Gas.
A gas is a compressible fluid. Not only will a gas conform to the shape of its container but it will also expand to fill the container.
In a gas, the molecules have enough kinetic energy so that the effect of intermolecular forces is small (or zero for an ideal gas), and the typical distance between neighboring molecules is much greater than the molecular size. A gas has no definite shape or volume, but occupies the entire container in which it is confined. A liquid may be converted to a gas by heating at constant pressure to the boiling point, or else by reducing the pressure at constant temperature.
At temperatures below its critical temperature, a gas is also called a vapor, and can be liquefied by compression alone without cooling. A vapor can exist in equilibrium with a liquid (or solid), in which case the gas pressure equals the vapor pressure of the liquid (or solid).
A supercritical fluid (SCF) is a gas whose temperature and pressure are above the critical temperature and critical pressure respectively. In this state, the distinction between liquid and gas disappears. A supercritical fluid has the physical properties of a gas, but its high density confers solvent properties in some cases, which leads to useful applications. For example, supercritical carbon dioxide is used to extract caffeine in the manufacture of decaffeinated coffee.
Plasma.
 
Like a gas, plasma does not have definite shape or volume. Unlike gases, plasmas are electrically conductive, produce magnetic fields and electric currents, and respond strongly to electromagnetic forces. Positively charged nuclei swim in a "sea" of freely-moving disassociated electrons, similar to the way such charges exist in conductive metal. In fact it is this electron "sea" that allows matter in the plasma state to conduct electricity.
The plasma state is often misunderstood, but it is actually quite common on Earth, and the majority of people observe it on a regular basis without even realizing it. Lightning, electric sparks, fluorescent lights, neon lights, plasma televisions, some types of flame and the stars are all examples of illuminated matter in the plasma state.
A gas is usually converted to a plasma in one of two ways, either from a huge voltage difference between two points, or by exposing it to extremely high temperatures.
Heating matter to high temperatures causes electrons to leave the atoms, resulting in the presence of free electrons. At very high temperatures, such as those present in stars, it is assumed that essentially all electrons are "free", and that a very high-energy plasma is essentially bare nuclei swimming in a sea of electrons.
Phase transitions.
This diagram illustrates transitions between the four fundamental states of matter.
A state of matter is also characterized by phase transitions. A phase transition indicates a change in structure and can be recognized by an abrupt change in properties. A distinct state of matter can be defined as any set of states distinguished from any other set of states by a phase transition. Water can be said to have several distinct solid states. The appearance of superconductivity is associated with a phase transition, so there are superconductive states. Likewise, ferromagnetic states are demarcated by phase transitions and have distinctive properties.
When the change of state occurs in stages the intermediate steps are called mesophases. Such phases have been exploited by the introduction of liquid crystal technology.
The state or "phase" of a given set of matter can change depending on pressure and temperature conditions, transitioning to other phases as these conditions change to favor their existence; for example, solid transitions to liquid with an increase in temperature. Near absolute zero, a substance exists as a solid. As heat is added to this substance it melts into a liquid at its melting point, boils into a gas at its boiling point, and if heated high enough would enter a plasma state in which the electrons are so energized that they leave their parent atoms.
Forms of matter that are not composed of molecules and are organized by different forces can also be considered different states of matter. Superfluids (like Fermionic condensate) and the quark–gluon plasma are examples.
In a chemical equation, the state of matter of the chemicals may be shown as (s) for solid, (l) for liquid, and (g) for gas. An aqueous solution is denoted (aq). Matter in the plasma state is seldom used (if at all) in chemical equations, so there is no standard symbol to denote it. In the rare equations that plasma is used in plasma is symbolized as (p).
Non-classical states.
Glass.
Glass is a non-crystalline or amorphous solid material that exhibits a glass transition when heated towards the liquid state. Glasses can be made of quite different classes of materials: inorganic networks (such as window glass, made of silicate plus additives), metallic alloys, ionic melts, aqueous solutions, molecular liquids, and polymers.
Thermodynamically, a glass is in a metastable state with respect to its crystalline counterpart. The conversion rate, however, is practically zero.
Crystals with some degree of disorder.
A plastic crystal is a molecular solid with long-range positional order but with constituent molecules retaining rotational freedom; in an orientational glass this degree of freedom is frozen in a quenched disordered state.
Similarly, in a spin glass magnetic disorder is frozen.
Liquid crystal states.
Liquid crystal states have properties intermediate between mobile liquids and ordered solids. Generally, they are able to flow like a liquid, but exhibiting long-range order. For example, the nematic phase consists of long rod-like molecules such as para-azoxyanisole, which is nematic in the temperature range 118–136 °C. In this state
the molecules flow as in a liquid, but they all point in the same direction (within each domain) and cannot rotate freely.
Other types of liquid crystals are described in the main article on these states. Several types have technological importance, for example, in liquid crystal displays.
Magnetically ordered.
Transition metal atoms often have magnetic moments due to the net spin of electrons that remain unpaired and do not form chemical bonds. In some solids the magnetic moments on different atoms are ordered and can form a ferromagnet, an antiferromagnet or a ferrimagnet.
In a ferromagnet—for instance, solid iron—the magnetic moment on each atom is aligned in the same direction (within a magnetic domain). If the domains are also aligned, the solid is a permanent magnet, which is magnetic even in the absence of an external magnetic field. The magnetization disappears when the magnet is heated to the Curie point, which for iron is 768 °C.
An antiferromagnet has two networks of equal and opposite magnetic moments, which cancel each other out so that the net magnetization is zero. For example, in nickel(II) oxide (NiO), half the nickel atoms have moments aligned in one direction and half in the opposite direction.
In a ferrimagnet, the two networks of magnetic moments are opposite but unequal, so that cancellation is incomplete and there is a non-zero net magnetization. An example is magnetite (Fe3O4), which contains Fe2+ and Fe3+ ions with different magnetic moments.
Microphase-separated.
 Copolymers can undergo microphase separation to form a diverse array of periodic nanostructures, as shown in the example of the styrene-butadiene-styrene block copolymer shown at right. Microphase separation can be understood by analogy to the phase separation between oil and water. Due to chemical incompatibility between the blocks, block copolymers undergo a similar phase separation. However, because the blocks are covalently bonded to each other, they cannot demix macroscopically as water and oil can, and so instead the blocks form nanometer-sized structures. Depending on the relative lengths of each block and the overall block topology of the polymer, many morphologies can be obtained, each its own phase of matter.
Quantum spin liquid.
A disordered state in a system of interacting quantum spins which preserves its disorder to very low temperatures, unlike other disordered states.
Low-temperature states.
Superfluid.
Close to absolute zero, some liquids form a second liquid state described as superfluid because it has zero viscosity (or infinite fluidity; i.e., flowing without friction). This was discovered in 1937 for helium, which forms a superfluid below the lambda temperature of 2.17 K. In this state it will attempt to "climb" out of its container. It also has infinite thermal conductivity so that no temperature gradient can form in a superfluid. Placing a superfluid in a spinning container will result in quantized vortices.
These properties are explained by the theory that the common isotope helium-4 forms a Bose–Einstein condensate (see next section) in the superfluid state. More recently, Fermionic condensate superfluids have been formed at even lower temperatures by the rare isotope helium-3 and by lithium-6.
Bose–Einstein condensate.
In 1924, Albert Einstein and Satyendra Nath Bose predicted the "Bose–Einstein condensate" (BEC), sometimes referred to as the fifth state of matter. In a BEC, matter stops behaving as independent particles, and collapses into a single quantum state that can be described with a single, uniform wavefunction.
In the gas phase, the Bose–Einstein condensate remained an unverified theoretical prediction for many years. In 1995, the research groups of Eric Cornell and Carl Wieman, of JILA at the University of Colorado at Boulder, produced the first such condensate experimentally. A Bose–Einstein condensate is "colder" than a solid. It may occur when atoms have very similar (or the same) quantum levels, at temperatures very close to absolute zero (−273.15 °C).
Fermionic condensate.
A "fermionic condensate" is similar to the Bose–Einstein condensate but composed of fermions. The Pauli exclusion principle prevents fermions from entering the same quantum state, but a pair of fermions can behave as a boson, and multiple such pairs can then enter the same quantum state without restriction.
Rydberg molecule.
One of the metastable states of strongly non-ideal plasma is Rydberg matter, which forms upon condensation of excited atoms. These atoms can also turn into ions and electrons if they reach a certain temperature. In April 2009, "Nature" reported the creation of Rydberg molecules from a Rydberg atom and a ground state atom, confirming that such a state of matter could exist. The experiment was performed using ultracold rubidium atoms.
Quantum Hall state.
A "quantum Hall state" gives rise to quantized Hall voltage measured in the direction perpendicular to the current flow. A "quantum spin Hall state" is a theoretical phase that may pave the way for the development of electronic devices that dissipate less energy and generate less heat. This is a derivation of the Quantum Hall state of matter.
Strange matter.
Strange matter is a type of quark matter that may exist inside some neutron stars close to the Tolman–Oppenheimer–Volkoff limit (approximately 2–3 solar masses). It may be stable at lower energy states once formed.
Photonic matter.
In photonic matter, photons behave as if they had mass, and can interact with each other, even forming photonic "molecules". This is in contrast to the usual properties of photons, which have no rest mass, and cannot interact.
Dropleton.
A "quantum fog" of electrons and holes that flow around each other and even ripple like a liquid, rather than existing as discrete pairs.
High-energy states.
Degenerate matter.
Under extremely high pressure, ordinary matter undergoes a transition to a series of exotic states of matter collectively known as degenerate matter. In these conditions, the structure of matter is supported by the Pauli exclusion principle. These are of great interest to astrophysicists, because these high-pressure conditions are believed to exist inside stars that have used up their nuclear fusion "fuel", such as the white dwarfs and neutron stars.
Electron-degenerate matter is found inside white dwarf stars. Electrons remain bound to atoms but are able to transfer to adjacent atoms. Neutron-degenerate matter is found in neutron stars. Vast gravitational pressure compresses atoms so strongly that the electrons are forced to combine with protons via inverse beta-decay, resulting in a superdense conglomeration of neutrons. (Normally free neutrons outside an atomic nucleus will decay with a half life of just under 15 minutes, but in a neutron star, as in the nucleus of an atom, other effects stabilize the neutrons.)
Quark–gluon plasma.
Quark–gluon plasma is a phase in which quarks become free and able to move independently (rather than being perpetually bound into particles) in a sea of gluons (subatomic particles that transmit the strong force that binds quarks together); this is similar to splitting molecules into atoms. This state may be briefly attainable in particle accelerators, and allows scientists to observe the properties of individual quarks, and not just theorize. See also Strangeness production.
Quark–gluon plasma was discovered at CERN in 2000.
Color-glass condensate.
Color-glass condensate is a type of matter theorized to exist in atomic nuclei traveling near the speed of light. According to Einstein's theory of relativity, a high-energy nucleus appears length contracted, or compressed, along its direction of motion. As a result, the gluons inside the nucleus appear to a stationary observer as a "gluonic wall" traveling near the speed of light. At very high energies, the density of the gluons in this wall is seen to increase greatly. Unlike the quark–gluon plasma produced in the collision of such walls, the color-glass condensate describes the walls themselves, and is an intrinsic property of the particles that can only be observed under high-energy conditions such as those at RHIC and possibly at the Large Hadron Collider as well.
Very high energy states.
The gravitational singularity predicted by general relativity to exist at the center of a black hole is "not" a phase of matter; it is not a material object at all (although the mass-energy of matter contributed to its creation) but rather a property of spacetime at a location. It could be argued, of course, that all particles are properties of spacetime at a location, leaving a half-note of controversy on the subject.
Other proposed states.
Supersolid.
A supersolid is a spatially ordered material (that is, a solid or crystal) with superfluid properties. Similar to a superfluid, a supersolid is able to move without friction but retains a rigid shape. Although a supersolid is a solid, it exhibits so many characteristic properties different from other solids that many argue it is another state of matter.
String-net liquid.
In a string-net liquid, atoms have apparently unstable arrangement, like a liquid, but are still consistent in overall pattern, like a solid. When in a normal solid state, the atoms of matter align themselves in a grid pattern, so that the spin of any electron is the opposite of the spin of all electrons touching it. But in a string-net liquid, atoms are arranged in some pattern that requires some electrons to have neighbors with the same spin. This gives rise to curious properties, as well as supporting some unusual proposals about the fundamental conditions of the universe itself.
Superglass.
A superglass is a phase of matter characterized, at the same time, by superfluidity and a frozen amorphous structure.
Dark matter.
While dark matter is estimated to comprise 83% of the mass of matter in the universe, most of its properties remain a mystery due to the fact that it neither absorbs nor emits electromagnetic radiation, and there are many competing theories regarding what dark matter is actually made of. Thus, while it is hypothesized to exist and comprise the vast majority of matter in the universe, almost all of its properties are unknown and a matter of speculation, because it has only been observed through its gravitational effects.
Equilibrium gel.
Equilibrium gel is made from a synthetic clay called Laponite. Unlike other gels, it maintains the same consistency throughout its structure and is stable, which means it does not separate into sections of solid mass and those of more liquid mass. Equilibrium gel filtration liquid chromatography is a technique used for the quantitation of ligand binding.

</doc>
<doc id="37462" url="http://en.wikipedia.org/wiki?curid=37462" title="Paul Molitor">
Paul Molitor

Paul Leo Molitor (born August 22, 1956), nicknamed "Molly" and "The Ignitor", is an American former Major League Baseball (MLB) player and current manager of the Minnesota Twins, who is in the Baseball Hall of Fame. During his 21-year baseball career, he played for the Milwaukee Brewers (1978–1992), Toronto Blue Jays (1993–1995), and Minnesota Twins (1996–1998). He was known for his exceptional hitting and speed. He made seven All-Star Game appearances and was the World Series MVP in 1993.
Molitor grew up in Minnesota and attended the University of Minnesota before beginning his MLB career. Molitor has served as a coach for the Seattle Mariners and the Twins since his retirement as a player. In 2004, he was elected to the Hall of Fame in his first year of eligibility, becoming one of the first players enshrined after spending a significant portion of his career as a designated hitter. He was a finalist for the Major League Baseball All-Century Team. On November 3, 2014, Molitor was announced as the 13th manager for the Minnesota Twins. 
Early life.
Molitor was born in Saint Paul, Minnesota. After graduating from Cretin High School, he was selected in the 28th round of the 1974 free agent draft as a pitcher by the St. Louis Cardinals, but opted instead to attend college at the University of Minnesota. He was a three-year starter for the Golden Gophers, earning All American honors as a shortstop for his sophomore and junior years. Between his junior and senior seasons, Molitor suffered a broken jaw. With his jaw wired shut for eight weeks, Molitor lost 40 pounds.
After his junior year in college, he was selected third overall in the 1977 Major League Baseball Draft by the Milwaukee Brewers. He signed with the Brewers and began his professional career in Iowa, playing for the Class A Burlington Bees of the Midwest League. In 64 games with Burlington, Molitor hit for a .346 batting average, 8 home runs, 50 runs batted in (RBI) and 14 stolen bases.
Playing career.
Milwaukee Brewers.
Molitor began as a shortstop, then moved to second base when Robin Yount returned from a brief retirement. He made his MLB debut in 1978, playing in 125 games and hitting .273 with 6 home runs, 45 RBI and 30 stolen bases. In 1981, he spent time at center field and right field to avoid the injuries associated with infield play. Molitor was moved to third base before the 1982 season. Molitor was part of a young Milwaukee Brewers team that lost the 1982 World Series in seven games to the St. Louis Cardinals. Molitor batted .355 during the series. In Game 1, he had five hits, a World Series record. During the 1982 season, he hit .302 and led the American League (AL) with 136 runs scored.
Molitor struggled with injuries for much of his early career, being placed on the disabled list six times between 1980 and 1986. In 1984, Molitor struggled with elbow problems, played in only 13 games and ultimately underwent surgery in an attempt to salvage his career. He played in 140 games in 1985, hitting .297 with 10 home runs and 48 RBI. He followed that with a .281 average, 9 home runs and 55 RBI in 1986. That year he suffered a hamstring injury, returned for a few days, then reinjured it. He played in 105 games that season.
Molitor attracted national media attention in 1987 during his 39-game hitting streak. Near the end of the streak, columnist Mike Downey wrote that "the amazing thing about Paul Molitor's recent bat-o-rama is not that he has hit in 33 straight games but that he has played in 33 straight games." The streak ended with Molitor in the on-deck circle when Rick Manning got a game-ending hit to beat the Cleveland Indians on August 26, 1987. Fans booed Manning for driving in the winning run and thus depriving Molitor of one last chance to reach 40 games. The streak stands as the fifth-longest in modern-day baseball history, and remains the longest since Pete Rose's 44-game hit streak in 1978.
Toronto Blue Jays.
Although Molitor wanted to remain with Milwaukee when he became a free agent after the 1992 season, the franchise offered him a one-year contract with a $900,000 pay cut (to $2.5 million), while the Toronto Blue Jays offered a three-year, $13 million ($ in current dollar terms) deal, leading to his signing with the Blue Jays. Agent Ron Simon said, "I was also talking with Milwaukee, but it became clear to us that Milwaukee didn't have the same kind of interest in signing Molitor, perhaps because of their financial situation."
Molitor quickly became an offensive juggernaut. He hit .332 with 22 home runs and 111 RBI. Returning to the playoffs for the first time since 1982, he was a key part of the Blue Jays' second World Championship. Molitor hit 2 doubles, two triples, and 2 home runs in the series earning the World Series MVP Award and tied a World Series record by batting .500 (12-for-24) in the six-game series. In 1993, Molitor led the AL in plate appearances (675) and hits (211).
In 1994, a strike-shortened season, Molitor hit .341 and led the AL in games played (115) and singles (107). He also stole 20 bases that season without ever being caught, one short of Kevin McReynolds' 1988 major league record of 21. Molitor's average dropped to .270 in 1995, his lowest mark in more than ten years.
Minnesota Twins.
He left the Blue Jays after the season, and joined his hometown Minnesota Twins for the final three seasons of his career, where he acquired his 3,000th hit. He is the only player to reach the 3,000 hits plateau with a triple. Molitor was relishing the opportunity to play with Twins superstar Kirby Puckett, but Puckett developed career-ending glaucoma during spring training in 1996 and never played again. In 1996, Molitor became the second 40-year-old, after Hall of Famer Sam Rice, to have a 200-hit season, leading the league with 225, while also leading the league in singles with 167. Molitor also remains the last MLB player to drive in 100 or more runs in a season while hitting fewer than 10 home runs (9 HR, 113 RBIs).
Molitor hit .305 in 1997, his twelfth season to finish with a batting average higher than .300. In 1998, he hit .281 with 4 home runs, 69 RBI and 9 stolen bases. Other than his very brief 1984 season, the 1998 season was the first in Molitor's career in which he did not reach double-digit stolen base totals. He retired in December, saying, "My heart tells me I've done what I can do on the field and in this game," Molitor said. "I'm happy to leave it playing my last season in a Twins uniform... Now I'm going to redirect my efforts to find out what else the future holds."
Coaching career.
After retiring as a player, Molitor remained with the Twins as a bench coach for three seasons. He was considered a leading candidate to manage the team when Tom Kelly retired after 2001, but he declined in part because the Twins were still being targeted for potential contraction. Molitor was a hitting coach with the Mariners in 2004. Molitor joined the Twins coaching staff in 2014 to oversee baserunning, bunting, infield instruction, and positioning. He also assisted with in-game strategy.
The Twins hired Molitor to fill their manager vacancy for the 2015 season, and introduced him in press conference on November 4.
Accomplishments.
Molitor's lifetime statistics include 2,683 games played, 1,782 runs scored, 3,319 hits, 234 home runs, 1,307 runs batted in, a .306 batting average, and 504 stolen bases. His 3,319 hits rank him ninth all-time. In addition, he batted .368 in five postseason series, and was an all-star seven times. Molitor recorded these statistics while missing nearly 500 games due to various injuries throughout his career. In 1999, Molitor ranked No. 99 on "The Sporting News"' list of the 100 Greatest Baseball Players, and he was nominated as a finalist for the Major League Baseball All-Century Team. Molitor was elected to the Wisconsin Athletic Hall of Fame in 1999.
On June 11, 1999, the Brewers retired Molitor's uniform number 4. During the ceremony at Milwaukee County Stadium, Molitor announced that if he went into the Hall of Fame, he would do so as a Brewer. On January 6, 2004, he was elected to the Hall in his first year of eligibility, with 85.2% of the votes. True to his word, he joined Robin Yount as the only Hall of Famers to be depicted on their plaques with Brewers caps. At the time of his induction, Molitor was the hitting coach for the Seattle Mariners.
Molitor is one of four players in major league history with at least 3,000 hits, a .300 lifetime batting average, and 500 stolen bases. The other three are Ty Cobb, Honus Wagner, and Eddie Collins, none of whom played the game beyond 1930. Molitor is the only player ever to accomplish those feats and hit at least 200 home runs. Molitor is also the first player in World Series history to have at least two home runs, two doubles, and two triples in one series (1993). He is a member of an exclusive club, hitting .300 or better in full season across three decades (1970s, 80s, and 90s).
Personal.
During the early years of his career, Molitor began using cocaine and cannabis. During the trial of a drug dealer in 1984, Molitor was named as a customer of the man. A few months later, he admitted that he had used drugs. Many years later, he said, "There are things you're not so proud of — failures, mistakes, dabbling in drugs, a young ballplayer in the party scene. Part of it was peer pressure. I was young and single, and hung around with the wrong people... You learn from it. You find a positive in it. It makes you appreciate the things that are good."
He stopped using drugs in 1981, and has since visited schools to lecture about the dangers of drug use. During his Hall of Fame induction speech, Molitor mentioned his difficult family relationships. He admitted that he had a son in Toronto - conceived in between marriages - that he had not gotten to know well.
External links.
class="wikitable succession-box collapsible autocollapse" style="margin: 0 auto 0 auto; font-size:95%;clear:both;"
Awards and achievements titles

</doc>
<doc id="37463" url="http://en.wikipedia.org/wiki?curid=37463" title="Miller's knot">
Miller's knot

A miller's knot (also sack knot or bag knot) is a binding knot used to secure the opening of a sack or bag. Historically, large sacks often contained grains; thus the association of these knots with the miller's trade. Several knots are known interchangeably by these three names. 
Tying.
This is to tie a Constrictor knot version of the miller's knot:
To tie the other variants:
Tying other knots that also may function very well as a bag knot:
Variations.
A slipped Constrictor knot where the ends are passed through the opposing slips for security is quite secure as a bag knot. Unslipped, it is even more secure, but it may have to be cut to open the bag.
A slipped Strangle knot where the ends are passed through the opposing slips for security is also quite secure as a bag knot. 
A Bottle sling around a swirled and folded neck of the bag is also a very solid and reliable bag knot.
As noted above, several other distinct knots have historically been known as miller's, sack, or bag knots. The common aspects of these are two crossing turns, and both ends tucked under a turn near the crossing point. To avoid ambiguity, unslipped versions of these knots are listed below by the reference numbers found in "The Ashley Book of Knots". All of these knots can also be made in a slipped form by starting with a bight and/or by completing the final tuck with a bight instead of the end.
#1243.
This knot is also a useful hitch and is known by the name ground-line hitch when used for that purpose. It should be tightened by pulling the end first.
#1674.
Shown in a slipped form at entry #1244, this variation is noted by Ashley as having better binding characteristics than the others.

</doc>
<doc id="37466" url="http://en.wikipedia.org/wiki?curid=37466" title="Butterfly loop">
Butterfly loop

The butterfly loop, also known as lineman's loop, butterfly knot, alpine butterfly knot and lineman's rider, is a knot used to form a fixed loop in the middle of a rope. Tied in the bight, it can be made in a rope without access to either of the ends; this is a distinct advantage when working with long climbing ropes. The butterfly loop is an excellent mid-line rigging knot; it handles multi-directional loading well and has a symmetrical shape that makes it easy to inspect. In a climbing context it is also useful for traverse lines, some anchors, shortening rope slings, and for isolating damaged sections of rope.
History.
The earliest known presentation of the knot was in A.A. Burger's 1914 work "Rope and Its Uses", included in an agricultural extension bulletin from what is now Iowa State University. Burger called the knot a lineman's rider stating it was often used by "linemen and especially telephone men". The knot's security and ability to withstand tension in any direction are both discussed.
The knot's association with mountaineering—and with butterflies—originates from a 1928 article in "Alpine Journal" by C.E.I. Wright and J.E. Magowan. The authors claim to have developed the butterfly noose themselves while attempting to improve the selection of knots available to climbers. The name is "so styled on the basis of a more or less fanciful resemblance imagined in the form of the knot." In the second part of the article they express dissatisfaction regarding their earlier use of the word "noose," since the knot is non-collapsing, and refer to the knot as butterfly loop or simply butterfly. Wright and Magowan call the butterfly loop "new," along with several other of their knots, in the sense they were unable to identify any earlier record of them. However, they prudently added that it "might be rash to claim they have never been used before."
When Clifford Ashley covered the knot in 1944, calling it the lineman's loop, he attributed its first publication to J.M. Drew but made no specific reference as to the source of this claim. A 1912 article called "Some Knots and Splices" by Drew appears in the bibliography of "The Ashley Book of Knots". A 1913 reprint of this Drew article does not mention the butterfly loop.
Use.
The loop is typically attached to a climbing harness by carabiner.
It can also be used to isolate a worn section of rope, where the knot is tied such that the worn section is isolated in the loop (which of course does not receive a carabiner nor bear any loads in this case). The loop portion is isolated when the other two legs are loaded, and in fact the butterfly can be tied as a bend with the ends emerging where the loop would be.
Errors in tying the butterfly loop can produce a similar looking but inferior knot, the so-called "false butterfly", which is prone to slipping. However, some sources suggest this behavior can be exploited purposely for shock absorption. Wright and Magowan called this less secure loop knot the "half-hitch noose".
Variations.
The double butterfly loop has two non-collapsing loops, allowing for two clip in points, both of which have the same advantages and disadvantages of a single-loop butterfly.

</doc>
<doc id="37469" url="http://en.wikipedia.org/wiki?curid=37469" title="Constrictor knot">
Constrictor knot

The constrictor knot is one of the most effective binding knots. Simple and secure, it is a harsh knot that can be difficult or impossible to untie once tightened. It is made similarly to a clove hitch but with one end passed under the other, forming an overhand knot under a riding turn. The double constrictor knot is an even more robust variation that features two riding turns.
History.
First called "constrictor knot" in Clifford Ashley's 1944 work "The Ashley Book of Knots", this knot likely dates back much further. Although Ashley seemed to imply that he had invented the constrictor knot over 25 years before publishing "The Ashley Book of Knots", research indicates that he was not its originator. Ashley's publication of the knot did bring it to wider attention.
Although the description is not entirely without ambiguity, the constrictor knot is thought to have appeared under the name "gunner's knot" in the 1866 work "The Book of Knots", written under the pseudonym Tom Bowling. in relation to the clove hitch, which he illustrated and called the "builder's knot". He wrote, "The Gunner's knot (of which we do not give a diagram) only differs from the builder's knot, by the ends of the cords being simply knotted before being brought from under the loop which crosses them." Oddly, when J. T. Burgess copied from Bowling, he changed this text to merely state "when the ends are knotted, the builder's knot becomes the gunner's Knot." Although this clove hitch with knotted ends "is" a workable binding knot, Burgess was not actually describing the constrictor knot. In 1917, A. Hyatt Verrill illustrated Burgess' clove hitch variation in "Knots, Splices and Rope Work".
The constrictor knot was clearly described but not pictured as the "timmerknut" ("timber knot") in the 1916 Swedish book "Om Knutar" ("On Knots") by Hjalmar Öhrvall. Finnish scout leader Martta Ropponen presented the knot in her 1931 scouting handbook "Solmukirja" ("Knot Book"), the first published work known to contain an illustration of the constrictor knot. Cyrus L. Day relates that, "she had never seen it in Finland, she wrote to me in 1954, but had learned about it from a Spaniard named Raphael Gaston, who called it a whip knot, and told her it was used in the mountains of Spain by muleteers and herdsmen." The Finnish name "ruoskasolmu" ("whip knot") was a translation from Esperanto, the language Ropponen used to correspond with Gaston.
Tying.
The method shown below is the most basic way to tie the knot. There are also at least three methods to tie the constrictor knot in the bight and slip it over the end of an object to be bound. 
Variations.
Double constrictor knot.
If a stronger and even more secure knot is required an extra riding turn can be added to the basic knot to form a double constrictor knot. It is particularly useful when tying the knot with very slippery twine, especially when waxed. Adding more than one extra riding turn does not add to its security and makes the knot more difficult to tighten evenly.
Slipped constrictor knot.
This variation is useful if it is known beforehand that the constrictor will need to be released. Depending on the knotting material and how tightly it is cinched, the slipped form can still be very difficult to release.
The slipped constrictor can also be tied in the bight and slipped over the object to constrict. Despite its advertised advantage (quick release), the slipped constrictor knot can also be hard to release when worked extremely tight in certain rope materials.
Usage.
The constrictor knot is appropriate for situations where secure temporary or semi-permanent binding is needed. Made with small-stuff it is especially effective, as the binding force is concentrated over a smaller area.
When tying over soft material such as the neck of a bag, hard stiff cord is more effective. When tying over hard surfaces, soft stretchy line is preferred. The constrictor knot's severe bite (which makes it so effective) can damage or disfigure items it is tied around. To exert extreme tension on the knot without injuring the hands, one can fashion handles using marlinespike hitches made around two rods. 
Constrictor knots can be used for temporarily binding the fibres of a rope (or strand ends) together while splicing, or when cutting to length and before properly whipping the ends. Constrictor knots can also be quite effective as improvised hose clamps or cable ties. The knot has also been recommended for ligatures in human and veterinary surgery, where it has been shown to be far superior to any of the knots commonly used for ligation. Noted master-rigger Brion Toss says of the constrictor: "To know the knot is to constantly find uses for it…"
Releasing.
A heavily tightened constrictor knot will likely jam. If the ends are long enough, one can sometimes untie it by pulling one end generally parallel to the bound object and a bit up away from it, and prying it into the opposite end's part to open the knot. Tools that can be forced between parts of the knot (such as picks and marlinespikes) may help.
If the ends have been trimmed short, or the knot is otherwise hopelessly jammed, it can be easily released by cutting the riding turn with a sharp knife. The knot will spring apart as soon as the riding turn is cut. If care is taken not to cut too deeply, the underlying wraps will protect the bound object from being damaged by the knife.
Security.
The constrictor and double constrictor are both extremely secure when tied tightly around convex objects with cord scaled for the task at hand. If binding around a not fully convex, or square-edged object, arrange the knot so the overhand knot portion is stretched across a convex portion, or a corner, with the riding turn squarely on top of it. In situations where the object leaves gaps under the knot and there are no corners, it is possible to finish the constrictor knot off with an additional overhand knot, in the fashion of a reef knot, to help stabilize it. Those recommendations aside, constrictor knots do function best on fully convex objects.
If the constricted object (such as a temporarily whipped rope) ends very close to where a constrictor binds it, a boa knot may prove a more stable solution.

</doc>
<doc id="37472" url="http://en.wikipedia.org/wiki?curid=37472" title="Trondheim">
Trondheim

Trondheim (]), historically Kaupangen, Nidaros and Trondhjem, is a city and municipality in Sør-Trøndelag county, Norway. With a population of 181,513 (October 1, 2013), it is the third most populous municipality in Norway, although the fourth largest urban area. It is also the third largest city in the country, with a population (2013) of 169,972 inhabitants within the city borders. The city functions as the administrative centre of Sør-Trøndelag county. Trondheim lies on the south shore of the Trondheimsfjord at the mouth of the river Nidelva. The city is dominated by the Norwegian University of Science and Technology (NTNU), SINTEF, St. Olavs University Hospital and other technology-oriented institutions.
The settlement was founded in 997 as a trading post, and it served as the capital of Norway during the Viking Age until 1217. From 1152 to 1537, the city was the seat of the Archdiocese of Nidaros; since then, it has remained the seat of the Diocese of Nidaros and the Nidaros Cathedral. It was incorporated in 1838. The current municipality dates from 1964, when Trondheim merged with Byneset, Leinstrand, Strinda and Tiller.
History.
Trondheim was named Kaupangen (English: market place or trading place) by Viking King Olav Tryggvason in 997. Shortly thereafter it came to be called "Nidaros". In the beginning it was frequently used as a military retainer (Old Norse: "hird"-man) of King Olav. It was frequently used as the seat of the king, and was the capital of Norway until 1217.
People have been living in the region for thousands of years as evidenced by the rock carvings in central Norway, the Nøstvet and Lihult cultures and the Corded Ware culture. In ancient times, the Kings of Norway were hailed at Øretinget in Trondheim, the place for the assembly of all free men by the mouth of the river Nidelva. Harald Fairhair (865–933) was hailed as the king here, as was his son, Haakon I – called 'the Good'. The battle of "Kalvskinnet" took place in Trondheim in 1179: King Sverre Sigurdsson and his "Birkebeiner" warriors were victorious against Erling Skakke (a rival to the throne). Some scholars believe that the famous Lewis chessmen, 12th-century chess pieces carved from walrus ivory found in the Hebrides and now at the British Museum, may have been made in Trondheim.
Trondheim was the seat of the (Catholic) Archdiocese of Nidaros for Norway from 1152. Due to the introduction of Lutheran Protestantism in 1537, the last Archbishop, Olav Engelbrektsson, had to flee from the city to the Netherlands, where he died in present-day Lier, Belgium.
The city has experienced several major fires. Since much of the city was made of wooden buildings, many of the fires caused severe damage. Great fires ravaged the city in 1598, 1651, 1681, 1708, twice in 1717, 1742, 1788, 1841 and 1842; however, these were only the worst cases and there have been several smaller fires in the city. The 1651 fire destroyed 90% of all buildings within the city limits. The fire in 1681 (the "Horneman Fire") led to an almost total reconstruction of the city, overseen by General Johan Caspar von Cicignon, originally from Luxembourg. Broad avenues like "Munkegaten" were created, with no regard for property rights, in order to stop the next fire. At the time, the city had a population of roughly 8000 inhabitants. 
After the Treaty of Roskilde on 26 February 1658, Trondheim and the rest of Trøndelag, became Swedish territory for a brief period, but the area was reconquered 10 months later. The conflict was finally settled by the Treaty of Copenhagen on 27 May 1660.
During World War II, Trondheim was occupied by Nazi Germany from 9 April 1940, the first day of the invasion of Norway, until the end of the war in Europe, 8 May 1945. The home of the most notorious Norwegian Gestapo agent, Henry Rinnan, was in Trondheim. The city and its citizens were also subject to harsh treatment by the occupying powers, including imposition of martial law in October 1942. During this time the Germans turned the city and its environs into a major base for submarines (which included building the large submarine base and bunkerDORA 1), and also contemplated a scheme to build a new city for 300,000 inhabitants, "Nordstern" ("Northern Star"), centred 15 km southwest of Trondheim, near the wetlands of Øysand in the outskirts of Melhus municipality. This new metropolis was to be accompanied by a massively expanded version of the already existing naval base, which was intended to become the primary future stronghold of the German Kriegsmarine. Today there are few physical remains of this enormous construction project.
Municipal history.
The city of Trondheim was established on 1 January 1838 (see formannskapsdistrikt). On 1 January 1864, part of Strinda (population: 1,229) was amalgamated with Trondheim. Then on 1 January 1893, another part of Strinda (population: 4,097) was transferred to Trondheim. On 1 January 1952, the Lade area of Strinda (population: 2,230) was transferred to Trondheim. On 1 January 1964, a major municipal merger took place: the neighbouring municipalities of Leinstrand (population: 4,193), Byneset (population: 2,049), Strinda (population: 44,600), and Tiller (population: 3,595) were all merged with the city of Trondheim (population: 56,982), which nearly doubled the population of the municipality.
Toponymy.
Following the example set by the renaming of the capital "Kristiania" to "Oslo", "Nidaros" was reintroduced as the official name of the city for a brief period from 1 January 1930 until 6 March 1931. The name was restored in order to reaffirm the city's link with its glorious past, despite the fact that a 1928 referendum on the name of the city had resulted in 17,163 votes in favour of "Trondhjem" and only 1,508 votes in favour of Nidaros. Public outrage later in the same year, even taking the form of riots, forced the Storting to settle for the medieval city name "Trondheim". The name of the diocese was, however, changed from "Trondhjem stift" to "Nidaros bispedømme" (English: Diocese of Nidaros) in 1918.
Briefly during World War II Trondheim has been named Drontheim, as a German exonym.
Historically, "Trondheimen" indicates the area around the Trondheimsfjord. The spelling "Trondhjem" was officially rejected, but many still prefer that spelling of the city's name.
Coat-of-arms and seal.
The coat-of-arms dates back to the 13th century. To the left, there is an archbishop with his staff and mitre in a church archway. On the right, a crowned king holding scales in a castle archway. These two pictures rest on a base which forms an arch. Underneath that arch, are three male heads which symbolize the city's rank as Norway's first capital and the archbishop's place of residence. The scales symbolize justice and the motif is based on the political philosophy of the 13th century, where the balance of power between king and church was an important issue. The three heads at the bottom may symbolize the city council. The motif is unique in Norwegian municipal heraldry, but similar motifs are found in bishopric cities on the continent. The design of the coat-of-arms that was adopted in 1897, and is still used today, was made by Håkon Thorsen.
Jewish history.
Jews began to settle in Trondheim in 1880, after the change of the Norwegian constitution in 1851, granting Jews permission to settle in Norway. The first synagogue in Trondheim was established in 1899, and a newer one came into use by 1925. By 1900, 119 Jews were living in Trondheim, reaching 260 by 1940. The Nazi regime confiscated the synagogue in 1941, and used it for military uses. On January 1942, the town Jews identification cards were stamped with the letter "J", and confiscations started to be more and more common. Shortly after, Jews from Trondheim began to emigrate to Sweden. The rest were sent to Auschwitz in October 1942. In 1945, after the end of the war, around 80 Jews returned to the city. Out of the 135 individuals sent to Auschwitz, 5 remained. The synagogue was repaired in 1947. In May 1997, a Jewish museum was opened in Trondheim. At the turn of the 21st century, 120 Jews were living in Trondheim.
Geography.
Trondheim is situated where the river Nidelva meets Trondheimsfjorden with an excellent harbour and sheltered condition. The river used to be deep enough for most boats in the Middle Ages. An avalanche of mud and stones made it less navigable and partly ruined the harbour in the mid-17th century.
The municipality's top elevation is the Storheia hill, 565 m above sea level. At summer solstice, the sun rises at 03:00 and sets at 23:40, but stays just below the horizon–there is no darkness (no need for artificial lighting outdoors) from 23 May to 19 July under cloud-free conditions. At winter solstice, the sun rises at 10:01, stays very low above the horizon (at midday its altitude is slightly more than 3 degrees over the horizon), and sets at 14:31.
Climate.
Trondheim city has a predominantly hemiboreal Oceanic climate (Koppen: "Cfb"), but closely borders on humid continental, sub-polar oceanic and subarctic climates. The part of the municipality further away from the fjord has colder winters (the January mean at "Klett" 1961-90 is -5.5 °C). The part close to the fjord, such as the city center, has milder winters (the January mean for Trondheim city center 58 m above sea-level based on the years 1961–90 was -2.5 °C, but recent years have been warmer. Trondheim is mostly sheltered from the strong south and southwesterly winds which can occur along the outer seaboard. The warmest temperature ever recorded was 35 °C on 22 July 1901, and the coldest was -26.1 °C in February 1899. Trondheim experiences moderate snowfall from November to March, but mixed with mild weather and rainfall. Based on the 1961–90 average recorded at the airport, there are 14 days each winter with at least 25 cm of snow cover on the ground and 22 days with a daily minimum temperature of -10 °C or less. There is often more snow and later snowmelt in suburban areas at somewhat higher elevation, such as Byåsen and Heimdal, with good skiing conditions in Bymarka. Spring often sees much sunshine, but nights can be chilly. The daily high temperature can exceed 20 °C from late April to late September, but not reliably so. Temperatures have tended to be warmer in recent years. The Trøndelag area has seen average temperatures increase by almost 2 C-change in the last 25 years.
The weather station at Voll (127 m amsl) in Trondheim started operating in 1923, but was discontinued in 1967 and did not start up again until 1997. The lapse rate is approximately 0.6 C-change per 100 m, so the city center will be about 0.6 C-change warmer than Voll, while higher altitudes than Voll will be accordingly colder.
<br>
Fauna.
Several wetland habitats can be found within the city limits. The "Gaulosen" is one of these. Here you will find a newly built observation tower and information on the birdlife which can be found therein.
Despite Trondheim being Norway's third largest city, wild animals can be seen. Otters and beavers thrive in Nidelva and Bymarka. Badgers and foxes are not uncommon sights. Moose and deer are common in the hills surrounding the city, and might wander into the city, especially in May when the one year olds are chased away by their mothers, or in late winter when food grows scarce in the snow-covered higher regions. Since 2002, a wolverine has stayed in Bymarka.
Cityscape.
Most of the downtown area of Trondheim is scattered with small specialty stores and shops, however a considerable part of the downtown shopping area is concentrated around the pedestrianized streets "Nordre gate" (English: Northern street), "Olav Tryggvasons gate" and Thomas Angells gate even though the rest of the city center also is riddled with everything from old, well-established companies to new, hip and trendy shops.
In the mid- to late 1990s, the area surrounding the old drydock and ship construction buildings of the defunct Trondhjems mekaniske Værksted shipbuilding company at the Nedre Elvehavn were renovated and old industrial buildings were torn down to make way for condominiums. A shopping mall was also built, known as Solsiden (The Sunny Side). This is a popular residential and shopping area, especially for young people.
DORA 1 is a German submarine base that housed the 13th U-boat Flotilla during the World War II occupation of Norway. Today the bunker houses various archives, among them the city archives, the university and state archives. More recently, DORA has been used as a concert venue.
Kristiansten Fortress, built 1681–1684, is located on a hill east in Trondheim. It repelled the invading Swedes in 1718, but was decommissioned in 1816 by Crown Prince Regent Charles John.
A statue of Olav Tryggvason, the founder of Trondheim, is located in the city's central plaza, mounted on top of an obelisk. The statue base is also a sun dial, but it is calibrated to UTC+1 so that the reading is inaccurate by one hour in the summer.
The islet Munkholmen is a popular tourist attraction and recreation site. The islet has served as a place of execution, a monastery, a fortress, prison, and a World War II anti-aircraft gun station.
Stiftsgården is the royal residence in Trondheim, originally constructed in 1774 by Cecilie Christine Schøller. At 140 rooms constituting 4000 m2, it is possibly the largest wooden building in Northern Europe, and has been used by royals and their guests since 1800.
A statue of Leif Ericson is located at the seaside, close to the old Customs Building, the cruise ship facilities and the new swimming Hall. The statue is a replica, the original being located at a Seattle marina.
Nidaros Cathedral.
The Nidaros Cathedral and the Archbishop's Palace are located side by side in the middle of the city centre. The cathedral, built from 1070 on, is the most important Gothic monument in Norway and was Northern Europe's most important Christian pilgrimage site during the Middle Ages, with pilgrimage routes leading to it from Oslo in southern Norway and from the Jämtland and Värmland regions of Sweden. Today, it is the northernmost medieval cathedral in the world, and the second largest in Scandinavia.
During the Middle Ages, and again after independence was restored in 1814, the Nidaros Cathedral was the coronation church of the Norwegian kings. King Haakon VII was the last monarch to be crowned there, in 1906. Starting with King Olav V in 1957, coronation was replaced by consecration. In 1991, the present King Harald V and Queen Sonja were consecrated in the cathedral. On 24 May 2002, their daughter Princess Märtha Louise married the writer Ari Behn in the cathedral.
The Pilgrim's Route ("Pilegrimsleden") to the site of Saint Olufs's tomb at Nidaros Cathedral, has recently been re-instated. Also known as St. Olav's Way, ("Sankt Olavs vei"), the main route, which is approximately 640 km long, starts in Oslo and heads North, along the Lake Mjøsa, up the valley Gudbrandsdalen, over the mountain range Dovrefjell and down the Oppdal valley to end at Nidaros Cathedral in Trondheim. There is a Pilgrim's Office in Oslo which gives advice to pilgrims, and a Pilgrim Centre in Trondheim, under the aegis of the cathedral, which awards certificates to successful pilgrims upon the completion of their journey.
Museums.
The Trondheim Museum of Arts has Norway's third largest public art collection, mainly Norwegian art from the last 150 years. The National Museum of Decorative Arts boasts a large collection of decorative arts and design, including a great number of tapestries from the Norwegian tapestry artist Hannah Ryggen, as well as Norway's only permanent exhibibition of Japanese arts and crafts. Sverresborg, also named Zion after King David's castle in Jerusalem, was a fortification built by Sverre Sigurdsson. It is now an open air museum, consisting of more than 60 buildings. The castle was originally built in 1182–1183, but did not last for long as it was burned down in 1188. However, the Sverresaga indicates it had been restored by 1197. 
Trondheim Science Museum (Norwegian: "Vitensenteret i Trondheim") is a scientific hands-on experience center. The Museum of Natural History and Archaeology is part of the Norwegian University of Science and Technology. There are also a variety of small history, science and natural history museums, such as the Trondheim Maritime Museum, the "Armoury", adjacent to the Archbishops's Palace, the music and musical instrument museum Ringve National Museum, Ringve Botanical Garden, the Trondheim Tramway Museum, and the Jewish Museum, co-located with the city's synagogue, which is among the northernmost in the world.
 (National Center of Pop and Rock Culture) opened at the Pier in August 2010. It is located inside an old building, but characterized by an easily recognizable roof the shape of a box. "The box" is decorated by thousands of tiny lights that changes in a variety of coulours and patterns, and is a landmark in the cityscape - especially in dark winter evenings.
Churches.
The Church of Norway has 21 churches within the municipality of Trondheim. They are all a part of the Diocese of Nidaros, which is based in Trondheim at the Nidaros Cathedral. Many of the churches are several hundred years old, with a couple which were built almost 1000 years ago.
Political structure.
On 1 January 2005, the city was reorganized from five boroughs into four, with each of these having separate social services offices. The current boroughs are Midtbyen (44,967 inhabitants), Østbyen (42,707 inhabitants), Lerkendal (46,603 inhabitants) and Heimdal (30,744) inhabitants. The Population statistics listed are as of 1 January 2008.
Prior to 2005, Trondheim was divided into the boroughs "Sentrum", "Strinda", "Nardo", "Byåsen" and "Heimdal".
Education and research.
Trondheim is home to both the Norwegian University of Science and Technology (NTNU) with its many technical lab facilities and disciplines, as well as the Sør-Trøndelag University College (HiST), and BI-Trondheim, a satellite campus for the Norwegian Business School (BI). 
St. Olavs University Hospital, a regional hospital for Central Norway, is located in downtown Trondheim. St. Olavs is a teaching hospital and cooperates closely with the Norwegian University of Science and Technology (NTNU) on both research and medical education.
SINTEF, the largest independent research organisation in Scandinavia, has 1800 employees with 1300 of these located in Trondheim. The Air Force Academy of the Royal Norwegian Air Force is located at Kuhaugen in Trondheim.
The Geological Survey of Norway is located at Lade in Trondheim and is a major geoscientific institution with 220 employees of which 70% are scientists.
There are 11 high schools in the city. Trondheim katedralskole ("Trondheim Cathedral School") was founded in 1152 and is the oldest gymnasium-level school of Norway, while Brundalen videregående skole is the largest in Sør-Trøndelag with its 1100 students and 275 employees. Brundalen Skole, has big festivals each year, and is building out because to increase space.
Media.
Adresseavisen is the largest regional newspaper and the oldest active newspaper in Norway, having been established in 1767. The newspaper owns the regional television channel TVAdressa and the radio channel RadioAdressa. The two Headquarters of The Norwegian Broadcasting Corporation (NRK) are located at Tyholt in Trondheim and Oslo. The student press of Trondheim features three types of media. Under Dusken is the student paper, Radio Revolt is the student radio, and Student-TV broadcasts videos online.
Transportation.
Trondheim has an international airport, Trondheim Airport, Værnes, situated in Stjørdal, which is Norway's fourth largest airport in terms of passenger traffic. Værnes has non-stop connections to cities such as London, Amsterdam, Frankfurt and Berlin.
Major railway connections are the northbound Nordland Line, the eastbound Meråker Line to Åre and Östersund in Sweden, and two southbound connections to Oslo, the Røros Line and Dovre Line.
The Coastal Express ships (Hurtigruten: Covering the Bergen–Kirkenes stretch of the coast) call at Trondheim, as do many cruise ships during the summer season. Since 1994 there is also a fast commuter boat service to Kristiansund, the closest coastal city to the southwest.
Trondheim also boasts the northernmost (since closure of Arkhangelsk tram in 2004) tramway line in the world: the Gråkallen Line, the last remaining segment of the Trondheim Tramway, is an 8.8 km route (which is mostly single-track outside the innermost parts of the city; except the stretch between Breidablikk and Nordre Hoem stations) which runs from the city centre, through the Byåsen district, and up to Lian, in the large recreation area Bymarka. Trondheim boasts the world's only bicycle lift, "Trampe".
The bus network, operated by AtB, runs throughout most of the city and its suburbs. In addition, the Nattbuss (Night Bus) service ensures cheap and effective transport for those enjoying nightlife in the city centre during the weekends. The Nattbus has other prices than ordinary buses. The European route E6 highway passes through the city centre of Trondheim in addition to a motorway bypass along the eastern rim of the city.
Culture.
Stage.
The main regional theatre, Trøndelag Teater, is situated in Trondheim. The theatre is the oldest theatre in Scandinavia; still in use from 1816. The city also features an alternative theatre house, called Avant Garden.
Music.
Trondheim has a broad music scene, and is known for its strong communities committed to rock, jazz and classical music, the latter two spearheaded by the music conservatory at NTNU and the municipal music school, "Trondheim Kommunale Musikk- og Kulturskole", with the Trondheim Symphony Orchestra and the Trondheim Soloists being the best-known arenas. Classical artists hailing from Trondheim include violinist Arve Tellefsen, Elise Båtnes and Marianne Thorsen. Also the Nidaros Cathedral Boys' Choir.
Pop/rock artists and bands associated with Trondheim include Åge Aleksandersen, Margaret Berger, DumDum Boys, Lasse Marhaug, Gåte, Keep Of Kalessin, Lumsk, Motorpsycho, Kari Rueslåtten, The 3rd and the Mortal, TNT, Tre Små Kinesere, The Kids, Casino Steel (of The Boys), Atrox, Bloodthorn, Manes, child prodigy Malin Reitan and Aleksander With. The most popular punk scene is UFFA.
Georg Kajanus, creator of the bands Eclection, Sailor and DATA, was born in Trondheim. The music production team Stargate started out in Trondheim.
Film.
Trondheim features a lively film scene, including three filmfests: Minimalen Short Film Fest and Kosmorama International Film Fest in March, and Trondheim Documentarfestival in November.
Sports and recreation.
Granåsen, a Nordic skiing venue located in Byåsen, regularly hosts World Cup competitions in ski jumping, biathlon and cross-country skiing, as well as the 1997 FIS Nordic World Ski Championships. Trondheim attempted but failed to become the Norwegian candidate for the 2018 Winter Olympics. Hiking and recreational skiing is available around the city, particularly in Bymarka, which can be reached by the tramway. Trondheim Golfklubb has a nine-hole golf course in Byåsen. The World Allround Speed Skating Championships were hosted at Øya Stadion in 1907, 1911, 1926, 1933 and 1937.
Rosenborg BK is the city's premier football club and plays their home matches at Lerkendal Stadion. They have won the Norwegian Premier League twenty two times between 1967 and 2010, and had until 2007 played eleven times in the UEFA Champions League. Byåsen IL plays in the Women's handball league, and is a regular in EHF Women's Champions League, playing their home games at Trondheim Spektrum. Rosenborg IHK plays in the premier ice hockey league, with their home games played at Leangen Ishall.
Liverpool FC is the most popular football club among the residents of Trondheim, as in most other Norwegian cities. Several hundred make the pilgrimage via John Lennon Airport to Anfield for every home game wearing jester's hats, red wigs and festooned in badges.
Student culture.
With students comprising almost a fifth of the population, the city of Trondheim is heavily influenced by student culture. Most noticeable is Studentersamfundet i Trondhjem, the city's student society. Its characteristic round, red building from 1929 sits at the head of the bridge crossing the river southwards from the city centre. As the second largest university in Norway, the Norwegian University of Science and Technology (NTNU) is the host of some 24,000 students. Sør-Trøndelag University College has 6,000 students.
Student culture in Trondheim is characterized by a long-standing tradition of volunteer work. The student society is for example run by more than 1,200 volunteers. NTNUI, Norway's largest sports club, is among the other volunteer organizations that dominate student culture in Trondheim. Students in Trondheim are also behind two major Norwegian culture festivals, UKA and The International Student Festival in Trondheim (ISFiT). NTNU lists over 200 student organizations with registered web pages on its servers alone.
In popular culture.
Trondheim culture is parodied on the Monty Python album "Another Monty Python Record" in the form of the fictitious Trondheim Hammer Dance.
International relations.
Twin towns – Sister cities.
Trondheim is twinned with:

</doc>
<doc id="37476" url="http://en.wikipedia.org/wiki?curid=37476" title="Civil liberties">
Civil liberties

Civil liberties are personal guarantees and freedoms that the government cannot abridge, either by law or by judicial interpretation. Though the scope of the term differs amongst various countries, some examples of civil liberties include the freedom from torture, freedom from forced disappearance, freedom of conscience, freedom of press, freedom of religion, freedom of expression, freedom of assembly, the right to security and liberty, freedom of speech, the right to privacy, the right to equal treatment under the law and due process, the right to a fair trial, and the right to life. Other civil liberties include the right to own property, the right to defend oneself, and the right to bodily integrity. Within the distinctions between civil liberties and other types of liberty, distinctions exist between positive liberty/positive rights and negative liberty/negative rights.
Overview.
Many contemporary states have a constitution, a bill of rights, or similar constitutional documents that enumerate and seek to guarantee civil liberties. Other states have enacted similar laws through a variety of legal means, including signing and ratifying or otherwise giving effect to key conventions such as the European Convention on Human Rights and the International Covenant on Civil and Political Rights. The existence of some claimed civil liberties is a matter of dispute, as are the extent of most civil rights. Controversial examples include property rights, reproductive rights, and civil marriage. Whether the existence of victimless crimes infringes upon civil liberties is a matter of dispute. Another matter of debate is the suspension or alteration of certain civil liberties in times of war or state of emergency, including whether and to what extent this should occur.
The formal concept of civil liberties dates back to the English legal charter Magna Carta, which in turn was based on pre-existing documents namely the Charter of Liberties. Sealed in 1215, Magna Carta is a landmark document in English legal history and constitutional history.
Asia.
China.
The Constitution of People's Republic of China (which applies only to mainland China, not to Hong Kong, Macau and Taiwan), especially its Fundamental Rights and Duties of Citizens, claims to protect many civil liberties.
India.
The Fundamental Rights — embodied in Part III of the constitution — guarantee liberties such that all Indians can lead their lives in peace as citizens of India. The six fundamental rights are right to equality, right to freedom, right against exploitation, right to freedom of religion, cultural and educational rights and right to constitutional remedies.
These include individual rights common to most liberal democracies, incorporated in the fundamental law of the land and are enforceable in a court of law. Violations of these rights result in punishments as prescribed in the Indian Penal Code, subject to discretion of the judiciary. These rights are neither absolute nor immune from constitutional amendments. They have been aimed at overturning the inequalities of pre-independence social practices. Specifically, they resulted in abolishment of un-touchability and prohibit discrimination on the grounds of religion, race, caste, sex, or place of birth. They forbid human trafficking and unfree labour. They protect cultural and educational rights of ethnic and religious minorities by allowing them to preserve their languages and administer their own educational institutions.
All people, irrespective of race, religion, caste or sex, have the right to approach the High Courts or the Supreme Court for the enforcement of their fundamental rights. It is not necessary that the aggrieved party has to be the one to do so. In public interest, anyone can initiate litigation in the court on their behalf. This is known as "Public interest litigation". High Court and Supreme Court judges can also act on their own on the basis of media reports.
The Fundamental Rights emphasize equality by guaranteeing to all citizens the access and use of public institutions and protections, irrespective of their background. The rights to life and personal liberty apply for persons of any nationality, while others, such as the freedom of speech and expression are applicable only to the citizens of India (including non-resident Indian citizens). The right to equality in matters of public employment cannot be conferred to overseas citizens of India.
Fundamental Rights primarily protect individuals from any arbitrary State actions, but some rights are enforceable against private individuals too. For instance, the constitution abolishes untouchability and prohibits "begar". These provisions act as a check both on State action and actions of private individuals. Fundamental Rights are not absolute and are subject to reasonable restrictions as necessary for the protection of national interest. In the "Kesavananda Bharati vs. state of Kerala" case, the Supreme Court ruled that all provisions of the constitution, including Fundamental Rights can be amended. However, the Parliament cannot alter the basic structure of the constitution like secularism, democracy, federalism, separation of powers. Often called the "Basic structure doctrine", this decision is widely regarded as an important part of Indian history. In the 1978 "Maneka Gandhi v. Union of India" case, the Supreme Court extended the doctrine's importance as superior to any parliamentary legislation.According to the verdict, no act of parliament can be considered a law if it violated the basic structure of the constitution. This landmark guarantee of Fundamental Rights was regarded as a unique example of judicial independence in preserving the sanctity of Fundamental Rights.
The Fundamental Rights can only be altered by a constitutional amendment, hence their inclusion is a check not only on the executive branch, but also on the Parliament and state legislatures. The imposition of a state of emergency may lead to a temporary suspension of the rights conferred by Article 19 (including freedoms of speech, assembly and movement, etc.) to preserve national security and public order. The President can, by order, suspend the constitutional written remedies as well.
Russia.
The Constitution of Russian Federation guarantees in theory many of the same rights and civil liberties as the U.S. except to bear arms, i.e.: freedom of speech, freedom of religion, freedom of association and assembly, freedom to choose language, to due process, to a fair trial, privacy, freedom to vote, right for education, etc. However, human rights groups like Amnesty International have warned that Vladimir Putin has seriously curtailed freedom of expression, freedom of assembly and freedom of association amidst growing authoritarianism.
Australia.
Although Australia does not have an enshrined Bill of Rights or similar binding legal document, civil liberties are assumed as protected through a series of rules and conventions. Australia was a key player and signatory to the UN Universal Declaration on Human Rights (1948)
The Constitution of Australia (1900) does offer very limited protection of rights:
Certain High Court interpretations of the Constitution have allowed for implied rights such as freedom of speech and the right to vote to be established, however others such as freedom of assembly and freedom of association are yet to be identified.
Refugee Issues
Within the past decade Australia has experienced increasing contention regarding its treatment of those seeking asylum. Although Australia is a signatory to the UN Refugee Convention (1951), successive governments have demonstrated an increasing tightening of borders; particularly against those who seek passage via small water vessels.
The Abbott Government (2013) like its predecessors (the Gillard and Howard Governments) has encountered particular difficulty curbing asylum seekers via sea, increasingly identified as "illegal immigration". The recent involvement of the Australian Navy in refugee rescue operations has many human rights groups such as Amnesty International concerned over the "militarisation" of treatment of refugees. The current "turn-back" policy is particularly divisive, as it involves placing refugees in government lifeboats and turning them towards Indonesia. Despite opposition however, the Abbott government's response has so far seen a reduction in the amount of potential refugees undertaking the hazardous cross to Australia, which is argued by the government as an indicator for its policy success.
Europe.
European Convention on Human Rights.
The European Convention on Human Rights, to which almost all European countries belong (apart from Belarus), enumerates a number of civil liberties and is of varying constitutional force in different European states.
Czech Republic.
Following the Velvet Revolution, a constitutional overhaul took place in Czechoslovakia. In 1991, the Charter of Fundamental Rights and Basic Freedoms was adopted, having the same legal standing as the Constitution. The Czech Republic has kept the Charter in its entirety following the dissolution of Czechoslovakia as Act No. 2/1993 Coll. (Constitution being No. 1).
France.
France's 1789 Declaration of the Rights of Man and of the Citizen listed many civil liberties and is of constitutional force.
Germany.
The German constitution, the "Grundgesetz" (lit. "Basic Law"), starts with an elaborate listing of civil liberties and states in sec. 1 "The dignity of man is inviolable. To respect and protect it shall be the duty of all public authority." Following the "Austrian System", the people have the right to appeal to the Federal Constitutional Court of Germany ("Bundesverfassungsgericht") if they feel their civil rights are being violated. This procedure has shaped German law considerably over the years.
United Kingdom.
Civil liberties in the United Kingdom date back to Magna Carta in 1215 and 17th century common law and statute law, such as the 1628 Petition of Right and the Bill of Rights 1689. Parts of these laws remain in statute today and are supplemented by other pieces of legislation and conventions that collectively form the uncodified Constitution of the United Kingdom. In addition, the United Kingdom is a signatory to the European Convention on Human Rights which covers both human rights and civil liberties. The Human Rights Act 1998 incorporates the great majority of Convention rights directly into UK law.
In June 2008 the then Shadow Home Secretary David Davis resigned his parliamentary seat over what he described as the "erosion of civil liberties" by the then Labour government, and was re-elected on a civil liberties platform (although he was not opposed by candidates of other major parties). This was in reference to anti-terrorism laws and in particular the extension to pre-trial detention, that is perceived by many to be an infringement of habeas corpus established in Magna Carta.
North America.
Canada.
The Constitution of Canada includes the Canadian Charter of Rights and Freedoms which guarantees many of the same rights as the U.S. constitution, with the notable exceptions of protection against establishment of religion. However, the Charter does protect freedom of religion. The Charter also omits any mention of, or protection for, property.
United States.
The United States Constitution, especially its Bill of Rights, protects civil liberties. The passage of the Fourteenth Amendment further protected civil liberties by introducing the Privileges or Immunities Clause, Due Process Clause, and Equal Protection Clause. Human rights within the United States are often called civil rights, which are those rights, privileges and immunities held by all people, in distinction to "political" rights, which are the rights that inhere to those who are entitled to participate in elections, as candidates or voters. Before universal suffrage, this distinction was important, since many people were ineligible to vote but still were considered to have the fundamental freedoms derived from the rights to life, liberty and the pursuit of happiness. This distinction is less important now that Americans enjoy near universal suffrage, and civil liberties are now taken to include the political rights to vote and participate in elections. Because Indian tribal governments retain sovereignty over tribal members, the U.S. Congress in 1968 enacted a law that essentially applies most of the protections of the Bill of Rights to tribal members, to be enforced mainly by tribal courts.
Civil liberties on the internet.
Civil liberties have assumed a new role and shape due to technological changes, e-surveillance and conflict of laws in cyberspace.<ref name=" http://perry4law.org/clic/?p=83"></ref> A new category of civil liberties has emerged that is known as civil liberties protection in cyberspace.<ref name=" http://ptlb.in/clpic/"></ref> Further, securing cyberspace while protecting privacy and civil liberties has also become a challenge for various countries.<ref name=" https://www.dhs.gov/blog/2013/04/02/securing-cyberspace-while-protecting-privacy-and-civil-liberties"></ref><ref name=" http://www.hoover.org/sites/default/files/uploads/documents/0817999825_183.pdf"></ref>
The United States Supreme Court has also held that generally the cell phone of an arrested person cannot be searched without a warrant.<ref name=http://www.electroniccourts.in/privacylawsindia/?p=103"></ref> The European Union Court of Justice has also held that individuals have a Right to be forgotten in cyberspace.<ref name=http://www.electroniccourts.in/privacylawsindia/?p=79"></ref> Even United Nations Third Committee has approved the text titled Right to Privacy in the Digital Age.<ref name=http://ptlb.in/clpic/?p=244"></ref>
Further reading.
</dl>

</doc>
<doc id="37479" url="http://en.wikipedia.org/wiki?curid=37479" title="Jamie Zawinski">
Jamie Zawinski

James Werner "Jamie" Zawinski (born November 3, 1968 in Pittsburgh, Pennsylvania), commonly known as jwz, is an American hacker responsible for significant contributions to the free software projects Mozilla and XEmacs, and early versions of the Netscape Navigator web browser. He maintains the XScreenSaver project which provides screenblanking for Mac OS X and for Unix and Unix-like computer operating systems using the X Window System.
Zawinski is currently the proprietor of the DNA Lounge, a nightclub in San Francisco.
Biography.
Zawinski's early career included stints with Scott Fahlman's Lisp research group at Carnegie Mellon University, Expert Technologies, Inc. and Robert Wilensky and Peter Norvig's group at Berkeley. In the early 1990s, he was hired by Richard P. Gabriel's Lucid Inc. where he was eventually put to work on Lucid's Energize C++ IDE. Lucid decided to use GNU Emacs as the text editor for their IDE due to its free license, popularity, and extensibility. Zawinski and the other programmers made fundamental changes to GNU Emacs to add new functionality. Tensions over how to merge these patches into the main tree eventually led to the fork of the project into GNU Emacs and XEmacs.
Zawinski, with Marc Andreessen's help, worked on the early releases of Netscape Navigator, particularly the 1.0 release of the Unix version.
He became quite well known in the early days of the world wide web through an easter egg in the Netscape browser: typing "about:jwz" into the address box would take the user to his home page (a similar trick worked for other Netscape staffers). In addition, Zawinski says he came up with the name "Mozilla" in a staff meeting.
In 2000, Zawinski starred in the 60-minute-long PBS documentary "Code Rush". The footage was taken during 1998 while Zawinski was still working for Netscape in which he is portrayed as a pivotal person in the company. In addition, he underlined his preference for the night scene which led him to buy a nightclub.
Zawinski was a major proponent of opening the source code of the Mozilla browser and a key person in the creation the Mozilla project, but became disillusioned with the project when others decided to rewrite the code instead of incrementally improving it. When Netscape was acquired by AOL he wrote a famous bulletin explaining the nature of the Free Software Mozilla code. He resigned from Netscape Communications Corporation on April 1, 1999.
 His current occupation is managing his DNA Lounge nightclub in San Francisco.
"The company got big, and big companies just aren't creative.
There exist counterexamples to this, but in general, great things are accomplished by small groups of people who are driven, who have unity of purpose.
The more people involved, the slower and stupider their union becomes."
- Jamie Zawinski (on his resignation from AOL)
Principles.
Jamie Zawinski is a Lisp programmer, but most of his projects are written in Perl and C.
While still working for Netscape, Zawinski was supposedly known for his dislike of C++, stemming from his view that the language is too complex:
Because of this he believes C++ to be responsible for bloat and compatibility problems in Netscape 4.0.
Also, Zawinski criticizes several language and library deficiencies he encountered while programming in Java, precisely an overhead of certain classes but also a lack of features such as C-like assertions and typedefs. Despite the positive aspects, ultimately Zawinski returned to programming in C "since it's still the only way to ship portable programs."
In his post-Netscape life, he continued to proselytize against C++. In Peter Seibel's book "Coders at Work: Reflections on the Craft of Programming", Zawinski calls C++ an "abomination." 
Zawinski's law of software envelopment.
"Zawinski's law of software envelopment" (also known as "Zawinski's law") relates the pressure of popularity to the phenomenon of software bloat:
Examples of the law in action include Emacs, MATLAB, Mozilla, Opera, Trillian, and Drupal.
This law is attributed to Zawinski, who popularized it. It may have been inspired by the humorous "Law of Software Development and Envelopment at MIT", which was posted on Usenet in 1989 by Greg Kuperberg, who wrote:

</doc>
<doc id="37481" url="http://en.wikipedia.org/wiki?curid=37481" title="Intranet">
Intranet

An intranet is a computer network that uses Internet Protocol technology to share information, operational systems, or computing services within an organization. This term is used in contrast to "extranet", a network between organizations, and instead refers to a network within an organization. Sometimes, the term refers only to the organization's internal website, but may be a more extensive part of the organization's information technology infrastructure, and may be composed of multiple local area networks. The objective is to organize each individual's desktop with minimal cost, time and effort to be more productive, cost efficient, timely, and competitive.
An intranet may host multiple private websites and constitute an important component and focal point of internal communication and collaboration. Any of the well known Internet protocols may be found in an intranet, such as HTTP (web services), SMTP (e-mail), and FTP (file transfer protocol). Internet technologies are often deployed to provide modern interfaces to legacy information systems hosting corporate data.
An intranet can be understood as a private analog of the Internet, or as a private extension of the Internet confined to an organization. The first intranet websites and home pages were published in 1991, and began to appear in non-educational organizations in 1994.
Intranets are sometimes contrasted to extranets. While intranets are generally restricted to employees of the organization, extranets may also be accessed by customers, suppliers, or other approved parties. Extranets extend a private network onto the Internet with special provisions for authentication, authorization and accounting (AAA protocol).
In many organizations, intranets are protected from unauthorized external access by means of a network gateway and firewall. For smaller companies, intranets may be created simply by using private IP address ranges. In these cases, the intranet can only be directly accessed from a computer in the local network; however, companies may provide access to off-site employees by using a virtual private network, or by other access methods, requiring user authentication and encryption.
Uses.
Increasingly, intranets are being used to deliver tools, e.g. "collaboration" (to facilitate working in groups and teleconferencing) or sophisticated corporate directories, sales and customer relationship management tools, project management etc., to advance productivity.
Intranets are also being used as corporate culture-change platforms. For example, large numbers of employees discussing key issues in an intranet forum application could lead to new ideas in management, productivity, quality, and other corporate issues.
In large intranets, website traffic is often similar to public website traffic and can be better understood by using web metrics software to track overall activity. User surveys also improve intranet website effectiveness. Larger businesses allow users within their intranet to access public internet through firewall servers. They have the ability to screen messages coming and going keeping security intact.
When part of an intranet is made accessible to customers and others outside the business, that part becomes part of an extranet. Businesses can send private messages through the public network, using special encryption/decryption and other security safeguards to connect one part of their intranet to another.
Intranet user-experience, editorial, and technology teams work together to produce in-house sites. Most commonly, intranets are managed by the communications, HR or CIO departments of large organizations, or some combination of these.
Because of the scope and variety of content and the number of system interfaces, intranets of many organizations are much more complex than their respective public websites. Intranets and their use are growing rapidly. According to the Intranet design annual 2007 from Nielsen Norman Group, the number of pages on participants' intranets averaged 200,000 over the years 2001 to 2003 and has grown to an average of 6 million pages over 2005–2007.
Planning and creation.
Most organizations devote considerable resources into the planning and implementation of their intranet as it is of strategic importance to the organization's success. Some of the planning would include topics such as:
These are in addition to the hardware and software decisions (like content management systems), participation issues (like good taste, harassment, confidentiality), and features to be supported.
Intranets are often static sites. Essentially they are a shared drive, serving up centrally stored documents alongside internal articles or communications (often one-way communication). However organisations are now starting to think of how their intranets can become a 'communication hub' for their team by using companies specialising in 'socialising' intranets.
The actual implementation would include steps such as:
Another useful component in an intranet structure might be key personnel committed to maintaining the Intranet and keeping content current. For feedback on the intranet, social networking can be done through a forum for users to indicate what they want and what they do not like.
Intranet software.
Microsoft SharePoint is the dominant software used for creating intranets. Estimates indicate that around 50% of all intranets are developed using SharePoint, however there are many alternatives. Other intranet software includes:

</doc>
<doc id="37483" url="http://en.wikipedia.org/wiki?curid=37483" title="Womyn">
Womyn

"Womyn" is one of several alternative spellings of the English word "women" used by some feminists. There are many alternative spellings, including "womban" and "womon" (singular), and "wimmin" (plural). Some writers who use alternative spellings may see them as an expression of female independence and a repudiation of traditions that define females by reference to a male norm.
Background.
In Old English sources, the word "man" was gender-neutral, with a meaning similar to the modern English usage of "one" as an indefinite pronoun. The words "wer" and "wyf" were used to specify a man or woman where necessary, respectively. Combining them into "wer-man" or "wyf-man" expressed the concept of "any man" or "any woman". Feminist writers have suggested that the less prejudicial usage of the Old English sources reflects more egalitarian notions of gender at the time. 
Reasoning.
Some feminists object to the fact that "woman" and "women" are just "man" and "men" with a "wo-" prepended.
Variants.
Womon/womyn.
"Womyn" appeared as an Older Scots spelling of "woman" in the Scots poetry of James Hogg. Its usage as a feminist spelling of "women" (with "womon" as the singular form) first appeared in print in 1976 referring to the first Michigan Womyn's Music Festival, an annual art festival that admits only womyn-born womyn.
Womon/wimmin.
"Wimmin" appeared in 19th century renderings of Black American English, without any feminist significance. Z. Budapest promoted the use of "wimmin" (singular "womon") in the 1970s as part of her Dianic Wicca movement, which claims that present-day patriarchy represents a fall from a matriarchal golden age.

</doc>
<doc id="37484" url="http://en.wikipedia.org/wiki?curid=37484" title="Clit (disambiguation)">
Clit (disambiguation)

Clit is a colloquial abbreviation for clitoris.
Clit or Cliţ can also refer to:

</doc>
<doc id="37486" url="http://en.wikipedia.org/wiki?curid=37486" title="Nuke">
Nuke

Nuke may refer to: 

</doc>
<doc id="37495" url="http://en.wikipedia.org/wiki?curid=37495" title="Noun">
Noun

A noun (Latin: "nōmen", "name") is a word that functions as the name of some specific thing or set of things, such as living creatures, objects, places, actions, qualities, states of existence, or ideas. Linguistically, a noun is a member of a large, open part of speech whose members can occur as the main word in the subject of a clause, the object of a verb, or the object of a preposition.
Lexical categories (parts of speech) are defined in terms of the ways in which their members combine with other kinds of expressions. The syntactic rules for nouns differ from language to language. In English, nouns are those words which can occur with articles and attributive adjectives and can function as the head of a noun phrase.
History <span id="Substantive as a word for noun" />.
Word classes (parts of speech) were described by Sanskrit grammarians from at least the 5th century BC. In Yāska's "Nirukta", the noun ("nāma") is one of the four main categories of words defined.
The Ancient Greek equivalent was "ónoma" (ὄνομα), referred to by Plato in the "Cratylus" dialog, and later listed as one of the eight parts of speech in "The Art of Grammar", attributed to Dionysius Thrax (2nd century BC). The term used in Latin grammar was "nōmen". All of these terms for "noun" were also words meaning "name". The English word "noun" is derived from the Latin term, through the Anglo-Norman "noun".
The word classes were defined partly by the grammatical forms that they take. In Sanskrit, Greek and Latin, for example, nouns are categorized by gender and inflected for case and number. Because adjectives share these three grammatical categories, adjectives were originally placed in the same class as nouns. For example, in "The Art of Grammar", words of adjectival type are largely contained in the subclass of "ónoma" described as "paragōgón" (plural "paragōgá"), meaning "derived". Similarly, the Latin "nōmen" included both nouns (substantives) and adjectives, as originally did the English word "noun", the two types being distinguished as "nouns substantive" and "nouns adjective". (The word "nominal" is now sometimes used to denote a class that includes both nouns and adjectives.)
Many European languages use a cognate of the word "substantive" as the basic term for noun (for example, Spanish "sustantivo", "noun"). Nouns in the dictionaries of such languages are demarked by the abbreviation "s." or "sb." instead of "n", which may be used for proper nouns instead. In English, some modern authors use the word "substantive" to refer to a class that includes both nouns (single words) and noun phrases (multiword units, also called noun equivalents). It can also be used as a counterpart to "attributive" when distinguishing between a noun being used as the head (main word) of a noun phrase and a noun being used as a noun adjunct. For example, the noun "knee" can be said to be used substantively in "my knee hurts", but attributively in "the patient needed knee replacement".
Definitions of nouns.
Nouns have sometimes been defined in terms of the grammatical categories to which they are subject (classed by gender, inflected for case and number). Such definitions tend to be language-specific, since nouns do not have the same categories in all languages.
Nouns are frequently defined, particularly in informal contexts, in terms of their semantic properties (their meanings). Nouns are described as words that refer to a "person", "place", "thing", "event", "substance", "quality", "quantity", etc. However this type of definition has been criticized by contemporary linguists as being uninformative.
There have been offered several examples of English-language nouns which do not have any reference: "drought", "enjoyment", "finesse", "behalf" (as found in "on behalf of"), "dint" ("in dint of"), and "sake" ("for the sake of").
Linguists often prefer to define nouns (and other lexical categories) in terms of their formal properties. These include morphological information, such as what prefixes or suffixes they take, and also their syntax – how they combine with other words and expressions of particular types. Such definitions may nonetheless still be language-specific, since syntax as well as morphology varies between languages. For example, in English it might be noted that nouns are words that can co-occur with definite articles (as stated at the start of this article), but this would not apply in Russian, which has no definite articles.
There have been several attempts, sometimes controversial, to produce a stricter definition of nouns on a semantic basis. Some of these are referenced in the Further reading section below.
Gender.
In some languages, nouns are assigned to genders, such as masculine, feminine and neuter (or other combinations). The gender of a noun (as well as its number and case, where applicable) will often entail agreement in words that modify or are related to it. For example, in French, the singular form of the definite article is "le" with masculine nouns and "la" with feminines; adjectives and certain verb forms also change (with the addition of "-e" with feminines). Grammatical gender often correlates with the form of the noun and the inflection pattern it follows; for example, in both Italian and Russian most nouns ending "-a" are feminine. Gender can also correlate with the sex of the noun's referent, particularly in the case of nouns denoting people (and sometimes animals). Nouns do not have gender in Modern English, although many of them denote people or animals of a specific sex.
Classification of nouns.
Proper nouns and common nouns.
A "proper noun" or "proper name" is a noun representing unique entities (such as "Earth", "India", "Jupiter", "Harry", or "BMW"), as distinguished from common nouns which describe a class of entities (such as "city", "animal, planet", "person" or "car").
Countable and uncountable nouns.
"Count nouns" or "countable nouns" are common nouns that can take a plural, can combine with numerals or counting quantifiers (e.g., "one", "two", "several", "every", "most"), and can take an indefinite article such as "a" or "an" (in languages which have such articles). Examples of count nouns are "chair", "nose", and "occasion".
"Mass nouns" or "uncountable" (or "non-count") "nouns" differ from count nouns in precisely that respect: they cannot take plurals or combine with number words or the above type of quantifiers. For example, it is not possible to refer to "a furniture" or "three furnitures". This is true even though the pieces of furniture comprising "furniture" could be counted. Thus the distinction between mass and count nouns should not be made in terms of what sorts of things the nouns refer to, but rather in terms of how the nouns "present" these entities.
Many nouns have both countable and uncountable uses; for example, "beer" is countable in "give me three beers", but uncountable in "he likes beer".
Collective nouns.
"Collective nouns" are nouns that – even when they are inflected for the singular – refer to "groups" consisting of more than one individual or entity. Examples include "committee", "government", and "police". In English these nouns may be followed by a singular or a plural verb and referred to by a singular or plural pronoun, the singular being generally preferred when referring to the body as a unit and the plural often being preferred, especially in British English, when emphasizing the individual members. Examples of acceptable and unacceptable use given by Gowers in "Plain Words" include: 
Concrete nouns and abstract nouns.
"Concrete nouns" refer to physical entities that can, in principle at least, be observed by at least one of the senses (for instance, "chair", "apple", "Janet" or "atom"). "Abstract nouns", on the other hand, refer to abstract objects; that is, ideas or concepts (such as "justice" or "hatred"). While this distinction is sometimes exclusive, some nouns have multiple senses, including both concrete and abstract ones; consider, for example, the noun "art", which usually refers to a concept (e.g., "Art is an important element of human culture") but which can refer to a specific artwork in certain contexts (e.g., "I put my daughter's art up on the fridge").
Some abstract nouns developed etymologically by figurative extension from literal roots. These include "drawback, fraction, holdout," and "uptake". Similarly, some nouns have both abstract and concrete senses, with the latter having developed by figurative extension from the former. These include "view, filter, structure," and "key".
In English, many abstract nouns are formed by adding noun-forming suffixes ("-ness", "-ity", "-ion") to adjectives or verbs. Examples are "happiness" (from the adjective "happy"), "circulation" (from the verb "circulate") and "serenity" (from the adjective "serene").
Noun phrases.
A noun phrase is a phrase based on a noun, pronoun, or other noun-like word (nominal) optionally accompanied by modifiers such as determiners and adjectives. A noun phrase functions within a clause or sentence in a role such as that of subject, object, or complement of a verb or preposition. For example, in the sentence "The black cat sat on a dear friend of mine", the noun phrase "the black cat" serves as the subject, and the noun phrase "a dear friend of mine" serves as the complement of the preposition "on".
Pronouns.
Nouns and noun phrases can typically be replaced by pronouns, such as "he", "it", "which", and "those", in order to avoid repetition or explicit identification, or for other reasons. For example, in the sentence "Janeth thought that he was weird", the word "he" is a pronoun standing in place of the name of the person in question. The English word "one" can replace parts of noun phrases, and it sometimes stands in for a noun. An example is given below:
But "one" can also stand in for bigger sub parts of a noun phrase. For example, in the following example, "one" can stand in for "new car".
Nominalization.
Nominalization is a process whereby a word that belongs to another part of speech comes to be used as a noun.
In French and Spanish, for example, adjectives frequently act as nouns referring to people who have the characteristics denoted by the adjective. This sometimes happens in English as well, as in the following examples:
Further reading.
For definitions of nouns based on the concept of "identity criteria":
For more on identity criteria:
For the concept that nouns are "prototypically referential":
For an attempt to relate the concepts of identity criteria and prototypical referentiality:
Understanding nouns in the context of WordNet:

</doc>
<doc id="37496" url="http://en.wikipedia.org/wiki?curid=37496" title="Fisherman's knot">
Fisherman's knot

The fisherman's knot is a bend (a knot for joining two lines) with a symmetrical structure consisting of two overhand knots, each tied around the standing part of the other. Other names for the fisherman's knot include: angler's knot, English knot, halibut knot, waterman's knot.
Though the fisherman's knot is associated with fishing, it can slip when tied in nylon monofilament and other slippery lines; however, if more holding strength is required, the overhand knots can be made with more turns, as in the double fisherman's knot, and so on. It is compact, jamming when tightened and the working ends can be cropped very close to the knot. It can also be easily tied with cold, wet hands. Though these properties are well suited to fishing, there are other knots which may provide superior performance, such as the blood knot.
In knitting, the knot is used to join two strands of yarn. In this context, it is commonly known as "the magic knot".

</doc>
<doc id="37500" url="http://en.wikipedia.org/wiki?curid=37500" title="Rutger Hauer">
Rutger Hauer

Rutger Oelsen Hauer (]; born 23 January 1944) is a Dutch actor, writer, and environmentalist. He acted in both Dutch and English-language TV series and films.
His career began in 1969 with the title role in the Dutch television series "Floris". His film credits include "Flesh+Blood", "Blind Fury", "Blade Runner", "The Hitcher", "Escape from Sobibor" (for which he won a Golden Globe Award for Best Supporting Actor), "Nighthawks", "Wedlock", "Sin City", "Confessions of a Dangerous Mind", "Ladyhawke", "Buffy the Vampire Slayer", "The Osterman Weekend", "The Blood of Heroes", "Batman Begins", "Hobo with a Shotgun", and "The Rite".
Hauer founded the Rutger Hauer Starfish Association, an AIDS awareness organization.
Early life.
Rutger Oelsen Hauer was born on 23 January 1944 in Breukelen in the Netherlands. He is the son of drama teachers Teunke (neé Mellema) and Arend Hauer. He has three sisters, one older and two younger.
Hauer grew up in Amsterdam. Since his parents were very occupied with their careers, he and his sisters were brought up mostly by nannies. He went to a Waldorf school.
At the age of 15, Hauer ran off to sea and spent a year scrubbing decks aboard a freighter. Returning home, he worked as an electrician and a joiner for three years while attending acting classes at night school. Hauer served in the Royal Netherlands Navy.
Career.
Hauer joined an experimental troupe, with which he remained for five years before Paul Verhoeven cast him in the lead role of the successful 1969 television series "Floris", a Dutch medieval action drama. The role made him famous in his native country, and Hauer reprised his role for the 1975 German remake "Floris von Rosemund". Hauer's career changed course when Verhoeven cast him in "Turkish Delight" (1973). The movie found box-office favour abroad as well as at home, and within two years, Hauer was invited to make his English-language debut in the British film "The Wilby Conspiracy" (1975). Set in South Africa, the film was an action-drama with a focus on apartheid. Hauer's supporting role, however, was barely noticed in Hollywood, and he returned to Dutch films for several years. During this period, he made "Katie Tippel" (1975) and worked again with Verhoeven on "Soldier of Orange" (1977), and "Spetters" (1980). These two films paired Hauer with fellow Dutch actor Jeroen Krabbé.
Hauer made his American debut in the Sylvester Stallone film "Nighthawks" (1981) as a psychopathic and cold blooded terrorist named Wulfgar. The following year, he appeared in arguably his most famous and acclaimed role as the eccentric and violent but sympathetic anti-hero Roy Batty in Ridley Scott's 1982 science fiction thriller "Blade Runner", in which he improvised the famous tears in rain monologue. Hauer went on to play the adventurer courting Theresa Russell in "Eureka" (1983), the investigative reporter opposite John Hurt in "The Osterman Weekend" (1983), the hardened Landsknecht mercenary Martin in "Flesh & Blood" (1985), and the knight paired with Michelle Pfeiffer in "Ladyhawke" (1985).
He continued to make an impression on audiences in "The Hitcher" (1986), in which he played a mysterious hitchhiker intent on murdering a lone motorist and anyone else in his way. At the height of Hauer's fame, he was set to be cast as RoboCop though the role went to Peter Weller. That same year, Hauer starred as Nick Randall in "" as the descendant of the character played by Steve McQueen in the television series of the same name. In "The Legend of the Holy Drinker" (1989), Hauer showed a more soulful side. Phillip Noyce also attempted to capitalize, with far less success, on Hauer's spiritual qualities in the martial arts action adventure "Blind Fury" (1989). Hauer returned to science fiction with "The Blood of Heroes" (1990), in which he played a former champion in a post-apocalyptic world.
By the 1990s, Hauer was well known for his humorous Guinness commercials as well as his screen roles, which had increasingly involved low-budget films such as "Split Second", "Omega Doom", and "New World Disorder". He also appeared in the Kylie Minogue music video "On a Night Like This". In the late 1980s and 1990s, as well as in 2000, Hauer acted in several British and American television productions, including "Inside the Third Reich", "Escape from Sobibor" (for which he received a Golden Globe Award for Best Supporting Actor), "Fatherland", "" as Amelia Earhart's navigator Noonan, "Hostile Waters", "Merlin", "The 10th Kingdom", "Smallville", "Alias", and "Salem's Lot". In 1999, Hauer was awarded the Dutch "Best Actor of the Century Rembrandt Award".
Hauer played an assassin in "Confessions of a Dangerous Mind" (2003), a villainous cardinal with influential power in "Sin City" (2005) and a devious corporate executive running Wayne Enterprises in "Batman Begins" (2005). He also hosted the British reality television documentary "Shock Treatment" in 2005. He starred in "" as Real Madrid coach Rudi Van Der Merwe. In 2007 he recorded the voice-overs for the UK advertising campaign for Lurpak butter. In 2009, his role in avant-garde filmmaker Cyrus Frisch's "Dazzle", received positive reviews. The film was praised in Dutch press as "the most relevant Dutch film of the year". The same year, Hauer starred in the title role of "Barbarossa", an Italian film directed by Renzo Martinelli. In April 2010, he was cast in the live action adaptation of the short and fictitious "Grindhouse" trailer "Hobo With a Shotgun" (2011). In March 2011, it was announced that Hauer would play vampire hunter Van Helsing in legendary horror director Dario Argento's "Dracula 3D". He also starred as "Niall Brigant" in season 6 of HBO's "True Blood".
Hauer is a knight in the Order of the Netherlands Lion since 2013.
In 2015 he was the voice in a Lurpak commercials.
Personal life.
Hauer is an environmentalist. He advocated for the release of Sea Shepherd Conservation Society leader, Paul Watson, who was convicted in 1994 for sinking a Norwegian whaling vessel. Hauer has also established an AIDS awareness organization called the Rutger Hauer Starfish Association. Hauer married his second wife, Ineke ten Cate, in 1985 (they had been together since 1968); and he has one child born in 1966, actress Aysha Hauer who made him a grandfather in 1987. In April 2007, he published his autobiography "All Those Moments: Stories of Heroes, Villains, Replicants, and Blade Runners" (co-written with Patrick Quinlan), where he discusses many of his movie roles. Proceeds of the book go to Hauer's Starfish Association.
Filmography.
The filmography of Rutger Hauer gives an overview of all his performances as an actor in films, television films, and television series from 1969 to date, and also in upcoming films.

</doc>
<doc id="37503" url="http://en.wikipedia.org/wiki?curid=37503" title="Terrarium">
Terrarium

Terrariums are usually sealable glass containers that can be opened for maintenance and to access the plants inside. However, this is not essential; terrariums can also be madials, and some are open to the atmosphere rather than being sealed. Terrariums are often kept as decorative or ornamental items in the same way as aquariums.
Closed terrariums create a unique environment for plant growth, as the transparent walls allow for both heat and light to enter the terrarium. The sealed container combined with the heat entering the terrarium allows for the creation of a small scale water cycle. This happens because moisture from both the soil and plants evaporates in the elevated temperatures inside the terrarium. This water vapour then condenses on the walls of the container, and eventually falls back to the plants and soil below. This contributes to creating an ideal environment for growing plants due to the constant supply of water, thereby preventing the plants from becoming over dry. In addition to this, the light that passes through the transparent material of the terrarium allows for the plants within to photosynthesis, an important aspect of plant growth.
History.
The first terrarium was developed by botanist Nathaniel Bagshaw Ward in 1842. Ward had an interest in observing insect behaviour and accidentally left one of the jars unattended. A fern spore in the jar grew, germinated into a plant, and the terrarium was born. The trend quickly spread in the Victorian Era amongst the English. Instead of the terrarium, it was known as the Wardian Case.
The story goes that Ward hired carpenters to build his Wardian Cases to export native British plants to Sydney, Australia. After months of travel, the plants arrived well and thriving. Likewise, plants from Australia were sent to London using the same method and Ward received his Australian plants in perfect condition. His experiment indicated that plants can be sealed in glass without ventilation and continue thriving. 
Types.
Because of the different conditions within, terrariums can be classified into two types: closed and open.
Closed terrariums.
Tropical plant varieties, such as mosses, orchids, ferns and air plants, are generally kept within closed terrariums due to the conditions being similar to the humid and sheltered environment of the tropics. 
Keeping the terrarium sealed allows for the circulation of water, but terrariums must be opened once a week to remove excess moisture from the air and walls of the container. This is done to prevent growth of mould which could damage the plants and discolour the sides of the terrarium, this contradicts the myth that terrariums are never opened. Terrariums must also be watered occasionally, the absence of condensation on the walls of the terrarium or any wilting of the plants is an indicator that the terrarium requires water. 
Closed terrariums also require a special soil mix to ensure both good growing conditions and to reduce the risks of microbial damage. A common medium used is peat-lite a mixture of peat moss, vermiculite and perlite. The mixture must be sterile in order to avoid introducing potentially harmful microbes. 
Open terrariums.
Open terrariums are better suited to dry plants such as succulents. Not all plants require or are suited to the moist environment of closed terrariums. So for plants adapted to dry climates, open, unsealed, terrariums are used to keep the air in the terrarium free from excess moisture.

</doc>
<doc id="37504" url="http://en.wikipedia.org/wiki?curid=37504" title="Stock (disambiguation)">
Stock (disambiguation)

Stock is a representation of capital paid or invested into a business entity by stockholders.
Stock may also refer to:

</doc>
<doc id="37506" url="http://en.wikipedia.org/wiki?curid=37506" title="Garnet">
Garnet

Garnets are a group of silicate minerals that have been used since the Bronze Age as gemstones and abrasives.
All species of garnets possess similar physical properties and crystal forms, but differ in chemical composition. The different species are pyrope, almandine, spessartine, grossular (varieties of which are hessonite or cinnamon-stone and tsavorite), uvarovite and andradite. The garnets make up two solid solution series: pyrope-almandine-spessartine and uvarovite-grossular-andradite.
Physical properties.
Properties.
Garnet species are found in many colors including red, orange, yellow, green, purple, brown, blue, black, pink and colorless. The rarest of these is the blue garnet, discovered in the late 1990s in Bekily, Madagascar. It is also found in parts of the United States, Russia, Kenya, Tanzania, and Turkey. It changes color from blue-green in the daylight to purple in incandescent light, as a result of the relatively high amounts of vanadium (about 1 wt.% V2O3). Other varieties of color-changing garnets exist. In daylight, their color ranges from shades of green, beige, brown, gray, and blue, but in incandescent light, they appear a reddish or purplish/pink color. Because of their color-changing quality, this kind of garnet is often mistaken for Alexandrite. 
Garnet species' light transmission properties can range from the gemstone-quality transparent specimens to the opaque varieties used for industrial purposes as abrasives. The mineral's luster is categorized as vitreous (glass-like) or resinous (amber-like).
Crystal structure.
Garnets are nesosilicates having the general formula "X"3"Y"2(Si O4)3. The "X" site is usually occupied by divalent cations (Ca, Mg, Fe, Mn)2+ and the "Y" site by trivalent cations (Al, Fe, Cr)3+ in an octahedral/tetrahedral framework with [SiO4]4− occupying the tetrahedra. Garnets are most often found in the dodecahedral crystal habit, but are also commonly found in the trapezohedron habit. (Note: the word "trapezohedron" as used here and in most mineral texts refers to the shape called a Deltoidal icositetrahedron in solid geometry.) They crystallize in the cubic system, having three axes that are all of equal length and perpendicular to each other. Garnets do not show cleavage, so when they fracture under stress, sharp irregular pieces are formed (conchoidal).
Hardness.
Because the chemical composition of garnet varies, the atomic bonds in some species are stronger than in others. As a result, this mineral group shows a range of hardness on the Mohs scale of about 6.5 to 7.5. The harder species like almandine are often used for abrasive purposes.
Magnetics used in garnet series identification.
For gem identification purposes, a pick-up response to a strong neodymium magnet separates garnet from all other natural transparent gemstones commonly used in the jewelry trade. Magnetic susceptibility measurements in conjunction with refractive index can be used to distinguish garnet species and varieties, and determine the composition of garnets in terms of percentages of end-member species within an individual gem. See http://gemstonemagnetism.com.
Garnet group endmember species.
Pyralspite garnets – aluminium in "Y" site.
Almandine.
Almandine, sometimes incorrectly called almandite, is the modern gem known as carbuncle (though originally almost any red gemstone was known by this name). The term "carbuncle" is derived from the Latin meaning "live coal" or burning charcoal. The name "Almandine" is a corruption of Alabanda, a region in Asia Minor where these stones were cut in ancient times. Chemically, almandine is an iron-aluminium garnet with the formula Fe3Al2(SiO4)3; the deep red transparent stones are often called precious garnet and are used as gemstones (being the most common of the gem garnets). Almandine occurs in metamorphic rocks like mica schists, associated with minerals such as staurolite, kyanite, andalusite, and others. Almandine has nicknames of Oriental garnet, almandine ruby, and carbuncle.
Pyrope.
Pyrope (from the Greek "pyrōpós" meaning "fire-eyed") is red in color and chemically an aluminium silicate with the formula Mg3Al2(SiO4)3, though the magnesium can be replaced in part by calcium and ferrous iron. The color of pyrope varies from deep red to black. Pyrope and spessartine gemstones have been recovered from the Sloan diamondiferous kimberlites in Colorado, from the Bishop Conglomerate and in a Tertiary age lamprophyre at Cedar Mountain in Wyoming.
A variety of pyrope from Macon County, North Carolina is a violet-red shade and has been called "rhodolite", Greek for "rose". In chemical composition it may be considered as essentially an isomorphous mixture of pyrope and almandine, in the proportion of two parts pyrope to one part almandine. Pyrope has tradenames some of which are misnomers; "Cape ruby", "Arizona ruby", "California ruby", "Rocky Mountain ruby", and "Bohemian garnet" from the Czech Republic. Another intriguing find is the blue color-changing garnets from Madagascar, a pyrope-spessartine mix. The color of these blue garnets is not like sapphire blue in subdued daylight but more reminiscent of the grayish blues and greenish blues sometimes seen in spinel. However, in white LED light, the color is equal to the best cornflower blue sapphire, or D block tanzanite; this is due to the blue garnet's ability to absorb the yellow component of the emitted light.
Pyrope is an indicator mineral for high-pressure rocks. The garnets from mantle-derived rocks, peridotites, and eclogites commonly contain a pyrope variety.
Spessartine.
Spessartine or spessartite is manganese aluminium garnet, Mn3Al2(SiO4)3. Its name is derived from Spessart in Bavaria. It occurs most often in granite pegmatite and allied rock types and in certain low grade metamorphic phyllites. Spessartine of an orange-yellow is found in Madagascar. Violet-red spessartines are found in rhyolites in Colorado and Maine.
Ugrandite group – calcium in "X" site.
Andradite.
Andradite is a calcium-iron garnet, Ca3Fe2(SiO4)3, is of variable composition and may be red, yellow, brown, green or black. The recognized varieties are topazolite (yellow or green), demantoid (green) and melanite (black). Andradite is found both in deep-seated igneous rocks like syenite as well as serpentines, schists, and crystalline limestone. Demantoid has been called the "emerald of the Urals" from its occurrence there, and is one of the most prized of garnet varieties. Topazolite is a golden-yellow variety and melanite is a black variety.
Grossular.
Grossular is a calcium-aluminium garnet with the formula Ca3Al2(SiO4)3, though the calcium may in part be replaced by ferrous iron and the aluminium by ferric iron. The name grossular is derived from the botanical name for the gooseberry, "grossularia", in reference to the green garnet of this composition that is found in Siberia. Other shades include cinnamon brown (cinnamon stone variety), red, and yellow. Because of its inferior hardness to zircon, which the yellow crystals resemble, they have also been called "hessonite" from the Greek meaning inferior. Grossular is found in contact metamorphosed limestones with vesuvianite, diopside, wollastonite and wernerite.
Grossular garnet from Kenya and Tanzania has been called tsavorite. Tsavorite was first described in the 1960s in the area of Kenya, from which the gem takes its name.
Uvarovite.
Uvarovite is a calcium chromium garnet with the formula Ca3Cr2(SiO4)3. This is a rather rare garnet, bright green in color, usually found as small crystals associated with chromite in peridotite, serpentinite, and kimberlites. It is found in crystalline marbles and schists in the Ural mountains of Russia and Outokumpu, Finland.
Less common species.
Knorringite.
Knorringite is a magnesium-chromium garnet species with the formula Mg3Cr2(SiO4)3. Pure endmember knorringite never occurs in nature. Pyrope rich in the knorringite component is only formed under high pressure and is often found in kimberlites. It is used as an indicator mineral in the search for diamonds.
Synthetic garnets.
The crystallographic structure of garnets has been expanded from the prototype to include chemicals with the general formula "A"3"B"2("C" O4)3. Besides silicon, a large number of elements have been put on the "C" site, including Ge, Ga, Al, V and Fe.
Yttrium aluminium garnet (YAG), Y3Al2(AlO4)3, is used for synthetic gemstones. Due to its fairly high refractive index, YAG was used as a diamond simulant in the 1970s until the methods of producing the more advanced simulant cubic zirconia in commercial quantities were developed. When doped with neodymium (Nd3+), these YAl-garnets may be used as the lasing medium in lasers.
Interesting magnetic properties arise when the appropriate elements are used. In yttrium iron garnet (YIG), Y3Fe2(FeO4)3, the five iron(III) ions occupy two octahedral and three tetrahedral sites, with the yttrium(III) ions coordinated by eight oxygen ions in an irregular cube. The iron ions in the two coordination sites exhibit different spins, resulting in magnetic behavior. YIG is a ferrimagnetic material having a Curie temperature of 550 K.
Another example is gadolinium gallium garnet, Gd3Ga2(GaO4)3 which is synthesized for use as a substrate for liquid-phase epitaxy of magnetic garnet films for bubble memory and magneto-optical applications.
Geological importance of garnet.
The Garnet group is a key mineral in interpreting the genesis of many igneous and metamorphic rocks via geothermobarometry. Diffusion of elements is relatively slow in garnet compared to rates in many other minerals, and garnets are also relatively resistant to alteration. Hence, individual garnets commonly preserve compositional zonations that are used to interpret the temperature-time histories of the rocks in which they grew. Garnet grains that lack compositional zonation commonly are interpreted as having been homogenized by diffusion, and the inferred homogenization also has implications for the temperature-time history of the host rock.
Garnets are also useful in defining metamorphic facies of rocks. For instance, eclogite can be defined as a rock of basalt composition, but mainly consisting of garnet and omphacite. Pyrope-rich garnet is restricted to relatively high-pressure metamorphic rocks, such as those in the lower crust and in the Earth's mantle. Peridotite may contain plagioclase, or aluminium-rich spinel, or pyrope-rich garnet, and the presence of each of the three minerals defines a pressure-temperature range in which the mineral could equilibrate with olivine plus pyroxene: the three are listed in order of increasing pressure for stability of the peridotite mineral assemblage. Hence, garnet peridotite must have been formed at great depth in the earth. Xenoliths of garnet peridotite have been carried up from depths of 100 km and greater by kimberlite, and garnets from such disaggegated xenoliths are used as a kimberlite indicator minerals in diamond prospecting. At depths of about 300 to and greater, a pyroxene component is dissolved in garnet, by the substitution of (Mg,Fe) plus Si for 2Al in the octahedral (Y) site in the garnet structure, creating unusually silica-rich garnets that have solid solution towards majorite. Such silica-rich garnets have been identified as inclusions within diamonds.
Uses of garnets.
Gemstones.
Red garnets were the most commonly used gemstones in the Late Antique Roman world, and the Migration Period art of the "barbarian" peoples who took over the territory of the Western Roman Empire. They were especially used inlaid in gold cells in the cloisonné technique, a style often just called garnet cloisonné, found from Anglo-Saxon England, as at Sutton Hoo, to the Black Sea.
Pure crystals of garnet are still used as gemstones. The gemstone varieties occur in shades of green, red, yellow, and orange. In the US it is known as the birthstone for January. It is the state mineral of Connecticut, New York's gemstone, and star garnet (garnet with rutile asterisms) is the state gemstone of Idaho.
Industrial uses.
Garnet sand is a good abrasive, and a common replacement for silica sand in sand blasting. Alluvial garnet grains which are rounder are more suitable for such blasting treatments. Mixed with very high pressure water, garnet is used to cut steel and other materials in water jets. For water jet cutting, garnet extracted from hard rock is suitable since it is more angular in form, therefore more efficient in cutting.
Garnet paper is favored by cabinetmakers for finishing bare wood. 
Garnet sand is also used for water filtration media.
As an abrasive garnet can be broadly divided in two categories; blasting grade and water jet grade. The garnet, as it is mined and collected, is crushed to finer grains; all pieces which are larger than 60 mesh (250 micrometers) are normally used for sand blasting. The pieces between 60 mesh (250 micrometers) and 200 mesh (74 micrometers) are normally used for water jet cutting. The remaining garnet pieces that are finer than 200 mesh (74 micrometers) are used for glass polishing and lapping. Regardless of the application, the larger grain sizes are used for faster work and the smaller ones are used for finer finishes.
There are different kinds of abrasive garnets which can be divided based on their origin. The largest source of abrasive garnet today is
garnet-rich beach sand which is quite abundant on Indian and Australian coasts and the main producers today are Australia and India.
This material is particularly popular due to its consistent supplies, huge quantities and clean material. The common problems with this material are the presence of ilmenite and chloride compounds. Since the material has been naturally crushed and ground on the beaches for past centuries, the material is normally available in fine sizes only. Most of the garnet at the Tuticorin beach in south India is 80 mesh, and ranges from 56 mesh to 100 mesh size.
"River garnet" is particularly abundant in Australia. The river sand garnet occurs as a placer deposit.
"Rock garnet" is perhaps the garnet type used for the longest period of time. This type of garnet is produced in America, China and western India. These crystals are crushed in mills and then purified by wind blowing, magnetic separation, sieving and, if required, washing. Being freshly crushed, this garnet has the sharpest edges and therefore performs far better than other kinds of garnet. Both the river and the beach garnet suffer from the tumbling effect of hundreds of thousands of years which rounds off the edges.
Garnet has been mined in western Rajasthan in northwestern India for the past 200 years, but mainly for the gemstone grade stones. Abrasive garnet was mainly mined as a secondary product while mining for gem garnets and was used as lapping and polishing media for the glass industries. The host rock of the garnet here is garnetiferous mica schist and the total percentage of garnet is not more than 7% to 10%, which makes the material extremely costly and non-economical to extract for non-gemstone applications.

</doc>
<doc id="37508" url="http://en.wikipedia.org/wiki?curid=37508" title="Magma">
Magma

Magma (from Greek μάγμα, "thick unguent") is a mixture of molten or semi-molten rock, volatiles and solids that is found beneath the surface of the Earth, and is expected to exist on other terrestrial planets. Besides molten rock, magma may also contain suspended crystals, dissolved gas and sometimes gas bubbles. Magma often collects in magma chambers that may feed a volcano or turn into a pluton. Magma is capable of intrusion into adjacent rocks (forming igneous dikes and sills), extrusion onto the surface as lava, and explosive ejection as tephra to form pyroclastic rock.
Magma is a complex high-temperature fluid substance. Temperatures of most magmas are in the range 700 °C to 1300 °C (or 1300 °F to 2400 °F), but very rare carbonatite melts may be as cool as 600 °C, and komatiite melts may have been as hot as 1600 °C. Most are silicate mixtures.
Environments of magma formation and compositions are commonly correlated. Environments include subduction zones, continental rift zones, mid-ocean ridges and hotspots. Despite being found in such widespread locales, the bulk of the Earth's crust and mantle is not molten. Except for the liquid outer core, most of the Earth takes the form of a rheid, a form of solid that can move or deform under pressure. Magma, as liquid, preferentially forms in high temperature, low pressure environments within several kilometers of the Earth's surface.
Magma compositions may evolve after formation by fractional crystallization, contamination, and magma mixing. By definition rock formed of solidified magma is called igneous rock.
While the study of magma has historically relied on observing magma in the form of lava outflows, magma has been encountered in situ three times during geothermal drilling projects—twice in Iceland (see #Magma usage for energy production below), and once in Hawaii.
Source.
Partial melting.
Melting of solid rocks to form magma is controlled by three physical parameters: its temperature, pressure, and composition. Mechanisms are discussed in the entry for igneous rock.
When rocks melt they do so incrementally and gradually; most rocks are made of several minerals, all of which have different melting points, and the physical/chemical relationships controlling melting are complex. As a rock melts, its volume changes. When enough rock is melted, the small globules of melt (generally occurring in between mineral grains) link up and soften the rock. Under pressure within the earth, as little as a fraction of a percent partial melting may be sufficient to cause melt to be squeezed from its source.
Melts can stay in place long enough to melt to 20% or even 35%, but rocks are rarely melted in excess of 50%, because eventually the melted rock mass becomes a crystal and melt mush that can then ascend "en masse" as a diapir, which may then cause further decompression melting.
Geochemical implications of partial melting.
The degree of partial melting is critical for determining what type of magma is produced. The degree of partial melting required to form a melt can be estimated by considering the relative enrichment of incompatible elements versus compatible elements. Incompatible elements commonly include potassium, barium, caesium, rubidium.
Rock types produced by small degrees of partial melting in the Earth's mantle are typically alkaline (Ca, Na), potassic (K) and/or peralkaline (high aluminium to silica ratio). Typically, primitive melts of this composition form lamprophyre, lamproite, kimberlite and sometimes nepheline-bearing mafic rocks such as alkali basalts and essexite gabbros or even carbonatite.
Pegmatite may be produced by low degrees of partial melting of the crust. Some granite-composition magmas are eutectic (or cotectic) melts, and they may be produced by low to high degrees of partial melting of the crust, as well as by fractional crystallization. At high degrees of partial melting of the crust, granitoids such as tonalite, granodiorite and monzonite can be produced, but other mechanisms are typically important in producing them.
Magma usage for energy production.
The Iceland Deep Drilling Project, while drilling several 5000m holes in an attempt to harness the heat in the volcanic bedrock below the surface of Iceland, struck a pocket of magma at 2,100m. Being only the third time in recorded history that magma had been reached, IDDP decided to invest in the hole, naming it IDDP-1. 
A cemented steelcase was constructed in the hole with a perforation at the bottom close to the magma. The high temperatures and pressure of the magma steam were used to generate 36MW of power, making IDDP-1 the world’s first magma-enhanced geothermal system.
Evolution of magmas.
Primary melts.
When a rock melts, the liquid is a "primary melt". Primary melts have not undergone any differentiation and represent the starting composition of a magma. In nature it is rare to find primary melts. The leucosomes of migmatites are examples of primary melts. Primary melts derived from the mantle are especially important, and are known as "primitive melts" or primitive magmas. By finding the primitive magma composition of a magma series it is possible to model the composition of the mantle from which a melt was formed, which is important in understanding evolution of the mantle.
Parental melts.
Where it is impossible to find the primitive or primary magma composition, it is often useful to attempt to identify a parental melt. A parental melt is a magma composition from which the observed range of magma chemistries has been derived by the processes of igneous differentiation. It need not be a primitive melt.
For instance, a series of basalt flows are assumed to be related to one another. A composition from which they could reasonably be produced by fractional crystallization is termed a "parental melt". Fractional crystallization models would be produced to test the hypothesis that they share a common parental melt.
At high degrees of partial melting of the mantle, komatiite and picrite are produced.
Migration.
Magma develops within the mantle or crust when the temperature-pressure conditions favor the molten state. Magma rises toward the Earth's surface when it is less dense than the surrounding rock and when a structural zone allows movement. Magma develops or collects in areas called magma chambers. Magma can remain in a chamber until it cools and crystallizes forming igneous rock, it erupts as a volcano, or moves into another magma chamber.
Cooling of magmas.
There are two known processes by which magma ceases to exist: by volcanic eruption, or by crystallization within the crust or mantle to form a pluton. In both cases the bulk of the magma eventually cools and forms igneous rocks.
When magma cools it begins to form solid mineral phases. Some of these settle at the bottom of the magma chamber forming cumulates that might form mafic layered intrusions. Magma that cools slowly within a magma chamber usually ends up forming bodies of plutonic rocks such as gabbro, diorite and granite, depending upon the composition of the magma. Alternatively, if the magma is erupted it forms volcanic rocks such as basalt, andesite and rhyolite (the extrusive equivalents of gabbro, diorite and granite, respectively).
Volcanism.
During a volcanic eruption the magma that leaves the underground is called lava. Lava cools and solidifies relatively quickly compared to underground bodies of magma. This fast cooling does not allow crystals to grow large, and a part of the melt does not crystallize at all, becoming glass. Rocks largely composed of volcanic glass include obsidian, scoria and pumice.
Before and during volcanic eruptions, volatiles such as CO2 and H2O partially leave the melt through a process known as exsolution. Magma with low water content becomes increasingly viscous. If massive exsolution occurs when magma heads upwards during a volcanic eruption, the resulting eruption is usually explosive.
Composition, melt structure and properties.
Silicate melts are composed mainly of silicon, oxygen, aluminium, alkalis (sodium, potassium, calcium), magnesium and iron. Silicon atoms are in tetrahedral coordination with oxygen, as in almost all silicate minerals, but in melts atomic order is preserved only over short distances. The physical behaviours of melts depend upon their atomic structures as well as upon temperature and pressure and composition.
Viscosity is a key melt property in understanding the behaviour of magmas. More silica-rich melts are typically more polymerized, with more linkage of silica tetrahedra, and so are more viscous. Dissolution of water drastically reduces melt viscosity. Higher-temperature melts are less viscous.
Generally speaking, more mafic magmas, such as those that form basalt, are hotter and less viscous than more silica-rich magmas, such as those that form rhyolite. Low viscosity leads to gentler, less explosive eruptions.
Characteristics of several different magma types are as follows:
Temperature.
At any given pressure and for any given composition of rock, a rise in temperature past the solidus will cause melting. Within the solid earth, the temperature of a rock is controlled by the geothermal gradient and the radioactive decay within the rock. The geothermal gradient averages about 25 °C/km with a wide range from a low of 5–10 °C/km within oceanic trenches and subduction zones to 30–80 °C/km under mid-ocean ridges and volcanic arc environments.
Pressure.
As magma buoyantly rises it will cross the solidus-liquidus and its temperature will reduce by adiabatic cooling. At this point it will liquefy and if erupted onto the surface will form lava. Melting can also occur due to a reduction in pressure by a process known as decompression melting.
Composition.
It is usually very difficult to change the bulk composition of a large mass of rock, so composition is the basic control on whether a rock will melt at any given temperature and pressure. The composition of a rock may also be considered to include "volatile" phases such as water and carbon dioxide.
The presence of volatile phases in a rock under pressure can stabilize a melt fraction. The presence of even 0.8% water may reduce the temperature of melting by as much as 100 °C. Conversely, the loss of water and volatiles from a magma may cause it to essentially freeze or solidify.
Also a major portion of all magma is silica, which is a compound of silicon and oxygen. Magma also contains gases, which expand as the magma rises. Magma that is high in silica resists flowing, so expanding gases are trapped in it. Pressure builds up until the gases blast out in a violent, dangerous explosion. Magma that is relatively poor in silica flows easily, so gas bubbles move up through it and escape fairly gently.

</doc>
<doc id="37510" url="http://en.wikipedia.org/wiki?curid=37510" title="Respiration">
Respiration

Respiration may refer to:

</doc>
<doc id="37512" url="http://en.wikipedia.org/wiki?curid=37512" title="Adjective">
Adjective

In linguistics, an adjective is a describing word, the main syntactic role of which is to qualify a noun or noun phrase, giving more information about the object signified.
Adjectives are one of the English parts of speech, although historically they were classed together with the nouns. Certain words that were traditionally considered to be adjectives, including "the", "this", "my", etc., are today usually classed separately, as determiners.
Etymology.
"Adjective" comes from Latin "(nōmen) adjectīvum" "additional (noun)", a calque of Ancient Greek: ἐπίθετον (ὄνομα) "epítheton (ónoma)" "additional (noun)". In the grammatical tradition of Latin and Greek, because adjectives were inflected for gender, number, and case like nouns (a process called declension), they were considered a subtype of noun. The words that are today typically called nouns were then called "substantive nouns" ("nōmen substantīvum"). The terms "noun substantive" and "noun adjective" were formerly used in English, until the word "noun" came to refer only to the former type, and the second type came to be known simply as adjectives.
Types of use.
A given occurrence of an adjective can generally be classified into one of three kinds of use:
Distribution.
Adjectives feature as a part of speech (word class) in most languages. In some languages, the words that serve the semantic function of adjectives may be categorized together with some other class, such as nouns or verbs. For example, rather than an adjective meaning "big", a language might have a verb that means "to be big", and could then use an attributive verb construction analogous to "big-being house" to express what English expresses as "big house". Such an analysis is possible for the Chinese languages, for example.
Different languages do not always use adjectives in exactly the same situations. For example, where English uses "to be hungry" ("hungry" being an adjective), Dutch and French use "honger hebben" and "avoir faim" respectively (literally "to have hunger", the words for "hunger" being nouns). Similarly, where Hebrew uses the adjective זקוק "zaqūq" (roughly "in need of"), English uses the verb "to need".
In languages which have adjectives as a word class, they are usually an open class; that is, it is relatively common for new adjectives to be formed via such processes as derivation. However, Bantu languages are well known for having only a small closed class of adjectives, and new adjectives are not easily derived. Similarly, native Japanese adjectives ("i"-adjectives) are considered a closed class (as are native verbs), although nouns (an open class) may be used in the genitive to convey some adjectival meanings, and there is also the separate open class of adjectival nouns ("na"-adjectives).
Adjectives and adverbs.
Many languages, including English, distinguish between adjectives, which qualify nouns and pronouns, and adverbs, which mainly modify verbs, adjectives, and other adverbs. Not all languages have exactly this distinction and many languages, including English, have words that can function as both. For example, in English "fast" is an adjective in "a fast car" (where it qualifies the noun "car"), but an adverb in "he drove fast" (where it modifies the verb "drove").
In Dutch and German, adjectives and adverbs are usually identical in form and many grammarians do not make the distinction, but patterns of inflection can suggest a difference:
A German word like "klug" ("clever(ly)") takes endings when used as an attributive adjective, but not when used adverbially. (It also takes no endings when used as a predicative adjective: "er ist klug", "he is clever".) Whether these are distinct parts of speech or distinct usages of the same part of speech is a question of analysis. It is worth noting that while German linguistic terminology distinguishes "adverbiale" from "adjektivische Formen", school German refers to both as "Eigenschaftswörter" ("property words").
Determiners.
Linguists today distinguish determiners from adjectives, considering them to be two separate parts of speech (or "lexical categories"), but formerly determiners were considered to be adjectives in some of their uses. In English dictionaries, which typically still do not treat determiners as their own part of speech, determiners are often recognizable by being listed both as adjectives and as pronouns. Determiners are words that are neither nouns nor pronouns, yet reference a thing already in context. Determiners generally do this by indicating definiteness (as in "a" vs. "the"), quantity (as in "one" vs. "some" vs. "many"), or another such property.
Adjective phrases.
An adjective acts as the head of an "adjective phrase" or "adjectival phrase" (AP). In the simplest case, an adjective phrase consists solely of the adjective; more complex adjective phrases may contain one or more adverbs modifying the adjective (""very" strong"), or one or more complements (such as "worth "several dollars"", "full "of toys"", or "eager "to please""). In English, attributive adjective phrases that include complements typically follow the noun that they qualify ("an evildoer "devoid of redeeming qualities"").
Other modifiers of nouns.
In many languages, including English, it is possible for nouns to modify other nouns. Unlike adjectives, nouns acting as modifiers (called "attributive nouns" or "noun adjuncts") usually are not predicative; a beautiful park is beautiful, but a car park is not "car". The modifier often indicates origin (""Virginia" reel"), purpose (""work" clothes"), or semantic patient (""man" eater"); however, it may generally indicate almost any semantic relationship. It is also common for adjectives to be derived from nouns, as in "boyish", "birdlike", "behavioral (behavioural)", "famous", "manly", "angelic", and so on.
Many languages have special verbal forms called participles that can act as noun modifiers (alone or as the head of a phrase). Sometimes participles develop into pure adjectives. Examples of this in English include "relieved" (the past participle of the verb "relieve", used as an adjective in sentences such as "I am so relieved to see you"), "spoken" (as in "the spoken word"), and "going" (the present participle of the verb "go", used as an adjective in such phrases as "the going rate").
Other constructs that often modify nouns include prepositional phrases (as in "a rebel "without a cause""), relative clauses (as in "the man "who wasn't there""), and infinitive phrases (as in "a cake "to die for""). Some nouns can also take complements such as content clauses (as in "the idea "that I would do that""), but these are not commonly considered modifiers. For more information about possible modifiers and dependents of nouns, see Components of noun phrases.
Adjective order.
In many languages, attributive adjectives usually occur in a specific order. In general, the adjective order in English is:
This means that in English, adjectives pertaining to size precede adjectives pertaining to age ("little old", not "old little"), which in turn generally precede adjectives pertaining to color ("old white", not "white old"). So, we would say "One (quantity) nice (opinion) little (size) round (shape) old (age) white (color) brick (material) house."
This order may be more rigid in some languages than others; in some, like Spanish, it may only be a default ("unmarked") word order, with other orders being permissible.
Due partially to borrowings from French, English has some adjectives that follow the noun as postmodifiers, called postpositive adjectives, as in "time immemorial" and "attorney general". Adjectives may even change meaning depending on whether they precede or follow, as in "proper": "They live in a proper town" (a real town, not a village) vs. "They live in the town proper" (in the town itself, not in the suburbs). All adjectives can follow nouns in certain constructions, such as "tell me something new".
Comparison of adjectives.
In many languages, some adjectives are "comparable". For example, a person may be "polite", but another person may be "more polite", and a third person may be the "most polite" of the three. The word "more" here modifies the adjective "polite" to indicate a comparison is being made, and "most" modifies the adjective to indicate an absolute comparison (a "superlative").
Among languages that allow adjectives to be compared, different means are used to indicate the comparison. Many languages do not distinguish comparative from superlative forms.
In English, there are three different means to indicate comparison: most simple adjectives take the suffixes "-er" and "-est", as
a very few adjectives are "irregular":
all others are compared by means of the words "more" and "most". There is no simple rule to decide which means is correct for any given adjective, however. The general tendency is for simpler adjectives, and those from Anglo-Saxon to take the suffixes, while longer adjectives and those from French, Latin, Greek do not—but sometimes "sound" of the word is the deciding factor.
Many adjectives do not naturally lend themselves to comparison. For example, some English speakers would argue that it does not make sense to say that one thing is "more ultimate" than another, or that something is "most ultimate", since the word "ultimate" is already absolute in its semantics. Such adjectives are called "non-comparable" or "absolute". Nevertheless, native speakers will frequently play with the raised forms of adjectives of this sort. Although "pregnant" is logically non-comparable (either one is pregnant or not), one may hear a sentence like "She looks more and more pregnant each day". Likewise "extinct" and "equal" appear to be non-comparable, but one might say that a language about which nothing is known is "more extinct" than a well-documented language with surviving literature but no speakers, while George Orwell wrote "All animals are equal, but some are more equal than others". These cases may be viewed as evidence that the base forms of these adjectives are not as absolute in their semantics as is usually thought.
Comparative and superlative forms are also occasionally used for other purposes than comparison. In English comparatives can be used to suggest that a statement is only tentative or tendential: one might say "John is more the shy-and-retiring type," where the comparative "more" is not really comparing him with other people or with other impressions of him, but rather, could be substituting for "on the whole". In Italian, superlatives are frequently used to put strong emphasis on an adjective: "Bellissimo" means "most beautiful", but is in fact more commonly heard in the sense "extremely beautiful".
Restrictiveness.
Attributive adjectives, and other noun modifiers, may be used either "restrictively" (helping to identify the noun's referent, hence "restricting" its reference) or "non-restrictively" (helping to describe an already-identified noun). For example:
In some languages, such as Spanish, restrictiveness is consistently marked; for example, in Spanish "la tarea difícil" means "the difficult task" in the sense of "the task that is difficult" (restrictive), whereas "la difícil tarea" means "the difficult task" in the sense of "the task, which is difficult" (non-restrictive). In English, restrictiveness is not marked on adjectives, but is marked on relative clauses (the difference between "the man "who recognized me" was there" and "the man, "who recognized me", was there" being one of restrictiveness).
Agreement.
In some languages, adjectives alter their form to reflect the gender, case and number of the noun that they describe. This is called agreement or concord. Usually it takes the form of inflections at the end of the word, as in Latin:
In the Celtic languages, however, initial consonant lenition marks the adjective with a feminine noun, as in Irish:
Often a distinction is made here between attributive and predicative usage. Whereas English is an example of a language in which adjectives never agree and French of a language in which they always agree, in German they agree only when used attributively, and in Hungarian only when used predicatively.

</doc>
<doc id="37513" url="http://en.wikipedia.org/wiki?curid=37513" title="Adverb">
Adverb

An adverb is a word that modifies a verb, adjective, other adverb, determiner, noun phrase, clause, or sentence. Adverbs typically express manner, place, time, frequency, degree, level of certainty, etc., answering questions such as "how?", "in what way?", "when?", "where?", and "to what extent?". This function is called the adverbial function, and may be realised by single words (adverbs) or by multi-word expressions (adverbial phrases and adverbial clauses).
Adverbs are traditionally regarded as one of the parts of speech. However, modern linguists note that it has come to be used as a kind of "catch-all" category, used to classify words with various different types of syntactic behavior, not necessarily having much in common except that they do not fit into any of the other available categories (noun, adjective, preposition, etc.)
Functions.
The English word "adverb" derives (through French) from Latin "adverbium", from "ad-" ("to"), "verbum" ("word", "verb"), and the nominal suffix "-ium". The term implies that the principal function of adverbs is to act as modifiers of verbs or verb phrases. An adverb used in this way may provide information about the manner, place, time, frequency, certainty, or other circumstances of the activity denoted by the verb or verb phrase. Some examples:
Adverbs can also be used as modifiers of adjectives, and of other adverbs, often to indicate degree. Examples:
They can also modify noun phrases, prepositional phrases, or whole clauses or sentences, as in the following examples:
Adverbs are thus seen to perform a wide range of modifying functions. The major exception is the function of modifier of nouns, which is performed instead by adjectives (compare "she sang loudly" with "her loud singing disturbed me"; here the verb "sang" is modified by the adverb "loudly", whereas the noun "singing" is modified by the adjective "loud"). However, as seen above, adverbs may modify noun "phrases", and so the two functions may sometimes be superficially very similar:
The word "even" in the first sentence is an adverb, since it is an "external" modifier, modifying "camels" as a noun phrase (compare "even these camels ..."), whereas the word "even" in the second sentence is an adjective, since it is an "internal" modifier, modifying "numbers" as a noun (compare "these even numbers ..."). It is nonetheless possible for certain adverbs to modify a noun; in English the adverb follows the noun in such cases, as in:
Adverbs can sometimes be used as predicative expressions; in English this applies especially to adverbs of location:
When the function of an adverb is performed by an expression consisting of more than one word, it is called an adverbial phrase or adverbial clause, or simply an adverbial.
Formation and comparison.
In English, adverbs of manner (answering the question "how?") are often formed by adding "-ly" to adjectives. Other languages often have similar methods for deriving adverbs from adjectives (French, for example, uses the suffix "-ment"), or else use the same form for both adjectives and adverbs. Many other adverbs, however, are not related to adjectives in this way; they may be derived from other words or phrases, or may be single morphemes. Examples of such adverbs in English include "here, there, together, yesterday, aboard, very, almost", etc.
Where the meaning permits, adverbs may undergo comparison, taking comparative and superlative forms. In English this is usually done by adding "more" and "most" before the adverb ("more slowly, most slowly"), although there are a few adverbs that take inflected forms, such as "well", for which "better" and "best" are used.
For more information about the formation and use of adverbs in English, see English grammar: Adverbs. For other languages, see In specific languages below, and the articles on individual languages and their grammars.
Adverbs as a "catch-all" category.
Adverbs are considered a part of speech in traditional English grammar, and are still included as a part of speech in grammar taught in schools and used in dictionaries. However, modern grammarians recognize that words traditionally grouped together as adverbs serve a number of different functions. Some describe adverbs a "catch-all" category that includes all words that do not belong to one of the other parts of speech.
A logical approach to dividing words into classes relies on recognizing which words can be used in a certain context. For example, the only type of word that can be inserted in the following template to form a grammatical sentence is a noun:
When this approach is taken, it is seen that adverbs fall into a number of different categories. For example, some adverbs can be used to modify an entire sentence, whereas others cannot. Even when a sentential adverb has other functions, the meaning is often not the same. For example, in the sentences "She gave birth naturally" and "Naturally, she gave birth", the word "naturally" has different meanings: as a sentential adverb it means something like "of course", while as a verb-modifying adverb it means "in a natural manner".
Words like "very" afford another example. We can say "Perry is very fast", but not "Perry very won the race". These words can modify adjectives but not verbs. On the other hand, there are words like "here" and "there" that cannot modify adjectives. We can say "The sock looks good there" but not "It is a there beautiful sock". The fact that many adverbs can be used in more than one of these functions can confuse the issue, and it may seem like splitting hairs to say that a single adverb is really two or more words that serve different functions. However, this distinction can be useful, especially when considering adverbs like "naturally" that have different meanings in their different functions. Rodney Huddleston distinguishes between a "word" and a "lexicogrammatical-word".
Grammarians find difficulty categorizing negating words, such as the English "not". Although traditionally listed as an adverb, this word does not behave grammatically like any other, and it probably belongs in a class on its own.
In specific languages.
Listed below are some of the principles for formation and use of adverbs in certain languages. For more information, see the articles on individual languages and their grammars.

</doc>
<doc id="37514" url="http://en.wikipedia.org/wiki?curid=37514" title="Depleted uranium">
Depleted uranium

Depleted uranium (DU; also referred to in the past as Q-metal, depletalloy or D-38) is uranium with a lower content of the fissile isotope U-235 than natural uranium. (Natural uranium is about 0.72% U-235—the fissile isotope, and the DU used by the U.S. Department of Defense contain less than 0.3% U-235). Uses of DU take advantage of its very high density of 19.1 g/cm3 (68.4% denser than lead). Civilian uses include counterweights in aircraft, radiation shielding in medical radiation therapy and industrial radiography equipment and containers used to transport radioactive materials. Military uses include defensive armor plating and armor-piercing projectiles.
Most depleted uranium arises as a byproduct of the production of enriched uranium for use in nuclear reactors and in the manufacture of nuclear weapons. Enrichment processes generate uranium with a higher-than-natural concentration of lower-mass uranium isotopes (in particular U-235, which is the uranium isotope supporting the fission chain reaction) with the bulk of the feed ending up as depleted uranium, in some cases with mass fractions of U-235 and U-234 less than a third of those in natural uranium. U-238 has a much longer halflife than the lighter isotopes, and DU therefore emits less alpha radiation than the same mass of natural uranium. DU from nuclear reprocessing will have different isotopic ratios from enrichment-byproduct DU, and can be distinguished from it by the presence of U-236.
DU used in US munitions has 60% of the radioactivity of natural uranium. Trace transuranics (another indicator of the use of reprocessed material) have been reported to be present in some US tank armor.
The use of DU in munitions is controversial because of questions about potential long-term health effects. Normal functioning of the kidney, brain, liver, heart, and numerous other systems can be affected by uranium exposure, because uranium is a toxic metal. It is only weakly radioactive because of its long radioactive half-life (4.468 billion years for uranium-238, 700 million years for uranium-235; or 1 part per million every and years, respectively). The biological half-life (the average time it takes for the human body to eliminate half the amount in the body) for uranium is about 15 days. The aerosol or spallation frangible powder produced during impact and combustion of depleted uranium munitions can potentially contaminate wide areas around the impact sites, leading to possible inhalation by human beings.
The actual level of acute and chronic toxicity of DU is also controversial. Several studies using cultured cells and laboratory rodents suggest the possibility of leukemogenic, and of genetic, reproductive, and neurological effects from chronic exposure.
A 2005 epidemiology review concluded: "In aggregate the human epidemiological evidence is consistent with increased risk of birth defects in offspring of persons exposed to DU."
History.
Enriched uranium was first manufactured in the early 1940s when the United States and Britain began their nuclear weapons programs. Later in the decade, France and the Soviet Union began their nuclear weapons and nuclear power programs. It was at this time that depleted uranium was first stored as an unusable waste product (uranium hexafluoride). There was some hope that the enrichment process would be improved and fissionable isotopes of U-235 could, at some future date, be extracted from the depleted uranium. This re-enrichment recovery of the residual uranium-235 contained in the depleted uranium is no longer a matter of the future: it has been practiced for several years. Also, it is possible to design civilian power-generating reactors using unenriched fuel, but only about 10% of those ever built (such as the CANDU reactor) utilize that technology. Both nuclear weapons production and naval reactors require fuel containing concentrated U-235.
In the 1970s, the Pentagon reported that the Soviet military had developed armor plating for Warsaw Pact tanks that NATO ammunition could not penetrate. The Pentagon began searching for material to make denser armor-piercing projectiles. After testing various metals, ordnance researchers settled on depleted uranium.
The US and NATO militaries used DU penetrator rounds in the 1991 Gulf War, the Bosnia war, bombing of Serbia, and the 2003 invasion of Iraq.
While clearing a decades-old Hawaii firing range in 2005, workers found depleted uranium fins from training rounds from the formerly classified Davy Crockett recoilless gun tactical battlefield nuclear delivery system from the 1960s and 1970s. These training rounds had been forgotten because they were used in a highly classified program and had been fired before DU had become an item of interest, more than 20 years before the Gulf War.
Production and availability.
Natural uranium metal contains about 0.71% U-235, 99.28% U-238, and about 0.0054% U-234. In order to produce enriched uranium, the process of isotope separation removes a substantial portion of the U-235 for use in nuclear power, weapons, or other uses. The remainder, "depleted uranium", contains only 0.2% to 0.4% U-235. Because natural uranium begins with such a low percentage of U-235, enrichment produces large quantities of depleted uranium. For example, producing 1 kg of 5% enriched uranium requires 11.8 kg of natural uranium, and leaves about 10.8 kg of depleted uranium with only 0.3% U-235 remaining.
The Nuclear Regulatory Commission (NRC) defines "depleted uranium" as uranium with a percentage of the 235U isotope that is less than 0.711% by weight (see ). The military specifications designate that the DU used by the U.S. Department of Defense (DoD) contain less than 0.3% 235U (AEPI, 1995). In actuality, DoD uses only DU that contains approximately 0.2% 235U (AEPI, 1995).
Depleted Uranium is also produced by recycling 'spent' nuclear fuel, in which case it contains traces of Pu and Np and has therefore been called 'dirty DU' although the quantities are so small that they are considered to be not of serious radiological significance (even) by ECRR.
Uranium hexafluoride.
Some depleted uranium produced is stored as uranium hexafluoride, a crystalline solid, (D)UF6, in steel cylinders in open air storage yards close to enrichment plants. Each cylinder holds up to 12.7 tonnes (or 14 short tons) of UF6. In the U.S. 560,000 tonnes of depleted UF6 had accumulated by 1993. In 2008, 686,500 tonnes in 57,122 storage cylinders were located near Portsmouth, Ohio, Oak Ridge, Tennessee, and Paducah, Kentucky.
The storage of DUF6 presents environmental, health, and safety risks because of its chemical instability. When UF6 is exposed to water vapor in the air, it reacts with the moisture to produce UO2F2 (uranyl fluoride), a solid, and HF (hydrogen fluoride), a gas, both of which are highly soluble and toxic. The uranyl fluoride solid acts to plug the leak, limiting further escape of depleted UF6. Release of the hydrogen fluoride gas to the atmosphere is also slowed by the plug formation. Storage cylinders are regularly inspected for signs of corrosion and leaks, and are repainted and repaired as necessary.
A tenfold jump in uranium prices has transformed approximately one-third of the U.S. depleted uranium inventory into an asset worth $7.6 billion, assuming DOE re-enriches the tails. This estimate is based on February 2008 market price for uranium and enrichment services, and DOE's access to sufficient uranium enrichment capacity.
There have been several accidents involving uranium hexafluoride in the United States, including one in which 32 workers were exposed to a cloud of UF6 and its reaction products. 1 person died, and while a few workers with higher exposure experienced short-term kidney damage (e.g., protein in the urine), none of them showed lasting damage from the exposure to uranium. The U.S. government has been converting DUF6 to solid uranium oxides for use or disposal. Such disposal of the entire DUF6 inventory could cost anywhere from $15 million to $450 million.
Military applications.
Depleted uranium is very dense; at 19,050 kg/m³, it is 1.67 times as dense as lead, only slightly less dense than tungsten and gold, and 84% as dense as osmium or iridium, which are the densest known substances under standard (i.e., Earth-surface) pressures. Consequently a DU projectile of given mass has a smaller diameter than an equivalent lead projectile, with less aerodynamic drag and deeper penetration due to a higher pressure at point of impact. DU projectile ordnance is often inherently incendiary because uranium is flammable.
Armor plate.
Because of its high density, depleted uranium can also be used in tank armor, sandwiched between sheets of steel armor plate. For instance, some late-production M1A1HA and M1A2 Abrams tanks built after 1998 have DU reinforcement as part of the armor plating in the front of the hull and the front of the turret, and there is a program to upgrade the rest (see Chobham armor).
Nuclear weapons.
Depleted uranium is used as a tamper in fission bombs.
Ammunition.
Most military use of depleted uranium has been as 30 mm caliber ordnance, primarily the 30 mm PGU-14/B armour-piercing incendiary round from the GAU-8 Avenger cannon of the A-10 Thunderbolt II used by the United States Air Force. 25 mm DU rounds have been used in the M242 gun mounted on the U.S. Army's Bradley Fighting Vehicle and the Marine Corps's LAV-25.
The U.S. Marine Corps uses DU in the 25 mm PGU-20 round fired by the GAU-12 Equalizer cannon of the AV-8B Harrier, and also in the 20 mm M197 gun mounted on AH-1 Cobra helicopter gunships. The United States Navy's Phalanx CIWS's M61 Vulcan Gatling gun used 20 mm armor-piercing penetrator rounds with discarding plastic sabots made using depleted uranium, later changed to tungsten.
Another use of depleted uranium is in kinetic energy penetrators, anti-armor rounds such as the 120 mm sabot rounds fired from the British Challenger 1, Challenger 2, M1A1 and M1A2 Abrams. Kinetic energy penetrator rounds consist of a long, relatively thin penetrator surrounded by a discarding sabot. Staballoys are metal alloys of depleted uranium with a very small proportion of other metals, usually titanium or molybdenum. One formulation has a composition of 99.25% by mass of depleted uranium and 0.75% by mass of titanium. Staballoys are approximately 1.67 times as dense as lead and are designed for use in kinetic energy penetrator armor-piercing ammunition. The US Army uses DU in an alloy with around 3.5% titanium.
According to 2005 research, at least some of the most promising tungsten alloys that have been considered as replacement for depleted uranium in penetrator ammunitions, such as tungsten-cobalt or tungsten-nickel-cobalt alloys, also possess extreme carcinogenic properties, which by far exceed those (confirmed or suspected) of depleted uranium itself: 100% of rats implanted with a pellet of such alloys developed lethal rhabdomyosarcoma within a few weeks.
Depleted uranium is favored for the penetrator because it is self-sharpening and flammable. On impact with a hard target, such as an armored vehicle, the nose of the rod fractures in such a way that it remains sharp. The impact and subsequent release of heat energy causes it to ignite. When a DU penetrator reaches the interior of an armored vehicle it catches fire, often igniting ammunition and fuel, killing the crew and possibly causing the vehicle to explode. DU is used by the U.S. Army in 120 mm or 105 mm cannons employed on the M1 Abrams tank. The Russian military has used DU ammunition in tank main gun ammunition since the late 1970s, mostly for the 115 mm guns in the T-62 tank and the 125 mm guns in the T-64, T-72, T-80, and T-90 tanks.
The DU content in various ammunition is 180 g in 20 mm projectiles, 200 g in 25 mm ones, 280 g in 30 mm, 3.5 kg in 105 mm, and 4.5 kg in 120 mm penetrators. DU was used during the mid-1990s in the U.S. to make hand grenades, cluster bombs, and land mines, but those applications have been discontinued, according to Alliant Techsystems. The US Navy used DU in its 20 mm Phalanx CIWS guns, but switched in the late 1990s to armor-piercing tungsten.
It is thought that between 17 and 20 countries have weapons incorporating depleted uranium in their arsenals. They include the U.S., the UK, France, Russia, China, India, Turkey, Saudi Arabia, Israel, Bahrain, Egypt, Kuwait, Pakistan, Thailand, Iraq and Taiwan. Iran also has performed wide research on DU penetrators since 2001. DU ammunition is manufactured in 18 countries. Only the US and the UK have acknowledged using DU weapons.
In a three-week period of conflict in Iraq during 2003 it was estimated that over 1000 tons of depleted uranium munitions were used.
Legal status in weapons.
In 1996 the International Court of Justice (ICJ) gave an advisory opinion on the "legality of the threat or use of nuclear weapons". This made it clear, in paragraphs 54, 55 and 56, that international law on poisonous weapons—the Second Hague Declaration of 29 July 1899, Hague Convention IV of 18 October 1907 and the Geneva Protocol of 17 June 1925—did not cover nuclear weapons, because their prime or exclusive use was not to poison or asphyxiate. This ICJ opinion was about nuclear weapons, but the sentence "The terms have been understood, in the practice of States, in their ordinary sense as covering weapons whose prime, or even exclusive, effect is to poison or asphyxiate," also removes depleted uranium weaponry from coverage by the same treaties as their primary use is not to poison or asphyxiate, but to destroy materiel and kill soldiers through kinetic energy.
The Sub-Commission on Prevention of Discrimination and Protection of Minorities of the United Nations Human Rights Commission, passed two motions — the first in 1996 and the second in 1997. They listed weapons of mass destruction, or weapons with indiscriminate effect, or of a nature to cause superfluous injury or unnecessary suffering and urged all states to curb the production and the spread of such weapons. Included in the list was weaponry containing depleted uranium. The committee authorized a working paper, in the context of human rights and humanitarian norms, of the weapons.
The requested UN working paper was delivered in 2002 by Y. K. J. Yeung Sik Yuen in accordance with Sub-Commission on the Promotion and Protection of Human Rights resolution 2001/36. He argues that the use of DU in weapons, along with the other weapons listed by the Sub‑Commission, may breach one or more of the following treaties: the Universal Declaration of Human Rights, the Charter of the United Nations, the Genocide Convention, the United Nations Convention Against Torture, the Geneva Conventions including Protocol I, the Convention on Conventional Weapons of 1980, and the Chemical Weapons Convention. Yeung Sik Yuen writes in Paragraph 133 under the title "Legal compliance of weapons containing DU as a new weapon":
 Annex II to the Convention on the Physical Protection of Nuclear Material 1980 (which became operative on 8 February 1997) classifies DU as a category II nuclear material. Storage and transport rules are set down for that category which indicates that DU is considered sufficiently "hot" and dangerous to warrant these protections. But since weapons containing DU are relatively new weapons no treaty exists yet to regulate, limit or prohibit its use. The legality or illegality of DU weapons must therefore be tested by recourse to the general rules governing the use of weapons under humanitarian and human rights law which have already been analysed in Part I of this paper, and more particularly at paragraph 35 which states that parties to Protocol I to the Geneva Conventions of 1949 have an obligation to ascertain that new weapons do not violate the laws and customs of war or any other international law. As mentioned, the International Court of Justice considers this rule binding customary humanitarian law.
Louise Arbour, chief prosecutor for the International Criminal Tribunal for the Former Yugoslavia led a committee of staff lawyers to investigate possible treaty prohibitions against the use of DU in weapons. Their findings were that:
 There is no specific treaty ban on the use of DU projectiles. There is a developing scientific debate and concern expressed regarding the impact of the use of such projectiles and it is possible that, in future, there will be a consensus view in international legal circles that use of such projectiles violate general principles of the law applicable to use of weapons in armed conflict. No such consensus exists at present.
Requests for a moratorium on military use.
Some states and the International Coalition to Ban Uranium Weapons, a coalition of more than 155 non-governmental organizations, have asked for a ban on the production and military use of depleted uranium weapons.
The European Parliament has repeatedly passed resolutions requesting an immediate moratorium on the further use of depleted uranium ammunition, but France and Britain – the only EU states that are permanent members of the United Nations Security Council – have consistently rejected calls for a ban, maintaining that its use continues to be legal, and that the health risks are unsubstantiated.
In 2007 France, Britain, the Netherlands, and the Czech Republic voted against a United Nations General Assembly resolution to hold a debate in 2009 about the effects of the use of armaments and ammunitions containing depleted uranium. All other European Union nations voted in favour or abstained. The ambassador from the Netherlands explained his negative vote as being due to the reference in the preamble to the resolution "to potential harmful effects of the use of depleted uranium munitions on human health and the environment [which] cannot, in our view, be supported by conclusive scientific studies conducted by relevant international organizations." None of the other permanent members of the United Nations Security Council supported the resolution as China was absent for the vote, Russia abstained and the United States voted against the resolution.
In September 2008, and in response to the 2007 General Assembly resolution, the UN Secretary General published the views of 15 states alongside those of the International Atomic Energy Agency (IAEA) and World Health Organization (WHO). The IAEA and WHO evidence differed little from previous statements on the issue. The report was largely split between states concerned about depleted uranium's use, such as Finland, Cuba, Japan, Serbia, Argentina, and predominantly NATO members, who do not consider the use of depleted uranium munitions problematic.
In December 2008, 141 states supported a resolution requesting that three UN agencies: United Nations Environment Programme (UNEP), WHO and IAEA update their research on the impact of uranium munitions by late 2010 – to coincide with the General Assembly's 65th Session, four voted against, 34 abstained and 13 were absent As before Britain and France voted against the resolution. All other European Union nations voted in favour or abstained: the Netherlands, which voted against a resolution in 2007, voted in favour, as did Finland and Norway, both of which had abstained in 2007, while the Czech Republic, which voted against the resolution in 2007, abstained. The two other states that voted against the resolution were Israel and the United States (both of which voted against in 2007), while as before China was absent for the vote, and Russia abstained.
On June 21, 2009, Belgium became the first country in the world to ban: "inert ammunition and armour that contains depleted uranium or any other industrially manufactured uranium." The move followed a unanimous parliamentary vote on the issue on 22 March 2007. The text of the 2007 law allowed for two years to pass until it came into force. In April 2009, the Belgian Senate voted unanimously to restrict investments by Belgian banks into the manufacturers of depleted uranium weapons.
In September 2009 the Latin American Parliament passed a resolution calling for a regional moratorium on the use, production and procurement of uranium weapons. It also called on the Parlatino's members to work towards an international uranium weapons treaty.
In April 2011 the Congress of Costa Rica passed a law prohibiting uranium weapons in its territories, becoming the second country in the world to do so. In November 2010 the Irish Senate passed a bill seeking to outlaw depleted uranium weapons, but it lapsed before approval by the Dáil
Civilian applications.
Depleted uranium has a very high density and is primarily used as shielding material for other radioactive material, and as ballast. Examples include sailboat keels, as counterweights and as shielding in industrial radiography cameras.
Shielding in industrial radiography cameras.
Industrial radiography cameras include a very high activity gamma radiation source (typically Ir-192 with an activity above 10 TBq). Depleted uranium is often used in the cameras as a shield to protect individuals from the gamma source. Typically the uranium shield is supported and enclosed in polyurethane foam for thermal, mechanical and oxidation protection.
Coloring in consumer products.
Consumer product uses have included incorporation into dental porcelain, used for false teeth to simulate the fluorescence of natural teeth, and uranium-bearing reagents used in chemistry laboratories (e.g. uranyl acetate, used in analytical chemistry and as a stain in electron microscopy). Uranium (both depleted uranium and natural uranium) was widely used as a coloring matter for porcelain and glass in the 19th and early-to-mid-20th century. The practice was largely discontinued in the late 20th century. In 1999 concentrations of 10% depleted uranium were being used in "jaune no.17" a yellow enamel powder that was being produced in France by Cristallerie de Saint-Paul, a manufacturer of enamel pigments. The depleted uranium used in the powder was sold by Cogéma's Pierrelatte facility. In February 2000, Cogema discontinued the sale of depleted uranium to producers of enamel and glass.
Trim weights in aircraft.
Aircraft that contain depleted uranium trim weights for stabilizing wings and control surfaces (such as the Boeing 747–100) may contain between 400 to 1,500 kg of DU. This application is controversial because the DU might enter the environment if the aircraft were to crash. The metal can also oxidize to a fine powder in a fire. Its use has been phased out in many newer aircraft. Boeing and McDonnell-Douglas discontinued using DU counterweights in the 1980s. Depleted uranium was released during the crash of El Al Flight 1862 on 4 October 1992, in which 152 kg was lost, but a case study concluded that there was no evidence to link depleted uranium from the plane to any health problems.() Counterweights manufactured with cadmium plating are considered non-hazardous while the plating is intact.
U.S. NRC general license.
U.S. Nuclear Regulatory Commission regulations at establish a general license for the use of depleted uranium contained in industrial products or devices for mass-volume applications. This general license allows anyone to possess or use depleted uranium for authorized purposes. Generally, a registration form is required, along with a commitment to not abandon the material. Agreement states may have similar, or more stringent, regulations.
Sailboat keel.
"Pen Duick VI", a boat designed by André Mauric and used for racing, was equipped with a keel in depleted uranium. The benefit is that, due to the very high density of uranium, the keel could be thinner for a given weight, and so have less resistance than a normal keel. It was later replaced by a standard lead keel.
Sampling Calorimeters for detectors in high-energy particle physics.
Depleted uranium has been used in a number of sampling calorimeters (such as in the D0 and ZEUS detectors) in due to its high density and natural radioactivity.
Health considerations.
Normal functioning of the kidney, brain, liver, heart, and numerous other systems can be affected by uranium exposure because, in addition to being weakly radioactive, uranium is a toxic metal, although less toxic than other heavy metals such as arsenic and mercury. It is weakly radioactive but is 'persistently' so because of its long half-life. The Agency for Toxic Substances and Disease Registry states that: "to be exposed to radiation from uranium, you have to eat, drink, or breathe it, or get it on your skin." If DU particles do enter an individual, the type of danger presented—toxic vs. radiological—and the organ most likely to be affected depend on the solubility of the particles.
In military conflicts involving DU munitions, the major concern is inhalation of DU particles in aerosols arising from the impacts of DU-enhanced projectiles with their targets. When depleted uranium munitions penetrate armor or burn, they create depleted uranium oxides in the form of dust that can be inhaled or contaminate wounds. The Institute of Nuclear Technology-Radiation Protection of Attiki, Greece, has noted that "the aerosol produced during impact and combustion of depleted uranium munitions can potentially contaminate wide areas around the impact sites or can be inhaled by civilians and military personnel." The utilisation of DU in incendiary ammunition is controversial because of potential adverse health effects and its release into the environment.
The U.S. Department of Defense claims that no human cancer of any type has been seen as a result of exposure to either natural or depleted uranium. Militaries have long had risk-reduction procedures for their troops to follow, and studies are in consistent agreement that veterans who used DU-enhanced munitions have not suffered, so far, from an increased risk of cancer (see the Gulf War and Balkans sections below). The effects of DU on civilian populations are, however, a topic of intense and ongoing controversy.
As early as 1997, British Army doctors warned the British MoD (Ministry of Defence) that exposure to depleted uranium increased the risk of developing lung, lymph and brain cancer, and recommended a series of safety precautions. According to a report issued summarizing the advice of the doctors, "Inhalation of insoluble uranium dioxide dust will lead to accumulation in the lungs with very slow clearance—if any. … Although chemical toxicity is low, there may be localised radiation damage of the lung leading to cancer." The report warns that "All personnel … should be aware that uranium dust inhalation carries a long-term risk … [the dust] has been shown to increase the risks of developing lung, lymph and brain cancers." In 2003, the Royal Society called, again, for urgent attention to be paid to the possible health and environmental impact of depleted uranium, and added its backing to the United Nations Environment Programme's call for a scientific assessment of sites struck with depleted uranium. In early 2004, the UK Pensions Appeal Tribunal Service attributed birth defect claims from a February 1991 Gulf War combat veteran to depleted uranium poisoning. Also, a 2005 epidemiology review concluded: "In aggregate the human epidemiological evidence is consistent with increased risk of birth defects in offspring of persons exposed to DU." Studies using cultured cells and laboratory rodents continue to suggest the possibility of leukemogenic, genetic, reproductive, and neurological effects from chronic exposure.
Chemical toxicity.
The chemical toxicity of depleted uranium is about a million times greater "in vitro" than its radiological hazard, with the kidney considered to be the main target organ. Health effects of DU are determined by factors such as the extent of exposure and whether it was internal or external. Three main pathways exist by which internalization of uranium may occur: inhalation, ingestion, and embedded fragments or shrapnel contamination. Properties such as phase (e.g. particulate or gaseous), oxidation state (e.g. metallic or ceramic), and the solubility of uranium and its compounds influence their absorption, distribution, translocation, elimination and the resulting toxicity. For example, metallic uranium is less toxic compared to hexavalent uranium(VI) uranyl compounds such as uranium trioxide.
Uranium is pyrophoric when finely divided. It will corrode under the influence of air and water producing insoluble uranium(IV) and soluble uranium (VI) salts. Soluble uranium salts are toxic. Uranium slowly accumulates in several organs, such as the liver, spleen, and kidneys. The World Health Organization has established a daily "tolerated intake" of soluble uranium salts for the general public of 0.5 µg/kg body weight, or 35 µg for a 70 kg adult.
Epidemiological studies and toxicological tests on laboratory animals point to it as being immunotoxic, teratogenic, neurotoxic, with carcinogenic and leukemogenic potential. A 2005 report by epidemiologists concluded: "the human epidemiological evidence is consistent with increased risk of birth defects in offspring of persons exposed to DU."
Early studies of depleted uranium aerosol exposure assumed that uranium combustion product particles would quickly settle out of the air and thus could not affect populations more than a few kilometers from target areas, and that such particles, if inhaled, would remain undissolved in the lung for a great length of time and thus could be detected in urine. Violently burning uranium droplets produce a gaseous vapor comprising about half of the uranium in their original mass. Uranyl ion contamination in uranium oxides has been detected in the residue of DU munitions fires.
Approximately 90 micrograms of natural uranium, on average, exist in the human body as a result of normal intake of water, food and air. Most is in the skeleton. The biochemistry of depleted uranium is the same as natural uranium.
Radiological hazards.
The primary radiation danger from pure depleted uranium is due to alpha particles, which do not travel far through air, and do not penetrate clothing. However, in a matter of a month or so, a sample of pure depleted uranium will generate small amounts of thorium-234 and protactinium-234, which emit the more penetrating beta particles at almost the same rate as the uranium emits alpha rays. This is because uranium-238 decays directly to thorium-234, which with a half-life of 24 days decays to protactinium-234, which in turn decays in a matter of hours to the long-lived uranium-234. A quasi-steady state is therefore reached within a few multiples of 24 days.
Available evidence suggests that the radiation risk is small relative to the chemical hazard.
Surveying the veteran-related evidence pertaining to the Gulf War, a 2001 editorial in the "BMJ" concluded it was not possible to justify claims of radiation-induced lung cancer and leukaemia in veterans of that conflict. While agreeing with the editorial's conclusion, a reply noted that its finding in the negative was guaranteed, given that "global dose estimates or results of mathematical modelling are too inaccurate to be used as dose values for an individual veteran", and that, as of April 2001, no practical method of measuring the expected small doses that each individual veteran would receive had been suggested. The author of the reply, a radiation scientist, went on to suggest a method that had been used several times before, including after the 1986 Chernobyl accident. Despite the widespread use of DU in the Iraq War, at least a year after the conflict began, testing for UK troops was still only in the discussion phase.
The Royal Society DU Working Group concluded in 2002 that there were "very low" health risks associated with the use of depleted uranium, though also ventured that, "[i]n extreme conditions and under worst-case assumptions" lung and kidney damage could occur, and that in "worst-case scenarios high local levels of uranium could occur in food or water that could have adverse effects on the kidney." In 2003, the Royal Society issued another urgent call to investigate the actual health and environmental impact of depleted uranium. The same year, a cohort study of Gulf War veterans found no elevated risks of cancer generally, nor of any specific cancers in particular, though recommended follow up studies.
According to the World Health Organization, a radiation dose from it would be about 60% of that from purified natural uranium with the same mass; the radiological dangers are lower due to its longer half-life and the removal of the more radioactive isotopes.
Gulf War syndrome and soldier complaints.
Since 1991, the year the Gulf War ended, veterans and their families voiced concern about subsequent health problems. In 1999, assessment of the first 1,000 veterans involved in the Ministry of Defence's Gulf War medical assessment programme found "no evidence" of a single illness, physical or mental, that would explain the pattern of symptoms observed in the group. Nevertheless, in 1999, MEDACT petitioned for the WHO to conduct an investigation into illnesses in veterans and Iraqi civilians. A major 2006 review of peer-reviewed literature by a US Institute of Medicine committee concluded that, "[b]ecause the symptoms vary greatly among individuals," they do not point to a syndrome unique to Gulf War veterans, though their report conceded that the lack of objective pre-deployment health data meant definitive conclusions were effectively impossible. Simon Wessely praised the IOM's review, and noted that despite its central conclusion that no novel syndrome existed, its other findings made it "equally clear that service in the Gulf war did aversely affect health in some personnel." Aside from the lack of baseline data to guide analysis of the veterans' postwar health, because no detailed health screening was carried out when the veterans entered service, another major stumbling block with some studies, like the thousand-veteran one, is that the subjects are self-selected, rather than a random sample, making general conclusions impossible.
Increased rates of immune system disorders and other wide-ranging symptoms, including chronic pain, fatigue and memory loss, have been reported in over one quarter of combat veterans of the 1991 Gulf War. Combustion products from depleted uranium munitions are being considered as one of the potential causes by the Research Advisory Committee on Gulf War Veterans' Illnesses, as DU was used in 30 mm and 25 mm cannon rounds on a large scale for the first time in the Gulf War. Veterans of the conflicts in the Persian Gulf, Bosnia and Kosovo have been found to have up to 14 times the usual level of chromosome abnormalities in their genes. Serum-soluble genotoxic teratogens produce congenital disorders, and in white blood cells causes immune system damage.
Human epidemiological evidence is consistent with increased risk of birth defects in the offspring of persons exposed to DU. A 2001 study of 15,000 February 1991 U.S. Gulf War combat veterans and 15,000 control veterans found that the Gulf War veterans were 1.8 (fathers) to 2.8 (mothers) times more likely to have children with birth defects. After examination of children's medical records two years later, the birth defect rate increased by more than 20%:
Dr. Kang found that male Gulf War veterans reported having infants with likely birth defects at twice the rate of non-veterans. Furthermore, female Gulf War veterans were almost three times more likely to report children with birth defects than their non-Gulf counterparts. The numbers changed somewhat with medical records verification. However, Dr. Kang and his colleagues concluded that the risk of birth defects in children of deployed male veterans still was about 2.2 times that of non-deployed veterans.
In early 2004, the UK Pensions Appeal Tribunal Service attributed birth defect claims from a February 1991 Gulf War combat veteran to depleted uranium poisoning. Looking at the risk of children of UK Gulf War veterans suffering genetic diseases such as congenital malformations, commonly called "birth defects", one study found that the overall risk of any malformation was 50% higher in Gulf War veterans as compared to other veterans.
The U.S. Army has commissioned ongoing research into potential risks of depleted uranium and other projectile weapon materials like tungsten, which the U.S. Navy has used in place of DU since 1993. Studies by the U.S. Armed Forces Radiobiology Research Institute conclude that moderate exposures to either depleted uranium or uranium present a significant toxicological threat.
In 2003 Professor Brian Spratt FRS, chairman of the Royal Society's working group on depleted uranium, said: "The question of who carries out the initial monitoring and clean-up is a political rather than scientific question," and "the coalition needs to acknowledge that depleted uranium is a potential hazard and make in-roads into tackling it by being open about where and how much depleted uranium has been deployed."
A 2008 review of all relevant articles appearing in the peer-reviewed journals on MEDLINE through to the end of 2007, including multiple cohort studies of veterans, found no consistent evidence of excess risks of neoplasms that could have some link to DU, and that "[t]he overall incidence of cancers is not increased in the cohort studies of Gulf war and Balkans veterans".
Though a more comprehensive assessment is possible, a 2011 update on a cancer scare regarding Italian soldiers who had served in the Balkans found lower than expected incidence rates for all cancers, a finding "consistent with lacking evidence of an increased cancer incidence among troops of other countries deployed in the areas of Iraq, Bosnia, and Kosovo, where armour-penetrating depleted uranium shells have been used."
One particular subgroup of veterans that may be at higher risk comprises those who have internally retained fragments of DU from shrapnel wounds. A laboratory study on rats produced by the Armed Forces Radiobiology Research Institute showed that, after a study period of 6 months, rats treated with depleted uranium coming from implanted pellets, comparable to the average levels in the urine of Desert Storm veterans with retained DU fragments, had developed a significant tendency to lose weight with respect to the control group.
Substantial amounts of uranium were accumulating in their brains and central nervous systems, and showed a significant reduction of neuronal activity in the hippocampus in response to external stimuli. The conclusions of the study show that brain damage from chronic uranium intoxication is possible at lower doses than previously thought. Results from computer-based neurocognitive tests performed in 1997 showed an association between uranium in the urine and "problematic performance on automated tests assessing performance efficiency and accuracy."
Iraqi population.
Since 2001, medical personnel at the Basra hospital in southern Iraq have reported a sharp increase in the incidence of child leukemia and genetic malformation among babies born in the decade following the Gulf War. Iraqi doctors attributed these malformations to possible long-term effects of DU, an opinion that was echoed by several newspapers. In 2004, Iraq had the highest mortality rate due to leukemia of any country. In 2003, the Royal Society called for Western militaries to disclose where and how much DU they had used in Iraq so that rigorous, and hopefully conclusive, studies could be undertaken out in affected areas. The International Coalition to Ban Uranium Weapons (ICBUW) likewise urged that an epidemiological study be made in the Basra region, as asked for by Iraqi doctors, but no peer-reviewed study has yet been undertaken in Basra.
A medical survey, "Cancer, Infant Mortality and Birth Sex Ratio in Fallujah, Iraq 2005–2009" published in July 2010, states that the "…increases in cancer and birth defects…are alarmingly high" and that infant mortality 2009/2010 has reached 13.6%. The group compares the dramatic increase, five years after the actual war 2004, or exposure, with the lymphoma Italian peacekeepers developed after the Balkan wars, and the increased cancer risk in certain parts of Sweden due to the Chernobyl fallout. The origin and time of introduction of the carcinogenic agent causing the genetic stress the group will address in a separate report. The report mentions depleted uranium as one "potentially relevant exposure" but makes no conclusions on the source.
Four studies in the second half of 2012—one of which described the people of Fallujah as having "the highest rate of genetic damage in any population ever studied"—renewed calls for the US and UK to investigate the possible links between their military assault on the city in 2004 and the explosion in deformities, cancers, and other serious health problems, even though no depleted uranium was found in soil samples taken from Fallujah.
The Balkans.
In 2001, the World Health Organization reported that data from Kosovo was inconclusive and called for further studies.
A 2003 study by the United Nations Environment Programme (UNEP) in Bosnia and Herzegovina stated that low levels of contaminate were found in drinking water and air particulate at DU penetrator impact points. The levels were stated as not a cause for alarm. Yet, Pekka Haavisto, chairman of the UNEP DU projects stated, "The findings of this study stress again the importance of appropriate clean-up and civil protection measures in a post-conflict situation."
A team of Italian scientists from the University of Siena reported in 2005 that although DU was "clearly" added to the soil in the study area, "the phenomenon was very limited spatially and the total uranium concentrations fell within the natural range of the element in soils. Moreover, the absolute uranium concentrations indicate that there was no contamination of the earthworm species studied."
Contamination as a result of the Afghan War.
The Canadian Uranium Medical Research Centre obtained urine samples from bombed civilian areas in Jalalabad that showed concentrations of 80–400 ng/L of undepleted uranium, far higher than the typical concentration in the British population of ~5 ng/L.
Studies indicating negligible effects.
Studies in 2005 and earlier have concluded that DU ammunition has no measurable detrimental health effects.
A 1999 literature review conducted by the Rand Corporation stated: "No evidence is documented in the literature of cancer or any other negative health effect related to the radiation received from exposure to depleted or natural uranium, whether inhaled or ingested, even at very high doses," and a RAND report authored by the U.S. Defense department undersecretary charged with evaluating DU hazards considered the debate to be more political than scientific.
A 2001 oncology study concluded that "the present scientific consensus is that DU exposure to humans, in locations where DU ammunition was deployed, is very unlikely to give rise to cancer induction". Former NATO Secretary General Lord Robertson stated in 2001 that "the existing medical consensus is clear. The hazard from depleted uranium is both very limited, and limited to very specific circumstances".
A 2002 study from the Australian defense ministry concluded that "there has been no established increase in mortality or morbidity in workers exposed to uranium in uranium processing industries... studies of Gulf War veterans show that, in those who have retained fragments of depleted uranium following combat related injury, it has been possible to detect elevated urinary uranium levels, but no kidney toxicity or other adverse health effects related to depleted uranium after a decade of follow-up." Pier Roberto Danesi, then-director of the International Atomic Energy Agency (IAEA) Seibersdorf +Laboratory, stated in 2002 that "There is a consensus now that DU does not represent a health threat".
The IAEA reported in 2003 that, "based on credible scientific evidence, there is no proven link between DU exposure and increases in human cancers or other significant health or environmental impacts," although "Like other heavy metals, DU is potentially poisonous. In sufficient amounts, if DU is ingested or inhaled it can be harmful because of its chemical toxicity. High concentration could cause kidney damage." The IAEA concluded that while depleted uranium is a potential carcinogen, there is no evidence that it has been carcinogenic in humans.
A 2005 study by Sandia National Laboratories' Al Marshall used mathematical models to analyze potential health effects associated with accidental exposure to depleted uranium during the 1991 Gulf War. Marshall's study concluded that the reports of cancer risks from DU exposure are not supported by his analysis nor by veteran medical statistics. Marshall also examined possible genetic effects due to radiation from depleted uranium. Chemical effects, including potential reproductive issues, associated with depleted uranium exposure were discussed in some detail in a subsequent journal paper.
Atmospheric contamination as a result of military actions.
Elevated radiation levels consistent with very low level atmospheric depleted uranium contamination have been found in air samples taken by the UK Atomic Weapons Establishment at several monitoring sites in Britain. These elevated readings appear to coincide with Operation Anaconda in Afghanistan, and the Shock and Awe bombing campaign at the start of the Second Gulf War.
Other contamination cases.
On October 4, 1992, an El Al Boeing 747-F cargo aircraft Flight 1862, crashed into an apartment building in Amsterdam. Local residents and rescue workers complained of various unexplained health issues which were being attributed to the release of hazardous materials during the crash and subsequent fires. Authorities conducted an epidemiological study in 2000 of those believed to be affected by the accident. The study concluded that there was no evidence to link depleted uranium (used as counterbalance weights on the elevators of the plane) to any of the reported health complaints.
Safety and environmental issues.
About 95% of the depleted uranium produced until now is stored as uranium hexafluoride, (D)UF6, in steel cylinders in open air yards close to enrichment plants. Each cylinder contains up to 12.7 tonnes (or 14 US tons) of UF6. In the U.S. alone, 560,000 tonnes of depleted UF6 had accumulated by 1993. In 2005, 686,500 tonnes in 57,122 storage cylinders were located near Portsmouth, Ohio, Oak Ridge, Tennessee, and Paducah, Kentucky.
The long-term storage of DUF6 presents environmental, health, and safety risks because of its chemical instability. When UF6 is exposed to moist air, it reacts with the water in the air and produces UO2F2 (uranyl fluoride) and HF (hydrogen fluoride), both of which are highly soluble and toxic. Storage cylinders must be regularly inspected for signs of corrosion and leaks. The estimated lifetime of the steel cylinders is measured in decades.
There have been several accidents involving uranium hexafluoride in the United States.
The vulnerability of DUF6 storage cylinders to terrorist attack is apparently not the subject of public reports. However, the U.S. government has been converting DUF6 to solid uranium oxides for disposal.
Disposing of the whole DUF6 inventory could cost anywhere from 15 to 450 million dollars.
External links.
Scientific bodies

</doc>
