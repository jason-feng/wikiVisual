<doc id="30653" url="http://en.wikipedia.org/wiki?curid=30653" title="Tuberculosis">
Tuberculosis

Tuberculosis, MTB, or TB (short for "tubercle bacillus"), in the past also called phthisis, phthisis pulmonalis, or consumption, is a widespread, and in many cases fatal, infectious disease caused by various strains of mycobacteria, usually "Mycobacterium tuberculosis". Tuberculosis typically attacks the lungs, but can also affect other parts of the body. It is spread through the air when people who have an active TB infection cough, sneeze, or otherwise transmit respiratory fluids through the air. Most infections do not have symptoms, known as latent tuberculosis. About one in ten latent infections eventually progresses to active disease which, if left untreated, kills more than 50% of those so infected.
The classic symptoms of active TB infection are a chronic cough with blood-tinged sputum, fever, night sweats, and weight loss (the latter giving rise to the formerly common term for the disease, "consumption"). Infection of other organs causes a wide range of symptoms. Diagnosis of active TB relies on radiology (commonly chest X-rays), as well as microscopic examination and microbiological culture of body fluids. Diagnosis of latent TB relies on the tuberculin skin test (TST) and/or blood tests. Treatment is difficult and requires administration of multiple antibiotics over a long period of time. Social contacts are also screened and treated if necessary. Antibiotic resistance is a growing problem in multiple drug-resistant tuberculosis (MDR-TB) infections. Prevention relies on screening programs and vaccination with the bacillus Calmette-Guérin vaccine.
One-third of the world's population is thought to have been infected with "M. tuberculosis", and new infections occur in about 1% of the population each year. In 2007, an estimated 13.7 million chronic cases were active globally, while in 2013, an estimated 9 million new cases occurred. In 2013 there were between 1.3 and 1.5 million associated deaths, most of which occurred in developing countries. The total number of tuberculosis cases has been decreasing since 2006, and new cases have decreased since 2002. The rate of tuberculosis in different areas varies across the globe; about 80% of the population in many Asian and African countries tests positive in tuberculin tests, while only 5–10% of the United States population tests positive. More people in the developing world contract tuberculosis because of a poor immune system, largely due to high rates of HIV infection and the corresponding development of AIDS.
Signs and symptoms.
Tuberculosis may infect any part of the body, but most commonly occurs in the lungs (known as pulmonary tuberculosis). Extrapulmonary TB occurs when tuberculosis develops outside of the lungs, although extrapulmonary TB may coexist with pulmonary TB, as well.
General signs and symptoms include fever, chills, night sweats, loss of appetite, weight loss, and fatigue. Significant nail clubbing may also occur.
Pulmonary.
If a tuberculosis infection does become active, it most commonly involves the lungs (in about 90% of cases). Symptoms may include chest pain and a prolonged cough producing sputum. About 25% of people may not have any symptoms (i.e. they remain "asymptomatic"). Occasionally, people may cough up blood in small amounts, and in very rare cases, the infection may erode into the pulmonary artery or a Rasmussen's aneurysm, resulting in massive bleeding. Tuberculosis may become a chronic illness and cause extensive scarring in the upper lobes of the lungs. The upper lung lobes are more frequently affected by tuberculosis than the lower ones. The reason for this difference is not entirely clear. It may be due either to better air flow, or to poor lymph drainage within the upper lungs.
Extrapulmonary.
In 15–20% of active cases, the infection spreads outside the lungs, causing other kinds of TB. These are collectively denoted as "extrapulmonary tuberculosis". Extrapulmonary TB occurs more commonly in immunosuppressed persons and young children. In those with HIV, this occurs in more than 50% of cases. Notable extrapulmonary infection sites include the pleura (in tuberculous pleurisy), the central nervous system (in tuberculous meningitis), the lymphatic system (in scrofula of the neck), the genitourinary system (in urogenital tuberculosis), and the bones and joints (in Pott disease of the spine), among others. When it spreads to the bones, it is also known as "osseous tuberculosis". a form of osteomyelitis. Sometimes, bursting of a tubercular abscess through skin results in tuberculous ulcer. An ulcer originating from nearby infected lymph nodes is painless, slowly enlarging and has an appearance of "wash leather". A potentially more serious, widespread form of TB is called "disseminated" TB, commonly known as miliary tuberculosis. Miliary TB makes up about 10% of extrapulmonary cases.
Causes.
Mycobacteria.
The main cause of TB is "Mycobacterium tuberculosis", a small, aerobic, nonmotile bacillus. The high lipid content of this pathogen accounts for many of its unique clinical characteristics. It divides every 16 to 20 hours, which is an extremely slow rate compared with other bacteria, which usually divide in less than an hour. Mycobacteria have an outer membrane lipid bilayer. If a Gram stain is performed, MTB either stains very weakly "Gram-positive" or does not retain dye as a result of the high lipid and mycolic acid content of its cell wall. MTB can withstand weak disinfectants and survive in a dry state for weeks. In nature, the bacterium can grow only within the cells of a host organism, but "M. tuberculosis" can be cultured in the laboratory.
Using histological stains on expectorated samples from phlegm (also called "sputum"), scientists can identify MTB under a microscope. Since MTB retains certain stains even after being treated with acidic solution, it is classified as an acid-fast bacillus (AFB). The most common acid-fast staining techniques are the Ziehl–Neelsen stain, which dyes AFBs a bright red that stands out clearly against a blue background, and the auramine-rhodamine stain followed by fluorescence microscopy.
The "M. tuberculosis" complex (MTBC) includes four other TB-causing mycobacteria: "M. bovis", "M. africanum", "M. canetti", and "M. microti". "M. africanum" is not widespread, but it is a significant cause of tuberculosis in parts of Africa. "M. bovis" was once a common cause of tuberculosis, but the introduction of pasteurized milk has largely eliminated this as a public health problem in developed countries. "M. canetti" is rare and seems to be limited to the Horn of Africa, although a few cases have been seen in African emigrants. "M. microti" is also rare and is mostly seen in immunodeficient people, although the prevalence of this pathogen has possibly been significantly underestimated.
Other known pathogenic mycobacteria include "M. leprae", "M. avium", and "M. kansasii". The latter two species are classified as "nontuberculous mycobacteria" (NTM). NTM cause neither TB nor leprosy, but they do cause pulmonary diseases that resemble TB.
Risk factors.
A number of factors make people more susceptible to TB infections. The most important risk factor globally is HIV; 13% of all people with TB are infected by the virus. This is a particular problem in sub-Saharan Africa, where rates of HIV are high. Of people without HIV who are infected with tuberculosis, about 5–10% develop active disease during their lifetimes; in contrast, 30% of those coinfected with HIV develop the active disease.
Tuberculosis is closely linked to both overcrowding and malnutrition, making it one of the principal diseases of poverty. Those at high risk thus include: people who inject illicit drugs, inhabitants and employees of locales where vulnerable people gather (e.g. prisons and homeless shelters), medically underprivileged and resource-poor communities, high-risk ethnic minorities, children in close contact with high-risk category patients, and health-care providers serving these patients.
Chronic lung disease is another significant risk factor. Silicosis increases the risk about 30-fold. Those who smoke cigarettes have nearly twice the risk of TB compared to nonsmokers.
Other disease states can also increase the risk of developing tuberculosis. These include alcoholism and diabetes mellitus (three-fold increase).
Certain medications, such as corticosteroids and infliximab (an anti-αTNF monoclonal antibody), are becoming increasingly important risk factors, especially in the developed world.
Also a genetic susceptibility element exists, for which the overall importance remains undefined.
Mechanism.
Transmission.
When people with active pulmonary TB cough, sneeze, speak, sing, or spit, they expel infectious aerosol droplets 0.5 to 5.0 µm in diameter. A single sneeze can release up to 40,000 droplets. Each one of these droplets may transmit the disease, since the infectious dose of tuberculosis is very small (the inhalation of fewer than 10 bacteria may cause an infection).
People with prolonged, frequent, or close contact with people with TB are at particularly high risk of becoming infected, with an estimated 22% infection rate. A person with active but untreated tuberculosis may infect 10–15 (or more) other people per year. Transmission should occur from only people with active TB – those with latent infection are not thought to be contagious. The probability of transmission from one person to another depends upon several factors, including the number of infectious droplets expelled by the carrier, the effectiveness of ventilation, the duration of exposure, the virulence of the "M. tuberculosis" strain, the level of immunity in the uninfected person, and others. The cascade of person-to-person spread can be circumvented by effectively segregating those with active ("overt") TB and putting them on anti-TB drug regimens. After about two weeks of effective treatment, subjects with nonresistant active infections generally do not remain contagious to others. If someone does become infected, it typically takes three to four weeks before the newly infected person becomes infectious enough to transmit the disease to others.
Pathogenesis.
About 90% of those infected with "M. tuberculosis" have asymptomatic, latent TB infections (sometimes called LTBI), with only a 10% lifetime chance that the latent infection will progress to overt, active tuberculous disease. In those with HIV, the risk of developing active TB increases to nearly 10% a year. If effective treatment is not given, the death rate for active TB cases is up to 66%.
TB infection begins when the mycobacteria reach the pulmonary alveoli, where they invade and replicate within endosomes of alveolar macrophages. Macrophages identify the bacterium as "foreign" and attempt to eliminate it by phagocytosis. During this process, the entire bacterium is enveloped by the macrophage and stored temporarily in a membrane-bound vesicle called a phagosome. The phagosome then combines with a lysosome to create a phagolysosome. In the phagolysosome, the cell attempts to use reactive oxygen species and acid to kill the bacterium. However, M. tuberculosis has a thick, waxy mycolic acid capsule that protects it from these toxic substances. M. tuberculosis actually reproduces inside the macrophage and will eventually kill the immune cell.
The primary site of infection in the lungs, known as the "Ghon focus", is generally located in either the upper part of the lower lobe, or the lower part of the upper lobe. Tuberculosis of the lungs may also occur via infection from the blood stream. This is known as a Simon focus and is typically found in the top of the lung. This hematogenous transmission can also spread infection to more distant sites, such as peripheral lymph nodes, the kidneys, the brain, and the bones. All parts of the body can be affected by the disease, though for unknown reasons it rarely affects the heart, skeletal muscles, pancreas, or thyroid.
Tuberculosis is classified as one of the granulomatous inflammatory diseases. Macrophages, T lymphocytes, B lymphocytes, and fibroblasts aggregate to form granulomas, with lymphocytes surrounding the infected macrophages. When other macrophages attack the infected macrophage, they fuse together to form a giant multinucleated cell in the alveolar lumen. The granuloma may prevent dissemination of the mycobacteria and provide a local environment for interaction of cells of the immune system. However more recent evidence suggests that the bacteria use the granulomas to avoid destruction by the host's immune system. Macrophages and dendritic cells in the granulomas are unable to present antigen to lymphocytes; thus the immune response is suppressed. Bacteria inside the granuloma can become dormant, resulting in latent infection. Another feature of the granulomas is the development of abnormal cell death (necrosis) in the center of tubercles. To the naked eye, this has the texture of soft, white cheese and is termed caseous necrosis.
If TB bacteria gain entry to the blood stream from an area of damaged tissue, they can spread throughout the body and set up many foci of infection, all appearing as tiny, white tubercles in the tissues. This severe form of TB disease, most common in young children and those with HIV, is called miliary tuberculosis. People with this disseminated TB have a high fatality rate even with treatment (about 30%).
In many people, the infection waxes and wanes. Tissue destruction and necrosis are often balanced by healing and fibrosis. Affected tissue is replaced by scarring and cavities filled with caseous necrotic material. During active disease, some of these cavities are joined to the air passages bronchi and this material can be coughed up. It contains living bacteria, so can spread the infection. Treatment with appropriate antibiotics kills bacteria and allows healing to take place. Upon cure, affected areas are eventually replaced by scar tissue.
Diagnosis.
Active tuberculosis.
Diagnosing active tuberculosis based merely on signs and symptoms is difficult, as is diagnosing the disease in those who are immunosuppressed. A diagnosis of TB should, however, be considered in those with signs of lung disease or constitutional symptoms lasting longer than two weeks. A chest X-ray and multiple sputum cultures for acid-fast bacilli are typically part of the initial evaluation. Interferon-γ release assays and tuberculin skin tests are of little use in the developing world. IGRA have similar limitations in those with HIV.
A definitive diagnosis of TB is made by identifying "M. tuberculosis" in a clinical sample (e.g., sputum, pus, or a tissue biopsy). However, the difficult culture process for this slow-growing organism can take two to six weeks for blood or sputum culture. Thus, treatment is often begun before cultures are confirmed.
Nucleic acid amplification tests and adenosine deaminase testing may allow rapid diagnosis of TB. These tests, however, are not routinely recommended, as they rarely alter how a person is treated. Blood tests to detect antibodies are not specific or sensitive, so they are not recommended.
Latent tuberculosis.
The Mantoux tuberculin skin test is often used to screen people at high risk for TB. Those who have been previously immunized may have a false-positive test result. The test may be falsely negative in those with sarcoidosis, Hodgkin's lymphoma, malnutrition, or most notably, in those who truly do have active tuberculosis. Interferon gamma release assays (IGRAs), on a blood sample, are recommended in those who are positive to the Mantoux test. These are not affected by immunization or most environmental mycobacteria, so they generate fewer false-positive results. However, they are affected by "M. szulgai", "M. marinum", and "M. kansasii". IGRAs may increase sensitivity when used in addition to the skin test, but may be less sensitive than the skin test when used alone.
Prevention.
Tuberculosis prevention and control efforts primarily rely on the vaccination of infants and the detection and appropriate treatment of active cases. The World Health Organization has achieved some success with improved treatment regimens, and a small decrease in case numbers.
Vaccines.
The only available vaccine as of 2011 is bacillus Calmette-Guérin (BCG). In children it decreases the risk of getting the infection by 20% and the risk of infection turning into disease by nearly 60%.
It is the most widely used vaccine worldwide, with more than 90% of all children being vaccinated. The immunity it induces decreases after about ten years. As tuberculosis is uncommon in most of Canada, the United Kingdom, and the United States, BCG is administered to only those people at high risk. Part of the reasoning arguing against the use of the vaccine is that it makes the tuberculin skin test falsely positive, so is of no use in screening. A number of new vaccines are currently in development.
Public health.
The World Health Organization declared TB a "global health emergency" in 1993, and in 2006, the Stop TB Partnership developed a Global Plan to Stop Tuberculosis that aims to save 14 million lives between its launch and 2015. A number of targets they have set are not likely to be achieved by 2015, mostly due to the increase in HIV-associated tuberculosis and the emergence of multiple drug-resistant tuberculosis. A tuberculosis classification system developed by the American Thoracic Society is used primarily in public health programs.
Management.
Treatment of TB uses antibiotics to kill the bacteria. Effective TB treatment is difficult, due to the unusual structure and chemical composition of the mycobacterial cell wall, which hinders the entry of drugs and makes many antibiotics ineffective. The two antibiotics most commonly used are isoniazid and rifampicin, and treatments can be prolonged, taking several months. Latent TB treatment usually employs a single antibiotic, while active TB disease is best treated with combinations of several antibiotics to reduce the risk of the bacteria developing antibiotic resistance. People with latent infections are also treated to prevent them from progressing to active TB disease later in life. Directly observed therapy, i.e., having a health care provider watch the person take their medications, is recommended by the WHO in an effort to reduce the number of people not appropriately taking antibiotics. The evidence to support this practice over people simply taking their medications independently is poor. Methods to remind people of the importance of treatment do, however, appear effective.
New onset.
The recommended treatment of new-onset pulmonary tuberculosis, as of 2010, is six months of a combination of antibiotics containing rifampicin, isoniazid, pyrazinamide, and ethambutol for the first two months, and only rifampicin and isoniazid for the last four months. Where resistance to isoniazid is high, ethambutol may be added for the last four months as an alternative.
Recurrent disease.
If tuberculosis recurs, testing to determine to which antibiotics it is sensitive is important before determining treatment. If multiple drug-resistant TB is detected, treatment with at least four effective antibiotics for 18 to 24 months is recommended.
Medication resistance.
Primary resistance occurs when a person becomes infected with a resistant strain of TB. A person with fully susceptible TB may develop secondary (acquired) resistance during therapy because of inadequate treatment, not taking the prescribed regimen appropriately (lack of compliance), or using low-quality medication. Drug-resistant TB is a serious public health issue in many developing countries, as its treatment is longer and requires more expensive drugs. MDR-TB is defined as resistance to the two most effective first-line TB drugs: rifampicin and isoniazid. Extensively drug-resistant TB is also resistant to three or more of the six classes of second-line drugs. Totally drug-resistant TB is resistant to all currently used drugs. It was first observed in 2003 in Italy, but not widely reported until 2012, and has also been found in Iran and India. Bedaquiline is tentatively supported for use in multiple drug-resistant TB.
XDR-TB is a term sometimes used to define "extensively resistant" TB, and constitutes one in ten cases of MDR-TB. Cases of XDR TB have been identified in more than 90% of countries.
Prognosis.
Progression from TB infection to overt TB disease occurs when the bacilli overcome the immune system defenses and begin to multiply. In primary TB disease (some 1–5% of cases), this occurs soon after the initial infection. However, in the majority of cases, a latent infection occurs with no obvious symptoms. These dormant bacilli produce active tuberculosis in 5–10% of these latent cases, often many years after infection.
The risk of reactivation increases with immunosuppression, such as that caused by infection with HIV. In people coinfected with "M. tuberculosis" and HIV, the risk of reactivation increases to 10% per year. Studies using DNA fingerprinting of "M. tuberculosis" strains have shown reinfection contributes more substantially to recurrent TB than previously thought, with estimates that it might account for more than 50% of reactivated cases in areas where TB is common. The chance of death from a case of tuberculosis is about 4% as of 2008, down from 8% in 1995.
Epidemiology.
Roughly one-third of the world's population has been infected with "M. tuberculosis", with new infections occurring in about 1% of the population each year. However, most infections with "M. tuberculosis" do not cause TB disease, and 90–95% of infections remain asymptomatic. In 2012, an estimated 8.6 million chronic cases were active. In 2010, 8.8 million new cases of TB were diagnosed, and 1.20–1.45 million deaths occurred, most of these occurring in developing countries. Of these 1.45 million deaths, about 0.35 million occur in those also infected with HIV.
Tuberculosis is the second-most common cause of death from infectious disease (after those due to HIV/AIDS). The total number of tuberculosis cases has been decreasing since 2005, while new cases have decreased since 2002. China has achieved particularly dramatic progress, with about an 80% reduction in its TB mortality rate between 1990 and 2010. The number of new cases has declined by 17% between 2004–2014. Tuberculosis is more common in developing countries; about 80% of the population in many Asian and African countries test positive in tuberculin tests, while only 5–10% of the US population test positive. Hopes of totally controlling the disease have been dramatically dampened because of a number of factors, including the difficulty of developing an effective vaccine, the expensive and time-consuming diagnostic process, the necessity of many months of treatment, the increase in HIV-associated tuberculosis, and the emergence of drug-resistant cases in the 1980s.
In 2007, the country with the highest estimated incidence rate of TB was Swaziland, with 1,200 cases per 100,000 people. India had the largest total incidence, with an estimated 2.0 million new cases. In developed countries, tuberculosis is less common and is found mainly in urban areas. Rates per 100,000 people in different areas of the world were: globally 178, Africa 332, the Americas 36, Eastern Mediterranean 173, Europe 63, Southeast Asia 278, and Western Pacific 139 in 2010. In Canada and Australia, tuberculosis is many times more common among the aboriginal peoples, especially in remote areas. In the United States Native Americans have a fivefold greater mortality from TB, and racial and ethnic minorities accounted for 84% of all reported TB cases.
The rates of TB varies with age. In Africa, it primarily affects adolescents and young adults. However, in countries where incidence rates have declined dramatically (such as the United States), TB is mainly a disease of older people and the immunocompromised (risk factors are listed above).
Worldwide, 22 "high-burden" states or countries together experience 80% of cases as well as 83% of deaths.
History.
Tuberculosis has been present in humans since antiquity. The earliest unambiguous detection of "M. tuberculosis" involves evidence of the disease in the remains of bison in Wyoming dated to around 17,000 years ago. However, whether tuberculosis originated in bovines, then was transferred to humans, or whether it diverged from a common ancestor, is currently unclear. A comparison of the genes of "M. tuberculosis" complex (MTBC) in humans to MTBC in animals suggests humans did not acquire MTBC from animals during animal domestication, as was previously believed. Both strains of the tuberculosis bacteria share a common ancestor, which could have infected humans as early as the Neolithic Revolution.
Skeletal remains show prehistoric humans (4000 BC) had TB, and researchers have found tubercular decay in the spines of Egyptian mummies dating from 3000–2400 BC. Genetic studies suggest TB was present in the Americas from about 100 AD.
"Phthisis" is a Greek word for consumption, an old term for pulmonary tuberculosis; around 460 BC, Hippocrates identified phthisis as the most widespread disease of the times. It was said to involve fever and the coughing up of blood, which was almost always fatal.
Before the Industrial Revolution, folklore often associated tuberculosis with vampires. When one member of a family died from it, the other infected members would lose their health slowly. People believed this was caused by the original person with TB draining the life from the other family members.
Although the pulmonary form associated with tubercles was established as a pathology by Dr Richard Morton in 1689, due to the variety of its symptoms, TB was not identified as a single disease until the 1820s. It was not named "tuberculosis" until 1839, by J. L. Schönlein.
During 1838–1845, Dr. John Croghan, the owner of Mammoth Cave, brought a number of people with tuberculosis into the cave in the hope of curing the disease with the constant temperature and purity of the cave air; they died within a year. Hermann Brehmer opened the first TB sanatorium in 1859 in Görbersdorf (now Sokołowsko), Silesia.
The bacillus causing tuberculosis, "M. tuberculosis", was identified and described on 24 March 1882 by Robert Koch. He received the Nobel Prize in physiology or medicine in 1905 for this discovery. Koch did not believe the bovine (cattle) and human tuberculosis diseases were similar, which delayed the recognition of infected milk as a source of infection. Later, the risk of transmission from this source was dramatically reduced by the invention of the pasteurization process. Koch announced a glycerine extract of the tubercle bacilli as a "remedy" for tuberculosis in 1890, calling it "tuberculin". While it was not effective, it was later successfully adapted as a screening test for the presence of pre-symptomatic tuberculosis.
Albert Calmette and Camille Guérin achieved the first genuine success in immunization against tuberculosis in 1906, using attenuated bovine-strain tuberculosis. It was called bacille Calmette–Guérin (BCG). The BCG vaccine was first used on humans in 1921 in France, but received widespread acceptance in the US, Great Britain, and Germany only after World War II.
Tuberculosis caused the most widespread public concern in the 19th and early 20th centuries as an endemic disease of the urban poor. In 1815, one in four deaths in England was due to "consumption". By 1918, one in six deaths in France was still caused by TB. After TB was determined to be contagious, in the 1880s, it was put on a notifiable disease list in Britain; campaigns were started to stop people from spitting in public places, and the infected poor were "encouraged" to enter sanatoria that resembled prisons (the sanatoria for the middle and upper classes offered excellent care and constant medical attention). Whatever the (purported) benefits of the "fresh air" and labor in the sanatoria, even under the best conditions, 50% of those who entered died within five years ("circa" 1916).
In Europe, rates of tuberculosis began to rise in the early 1600s to a peak level in the 1800s, when it caused nearly 25% of all deaths. By the 1950s, mortality had decreased nearly 90%. Improvements in public health began significantly reducing rates of tuberculosis even before the arrival of streptomycin and other antibiotics, although the disease remained a significant threat to public health such that when the Medical Research Council was formed in Britain in 1913, its initial focus was tuberculosis research.
In 1946, the development of the antibiotic streptomycin made effective treatment and cure of TB a reality. Prior to the introduction of this drug, the only treatment (except sanatoria) was surgical intervention, including the "pneumothorax technique", which involved collapsing an infected lung to "rest" it and allow tuberculous lesions to heal.
Because of the emergence of MDR-TB, surgery has been re-introduced as an option within the generally accepted standard of care in treating TB infections. Current surgical interventions involve removal of pathological chest cavities ("bullae") in the lungs to reduce the number of bacteria and to increase the exposure of the remaining bacteria to drugs in the bloodstream, thereby simultaneously reducing the total bacterial load and increasing the effectiveness of systemic antibiotic therapy.
Hopes of completely eliminating TB ("cf." smallpox) from the population were dashed after the rise of drug-resistant strains in the 1980s. The subsequent resurgence of tuberculosis resulted in the declaration of a global health emergency by the World Health Organization in 1993.
Society and culture.
Public health efforts.
The World Health Organization, Bill and Melinda Gates Foundation, and US government are subsidizing a fast-acting diagnostic tuberculosis test for use in low- and middle-income countries. In addition to being fast-acting, the test can determine if there is resistance to the antibiotic rifampicin which may indicate multi-drug resistant tuberculosis and is accurate in those who are also infected with HIV. Many resource-poor places as of 2011 only have access to sputum microscopy.
India had the highest total number of TB cases worldwide in 2010, in part due to poor disease management within the private and public health care sector. Programs such as the Revised National Tuberculosis Control Program are working to reduce TB levels amongst people receiving public health care.
A 2014 the EIU-healthcare report that the need to address apathy and urging for increased funding. The report cites among others Lucica Ditui "[TB] is like an orphan. It has been neglected even in countries with a high burden and often forgotten by donors and those investing in health interventions."
Slow progress has led to frustration, expressed by executive director of the Global Fund to Fight AIDS, Tuberculosis and Malaria – Mark Dybul: "we have the tools to end TB as a pandemic and public health threat on the planet, but we are not doing it." Several international organizations are pushing for more transparency in treatment, and more countries are implementing mandatory reporting of cases to the government, although adherence is often sketchy. Commercial treatment-providers may at times overprescribe second-line drugs as well as supplementary treatment, promoting demands for further regulations. The government of Brazil provides universal TB-care, which reduces this problem. Conversely falling rates of TB-infection may not relate to the number of programs directed at reducing infection rates, but may be tied to increased level of education, income and health of the population. Costs of the disease, as calculated by the World Bank in 2009 may exceed 150 billion USD per year in "high burden" countries. Lack of progress eradicating the disease may also be due to lack of patient follow-up – as among the 250M rural migrants in China.
Stigma.
Slow progress in preventing the disease may in part be due to stigma associated with TB. Stigma may be due to the fear of transmission from affected individuals. This stigma may additionally arise due to links between TB and poverty, and in Africa, AIDS. Such stigmatization may be both real and perceived, for example; in Ghana individuals with TB are banned from attending public gatherings.
Stigma towards TB may result in delays in seeking treatment, lower treatment compliance, and family members keeping cause of death secret – allowing the disease to spread further. At odds is Russia, where stigma was associated with increased treatment compliance. TB stigma also affects socially marginalized individuals to a greater degree and varies between regions.
One way to decrease stigma may be through the promotion of "TB clubs", where those infected may share experiences and offer support, or through counseling. Some studies have shown TB education programs to be effective in decreasing stigma, and may thus be effective in increasing treatment adherence. Despite this, studies on relationship between reduced stigma and mortality are lacking as of 2010, and similar efforts to decrease stigma surrounding AIDS have been minimally effective. Some have claimed the stigma to be worse than the disease, and healthcare providers may unintentionally reinforce stigma, as those with TB are often perceived as difficult or otherwise undesirable.
Research.
The BCG vaccine has limitations, and research to develop new TB vaccines is ongoing. A number of potential candidates are currently in phase I and II clinical trials. Two main approaches are being used to attempt to improve the efficacy of available vaccines. One approach involves adding a subunit vaccine to BCG, while the other strategy is attempting to create new and better live vaccines. MVA85A, an example of a subunit vaccine, currently in trials in South Africa, is based on a genetically modified vaccinia virus. Vaccines are hoped to play a significant role in treatment of both latent and active disease.
To encourage further discovery, researchers and policymakers are promoting new economic models of vaccine development, including prizes, tax incentives, and advance market commitments. A number of groups, including the Stop TB Partnership, the South African Tuberculosis Vaccine Initiative, and the Aeras Global TB Vaccine Foundation, are involved with research. Among these, the Aeras Global TB Vaccine Foundation received a gift of more than $280 million (US) from the Bill and Melinda Gates Foundation to develop and license an improved vaccine against tuberculosis for use in high burden countries.
A number of medications are being studied for multi drug resistant tuberculosis including: bedaquiline and delamanid. Bedaquiline received U.S. Food and Drug Administration (FDA) approval in late 2012. The safety and effectiveness of these new agents are still uncertain, because they are based on the results of a relatively small studies. However, existing data suggest that patients taking bedaquiline in addition to standard TB therapy are five times more likely to die than those without the new drug, which has resulted in medical journal articles raising health policy questions about why the FDA approved the drug and whether financial ties to the company making bedaquiline influenced physicians' support for its use 
Other animals.
Mycobacteria infect many different animals, including birds, rodents, and reptiles. The subspecies "Mycobacterium tuberculosis", though, is rarely present in wild animals. An effort to eradicate bovine tuberculosis caused by "Mycobacterium bovis" from the cattle and deer herds of New Zealand has been relatively successful. Efforts in Great Britain have been less successful.

</doc>
<doc id="30654" url="http://en.wikipedia.org/wiki?curid=30654" title="Triangle">
Triangle

A triangle is a polygon with three edges and three vertices. It is one of the basic shapes in geometry. A triangle with vertices "A", "B", and "C" is denoted formula_1.
In Euclidean geometry any three points, when non-collinear, determine a unique triangle and a unique plane (i.e. a two-dimensional Euclidean space). This article is about triangles in Euclidean geometry except where otherwise noted.
Types of triangle.
By relative lengths of sides.
Triangles can be classified according to the relative lengths of their sides:
Hatch marks, also called tick marks, are used in diagrams of triangles and other geometric figures to identify sides of equal lengths. A side can be marked with a pattern of "ticks", short line segments in the form of tally marks; two sides have equal lengths if they are both marked with the same pattern. In a triangle, the pattern is usually no more than 3 ticks. An equilateral triangle has the same pattern on all 3 sides, an isosceles triangle has the same pattern on just 2 sides, and a scalene triangle has different patterns on all sides since no sides are equal. Similarly, patterns of 1, 2, or 3 concentric arcs inside the angles are used to indicate equal angles. An equilateral triangle has the same pattern on all 3 angles, an isosceles triangle has the same pattern on just 2 angles, and a scalene triangle has different patterns on all angles since no angles are equal.
By internal angles.
Triangles can also be classified according to their internal angles, measured here in degrees.
A triangle that has two angles with the same measure also has two sides with the same length, and therefore it is an isosceles triangle. It follows that in a triangle where all angles have the same measure, all three sides have the same length, and such a triangle is therefore equilateral.
Basic facts.
Triangles are assumed to be two-dimensional plane figures, unless the context provides otherwise (see Non-planar triangles, below). In rigorous treatments, a triangle is therefore called a "2-simplex" (see also Polytope). Elementary facts about triangles were presented by Euclid in books 1–4 of his "Elements", around 300 BC.
The sum of the measures of the interior angles of a triangle in Euclidean space is always 180 degrees. This fact is equivalent to Euclid's parallel postulate. This allows determination of the measure of the third angle of any triangle given the measure of two angles. An "exterior angle" of a triangle is an angle that is a linear pair (and hence supplementary) to an interior angle. The measure of an exterior angle of a triangle is equal to the sum of the measures of the two interior angles that are not adjacent to it; this is the exterior angle theorem. The sum of the measures of the three exterior angles (one for each vertex) of any triangle is 360 degrees.
Similarity and congruence.
Two triangles are said to be "similar" if every angle of one triangle has the same measure as the corresponding angle in the other triangle. The corresponding sides of similar triangles have lengths that are in the same proportion, and this property is also sufficient to establish similarity.
Some basic theorems about similar triangles are:
Two triangles that are congruent have exactly the same size and shape: all pairs of corresponding interior angles are equal in measure, and all pairs of corresponding sides have the same length. (This is a total of six equalities, but three are often sufficient to prove congruence.)
Some individually necessary and sufficient conditions for a pair of triangles to be congruent are:
Some individually sufficient conditions are:
An important condition is:
Using right triangles and the concept of similarity, the trigonometric functions sine and cosine can be defined. These are functions of an angle which are investigated in trigonometry.
Right triangles.
A central theorem is the Pythagorean theorem, which states in any right triangle, the square of the length of the hypotenuse equals the sum of the squares of the lengths of the two other sides. If the hypotenuse has length "c", and the legs have lengths "a" and "b", then the theorem states that
The converse is true: if the lengths of the sides of a triangle satisfy the above equation, then the triangle has a right angle opposite side "c".
Some other facts about right triangles:
For all triangles, angles and sides are related by the law of cosines and law of sines (also called the "cosine rule" and "sine rule").
Existence of a triangle.
The triangle inequality states that the sum of the lengths of any two sides of a triangle must be greater than or equal to the length of the third side. That sum can equal the length of the third side only in the case of a degenerate triangle, one with collinear vertices. It is not possible for that sum to be less than the length of the third side. A triangle with three given side lengths exists if and only if those side lengths satisfy the triangle inequality.
Three given angles form a non-degenerate triangle (and indeed an infinitude of them) if and only if both of these conditions hold: (a) each of the angles is positive, and (b) the angles sum to 180°. If degenerate triangles are permitted, angles of 0° are permitted.
Trigonometric conditions.
Three positive angles "α", "β", and "γ", each of them less than 180°, are the angles of a triangle if and only if any one of the following conditions holds:
the latter equality applying only if none of the angles is 90° (so the tangent function's value is always finite).
Points, lines, and circles associated with a triangle.
There are thousands of different constructions that find a special point associated with (and often inside) a triangle, satisfying some unique property: see the references section for a catalogue of them. Often they are constructed by finding three lines associated in a symmetrical way with the three sides (or vertices) and then proving that the three lines meet in a single point: an important tool for proving the existence of these is Ceva's theorem, which gives a criterion for determining when three such lines are concurrent. Similarly, lines associated with a triangle are often constructed by proving that three symmetrically constructed points are collinear: here Menelaus' theorem gives a useful general criterion. In this section just a few of the most commonly encountered constructions are explained.
A perpendicular bisector of a side of a triangle is a straight line passing through the midpoint of the side and being perpendicular to it, i.e. forming a right angle with it. The three perpendicular bisectors meet in a single point, the triangle's circumcenter, usually denoted by O; this point is the center of the circumcircle, the circle passing through all three vertices. The diameter of this circle, called the "circumdiameter", can be found from the law of sines stated above. The circumcircle's radius is called the "circumradius".
Thales' theorem implies that if the circumcenter is located on one side of the triangle, then the opposite angle is a right one. If the circumcenter is located inside the triangle, then the triangle is acute; if the circumcenter is located outside the triangle, then the triangle is obtuse.
An altitude of a triangle is a straight line through a vertex and perpendicular to (i.e. forming a right angle with) the opposite side. This opposite side is called the "base" of the altitude, and the point where the altitude intersects the base (or its extension) is called the "foot" of the altitude. The length of the altitude is the distance between the base and the vertex. The three altitudes intersect in a single point, called the orthocenter of the triangle, usually denoted by H. The orthocenter lies inside the triangle if and only if the triangle is acute.
An angle bisector of a triangle is a straight line through a vertex which cuts the corresponding angle in half. The three angle bisectors intersect in a single point, the incenter, usually denoted by I, the center of the triangle's incircle. The incircle is the circle which lies inside the triangle and touches all three sides. Its radius is called the "inradius". There are three other important circles, the excircles; they lie outside the triangle and touch one side as well as the extensions of the other two. The centers of the in- and excircles form an orthocentric system.
A median of a triangle is a straight line through a vertex and the midpoint of the opposite side, and divides the triangle into two equal areas. The three medians intersect in a single point, the triangle's centroid or geometric barycenter, usually denoted by G. The centroid of a rigid triangular object (cut out of a thin sheet of uniform density) is also its center of mass: the object can be balanced on its centroid in a uniform gravitational field. The centroid cuts every median in the ratio 2:1, i.e. the distance between a vertex and the centroid is twice the distance between the centroid and the midpoint of the opposite side.
The midpoints of the three sides and the feet of the three altitudes all lie on a single circle, the triangle's nine-point circle. The remaining three points for which it is named are the midpoints of the portion of altitude between the vertices and the orthocenter. The radius of the nine-point circle is half that of the circumcircle. It touches the incircle (at the Feuerbach point) and the three excircles.
The centroid (yellow), orthocenter (blue), circumcenter (green) and center of the nine-point circle (red point) all lie on a single line, known as Euler's line (red line). The center of the nine-point circle lies at the midpoint between the orthocenter and the circumcenter, and the distance between the centroid and the circumcenter is half that between the centroid and the orthocenter.
The center of the incircle is not in general located on Euler's line.
If one reflects a median in the angle bisector that passes through the same vertex, one obtains a symmedian. The three symmedians intersect in a single point, the symmedian point of the triangle.
Computing the sides and angles.
There are various standard methods for calculating the length of a side or the measure of an angle. Certain methods are suited to calculating values in a right-angled triangle; more complex methods may be required in other situations.
Trigonometric ratios in right triangles.
In right triangles, the trigonometric ratios of sine, cosine and tangent can be used to find unknown angles and the lengths of unknown sides. The sides of the triangle are known as follows:
Sine, cosine and tangent.
The "sine" of an angle is the ratio of the length of the opposite side to the length of the hypotenuse. In our case
Note that this ratio does not depend on the particular right triangle chosen, as long as it contains the angle "A", since all those triangles are similar.
The "cosine" of an angle is the ratio of the length of the adjacent side to the length of the hypotenuse. In our case
The "tangent" of an angle is the ratio of the length of the opposite side to the length of the adjacent side. In our case
The acronym "SOH-CAH-TOA" is a useful mnemonic for these ratios.
Inverse functions.
The inverse trigonometric functions can be used to calculate the internal angles for a right angled triangle with the length of any two sides.
Arcsin can be used to calculate an angle from the length of the opposite side and the length of the hypotenuse.
Arccos can be used to calculate an angle from the length of the adjacent side and the length of the hypontenuse.
Arctan can be used to calculate an angle from the length of the opposite side and the length of the adjacent side.
In introductory geometry and trigonometry courses, the notation sin−1, cos−1, etc., are often used in place of arcsin, arccos, etc. However, the arcsin, arccos, etc., notation is standard in higher mathematics where trigonometric functions are commonly raised to powers, as this avoids confusion between multiplicative inverse and compositional inverse.
Sine, cosine and tangent rules.
The law of sines, or sine rule, states that the ratio of the length of a side to the sine of its corresponding opposite angle is constant, that is
This ratio is equal to the diameter of the circumscribed circle of the given triangle. Another interpretation of this theorem is that every triangle with angles α, β and γ is similar to a triangle with side lengths equal to sin α, sin β and sin γ. This triangle can be constructed by first constructing a circle of diameter 1, and inscribing in it two of the angles of the triangle. The length of the sides of that triangle will be sin α, sin β and sin γ. The side whose length is sin α is opposite to the angle whose measure is α, etc.
The law of cosines, or cosine rule, connects the length of an unknown side of a triangle to the length of the other sides and the angle opposite to the unknown side. As per the law:
For a triangle with length of sides "a", "b", "c" and angles of α, β, γ respectively, given two known lengths of a triangle "a" and "b", and the angle between the two known sides γ (or the angle opposite to the unknown side "c"), to calculate the third side "c", the following formula can be used:
If the lengths of all three sides of any triangle are known the three angles can be calculated:
The law of tangents or tangent rule, can be used to find a side or an angle when you know two sides and an angle or two angles and a side. It states that:
Solution of triangles.
"Solution of triangles" is the historical term for the solving of the main trigonometric problem: to find missing characteristics of a triangle (three angles, the lengths of the three sides etc.) when at least three of these characteristics are given. The triangle can be located on a plane or on a sphere. This problem often occurs in various trigonometric applications, such as geodesy, astronomy, construction, navigation etc.
Computing the area of a triangle.
Calculating the area "T" of a triangle is an elementary problem encountered often in many different situations. The best known and simplest formula is:
where "b" is the length of the base of the triangle, and "h" is the height or altitude of the triangle. The term "base" denotes any side, and "height" denotes the length of a perpendicular from the vertex opposite the side onto the line containing the side itself. In 499 CE Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, used this method in the "Aryabhatiya" (section 2.6).
Although simple, this formula is only useful if the height can be readily found, which is not always the case. For example, the surveyor of a triangular field might find it relatively easy to measure the length of each side, but relatively difficult to construct a 'height'. Various methods may be used in practice, depending on what is known about the triangle. The following is a selection of frequently used formulae for the area of a triangle.
Using trigonometry.
The height of a triangle can be found through the application of trigonometry.
"Knowing SAS": Using the labels in the image on the right, the altitude is . Substituting this in the formula formula_24 derived above, the area of the triangle can be expressed as:
(where α is the interior angle at "A", β is the interior angle at "B", formula_27 is the interior angle at "C" and "c" is the line AB).
Furthermore, since sin α = sin ("π" − α) = sin (β + formula_27), and similarly for the other two angles:
"Knowing AAS":
and analogously if the known side is "a" or "c".
"Knowing ASA":
and analogously if the known side is "b" or "c".
Using Heron's formula.
The shape of the triangle is determined by the lengths of the sides. Therefore the area can also be derived from the lengths of the sides. By Heron's formula:
where formula_33 is the "semiperimeter", or half of the triangle's perimeter.
Three other equivalent ways of writing Heron's formula are
Using vectors.
The area of a parallelogram embedded in a three-dimensional Euclidean space can be calculated using vectors. Let vectors AB and AC point respectively from "A" to "B" and from "A" to "C". The area of parallelogram "ABDC" is then
which is the magnitude of the cross product of vectors AB and AC. The area of triangle ABC is half of this,
The area of triangle "ABC" can also be expressed in terms of dot products as follows:
In two-dimensional Euclidean space, expressing vector AB as a free vector in Cartesian space equal to ("x"1,"y"1) and AC as ("x"2,"y"2), this can be rewritten as:
Using coordinates.
If vertex "A" is located at the origin (0, 0) of a Cartesian coordinate system and the coordinates of the other two vertices are given by and , then the area can be computed as 1⁄2 times the absolute value of the determinant
For three general vertices, the equation is:
which can be written as
If the points are labeled sequentially in the counterclockwise direction, the above determinant expressions are positive and the absolute value signs can be omitted. The above formula is known as the shoelace formula or the surveyor's formula.
If we locate the vertices in the complex plane and denote them in counterclockwise sequence as , , and , and denote their complex conjugates as formula_44, formula_45, and formula_46, then the formula
is equivalent to the shoelace formula.
In three dimensions, the area of a general triangle , and ) is the Pythagorean sum of the areas of the respective projections on the three principal planes (i.e. "x" = 0, "y" = 0 and "z" = 0):
Using line integrals.
The area within any closed curve, such as a triangle, is given by the line integral around the curve of the algebraic or signed distance of a point on the curve from an arbitrary oriented straight line "L". Points to the right of "L" as oriented are taken to be at negative distance from "L", while the weight for the integral is taken to be the component of arc length parallel to "L" rather than arc length itself.
This method is well suited to computation of the area of an arbitrary polygon. Taking "L" to be the "x"-axis, the line integral between consecutive vertices ("xi","yi") and ("xi"+1,"yi"+1) is given by the base times the mean height, namely ("xi"+1 − "xi")("yi" + "yi"+1)/2. The sign of the area is an overall indicator of the direction of traversal, with negative area indicating counterclockwise traversal. The area of a triangle then falls out as the case of a polygon with three sides.
While the line integral method has in common with other coordinate-based methods the arbitrary choice of a coordinate system, unlike the others it makes no arbitrary choice of vertex of the triangle as origin or of side as base. Furthermore the choice of coordinate system defined by "L" commits to only two degrees of freedom rather than the usual three, since the weight is a local distance (e.g. "xi"+1 − "xi" in the above) whence the method does not require choosing an axis normal to "L".
When working in polar coordinates it is not necessary to convert to cartesian coordinates to use line integration, since the line integral between consecutive vertices ("ri",θ"i") and ("ri"+1,θ"i"+1) of a polygon is given directly by "riri"+1sin(θ"i"+1 − θ"i")/2. This is valid for all values of θ, with some decrease in numerical accuracy when |θ| is many orders of magnitude greater than π. With this formulation negative area indicates clockwise traversal, which should be kept in mind when mixing polar and cartesian coordinates. Just as the choice of "y"-axis () is immaterial for line integration in cartesian coordinates, so is the choice of zero heading () immaterial here.
Formulas resembling Heron's formula.
Three formulas have the same structure as Heron's formula but are expressed in terms of different variables. First, denoting the medians from sides "a", "b", and "c" respectively as "ma", "mb", and "mc" and their semi-sum ("ma" + "mb" + "mc")/2 as σ, we have
Next, denoting the altitudes from sides "a", "b", and "c" respectively as "ha", "hb", and "hc", and denoting the semi-sum of the reciprocals of the altitudes as formula_50 we have
And denoting the semi-sum of the angles' sines as , we have
where "D" is the diameter of the circumcircle: formula_53
Using Pick's theorem.
See Pick's theorem for a technique for finding the area of any arbitrary lattice polygon (one drawn on a grid with vertically and horizontally adjacent lattice points at equal distances, and with vertices on lattice points).
The theorem states:
where "formula_55" is the number of internal lattice points and "B" is the number of lattice points lying on the border of the polygon.
Other area formulas.
Numerous other area formulas exist, such as
where "r" is the inradius, and "s" is the semiperimeter (in fact this formula holds for "all" tangential polygons);
and
for circumdiameter "D"; and
for angle α ≠ 90°.
Denoting the radius of the inscribed circle as "r" and the radii of the excircles as "r"1, "r"2, and "r"3, the area can be expressed as
In 1885, Baker gave a collection of over a hundred distinct area formulas for the triangle. These include:
for circumradius (radius of the circumcircle) "R", and
Upper bound on the area.
The area of any triangle with perimeter "p" is less than or equal to formula_66 with equality holding if and only if the triangle is equilateral.:657
Other upper bounds on the area "T" are given by:p.290
and
both again holding if and only if the triangle is equilateral.
Bisecting the area.
There are infinitely many lines that bisect the area of a triangle. Three of them are the medians, which are the only area bisectors that go through the centroid. Three other area bisectors are parallel to the triangle's sides.
Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter. There can be one, two, or three of these for any given triangle.
Further formulas for general Euclidean triangles.
The formulas in this section are true for all Euclidean triangles.
The medians and the sides are related by:p.70
and
and equivalently for "mb" and "mc".
For angle α opposite side "a", the length of the internal angle bisector is given by
for semiperimeter "s", where the bisector length is measured from the vertex to where it meets the opposite side.
The interior perpendicular bisectors are given by
where the sides are formula_75 and the area is formula_76:Thm 2
The altitude from, for example, the side of length "a" is
The following formulas involve the circumradius "R" and the inradius "r":
where "ha" etc. are the altitudes to the subscripted sides;:p.79
and
Suppose two adjacent but non-overlapping triangles share the same side of length "f" and share the same circumcircle, so that the side of length "f" is a chord of the circumcircle and the triangles have side lengths ("a", "b", "f") and ("c", "d", "f"), with the two triangles together forming a cyclic quadrilateral with side lengths in sequence ("a", "b", "c", "d"). Then:84
Let "M" be the centroid of a triangle with vertices "A", "B", and "C", and let "P" be any interior point. Then the distances between the points are related by:174
Let "pa", "pb", and "pc" be the distances from the centroid to the sides of lengths "a", "b", and "c". Then:173
and
The product of two sides of a triangle equals the altitude to the third side times the diameter of the circumcircle.:p.64
Carnot's Theorem states that the sum of the distances from the circumcenter to the three sides equals the sum of the circumradius and the inradius.:p.83 Here a segment's length is considered to be negative if and only if the segment lies entirely outside the triangle. This method is especially useful for deducing the properties of more abstract forms of triangles, such as the ones induced by Lie algebras, that otherwise have the same properties as usual triangles.
Euler's theorem states that the distance "d" between the circumcenter and the incenter is given by:p.85
or equivalently
where "R" is the circumradius and "r" is the inradius. Thus for all triangles "R" ≥ 2"r", with equality holding for equilateral triangles.
If we denote that the orthocenter divides one altitude into segments of lengths "u" and "v", another altitude into segment lengths "w" and "x", and the third altitude into segment lengths "y" and "z", then "uv" = "wx" = "yz".:p.94
The distance from a side to the circumcenter equals half the distance from the opposite vertex to the orthocenter.:p.99
The sum of the squares of the distances from the vertices to the orthocenter plus the sum of the squares of the sides equals twelve times the square of the circumradius.:p.102
For any triangle,
Morley's trisector theorem.
Morley's trisector theorem states that in any triangle, the three points of intersection of the adjacent angle trisectors form an equilateral triangle, called the Morley triangle.
Figures inscribed in a triangle.
Conics.
As discussed above, every triangle has a unique inscribed circle (incircle) that is interior to the triangle and tangent to all three sides.
Every triangle has a unique Steiner inellipse which is interior to the triangle and tangent at the midpoints of the sides. Marden's theorem shows how to find the foci of this ellipse. This ellipse has the greatest area of any ellipse tangent to all three sides of the triangle.
The Mandart inellipse of a triangle is the ellipse inscribed within the triangle tangent to its sides at the contact points of its excircles.
For any ellipse inscribed in a triangle "ABC", let the foci be "P" and "Q". Then
Convex polygon.
Every convex polygon with area "T" can be inscribed in a triangle of area at most equal to 2"T". Equality holds (exclusively) for a parallelogram.
Hexagon.
The Lemoine hexagon is a cyclic hexagon with vertices given by the six intersections of the sides of a triangle with the three lines that are parallel to the sides and that pass through its symmedian point. In either its simple form or its self-intersecting form, the Lemoine hexagon is interior to the triangle with two vertices on each side of the triangle.
Squares.
Every acute triangle has three inscribed squares (squares in its interior such that all four of a square's vertices lie on a side of the triangle, so two of them lie on the same side and hence one side of the square coincides with part of a side of the triangle). In a right triangle two of the squares coincide and have a vertex at the triangle's right angle, so a right triangle has only two "distinct" inscribed squares. An obtuse triangle has only one inscribed square, with a side coinciding with part of the triangle's longest side. Within a given triangle, a longer common side is associated with a smaller inscribed square. If an inscribed square has side of length "q" and the triangle has a side of length "a", part of which side coincides with a side of the square, then "q", "a", and the triangle's area "T" are related according to
The largest possible ratio of the area of the inscribed square to the area of the triangle is 1/2, which occurs when , , and the altitude of the triangle from the base of length "a" is equal to "a". The smallest possible ratio of the side of one inscribed square to the side of another in the same non-obtuse triangle is formula_92
Triangles.
From an interior point in a reference triangle, the nearest points on the three sides serve as the vertices of the pedal triangle of that point. If the interior point is the circumcenter of the reference triangle, the vertices of the pedal triangle are the midpoints of the reference triangle's sides, and so the pedal triangle is called the midpoint triangle or medial triangle. The midpoint triangle subdivides the reference triangle into four congruent triangles which are similar to the reference triangle.
The Gergonne triangle or intouch triangle of a reference triangle has its vertices at the three points of tangency of the reference triangle's sides with its incircle. The extouch triangle of a reference triangle has its vertices at the points of tangency of the reference triangle's excircles with its sides (not extended).
Figures circumscribed about a triangle.
The tangential triangle of a reference triangle (other than a right triangle) is the triangle whose sides are on the tangent lines to the reference triangle's circumcircle at its vertices.
As mentioned above, every triangle has a unique circumcircle, a circle passing through all three vertices, whose center is the intersection of the perpendicular bisectors of the triangle's sides.
Further, every triangle has a unique Steiner circumellipse, which passes through the triangle's vertices and has its center at the triangle's centroid. Of all ellipses going through the triangle's vertices, it has the smallest area.
The Kiepert hyperbola is the unique conic which passes through the triangle's three vertices, its centroid, and its circumcenter.
Of all triangles contained in a given convex polygon, there exists a triangle with maximal area whose vertices are all vertices of the given polygon.
Specifying the location of a point in a triangle.
One way to identify locations of points in (or outside) a triangle is to place the triangle in an arbitrary location and orientation in the Cartesian plane, and to use Cartesian coordinates. While convenient for many purposes, this approach has the disadvantage of all points' coordinate values being dependent on the arbitrary placement in the plane.
Two systems avoid that feature, so that the coordinates of a point are not affected by moving the triangle, rotating it, or reflecting it as in a mirror, any of which give a congruent triangle, or even by rescaling it to give a similar triangle. Trilinear coordinates specify the relative distances of a point from the sides, so that coordinates "x : y : z" indicate that the ratio of the distance of the point from the first side to its distance from the second side is "x : y", etc. Barycentric coordinates of the form formula_93 specify the point's location by the relative weights that would have to be put on the three vertices in order to balance the otherwise weightless triangle on the given point.
Non-planar triangles.
A non-planar triangle is a triangle which is not contained in a (flat) plane. Some examples of non-planar triangles in non-Euclidean geometries are spherical triangles in spherical geometry and hyperbolic triangles in hyperbolic geometry.
While the measures of the internal angles in planar triangles always sum to 180°, a hyperbolic triangle has measures of angles that sum to less than 180°, and a spherical triangle has measures of angles that sum to more than 180°. A hyperbolic triangle can be obtained by drawing on a negatively curved surface, such as a saddle surface, and a spherical triangle can be obtained by drawing on a positively curved surface such as a sphere. Thus, if one draws a giant triangle on the surface of the Earth, one will find that the sum of the measures of its angles is greater than 180°; in fact it will be between 180° and 540°. In particular it is possible to draw a triangle on a sphere such that the measure of each of its internal angles is equal to 90°, adding up to a total of 270°.
Specifically, on a sphere the sum of the angles of a triangle is
where "f" is the fraction of the sphere's area which is enclosed by the triangle. For example, suppose that we draw a triangle on the Earth's surface with vertices at the North Pole, at a point on the equator at 0° longitude, and a point on the equator at 90° West longitude. The great circle line between the latter two points is the equator, and the great circle line between either of those points and the North Pole is a line of longitude; so there are right angles at the two points on the equator. Moreover, the angle at the North Pole is also 90° because the other two vertices differ by 90° of longitude. So the sum of the angles in this triangle is 90° + 90° + 90° = 270°. The triangle encloses 1/4 of the northern hemisphere (90°/360° as viewed from the North Pole) and therefore 1/8 of the Earth's surface, so in the formula ; thus the formula correctly gives the sum of the triangle's angles as 270°.
From the above angle sum formula we can also see that the Earth's surface is locally flat: If we draw an arbitrarily small triangle in the neighborhood of one point on the Earth's surface, the fraction "f" of the Earth's surface which is enclosed by the triangle will be arbitrarily close to zero. In this case the angle sum formula simplifies to 180°, which we know is what Euclidean geometry tells us for triangles on a flat surface.
Triangles in construction.
Rectangles have been the most popular and common geometric form for buildings since the shape is easy to stack and organize; as a standard, it is easy to design furniture and fixtures to fit inside rectangularly shaped buildings. But triangles, while more difficult to use conceptually, provide a great deal of strength. As computer technology helps architects design creative new buildings, triangular shapes are becoming increasingly prevalent as parts of buildings and as the primary shape for some types of skyscrapers as well as building materials. In Tokyo in 1989, architects had wondered whether it was possible to build a 500-story tower to provide affordable office space for this densely packed city, but with the danger to buildings from earthquakes, architects considered that a triangular shape would have been necessary if such a building was ever to have been built (it hasn't by 2011).
In New York City, as Broadway crisscrosses major avenues, the resulting blocks are cut like triangles, and buildings have been built on these shapes; one such building is the triangularly shaped Flatiron Building which real estate people admit has a "warren of awkward spaces that do not easily accommodate modern office furniture" but that has not prevented the structure from becoming a landmark icon. Designers have made houses in Norway using triangular themes. Triangle shapes have appeared in churches as well as public buildings including colleges as well as supports for innovative home designs.
Triangles are sturdy; while a rectangle can collapse into a parallelogram from pressure to one of its points, triangles have a natural strength which supports structures against lateral pressures. A triangle will not change shape unless its sides are bent or extended or broken or if its joints break; in essence, each of the three sides supports the other two. A rectangle, in contrast, is more dependent on the strength of its joints in a structural sense. Some innovative designers have proposed making bricks not out of rectangles, but with triangular shapes which can be combined in three dimensions. It is likely that triangles will be used increasingly in new ways as architecture increases in complexity. It is important to remember that triangles are strong in terms of rigidity, but while packed in a tessellating arrangement triangles are not as strong as hexagons under compression (hence the prevalence of hexagonal forms in nature). Tessellated triangles still maintain superior strength for cantilevering however, and this is the basis for one of the strongest man made structures, the tetrahedral truss.

</doc>
<doc id="30656" url="http://en.wikipedia.org/wiki?curid=30656" title="Torino scale">
Torino scale

The Torino Scale is a method for categorizing the impact hazard associated with near-Earth objects (NEOs) such as asteroids and comets.
It is intended as a communication tool for astronomers and the public to assess the seriousness of collision predictions, by combining probability statistics and known kinetic damage potentials into a single threat value. The Palermo Technical Impact Hazard Scale is a similar, but more complex scale.
Overview.
The Torino Scale uses an integer scale from 0 to 10. A 0 indicates an object has a negligibly small chance of collision with the Earth, compared with the usual "background noise" of collision events, or is too small to penetrate Earth's atmosphere intact. A 10 indicates that a collision is certain, and the impacting object is large enough to precipitate a global disaster.
An object is assigned a 0 to 10 value based on its collision probability and the kinetic energy (expressed in megatons of TNT) of the possible collision.
The Torino Scale is defined only for potential impacts less than 100 years in the future.
"For an object with multiple potential collisions on a set of dates, a Torino Scale value should be determined for each date. It may be convenient to summarize such an object by the greatest Torino Scale value within the set."
History and naming.
The Torino Scale was created by Professor Richard P. Binzel in the Department of Earth, Atmospheric, and Planetary Sciences, at the Massachusetts Institute of Technology (MIT). The first version, called "A Near-Earth Object Hazard Index", was presented at a United Nations conference in 1995 and was published by Binzel in the subsequent conference proceedings ("Annals of the New York Academy of Sciences," volume 822, 1997.)
A revised version of the "Hazard Index" was presented at a June 1999 international conference on NEOs held in Torino (Turin), Italy. The conference participants voted to adopt the revised version, where the bestowed name "Torino Scale" recognizes the spirit of international cooperation displayed at that conference toward research efforts to understand the hazards posed by NEOs. ("Torino Scale" is the proper usage, not "Turin Scale.")
Due to exaggerated press coverage of Level 1 asteroids, a rewording of the Torino Scale was published in 2005, adding more details and renaming the categories: in particular, Level 1 was changed from "Events meriting careful monitoring" to "Normal".
Current Torino Scale.
The Torino Scale also uses a color code scale: white, green, yellow, orange, red. Each color code has an overall meaning:
No object has ever been rated above level 4; Currently all objects are rated level 0 (see below).
Actual impacts and impact energy comparisons.
The Chicxulub impact, believed by many to be a significant factor in the extinction of the dinosaurs, has been estimated at 100 million (108) megatons, or Torino Scale 10.
The impact which created the Barringer Crater, and the Tunguska event in 1908 are both estimated to be in the 3–10 megaton range, corresponding to Torino Scale 8. The 2013 Chelyabinsk meteor had a total kinetic energy prior to impact of about 0.4 megatons, corresponding to Torino Scale 0. Between 2000 and 2013, 26 asteroid impacts with energy of 1-600 kiloton were detected.
The biggest hydrogen bomb ever exploded, the Tsar Bomba, was around 50 megatons. 
The 1883 eruption of Krakatoa was the equivalent of roughly 200 megatons.
The comet C/2013 A1, which passed close to Mars in 2014, is estimated to have a potential impact energy of 5 million to 24 billion Mt, and in March 2013 was estimated to have an impact probability of ~1:1250, corresponding to the Martian analogue of Torino Scale 6. The impact probability was reduced to ~1:120000 in April 2013, corresponding to Torino Scale 1 or 2.
Objects with non-zero Torino ratings.
Currently non-zero.
Since March 2014, there have been no objects rated at a Torino Scale level greater than zero.
Downgraded to zero.
This is a partial list of near-Earth asteroids that have been listed with a Torino Scale rating of 1+ and been lowered to 0 or been removed from the Sentry Risk Table altogether. Most objects that reach a Torino Scale of 1 have a short observation arc of less than 2 weeks and are quickly removed as the observation arc gets longer and more accurate.
References.
 This article incorporates  from websites or documents of the .

</doc>
<doc id="30657" url="http://en.wikipedia.org/wiki?curid=30657" title="Terabyte">
Terabyte

The terabyte is a multiple of the unit byte for digital information. The prefix "tera" represents the fourth power of 1000, and means 1012 in the International System of Units (SI), and therefore one terabyte is one trillion (short scale) bytes. The unit symbol for the terabyte is TB.
1 TB = = = .
A related unit, the tebibyte (TiB), using a binary prefix, is the corresponding 4th power of 1024. One terabyte is about 0.9095 tebibytes, or 931 gibibytes.
History.
The first hard disk drives were created in the 1950s and 1960s and were the size of a refrigerator, with a capacity of a few megabytes. In 1982, the first IBM PC with a hard disk drive was released, and had a capacity of 5 megabytes (0.000 005 TB). The first single hard disks of terabyte size reached the mass market in early 2008. s of 2014[ [update]], 1 terabyte solid state drives use an mSATA form factor.
Costs.
In 1991, consumer grade, 1 gigabyte (1/1000 TB) disk drives were available for US$2699 and more, and two years later prices for this capacity had dropped to US$1499. By 1995, 1 GB drives could be purchased for US$849.
Illustrative usage examples.
Examples of the use of "terabyte" to describe data sizes in different fields are:

</doc>
<doc id="30658" url="http://en.wikipedia.org/wiki?curid=30658" title="TWA Flight 800">
TWA Flight 800

Trans World Airlines Flight 800 (TWA 800), was a Boeing 747-100 that exploded and crashed into the Atlantic Ocean near East Moriches, New York, on July 17, 1996, at about 8:31 p.m. EDT, 12 minutes after takeoff from John F. Kennedy International Airport on a scheduled international passenger flight to Rome, with a stopover in Paris. All 230 people on board were killed in the third-deadliest aviation accident in U.S. territory.
Accident investigators from the National Transportation Safety Board (NTSB) traveled to the scene, arriving the following morning, and there was much initial speculation that a terrorist attack was the cause of the crash. Consequently, the Federal Bureau of Investigation (FBI) initiated a parallel criminal investigation. Sixteen months later, the FBI announced that no evidence had been found of a criminal act and closed its active investigation.
The four-year NTSB investigation concluded with the approval of the Aircraft Accident Report on August 23rd, 2000, ending the most extensive, complex, and costly air disaster investigation in U.S. history. The report's conclusion was that the probable cause of the accident was an explosion of flammable fuel/air vapors in a fuel tank, and, although it could not be determined with certainty, the most likely cause of the explosion was a short circuit. As a result of the investigation, new requirements were developed for aircraft to prevent future fuel tank explosions.
TWA Flight 800 conspiracy theories exist, the most prevalent being that a missile strike from a terrorist or an accidental launch from a U.S. Navy vessel caused the crash, and is the subject of a government coverup.
Accident flight.
The accident airplane, registration N93119, (Boeing 747-131) was manufactured by Boeing in July 1971; it had been ordered by Eastern Air Lines, but after Eastern canceled its 747 orders, the plane was purchased new by TWA. The aircraft had completed 16,869 flights with 93,303 hours of operation. On the day of the accident, the airplane departed Athens, Greece as TWA Flight 881 and arrived at John F. Kennedy International Airport (JFK) about 4:38pm. The aircraft was refueled, and there was a crew change; the new flight crew consisted of 58-year-old Captain Ralph G. Kevorkian, 57-year-old Captain/Check Airman Steven E. Snyder, and 63-year-old Flight Engineer/Check Airman Richard G. Campbell (all with more than 30 years of employment at TWA), as well as 24-year-old flight engineer trainee Oliver Krick, who was starting the sixth leg of his initial operating experience training.
The ground-maintenance crew locked out the thrust reverser for engine #3 (treated as a minimum equipment list item) because of technical problems with the thrust reverser sensors during the landing of TWA 881 at JFK, prior to Flight 800's departure. In addition, severed cables for the engine #3 thrust reverser were replaced. During refueling of the aircraft, the volumetric shutoff (VSO) control was believed to have been triggered before the tanks were full. To continue the pressure fueling, a TWA mechanic overrode the automatic VSO by pulling the volumetric fuse and an overflow circuit breaker. Maintenance records indicate that the airplane had numerous VSO-related maintenance writeups in the weeks before the accident.
TWA 800 was scheduled to depart JFK for Paris around 7:00pm, but the flight was delayed until 8:02pm by a disabled piece of ground equipment and a passenger/baggage mismatch. After the owner of the baggage in question was confirmed to be on board, the flight crew prepared for departure and the aircraft pushed back from Gate 27 at the TWA Flight Center.
TWA 800 then received a series of heading changes and generally increasing altitude assignments as it climbed to its intended cruising altitude. Weather in the area was light winds with scattered clouds, and there were dusk lighting conditions. The last radio transmission from the airplane occurred at 8:30pm when the flight crew received and then acknowledged instructions from New York Center to climb to 15000 ft. The last recorded radar transponder return from the airplane was recorded by the Federal Aviation Administration (FAA) radar site at Trevose, Pennsylvania at 8:31:12pm.
Thirty-eight seconds later, the captain of an Eastwind Airlines Boeing 737 reported to Boston ARTCC that he "just saw an explosion out here", adding, "we just saw an explosion up ahead of us here...about 16000 ft or something like that, it just went down into the water." Subsequently, many air traffic control facilities in the New York/Long Island area received reports of an explosion from other pilots operating in the area. Many witnesses in the vicinity of the crash stated that they saw or heard explosions, accompanied by a large fireball or fireballs over the ocean, and observed debris, some of which was burning while falling into the water.
Individuals in various civilian, military, and police vessels reached the crash site and searched for survivors within minutes of the initial water impact, but no survivors were found, making TWA 800 the second-deadliest aircraft accident in United States history at that time.
Initial investigation.
The NTSB was notified about 8:50pm the day of the accident; a full go-team was assembled in Washington, D.C. and arrived on scene early the next morning. Meanwhile, initial witness descriptions led many to believe the cause of the crash was a bomb or surface-to-air missile attack. The NTSB does not investigate criminal activity. In past investigations, once it was established that a crash was, in fact, a criminal act, the FBI had become the lead federal investigative body, with the NTSB providing any requested support. In the case of TWA 800, the FBI initiated a parallel criminal investigation alongside the NTSB's accident investigation.
Search and recovery operations.
Search and recovery operations were conducted by federal, state, and local agencies, as well as government contractors. Remote-operated vehicles (ROVs), side-scan sonar, and laser line-scanning equipment were used to search for and investigate underwater debris fields. Victims and wreckage were recovered by scuba divers and ROVs; later scallop trawlers were used to recover wreckage embedded in the ocean floor. In one of the largest diver-assisted salvage operations ever conducted, often working in very difficult and dangerous conditions, over 95% of the airplane wreckage was eventually recovered. The search and recovery effort identified three main areas of wreckage underwater. The yellow zone, red zone, and green zone contained wreckage from front, center, and rear sections of the airplane, respectively. The green zone with the aft portion of the aircraft was located the furthest along the flight path.
Pieces of wreckage were transported by boat to shore and then by truck to leased hangar space at the former Grumman Aircraft facility in Calverton, New York, for storage, examination, and reconstruction. This facility became the command center and headquarters for the investigation. NTSB and FBI personnel were present to observe all transfers to preserve the evidentiary value of the wreckage. The cockpit voice recorder and flight data recorder were recovered by U.S. Navy divers a week after the accident; they were immediately shipped to the NTSB laboratory in Washington, D.C., for readout. The victims were transported to the Suffolk County Medical Examiner's Office in Hauppauge, New York.
Tensions in the investigation.
Relatives of TWA 800 passengers and crew, as well as the media, gathered at the Ramada Plaza JFK Hotel. Many waited until the remains of their family members had been recovered, identified, and released. This hotel became known as the "Heartbreak Hotel" for its role in handling families of victims of several airliner crashes. Ying Chan, Jose Lambiet, and Jere Hester of the New York "Daily News" wrote that for the families the hotel became "a makeshift grief counseling center".
Grief turned to anger at TWA's delay in confirming the passenger list, conflicting information from agencies and officials, and mistrust of the recovery operation's priorities. Although NTSB vice chairman Robert Francis stated that all bodies were being retrieved as soon as they were spotted, and that wreckage was being recovered only if divers believed that victims were hidden underneath, many families were suspicious that investigators were not being truthful, or withholding information.
Much anger and political pressure was also directed at Suffolk County Medical Examiner Dr. Charles V. Wetli as recovered bodies backlogged at the morgue. Under constant and considerable pressure to identify victims with minimal delay, pathologists worked non-stop. Since the primary objective was to identify all remains rather than performing a detailed forensic autopsy, the thoroughness of the examinations was highly variable. Ultimately, remains of all 230 victims were recovered and identified, the last over 10 months after the crash.
With lines of authority unclear, differences in agendas and culture between the FBI and NTSB resulted in discord. The FBI, from the start assuming that a criminal act had occurred, saw the NTSB as indecisive. Expressing frustration at the NTSB's unwillingness to speculate on a cause, one FBI agent described the NTSB as "No opinions. No nothing". Meanwhile the NTSB was required to refute or play down speculation about conclusions and evidence, frequently supplied to reporters by law enforcement officials and politicians. The International Association of Machinists and Aerospace Workers (IAMAW), an invited party to the NTSB investigation, criticized the undocumented removal by FBI agents of wreckage from the hangar where it was stored.
Witness interviews.
Most witnesses to the accident had seen a "streak of light" that was unanimously described as ascending, moving to a point where a large fireball appeared, with several witnesses reporting that the fireball split in two as it descended toward the water. There was intense public interest in these witness reports and much speculation that the reported streak of light was a missile that had struck TWA 800, causing the airplane to explode. These witness accounts were a major reason for the initiation and duration of the FBI's criminal investigation.
Approximately 80 FBI agents conducted interviews with potential witnesses daily. No verbatim records of the witness interviews were produced; instead, the agents who conducted the interviews wrote summaries that they then submitted. Witnesses were not asked to review or correct the summaries. Included in some of the witness summaries were drawings or diagrams of what the witness observed. Witnesses were not allowed to testify at the court hearings.
Within days of the crash the NTSB announced its intent to form its own witness group and to interview witnesses to the crash. After the FBI raised concerns about non-governmental parties in the NTSB's investigation having access to this information and possible prosecutorial difficulties resulting from multiple interviews of the same witness, the NTSB deferred and did not interview witnesses to the crash. A Safety Board investigator later reviewed FBI interview notes and briefed other Board investigators on their contents. In November 1996, the FBI agreed to allow the NTSB access to summaries of witness accounts in which personally identifying information had been redacted and to conduct a limited number of witness interviews. In April 1998, the FBI provided the NTSB with the identities of the witnesses but due to the time elapsed a decision was made to rely on the original FBI documents rather than reinterview witnesses.
Further investigation and analysis.
Examination of the cockpit voice recorder (CVR) and flight data recorder data showed a normal takeoff and climb, with the aircraft in normal flight before both abruptly stopped at 8:31:12pm. At 8:29:15pm the captain was heard to say, "Look at that crazy fuel flow indicator there on number four...see that?" A noise recorded on the last few tenths of a second of the CVR was similar to the last noises recorded from other airplanes that had experienced in-flight breakups. This, together with the distribution of wreckage and witness reports, all indicated a sudden catastrophic in-flight breakup of TWA 800.
Possible causes of the in-flight breakup.
Investigators considered several possible causes for the structural breakup: structural failure and decompression, detonation of a high-energy explosive device, such as a missile warhead exploding either upon impact with the airplane, or just before impact, a bomb exploding inside the airplane, or a fuel/air explosion in the center wing fuel tank.
Structural failure and decompression.
Close examination of the wreckage revealed no evidence of structural faults such as fatigue, corrosion or mechanical damage that could have caused the in-flight breakup. It was also suggested that the breakup could have been initiated by an in-flight separation of the forward cargo door, but all evidence indicated that the door was closed and locked at impact. The NTSB concluded that "the in-flight breakup of TWA flight 800 was not initiated by a preexisting condition resulting in a structural failure and decompression."
Live missile or bomb detonation.
A review of recorded data from long-range and airport surveillance radars revealed multiple contacts of airplanes/objects in TWA 800's vicinity at the time of the accident. None of these contacts intersected TWA 800's position at any time. Attention was drawn to data from the Islip, New York, ARTCC facility that showed three tracks in the vicinity of TWA 800 that did not appear in any of the other radar data. None of these sequences intersected TWA 800's position at any time either. All the reviewed radar data showed no radar returns consistent with a missile or other projectile traveling toward TWA 800.
The NTSB addressed allegations that the Islip radar data showed groups of military surface targets converging in a suspicious manner in an area around the accident, and that a 30-knot radar track, never identified and 3 NM from the crash site, was involved in foul play, as evidenced by its failure to divert from its course and assist with the search and rescue operations. Military records examined by the NTSB showed no military surface vessels within 15 NM of TWA 800 at the time of the accident. In addition, the records indicated that the closest area scheduled for military use, warning area W-387A/B, was 160 NM south.
The NTSB reviewed the 30-knot target track to try to determine why it did not divert from its course and proceed to the area where the TWA 800 wreckage had fallen. TWA 800 was behind the target, and with the likely forward-looking perspective of the target's occupant(s), the occupants would not have been in a position to observe the aircraft's breakup and/or subsequent explosions/fireball(s). Additionally, it was unlikely that the occupants of the target track would have been able to hear the explosions over the sound of its engines and the noise of the hull traveling through water, even more so if the occupants were in an enclosed bridge or cabin. Further, review of the Islip radar data for other similar summer days and nights in 1999 indicated that the 30-knot track was consistent with normal commercial fishing, recreational, and/or cargo vessel traffic.
Trace amounts of explosive residue were detected on three samples of material from three separate locations of the recovered airplane wreckage (described by the FBI as a piece of canvas-like material and two pieces of a floor panel). These samples were submitted to the FBI's laboratory in Washington, D.C., which determined that one sample contained traces of cyclotrimethylenetrinitramine (RDX), another nitroglycerin, and the third a combination of RDX and pentaerythritol tetranitrate (PETN); these findings received much media attention at the time. In addition, the backs of several damaged passenger seats were observed to have an unknown red/brown-shaded substance on them. According to the seat manufacturer, the locations and appearance of this substance were consistent with adhesive used in the construction of the seats, and additional laboratory testing by NASA identified the substance as being consistent with adhesives.
Further examination of the airplane structure, seats, and other interior components found no damage typically associated with a high-energy explosion of a bomb or missile warhead ("severe pitting, cratering, petalling, or hot gas washing"). This included the pieces on which trace amounts of explosives were found. Of the 5 percent of the fuselage that was not recovered, none of the missing areas were large enough to have covered all the damage that would have been caused by the detonation of a bomb or missile. None of the victims' remains showed any evidence of injuries that could have been caused by high-energy explosives.
The NTSB considered the possibility that the explosive residue was due to contamination from the aircraft's use in 1991 transporting troops during the Gulf War or its use in a dog-training explosive detection exercise about one month before the accident. Testing conducted by the FAA's Technical Center indicated that residues of the type of explosives found on the wreckage would dissipate completely after 2 days of immersion in sea water (almost all recovered wreckage was immersed longer than 2 days). The NTSB concluded that it was "quite possible" that the explosive residue detected was transferred from military ships or ground vehicles, or the clothing and boots of military personnel, onto the wreckage during or after the recovery operation and was not present when the aircraft crashed into the water.
Although it was unable to determine the exact source of the trace amounts of explosive residue found on the wreckage, the lack of any other corroborating evidence associated with a high-energy explosion led the NTSB to conclude that "the in-flight breakup of TWA flight 800 was not initiated by a bomb or missile strike."
Fuel/air explosion in the center wing fuel tank.
In order to evaluate the sequence of structural breakup of the airplane, the NTSB formed the Sequencing Group, which examined individual pieces of the recovered structure, two-dimensional reconstructions or layouts of sections of the airplane, and various-sized three-dimensional reconstructions of portions of the airplane. In addition, the locations of pieces of wreckage at the time of recovery and differences in fire effects on pieces that are normally adjacent to each other were evaluated. The Sequencing Group concluded that the first event in the breakup sequence was a fracture in the wing center section of the aircraft, caused by an "overpressure event" in the center wing fuel tank (CWT). An overpressure event was defined as a rapid increase in pressure resulting in failure of the structure of the CWT.
Because there was no evidence that a high-energy explosive device detonated in this (or any other) area of the airplane, this overpressure event could only have been caused by a fuel/air explosion in the CWT. Some 50 gal of fuel were present in the CWT of TWA 800; tests recreating the conditions of the flight showed the combination of liquid fuel and fuel/air vapor to be flammable. A major reason for the flammability of the fuel/air vapor in the CWT of the 747 was the large amount of heat generated and transferred to the CWT by air conditioning packs located directly below the tank; with the CWT temperature raised to a sufficient level, a single ignition source could cause an explosion.
Computer modeling and scale model testing were used to predict and demonstrate how an explosion would progress in a 747 CWT. During this time, quenching was identified as an issue, where the explosion would extinguish itself as it passed through the complex structure of the CWT. Because the research data regarding quenching was limited, a complete understanding of quenching behavior was not possible, and the issue of quenching remained unresolved.
In order to better determine whether a fuel/air vapor explosion in the CWT would generate sufficient pressure to break apart the fuel tank and lead to the destruction of the airplane, tests were conducted in July and August 1997, using a retired Air France 747 at Bruntingthorpe Airfield, England. These tests simulated a fuel/air explosion in the CWT by igniting a propane/air mixture; this resulted in the failure of the tank structure due to overpressure. While the NTSB acknowledged that the test conditions at Bruntingthorpe were not fully comparable to the conditions that existed on TWA 800 at the time of the accident, previous fuel explosions in the CWTs of commercial airliners such as Avianca Flight 203 and Philippine Airlines Flight 143 confirmed that a CWT explosion could break apart the fuel tank and lead to the destruction of an airplane.
Ultimately, based on "the accident airplane's breakup sequence; wreckage damage characteristics; scientific tests and research on fuels, fuel tank explosions, and the conditions in the CWT at the time of the accident; and analysis of witness information," the NTSB concluded that "the TWA flight 800 in-flight breakup was initiated by a fuel/air explosion in the CWT."
In-flight breakup sequence and crippled flight.
Recovery locations of the wreckage from the ocean (the red, yellow, and green zones) clearly indicated that: (1) the red area pieces (from the forward portion of the wing center section and a ring of fuselage directly in front) were the earliest pieces to separate from the airplane; (2) the forward fuselage section departed simultaneously with or shortly after the red area pieces, landing relatively intact in the yellow zone; (3) the green area pieces (wings and the aft portion of the fuselage) remained intact for a period after the separation of the forward fuselage, and impacted the water in the green zone.
Fire damage and soot deposits on the recovered wreckage indicated that some areas of fire existed on the airplane as it continued on in crippled flight after the loss of the forward fuselage. After about 34 seconds (based on information from witness documents), the outer portions of both the right and left wings failed. Shortly after, the left wing separated from what remained of the main fuselage, which resulted in further development of the fuel-fed fireballs as the pieces of wreckage fell to the ocean.
Only the FAA radar facility in North Truro, Massachusetts, using specialized processing software from the United States Air Force 84th Radar Evaluation Squadron, was capable of estimating the altitude of TWA 800 after it lost power due to the CWT explosion. Because of accuracy limitations, this radar data could not be used to determine whether the aircraft climbed after the nose separated. Instead, the NTSB conducted a series of computer simulations to examine the flightpath of the main portion of the fuselage. Hundreds of simulations were run using various combinations of possible times the nose of TWA 800 separated (the exact time was unknown), different models of the behavior of the crippled aircraft (the aerodynamic properties of the aircraft without its nose could only be estimated), and longitudinal radar data (the recorded radar tracks of the east/west position of TWA 800 from various sites differed). These simulations indicated that after the loss of the forward fuselage the remainder of the aircraft continued on in crippled flight, then pitched up while rolling to the left (north), climbing to a maximum altitude between 15537 and from its last recorded altitude, 13760 ft.
Analysis of reported witness observations.
At the start of FBI's investigation, because of the possibility that international terrorists might have been involved, assistance was requested from the Central Intelligence Agency (CIA). CIA analysts, relying on sound-propagation analysis, were able to conclude that the witnesses could not be describing a missile approaching an intact aircraft, but were seeing a trail of burning fuel coming from the aircraft after the initial explosion. This conclusion was reached after calculating how long it took for the sound of the initial explosion to reach the witnesses, and using that to correlate the witness observations with the accident sequence. In all cases the witnesses could not be describing a missile approaching an intact aircraft, as the plane had already exploded before their observations began.
As the investigation progressed, the NTSB decided to form a witness group to more fully address the accounts of witnesses. From November 1996, through April 1997, this group reviewed summaries of witness accounts on loan from the FBI (with personal information redacted), and conducted interviews with crewmembers from a New York Air National Guard HH-60 helicopter and C-130 airplane, as well as a U.S. Navy P-3 airplane that were flying in the vicinity of TWA 800 at the time of the accident.
In February 1998, the FBI, having closed its active investigation, agreed to fully release the witness summaries to the NTSB. With access to these documents no longer controlled by the FBI, the NTSB formed a second witness group to review the documents. Because of the amount of time that had elapsed (about 21 months) before the NTSB received information about the identity of the witnesses, the witness group chose not to re-interview the witnesses, but instead to rely on the original summaries of witness statements FBI written by FBI agents as the best available evidence of the observations initially reported by the witnesses. Despite the two and a half years that had elapsed since the accident, the witness group did interview the captain of Eastwind Airlines flight 507, who was the first to report the explosion of TWA 800, because of his vantage point and experience as an airline pilot.
The NTSB's review of the released witness documents determined that they contained 736 witness accounts, of which 258 were characterized as "streak of light" witnesses ("an object moving in the sky...variously described [as] a point of light, fireworks, a flare, a shooting star, or something similar.") The NTSB Witness Group concluded that the streak of light reported by witnesses might have been the actual airplane during some stage of its flight before the fireball developed, noting that most of the 258 streak of light accounts were generally consistent with the calculated flightpath of the accident airplane after the CWT explosion.
38 witnesses described a streak of light that ascended vertically, or nearly so, and these accounts "seem[ed] to be inconsistent with the accident airplane's flightpath." In addition, 18 witnesses reported seeing a streak of light that originated at the surface, or the horizon, which did not "appear to be consistent with the airplane's calculated flightpath and other known aspects of the accident sequence." Regarding these differing accounts, the NTSB noted that based on their experience in previous investigations "witness reports are often inconsistent with the known facts or with other witnesses' reports of the same events." The interviews conducted by the FBI focused on the possibility of a missile attack; suggested interview questions given to FBI agents such as "Where was the sun in relation to the aircraft and the missile launch point?" and "How long did the missile fly?" could have biased interviewees' responses in some cases. The NTSB concluded that given the large number of witnesses in this case, they "did not expect all of the documented witness observations to be consistent with one another." and "did not view these apparently anomalous witness reports as persuasive evidence that some witnesses might have observed a missile."
After missile visibility tests were conducted in April 2000, at Eglin Air Force Base, Fort Walton Beach, Florida, the NTSB determined that if witnesses had observed a missile attack they would have seen: (1) a light from the burning missile motor ascending very rapidly and steeply for about 8 seconds; (2) the light disappearing for up to 7 seconds; (3) upon the missile striking the aircraft and igniting the CWT another light, moving considerably more slowly and more laterally than the first, for about 30 seconds; (4) this light descending while simultaneously developing into a fireball falling toward the ocean. None of the witness documents described such a scenario.
Because of their unique vantage points and/or the level of precision and detail provided in their accounts, five witness accounts generated special interest: the pilot of Eastwind Airlines flight 507, the crew members in the HH-60 helicopter, a streak-of-light witness aboard US Airways flight 217, a land witness on the Beach Lane Bridge in Westhampton Beach, New York as well as a witness on a boat near Great Gun Beach. Advocates of a missile-attack scenario asserted that some of these witnesses observed a missile; Analysis demonstrated that the observations were not consistent with a missile attack on TWA 800, but instead were consistent with these witnesses having observed some part of the in-flight fire and breakup sequence after the CWT explosion.
The NTSB concluded that "the witness observations of a streak of light were not related to a missile and that the streak of light reported by most of these witnesses was burning fuel from the accident airplane in crippled flight during some portion of the post-explosion, preimpact breakup sequence". The NTSB further concluded that "the witnesses' observations of one or more fireballs were of the airplane's burning wreckage falling toward the ocean".
Possible ignition sources of the center wing fuel tank.
In an attempt to determine what ignited the flammable fuel/air vapor in the CWT and caused the explosion, the NTSB evaluated numerous potential ignition sources. All but one were considered very unlikely to have been the source of ignition.
Missile fragment or small explosive charge.
Although the NTSB had already reached the conclusion that a missile strike did not cause the structural failure of the airplane, the possibility that a missile could have exploded close enough to TWA 800 for a missile fragment to have entered the CWT and ignited the fuel/air vapor, yet far enough away not to have left any damage characteristic of a missile strike, was considered. Computer simulations using missile performance data simulated a missile detonating in a location such that a fragment from the warhead could penetrate the CWT. Based on these simulations the NTSB concluded that it was "very unlikely" that a warhead detonated in such a location where a fragment could penetrate the CWT, but no other fragments impact the surrounding airplane structure leaving distinctive impact marks.
Similarly, the investigation considered the possibility that a small explosive charge placed on the CWT could have been the ignition source. Testing by the NTSB and the British Defence Evaluation and Research Agency demonstrated that when metal of the same type and thickness of the CWT was penetrated by a small charge, there was petalling of the surface where the charge was placed, pitting on the adjacent surfaces, and visible hot gas washing damage in the surrounding area. Since none of the recovered CWT wreckage exhibited these damage characteristics, and none of the areas of missing wreckage were large enough to encompass all the expected damage, the investigation concluded that this scenario was "very unlikely."
Other potential sources.
The NTSB also investigated whether the fuel/air mixture in the CWT could have been ignited by lightning strike, meteor strike, auto-ignition or hot surface ignition, a fire migrating to the CWT from another fuel tank via the vent system, an uncontained engine failure, a turbine burst in the air conditioning packs beneath the CWT, a malfunctioning CWT jettison/override pump, a malfunctioning CWT scavenger pump, or static electricity. After analysis the investigation determined that these potential sources were "very unlikely" to have been the source of ignition.
Fuel quantity indication system.
Because a combustible fuel/air mixture will always exist in fuel tanks, Boeing designers had attempted to eliminate all possible sources of ignition in the 747's tanks. To do so, all devices are protected from vapor intrusion, and voltages and currents used by the Fuel Quantity Indication System (FQIS) are kept very low. In the case of the 747-100 series, the only wiring located inside the CWT is that which is associated with the FQIS.
In order for the FQIS to have been Flight 800's ignition source, a transfer of higher-than-normal voltage to the FQIS would have needed to occur, as well as some mechanism whereby the excess energy was released by the FQIS wiring into the CWT. While the NTSB determined that factors suggesting the likelihood of a short circuit event existed, they added that "neither the release mechanism nor the location of the ignition inside the CWT could be determined from the available evidence." Nonetheless, the NTSB concluded that "the ignition energy for the CWT explosion most likely entered the CWT through the FQIS wiring."
Though the FQIS itself was designed to prevent danger by minimizing voltages and currents, the innermost tube of Flight 800's FQIS compensator showed damage similar to that of the compensator tube identified as the ignition source for the surge tank fire that destroyed a 747 near Madrid in 1976. This was not considered proof of a source of ignition. Evidence of arcing was found in a wire bundle that included FQIS wiring connecting to the center wing tank. Arcing signs were also seen on two wires sharing a cable raceway with FQIS wiring at station 955.
The captain's cockpit voice recorder channel showed two "dropouts" of background power harmonics in the second before the recording ended (with the separation of the nose). This might well be the signature of an arc on cockpit wiring adjacent to the FQIS wiring. The captain commented on the "crazy" readings of the number 4 engine fuel flow gauge about 2 1/2 minutes before the CVR recording ended. Finally, the Center Wing Tank fuel quantity gauge was recovered and indicated 640 pounds instead of the 300 pounds that had been loaded into that tank. Experiments showed that applying power to a wire leading to the fuel quantity gauge can cause the digital display to change by several hundred pounds before the circuit breaker trips. Thus the gauge anomaly could have been caused by a short to the FQIS wiring. The NTSB concluded that the most likely source of sufficient voltage to cause ignition was a short from damaged wiring, or within electrical components of the FQIS. As not all components and wiring were recovered, it was not possible to pinpoint the source of the necessary voltage.
Conclusions.
The NTSB investigation ended with the adoption of its final report on August 23, 2000. In it the Board determined that the probable cause of the TWA 800 accident was:
[An] explosion of the center wing fuel tank (CWT), resulting from ignition of the flammable fuel/air mixture in the tank. The source of ignition energy for the explosion could not be determined with certainty, but, of the sources evaluated by the investigation, the most likely was a short circuit outside of the CWT that allowed excessive voltage to enter it through electrical wiring associated with the fuel quantity indication system.
In addition to the probable cause, the NTSB found the following contributing factors to the accident:
During the course of its investigation, and in its final report, the NTSB issued fifteen safety recommendations, mostly covering fuel tank and wiring-related issues. Among the recommendations was that significant consideration should be given to the development of modifications such as nitrogen-inerting systems for new airplane designs and, where feasible, for existing airplanes.
Controversy.
The NTSB's conclusions about the cause of the TWA 800 disaster took four years and one month to be published. The FBI's earliest investigations and interviews, later used by the NTSB, were performed under the assumption of a missile attack, a fact noted in the NTSB's final report. Six months into the investigation, the NTSB's chairman, Jim Hall, was quoted as saying, "All three theories—a bomb, a missile, or mechanical failure—remain." Speculation was fueled in part by early descriptions, visuals and eyewitness accounts of the disaster that indicated a sudden explosion and trails of fire in the sky moving in an upward direction.
The two most prevalent conspiracy theories concerning Flight 800 involve a terrorist bomb on board or a missile strike (attributed by some to American armed forces). Supporters of these explanations claim that the NTSB's report was created as a cover-up, that the NTSB did not investigate sufficiently, or that the NTSB did not have all the evidence it needed to reach the correct conclusion.
On July 17, 2013, the 17th anniversary of the tragedy, the Epix premium TV channel aired the documentary "TWA Flight 800," which alleges that the crash investigation was a cover-up. The film highlights extensive eyewitness interviews, with many interviewees directly objecting to publicly described versions of their own descriptions of events. It also highlights interviews with investigators who had been involved in the original inquest, six of whom had filed a petition to reopen the probe. Their petition was based on eyewitness accounts, radar evidence indicating a possible missile and claims of evidence tampering. They dubbed it "The TWA 800 Project". Former NTSB investigator Henry Hughes has been quoted that he believes a bomb or a missile caused the crash.
To consider the petition, the NTSB assembled a team of investigators not previously involved with the original investigation. On July 2, 2014, the NTSB said it would not reconsider its finding that the crash was caused by a fuel tank explosion. In a press release they stated: "After a thorough review of all the information provided by the petitioners, the NTSB denied the petition in its entirety because the evidence and analysis presented did not show the original findings were incorrect."
Aftermath.
Many Internet users responded to the incident; the resulting web traffic set records for Internet activity at the time. CNN's traffic quadrupled to 3.9 million hits per day. After the tragedy, the website of "The New York Times" saw its traffic increase to 1.5 million hits per day, 50% higher than its previous rate. In 1996, few U.S. government websites were updated daily, but the United States Navy's crash website was constantly updated and had detailed information about the salvage of the crash site.
The wreckage is permanently stored in an NTSB facility in Ashburn, Loudoun County, Virginia that was custom-built for the purpose. The reconstructed aircraft is used to train accident investigators.
On July 18, 2008, the Secretary of Transportation visited the facility and announced a final rule designed to prevent accidents caused by fuel-tank explosions. The rule would require airlines to pump inert gas into the tanks, and will cover all new passenger and cargo airliners, and passenger planes built in most of the 1990s, but not old cargo planes. The NTSB had first recommended such a rule just five months after the incident and 33 years after a similar recommendation issued by the Civil Aeronautics Board Bureau of Safety on December 17, 1963, nine days after the crash of Pan Am Flight 214.
The crash of TWA Flight 800, and that of ValuJet Flight 592 earlier in 1996, prompted Congress to pass the Aviation Disaster Family Assistance Act of 1996 as part of the federal aviation appropriations bill. Among other things, the Act gives NTSB, instead of the particular airline involved, responsibility for coordinating services to the families of victims of fatal aircraft accidents in the United States. In addition, it restricts lawyers and other parties from contacting family members within 30 days of the accident.
During the investigation, the NTSB and the FBI clashed with each other many times. The agencies needed a detailed protocol describing which agency takes the lead when it is initially unclear whether an event is an accident or a criminal act. 49 Code of Federal Regulations 831.5 specified in 1996 (as it does now) that the NTSB’s aviation accident investigations have priority over all other federal investigations. However, after the TWA flight 800 investigation, the NTSB recognized the need for better clarity. The NTSB sought and secured language to clarify the issue in 49 USC 1131(a)(2)(B), which was amended in 2000 to read: 
If the Attorney General, in consultation with the Chairman of the [NTSB], determines and notifies the [NTSB] that circumstances reasonably indicate that the accident may have been caused by an intentional criminal act, the [NTSB] shall relinquish investigative priority to the [FBI]. The relinquishment of investigative priority by the [NTSB] shall not otherwise affect the authority of the [NTSB] to continue its investigation under this section
https://twa800.sites.usa.gov/improvements/
In 2005, the NTSB and the FBI entered into a Memorandum of Understanding (MOU) that states that, “[i]n the immediate aftermath of a transportation accident, the NTSB is the presumptive lead investigative agency and will assume control of the accident scene.” The FBI may still conduct a criminal investigation, but the NTSB investigation has priority. When investigative priority remains with the NTSB, the FBI must coordinate its investigative activities with the NTSB investigator-in-charge. This authority includes interviewing witnesses. The MOU states that: “[t]his procedure is intended…to ensure that neither NTSB nor FBI investigative activity unnecessarily complicates or compromises the other agency’s investigation. The new statutory language and the MOU have improved coordination between the NTSB and FBI since the TWA flight 800 accident. Today, FBI and NTSB personnel conduct joint exercises. They can call upon one another’s laboratories and other assets. The NTSB and the FBI have designated liaisons to ensure that information flows between agencies, and to coordinate on-scene operations.
Heidi Snow, the fiancée of TWA800 victim Michel Breistroff, established the AirCraft Casualty Emotional Support Services (ACCESS) nonprofit group together with Pan Am Flight 103 victims.
International Memorial.
The TWA Flight 800 International Memorial was dedicated in a 2 acre parcel immediately adjoining the main pavilion at Smith Point County Park in Shirley, New York, on July 14, 2004. The memorial is located at . Funds for the memorial were raised by the Families of TWA Flight 800 Association. David Busch of Busch Associates in Bay Shore, New York designed the memorial. The memorial includes landscaped grounds, flags from the 13 countries of the victims, and a curved black granite memorial with the names engraved on one side and an illustration on the other of a wave releasing 230 seagulls into the sky. In July 2006, an abstract design of a 10 ft high lighthouse in black granite designed by Harry Edward Seaman, who had lost his cousin in the crash, was added. The lighthouse sits above a tomb holding many of the victims' personal belongings.
Passengers and crew.
There were 230 people on board TWA 800 including 18 crew and 20 off-duty employees, most of whom were crew meant to cover the Paris-Rome leg of the flight.
Of the 230 people on board there were individuals from the United States, Denmark, Belgium, Algeria, Israel, Portugal, Germany, and the United Kingdom.
Some of the notable passengers who died included:

</doc>
<doc id="30659" url="http://en.wikipedia.org/wiki?curid=30659" title="Triangulum">
Triangulum

Triangulum is a small constellation in the northern sky. Its name is Latin for "triangle", derived from its three brightest stars, which form a long and narrow triangle. Known to the ancient Babylonians and Greeks, Triangulum was one of the 48 constellations listed by the 2nd century astronomer Ptolemy. The celestial cartographers Johann Bayer and John Flamsteed catalogued the constellation's stars, giving six of them Bayer designations.
The white stars Beta and Gamma Trianguli, of apparent magnitudes 3.00 and 4.00, respectively, form the base of the triangle and the yellow-white Alpha Trianguli, of magnitude 3.41, the apex. Iota Trianguli is a notable double star system, and there are three star systems with planets located in Triangulum. The constellation contains several galaxies, the brightest and nearest of which is the Triangulum Galaxy or Messier 33 —a member of the Local Group. The first quasar ever observed, 3C 48, also lies within Triangulum's boundaries.
History and mythology.
In the Babylonian star catalogues, Triangulum, together with Gamma Andromedae, formed the constellation known as MULAPIN (𒀯𒀳) "The Plough". It is notable as the first constellation presented on (and giving its name to) a pair of tablets containing canonical star lists that were compiled around 1000 BC, the MUL.APIN. The Plough was the first constellation of the "Way of Enlil"—that is, the northernmost quarter of the Sun's path, which corresponds to the 45 days on either side of summer solstice. Its first appearance in the pre-dawn sky (heliacal rising) in February marked the time to begin spring ploughing in Mesopotamia.
The Ancient Greeks called Triangulum "Deltoton" (Δελτωτόν), as the constellation resembled an upper-case Greek letter delta (Δ). It was transliterated by Roman writers, then later Latinised as Deltotum. Eratosthenes linked it with the Nile Delta, while the Roman writer Hyginus associated it with the triangular island of Sicily, formerly known as Trinacria due to its shape. It was also called "Sicilia", because the Romans believed Ceres, patron goddess of Sicily, begged Jupiter to place the island in the heavens. Greek astronomers such as Hipparchos and Ptolemy called it "Trigonon" (Τρίγωνον), and later, it was Romanized as Trigonum. Other names referring to its shape include Tricuspis and Triquetrum. Alpha and Beta Trianguli were called "Al Mīzān", which is Arabic for "The Scale Beam". In Chinese astronomy, Gamma Andromedae and neighbouring stars including Beta, Gamma and Delta Trianguli were called "Teen Ta Tseang Keun" (天大将军, "Heaven's great general"), representing honour in astrology and a great general in mythology.
Later, the 17th-century German celestial cartographer Johann Bayer called the constellation Triplicitas and Orbis terrarum tripertitus, for the three regions Europe, Asia, and Africa. Triangulus Septentrionalis was a name used to distinguish it from Triangulum Australe, the Southern Triangle. Polish astronomer Johannes Hevelius excised three faint stars— 6, 10 and 12 Trianguli—to form the new constellation of Triangulum Minus in his 1690 "Firmamentum Sobiescianum", renaming the original as Triangulum Majus. The smaller constellation was not recognised by the International Astronomical Union (IAU) when the constellations were established in the 1920s.
Characteristics.
A small constellation, Triangulum is bordered by Andromeda to the north and west, Pisces to the west and south, Aries to the south, and Perseus to the east. The centre of the constellation lies half way between Gamma Andromedae and Alpha Arietis. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is 'Tri'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined as a polygon of 14 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 01h 31.3m and 02h 50.4m, while the declination coordinates are between 25.60° and 37.35°. Covering 132 square degrees and 0.320% of the night sky, Triangulum ranks 78th of the 88 constellations in size.
Notable features.
Bayer catalogued five stars in the constellation, giving them the Bayer designations Alpha to Epsilon. John Flamsteed added Eta, Iota and four Roman letters; of these, only Iota is still used as the others were dropped in subsequent catalogues and star charts. Flamsteed gave 16 stars Flamsteed designations, of which numbers 1 and 16 are not used—1's coordinates were in error as there was no star present at the location that corresponds to any star in his "Catalogus Britannicus"; Baily presumed that the coordinates were mistranscribed 32s in error by Flamsteed and in fact referred to 7.4 magnitude HD 10407. Baily also noted that 16 Trianguli was closer to Aries and included it in the latter constellation.
Stars.
Three stars make up the long narrow triangle that gives the constellation its name. The brightest member is the white giant star Beta Trianguli of apparent magnitude 3.00, lying 127 light-years distant from Earth. It is actually a spectroscopic binary system; the primary is a white star of spectral type A5IV with 3.5 times the mass of our sun that is beginning to expand and evolve off the main sequence. The secondary is poorly known, but calculated to be a yellow-white F-type main-sequence star around 1.4 solar masses. The two orbit around a common centre of gravity every 31 days, and are surrounded by a ring of dust that extends from 50 to 400 AU away from the stars.
The second-brightest star, the yellow-white subgiant star Alpha Trianguli (3.41m) with a close dimmer companion, is also known as Caput Trianguli or Ras al Muthallath, and is at the apex of the triangle. It lies around 7 degrees north-northwest of Alpha Arietis. Making up the triangle is Gamma Trianguli, a white main sequence star of spectral type A1Vnn of apparent magnitude 4.00 about 112 light-years from Earth. It is around double the size of and around 33 times as luminous as the sun and rotates rapidly. Like Beta, it is surrounded by a dusty debris disk, which has a radius 80 times the distance of the Earth from the Sun. Lying near Gamma and forming an optical triple system with it are Delta and 7 Trianguli. Delta is a spectroscopic binary system composed of two yellow main sequence stars of similar dimensions to the Sun that lies 35 light-years from Earth. The two stars orbit each other every ten days and are a mere 0.1 AU apart. This system is the closest in the constellation to the Earth. Only of magnitude 5.25, 7 Trianguli is much further away at around 280 light-years distant from Earth.
Iota Trianguli is a double star whose components can be separated by medium-sized telescopes into a strong yellow and a contrasting pale blue star. Both of these are themselves close binaries. X Trianguli is an eclipsing binary system that ranges between magnitudes 8.5 and 11.2 over a period of 0.97 days. RW Trianguli is a cataclysmic variable star system composed of a white dwarf primary and an orange main sequence star of spectral type K7 V. The former is drawing off matter from the latter, forming a prominent accretion disc. The system is around 1075 light-years distant.
R Trianguli is a long period (Mira) variable that ranges from magnitude 6.2 to 11.7 over a period of 267 days. It is a red giant of spectral type M3.5-8e, lying around 960 light-years away. HD 12545, also known as XX Trianguli, is
an orange giant of spectral type K0III around 520 light-years distant with a visual magnitude of 8.42. A huge starspot larger than the diameter of the sun was detected on its surface in 1999 by astronomers using Doppler imaging.
Three star systems appear to have planets. HD 9446 is a sun-like star around 171 light-years distant that has two planets of masses 0.7 and 1.8 times that of Jupiter, with orbital periods of 30 and 193 days respectively. WASP-56 is a sun-like star of spectral type G6 and apparent magnitude 11.48 with a planet 0.6 the mass of Jupiter that has a period of 4.6 days. HD 13189 is an orange giant of spectral type K2II about 2–7 times as massive as the sun with a planetary or brown dwarf companion between 8 and 20 times as massive as Jupiter, which takes 472 days to complete an orbit. It is one of the largest stars discovered to have a planetary companion.
Deep-sky objects.
The Triangulum Galaxy, also known as Messier 33, was discovered by Giovanni Battista Hodierna in the 1600s. A distant member of the Local Group, it is about 2.3 million light-years away, and at magnitude 5.8 it is bright enough to be seen by the naked eye under the darkest skies. Under light-polluted skies, it is challenging or invisible even in a small telescope or binoculars. Because of its low surface brightness, low power is required. It is a spiral galaxy with a diameter of 46,000 light-years and is thus smaller than both the Andromeda Galaxy and the Milky Way. A distance of less than 300 kiloparsecs between it and Andromeda supports the hypothesis that it is a satellite of the larger galaxy. Within the constellation, it lies near the border of Pisces, 3.5 degrees west-northwest of Alpha Trianguli and 7 degrees southwest of Beta Andromedae. Within the galaxy, NGC 604 is an H II region where star formation takes place.
In addition to M33, there are several NGC galaxies of visual magnitudes 12 to 14. The largest of these include the 10 arcminute long magnitude 12 NGC 925 spiral galaxy and the 5 arcminute long magnitude 11.6 NGC 672 barred spiral galaxy. The latter is close by and appears to be interacting with IC 1727. The two are 88,000 light-years apart and lie around 18 million light-years away. These two plus another four nearby dwarf irregular galaxies constitute the NGC 672 group, and all six appear to have had a burst of star formation in the last ten million years. The group is thought connected to another group of six galaxies known as the NGC 784 group, named for its principal galaxy, the barred spiral NGC 784. Together with two isolated dwarf galaxies, these fourteen appear to be moving in a common direction and constitute a group possibly located on a dark matter filament. 3C 48 was the first quasar ever to be observed, although its true identity was not uncovered until after that of 3C 273 in 1963. It has an apparent magnitude of 16.2 and is located about 5 degrees northwest of Alpha Trianguli.
References.
Coordinates: 

</doc>
<doc id="30660" url="http://en.wikipedia.org/wiki?curid=30660" title="Tucana">
Tucana

Tucana is a constellation of stars in the southern sky, named after the toucan, a South American bird. It is one of twelve constellations conceived in the late sixteenth century by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. Tucana first appeared on a 35-cm (14 in) diameter celestial globe published in 1598 in Amsterdam by Plancius and Jodocus Hondius and was depicted in Johann Bayer's star atlas "Uranometria" of 1603. French explorer and astronomer Nicolas Louis de Lacaille gave its stars Bayer designations in 1756. The constellations Tucana, Grus, Phoenix and Pavo are collectively known as the "Southern Birds".
Tucana is not a prominent constellation as all of its stars are third magnitude or fainter; the brightest is Alpha Tucanae with an apparent visual magnitude of 2.87. Beta Tucanae is a star system with six member stars, while Kappa is a quadruple system. Five star systems have been found to have exoplanets to date. The constellation contains 47 Tucanae, one of the brightest globular clusters in the sky, and most of the Small Magellanic Cloud.
History.
Tucana is one of the twelve constellations established by the Dutch astronomer Petrus Plancius from the observations of the southern sky by the Dutch explorers Pieter Dirkszoon Keyser and Frederick de Houtman, who had sailed on the first Dutch trading expedition, known as the "Eerste Schipvaart", to the East Indies. It first appeared on a 35-cm (14 in) diameter celestial globe published in 1598 in Amsterdam by Plancius with Jodocus Hondius. The first depiction of this constellation in a celestial atlas was in the German cartographer Johann Bayer's "Uranometria" of 1603. Both Plancius and Bayer depict it as a toucan. De Houtman included it in his southern star catalogue the same year under the Dutch name "Den Indiaenschen Exster, op Indies Lang ghenaemt" "the Indian magpie, named Lang in the Indies", by this meaning a particular bird with a long beak—a hornbill, a bird native to the East Indies. A 1603 celestial globe by Willem Blaeu depicts it with a casque. It was interpreted on Chinese charts as "Neaou Chuy" "beak bird", and in England as "Brasilian Pye", while Johannes Kepler and Giovanni Battista Riccioli termed it "Anser Americanus" "American Goose", and Caesius as "Pica Indica". Tucana and the nearby constellations Phoenix, Grus and Pavo are collectively called the "Southern Birds".
Characteristics.
Irregular in shape, Tucana is bordered by Hydrus to the east, Grus and Phoenix to the north, Indus to the west and Octans to the south. Covering 295 square degrees, it ranks 48th of the 88 constellations in size. The recommended three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Tuc'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 10 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 22h 08.45m and 01h 24.82m, while the declination coordinates are between −56.31° and −75.35°. As one of the deep southern constellations, it remains below the horizon at latitudes north of the 30th parallel in the Northern Hemisphere, and is circumpolar at latitudes south of the 50th parallel in the Southern Hemisphere.
Notable features.
Stars.
Although he depicted Tucana on his chart, Bayer did not assign its stars Bayer designations. French explorer and astronomer Nicolas Louis de Lacaille labelled them Alpha to Rho in 1756, but omitted Omicron and Xi, and labelled a pair of stars close together Lambda Tucanae, and a group of three stars Beta Tucanae. In 1879, American astronomer Benjamin Gould designated a star Xi Tucanae—this had not been given a designation by Lacaille who had recognized it as nebulous, and it is now known as the globular cluster 47 Tucanae. Mu Tucanae was dropped by Francis Baily, who felt the star was too faint to warrant a designation, and Kappa's two components came to be known as Kappa1 and Kappa2.
The layout of the brighter stars of Tucana has been likened to a kite. Within the constellation's boundaries are around 80 stars brighter than an apparent magnitude of 7. At an apparent magnitude of 2.86, Alpha Tucanae is the brightest star in the constellation and marks the toucan's head. It is an orange subgiant of spectral type K3III around 199 light-years distant from our Solar System. A cool star with a surface temperature of 4300 K, it is 424 times as luminous as the sun and 37 times its diameter. It is 2.5 to 3 times as massive. Alpha Tucanae is a spectroscopic binary, which means that the two stars have not been individually resolved using a telescope, but the presence of the companion has been inferred from measuring changes in the spectrum of the primary. The orbital period of the binary system is 4197.7 days (11.5 years). Nothing is known about the companion. Two degrees southeast of Alpha is the red-hued Nu Tucanae, of spectral type M4III and lying around 290 light-years distant. It is classified as a semiregular variable star and its brightness varies from magnitude +4.75 to +4.93. Described by Richard Hinckley Allen as bluish, Gamma Tucanae is a yellow-white sequence star of spectral type F4V and an apparent magnitude of 4.00 located around 75 light-years from Earth. It also marks the toucan's beak.
Beta, Delta and Kappa are multiple star systems containing six, two and four stars respectively. Located near the tail of the toucan, Beta Tucanae's two brightest components, Beta1 and Beta2 are separated by an angle of 27 arcseconds and have apparent magnitudes of 4.4 and 4.5 respectively. They can be separated in small telescopes. A third star, Beta3 Tucanae, is separated by 10 arcminutes from the two, and able to be seen as a separate star with the unaided eye. Each star is itself a binary star, making six in total. Lying in the southwestern corner of the constellation around 251 light-years away from Earth, Delta Tucanae consists of a blue-white primary contrasting with a yellowish companion. Delta Tucanae A is a main sequence star of spectral type B9.5V and an apparent magnitude of 4.49. The companion has an apparent magnitude of 9.3. The Kappa Tucanae system shines with an combined apparent magnitude of 4.25, and is located around 68 light-years from our Solar System. The brighter component is a yellowish star, known as Kappa Tucanae A with an apparent magnitude of 5.33 and spectral type F6V, while the fainter lies 5 arcseconds to the northwest. Known as Kappa Tucanae B, it has an apparent magnitude of 7.58 and spectral type K1V. Five arcminutes to the northwest is a fainter star of apparent magnitude 7.24 —actually a pair of orange main sequence stars of spectral types K2V and K3V, which can be seen individually as stars one arcsecond apart with a telescope such as a Dobsonian with high power.
Lambda Tucanae is an optical double—that is, the name is given to two stars (Lambda1 and Lambda2) which appear close together from our viewpoint, but are in fact far apart in space. Lambda1 is itself a binary star, with two components—a yellow-white star of spectral type F7IV-V and an apparent magnitude of 6.22, and a yellow main sequence star of spectral type G1V and an apparent magnitude of 7.28. The system is 186 light-years distant. Lambda2 is an orange subgiant of spectral type K2III that is expanding and cooling and has left the main sequence. Of apparent magnitude 5.46, it is approximately 220 light-years distant from Earth.
Epsilon Tucanae traditionally marks the toucan's left leg. A B-type subgiant, it has a spectral type B9IV and an apparent magnitude of 4.49. It is approximately 373 light-years from Earth. It is around four times as massive as our Sun.
Theta Tucanae is a white A-type star around 423 light-years distant from Earth, which is actually a close binary system. The main star is classified as a Delta Scuti variable—a class of short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. It is around double the Sun's mass, having siphoned off one whole solar mass from its companion, now a hydrogen-depleted dwarf star of around only 0.2 solar masses. The system shines with a combined light that varies between magnitudes 6.06 to 6.15 every 70 to 80 minutes.
Zeta Tucanae is a yellow-white main sequence star of spectral type F9.5V and an apparent magnitude of 4.20 located 28 light-years away from our Solar System. Despite having a slightly lower mass, this star is more luminous than the Sun. The composition and mass of this star are very similar to the Sun, with a slightly lower mass and an estimated age of three billion years. The solar-like qualities make it a target of interest for investigating the possible existence of a life-bearing planet. It appears to have a debris disk orbiting it at a minimum radius of 2.3 astronomical units. As of 2009, no planet has been discovered in orbit around this star.
Five star systems have been found to have planets, four of which have been discovered by the High Accuracy Radial Velocity Planet Searcher (HARPS) in Chile. HD 4308 is a star with around 83% of the Sun's mass located 72 light-years away with a super-Earth planet with an orbital period of around 15 days. HD 215497 is an orange star of spectral type K3V around 142 light-years distant. It is orbited by a hot super-Earth every 3 days and a second planet around the size of Saturn with a period of around 567 days. HD 221287 has a spectral type of F7V and lies 173 light-years away, and has a super-Jovian planet. HD 7199 has spectral type KOIV/V and is located 117 light-years away. It has a planet with around 30% the mass of Jupiter that has an orbital period of 615 days. HD 219077 has a planet around 10 times as massive as Jupiter in a highly eccentric orbit.
Deep-sky objects.
The second-brightest globular cluster in the sky after Omega Centauri, 47 Tucanae (NGC 104) lies just west of the Small Magellanic Cloud. Only 14,700 light-years distant from Earth, it is thought to be around 12 billion years old. Mostly composed of old, yellow stars, it does possess a contingent of blue stragglers, hot stars that are hypothesized to form from binary star mergers. 47 Tucanae has an apparent magnitude of 3.9, meaning that it is visible to the naked eye; it is a Shapley class III cluster, which means that it has a clearly defined nucleus. Nearby globular clusters are the diminutive NGC 121, 10 arcminutes away from the bigger cluster's edge, and Lindsay 8.
NGC 362 is another globular cluster in Tucana with an apparent magnitude of 6.4, 27,700 light-years from Earth. Like neighboring 47 Tucanae, NGC 362 is a Shapley class III cluster and among the brightest globular clusters in the sky. Unusually for a globular cluster, its orbit takes it very close to the center of the Milky Way—approximately 3,000 light-years. It was discovered in the 1820s by James Dunlop. Its stars become visible at 180x magnification through a telescope.
Located at the southern end of Tucana, the Small Magellanic Cloud is a dwarf galaxy that is one of the nearest neighbors to the Milky Way galaxy at a distance of 210,000 light-years. Though it probably formed as a disk shape, tidal forces from the Milky Way have distorted it. Along with the Large Magellanic Cloud, it lies within the Magellanic Stream, a cloud of gas that connects the two galaxies. NGC 346 is a star-forming region located in the Small Magellanic Cloud. It has an apparent magnitude of 10.3. Within it lies the triple star system HD 5980, each of its members among the most luminous stars known.
The Tucana Dwarf galaxy, which was discovered in 1990, is a dwarf spheroidal galaxy of type dE5 that is an isolated member of our Local Group. It is located 870 kpc from our Solar System and around 1100 kpc from the barycentre of the Local Group—the second most remote of all member galaxies after the Sagittarius Dwarf Irregular Galaxy.
The barred spiral galaxy NGC 7408 is located 3 degrees northwest of Delta Tucanae, and was initially mistaken for a planetary nebula.
In 1998, part of the constellation was the subject of a two-week observation program by the Hubble Space Telescope, which resulted in the Hubble Deep Field South. The potential area to be covered needed to be at the poles of the telescope's orbit for continuous observing, with the final choice resting upon the discovery of a quasar, QSO J2233-606, in the field.
External links.
Coordinates: 

</doc>
<doc id="30662" url="http://en.wikipedia.org/wiki?curid=30662" title="Triangulum Australe">
Triangulum Australe

Triangulum Australe is a small constellation in the far southern celestial hemisphere. Its name is Latin for "the southern triangle", which distinguishes it from Triangulum in the northern sky and is derived from the almost equilateral pattern of its three brightest stars. It was first depicted on a celestial globe as Triangulus Antarcticus by Petrus Plancius in 1589, and later with more accuracy and its current name by Johann Bayer in his 1603 "Uranometria". The French explorer and astronomer Nicolas Louis de Lacaille charted and gave the brighter stars their Bayer designations in 1756.
Alpha Trianguli Australis, known as Atria, is a second magnitude orange giant and the brightest star in the constellation, as well as the 42nd-brightest star in the night sky. Completing the triangle are the two white main sequence stars Beta and Gamma Trianguli Australis. Although the constellation lies in the Milky Way and contains many stars, deep-sky objects are not prominent. Notable features include the open cluster NGC 6025 and planetary nebula NGC 5979.
History.
Italian navigator Amerigo Vespucci explored the New World at the beginning of the 16th century. He learnt to recognize the stars in the southern hemisphere and made a catalogue for his patron king Manuel I of Portugal, which is now lost. As well as the catalogue, Vespucci wrote descriptions of the southern stars, including a triangle which may be either Triangulum Australe or Apus. This was sent to his patron in Florence, Lorenzo di Pierfrancesco de' Medici, and published as "Mundus Novus" in 1504. The first depiction of the constellation was provided in 1589 by Flemish astronomer and clergyman Petrus Plancius on a 32½-cm diameter celestial globe published in Amsterdam by Dutch cartographer Jacob Floris van Langren, where it was called Triangulus Antarcticus and incorrectly portrayed to the south of Argo Navis. His student Petrus Keyzer, along with Dutch explorer Frederick de Houtman, coined the name Den Zuyden Trianghel. Triangulum Australe was more accurately depicted in Johann Bayer's celestial atlas "Uranometria" in 1603, where it was also given its current name.
Nicolas Louis de Lacaille portrayed the constellations of Norma, Circinus and Triangulum Australe as a set square and ruler, a compass, and a surveyor's level respectively in a set of draughtsman's instruments in his 1756 map of the southern stars. Also depicting it as a surveyor's level, German Johann Bode gave it the alternate name of Libella in his "Uranographia".
German poet and author Philippus Caesius saw the three main stars as representing the Three Patriarchs, Abraham, Isaac and Jacob (with Atria as Abraham). The Wardaman people of the Northern Territory in Australia perceived the stars of Triangulum Australe as the tail of the Rainbow Serpent, which stretched out from near Crux across to Scorpius. Overhead in October, the Rainbow Serpent "gives Lightning a nudge" to bring on the wet season rains in November.
Characteristics.
Triangulum Australe is a small constellation bordered by Norma to the north, Circinus to the west, Apus to the south and Ara to the east. It lies near the Pointers (Alpha and Beta Centauri), with only Circinus in between. The constellation is located within the Milky Way, and hence has many stars. A roughly equilateral triangle, it is easily identifiable. Triangulum Australe lies too far south in the celestial southern hemisphere to be visible from Europe, yet is circumpolar from most of the southern hemisphere. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "TrA". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 18 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 14h 56.4m and 17h 13.5m, while the declination coordinates are between −60.26° and −70.51°. Triangulum Australe culminates each year at 9 p.m. on 23 August.
Notable features.
Bright stars.
In defining the constellation, Lacaille gave twelve stars Bayer designations of Alpha through to Lambda, with two close stars called Eta (one now known by its Henry Draper catalogue number), while Lambda was later dropped due to its dimness. The three brightest stars, Alpha, Beta and Gamma, make up the triangle. Readily identified by its orange hue, Alpha Trianguli Australis is a bright giant star of spectral type K2 IIb-IIIa with an apparent magnitude of +1.91 that is the 42nd-brightest star in the night sky. It lies 424 ly away and has an absolute magnitude of −3.68 and is 5500 times more luminous than our sun. With a diameter 130 times that of our sun, it would almost reach the orbit of Venus if placed at the centre of our solar system. The proper name Atria is a contraction of its Bayer designation. Beta Trianguli Australis is a double star, the primary being a F-type main-sequence star with a stellar classification of F1V, and an apparent magnitude of 2.85. Lying only 40 ly away, it has an absolute magnitude of 2.38. Its companion, almost 3 arcminutes away, is a 13th magnitude star which may or may not be in orbit around Beta. The remaining member of the triangle is Gamma Trianguli Australis with an apparent magnitude of 2.87. It is an A-type main sequence star of spectral class A1 V, which lies 180 ly away.
Located outside the triangle near Beta, Delta Trianguli Australis is the fourth brightest star at apparent magnitude +3.8. It is a yellow giant of spectral type G2Ib-II and lies 606 light years (182 parsecs) away. A binary star, it has a 12th magnitude companion star separated by 30 arcseconds from the primary. Lying halfway between Beta and Gamma, Epsilon Trianguli Australis is another double star. The primary component, Epsilon Trianguli Australis A, is an orange K-type sub-giant of spectral type K1.5III with an apparent magnitude of +4.11. The companion, Epsilon Trianguli Australis B (or HD 138510), is a white main sequence star of spectral type A9IV/V which has an apparent magnitude of +9.32, Zeta Trianguli Australis appears as a star of apparent magnitude +4.91 and spectral class F9V, but is actually a spectroscopic binary with a near companion, probably a red dwarf. The pair orbit each other once every 13 days. A young star, its proper motion indicates it is a member of the Ursa Major moving group. Iota Trianguli Australis shows itself to be a multiple star system composed of a yellow and a white star when seen though a 7.5 cm telescope. The brighter star has a spectral type of F4IV and is a spectroscopic binary whose components are two yellow-white stars which orbit each other every 39.88 days. The primary is a Gamma Doradus variable, pulsating over a period of 1.45 days. The fainter star is not associated with the system, hence the system is an optical double. HD 147018 is a sun-like star of apparent magnitude 8.3 and spectral type G9V, which was found to have two exoplanets, HD 147018 b and HD 147018 c, in 2009.
Of apparent magnitude 5.11, the yellow bright giant Kappa Trianguli Australis of spectral type G5IIa lies around 1207 light years (370 parsecs) distant from our solar system. Eta Trianguli Australis (or Eta1 Trianguli Australis) is a Be star of spectral type B7IVe which is 661 light years (203 parsecs) from earth, with an apparent magnitude of 5.89. Lacaille named a close-by star as Eta as well, which was inconsistently followed by Francis Baily, who used the name for the brighter or both stars in two different publications. Despite their faintness, Benjamin Gould upheld their Bayer designation as they were closer than 25 degrees to the south celestial pole. The second Eta is now designated as HD 150550. It is a variable star of average magnitude 6.53 and spectral type A1III.
Variable stars.
Triangulum Australe contains several cepheid variables, all of which are too faint to be seen with the naked eye: R Trianguli Australis ranges from apparent magnitude 6.4 to 6.9 over a period of 3.389 days, S Trianguli Australis varies from magnitude 6.1 to 6.8 over 6.323 days, and U Trianguli Australis' brightness changes from 7.5 to 8.3 over 2.568 days. All three are yellow-white giants of spectral type F7Ib/II, F8II, and F8Ib/II respectively. RT Trianguli Australis is an unusual cepheid variable which shows strong absorption bands in molecular fragments of C2, ⫶CH and ⋅CN, and has been classified as a carbon cepheid of spectral type R. It varies between magnitudes 9.2 and 9.97 over 1.95 days. Lying nearby Gamma, X Trianguli Australis is a variable carbon star with an average magnitude of 5.63. It has two periods of around 385 and 455 days, and is of spectral type C5, 5(Nb).
EK Trianguli Australis, a dwarf nova of the SU Ursae Majoris type, was first noticed in 1978 and officially described in 1980. It consists of a white dwarf and a donor star which orbit each other every 1.5 hours. The white dwarf sucks matter from the other star onto an accretion disc and periodically erupts, reaching magnitude 11.2 in superoutbursts, 12.1 in normal outbursts and remaining at magnitude 16.7 when quiet. Nova Trianguli Australis 2008 was a slow nova which peaked at magnitude 8.4 in April 2008, before fading to magnitude 12.4 by September of that year.
Deep-sky objects.
Triangulum Australe has few deep-sky objects—one open cluster and a few planetary nebulae and faint galaxies. NGC 6025 is an open cluster with about 30 stars ranging from 7th to 9th magnitude. Located 3 degrees north and 1 east of Beta Trianguli Australis, it lies about 2500 ly away and is about 11 ly in diameter. Its brightest star is MQ Trianguli Australis at apparent magnitude 7.1. NGC 5979, a planetary nebula of apparent magnitude 12.3, has a blue-green hue at higher magnifications, while Henize 2-138 is a smaller planetary nebula of magnitude 11.0. NGC 5938 is a remote spiral galaxy around 300 million light-years (90 megaparsecs) away. It is located 5 degrees south of Epsilon Trianguli Australis. ESO 69-6 is a pair of merging galaxies located about 600 million light years (185 megaparsecs) away. Their contents have been dragged out in long tails by the interaction.
References.
Sources
</dl>
Online sources
</dl>
External links.
Coordinates: 

</doc>
<doc id="30664" url="http://en.wikipedia.org/wiki?curid=30664" title="Telescopium">
Telescopium

Telescopium is a minor constellation in the southern celestial hemisphere, one of twelve created in the 18th century by French astronomer Nicolas Louis de Lacaille and one of several depicting scientific instruments. Its name is a Latinized form of the Greek word for telescope. Telescopium was later much reduced in size by Francis Baily and Benjamin Gould.
The brightest star in the constellation is Alpha Telescopii, a blue-white subgiant with an apparent magnitude of 3.5, followed by the orange giant star Zeta Telescopii at magnitude 4.1. Eta and PZ Telescopii are two young star systems with debris disks and brown dwarf companions. Telescopium hosts two unusual stars with very little hydrogen that are likely to be the result of two merged white dwarfs: HD 168476, also known as PV Telescopii, is a hot blue extreme helium star, while RS Telescopii is an R Coronae Borealis variable. RR Telescopii is a cataclysmic variable that brightened as a nova to magnitude 6 in 1948.
History.
Telescopium was introduced in 1751–52 by Nicolas Louis de Lacaille with the French name "le Telescope", depicting an aerial telescope, after he had observed and catalogued 10,000 southern stars during a two-year stay at the Cape of Good Hope. He devised 14 new constellations in uncharted regions of the Southern Celestial Hemisphere not visible from Europe. All but one honored instruments that symbolised the Age of Enlightenment. Covering 40 degrees of the night sky, the telescope stretched out northwards between Sagittarius and Scorpius. Lacaille had Latinised its name to "Telescopium" by 1763.
The constellation was known by other names. It was called "Tubus Astronomicus" in the eighteenth century, during which time three constellations depicting telescopes were recognised—Tubus Herschelii Major between Gemini and Auriga and Tubus Herschelii Minor between Taurus and Orion, both of which had fallen out of use by the nineteenth century. Johann Bode called it the "Astronomische Fernrohr" in his 1805 "Gestirne" and kept its size, but later astronomers Francis Baily and Benjamin Gould subsequently shrank its boundaries. The much-reduced constellation lost several brighter stars to neighbouring constellations: Beta Telescopii became Eta Sagittarii, which it had been before Lacaille placed it in Telescopium, Gamma was placed in Scorpius and renamed G Scorpii by Gould, Theta Telescopii reverted to its old appellation of d Ophiuchi, and Sigma Telescopii was placed in Corona Australis. Initially uncatalogued, the latter is now known as HR 6875. The original object Lacaille had named Eta Telescopii—the open cluster Messier 7—was in what is now Scorpius, and Gould used the Bayer designation for a magnitude 5 star, which he felt warranted a letter.
Characteristics.
A small constellation, Telescopium is bordered by Sagittarius and Corona Australis to the north, Ara to the west, Pavo to the south, and Indus to the east, cornering on Microscopium to the northeast. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Tel'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a quadrilateral ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between 18h 09.1m and 20h 29.5m, while the declination coordinates are between −45.09° and −56.98°. The whole constellation is visible to observers south of latitude 33°N.
Notable features.
Stars.
Within the constellation's borders, there are 57 stars brighter than or equal to apparent magnitude 6.5. With a magnitude of 3.5, Alpha Telescopii is the brightest star in the constellation. It is a blue-white subgiant of spectral type B3IV which lies around 250 light-years away. Close by Alpha Telescopii are the two blue-white stars sharing the designation of Delta Telescopii. Delta¹ Telescopii is of spectral type B6IV and apparent magnitude 4.9, while Delta² Telescopii is of spectral type B3III and magnitude 5.1. They form an optical double, as the stars are estimated to be around 710 and 1190 light-years away respectively. The faint (magnitude 12.23) Gliese 754, a red dwarf of spectral type M4.5V, is one of the nearest 100 stars to Earth at 19.3 light-years distant. Its eccentric orbit around the Galaxy indicates that it may have originated in the Milky Way's thick disk.
At least four of the fifteen stars visible to the unaided eye are orange giants of spectral class K. The second brightest star in the constellation—at apparent magnitude 4.1—is Zeta Telescopii, an orange subgiant of spectral type K1III-IV. Around 1.53 times as massive as the Sun, it shines with 512 times its luminosity. Located 127 light years away from Earth, it has been described as yellow or reddish in appearance. Epsilon Telescopii is a binary star system: the brighter component, Epsilon Telescopii A, is an orange giant of spectral type K0III with an apparent magnitude of +4.52, while the 13th magnitude companion, Epsilon Telescopii B, is 21 arcseconds away from the primary, and just visible with a 15 cm aperture telescope on a dark night. The system is 417 light-years away. Iota Telescopii and HD 169405—magnitude 5 orange giants of spectral types K0III and K0.5III respectively—make up the quartet. They are around 370 and 497 light-years away from the Sun respectively. Another ageing star, Kappa Telescopii is a yellow giant with a spectral type G9III and apparent magnitude of 5.18. Around 1.87 billion years old, this star of around 1.6 solar masses has swollen to 11 times the Sun's diameter. It is approximately 293 light-years from Earth, and is another optical double.
Xi Telescopii is an irregular variable star that ranges between magnitudes 4.89 and 4.94. Located 1079 light-years distant, it is a red giant of spectral type M2III that has a diameter around 5.6 times the Sun's, and a luminosity around 2973 times that of the Sun. Another irregular variable, RX Telescopii is a red supergiant that varies between magnitudes 6.45 and 7.47, just visible to the unaided eye under good viewing conditions. BL Telescopii is an Algol-like eclipsing binary system that varies between apparent magnitudes 7.09 and 9.08 over a period of just over 778 days (2 years 48 days). The primary is a yellow supergiant that is itself intrinsically variable. Dipping from its baseline magnitude of 9.6 to 16.5, RS Telescopii is a rare R Coronae Borealis variable—an extremely hydrogen-deficient supergiant thought to have arisen as the result of the merger of two white dwarfs; fewer than 100 have been discovered as of 2012. The dimming is thought to be caused by carbon dust expelled by the star. As of 2012, four dimmings have been observed. PV Telescopii is a class B-type (blue) extreme helium star that is the prototype of a class of variables known as PV Telescopii variables. First discovered in 1952, it was found to have a very low level of hydrogen. One theory of its origin is that it is the result of a merger between a helium- and a carbon-oxygen white dwarf. If the combined mass does not exceed the Chandrasekhar limit, the former will accrete onto the latter star and ignite to form a supergiant. Later this will become an extreme helium star before cooling to become a white dwarf.
While RR Telescopii, also designated "Nova Telescopii 1948", is often called a slow nova, it is now classified as a symbiotic nova system composed of an M5III pulsating red giant and a white dwarf; between 1944 and 1948 it brightened by about 7 magnitudes before being noticed at apparent magnitude 6.0 in mid-1948. It has since faded slowly to about apparent magnitude 12. QS Telescopii is a binary system composed of a white dwarf and main sequence donor star, in this case the two are close enough to be tidally locked, facing one another. Known as polars, material from the donor star does not form an accretion disk around the white dwarf, but rather streams directly onto it. This is due to the presence of the white dwarf's strong magnetic field.
Although no star systems in Telescopium have confirmed planets, several have been found to have brown dwarf companions. A member of the 12-million-year-old Beta Pictoris moving group of stars that share a common proper motion through space, Eta Telescopii is a young white main sequence star of magnitude 5.0 and spectral type A0V. It has a debris disk and brown dwarf companion of spectral type M7V or M8V that is between 20 and 50 times as massive as Jupiter. The system is complex, as it has a common proper motion with (and is gravitationally bound to) the star HD 181327, which has its own debris disk. This latter star is a yellow-white main sequence star of spectral type F6V of magnitude 7.0. PZ Telescopii is another young star with a debris disk and substellar brown dwarf companion, though at 24 million years of age appears too old to be part of the Beta Pictoris moving group. HD 191760 is a yellow subgiant—a star that is cooling and expanding off the main sequence—of spectral type G3IV/V. Estimated to be just over four billion years old, it is slightly (1.1 to 1.3 times) more massive as the Sun, 2.69 times as luminous, and has around 1.62 times its radius. Using the High Accuracy Radial Velocity Planet Searcher (HARPS) instrument on the ESO 3.6 m Telescope, it was found to have a brown dwarf around 38 times as massive as Jupiter orbiting at an average distance of 1.35 AU with a period of 505 days. This is an unusually close distance from the star, within a range that has been termed the brown-dwarf desert.
Deep sky objects.
The globular cluster NGC 6584 lies near Theta Arae and is 45,000 light-years distant from Earth. It is an Oosterhoff type I cluster, and contains at least 69 variable stars, most of which are RR Lyrae variables. The planetary nebula IC 4699 is of 13th magnitude and lies midway between Alpha and Epsilon Telescopii.
IC 4889 is an elliptical galaxy of apparent magnitude 11.3, which can be found 2 degrees north-north-west of 5.3-magnitude Nu Telescopii. Observing it through a 40 cm telescope will reveal its central region and halo. The Telescopium group is group of twelve galaxies spanning three degrees in the northeastern part of the constellation, lying around 37 megaparsecs (120 million light-years) from our own galaxy. The brightest member is the elliptical galaxy NGC 6868, and to the west lies the spiral galaxy NGC 6861. These are the brightest members of two respective subgroups within the galaxy group, and are heading toward a merger in the future. Occupying an area of around 4' × 2', NGC 6845 is an interacting system of four galaxies—two spiral and two lenticular galaxies—that is estimated to be around 88 megaparsecs (287 million light-years) distant. SN 2008da was a type II supernova observed in one of the spiral galaxies, NGC 6845A, in June 2008. SN 1998bw was a luminous supernova observed in the spiral arm of the galaxy ESO184-G82 in April 1998, and is notable in that it is highly likely to the source of the gamma ray burst GRB 980425. 
References.
Sources
</dl>
Online sources
</dl>
Coordinates: 

</doc>
<doc id="30666" url="http://en.wikipedia.org/wiki?curid=30666" title="Trivium">
Trivium

The Trivium is a systematic method of critical thinking used to derive factual certainty from information perceived with the traditional five senses: sight, sound, taste, touch, and smell. In the medieval university, the trivium was the lower division of the seven liberal arts, and comprised grammar, logic, and rhetoric (input, process and output).
Etymologically, the Latin word trivium means "the place where three roads meet" (tri + via); hence, the subjects of the trivium are the foundation for the quadrivium, the upper division of the medieval education in the liberal arts, which comprised Arithmetic (number), Geometry (number in space), Music (number in time), and Astronomy (number in space and time). Educationally, the trivium and the quadrivium imparted to the student the seven liberal arts of Classical antiquity.
The trivium is implicit in the "De nuptiis Philologiae et Mercurii" ("On the Marriage of Philology and Mercury"), by Martianus Capella, although the term was not used until the Carolingian Renaissance, when the term was coined, in imitation of the earlier quadrivium. Grammar, Logic, and Rhetoric were essential to a Classical education, as explained in Plato's dialogues. Together, the three subjects were included to and denoted by the word "trivium" during the Middle Ages, but the tradition of first learning those three subjects was established in ancient Greece. Contemporary iterations have taken various forms, including those found in certain British and American universities (some being part of the Classical education movement) and at the independent Oundle School, in the United Kingdom.
Description.
Grammar teaches the mechanics of language to the student. This is the step where the student "comes to terms", i.e. defining the objects and information perceived by the five senses. Hence, the Law of Identity: "a tree is a tree, and not a cat".
Logic (also dialectic) is the "mechanics" of thought and of analysis; the process of identifying fallacious arguments and statements, and so systematically removing contradictions, thereby producing factual knowledge that can be trusted.
Rhetoric is the application of language in order to instruct and to persuade the listener and the reader. It is the knowledge (grammar) now understood (logic) being transmitted outwards, as wisdom (rhetoric).
In "The Trivium: The Liberal Arts of Logic, Grammar, and Rhetoric" (2002), Sister Miriam Joseph thus described the Trivium:
Grammar is the art of inventing symbols and combining them to express thought; logic is the art of thinking; and rhetoric is the art of communicating thought from one mind to another; the adaptation of language to circumstance.
Grammar is concerned with the thing as-it-is-symbolized. Logic is concerned with the thing as-it-is-known. Rhetoric is concerned with the thing as-it-is-communicated.
In the "Dictionary of Word Origins" (1990), John Ayto said that study of the trivium (grammar, logic, and rhetoric) was requisite preparation for study of the quadrivium (arithmetic, geometry, music, and astronomy). For the medieval student, the trivium was the curricular beginning of the acquisition of the seven liberal arts; as such, it was the principal undergraduate course of study. From that contrast, between the simpler trivium and the difficult quadrivium, arose the word "trivial".

</doc>
<doc id="30667" url="http://en.wikipedia.org/wiki?curid=30667" title="Last Supper">
Last Supper

The Last Supper is the final meal that, in the Gospel accounts, Jesus shared with his Apostles in Jerusalem before his crucifixion. The Last Supper is commemorated by Christians especially on Maundy Thursday. Moreover, the Last Supper provides the scriptural basis for the Eucharist also known as "Holy Communion" or "The Lord's Supper".
The First Epistle to the Corinthians is the earliest known mention of the Last Supper. The four canonical Gospels all state that the Last Supper took place towards the end of the week, after Jesus' triumphal entry into Jerusalem and that Jesus and his Apostles shared a meal shortly before Jesus was crucified at the end of that week. During the meal Jesus predicts his betrayal by one of the Apostles present, and foretells that before the next morning, Peter will deny knowing him.
The three Synoptic Gospels and the First Epistle to the Corinthians include the account of the institution of the Eucharist in which Jesus takes bread, breaks it and gives it to the Apostles, saying: "This is my body which is given for you". The Gospel of John does not include this episode, but tells of Jesus washing the feet of the Apostles, giving the new commandment "to love one another as I have loved you", and has a detailed farewell discourse by Jesus, calling the Apostles who follow his teachings "friends and not servants", as he prepares them for his departure.
Scholars have looked to the Last Supper as the source of early Christian Eucharist traditions. Others see the account of the Last Supper as derived from 1st-century eucharistic practice as described by Paul in the mid-50s.
The Last Supper served the dual purpose of venerating Passover, the escape of the Jews from slavery in Egypt, and the establishment of a new tradition, Christianity.
Terminology.
The term "Last Supper" does not appear in the New Testament, but traditionally many Christians refer to the New Testament accounts of the last meal Jesus shared with his Apostles as the "Last Supper".
Most Protestants use the term "Lord's Supper", stating that the term "last" suggests this was one of several meals and not "the" meal. The term "Lord's Supper" refers both to the biblical event and the act of "Holy Communion" and Eucharistic ("thanksgiving") celebration within their liturgy. Evangelical Protestants also use the term "Lord's Supper", but most do not use the terms "Eucharist" or the word "Holy" with the name "Communion".
The Eastern Orthodox use the term "Mystical Supper" which refers both to the biblical event and the act of Eucharistic celebration within liturgy.
Scriptural basis.
The last meal that Jesus shared with his disciples is described in all four canonical Gospels (, , and ). This meal later became known as the Last Supper. The Last Supper was likely a retelling of the events of the last meal of Jesus among the early Christian community, and became a ritual which recounted that meal.
Paul's First Epistle to the Corinthians, which was likely written before the Gospels, includes a reference to the Last Supper but emphasizes the theological basis rather than giving a detailed description of the event or its background.
Background and setting.
The overall narrative that is shared in all Gospel accounts that leads to the Last Supper is that after the Triumphal entry into Jerusalem early in the week, and encounters with various people and the Jewish elders, Jesus and his disciples share a meal towards the end of the week. After the meal, Jesus is betrayed, arrested, tried, and then crucified.
Key events in the meal are the preparation of the disciples for the departure of Jesus, the predictions about the impending betrayal of Jesus, and the foretelling of the upcoming denial of Jesus by Apostle Peter.
Prediction of Judas' betrayal.
In , , and during the meal, Jesus predicted that one of his Apostles would betray him. Jesus is described as reiterating, despite each Apostle's assertion that he would not betray Jesus, that the betrayer would be one of those who were present, and saying that there would be "woe to the man who betrays the Son of man! It would be better for him if he had not been born." In and , Judas is specifically identified as the traitor. In the Gospel of John, when asked about the traitor, Jesus states: “It is the one to whom I will give this piece of bread when I have dipped it in the dish.” Then, dipping the piece of bread, he gave it to Judas, the son of Simon Iscariot. As soon as Judas took the bread, Satan entered into him."
Institution of the Eucharist.
The Eucharist, which "is recorded as celebrated by the early Christian community at Jerusalem and by St. Paul on his visit to Troas", is held to have been instituted by Christ.
The institution of the Lord's Supper is recorded in the three Synoptic Gospels and in Paul's first epistle to the Corinthians. The words of institution differ slightly in each account, reflecting a Marcan tradition (upon which Matthew is based) and a Pauline tradition (upon which Luke is based). In addition, is a disputed text which does not appear in some of the early manuscripts of Luke. Some scholars, therefore, believe that it is an interpolation, while others have argued that it is original.
A comparison of the accounts given in the Gospels and 1 Corinthians is shown in the table below, with text from the ASV. The disputed text from Luke 22:19b-20 is in italics.
Jesus' actions in sharing the bread and wine have been linked with which refers to a blood sacrifice that, as recounted in , Moses offered in order to seal a covenant with God. Scholars often interpret the description of Jesus' action as asking his disciples to consider themselves part of a sacrifice, where Jesus is the one due to physically undergo it.
Although the Gospel of John does not include a description of the bread and wine ritual during the Last Supper, most scholars agree that (the Bread of Life Discourse) has a Eucharistic nature and resonates with the "words of institution" used in the Synoptic Gospels and the Pauline writings on the Last Supper.
Prediction of Peter's denial.
In , , and Jesus predicts that Peter will deny knowledge of him, stating that Peter will disown him three times before the rooster crows the next morning. The three Synoptic Gospels mention that after the arrest of Jesus Peter denied knowing him three times, but after the third denial, heard the rooster crow and recalled the prediction as Jesus turned to look at him. Peter then began to cry bitterly.
Elements unique to the Gospel of John.
In John, Jesus has his last supper and is executed not on the day Nisan 15 (the first night of Passover) but on Nisan 14, when the Passover lambs were slaughtered. Presumably the author preferred this date because it associated Jesus as the Lamb of God with the sacrificial lambs of Passover.
 includes the account of the washing the feet of the Apostles by Jesus before the meal. In this episode, Apostle Peter objects and does not want to allow Jesus to wash his feet, but Jesus answers him, “Unless I wash you, you have no part with me”, after which Peter agrees.
In the Gospel of John, after the departure of Judas from the Last Supper, Jesus tells his remaining eleven disciples that he will be with them for only a short time, then gives them a New Commandment, stating: “A new command I give you: Love one another. As I have loved you, so you must love one another. By this everyone will know that you are my disciples, if you love one another.” in . Two similar statements also appear later in : "My command is this: Love each other as I have loved you", and : "This is my command: Love each other."
At the Last Supper in the Gospel of John, Jesus gives an extended sermon to his disciples. This discourse resembles farewell speeches called testaments, in which a father or religious leader, often on the deathbed, leaves instructions for his children or followers.
This sermon is referred to as the Farewell discourse of Jesus, and has historically been considered a source of Christian doctrine, particularly on the subject of Christology. is generally known as the "Farewell Prayer" or the "High Priestly Prayer", given that it is an intercession for the coming Church. The prayer begins with Jesus' petition for his glorification by the Father, given that completion of his work and continues to an intercession for the success of the works of his disciples and the community of his followers.
Time and place.
Date.
Scholarly estimates for the date of the crucifixion generally fall in the range AD 30-36. Physicist Colin Humphreys rules out the year 36 on astronomical grounds. He presents other grounds for holding that the crucifixion of Jesus occurred in the afternoon of Friday, 3 April 33, and says that this was 14 Nisan in the official Jewish calendar that year.
The Gospels say that Jesus died on a Friday and that his body was left in the tomb for the whole of the next day, which was a Shabbat (Saturday). The Synoptic Gospels present the Last Supper as a Passover meal and they seem to suggest that it was held on the evening before the crucifixion (although in no Gospel is it unequivocally said that this meal took place on the night before Jesus died). This would mean that the Passover feast (15 Nisan) began at sunset on what now would commonly be called Thursday evening and lasted until sunset on Friday (the Jewish calendar reckons a date as beginning at sunset, not at midnight). On the contrary, the Gospel of John presents the feast as beginning on the evening "following" the afternoon death of Jesus. This would mean that the Friday of the crucifixion was the day of preparation for the feast (14 Nisan), not the feast itself. Various attempts to reconcile these two accounts have been made, some of which are indicated in the by Francis Mershman in the 1912 Catholic Encyclopedia.
In the 1950s Annie Jaubert argued that, while in the year of Jesus' death the official lunar calendar had Passover begin on a Friday evening, a 364-day year was also used, for instance by the Qumran community, and that Jesus celebrated the Passover on the date given in that calendar, which always had the feast begin on Tuesday evening. More recently, Humphreys, who holds that the "Palm Sunday" entry of Jesus into Jerusalem occurred on Monday, not Sunday, argued that the Last Supper took place on the evening of Wednesday 1 April 33. If the Last Supper was on Tuesday (Jaubert) or Wednesday (Humphreys), this would allow more time than in the traditional view (Last Supper on Thursday) for interrogation of Jesus and his presentation to Pilate before he was crucified on Friday.
Location.
According to later tradition, the Last Supper took place in what is called today The Room of the Last Supper on Mount Zion, just outside of the walls of the Old City of Jerusalem, and is traditionally known as "The Upper Room". This is based on the account in the Synoptic Gospels that states that Jesus had instructed a pair of unnamed disciples to go to "the city" to meet "a man carrying a jar of water", who would lead them to a house, where they would find "a large upper room furnished and ready". In this upper room they "prepare the Passover".
No more specific indication of the location is given in the New Testament, and the "city" referred to may be a suburb of Jerusalem, such as Bethany, rather than Jerusalem itself. The traditional location is in an area that, according to archaeology, had a large Essene community, a point made by scholars who suspect a link between Jesus and the group (Kilgallen 265).
Saint Mark's Syrian Orthodox Church in Jerusalem is another possible site for the room in which the Last Supper was held, and contains a Christian stone inscription testifying to early reverence for that spot. Certainly the room they have is older than that of the current coenaculum (crusader - 12th century) and as the room is now underground the relative altitude is correct (the streets of 1st century Jerusalem were at least twelve feet (3.6 metres) lower than those of today, so any true building of that time would have even its upper storey currently under the earth). They also have a revered Icon of the Virgin Mary, reputedly painted from life by St Luke.
Bargil Pixner claims the original site is located beneath the current structure of the Cenacle on Mount Zion.
Theology of the Last Supper.
St. Thomas Aquinas viewed The Father, Christ, and the Holy Spirit as teachers and masters who provide lessons, at times by example. For Aquinas, the Last Supper and the Cross form the summit of the teaching that wisdom flows from intrinsic grace, rather than external power. For Aquinas, at the Last Supper Christ taught by example, showing the value of humility (as reflected in John's foot washing narrative) and self-sacrifice, rather than by exhibiting external, miraculous powers.
Aquinas stated that based on (in the Farewell discourse) in which Jesus said: "No longer do I call you servants; ...but I have called you friends". Those who are followers of Christ and partake in the Sacrament of the Eucharist become his friends, as those gathered at the table of the Last Supper. For Aquinas, at the Last Supper Christ made the promise to be present in the Sacrament of the Eucharist, and to be with those who partake in it, as he was with his disciples at the Last Supper.
John Calvin believed only in the two sacraments of Baptism and the "Lord's Supper" (i.e., Eucharist). Thus, his analysis of the Gospel accounts of the Last Supper were an important part of his entire theology. Calvin related the Synoptic Gospel accounts of the Last Supper with the Bread of Life Discourse in that states: "I am the bread of life. He who comes to me will never go hungry."
Calvin also believed that the acts of Jesus at the Last Supper should be followed as an example, stating that just as Jesus gave thanks to the Father before breaking the bread, those who go to the "Lord's Table" to receive the sacrament of the Eucharist must give thanks for the "boundless love of God" and celebrate the sacrament with both joy and thanksgiving.
Remembrances.
The institution of the Eucharist at the Last Supper is remembered by Roman Catholics as one of the Luminous Mysteries of the Rosary, the First Station of the Scriptural Way of the Cross and by most Christians as the "inauguration of the New Covenant", mentioned by the prophet Jeremiah, fulfilled at the last supper when Jesus "took bread, and after blessing it broke it and gave it to them, and said, 'Take; this is my body.' And he took a cup, and when he had given thanks he gave it to them, and they all drank of it. And he said to them, 'This is my blood of the covenant, which is poured out for many.'" Other Christian groups consider the Bread and Wine remembrance to be a change to the Passover ceremony, as Jesus Christ has become "our Passover, sacrificed for us", and hold that partaking of the Passover Communion (or fellowship) is now the sign of the New Covenant, when properly understood by the practicing believer.
These meals evolved into more formal worship services and became codified as the Mass in the Catholic Church, and as the Divine Liturgy in the Eastern Orthodox Church; at these liturgies, Catholics and Eastern Orthodox celebrate the Sacrament of the Eucharist. The name "Eucharist" is from the Greek word "εὐχαριστία" (eucharistia) which means "thanksgiving".
Early Christianity observed a ritual meal known as the "agape feast" These "love feasts" were apparently a full meal, with each participant bringing food, and with the meal eaten in a common room. They were held on Sundays, which became known as the Lord's Day, to recall the resurrection, the appearance of Christ to the disciples on the road to Emmaus, the appearance to Thomas and the Pentecost which all took place on Sundays after the Passion.
Passover parallels.
Raymond Brown has argued that during the Jewish Passover Seder, the first cup of wine is drunk before the eating of the (unleavened) bread, but here it occurs after. This may indicate that the event was not the first Passover Seder (which occurs on Nisan 15), and hence more in line with John's chronology which places it on Nisan 14, although the meal could easily have been altered during the Last Supper for symbolic or religious purposes. Among Christian denominations, the Eastern Orthodox Church holds that this Eucharistic meal was not the Passover Seder, but a separate meal. The Presbyterian Church (U.S.A.) documents also specifically reject the Seder arguments and state that given that no Jewish Seder texts exist earlier than the 9th century, it is historically implausible to attempt a reconstruction of the Seder to create a parallel to the Last Supper, and that the Gospel accounts clearly indicate that the purpose of the Last Supper was not the annual repetition of the Exodus.
The fifth chapter in Quran, "Al-Ma'ida" (the table) contains a reference to a meal (Sura 5:113) with a table sent down from God to ʿĪsá (i.e., Jesus) and the apostles (Hawariyyin). However, there is nothing in Sura 5:113 to indicate that Jesus was celebrating that meal regarding his impending death, especially as the Qur'an insists that Jesus was never crucified to begin with. Thus although, Sura 5:113 refers to "a meal", there is no indication that it is the Last Supper. However, some scholars believe that Jesus' manner of speech during which the table was sent down suggests that it was an affirmation of the apostles' resolves and to strengthen their faiths as the impending trial was about to befall them.
Historicity.
Some scholars consider the Lord's supper to have derived not from Jesus' last supper with the disciples but rather from the gentile tradition of memorial dinners for the dead. In this view, the Last Supper is a tradition associated mainly with the gentile churches that Paul established, rather than with the earlier, Jewish congregations.
Luke is the only Gospel in which Jesus tells his disciples to repeat the ritual of bread and wine. Bart D. Ehrman states that these particular lines do not appear in certain ancient manuscripts and might not be original to the text.
However, many early Church Fathers have attested to the belief that at the Last Supper, Christ made the promise to be present in the Sacrament of the Eucharist, with attestations dating back to the first century AD. The teaching was also affirmed by many councils throughout the Church's history.
Artistic depictions.
The Last Supper has been a popular subject in Christian art. Such depictions date back to early Christianity and can be seen in the Catacombs of Rome. Byzantine artists frequently focused on the Apostles receiving Communion, rather than the reclining figures having a meal. By the Renaissance, the Last Supper was a favorite topic in Italian art.
There are three major themes in the depictions of the Last Supper: the first is the dramatic and dynamic depiction of Jesus' announcement of his betrayal. The second is the moment of the institution of the tradition of the Eucharist. The depictions here are generally solemn and mystical. The third major theme is the farewell of Jesus to his disciples, in which Judas Iscariot is no longer present, having left the supper. The depictions here are generally melancholy, as Jesus prepares his disciples for his departure. There are also other, less frequently depicted scenes, such as the washing of the feet of the disciples.
Well known examples include Leonardo da Vinci's depiction, which is considered the first work of High Renaissance art due to its high level of harmony, Tintoretto's depiction which is unusual in that it includes secondary characters carrying or taking the dishes from the table and Salvadore Dali's depiction combines the typical Christian themes with modern approaches of Surrealism.

</doc>
<doc id="30669" url="http://en.wikipedia.org/wiki?curid=30669" title="Tunguska event">
Tunguska event

The Tunguska event was a large explosion, caused by an asteroid or comet, which occurred near the Podkamennaya Tunguska River in what is now Krasnoyarsk Krai, Russia, at about 07:14 KRAT (00:14 UT) on June 30 [O.S. June 17], 1908. The explosion occurred at an altitude of 5 – at 60.886°N, 101.894°E. It is classified as an impact event even though the object is believed to have burst in the air rather than hit the surface. Different studies have yielded widely varying estimates of the impacting object's size, on the order of 60 m to 190 m. It is the largest impact event on Earth in recorded history.
Since the 1908 event, there have been an estimated 1,000 scholarly papers (mainly in Russian) published on the Tunguska explosion. Many scientists have participated in Tunguska studies: the best known are Leonid Kulik, Yevgeny Krinov, Kirill Florensky, Nikolai Vladimirovich Vasiliev, and Wilhelm Fast. In 2013, a team of researchers led by Victor Kvasnytsya of the National Academy of Sciences of Ukraine published analysis results of micro-samples from a peat bog near the blast epicenter showing fragments that may be of meteoritic origin.
Estimates of the energy of the blast range from as low as three to as high as 30 megatons of TNT (between 13 and 130 PJ). Most likely it was between 10 and, and if so, the energy of the explosion was about 1,000 times greater than that of the atomic bomb dropped on Hiroshima, Japan; roughly equal to that of the United States' Castle Bravo ground-based thermonuclear test detonation on March 1, 1954; and about two-fifths that of the Soviet Union's later Tsar Bomba (the largest nuclear weapon ever detonated).
It is estimated that the Tunguska explosion knocked down some 80 million trees over an area of 2150 km2, and that the shock wave from the blast would have measured 5.0 on the Richter scale. An explosion of this magnitude would be capable of destroying a large metropolitan area, but due to the remoteness of the location, no fatalities were documented. This event has helped to spark discussion of asteroid impact avoidance.
Description.
At around 7:17 a.m. local time, Evenki natives and Russian settlers in the hills northwest of Lake Baikal observed a column of bluish light, nearly as bright as the Sun, moving across the sky. About ten minutes later, there was a flash and a sound similar to artillery fire. Eyewitnesses closer to the explosion reported that the source of the sound moved from the east to the north of them. The sounds were accompanied by a shock wave that knocked people off their feet and broke windows hundreds of kilometres away. The majority of witnesses reported only the sounds and the tremors, and did not report seeing the explosion. Eyewitness accounts vary regarding the sequence and duration of the events.
The explosion registered at seismic stations across Eurasia. It is estimated that, in some places, the resulting shock wave was equivalent to an earthquake measuring 5.0 on the Richter scale. It also produced fluctuations in atmospheric pressure strong enough to be detected in Great Britain. Over the next few days, night skies in Asia and Europe were aglow; it has been theorized that this was due to light passing through high-altitude ice particles that had formed at extremely low temperatures—a phenomenon that many years later would be produced by space shuttles. In the United States, the Smithsonian Astrophysical Observatory and the Mount Wilson Observatory observed a months-long decrease in atmospheric transparency due to an increase in suspended dust particles.
Selected eyewitness reports.
Testimony of S. Semenov, as recorded by Leonid Kulik's expedition in 1930:
At breakfast time I was sitting by the house at Vanavara Trading Post ["65 kilometres/40 miles south of the explosion"], facing north. [...] I suddenly saw that directly to the north, over Onkoul's Tunguska Road, the sky split in two and fire appeared high and wide over the forest ["as Semenov showed, about 50 degrees up—expedition note"]. The split in the sky grew larger, and the entire northern side was covered with fire. At that moment I became so hot that I couldn't bear it, as if my shirt was on fire; from the northern side, where the fire was, came strong heat. I wanted to tear off my shirt and throw it down, but then the sky shut closed, and a strong thump sounded, and I was thrown a few metres. I lost my senses for a moment, but then my wife ran out and led me to the house. After that such noise came, as if rocks were falling or cannons were firing, the earth shook, and when I was on the ground, I pressed my head down, fearing rocks would smash it. When the sky opened up, hot wind raced between the houses, like from cannons, which left traces in the ground like pathways, and it damaged some crops. Later we saw that many windows were shattered, and in the barn a part of the iron lock snapped.
Testimony of Chuchan of Shanyagir tribe, as recorded by I. M. Suslov in 1926:
We had a hut by the river with my brother Chekaren. We were sleeping. Suddenly we both woke up at the same time. Somebody shoved us. We heard whistling and felt strong wind. Chekaren said, 'Can you hear all those birds flying overhead?' We were both in the hut, couldn't see what was going on outside. Suddenly, I got shoved again, this time so hard I fell into the fire. I got scared. Chekaren got scared too. We started crying out for father, mother, brother, but no one answered. There was noise beyond the hut, we could hear trees falling down. Chekaren and I got out of our sleeping bags and wanted to run out, but then the thunder struck. This was the first thunder. The Earth began to move and rock, wind hit our hut and knocked it over. My body was pushed down by sticks, but my head was in the clear. Then I saw a wonder: trees were falling, the branches were on fire, it became mighty bright, how can I say this, as if there was a second sun, my eyes were hurting, I even closed them. It was like what the Russians call lightning. And immediately there was a loud thunderclap. This was the second thunder. The morning was sunny, there were no clouds, our Sun was shining brightly as usual, and suddenly there came a second one!
Chekaren and I had some difficulty getting out from under the remains of our hut. Then we saw that above, but in a different place, there was another flash, and loud thunder came. This was the third thunder strike. Wind came again, knocked us off our feet, struck against the fallen trees.
We looked at the fallen trees, watched the tree tops get snapped off, watched the fires. Suddenly Chekaren yelled "Look up" and pointed with his hand. I looked there and saw another flash, and it made another thunder. But the noise was less than before. This was the fourth strike, like normal thunder.
Now I remember well there was also one more thunder strike, but it was small, and somewhere far away, where the Sun goes to sleep.
"Sibir" newspaper, July 2, 1908:
On the 17th of June, around 9 a.m. in the morning, we observed an unusual natural occurrence. In the north Karelinski village [200 verst north of Kirensk] the peasants saw to the north west, rather high above the horizon, some strangely bright (impossible to look at) bluish-white heavenly body, which for 10 minutes moved downwards. The body appeared as a "pipe", i.e., a cylinder. The sky was cloudless, only a small dark cloud was observed in the general direction of the bright body. It was hot and dry. As the body neared the ground (forest), the bright body seemed to smudge, and then turned into a giant billow of black smoke, and a loud knocking (not thunder) was heard, as if large stones were falling, or artillery was fired. All buildings shook. At the same time the cloud began emitting flames of uncertain shapes. All villagers were stricken with panic and took to the streets, women cried, thinking it was the end of the world.
The author of these lines was meantime in the forest about 6 verst [6.4 km] north of Kirensk, and heard to the north east some kind of artillery barrage, that repeated in intervals of 15 minutes at least 10 times. In Kirensk in a few buildings in the walls facing north east window glass shook.
"Siberian Life" newspaper, July 27, 1908:
When the meteorite fell, strong tremors in the ground were observed, and near the Lovat village of the Kansk uezd two strong explosions were heard, as if from large-caliber artillery.
"Krasnoyaretz" newspaper, July 13, 1908:
Kezhemskoe village. On the 17th an unusual atmospheric event was observed. At 7:43 the noise akin to a strong wind was heard. Immediately afterwards a horrific thump sounded, followed by an earthquake that literally shook the buildings, as if they were hit by a large log or a heavy rock. The first thump was followed by a second, and then a third. Then the interval between the first and the third thumps were accompanied by an unusual underground rattle, similar to a railway upon which dozens of trains are travelling at the same time. Afterwards for 5 to 6 minutes an exact likeness of artillery fire was heard: 50 to 60 salvoes in short, equal intervals, which got progressively weaker. After 1.5–2 minutes after one of the "barrages" six more thumps were heard, like cannon firing, but individual, loud and accompanied by tremors.
The sky, at the first sight, appeared to be clear. There was no wind and no clouds. However upon closer inspection to the north, i.e. where most of the thumps were heard, a kind of an ashen cloud was seen near the horizon, which kept getting smaller and more transparent and possibly by around 2–3 p.m. completely disappeared.
Investigations.
There was little scientific curiosity about the impact at the time, possibly due to the isolation of the Tunguska region. If there were any early expeditions to the site, the records were likely to have been lost during the subsequent chaotic years—World War I, the Russian Revolution of 1917 and the Russian Civil War.
The first recorded expedition arrived at the scene more than a decade after the event. In 1921, the Russian mineralogist Leonid Kulik, visiting the Podkamennaya Tunguska River basin as part of a survey for the Soviet Academy of Sciences, deduced from local accounts that the explosion had been caused by a giant meteorite impact. He persuaded the Soviet government to fund an expedition to the Tunguska region, based on the prospect of meteoric iron that could be salvaged to aid Soviet industry. Kulik's party eventually undertook an expedition in 1927.
Upon arrival, Kulik made arrangements with the local Evenki hunters to guide his party to the impact site. Reaching the explosion site was an extremely arduous task. Upon reaching an area just south of the site, the superstitious Evenki hunters would go no farther, fearing what they called the Valleymen. Kulik had to return to the nearby village, and his party was delayed for several days while they sought new guides.
The spectacle that confronted Kulik as he stood on a ridge overlooking the devastated area was overwhelming. To the explorers' surprise, no crater was to be found. There was instead around ground zero a vast zone (8 km across) of trees scorched and devoid of branches, but standing upright. The trees farther away had been partly scorched and knocked down in a direction away from the centre. Much later, in the 1960s, it was established that the zone of leveled forest occupied an area of some 2150 km2, its shape resembling a gigantic spread-eagled butterfly with a "wingspan" of 70 km and a "body length" of 55 km.
Upon closer examination, Kulik located holes which he erroneously concluded were meteorite holes; however, he did not have the means at that time to excavate the holes.
During the next ten years there were three more expeditions to the area. Kulik found several dozens of little "pothole" bogs, each some 10 to in diameter, that he thought might be meteoric craters. After a laborious exercise in draining one of these bogs (the so-called "Suslov’s crater", 32 m in diameter), he found there was an old stump on the bottom, ruling out the possibility that it was a meteoric crater. In 1938, Kulik arranged for an aerial photographic survey of the area covering the central part of the leveled forest (some 250 km2). The negatives of these aerial photographs (1,500 negatives, each 18 by) were burned in 1975 by order of Yevgeny Krinov, then Chairman of the Committee on Meteorites of the USSR Academy of Sciences. It was done under the pretext that they were a fire hazard, but the truth may have been the active dislike by official meteorite specialists of anything associated with the Tunguska event, which was seen as an unyielding enigma. However, positive imprints were preserved for further studies in the Russian city of Tomsk.
Expeditions sent to the area in the 1950s and 1960s found microscopic silicate and magnetite spheres in siftings of the soil. Similar spheres were predicted to exist in the felled trees, although they could not be detected by contemporary means. Later expeditions did identify such spheres in the resin of the trees. Chemical analysis showed that the spheres contained high proportions of nickel relative to iron, which is also found in meteorites, leading to the conclusion they were of extraterrestrial origin. The concentration of the spheres in different regions of the soil was also found to be consistent with the expected distribution of debris from a meteorite air burst. Later studies of the spheres found unusual ratios of numerous other metals relative to the surrounding environment, which was taken as further evidence of their extraterrestrial origin.
Chemical analysis of peat bogs from the area also revealed numerous anomalies considered consistent with an impact event. The isotopic signatures of stable carbon, hydrogen, and nitrogen isotopes at the layer of the bogs corresponding to 1908 were found to be inconsistent with the isotopic ratios measured in the adjacent layers, and this abnormality was not found in bogs located outside the area. The region of the bogs showing these anomalous signatures also contains an unusually high proportion of iridium, similar to the iridium layer found in the Cretaceous–Paleogene boundary. These unusual proportions are believed to result from debris from the falling body that deposited in the bogs. The nitrogen is believed to have been deposited as acid rain, a suspected fallout from the explosion.
Earth impactor model.
Asteroid air burst.
The leading scientific explanation for the explosion is the air burst of an asteroid 6–10 kilometres (4–6 miles) above Earth's surface.
Meteoroids enter Earth's atmosphere from outer space every day, travelling at a speed of at least 11 km/s. The heat generated by compression of air in front of the body (ram pressure) as it travels through the atmosphere is immense and most asteroids burn up or explode before they reach the ground. Since the second half of the 20th century, close monitoring of Earth's atmosphere has led to the discovery that such asteroid air bursts occur rather frequently. A stony asteroid of about 10 metres (30 ft) in diameter can produce an explosion of around 20 kilotons, similar to that of the Fat Man bomb dropped on Nagasaki, and data released by the U.S. Air Force's Defense Support Program indicate that such explosions occur high in the upper atmosphere more than once a year. Tunguska-like megaton-range events are much rarer. Eugene Shoemaker estimated that such events occur about once every 300 years.
Blast patterns.
The explosion's effect on the trees near the epicentre of the explosion was replicated during atmospheric nuclear tests in the 1950s and 1960s,["discuss"] and was similar to the effects of the conventional Operation Blowdown. These effects are caused by the blast wave produced by large explosions. The trees directly below the explosion are stripped as the blast wave moves vertically downward, while trees farther away are knocked over because the blast wave is travelling closer to horizontal when it reaches them.
Soviet experiments performed in the mid-1960s, with model forests (made of matches on wire stakes) and small explosive charges slid downward on wires, produced butterfly-shaped blast patterns strikingly similar to the pattern found at the Tunguska site. The experiments suggested that the object had approached at an angle of roughly 30 degrees from the ground and 115 degrees from north and had exploded in mid-air.
Asteroid or comet.
In 1930, the British astronomer F.J.W. Whipple suggested that the Tunguska body was a small comet. A cometary meteorite, being composed primarily of ice and dust, could have been completely vaporized by the impact with Earth's atmosphere, leaving no obvious traces. The comet hypothesis was further supported by the glowing skies (or "skyglows" or "bright nights") observed across Europe for several evenings after the impact, possibly explained by dust and ice that had been dispersed from the comet's tail across the upper atmosphere. The cometary hypothesis gained a general acceptance amongst Soviet Tunguska investigators by the 1960s.
In 1978, Slovak astronomer Ľubor Kresák suggested that the body was a fragment of the short-period Comet Encke, which is responsible for the Beta Taurid meteor shower: the Tunguska event coincided with a peak in that shower, and the approximate trajectory of the Tunguska impactor is consistent with what would be expected from such a fragment. It is now known that bodies of this kind explode at frequent intervals tens to hundreds of kilometres above the ground. Military satellites have been observing these explosions for decades.
In 1983, astronomer Zdeněk Sekanina published a paper criticizing the comet hypothesis. He pointed out that a body composed of cometary material, travelling through the atmosphere along such a shallow trajectory, ought to have disintegrated, whereas the Tunguska body apparently remained intact into the lower atmosphere. Sekanina argued that the evidence pointed to a dense, rocky object, probably of asteroidal origin. This hypothesis was further boosted in 2001, when Farinella, Foschini, "et al." released a study suggesting that the object had arrived from the direction of the asteroid belt.
Proponents of the comet hypothesis have suggested that the object was an extinct comet with a stony mantle that allowed it to penetrate the atmosphere.
The chief difficulty in the asteroid hypothesis is that a stony object should have produced a large crater where it struck the ground, but no such crater has been found. It has been hypothesized that the passage of the asteroid through the atmosphere caused pressures and temperatures to build up to a point where the asteroid abruptly disintegrated in a huge explosion. The destruction would have to have been so complete that no remnants of substantial size survived, and the material scattered into the upper atmosphere during the explosion would have caused the skyglows. Models published in 1993 suggested that the stony body would have been about 60 m across, with physical properties somewhere between an ordinary chondrite and a carbonaceous chondrite.
Christopher Chyba and others have proposed a process whereby a stony meteorite could have exhibited the behavior of the Tunguska impactor. Their models show that when the forces opposing a body's descent become greater than the cohesive force holding it together, it blows apart, releasing nearly all its energy at once. The result is no crater, with damage distributed over a fairly wide radius, and all of the damage resulting from the thermal energy released in the blast.
Three-dimensional numerical modelling of the Tunguska impact done by Utyuzhnikov and Rudenko in 2008 supports the comet hypothesis. According to their results, the comet matter dispersed in the atmosphere, while the destruction of the forest was caused by the shock wave.
During the 1990s, Italian researchers, coordinated by the physicist Giuseppe Longo from University of Bologna, extracted resin from the core of the trees in the area of impact to examine trapped particles that were present during the 1908 event. They found high levels of material commonly found in rocky asteroids and rarely found in comets.
Kelly "et al." (2009) contend that the impact was caused by a comet because of the sightings of noctilucent clouds following the impact, a phenomenon caused by massive amounts of water vapor in the upper atmosphere. They compared the noctilucent cloud phenomenon to the exhaust plume from NASA's "Endeavour" space shuttle.
In 2010, an expedition led by Vladimir Alexeev with scientists from the Troitsk Innovation and Nuclear Research Institute (TRINITY) used ground penetrating radar to examine the Suslov crater at the Tunguska site. What they found was that the crater was created by the violent impact of a celestial body. The layers of the crater consisted of modern permafrost on top, older damaged layers underneath, and finally, deep below, fragments of the celestial body were discovered. Preliminary analysis showed that it was a huge piece of ice that shattered on impact, which seem to support the theory that a comet caused the cataclysm. In contrast, in 2013, analysis of fragments from the Tunguska site by a joint US-European team was consistent with an iron meteoroid.
Lake Cheko.
In June 2007, scientists from the University of Bologna identified a lake in the Tunguska region as a possible impact crater from the event. They do not dispute that the Tunguska body exploded in midair but believe that a one-meter fragment survived the explosion and struck the ground. Lake Cheko is a small, bowl-shaped lake approximately 8 kilometres north-northwest of the epicentre. The hypothesis has been disputed by other impact crater specialists. A 1961 investigation had dismissed a modern origin of Lake Cheko, saying that the presence of metres-thick silt deposits at the lake's bed suggests an age of at least 5,000 years, but more recent research suggests that only a meter or so of the sediment layer on the lake bed is "normal lacustrine sedimentation", a depth indicating a much younger lake of about 100 years. Acoustic-echo soundings of the lake floor provide support for the hypothesis that the lake was formed by the Tunguska event. The soundings revealed a conical shape for the lake bed, which is consistent with an impact crater.
Magnetic readings indicate a possible meter-sized chunk of rock below the lake's deepest point that may be a fragment of the colliding body. Finally, the lake's long axis points to the epicentre of the Tunguska explosion, about 7.0 km away. Work is still being done at Lake Cheko to determine its origins.
The main points of the study are that "Cheko, a small lake located in Siberia close to the epicentre of the 1908 Tunguska explosion, might fill a crater left by the impact of a fragment of a cosmic body. Sediment cores from the lake's bottom were studied to support or reject this hypothesis. A 175 cm-long core, collected near the center of the lake, consists of an upper c. one-metre (39 in)-thick sequence of lacustrine deposits overlaying coarser chaotic material. 210Pb and 137Cs indicate that the transition from lower to upper sequence occurred close to the time of the Tunguska event. Pollen analysis reveals that remains of aquatic plants are abundant in the top post-1908 sequence but are absent in the lower pre-1908 portion of the core. These results, including organic C, N and δ13C data, suggest that Lake Cheko formed at the time of the Tunguska event."
Speculative conjectures.
The behaviour of meteoroids in Earth's atmosphere was less well understood during the early decades of the 20th century. Due to this, as well as the paucity of relevant data resulting from Soviet secrecy during the Cold War, a great many other conjectures about the Tunguska event sprang up, none of which are accepted by the majority of the scientific community.
Fragment of near-earth object 2005 NB56.
One study "suggests that a chunk of 2005 NB56 caused the 5–10 megaton fireball, bouncing off the atmosphere and back into orbit around the sun". The scientists involved in the study claim that the object that caused the event will pass close to Earth again in 2045.
However, the orbit of 2005 NB56 has been computed on the basis on an observed arc of only 17 days, and it is therefore impossible to predict its position in 1908 with sufficient accuracy to verify the possible connection.
Natural H-Bomb.
In 1989, Serge J.D. D'Alessio proposed that some of the deuterium in a comet entering Earth's atmosphere may have undergone a nuclear fusion reaction. leaving a distinctive signature in the form of carbon-14. They concluded that any release of nuclear energy would have been almost negligible. Independently, in 1990, César Sirvent proposed that a deuterium comet, i.e., a comet with an anomalous high concentration of deuterium in its composition, could have exploded as a natural hydrogen bomb, generating most of the energy released. The sequence would be the first time a mechanical or kinetic explosion triggered a thermonuclear reaction. These proposals are inconsistent with our knowledge of the composition of comets and of the temperature and pressure conditions necessary for initiating a nuclear fusion reaction. Studies have found the concentration of radioactive isotopes in the blast region to be inconsistent with those expected following a nuclear explosion, fusion or otherwise.
Edward Drobyshevski has suggested that the event was caused by the explosion of the hydrogen-saturated part of the nucleus of a comet that struck Earth's atmosphere, with most of the remaining comet nucleus surviving, and possibly continuing to orbit the sun.
Black hole.
In 1973, Albert A. Jackson and Michael P. Ryan, physicists at the University of Texas at Austin, proposed that the Tunguska event was caused by a small (around 1017 kg to 1019 kg) black hole passing through Earth. This hypothesis is considered flawed, as there was no so-called exit event—a second explosion occurring as the black hole, having tunnelled through Earth, shot out the other side on its way back into space. Based on the direction of impact, the exit event would have occurred in the North Atlantic, closer than the impact event to the seismic recording stations that collected much of the evidence of the event. The hypothesis also fails to account for evidence that cosmic material was deposited by the extraterrestrial body, including dust trails in the atmosphere and the distribution of high-nickel magnetic spherules around the impact area.
Antimatter.
In 1941, Lincoln LaPaz, and later in 1965, Clyde Cowan, Chandra R. Atluri, and Willard F. Libby suggested that the Tunguska event was caused by the annihilation of a chunk of antimatter falling from space. As with the other hypotheses described in this section, this does not account for the mineral debris left in the area of the explosion.
Nikola Tesla.
In popular literature and on conspiracy theory websites Nikola Tesla is pointed to as the cause of the Tunguska event, either as a result of running his Wardenclyffe tower wireless power transmitter or from testing his death ray.
Geophysical hypothesis.
Astrophysicist Wolfgang Kundt has suggested the Tunguska event was caused by the sudden release and subsequent explosion of 10 million tons of natural gas from within Earth's crust. The similar verneshot hypothesis has also been suggested as a possible cause of the Tunguska event.
Similar events.
The Tunguska event is the strongest, but not the only, example of unexplained explosion events or bolide air-bursts. There have been a number of similar events (e.g. the 1930 Curuçá River event in Brazil). Modern developments in infrasound detection by the Comprehensive Nuclear-Test-Ban Treaty Organization and infrared DSP satellite technology have reduced the likelihood of undetected airbursts.
A much smaller air burst occurred over a populated area in Russia on February 15, 2013, at 7:25:00 Moscow time at Chelyabinsk in the Ural district of Russia. It inflicted over 1,200 injuries, mainly from broken glass falling from windows shattered by the meteor's shock wave.
Tunguska afterglow.
On the night of 30 June 1908 and the next three nights, aurora-like displays were seen in northern Europe. W. F. Denning wrote that "... certain features of the glows struck me as essentially different from exhibitions of normal Auroræ Boreales."
References.
Notes
Bibliography
</dl>

</doc>
<doc id="30674" url="http://en.wikipedia.org/wiki?curid=30674" title="The Terrorist (1997 film)">
The Terrorist (1997 film)

The Terrorist (Tamil: தீவிரவாதி ("Theeviravaathi")) is an Indian Tamil film directed by Santosh Sivan. The film portrays a period in the life of a 19-year-old woman, Malli (Ayesha Dharker), sent to assassinate a leader in South Asia through a suicide bombing. It stars Dharkar, K. Krishna and Sonu Sisupal. Released in 1998, the film was shot in 15 days, with natural lighting, on a budget of $50,000. 
The film won a number of awards at international film festivals. Actor John Malkovich first saw the film at the 1998 Cairo International Film Festival and subsequently adopted the film as a kind of post-facto executive producer (the reissued film's titles read "John Malkovich Presents"). Critic Roger Ebert has included the film in his series of "Great Movies" reviews. Ebert concludes his review with the following line: "Every time I see the film, I feel a great sadness, that a human imagination could be so limited that it sees its own extinction as a victory."
The film that proved his mastery over the visual language was The Terrorist which has become a textbook of sorts for visual communication students, with scenes from the movie being used by Michael Chapman, Martin Scorsese’s cinematographer, to explain the tenets of cinematography during workshops. According to film critic Roger Ebert, it was a film ‘scripted by the camera’. Says Sivan: “One day I got a call from Samuel Lee Jackson who was interested to cast the heroine of The Terrorist, Ayesha, in a Hollywood film.”
Plot.
"The Terrorist" focuses on a 19 year old woman named Malli, who joined a terrorist organization at a very young age after her brother was killed in the cause. She eventually volunteers herself to become a suicide bomber in an assassination mission. As the plot moves forward, she discovers the importance of human life, after realizing she is pregnant. This causes Malli to question her determination to complete the mission.
Inspiration.
On 21 May 1991, Rajiv Gandhi was campaigning in favour of a UCPI candidate for the upcoming parliamentary elections in Tamil Nadu, when he was assassinated by a suicide bomber in the Indian town of Sriperumbudur, near Madras.
The suicide bomber, Thenmozhi Rajaratnam aka Dhanu, is widely believed to be have been a LTTE member. Dhanu was a cousin of Shivarasan, the supposed mastermind of the assassination. Dhanu wore the belt bomb with the explosive material in her lower back region and the power pack, two switches and the circuitry in front.
When Santosh Sivan, a well-known cinematographer, wanted to make a film on terrorism and about a terrorist, he chose the above events as the inspiration for his story.
The film is not a direct biography of Dhanu, as she had a whole troupe working with her, as backup in case she failed.

</doc>
<doc id="30677" url="http://en.wikipedia.org/wiki?curid=30677" title="Tool">
Tool

A tool is any physical item that can be used to achieve a goal, especially if the item is not consumed in the process. Informally the word is also used to describe a procedure or process with a specific purpose. Tool use by humans dates back millions of years, and other animals are also known to employ simple tools.
Tools that are used in particular fields or activities may have different designations such as "instrument", "utensil", "implement", "machine", "device," or "apparatus". The set of tools needed to achieve a goal is "equipment". The knowledge of constructing, obtaining and using tools is technology.
History.
Anthropologists believe that the use of tools was an important step in the evolution of mankind. Humans evolved an opposable thumb — useful in holding tools — and increased dramatically in intelligence, which aided in the use of tools. Because tools are used extensively by both humans and wild chimpanzees, it is widely assumed that the first routine use of tools took place prior to the divergence between the two species. These early tools, however, were likely made of perishable materials such as sticks, or consisted of unmodified stones that cannot be distinguished from other stones as tools. 
Stone artifacts only date back to about 2.5 million years ago. However, a 2010 study suggests the hominin species "Australopithecus afarensis" ate meat by carving animal carcasses with stone implements. This finding pushes back the earliest known use of stone tools among hominins to about 3.4 million years ago.
Finds of actual tools date back at least 2.6 million years in Ethiopia. One of the earliest distinguishable stone tool forms is the hand axe.
Up until recently, weapons found in digs were the only tools of “early man” that were studied and given importance. Now, more tools are recognized as culturally and historically relevant. As well as hunting, other activities required tools such as preparing food, “…nutting, leatherworking, grain harvesting and woodworking…” Included in this group are “flake stone tools".
Tools are the most important items that the ancient humans used to climb to the top of the food chain; by inventing tools, they were able to accomplish tasks that human bodies could not, such as using a spear or bow and arrow to kill prey, since their teeth were not sharp enough to pierce many animals' skins. “Man the hunter” as the catalyst for Hominin change has been questioned. Based on marks on the bones at archaeological sites, it is now more evident that pre-humans were scavenging off of other predators' carcasses rather than killing their own food.
Mechanical devices experienced a major expansion in their use in Ancient Greece and Ancient Rome with the systematic employment of new energy sources, especially waterwheels. Their use expanded through the Dark Ages with the addition of windmills.
Machine tools occasioned a surge in producing new tools in the industrial revolution. Advocates of nanotechnology expect a similar surge as tools become microscopic in size.
Functions.
One can classify tools according to their basic functions:
Some tools may be combinations of other tools. An alarm-clock is for example a combination of a measuring tool (the clock) and a perception tool (the alarm). This enables the alarm-clock to be a tool that falls outside of all the categories mentioned above.
There is some debate on whether to consider protective gear items as tools, because they do not directly help perform work, just protect the worker like ordinary clothing. They do meet the general definition of tools and in many cases are necessary for the completion of the work. Personal protective equipment includes such items as gloves, safety glasses, ear defenders and biohazard suits.
Tool substitution.
Often, by design or coincidence, a tool may share key functional attributes with one or more other tools. In this case, some tools can substitute for other tools, either as a makeshift solution or as a matter of practical efficiency. "One tool does it all" is a motto of some importance for workers who cannot practically carry every specialized tool to the location of every work task; such as a carpenter who does not necessarily work in a shop all day and needs to do jobs in a customer's house. Tool substitution may be divided broadly into two classes: substitution "by-design", or "multi-purpose" , and substitution as makeshift. Substitution "by-design" would be tools that are designed specifically to accomplish multiple tasks using only that one tool. 
Substitution as makeshift is when human ingenuity comes into play and a tool is used for its unintended purpose such as a mechanic using a long screw driver to separate a cars control arm from a ball joint instead of using a tuning fork. In many cases, the designed secondary functions of tools are not widely known. As an example of the former, many wood-cutting hand saws integrate a carpenter's square by incorporating a specially shaped handle that allows 90° and 45° angles to be marked by aligning the appropriate part of the handle with an edge and scribing along the back edge of the saw. The latter is illustrated by the saying "All tools can be used as hammers." Nearly all tools can be used to function as a hammer, even though very few tools are intentionally designed for it and even fewer work as well as the original.
Tools are also often used to substitute for many mechanical apparatuses, especially in older mechanical devices. In many cases a cheap tool could be used to occupy the place of a missing mechanical part. A window roller in a car could easily be replaced with a pair of vise-grips or regular pliers. A transmission shifter or ignition switch would be able to be replaced with a screw-driver. Again, these would be considered tools that are being used for their unintended purposes, substitution as makeshift. Tools such as a rotary tool would be considered the substitution "by-design", or "multi-purpose". This class of tools allows the use of one tool that has at least two different capabilities. "Multi-purpose" tools are basically multiple tools in one device/tool. Tools such as this are often power tools that come with many different attachments like a rotary tool does, so you could say that a power drill is a "multi-purpose" tool because you can do more than just one thing with a power drill.
Multi-use tools.
A multi-tool is a hand tool that incorporates several tools into a single, portable device; the Swiss army knife represents one of the earliest examples. Other tools have a primary purpose but also incorporate other functionality - for example, lineman's pliers incorporate a gripper and cutter, and are often used as a hammer; and some hand saws incorporate a carpenter's square in the right-angle between the blade's dull edge and the saw's handle. This would also be the category in which the "multi-purpose" tools since they are also multiple tools in one (multi-use and multi-purpose can be used interchangeably). These types of tools were specifically made to catch the eye of many different craftsman who traveled to do their work. To these workers these types of tools were revolutionary because they were one tool or one device that could do several different things. With this new revolution of tools the traveling craftsman would not have to carry so many tools with them to job sites, being that their space would be limited to the vehicle they were driving. The problem of having to deal with so many different tools was solved with the overtaking of multi-use tools.
Use by other animals.
Observation has confirmed that a number of species can use tools including monkeys, apes, elephants, several birds, and sea otters. Philosophers originally thought that only humans had the ability to "make" tools, until zoologists observed birds and monkeys making tools. Now the unique relationship of humans with tools is considered to be that we are the only species that uses tools to make "other" tools.
Tool metaphors.
A telephone is a communication tool that interfaces between two people engaged in conversation at one level. It also interfaces between each user and the communication network at another level. It is in the domain of media and communications technology that a counter-intuitive aspect of our relationships with our tools first began to gain popular recognition. Marshall McLuhan famously said "We shape our tools. And then our tools shape us." McLuhan was referring to the fact that our social practices co-evolve with our use of new tools and the refinements we make to existing tools.
References.
Notes

</doc>
<doc id="30680" url="http://en.wikipedia.org/wiki?curid=30680" title="The New York Times">
The New York Times

The New York Times (NYT) is an American daily newspaper, founded and continuously published in New York City since September 18, 1851, by The New York Times Company. It has won 114 Pulitzer Prizes, more than any other news organization.
The paper's print version has the largest circulation of any metropolitan newspaper in the United States, and the second-largest circulation overall, behind "The Wall Street Journal". It is ranked 39th in the world by circulation. Following industry trends, its weekday circulation has fallen to fewer than one million daily since 1990. Nicknamed for years as "The Gray Lady", "The New York Times" is long regarded within the industry as a national "newspaper of record". It is owned by The New York Times Company. Arthur Ochs Sulzberger, Jr., (whose family (Ochs-Sulzberger) has controlled the paper for five generations, since 1896), is both the paper's publisher and the company's chairman. Its international version, formerly the "International Herald Tribune", is now called the "International New York Times".
The paper's motto, "All the News That's Fit to Print", appears in the upper left-hand corner of the front page. Since the mid-1970s, it has greatly expanded its lay-out and organization, adding special weekly sections on various topics supplementing the regular news, editorials, sports and features. Recently it has been organized into sections: News, Editorials/Opinions-Columns/Op-Ed, New York (metropolitan), Business, Sports of The Times, Arts, Science, Styles, Home, and other features. On Sunday, it is supplemented by sections of The Week in Review, "The New York Times Book Review", "The New York Times Magazine" and recently "". "The New York Times" stayed with the broadsheet full page set-up (as some others have changed into a tabloid lay-out) and an eight-column format for several years after most papers switched to six, and was one of the last newspapers to adopt color photography, especially on the front page.
History.
"The New York Times" was founded as the "New-York Daily Times" on September 18, 1851, by journalist and politician Henry Jarvis Raymond, (1820–1869), then a Whig Party member and later second chairman of the newly organized Republican Party National Committee, and former banker George Jones. Sold for a penny (equivalent to <br>{Inflation} - Amount must not have "" prefix: 1.  ¢ today), the inaugural edition attempted to address various speculations on its purpose and positions that preceded its release:
We shall be "Conservative", in all cases where we think Conservatism essential to the public good;—and we shall be "Radical" in everything which may seem to us to require radical treatment and radical reform. We do not believe that "everything" in Society is either exactly right or exactly wrong;—what is good we desire to preserve and improve;—what is evil, to exterminate, or reform.
The newspaper shortened its name to "The New-York Times" in 1857. It dropped the hyphen in the city name in the 1890s. On April 21, 1861, "The New York Times" departed from its original Monday–Saturday publishing schedule and joined other major dailies in adding a Sunday edition to offer daily coverage of the Civil War. One of the earliest public controversies it was involved with was the Mortara Affair, the subject of twenty editorials it published alone.
The main office of "The New York Times" was attacked during the New York Draft Riots sparked by the beginning of military conscription for the Northern Union Army now instituted in the midst of the Civil War on July 13, 1863. At "Newspaper Row", across from City Hall, Henry Raymond, owner and editor of "The New York Times", averted the rioters with "Gatling" (early machine, rapid-firing) guns, one of which he manned himself. The mob now diverted, instead attacked the headquarters of abolitionist publisher Horace Greeley's "New York Tribune" until forced to flee by the Brooklyn City Police, who had crossed the East River to help the Manhattan authorities.
The newspaper's influence grew during 1870-71 when it published a series of exposés on William Magear ("Boss") Tweed, leader of the city's Democratic Party—popularly known as "Tammany Hall" (from its early 19th Century meeting headquarters) — that led to the end of the "Tweed Ring's" domination of New York's City Hall. In the 1880s, "The New York Times" transitioned gradually from editorially supporting Republican Party candidates to becoming more politically independent and analytical; in 1884, the paper supported Democrat Grover Cleveland (former Mayor of Buffalo and Governor of New York State) in his first presidential campaign. While this move cost "The New York Times"‍ '​ readership among its more conservative, business-oriented, upper-class readers, the paper eventually regained most of its lost ground within a few years and slowly acquired a reputation for even-handedness and accurate modern reporting, especially by the 1890s under its new later owner/publisher's philosophies, Adolph Ochs of Chattanooga, Tennessee.
"The New York Times" was acquired by Adolph Ochs, publisher of the "Chattanooga Times", in 1896. The following year, he coined the paper's slogan, "All The News That's Fit To Print", which has since been printed in a box in the upper right hand corner of the front page; this was a jab at competing papers such as Joseph Pulitzer's "New York World" and William Randolph Hearst's "New York Journal" which were now being known for a lurid, sensationalist and often inaccurate reporting of facts and opinions known by the end of the century as "yellow journalism". Under Ochs guidance, continuing and expanding upon the Henry Raymond tradition, (which were from the era of James Gordon Bennett of the "New York Herald" which predated Pulitzer and Hearst's arrival in New York), "The New York Times" achieved international scope, circulation, and reputation. In 1904, "The New York Times" received the first on-the-spot wireless telegraph transmission from a naval battle, a report of the destruction of the Imperial Russian Navy's Baltic Fleet at the Battle of Port Arthur in the Straits of Tsushima off the eastern coast of Korea in the Yellow Sea in the western Pacific Ocean after just sailing across the globe from Europe from the press-boat "Haimun" during the Russo-Japanese War (one of the most important and history-changing naval battles in history). In 1910, the first air delivery of "The New York Times" to Philadelphia began. "The New York Times"‍ '​ first trans-Atlantic delivery by air to London occurred in 1919 by dirigible. In 1920, a "4 A.M. Airplane Edition" was sent by plane to Chicago so it could be in the hands of Republican convention delegates by evening.
In the 1940s, the paper extended its breadth and reach. The crossword began appearing regularly in 1942, and the fashion section in 1946. "The New York Times" began an international edition in 1946. The international edition stopped publishing in 1967, when "The New York Times" joined the owners of the "New York Herald Tribune" and "The Washington Post" to publish the "International Herald Tribune" in Paris. The paper bought a classical radio station (WQXR) in 1946. In addition to owning WQXR, the newspaper also formerly owned its AM sister, WQEW (1560 AM). The classical music radio format was simulcast on both frequencies until the early 1990s, when the big-band and standards music format of WNEW-AM (now WBBR) moved from 1130 AM to 1560. The AM radio station changed its call letters from WQXR to WQEW. By the beginning of the 21st century, "The New York Times" was leasing WQEW to ABC Radio for its Radio Disney format, which continues on 1560 AM. Disney became the owner of WQEW in 2007. On July 14, 2009, it was announced that WQXR was to be sold to WNYC, who on October 8, 2009, moved the station to 105.9 FM and began to operate the station as a non-commercial.
"The New York Times" is third in national circulation, after "USA Today" and "The Wall Street Journal". The newspaper is owned by The New York Times Company, in which descendants of Adolph Ochs, principally the Sulzberger family, maintain a dominant role. In 2009, article circulation dropped 7.3 percent to about 928,000; this is the first time since the 1980s that it has fallen under one million.s of 26, 2010, the paper reported a circulation of 906,100 copies on weekdays and 1,356,800 copies on Sundays. In the New York City metropolitan area, the paper costs $2.50 Monday through Saturday and $5 on Sunday. "The New York Times" has won 114 Pulitzer Prizes, more than any other newspaper.
In 2009, the newspaper began production of local inserts in regions outside of the New York area. Beginning October 16, 2009, a two-page "Bay Area" insert was added to copies of the Northern California edition on Fridays and Sundays. The newspaper commenced production of a similar Friday and Sunday insert to the Chicago edition on November 20, 2009. The inserts consist of local news, policy, sports, and culture pieces, usually supported by local advertisements.
In addition to its New York City headquarters, the newspaper has 10 news bureaus in the New York region, 11 national news bureaus and 26 foreign news bureaus. "The New York Times" reduced its page width to 12 in from 13.5 in on August 6, 2007, adopting the width that has become the U.S. newspaper industry standard.
Because of its steadily declining sales attributed to the rise of online alternative media and social media, the newspaper has been going through a downsizing for several years, offering buyouts to workers and cutting expenses, in common with a general trend among print news media.
Headquarters building.
The newspaper's first building was located at 113 Nassau Street in New York City. In 1854, it moved to 138 Nassau Street, and in 1858, it moved to 41 Park Row, making it the first newspaper in New York City housed in a building built specifically for its use.
The paper moved its headquarters to the Times Tower, located at 1475 Broadway in 1904, in an area called Longacre Square, that was later renamed Times Square in honor of the newspaper. The top of the building – now known as One Times Square – is the site of the New Year's Eve tradition of lowering a lighted ball, that was started by the paper. The building is also notable for its electronic news ticker – popularly known as "The Zipper" – where headlines crawled around the outside of the building. It is still in use, but is now operated by the Reuters news agency. After nine years in its Times Square tower, the newspaper had an Annex built at 229 West 43rd Street. After several expansions, the 43rd Street building became the newspaper's main headquarters in 1960 and the Times Tower on Broadway was sold the following year. It served as the newspaper's main printing plant until 1997, when the newspaper opened a state-of-the-art printing plant in the College Point section of the borough of Queens.
A decade later, The "New York Times" moved its newsroom and businesses headquarters from West 43rd Street to a gleaming new tower at 620 Eighth Avenue between West 40th and 41st Streets, in Manhattan – directly across Eighth Avenue from the Port Authority Bus Terminal. The new headquarters for the newspaper, known officially as The New York Times Building but unofficially called the new "Times Tower" by many New Yorkers, is a skyscraper designed by Renzo Piano.
"New York Times v. Sullivan".
The paper's involvement in a 1964 libel case helped bring one of the key United States Supreme Court decisions supporting freedom of the press, "New York Times Co. v. Sullivan". In it, the United States Supreme Court established the "actual malice" standard for press reports about public officials or public figures to be considered defamatory or libelous. The malice standard requires the plaintiff in a defamation or libel case prove the publisher of the statement knew the statement was false or acted in reckless disregard of its truth or falsity. Because of the high burden of proof on the plaintiff, and difficulty in proving what is inside a person's head, such cases by public figures rarely succeed.
The Pentagon Papers.
In 1971, the Pentagon Papers, a secret United States Department of Defense history of the United States' political and military involvement in the Vietnam War from 1945 to 1967, were given ("leaked") to Neil Sheehan of "The New York Times" by former State Department official Daniel Ellsberg, with his friend Anthony Russo assisting in copying them. "The New York Times" began publishing excerpts as a series of articles on June 13. Controversy and lawsuits followed. The papers revealed, among other things, that the government had deliberately expanded its role in the war by conducting air strikes over Laos, raids along the coast of North Vietnam, and offensive actions taken by U.S. Marines well before the public was told about the actions, all while President Lyndon B. Johnson had been promising not to expand the war. The document increased the credibility gap for the U.S. government, and hurt efforts by the Nixon administration to fight the ongoing war.
When "The New York Times" began publishing its series, President Richard Nixon became incensed. His words to National Security Advisor Henry Kissinger included "People have gotta be put to the torch for this sort of thing..." and "Let's get the son-of-a-bitch in jail." After failing to get "The New York Times" to stop publishing, Attorney General John Mitchell and President Nixon obtained a federal court injunction that "The New York Times" cease publication of excerpts. The newspaper appealed and the case began working through the court system. On June 18, 1971, "The Washington Post" began publishing its own series. Ben Bagdikian, a "Post" editor, had obtained portions of the papers from Ellsberg. That day the "Post" received a call from the Assistant Attorney General, William Rehnquist, asking them to stop publishing. When the "Post" refused, the U.S. Justice Department sought another injunction. The U.S. District court judge refused, and the government appealed. On June 26, 1971 the U.S. Supreme Court agreed to take both cases, merging them into "New York Times Co. v. United States" 403 US 713. On June 30, 1971, the Supreme Court held in a 6–3 decision that the injunctions were unconstitutional prior restraints and that the government had not met the burden of proof required. The justices wrote nine separate opinions, disagreeing on significant substantive issues. While it was generally seen as a victory for those who claim the First Amendment enshrines an absolute right to free speech, many felt it a lukewarm victory, offering little protection for future publishers when claims of national security were at stake.
Discrimination in employment.
Discriminatory practices restricting women in editorial positions were part of the history, correlating with effects on the journalism published at the time. The newspaper's first general woman reporter was Jane Grant, who described her experience afterwards. She wrote, "In the beginning I was charged not to reveal the fact that a female had been hired". Other reporters nicknamed her Fluff and she was subjected to considerable hazing. Because of her gender, promotions were out of the question, according to the then-managing editor. She was there for fifteen years, interrupted by World War I.
In 1935, Anne McCormick wrote to Arthur Hays Sulzberger, "I hope you won't expect me to revert to 'woman's-point-of-view' stuff." Later, she interviewed major political leaders and appears to have had easier access than her colleagues did. Even those who witnessed her in action were unable to explain how she got the interviews she did. Clifton Daniel said, "[After World War II,] I'm sure Adenauer called her up and invited her to lunch. She never had to grovel for an appointment." Covering world leaders' speeches after World War II at the National Press Club was limited to men by a Club rule. When women were eventually allowed in to hear the speeches, they still were not allowed to ask the speakers questions, although men were allowed and did ask, even though some of the women had won Pulitzer Prizes for prior work. "Times" reporter Maggie Hunter refused to return to the Club after covering one speech on assignment. Nan Robertson's article on the Union Stock Yards, Chicago, was read aloud as anonymous by a professor, who then said, "'It will come as a surprise to you, perhaps, that the reporter is a "girl,"' he began... [G]asps; amazement in the ranks. 'She had used all her senses, not just her eyes, to convey the smell and feel of the stockyards. She chose a difficult subject, an offensive subject. Her imagery was strong enough to revolt you.'" "The New York Times" hired Kathleen McLaughlin after ten years at the "Chicago Tribune", where "[s]he did a series on maids, going out herself to apply for housekeeping jobs."
End of tenure track.
In February 2013, the paper stopped offering lifelong positions for its journalists and editors.
Ownership.
In 1896, Adolph Ochs bought the "New York Times", a money-losing newspaper, and formed the New York Times Company. The Ochs-Sulzberger family, one of the United States‍ '​ newspaper dynasties, has owned "The New York Times" ever since. After the publisher went public in the 1960s, the family continued to exert control through its ownership of the vast majority of Class B voting shares. Class A shareholders are permitted restrictive voting rights while Class B shareholders are allowed open voting rights.
The Ochs-Sulzberger family trust controls roughly 88 percent of the company's class B shares. Any alteration to the dual-class structure must be ratified by six of eight directors who sit on the board of the Ochs-Sulzberger family trust. The Trust board members are Daniel H. Cohen, James M. Cohen, Lynn G. Dolnick, Susan W. Dryfoos, Michael Golden, Eric M. A. Lax, Arthur O. Sulzberger, Jr. and Cathy J. Sulzberger.
Turner Catledge, the top editor at "The New York Times" from 1952 to 1968, wanted to hide the ownership influence. Arthur Sulzberger routinely wrote memos to his editor, each containing suggestions, instructions, complaints, and orders. When Catledge would receive these memos he would erase the publisher's identity before passing them to his subordinates. Catledge thought that if he removed the publisher's name from the memos it would protect reporters from feeling pressured by the owner.
Carlos Slim loan and investment.
On January 20, 2009, the "New York Times" reported that Carlos Slim, Mexican telecommunications magnate and the world's second richest person, loaned it $250 million "to help the newspaper company finance its businesses". Since then, Slim has made additional investments in "Times" stock; 
s of 6, 2011[ [update]], according to Reuters, his position was estimated at over 8.1% of Class A shares.
Dual-class shares.
Dual-class structures caught on in the mid-20th century as families such as the Grahams of The Washington Post Company sought to gain access to public capital without losing control. Dow Jones & Co., publisher of "The Wall Street Journal", had a similar structure and was controlled by the Bancroft family but was later bought by News Corporation in 2007, which itself is controlled by Rupert Murdoch and his family through a similar dual-class structure.
Content.
Sections.
The newspaper is organized in three sections, including the magazine.
Some sections, such as Metro, are only found in the editions of the paper distributed in the New York–New Jersey–Connecticut Tri-State Area and not in the national or Washington, D.C. editions. Aside from a weekly roundup of reprints of editorial cartoons from other newspapers, "The New York Times" does not have its own staff editorial cartoonist, nor does it feature a comics page or Sunday comics section. In September 2008, "The New York Times" announced that it would be combining certain sections effective October 6, 2008, in editions printed in the New York metropolitan area. The changes folded the Metro Section into the main International / National news section and combined Sports and Business (except Saturday through Monday, when Sports is still printed as a standalone section). This change also included having the name of the Metro section be called New York outside of the Tri-State Area. The presses used by "The New York Times" allow four sections to be printed simultaneously; as the paper had included more than four sections all days except Saturday, the sections had to be printed separately in an early press run and collated together. The changes will allow "The New York Times" to print in four sections Monday through Wednesday, in addition to Saturday. "The New York Times"‍ '​ announcement stated that the number of news pages and employee positions will remain unchanged, with the paper realizing cost savings by cutting overtime expenses. According to Russ Stanton, editor of the "Los Angeles Times", a competitor, the newsroom of "The New York Times" is twice the size of the "Los Angeles Times", which currently has a newsroom of 600.
In March 2014, Vanessa Friedman was named the "fashion director and chief fashion critic" of the New York Times.
Style.
When referring to people, "The New York Times" generally uses honorifics, rather than unadorned last names (except in the sports pages, Book Review and Magazine). It stayed with an eight-column format until September 1976, years after other papers had switched to six, and it was one of the last newspapers to adopt color photography, with the first color photograph on the front page appearing on October 16, 1997. In the absence of a major headline, the day's most important story generally appears in the top-right column, on the main page. The typefaces used for the headlines are custom variations of Cheltenham. The running text is set at 8.7 point Imperial.
Joining a roster of other major American newspapers in the last ten years, including "USA Today", "The Wall Street Journal" and "The Washington Post", "The New York Times" announced on July 18, 2006, that it would be narrowing the width of its paper by six inches. In an era of dwindling circulation and significant advertising revenue losses for most print versions of American newspapers, the move, which would result in a 5 percent reduction in news coverage, would have a target savings of $12 million a year for the paper. The change from the traditional 54 in broadsheet style to a more compact 48-inch web width (12-inch page width) was addressed by both Executive Editor Bill Keller and "The New York Times" President Scott Heekin-Canedy in memos to the staff. Keller defended the "more reader-friendly" move indicating that in cutting out the "flabby or redundant prose in longer pieces" the reduction would make for a better paper. Similarly, Keller confronted the challenges of covering news with "less room" by proposing more "rigorous editing" and promised an ongoing commitment to "hard-hitting, ground-breaking journalism". The official change went into effect on August 6, 2007.
"The New York Times" printed a display advertisement on its first page on January 6, 2009, breaking tradition at the paper. The advertisement for CBS was in color and was the entire width of the page. The newspaper promised it would place first-page advertisements on only the lower half of the page.
In August 2014, "The New York Times" decided to increase their use of the term "torture" in stories about harsh interrogations, shifting from their previous description of the interrogations as "harsh" or "brutal".
The paper maintains a strict profanity policy; e.g. a 2007 review of a concert by punk bank Fucked Up completely avoided mention of the group's name.
Reputation and awards.
"The New York Times" has established links regionally with 16 bureaus in the New York region, nationally, with 11 bureaus within the US, and globally, with 26 foreign news bureaus.
"The New York Times" has won 117 Pulitzer Prizes, more than any other newspaper. The prize is awarded for excellence in journalism in a range of categories.
It has also won four Peabody Awards, including a personal one for Jack Gould in 1956.
Web presence.
"The New York Times" has had a presence on the Web since 1996, and has been ranked one of the top websites. Accessing some articles requires registration, though this could be bypassed in some cases through "Times" RSS feeds. The website had 555 million pageviews in March 2005. The domain "nytimes.com" attracted at least 146 million visitors annually by 2008 according to a Compete.com study. "The New York Times" Web site ranks 59th by number of unique visitors, with over 20 million unique visitors in March 2009 making it the most visited newspaper site with more than twice the number of unique visitors as the next most popular site. Also, as of 2009[ [update]], nytimes.com produced 22 of the 50 most popular newspaper blogs.
In September 2005, the paper decided to begin subscription-based service for daily columns in a program known as "TimesSelect", which encompassed many previously free columns. Until being discontinued two years later, "TimesSelect" cost $7.95 per month or $49.95 per year, though it was free for print copy subscribers and university students and faculty. To avoid this charge, bloggers often reposted TimesSelect material, and at least one site once compiled links of reprinted material. On September 17, 2007, "The New York Times" announced that it would stop charging for access to parts of its Web site, effective at midnight the following day, reflecting a growing view in the industry that subscription fees cannot outweigh the potential ad revenue from increased traffic on a free site. In addition to opening almost the entire site to all readers, "The New York Times" news archives from 1987 to the present are available at no charge, as well as those from 1851 to 1922, which are in the public domain. Access to the "Premium Crosswords" section continues to require either home delivery or a subscription for $6.95 per month or $39.95 per year. "Times" columnists including Nicholas Kristof and Thomas Friedman had criticized "TimesSelect", with Friedman going so far as to say "I hate it. It pains me enormously because it's cut me off from a lot, a lot of people, especially because I have a lot of people reading me overseas, like in India ... I feel totally cut off from my audience."
"The New York Times" was made available on the iPhone and iPod Touch in 2008, and on the iPad mobile devices in 2010. It was also the first newspaper to offer a video game as part of its editorial content, "Food Import Folly" by Persuasive Games. In 2010, "The New York Times" editors collaborated with students and faculty from New York University's Studio 20 Journalism Masters program to launch and produce "The Local East Village", a hyperlocal blog designed to offer news "by, for and about the residents of the East Village". That same year, reCAPTCHA helped to digitize old editions of "The New York Times".
In 2012, "The New York Times" introduced a Chinese-language news site, cn.nytimes.com, with content created by staff based in Shanghai, Beijing and Hong Kong, though the server was placed outside of China to avoid censorship issues. On October 15, "The New York Times" announced that it was adding a Portuguese-language news site next year. In March 2013, "The New York Times" and National Film Board of Canada announced a partnership entitled "A Short History of the Highrise", which will create four short documentaries for the internet about life in highrise buildings as part of the NFB's "Highrise" project, utilizing images from the newspaper's photo archives for the first three films, and user-submitted images for the final film. The third project in the series, "A Short History of the Highrise," won a Peabody Award in 2013.
Falling print advertising revenue and projections of continued decline resulted in a paywall being instituted in 2011, regarded as modestly successful after garnering several hundred thousand subscriptions and about $100 million in revenue as of 2012[ [update]]. The paywall was announced on March 17, 2011, that starting on March 28, 2011 (March 17, 2011 for Canada), it would charge frequent readers for access to its online content. Readers would be able to access up to 20 articles each month without charge. (Although beginning in April 2012, the number of free-access articles was halved to just 10 articles per month.) Any reader who wanted to access more would have to pay for a digital subscription. This plan would allow free access for occasional readers, but produce revenue from "heavy" readers. Digital subscriptions rates for four weeks range from $15 to $35 depending on the package selected, with periodic new subscriber promotions offering four-week all-digital access for as low as 99¢. Subscribers to the paper's print edition get full access without any additional fee. Some content, such as the front page and section fronts will remain free, as well as the Top News page on mobile apps. In January 2013, the "Times"‍ '​ public editor Margaret Sullivan announced that for the first time in many decades, the paper generated more revenue through subscriptions than through advertising.
Online content is available through a metered paywall begun in 2011. The first ten articles per month are free to read, while additional articles require a subscription. The paper's website was hacked on August 29, 2013, by the Syrian Electronic Army, a hacking group that supports the government of Syrian President Bashar al-Assad. The SEA managed to penetrate the paper's domain name registrar, Melbourne IT, and alter DNS records for the "Times", putting some of its websites out of service for hours.
Mobile presence.
The "Times Reader" is a digital version of "The New York Times". It was created via a collaboration between the newspaper and Microsoft. "Times Reader" takes the principles of print journalism and applies them to the technique of online reporting. "Times Reader" uses a series of technologies developed by Microsoft and their Windows Presentation Foundation team. It was announced in Seattle in April 2006 by Arthur Ochs Sulzberger Jr., Bill Gates, and Tom Bodkin. In 2009 the "Times Reader" 2.0 was rewritten in Adobe AIR. In December 2013, the newspaper announced that the Times Reader app would be discontinued on January 6, 2014, urging readers of the app to instead begin using the subscription-only "Today's Paper" app.
In 2008, "The New York Times" created an app for the iPhone and iPod touch which allowed users to download articles to their mobile device enabling them to read the paper even when they were unable to receive a signal. In April 2010, "The New York Times" announced it will begin publishing daily content through an iPad app. s of 2010[ [update]], "The New York Times" iPad app is ad-supported and available for free without a paid subscription, but translated into a subscription-based model in 2011.
In 2010, the newspaper also launched an App for Android smartphones.
Moscow.
Communication with its Russian readers is a special project of "The New York Times" launched in February 2008, guided by Clifford J. Levy. Some "Times" articles covering the broad spectrum of political and social topics in Russia are being translated into Russian and offered for the attention of Russia's bloggers in "The New York Times" community blog. After that, selected responses of Russian bloggers are being translated into English and published at "The New York Times" site among comments from English readers.
Reporter resources.
The website's "Newsroom Navigator" collects online resources for use by reporters and editors. It is maintained by Rich Meislin. Further specific collections are available to cover the subjects of business, politics and health. In 1998, Meislin was editor-in-chief of electronic media at the newspaper.
Interruptions.
Due to holidays, no editions were printed on November 23, 1851; January 2, 1852; July 4, 1852; January 2, 1853; January 1, 1854.
Due to strikes, the regular edition of "The New York Times" was not printed during the following periods:
Coverage issues.
Political persuasion overall.
According to a 2007 survey by conservative-leaning Rasmussen Reports of public perceptions of major media outlets, 40% saw the paper as having a liberal slant, 20% no political slant and 11% believe it has a conservative slant. In December 2004, a University of California, Los Angeles study by former fellows of a conservative think tank gave "The New York Times" a score of 63.5 on a 100-point scale, with 0 being most conservative and 100 being most liberal. Special Report, an evening program on Fox News, comparatively, received 39.7. The validity of the study has been questioned by organizations, including the liberal media "watchdog" group Media Matters for America. In mid-2004, the newspaper's then public editor (ombudsman), Daniel Okrent, wrote an opinion piece in which he said that "The New York Times" did have a liberal bias in news coverage of certain social issues such as abortion and permitting gay marriage. He stated that this bias reflected the paper's cosmopolitanism, which arose naturally from its roots as a hometown paper of New York City. Okrent did not comment at length on the issue of bias in coverage of other "hard news", such as fiscal policy, foreign policy, or civil liberties. "The New York Times" has not endorsed a Republican for president since Dwight D. Eisenhower in 1956; since that year it has endorsed every Democratic nominee; although it did endorse incumbent Republican Mayors of New York City Rudy Giuliani in 1997 and Michael Bloomberg in 2005 and 2009, respectively.
"The Huffington Post" criticized "The New York Times" for its coverage of foreign leaders through profiles. It cited a glowing report for Italian Prime Minister Mario Monti versus a dismissive report on Ecuadorian President Rafael Correa, despite the fact that the two men have similar background in getting PhDs in economics from U.S. schools.
Iraq War.
A year after the war started the newspaper asserted that some of its articles had not been as rigorous as they should have been, and were insufficiently qualified, frequently overly dependent upon information from Iraqi exiles desiring regime change. Reporter Judith Miller retired after criticisms that her reporting of the lead-up to the Iraq War was factually inaccurate and overly favorable to the Bush administration's position, for which "The New York Times" later apologized. One of Miller's prime sources was Ahmed Chalabi, an Iraqi expatriate who returned to Iraq after the U.S. invasion and held a number of governmental positions culminating in acting oil minister and deputy prime minister from May 2005 until May 2006.
Israeli–Palestinian conflict.
A 2003 study in "The Harvard International Journal of Press/Politics" concluded that "The New York Times" reporting was more favorable to Israelis than to Palestinians.
For its coverage of the Israeli–Palestinian conflict, some have claimed that the paper is pro-Palestinian, others it is pro-Israel. "The Israel Lobby and U.S. Foreign Policy", by political science professors John Mearsheimer and Stephen Walt, alleges that "The New York Times" sometimes criticizes Israeli policies but is not even-handed and is generally pro-Israel. On the other hand, the Simon Wiesenthal Center has criticized "The New York Times" for printing cartoons regarding the Israeli-Palestinian conflict that were claimed to be anti-Semitic.
Israeli Prime Minister Benjamin Netanyahu has rejected a proposal to write an article for the paper on grounds of lack of objectivity. A piece in which Thomas Friedman commented that praise awarded to Netanyahu during a speech at congress was "paid for by the Israel lobby" elicited an apology and clarification from its writer.
"The New York Times"‍ '​ public editor Clark Hoyt concluded in his January 10, 2009, column, "Though the most vociferous supporters of Israel and the Palestinians do not agree, I think "The New York Times", largely barred from the battlefield and reporting amid the chaos of war, has tried its best to do a fair, balanced and complete job — and has largely succeeded." 
The controversy was brought to the forefront in 2014 when the New York Times was forced to admit factual errors included in an Op-Ed piece criticizing Israeli Prime Minister, Benjamin Netanyahu.
Balkan and anti-Serbian bias.
Former "New York Times" journalist Daniel Simpson has criticized the newspaper's bias in representing wars in Yugoslavia in the 1990s. He was especially critical of the anti-Serbian bias of the paper, and has published a book "A Rough Guide to the Dark Side: or Why I quit my job at the New York Times, to get myself mixed up with Balkan gangsters" in which he explained the relevant issues. He also claimed that he was asked to report about the alleged WMD trade of Serbs with Iraq, which turned out to be false, while his attempts at more neutral reporting were rejected.
World War II.
On November 14, 2001, in "The New York Times"‍ '​ 150th anniversary issue, former executive editor Max Frankel wrote that before and during World War II, the "Times" had maintained a consistent policy to minimize reports on the Holocaust in their news pages. Laurel Leff, associate professor of journalism at Northeastern University, concluded that the newspaper had downplayed the Third Reich targeting of Jews for genocide. Her 2005 book "Buried by the Times" documents the NYT's tendency before, during and after World War II to place deep inside its daily editions the news stories about the ongoing persecution and extermination of Jews, while obscuring in those stories the special impact of the Nazis' crimes on Jews in particular. Leff attributes this dearth in part to the complex personal and political views of the newspaper's Jewish publisher, Arthur Hays Sulzberger, concerning Jewishness, antisemitism, and Zionism.
During the war, "New York Times" journalist William L. Laurence was "on the payroll of the War Department".
Ethics incidents.
Failure to report famine in Ukraine.
The "Times" has been criticized for the work of reporter Walter Duranty, who served as its Moscow bureau chief from 1922 through 1936. Duranty wrote a series of stories in 1931 on the Soviet Union and won a Pulitzer Prize for his work at that time; however, he has been criticized for his denial of widespread famine, most particularly the Ukrainian famine in the 1930s. In 2003, after the Pulitzer Board began a renewed inquiry, the "Times" hired Mark von Hagen, professor of Russian history at Columbia University, to review Duranty's work. Von Hagen found Duranty's reports to be unbalanced and uncritical, and that they far too often gave voice to Stalinist propaganda. In comments to the press he stated, "For the sake of The New York Times' honor, they should take the prize away."
Fashion news articles promoting advertisers.
In the mid to late 1950s, "fashion writer[s]... were required to come up every month with articles whose total column-inches reflected the relative advertising strength of every ["department" or "specialty"] store ["assigned" to a writer]... The monitor of all this was... the advertising director [of the "Times"]... " However, within this requirement, story ideas may have been the reporters' and editors' own.
Plagiarism.
In May 2003, "Times" reporter Jayson Blair was forced to resign from the newspaper after he was caught plagiarizing and fabricating elements of his stories. Some critics contended that Blair's race was a major factor in his hiring and in "The New York Times"‍ '​ initial reluctance to fire him.
Duke University lacrosse case.
The newspaper was criticized for largely reporting the prosecutors' version of events in the 2006 Duke lacrosse case. Suzanne Smalley of "Newsweek" criticized the newspaper for its "credulous" coverage of the charges of rape against Duke University lacrosse players. Stuart Taylor, Jr. and KC Johnson, in their book "Until Proven Innocent: Political Correctness and the Shameful Injustices of the Duke Lacrosse Rape Case", write: "at the head of the guilt-presuming pack, "The New York Times" vied in a race to the journalistic bottom with trash-TV talk shows."
Quotes out of context.
In February 2009, a "Village Voice" music blogger accused the newspaper of using "chintzy, ad-hominem allegations" in an article on British Tamil music artist M.I.A. concerning her activism against the Sinhala-Tamil conflict in Sri Lanka. M.I.A. criticized the paper in January 2010 after a travel piece rated post-conflict Sri Lanka the "#1 place to go in 2010". In June 2010, "The New York Times Magazine" published a correction on its cover article of M.I.A., acknowledging that the interview conducted by current "W" editor and then-"Times Magazine" contributor Lynn Hirschberg contained a recontextualization of two quotes. In response to the piece, M.I.A. broadcast Hirschberg's phone number and secret audio recordings from the interview via her Twitter and website.
Delayed publication of 2005 NSA warrantless surveillance story.
The "New York Times" has been criticized for the 13-month delay of the December 2005 story revealing the U.S. National Security Agency warrantless surveillance program. Ex-NSA officials blew the whistle on the program to journalists James Risen and Eric Lichtblau, who presented an investigative article to the newspaper in November 2004, weeks before America's presidential election. Contact with former agency officials began the previous summer.
Former "NYT" executive editor Bill Keller decided not to report the piece after being pressured by the Bush administration and being advised not to do so by "Times" Washington bureau chief Philip Taubman. Keller explained the silence's rationale in an interview with the newspaper in 2013, stating "Three years after 9/11, we, as a country, were still under the influence of that trauma, and we, as a newspaper, were not immune".
In 2014, "PBS Frontline" interviewed Risen and Lichtblau, who said that the newspaper's plan was to not publish the story at all. "The editors were furious at me," Risen said to the program. "They thought I was being insubordinate." Risen wrote a book about the mass surveillance revelations after the "Times" declined the piece's publication, and only released it after Risen told them that he would publish the book. Another reporter told NPR that the newspaper "avoided disaster" by ultimately publishing the story.
External links.
Official New York Times web sites
Unofficial "New York Times" related web sites

</doc>
<doc id="30683" url="http://en.wikipedia.org/wiki?curid=30683" title="Toho">
Toho

Toho Co. Ltd. (東宝株式会社, Tōhō Kabushiki-Kaisha, TYO: /JASDAQ: ) is a Japanese film, theater production, and distribution company. It has its headquarters in Yūrakuchō, Chiyoda, Tokyo, and is one of the core companies of the Hankyu Hanshin Toho Group. Outside Japan, it is best known as the producer and distributor of many kaiju and tokusatsu films, the Chouseishin tokusatsu superhero television franchise, the films of Akira Kurosawa, and the anime films of Studio Ghibli. Other famous directors, including Yasujirō Ozu, Kenji Mizoguchi, Masaki Kobayashi, and Mikio Naruse, also directed films for Toho. 
Toho's most famous creation is Godzilla, who features in 29 of the company's films. Godzilla, Mothra, King Ghidorah, Mechagodzilla, and Rodan are described as Toho's Big Five because of the monsters' numerous appearances in all three eras of the franchise, as well as spin-offs. Toho has also been involved in the production of numerous anime titles. Its subdivisions are Toho Pictures Incorporated, Toho International Company Limited, Toho E. B. Company Limited, and Toho Music Corporation & Toho Costume Company Limited. The company is the largest shareholder (7.96%) of Fuji Media Holdings Inc.
History.
Toho was created by the founder of Hankyu Railway, Ichizo Kobayashi, in 1932 as the "Tokyo-Takarazuka Theater Company" (東京宝塚劇場株式会社, Tōkyō Takarazuka Gekijō Kabushiki-Gaisha). It managed much of the kabuki in Tokyo and, among other properties, the Tokyo Takarazuka Theater and the Imperial Garden Theater in Tokyo; Toho and Shochiku enjoyed a duopoly over theaters in Tokyo for many years.
After several successful film exports to the United States during the 1950s through Henry G. Saperstein, Toho opened the La Brea Theatre in Los Angeles to show its own films without the need to sell them to a distributor. It was known as the Toho Theatre from the late 1960s until the 1970s. Toho also had a theater in San Francisco and opened a theater in New York in 1963.
The Shintoho Company, which existed until 1964, was named New Toho because it broke off from the original company.
The company has contributed to the production of some American films, including Sam Raimi's "A Simple Plan". 
Major productions and distributions.
Television.
Anime TV series.
In more recent years and for a period, they have produced video games. One of their first video games was the 1990 NES game titled "Circus Caper". Later, they followed with a series of games based on Godzilla and a 1992 game called "Serizawa Nobuo no Birdy Try". It also published games such as "Super Aleste". They even worked with Bandai on "Dr. Jekyll and Mr. Hyde", released in Japan in 1988 and in the United States in 1989.
Headquarters.
Toho's headquarters, the Toho Hibiya Building (東宝日比谷ビル, "Tōhō Hibiya Biru"), are in Yūrakuchō, Chiyoda, Tokyo. The company moved into its current headquarters in April 2005.
Further reading.
"Mushroom Clouds and Mushroom Men - The Fantastic Cinema of Ishiro Honda," Peter H. Brothers (AuthorHouse 2009).
"" Stuart Galbraith IV (Scarecrow Press 2008)

</doc>
<doc id="30684" url="http://en.wikipedia.org/wiki?curid=30684" title="Tundra">
Tundra

In physical geography, tundra is type of biome where the tree growth is hindered by low temperatures and short growing seasons. The term "tundra" comes through Russian тундра from the Kildin Sami word "tūndâr" "uplands", "treeless mountain tract". There are three types of tundra: arctic tundra, alpine tundra, and Antarctic tundra. In tundra, the vegetation is composed of dwarf shrubs, sedges and grasses, mosses, and lichens. Scattered trees grow in some tundra regions. The ecotone (or ecological boundary region) between the tundra and the forest is known as the tree line or timberline.
Arctic.
Arctic tundra occurs in the far Northern Hemisphere, north of the taiga belt. The word "tundra" usually refers only to the areas where the subsoil is permafrost, or permanently frozen soil. (It may also refer to the treeless plain in general, so that northern Sápmi would be included.) Permafrost tundra includes vast areas of northern Russia and Canada. The polar tundra is home to several peoples who are mostly nomadic reindeer herders, such as the Nganasan and Nenets in the permafrost area (and the Sami in Sápmi).
Arctic tundra contains areas of stark landscape and is frozen for much of the year. The soil there is frozen from 25 - down, and it is impossible for trees to grow. Instead, bare and sometimes rocky land can only support low growing plants such as moss, heath (Ericaceae varieties such as crowberry and black bearberry), and lichen. There are two main seasons, winter and summer, in the polar tundra areas. During the winter it is very cold and dark, with the average temperature around -28 °C, sometimes dipping as low as -50 °C. However, extreme cold temperatures on the tundra do not drop as low as those experienced in taiga areas further south (for example, Russia's and Canada's lowest temperatures were recorded in locations south of the tree line). During the summer, temperatures rise somewhat, and the top layer of seasonally-frozen soil melts, leaving the ground very soggy. The tundra is covered in marshes, lakes, bogs and streams during the warm months. Generally daytime temperatures during the summer rise to about 12 °C but can often drop to 3 °C or even below freezing. Arctic tundras are sometimes the subject of habitat conservation programs. In Canada and Russia, many of these areas are protected through a national Biodiversity Action Plan.
Tundra tends to be windy, with winds often blowing upwards of 50 –. However, in terms of precipitation, it is desert-like, with only about 15 – falling per year (the summer is typically the season of maximum precipitation). Although precipitation is light, evaporation is also relatively minimal. During the summer, the permafrost thaws just enough to let plants grow and reproduce, but because the ground below this is frozen, the water cannot sink any lower, and so the water forms the lakes and marshes found during the summer months. There is a natural pattern of accumulation of fuel and wildfire which varies depending on the nature of vegetation and terrain. Research in Alaska has shown fire-event return intervals, (FRIs) that typically vary from 150 to 200 years with dryer lowland areas burning more frequently than wetter highland areas. 
The biodiversity of tundra is low: 1,700 species of vascular plants and only 48 species of land mammals can be found, although millions of birds migrate there each year for the marshes. There are also a few fish species. There are few species with large populations. Notable animals in the Arctic tundra include caribou (reindeer), musk ox, Arctic hare, Arctic fox, snowy owl, lemmings, and polar bears (only near ocean-fed bodies of water). Tundra is largely devoid of poikilotherms such as frogs or lizards.
Due to the harsh climate of Arctic tundra, regions of this kind have seen little human activity, even though they are sometimes rich in natural resources such as oil and uranium. In recent times this has begun to change in Alaska, Russia, and some other parts of the world.
Relationship with global warming.
A severe threat to tundra is global warming, which causes permafrost to melt. The melting of the permafrost in a given area on human time scales (decades or centuries) could radically change which species can survive there.
Another concern is that about one third of the world's soil-bound carbon is in taiga and tundra areas. When the permafrost melts, it releases carbon in the form of carbon dioxide and methane, both of which are greenhouse gases. The effect has been observed in Alaska. In the 1970s the tundra was a carbon sink, but today, it is a carbon source. Methane is produced when vegetation decays in lakes and wetlands.
The amount of greenhouse gases which will be released under projected scenarios for global warming have not been reliably quantified by scientific studies, although a few studies were reported to be underway in 2011. It is uncertain whether the impact of increased greenhouse gases from this source will be minimal or massive.
In locations where dead vegetation and peat has accumulated there is a risk of wildfire such as the 1039 km2 of tundra which burned in 2007 on the north slope of the Brooks Range in Alaska. Such events may both result from and contribute to global warming.
Antarctic.
Antarctic tundra occurs on Antarctica and on several Antarctic and subantarctic islands, including South Georgia and the South Sandwich Islands and the Kerguelen Islands. Most of Antarctica is too cold and dry to support vegetation, and most of the continent is covered by ice fields. However, some portions of the continent, particularly the Antarctic Peninsula, have areas of rocky soil that support plant life. The flora presently consists of around 300–400 lichens, 100 mosses, 25 liverworts, and around 700 terrestrial and aquatic algae species, which live on the areas of exposed rock and soil around the shore of the continent. Antarctica's two flowering plant species, the Antarctic hair grass ("Deschampsia antarctica") and Antarctic pearlwort ("Colobanthus quitensis"), are found on the northern and western parts of the Antarctic Peninsula.
In contrast with the Arctic tundra, the Antarctic tundra lacks a large mammal fauna, mostly due to its physical isolation from the other continents. Sea mammals and sea birds, including seals and penguins, inhabit areas near the shore, and some small mammals, like rabbits and cats, have been introduced by humans to some of the subantarctic islands. The Antipodes Subantarctic Islands tundra ecoregion includes the Bounty Islands, Auckland Islands, Antipodes Islands, the Campbell Island group, and Macquarie Island. Species endemic to this ecoregion include "Nematoceras dienemum" and "Nematoceras sulcatum", the only Subantarctic orchids; the royal penguin; and the Antipodean albatross.
The flora and fauna of Antarctica and the Antarctic Islands (south of 60° south latitude) are protected by the Antarctic Treaty.
Alpine.
Alpine tundra does not contain trees because the climate and soils at high altitude block tree growth. Alpine tundra is distinguished from arctic tundra in that alpine tundra typically does not have permafrost, and alpine soils are generally better drained than arctic soils. Alpine tundra transitions to subalpine forests below the tree line; stunted forests occurring at the forest-tundra ecotone are known as "Krummholz".
Alpine tundra occurs in mountains worldwide. The flora of the alpine tundra is characterized by dwarf shrubs close to the ground. The cold climate of the alpine tundra is caused by the low air temperatures, and is similar to polar climate.
Climatic classification.
Tundra climates ordinarily fit the Köppen climate classification ET, signifying a local climate in which at least one month has an average temperature high enough to melt snow (0 C), but no month with an average temperature in excess of 10 C. The cold limit generally meets the EF climates of permanent ice and snows; the warm-summer limit generally corresponds with the poleward or altitudinal limit of trees, where they grade into the subarctic climates designated Dfd and Dwd (extreme winters as in parts of Siberia), Dfc typical in Alaska, Canada, parts of Scandinavia, European Russia, and Western Siberia (cold winters with months of freezing), or even Cfc (no month colder than -3 C as in parts of Iceland and southernmost South America). Tundra climates as a rule are hostile to woody vegetation even where the winters are comparatively mild by polar standards, as in Iceland.
Despite the potential diversity of climates in the ET category involving precipitation, extreme temperatures, and relative wet and dry seasons, this category is rarely subdivided. Rainfall and snowfall are generally slight due to the low vapor pressure of water in the chilly atmosphere, but as a rule potential evapotranspiration is extremely low, allowing soggy terrain of swamps and bogs even in places that get precipitation typical of deserts of lower and middle latitudes. The amount of native tundra biomass depends more on the local temperature than the amount of precipitation.
Further reading.
</dl>

</doc>
<doc id="30685" url="http://en.wikipedia.org/wiki?curid=30685" title="The Chronicles of Narnia">
The Chronicles of Narnia

The Chronicles of Narnia is a series of seven high fantasy novels by author C. S. Lewis. It is considered a classic of children's literature and is the author's best-known work, having sold over 100 million copies in 47 languages. Written by Lewis between 1949 and 1954, illustrated by Pauline Baynes and originally published in London between October 1950 and March 1956, "The Chronicles of Narnia" has been adapted several times, complete or in part, for radio, television, the stage, and film.
Set in the fictional realm of Narnia, a fantasy world of magic, mythical beasts, and talking animals, the series narrates the adventures of various children who play central roles in the unfolding history of that world. Except in "The Horse and His Boy", the protagonists are all children from the real world, magically transported to Narnia, where they are called upon by the lion Aslan to protect Narnia from evil and restore the throne to its rightful line. The books span the entire history of Narnia, from its creation in "The Magician's Nephew" to its eventual destruction in "The Last Battle".
Inspiration for the series is taken from multiple sources; in addition to adapting numerous traditional Christian themes, the books freely borrow characters and ideas from Greek and Roman mythology as well as from traditional British and Irish fairy tales. The books have profoundly influenced adult and children's fantasy literature since World War II. Lewis's exploration of themes not usually present in children's literature, such as religion, as well as the books' perceived treatment of issues including race and gender, has caused some controversy.
Background and conception.
Although Lewis originally conceived what would become "The Chronicles of Narnia" in 1939, he did not finish writing the first book "The Lion, the Witch and the Wardrobe" until 1949. "The Magician's Nephew", the penultimate book to be published, but the last to be written, was completed in 1954. Lewis did not write the books in the order in which they were originally published, nor were they published in their current chronological order of presentation. The original illustrator, Pauline Baynes, created pen and ink drawings for the "Narnia" books that are still used in the editions published today. Lewis was awarded the 1956 Carnegie Medal for "The Last Battle", the final book in the saga. Fellow children's author Roger Lancelyn Green first referred to the series as "The Chronicles of Narnia", in March 1951, after he had read and discussed with Lewis his recently completed fourth book "The Silver Chair", originally entitled "Night under Narnia".
Lewis described the origin of "The Lion, the Witch and the Wardrobe" in an essay entitled "It All Began with a Picture":
The "Lion" all began with a picture of a Faun carrying an umbrella and parcels in a snowy wood. This picture had been in my mind since I was about sixteen. Then one day, when I was about forty, I said to myself: 'Let's try to make a story about it.'
Shortly before the start of World War II, many children were evacuated to the English countryside in anticipation of attacks on London and other major urban areas by Nazi Germany. As a result, on 2 September 1939, three school girls, Margaret, Mary and Katherine, came to live at The Kilns in Risinghurst, Lewis' home three miles east of Oxford city centre. Lewis later suggested that the experience gave him a new appreciation of children and in late September he began a children's story on an odd sheet of paper which has survived as part of another manuscript:
This book is about four children whose names were Ann, Martin, Rose and Peter. But it is most about Peter who was the youngest. They all had to go away from London suddenly because of Air Raids, and because Father, who was in the Army, had gone off to the War and Mother was doing some kind of war work. They were sent to stay with a kind of relation of Mother's who was a very old professor who lived all by himself in the country.
In "It All Began With a Picture" C. S. Lewis continues:
At first I had very little idea how the story would go. But then suddenly Aslan came bounding into it. I think I had been having a good many dreams of lions about that time. Apart from that, I don't know where the Lion came from or why he came. But once he was there, he pulled the whole story together, and soon he pulled the six other Narnian stories in after him.
The manuscript for "The Lion, the Witch and the Wardrobe" was complete by the end of March 1949.
Name.
The name "Narnia" is based on Narni, Italy, written in Latin as "Narnia". Lancelyn Green wrote: 
When Walter Hooper asked [C. S. Lewis] where he found the word 'Narnia', Lewis showed him Murray's Small Classical Atlas, ed. G.B. Grundy (1904), which he acquired when he was reading the classics with Mr Kirkpatrick at Great Bookham [1914–1917]. On plate 8 of the Atlas is a map of ancient Italy. Lewis had underscored the name of a little town called Narnia, simply because he liked the sound of it. Narnia — or 'Narni' in Italian — is in Umbria, halfway between Rome and Assisi.
Publication history.
"The Chronicles of Narnia's" seven books have been in continuous publication since 1956, selling over 100 million copies in 47 languages and with editions in Braille.
The first five books were originally published in the United Kingdom by Geoffrey Bles. The first edition of "The Lion, the Witch and the Wardrobe" was released in London on 16 October 1950. Although three more books, "Prince Caspian", "The Voyage of the Dawn Treader" and "The Horse and His Boy", were already complete, they were not released immediately at that time, but appeared (along with "The Silver Chair") one at a time in each of the subsequent years (1951–1954). The last two books ("The Magician's Nephew" and "The Last Battle") were published in the United Kingdom originally by The Bodley Head in 1955 and 1956.
In the United States, the publication rights were first owned by Macmillan Publishers, and later by HarperCollins. The two issued both hardcover and paperback editions of the series during their tenure as publishers, while at the same time Scholastic, Inc. produced paperback versions for sale primarily through direct mail order, book clubs, and book fairs. Harper Collins also published several one-volume collected editions containing the full text of the series. As noted below (see Reading Order), the first American publisher, Macmillan, numbered the books in publication sequence, but when Harper Collins won the rights in 1994, at the suggestion of Lewis' stepson they used the series' internal chronological order. Scholastic switched the numbering of its paperback editions in 1994 to mirror that of Harper Collins.
Books.
The seven books that make up "The Chronicles of Narnia" are presented here in order of original publication date:
"The Lion, the Witch and the Wardrobe" (1950).
"The Lion, the Witch and the Wardrobe", completed by the end of March 1949 and published by Geoffrey Bles in the United Kingdom on 16 October 1950, tells the story of four ordinary children: Peter, Susan, Edmund, and Lucy Pevensie, who have been evacuated to the English countryside from London in 1940 following the outbreak of World War II. They discover a wardrobe in Professor Digory Kirke's house that leads to the magical land of Narnia. The Pevensie children help Aslan, a talking lion, save Narnia from the evil White Witch, who has reigned over the land of Narnia for a century of perpetual winter with no Christmas. The children become kings and queens of this new-found land and establish the Golden Age of Narnia, leaving a legacy to be rediscovered in later books.
"Prince Caspian: The Return to Narnia" (1951).
Completed after Christmas 1949 and published on 15 October 1951, "Prince Caspian: The Return to Narnia" tells the story of the Pevensie children's second trip to Narnia. They are drawn back by the power of Susan's horn, blown by Prince Caspian to summon help in his hour of need. Narnia, as they knew it, is no more, as more than 1,000 years have passed and their castle is in ruins, while all Narnians have retreated so far within themselves that only Aslan's magic can wake them. Caspian has fled into the woods to escape his uncle, Miraz, who has usurped the throne. The children set out once again to save Narnia.
"The Voyage of the Dawn Treader" (1952).
Written between January and February 1950 and published on 15 September 1952, "The Voyage of the Dawn Treader" sees Edmund and Lucy Pevensie, along with their priggish cousin, Eustace Scrubb, return to Narnia. Once there, they join Caspian's voyage on the ship "Dawn Treader" to find the seven lords who were banished when Miraz took over the throne. This perilous journey brings them face to face with many wonders and dangers as they sail toward Aslan's country at the edge of the world.
"The Silver Chair" (1953).
Completed at the beginning of March 1951 and published 7 September 1953, "The Silver Chair" is the first Narnia book without any of the Pevensie children. Instead, Aslan calls Eustace back to Narnia together with his classmate Jill Pole. There they are given four signs to aid them in the search for Prince Rilian, Caspian's son, who disappeared after setting out ten years earlier to avenge his mother's death. Fifty years have passed in Narnia and Caspian, who was barely an adult in "The Voyage of the Dawn Treader", is now an old man, while Eustace is still a child.
Eustace and Jill, with the help of Puddleglum the Marsh-wiggle, face danger and betrayal on their quest to find Rilian.
"The Horse and His Boy" (1954).
Begun in March and completed at the end of July 1950, "The Horse and His Boy" was published on 6 September 1954. The story takes place during the reign of the Pevensies in Narnia, an era which begins and ends in the last chapter of "The Lion, the Witch and the Wardrobe". A talking horse called Bree and a young boy named Shasta, both of whom are in bondage in the country of Calormen, are the protagonists. By "chance", they meet and plan their return to Narnia and freedom. Along the way they meet Aravis and her talking horse Hwin who are also fleeing to Narnia.
"The Magician's Nephew" (1955).
Completed in February 1954
and published by Bodley Head in London on 2 May 1955, the prequel "The Magician's Nephew" brings the reader back to the origins of Narnia where we learn how Aslan created the world and how evil first entered it. Digory Kirke and his friend Polly Plummer stumble into different worlds by experimenting with magic rings made by Digory's uncle. They encounter Jadis (The White Witch) in the dying world of Charn, and witness the creation of Narnia. Many long-standing questions about the world are answered as a result. The story is set in 1900, when Digory was a 12-year-old boy. He is a middle-aged professor and host to the Pevensie children by the time of "The Lion, the Witch and the Wardrobe" 40 years later.
"The Last Battle" (1956).
Completed in March 1953 and published 4 September 1956, "The Last Battle" chronicles the end of the world of Narnia. Jill and Eustace return to save Narnia from Shift, an ape, who tricks Puzzle, a donkey, into impersonating the lion Aslan, precipitating a showdown between the Calormenes and King Tirian.
This later on leads to the end of Narnia, revealing a new but true Narnia that Aslan brings them to.
Reading order.
Fans of the series often have strong opinions over the order in which the books should be read. The issue revolves around the placement of "The Magician's Nephew" and "The Horse and His Boy" in the series. Both are set significantly earlier in the story of Narnia than their publication order and fall somewhat outside the main story arc connecting the others. The reading order of the other five books is not disputed.
When first published, the books were not numbered. The first American publisher, Macmillan, enumerated them according to their original publication order, while some early British editions specified the internal chronological order. When Harper Collins took over the series rights in 1994, they adopted chronological order. To make the case for chronological order, Lewis' stepson, Douglas Gresham, quoted Lewis' 1957 reply to a letter from an American fan who was having an argument with his mother about the order:
I think I agree with your [chronological] order for reading the books more than with your mother's. The series was not planned beforehand as she thinks. When I wrote "The Lion" I did not know I was going to write any more. Then I wrote "P. Caspian" as a sequel and still didn't think there would be any more, and when I had done "The Voyage" I felt quite sure it would be the last, but I found I was wrong. So perhaps it does not matter very much in which order anyone read them. I’m not even sure that all the others were written in the same order in which they were published.
In the 2005 Harper Collins adult editions of the books, the publisher cites this letter to assert Lewis' preference for the numbering they adopted by including this notice on the copyright page:
Although The Magician's Nephew was written several years after C. S. Lewis first began The Chronicles of Narnia, he wanted it to be read as the first book in the series. Harper Collins is happy to present these books in the order in which Professor Lewis preferred.
Paul Ford cites several scholars who have weighed in against this view, and continues, "most scholars disagree with this decision and find it the least faithful to Lewis's deepest intentions". Scholars and readers who appreciate the original order believe that Lewis was simply being gracious to his youthful correspondent and that he could have changed the books' order in his lifetime had he so desired. They maintain that much of the magic of Narnia comes from the way the world is gradually presented in "The Lion, the Witch and the Wardrobe" – that the mysterious wardrobe, as a narrative device, is a much better introduction to Narnia than "The Magician's Nephew", where the word "Narnia" appears in the first paragraph as something already familiar to the reader. Moreover, they say, it is clear from the texts themselves that "The Lion, the Witch and the Wardrobe" was intended to be read first. When Aslan is first mentioned in "The Lion, the Witch and the Wardrobe", for example, the narrator says that "None of the children knew who Aslan was, any more than you do" — which is nonsensical if one has already read "The Magician's Nephew". Other similar textual examples are also cited.
Doris Meyer, author of "C. S. Lewis in Context" and "Bareface: A guide to C. S. Lewis", writes that rearranging the stories chronologically "lessens the impact of the individual stories" and "obscures the literary structures as a whole". Peter Schakel devotes an entire chapter to this topic in his book "Imagination and the Arts in C. S. Lewis: Journeying to Narnia and Other Worlds", and in "Reading with the Heart: The Way into Narnia" he writes:
The only reason to read "The Magician's Nephew" first [...] is for the chronological order of events, and that, as every story teller knows, is quite unimportant as a reason. Often the early events in a sequence have a greater impact or effect as a flashback, told after later events which provide background and establish perspective. So it is [...] with the "Chronicles". The artistry, the archetypes, and the pattern of Christian thought all make it preferable to read the books in the order of their publication.
Main characters.
Aslan.
Aslan, the Great Lion, is the eponymous lion of "The Lion, the Witch and the Wardrobe", and his role in Narnia is developed throughout the remaining books. He is also the only character to appear in all seven books. Aslan is a talking lion, the King of Beasts, son of the Emperor-Over-the-Sea. He is a wise, compassionate, magical authority (both temporal and spiritual) who serves as mysterious and benevolent guide to the human children who visit, as well as being the guardian and saviour of Narnia. C. S. Lewis described Aslan as an alternative version of Jesus as the form in which Christ might have appeared in an alternative reality.
Pevensie Family.
The four Pevensie siblings are the main human protagonists of "The Chronicles of Narnia". Varying combinations of some or all of them appear in five of the seven novels. They are introduced in "The Lion, the Witch and the Wardrobe", and eventually become Kings and Queens of Narnia reigning as a tetrarchy: High King Peter the Magnificent, Queen Susan the Gentle, King Edmund the Just, and Queen Lucy the Valiant. Although introduced in the series as children, the siblings grow up into adults while reigning in Narnia. They go back to being children once they get back to their own world, but feature as adults in "The Horse and His Boy" during their Narnia reign.
Echoing the Christian theme of betrayal, repentance, and subsequent redemption via blood sacrifice, Edmund betrays his siblings to Jadis, the White Witch, but quickly realises the true nature of the witch and her evil intentions towards his siblings, and joins Aslan's side. At that point he is redeemed by the sacrifice of Aslan's life and he joins the fight against the White Witch. Lucy is the youngest of the four Pevensie siblings. Of all the Pevensie children, Lucy is the closest to Aslan, and of all the human characters who visit Narnia, Lucy is perhaps the one who believes in Narnia the most.
All four appear in "The Lion, the Witch, and the Wardrobe" and "Prince Caspian"; in the latter, however, Aslan tells Peter and Susan that they will not return, as they are getting too old. Susan, Lucy, and Edmund appear in "The Horse and His Boy" – Peter is said to be away fighting giants on the other side of Narnia. Lucy and Edmund appear in "The Voyage of the Dawn Treader", where Aslan tells them, too, that they are getting too old. Peter, Edmund, and Lucy appear in "The Last Battle".
Susan doesn't appear in "The Last Battle" because by that time she has stopped believing in Narnia. Asked by a child in 1958 if he would please write another book entitled "Susan of Narnia" so that the entire Pevensie family would be reunited, C. S. Lewis replied: "I am so glad you like the Narnian books and it was nice of you to write and tell me. There's no use just asking me to write more. When stories come into my mind I have to write them, and when they don't I can't!..."*
Eustace Scrubb.
Eustace Clarence Scrubb is a cousin of the Pevensies, and a classmate of Jill Pole at their school Experiment House. He is portrayed at first as a brat and a bully, but comes to improve his nasty behaviour when his greed turns him into a dragon for a while. His distress at having to live as a dragon causes him to reflect upon how horrible he has been, and he soon becomes a better person so Aslan changes him back into a boy. In the later books, Eustace comes across as a much nicer person, although he is still rather grumpy and argumentative. Nonetheless, he becomes a hero along with Jill Pole when the pair succeed in freeing the lost Prince Rilian from the clutches of an evil witch. He appears in "The Voyage of the Dawn Treader", "The Silver Chair", and "The Last Battle."
Jill Pole.
Jill Pole is not related to any of the other children who enter Narnia. She is merely a classmate and neighbour of Eustace Scrubb. She appears in "The Silver Chair", where she is the viewpoint character for most of the action, and returns in "The Last Battle". In "The Silver Chair" Eustace introduces her to the Narnian world, where Aslan gives her the task of memorising a series of signs that will help her and Eustace on their quest to find Caspian's lost son. In "The Last Battle" she and Eustace accompany King Tirian in his ill-fated defence of Narnia against the Calormenes.
Digory Kirke.
Digory Kirke is the character referred to in the title of "The Magician's Nephew". He first appears as a minor character in "The Lion, the Witch and the Wardrobe", but his true significance in the narrative is only revealed in "The Magician's Nephew". He returns in "The Last Battle".
Polly Plummer.
Polly Plummer appears in "The Magician's Nephew" and "The Last Battle". She is the next-door neighbour of the young Digory Kirke. She is tricked by a wicked magician (who is Digory's uncle) into touching a magic ring which transports her to the Wood between the Worlds and leaves her there stranded. The wicked uncle persuades Digory to follow her with a second magic ring that has the power to bring her back. This sets up the pair's adventures into other worlds, and they witness the creation of Narnia as described in "The Magician's Nephew".
Prince Caspian / Caspian X.
Prince Caspian, later to become King Caspian X of Narnia, Lord of Cair Paravel and Emperor of The Lone Islands – also called "Caspian the Seafarer" and "Caspian the Navigator" — is the title character of the second book in the series, first introduced as the young nephew and heir of King Miraz of Narnia. "Prince Caspian: The Return to Narnia" is set 1300 years after the rule of High King Peter and his siblings, when Old Narnians have been driven into hiding by Caspian's ancestors the Telmarines. Caspian is also a central character in "The Voyage of the Dawn Treader", and appears briefly at the beginning and end of "The Silver Chair".
White Witch / Jadis.
Jadis, commonly known during her rule of Narnia as the White Witch, is the main antagonist of "The Magician's Nephew" and "The Lion, The Witch and the Wardrobe". She is the witch responsible for the freezing of Narnia resulting in the Hundred Year Winter. The White Witch was born in the world of Charn, before the creation of Narnia, and died in battle in Narnian year 1000.
Shasta / Cor.
Shasta, later known as Cor of Archenland, is the principal character in "The Horse and His Boy". Born the eldest son and heir of King Lune of Archenland, and elder twin of Prince Corin, Cor was kidnapped as an infant and raised as a fisherman's son in the country of Calormen. Learning that he is about to be sold into slavery at the beginning of "The Horse and His Boy", Shasta escapes to freedom, saves Archenland and Narnia from invasion, learns of his true identity, and is restored to his heritage. Shasta grows up to become King of Archenland, marries the Calormene Tarkheena Aravis, and fathers the next (and most famous) king of Archenland, Ram the Great.
Aravis.
Aravis, daughter of Kidrash Tarkaan, is the secondary protagonist in "The Horse and His Boy". Escaping a forced betrothal to the loathsome Ahoshta, she joins Shasta on his journey and inadvertently overhears a plot by Rabadash, crown prince of Calormen, to invade Archenland. She later marries Shasta, now known as Prince Cor, and becomes queen of Archenland at his side.
Bree.
Bree (Breehy-hinny-brinny-hoohy-hah) is Shasta's mount and mentor in "The Horse and His Boy". A Talking Horse of Narnia, he wandered into Calormen as a foal and was captured. He first appears as a Calormene nobleman's war-horse; when the nobleman buys Shasta as a slave, Bree organises and carries out their joint escape. Though friendly, he is also vain and a braggart until his encounter with Aslan late in the story.
Trumpkin.
Trumpkin the Dwarf is the narrator of several chapters of "Prince Caspian"; he is one of Caspian's rescuers and a leading figure in the "Old Narnian" rebellion, and accompanies the Pevensie children from the ruins of Cair Paravel to the Old Narnian camp. In "The Voyage of the Dawn Treader" we learn that Caspian has made him his Regent in Narnia while he is away at sea, and he appears briefly in this role (now elderly and very deaf) in "The Silver Chair".
Puddleglum.
Puddleglum the Marsh-wiggle guides Eustace and Jill on their quest in "The Silver Chair". Though always comically pessimistic, he provides the voice of reason and as such intervenes critically in the climactic enchantment scene.
King Tirian.
The last King of Narnia is the viewpoint character for much of "The Last Battle". Having rashly killed a Calormene for mistreating a Narnian Talking Horse, he is imprisoned by the villainous ape Shift but released by Eustace and Jill. Together they fight faithfully to the last and are welcomed into Aslan's Kingdom.
Narnian universe.
The main setting of "The Chronicles of Narnia" is the world of Narnia constructed by Lewis and, in "The Magician's Nephew", the world containing the city of Charn. The Narnian and Charnian worlds are themselves posited as just two in a multiverse of countless worlds that includes our own universe, the main protagonists' world of origin. Passage between these worlds is possible, though rare, and may be accomplished by various means. Narnia itself is described as populated by a wide variety of creatures, most of which would be recognisable to those familiar with European mythologies and British fairy tales.
Inhabitants.
Lewis' stories are populated with two distinct types of character: Humans originating from the reader's world of Earth, and Narnian creatures and their descendants created by Aslan. This is typical of works that involve parallel universes. The majority of characters from the reader's world serve as the protagonists of the various books, although some are only mentioned in passing depending on chronology. Lewis does not limit himself to a single source of inspiration; instead, he borrows from many sources,including ancient Greek and German mythology, as well as Celtic literature. 
Geography.
"The Chronicles of Narnia" describes the world in which Narnia exists as one major landmass faced by "the Great Eastern Ocean". This ocean contains the islands explored in "The Voyage of the Dawn Treader". On the main landmass Lewis places the countries of Narnia, Archenland, Calormen, and Telmar, along with a variety of other areas that are not described as countries. The author also provides glimpses of more fantastic locations that exist in and around the main world of Narnia, including an edge and an underworld.
There are several maps of the Narnian universe available, including what many consider the "official" one, a full-colour version published in 1972 by the books' illustrator, Pauline Baynes. This is currently out of print, although smaller copies can be found in the most recent HarperCollins 2006 hardcover edition of "The Chronicles of Narnia". Two other maps were produced as a result of the popularity of the 2005 film "". One, the "Rose Map of Narnia", is based loosely on Baynes' map and has Narnian trivia printed on the reverse. The other, made in a monochromatic, archaic style reminiscent of maps of Tolkien's Middle-earth, is available in print and in an interactive version on the DVD of the movie. The latter map depicts only the country Narnia and not the rest of Lewis' world.
Cosmology.
A recurring plot device in "The Chronicles" is the interaction between the various worlds that make up the Narnian multiverse. A variety of methods are used to initiate these cross-overs which generally serve to introduce characters to the land of Narnia. The Cosmology of Narnia is not as internally consistent as that of Lewis' contemporary Tolkien's Middle-earth, but suffices given the more fairy tale atmosphere of the work. During the course of the series we learn in passing, that the world of Narnia is flat and geocentric and has different stars from those of Earth, and that the passage of time does not correspond directly to the passage of time in our world.
History.
"The Chronicles" cover the entire history of the world of Narnia, describing the process by which it was created, offering snapshots of life in Narnia as its history unfolds, and how it is ultimately destroyed. As is often the case in a children's series, children themselves, usually from our world, play a prominent role in all of these events. The history of Narnia is generally divided into the following periods: creation and the period shortly afterwards, the rule of the White Witch, the Golden Age, the invasion and rule of the Telmarines, their subsequent defeat by Caspian X, the rule of King Caspian and his descendants, and the destruction of Narnia. Like many stories, the narrative is not necessarily always presented in chronological order.
Influences.
Lewis' life.
Lewis' early life has parallels with "The Chronicles of Narnia". At the age of seven, he moved with his family to a large house on the edge of Belfast. Its long hallways and empty rooms inspired Lewis and his brother to invent make-believe worlds whilst exploring their home, an activity reflected in Lucy's discovery of Narnia in "The Lion, the Witch and the Wardrobe". Like Caspian and Rilian, Lewis lost his mother at an early age, spending much of his youth in English boarding schools similar to those attended by the Pevensie children, Eustace Scrubb, and Jill Pole. During World War II many children were evacuated from London and other urban areas because of German air raids. Some of these children, including one named Lucy (Lewis' goddaughter) stayed with him at his home The Kilns near Oxford, just as the Pevensies stayed with The Professor in "The Lion, the Witch and the Wardrobe".
Influences from mythology and cosmology.
Drew Trotter, president of the Center for Christian Study, noted that the producers of the film "" felt that the books' plots adhere to the archetypal "monomyth" pattern as detailed in Joseph Campbell's "The Hero with a Thousand Faces".
Lewis was widely read in medieval Celtic literature, an influence reflected throughout the books, and most strongly in "The Voyage of the Dawn Treader." The entire book imitates one of the immrama, a type of traditional Old Irish tale that combines elements of Christianity and Irish mythology to tell the story of a hero's sea journey to the Otherworld. Medieval Ireland also had a tradition of High Kings ruling over lesser kings and queens or princes, as in Narnia. Lewis' term "Cair," as in Cair Paravel, also mirrors "Caer", or "fortress" in the Welsh language. Reepicheep's small boat is a "coracle", a type of vessel traditionally used in the Celtic regions of the British Isles. Some creatures in the book such as the one-footed Dufflepuds reflect elements of Greek, Roman and Medieval mythology while other Narnian creatures are borrowed from Greek and Germanic mythology: for example, centaurs from the former and dwarfs from the latter.
In 2008 Michael Ward published "Planet Narnia", which proposed that each of the seven books related to one of the seven moving heavenly bodies or "planets" known in the Middle Ages according to the Ptolemaic geocentric model of cosmology (a theme to which Lewis returned habitually throughout his work). At that time, each of these heavenly bodies was believed to have certain attributes, and Ward contends that these attributes were deliberately but subtly used by Lewis to furnish elements of the stories of each book:
In "The Lion" [the child protagonists] become monarchs under sovereign Jove; in "Prince Caspian" they harden under strong Mars; in "The "Dawn Treader"" they drink light under searching Sol; in "The Silver Chair" they learn obedience under subordinate Luna; in "The Horse and His Boy" they come to love poetry under eloquent Mercury; in "The Magician's Nephew" they gain life-giving fruit under fertile Venus; and in "The Last Battle" they suffer and die under chilling Saturn."
Similarly, Lewis' interest in the literary symbolism of medieval and Renaissance astrology is more overtly referenced in other works such as his study of medieval cosmology "The Discarded Image", in his early poetry as well as in "Space Trilogy". Narnia scholar Paul F. Ford finds Ward's assertion that Lewis intended "The Chronicles" to be an embodiment of medieval astrology implausible, though Ford addresses an earlier (2003) version of Ward's thesis (also called "Planet Narnia", published in the "Times Literary Supplement"). Ford argues that Lewis did not start with a coherent plan for the books, but Ward's book answers this by arguing that the astrological associations grew in the writing.
George MacDonald's "Phantastes" (1858) influenced the structure and setting of "The Chronicles". It was a work that was " a great balm to the soul"
Influences on other works.
Influences on literature.
"The Chronicles of Narnia" has been a significant influence on both adult and children's fantasy literature in the post-World War II era. Examples include:
Philip Pullman's acclaimed fantasy series "His Dark Materials" is seen as a response to "The Chronicles". Pullman is a self-described atheist who wholly rejects the spiritual themes that permeate "The Chronicles", yet his series nonetheless addresses many of the same issues and introduces some similar character types, including talking animals. In another parallel, the first books in each series – Pullman's "Northern Lights" and "The Lion, the Witch, and the Wardrobe" – both open with a young girl hiding in a wardrobe.
Neil Gaiman's young-adult horror novella "Coraline" has been compared to "The Lion, the Witch, and the Wardrobe", as both books involve young girls travelling to magical worlds through doors in their new houses and fighting evil with the help of talking animals. His "Sandman" comic book series also features a Narnia-like "dream island" in its story arc entitled "A Game of You".
The novel "Bridge to Terabithia" by Katherine Paterson has Leslie, one of the main characters, reveal to her co-protagonist Jesse her love of Lewis' books, subsequently lending him "The Chronicles of Narnia" so that he can learn how to behave like a king. Her book also features the island name "Terabithia", which sounds similar to Terebinthia, a Narnian island that appears in "Prince Caspian" and "The Voyage of the Dawn Treader". Katherine Paterson herself acknowledges that Terabithia is likely to be derived from Terebinthia:
I thought I had made it up. Then, rereading "The Voyage of the Dawn Treader" by C. S. Lewis, I realized that I had probably gotten it from the island of Terebinthia in that book. However, Lewis probably got that name from the Terebinth tree in the Bible, so both of us pinched from somewhere else, probably unconsciously."
Science-fiction author Greg Egan's short story "Oracle" depicts a parallel universe in which an author nicknamed Jack (Lewis' nickname) has written novels about the fictional "Kingdom of Nesica", and whose wife is dying of cancer, paralleling the death of Lewis' wife Joy Davidman. Several Narnian allegories are also used to explore issues of religion and faith versus science and knowledge.
Lev Grossman's "New York Times" best-seller "The Magicians" is a contemporary dark fantasy about an unusually gifted young man obsessed with Fillory, the magical land of his favourite childhood books. Fillory is a thinly veiled substitute for Narnia, and clearly the author expects it to be experienced as such. Not only is the land home to many similar talking animals and mythical creatures, it is also accessed through a grandfather clock in the home of an uncle to whom five English children are sent during World War II. Moreover, the land is ruled by two Aslan-like rams named Ember and Umber, and terrorised by The Watcherwoman. She, like the White Witch, freezes the land in time. The book's plot revolves heavily around a place very like the "wood between the worlds" from "The Magician's Nephew", an interworld waystation in which pools of water lead to other lands. This reference to "The Magician's Nephew" is echoed in the title of the book.
J. K. Rowling, author of the Harry Potter series, has said that she was a fan of the works of Lewis as a child, and cites the influence of "The Chronicles" on her work: "I found myself thinking about the wardrobe route to Narnia when Harry is told he has to hurl himself at a barrier in Kings Cross Station — it dissolves and he's on platform Nine and Three-Quarters, and there's the train for Hogwarts." Nevertheless she is at pains to stress the differences between Narnia and her world: "Narnia is literally a different world", she says, "whereas in the Harry books you go into a world within a world that you can see if you happen to belong. A lot of the humour comes from collisions between the magic and the everyday worlds. Generally there isn't much humour in the Narnia books, although I adored them when I was a child. I got so caught up I didn't think CS Lewis was especially preachy. Reading them now I find that his subliminal message isn't very subliminal." "New York Times" writer Charles McGrath notes the similarity between Dudley Dursley, the obnoxious son of Harry's neglectful guardians, and Eustace Scrubb, the spoiled brat who torments the main characters until he is redeemed by Aslan.
Influences on popular culture.
As with any popular long-lived work, contemporary culture abounds with references to the lion Aslan, travelling via wardrobe and direct mentions of "The Chronicles". Examples include:
Charlotte Staples Lewis, a character first seen early in the fourth season of the TV series "Lost", is named in reference to C. S. Lewis. "Lost" producer Damon Lindelof said that this was a clue to the direction the show would take during the season. The book "Ultimate Lost and Philosophy", edited by William Irwin and Sharon Kaye, contains a comprehensive essay on "Lost" plot motifs based on "The Chronicles".
The second SNL Digital Short by Andy Samberg and Chris Parnell features a humorous nerdcore hip hop song titled "Chronicles of Narnia (Lazy Sunday)", which focuses on the performers' plan to see "The Chronicles of Narnia: The Lion, the Witch and the Wardrobe" at a cinema. It was described by "Slate" magazine as one of the most culturally significant "Saturday Night Live" skits in many years, and an important commentary on the state of rap. Swedish Christian power metal band Narnia, whose songs are mainly about the "Chronicles of Narnia" or the Bible, feature Aslan on all their album covers. In anticipation of the 9 December 2005 premiere of the film "The Chronicles of Narnia: The Lion, the Witch and the Wardrobe", various Christian artists released a based on "The Chronicles of Narnia".
During interviews, the primary creator of the Japanese anime and gaming series "Digimon" has noted the heavy influence of "The Chronicles of Narnia" on his series.
Influences on music.
"The Roar of Love" is a 1980 concept album by Christian band 2nd Chapter of Acts based on "The Lion the Witch and the Wardrobe".
Christian themes.
A convert to Christianity in later life, Lewis had authored a number of works on Christian apologetics and other literature with Christian-based themes before writing the "Narnia" books. The character Aslan is widely accepted by literary academia as being based on Jesus Christ. Lewis did not initially plan to incorporate Christian theological concepts into his "Narnia" stories. Lewis maintained that the "Narnia" books were not allegorical, preferring to term their Christian aspects a "supposition".
"The Chronicles" have, consequently, a large Christian following, and are widely used to promote Christian ideas. However, some Christians object that "The Chronicles" promote "soft-sell paganism and occultism" due to recurring pagan imagery and themes.
Criticism.
Accusations of gender stereotyping.
In later years, both Lewis and the "Chronicles" have been criticised (often by other authors of fantasy fiction) for gender role stereotyping, though other authors have defended Lewis in this area. For example, Lucy gets a healing potion and a dagger, while Peter gets a sword. Most allegations of sexism centre on the description of Susan Pevensie in "The Last Battle" when Lewis writes that Susan is "no longer a friend of Narnia" and interested "in nothing nowadays except nylons and lipstick and invitations".
J.K. Rowling has said:
There comes a point where Susan, who was the older girl, is lost to Narnia because she becomes interested in lipstick. She's become irreligious basically because she found sex. I have a big problem with that.
Philip Pullman, inimical to Lewis on many fronts, calls the "Narnia" stories "monumentally disparaging of women". His interpretation of the Susan passages reflects this view:
Susan, like Cinderella, is undergoing a transition from one phase of her life to another. Lewis didn't approve of that. He didn't like women in general, or sexuality at all, at least at the stage in his life when he wrote the Narnia books. He was frightened and appalled at the notion of wanting to grow up.
In fantasy author Neil Gaiman's short story "The Problem of Susan" (2004), an elderly woman, Professor Hastings, deals with the grief and trauma of her entire family's death in a train crash. Although the woman's maiden name is not revealed, details throughout the story strongly imply that this character is the elderly Susan Pevensie. The story is written for an adult audience and deals with issues of sexuality and violence and through it Gaiman presents a critique of Lewis' treatment of Susan.
Other writers, including fan-magazine editor Andrew Rilstone, oppose this view, arguing that the "lipsticks, nylons and invitations" quote is taken out of context. They maintain that in "The Last Battle", Susan is excluded from Narnia explicitly because she no longer believes in it. At the end of "The Last Battle" Susan is still alive with her ultimate fate unspecified. Moreover, in "The Horse and His Boy", Susan's adulthood and sexual maturity are portrayed in a positive light, and therefore argued to be unlikely reasons for her exclusion from Narnia.
Lewis supporters also cite the positive roles of women in the series, including Jill Pole in "The Silver Chair", Aravis Tarkheena in "The Horse and His Boy", Polly Plummer in "The Magician's Nephew," and particularly Lucy Pevensie in "The Lion, the Witch and the Wardrobe". Alan Jacobs, an English professor at Wheaton College, asserts that Lucy is the most admirable of the human characters and that generally the girls come off better than the boys throughout the series (Jacobs, 2008: 259). In her contribution to "The Chronicles of Narnia and Philosophy", Karin Fry, an Assistant Professor of Philosophy at the University of Wisconsin, Stevens Point, notes that "the most sympathetic female characters in "The Chronicles" are consistently the ones who question the traditional roles of women and prove their worth to Aslan through actively engaging in the adventures just like the boys." Fry goes on to say:
The characters have positive and negative things to say about both male and female characters, suggesting an equality between sexes. However, the problem is that many of the positive qualities of the female characters seem to be those by which they can rise above their femininity ... The superficial nature of stereotypical female interests is condemned.
Accusations of racism.
In addition to sexism, Pullman and others have also accused the Narnia series of fostering racism. Over the alleged racism in "The Horse and His Boy", newspaper editor Kyrie O'Connor wrote:
It's just too dreadful. While the book's storytelling virtues are enormous, you don't have to be a bluestocking of political correctness to find some of this fantasy anti-Arab, or anti-Eastern, or anti-Ottoman. With all its stereotypes, mostly played for belly laughs, there are moments you'd like to stuff this story back into its closet.
Gregg Easterbrook, writing in "The Atlantic", calls the Calormenes "standins for Muslims", while novelist Philip Hensher raises specific concerns that a reader might gain the impression Islam is a "Satanic cult". In rebuttal to this charge, at an address to a C. S. Lewis conference, Dr. Devin Brown argued that there are too many dissimilarities between the Calormene religion and Islam, particularly in the areas of polytheism and human sacrifice, for Lewis' writing to be regarded as critical of Islam.
Adaptations of "The Chronicles of Narnia".
Television.
Various books from "The Chronicles of Narnia" have been adapted for television over the years, including:
"The Lion, the Witch and the Wardrobe" was first adapted in 1967. Comprising ten episodes of thirty minutes each, the screenplay was written by Trevor Preston, and directed by Helen Standage. Unlike subsequent adaptations, it is currently unavailable to purchase for home viewing. The book was adapted again in 1979, this time as an animated cartoon co-produced by Bill Meléndez and the Children's Television Workshop, with a screenplay by David D. Connell. Winner of the 1979 Emmy award for Outstanding Animated Program, it was one of the first major made-for-television feature-length animated films. Many of the characters' voices in the British TV release were re-recorded by British actors and actresses with the exception of the characters Aslan, Peter, Susan, and Lucy.
Between 1988–1990, the first four books (as published) were adapted by the BBC as four television serials. They were also aired in America on the PBS/Disney show WonderWorks. They were nominated for a total of 14 Emmy awards, including "Outstanding Children's Program", and a number of BAFTA awards including Best Children's Programme (Entertainment / Drama) in 1988, 1989 and 1990. The serials were later edited into three feature-length films (the second of which combined "Prince Caspian" and "The Voyage of the Dawn Treader" into one) and released on VHS and DVD.
Radio.
A critically acclaimed BBC Radio 4 dramatisation was produced in the 1980s, starring Maurice Denham as Professor Kirke. Collectively titled "Tales of Narnia", the programs covered the entire series with a running time of approximately 15 hours. In Great Britain, BBC Audiobooks release both audio cassette and compact disc versions of the series.
Between 1999 and 2002 Focus on the Family produced radio dramatisations of the entire series through its Radio Theatre program. Over one hundred performers took part including Paul Scofield as "The Storyteller" and David Suchet as Aslan. Accompanied by an original orchestral score and cinema-quality digital sound design, the series was hosted by Lewis' stepson Douglas Gresham and ran for just over 22 hours. Recordings of the entire adaptation were released on compact disc between 1999–2003.
Stage.
Many stage adaptations of "The Lion, the Witch and the Wardrobe" have been produced over the years.
In 1984, Vanessa Ford Productions presented "The Lion, the Witch and the Wardrobe" at London's Westminster Theatre. Adapted by Glyn Robbins, the play was directed by Richard Williams and designed by Marty Flood. The production was later revived at Westminster and The Royalty Theatre and went on tour until 1997. Productions of other tales from "The Chronicles" were also staged, including "The Voyage of the Dawn Treader" (1986), "The Magician's Nephew" (1988) and "The Horse and His Boy" (1990).
The Royal Shakespeare Company premiered "The Lion, the Witch and the Wardrobe" in Stratford-upon-Avon in 1998. The novel was adapted as a musical production by Adrian Mitchell, with music by Shaun Davey. The show was originally directed by Adrian Noble and designed by Anthony Ward, with the revival directed by Lucy Pitman-Wallace. Well received by audiences, the production was periodically re-staged by the RSC for several years afterwards. Limited engagements were subsequently undertaken at the Barbican Theatre in London and at Sadler's Wells. This adaptation also toured the United States in the early 2000s.
Film.
Sceptical that any cinematic adaptation could render the more fantastical elements and characters of the story realistically, Lewis never sold the film rights to the "Narnia" series. In answering a letter with a question posed by a child in 1957, asking if the Narnia series could please be on television, C. S. Lewis wrote back: "They'd be no good on TV. Humanized beasts can't be presented to the "eye" without at once becoming either hideous or ridiculous. I wish the idiots who run the film world [would] realize that there are stories [which] are for the "ear" alone." Only after seeing a demo reel of CGI animals did Douglas Gresham, Lewis's stepson and literary executor, and the films' co-producer, give approval for a film adaptation.
The first novel adapted was "The Lion, the Witch and the Wardrobe" as ' released in December 2005. Produced by Walden Media and distributed by Walt Disney Pictures, the film was directed by Andrew Adamson, with a screenplay by Ann Peacock, Stephen McFeely and Christopher Markus. The movie was a critical and box-office success, grossing over $745 million worldwide and as of 2011[ [update]] ranked 38th on the list of highest-grossing films in nominal terms. Disney and Walden Media then co-produced a sequel ', released in May 2008, which grossed over $419 million worldwide.
In December 2008 Disney pulled out of financing the remainder of the "Chronicles of Narnia" film series. Already in pre-production at the time, 20th Century Fox and Walden Media eventually co-produced "", which was released in December 2010 going on to gross over $415 million worldwide.
References.
</dl>

</doc>
<doc id="30689" url="http://en.wikipedia.org/wiki?curid=30689" title="Take Me Out to the Ball Game">
Take Me Out to the Ball Game

"Take Me Out to the Ball Game" is a 1908 Tin Pan Alley song by Jack Norworth and Albert Von Tilzer which has become the unofficial anthem of North American baseball, although neither of its authors had attended a game prior to writing the song. The song (chorus only) is traditionally sung during the middle of the seventh inning of a baseball game. Fans are generally encouraged to sing along, and at some ballparks, the words "home team" are replaced with the team name.
History of the song.
Jack Norworth, while riding a subway train, was inspired by a sign that said "Baseball Today – Polo Grounds". In the song, Katie's (and later Nelly's) beau calls to ask her out to see a show. She accepts the date, but only if her date will take her out to the baseball game. The words were set to music by Albert Von Tilzer. (Norworth and Von Tilzer finally saw their first Major League Baseball games 32 and 20 years later, respectively.) The song was first sung by Norworth's then-wife Nora Bayes and popularized by many other vaudeville acts. It was played at a ballpark for the first known time in 1934, at a high-school game in Los Angeles, and researchers think it made its debut at a major-league park later that year.
Norworth wrote an alternative version of the song in 1927. (Norworth and Bayes were famous for writing and performing such smash hits as "Shine On, Harvest Moon".) With the sale of so many records, sheet music, and piano rolls, the song became one of the most popular hits of 1908. The Haydn Quartet singing group, led by popular tenor Harry MacDonough, recorded a successful version on Victor Records.
The most famous recording of the song was credited to "Billy Murray and the Haydn Quartet", even though Murray did not sing on it. The confusion, nonetheless, is so pervasive that, when "Take Me Out to the Ball Game" was selected by the National Endowment for the Arts and the Recording Industry Association of America as one of the 365 top "Songs of the Century", the song was credited to Billy Murray, implying his recording of it as having received the most votes among songs from the first decade. The first recorded version was by Edward Meeker. Meeker's recording was selected by the Library of Congress as a 2010 addition to the National Recording Registry, which selects recordings annually that are "culturally, historically, or aesthetically significant".
Lyrics.
Below are the lyrics of the 1908 version, which is out of copyright.
<poem>
Katie Casey was baseball mad,
Had the fever and had it bad.
Just to root for the home town crew,
Ev'ry sou1
Katie blew.
On a Saturday her young beau
Called to see if she'd like to go
To see a show, but Miss Kate said "No,
I'll tell you what you can do:"
Chorus
Take me out to the ball game,
Take me out with the crowd;
Just buy me some peanuts and Cracker Jack,
I don't care if I never get back.
Let me root, root, root for the home team,
If they don't win, it's a shame.
For it's one, two, three strikes, you're out,
At the old ball game.
Katie Casey saw all the games,
Knew the players by their first names.
Told the umpire he was wrong,
All along,
Good and strong.
When the score was just two to two,
Katie Casey knew what to do,
Just to cheer up the boys she knew,
She made the gang sing this song:
</poem>
1 The term "sou", a coin of French origin, was at the time common slang for a low-denomination coin. In French the expression 'sans le sou' means penniless. Carly Simon's version, produced for Ken Burns' 1994 documentary "Baseball", reads "Ev'ry cent/Katie spent".
Recordings of the song.
The song (or at least its chorus) has been recorded or cited countless times in the 100 years since it was written. The original music and 1908 lyrics of the song are now in the public domain in the United States and the United Kingdom (worldwide copyright remains until 70 years after the composers' deaths), but the copyright to the revised 1927 lyrics remains in effect. It has been used as an instrumental underscore or introduction to many films or skits having to do with baseball.
The first verse of the 1927 version is sung by Gene Kelly and Frank Sinatra at the start of the MGM musical film, "Take Me Out to the Ball Game" (1949), a movie that also features a song about the famous and fictitious double play combination, "O'Brien to Ryan to Goldberg".
In the early to mid-1980s, the Kidsongs Kids recorded a different version of this song for "A Day at Old MacDonald's Farm."
In the mid-1990s, a Major League Baseball ad campaign featured versions of the song performed by musicians of several different genres. An alternative rock version by the Goo Goo Dolls was also recorded. Multiple genre Louisiana singer-songwriter Dr. John and pop singer Carly Simon both recorded different versions of the song for the PBS documentary series Baseball, by Ken Burns.
In 2001, Nike aired a commercial featuring a diverse group of Major League Baseball players singing lines of the song in their native languages. The players and languages featured were Ken Griffey, Jr. (American English), Alex Rodriguez (Caribbean Spanish), Chan Ho Park (Korean), Kazuhiro Sasaki (Japanese), Graeme Lloyd (Australian English), Éric Gagné (Québécois French), Andruw Jones (Dutch), John Franco (Italian), Iván Rodríguez (Caribbean Spanish), and Mark McGwire (American English).
The song in popular culture.
The iconic song has been used and alluded to in many different ways.
In the 1935 Marx Brothers' film "A Night at the Opera", in one of the more unusual uses of the song, composer Herbert Stothart arranged for a full pit orchestra to segue seamlessly from the overture of "Il trovatore" into the chorus of "Take Me Out to the Ball Game".
A 1955 version by Stuart McKay shifted the lyrics two syllables forward to make the song end surprisingly early. In McKay's version the initial "Take me" was sung as an unaccented pickup, causing the final "Game" to land on the same note as "Old" in the original, and leaving last two notes unsung.
In 1988, for the 80th anniversary of the song and the 100th anniversary of the poem "Casey at the Bat", "Sports Illustrated" writer Frank Deford constructed a fanciful story (later expanded to book form as "Casey on the Loose") which posited Katie Casey as being the daughter of the famous slugger from the poem.
In 1994, radio station WJMP, broadcasting to the Akron, Ohio market, played the song continuously during the Major League Baseball players' strike of 1994 as a protest.
The 2001 children's book "Take Me Out of the Bathtub and other Silly Dilly Songs" by Alan Katz and David Catrow, featuring silly words to well-known tunes, recast the end of the chorus as "I used one, two, three bars of soap. Take me out...I'm clean!" in its title number.
In 2006, Jim Burke authored and illustrated a children's book version of "Take Me Out To The Ballgame".
In 2008, Andy Strasberg, Bob Thompson and Tim Wiles (from the Baseball Hall of Fame) wrote a comprehensive book on the history of the song, "Baseball's Greatest Hit: The Story of 'Take Me Out to the Ball Game"'. The book, published by Hal Leonard Books, included a CD with 16 different recordings of the song from various points in time, ranging from a 1908 recording by Fred Lambert, to a seventh-inning-stretch recording by Harry Caray.
From March 13, 2015, the tune of "Take Me Out to the Ball Game" was adopted as the departure melody for trains on the Tokyo Metro Namboku Line at Kōrakuen Station in Tokyo, Japan. Baseball is popular in Japan.
Trivia.
Instrumental parts of "Take Me Out To The Ball Game" can be heard in the background music for Joe E. Brown's 1932 movie "Fireman, Save My Child".
In 1985, it was featured in Kidsongs A Day at Old MacDonald's Farm, which shows the kids playing baseball. Also, Don Mattingly, one of the New York Yankees baseball players, is seen hitting a home run.
Though not so indicated in the lyrics, the chorus is usually sung with a pause in the middle of the word "Cracker", giving 'Cracker Jack' a pronunciation "Cra---cker Jack". Also, there is a noticeable pause between the first and second words "root".
An episode of "Sam & Cat" featured the chorus, but with modified and nonsensical lyrics that start with "Take me down to the basement, fill the buckets with cheese."

</doc>
<doc id="30690" url="http://en.wikipedia.org/wiki?curid=30690" title="Tai chi">
Tai chi

Often shortened to t'ai chi, taiji or tai chi in English usage, T'ai chi ch'uan or tàijíquán is an internal Chinese martial art practised for both its defence training and its health benefits. It is also typically practised for a variety of other personal reasons: its hard and soft martial art technique, demonstration competitions, and longevity. As a result, a multitude of training forms exist, both traditional and modern, which correspond to those aims. Some training forms of t'ai chi ch'uan are especially known for being practiced with relatively slow movement.
Today, t'ai chi ch'uan has spread worldwide. Most modern styles of t'ai chi ch'uan trace their development to at least one of the five traditional schools: Chen, Yang, Wu (Hao), Wu, and Sun.
Overview.
The term "t'ai chi ch'uan" translates as "supreme ultimate fist", "boundless fist", "supreme ultimate boxing" or "great extremes boxing". The "chi" in this instance is the Wade–Giles transliteration of the Pinyin "jí", and is distinct from "qì" ("ch'i", "life energy"). The concept of the "taiji" ("supreme ultimate"), in contrast with "wuji" ("without ultimate"), appears in both Taoist and Confucian Chinese philosophy, where it represents the fusion or mother of "Yin and Yang" into a single ultimate, represented by the "taijitu" symbol . T'ai chi ch'uan theory and practice evolved in agreement with many Chinese philosophical principles, including those of Taoism and Confucianism.
T'ai chi ch'uan training involves five elements, "taolu" (solo hand and weapons routines/forms), "neigong" & "qigong" (breathing, movement and awareness exercises and meditation), "tuishou" (response drills) and "sanshou" (self defence techniques). While t'ai chi ch'uan is typified by some for its slow movements, many t'ai chi styles (including the three most popular – Yang, Wu, and Chen) – have secondary forms with faster pace. Some traditional schools of t'ai chi teach partner exercises known as "tuishou" ("pushing hands"), and martial applications of the "taolu's" (forms') postures.
In China, t'ai chi ch'uan is categorized under the Wudang grouping of Chinese martial arts – that is, the arts applied with internal power. Although the Wudang name falsely suggests these arts originated at the so-called Wudang Mountain, it is simply used to distinguish the skills, theories and applications of "neijia" ("internal arts") from those of the Shaolin grouping, "waijia" ("hard" or "external") martial art styles.
Since the first widespread promotion of t'ai chi ch'uan's health benefits by Yang Shaohou, Yang Chengfu, Wu Chien-ch'uan, and Sun Lutang in the early 20th century, it has developed a worldwide following among people with little or no interest in martial training, for its benefit to health and health maintenance. Medical studies of t'ai chi support its effectiveness as an alternative exercise and a form of martial arts therapy.
It is purported that focusing the mind solely on the movements of the form helps to bring about a state of mental calm and clarity. Besides general health benefits and stress management attributed to t'ai chi ch'uan training, aspects of traditional Chinese medicine are taught to advanced t'ai chi ch'uan students in some traditional schools.
Some other forms of martial arts require students to wear a uniform during practice. In general, t'ai chi ch'uan schools do not require a uniform, but both traditional and modern teachers often advocate loose, comfortable clothing and flat-soled shoes.
The physical techniques of t'ai chi ch'uan are described in the "T'ai chi classics", a set of writings by traditional masters, as being characterized by the use of leverage through the joints based on coordination and relaxation, rather than muscular tension, in order to neutralize, yield, or initiate attacks. The slow, repetitive work involved in the process of learning how that leverage is generated gently and measurably increases, opens the internal circulation (breath, body heat, blood, lymph, peristalsis, etc.).
The study of t'ai chi ch'uan primarily involves three aspects:
Name.
T'ai chi ch'uan / Taijiquan is formed by the combination of three Chinese characters (hanzi):
Despite having a single Chinese spelling, 太極拳, there are two different spellings in the English usage, one derived from the Wade–Giles and the other from the Pinyin transliteration, with the West mostly being familiar with the Wade–Giles, t'ai chi ch'uan. This name is often shortened by Westerners to "t'ai chi" (or "tai chi," a common misspelling). This shortened name is the same as that of t'ai chi philosophy, sometimes resulting in confusion between the two. The "chi" in the martial art's name can also be mistaken for "ch'i" (氣), especially as "ch'i" is involved in the practice of t'ai chi ch'uan. The 'up-to-date' Pinyin transliteration, tàijíquán, is not subject to such misinterpretation, as the spelling of the hanzi 極, "jí" is quite distinct from that of 氣, "qi". "T'ai chi ch'uan" (including "t'ai chi" and their misspellings) remains the popular spelling used by the general public today. Many professional practitioners, masters, and martial arts bodies (such as the IWUF) write it as taijiquan.
Historic origin.
When tracing t'ai chi ch'uan's formative influences to Taoist and Buddhist monasteries, there seems little more to go on than legendary tales from a modern historical perspective, but t'ai chi ch'uan's practical connection to and dependence upon the theories of Sung dynasty Neo-Confucianism (a conscious synthesis of Taoist, Buddhist, and Confucian traditions, especially the teachings of Mencius) is claimed by some traditional schools. T'ai chi ch'uan's theories and practice are believed by these schools to have been formulated by the Taoist monk Zhang Sanfeng in the 12th century, at about the same time that the principles of the Neo-Confucian school were making themselves felt in Chinese intellectual life. However, modern research casts serious doubts on the validity of those claims, pointing out that a 17th-century piece called "Epitaph for Wang Zhengnan" (1669), composed by Huang Zongxi (1610–1695 A.D.), is the earliest reference indicating any connection between Zhang Sanfeng and martial arts whatsoever, and must not be taken literally but must be understood as a political metaphor instead. Claims of connections between t'ai chi ch'uan and Zhang Sanfeng appeared no earlier than the 19th century.
History records that Yang Luchan trained with the Chen family for 18 years before he started to teach the art in Beijing, which strongly suggests that his art was based on, or heavily influenced by, the Chen family art. The Chen family are able to trace the development of their art back to Chen Wangting in the 17th century.
What is now known as "t'ai chi ch'uan" appears to have received this appellation from only around the mid-1800s. There was a scholar in the Imperial Court by the name of Ong Tong He who witnessed a demonstration by Yang Luchan at a time before Yang had established his reputation as a teacher. Afterwards Ong wrote: "Hands holding Taiji shakes the whole world, a chest containing ultimate skill defeats a gathering of heroes." Before this time the art may have had a number of different names, and appears to have been generically described by outsiders as "zhan quan" (沾拳, "touch boxing"), "mian quan" (绵拳, "soft boxing") or "shisan shi" (十三式, "the thirteen techniques").
Relation to "taiji" philosophy.
In modern usage, the term 太極,"t'ai chi / taiji" (unless further qualified as in "taiji philosophy" or "taiji diagram") is now commonly understood, both in the West and in mainland China, to refer to the martial art and exercise system. However, the term has its origins in Chinese philosophy. The word "taiji" translates to "great pole/goal" or "supreme ultimate", and is believed to be a pivotal, spiraling, or coiling force that transforms the neutrality of "wuji" to a state of polarity depicted by the "taijitu". T'ai chi / taiji is thus symbolically represented by a state between "wuji" and the polar "yin and yang", not by the actual "yin and yang" symbol, as is frequently misinterpreted. The combination of the term "taiji" and "quan" ("fist"), produces the martial art's name taijiquan or "taiji fist", showing the close link and use of the "taiji" concept in the martial art. Taijiquan does not directly refer to the use of qi as is commonly assumed. The practice of taijiquan is meant to be in harmony with "taiji" philosophy, utilising and manipulating "qi" via "taiji", to produce great effect with minimal effort.
The appropriateness of this more recent appellation is seen in the oldest literature preserved by these schools where the art is said to be a study of "yin" (receptive) and "yang" (active) principles, using terminology found in the Chinese classics, especially the I Ching and the Tao Te Ching.
History and styles.
There are five major styles of t'ai chi ch'uan, each named after the Chinese family from which it originated:
The order of verifiable age is as listed above. The order of popularity (in terms of number of practitioners) is Yang, Wu, Chen, Sun, and Wu/Hao. The major family styles share much underlying theory, but differ in their approaches to training.
There are now dozens of new styles, hybrid styles, and offshoots of the main styles, but the five family schools are the groups recognized by the international community as being the orthodox styles. Other important styles are Zhaobao t'ai chi ch'uan, a close cousin of Chen-style, which has been newly recognized by Western practitioners as a distinct style, the Fu style, created by Fu Chen Sung, which evolved from Chen, Sun and Yang styles, and also incorporates movements from Baguazhang (Pa Kua Chang) and the Cheng-style (鄭氏) of Cheng Man Ch'ing which is a simplification of the traditional Yang style. 
The differences between the different styles range from varying speeds to the way in which the movements are performed. For example, the form "Parting the wild horse's mane" in Yang-style does not at all resemble the very same movement in Sun-style. Also, the Sun 73 forms take as long to perform as the Yang 24 forms.
All existing styles can be traced back to the Chen-style, which had been passed down as a family secret for generations. The Chen family chronicles record Chen Wangting, of the family's 9th generation, as the inventor of what is known today as t'ai chi ch'uan. Yang Luchan became the first person outside the family to learn t'ai chi ch'uan. His success in fighting earned him the nickname Yang Wudi, which means "Unbeatable Yang", and his fame and efforts in teaching greatly contributed to the subsequent spreading of t'ai chi ch'uan knowledge.
T'ai chi ch'uan in the USA.
Choy Hok Pang, a disciple of Yang Chengfu, was the first known proponent of t'ai chi ch'uan to openly teach in the United States in 1939. Subsequently, his son and student Choy Kam Man emigrated to San Francisco from Hong Kong in 1949 to teach t'ai chi ch'uan in San Francisco's Chinatown. Choy Kam Man taught until he died in 1994.
Sophia Delza, a professional dancer and student of Ma Yueliang, performed the first known public demonstration of t'ai chi ch'uan in the United States at the Museum of Modern Art in New York City in 1954. She also wrote the first English language book on t'ai chi, "T'ai Chi Ch'uan: Body and Mind in Harmony", in 1961. She taught regular classes at Carnegie Hall, the Actors Studio, and the United Nations.
Another early practitioner of t'ai chi ch'uan to openly teach in the United States was Zheng Manqing, who opened his school Shr Jung T'ai Chi after he moved to New York from Taiwan in year 1964. Unlike the older generation of t'ai chi practitioners, Zheng was highly cultured and educated, and thus he was able to transcribe Yang's dictation into a written manuscript that became the de facto manual for Yang style t'ai chi. Zheng felt Yang's traditional 108-movement Long Form was unnecessarily long and repetitive, which makes it difficult for learn and make progress. He thus created a shortened 37-movement version and taught that in his schools. Zheng's form became very popular and was the dominant form in the New York-Philadelphia-Washington DC corridor until other teachers started to emigrate to the United States in larger numbers in the 90's. He taught until his death in 1975. 
T'ai chi ch'uan lineage tree.
Note:
Modern forms.
The Cheng Man-ch'ing (Zheng Manqing) and Chinese Sports Commission short forms are derived from Yang family forms, but neither is recognized as Yang family t'ai chi ch'uan by standard-bearing Yang family teachers. The Chen, Yang, and Wu families are now promoting their own shortened demonstration forms for competitive purposes.
T'ai chi ch'uan today.
In the last twenty years or so, t'ai chi ch'uan classes that purely emphasise health have become popular in hospitals, clinics, as well as community and senior centres. This has occurred as the baby boomers generation has aged and the art's reputation as a low-stress training method for seniors has become better known.
As a result of this popularity, there has been some divergence between those that say they practice t'ai chi ch'uan primarily for self-defence, those that practice it for its aesthetic appeal (see "wushu" below), and those that are more interested in its benefits to physical and mental health. The "wushu" aspect is primarily for show; the forms taught for those purposes are designed to earn points in competition and are mostly unconcerned with either health maintenance or martial ability. More traditional stylists believe the two aspects of health and martial arts are equally necessary: the "yin and yang" of t'ai chi ch'uan. The t'ai chi ch'uan "family" schools, therefore, still present their teachings in a martial art context, whatever the intention of their students in studying the art.
T'ai chi ch'uan as sport.
In order to standardize t'ai chi ch'uan for "wushu" tournament judging, and because many t'ai chi ch'uan teachers have either moved out of China or had been forced to stop teaching after the Communist regime was established in 1949, the government sponsored the Chinese Sports Committee, who brought together four of their "wushu" teachers to truncate the Yang family hand form to 24 postures in 1956. They wanted to retain the look of t'ai chi ch'uan, but create a routine that would be less difficult to teach and much less difficult to learn than longer (in general, 88 to 108 posture), classical, solo hand forms. In 1976, they developed a slightly longer form also for the purposes of demonstration that still would not involve the complete memory, balance, and coordination requirements of the traditional forms. This became the "Combined 48 Forms" that were created by three "wushu" coaches, headed by Men Hui Feng. The combined forms were created based on simplifying and combining some features of the classical forms from four of the original styles: Chen, Yang, Wu, and Sun. As t'ai chi ch'uan again became popular on the mainland, more competitive forms were developed to be completed within a six-minute time limit. In the late-1980s, the Chinese Sports Committee standardized many different competition forms. They developed sets to represent the four major styles as well as combined forms. These five sets of forms were created by different teams, and later approved by a committee of "wushu" coaches in China. All sets of forms thus created were named after their style, e.g., the "Chen-style national competition form" is the "56 Forms", and so on. The combined forms are "The 42-Form" or simply the "Competition Form". Another modern form is the "97 movements combined t'ai chi ch'uan form", created in the 1950s; it contains characteristics of the Yang, Wu, Sun, Chen, and Fu styles blended into a combined form. The "wushu" coach Bow Sim Mark is a notable exponent of the "67 combined form".
These modern versions of t'ai chi ch'uan (often listed as the pinyin romanization "taijiquan" among practitioners, teachers and masters) have since become an integral part of international "wushu" tournament competition, and have been featured in popular movies, starring or choreographed by well-known "wushu" competitors, such as Jet Li and Donnie Yen.
In the 11th Asian Games of 1990, "wushu" was included as an item for competition for the first time with the "42-Form" being chosen to represent t'ai chi ch'uan. The International Wushu Federation (IWUF) applied for "wushu" to be part of the Olympic games, but will not count medals.
Practitioners also test their practical martial skills against students from other schools and martial arts styles in "tuishou" ("pushing hands") and "sanshou" competition.
Philosophy.
The philosophy of t'ai chi ch'uan is that, if one uses hardness to resist violent force, then both sides are certainly to be injured at least to some degree. Such injury, according to t'ai chi ch'uan theory, is a natural consequence of meeting brute force with brute force. Instead, students are taught not to directly fight or resist an incoming force, but to meet it in softness and follow its motion while remaining in physical contact until the incoming force of attack exhausts itself or can be safely redirected, meeting "yang" with "yin". When done correctly, this "yin/yang" or "yang/yin" balance in combat, or in a broader philosophical sense, is a primary goal of t'ai chi ch'uan training. Lao Tzu provided the archetype for this in the Tao Te Ching when he wrote, "The soft and the pliable will defeat the hard and strong."
Traditional schools also emphasize that one is expected to show "wude" ("martial virtue/heroism"), to protect the defenseless, and show mercy to one's opponents.
Training and techniques.
The core training involves two primary features: the first being "taolu" (solo "forms"), a slow sequence of movements which emphasize a straight spine, abdominal breathing and a natural range of motion; the second being different styles of "tuishou" ("pushing hands") for training movement principles of the form with a partner and in a more practical manner.
Solo ("taolu", "neigong" and "qigong").
The "taolu" (solo "forms") should take the students through a complete, natural range of motion over their centre of gravity. Accurate, repeated practice of the solo routine is said to retrain posture, encourage circulation throughout the students' bodies, maintain flexibility through their joints, and further familiarize students with the martial application sequences implied by the various forms. The major traditional styles of t'ai chi have forms that differ somewhat in terms of aesthetics, but there are also many obvious similarities that point to their common origin. The solo forms – empty-hand and weapon – are catalogues of movements that are practised individually in pushing hands and martial application scenarios to prepare students for self-defence training. In most traditional schools, different variations of the solo forms can be practised: fast/slow, small-circle / large-circle, square/round (which are different expressions of leverage through the joints), low-sitting / high-sitting (the degree to which weight-bearing knees are kept bent throughout the form), for example.
Breathing exercises; "neigong" ("internal skill") or, more commonly, "qigong" ("life energy cultivation") are practiced to develop "qi" ("life energy") in coordination with physical movement and "zhan zhuang" ("standing like a post") or combinations of the two. These were formerly taught only to disciples as a separate, complementary training system. In the last 60 years they have become better known to the general public.
Qigong versus t'ai chi ch'uan.
"Qigong" involves coordinated movement, breath, and awareness used for health, meditation, and martial arts training. While many scholars and practitioners consider t'ai chi ch'uan to be a type of "qigong", the two are commonly distinguished as separate but closely related practices, with "qigong" playing an important role in training for t'ai chi ch'uan, and with many ta'i chi ch'uan movements performed as part of "qigong" practice. The focus of "qigong" is typically more on health or meditation than martial applications.
Partnered ("tuishou" and "sanshou").
T'ai chi ch'uan's martial aspect relies on sensitivity to the opponent's movements and centre of gravity dictating appropriate responses. Effectively affecting or "capturing" the opponent's centre of gravity immediately upon contact, is trained as the primary goal of the martial t'ai chi ch'uan student. The sensitivity needed to capture the centre is acquired over thousands of hours of first "yin" (slow, repetitive, meditative, low-impact) and then later adding "yang" ("realistic," active, fast, high-impact) martial training through "taolu" ("forms"), "tuishou" ("pushing hands"), and "sanshou" ("sparring"). T'ai chi ch'uan trains in three basic ranges: close, medium and long, and then everything in between. Pushes and open-hand strikes are more common than punches, and kicks are usually to the legs and lower torso, never higher than the hip, depending on style. The fingers, fists, palms, sides of the hands, wrists, forearms, elbows, shoulders, back, hips, knees, and feet are commonly used to strike, with strikes to the eyes, throat, heart, groin, and other acupressure points trained by advanced students. "Chin na", which are joint traps, locks, and breaks are also used. Most t'ai chi ch'uan teachers expect their students to thoroughly learn defensive or neutralizing skills first, and a student will have to demonstrate proficiency with them before offensive skills will be extensively trained.
In addition to the physical form, martial t'ai chi ch'uan schools also focus on how the energy of a strike affects the other person. A palm strike that looks to have the same movement may be performed in such a way that it has a completely different effect on the target's body. A palm strike that could simply push the opponent backward, could instead be focused in such a way as to lift the opponent vertically off the ground, breaking his/her centre of gravity; or that it could terminate the force of the strike within the other person's body with the intent of causing internal damage.
Most aspects of a trainee's t'ai chi ch'uan development are meant to be covered within the
partnered practice of "tuishou", and so, "sanshou" ("sparring") is not as commonly used as a method of training, but more advanced students sometimes do practice by "sanshou". "Sanshou" is more common to tournaments such as "wushu" tournaments.
Weapons.
Variations of t'ai chi ch'uan involving weapons also exist such as "taijijian".
The weapons training and fencing applications employ:
More exotic weapons still used by some traditional styles include:
Health.
A 2011 overview of existing research on t'ai chi ch'uan's health effects found evidence of medical benefit for preventing falls, mental health, and general health in elderly people. There wasn't conclusive evidence for any of the other conditions researched, including Parkinson's disease, diabetes, cancer and arthritis.
The practice of t'ai chi ch'uan is encouraged by the National Parkinson Foundation and Diabetes Australia.
Attire and ranking.
In practice traditionally there is no specific uniform required in the practice of t'ai chi ch'uan. Modern day practitioners usually wear comfortable, loose T-shirts and trousers made from breathable natural fabrics, that allow for free movement during practice. Despite this, t'ai chi ch'uan has become synonymous with "t'ai chi uniforms" or "kung fu uniforms" that usually consist of loose-fitting traditional Chinese styled trousers and a long or short-sleeved shirt, with a Mandarin collar and buttoned with Chinese frog buttons. The long-sleeved variants are referred to as Northern-style uniforms, whilst the short-sleeved, Southern-style uniforms. The colour of this clothing is usually, all white, all black, black & white, or any other colour, mostly being either all a single solid colour or a combination of 2 colours: one colour being the actual clothing and the binding being a contrasting colour. They are normally made from natural fabrics such as cotton or silk. These "uniforms" are not a requirement, but rather are usually worn by masters & professional practitioners during demonstrations, tournaments and other public exhibitions.
There is no standardized t'ai chi ch'uan ranking system, and not all schools use belt rankings. Some schools may present students with belts depicting rank, similar to "dans" in Japanese martial arts. A simple uniform element of respect and allegiance to one's teacher and their methods and community, belts also mark hierarchy, skill, and accomplishment of practice in one school's style and system. During "wushu" tournaments, masters and grandmasters often wear "kung fu uniforms" which tend to have no belts. Wearing a belt signifying rank in such a situation would be unusual.
In popular culture.
T'ai chi ch'uan plays an important role in many martial arts and fighting action movies, series, novels, especially in those ones which belong to the wuxia genre, as well as in video games, trading cards games, etc. Fictional portrayals often refer to Zhang San Feng, who is reported to be the first one harnessing and operationalising the benefits of the 'internal' and the 'soft', and to the Taoist monasteries of Wudang Mountains, where he lived.

</doc>
<doc id="30691" url="http://en.wikipedia.org/wiki?curid=30691" title="Lisa Beamer">
Lisa Beamer

Lisa Brosious Beamer (born April 10, 1969) is the widow of Todd Beamer, a victim of the United Flight 93 crash as part of the September 11, 2001 attacks in the United States. She is a 1991 graduate of Wheaton College; she gave the 2011 commencement address at Wheaton.
In the immediate aftermath of the attacks, Beamer had a high profile, with more than 200 media appearances in 6 months. She was introduced by President George W. Bush at a commemoration ceremony. Shortly after the attacks, she set up the Todd M. Beamer Memorial Foundation, which was initially run by a family friend. The organization sought to trademark the phrase "Let's Roll," which was the subject of some criticism after some accused her of seeking to profit from her husband's death.
In 2003, Beamer and co-author Ken Abraham wrote a book about Todd and her attempts to deal with her grief over his death, "Let's Roll!: Ordinary People, Extraordinary Courage". The book is about Todd and Lisa's life before the crash and her life since. Royalties from the book were donated to the Todd M. Beamer Foundation (since renamed Heroic Choices), which was founded in 2001 by Lisa Beamer and others to build resiliency in children who have suffered trauma. As of 2007, Beamer's foundation, Heroic Choices, was struggling to maintain financial viability. According to the Board Chair, "[as with any charity created after 9/11], the farther you get away from the event, the more difficult it is to raise funds."

</doc>
<doc id="30696" url="http://en.wikipedia.org/wiki?curid=30696" title="Green Party of the United States">
Green Party of the United States

The Green Party of the United States (GPUS) is a green political party in the United States founded in 1984 as a federation of state green parties. With its founding, the Green Party of the United States became the primary national Green organization in that country, eclipsing the Greens/Green Party USA, which emphasized non-electoral movement building. The Association of State Green Parties (ASGP), a forerunner organization, first gained widespread public attention during Ralph Nader's Presidential run. At the state legislature level the party has several members elected, including in California, Maine and Arkansas. A number of Greens around the United States hold positions on the municipal level, including on school boards, city councils and as mayors. The party promotes environmentalism and social justice with policy principles in nonviolence, grassroots democracy and participatory democracy, gender equality, and anti-racism. It places itself on the center-left of the political spectrum.
Ideology.
The Green Party follows the ideology Green politics which is based on the Four Pillars of the Green Party: Ecological Wisdom, Social and Economic Justice, Grassroots Democracy, and Nonviolence and Peace. It emphasizes environmentalism, non-hierarchical participatory democracy, social justice, respect for diversity, peace, and nonviolence. Their "Ten Key Values," which are described as non-authoritarian guiding principles, are as follows:
The Green Party does not accept donations from corporations, political action committees (PACs), 527(c) organizations or soft money. The party's platforms and rhetoric harshly criticize any corporate influence and control over government, media, and society at large.
History.
Early years.
The political movement that began in 1984 as the decentralized Committees of Correspondence (GCoC) evolved into a more centralized structure by 1990, opening a national clearinghouse, and forming governing bodies, bylaws, and a platform under the name The Green Committees of Correspondence (GCoC) and by 1990, simply, The Greens. The organization conducted non-electoral grassroots organizing efforts, educational activities, and electoral campaigns.
Internal divisions arose between members who saw electoral politics as ultimately corrupting and supported the notion of an "anti-party party" formed by Petra Kelly and other leaders of Die Grünen in Germany, vs. those who saw electoral strategies as a crucial engine of social change (organized as The Green Politics Network in 1990 and The National Association of Statewide Green Parties by 1994). A struggle for the direction of the organization culminated a "compromise agreement," ratified in 1990 at the Greens National Congress in Elkins, West Virginia – in which both strategies would be accommodated within the same organization under a 527 political organization renamed The Greens/Green Party USA (G/GPUSA).
The compromise agreement subsequently collapsed and two Green Party organizations have co-existed in the United States since the mid-1990s, now operating independently as the Green Party of the United States and the G/GPUSA, which is no longer registered as a political party.
Fundraising and position on super PACs.
In the early decades of Green organizing in the United States, the prevailing U.S. system of money-dominated elections was universally rejected by Greens, so that some Greens were reluctant to have Greens participate in the election system at all, because they deemed the campaign finance system inherently corrupt. Other Greens felt strongly that the Green Party should develop in the electoral arena; many of these Greens felt that adopting an alternative model of campaign finance, emphasizing self-imposed contribution limits, would present a wholesome and attractive contrast to the odious campaign finance practices of the money-dominated major parties.
Over the years, some state Green parties have come to place less emphasis on the principle of self-imposed limits than they did in the past. Nevertheless, it is safe to say that Green Party fundraising (for candidates' campaigns and for the party itself) still tends to rely on relatively small contributions, and that Greens generally decry not only the rise of the super-PACs but also the big-money system, which some Greens criticize as plutocracy.
Some Greens feel that the Green Party's position should be simply to follow the laws and regulations of campaign finance. Other Greens argue that it would injure the Green Party not to practice a principled stand against the anti-democratic influence of money in the political process.
Candidates for office, like Jill Stein, the 2012 Green Party nominee for the President of the United States, typically rely on smaller donations to fund their campaigns.
Structure and composition.
Committees.
The Green Party has two national committees recognized by the Federal Election Commission:
Caucuses.
Four identity caucuses have achieved representation on the GNC:
Three other caucuses are working toward formal recognition by the GNC:
The Blue Greens (workers' caucus) and the Native American caucus also exist, but have not established organizing committees yet.
State parties.
The following is a list of the accredited state chapters of the Green Party of the United States as listed on the Party's official website.
The Green Party does not currently operate state chapters in Alabama, Kansas, North Dakota, Oklahoma, South Dakota, Utah, or Vermont. Its Presidential candidates have been able to appear on the ballot in some of those states, however. In addition, the Green Party operates a chapter in the US Virgin Islands.
Geographic distribution.
The Green Party has its strongest popular support on the Pacific Coast, Upper Great Lakes, and Northeast, as reflected in the geographical distribution of Green candidates elected. Californians have elected 55 of the 226 office-holding Greens nationwide as of June 2007. Other states with high numbers of Green elected officials include Pennsylvania (31), Wisconsin (23), Massachusetts (18), and Maine (17). Maine has the highest per capita number of Green elected officials in the country, and the largest Green registration percentage with more than 29,273 Greens comprising 2.95% of the electorate as of November 2006. Madison, Wisconsin, is the city with the most Green elected officials (8) followed by Portland, Maine (7).
In 2005, the Green Party had 305,000 registered members in states allowing party registration, and tens of thousands of members and contributors in the rest of the country. One challenge that the Green Party (as well as other third parties) faces is the difficulty of overcoming ballot access laws in many states.
Office holders.
As of October 18, 2012, there were 134 elected Greens across the United States. Positions held varied greatly, from mayor to city council, school board to sanitation district. Twenty-three states had Greens elected at the municipal level, representing every region of the country except for East South Central. Greens held mayorships in California and New York, and positions on city, neighborhood, or common councils in the West, South, Midwest, and Northeast. Major cities with a Green presence were spread throughout the country and included Los Angeles, Minneapolis, Milwaukee, Cleveland, Oklahoma City, and Washington, DC.
The Green Party in the United States has won elected office at the local level; most winners of public office in the United States who are considered Greens have won nonpartisan elections. The highest-ranking Greens ever elected in the nation were: John Eder, a member of the Maine House of Representatives until his defeat in November 2006; Audie Bock, elected to the California State Assembly in 1999 but switched her registration to Independent seven months later running as an independent in the 2000 election; Richard Carroll, elected to the Arkansas House of Representatives in 2008 but switched parties to become a Democrat five months after his election; and Fredrick Smith, elected to the Arkansas House of Representatives in 2012, but re-registered as a Democrat in 2014.
In November 2010, Ben Chipman, a former Green Party leader, ran for Maine House of Representaitves as an unenrolled candidate and was elected. Chipman was re-elected in 2012 and 2014.
As of 2014, Mayor Gayle McLaughlin is the most notable Green elected official in the United States. McLaughlin is serving her second term as mayor of Richmond, California. McLaughlin defeated two Democrats in 2006 to become mayor, and was reelected in 2010. Richmond, with a population of over 100,000 people, is the largest city in the country with a Green mayor.
Fairfax, California, Arcata, California, Sebastopol, California, and New Paltz, New York are the only towns in the United States to ever hold a Green Party majority in their town councils. Twin Ridges Elementary in Nevada County, California held the first Green Party majority school board in the United States.

</doc>
<doc id="30697" url="http://en.wikipedia.org/wiki?curid=30697" title="Triple jump">
Triple jump

The triple jump, sometimes referred to as the hop, step and jump or the hop, skip and jump, is a track and field event, similar to the long jump. The competitor runs down the track and performs a hop, a bound and then a jump into the sand pit. The triple jump was inspired by the ancient Olympic Games and has been a modern Olympics event since the Games' inception in 1896.
According to IAAF rules, "the hop shall be made so that an athlete lands first on the same foot
as that from which he has taken off; in the step he shall land on the
other foot, from which, subsequently, the jump is performed." 
The current male and female world record holders are Jonathan Edwards of Great Britain, with a jump of 18.29 m ( ft  in), and Inessa Kravets of Ukraine, with a jump of 15.50 m ( ft  in). Both records were set during 1995 World Championships in Gothenburg.
History.
Historical sources on the ancient Olympic Games occasionally mention jumps of 15 meters or more. This led sports historians to conclude that these must have been a series of jumps, thus providing the basis for the triple jump. However, there is no evidence for the triple jump being included in the ancient Olympic Games, and it is possible
that the recorded extraordinary distances are due to artistic license of the authors of victory poems, rather than attempts to report accurate results.
The triple jump was a part of the inaugural modern Olympics in Athens, although at the time it consisted of two hops on the same foot and then a jump. In fact, the first modern Olympic champion, James Connolly, was a triple jumper. Early Olympics also included the standing triple jump, although this has since been removed from the Olympic program and is rarely performed in competition today. The women's triple jump was introduced into the Atlanta Olympics in 1996.
In Irish mythology the geal-ruith (triple jump), was an event contested in the ancient Irish Tailteann Games as early as 1829 BC.
Technique.
Approach.
The athlete sprints down a runway to a takeoff mark, from which the triple jump is measured. The takeoff mark is commonly a physical piece of wood or similar material embedded in the runway, or a rectangle painted on the runway surface. In modern championships a strip of plasticine, tape, or modeling clay is attached to the far edge of the board to record athletes overstepping or "scratching" the mark, defined by the trailing edge of the board. There are three phases of the triple jump: the "hop" phase, the "bound" or "step" phase, and the "jump" phase. These three phases are executed in one continuous sequence.
 Phases of Phillips Idowu jumping at the 2008 Summer Olympics
Hop.
The hop starts with the athlete jumping from the take off board on one leg, which for descriptive purposes will be the right leg . The objective of the first phase is to hop "out", focusing all momentum forward. The hop landing phase is very active, involving a powerful backward "pawing" action of the right leg, with the right take-off foot landing heel first on the runway. 
Step.
The hop landing also marks the beginning of the step phase, where the athlete utilises the backward momentum of the right leg to immediately execute a powerful jump forwards and upwards, the left leg assisting the take-off with a powerful hip flexion thrust. This leads to the familiar step-phase mid-air position, with the right take off leg trailing flexed at the knee, and the left leg now leading flexed at the hip and knee. The jumper then holds this position for as long as possible, before extending the knee of the leading left leg and then immediately beginning a powerful backward motion of the whole left leg, again landing on the runway with a powerful pawing action. 
Jump.
The step landing forms the beginning of the take-off of the final phase (the jump), where the athlete utilises the backward force from the left leg to take off again. The jump phase is very similar to the long jump although most athletes have lost too much speed by this time to manage a full hitch kick, and most use a hang or sail technique. 
When landing in the sand-filled pit, the jumper should aim to avoid sitting back on landing, or placing either hand behind the feet. The sand pit usually begins 13m from the take off board for male international competition, or 11m from the board for international female and club-level male competition. Each phase of the triple jump should get progressively higher, and there should be a regular rhythm to the 3 landings.
Foul.
A "foul", also known as a "scratch," or missed jump, occurs when a jumper oversteps the takeoff mark, misses the pit entirely, does not use the correct foot sequence throughout the phases, or does not perform the attempt in the allotted amount of time (usually about 90 seconds). When a jumper "scratches," the seated official will raise a red flag and the jumper who was "on deck," or up next, prepares to jump.
Records.
Outdoor.
"Note: As in all track-and-field events, results cannot count towards records if they are Wind assisted (>2.0 m/s)."

</doc>
<doc id="30698" url="http://en.wikipedia.org/wiki?curid=30698" title="Trinitrotoluene">
Trinitrotoluene

Trinitrotoluene (TNT), or more specifically 2,4,6-trinitrotoluene, is a chemical compound with the formula C6H2(NO2)3CH3. This yellow-colored solid is sometimes used as a reagent in chemical synthesis, but it is best known as a useful explosive material with convenient handling properties. The explosive yield of TNT is considered to be the standard measure of strength of bombs and other explosives. In chemistry, TNT is used to generate charge transfer salts.
While the two words are sometimes used interchangeably in common conversation, TNT is not the same as dynamite, a special formatting of nitroglycerin for use as an industrial explosive.
History.
TNT was first prepared in 1863 by German chemist Julius Wilbrand and originally used as a yellow dye. Its potential as an explosive was not appreciated for several years mainly because it was so difficult to detonate and because it was less powerful than alternatives. TNT can be safely poured when liquid into shell cases, and is so insensitive that in 1910, it was exempted from the UK's Explosives Act 1875 and was not considered an explosive for the purposes of manufacture and storage.
The German armed forces adopted it as a filling for artillery shells in 1902. TNT-filled armour-piercing shells would explode after they had penetrated the armour of British capital ships, whereas the British lyddite-filled shells tended to explode upon striking armour, thus expending much of their energy outside the ship. The British started replacing lyddite with TNT in 1907.
The United States Navy continued filling armor piercing shells with explosive D after some other nations had switched to TNT; but began filling naval mines, bombs, depth charges, and torpedo warheads with burster charges of crude "grade B" TNT with the color of brown sugar and requiring an explosive booster charge of granular crystallized "grade A" TNT for detonation. High explosive shells were filled with "grade A" TNT, which became preferred for this other use as industrial chemical capacity became available for removing xylene and similar hydrocarbons from the toluene feedstock and other nitrotoluene isomer byproducts from the nitrating reactions.
TNT is still widely used by the United States military, as well as construction companies around the world. The majority of TNT currently used by the US military is manufactured by Radford Army Ammunition Plant near Radford, Virginia.
Difference from Dynamite.
Though both trinitrotoluene (TNT) and dynamite are high explosives, they use different chemicals and materials. Dynamite is an absorbent mixture soaked in nitroglycerin then compacted into a cylindrical shape and wrapped in paper. TNT is a chemical compound called 2,4,6-trinitrotoluene. (Military dynamite is a dynamite substitute, also formulated without nitroglycerin, containing 75% RDX, 15% TNT, 5% SAE 10 motor oil, and 5% cornstarch, but much safer to store and handle for long time than Nobel's dynamite.)
A stick of dynamite (0.19 kg, 75% nitroglycerin, no other explosives in the mixture of dynamite) contains roughly 1 MJ of energy. The energy density (joules/kilogram or J/kg) of dynamite is approximately 5.0 MJ/kg, compared to 4.0 MJ/kg of TNT (for TNT r.e. factor=1.00; for Nobel dynamite r.e. factor=1.25).
Preparation.
In industry, TNT is produced in a three-step process. First, toluene is nitrated with a mixture of sulfuric and nitric acid to produce mononitrotoluene (MNT). The MNT is separated and then renitrated to dinitrotoluene or DNT. In the final step, the DNT is nitrated to trinitrotoluene or TNT using an anhydrous mixture of nitric acid and oleum. Nitric acid is consumed by the manufacturing process, but the diluted sulfuric acid can be reconcentrated and reused. Subsequent to nitration, TNT is stabilized by a process called sulfitation, where the crude TNT is treated with aqueous sodium sulfite solution in order to remove less stable isomers of TNT and other undesired reaction products. The rinse water from sulphitation is known as red water and is a significant pollutant and waste product of TNT manufacture.
Control of nitrogen oxides in feed nitric acid is very important because free nitrogen dioxide can result in oxidation of the methyl group of toluene. This reaction is highly exothermic and carries with it the risk of a runaway reaction leading to an explosion.
In the laboratory, 2,4,6-trinitrotoluene is produced by a two-step process. A nitrating mixture of concentrated nitric and sulfuric acids is used to nitrate toluene to a mixture of mono- and di-nitrotoluene isomers, with cooling to maintain careful temperature control. The nitrated toluenes are then separated, washed with dilute sodium bicarbonate to remove oxides of nitrogen, and then carefully nitrated with a mixture of fuming nitric acid and sulfuric acid. Towards the end of the nitration, the mixture is heated on a steam bath. The trinitrotoluene is separated, washed with a dilute solution of sodium sulfite and then recrystallized from alcohol.
Applications.
TNT is one of the most commonly used explosives for military, industrial, and mining applications. TNT has been used in conjunction with hydraulic fracturing, a process used to recover oil and gas from shale formations. The technique involves displacing and detonating nitroglycerin in hydraulically induced fractures followed by wellbore shots using pelletized TNT. 
TNT is valued partly because of its insensitivity to shock and friction, which reduces the risk of accidental detonation, compared to other more sensitive high explosives such as nitroglycerin. TNT melts at 80 °C (176 °F), far below the temperature at which it will spontaneously detonate, allowing it to be poured as well as safely combined with other explosives. TNT neither absorbs nor dissolves in water, which allows it to be used effectively in wet environments. Additionally, it is stable compared to other high explosives. In order to initiate an explosion, TNT must first be detonated using a pressure wave from a more sensitive explosive called an explosive booster.
Although blocks of TNT are available in various sizes (e.g. 250 g, 500 g, 1,000 g), it is more commonly encountered in synergistic explosive blends comprising a variable percentage of TNT plus other ingredients. Examples of explosive blends containing TNT include:
Explosive character.
Upon detonation, TNT decomposes as follows:
The reaction is exothermic but has a high activation energy in the gas phase (~62 kcal/mol). The condensed phases (solid or liquid) show markedly lower activation energies of roughly 35 kcal/mol due to unique bimolecular decomposition routes at elevated densities. Because of the production of carbon, TNT explosions have a sooty appearance. Because TNT has an excess of carbon, explosive mixtures with oxygen-rich compounds can yield more energy per kilogram than TNT alone. During the 20th century, amatol, a mixture of TNT with ammonium nitrate was a widely used military explosive.
Detonation of TNT can be done using a high velocity initiator or by efficient concussion.
For many years, TNT used to be the reference point for the Figure of Insensitivity. TNT had a rating of exactly 100 on the F of I scale. The reference has since been changed to a more sensitive explosive called RDX, which has an F of I of 80.
Energy content.
Pentolite is a high explosive used for military and civilian purposes e.g. warheads and booster charges.
TNT is reported to contain 2.8 mega joules per kilogram explosive energy. The actual heat of combustion is 14.5 megajoules per kilogram, which requires that some of the carbon in TNT react with atmospheric oxygen, which does not occur in the initial event. The explosive energy utilized by NIST is 4184 J/g (4.184 MJ/kg). The energy density of TNT is used as a reference-point for many other types of explosives, including nuclear weapons, the energy content of which is measured in kilotons (~4.184 terajoules) or megatons (~4.184 peta joules) of TNT equivalent.
For comparison, gunpowder contains 3 megajoules per kilogram, dynamite contains 7.5 megajoules per kilogram, and gasoline contains 47.2 megajoules per kilogram (though gasoline requires an oxidant, so an optimized gasoline and O2 mixture contains 10.4 megajoules per kilogram).
Detection.
Various methods can be used to detect TNT including optical and electrochemical sensors and explosive-sniffing dogs.
In 2013, researchers from the Indian Institutes of Technology using noble-metal quantum clusters could detect TNT at the sub-zeptomolar (10−18 mol/m3) level.
Safety and toxicity.
TNT is poisonous, and skin contact can cause skin irritation, causing the skin to turn a bright yellow-orange color. During the First World War, munition workers who handled the chemical found that their skin turned bright yellow, which resulted in their acquiring the nickname "canary girls" or simply "canaries."
People exposed to TNT over a prolonged period tend to experience anemia and abnormal liver functions. Blood and liver effects, spleen enlargement and other harmful effects on the immune system have also been found in animals that ingested or breathed trinitrotoluene. There is evidence that TNT adversely affects male fertility. TNT is listed as a possible human carcinogen, with carcinogenic effects demonstrated in animal experiments (rat), although effects upon humans so far amount to none [according to IRIS of March 15, 2000].
 Consumption of TNT produces red urine through the presence of breakdown products and not blood as sometimes believed.
Some military testing grounds are contaminated with TNT. Wastewater from munitions programs including contamination of surface and subsurface waters may be colored pink because of the presence of TNT. Such contamination, called "pink water", may be difficult and expensive to remedy.
TNT is prone to exudation of dinitrotoluenes and other isomers of trinitrotoluene. Even small quantities of such impurities can cause such effect. The effect shows especially in projectiles containing TNT and stored at higher temperatures, e.g. during summer. Exudation of impurities leads to formation of pores and cracks (which in turn cause increased shock sensitivity). Migration of the exudated liquid into the fuze screw thread can form "fire channels", increasing the risk of accidental detonations; fuze malfunction can result from the liquids migrating into its mechanism. Calcium silicate is mixed with TNT to mitigate the tendency towards exudation.
Ecological impact.
Because of its use in construction and demolition, TNT has become the most widely used explosive, and thus its toxicity is the most characterized and reported. Residual TNT post explosion can partition between multiple environmental including water, soil, atmosphere, biosphere.
The concentration of TNT in contaminated soil can reach 50 g/kg of soil, where the highest concentrations can be found on or near the surface. In the last decade, the United States Environmental Protection Agency (USEPA) has declared TNT a pollutant whose removal is priority. The USEPA maintains that TNT levels in soil should not exceed 17.2 gram per kilogram of soil and 0.01 milligrams per liter of water.
Aqueous solubility.
Dissolution involves how rapidly solid TNT in contact with water is solubilized. The relatively low aqueous solubility of TNT causes the dissolution of solid particles to be continuously released to the environment over extended periods of time. Studies have shown that the TNT dissolved slower in saline water than in freshwater. However, when salinity was altered, TNT dissolved at the same speed. (Figure 2) Because TNT is moderately soluble in water, it can migrate through subsurface soil, and cause groundwater contamination. 
Soil adsorption.
Adsorption measures the distribution between soluble and sediment sorbed contaminants following attainment of equilibrium. Explosives such as TNT and its transformation products are known to adsorb to surface soils and sediments, where they undergo reactive transformation or remained stored. The movement or organic contaminants through soils is a function of their ability to associate with the mobile phase (water) and a stationary phase (soil). Materials that associate strongly with soils move slowly through soil. Materials that associate strongly with water move through water with rates approaching that of ground water movement.
The association constant for TNT with a soil is: 2.7-11 liters per kilogram of soil. This means that TNT has 1-10-fold tendency to adhere to a soil particulates than not when introduced into the soil. Hydrogen bonding and ion exchange are two suggested mechanisms of sorption between the nitro functional groups and soil colloids.
The number of functional groups on TNT influences the ability to adsorb into soil. Adsorption coefficient values have been shown to increase with an increase in the number of amino groups. Thus, sorption of the TNT decomposition product 2,4-diamino-6-nitrotoluene (2,4-DANT) was greater than that for 4-amino-2,6-dinitrotoluene (4-ADNT), which was greater than that for TNT. Lower adsorption coefficients for 2,6-DNT compared to 2,4-DNT can be attributed to the steric hindrance of the NO3 group in the ortho position.
Research has shown that in freshwater environments, with a high abundances of Ca2+, the sorption of TNT and its transformation products to soils and sediments may be lower than observed in a saline environment, dominated by K+ and Na+. Therefore, when considering the adsorption of TNT, the type of soil or sediment and the ionic composition and strength of the ground water are important factors.
The association constants for TNT and its degradation products with clays have been determined. Clay minerals have a significant effect on the sorption of energetic compounds. and can be ranked, as seen in Table 2. It should be noted that soil properties, such as organic carbon content and cation exchange capacity had significant impacts of the adsorption coefficients reported in the table below.
Additional studies have shown that the mobility of TNT degradation products is likely to be lower “than TNT in subsurface environments where specific adsorption to clay minerals dominates the sorption process.” Thus, the mobility of TNT and its transformation products are dependent on the characteristics of the sorbent. The mobility of TNT in groundwater and soil has been extrapolated from “sorption and desorption isotherm models determined with humic acids, in aquifer sediments, and soils”. From these models, it is predicted that TNT has a low retention and transports readily in the environment.
Compared to other explosives, TNT has a higher association constant with soil, meaning it adheres more with soil than with water. Conversely, other explosives, such as RDX and HMX with low association constants (ranging from 0.06-7.3 L/kg and 0-1.6 L/kg respectively) can move more rapidly in water.
Chemical breakdown.
TNT is a reactive molecule and is particularly prone to react with reduced components of sediments or photodegradation in the presence of sunlight. TNT is thermodynamically and kinetically capable of reacting with a wide number of components of many environmental systems. This includes wholly abiotic reactants, like photons, hydrogen sulfide, Fe2+, or microbial communities, both oxic and anoxic.
Soils with high clay contents or small particle sizes and high total organic carbon content have been shown to promote TNT transformation. Possible TNT transformations include reduction of one, two, or three nitro-moieties to amines and coupling of amino transformation products to form dimers. Formation of the two monoamino transformation products, 2-ADNT and 4-ADNT are energetically favored, and therefore are observed in contaminated soils and ground water. The diamino products are energetically less favorable, and even less likely are the triamino products.
The transformation of TNT is significantly enhanced under anaerobic conditions as well as under highly reducing conditions. TNT transformations in soils can occur both biologically and abiotically.
Photolysis is a major process that impacts the transformation of energetic compounds. The alteration of a molecule in photolysis occurs in the presence of direct absorption of light energy by the transfer of energy from a photosensitized compound. Phototransformation of TNT “results in the formation of nitrobenzenes, benzaldehydes, azodicarboxylic acids, and nitrophenols, as a result of the oxidation of methyl groups, reduction of nitro groups, and dimer formation.”
Evidence of the photolysis of TNT has been seen due to the color change to pink of the wastewaters when exposed to sunlight. Photolysis was more rapid in river water than in distilled water. Ultimately, photolysis affects the fate of TNT primarily in the aquatic environment but could also affect the reaction when exposed to sunlight on the soil surface.
Biodegradation.
The ligninolytic physiological phase and manganese peroxidase system of fungi can cause a very limited amount of mineralization of TNT in a liquid culture; though not in soil. An organism capable of the remediation of large amounts of TNT in soil has yet to be discovered. Both wild and transgenic plants can phytoremediate explosives from soil and water.

</doc>
<doc id="30699" url="http://en.wikipedia.org/wiki?curid=30699" title="Toluene">
Toluene

Toluene , formerly known as toluol , is a colorless, water-insoluble liquid with the smell associated with paint thinners. It is a mono-substituted benzene derivative, consisting of a CH3 group attached to a phenyl group. As such, its IUPAC systematic name is methylbenzene. It is an aromatic hydrocarbon.
Toluene is widely used as an industrial feedstock and as a solvent. Like other solvents, toluene is sometimes also used as an inhalant drug for its intoxicating properties; however, inhaling toluene has potential to cause severe neurological harm. Toluene is an important organic solvent. Its economic significance is considerable: In 2013, worldwide about 24.5 billion US-dollars were generated with the sale of toluene. 
History.
The compound was first isolated in 1837 through a distillation of pine oil by a Polish chemist named Filip Walter, who named it "retinaphtha".
This name was replaced shortly after by the word "toluene" derived from the older name "toluol", which refers to tolu balsam, an aromatic extract from the tropical Colombian tree "Myroxylon balsamum" from which toluene was also isolated later. It was originally named by Jöns Jakob Berzelius.
Chemical properties.
Toluene reacts as a normal aromatic hydrocarbon towards electrophilic aromatic substitution. Owing to greater electron-releasing properties of the methyl group vs hydrogen, toluene is more reactive than benzene to electrophiles. It undergoes sulfonation to give "p"-toluenesulfonic acid, and chlorination by Cl2 in the presence of FeCl3 to give ortho and para isomers of chlorotoluene.
Importantly the methyl side chain in toluene is susceptible to oxidation. Potassium permanganate converts toluene to benzoic acid, whereas chromyl chloride leads to benzaldehyde (Étard reaction). The methyl group undergoes halogenation can be performed under free radical conditions. For example, "N"-bromosuccinimide (NBS) heated with toluene in the presence of AIBN leads to benzyl bromide. The same conversion can be effected with elemental bromine in the presence of UV light or even sunlight. Toluene may also be brominated by treating it with HBr and H2O2 in the presence of light.
The methyl group in toluene undergoes deprotonation only with very strong bases, its pKa is approximately 45.
Catalytic hydrogenation of toluene gives methylcyclohexane. The reaction requires a high pressure of hydrogen and a catalyst.
Production.
Toluene occurs naturally at low levels in crude oil and is usually produced in the production of gasoline via a catalytic reformer, in an ethylene cracker, or the production coke from coal. Final separation, either via distillation or solvent extraction, takes place in one of the many available processes for extraction of the BTX aromatics (benzene, toluene, and xylene isomers).
Laboratory preparation.
Toluene is so inexpensively produced industrially that it is not prepared in the laboratory. In principle it could be prepared by a variety of methods.
For example, although only of didactical interest, benzene reacts with methyl chloride in presence of a Lewis acid such as aluminium chloride to give toluene:
Such reactions are complicated by polymethylation because toluene is more susceptible to alkylation than is benzene.
Uses.
Toluene is mainly used as a precursor to benzene. The process involves hydrodealkylation:
The second ranked application involves its disproportionation to a mixture of benzene and xylene. When oxidized it yields benzaldehyde and benzoic acid, two important intermediates in chemistry.
Precursor to other chemicals.
Aside from being converted to benzene and xylene, toluene is a raw material for toluene diisocyanate (used in the manufacture of polyurethane foam) and TNT.
Also an important precursor in the production of synthetic drugs.
Solvent.
Toluene is a common solvent, e.g. for paints, paint thinners, silicone sealants, many chemical reactants, rubber, printing ink, adhesives (glues), lacquers, leather tanners, and disinfectants. 
Fuel.
Toluene can be used as an octane booster in gasoline fuels used in internal combustion engines. Toluene at 86% by volume fueled all the turbo Formula 1 teams in the 1980s, first pioneered by the Honda team. The remaining 14% was a "filler" of n-heptane, to reduce the octane to meet Formula 1 fuel restrictions. Toluene at 100% can be used as a fuel for both two-stroke and four-stroke engines; however, due to the density of the fuel and other factors, the fuel does not vaporize easily unless preheated to 70 degrees Celsius (Honda accomplished this in their Formula 1 cars by routing the fuel lines through the muffler system to heat the fuel). 
In Australia, toluene has been found to have been illegally combined with petrol in fuel outlets for sale as standard vehicular fuel. Toluene attracts no fuel excise, whereas other fuels are taxed at over 40%, so fuel suppliers are able to profit from substituting the cheaper toluene for petrol. The extent of toluene substitution has not been determined.
Toluene is another in a group of fuels that have recently been used as components for jet fuel surrogate blends. Toluene is used as a jet fuel surrogate for its content of aromatic compounds.
Niche applications.
In the laboratory, toluene is used as a solvent for carbon nanomaterials, including nanotubes and fullerenes, and it can also be used as a fullerene indicator. The color of the toluene solution of C60 is bright purple. It is also used as a cement for fine polystyrene kits (by dissolving and then fusing surfaces) as it can be applied very precisely by brush and contains none of the bulk of an adhesive. Toluene can be used to break open red blood cells in order to extract hemoglobin in biochemistry experiments.
Toluene has also been used as a coolant for its good heat transfer capabilities in sodium cold traps used in nuclear reactor system loops.
Toluene had also been used in the process of removing the cocaine from coca leaves in the production of Coca-Cola syrup.
Toxicology and metabolism.
Inhalation of toluene in low to moderate levels can cause tiredness, confusion, weakness, drunken-type actions, memory loss, nausea, loss of appetite, and hearing and color vision loss. These symptoms usually disappear when exposure is stopped. Inhaling high levels of toluene in a short time may cause light-headedness, nausea, or sleepiness, unconsciousness - and even death. Toluene is, however, much less toxic than benzene, and has, as a consequence, largely replaced it as an aromatic solvent in chemical preparation. The EPA considers that there is inadequate information to assess the carcinogenic potential of toluene.
Similar to many other solvents such as 1,1,1-trichloroethane and some alkylbenzenes, toluene has been shown to act as a non-competitive NMDA receptor antagonist and GABAA receptor positive allosteric modulator. Additionally, toluene has been shown to display antidepressant-like effects in rodents in the forced swim test (FST) and the tail suspension test (TST).
It is sometimes used as an inhalant, likely on account of its euphoric and dissociative effects. 
Bioremediation.
Several types of fungi including "Cladophialophora", "Exophiala", "Leptodontium", "Pseudeurotium zonatum", and "Cladosporium sphaerospermum", and certain species of bacteria can degrade toluene using it as a source of carbon and energy.
Legal status.
Toluene is an intoxicative inhalant and its possession and use are regulated in many jurisdictions. As of 2007, 24 U.S. states had laws penalizing use, possession with intent to use, and/or distribution of inhalants such as toluene.

</doc>
<doc id="30701" url="http://en.wikipedia.org/wiki?curid=30701" title="The Computer Contradictionary">
The Computer Contradictionary

The Computer Contradictionary is a non-fiction book by Stan Kelly-Bootle that compiles a satirical list of definitions of computer industry terms. It is an example of "cynical lexicography" in the tradition of Ambrose Bierce's "The Devil's Dictionary". Rather than offering a factual account of usage, its definitions are largely made up by the author.
The book was published in May 1995 by MIT Press and is an update of Kelly-Bootle's "The Devil's DP Dictionary" which appeared in 1981.
Reception.
The Los Angeles Times panned the book, wrote that it was "smartly-titled" but was an "awfully stupid book". "ACM Computing Reviews" recommended dipping into it because "a dictionary is a difficult read".

</doc>
<doc id="30703" url="http://en.wikipedia.org/wiki?curid=30703" title="TRN">
TRN

TRN may refer to:

</doc>
<doc id="30706" url="http://en.wikipedia.org/wiki?curid=30706" title="The Great Divorce">
The Great Divorce

The Great Divorce is a work of theological fantasy by C. S. Lewis, in which he reflects on the Christian conception of Heaven and Hell.
The working title was "Who Goes Home?" but the final name was changed at the publisher's insistence. The title refers to William Blake's poem "The Marriage of Heaven and Hell". "The Great Divorce" was first printed as a serial in an Anglican newspaper called "The Guardian" in 1944 and 1945, and soon thereafter in book form.
Sources.
Lewis's diverse sources for this work include the works of St. Augustine, Dante Aligheri, John Milton, John Bunyan, Emanuel Swedenborg and Lewis Carroll, as well as an American science fiction author whose name Lewis had forgotten but whom he mentions in his preface (). George MacDonald, whom Lewis utilizes as a character in the story, Dante, Prudentius and Jeremy Taylor are alluded to in the text of chapter 9.
Plot summary.
The narrator inexplicably finds himself in a grim and joyless city, the "grey town", which is either Hell or Purgatory depending on how long one stays there. He eventually finds a bus for those who desire an excursion to some other place (and which eventually turns out to be the foothills of Heaven). He enters the bus and converses with his fellow passengers as they travel. When the bus reaches its destination, the passengers on the bus — including the narrator — are gradually revealed to be ghosts. Although the country is the most beautiful they have ever seen, every feature of the landscape (including streams of water and blades of grass) is unyieldingly solid compared to themselves: it causes them immense pain to walk on the grass, and even a single leaf is far too heavy for any to lift.
Shining figures, men and women whom they have known on Earth, come to meet them, and to urge them to repent and enter Heaven proper. They promise that as the ghosts travel onward and upward, they will become more solid and thus feel less and less discomfort. These figures, called "spirits" to distinguish them from the ghosts, offer to assist them in the journey toward the mountains and the sunrise.
Almost all of the ghosts choose to return instead to the grey town, giving various reasons and excuses. Much of the interest of the book lies in the recognition it awakens of the plausibility and familiarity, along with the thinness and self-deception, of the excuses that the ghosts refuse to abandon, even though to do so would bring them to "reality" and "joy forevermore". An artist refuses, arguing that he must preserve the reputation of his school of painting; a bitter cynic predicts that Heaven is a trick; a bully ("Big Man") is offended that people he believes beneath him are there; a nagging wife is angry that she will not be allowed to dominate her husband in Heaven. One man corrupted on Earth by lust, which takes the form of an ugly lizard, permits an angel to kill the lizard and is saved.
The narrator is met by the writer George MacDonald, whom he hails as his mentor, just as Dante did when encountering Virgil in the "Divine Comedy"; and MacDonald becomes the narrator's guide in his journey, just as Virgil became Dante's. MacDonald explains that it is possible for a soul to choose to remain in Heaven despite having been in the grey town; for such souls, the goodness of Heaven will work backwards into their lives, turning even their worst sorrows into joy, and changing their experience on Earth to an extension of Heaven. Conversely, the evil of Hell works so that if a soul remains in, or returns to, the grey town, even its happiness on Earth will lose its meaning, and its experience on Earth would have been Hell. Few of the ghosts realize that the grey town is, in fact, Hell. Indeed it is not that much different from the life they led on Earth: joyless, friendless and uncomfortable. It just goes on forever, and gets worse and worse, with some characters whispering their fear of the "night" that is eventually to come.
According to MacDonald, while it is possible to leave Hell and enter Heaven, doing so implies turning away (repentance); or as depicted by Lewis, embracing ultimate and unceasing joy itself.
In answer to the narrator's question, MacDonald confirms that what is going on is a dream. The use of chess imagery as well as the correspondence of dream elements to elements in the narrator's waking life is reminiscent of "Alice's Adventures in Wonderland" and "Through the Looking-Glass".
The narrator discovers that the vast grey town and its ghostly inhabitants are minuscule to the point of being invisible compared with the immensity of Heaven and reality. This is illustrated in the encounter of the blessed woman and her husband: she is surrounded by gleaming attendants while he shrinks down to invisibility as he uses a collared tragedian — representative of his self-punishing emotional blackmail of others — to speak for him.
Toward the end, the narrator expresses the terror and agony of remaining a ghost in the advent of full daybreak in Heaven, comparing the weight of sunlight to having large blocks fall on one's body (at this point falling books awaken him). This parallels that of the man with his dream of judgment day in the House of the Interpreter of "The Pilgrim's Progress". The book ends with the narrator awakening from his dream of Heaven into the unpleasant reality of wartime Britain, in conscious imitation of "The Pilgrim's Progress", the last sentence of the "First Part" of which is: "So I awoke, and behold, it was a Dream."
Stage adaptation.
Philadelphia playwright and actor Anthony Lawton's original adaptation of "The Great Divorce" has been staged several times by Lantern Theater Company, including a weeklong run in February 2012. It also was adapted by Robert Smyth at Lamb's Players Theatre in San Diego, California, in 2004, and was included in their mainstage season for that year. Smyth originally adapted it for a C. S. Lewis conference in Oxford and Cambridge, England, before securing permission to include it in their season a year later.
In 2007 the Magis Theatre Company of New York City presented their adaptation in an off-Broadway run at Theatre 315 in the Theatre District with music by award-winning composer Elizabeth Swados and puppets by Ralph Lee. Lauded by the New York Times for its imagination, theatrical skill and daring, theatre critic Neil Genzlinger called the production thought provoking "with plenty to say to those interested in matters of the spirit." In the following years Magis worked closely with the C. S. Lewis estate to make its adaptation available to over a dozen theatre companies from Canada to Ecuador. The Taproot Theatre of Seattle chose the Magis adaptation to open its new Theater Space in 2010 and extended the run due to popular demand. The Pacific Theatre Company presented the Magis adaptation in its 2010–2011 season.
In late 2012, the Fellowship for the Performing Arts received permission from the C. S. Lewis estate to produce a stage version of "The Great Divorce". The production premiered in Phoenix on December 14, 2013, and has continued touring throughout the United States in 2014 and 2015.
Motion picture.
It has been announced that Mpower Pictures and Beloved Pictures are currently working on a film adaptation of "The Great Divorce". Stephen McEveety will lead the production team and author N. D. Wilson has been tapped to write the script. A 2013 release was originally planned.

</doc>
<doc id="30707" url="http://en.wikipedia.org/wiki?curid=30707" title="Temporomandibular joint dysfunction">
Temporomandibular joint dysfunction

Temporomandibular joint dysfunction (sometimes abbreviated to TMD or TMJD and also termed temporomandibular joint dysfunction syndrome, temporomandibular disorder or many other names), is an umbrella term covering pain and dysfunction of the muscles of mastication (the muscles that move the jaw) and the temporomandibular joints (the joints which connect the mandible to the skull). The most important feature is pain, followed by restricted mandibular movement, and noises from the temporomandibular joints (TMJ) during jaw movement. Although TMD is not life-threatening, it can be detrimental to quality of life, because the symptoms can become chronic and difficult to manage. About 20% to 30% of the adult population are affected to some degree. Usually people affected by TMD are between 20 and 40 years of age, and it is more common in females than males. TMD is the second most frequent cause of orofacial pain after dental pain (i.e. toothache).
TMD is a symptom complex rather than a single condition, and it is thought to be caused by multiple factors. However, these factors are poorly understood, and there is disagreement as to their relative importance. There are many treatments available, although there is a general lack of evidence for any treatment in TMD, and no widely accepted treatment protocol exists. Common treatments that are used include provision of occlusal splints, psychosocial interventions like cognitive behavioral therapy, and medications like analgesics (pain killers) or others. Most sources now agree that no irreversible treatment should be carried out for TMD.
Classification.
TMD is considered by some to be one of the 4 major symptom complexes in chronic orofacial pain, along with burning mouth syndrome, atypical facial pain and atypical odontalgia. TMD has been considered as a type of musculoskeletal, neuromuscular, or rheumatological disorder. It has also been called a functional pain syndrome, and a psychogenic disorder. Others consider TMD a "central sensitivity syndrome", in reference to evidence that TMD might be caused by a centrally mediated sensitivity to pain. It is hypothesized that there is a great deal of similarity between TMD and other pain syndromes like fibromyalgia, irritable bowel syndrome, interstitial cystitis, headache, chronic lower back pain and chronic neck pain. These disorders have also been theorized to be caused by centrally mediated sensitivity to pain, and furthermore they often occur together.
Definitions and terminology.
Frequently, TMD has been treated as a single syndrome, but the prevailing modern view is that TMD is a cluster of related disorders with many common features. Indeed, some have suggested that in the future the term TMD may be discarded as the different causes are fully identified and separated into different conditions. Sometimes, "temporomandibular joint dysfunction" is described as the most common form of temporomandibular disorder, whereas many other sources use the term temporomandibular disorder synonymously, or instead of the term temporomandibular joint dysfunction. In turn, the term temporomandibular disorder is described as "a clinical term [referring to] musculoskeletal disorders affecting the temporomandibular joints and their associated musculature. It is a collective term which represents a diverse group of pathologies involving the temporomandibular joint, the muscles of mastication, or both". Another definition of temporomandibular disorders is "a group of conditions with similar signs and symptoms that affect the termporomandibular joints, the muscles of mastication, or both." Temporomandibular disorder is a term that creates confusion since it refers to a group of similarly symptomatic conditions, whilst many sources use the term temporomandibular disorders as a vague description rather than a specific syndrome, and refer to any condition which may affect the temporomandibular joints (see table). The temporomandibular joint is susceptible to a huge range of diseases, some rarer than others, and there is no implication that all of these will cause any symptoms or limitation in function at all.
The preferred terms in medical publications is to an extent influenced by geographic location, e.g. in the United Kingdom, the term "pain dysfunction syndrome" is in common use, and in other countries different terms are used. In the United States, the term "temporomandibular disorder" is generally favored. The American Academy of Orofacial Pain uses temporomandibular disorder, whilst the National Institute of Dental and Craniofacial Research uses temporomandibular joint disorder. It is common for sources to arbitrarily use a preferred term and then list a handful of other synonyms. A more complete list of synonyms for this topic is extensive, with some being more commonly used than others. In addition to those already mentioned, examples include "temporomandibular joint pain dysfunction syndrome", "temporomandibular pain dysfunction syndrome", "temporomandibular joint syndrome", "temporomandibular dysfunction syndrome", "temporomandibular dysfunction", "temporomandibular disorder", "temporomandibular syndrome", "facial arthromyalgia", "myofacial pain dysfunction syndrome", "craniomandibular dysfunction", "myofacial pain dysfunction", "masticatory myalgia", "mandibular dysfunction", and "Costen's syndrome".
The lack of standardization in terms is not restricted to medical papers. Notable internationally recognized sources vary in both their preferred term, and their offered definition, e.g.
"Temporomandibular Pain and Dysfunction Syndrome – Aching in the muscles of mastication, sometimes with an occasional brief severe pain on chewing, often associated with restricted jaw movement and clicking or popping sounds." (Classification of Chronic Pain, International Association for the Study of Pain).
"Headache or facial pain attributed to temporomandibular joint disorder." (International Classification of Headache Disorders 2nd edition (ICHD-2), International Headache Society).
"Temporomandibular joint-pain-dysfunction syndrome" listed in turn under "Temporomandibular joint disorders" (International Classification of Diseases 10th revision, World Health Organization).
In this article, the term temporomandibular disorder is taken to mean any disorder than affects the temporomandibular joint, and temporomandibular joint dysfunction (here also abbreviated to TMD) is taken to mean symptomatic (e.g. pain, limitation of movement, clicking) dysfunction of the temporomandibular joint, however there is no single, globally accepted term or definition concerning this topic.
By cause and symptoms.
It has been suggested that TMD may develop following trauma, particularly whiplash injury, although the evidence for this is not conclusive. This type of TMD is sometimes termed "posttraumatic TMD" (pTMD) to distinguish it from TMD of unknown cause, sometimes termed "idiopathic TMD" (iTMD). Sometimes muscle-related (myogenous) TMD (also termed myogenous TMD, or TMD secondary to myofascial pain and dysfunction) is distinguished from joint-related TMD (also termed arthogenous TMD, or TMD secondary to true articular disease), based upon whether the muscles of mastication or the TMJs themselves are predominantly involved. This classification, which effectively divides TMD into 2 syndromes, is followed by the American Academy of Orofacial Pain. However, since most people with TMD could be placed into both of these groups, which makes a single diagnosis difficult when this classification is used. The Research Diagnostic Criteria (RDC/TMD) allows for multiple diagnoses in an attempt to overcome the problems with other classifications. RDC/TMD considers temporomandibular disorders in 2 axes; axis I is the physical aspects, and axis II involves assessment of psychological status, mandibular function and TMD-related psychosocial disability. Axis I is further divided into 3 general groups. Group I are muscle disorders, group II are disc displacements and group III are joint disorders, although it is common for people with TMD to fit into more than one of these groups.
By duration.
Sometimes distinction is made between acute TMD, where symptoms last for less than 3 months, and chronic TMD, where symptoms last for more than 3 months. Not much is known about acute TMD since these individuals do not typically attend in secondary care (hospital).
Signs and symptoms.
Signs and symptoms of temporomandibular joint disorder vary in their presentation. The symptoms will usually involve more than one of the various components of the masticatory system, muscles, nerves, tendons, ligaments, bones, connective tissue, and/or the teeth.
The three classically described, cardinal signs and symptoms of TMD are:
Other signs and symptoms have also been described, although these are less common and less significant than the cardinal signs and symptoms listed above. Examples include:
Causes.
TMD is a symptom complex (i.e. a group of symptoms occurring together and characterizing a particular disease), which is thought to be caused by multiple, poorly understood factors, but the exact etiology is unknown. There are factors which appear to predispose to TMD (genetic, hormonal, anatomical), factors which may precipitate it (trauma, occlusal changes, parafunction), and also factors which may prolong it (stress and again parafunction). Overall, two hypotheses have dominated research into the causes of TMD, namely a psychosocial model and a theory of occlusal dysharmony. Interest in occlusal factors as a causative factor in TMD was especially widespread in the past, and the theory has since fallen out of favor and become controversial due to lack of evidence.
Disc displacement.
In people with TMD, it has been shown that the lower head of lateral pterygoid contracts during mouth closing (when it should relax), and is often tender to palpation. To theorize upon this observation, some have suggested that due to a tear in the back of the joint capsule, the articular disc may be displaced forwards (anterior disc displacement), stopping the upper head of lateral pterygoid from acting to stabilize the disc as it would do normally. As a biologic compensatory mechanism, the lower head tries to fill this role, hence the abnormal muscle activity during mouth closure. There is some evidence that anterior disc displacement is present in proportion of TMD cases. Anterior disc displacement with reduction refers to abnormal forward movement of the disc during opening which reduces upon closing. Anterior disc displacement without reduction refers to an abnormal forward, bunched-up position of the articular disc which does not reduce. In this latter scenario, the disc is not intermediary between the condyle and the articular fossa as it should be, and hence the articular surfaces of the bones themselves are exposed to a greater degree of wear (which may predispose to osteoarthritis in later life).
Degenerative joint disease.
The general term "degenerative joint disease" refers to arthritis (both osteoarthritis and rheumatoid arthritis) and arthrosis. The term arthrosis may cause confusion since in the specialized TMD literature it means something slightly different from in the wider medical literature. In medicine generally, arthrosis can be a nonspecific term for a joint, any disease of a joint (or specifically degenerative joint disease), and is also used as a synonym for osteoarthritis. In the specialized literature that has evolved around TMD research, arthrosis is differentiated from arthritis by the presence of low and no inflammation respectively. Both are however equally degenerative. The TMJs are sometimes described as one of the most used joints in the body. Over time, either with normal use or with parafunctional use of the joint, wear and degeneration can occur, termed osteoarthritis. Rheumatoid arthritis, an autoimmune joint disease, can also affect the TMJs. Degenerative joint diseases may lead to defects in the shape of the tissues of the joint, limitation of function (e.g. restricted mandibular movements), and joint pain.
Psychosocial factors.
Emotional stress (anxiety, depression, anger) may increase pain by causing autonomic, visceral and skeletal activity and by reduced inhibition via the descending pathways of the limbic system. The interactions of these biological systems have been described as a vicious "anxiety-pain-tension" cycle which is thought to be frequently involved in TMD. Put simply, stress and anxiety cause grinding of teeth and sustained muscular contraction in the face. This produces pain which causes further anxiety which in turn causes prolonged muscular spasm at trigger points, vasoconstriction, ischemia and release of pain mediators. The pain discourages use of the masticatory system (a similar phenomenon in other chronic pain conditions is termed "fear avoidance" behavior), which leads to reduced muscle flexibility, tone, strength and endurance. This manifests as limited mouth opening and a sensation that the teeth are not fitting properly.
Persons with TMD have a higher prevalence of psychological disorders than people without TMD. People with TMD have been shown to have higher levels of anxiety, depression, somatization and sleep deprivation, and these could be considered important risk factors for the development of TMD. In the 6 months before the onset, 50–70% of people with TMD report experiencing stressful life events (e.g. involving work, money, health or relationship loss). It has been postulated that such events induce anxiety and cause increased jaw muscle activity. Muscular hyperactivity has also been shown in people with TMD whilst taking examinations or watching horror films.
Others argue that a link between muscular hyperactivity and TMD has not been convincingly demonstrated, and that emotional distress may be more of a consequence of pain rather than a cause.
Bruxism.
Bruxism is an oral parafunctional activity where there is excessive clenching and grinding of the teeth. It can occur during sleep or whilst awake. The cause of bruxism itself is not completely understood, but psychosocial factors appear to be implicated in awake bruxism and dopaminergic dysfunction and other central nervous system mechanisms may be involved in sleep bruxism. If TMD pain and limitation of mandibular movement are greatest upon waking, and then slowly resolve throughout the day, this may indicate sleep bruxism. Conversely, awake bruxism tends to cause symptoms that slowly get worse throughout the day, and there may be no pain at all upon waking.
The relationship of bruxism with TMD is debated. Many suggest that sleep bruxism can be a causative or contributory factor to pain symptoms in TMD. Indeed, the symptoms of TMD overlap with those of bruxism. Others suggest that there is no strong association between TMD and bruxism. A systematic review investigating the possible relationship concluded that when self-reported bruxism is used to diagnose bruxism, there is a positive association with TMD pain, and when more strict diagnostic criteria for bruxism are used, the association with TMD symptoms is much lower. Self-reported bruxism is probably a poor method of identifying bruxism. There are also very many people who grind their teeth and who do not develop TMD. Bruxism and other parafunctional activities may play a role in perpetuating symptoms in some cases.
Other parafunctional habits such as pen chewing, lip and cheek biting (which may manifest as morsicatio buccarum and/or linea alba), are also suggested to contribute to the development of TMD. Other parafunctional activities might include jaw thrusting, excessive gum chewing, nail biting and eating very hard foods.
Trauma.
Trauma, both micro and macrotrauma, is sometimes identified as a possible cause of TMD, however the evidence is not strong. Prolonged mouth opening (hyper-extension) is also suggested as a possible cause. It is thought that this leads to microtrauma and subsequent muscular hyperactivity. This may occur during dental treatment, with oral intubation whilst under a general anesthetic, during singing or wind instrument practice (really these can be thought of as parafunctional activities). Damage may be incurred during violent yawning, laughing, road traffic accidents, sports injuries, interpersonal violence, or during dental treatment, (such as tooth extraction).
It has been proposed that a link exists between whiplash injuries (sudden neck hyper-extension usually occurring in road traffic accidents), and the development of TMD. This has been termed "post-traumatic TMD", to separate it from "idiopathic TMD". Despite multiple studies having been performed over the years, the cumulative evidence has been described as conflicting, with moderate evidence that TMD can occasionally follow whiplash injury. The research that suggests a link appears to demonstrate a low to moderate incidence of TMD following whiplash injury, and that pTMD has a poorer response to treatment than TMD which has not developed in relation to trauma.
Occlusal factors.
Occlusal factors as an etiologic factor in TMD is a controversial topic. Abnormalities of occlusion (problems with the bite) are often blamed for TMD but there is no evidence that these factors are involved. Occlusal abnormalities are incredibly common, and most people with occlusal abnormalities do not have TMD. Although occlusal features may affect observed electrical activity in masticatory muscles, there are no statistically significant differences in the number of occlusal abnormalities in people with TMD and in people without TMD. There is also no evidence for a causal link between orthodontic treatment and TMD. The modern, mainstream view is that the vast majority of people with TMD, occlusal factors are not related. Theories of occlusal factors in TMD are largely of historical interest. A causal relationship between occlusal factors and TMD was championed by Ramfjord in the 1960s. A small minority of dentists continue to prescribe occlusal adjustments in the belief that this will prevent or treat TMD despite the existence of systematic reviews of the subject which state that there is no evidence for such practices, and the vast majority of opinion being that no irreversible treatment should be carried out in TMD (see Occlusal adjustment).
Genetic factors.
TMD does not obviously run in families like a genetic disease. It has been suggested that a genetic predisposition for developing TMD (and chronic pain syndromes generally) could exist. This has be postulated to be explained by variations of the gene which codes for the enzyme catechol-O-methyl transferase (COMT) which may produce 3 different phenotypes with regards pain sensitivity. COMT (together with monoamine oxidase) is involved in breaking down catecholamines (e.g. dopamine, epinephrine, and norepinephrine). The variation of the COMT gene which produces less of this enzyme is associated with a high sensitivity to pain. Females with this variation, are at 2–3 times greater risk of developing TMD than females without this variant. However this theory is controversial since there is conflicting evidence.
Hormonal factors.
Since females are more often affected by TMD than males, the female sex hormone estrogen has been suggested to be involved. The results of one study suggested that the periods of highest pain in TMD can be correlated with rapid periods of change in the circulating estrogen level. Low estrogen was also correlated to higher pain. In the menstrual cycle, estrogen levels fluctuate rapidly during ovulation, and also rapidly increases just before menstruation and rapidly decreases during menstruation. Post-menopausal females who are treated with hormone replacement therapy are more likely to develop TMD, or may experience an exacerbation if they already had TMD. Several possible mechanisms by which estrogen might be involved in TMD symptoms have been proposed. Estrogen may play a role in modulating joint inflammation, nociceptive neurons in the trigeminal nerve, muscle reflexes to pain and μ-opioid receptors.
Possible associations.
TMD has been suggested to be associated with other conditions or factors, with varying degrees evidence and some more commonly than others. E.g. It has been shown that 75% of people with TMD could also be diagnosed with fibromyalgia, since they met the diagnostic criteria, and that conversely, 18% of people with fibromyalgia met diagnostic criteria for TMD. A possible link between many of these chronic pain conditions has been hypothesized to be due to shared pathophysiological mechanisms, and they have been collectively termed "central sensitivity syndromes", although other apparent associations cannot be explained in this manner.
Pathophysiology.
Anatomy and physiology.
Temporomandibular joints.
The temporomandibular joints are the dual articulation of the mandible with the skull. Each TMJ is classed as a "ginglymoarthrodial" joint since it is both a ginglymus (hinging joint) and an arthrodial (sliding) joint, and involves the condylar process of the mandible below, and the articular fossa (or glenoid fossa) of the temporal bone above. Between these articular surfaces is the articular disc (or meniscus), which is a biconcave, transversely oval disc composed of dense fibrous connective tissue. Each TMJ is covered by a fibrous capsule. There are tight fibers connecting the mandible to the disc, and loose fibers which connect the disc to the temporal bone, meaning there are in effect 2 joint capsules, creating an upper joint space and a lower joint space, with the articular disc in between. The synovial membrane of the TMJ lines the inside of the fibrous capsule apart from the articular surfaces and the disc. This membrane secretes synovial fluid, which is both a lubricant to fill the joint spaces, and a means to convey nutrients to the tissues inside the joint. Behind the disc is loose vascular tissue termed the "bilaminar region" which serves as a posterior attachment for the disc and also fills with blood to fill the space created when the head of the condyle translates down the articular eminence. Due to its concave shape, sometimes the articular disc is described as having an anterior band, intermediate zone and a posterior band. When the mouth is opened, the initial movement of the mandibular condyle is rotational, and this involves mainly the lower joint space, and when the mouth is opened further, the movement of the condyle is translational, involving mainly the upper joint space. This translation movement is achieved by the condylar head sliding down the articular eminence, which constitutes the front border of the articular fossa. The function of the articular eminence is to limit the forwards movement of the condyle. The ligament directly associated with the TMJ is the temporomandibular ligament, also termed the lateral ligament, which really is a thickening of the lateral aspect of the fibrous capsule. The stylomandibular ligament and the sphenomandibular ligament are not directly associated with the joint capsule. Together, these ligaments act to restrict the extreme movements of the joint.
Muscles of mastication.
The muscles of mastication are paired on each side and work together to produce the movements of the mandible. The main muscles involved are the masseter, temporalis and medial and lateral pterygoid muscles.
They can be thought of in terms of the directions they move the mandible, with most being involved in more than one type of movement due to the variation in the orientation of muscle fibers within some of these muscles.
Each lateral pterygoid muscle is composed of 2 heads, the upper or superior head and the lower or inferior head. The lower head originates from the lateral surface of the lateral pterygoid plate and inserts at a depression on the neck of mandibular condyle, just below the articular surface, termed the pterygoid fovea. The upper head originates from the infratemporal surface and the infratemporal crest of the greater wing of the sphenoid bone. The upper head also inserts at the fovea, but a part may be attached directly to the joint capsule and to the anterior and medial borders of the articular disc. The 2 parts of lateral pterygoid have different actions. The lower head contracts during mouth opening, and the upper head contracts during mouth closing. The function of the lower head is to steady the articular disc as it moves back with the condyle into the articular fossa. It is relaxed during mouth closure.
Mechanisms of main signs and symptoms.
Joint noises.
Noises from the TMJs are a symptom of dysfunction of these joints. The sounds commonly produced by TMD are usually described as a "click" or a "pop" when a single sound is heard and as "crepitation" or "crepitus" when there are multiple, grating, rough sounds. Most joint sounds are due to internal derangement of the joint, which is a term used to describe instability or abnormal position of the articular disc. Clicking often accompanies either jaw opening or closing, and usually occurs towards the end of the movement. The noise indicates that the articular disc has suddenly moved to and from a temporarily displaced position (disk displacement with reduction) to allow completion of a phase of movement of the mandible. If the disc displaces and does not reduce (move back into position) this may be associated with locking. Clicking alone is not diagnostic of TMD since it is present in high proportion of the general population, mostly in people who have no pain. Crepitus often indicates arthritic changes in the joint, and may occur at any time during mandibular movement, especially lateral movements. Perforation of the disc may also cause crepitus. Due to the proximity of the TMJ to the ear canal, joint noises are perceived to be much louder to the individual than to others. Often people with TMD are surprised that what sounds to them like very loud noises cannot be heard at all by others next to them. However, it is occasionally possible for loud joint noises to be easily heard by others in some cases and this can be a source of embarrassment e.g. when eating in company.
Pain.
Pain symptoms in TMD can be thought of as originating from the joint (arthralgia), or from the muscles (myofascial), or both. There is a poor correlation between TMD pain severity and evidence of tissue pathology.
Arthralgia.
Generally, degenerative joint changes are associated with greater pain.
Myofascial pain.
Pain originating from the muscles of mastication as a result of abnormal muscular function or hyperactivity. The muscular pain is frequently, but not always, associated with daytime clenching or nocturnal bruxism.
Referred TMD pain.
Sometimes TMD pain can radiate or be referred from its cause (i.e. the TMJ and/or the muscles of mastication) and be felt as headaches, earache or toothache.
Due to the proximity of the ear to the temporomandibular joint, TMJ pain can often be confused with ear pain. The pain may be referred in around half of all patients and experienced as otalgia (earache). Conversely, TMD is an important possible cause of secondary otalgia. Treatment of TMD may then significantly reduce symptoms of otalgia and tinnitus, as well as atypical facial pain. Despite some of these findings, some researchers question whether TMJD therapy can reduce symptoms in the ear, and there is currently an ongoing debate to settle the controversy.
Limitation of mandibular movement.
The jaw deviates to the affected side during opening, and restricted mouth opening usually signifies that both TMJs are involved, but severe trismus rarely occurs. If the greatest reduction in movement occurs upon waking then this may indicate that there is concomitant sleep bruxism. In other cases the limitation in movement gets worse throughout the day.
The jaw may lock entirely.
Limitation of mandibular movement itself may lead to further problems involving the TMJs and the muscles of mastication. Changes in the synovial membrane may lead to a reduction in lubrication of the joint and contribute to degenerative joint changes. The muscles become weak, and fibrosis may occur. All these factors may lead to a further limitation of jaw movement and increase in pain.
Degenerative joint disease, such as osteoarthritis or organic degeneration of the articular surfaces, recurrent fibrous and/or bony ankylosis, developmental abnormality, or pathologic lesions within the TMJ. Myofascial pain syndrome.
Diagnosis.
Pain is the most common reason for people with TMD to seek medical advice. 
Joint noises may require auscultation with a stethoscope to detect. Clicks of the joint may also be palpated, over the joint itself in the preauricular region, or via a finger inserted in the external acoustic meatus, which lies directly behind the TMJ.
The differential diagnosis is with degenerative joint disease (e.g. osteoarthritis), rheumatoid arthritis, temporal arteritis, otitis media, parotitis, mandibular osteomyelitis, Eagle syndrome, trigeminal neuralgia, oromandibular dystonia, deafferentation pains, and psychogenic pain.
Diagnostic criteria.
Various diagnostic systems have been described. Some consider the Research Diagnostic Criteria method the gold standard. Abbreviated to "RDC/TMD", this was first introduced in 1992 by Dworkin and LeResche in an attempt to classify temporomandibular disorders by etiology and apply universal standards for research into TMD. This method involves 2 diagnostic axes, namely axis I, the physical diagnosis, and axis II, the psychologic diagnosis. Axis I contains 3 different groups which can occur in combinations of 2 or all 3 groups, (see table).
McNeill 1997 described TMD diagnostic criteria as follows:
The International Headache Society's diagnostic criteria for "headache or facial pain attributed to temporomandibular joint disorder" is similar to the above:
Management.
TMD can be difficult to manage, and since the disorder transcends the boundaries between several health-care disciplines — in particular, dentistry and neurology, the treatment may often involve multiple approaches and be multidisciplinary. Most who are involved in treating and, researching TMD now agree that any treatment carried out should not permanently alter the jaw or teeth, and should be reversible. To avoid permanent change, over-the-counter or prescription pain medications may be prescribed.
Psychosocial and behavioral interventions.
Given the important role that psychosocial factors appear to play in TMD, psychosocial interventions could be viewed to be central to management of the condition. There is a suggestion that treatment of factors that modulate pain sensitivity such as mood disorders, anxiety and fatigue, may be important in the treatment of TMD, which often tends to attempt to address the pain directly.
Cognitive Behavioral Therapy (CBT) has been used in TMD and has been shown to be efficacious by meta analyses.
Hypnosis is suggested by some to be appropriate for TMD. Studies have suggested that it may even be more beneficial than occlusal splint therapy, and has comparable effects to relaxation techniques.
Relaxation techniques include progressive muscle relaxation, yoga, and meditation. It has been suggested that TMD involves increased sensitivity to external stimuli leading to an increased sympathetic ("fight or flight") response with cardiovascular and respiratory alterations. Relaxation techniques cause reduced sympathetic activity, including muscle relaxation and reducing sensitivity to external stimuli, and provoke a general sense of well being and reduced anxiety.
Devices.
Occlusal splints (also termed bite plates or intra-oral appliances) are often used by dentists to treat TMD. They are usually made of acrylic and can be hard or soft. They can be designed to fit onto the upper teeth or the lower teeth. They may cover all the teeth in one arch (full coverage splint) or only some (partial coverage splint). Splints are also termed according to their intended mechanism, such as the anterior positioning splint or the stabilization splint. Although occlusal splints are generally considered a reversible treatment, sometimes partial coverage splints lead to pathologic tooth migration (changes in the position of teeth). Normally splints are only worn during sleep, and therefore probably do nothing for people who engage in parafunctional activities during wakefulness rather than during sleep. There is slightly more evidence for the use of occlusal splints in sleep bruxism than in TMD. At the least, they will mechanically protect the teeth from pathologic tooth wear associated with bruxism. A splint can also have a diagnostic role if it demonstrates excessive occlusal wear after a period of wearing it each night. This may confirm the presence of sleep bruxism if it was in doubt. Soft splints are occasionally reported to worsen discomfort related to TMD. Specific types of occlusal splint are discussed below.
A stabilization splint is a hard acrylic splint that forces the teeth to meet in an "ideal" relationship for the muscles of mastication and the TMJs. It is claimed that this technique reduces abnormal muscular activity and promotes "neuromuscular balance". A stabilization splint is only intended to be used for about 2–3 months. It is more complicated to construct than other types of splint since a face bow record is required and significantly more skill on the part of the dental technician. This kind of splint should be properly fitted to avoid exacerbating the problem and used for brief periods of time. The use of the splint should be discontinued if it is painful or increases existing pain. A systematic review of all the scientific studies investigating the efficacy of stabilization splints concluded the following:
"On the basis of our analysis we conclude that the literature seems to suggest that there is insufficient evidence either for or against the use of stabilization splint therapy over other active interventions for the treatment of TMD. However, there is weak evidence to suggest that the use of stabilization splints for the treatment of TMD may be beneficial for reducing pain severity, at rest and on palpation, when compared to no treatment".
Partial coverage splints are recommended by some experts, but they have the potential to cause unwanted tooth movements, which can occasionally be severe. The mechanism of this tooth movement is that the splint effectively holds some teeth out of contact and puts all the force of the bite onto the teeth which the splint covers. This can cause the covered teeth to be intruded, and those that are not covered to over-erupted. I.e. a partial coverage splint can act as a Dahl appliance. Examples of partial coverage splints include the NTI-TSS ("nociceptive trigeminal inhibitor tension suppression system"), which covers the upper front teeth only. Due to the risks involved with long term use, some discourage the use of any type of partial coverage splint.
An anterior positioning splint is a splint that designed to promote an anteriorly displaced disc. It is rarely used. A 2010 review of all the scientific studies carried out to investigate the use of occlusal splints in TMD concluded:
"Hard stabilization appliances, when adjusted properly, have good evidence of modest efficacy in the treatment of TMD pain compared to non-occluding appliances and no treatment. Other types of appliances, including soft stabilization appliances, anterior positioning appliances, and anterior bite appliances, have some RCT evidence of efficacy in reducing TMD pain. However, the potential for adverse events with these appliances is higher and suggests the need for close monitoring in their use." 
Ear canal inserts are also available, but no published peer-reviewed clinical trials have shown them to be useful.
Medication.
Medication is the main method of managing pain in TMD, mostly because there is little if any evidence of the effectiveness of surgical or dental interventions. Many drugs have been used to treat TMD pain, such as analgesics (pain killers), benzodiazepines (e.g. clonazepam, prazepam, diazepam), anticonvulsants (e.g. gabapentin), muscle relaxants (e.g. cyclobenzaprine), and others. Analgesics that have been studied in TMD include non-steroidal anti-inflammatory drugs (e.g. piroxicam, diclofenac, naproxen) and cyclo-oxygenase-2 inhibitors (e.g. celecoxib). Topical methyl salicylate and topical capsaicin have also been used. Other drugs that have been described for use in TMD include glucosamine hydrochloride/chondroitin sulphate and propranolol. Despite many randomized control trials being conducted on these commonly used medications for TMD a systematic review carried out in 2010 concluded that there was insufficient evidence to support or not to support the use of these drugs in TMD. Low-doses of anti-muscarinic tricyclic antidepressants such as amitriptyline, or nortriptyline have also been described. In a subset of people with TMD who are not helped by either noninvasive and invasive treatments, long term use of opiate analgesics has been suggested, although these drugs carry a risk of drug dependence and other side effects. Examples include morphine, fentanyl, oxycodone, tramadol, hydrocodone, and methadone.
Botulinum toxin solution ("Botox") is sometimes used to treat TMD. Injection of botox into the lateral pterygoid muscle has been investigated in multiple randomized control trials, and there is evidence that it is of benefit in TMD. It is theorized that spasm of lateral pterygoid causes anterior disc displacement. Botulinum toxin causes temporary muscular paralysis by inhibiting acetylcholine release at the neuromuscular junction. The effects usually last for a period of months before they wear off. Complications include the creation of a "fixed" expression due to diffusion of the solution and subsequent involvement of the muscles of facial expression, which lasts until the effects of the botox wear off. Injections of local anesthetic, sometimes combined with steroids, into the muscles (e.g. the temoralis muscle or its tendon) are also sometimes used. Local anesthetics may provide temporary pain relief, and steroids inhibit pro-inflammatory cytokines. Steroids and other medications are sometimes injected directly into the joint (See Intra-articular injections).
Physiotherapy, biofeedback and similar non-invasive measures.
Physiotherapy (physical therapy) is sometimes used as an adjuvant to other methods of treatment in TMD. There are many different approaches described, but exercises aiming to increase the range of mandibular movements are commonly involved. Jaw exercises aim to directly oppose the negative effects of disuse that may occur in TMD, due to pain discouraging people from moving their jaw. After initial instruction, people are able to perform a physical therapy regimen at home. The most simple method is by regular stretching within pain tolerance, using the thumb and a finger in a "scissor" maneuver. Gentle force is applied until pain of resistance is felt, and then the position is held for several seconds. Commercial devices have been developed to carry out this stretching exercise (e.g. the "Therabite" appliance). Over time, the amount of mouth opening possible without pain can be gradually increased. A baseline record of the distance at the start of physical therapy (e.g. the number of fingers that can be placed vertically between the upper and lower incisors), can chart any improvement over time.
It has been suggested that massage therapy for TMD improves both the subjective and objective health status. "Friction massage" uses surface pressure to causes temporary ischemia and subsequent hyperemia in the muscles, and this is hypothesized to inactivate trigger points and disrupt small fibrous adhesions with in the muscle that have formed following surgery or muscular shortening due to restricted movement.
Occasionally physiotherapy for TMD may include the use of transcutaneous electrical nerve stimulation (TENS), which may override pain by stimulation of superficial nerve fibers and lead to pain reduction which extends after the time where the TENS is being actually being applied, possibly due to release of endorphins. Others recommend the use of ultrasound, theorized to produce tissue heating, alter blood flow and metabolic activity at a level that is deeper than possible with surface heat applications. There is tentative evidence that low level laser therapy may help with pain.
There is some evidence that some people who use nighttime biofeedback to reduce nighttime clenching experience a reduction in TMD.
Occlusal adjustment.
This is the adjustment or reorganizing of the existing occlusion, carried out in the belief that this will redistribute forces evenly across the dental arches and/or achieve a more favorable position of the condyles in the fossae, which is purported to lessen tooth wear, bruxism and TMD, but this is controversial. These techniques are sometimes termed "occlusal rehabilitation" or "occlusal equilibration". At its simplest, occlusal adjustment involves selective grinding (with a dental drill) of the enamel of the occlusal surfaces of teeth, with the aim of allowing the upper teeth to fit with the lower teeth in a more harmonious way. However, there is much disagreement between proponents of these techniques on most of the aspects involved, including the indications and the exact goals. Occlusal adjustment can also be very complex, involving orthodontics, restorative dentistry or even orthognathic surgery. Some have criticized these occlusal reorganizations as having no evidence base, and irreversibly damaging the dentition on top of the damage already caused by bruxism. A "middle ground" view of these techniques is that occlusal adjustment in most cases of TMD is neither desirable nor helpful as a first line treatment, and furthermore, with few exceptions, any adjustments should be reversible. However, most dentists consider this unnecessary overtreatment, with no evidence of benefit. Specifically, orthodontics and orthognathic surgery are not considered by most to be appropriate treatments for TMD. A systematic review investigating all the scientific studies carried out on occlusal adjustments in TMD concluded the following: 
"There is an absence of evidence of effectiveness for occlusal adjustment. Based on these data occlusal adjustment cannot be recommended for the treatment or prevention of TMD.
These conclusions were based largely on the fact that, despite many different scientific studies investigating this measure as a therapy, overall no statistically significant differences can be demonstrated between treatment with occlusal adjustment and treatment with placebo. The reviewers also stated that there are ethical implications if occlusal adjustment was found to be ineffective in preventing TMD.
Orthodontic treatment, as described earlier, is sometimes listed as a possible predisposing factor in the development of TMD. On the other hand, orthodontic treatment is also often carried out in the belief that it may treat or prevent TMD. Another systematic review investigating the relationship between orthodontics and TMD concluded the following:
"There is no evidence to support or refute the use of orthodontic treatment for the treatment of TMD. In addition, there are no data which identify a link between active orthodontic intervention and the causation of TMD. Based on the lack of data, orthodontic treatment cannot be recommended for the treatment or prevention of TMD." 
A common scenario where a newly placed dental restoration (e.g. a crown or a filling) is incorrectly contoured, and creates a premature contact in the bite. This may localize all the force of the bite onto one tooth, and cause inflammation of the periodontal ligament and reversible increase in tooth mobility. The tooth may become tender to bite on. Here, the "occlusal adjustment" has already taken place inadvertently, and the adjustment aims to return to the pre-existing occlusion. This should be distinguished from attempts to deliberately reorganize the native occlusion.
Surgery.
Attempts in the last decade to develop surgical treatments based on MRI and CAT scans now receive less attention. These techniques are reserved for the most difficult cases where other therapeutic modalities have failed. The American Society of Maxillofacial Surgeons recommends a conservative/non-surgical approach first. Only 20% of patients need to proceed to surgery.
Examples of surgical procedures that are used in TMD, some more commonly than others, include arthrocentesis, arthroscopy, menisectomy, disc repositioning, condylotomy or joint replacement. Invasive surgical procedures in TMD may cause symptoms to worsen. Menisectomy, also termed discectomy refers to surgical removal of the articular disc. This is rarely carried out in TMD, it may have some benefits for pain, but dysfunction may persist and overall there it leads to degeneration or remodeling of the TMJ.
Alternative medicine.
Acupuncture.
Acupuncture is sometimes used for TMD. There is limited evidence that acupuncture is an effective symptomatic treatment for TMD. A short term reduction in muscular pain of muscular origin can usually be observed after acupuncture in TMD, and this is more than is seen with placebo. There are no reported adverse events of acupuncture when used for TMD, and some suggest that acupuncture is best employed as an adjuvent to other treatments in TMD. However, some suggest that acupuncture may be no more effective than sham acupuncture, that many of the studies investigating acupuncture and TMD suffer from significant risk of bias, and that the long term efficacy of acupuncture for TMD is unknown.
Chiropractic.
Chiropractic adjustments (also termed manipulations or mobilizations) are sometimes used in the belief that this will treat TMD. Related conditions that are also claimed to be treatable by chiropractic include tension headaches and neck pain. Some sources suggest that there is some evidence of efficacy of chiropractic treatment in TMD, but the sources cited for these statements were case reports and a case series of only 9 participants. One review concluded "inconclusive evidence in a favorable direction regarding mobilization and massage for TMD". Overall, although there is general agreement that chiropractic may be of comparable benefit to other manual therapies for lower back pain, there is no credible evidence of efficacy in other conditions, including TMD. However, there is some evidence of possible adverse effects from cervical (neck) vertebral manipulation, which sometimes may be serious.
Prognosis.
It has been suggested that the natural history of TMD is benign and self-limiting, with symptoms slowly improving and resolving over time. The prognosis is therefore good. However, the persistent pain symptoms, psychological discomfort, physical disability and functional limitations may detriment quality of life. It has been suggested that TMD does not cause permanent damage and does not progress to arthritis in later life, however degenerative disorders of the TMJ such as osteoarthritis are included within the spectrum of TMDs in some classifications.
Epidemiology.
TMD mostly affects people in the 20 – 40 age group, and the average age is 33.9 years. People with TMD tend to be younger adults, who are otherwise healthy. Within the catchall umbrella of TMD, there are peaks for disc displacements at age 30, and for inflammatory-degenerative joint disorders at age 50.
About 75% of the general population may have at least one abnormal sign associated with the TMJ (e.g. clicking), and about 33% have at least one symptom of TMD. However, only in 3.6–7% will this be of sufficient severity to trigger the individual to seek medical advice.
For unknown reasons, females are more likely to be affected than males, in a ratio of about 2:1, although others report this ratio to be as high as 9:1. Females are more likely to request treatment for TMD, and their symptoms are less likely to resolve. Females with TMD are more likely to be nulliparous than females without TMD. It has also been reported that female caucasians are more likely to be affected by TMD, and at an earlier age, than female African Americans.
According to the most recent analyses of epidemiologic data using the RDC/TMD diagnostic criteria, of all TMD cases, group I (muscle disorders) accounts for 45.3%, group II (disc displacements) 41.1%, and group III (joint disorders) 30.1% (individuals may have diagnoses from more than one group). Using the RDC/TMD criteria, TMD has a prevelence in the general population of 9.7% for group I, 11.4% for group IIa, and 2.6% for group IIIa.
History.
Temporomandibular disorders were described as early as ancient Egypt. An older name for the condition is "Costen's syndrome", eponymously referring to James B. Costen. Costen was an otolaryngologist, and although he was not the first physician to describe TMD, he wrote extensively on the topic, starting in 1934, and was the first to approach the disorder in an integrated and systematic way. Costen hypothesized that malocclusion caused TMD, and placed emphasis on ear symptoms, such as tinnitus, otaglia, impaired hearing, and even dizziness. Specifically, Costen believed that the cause of TMD was mandibular over-closure, recommending a treatment revolving around building up the bite. The eponym "Costen syndrome" became commonly used shortly after his initial work, but in modern times it has been dropped, partially because occlusal factors are now thought to play little, if any, role in the development of TMD, and also because ear problems are now thought to be less associated with TMD. Other historically important terms that were used for TMD include "TMJ disease" or "TMJ syndrome", which are now rarely used.

</doc>
<doc id="30709" url="http://en.wikipedia.org/wiki?curid=30709" title="The Screwtape Letters">
The Screwtape Letters

The Screwtape Letters is a Christian apologetic novel written by C. S. Lewis. It is written in a satirical, epistolary style and while it is fictional in format, the plot and characters are used to address Christian theological issues, primarily those to do with temptation and resistance to it. First published in February 1942, the story takes the form of a series of letters from a senior Demon Screwtape to his nephew Wormwood, a Junior Tempter. The uncle's mentorship pertains to the nephew's responsibility for securing the damnation of a British man known only as "the Patient".
Summary.
In "The Screwtape Letters", C. S. Lewis provides a series of lessons in the importance of taking a deliberate role in Christian faith, by portraying a typical human life, with all its temptations and failings, seen from devils' viewpoints. Here, Screwtape holds an administrative post in the bureaucracy ("Lowerarchy") of Hell, and acts as a mentor to Wormwood, the inexperienced (and incompetent) tempter. In the thirty-one letters which comprise the book, Screwtape gives Wormwood detailed advice on various methods of undermining faith and promoting sin in the Patient, interspersed with observations on human nature and Christian doctrine. In Screwtape's advice, individual benefit and greed are seen as the greatest good, and neither demon is capable of comprehending God's love for man or acknowledging human virtue.
Versions of the letters were originally published weekly in the Anglican periodical "The Guardian" between May and November 1941, and the standard edition contains an introduction explaining how the author chose to write his story.
Lewis wrote the sequel "Screwtape Proposes a Toast" in 1959, a critique of certain trends in British public education (in Great Britain, "Public Education" means non state schooling). An omnibus edition with a new preface by Lewis was published by Bles in 1961 and MacMillan in 1962.
"The Screwtape Letters" is one of Lewis' most popular works, although he claimed that it was "not fun" to write, and "resolved never to write another 'Letter'."
Both "The Screwtape Letters" and "Screwtape Proposes a Toast" have been released on both audio cassette and CD, with narrations by John Cleese, Joss Ackland and Ralph Cosham.
Plot overview.
"The Screwtape Letters" comprises 31 letters written by a senior demon named Screwtape to his nephew, Wormwood (named after a star in Revelation), a younger and less experienced demon, charged with guiding a man (called "the patient") toward "Our Father Below" (Devil / Satan) from "the Enemy" (God).
After the second letter, the Patient converts to Christianity, and Wormwood is chastised for allowing this. A striking contrast is formed between Wormwood and Screwtape during the rest of the book, wherein Wormwood is depicted through Screwtape's letters as anxious to tempt his patient into extravagantly wicked and deplorable sins, and often reckless, while Screwtape takes a more subtle stance, as in Letter XII wherein he remarks: "...the safest road to hell is the gradual one - the gentle slope, soft underfoot, without sudden turnings, without milestones, without signposts".
In Letter VIII, Screwtape explains to his protégé the different purposes that God and the devils have for the human race: "We want cattle who can finally become food; He wants servants who can finally become sons". With this end in mind, Screwtape urges Wormwood in Letter VI to promote passivity and irresponsibility in the Patient: "(God) wants men to be concerned with what they do; our business is to keep them thinking about what will happen to them".
With his own views on theology, Lewis herein describes sex, love, pride, gluttony, and war. Lewis, an Oxford and Cambridge scholar himself, suggests in his work that even intellectuals are not impervious to the influence of such demons, especially during placated acceptance of the "Historical Point of View" (Letter XXVII).
In Letter XXII, after several attempts to find a licentious woman for the Patient, and after Screwtape's receiving a painful punishment for having divulged to Wormwood God's genuine love for humanity, Screwtape notes that the Patient has fallen in love with a Christian girl. Toward the end of this letter, Screwtape becomes a large centipede, mimicking a similar transformation in Book X of "Paradise Lost", wherein the demons are changed into snakes. Late in the correspondence, it is revealed that the young man is placed in harm's way by his military duties. While Wormwood is delighted at this, Screwtape admonishes Wormwood to keep the Patient safe, in hope that they can compromise his faith over a long lifetime.
In the last letter, the Patient has been killed during an air raid (World War II having broken out between the fourth and fifth letters), and has gone to Heaven, and that Wormwood is to suffer the consumption of his spiritual essence by the other demons, especially by Screwtape himself. Screwtape responds to Wormwood's final letter that he may expect as little assistance as Screwtape would expect from Wormwood were their situations reversed ("My love for you and your love for me are as alike as two peas...The only difference is that I am the stronger."), mimicking the situation where Wormwood himself informed on his uncle to the Infernal Police for Infernal Heresy (making a religiously positive remark that would offend Satan).
Literary sequels.
"Screwtape Proposes a Toast".
The short sequel essay "Screwtape Proposes a Toast" (1959), first published as an article in the "Saturday Evening Post", is an addendum to "The Screwtape Letters"; the two works are often published together as one book. "Screwtape Proposes a Toast" takes the form of an after-dinner speech given by Screwtape at the Tempters' Training College for young demons. "Screwtape Proposes a Toast" is Lewis' criticism of leveling and featherbedding trends in public education; more specifically, as he reveals in the foreword to the American edition, public education in America (though in the text, it is English education that is held up as the purportedly awful example).
The Cold War opposition between the West and the Communist World is explicitly discussed as a backdrop to the educational issues. Screwtape and other demons are portrayed as consciously using the subversion of education and intellectual thought in the West to bring about its overthrow by the communist enemy from without and within. In this sense "Screwtape Proposes a Toast" is more strongly political than "The Screwtape Letters", wherein no strong stand is made on political issues of the day, i.e., World War II.
Other literary sequels.
Though C. S. Lewis had resolved not to write another letter, and only revisited the character of Screwtape once, in "Screwtape Proposes a Toast", the format, referred to by Lewis himself as a kind of "demonic ventriloquism", has inspired other authors to prepare sequels or similar works, such as:
Adaptations.
Audio drama.
Focus on the Family Radio Theatre, a project of Focus on the Family, was granted the rights to dramatize "The Screwtape Letters" as a feature length audio drama. Production began in 2008, and the product was released in the fall of 2009. Andy Serkis, known for playing Gollum in "The Lord of the Rings" film trilogy, provides the voice for Screwtape, with Bertie Carvel as Wormwood, Philip Bird as The Patient "(identified in this production as "John Hamilton")", Laura Michael Kelly as The Girl "(identified in this production as "Dorothy")", Roger Hammond as Toadpipe, Christina Greatrex as Slumtrimpet, Janet Henfrey as Glubose, Philip Sherlock as the Messenger, Susie Brann as the Presenter and Geoffrey Palmer as C.S. Lewis. There is a 7-and-a-half minute video preview of the Radio Theatre production with interviews and making-of footage. This production was a 2010 Audie Award finalist.
Comic book adaptation.
Marvel Comics and religious book publisher Thomas Nelson produced a comic book adaptation of "The Screwtape Letters" in 1994.
Film adaptation.
"The Screwtape Letters" is a planned film based on the novel. 20th Century Fox bought the film rights to the book in the 1950s and partnered with Walden Media to make this film just as they were doing with "" (2010). Walden originally intended to release the film in 2008, however the current release date was set for 2012. Ralph Winter, the producer, credited the success of the "Chronicles of Narnia" film series for the greenlighting of "The Screwtape Letters". "The Screwtape Letters" is to be a live-action film. Because the novel is a series of letters with limited action, critics have questioned how a film adaptation is possible.
Stage adaptation.
The stage play "Dear Wormwood" (later renamed "Screwtape"), written by James Forsyth, was published in 1961. The setting is changed to wartime London, where we actually see Wormwood going about the business of tempting his "patient" (in the play, given the name "Michael Green"). The ending is changed as well, with Wormwood trying to repent and beg for forgiveness, when it appears that his mission has failed.
Philadelphia playwright and actor Anthony Lawton's original adaptation of "The Screwtape Letters" has been staged several times since 2000 by Lantern Theater Company, most recently in May/June 2014. In Lawton's adaptation, each of Screwtape's letters is punctuated by varied dances including tap, Latin ballroom, jazz, martial arts, and rock – and whips and fire-eating. Screwtape performs these dances with his secretary, Toadpipe.
The Fellowship for the Performing Arts obtained from the Lewis estate the rights to adapt "The Screwtape Letters" for the stage. The initial production opened off-off-Broadway at Theatre 315 in New York City in January 2006. The initial three-week run was extended to eleven and finally closed because the theater was contractually obligated to another production. It was co-written by Max McLean (who also starred) and Jeffrey Fiske (who also directed). A second, expanded production opened off Broadway at the Theatre at St. Clements on 18 October 2007, originally scheduled to run through 6 January 2008. The production re-opened at the Mercury Theater in Chicago in September 2008, and continued on a national tour including San Francisco, Phoenix, Louisville, Chattanooga, Fort Lauderdale, Houston and Austin, through January 2010 as well as playing at The Shakespeare Theatre in Washington, D.C. for ten weeks. "The Screwtape Letters" played for 309 performances at New York City’s Westside Theatre in 2010. The 2011 tour visited performing arts venues in cities throughout the United States including Los Angeles, Houston, Dallas, Atlanta, Seattle, Minneapolis, and Boston. The 2012-2013 tour began in Los Angeles in January 2012, with return engagements in San Francisco, San Diego, Seattle, Chicago and Atlanta as well as stops in several other cities. "The Screwtape Letters" has been described as "Humorous and lively...the Devil has rarely been given his due more perceptively!" by "The New York Times", "A profound experience" by "Christianity Today" and "Wickedly witty...One hell of good show!" by "The Wall Street Journal".
The Barley Sheaf Players of Lionville, Pennsylvania performed James Forsyth's play "Screwtape" in September 2010. It was directed by Scott Ryan and the play ran the last 3 weekends in September. The Production was reviewed by Paul Recupero for "Stage Magazine".
Cultural references.
Comics.
In the Sunday comic strip "Calvin and Hobbes", Calvin's teacher Miss Wormwood, who repeatedly fails to teach Calvin the value of education and attentiveness, is named after Screwtape's protégé.
Documentary.
I"Affectionately Yours, Screwtape: The Devil and C.S. Lewis" (January 1, 2007), directed by Tom Dallis and written by Amy Dallis, aired on the History Channel
Literature.
In 2010, the "Marine Corps Gazette" began publishing a series of articles entitled "The Attritionist Letters" styled in the manner of "The Screwtape Letters". In the letters, General Screwtape chastises Captain Wormwood for his inexperience and naivete while denouncing the concepts of maneuver warfare in favor of attrition warfare.
Music.
Called To Arms' concept album "Peril and the Patient" (August 10, 2010) is based entirely on "The Screwtape Letters".
In U2's music video for the song "Hold Me, Thrill Me, Kiss Me, Kill Me" (1995), an animated Bono is seen walking down the street holding the book "The Screwtape Letters". While on stage during the Zoo TV Tour Bono would dress as Mr. MacPhisto, his alter ego. Bono would wear a gold suit and devil horns and usually make prank calls to politicians.
The lyrics for The Receiving End of Sirens' song "Oubliette (Disappear)", from the album "The Earth Sings Mi Fa Mi" (2007) were inspired by a passage from "The Screwtape Letters".
Speeches.
U.S. President Ronald Reagan quoted "The Screwtape Letters" in his famous 1983 speech to the National Association of Evangelicals.
Other uses.
David Foster Wallace praised the book in interviews and listed it first on his list of top ten favorite books.
In an October 2013 interview in "New York" magazine, U.S. Supreme Court Justice Antonin Scalia, professed his admiration for the book. Scalia remarked, ""The Screwtape Letters" is a great book. It really is, just as a study of human nature." The book was discussed in the highly publicized interview during Scalia's discourse regarding the nature of his Catholic faith.

</doc>
<doc id="30710" url="http://en.wikipedia.org/wiki?curid=30710" title="Tree of life">
Tree of life

The concept of a tree of life has been used in biology, religion, philosophy, and mythology. A tree of life is a common motif in various world theologies, mythologies, and philosophies. It alludes to the interconnection of all life on our planet and serves as a metaphor for common descent in the evolutionary sense. The term "tree of life" may also be used as a synonym for "sacred tree".
The tree of knowledge, connecting to heaven and the underworld, and the tree of life, connecting all forms of creation, are both forms of the world tree or cosmic tree, according to the "Encyclopædia Britannica", and are portrayed in various religions and philosophies as the same tree.
Religion and mythology.
Various trees of life are recounted in folklore, culture and fiction, often relating to immortality or fertility. They had their origin in religious symbolism.
Ancient Iran.
In pre-Islamic Persian mythology, the Gaokerena world tree is a large, sacred Haoma tree which bears all seeds. Ahriman (Ahreman, Angremainyu) created a frog to invade the tree and destroy it, aiming to prevent all trees from growing on the earth. As a reaction, God (Ahura Mazda) created two kar fish staring at the frog to guard the tree. The two fishes are always staring at the frog and stay ready to react to it. Because Ahriman is responsible for all evil including death, while Ahura Mazda is responsible for all good (including life) the concept of world tree in Persian Mythology is very closely related to the concept of Tree of Life.
The sacred plant "haoma" and the drink made from it. The preparation of the drink from the plant by pounding and the drinking of it are central features of Zoroastrian ritual. Haoma is also personified as a divinity. It bestows essential vital qualities—health, fertility, husbands for maidens, even immortality. The source of the earthly haoma plant is a shining white tree that grows on a paradisiacal mountain. Sprigs of this white haoma were brought to earth by divine birds.
Haoma is the Avestan form of the Sanskrit "soma". The near identity of the two in ritual significance is considered by scholars to point to a salient feature of an Indo-Iranian religion antedating Zoroastrianism.
Another related issue in ancient mythology of Iran is the myth of Mashyа and Mashyane, two trees who were the ancestors of all living beings. This myth can be considered as a prototype for the creation myth where living beings are created by Gods (who have a human form).
Ancient Egypt.
To the Ancient Egyptians, the Tree of Life represented the hierarchical chain of events that brought every thing into existence. The spheres of the Tree of Life demonstrate the order, process, and method of creation.
In Egyptian mythology, in the Ennead system of Heliopolis, the first couple, apart from Shu and Tefnut (moisture and dryness) and Geb and Nuit (earth and sky), are Isis and Osiris. They were said to have emerged from the acacia tree of Iusaaset, which the Egyptians considered the tree of life, referring to it as the "tree in which life and death are enclosed." Acacia trees contain DMT, a psychedelic drug associated with spiritual experiences. A much later myth relates how Set killed Osiris, putting him in a coffin, and throwing it into the Nile, the coffin becoming embedded in the base of a tamarisk tree.
The Egyptians' Holy Sycamore also stood on the threshold of life and death, connecting the two worlds.
Armenia.
In ancient Armenia, the Tree of Life (Կենաց Ծառ) was a religious symbol and was drawn on walls of fortresses and carved on the armor of warriors. The branches of the tree were equally divided on the right and left sides of the stem, with each branch having one leaf, and one leaf on the apex of the tree. Servants stood on each side of the tree with one of their hands up as if they are taking care of the tree.
Assyria.
The Assyrian Tree of Life was represented by a series of nodes and criss-crossing lines. It was apparently an important religious symbol, often attended to by eagle-headed gods and priests, or the King. Assyrilogists have not reached consensus as to the meaning of this symbol. It is multi-valent. The name "Tree of Life" has been attributed to it by modern scholarship; it is not used in the Assyrian sources. In fact, no textual evidence pertaining to the symbol is known to exist.
Baha'i Faith.
The concept of the tree of life appears in the writings of the Baha'i Faith, where it can refer to the Manifestation of God, a great teacher who appears to humanity from age to age. An example of this can be found in the "Hidden Words" of Bahá'u'lláh:
"Have ye forgotten that true and radiant morn, when in those hallowed and blessed surroundings ye were all gathered in My presence beneath the shade of the tree of life, which is planted in the all-glorious paradise? Awestruck ye listened as I gave utterance to these three most holy words: O friends! Prefer not your will to Mine, never desire that which I have not desired for you, and approach Me not with lifeless hearts, defiled with worldly desires and cravings. Would ye but sanctify your souls, ye would at this present hour recall that place and those surroundings, and the truth of My utterance should be made evident unto all of you."
Bahá'u'lláh refers to his male descendents as branches (Aghsán) and calls women leaves.
A distinction has been made between the tree of life and the tree of the knowledge of good and evil. The latter represents the physical world with its opposites, such as good and evil and light and dark. In a different context from the one above, the tree of life represents the spiritual realm, where this duality does not exist.
Buddhism.
The "Bo" tree, also called "Bodhi" tree, according to Buddhist tradition, is the pipal (Ficus religiosa) under which the Buddha sat when he attained Enlightenment (Bodhi) at Bodh Gaya (near Gaya, west-central Bihar state, India). A living pipal at Anuradhapura, Ceylon (now Sri Lanka), is said to have grown from a cutting from the Bo tree sent to that city by King Ashoka in the 3rd century BCE.
According to Tibetan tradition when Buddha went to the holy Lake Manasorovar along with 500 monks, he took with him the energy of Prayaga Raj. Upon his arrival, he installed the energy of Prayaga Raj near Lake Manasorovar, at a place now known as Prayang. Then he planted the seed of this eternal banyan tree next to Mt. Kailash on a mountain known as the "Palace of Medicine Buddha".
China.
In Chinese mythology, a carving of a Tree of Life depicts a phoenix and a dragon; the dragon often represents immortality. A Taoist story tells of a tree that produces a peach every three thousand years. The one who eats the fruit receives immortality.
An archaeological discovery in the 1990s was of a sacrificial pit at Sanxingdui in Sichuan, China. Dating from about 1200 BCE, it contained three bronze trees, one of them 4 meters high. At the base was a dragon, and fruit hanging from the lower branches. At the top is a strange bird-like (phoenix) creature with claws. Also found in Sichuan, from the late Han dynasty (c 25 – 220 CE), is another tree of life. The ceramic base is guarded by a horned beast with wings. The leaves of the tree are coins and people. At the apex is a bird with coins and the Sun.
Christianity.
In Catholic Christianity, the Tree of Life represents the immaculate state of humanity free from corruption and Original Sin before the Fall. Pope Benedict XVI has said that "the Cross is the true tree of life." Saint Bonaventure taught that the medicinal fruit of the Tree of Life is Christ himself. Saint Albert the Great taught that the Eucharist, the Body and Blood of Christ, is the Fruit of the Tree of Life.
In Eastern Christianity the tree of life is the love of God.
Latter Day Saint movement.
The tree of life appears in the Book of Mormon in a revelation to Lehi (see ). It is symbolic of the love of God (see ). Its fruit is described as "most precious and most desirable above all other fruits," which "is the greatest of all the gifts of God" (see ). In another scriptural book, salvation is called "the greatest of all the gifts of God" (see ). In the same book eternal life is also called the "greatest of all the gifts of God" (see ). Because of these references, the tree of life and its fruit is sometimes understood to be symbolic of salvation and post-mortal existence in the presence of God and his love.
Swedenborgianism.
According to Swedenborgianism, the first twelve chapters of Genesis are a symbolic retelling of ancient truths. In his "Arcana Coelestia",
Emanuel Swedenborg (1688–1772) expounded on the symbolism and underlying spiritual meaning of both Genesis and Exodus, and the symbolism regarding the tree of life.
Europe.
In "Dictionaire Mytho-Hermetiqe" (Paris, 1737), Antoine-Joseph Pernety, a famous alchemist, identified the Tree of Life with the Elixir of Life and the Philosopher's Stone.
In "Eden in the East" (1998), Stephen Oppenheimer suggests that a tree-worshipping culture arose in Indonesia and was diffused by the so-called "Younger Dryas" event of c. 8000 BCE, when the sea level rose. This culture reached China (Szechuan), then India and the Middle East. Finally the Finno-Ugaritic strand of this diffusion spread through Russia to Finland where the Norse myth of Yggdrasil took root.
Georgia.
The Borjgali (Georgian: ბორჯღალი) is an ancient Georgian Tree of Life symbol.
Germanic paganism and Norse mythology.
In Germanic paganism, trees played (and, in the form of reconstructive Heathenry and Germanic Neopaganism, continue to play) a prominent role, appearing in various aspects of surviving texts and possibly in the name of gods.
The tree of life appears in Norse religion as "Yggdrasil", the world tree, a massive tree (sometimes considered a yew or ash tree) with extensive lore surrounding it. Perhaps related to Yggdrasil, accounts have survived of Germanic Tribes' honouring sacred trees within their societies. Examples include Thor's Oak, sacred groves, the Sacred tree at Uppsala, and the wooden Irminsul pillar. In Norse Mythology, the apples from Iðunn's ash box provide immortality for the gods.
Hinduism.
The Eternal Banyan Tree ("Akshaya Vata") is located on the bank of the Yamuna inside the courtyard of Allahabad Fort near the confluence of the Yamuna and Ganga Rivers in Allahabad. The eternal and divine nature of this tree has been documented at length in the scriptures.
During the cyclic destruction of creation when the whole earth was enveloped by waters, "akshaya vata" remained unaffected. It is on the leaves of this tree that Lord Krishna rested in the form of a baby when land was no longer visible. And it is here that the immortal sage, Markandeya, received the cosmic vision of the Lord. It is under this tree that Buddha meditates eternally. Legend also has it that the Bodi tree at Gaya is a manifestation of this tree.
Islam.
The "Tree of Immortality" (Arabic: شجرة الخلود) is the tree of life motif as it appears in the Quran. It is also alluded to in hadiths and tafsir. Unlike the biblical account, the Quran mentions only one tree in Eden, also called the tree of immortality, which Allah specifically forbade to Adam and Eve. Satan, disguised as a serpent, repeatedly told Adam to eat from the tree, and eventually both Adam and Eve did so, thus disobeying Allah. The hadiths also speak about other trees in heaven.
According to the Ahmadiyya movement, Quranic reference to the tree is symbolic; eating of the forbidden tree signifies that Adam disobeyed God.
Jewish sources.
"Etz Chaim", Hebrew for "tree of life," is a common term used in Judaism. The expression, found in the Book of Proverbs, is figuratively applied to the Torah itself. "Etz Chaim" is also a common name for yeshivas and synagogues as well as for works of Rabbinic literature. It is also used to describe each of the wooden poles to which the parchment of a Sefer Torah is attached.
The tree of life is mentioned in the Book of Genesis; it is distinct from the tree of the knowledge of good and evil. After Adam disobeyed God by eating fruit from the tree of the knowledge of good and evil, he was driven out of the garden of Eden. Remaining in the garden, however, was the tree of life. To prevent the man's access to this tree in the future, Cherubims with a flaming sword were placed at the east of the garden. ()
In the Book of Proverbs, the tree of life is associated with wisdom: "[Wisdom] is a tree of life to them that lay hold upon her, and happy "[is every one]" that retaineth her." () In the tree of life is associated with calmness: "A soothing tongue is a tree of life; but perverseness therein is a wound to the spirit."
The Book of Enoch, generally considered non-canonical, states that in the time of the great judgment God will give all those whose names are in the Book of Life fruit to eat from the Tree of Life.
Kabbalah.
Jewish mysticism depicts the Tree of Life in the form of ten interconnected nodes, as the central symbol of the Kabbalah. It comprises the ten Sephirot powers in the Divine realm. The panentheistic and anthropomorphic emphasis of this emanationist theology interpreted the Torah, Jewish observance, and the purpose of Creation as the symbolic esoteric drama of unification in the Sephirot, restoring harmony to Creation. From the time of the Renaissance onwards, Jewish Kabbalah became incorporated as an important tradition in non-Jewish Western culture, first through its adoption by Christian Cabala, and continuing in Western esotericism occult Hermetic Qabalah. These adapted the Judaic Kabbalah Tree of Life syncretically by associating it with other religious traditions, esoteric theologies, and magical practices.
Mesoamerica.
The concept of world trees is a prevalent motif in pre-Columbian Mesoamerican cosmologies and iconography. World trees embodied the four cardinal directions, which represented also the fourfold nature of a central world tree, a symbolic "axis mundi" connecting the planes of the Underworld and the sky with that of the terrestrial world.
Depictions of world trees, both in their directional and central aspects, are found in the art and mythological traditions of cultures such as the Maya, Aztec, Izapan, Mixtec, Olmec, and others, dating to at least the Mid/Late Formative periods of Mesoamerican chronology. Among the Maya, the central world tree was conceived as or represented by a "ceiba" tree, and is known variously as a "wacah chan" or "yax imix che", depending on the Mayan language. The trunk of the tree could also be represented by an upright caiman, whose skin evokes the tree's spiny trunk.
Directional world trees are also associated with the four Yearbearers in Mesoamerican calendars, and the directional colors and deities. Mesoamerican codices which have this association outlined include the Dresden, Borgia and Fejérváry-Mayer codices. It is supposed that Mesoamerican sites and ceremonial centers frequently had actual trees planted at each of the four cardinal directions, representing the quadripartite concept.
World trees are frequently depicted with birds in their branches, and their roots extending into earth or water (sometimes atop a "water-monster," symbolic of the underworld). The central world tree has also been interpreted as a representation of the band of the Milky Way.
Middle East.
The "Epic of Gilgamesh" is a similar quest for immortality. In Mesopotamian mythology, Etana searches for a 'plant of birth' to provide him with a son. This has a solid provenance of antiquity, being found in cylinder seals from Akkad (2390–2249 BCE).
"The Book of One Thousand and One Nights" has a story, 'The Tale of Buluqiya', in which the hero searches for immortality and finds a paradise with jewel-encrusted trees. Nearby is a Fountain of Youth guarded by Al-Khidr. Unable to defeat the guard, Buluqiya has to return empty-handed.
North America.
In a myth passed down among the Iroquois, "The World on the Turtle's Back", explains the origin of the land in which a "tree of life" is described. According to the myth, it is found in the heavens, where the first humans lived, until a pregnant woman fell and landed in an endless sea. Saved by a giant turtle from drowning, she formed the world on its back by planting bark taken from the tree.
The tree of life motif is present in the traditional Ojibway cosmology and traditions. It is sometimes described as Grandmother Cedar, or "Nookomis Giizhig" in Anishinaabemowin.
In the book Black Elk Speaks, Black Elk, an Oglala Lakota (Sioux) "wičháša wakȟáŋ" (medicine man and holy man), describes his vision in which after dancing around a dying tree that has never bloomed he is transported to the other world (spirit world) where he meets wise elders, 12 men and 12 women. The elders tell Black Elk that they will bring him to meet "Our Father, the two-legged chief" and bring him to the center of a hoop where he sees the tree in full leaf and bloom and the "chief" standing against the tree. Coming out of his trance he hopes to see that the earthly tree has bloomed, but it is dead.
Serer religion.
In Serer religion, the tree of life as a religious concept forms the basis of Serer cosmogony. Trees were the first things created on Earth by the supreme being Roog (or Koox among the Cangin). In the competing versions of the Serer creation myth, the "Somb" ("Prosopis africana") and the "Saas" tree (acacia albida) are both viewed as trees of life. However, the prevailing view is that, the "Somb" was the first tree on Earth and the progenitor of plant life. The "Somb" was also used in the Serer tumuli and burial chambers, many of which had survived for more than a thousand years. Thus, "Somb" is not only the Tree of Life in Serer society, but the symbol of immortality.
Turkic world.
The World Tree or Tree of Life is a central symbol in Turkic mythology. The blue sky around the tree reflects the peaceful nature of the country and the red ring that surrounds all of the elements symbolizes the ancient faith of rebirth, growth and development of the Turkic peoples.
Biology.
The tree of life is a metaphor describing the relationship of all life on Earth in an evolutionary context. Charles Darwin talked about envisioning evolution as a "tangled bank" in "On the Origin of Species"; however, the book's sole illustration is of a branched diagram that is very tree-like. 
From the first growth of the tree, many a limb and branch has decayed and dropped off; and these fallen branches of various sizes may represent those whole orders, families, and genera which have now no living representatives, and which are known to us only in a fossil state. As we here and there see a thin, straggling branch springing from a fork low down in a tree, and which by some chance has been favoured and is still alive on its summit, so we occasionally see an animal like the Ornithorhynchus (Platypus) or Lepidosiren (South American lungfish), which in some small degree connects by its affinities two large branches of life, and which has apparently been saved from fatal competition by having inhabited a protected station. As buds give rise by growth to fresh buds, and these, if vigorous, branch out and overtop on all sides many a feebler branch, so by generation I believe it has been with the great Tree of Life, which fills with its dead and broken branches the crust of the earth, and covers the surface with its ever-branching and beautiful ramifications.—Charles Darwin, On the Origin of Species
The evolutionary relationships of the tree of life were refined using genetic data by the American microbiologist Carl Woese, the discoverer of the domain Archaea and a pioneer in molecular (genetic) methods in evolutionary biology. In February 2009, BBC One broadcast an animated, interactive tree of life as part of its "Darwin Season."
The Tree of Life Web Project is an ongoing Internet project containing information about phylogeny and biodiversity, produced by biologists from around the world. Each page contains information about one group of organisms and is organized according to a branched tree-like form, thus showing relationships between organisms and groups of organisms.
The neuroanatomical term "arbor vitae" (tree of life) describes the branching pattern between the cortical grey matter and subcortical white matter of the cerebellum.
Popular culture.
Art and architecture.
A 2½ story high "Tree of Life" sculpture by Wisconsin artist Nancy Metz White was installed in Mitchell Boulevard Park in Milwaukee in 2002. The tree is made of brightly painted welded steel and forge flashings recycled from Milwaukee heavy industry.
Austrian symbolist artist Gustav Klimt portrayed his version of the tree of life in his painting, "The Tree of Life, Stoclet Frieze". This iconic painting later inspired the external facade of the "New Residence Hall" (also called the "Tree House"), a colorful 21-story student residence hall at Massachusetts College of Art and Design in Boston, Massachusetts.
Contemporary Welsh artist Jen Delyth created a Celtic Tree of Life symbol, in part based on ancient Celtic veneration of trees and traditional Celtic designs.
Music.
In their album "Emissaries" the black metal Melechesh make a reference to the Tree of Life in their song "Touching the Spheres of Sephiroth."
American rock band O.A.R. featured a tree of life both on the cover art and on the actual c.d. for the album In Between Now and Then
Double album "Bath"/"Leaving Your Body Map" by avant-garde metal band maudlin of the Well was constructed based upon a parallel qabalistic Tree of Life structure.
The double album Axis Mutatis by the electronic group The Shamen contains in some limited editions the instrumental album "Arbor Bona Arbor Mala." The title refers to the tree of life, the ancient symbol found in virtually all Shamanic cultures, linking the underworld with the earth and the heavens. Also, on the cover of Axis Mutatis appears a representation of the tree of life by William Latham.
In Korean boy band, EXO's Music Video MAMA, the twelve forces (EXO's members) will be the one to restore the tree of life.
Rapper Ab-Soul uses the tree of life as the cover of his Control System album

</doc>
<doc id="30715" url="http://en.wikipedia.org/wiki?curid=30715" title="Technocracy (disambiguation)">
Technocracy (disambiguation)

Technocracy is a form of government by technicians; specifically: management of society by technical experts.
Technocracy or technocrat may also refer to:

</doc>
<doc id="30717" url="http://en.wikipedia.org/wiki?curid=30717" title="Tales of the Reaching Moon">
Tales of the Reaching Moon

Tales of the Reaching Moon was a British fanzine dedicated to the fantasy world of Glorantha and producing material for fantasy role-playing games based there. The editor, David Hall, published 20 issues from 1989 to 2002 (2/yr until 1994, then annually). The magazine was originally published with a monochrome cover but had a full colour cover from issue 12 onwards. Most of the later issues had a central theme fleshed out through a variety of related articles by different authors. A list of issues with themes is given below:
The fanzine printed gaming material for a variety of rule-systems, including RuneQuest and Pendragon Pass. In addition to this it also had fiction, news and a Rumours section based on the format of the RuneQuest supplements.

</doc>
<doc id="30718" url="http://en.wikipedia.org/wiki?curid=30718" title="Tide">
Tide

Tides are the rise and fall of sea levels caused by the combined effects of gravitational forces exerted by the Moon, Sun, and rotation of the Earth.
Some shorelines experience two nearly equal high and low tides each day, called a semi-diurnal tide. Some locations experience only one high and low tide each day, called a diurnal tide. Some locations experience two uneven tides a day, or sometimes one high and one low each day; this is called a mixed tide. The times and amplitude of tides at a locale are influenced by the alignment of the Sun and Moon, by the pattern of tides in the deep ocean, by the amphidromic systems of the oceans, and the shape of the coastline and near-shore bathymetry (see "Timing").
Tides vary on timescales ranging from hours to years due to numerous influences. To make accurate records, tide gauges at fixed stations measure the water level over time. Gauges ignore variations caused by waves with periods shorter than minutes. These data are compared to the reference (or datum) level usually called mean sea level.
While tides are usually the largest source of short-term sea-level fluctuations, sea levels are also subject to forces such as wind and barometric pressure changes, resulting in storm surges, especially in shallow seas and near coasts.
Tidal phenomena are not limited to the oceans, but can occur in other systems whenever a gravitational field that varies in time and space is present. For example, the solid part of the Earth is affected by tides, though this is not as easily seen as the water tidal movements.
Characteristics.
Tide changes proceed via the following stages:
Tides produce oscillating currents known as tidal streams. The moment that the tidal current ceases is called slack water or slack tide. The tide then reverses direction and is said to be turning. Slack water usually occurs near high water and low water. But there are locations where the moments of slack tide differ significantly from those of high and low water.
Tides are commonly "semi-diurnal" (two high waters and two low waters each day), or "diurnal" (one tidal cycle per day). The two high waters on a given day are typically not the same height (the daily inequality); these are the "higher high water" and the "lower high water" in tide tables. Similarly, the two low waters each day are the "higher low water" and the "lower low water". The daily inequality is not consistent and is generally small when the Moon is over the equator.
Tidal constituents.
"Tidal constituents" are the net result of multiple influences impacting tidal changes over certain periods of time. Primary constituents include the Earth's rotation, the position of the Moon and Sun relative to the Earth, the Moon's altitude (elevation) above the Earth's equator, and bathymetry. Variations with periods of less than half a day are called "harmonic constituents". Conversely, cycles of days, months, or years are referred to as "long period" constituents.
The tidal forces affect the entire earth, but the movement of the solid Earth is only centimeters. The atmosphere is much more fluid and compressible so its surface moves kilometers, in the sense of the contour level of a particular low pressure in the outer atmosphere.
Principal lunar semi-diurnal constituent.
In most locations, the largest constituent is the "principal lunar semi-diurnal", also known as the "M2" (or "M"2) tidal constituent. Its period is about 12 hours and 25.2 minutes, exactly half a "tidal lunar day", which is the average time separating one lunar zenith from the next, and thus is the time required for the Earth to rotate once relative to the Moon. Simple tide clocks track this constituent. The lunar day is longer than the Earth day because the Moon orbits in the same direction the Earth spins. This is analogous to the minute hand on a watch crossing the hour hand at 12:00 and then again at about 1:05½ (not at 1:00).
The Moon orbits the Earth in the same direction as the Earth rotates on its axis, so it takes slightly more than a day—about 24 hours and 50 minutes—for the Moon to return to the same location in the sky. During this time, it has passed overhead (culmination) once and underfoot once (at an hour angle of 00:00 and 12:00 respectively), so in many places the period of strongest tidal forcing is the above-mentioned, about 12 hours and 25 minutes. The moment of highest tide is not necessarily when the Moon is nearest to zenith or nadir, but the period of the forcing still determines the time between high tides.
Because the gravitational field created by the Moon weakens with distance from the Moon, it exerts a slightly stronger than average force on the side of the Earth facing the Moon, and a slightly weaker force on the opposite side. The Moon thus tends to "stretch" the Earth slightly along the line connecting the two bodies. The solid Earth deforms a bit, but ocean water, being fluid, is free to move much more in response to the tidal force, particularly horizontally. As the Earth rotates, the magnitude and direction of the tidal force at any particular point on the Earth's surface change constantly; although the ocean never reaches equilibrium—there is never time for the fluid to "catch up" to the state it would eventually reach if the tidal force were constant—the changing tidal force nonetheless causes rhythmic changes in sea surface height.
Semi-diurnal range differences.
When there are two high tides each day with different heights (and two low tides also of different heights), the pattern is called a "mixed semi-diurnal tide".
Range variation: springs and neaps.
The semi-diurnal range (the difference in height between high and low waters over about half a day) varies in a two-week cycle. Approximately twice a month, around new moon and full moon when the Sun, Moon, and Earth form a line (a condition known as syzygy), the tidal force due to the sun reinforces that due to the Moon. 
The tide's range is then at its maximum; this is called the spring tide. It is not named after the season, but, like that word, derives from the meaning "jump, burst forth, rise", as in a natural spring.
When the Moon is at first quarter or third quarter, the sun and Moon are separated by 90° when viewed from the Earth, and the solar tidal force partially cancels the Moon's. At these points in the lunar cycle, the tide's range is at its minimum; this is called the "neap tide", or "neaps" (a word of uncertain origin).
Spring tides result in high waters that are higher than average, low waters that are lower than average, 'slack water' time that is shorter than average, and stronger tidal currents than average. Neaps result in less-extreme tidal conditions. There is about a seven-day interval between springs and neaps.
Lunar altitude.
The changing distance separating the Moon and Earth also affects tide heights. When the Moon is closest, at perigee, the range increases, and when it is at apogee, the range shrinks. Every 7½ lunations (the full cycles from full moon to new to full), perigee coincides with either a new or full moon causing perigean spring tides with the largest "tidal range". Even at its most powerful this force is still weak causing tidal differences of inches at most.
Bathymetry.
The shape of the shoreline and the ocean floor changes the way that tides propagate, so there is no simple, general rule that predicts the time of high water from the Moon's position in the sky. Coastal characteristics such as underwater bathymetry and coastline shape mean that individual location characteristics affect tide forecasting; actual high water time and height may differ from model predictions due to the coastal morphology's effects on tidal flow. However, for a given location the relationship between lunar altitude and the time of high or low tide (the lunitidal interval) is relatively constant and predictable, as is the time of high or low tide relative to other points on the same coast. For example, the high tide at Norfolk, Virginia, U.S., predictably occurs approximately two and a half hours before the Moon passes directly overhead.
Land masses and ocean basins act as barriers against water moving freely around the globe, and their varied shapes and sizes affect the size of tidal frequencies. As a result, tidal patterns vary. For example, in the U.S., the East coast has predominantly semi-diurnal tides, as do Europe's Atlantic coasts, while the West coast predominantly has mixed tides.
Other constituents.
These include solar gravitational effects, the obliquity (tilt) of the Earth's equator and rotational axis, the inclination of the plane of the lunar orbit and the elliptical shape of the Earth's orbit of the sun.
A compound tide (or overtide) results from the shallow-water interaction of its two parent waves.
Phase and amplitude.
Because the "M"2 tidal constituent dominates in most locations, the stage or "phase" of a tide, denoted by the time in hours after high water, is a useful concept. Tidal stage is also measured in degrees, with 360° per tidal cycle. Lines of constant tidal phase are called "cotidal lines", which are analogous to contour lines of constant altitude on topographical maps. High water is reached simultaneously along the cotidal lines extending from the coast out into the ocean, and cotidal lines (and hence tidal phases) advance along the coast. Semi-diurnal and long phase constituents are measured from high water, diurnal from maximum flood tide. This and the discussion that follows is precisely true only for a single tidal constituent.
For an ocean in the shape of a circular basin enclosed by a coastline, the "cotidal lines" point radially inward and must eventually meet at a common point, the amphidromic point. The amphidromic point is at once cotidal with high and low waters, which is satisfied by "zero" tidal motion. (The rare exception occurs when the tide encircles an island, as it does around New Zealand, Iceland and Madagascar.) Tidal motion generally lessens moving away from continental coasts, so that crossing the cotidal lines are contours of constant "amplitude" (half the distance between high and low water) which decrease to zero at the amphidromic point. For a semi-diurnal tide the amphidromic point can be thought of roughly like the center of a clock face, with the hour hand pointing in the direction of the high water cotidal line, which is directly opposite the low water cotidal line. High water rotates about the amphidromic point once every 12 hours in the direction of rising cotidal lines, and away from ebbing cotidal lines. This rotation is generally clockwise in the southern hemisphere and counterclockwise in the northern hemisphere, and is caused by the Coriolis effect. The difference of cotidal phase from the phase of a reference tide is the "epoch". The reference tide is the hypothetical constituent "equilibrium tide" on a landless Earth measured at 0° longitude, the Greenwich meridian.
In the North Atlantic, because the cotidal lines circulate counterclockwise around the amphidromic point, the high tide passes New York Harbor approximately an hour ahead of Norfolk Harbor. South of Cape Hatteras the tidal forces are more complex, and cannot be predicted reliably based on the North Atlantic cotidal lines.
Physics.
History of tidal physics.
Investigation into tidal physics was important in the early development of heliocentrism and celestial mechanics, with the existence of two daily tides being explained by the Moon's gravity. Later the daily tides were explained more precisely by the interaction of the Moon's and the sun's gravity.
Seleucus of Seleucia theorized around 150 B.C. that tides were caused by the Moon.
Simon Stevin in his 1608 "De spiegheling der Ebbenvloet", The theory of ebb and flood, dismissed a large number of misconceptions that still existed about ebb and flood. Stevin pleaded for the idea that the attraction of the Moon was responsible for the tides and spoke in clear terms about ebb, flood, spring tide and neap tide, stressing that further research needed to be made.
In 1609 Johannes Kepler also correctly suggested that the gravitation of the Moon caused the tides, which he based upon ancient observations and correlations. It was originally mentioned in Ptolemy's Tetrabiblos as having derived from ancient observation.
Galileo Galilei in his 1632 "Dialogue Concerning the Two Chief World Systems", whose working title was "Dialogue on the Tides", gave an explanation of the tides. The resulting theory, however, was incorrect as he attributed the tides to the sloshing of water caused by the Earth's movement around the sun. He hoped to provide mechanical proof of the Earth's movement – the value of his tidal theory is disputed. Galileo rejected Kepler's explanation of the tides.
Isaac Newton (1642–1727) was the first person to explain tides as the product of the gravitational attraction of astronomical masses. His explanation of the tides (and many other phenomena) was published in the "Principia" (1687) and used his theory of universal gravitation to explain the lunar and solar attractions as the origin of the tide-generating forces.
Newton and others before Pierre-Simon Laplace worked the problem from the perspective of a static system (equilibrium theory), that provided an approximation that described the tides that would occur in a non-inertial ocean evenly covering the whole Earth. The tide-generating force (or its corresponding potential) is still relevant to tidal theory, but as an intermediate quantity (forcing function) rather than as a final result; theory must also consider the Earth's accumulated dynamic tidal response to the applied forces, which response is influenced by ocean depth, the Earth's rotation, and other factors.
In 1740, the Académie Royale des Sciences in Paris offered a prize for the best theoretical essay on tides. Daniel Bernoulli, Leonhard Euler, Colin Maclaurin and Antoine Cavalleri shared the prize.
Maclaurin used Newton's theory to show that a smooth sphere covered by a sufficiently deep ocean under the tidal force of a single deforming body is a prolate spheroid (essentially a three-dimensional oval) with major axis directed toward the deforming body. Maclaurin was the first to write about the Earth's rotational effects on motion. Euler realized that the tidal force's "horizontal" component (more than the vertical) drives the tide. In 1744 Jean le Rond d'Alembert studied tidal equations for the atmosphere which did not include rotation.
Pierre-Simon Laplace formulated a system of partial differential equations relating the ocean's horizontal flow to its surface height, the first major dynamic theory for water tides. The Laplace tidal equations are still in use today. William Thomson, 1st Baron Kelvin, rewrote Laplace's equations in terms of vorticity which allowed for solutions describing tidally driven coastally trapped waves, known as Kelvin waves.
Others including Kelvin and Henri Poincaré further developed Laplace's theory. Based on these developments and the lunar theory of E W Brown describing the motions of the Moon, Arthur Thomas Doodson developed and published in 1921 the first modern development of the tide-generating potential in harmonic form: Doodson distinguished 388 tidal frequencies. Some of his methods remain in use.
Forces.
The tidal force produced by a massive object (Moon, hereafter) on a small particle located on or in an extensive body (Earth, hereafter) is the vector difference between the gravitational force exerted by the Moon on the particle, and the gravitational force that would be exerted on the particle if it were located at the Earth's center of mass. 
The solar "gravitational force" on the Earth is on average 179 times stronger than the lunar, but because the Sun is on average 389 times farther from the Earth, its field gradient is weaker. The solar tidal force is 46% as large as the lunar. More precisely, the lunar tidal acceleration (along the Moon–Earth axis, at the Earth's surface) is about 1.1 × 10−7 "g", while the solar tidal acceleration (along the Sun–Earth axis, at the Earth's surface) is about 0.52 × 10−7 "g", where "g" is the gravitational acceleration at the Earth's surface. Venus has the largest effect of the other planets, at 0.000113 times the solar effect.
The ocean's surface is closely approximated by an equipotential surface, (ignoring ocean currents) commonly referred to as the geoid. Since the gravitational force is equal to the potential's gradient, there are no tangential forces on such a surface, and the ocean surface is thus in gravitational equilibrium. Now consider the effect of massive external bodies such as the Moon and Sun. These bodies have strong gravitational fields that diminish with distance and act to alter the shape of an equipotential surface on the Earth. This deformation has a fixed spatial orientation relative to the influencing body. The Earth's rotation relative to this shape causes the daily tidal cycle. Gravitational forces follow an inverse-square law (force is inversely proportional to the square of the distance), but tidal forces are inversely proportional to the cube of the distance. The ocean surface moves because of the changing tidal equipotential, rising when the tidal potential is high, which occurs on the parts of the Earth nearest to and furthest from the Moon. When the tidal equipotential changes, the ocean surface is no longer aligned with it, so the apparent direction of the vertical shifts. The surface then experiences a down slope, in the direction that the equipotential has risen.
Laplace's tidal equations.
Ocean depths are much smaller than their horizontal extent. Thus, the response to tidal forcing can be modelled using the Laplace tidal equations which incorporate the following features:
The boundary conditions dictate no flow across the coastline and free slip at the bottom.
The Coriolis effect (inertial force) steers flows moving towards the equator to the west and flows moving away from the equator toward the east, allowing coastally trapped waves. Finally, a dissipation term can be added which is an analog to viscosity.
Amplitude and cycle time.
The theoretical amplitude of oceanic tides caused by the moon is about 54 cm at the highest point, which corresponds to the amplitude that would be reached if the ocean possessed a uniform depth, there were no landmasses, and the Earth were rotating in step with the moon's orbit. The sun similarly causes tides, of which the theoretical amplitude is about 25 cm (46% of that of the moon) with a cycle time of 12 hours. At spring tide the two effects add to each other to a theoretical level of 79 cm, while at neap tide the theoretical level is reduced to 29 cm. Since the orbits of the Earth about the sun, and the moon about the Earth, are elliptical, tidal amplitudes change somewhat as a result of the varying Earth–sun and Earth–moon distances. This causes a variation in the tidal force and theoretical amplitude of about ±18% for the moon and ±5% for the sun. If both the sun and moon were at their closest positions and aligned at new moon, the theoretical amplitude would reach 93 cm.
Real amplitudes differ considerably, not only because of depth variations and continental obstacles, but also because wave propagation across the ocean has a natural period of the same order of magnitude as the rotation period: if there were no land masses, it would take about 30 hours for a long wavelength surface wave to propagate along the equator halfway around the Earth (by comparison, the Earth's lithosphere has a natural period of about 57 minutes). Earth tides, which raise and lower the bottom of the ocean, and the tide's own gravitational self attraction are both significant and further complicate the ocean's response to tidal forces.
Dissipation.
Earth's tidal oscillations introduce dissipation at an average rate of about 3.75 terawatts.
About 98% of this dissipation is by marine tidal movement.
Dissipation arises as basin-scale tidal flows drive smaller-scale flows which experience turbulent dissipation. This tidal drag creates torque on the moon that gradually transfers angular momentum to its orbit, and a gradual increase in Earth–moon separation. The equal and opposite torque on the Earth correspondingly decreases its rotational velocity. Thus, over geologic time, the moon recedes from the Earth, at about 3.8 cm/year, lengthening the terrestrial day.
Day length has increased by about 2 hours in the last 600 million years. Assuming (as a crude approximation) that the deceleration rate has been constant, this would imply that 70 million years ago, day length was on the order of 1% shorter with about 4 more days per year.
Observation and prediction.
History.
From ancient times, tidal observation and discussion has increased in sophistication, first marking the daily recurrence, then tides' relationship to the sun and moon. Pytheas travelled to the British Isles about 325 BC and seems to be the first to have related spring tides to the phase of the moon.
In the 2nd century BC, the Babylonian astronomer, Seleucus of Seleucia, correctly described the phenomenon of tides in order to support his heliocentric theory. He correctly theorized that tides were caused by the moon, although he believed that the interaction was mediated by the pneuma. He noted that tides varied in time and strength in different parts of the world. According to Strabo (1.1.9), Seleucus was the first to link tides to the lunar attraction, and that the height of the tides depends on the moon's position relative to the sun.
The "Naturalis Historia" of Pliny the Elder collates many tidal observations, e.g., the spring tides are a few days after (or before) new and full moon and are highest around the equinoxes, though Pliny noted many relationships now regarded as fanciful. In his "Geography", Strabo described tides in the Persian Gulf having their greatest range when the moon was furthest from the plane of the equator. All this despite the relatively small amplitude of Mediterranean basin tides. (The strong currents through the Euripus Strait and the Strait of Messina puzzled Aristotle.) Philostratus discussed tides in Book Five of "The Life of Apollonius of Tyana". Philostratus mentions the moon, but attributes tides to "spirits". In Europe around 730 AD, the Venerable Bede described how the rising tide on one coast of the British Isles coincided with the fall on the other and described the time progression of high water along the Northumbrian coast.
The first tide table in China was recorded in 1056 AD primarily for visitors wishing to see the famous tidal bore in the Qiantang River. The first known British tide table is thought to be that of John Wallingford, who died Abbot of St. Albans in 1213, based on high water occurring 48 minutes later each day, and three hours earlier at the Thames mouth than upriver at London.
William Thomson (Lord Kelvin) led the first systematic harmonic analysis of tidal records starting in 1867. The main result was the building of a tide-predicting machine using a system of pulleys to add together six harmonic time functions. It was "programmed" by resetting gears and chains to adjust phasing and amplitudes. Similar machines were used until the 1960s.
The first known sea-level record of an entire spring–neap cycle was made in 1831 on the Navy Dock in the Thames Estuary. Many large ports had automatic tide gage stations by 1850.
William Whewell first mapped co-tidal lines ending with a nearly global chart in 1836. In order to make these maps consistent, he hypothesized the existence of amphidromes where co-tidal lines meet in the mid-ocean. These points of no tide were confirmed by measurement in 1840 by Captain Hewett, RN, from careful soundings in the North Sea.
Timing.
The tidal forces due to the Moon and Sun generate very long waves which travel all around the ocean following the paths shown in co-tidal charts. The time when the crest of the wave reaches a port then gives the time of high water at the port. The time taken for the wave to travel around the ocean also means that there is a delay between the phases of the moon and their effect on the tide. Springs and neaps in the North Sea, for example, are two days behind the new/full moon and first/third quarter moon. This is called the tide's "age".
The ocean bathymetry greatly influences the tide's exact time and height at a particular coastal point. There are some extreme cases; the Bay of Fundy, on the east coast of Canada, is often stated to have the world's highest tides because of its shape, bathymetry, and its distance from the continental shelf edge. Measurements made in November 1998 at Burntcoat Head in the Bay of Fundy recorded a maximum range of 16.3 m and a highest predicted extreme of 17 m.
Similar measurements made in March 2002 at Leaf Basin, Ungava Bay in northern Quebec gave similar values (allowing for measurement errors), a maximum range of 16.2 m and a highest predicted extreme of 16.8 m. Ungava Bay and the Bay of Fundy lie similar distances from the continental shelf edge, but Ungava Bay is free of pack ice for only about four months every year while the Bay of Fundy rarely freezes.
Southampton in the United Kingdom has a double high water caused by the interaction between the region's different tidal harmonics, caused primarily by the east/west orientation of the English Channel and the fact that when it is high water at Dover it is low water at Land's End (some 300 nautical miles distant) and vice versa. This is contrary to the popular belief that the flow of water around the Isle of Wight creates two high waters. The Isle of Wight is important, however, since it is responsible for the 'Young Flood Stand', which describes the pause of the incoming tide about three hours after low water.
Because the oscillation modes of the Mediterranean Sea and the Baltic Sea do not coincide with any significant astronomical forcing period, the largest tides are close to their narrow connections with the Atlantic Ocean. Extremely small tides also occur for the same reason in the Gulf of Mexico and Sea of Japan. Elsewhere, as along the southern coast of Australia, low tides can be due to the presence of a nearby amphidrome.
Analysis.
Isaac Newton's theory of gravitation first enabled an explanation of why there were generally two tides a day, not one, and offered hope for detailed understanding. Although it may seem that tides could be predicted via a sufficiently detailed knowledge of the instantaneous astronomical forcings, the actual tide at a given location is determined by astronomical forces accumulated over many days. Precise results require detailed knowledge of the shape of all the ocean basins—their bathymetry and coastline shape.
Current procedure for analysing tides follows the method of harmonic analysis introduced in the 1860s by William Thomson. It is based on the principle that the astronomical theories of the motions of sun and moon determine a large number of component frequencies, and at each frequency there is a component of force tending to produce tidal motion, but that at each place of interest on the Earth, the tides respond at each frequency with an amplitude and phase peculiar to that locality. At each place of interest, the tide heights are therefore measured for a period of time sufficiently long (usually more than a year in the case of a new port not previously studied) to enable the response at each significant tide-generating frequency to be distinguished by analysis, and to extract the tidal constants for a sufficient number of the strongest known components of the astronomical tidal forces to enable practical tide prediction. The tide heights are expected to follow the tidal force, with a constant amplitude and phase delay for each component. Because astronomical frequencies and phases can be calculated with certainty, the tide height at other times can then be predicted once the response to the harmonic components of the astronomical tide-generating forces has been found.
The main patterns in the tides are
The "Highest Astronomical Tide" is the perigean spring tide when both the sun and the moon are closest to the Earth.
When confronted by a periodically varying function, the standard approach is to employ Fourier series, a form of analysis that uses sinusoidal functions as a "basis" set, having frequencies that are zero, one, two, three, etc. times the frequency of a particular fundamental cycle. These multiples are called "harmonics" of the fundamental frequency, and the process is termed harmonic analysis. If the basis set of sinusoidal functions suit the behaviour being modelled, relatively few harmonic terms need to be added. Orbital paths are very nearly circular, so sinusoidal variations are suitable for tides.
For the analysis of tide heights, the Fourier series approach has in practice to be made more elaborate than the use of a single frequency and its harmonics. The tidal patterns are decomposed into many sinusoids having many fundamental frequencies, corresponding (as in the lunar theory) to many different combinations of the motions of the Earth, the moon, and the angles that define the shape and location of their orbits.
For tides, then, "harmonic analysis" is not limited to harmonics of a single frequency. In other words, the harmonies are multiples of many fundamental frequencies, not just of the fundamental frequency of the simpler Fourier series approach. Their representation as a Fourier series having only one fundamental frequency and its (integer) multiples would require many terms, and would be severely limited in the time-range for which it would be valid.
The study of tide height by harmonic analysis was begun by Laplace, William Thomson (Lord Kelvin), and George Darwin. A.T. Doodson extended their work, introducing the "Doodson Number" notation to organise the hundreds of resulting terms. This approach has been the international standard ever since, and the complications arise as follows: the tide-raising force is notionally given by sums of several terms. Each term is of the form
where A is the amplitude, ω is the angular frequency usually given in degrees per hour corresponding to t measured in hours, and p is the phase offset with regard to the astronomical state at time "t" = 0 . There is one term for the moon and a second term for the sun. The phase p of the first harmonic for the moon term is called the lunitidal interval or high water interval. The next step is to accommodate the harmonic terms due to the elliptical shape of the orbits. Accordingly, the value of A is not a constant but also varying with time, slightly, about some average figure. Replace it then by A(t) where A is another sinusoid, similar to the cycles and epicycles of Ptolemaic theory. Accordingly,
which is to say an average value A with a sinusoidal variation about it of magnitude Aa, with frequency ωa and phase pa. Thus the simple term is now the product of two cosine factors:
Given that for any x and y
it is clear that a compound term involving the product of two cosine terms each with their own frequency is the same as "three" simple cosine terms that are to be added at the original frequency and also at frequencies which are the sum and difference of the two frequencies of the product term. (Three, not two terms, since the whole expression is formula_5.) Consider further that the tidal force on a location depends also on whether the moon (or the sun) is above or below the plane of the equator, and that these attributes have their own periods also incommensurable with a day and a month, and it is clear that many combinations result. With a careful choice of the basic astronomical frequencies, the Doodson Number annotates the particular additions and differences to form the frequency of each simple cosine term.
Remember that astronomical tides do "not" include weather effects. Also, changes to local conditions (sandbank movement, dredging harbour mouths, etc.) away from those prevailing at the measurement time affect the tide's actual timing and magnitude. Organisations quoting a "highest astronomical tide" for some location may exaggerate the figure as a safety factor against analytical uncertainties, distance from the nearest measurement point, changes since the last observation time, ground subsidence, etc., to avert liability should an engineering work be overtopped. Special care is needed when assessing the size of a "weather surge" by subtracting the astronomical tide from the observed tide.
Careful Fourier data analysis over a nineteen-year period (the "National Tidal Datum Epoch" in the U.S.) uses frequencies called the "tidal harmonic constituents". Nineteen years is preferred because the Earth, moon and sun's relative positions repeat almost exactly in the Metonic cycle of 19 years, which is long enough to include the 18.613 year lunar nodal tidal constituent. This analysis can be done using only the knowledge of the forcing "period", but without detailed understanding of the mathematical derivation, which means that useful tidal tables have been constructed for centuries. The resulting amplitudes and phases can then be used to predict the expected tides. These are usually dominated by the constituents near 12 hours (the "semi-diurnal" constituents), but there are major constituents near 24 hours ("diurnal") as well. Longer term constituents are 14 day or "fortnightly", monthly, and semiannual. Semi-diurnal tides dominated coastline, but some areas such as the South China Sea and the Gulf of Mexico are primarily diurnal. In the semi-diurnal areas, the primary constituents "M"2 (lunar) and "S"2 (solar) periods differ slightly, so that the relative phases, and thus the amplitude of the combined tide, change fortnightly (14 day period).
In the "M"2 plot above, each cotidal line differs by one hour from its neighbors, and the thicker lines show tides in phase with equilibrium at Greenwich. The lines rotate around the amphidromic points counterclockwise in the northern hemisphere so that from Baja California Peninsula to Alaska and from France to Ireland the "M"2 tide propagates northward. In the southern hemisphere this direction is clockwise. On the other hand "M"2 tide propagates counterclockwise around New Zealand, but this is because the islands act as a dam and permit the tides to have different heights on the islands' opposite sides. (The tides do propagate northward on the east side and southward on the west coast, as predicted by theory.)
The exception is at Cook Strait where the tidal currents periodically link high to low water. This is because cotidal lines 180° around the amphidromes are in opposite phase, for example high water across from low water at each end of Cook Strait. Each tidal constituent has a different pattern of amplitudes, phases, and amphidromic points, so the "M"2 patterns cannot be used for other tide components.
Example calculation.
Because the moon is moving in its orbit around the earth and in the same sense as the Earth's rotation, a point on the earth must rotate slightly further to catch up so that the time between semidiurnal tides is not twelve but 12.4206 hours—a bit over twenty-five minutes extra. The two peaks are not equal. The two high tides a day alternate in maximum heights: lower high (just under three feet), higher high (just over three feet), and again lower high. Likewise for the low tides.
When the Earth, moon, and sun are in line (sun–Earth–moon, or sun–moon–Earth) the two main influences combine to produce spring tides; when the two forces are opposing each other as when the angle moon–Earth–sun is close to ninety degrees, neap tides result. As the moon moves around its orbit it changes from north of the equator to south of the equator. The alternation in high tide heights becomes smaller, until they are the same (at the lunar equinox, the moon is above the equator), then redevelop but with the other polarity, waxing to a maximum difference and then waning again.
Current.
The tides' influence on current flow is much more difficult to analyse, and data is much more difficult to collect. A tidal height is a simple number which applies to a wide region simultaneously. A flow has both a magnitude and a direction, both of which can vary substantially with depth and over short distances due to local bathymetry. Also, although a water channel's center is the most useful measuring site, mariners object when current-measuring equipment obstructs waterways. A flow proceeding up a curved channel is the same flow, even though its direction varies continuously along the channel. Surprisingly, flood and ebb flows are often not in opposite directions. Flow direction is determined by the upstream channel's shape, not the downstream channel's shape. Likewise, eddies may form in only one flow direction.
Nevertheless, current analysis is similar to tidal analysis: in the simple case, at a given location the flood flow is in mostly one direction, and the ebb flow in another direction. Flood velocities are given positive sign, and ebb velocities negative sign. Analysis proceeds as though these are tide heights.
In more complex situations, the main ebb and flood flows do not dominate. Instead, the flow direction and magnitude trace an ellipse over a tidal cycle (on a polar plot) instead of along the ebb and flood lines. In this case, analysis might proceed along pairs of directions, with the primary and secondary directions at right angles. An alternative is to treat the tidal flows as complex numbers, as each value has both a magnitude and a direction.
Tide flow information is most commonly seen on nautical charts, presented as a table of flow speeds and bearings at hourly intervals, with separate tables for spring and neap tides. The timing is relative to high water at some harbour where the tidal behaviour is similar in pattern, though it may be far away.
As with tide height predictions, tide flow predictions based only on astronomical factors do not incorporate weather conditions, which can "completely" change the outcome.
The tidal flow through Cook Strait between the two main islands of New Zealand is particularly interesting, as the tides on each side of the strait are almost exactly out of phase, so that one side's high water is simultaneous with the other's low water. Strong currents result, with almost zero tidal height change in the strait's center. Yet, although the tidal surge normally flows in one direction for six hours and in the reverse direction for six hours, a particular surge might last eight or ten hours with the reverse surge enfeebled. In especially boisterous weather conditions, the reverse surge might be entirely overcome so that the flow continues in the same direction through three or more surge periods.
A further complication for Cook Strait's flow pattern is that the tide at the north side (e.g. at Nelson) follows the common bi-weekly spring–neap tide cycle (as found along the west side of the country), but the south side's tidal pattern has only "one" cycle per month, as on the east side: Wellington, and Napier.
The graph of Cook Strait's tides shows separately the high water and low water height and time, through November 2007; these are "not" measured values but instead are calculated from tidal parameters derived from years-old measurements. Cook Strait's nautical chart offers tidal current information. For instance the January 1979 edition for 41°13·9’S 174°29·6’E (north west of Cape Terawhiti) refers timings to Westport while the January 2004 issue refers to Wellington. Near Cape Terawhiti in the middle of Cook Strait the tidal height variation is almost nil while the tidal current reaches its maximum, especially near the notorious Karori Rip. Aside from weather effects, the actual currents through Cook Strait are influenced by the tidal height differences between the two ends of the strait and as can be seen, only one of the two spring tides at the north end (Nelson) has a counterpart spring tide at the south end (Wellington), so the resulting behaviour follows neither reference harbour.
Power generation.
Tidal energy can be extracted by two means: inserting a water turbine into a tidal current, or building ponds that release/admit water through a turbine. In the first case, the energy amount is entirely determined by the timing and tidal current magnitude. However, the best currents may be unavailable because the turbines would obstruct ships. In the second, the impoundment dams are expensive to construct, natural water cycles are completely disrupted, ship navigation is disrupted. However, with multiple ponds, power can be generated at chosen times. So far, there are few installed systems for tidal power generation (most famously, La Rance at Saint Malo, France) which face many difficulties. Aside from environmental issues, simply withstanding corrosion and biological fouling pose engineering challenges.
Tidal power proponents point out that, unlike wind power systems, generation levels can be reliably predicted, save for weather effects. While some generation is possible for most of the tidal cycle, in practice turbines lose efficiency at lower operating rates. Since the power available from a flow is proportional to the cube of the flow speed, the times during which high power generation is possible are brief.
Navigation.
Tidal flows are important for navigation, and significant errors in position occur if they are not accommodated. Tidal heights are also important; for example many rivers and harbours have a shallow "bar" at the entrance which prevents boats with significant draft from entering at low tide.
Until the advent of automated navigation, competence in calculating tidal effects was important to naval officers. The certificate of examination for lieutenants in the Royal Navy once declared that the prospective officer was able to "shift his tides".
Tidal flow timings and velocities appear in "tide charts" or a tidal stream atlas. Tide charts come in sets. Each chart covers a single hour between one high water and another (they ignore the leftover 24 minutes) and show the average tidal flow for that hour. An arrow on the tidal chart indicates the direction and the average flow speed (usually in knots) for spring and neap tides. If a tide chart is not available, most nautical charts have "tidal diamonds" which relate specific points on the chart to a table giving tidal flow direction and speed.
The standard procedure to counteract tidal effects on navigation is to (1) calculate a "dead reckoning" position (or DR) from travel distance and direction, (2) mark the chart (with a vertical cross like a plus sign) and (3) draw a line from the DR in the tide's direction. The distance the tide moves the boat along this line is computed by the tidal speed, and this gives an "estimated position" or EP (traditionally marked with a dot in a triangle).
Nautical charts display the water's "charted depth" at specific locations with "soundings" and the use of bathymetric contour lines to depict the submerged surface's shape. These depths are relative to a "chart datum", which is typically the water level at the lowest possible astronomical tide (although other datums are commonly used, especially historically, and tides may be lower or higher for meteorological reasons) and are therefore the minimum possible water depth during the tidal cycle. "Drying heights" may also be shown on the chart, which are the heights of the exposed seabed at the lowest astronomical tide.
Tide tables list each day's high and low water heights and times. To calculate the actual water depth, add the charted depth to the published tide height. Depth for other times can be derived from tidal curves published for major ports. The rule of twelfths can suffice if an accurate curve is not available. This approximation presumes that the increase in depth in the six hours between low and high water is: first hour — 1/12, second — 2/12, third — 3/12, fourth — 3/12, fifth — 2/12, sixth — 1/12.
Biological aspects.
Intertidal ecology.
Intertidal ecology is the study of intertidal ecosystems, where organisms live between the low and high water lines. At low water, the intertidal is exposed (or 'emersed') whereas at high water, the intertidal is underwater (or 'immersed'). Intertidal ecologists therefore study the interactions between intertidal organisms and their environment, as well as among the different species. The most important interactions may vary according to the type of intertidal community. The broadest classifications are based on substrates — rocky shore or soft bottom.
Intertidal organisms experience a highly variable and often hostile environment, and have adapted to cope with and even exploit these conditions. One easily visible feature is vertical zonation, in which the community divides into distinct horizontal bands of specific species at each elevation above low water. A species' ability to cope with desiccation determines its upper limit, while competition with other species sets its lower limit.
Humans use intertidal regions for food and recreation. Overexploitation can damage intertidals directly. Other anthropogenic actions such as introducing invasive species and climate change have large negative effects. Marine Protected Areas are one option communities can apply to protect these areas and aid scientific research.
Biological rhythms.
The approximately fortnightly tidal cycle has large effects on intertidal and marine organisms. Hence their biological rhythms tend to occur in rough multiples of this period. Many other animals such as the vertebrates, display similar rhythms. Examples include gestation and egg hatching. In humans, the menstrual cycle lasts roughly a lunar month, an even multiple of the tidal period. Such parallels at least hint at the common descent of all animals from a marine ancestor.
Other tides.
When oscillating tidal currents in the stratified ocean flow over uneven bottom topography, they generate internal waves with tidal frequencies. Such waves are called "internal tides".
Shallow areas in otherwise open water can experience rotary tidal currents, flowing in directions that continually change and thus the flow direction (not the flow) completes a full rotation in 12½ hours (for example, the Nantucket Shoals).
In addition to oceanic tides, large lakes can experience small tides and even planets can experience "atmospheric tides" and "Earth tides". These are continuum mechanical phenomena. The first two take place in fluids. The third affects the Earth's thin solid crust surrounding its semi-liquid interior (with various modifications).
Lake tides.
Large lakes such as Superior and Erie can experience tides of 1 to 4 cm, but these can be masked by meteorologically induced phenomena such as seiche. The tide in Lake Michigan is described as 0.5 to or 1¾ inches.
Atmospheric tides.
Atmospheric tides are negligible at ground level and aviation altitudes, masked by weather's much more important effects. Atmospheric tides are both gravitational and thermal in origin and are the dominant dynamics from about 80 to, above which the molecular density becomes too low to support fluid behavior.
Earth tides.
Earth tides or terrestrial tides affect the entire Earth's mass, which acts similarly to a liquid gyroscope with a very thin crust. The Earth's crust shifts (in/out, east/west, north/south) in response to lunar and solar gravitation, ocean tides, and atmospheric loading. While negligible for most human activities, terrestrial tides' semi-diurnal amplitude can reach about 55 cm at the equator—15 cm due to the sun—which is important in GPS calibration and VLBI measurements. Precise astronomical angular measurements require knowledge of the Earth's rotation rate and nutation, both of which are influenced by Earth tides. The semi-diurnal "M"2 Earth tides are nearly in phase with the moon with a lag of about two hours.
Some particle physics experiments must adjust for terrestrial tides. For instance, at CERN and SLAC, the very large particle accelerators account for terrestrial tides. Among the relevant effects are circumference deformation for circular accelerators and particle beam energy. Since tidal forces generate currents in conducting fluids in the Earth's interior, they in turn affect the Earth's magnetic field. Earth tides have also been linked to the triggering of earthquakes. See also earthquake prediction.
Galactic tides.
"Galactic tides" are the tidal forces exerted by galaxies on stars within them and satellite galaxies orbiting them. The galactic tide's effects on the Solar System's Oort cloud are believed to cause 90 percent of long-period comets.
Misapplications.
Tsunamis, the large waves that occur after earthquakes, are sometimes called "tidal waves", but this name is given by their "resemblance" to the tide, rather than any actual link to the tide. Other phenomena unrelated to tides but using the word "tide" are rip tide, storm tide, hurricane tide, and black or red tides.

</doc>
<doc id="30719" url="http://en.wikipedia.org/wiki?curid=30719" title="Tidal force">
Tidal force

The tidal force is a secondary effect of the force of gravity and is responsible for the tides. It arises because the gravitational force exerted by one body on another is not constant across it; the nearest side is attracted more strongly than the farthest side. Thus, the tidal force is differential. Consider the gravitational attraction of the moon on the oceans nearest the moon, the solid Earth and the oceans farthest from the moon. There is a mutual attraction between the moon and the solid earth which can be considered to act on its centre of mass. However, the near oceans are more strongly attracted and, since they are fluid, they approach the moon slightly, causing a high tide. The far oceans are attracted less. The attraction on the far-side oceans could be expected to cause a low tide but since the solid earth is attracted (accelerated) more strongly towards the moon, there is a "relative" acceleration of those waters in the outwards direction. Viewing the Earth as a whole, we see that all its mass experiences a mutual attraction with that of the moon but the near oceans more so than the far oceans, leading to a separation of the two.
In a more general usage in celestial mechanics, the expression 'tidal force' can refer to a situation in which a body or material (for example, tidal water) is mainly under the gravitational influence of a second body (for example, the Earth), but is also perturbed by the gravitational effects of a third body (for example, the Moon). The perturbing force is sometimes in such cases called a tidal force (for example, the perturbing force on the Moon): it is the difference between the force exerted by the third body on the second and the force exerted by the third body on the first.
Explanation.
When a body (body 1) is acted on by the gravity of another body (body 2), the field can vary significantly on body 1 between the side of the body facing body 2 and the side facing away from body 2. Figure 2 shows the differential force of gravity on a spherical body (body 1) exerted by another body (body 2). These so-called "tidal forces" cause strains on both bodies and may distort them or even, in extreme cases, break one or the other apart. The Roche limit is the distance from a planet at which tidal effects would cause an object to disintegrate because the differential force of gravity from the planet overcomes the attraction of the parts of the object for one another. These strains would not occur if the gravitational field were uniform, because a uniform field only causes the entire body to accelerate together in the same direction and at the same rate.
Effects of tidal forces.
In the case of an infinitesimally small elastic sphere, the effect of a tidal force is to distort the shape of the body without any change in volume. The sphere becomes an ellipsoid with two bulges, pointing towards and away from the other body. Larger objects distort into an ovoid, and are slightly compressed, which is what happens to the Earth's oceans under the action of the Moon. The Earth and Moon rotate about their common center of mass or barycenter, and their gravitational attraction provides the centripetal force necessary to maintain this motion. To an observer on the Earth, very close to this barycenter, the situation is one of the Earth as body 1 acted upon by the gravity of the Moon as body 2. All parts of the Earth are subject to the Moon's gravitational forces, causing the water in the oceans to redistribute, forming bulges on the sides near the Moon and far from the Moon.
When a body rotates while subject to tidal forces, internal friction results in the gradual dissipation of its rotational kinetic energy as heat. If the body is close enough to its primary, this can result in a rotation which is tidally locked to the orbital motion, as in the case of the Earth's moon. Tidal heating produces dramatic volcanic effects on Jupiter's moon Io. Stresses caused by tidal forces also cause a regular monthly pattern of moonquakes on Earth's Moon.
Tidal forces contribute to ocean currents, which moderate global temperatures by transporting heat energy toward the poles. It has been suggested that in addition to other factors, harmonic beat variations in tidal forcing may contribute to climate changes.
Tidal effects become particularly pronounced near small bodies of high mass, such as neutron stars or black holes, where they are responsible for the "spaghettification" of infalling matter. Tidal forces create the oceanic tide of Earth's oceans, where the attracting bodies are the Moon and, to a lesser extent, the Sun.
Tidal forces are also responsible for tidal locking and tidal acceleration.
Mathematical treatment.
For a given (externally generated) gravitational field, the tidal acceleration at a point with respect to a body is obtained by vectorially subtracting the gravitational acceleration at the center of the body (due to the given externally generated field) from the gravitational acceleration (due to the same field) at the given point. Correspondingly, the term tidal force is used to describe the forces due to tidal acceleration. Note that for these purposes the only gravitational field considered is the external one; the gravitational field of the body (as shown in the graphic) is not relevant. (In other words the comparison is with the conditions at the given point as they would be if there were no externally generated field acting unequally at the given point and at the center of the reference body. The externally generated field is usually that produced by a perturbing third body, often the Sun or the Moon in the frequent example-cases of points on or above the Earth's surface in a geocentric reference frame.)
Tidal acceleration does not require rotation or orbiting bodies; for example, the body may be freefalling in a straight line under the influence of a gravitational field while still being influenced by (changing) tidal acceleration.
By Newton's law of universal gravitation and laws of motion, a body of mass "m" at distance "R" from the center of a sphere of mass "M" feels a force formula_1,
equivalent to an acceleration formula_3,
where formula_5 is a unit vector pointing from the body "M" to the body "m" (here, acceleration from "m" towards "M" has negative sign).
Consider now the acceleration due to the sphere of mass "M" experienced by a particle in the vicinity of the body of mass "m". With "R" as the distance from the center of "M" to the center of "m", let ∆"r" be the (relatively small) distance of the particle from the center of the body of mass "m". For simplicity, distances are first considered only in the direction pointing towards or away from the sphere of mass "M". If the body of mass "m" is itself a sphere of radius ∆"r", then the new particle considered may be located on its surface, at a distance ("R" ± "∆r") from the centre of the sphere of mass "M", and "∆r" may be taken as positive where the particle's distance from "M" is greater than "R". Leaving aside whatever gravitational acceleration may be experienced by the particle towards "m" on account of "m"'s own mass, we have the acceleration on the particle due to gravitational force towards "M" as:
Pulling out the "R"2 term from the denominator gives:
The Maclaurin series of formula_8 is formula_9 which gives a series expansion of:
The first term is the gravitational acceleration due to "M" at the center of the reference body formula_11, i.e., at the point where formula_12 is zero. This term does not affect the observed acceleration of particles on the surface of "m" because with respect to "M", "m" (and everything on its surface) is in free fall. When the force on the far particle is subtracted from the force on the near particle, this first term cancels, as do all other even-order terms. The remaining (residual) terms represent the difference mentioned above and are tidal force (acceleration) terms. When ∆"r" is small compared to "R", the terms after the first residual term are very small and can be neglected, giving the approximate tidal acceleration formula_13(axial) for the distances ∆"r" considered, along the axis joining the centers of "m" and "M":
When calculated in this way for the case where ∆"r" is a distance along the axis joining the centers of "m" and "M", formula_13 is directed outwards from to the center of "m" (where ∆"r" is zero).
Tidal accelerations can also be calculated away from the axis connecting the bodies "m" and "M", requiring a vector calculation. In the plane perpendicular to that axis, the tidal acceleration is directed inwards (towards the center where ∆"r" is zero), and its magnitude is formula_17(axial)formula_18 in linear approximation as in Figure 2.
The tidal accelerations at the surfaces of planets in the Solar System are generally very small. For example, the lunar tidal acceleration at the Earth's surface along the Moon-Earth axis is about 1.1 × 10−7 g, while the solar tidal acceleration at the Earth's surface along the Sun-Earth axis is about 0.52 × 10−7 g, where g is the gravitational acceleration at the Earth's surface. Hence the tide-raising force (acceleration) due to the Sun is about 45% of that due to the Moon. The solar tidal acceleration at the Earth's surface was first given by Newton in the "Principia".

</doc>
<doc id="30722" url="http://en.wikipedia.org/wiki?curid=30722" title="Theremin">
Theremin

The theremin ( ; originally known as the ætherphone/etherphone, thereminophone or termenvox/thereminvox) is an early electronic musical instrument controlled without physical contact by the thereminist (performer). It is named after the Westernized name of its Russian inventor, Léon Theremin, who patented the device in 1928.
The instrument's controlling section usually consists of two metal antennas that sense the relative position of the thereminist's hands and control oscillators for frequency with one hand, and amplitude (volume) with the other. The electric signals from the theremin are amplified and sent to a loudspeaker.
The theremin was used in movie soundtracks such as Miklós Rózsa's for "Spellbound" and "The Lost Weekend" and Bernard Herrmann's for "The Day the Earth Stood Still" and as the theme tune for the ITV drama "Midsomer Murders". This has led to its association with a very eerie sound. Theremins are also used in concert music (especially avant-garde and 20th- and 21st-century new music) and in popular music genres such as rock. Psychedelic rock bands in particular, such as Hawkwind, have often used the theremin in their work.
On July 20, 2013, a group of 272 theremin players (Matryomin ensemble) in Hamamatsu, Shizuoka, Japan, achieved a Guinness world record as the largest theremin ensemble. () The name "Matryomin" is a portmanteau of the words "matryoshka" and "theremin".
History.
The theremin was originally the product of Soviet government-sponsored research into proximity sensors. The instrument was invented by a young Russian physicist named Lev Sergeevich Termen (known in the West as Léon Theremin) in October 1920 after the outbreak of the Russian Civil War. After a lengthy tour of Europe, during which time he demonstrated his invention to packed houses, Theremin found his way to the United States, where he patented his invention in 1928. Subsequently, Theremin granted commercial production rights to RCA.
Although the RCA Thereminvox (released immediately following the Stock Market Crash of 1929), was not a commercial success, it fascinated audiences in America and abroad. Clara Rockmore, a well-known thereminist, toured to wide acclaim, performing a classical repertoire in concert halls around the United States, often sharing the bill with Paul Robeson.
During the 1930s Lucie Bigelow Rosen was also taken with the theremin and together with her husband Walter Bigelow Rosen provided both financial and artistic support to the development and popularisation of the instrument.
In 1938, Theremin left the United States, though the circumstances related to his departure are in dispute. Many accounts claim he was taken from his New York City apartment by KGB agents, taken back to the Soviet Union and made to work in a "sharashka" laboratory prison camp at Magadan, Siberia. He reappeared 30 years later. In his 2000 biography of the inventor, "Theremin: Ether Music and Espionage", Albert Glinsky suggested the Russian had fled to escape crushing personal debts, and was then caught up in Stalin's political purges. In any case, Theremin did not return to the United States until 1991.
After a flurry of interest in America following the end of the Second World War, the theremin soon fell into disuse with serious musicians, mainly because newer electronic instruments were introduced that were easier to play. However, a niche interest in the theremin persisted, mostly among electronics enthusiasts and kit-building hobbyists. One of these electronics enthusiasts, Robert Moog, began building theremins in the 1950s, while he was a high-school student. Moog subsequently published a number of articles about building theremins, and sold theremin kits that were intended to be assembled by the customer. Moog credited what he learned from the experience as leading directly to his groundbreaking synthesizer, the Moog.
Since the release of the film "" in 1994, the instrument has enjoyed a resurgence in interest and has become more widely used by contemporary musicians. Even though many theremin sounds can be approximated on many modern synthesizers, some musicians continue to appreciate the expressiveness, novelty and uniqueness of using an actual theremin. The film itself has garnered excellent reviews.
Theremin kit building remains popular with electronics buffs; kits are available from Moog Music, Theremaniacs, Harrison Instruments, PAiA Electronics, and Jaycar. On the other end of the scale, many low-end Theremins, some of which have only pitch control, are offered online and offline, sometimes advertised as toys.
Operating principles.
The theremin is distinguished among musical instruments in that it is played without physical contact. The thereminist stands in front of the instrument and moves his or her hands in the proximity of two metal antennas. The distance from one antenna determines frequency (pitch), and the distance from the other controls amplitude (volume). Higher notes are played by moving the hand closer to the pitch antenna. Louder notes are played by moving the hand away from the volume antenna. Most frequently, the right hand controls the pitch and the left controls the volume, although some performers reverse this arrangement. Some low-cost theremins use a conventional, knob operated volume control and have only the pitch antenna. While commonly called antennas, they are not used for receiving or broadcasting radio waves, but act as plates of a capacitor.
The theremin uses the heterodyne principle to generate an audio signal. The instrument's pitch circuitry includes two radio frequency oscillators set below 500kc to minimize radio interference. One oscillator operates at a fixed frequency. The frequency of the other oscillator is controlled by the performer's distance from the pitch control antenna. The performer's hand acts as the grounded plate (the performer's body being the connection to ground) of a variable capacitor in an L-C (inductance-capacitance) circuit, which is part of the oscillator and determines its frequency. Some versions functioned with a change in capacitance between the performer and the instrument in the order of 0.01 picofarads to produce the full span of frequency shift. The difference between the frequencies of the two oscillators at each moment allows the creation of a difference tone in the audio frequency range, resulting in audio signals that are amplified and sent to a loudspeaker.
To control volume, the performer's other hand acts as the grounded plate of another variable capacitor. As in the tone circuit, the distance between the performer's hand and the volume control antenna determines the capacitance and hence natural resonant frequency of an LC circuit inductively coupled to another fixed LC oscillator circuit operating at a slightly higher resonant frequency. When a hand approaches the antenna, the natural frequency of that circuit is further lowered, which further detunes the connected oscillator and lowers its resonant plate current. The RF plate current of the oscillator is picked up by another winding and used to power the filament of another diode-connected triode, which thus acts as a variable conductance element changing the output amplitude. The harmonic timbre of the output, not being a pure tone, was an important feature of the theremin. Theremin's original design included audio frequency series/parallel LC equalization elements as well as a 3-winding variable-saturation transformer to control or induce harmonics in the audio output.
Modern circuit designs often simplify this circuit and avoid the complexity of two heterodyne oscillators by having a single pitch oscillator, akin to the original theremin's volume circuit. This approach is usually less stable and cannot generate the low frequencies that a heterodyne oscillator can. Better designs (e.g. Moog, Theremax) may use two pairs of heterodyne oscillators, for both pitch and volume.
Performance technique.
Important in theremin articulation is the use of the volume control antenna. Unlike touched instruments, where simply halting play or damping a resonator silences the instrument, the thereminist must "play the rests, as well as the notes", as Clara Rockmore observed. Although volume technique is less developed than pitch technique, some thereminists have worked to extend it, especially Pamelia Kurstin with her "walking bass" technique and Rupert Chappelle.
Recent versions of the theremin have been functionally updated: the Moog Ethervox, while functionally still a theremin, can also be used as a MIDI controller, and as such allows the artist to control any MIDI-compatible synthesizer with it, using the theremin's continuous pitch to drive modern synths. The Harrison Instruments Model 302 Theremin uses symmetrical horizontal plates instead of a vertical rod and horizontal loop to control pitch and volume, with the volume increasing as the hand approaches the plate.
The sound of the theremin has been described, by one critic, as "A cello lost in a dense fog, crying because it does not know how to get home."
Uses.
Concert music.
Concert composers who have written for theremin include Bohuslav Martinů, Percy Grainger, Christian Wolff, Joseph Schillinger, Moritz Eggert, Iraida Yusupova, Jorge Antunes, Vladimir Komarov, Anis Fuleihan, and Fazıl Say. Another large-scale theremin concerto is Kalevi Aho's Concerto for Theremin and Chamber Orchestra "Eight Seasons" (2011), written for Carolina Eyck.
Maverick composer Percy Grainger chose to use ensembles of four or six theremins (in preference to a string quartet) for his two earliest experimental "Free Music" compositions (1935–37) because of the instrument's complete 'gliding' freedom of pitch.
Musician Jean Michel Jarre used the instrument in his concerts Oxygen In Moscow and Space of Freedom in Gdańsk, providing also a short history of Léon Theremin's life.
The five-piece Spaghetti Western Orchestra use a Theremin as a replacement for Edda Dell'Orso's vocals in their interpretation of Ennio Morricone's "Once Upon a Time in the West".
Other notable contemporary Theremin players include Lydia Kavina, Pamelia Kurstin, and Barbara Buchholz. Dutch classical musician Thorwald Jørgensen has been described as "one of the most important exponents of classical music on the theremin".
Popular music.
Theremins and theremin-like sounds started to be incorporated into popular music from the end of the 1940s (with a series of Samuel Hoffman/Harry Revel collaborations) and this continued, with varying popularity, to the present.
While The Beach Boys' "Good Vibrations" features an instrument that sounds much like a Theremin, in fact the sound is made by an instrument called the Tannerin.
Jimmy Page of Led Zeppelin used a variation of the theremin (minus the loop) during performances of "Whole Lotta Love" and "No Quarter" throughout the performance history of Led Zeppelin, an extended multi-instrumental solo featuring theremin and bowed guitar in 1977, as well as the soundtrack for Death Wish II released in 1982. Brian Jones of The Rolling Stones also used the instrument on the group's 1967 albums "Between the Buttons" and "Their Satanic Majesties Request".
The Lothars are a Boston-area band formed in early 1997 whose CDs have featured as many as four theremins played at once – a first for pop music.
Although credited with a "Thereman" ["sic"] on the "Mysterons" track from the album "Dummy", Portishead actually used a monophonic synthesizer to achieve theremin-like effects, as confirmed by Adrian Utley, who is credited as playing the instrument; he has also created similar sounds on the songs "Half Day Closing", "Humming", "The Rip" and "Machine Gun".
Film music.
Russian composer Dmitri Shostakovich was one of the first to incorporate parts for the theremin in orchestral pieces, including a use in his score for the film "Odna" (Russian: "" – 1931, Leonid Trauberg and Grigori Kozintsev). While the theremin was not widely used in classical music performances, the instrument found great success in many motion pictures, notably, "Spellbound", "The Red House", "The Lost Weekend" (all three of which were written by Miklós Rózsa, the composer who pioneered the use of the instrument in Hollywood scores), "The Spiral Staircase", "Rocketship X-M", "The Day the Earth Stood Still", "The Thing (From Another World)", and "The Ten Commandments" (the 1956 DeMille film). The theremin is played and identified as such in use in the Jerry Lewis movie "The Delicate Delinquent". The theremin is prominent in the score for the 1956 short film "A Short Vision," which was aired on "The Ed Sullivan Show" the same year that it was used by the Hungarian composer Matyas Seiber. More recent appearances in film scores include "Monster House", "Ed Wood" and "The Machinist" (both featuring Lydia Kavina). The DVDs for "Ed Wood", "Bartleby" and "The Day the Earth Stood Still" and "Spellbound" (Criterion Collection) include short features on the theremin. Robby Virus, the founder and theremin player of the band Project:Pimento, was featured on the soundtrack to the movie "Hellboy" (2004).
A theremin was "not" used for the soundtrack of "Forbidden Planet", for which Louis and Bebe Barron built disposable oscillator circuits and a ring modulator to create the electronic tonalities used in the film.
Los Angeles-based thereminist Charles Richard Lester is featured on the soundtrack of "Monster House" and has performed the US premiere of Gavriil Popov's 1932 score for "Komsomol – Patron of Electrification" with the L. A. Philharmonic and Esa-Pekka Salonen in 2007.
In Lenny Abrahamson's 2014 film, "Frank", Clara, the character played by Maggie Gyllenhaal, plays the theremin in a band named soronprfbs.

</doc>
<doc id="30725" url="http://en.wikipedia.org/wiki?curid=30725" title="Thin client">
Thin client

A thin client (sometimes also called a lean, zero or slim client) is a computer or a computer program that depends heavily on another computer (its "server") to fulfill its computational roles. This is different from the traditional fat client, which is a computer designed to take on these roles by itself. The specific roles assumed by the server may vary, from providing data persistence (for example, for diskless nodes) to actual information processing on the client’s behalf.
Thin clients occur as components of a broader computer infrastructure, where many clients share their computations with the same server. As such, thin client infrastructures can be viewed as providing some computing service via several user interfaces. This is desirable in contexts where individual fat clients have much more functionality or power than the infrastructure requires.
Thin-client computing is also a way of easily maintaining computational services at a reduced total cost of ownership.
The most common type of modern thin client is a low-end computer terminal which only provides a graphical user interface – or more recently, in some cases, a web browser – to the end user.
History.
Thin clients have their roots in multi-user systems, traditionally mainframes accessed by some sort of terminal computer. As computer graphics matured, these terminals transitioned from providing a command-line interface to a full graphical user interface, as is common on modern advanced thin clients. The prototypical multiuser environment along these lines, Unix, began to support fully graphical X terminals, i.e., devices running display server software, from about 1984. X terminals remained relatively popular even after the arrival of other thin clients in the mid-late 1990s. Modern Unix derivatives like BSD and GNU/Linux continue the tradition of the multi-user, remote display/input session. Typically, X software is not made available on non-X-based thin clients, although no technical reason for this exclusion would prevent it.
Windows NT became capable of multi-user operations primarily through the efforts of Citrix Systems, which repackaged NT 3.5.1 as the multi-user operating system WinFrame in 1995. Microsoft licensed this technology back from Citrix and implemented it into Windows NT 4.0 Terminal Server Edition, under a project codenamed ‘Hydra’. Windows NT then became the basis of Windows 2000 and Windows XP. s of 2011[ [update]] Microsoft Windows systems support graphical terminals via the Remote Desktop Services component.
The term "thin client" was coined in 1993 by Tim Negris, VP of Server Marketing at Oracle Corp., while working with company founder Larry Ellison on the launch of Oracle 7. At the time, Oracle wished to differentiate their server oriented software from Microsoft’s desktop oriented products. Ellison subsequently popularized Negris’ buzzword with frequent use in his speeches and interviews about Oracle products.
The term stuck for several reasons. The earlier term ‘graphical terminal’ had been chosen to distinguish such terminals from text-based terminals, and thus put the emphasis heavily on "graphics - "which became obsolete as a distinguishing characteristic in the 1990s as text-only physical terminals themselves became obsolete, and text-only computer systems (a few of which existed in the 1980s) were no longer manufactured. The term ‘thin client’ also conveys better what was then viewed as the fundamental difference: thin clients can be designed with less expensive hardware, because they have reduced computational workloads.
By the 2010s, however, thin clients were not the only desktop devices for general purpose computing that were ‘thin’ - in the sense of having a small form factor and being relatively inexpensive. The Nettop form factor for desktop PCs was introduced, and nettops could run full feature Windows or Linux; tablets and tablet-laptop hybrids had also entered the market. However, while there was now little size difference, thin clients retained some key advantages over these competitors, such as not needing a local drive. However, ‘thin client’ can be a misnomer for slim form factor computers using flash memory such as compactflash, SD card, or permanent flash memory as a hard disc substitute.
Characteristics of thin clients.
Single point of failure.
The server, in taking on the whole processing load of several clients, forms a single point of failure for those clients. This has both positive and negative aspects. On one hand, the security threat model for the software becomes more focused on the servers. The clients do not run the software; therefore, only a small number of computers (the servers) need to be secured at a software level, rather than securing software installed on every single client computer (although client computers may still require physical security and strong authentication, to prevent unauthorised access, depending on requirements). On the other hand, any denial of service attack against the server will limit the access of many clients. The server software is typically written with virtual machine technology so every client is isolated and a client crash is easily handled and rebooted. The single point of failure can still exist, however. If the server crashes, data loss is possible.
For small networks, this single-point of failure property might be expanded. The hosting server can be integrated with file servers and print servers relevant to its clients. This can simplify the network and its maintenance, but might increase the risk against that server.
In practice, redundancy can be provided both in the form of additional connectivity from server to the network as well as in the servers themselves, using features like RAID, distributed servers (multiple networked servers appearing as one server to the users), clustered filesystems (which allow files to be accessed from multiple servers), VMWare High Availability and Fault Tolerance or Citrix XenApp's load balancing.
Cheap client hardware.
While the server must be robust enough to handle several client sessions at once, the clients can be assembled from much cheaper hardware than that of a fat client. Many clients have minimal RAM, some do not even have a hard drive. This reduces the power consumption of those clients, and makes the system marginally scalable, i.e. it is relatively cheap to connect additional client terminals. The thin clients usually have a very low total cost of ownership, but the need for a robust server infrastructure offsets some cost savings. Thin clients also generally use very low power and might not even require cooling fans, but the servers consume high power and almost always require an environmentally controlled air conditioned server room.
Client simplicity.
 Since the clients are made from low cost hardware with few moving parts, they can operate in more hostile environments than conventional computers. However, they inevitably need a network connection to their server, which must be isolated from such hostile environments. Since thin clients are cheap, they offer a low risk of theft in general, and are easy to replace if stolen or broken. Since they do not have any complicated boot images, the problem of boot image control is centralized to the server.
On the other hand, to achieve this simplicity, thin clients sometimes lag behind thick clients (PC Desktops) in terms of extensibility. For example, if a local software utility or set of device drivers are needed in order to support a locally attached peripheral device (e.g. printer, scanner, biometric security device), the thin client operating system may lack the resources needed to fully integrate the needed dependencies. Modern thin clients attempt to address this limitation via port mapping or USB redirection software. However, these methods cannot address all use case scenarios for the vast number of peripheral types being put to use today.
Slow bitmapped/animated graphics.
Thin clients tend to be optimized for use with simple lines, curves, and text, which can be rapidly drawn by the client using predefined stored procedures and cached bitmap data. In this regard, thin clients work well for basic office applications such as spreadsheets, word processing, data entry, and so forth.
However, all thin clients suffer performance problems when large areas of the graphics display must be updated rapidly with high detail bitmap graphics, which may also need to be redrawn several times per second for animation purposes. In a few cases it may be possible to use a video stream that was already previously compressed such as MPEG or H.264 video, but many graphical programs such as photo editors, 3D drawing programs, and animation tools require high detail uncompressed bitmaps to be displayed in order for the software to be used effectively. Graphics rich 3D games can be completely unusable on a thin client unless the updated screen area is kept very small or the overall screen resolution is very low, to reduce the amount of data sent to the client.
In an attempt to reduce network bandwidth, the server may try to compress high detail bitmaps on the fly before sending the data to the client, but this adds latency to the client-server communications, and may reduce user interface responsiveness. Many thin clients offer options to turn off various graphics rich user interface effects in order to increase performance, such as not showing the contents of a window while dragging or not displaying a desktop background.
Thin client variants.
Repurposing a PC as a thin client.
The following options allow a PC to be used as a thin client - in some cases, even if it has no working hard drive:
Ultra-thin client, zero client, or clientless.
Traditionally, a thin client ran a full operating system for the purposes of connecting to other computers. Some thin clients, such as the Sun Ray, use a simpler protocol for communicating display updates, and these are sometimes called ultra-thin clients or zero clients. Their tiny operating systems merely initialize the network, begin the networking protocol, handle display of the server's output, and transmit user input events. The full desktop is run remotely and the displayed graphics and text are compressed with either a remote display protocol such as PCoIP, or even just a video codec such as VP9 or Daala, and sent to the zero client. The client silicon is now much simpler and lower cost as all it requires is a video decoder and basic I/O.
RTE client.
A Run Time Environment (RTE) client contains task specific applications (e.g. Mozilla Firefox for Internet browsing) and only the minimal (often customized) underlying and supporting code (BIOS, firmware, kernel, libraries, plug-ins, etc.) to run only those applications. It contains all and only the code needed to accomplish its specific task, thus it is more than a zero client but less than a typical thin client computer. The RTE client does not have a general purpose operating system - it usually lacks shells (terminal windows), is not designed to be patched (updated online), has minimal connectivity to external resources, and is often found in read-only media (e.g. tamper resistant ROM chips, CD-ROM, etc.). Attempts to inject or run any other applications/processes/threads results in crashing the kernel (system). Due to the need to physically update the device, RTE clients are mostly found in stable environments demanding high security.
Web thin client.
Web thin clients only provide a web browser, and rely on web applications to provide general-purpose computing functionality. However, note that web applications may use web storage to store some data locally, e.g. for "offline mode", and they can perform significant processing tasks as well. Rich Internet Applications for instance may cross the boundary, and HTML5 Web Applications can leverage browsers as run-time environments through the use of a cache manifest or so called "packaged apps" (in Firefox OS and Chrome).
Examples of web thin clients include Chromebooks and Chromeboxes (which run Chrome OS) and phones running Firefox OS.
Chromebooks and Chromeboxes also have the capability of remote desktop using the free Chrome Remote Desktop browser extension, which means, other than being a web thin client, they can also be used as an ultra-thin client (see above) to access PC or Mac applications that do not run on the Chromebook directly. Indeed, they can be used as a web thin client and an ultra-thin-client simultaneously, with the user switching between web browser and PC or Mac application windows with a click.
Chromebooks are also able to store user documents locally - though, with the exception of media files (which have a dedicated player application to play them), all such files can only be opened and processed with web applications, since traditional desktop applications cannot be installed in Chrome OS.
Web thin clients are similar to RTE clients, but unlike first-generation RTE clients the operating system can typically be updated. Chrome OS, for example, automatically updates itself if its update servers (which are hosted by Google) are not blocked by a firewall - while still being tamper-resistant due to its use of Trusted Computing technologies.
Applications as thin clients.
The notion of a thin client extends indirectly to any client–server architecture, in which case, a thin client application is simply one which relies on its server to process most or all of its business logic. This idiom is relatively common for computer security reasons. A client obviously cannot be trusted with the logic that determines how trustworthy they are, because an adversary can circumvent that logic.
However, in web development in particular, many client applications are becoming fatter. This is due to the adoption of heavily client-side technologies like Flash and Ajax, which are themselves strongly driven by the highly interactive nature of Web 2.0 applications.

</doc>
<doc id="30731" url="http://en.wikipedia.org/wiki?curid=30731" title="Teleological argument">
Teleological argument

The teleological or physico-theological argument, also known as the argument from design, or intelligent design argument is an argument for the existence of God or, more generally, for an intelligent creator "based on perceived evidence of deliberate design in the natural or physical world". It is historically closely associated with the concept of Natural Theology.
The earliest recorded versions of this argument are associated with Socrates in ancient Greece, although it has been argued that he was taking up an older argument. Plato, his student, and Aristotle, Plato's student, developed complex approaches to the proposal that the cosmos has an intelligent cause, but it was the Stoics who, under their influence, "developed the battery of creationist arguments broadly known under the label "The Argument from Design"". 
Socratic philosophy influenced the development of the Abrahamic religions in many ways, and both types of teleological argument have a long tradition in them. In the Middle Ages, Islamic theologians such as Al Ghazali used the argument, although it was rejected as unnecessary by Quranic literalists, and as unconvincing by many Islamic philosophers. Later, the teleological argument was accepted by Saint Thomas Aquinas' and included as the fifth of his "Five Ways" of proving the existence of God. In early modern England clergymen such as William Turner and John Ray were well-known proponents. In the early 18th century, William Derham published his "Physico-Theology", which gave his "demonstration of the being and attributes of God from his works of creation". Later, William Paley, in his 1802 work on natural theology, published a prominent presentation of the design argument with his version of the watchmaker analogy and the first use of the phrase "argument from design". 
From the beginning, there have been numerous criticisms of the different versions of the teleological argument, and responses to its challenge to the claims against non-teleological natural science. Especially important were the general logical arguments made by David Hume in his "Dialogues Concerning Natural Religion", published 1779, and the explanation of biological complexity given in Charles Darwin's "Origin of Species", published in 1859. Since the 1960s, Paley's arguments, including the words "intelligent design", have been influential in the development of a creation science movement, especially the form known as the intelligent design movement, which not only uses the teleological argument to argue against the modern Darwinian understanding of evolution, but also makes the philosophical claim that it can provide a basis for scientific proof of the divine origin of biological species. 
Also starting already in classical Greece, two approaches to the teleological argument developed, distinguished by their understanding of whether the natural order was literally created or not. The non-creationist approach starts most clearly with Aristotle, although many thinkers, such as the Neoplatonists, believed it was already intended by Plato. This approach is not creationist in a simple sense, because while it agrees that a cosmic intelligence is responsible for the natural order, it rejects the proposal that this requires a "creator" to physically make and maintain this order. The Neoplatonists did not find the teleological argument convincing, and in this they were followed by medieval philosophers such as Al-Farabi and Avicenna. Later, Averroes and Thomas Aquinas considered the argument acceptable, but not necessarily the best argument. In contrast to the approach of such philosophers and theologians, the intelligent design movement makes a creationist claim for an intelligence that intervenes in the natural order.
History.
While the concept of an intelligence in the natural order goes back at least to the beginnings of philosophy and science, the concept of a designer of the natural world, or a creating intelligence which has human-like purposes, appears to have begun with classical philosophy. Religious thinkers in Judaism, Hinduism, Confucianism, Islam and Christianity also developed versions of the teleological argument. Later, variants on the argument from design were produced in Western philosophy and by Christian fundamentalism.
Classical philosophy.
Socrates and the pre-Socratics.
The argument from intelligent design appears to have begun with Socrates, although the concept of a cosmic intelligence is older and David Sedley has argued that Socrates was developing an older idea, citing Anaxagoras of Clazomenae, born about 500 BC, as a possible earlier proponent. The proposal that the order of nature showed evidence of having its own human-like "intelligence" goes back to the origins of Greek natural philosophy and science, and its attention to the orderliness of nature, often with special reference to the revolving of the heavens. Anaxagoras is the first person who is definitely known to have explained such a concept using the word "nous" (which is the original Greek term that leads to modern English "intelligence" via its Latin and French translations). Aristotle reports an earlier philosopher from Clazomenae named Hermotimus who had taken a similar position. Amongst Pre-Socratic philosophers before Anaxagoras, other philosophers had proposed a similar intelligent ordering principle causing life and the rotation of the heavens. For example Empedocles, like Hesiod much earlier, described cosmic order and living things as caused by a cosmic version of love, and Pythagoras and Heraclitus attributed the cosmos with "reason" ("logos"). In his "Philebus" 28c Plato has Socrates speak of this as a tradition, saying that "all philosophers agree—whereby they really exalt themselves—that mind ("nous") is king of heaven and earth. Perhaps they are right." and later states that the ensuing discussion "confirms the utterances of those who declared of old that mind ("nous") always rules the universe". 
Xenophon's report in his "Memorabilia" might be the earliest clear account of an argument that there is evidence in nature of intelligent design. The word traditionally translated and discussed as "design" is "gnōmē" and Socrates is reported by Xenophon to have pressed doubting young men to look at things in the market, and consider whether they could tell which things showed evidence of "gnōmē", and which seemed more to be by blind chance, and then to compare this to nature and consider whether it could be by blind chance. In Plato's "Phaedo", Socrates is made to say just before dying that his discovery of Anaxagoras' concept of a cosmic "nous" as the cause of the order of things, was an important turning point for him. But he also expressed disagreement with Anaxagoras' understanding of the implications of his own doctrine, because of Anaxagoras' materialist understanding of causation. Socrates complained that Anaxagoras restricted the work of the cosmic "nous" to the beginning, as if it were uninterested and all events since then just happened because of causes like air and water. Socrates, on the other hand, apparently insisted that the demiurge must be "loving", particularly concerning humanity. (In this desire to go beyond Anaxagoras and make the cosmic "nous" a more active manager, Socrates was apparently preceded by Diogenes of Apollonia.) 
Plato and Aristotle.
Plato's "Timaeus" is presented as a description of someone who is explaining a "likely story" in the form of a myth, and so throughout history commentators have disagreed about which elements of the myth can be seen as the position of Plato. Sedley nevertheless calls it "the creationist manifesto" and points out that although some of Plato's followers denied that he intended it, in classical times writers such as Aristotle, Epicurus, the Stoics and Galen all understood Plato as proposing the world originated in an "intelligent creative act". Plato has a character explain the concept of a "demiurge" with supreme wisdom and intelligence as the creator of the cosmos in his work . 
Plato's teleological perspective is also built upon the analysis of "a priori" order and structure in the world that he had already presented in "The Republic". The story does not propose creation "ex nihilo"; rather, the demiurge made order from the chaos of the cosmos, imitating the eternal Forms. 
 Plato's world of eternal and unchanging Forms, imperfectly represented in matter by a divine Artisan, contrasts sharply with the various mechanistic Weltanschauungen, of which atomism was, by the 4th century at least, the most prominent... This debate was to persist throughout the ancient world. Atomistic mechanism got a shot in the arm from Epicurus... while the Stoics adopted a divine teleology... The choice seems simple: either show how a structured, regular world could arise out of undirected processes, or inject intelligence into the system.
 — R. J. Hankinson, "Cause and Explanation in Ancient Greek Thought"
Plato's student and friend Aristotle (c. 384 – 322 BC), continued the Socratic tradition of criticising natural scientists such as Democritus who sought (as in modern science) to explain everything in terms of matter and chance motion. He was very influential in the future development of classical creationism, but was not a straightforward "creationist" because he required no creation interventions in nature, meaning he "insulated god from any requirement to intervene in nature, either as creator or as administrator". Instead of direct intervention by a creator it is "scarcely an exaggeration to say that for Aristotle the entire functioning of the natural world, as also the heavens, is ultimately to be understood as a shared striving towards godlike actuality". And whereas the myth in the "Timaeus" suggests that all living things are based on one single paradigm, not one for each species, and even tells a story of "devolution" whereby other living things devolved from humans, it was Aristotle who presented the influential idea that each type of normal living thing must be based on a fixed paradigm or form for that species.
Aristotle felt that biology was a particularly important example of a field where materialist natural science ignored information which was needed in order to understand living things well. For example birds use wings for the purpose of flight. Therefore the most complete explanation in regard to the natural, as well as the artificial, is for the most part teleological. In fact, proposals that species had changed by chance survival of the fittest, similar to what is now called "natural selection", were already known to Aristotle, and he rejected these with the same logic. He conceded that monstrosities (new forms of life) could come about by chance, but he disagreed with those who ascribed all nature purely to chance because he believed science can only provide a general account of that which is normal, "always, or for the most part". The distinction between what is normal, or by nature, and what is "accidental", or not by nature, is important in Aristotle's understanding of nature. As pointed out by Sedley, "Aristotle is happy to say ("Physics" II 8, 199a33-b4) without the slightest fear of blasphemy, crafts make occasional mistakes; therefore, by analogy, so can nature". According to Aristotle the changes which happen by nature are caused by their "formal causes", and for example in the case of a bird's wings there is also a final cause which is the purpose of flying. He explicitly compared this to human technology:
 If then what comes from art is for the sake of something, it is clear that what come from nature is too [...] This is clear most of all in the other animals, which do nothing by art, inquiry, or deliberation; for which reason some people are completely at a loss whether it is by intelligence or in some other way that spiders, ants, and such things work. [...] It is absurd to think that a thing does not happen for the sake of something if we do not see what sets it in motion deliberating. [...] This is most clear when someone practices medicine himself on himself; for nature is like that.
 — Aristotle, Physics, II 8.
The question of how to understand Aristotle's conception of nature having a purpose and direction something like human activity is controversial in the details. Martha Nussbaum for example has argued that in his biology this approach was practical and meant to show nature only being analogous to human art, explanations of an organ being greatly informed by knowledge of its essential function. Nevertheless, Nussbaum's position is not universally accepted. In any case, Aristotle was not understood this way by his followers in the Middle Ages, who saw him as consistent with monotheistic religion and a teleological understanding of all nature. Consistent with the medieval interpretation, in his "Metaphysics" and other works Aristotle clearly argued a case for their being one highest god or "prime mover" which was the ultimate cause, though specifically not the material cause, of the eternal forms or natures which cause the natural order, including all living things. And he clearly refers to this entity having an intellect that humans somehow share in, which helps humans see the true natures or forms of things without relying purely on sense perception of physical things, including living species. This understanding of nature, and Aristotle's arguments against materialist understandings of nature, were very influential in the Middle Ages in Europe. The idea of fixed species remained dominant in biology until Darwin, and a focus upon biology is still common today in teleological criticisms of modern science.
Roman era.
It was the Stoics who "developed the battery of creationist arguments broadly known under the label "The Argument from Design"". Cicero (c. 106 – c. 43 BC) reported the teleological argument of the Stoics in "De Natura Deorum (On the Nature of the Gods)" Book II, which includes an early version of the watchmaker analogy, which was later developed by William Paley.
 When you see a sundial or a water-clock, you see that it tells the time by design and not by chance. How then can you imagine that the universe as a whole is devoid of purpose and intelligence, when it embraces everything, including these artifacts themselves and their artificers?
 — Cicero, ""De Natura Deorum", ii. 34", M.T.Cicero"De natura Deorum"("the nature of the gods"),book II,XXIV
Another very important classical supporter of the teleological argument was Galen, whose compendious works were one of the major sources of medical knowledge until modern times, both in Europe and in Moslem lands. He was not a Stoic, but like them he looked back to the Socratics and was constantly engaged in arguing against atomists such as the Epicureans. Unlike Aristotle (who was however a major influence upon him), and unlike the Neoplatonists, he believed there was really evidence for something literally like the "demiurge" found in Plato's "Timaeus", which worked physical upon nature. In works such as especially his "On the Usefulness of Parts" he explained evidence for it in the complexity of animal construction. His work shows "early signs of contact and contrast between the pagan and the Judaeo-Christian tradition of creation", criticizing the account found in the Bible. "Moses, he suggests, would have contented himself with saying that God ordered the eyelashes not to grow and that they obeyed. In contrast to this, the Platonic tradition's Demiurge is above all else a technician." Surprisingly, neither Aristotle nor Plato are however considered by Galen as the best writer on this subject, but Xenophon. Galen shared with Xenophon a scepticism of the value of books about most speculative philosophy, except for inquiries such as whether there is "something in the world superior in power and wisdom to man". This he saw as having an everyday importance, a usefulness for living well. He also asserted that Xenophon was the author who reported the real position of Socrates, including his aloofness from many types of speculative science and philosophy.
Galen's connection of the teleological argument to discussions about the complexity of living things, and his insistence that this is possible for a practical scientist, foreshadows some aspects of modern uses of the teleological argument.
Medieval philosophy and theology.
Late classical Christian writers.
As an appeal to general revelation, Paul the Apostle (AD 5-67), argues in Romans 1:18-20, that because it has been made plain to all from what has been created in the world, it is obvious that there is a God.
Marcus Minucius Felix (c. late 2nd to 3rd century), an Early Christian writer, argued for the existence of God based on the analogy of an ordered house in his "The Orders of Minucius Felix": "Supposing you went into a house and found everything neat, orderly and well-kept, surely you would assume it had a master, and one
much better than the good things, his belongings ; so in this house of the universe, when throughout
heaven and earth you see the marks of foresight, order and law, may you not assume that the lord and
author of the universe is fairer than the stars themselves or than any portions of the entire world ?"
Augustine of Hippo (AD 354–430) in The City of God mentioned the idea that the world's "well-ordered changes and movements", and "the fair appearance of all visible things" was evidence for the world being created, and "that it could not have been created save by God".
Islamic philosophy.
Early Islamic philosophy played an important role in developing the philosophical understandings of God among Jewish and Christian thinkers in the Middle Ages, but concerning the teleological argument one of the lasting effects of this tradition came from its discussions of the difficulties which this type of proof has. Various forms of the argument from design have been used by Islamic theologians and philosophers from the time of the early Mutakallimun theologians in the 9th century, although it is rejected by fundamentalist or literalist schools, for whom the mention of God in the Koran should be sufficient evidence. The argument from design was also seen as an unconvincing sophism by the early Islamic philosopher Al-Farabi, who instead took the "emanationist" approach of the Neoplatonists such as Plotinus, whereby nature is rationally ordered, but God is not like a craftsman who literally manages the world. Later, Avicenna was also convinced of this, and proposed instead a cosmological argument for the existence of God. 
The argument was however later accepted by both the Aristotelian philosopher Averroes (Ibn Rushd) and his great anti-philosophy opponent Al-Ghazali. Averroes' term for the argument was "Dalīl al-ˁināya", which can be translated as "argument from providence". Both of them however accepted the argument "because" they believed it is explicitly mentioned in the Quran. Despite this, like Aristotle, the Neoplatonists, and Al-Farabi, Averroes proposed that order and continual motion in the world is caused by God's intellect. Whether Averroes was an "emanationist" like his predecessors has been a subject of disagreement and uncertainty. But it is generally agreed that what he adapted from those traditions, agreed with them about the fact that God does not create in the same was as a craftsman.
In fact then, Averroes treated the teleological argument as one of two "religious" arguments for the existence of God. The principal demonstrative proof is, according to Averroes, Aristotle's proof from motion in the universe that there must be a first mover which causes everything else to move. Averroes' position that the most logically valid proof should be physical rather than metaphysical (because then metaphysics would be proving itself) was in conscious opposition to the position of Avicenna. Later Jewish and Christian philosophers such as Thomas Aquinas were aware of this debate, and generally took a position closer to Avicenna.
Jewish philosophy.
An example of the teleological argument in Jewish philosophy appears when the medieval Aristotelian philosopher Maimonides cites the passage in Isaiah 40:26, where the "Holy One" says: "Lift up your eyes on high, and behold who hath created these things, that bringeth out their host by number:" However, Barry Holtz calls this "a crude form of the argument from design," and that this "is only one possible way of reading the text." He asserts that "Generally, in the biblical texts the existence of God is taken for granted."
Maimonides also recalled that Abraham (in the midrash, or explanatory text, of Genesis Rabbah 39:1) recognized the existence of "one transcendent deity from the fact that the world around him exhibits an order and design." The midrash makes an analogy between the obviousness that a building has an owner, and that the world is looked after by God. Abraham says "Is it conceivable that the world is without a guide?" Because of these examples, the 19th century philosopher Nachman Krochmal called the argument from design "a cardinal principle of the Jewish faith."
The American orthodox rabbi, Aryeh Kaplan, retells a legend about the 2nd century AD Rabbi Meir. When told by a philosopher that he did not believe that the world was created by God, the rabbi produced a beautiful poem that he claimed had come into being when a cat accidentally knocked over a pot of ink, "spilling ink all over the document. This poem was the result." The philosopher exclaims that would be impossible: "There must be an author. There must be a scribe." The rabbi concludes, "How could the universe ... come into being by itself? There must be an Author. There must be a Creator."
Thomism.
Thomas Aquinas (1225-1274), whose writings became widely accepted within Catholic western Europe, was heavily influenced by Aristotle, Averroes, and other Islamic and Jewish philosophers. He presented a teleological argument in his "Summa Theologica". In the work, Aquinas presented five ways in which he attempted to prove the existence of God: the "quinque viae". These arguments feature only "a posteriori" arguments, rather than literal reading of holy texts. He sums up his teleological argument as follows:
The fifth way is taken from the governance of the world. We see that things which lack knowledge, such as natural bodies, act for an end, and this is evident from their acting always, or nearly always, in the same way, so as to obtain the best result. Hence it is plain that they achieve their end, not fortuitously, but designedly. Now whatever lacks knowledge cannot move towards an end, unless it be directed by some being endowed with knowledge and intelligence; as the arrow is directed by the archer. Therefore, some intelligent being exists by whom all natural things are directed to their end; and this being we call God.—St Thomas Aquinas, "Summa Theologica: Article 3, Question 2)"
Aquinas notes that the existence of final causes, by which a cause is directed toward an effect, can only be explained by an appeal to intelligence. However, as natural bodies aside from humans do not possess intelligence, there must, he reasons, exist a being that directs final causes at every moment. That being is what we call God.
Modernity.
Newton and Leibniz.
Isaac Newton affirmed his belief in the truth of the argument when, in 1713, he wrote these words in an appendix to the second edition of his Principia:This most elegant system of the sun, planets, and comets could not have arisen without the design and dominion of an intelligent and powerful being.
This view, that "God is known from his works", was supported and popularized by Newton's friends Richard Bentley, Samuel Clarke and William Whiston in the Boyle lectures, which Newton supervised. Newton wrote to Bentley, just before Bentley delivered the first lecture, that:when I wrote my treatise about our Systeme I had an eye upon such Principles as might work with considering men for the beliefe [sic] of a Deity, and nothing can rejoice me more than to find it useful for that purpose.
The German philosopher Gottfried Leibniz disagreed with Newton's view of design in the teleological argument. In the Leibniz–Clarke correspondence, Samuel Clarke argued Newton's case that God constantly intervenes in the world to keep His design adjusted, while Leibniz thought that the universe was created in such a way that God would not need to intervene at all. As quoted by Ayval Leshem, Leibniz wrote:According to [Newton's] doctrine, God Almighty wants [i.e. needs] to wind up his watch from time to time; otherwise it would cease to move. He had not it seems, sufficient foresight to make it a perpetual motion
 Leibniz considered the argument from design to have "only moral certainty" unless it was supported by his own idea of pre-established harmony expounded in his Monadology. Bertrand Russell wrote that "The proof from the pre-established harmony is a particular form of the so-called physico-theological proof, otherwise known as the argument from design." According to Leibniz, the universe is completely made from individual substances known as monads, programmed to act in a predetermined way. Russell wrote:In Leibniz’s form, the argument states that the harmony of all the monads can only have arisen from a common cause. That they should all exactly synchronize, can only be explained by a Creator who pre-determined their synchronism.
British empiricists.
The 17th-century Dutch writers Lessius and Grotius argued that the intricate structure of the world, like that of a house, was unlikely to have arisen by chance. The empiricist John Locke, writing in the late 17th century, developed the Aristotelian idea that, excluding geometry, all science must attain its knowledge "a posteriori" - through sensual experience. In response to Locke, Anglican Irish Bishop George Berkeley advanced a form of idealism in which things only continue to exist when they are perceived. When humans do not perceive objects, they continue to exist because God is perceiving them. Therefore, in order for objects to remain in existence, God must exist omnipresently.
David Hume, in the mid-18th century, referred to the teleological argument in his "A Treatise of Human Nature". Here, he appears to give his support to the argument from design. John Wright notes that "Indeed, he claims that the whole thrust of his analysis of causality in the Treatise supports the Design argument", and that, according to Hume, "we are obliged 'to infer an infinitely perfect Architect.'”
However, later he was more critical of the argument in his "An Enquiry Concerning Human Understanding". This was presented as a dialogue between Hume and "a friend who loves sceptical paradoxes", where the friend gives a version of the argument by saying of its proponents, they "paint in the most magnificent colours the order, beauty, and
wise arrangement of the universe; and then ask if such a glorious display of intelligence
could come from a random coming together of atoms, or if chance could produce
something that the greatest genius can never sufficiently admire."
Hume also presented arguments both for and against the teleological argument in his "Dialogues Concerning Natural Religion". The character Cleanthes, summarizing the teleological argument, likens the universe to a man-made machine, and concludes by the principle of similar effects and similar causes that it must have a designing intelligence. 
 Look round the world: contemplate the whole and every part of it: You will find it to be nothing but one great-machine, subdivided into an infinite number of lesser machines, which again admit of subdivisions to a degree beyond what human senses and faculties can trace and explain. All these various machines, and even their most minute parts, are adjusted to each other with an accuracy, which ravishes into admiration all men who have ever contemplated them. The curious adapting of means to ends, throughout all nature, resembles exactly, though it much exceeds, the productions of human contrivance; of human design, thought, wisdom, and intelligence. Since therefore the effects resemble each other, we are led to infer, by all the rules of analogy, that the causes also resemble; and that the Author of Nature is somewhat similar to the mind of man; though possessed of much larger faculties, proportioned to the grandeur of the work which he has executed. By this argument "a posteriori," and by this argument alone, do we prove at once the existence of a Deity, and his similarity to human mind and intelligence.
 — David Hume, "Dialogues Concerning Natural Religion"
On the other hand, Hume's sceptic, Philo, is not satisfied with the argument from design. He attempts a number of refutations, including one that arguably foreshadows Darwin's theory, and makes the point that if God resembles a human designer, then assuming divine characteristics such as omnipotence and omniscience is not justified. He goes on to joke that far from being the perfect creation of a perfect designer, this universe may be "only the first rude essay of some infant deity... the object of derision to his superiors".
Derham's natural theology.
Starting in 1696 with his "Artificial Clockmaker", William Derham published a stream of teleological books. The best known of these are "Physico-Theology", 1713; "Astro-Theology", 1714; and "Christo-Theology", 1730. "Physico-Theology", for example, was explicitly subtitled "A demonstration of the being and attributes of God from his works of creation". A natural theologian, Derham listed scientific observations of the many variations in nature, and proposed that these proved "the unreasonableness of infidelity". At the end of the section on Gravity for instance, he writes:"What else can be concluded, but that all was made with manifest Design, and that all the whole Structure is the Work of some intelligent Being; some Artist, of Power and Skill equivalent to such a Work?" Also, of the "sense of sound" he writes:
For who but an intelligent Being, what less than an omnipotent and infinitely wise God could contrive, and make such a fine Body, such a Medium, so susceptible of every Impression, that the Sense of Hearing hath occasion for, to empower all Animals to express their Sense and Meaning to others.
Derham concludes: "For it is a Sign a Man is a wilful, perverse Atheist, that will impute so glorious a Work, as the Creation is, to any Thing, yea, a mere Nothing (as Chance is) rather than to God. A.S. Weber writes that Derham's "Physico-Theology" "directly influenced" William Paley's later work.
The power, and yet the limitations, of this kind of reasoning is illustrated in microcosm by the history of La Fontaine's fable of The Acorn and the Pumpkin, which first appeared in France in 1679. The light-hearted anecdote of how a doubting peasant is finally convinced of the wisdom behind creation arguably undermines this approach. However, beginning with Anne Finch's conversion of the story into a polemic against atheism, it has been taken up by a succession of moral writers as presenting a valid argument for the proposition that "The wisdom of God is displayed in creation".
Watchmaker analogy.
The watchmaker analogy, framing the teleological argument with reference to a timepiece, dates at least back to the Stoics, who were reported by Cicero in his "De Natura Deorum" (II.88), using such an argument against Epicureans, whom, they taunt, would "think more highly of the achievement of Archimedes in making a model of the revolutions of the firmament than of that of nature in creating them, although the perfection of the original shows a craftsmanship many times as great as does the counterfeit". It was also used by Robert Hooke and Voltaire, the latter of whom remarked: "The Universe troubles me, and much less can I think That this clock exists and should have no clockmaker."
William Paley presented his version of the watchmaker analogy at the start of his "Natural Theology" (1802).[S]uppose I found a watch upon the ground, and it should be inquired how the watch happened to be in that place, I should hardly think … that, for anything I knew, the watch might have always been there. Yet why should not this answer serve for the watch as well as for [a] stone [that happened to be lying on the ground]?… For this reason, and for no other; namely, that, if the different parts had been differently shaped from what they are, if a different size from what they are, or placed after any other manner, or in any order than that in which they are placed, either no motion at all would have been carried on in the machine, or none which would have answered the use that is now served by it.
According to Alister McGrath, Paley argued that "The same complexity and utility evident in the design and functioning of a watch can also be discerned in the natural world. Each feature of a biological organism, like that of a watch, showed evidence of being designed in such a way as to adapt the organism to survival within its environment. Complexity and utility are observed; the conclusion that they were designed and constructed by God, Paley holds, is as natural as it is correct."
Natural theology strongly influenced British science, with the expectation as expressed by Adam Sedgwick in 1831 that truths revealed by science could not conflict with the moral truths of religion. These natural philosophers saw God as the first cause, and sought secondary causes to explain design in nature: the leading figure Sir John Herschel wrote in 1836 that by analogy with other intermediate causes "the origination of fresh species, could it ever come under our cognizance, would be found to be a natural in contradistinction to a miraculous process".
As a theology student, Charles Darwin found Paley's arguments compelling. However, he later developed his theory of evolution in his 1859 book "On the Origin of Species", which offers an alternate explanation of biological order. In his autobiography, Darwin wrote that "The old argument of design in nature, as given by Paley, which formerly seemed to me so conclusive, fails, now that the law of natural selection has been discovered". Darwin struggled with the problem of evil of suffering in nature, but remained inclined to believe that nature depended upon "designed laws" and commended Asa Gray's statement about "Darwin's great service to Natural Science in bringing back to it Teleology: so that, instead of Morphology versus Teleology, we shall have Morphology wedded to Teleology."
Darwin owned he was "bewildered" on the subject, but was "inclined to look at everything as resulting from designed laws, with the details, whether good or bad, left to the working out of what we may call chance":
But I own that I cannot see, as plainly as others do, & as I shd wish to do, evidence of design & beneficence on all sides of us. There seems to me too much misery in the world. I cannot persuade myself that a beneficent & omnipotent God would have designedly created the Ichneumonidae with the express intention of their feeding within the living bodies of caterpillars, or that a cat should play with mice. Not believing this, I see no necessity in the belief that the eye was expressly designed.
Recent proponents.
Probabilistic arguments.
In 1928 and 1930, FR. Tennant published his "Philosophical Theology", which was a "bold endeavour to combine scientific and theological thinking". He proposed a version of the teleological argument based on the accumulation of the probabilities of each individual biological adaptation. "Tennant concedes that naturalistic accounts such as evolutionary theory may explain each of the individual adaptations he cites, but he insists that in this case the whole exceeds the sum of its parts: naturalism can explain each adaptation but not their totality." The "Routledge Encyclopedia of Philosophy" notes that "Critics have insisted on focusing on the cogency of each piece of theistic evidence - reminding us that, in the end, ten leaky buckets hold no more water than one." Also, "Some critics, such as John Hick and D.H. Mellor, have objected to Tennant’s particular use of probability theory and have challenged the relevance of any kind of probabilistic reasoning to theistic belief."
Richard Swinburne's "contributions to philosophical theology have sought to apply more
sophisticated versions of probability theory to the question of God’s existence, a methodological improvement on Tennant’s work but squarely in the same spirit." He uses Bayesian probability "taking account not only of the order and functioning of nature but also of the 'fit' between human intelligence and the universe, whereby one can understand its workings, as well as human aesthetic, moral, and religious experience. Swinburne writes: "the existence of order in the world confirms the existence of God if and only if the existence
of this order in the world is more probable if there is a God than if there is not. ... the probability of order of the right kind is very much greater if there is a God, and so that the existence of such order adds greatly to the probability that there is a God."
While discussing Hume's arguments, Alvin Plantinga offered a probability version of the teleological argument in his book "God and Other Minds":
Every "contingent" object such that we know whether or not it was the product of intelligent design, "was" the product of intelligent design.
The universe is a contingent object.
So probably the universe is designed.
Following Plantinga, Georges Dicker produced a slightly different version in his book about Bishop Berkeley:
A. The world ... shows amazing teleological order.
B. All Objects exhibiting such order ... are products of intelligent design.
C. Probably the world is a result of intelligent design.
D. Probably, God exists and created the world.
The "Encyclopædia Britannica" has the following criticism of such arguments: It can of course be said that any form in which the universe might be is statistically enormously improbable as it is only one of a virtual infinity of possible forms. But its actual form is no more improbable, in this sense, than innumerable others. It is only the fact that humans are part of it that makes it seem so special, requiring a transcendent explanation. 
Fine-tuned Universe.
A modern variation of the teleological argument is built upon the concept of the fine-tuned Universe: According to the website "Biologos": "Fine-tuning refers to the surprising precision of nature’s physical constants, and the beginning state of the Universe. To explain the present state of the universe, even the best scientific theories require that the physical constants of nature and the beginning state of the Universe have extremely precise values." Also, the fine-tuning of the Universe is the apparent delicate balance of conditions necessary for human life. In this view, speculation about a vast range of possible conditions in which life cannot exist is used to explore the probability of conditions in which life can and does exist. For example, it can be argued that if the force of the Big Bang explosion had been different by 1/1060 or the strong interaction force was only 5% different, life would be impossible. In terms of a teleological argument, the intuition in relation to a fine-tuned universe would be that God must have been responsible, if achieving such perfect conditions is so improbable. However, in regard to fine-tuning, Kenneth Himma writes: "The mere fact that it is enormously improbable that an event occurred... by itself, gives us no reason to think that it occurred by design… As intuitively tempting as it may be...” Himma attributes the “Argument from Suspicious Improbabilities”, a formalization of “the fine-tuning intuition” to George N. Schlesinger: To understand Schlesinger’s argument, consider your reaction to two different events. If John wins a 1-in-1,000,000,000 lottery game, you would not immediately be tempted to think that John (or someone acting on his behalf) cheated. If, however, John won three consecutive 1-in-1,000 lotteries, you would immediately be tempted to think that John (or someone acting on his behalf) cheated. Schlesinger believes that the intuitive reaction to these two scenarios is epistemically justified. The structure of the latter event is such that it… justifies a belief that intelligent design is the cause… Despite the fact that the probability of winning three consecutive 1-in-1,000 games is exactly the same as the probability of winning one 1-in-1,000,000,000 game, the former event… warrants an inference of intelligent design.
Himma considers Schlesinger’s argument to be subject to the same vulnerabilities he noted in other versions of the design argument: While Schlesinger is undoubtedly correct in thinking that we are justified in suspecting design in the case [of winning] three consecutive lotteries, it is because—and only because—we know two related empirical facts about such events. First, we already know that there exist intelligent agents who have the right motivations and causal abilities to deliberately bring about such events. Second, we know from past experience with such events that they are usually explained by the deliberate agency of one or more of these agents. Without at least one of these two pieces of information, we are not obviously justified in seeing design in such cases… [T]he problem for the fine-tuning argument is that we lack both of the pieces that are needed to justify an inference of design. First, the very point of the argument is to establish the fact that there exists an intelligent agency that has the right causal abilities and motivations to bring the existence of a universe capable of sustaining life. Second, and more obviously, we do not have any past experience with the genesis of worlds and are hence not in a position to know whether the existence of fine-tuned universes are usually explained by the deliberate agency of some intelligent agency. Because we lack this essential background information, we are not justified in inferring that there exists an intelligent Deity who deliberately created a universe capable of sustaining life.
Antony Flew, who spent most of his life as an atheist, converted to deism late in life, and postulated "an intelligent being as involved in some way in the design of conditions that would allow life to arise and evolve." He concluded that the fine-tuning of the universe was too precise to be the result of chance, so accepted the existence of God. He said that his commitment to "go where the evidence leads" meant that he ended up accepting the existence of God. Flew proposed the view, held earlier by Fred Hoyle, that the universe is too young for life to have developed purely by chance and that, therefore, an intelligent being must exist which was involved in designing the conditions required for life to evolve.
 Would you not say to yourself, “Some super-calculating intellect must have designed the properties of the carbon atom, otherwise the chance of my finding such an atom through the blind forces of nature would be utterly minuscule.” Of course you would… A common sense interpretation of the facts suggests that a superintellect has monkeyed with physics, as well as with chemistry and biology, and that there are no blind forces worth speaking about in nature. The numbers one calculates from the facts seem to me so overwhelming as to put this conclusion almost beyond question.
 — Fred Hoyle, "Engineering and Science", The Universe: Past and Present Reflections
Creation Science and intelligent design.
A version of the argument from design is central to both creation science and Intelligent design, but unlike Paley's openness to deistic design through God-given laws, proponents seek scientific confirmation of repeated miraculous interventions in the history of life, and argue that their theistic science should be taught in science classrooms.
The teaching of evolution was effectively barred from United States public school curricula by the outcome of the 1925 Scopes Trial, but in the 1960s the National Defense Education Act led to the Biological Sciences Curriculum Study reintroducing the teaching of evolution. In response, there was a resurgence of creationism, now presented as "creation science", based on biblical literalism but with Bible quotes optional. ("Explicit references to the Bible were optional: Morris's 1974 book "Scientific Creationism" came in two versions, one with Bible quotes, and one without.")
A 1989 survey found that virtually all literature promoting creation science presented the design argument, with John D. Morris saying "any living thing gives such strong evidence for design by an intelligent designer that only a willful ignorance of the data (II Peter 3:5) could lead one to assign such intricacy to chance." Such publications introduced concepts central to intelligent design, including "irreducible complexity" (a variant of the watchmaker analogy) and "specified complexity" (closely resembling a fine-tuning argument). The United States Supreme Court ruling on "Edwards v. Aguillard" barred the teaching of "Creation Science" in public schools because it breached the separation of church and state, and a group of creationists rebranded Creation Science as "intelligent design" which was presented as a scientific theory rather than as a religious argument.
Scientists disagreed with the assertion that intelligent design is scientific, and its introduction into the science curriculum of a Pennsylvania school district led to the 2005 "Kitzmiller v. Dover Area School District" trial, which ruled that the "intelligent design" arguments are essentially religious in nature and not science. The court took evidence from theologian John F. Haught, and ruled that "ID is not a new scientific argument, but is rather an old religious argument for the existence of God. He traced this argument back to at least Thomas Aquinas in the 13th century, who framed the argument as a syllogism: Wherever complex design exists, there must have been a designer; nature is complex; therefore nature must have had an intelligent designer." "This argument for the existence of God was advanced early in the 19th century by Reverend Paley": "The only apparent difference between the argument made by Paley and the argument for ID, as expressed by defense expert witnesses Behe and Minnich, is that ID's 'official position' does not acknowledge that the designer is God."
Proponents of the intelligent design movement such as Cornelius G. Hunter, have asserted that the methodological naturalism upon which science is based is religious in nature. They commonly refer to it as 'scientific materialism' or as 'methodological materialism' and conflate it with 'metaphysical naturalism'. They use this assertion to support their claim that modern science is atheistic, and contrast it with their preferred approach of a revived natural philosophy which welcomes supernatural explanations for natural phenomena and supports theistic science. This ignores the distinction between science and religion, established in Ancient Greece, in which science can not use supernatural explanations.
Intelligent design advocate Michael Behe proposed a development of Paley's watch analogy in which he argued in favour of intelligent design. Unlike Paley, Behe only attempts to prove the existence of an intelligent designer, rather than the God of classical theism. Behe uses the analogy of a mousetrap to propose irreducible complexity: he argues that if a mousetrap loses just one of its parts, it can no longer function as a mousetrap. He argues that irreducible complexity in an object guarantees the presence of intelligent design. Behe claims that there are instances of irreducible complexity in the natural world and that parts of the world must have been designed. This negative argument against step by step evolution ignores longstanding evidence that evolution proceeds through changes of function from preceding systems. The specific examples Behe proposes have been shown to have simpler homologues which could act as precursors with different functions. His arguments have been rebutted, both in general and in specific cases by numerous scientific papers. In response, Behe and others, "ironically, given the absence of any detail in their own explanation, complain that the proffered explanations lack sufficient detail to be empirically tested."
"Third way" proposal.
University of Chicago geneticist James A. Shapiro, writing in the Boston Review, states that advancements in genetics and molecular biology, and "the growing realization that cells have molecular computing networks which process information about internal operations and about the external environment to make decisions controlling growth, movement, and differentiation", have implications for the teleological argument. Shapiro states that these "natural genetic engineering" systems, can produce radical reorganizations of the "genetic apparatus within a single cell generation". Shapiro suggests what he calls a 'Third Way'; a non-creationist, non-Darwinian type of evolution:
What significance does an emerging interface between biology and information science hold for thinking about evolution? It opens up the possibility of addressing scientifically rather than ideologically the central issue so hotly contested by fundamentalists on both sides of the Creationist-Darwinist debate: Is there any guiding intelligence at work in the origin of species displaying exquisite adaptations ..."
In his book, "Evolution: A View from the 21st Century", Shapiro refers to this concept of "natural genetic engineering", which he says, has proved troublesome, because many scientists feel that it supports the intelligent design argument. He suggests that "function-oriented capacities [can] be attributed to cells", even though this is "the kind of teleological thinking that scientists have been taught to avoid at all costs."
Criticism.
Classical.
The original development of the argument from design was in reaction to atomistic, explicitly non-teleological, understandings of nature. Socrates, as reported by Plato and Xenophon, was reacting to such natural philosophers. While less has survived from the debates of the Hellenistic and Roman eras, it is clear from sources such as Cicero and Lucretius, that debate continued for generations, and several of the striking metaphors used to still today such as the unseen watchmaker, and the infinite monkey theorem, have their roots in this period. While the Stoics became the most well-known proponents of the argument from design, the atomistic counter arguments were refined most famously by the Epicureans. On the one hand they criticized the evidence for their being evidence of an intelligent design to nature, and the logic of the Stoics. On the defensive side, they were faced with the challenge of explaining how un-directed chance can cause something which appears to be a rational order. Much this defence revolved around arguments such as the infinite monkey metaphor. Democritus, had already apparently used such arguments in the time of Socrates, saying that there will be infinite planets, and only some having an order like the planet we know. But the Epicureans refined this argument, by proposing that the actual number of types of atoms in nature is small, not infinite, making it less coincidental that after a long period of time, certain orderly outcomes will result.
These were not the only positions held in classical times. A more complex position also continued to be held by some schools, such as the Neoplatonists, who, like Plato and Aristotle, insisted that Nature did indeed have a rational order, but were concerned about how to describe the way in which this rational order is caused. According to Plotinus for example, Plato's metaphor of a craftsman should be seen only as a metaphor, and Plato should be understood as agreeing with Aristotle that the rational order in nature works through a form of causation unlike everyday causation. In fact, according to this proposal each thing already has its own nature, fitting into a rational order, whereby the thing itself is "in need of, and directed towards, what is higher or better".
David Hume.
Louis Loeb writes that David Hume, in his "Enquiry", "insists that inductive inference cannot justify belief in extended objects." Loeb also quotes Hume as writing:It is only when two species of objects are found to be constantly conjoined, that we can infer the one from the other . . . If experience and observation and analogy be, indeed, the only guides which we can reasonably follow in inference of this nature; both the effect and cause must bear a similarity and resemblance to other effects and causes . . . which we have found, in many instances, to be conjoined with another . . . [The proponents of the argument] always suppose the universe, an effect quite singular and unparalleled, to be the proof of a Deity, a cause no less singular and unparalleled.
Loeb notes that "we observe neither God nor other universes, and hence no conjunction
involving them. There is no observed conjunction to ground an inference either
to extended objects or to God, as unobserved causes."
Hume also presented a criticism of the argument in his "Dialogues Concerning Natural Religion". The character "Philo", a religious sceptic, voices Hume's criticisms of the argument. He argues that the design argument is built upon a faulty analogy as, unlike with man-made objects, we have not witnessed the design of a universe, so do not know whether the universe was the result of design. Moreover, the size of the universe makes the analogy problematic: although our experience of the universe is of order, there may be chaos in other parts of the universe. Philo argues:
A very small part of this great system, during a very short time, is very imperfectly discovered to us; and do we thence pronounce decisively concerning the origin of the whole?—David Hume, Dialogues 2
Philo also proposes that the order in nature may be due to nature alone. If nature contains a principle of order within it, the need for a designer is removed. Philo argues that even if the universe is indeed designed, it is unreasonable to justify the conclusion that the designer must be an omnipotent, omniscient, benevolent God - the God of classical theism. It is impossible, he argues, to infer the perfect nature of a creator from the nature of its creation. Philo argues that the designer may have been defective or otherwise imperfect, suggesting that the universe may have been a poor first attempt at design. Hume also pointed out that the argument does not necessarily lead to the existence of one God: “why may not several deities combine in contriving and framing the world?” (p. 108).
Wesley C. Salmon developed Hume's insights, arguing that all things in the universe which exhibit order are, to our knowledge, created by material, imperfect, finite beings or forces. He also argued that there are no known instances of an immaterial, perfect, infinite being creating anything. Using the probability calculus of Bayes Theorem, Salmon concludes that it is very improbable that the universe was created by the type of intelligent being theists argue for.
Nancy Cartwright accuses Salmon of begging the question. One piece of evidence he uses in his probabilistic argument - that atoms and molecules are not caused by design - is equivalent to the conclusion he draws, that the universe is probably not caused by design. The atoms and molecules are what the universe is made up of and whose origins are at issue. Therefore, they cannot be used as evidence against the theistic conclusion.
Immanuel Kant.
Referring to it as the physico-theological proof, Immanuel Kant discussed the teleological argument in his Critique of Pure Reason. Even though he referred to it as "the oldest, clearest and most appropriate to human reason", he nevertheless rejected it, heading section VI with the words, "On the impossibility of a physico-theological proof". In accepting some of Hume's criticisms, Kant wrote that the argument "proves at most intelligence only in the arrangement of the 'matter' of the universe, and hence the existence not of a 'Supreme Being', but of an 'Architect'." Using the argument to try to prove the existence of God required "a concealed appeal to the Ontological argument."
Does not prove the existence of God.
In his "Traité de métaphysique" Voltaire observed that, even if the argument from design could prove the existence of a powerful intelligent designer, it would not prove that this designer is God.
 ... from this sole argument I cannot conclude anything further than that it is probable that an intelligent and superior being has skillfully prepared and fashioned the matter. I cannot conclude from that alone that this being has made matter out of nothing and that he is infinite in every sense.
 — Voltaire, "Traité de métaphysique"
Søren Kierkegaard questioned the existence of God, rejecting all rational arguments for God's existence (including the teleological argument) on the grounds that reason is inevitably accompanied by doubt. He proposed that the argument from design does not take into consideration future events which may serve to undermine the proof of God's existence: the argument would never finish proving God's existence. In the "Philosophical Fragments", Kierkegaard writes:
 The works of God are such that only God can perform them. Just so, but where then are the works of the God? The works from which I would deduce his existence are not directly and immediately given. The wisdom in nature, the goodness, the wisdom in the governance of the world -- are all these manifest, perhaps, upon the very face of things? Are we not here confronted with the most terrible temptations to doubt, and is it not impossible finally to dispose of all these doubts? But from such an order of things I will surely not attempt to prove God's existence; and even if I began I would never finish, and would in addition have to live constantly in suspense, lest something so terrible should suddenly happen that my bit of proof would be demolished.
 — Søren Kierkegaard, "Philosophical Fragments"
Argument from improbability.
Richard Dawkins is harshly critical of theology, creationism and intelligent design in his book "The God Delusion." In this book, he contends that an appeal to intelligent design can provide no explanation for biology because it not only begs the question of the designer's own origin but raises additional questions: an intelligent designer must itself be far more complex and difficult to explain than anything it is capable of designing. He believes the chances of life arising on a planet like the Earth are many orders of magnitude less probable than most people would think, but the anthropic principle effectively counters skepticism with regard to improbability. For example, Fred Hoyle suggested that potential for life on Earth was no more probable than a Boeing 747 being assembled by a hurricane from the scrapyard. Dawkins argues that a one-time event is indeed subject to improbability but once under way, natural selection itself is nothing like random chance. Furthermore, he refers to his counter argument to the argument from improbability by that same name:
 The argument from improbability is the big one. In the traditional guise of the argument from design, it is easily today's most popular argument offered in favour of the existence of God and it is seen, by an amazingly large number of theists, as completely and utterly convincing. It is indeed a very strong and, I suspect, unanswerable argument—but in precisely the opposite direction from the theist's intention. The argument from improbability, properly deployed, comes close to proving that God does "not" exist. My name for the statistical demonstration that God almost certainly does not exist is the Ultimate Boeing 747 gambit.
The creationist misappropriation of the argument from improbability always takes the same general form, and it doesn't make any difference… [if called] 'intelligent design' (ID). Some observed phenomenon—often a living creature or one of its more complex organs, but it could be anything from a molecule up to the universe itself—is correctly extolled as statistically improbable. Sometimes the language of information theory is used: the Darwinian is challenged to explain the source all the information in living matter, in the technical sense of information content as a measure of improbability or 'surprise value'… However statistically improbable the entity you seek to explain by invoking a designer, the designer himself has got to be at least as improbable. God is the Ultimate Boeing 747.
…The whole argument turns on the familiar question 'Who made God?'… A designer God cannot be used to explain organized complexity because any God capable of designing anything would have to be complex enough to demand the same kind of explanation in his own right. God presents an infinite regress from which he cannot help us to escape. This argument… demonstrates that God, though not technically disprovable, is very very improbable indeed.
 — Richard Dawkins, "The God Delusion"
Dawkins considered the argument from improbability to be "much more powerful" than the teleological argument, or argument from design, although he sometimes implies the terms are used interchangeably. He paraphrases St.Thomas' teleological argument as follows: “Things in the world, especially living things, look as though they have been designed. Nothing that we know looks designed unless it is designed. Therefore there must have been a designer, and we call him God.”
A flawed argument.
George H. Smith, in his book "Atheism: The Case Against God", points out what he considers to be a flaw in the argument from design:
Now consider the idea that nature itself is the product of design. How could this be demonstrated? Nature… provides the basis of comparison by which we distinguish between designed objects and natural objects. We are able to infer the presence of design only to the extent that the characteristics of an object differ from natural characteristics. Therefore, to claim that nature as a whole was designed is to destroy the basis by which we differentiate between artifacts and natural objects.
Perception of purpose in biology.
The philosopher of biology Michael Ruse has argued that Darwin treated the structure of organisms as if they had a purpose: "the organism-as-if-it-were-designed-by God picture was absolutely central to Darwin’s thinking in 1862, as it always had been." He refers to this as "the metaphor of design ... Organisms give the appearance of being designed, and thanks to Charles Darwin’s discovery of natural selection we know why this is true." In his review of Ruse's book, R.J. Richards writes, "Biologists quite routinely refer to the design of organisms and their traits, but properly speaking it’s "apparent" design to which they refer – an “as if” design." Robert Foley refers to this as "the illusion of purpose, design, and progress." He adds, "there is no purpose in a fundamentally causative manner in evolution but that the processes of selection and adaptation give the illusion of purpose through the utter functionality and designed nature of the biological world.
Richard Dawkins suggests that while biology can at first seem to be purposeful and ordered, upon closer inspection its true function becomes questionable. Dawkins rejects the claim that biology serves any designed function, claiming rather that biology only mimics such purpose. In his book "The Blind Watchmaker", Dawkins states that animals are the most complex things in the known universe: “Biology is the study of complicated things that give the appearance of having been designed for a purpose.” He argues that natural selection should suffice as an explanation of biological complexity without recourse to divine provenance.
Proponents of intelligent design creationism, such as William A. Dembski question the philosophical assumptions made by critics with regard to what a designer would or would not do. Dembski claims that such arguments are not merely beyond the purview of science: often they are tacitly or overtly theological while failing to provide a serious analysis of the hypothetical objective's relative merit. Some critics, such as Stephen Jay Gould suggest that any purported 'cosmic' designer would only produce optimal designs, while there are numerous biological criticisms to demonstrate that such an ideal is manifestly untenable. Against these ideas, Dembski characterizes both Dawkins' and Gould's argument as a rhetorical straw man. He suggests a principle of constrained optimization more realistically describes the best any designer could hope to achieve:
 Not knowing the objectives of the designer, Gould was in no position to say whether the designer proposed a faulty compromise among those objectives… In criticizing design, biologists tend to place a premium on functionalities of individual organisms and see design as optimal to the degree that those individual functionalities are maximized. But higher-order designs of entire ecosystems might require lower-order designs of individual organisms to fall short of maximal function.
 — William A. Dembski, "The Design Revolution: Answering the Toughest Questions About Intelligent Design"
Other criticisms.
The teleological argument assumes that one can infer the existence of intelligent design merely by examination, and because life is reminiscent of something a human might design, it too must have been designed. However, considering "snowflakes and crystals of certain salts", "[i]n no case do we find intelligence". "There are other ways that order and design can come about" such as by "purely physical forces".
The design claim can be challenged as an argument from analogy. Supporters of design suggest that natural objects and man-made objects have many similar properties, and man-made objects have a designer. Therefore, it is probable that natural objects must be designed as well. However, proponents must demonstrate that all the available evidence has been taken into account. Eric Rust argues that, when speaking of familiar objects such as watches, "we have a basis to make an inference from such an object to its designer". However, the "universe is a unique and isolated case" and we have nothing to compare it with, so "we have no basis for making an inference such as we can with individual objects. ... We have no basis for applying to the whole universe what may hold of constituent elements in the universe."
Most professional biologists support the modern evolutionary synthesis, not merely as an alternative explanation for the complexity of life but a better explanation with more supporting evidence. Living organisms obey the same physical laws as inanimate objects. Over very long periods of time self-replicating structures arose and later formed DNA.
Similar discussions in other civilizations.
Hinduism.
Nyaya, the Hindu school of logic, had a version of the argument from design. P.G. Patil writes that, in this view, it is not the complexity of the world from which one can infer the existence of a creator, but the fact that "the world is made up of parts." In this context, it is the Supreme Soul, Ishvara, who created all the world.
The argument is in five parts:
However, other Hindu schools, such as Samkhya, deny that the existence of God can ever be proved, because such a creator can never be perceived. Krishna Mohan Banerjee, in his "Dialogues on the Hindu Philosophy", has the Samkhya speaker saying, "the existence of God cannot be established because there is no proof. ... nor can it be proved by Inference, because you cannot exhibit an analogous instance."
Buddhist criticism of Hindu Nyaya logic.
Buddhism denies the existence of a creator god, and rejects the Nyaya syllogism for the teleological argument as being "logically flawed". Buddhists argue that "the 'creation' of the world cannot be shown to be analogous to the creation of a human artifact, such as a pot.
Confucianism.
The 18th century German philosopher Christian Wolff once thought that Confucius was a godless man, and that "the ancient Chinese had no natural religion, since they did not know the creator of the world". However, later, Wolff changed his mind to some extent. "On Wolff's reading, Confucius's religious perspective is thus more or less the weak deistic one of Hume's Cleanthes".
Taoism.
The Taoist writings of the 6th century BC philosopher Laozi, also known as Lao Tzu, have similarities with modern naturalist science. B. Schwartz notes that, in Taoism, "The processes of nature are not guided by a teleological consciousness ... the tao [dao] is not consciously providential.

</doc>
<doc id="30733" url="http://en.wikipedia.org/wiki?curid=30733" title="Tram">
Tram

Tramway
A tram (also known as tramcar; and in North America known as streetcar, trolley or trolley car), is a rail vehicle which runs on tracks along public urban streets (called street running), and also sometimes on separate rights of way. The lines or networks operated by tramcars are called tramways. Tramways powered by electricity, which were the most common type historically, were once called electric street railways. However, trams were widely used in urban areas before the universal adoption of electrification and, thus, the other methods of powering trams is listed below under "History".
Tram lines may also run between cities and/or towns (for example, interurbans, tram-train), and/or partially grade-separated even in the cities (light rail). Very occasionally, trams also carry freight. Tram vehicles are usually lighter and shorter than conventional :trains and rapid transit trains, but the size of trams (particularly light rail vehicles) is rapidly increasing. Some trams (for instance tram-trains) may also run on ordinary railway tracks, a tramway may be upgraded to a light rail or a rapid transit line, two urban tramways may be connected to an interurban, etc.
For all these reasons, the differences between the various modes of rail transportation are often indistinct.
Today, most trams use electrical power, usually fed by an overhead pantograph; in some cases by a sliding shoe on a third rail, trolley pole or bow collector. If necessary, they may have dual power systems — electricity in city streets, and diesel in more rural environments.
Trams are now included in the wider term "light rail", which also includes segregated systems.
Etymology and terminology.
The terms "tram" and "tramway" are derived from the Scots word "tram",[] referring respectively to a type of truck used in coal mines, and the tracks on which they ran. The word "tram" probably derived from Middle Flemish "tram" ("beam, handle of a barrow, bar, rung"), a North Sea Germanic word of unknown origin meaning the beam or shaft of a barrow or sledge, also the barrow itself. "Tram-car" is attested from 1873.
Although the terms "tram" and "tramway" have been adopted by many languages, they are not used universally in English; North Americans prefer "streetcar", "trolley", or "trolleycar". The term "streetcar" is first recorded in 1840, and originally referred to horsecars drawn by draft horses. When electrification came, Americans began to speak of "trolleycars" or later, "trolleys". These terms are believed to derive from the "troller" (possibly from the words "traveler" and "roller"), a four-wheeled device that was dragged along dual overhead wires by a cable that connected the troller to the top of the car and collected electrical power from the overhead wires.
The troller design frequently fell off the wires, and was soon replaced by the more reliable trolley pole. This newer device was fitted to the top of the car, and was spring-loaded in order to keep a small trolley wheel or alternately, a grooved lubricated "skate" mounted at the top of the pole, firmly in contact with the underside of the overhead wire. The terms "trolley pole" and "trolley wheel" both derive from the troller. Trams using trolley-pole current collection are normally powered through a single pole, with return current earthed through the steel wheels and rails. Modern trams often have an overhead pantograph mechanical linkage to connect to power, abandoning the trolley pole altogether.
In North America, trams are sometimes called "trolleys", even though strictly this may be incorrect, and the term may even be applied to cable cars, or conduit cars that instead draw power from an underground supply. Conventional diesel tourist buses decorated to look like streetcars are sometimes called "trolleys" in the US (tourist trolley). Furthering confusion, the term "tram" has instead been applied to open-sided, low-speed segmented vehicles on rubber tires generally used to ferry tourists short distances, for example on the Universal Studios backlot tour.
Over time, the term "trolley" has fallen into informal use, and may be applied loosely to a wide variety of different vehicle types. The word has taken on a historic or picturesque connotation, and is often associated with tourist or leisure travel. In North America, professional or formal documents generally use more precise alternative terms, such as "streetcar" or "light rail vehicle" (LRV).
Although the use of the term "trolley" for tram was not adopted in Europe, the term was later associated with the "trolleybus", a rubber-tyred vehicle running on hard pavement, which draws its power from pairs of overhead wires. These electric buses, which use twin trolley poles, are also called "trackless trolleys" (particularly in the northeastern US), or sometimes simply "trolleys" (in the UK, as well as in Seattle and Vancouver).
History.
Horse-drawn.
The very first tram was on the Swansea and Mumbles Railway in south Wales, UK; it was horse-drawn at first, and later moved by steam and electric power. The Mumbles Railway Act was passed by the British Parliament in 1804, and the first tram (similar to streetcars in the US some 30 years later) started operating in 1807.
The first streetcars, also known as horsecars in North America, were built in the United States and developed from city stagecoach lines and omnibus lines that picked up and dropped off passengers on a regular route without the need to be pre-hired. These trams were an animal railway, usually using teams of horses and sometimes mules to haul the cars, usually two as a team. Occasionally other animals were put to use, or humans in emergencies. The first streetcar line, developed by Irish born John Stephenson, was the New York and Harlem Railroad's Fourth Avenue Line which ran along The Bowery and Fourth Avenue in New York City. Service began in 1832. It was followed in 1835 by New Orleans, Louisiana, which has the oldest continuously operating street railway system in the world, according to the American Society of Mechanical Engineers.
In other world regions, the first tramway systems (all horse-drawn) were:
In many cases, these early forms of public transport developed out of industrial haulage routes or from the omnibus that first ran on public streets, using the newly invented iron or steel rail or 'tramway'. These were local versions of the stagecoach lines and picked up and dropped off passengers on a regular route, without the need to be pre-hired. Horsecars on tramlines were an improvement over the omnibus as the low rolling resistance of metal wheels on iron or steel rails (usually grooved from 1852 on), allowed the animals to haul a greater load for a given effort than the omnibus and gave a smoother ride. The horse-drawn streetcar combined the low cost, flexibility, and safety of animal power with the efficiency, smoothness, and all-weather capability of a rail right-of-way.
In Australia, there were horse-drawn lines or systems in: Adelaide, S.A.; Ballarat, Victoria; Brisbane, Queensland; Gawler, S.A.; Perth, W.A.; Sydney, N.SW.; Victor Harbor, S.A.
Steam.
The first mechanical trams were powered by steam. Generally, there were two types of steam tram. The first and most common had a small steam locomotive (called a tram engine in the UK) at the head of a line of one or more carriages, similar to a small train. Systems with such steam trams included Christchurch, New Zealand; Sydney, Australia; other city systems in New South Wales; Munich, Germany (from August 1883 on), Pakistan (from 1885) and the Dublin & Blessington Steam Tramway in Ireland. Steam tramways also were used on the suburban tramway lines around Milan and Padua; the last "Gamba de Legn" ("Peg-Leg") tramway ran on the Milan-Magenta-Castano Primo route in late 1958.
Tram engines usually had modifications to make them suitable for street running in residential areas. The wheels, and other moving parts of the machinery, were usually enclosed for safety reasons and to make the engines quieter. Measures were often taken to prevent the engines from emitting visible smoke or steam. Usually the engines used coke rather than coal as fuel to avoid emitting smoke; condensers or superheating were used to avoid emitting visible steam.
The other style of steam tram had the steam engine in the body of the tram, referred to as a tram engine or steam dummy. The most notable system to adopt such trams was in Paris. French-designed steam trams also operated in Rockhampton, in the Australian state of Queensland between 1909 and 1939. Stockholm, Sweden, had a steam tram line at the island of Södermalm between 1887 and 1901.
A major drawback of this style of tram was the limited space for the engine, so that these trams were usually underpowered.
Cable-hauled.
The next motive system for trams was the cable car, which was pulled along a fixed track by a moving steel cable. The power to move the cable was normally provided at a "powerhouse" site a distance away from the actual vehicle.
The first practical cable car line was tested in San Francisco, in 1873. Part of its success is attributed to the development of an effective and reliable cable grip mechanism, to grab and release the moving cable without damage. The second city to operate cable trams was Dunedin in New Zealand, from 1881 to 1957. From 1885 to 1940, the city of Melbourne, Victoria, Australia operated one of the largest cable systems in the world, at its peak running 592 trams on 75 km of track. There were also two isolated cable lines in Sydney, New South Wales, Australia; the North Sydney line from 1886 to 1900, and the King Street line from 1892 to 1905.
New York City developed at least seven cable car lines. A line in Washington DC ran to Georgetown (where some of the underground cable vaults can still be seen today). Los Angeles also had several cable car lines, including the Second Street Cable Railroad, which operated from 1885 to 1889, and the Temple Street Cable Railway, which operated from 1886 to 1898. The most extensive cable system in the US was in Chicago between 1882 and 1906.
In Dresden, Germany, in 1901 an elevated suspended cable car following the "Eugen Langen one-railed floating tram system" started operating. Cable cars operated on Highgate Hill in North London and Kennington to Brixton Hill In South London. They also worked around "Upper Douglas" in the Isle of Man (cable car 72/73 is the sole survivor of the fleet).
Cable cars suffered from high infrastructure costs, since an expensive system of cables, pulleys, stationary engines and lengthy underground vault structures beneath the rails had to be provided. They also required physical strength and skill to operate, and alert operators to avoid obstructions and other cable cars. The cable had to be disconnected ("dropped") at designated locations to allow the cars to coast by inertia, for example when crossing another cable line. The cable would then have to be "picked up" to resume progress, the whole operation requiring precise timing to avoid damage to the cable and the grip mechanism.
Breaks and frays in the cable, which occurred frequently, required the complete cessation of services over a cable route while the cable was repaired. Due to overall wear, the entire length of cable (typically several kilometres) would have to be replaced on a regular schedule. After the development of reliable electrically powered trams, the costly high-maintenance cable car systems were rapidly replaced in most locations.
Cable cars remained especially effective in hilly cities, since their nondriven wheels would not lose traction as they climbed or descended a steep hill. The moving cable would physically pull the car up the hill at a steady pace, unlike a low-powered steam or horse-drawn car. Cable cars do have wheel brakes and track brakes, but the cable also helps restrain the car to going downhill at a constant speed. Performance in steep terrain partially explains the survival of cable cars in San Francisco. However, the extensive cable car system of Chicago operated over a large relatively flat area.
The San Francisco cable cars, though significantly reduced in number, continue to perform a regular transportation function, in addition to being a well-known tourist attraction. A single cable line also survives in Wellington, New Zealand (rebuilt in 1979 as a funicular but still called the "Wellington Cable Car"). A third system, actually two separate cable lines with a shared power station in the middle, operates from the Welsh town of Llandudno up to the top of the Great Orme hill in North Wales, UK.
Hybrid funicular electric.
The Opicina Tramway in Trieste operates a hybrid funicular electric system. Conventional electric trams are operated in street running and on reserved track for most of their route. However, on one steep segment of track, they are assisted by cable tractors, which push the trams uphill and act as brakes for the downhill run. For safety, the cable tractors are always deployed on the downhill side of the tram vehicle.
Electric (trolley cars).
Electric trams were first experimentally installed in Saint Petersburg, Russia, invented and tested by Fyodor Pirotsky as early as 1880. These trams, like virtually all others mentioned in this section, used either a trolley pole or a pantograph, to feed power from electric wires strung above the tram route. Nevertheless, there were early experiments with battery-powered trams but these appear to have all been unsuccessful. The first trams in Bendigo, Australia, in 1892, were battery-powered but within as little as three months they were replaced with horse-drawn trams. In New York City some minor lines also used storage batteries. Then, comparatively recently, during the 1950s, a longer battery-operated tramway line ran from Milan to Bergamo.
The first regular electric tram service using pantographs or trolley poles, the Gross-Lichterfelde Tramway, went into service in Lichterfelde, a suburb of Berlin, Germany, by Siemens & Halske AG, in May 1881. The company Siemens still exists.
Another was by John Joseph Wright, brother of the famous mining entrepreneur Whitaker Wright, in Toronto in 1883. Earlier installations proved difficult or unreliable. Siemens' line, for example, provided power through a live rail and a return rail, like a model train, limiting the voltage that could be used, and providing electric shocks to people and animals crossing the tracks. Siemens later designed his own method of current collection, from an overhead wire, called the bow collector.
In 1883, Magnus Volk constructed his 2 ft gauge Volk's Electric Railway along the eastern seafront at Brighton, England. This two kilometer line, re-gauged to 2 ft in 1884, remains in service to this day, and is the oldest operating electric tramway in the world. The first tram for permanent service with overhead lines was the Mödling and Hinterbrühl Tram in Austria. It began operating in October 1883, but was closed in 1932.
Multiple functioning experimental electric trams were exhibited at the 1884 World Cotton Centennial World's Fair in New Orleans, Louisiana, but they were not deemed good enough to replace the Lamm fireless engines that then propelled the St. Charles Avenue Streetcar in that city.
Electric trams were first tested in service in the United States in Richmond, Virginia, in 1888, in the Richmond Union Passenger Railway built by Frank J. Sprague, though the first commercial installation of an electric streetcar in the United States was built in 1884 in Cleveland, Ohio and operated for a period of one year by the East Cleveland Street Railway Company.
The first electric street tramway in Britain, the Blackpool Tramway, was opened on 29 September 1885 using conduit collection along Blackpool Promenade. Since the closure of the Glasgow Corporation Tramways in 1962, this has been the only first-generation operational tramway in the UK, and is still in operation in a modernised form.
Sarajevo had the first electric trams on the continent of Europe, with a city-wide system in 1885. Budapest established its tramway system in 1887, and this line has grown to be the busiest tram line in Europe, with a tram running every 60 seconds at rush hour (however Istanbul's line T1, with a minimum headway of two minutes, probably carries more passengers – 265,000 per day). Bucharest and Belgrade ran a regular service from 1894. Ljubljana introduced its tram system in 1901 – it closed in 1958.
In Australia there were electric systems in Sydney, Newcastle, Geelong, Ballarat, Bendigo, Brisbane, Adelaide, Perth, Fremantle, Kalgoorlie, Leonora, Hobart and Launceston. By the 1970s, the only tramway system remaining in Australia was the extensive Melbourne system other than a few single lines remaining elsewhere: the Glenelg Tram, connecting Adelaide to the beachside suburb of Glenelg, and tourist trams in the Victorian Goldfields cities of Bendigo and Ballarat. An unusual line that operated from 1889 to 1896 connected Box Hill, then an outer suburb of Melbourne, to Doncaster, then a favoured picnic spot. In recent years the Melbourne system, generally recognised as one of the largest in the world, has been considerably moderrnised and expanded. The Adelaide line has also been extended to the Entertainment Centre, and there are plans to expand further.
In 1904 trams were put into operation in Hong Kong. The Hong Kong Tramway is still in operation today and uses double-decker trams exclusively.
Gas trams.
In the late 19th and early 20th centuries a number of systems in various parts of the world employed trams powered by gas, naphtha gas or coal gas in particular. Gas trams are known to have operated between Alphington and Clifton Hill in the northern suburbs of Melbourne, Australia (1886–1888); in Berlin and Dresden, Germany; in Estonia (1920s–1930); between Jelenia Góra, Cieplice, and Sobieszów in Poland (from 1897); and in the UK at Lytham St Annes, Neath (1896–1920), and Trafford Park, Manchester (1897–1908).
On 29 December 1886 the Melbourne newspaper The Argus reprinted a report from the San Francisco Bulletin that Mr Noble had demonstrated a new 'motor car' for tramways 'with success'. The tramcar 'exactly similar in size, shape, and capacity to a cable grip car' had the 'motive power' of gas 'with which the reservoir is to be charged once a day at power stations by means of a rubber hose'. The car also carried an electricity generator for 'lighting up the tram and also for driving the engine on steep grades and effecting a start'.
Comparatively little has been published about gas trams. However, research on the subject was carried out for an article in the October 2011 edition of "The Times", the historical journal of the Australian Association of Timetable Collectors, now the Australian Timetable Association.
A tram system powered by compressed gas was due to open in Malaysia in 2012, but as of January 2015[ [update]] there was no evidence of anything having happened; news about the project appears to have dried up.
Other power sources.
In some places, other forms of power were used to power the tram. Hastings and some other tramways, for example Stockholms Spårvägar in Sweden and some lines in Karachi, used petrol trams. Paris operated trams that were powered by compressed air using the Mekarski system.
Galveston Island Trolley in Texas operates diesel trams due to the city's hurricane-prone location, which would result in frequent damage to an electrical supply system.
Although Portland, Victoria promotes its tourist tram as being a cable car it actually operates using a hidden diesel motor. The tram, which runs on a circular route around the town of Portland, uses dummies and salons formerly used on the extensive Melbourne cable tramway system and now beautifully restored.
Design.
Single-ended vs double-ended.
A double-ended tram has an operator's cab and controls at each end of the vehicle, which allows it to easily be driven at full speed in either direction on a continuous segment of track. Typically at the end of a run, the tram's operator will walk from one end of the tram to the other, and then commence the tram route in the other direction. The tram is usually switched to another track by use of crossover points.
A single-ended tram has operator's controls at only one end, and can safely be driven at speed only in the forward direction (the vehicle often is capable of reverse movement, typically at slow speed, and usually with the assistance of somebody outside the vehicle to watch for obstacles). The configuration of the doors may be asymmetrical, favouring the side expected to be closest to the street kerb and footpath. At the end of a run, the tram must be turned around via a balloon loop or some other method, to face in the opposite direction for a return trip.
Two single-ended trams may be coupled into a "(semi-)permanently married pair" or "twinset", with operator's controls at each end of the combination. Such a setup is operated as if it were a double-ended tram, except that the operator must exit one vehicle and enter the other, when reversing at the end of the run.
In addition, if overhead electrical power is fed from a trolley pole, the direction of the trolley pole must be reversed at the end of the run, to ensure that the pole is "pulled" behind or "trailing" the vehicle, to avoid dewiring the power connection. Alternatively, a bidirectional pantograph may be used to feed power, eliminating the need for an extra procedure when reversing direction.
Low floor.
The latest generation of light rail vehicles is of partial or fully low-floor design, with the floor 300 to above top of rail, a capability not found in older vehicles. This allows them to load passengers, including those in wheelchairs, directly from low-rise platforms that are not much more than raised footpaths/sidewalks. This satisfies requirements to provide access to disabled passengers without using expensive wheelchair lifts, while at the same time making boarding faster and easier for other passengers.
Various companies have developed particular low-floor designs, varying from part-low-floor (with internal steps between the low-floor section and the high-floor sections over the bogies), e.g. Citytram and Siemens S70, to 100% low-floor, where the floor passes through a corridor between the drive wheels, thus maintaining a relatively constant (stepless) level from end to end of the tram.
Prior to the introduction of the Škoda ForCity, this carried the mechanical penalty of requiring bogies to be fixed and unable to pivot (except for less than 5 degrees in some trams) and thus reducing curve negotiation. This creates undue wear on the tracks and wheels.
Passengers appreciate the ease of boarding and alighting from low-floor trams and moving about inside 100% low-floor trams. Passenger satisfaction with low-floor trams is high.
Low-floor trams are now running in many cities around the world, including Adelaide, Amsterdam, Bratislava, Dublin, Gold Coast, Hiroshima, Houston, Istanbul, Melbourne, Milan, Prague, Riga, Strasbourg, Sydney, Vienna, Zagreb, Helsinki and Zürich.
Ultra low floor.
The Ultra Low Floor or (ULF) tram is a type of low-floor tram operating in Vienna, Austria as of 1997 and in Oradea, Romania, with the lowest floor-height of any such vehicle. In contrast to other low-floor trams, the floor in the interior of ULF is at sidewalk height (about 18 cm or 7 inches above the road surface), which makes access to trams easy for passengers in wheelchairs or with baby carriages. This configuration required a new undercarriage. The axles had to be replaced by a complicated electronic steering of the traction motors. Auxiliary devices are installed largely under the car's roof.
Articulated.
Articulated trams, invented and first used by the Boston Elevated Railway in 1912–13 at a total length of about twelve meters long (40 ft) for each pioneering example of twin-section articulated tram car, have two or more body sections, connected by flexible joints and a round platform at their pivoting midsection(s). Like articulated buses, they have increased passenger capacity. In practice, these trams can be up to 53 m long (such as in Budapest, Hungary), while a regular tram has to be much shorter. With this type, the articulation is normally suspended between carbody sections.
In the Škoda ForCity, which is the world's first 100% low floor tram with pivoting bogies, a Jacobs bogie supports the articulation between the two or more carbody sections. An articulated tram may be low-floor variety or high (regular) floor variety. Newer model trams may be up to 72 m long and carry 510 passengers at a comfortable 4 passengers/m2. At crush loadings this would be even higher.
Double decker.
Double decker trams were commonplace in Great Britain and Dublin Ireland before most tramways were torn up in the 1950s and 1960s.
New York City's New York Railways experimented in 1912 with a Brill double deck Hedley-Doyle stepless center entrance car, nicknamed the "Broadway Battleship," a term that spread to other large streetcars.
Hobart, Tasmania, Australia made extensive use of double decker trams. Arguably the most unusual double decker tram used to run between the isolated Western Australian outback village of Laverton and its small suburb of Gwalia.
Double decker trams still operate in Alexandria, Blackpool and Hong Kong.
Tram-train.
Tram-train operation uses vehicles such as the Flexity Link and Regio-Citadis, which are suited for use on urban tram lines and also meet the necessary indication, power, and strength requirements for operation on main-line railways. This allows passengers to travel from suburban areas into city-centre destinations without having to change from a train to a tram.
It has been primarily developed in Germanic countries, in particular Germany and Switzerland. Karlsruhe is a notable pioneer of the tram-train.
Non-commuter.
Cargo trams.
Since the 19th century goods have been carried on rail vehicles through the streets, often near docks and steelworks, for example the Weymouth Harbour Tramway in Weymouth, Dorset. Belgian vicinal tramway routes were used to haul agricultural proeduce, timber andcoal from Blégny colliery while several of the US interurbans carried freight. In Australia, three different "Freight Cars" operated in Melbourne between 1927 and 1977 and the city of Kislovodsk in Russia had a freight-only tram system consisting of one line which was used exclusively to deliver bottled Narzan mineral water to the railway station.
Today, the German city of Dresden has a regular "CarGoTram" service, run by the world's longest tram trainsets (59.4 m), carrying car parts across the city centre to its Volkswagen factory. In addition to Dresden, the cities of Vienna and Zürich currently use trams as mobile recycling depots.
At the turn of the 21st century, a new interest has arisen in using urban tramway systems to transport goods. The motivation now is to reduce air pollution, traffic congestion and damage to road surfaces in city centres.
One recent proposal to bring cargo tramways back into wider use was the plan by City Cargo Amsterdam to reintroduce them into the city of Amsterdam. In the spring of 2007 the city piloted this cargo tram operation, which among its aims aimed to reduce particulate pollution in the city by 20% by halving the number of lorries (5,000) unloading in the inner city during the permitted timeframe from 07:00 till 10:30. The pilot involved two cargo trams, operating from a distribution centre and delivering to a "hub" where special electric trucks delivered the trams' small containers to their final destination. The trial was successful, releasing an intended investment of €100 million in a fleet of 52 cargo trams distributing from four peripheral "cross docks" to 15 inner-city hubs by 2012. These specially built vehicles would be 30 ft long with 12 axles and a payload of 30 t. On weekdays, trams are planned to make 4 deliveries per hour between 7 a.m. and 11 a.m. and two per hour between 11 a.m. and 11 p.m. With each unloading operation taking on average 10 minutes, this means that each site would be active for 40 minutes out of each hour during the morning rush hour. In early 2009 the scheme was suspended owing to the financial crisis impeding fund-raising.
Hearse trams.
Specially appointed hearse trams, or funeral trolley cars, were used for funeral processions in many cities in the late 19th and early 20th century, particularly cities with large tram systems. The earliest known example in North America was Mexico City, which was already operating 26 funeral cars in 1886. In the United States, funeral cars were often given names. At the turn of the century, "almost every major city [in the US] had one or more":93 such cars in operation.
In Milan, Italy, hearse trams were used from the 1880s (initially horse-drawn) to the 1920s. The main cemeteries, Cimitero Monumentale and Cimitero Maggiore, included funeral tram stations. Additional funeral stations were located at Piazza Firenze and at Porta Romana. In the mid-1940s at least one special hearse tram was used in Turin, Italy. It was introduced due to the wartime shortage of automotive fuel.
Newcastle, NSW, Australia also operated two hearse trams between 1896 and 1948.
Dog car.
In Melbourne a "dog car" was used between 1937 and 1955 for transporting dogs and their owners to the Royal Melbourne Showgrounds.
Contractors' mobile offices.
Two former passenger cars from the Melbourne system were converted and used as mobile offices within the Preston Workshops between 1969 and 1974, by personnel from Commonwealth Engineering and ASEA who were connected with the construction of Melbourne's Z Class cars.
Restaurant trams.
A number of systems have introduced restaurant trams, particularly as a tourist attraction. This is specifically a modern trend. Systems which have or have had restaurant trams include Adelaide, Australia; Bendigo, Australia; Brussels, Belgium; Christchurch, New Zealand; Melbourne, Australia; Milan, Italy; Moscow, Russia; Turin, Italy; and Zurich, Switzerland.
These type of vehicles are particularly popular in Melbourne where three of the iconic "W" class trams have been converted to restaurant trams. All three often run in tandem and there are usually multiple meal sittings. Bookings often close months in advance.
Bistro trams with buffets operate between Krefeld and Düsseldorf in Germany, while Helsinki in Finland has a pub tram. Frankfurt, Germany has a tourist circle line called "Ebbelwei-Express", in which the traditional local drink "Apfelwein" is served.
Mobile Library Service.
Munich tram No.24, delivered in 1912, was refurbished as a mobile library in 1928. Known as "Städtische Wanderbücherei München", it was in public service until 1970. It was preserved and is now on public display in a railway museum in Hannover.
Nursery trams.
After World War Two, in both Warsaw and Wrocław, Poland, so-called trams-nurseries were in operation, collecting children from the workplaces of their parents (often tram employees). These mobile nursuries either carried the children around the system or delivered them to the nursery school run by transport company.
Specialized work trams.
Most systems had cars that were converted to specific uses on the system, other than simply the carriage of passengers. As just one example, the Melbourne system used or uses the following "technical" cars : a Ballast Motor, Ballast Trailers, a Blow Car, Breakdown Cars, Conductors and/or Drivers' Instruction Cars, a Laboratory Testing Car, a Line Marking Car, a Pantograph Testing Car, Per Way Locomotives, Rail Grinders, a Rail Hardner Loco., a Scrapper Car, Scrubbers, Sleeper Carriers, Track Cleaners, a Welding Car, a Wheel Transport Car and a Workshops Locomotive.
Advertising.
Many systems have passenger carrying vehicles with all-over advertising on the exterior and/or the interior.
Tramway operation.
There are two main types of tramways, the classic tramway build in the early 20th century with the tram system operating in mixed traffic and the later type which is most often associated with the tram system having its own right of way. Tram systems that have their own right of way are often called light rail but this does not always hold true. Though these two systems differ in their operation their equipment is much the same.
Tram and light rail transit systems around the world.
Throughout the world there are many tram systems; some dating from the late 19th or early 20th centuries. However a large number of the old systems were closed during the mid-20th century because of such perceived drawbacks as route inflexibility and maintenance expense. This was especially the case in North American, Australian, British, French and other West European cities. Some traditional tram systems did however survive and remain operating much as when first built over a century ago. In the past twenty years their numbers have been augmented by modern tramway or light rail systems in cities that had discarded this form of transport.
Popularity.
"Tramways with tramcars" (British English) or "street railways with streetcars" (American English) were common throughout the industrialised world in the late 19th and early 20th centuries but they had disappeared from most British, Canadian, French and US cities by the mid-20th century.
By contrast, trams in parts of continental Europe continued to be used by many cities, although there were contractions in some countries, including the Netherlands.
Since 1980 trams have returned to favour in many places, partly because their tendency to dominate the roadway, formerly seen as a disadvantage, is now considered to be a merit. New systems have been built in the United States, Great Britain, Ireland, France, Australia and many other countries.
In Milan, Italy, the old "Ventotto" trams are considered by its inhabitants a "symbol" of the city.
Largest tram systems.
The five largest tram networks in the world by track length are Melbourne (250 km), Kharkiv (232 km), St. Petersburg (220 km), Berlin (190 km), Moscow (181 km), and Vienna (172 km). Other large systems include (but are not limited to) Amsterdam (80.5 km), Antwerp, Belgrade (127 km), Bremen, Brussels, Bucharest, Budapest, Dresden, Gothenburg, Hanover, The Hague, Kiev, Leipzig, Łódź, Manchester (93 km), Milan (115 km), Oslo, Paris (90 km), Prague (142 km), Riga (182 km), Silesian Interurbans (201 km), Sofia, Stuttgart, Tricity, Toronto (82 km), Warsaw, Zagreb and Zurich (73 km).
The longest single tram line in the world is the 68 km Belgian Coast Tram, which runs almost the entire length of the Belgian coast.
Historically, the Paris Tram System was, at its peak, the world's largest system, with 1,111 km (690 mi) of track in 1925, before its complete destruction in the 1930s. The next largest system appears to have been 857 km, in Buenos Aires before the 1960s. The third largest was Chicago, with over 850 km of track, but it was all converted to bus services by the late 1950s. Before its decline, the BVG in Berlin operated a very large network with 634 km of route. Before its system started to be converted to trolleybus (and later bus) in the 1930s, the first-generation London network had 526 km of route in 1934. The Sydney tram network, before it was closed in the mid 20th century, had 291 km of track, and was thus the largest in Australia.
During a period in the 1980s, the world's largest tram system was in Leningrad (now known as St. Petersburg), USSR, and was included in Guinness World Records; however Saint Petersburg's tram system has declined in size since the fall of the Soviet Union.
Asia.
Tramway systems were well established in the Asian region at the start of the 20th century, but started a steady decline during the mid to late 1930s. The 1960s marked the end of its dominance in public transportation with most major systems closed and the equipment and rails sold for scrap; however, some extensive original lines still remain in service in Hong Kong and Japan. In recent years there has been renewed interest in the tram with modern systems being built in Japan, the Philippines, and South Korea.
In India trams still operate in Calcutta. Trams were discontinued in Chennai in 1954 and in Mumbai in 1960.
The Northern and Central areas of the City of Colombo in Sri Lanka had an electric Tram Car system (42" Gauge). This system commenced operations about 1900 and was discontinued by 1960.
Other countries with discontinued tram systems include Indonesia, Malaysia, Thailand, Pakistan and Vietnam. However, a tram system is planned for construction in Gwadar, Pakistan where construction started in late 2011. In China the cities of Beijing, Zhuhai, Nanjing and Shenzhen are planning tram networks for the future.
The first Japanese tram line was inaugurated in 1895 as the Kyoto Electric Railroad. The tram reached its zenith in 1932 when 82 rail companies operated 1,479 kilometers of track in 65 cities. The tram declined in popularity through the remaining years of the 1930s and during the 1960s many of the remaining operational tramways were shut down and dismantled.
Europe.
In many European cities much tramway infrastructure was lost in the mid-20th century, though not always on the same scale as in other parts of the world such as North America. Most of Eastern Europe retained tramway systems until recent years but some cities are now reconsidering their transport priorities. In contrast, some Western European cities are rehabilitating, upgrading, expanding and reconstructing their old tramway lines. Many Western European towns and cities are also building new tramway lines. Whereas most systems and vehicles in the light rail sector are being found in Eastern Europe; in the 1960s and 1970s, LRV systems were shut down in many places in Western Europe and urban transportation has been experiencing a sustained long running revival since the 1990s.
North America.
In North America, trams are generally known as "streetcars" (or sometimes as "trolleys"); the term "tram" is more likely to be understood as a tourist trolley, an aerial tramway, or a people-mover.
In most North American cities, streetcar lines were largely torn up in the mid-20th century for a variety of financial, technological and social reasons. Exceptions included Boston, New Orleans, Newark, Philadelphia (with a much shrunken network), Pittsburgh, San Francisco, Cleveland, and Toronto. Pittsburgh had kept most of its streetcar system serving the city and many suburbs until severe cutbacks on 27 January 1967, making it the longest-lasting large-network US streetcar system, though Pittsburgh's surviving streetcar lines were converted to light rail in the 1980s.
Toronto currently has the largest streetcar system in the Americas in terms of track length and ridership, operated by the Toronto Transit Commission. This is the only large-scale streetcar system existing in Canada, not including the light rail systems that some Canadian cities currently operate, or heritage streetcar lines operating only seasonally. Toronto's system currently uses Canadian Light Rail Vehicles and Articulated Light Rail Vehicles, after a history of using PCCs, Peter Witt cars, and horse-drawn carriages. The TTC has begun accepting delivery of a fleet of 204 of a variant of Bombardier's Flexity Outlook (also used in some European tram systems) as a replacement. Newer light rail lines in Toronto and Kitchener-Waterloo will be using the Flexity Freedom.
Streetcars once existed in Edmonton and Calgary, but both Canadian cities shut down their streetcar systems. In the late 1970s and early 1980s, both cities built and expanded new light rail systems. Streetcars also once operated in cities such as Ottawa, Montreal, Quebec City, Kitchener, Hamilton, Kingston, London, Windsor, Peterborough, Regina, and Saskatoon. Some of these cities have restored their old streetcars and now run them as a heritage feature for tourists, such as the Vancouver Downtown Historic Railway.
San Francisco's Muni Metro system is the largest surviving streetcar system in the United States, and has even revived previously closed streetcar lines such as the F Market & Wharves heritage streetcar line.
In a trend started in the 1980s, some American cities have brought back streetcars, examples of these being Memphis, Portland, Tampa, Little Rock, Seattle and Dallas. Prior to 2000, most of these new-generation streetcar systems were heritage streetcar lines, using vintage or replica-vintage vehicles, but following the 2001 opening of the Portland Streetcar system – the first to use modern vehicles – most new US systems have been designed to use modern, low-floor cars. Several additional cities are planning or proposing new streetcar systems, and such systems are under construction in Atlanta, Cincinnati, Dallas (a second system), Kansas City, Los Angeles, Milwaukee, Tucson, and Washington DC. Alternatively, in the late 20th century, several cities installed modern light rail systems, in part along the same corridors as their old streetcars systems, the first of these being the San Diego Trolley in San Diego in 1981.
Oceania.
Historically, there have been trams in the following Australian cities and towns: Brisbane, Queensland; Rockhampton, Queensland; Sydney, New South Wales; Newcastle, NSW; Maitland, NSW; Broken Hill, NSW; Yass, NSW; Camden, NSW; Melbourne, Victoria; Geelong, Victoria; Ballarat, Victoria; Bendigo, Victoria; Sorrento, Victoria; Adelaide, South Australia; Gawler, South Australia; Victor Harbor, South Australia; Moonta-Wallaroo, South Australia; Perth, Western Australia; Fremantle, WA; Kalgoorlie, WA; Laverton, WA; Hobart, Tasmania; and Launceston, Tasmania. These ranged from extensive systems to single lines. Virtually all known types of motive power have been utilised at some stage, in Australia.
Today, trams can be found in Melbourne (by length, the world's largest system), and to a lesser extent, Adelaide; all other major cities having largely dismantled their networks by the 1970s. Sydney reintroduced its tram in 1997 on a modern light rail network, while Ballarat and Bendigo retained their trams as heritage systems. In 2008 and 2009, the Bendigo Tramway Co. Ltd. conducted trials utilising their heritage trams for regular public transport. Portland, Victoria introduced a tourist tram in 1996 - this uses a former Melbourne cable car dummy and trailer car, but utilising a hidden diesel motor. A completely new publlic transport system opened on the Gold Coast, Queensland on 20 July 2014. The new system is known as the and is the first tram/ light rail system in Queensland,Australia since Brisbane closed their tram network in 1969. As from March 2014, the Sydney line was extended to Dulwich Hill, with a further extension planned for Circular Quay, as well as plans for a small system in the Sydney southern suburbs. There are also plans for the reintroduction of trams in Perth and Hobart, and for completely new systems in Canberra, and on the Sunshine Coast, Queensland. (Ironically, Walter Burley Griffin's 1912 prize-winning design for Canberra envisioned an extensive tram system.)
A distinctive feature of many Australian trams was the early use of a lowered central section between bogies (wheel-sets). This was intended to make passenger access easier, by reducing the number of steps required to reach the inside of the vehicle. It is believed that the design first originated in Christchurch, New Zealand, in the first decade of the 20th century. Cars with this design feature were frequently referred to as "drop-centres". Trams for Christchurch and Wellington built in the 1920s with an enclosed section at each end and an open-sided middle section were also known as "boon cars", but did not have the drop-centre. Trams built since the 1970s have had conventional high or low floors.
New Zealand's last public transport tramway system, that of Wellington, closed in 1966. Nevertheless there had been tramways ranging from large, comprehensive systems to single lines, in Auckland, Christchurch, Dunedin, Gisborne, Invercargill, Napier, New Plymouth, Greymouth, Westport, Hokitika, Ross, Brighton, Charleston, Kamiere and Kamara. An unusual feature of New Zealand's trams was the diversity of gauges. The 15 systems utilised no less than five gauges, thus making swapping of rolling stock from system to system, a bit of a challenge. Christchurch has subsequently reintroduced heritage trams over a new CBD route, but the overhead wiring plus some track was damaged by the earthquake of 2011. In November 2013 a limited circuit was reopened. Auckland has recently introduced heritage trams into the Wynyard area, near the CBD, using former Melbourne trams as no operable former Auckland cars are believed to exist. A heritage line exists in Queen Elizabeth Park on the Kapiti Coast, running through open countryside.
South America.
Buenos Aires in Argentina had once one of the most extensive tramway networks in the world with over 857 km (535 mi) of track, most of it dismantled during the 1960s in favor of bus transportation.
Now slowly coming back, the 2 km Puerto Madero Tramway running in the Puerto Madero district is spearheading the move with extensions to Retiro station and La Boca in the planning stages.
Another line, the PreMetro line E2 system feeding the Line E of the Buenos Aires Subway has been operating for the past few years on the outskirts of Buenos Aires, and a unique leisure "Tren de la Costa", an artery that stretches for 15 kilometres by the River Plate, from Olivos to the village of Tigre has also been running in Buenos Aires.
Also in the city Mendoza, in Argentina, a new tramway system is in construction, the Metrotranvía of Mendoza, which will have a route of 12.5 km and will link five districts of the Greater Mendoza conurbation. The opening of the system is scheduled for August 2011.
In Medellín, Colombia, there is a tram line under construction and the opening schedule is for December 2011.
Bogota, Colombia used to have a very extensive tram system until the violent events of the Bogotazo in 1948.
Pros and cons of tram systems.
All transit services, except personal rapid transit, involve a trade-off between speed and frequency of stops. Services that stop frequently have a lower overall speed, and are therefore less attractive for longer trips. Metros, light rail, monorail, and bus rapid transit are all forms of rapid transit, which generally signifies high speed and widely spaced stops. Trams are often used as a form of local transit, making frequent stops. Thus, the most meaningful comparison of advantages and disadvantages is with other forms of local transit, primarily the local bus.
Scale modelling of trams.
Model trams are popular in HO scale (1:87) and O scale (1:48 in the US and generally 1:43,5 and 1:45 in Europe and Asia). They are typically powered and will accept plastic figures inside. Common manufacturers are Roco and Lima, with many custom models being made as well. The German firm Hödl and the Austrian Halling specialize in 1:87 scale.
In the US, Bachmann Industries is a mass supplier of HO trams and kits. Bowser Manufacturing has produced white metal models for over 50 years. There are many boutique vendors offering limited run epoxy and wood models. At the high end are highly detailed brass models which are usually imported from Japan or Korea and can cost in excess of $500. Many of these run on gauge track, which is correct for the representation of (standard gauge) in HO scale as in US and Japan, but incorrect in 4 mm (1:76.2) scale, as it represents . This scale/gauge hybrid is called OO scale.
O scale trams are also very popular among tram modellers because the increased size allows for more detail and easier crafting of overhead wiring. In the US these models are usually purchased in epoxy or wood kits and some as brass models. The Saint Petersburg Tram Company produces highly detailed polyurethane non-powered O Scale models from around the world which can easily be powered by trucks from vendors like Q-Car.
In the US, one of the best resources for model tram enthusiasts is the East Penn Traction Club of Philadelphia and Trolleyville a website of the Southern California Traction Club.
It is thought that the first example of a working model tramcar in the UK built by an amateur for fun was in 1929, when Frank E. Wilson created a replica of London County Council Tramways E class car 444 in 1:16 scale, which he demonstrated at an early Model Engineer Exhibition. Another of his models was London E/1 1800, which was the only tramway exhibit in the Faraday Memorial Exhibition of 1931. Together with likeminded friends, Frank Wilson went on to found the Tramway & Light Railway Society in 1938, establishing tramway modelling as a hobby.
Further reading.
</dl>

</doc>
<doc id="30736" url="http://en.wikipedia.org/wiki?curid=30736" title="The Book of the Law">
The Book of the Law

Liber AL vel Legis (]) is the central sacred text of Thelema, written down from dictation mostly by Aleister Crowley, although Rose Edith Crowley is also known to have written two phrases into the manuscript of the Book after its dictation. Crowley claimed it was dictated to him by a discarnate entity named Aiwass or Aiwaz. However, the three chapters are largely written in the first person by the Thelemic deities Nuit, Hadit, and Ra-Hoor-Khuit respectively, rather than by Aiwass/Aiwaz.
The technical title of the book is Liber AL vel Legis, sub figura CCXX, as delivered by XCIII=418 to DCLXVI, although this title never occurs in the Book itself, which refers to itself as "the Book of the Law" and "the threefold Book of Law" (chapters 1:35, 3:75). CCXX is 220 in Roman figures, representing The Tree of Life (10 numbers times 22 paths), and is the number of verses of the Book in typescript. XCIII is 93, the enumeration of both "The word of the law" Thelema and Aiwass. DCLXVI is 666, the number of Crowley as Great Beast both as Adept and Magus. This is a way of saying that the book was delivered by Aiwass (whose number is both 93 and 418) to Crowley, who is The Beast 666.
The facsimile manuscript of the Book is not, however, numbered 220, but XXXI (31) as the first chapter's verses are unnumbered in the original manuscript: that is, no verse numbers were dictated to Crowley for chapter one. Both editions were titled by Crowley AL, pronounced "El", value 31, so therefore Liber 31 is the manuscript of "The Book of the Law" called AL (not be confused with Liber 31 by C. S. Jones (Frater Achad), which is an exegesis of some of the qabalistic symbolism of the "Book"), whereas Liber 220 is the edited (strictly according to the editing instructions dictated as part of the text of the Book itself), printed form of the text: see "The Equinox of The Gods" for a full account by Crowley of the reception and publishing of the "Book" according to these internal instructions.
Through the reception of the "Book", Crowley proclaimed the arrival of a new stage in the spiritual evolution of humanity, to be known as the "Æon of Horus". The primary precept of this new aeon is the charge to "Do what thou wilt".
The book contains three chapters, each of which was alleged to be written down in one hour, beginning at noon, on 8 April 9 April, and 10 April in Cairo, Egypt, in the year 1904. Crowley says that the author was an entity named Aiwass, whom he later referred to as his personal Holy Guardian Angel (analogous to but not identical with "Higher Self"). Biographer Lawrence Sutin quotes private diaries that fit this story, and writes that "if ever Crowley uttered the truth of his relation to the "Book"," his public account accurately describes what he remembered on this point.
Crowley himself wrote "Certain very serious questions have arisen with regard to the method by which this Book was obtained. I do not refer to those doubts—real or pretended—which hostility engenders, for all such are dispelled by study of the text; no forger could have prepared so complex a set of numerical and literal puzzles[...]"
The original title of the book was "Liber L vel Legis". Crowley retitled it "Liber AL vel Legis" in 1921, when he also gave the handwritten manuscript its own title, "Liber XXXI".
The book is often referred to simply as "Liber AL", "Liber Legis" or just "AL", though technically the latter two refer only to the manuscript.
Creation.
Summons.
According to Crowley, the story began on 16 March 1904, when he tried to "shew the Sylphs" by use of the Bornless Ritual to his wife, Rose Edith Kelly, while spending the night in the King's Chamber of the Great Pyramid of Giza. Although she could see nothing, she did seem to enter into a light trance and repeatedly said, "They're waiting for you!" Since Rose had no interest in magic or mysticism, he took little interest. However, on the 18th, after invoking Thoth (the god of knowledge), she mentioned Horus by name as the one waiting for him. Crowley, still skeptical, asked her numerous questions about Horus, which she answered accurately supposedly without having any prior study of the subject:
We cannot too strongly insist on the extraordinary character of this identification.
Calculate the odds! We cannot find a mathematical expression for tests 1,2,4,5, or 6, but the other 7 tests give us: 1/10 x 1/84 x 1/4 x 1/6 x 1/7 x 1/10 x 1/15 = 1/21,168,000
Twenty-one million to one against her getting through half the ordeal!
Crowley also gives a different chronology, in which an invocation of Horus preceded the questioning. Lawrence Sutin says this ritual described Horus in detail, and could have given Rose the answers to her husband's questions.
As part of his 'test' for Rose, Crowley claimed they visited the Bulaq Museum (even though that museum had been closed in 1902), where Crowley asked her to point out an image of Horus. Much to Crowley's initial amusement, she passed by several common images of the god, and went upstairs. From across the room Rose identified Horus on the stele of Ankh-ef-en-Khonsu, then housed under inventory number 666 (since moved to the Egyptian Museum of Cairo, number A 9422). The stela would subsequently be known to Thelemites (adherents of Thelema) as the "Stele of Revealing."
On 20 March, Crowley invoked Horus, "with great success". Between 23 March and 8 April, Crowley had the hieroglyphs on the stele translated. Also, Rose revealed that her "informant" was not Horus himself, but his messenger, Aiwass.
Finally, on 7 April, Rose gave Crowley his instructions—for three days he was to enter the "temple" and write down what he heard between noon and 1:00 p.m.
Writing.
Crowley said he wrote "The Book of the Law" on 8, 9 and 10 April 1904, between the hours of noon and 1:00 pm, in the flat where he and his new wife were staying for their honeymoon, which he described as being near the Boulak Museum in a fashionable European quarter of Cairo, let by the firm Congdon & Co. The apartment was on the ground floor, and the "temple" was the drawing room.
Crowley described the encounter in detail in "The Equinox of the Gods", saying that as he sat at his desk in Cairo, the voice of Aiwass came from over his left shoulder in the furthest corner of the room. This voice is described as passionate and hurried, and was "of deep timbre, musical and expressive, its tones solemn, voluptuous, tender, fierce or aught else as suited the moods of the message. Not bass—perhaps a rich tenor or baritone." Further, the voice was devoid of "native or foreign accent".
Crowley also got a "strong impression" of the speaker's general appearance. Aiwass had a body composed of "fine matter," which had a gauze-like transparency. Further, he "seemed to be a tall, dark man in his thirties, well-knit, active and strong, with the face of a savage king, and eyes veiled lest their gaze should destroy what they saw. The dress was not Arab; it suggested Assyria or Persia, but very vaguely."
Despite initially writing that it was an "excellent example of automatic writing," Crowley later insisted that it was not just automatic writing (though the writing included aspects of this, since when Crowley tried to stop writing he was compelled to continue. The writing also recorded Crowley's own thoughts). Rather he said that the experience was exactly like an actual voice speaking to him. This resulted in a few transcription errors, about which the scribe had to later inquire.
Note, moreover, with what greedy vanity I claim authorship even of all the other A∴A∴ Books in Class A, though I wrote them inspired beyond all I know to be I. Yet in these Books did Aleister Crowley, the master of English both in prose and in verse, partake insofar as he was That. Compare those Books with The Book of the Law! The style [of the former] is simple and sublime; the imagery is gorgeous and faultless; the rhythm is subtle and intoxicating; the theme is interpreted in faultless symphony. There are no errors of grammar, no infelicities of phrase. Each Book is perfect in its kind.
I, daring to snatch credit for these [...] dared nowise to lay claim to have touched The Book of the Law, not with my littlest finger-tip.
He also admits to the possibility that Aiwass may be identified with his own subconscious, although he thought this was unlikely:
Of course I wrote them, ink on paper, in the material sense; but they are not My words, unless Aiwaz be taken to be no more than my subconscious self, or some part of it: in that case, my conscious self being ignorant of the Truth in the Book and hostile to most of the ethics and philosophy of the Book, Aiwaz is a severely suppressed part of me. Such a theory would further imply that I am, unknown to myself, possessed of all sorts of praeternatural knowledge and power.
Crowley's former secretary Israel Regardie, on the other hand considered this statement by Crowley to be no real objection to Aiwass being a part of Crowley's unconscious mind, claiming that:
It can safely be said that current psychological theory would agree that any one person is possessed of all sorts of knowledge and power of which he is totally unconscious... Both Freudian and Jungian theory are on the side of such an assumption...
In his introduction to his edition of "The Law is for All", Israel Regardie stated:
It really makes little difference in the long run whether "The Book of the Law" was dictated to [Crowley] by a preterhuman intelligence named Aiwass or whether it stemmed from the creative deeps of Aleister Crowley. The book was written. And he became the mouthpiece for the Zeitgeist, accurately expressing the intrinsic nature of our time as no one else has done to date.
Crowley himself was initially opposed to the book and its message. "I was trying to forget the whole business."
The fact of the matter was that I resented "The Book of the Law" with my whole soul. For one thing, it knocked my Buddhism completely on the head. ... I was bitterly opposed to the principles of the Book on almost every point of morality. The third chapter seemed to me gratuitously atrocious.
Shortly after making a few copies for evaluation by close friends, the manuscript was misplaced and forgotten about. It would be several years before it was found, and the first official publication occurred in 1909.
"The Book of the Law" annoyed me; I was still obsessed by the idea that secrecy was necessary to a magical document, that publication would destroy its importance. I determined, in a mood which I can only describe as a fit of ill temper, to publish "The Book of the Law", and then get rid of it for ever.
Changes to the manuscript.
The final version of "Liber Legis" includes text that did not appear in the original writing, including many small changes to spelling. In several cases, stanzas from the Stele of Revealing were inserted within the text. For example, chapter 1, page 2, line 9 was written as "V.1. of Spell called the Song" and was replaced with:
<poem>
Above, the gemmèd azure is
She bends in ecstasy to kiss
The wingèd globe, the starry blue,
</poem>
On page 6 of chapter 1, the following is in the original manuscript:
And the sign shall be my ecstasy, the consciousness of the continuity of existence, the unfragmentary non-atomic fact of my universality." along with a note: "Write this in whiter words But go forth on.
This was later changed to:
And the sign shall be my ecstasy, the consciousness of the continuity of existence, the omnipresence of my body. (AL I:26)
Again in chapter 1, on page 19, Crowley writes, "(Lost 1 phrase) The shape of my star is—". Later, it was Rose who filled in the lost phrase:
The Five Pointed Star, with a Circle in the Middle, & the circle is Red. (AL I:60)
Chapter 2 has very few changes or corrections. Chapter 3 has a few spelling changes, and includes large chunks inserted from Crowley's paraphrase of The Stele of Revealing.
The phrase "Force of Coph Nia", which is found in chapter 3, on page 64 (verse 72), was filled in by Rose Kelly because that place in the manuscript had been left incomplete as not having been properly heard by Crowley during the supposed dictation. Israel Regardie proposed that Coph Nia could have been intended to represent Ain Soph, the Cabalistic phrase for Infinity, and that Rose might not have known that Hebrew letters are written from right to left or their meaning.
Speakers.
Although the "messenger" of "Liber AL" was Aiwass, each chapter is presented as an expression of one of three god-forms: Nuit, Hadit, and Ra-Hoor-Khuit.
The first chapter is spoken by Nuit, the Egyptian goddess of the night sky, called the Queen of Space. Crowley calls her the "Lady of the Starry Heaven, who is also Matter in its deepest metaphysical sense, who is the infinite in whom all we live and move and have our being."
The second chapter is spoken by Hadit, who refers to himself as the "complement of Nu," his bride. As such, he is the infinitely condensed point, the center of her infinite circumference. Crowley says of him, "He is eternal energy, the Infinite Motion of Things, the central core of all being. The manifested Universe comes from the marriage of Nuit and Hadit; without this could no thing be. This eternal, this perpetual marriage-feast is then the nature of things themselves; and therefore, everything that exists is a "crystallisation of divine ecstasy", and "He sees the expansion and the development of the soul through joy."
The third chapter is spoken by Ra-Hoor-Khuit, "a god of War and of Vengeance", also identified as Hoor-paar-kraat, the Crowned and Conquering Child.
Crowley sums up the speakers of the three chapters thus, "we have Nuit, Space, Hadit, the point of view; these experience congress, and so produce Heru-Ra-Ha, who combines the ideas of Ra-Hoor-Khuit and Hoor-paar-kraat."
The book also introduces:
Interpretation.
Thanks in large part to The Comment, interpretation of the often cryptic text is generally considered by Thelemites a matter for the individual reader. Crowley wrote about Liber AL in great detail throughout the remainder of his life, apparently attempting to decipher its mysteries.
The emancipation of mankind from all limitations whatsoever is one of the main precepts of the Book.
Aiwass, uttering the word Thelema (with all its implications), destroys completely the formula of the Dying God. Thelema implies not merely a new religion, but a new cosmology, a new philosophy, a new ethics. It co-ordinates the disconnected discoveries of science, from physics to psychology, into a coherent and consistent system. Its scope is so vast that it is impossible even to hint at the universality of its application.
Symbology of the "New Aeon of the Child".
The child is not merely a symbol of growth, but of complete moral independence and innocence. We may then expect the New Aeon to release mankind from its pretence of altruism, its obsession of fear and its consciousness of sin. It will possess no consciousness of the purpose of its own existence. It will not be possible to persuade it that it should submit to incomprehensible standards; it will suffer from spasms of transitory passion; it will be absurdly sensitive to pain and suffer from meaningless terror; it will be utterly conscienceless, cruel, helpless, affectionate and ambitious, without knowing why; it will be incapable of reason, yet at the same time intuitively aware of truth.
I might go on indefinitely to enumerate the stigmata of child psychology, but the reader can do it equally for himself, and every idea that comes to him as characteristic of children will strike him as applicable to the events of history since 1904, from the Great War to Prohibition. And if he possess any capacity for understanding the language of symbolism, he will be staggered by the adequacy and accuracy of the summary of the spirit of the New Aeon given in The Book of the Law.
Qabalah of "The Book of the Law".
The general method that Crowley used to interpret the obscurities of "Liber AL" was the Qabalah, especially its numerological method of gematria. He writes, "Many such cases of double entendre, paronomasia in one language or another, sometimes two at once, numerical-literal puzzles, and even (on one occasion) an illuminating connexion of letters in various lines by a slashing scratch, will be found in the Qabalistic section of the Commentary." In "Magick Without Tears" he wrote:
Now there was enough comprehensible at the time to assure me that the Author of the Book knew at least as much Qabalah as I did: I discovered subsequently more than enough to make it certain without error that he knew a very great deal more, and that of an altogether higher order, than I knew; finally, such glimmerings of light as time and desperate study have thrown on many other obscure passages, to leave no doubt whatever in my mind that he is indeed the supreme Qabalist of all time.
He considered the various gematria values of certain key words and phrases, overlapping between the English, Greek, and Hebrew languages, as evidence of the Book's praeterhuman origin.
... it claims to be the statement of transcendental truth, and to have overcome the difficulty of expressing such truth in human language by what really amounts to the invention of a new method of communicating thought, not merely a new language, but a new type of language; a literal and numerical cipher involving the Greek and Hebrew Cabbalas, the highest mathematics etc. It also claims to be the utterance of an illuminated mind co-extensive with the ultimate ideas of which the universe is composed.
How could he prove that he was in fact a being of a kind superior to any of the human race, and so entitled to speak with authority? Evidently he must show KNOWLEDGE and POWER such as no man has ever been known to possess.
He showed his KNOWLEDGE chiefly by the use of cipher or cryptogram in certain passages to set forth recondite facts, including some events which had yet to take place, such that no human being could possibly be aware of them; thus, the proof of his claim exists in the manuscript itself. It is independent of any human witness.
The study of these passages necessarily demands supreme human scholarship to interpret— it needs years of intense application. A great deal has still to be worked out. But enough has been discovered to justify his claim; the most sceptical intelligence is compelled to admit its truth.
This matter is best studied under the Master Therion, whose years of arduous research have led him to enlightenment.
On the other hand, the language of most of the Book is admirably simple, clear and vigorous. No one can read it without being stricken in the very core of his being.
The more than human POWER of Aiwass is shewn by the influence of his Master, and of the Book, upon actual events: and history fully supports the claim made by him. These facts are appreciable by everyone; but are better understood with the help of the Master Therion.
The existence of true religion presupposes that of some discarnate intelligence, whether we call him God or anything else. And this is exactly what no religion had ever proved scientifically. And this is what "The Book of the Law" does prove by internal evidence, altogether independent of any statement of mine. This proof is evidently the most important step in science that could possibly be made: for it opens up an entirely new avenue to knowledge. The immense superiority of this particular intelligence, AIWASS, to any other with which mankind has yet been in conscious communication is shown not merely by the character of the book itself, but by the fact of his comprehending perfectly the nature of the proof necessary to demonstrate the fact of his own existence and the conditions of that existence. And, further, having provided the proof required.
Prophecy of the Book.
Crowley would later consider the subsequent events of his life, and the apparent fulfilment of certain 'predictions' of the book, as further proof:
The author of "The Book of the Law" foresaw and provided against all such difficulties by inserting in the text discoveries which I did not merely not make for years afterwards, but did not even possess the machinery for making. Some, in fact, depend upon events which I had no part in bringing about.
One such key event was Charles Stansfeld Jones claiming the grade of Magister Templi, which Crowley saw as the birth of his 'Magical Son'. Crowley believed that Jones later went on to "discover the Key of it all" as foretold in the book (II:76, III:47).
Crowley believed that Jones' discovery of the critical value of 31 gave Crowley further insight into his qabalistic understanding and interpretation of the book. Upon receiving notification of this discovery, Crowley replied:
\ = 418. "Thou knowest not." Your key opens Palace. CCXX has unfolded like a flower. All solved, even II.76 & III.47. Did you know Π = 3.141593? And oh! lots more!
"The Comment".
Based on several passages, including: "My scribe Ankh-af-na-khonsu, the priest of the princes, shall not in one letter change this book; but lest there be folly, he shall comment thereupon by the wisdom of Ra-Hoor-Khuit" (AL I:36), Crowley felt compelled to interpret AL in writing. He wrote two large sets of commentaries where he attempted to decipher each line.
However, he was not satisfied with these attempts. In 1912, he prepared AL and his current comments on it for publication in The Equinox, I(7). He recalls in his confessions (p. 674) that he thought the existing commentary was "shamefully meagre and incomplete." He later explains, "I had stupidly supposed this Comment to be a scholarly exposition of the Book, an elucidation of its obscurities and a demonstration of its praeterhuman origin. I understand at last that this idea is nonsense. The Comment must be an interpretation of the Book intelligible to the simplest minds, and as practical as the Ten Commandments." Moreover, this Comment should be arrived at "inspirationally," as the Book itself had been.
Years later in 1925 while in Tunis, Tunisia, Crowley received his inspiration. He published the Comment in the Tunis edition of "AL", of which only 11 copies were printed, and what was to become called simply The Comment (which is also called the Short Comment or Tunis Comment), and signed it as Ankh-f-n-khonsu (lit. "He Lives in Khonsu"—a historical priest who lived in Thebes in the 26th dynasty, associated with the Stele of Revealing). It advises the reader that the "study" of the Book is forbidden and states that those who "discuss the contents" are to be shunned. It also suggests that the book be destroyed after first reading.
Crowley later tasked his friend and fellow O.T.O. member Louis Wilkinson with preparing an edited version of Crowley's commentaries which was published some time after Crowley's death as "The Law is for All."
Michael Aquino's commentary.
Michael Aquino of the Temple of Set produced a commentary on "The Book of the Law" based on a Setian perspective. Aquino's commentary is based on concepts introduced in "The Book of Coming Forth by Night", a text that Aquino claimed was divinely inspired by the Egyptian god Set. Aquino stated that the commentary is based on "the perceptual vantage-point of the Aeon of Set as opposed to that of the Aeon of Horus." Aquino claimed that Crowley incorrectly identified the deities depicted on the Stele of Revealing as belonging to the "Osirian triad" (i.e. Osiris, Isis, and Horus the Younger) whereas they are actually associated with the Theban Sun-cult associated with Horus the Elder. In Egyptian mythology, Horus the Younger was the enemy of Set, whereas Horus the Elder, also known as "Harwer" was actually closely associated with Set and was also cast as "the champion of Set in the Osirian mythos".
Skeptical interpretations.
Crowley's former secretary Israel Regardie argued in his biography of Crowley, "The Eye in the Triangle", that Aiwass was an unconscious expression of Crowley's personality. Regardie stated that although Crowley initially regarded Aiwass as one of the secret chiefs, years later he came to believe that Aiwass was his own Holy Guardian Angel. Regardie argued: "If Aiwass was his own Higher Self, then the inference is none other than that Aleister Crowley was the author of the Book, and that he was the external mask for a variety of different hierarchical personalities ... The man Crowley was the lowest rung of the hierarchical ladder, the outer shell of a God, even as we all are, the persona of a Star ... He is the author of "The Book of the Law" even as he is the author of "The Book of the Heart Girt with a Serpent" and "Liber Lapidis Lazuli", and so forth ... these latter books reveal a dialogue between the component parts of Crowley. It seems to me that basically this "Liber Legis" is no different". Regardie also noted resemblances between "The Book of the Law" and these latter holy books, such as the inclusion of "rambling, unintelligible" passages, "some repugnant to reason by their absurdity, and their jarring goatish quality". In 1906 Crowley wrote: "It has struck me – in connection with reading Blake that Aiwass, etc. "Force and Fire" is the very thing I lack. My "conscience" is really an obstacle and a delusion, being a survival of heredity and education." Regardie considered this an "illuminating admission" and argued that due to Crowley’s early religious training he developed an overly rigid superego or conscience. When he rebelled against Christianity, "he must have yearned for qualities and characteristics diametrically opposed to his own. In "The Book of the Law" the wish is fulfilled". "The Book of the Law" was therefore a "colossal wish-fulfilment". Regardie noted that the Book’s rejection of Judaeo-Christian mores was completely in accord with Crowley’s own moral and religious values and that in this sense "it is his Book". Furthermore, although Crowley claimed to have initially objected to the Book's contents, Regardie said that he could not see what a person like Crowley would possibly object to. Regardie referred to Crowley's 1909 statement: "I want blasphemy, murder, rape, revolution, anything, bad or good, but strong", and pointed out that "The Book of the Law" delivered all these things.
He also argued that Rose's ability to answer Crowley's questions about Horus and the Qabala was not as remarkable as Crowley claimed. Rose had been married to Crowley for eight months at this point and Regardie stated that Crowley may well have used Rose as a 'sounding board' for many of his own ideas. Therefore she may not have been as ignorant of magick and mysticism as Crowley let on.
Charles R. Cammell, author of "Aleister Crowley: The Man, the Mage, the Poet" also believed the Book was an expression of Crowley's personality:
The mind behind the maxims is cold, cruel and relentless. Mercy there is none, nor consolation; nor hope save in the service of this dread messenger of the gods of Egypt. Such is "Liber Legis" in letter and spirit; and as such, and in consideration of its manner of reception, it is a document of curious interest. That it is in part (but in part only) an emanation from Crowley's unconscious mind I can believe; for it bears a likeness to his own Daemonic personality.
Journalist Sarah Veale has also argued that Aiwass was an externalised part of Crowley's psyche, and in support of this hypothesis quotes Crowley himself as saying:
Ah, you realize that magick is something we do to ourselves. But it is more convenient to assume the objective existence of an angel who gives us new knowledge than to allege that our invocation has awakened a supernormal power in ourselves." (Kaczynski, 542).
Veale also pointed out the similarity in rhythmic style between "The Book of the Law" and some of Crowley's own non-channelled writings. In "Magick in theory and practice", Crowley claimed that invoking the "barbarous names" in iambic tetrameter was very useful. Many of his own poems are written in iambic tetrameter, such as this excerpt from "The Riddle", a poem to his former lover, Jerome Pollitt:
<poem>Habib hath heard; let all Iran
who spell aright from A to Z
Exalt thy fame and understand
with whom I made a marriage-bed</poem>
Veale states that there are other similarities in writing styles besides the use of the same poetic meter. The fact that a supposedly discarnate intelligence just happened to have the same writing style as Crowley, suggests that Aiwass may have just been part of Crowley's unconscious mind after all.
Scholar Joshua Gunn also argued that the stylistic similarities between the Book and Crowley's poetic writings were too great for it to be anything other than Crowley's work:
Although Crowley sincerely believed that "The Book of the Law" was inspired by superhuman intelligences, its clichéd imagery, overwrought style, and overdone ecophonetic displays are too similar to Crowley's other poetic writings to be the product of something supernatural.
Editions.
The original manuscript of "The Book of the Law" was sent on Crowley's death to Karl Germer, the executor of his will and head of the A.'.A.'. On Germer's death no trace of it could be found in his papers. There matters rested until 1984, when Tom Whitmore, the new owner of a house in Berkeley, California, began searching through the junk left in the basement by the previous owner. Among the used mattresses, lumber, and outdated high school textbooks were two boxes of assorted papers and newspaper clippings dealing with Germer's affairs, the charter of the O.T.O. and an envelope containing the manuscript of "The Book of the Law". Whitmore donated the papers to the O.T.O. How they found their way to a Berkeley basement remains a complete mystery. 
"Liber AL" is also published in many books, including:
And at least one out-of-print audio version common on eBay:

</doc>
<doc id="30740" url="http://en.wikipedia.org/wiki?curid=30740" title="Classical unities">
Classical unities

The classical unities, Aristotelian unities, or three unities are rules for drama derived from a passage in Aristotle's "Poetics". In their neoclassical form they are as follows:
Aristotle's unities.
Aristotle dealt with the unity of action in some detail, under the general subject of "definition of tragedy", where he wrote:
Now, according to our definition, Tragedy is an imitation of an action that is complete, and whole, and of a certain magnitude … As therefore, in the other imitative arts, the imitation is one when the object imitated is one, so the plot, being an imitation of an action, must imitate one action and that a whole, the structural union of the parts being such that, if any one of them is displaced or removed, the whole will be disjointed and disturbed. For a thing whose presence or absence makes no visible difference, is not an organic part of the whole.
His only reference to the time in the fictive world is in a distinction between the epic and tragic forms:
Epic poetry agrees with Tragedy in so far as it is an imitation in verse of characters of a higher type. They differ, in that Epic poetry admits but one kind of metre, and is narrative in form. They differ, again, in their length: for Tragedy endeavours, as far as possible, to confine itself to a single revolution of the sun, or but slightly to exceed this limit; whereas the Epic action has no limits of time.
Unlike his prescriptive attitude regarding the plot (unity of action), Aristotle here merely remarks on the typical duration of a tragedy's action, and does not suggest any kind of imperative that it always ought to be so. He was writing after the golden age of Greek drama, and many Greek playwrights wrote plays that do not fit within these conventions. 
Aristotle does not actually mention the neoclassical unity of place at all. However, the prevalent interpretation of his "Poetics" during the Middle Ages inclined toward interpreting his comment on time as another "unity".
European literature.
Italian critics of the 16th century, from Lodovico Castelvetro onwards, and then 17th-century French critics, proponents of the neoclassical movement, both expanded Aristotle's descriptions. The result was to make them into prescriptions for structuring plays. French drama of the 17th century, particularly that of Molière and Racine was highly regular; whereas the English dramatists writing for the Elizabethan and Jacobean stage were largely unaware of these strictures.
By the later 17th century, however, English dramatists (under the influence of French criticism picked up by those in exile during the English Interregnum) did begin to assess their own plays according to these rules. Thus, John Dryden, among many others, compares the "irregular" Shakespeare (only two of Shakespeare's plays conform to the unities - "The Comedy of Errors" and "The Tempest") with the "regular" Dryden in his "Essay of Dramatick Poesie" (1668), and makes use of the unity of time in this passage criticizing Shakespeare's history plays:
... if you consider the Historical Playes of Shakespeare, they are rather so many Chronicles of Kings, or the business many times of thirty or forty years, crampt into a representation of two hours and a half, which is not to imitate or paint Nature, but rather to draw her in miniature, to take her in little; to look upon her through the wrong end of a Perspective, and receive her Images not onely much less, but infinitely more imperfect then the life: this instead of making a Play delightful, renders it ridiculous.
However, Dryden declared Shakespeare "incomparable" because of his disregard for convention:
... in most of the irregular Playes of Shakespeare or Fletcher (for Ben Johnson's are for the most part regular) there is a more masculine fancy and greater spirit in all the writing, then[sic] there is in any of the French.
Alexander Pope criticizes the violation of the unities in his "Dunciad". In the 1728 version of the poem, the goddess Dulness notes that "Time himself stands still at her command,/ Realms shift their place, and Ocean turns to land" ("Dunciad" 1728, i, 69–70). Additionally, he notes a violation of unity of action, as tragedy and comedy were mixed.
Samuel Johnson, too, applied the unities to drama in his "Prefaces to Shakespeare". He was well aware that Aristotle had only recommended the unity of action, and knew that rules must serve drama, not vice versa:
Whether Shakespeare knew the unities, and rejected them by design, or deviated from them by happy ignorance, it is, I think, impossible to decide, and useless to inquire. We may reasonably suppose, that, when he rose to notice, he did not want the counsels and admonitions of scholars and critics, and that he at last deliberately persisted in a practice, which he might have begun by chance. As nothing is essential to the fable, but unity of action, and as the unities of time and place arise evidently from false assumptions, and, by circumscribing the extent of the drama, lessen its variety, I cannot think it much to be lamented, that they were not known by him, or not observed: Nor, if such another poet could arise, should I very vehemently reproach him, that his first act passed at Venice, and his next in Cyprus. Such violations of rules merely positive, become the comprehensive genius of Shakespeare…
The classical unities were influential in dramatic criticism until Victor Hugo's "Hernani" (1830); one of the things that made that play controversial at its debut was its violation of these rules of classicism. In the Spanish theatrical tradition, there is Lope de Vega's "Arte nuevo de hacer comedias" of 1609, which is a defense of the new form for writing and representation of Golden Age Spanish theater. Lope's "Arte nuevo", is a 389 verse poem which explicitly defends his and other dramaturges, distancing from Aristotelian unities of theater.

</doc>
<doc id="30741" url="http://en.wikipedia.org/wiki?curid=30741" title="Tlaloc">
Tlaloc

Tlaloc (Classical Nahuatl: "Tlāloc" ) was an important deity in Aztec religion; as supreme god of the rains, he was also by extension a god of fertility and of water. He was widely worshiped as a beneficent giver of life and sustenance, but he was also feared for his ability to send hail, thunder, and lightning, and for being the lord of the powerful element of water. Tlaloc is also associated with caves, springs, and mountains, most specifically the sacred mountain in which he was believed to reside. His animal forms include herons and other wet or water dwelling creatures such as amphibians, snails, and possibly sea creatures, particularly ones that inhabit seashells. A specific plant also bears a relationship to Tlaloc. Known to the Aztecs as Yauhtli, "Tagetes lucida", was burned as a ritual incense in native religious ceremonies.
The cult of Tlaloc is one of the oldest and most universal in ancient Mexico. Although the name Tlaloc is specifically Aztec, worship of a storm god like Tlaloc, almost always associated with mountaintop shrines and with life-giving rain, is as at least as old as Teotihuacan and likely was adopted from the Maya god Chaac or vice versa, and/or ultimately perhaps from an earlier Olmec precursor. An underground Tlaloc shrine has been found at Teotihuacan.
In Aztec cosmology, the four corners of the universe are marked by "the four Tlalocs" (Classical Nahuatl: "Tlālōquê" ) which both hold up the sky and function as the frame for the passing of time. Tlaloc was the patron of the Calendar day "Mazātl." In Aztec mythology, Tlaloc was the lord of the third sun which was destroyed by fire.
Additionally, Tlaloc is thought to be one of the patron deities of the trecena of 1 Quiahuitl (along with Chicomecoatl). Trecenas are the thirteen-day periods into which the 260-day calendar is divided. The first day of each trecena dictates the augury, or omen, and the patron deity or deities associated with the trecena.
In the Aztec capital Tenochtitlan, one of the two shrines on top of the Great Temple was dedicated to Tlaloc. The high priest who was in charge of the Tlaloc shrine was called "Quetzalcoatl Tlaloc Tlamacazqui." It was the northernmost side of this temple that was dedicated to Tlaloc, the god of rain and agricultural fertility. In this area, a bowl was kept in which sacrificial hearts placed on certain occasions, as offerings to the rain gods. Although Templo Mayor had its northern section dedicated to Tlaloc, the most important site of worship of the rain god was on the peak of Mount Tlaloc, a 4100-meter-high mountain on the eastern rim of the Valley of Mexico. Here the Aztec ruler came and conducted important ceremonies once a year, and throughout the year pilgrims offered precious stones and figures at the shrine. Many of the offerings found here also related to water and the sea.
Representations.
In Aztec iconography, Tlaloc is usually depicted with goggle eyes and fangs. He is most often coupled with lightning, maize, and water in visual representations and artwork. Tlaloc is thought to be one of the most common and appreciated of all deities at Teotihuacan and it is specifically here, in Teotihuacan, that representations of Tlaloc often show him having jaguar teeth and features. This differs from the Maya version of Tlaloc, however, as the Maya version shows no specific relation to jaguars. The inhabitants of Teotihuacan thought of thunder as the rumblings of the jaguar and associated thunder with Tlaloc as well. It is likely that this god was given these associations because he is also known as "the provider" among the Aztecs. Offerings dedicated to Tlaloc in Tenochtitlan were known to include several jaguar skulls and even a complete jaguar skeleton. Jaguars were considered the ultimate sacrificial animal due to their value.
Tlaloc's impersonators often wore the distinctive mask and heron-feather headdress, usually carrying a cornstalk or a symbolic lightning bolt wand; another symbol was a ritual water jar. Along with this, Tlaloc is manifested in the form of boulders at shrine-sites, and in the Valley of Mexico the primary shrine of this deity was located atop Mount Tlaloc.
In Coatlinchan, a colossal statue weighing 168 tons was found that was thought to represent Tlaloc. However, one scholar believes that the statue may not have been Tlaloc at all but his sister or some other female deity. This statue was relocated to the National Museum of Anthropology in Mexico City in 1964.
Mythology.
In Aztec mythic cosmography, Tlaloc ruled the fourth layer of the upper world, or heavens, which is called Tlalocan ("place of Tlaloc") in several Aztec codices, such as the Vaticanus A and Florentine codices. Described as a place of unending springtime and a paradise of green plants, Tlalocan was the destination in the afterlife for those who died violently from phenomena associated with water, such as by lightning, drowning, and water-borne diseases. These violent deaths also included leprosy, venereal disease, sores, dropsy, scabies, gout, and child sacrifices.
The Nahua believed that Huitzilopochtli could provide them with fair weather for their crops and they placed an image of Tlaloc, who was the rain-god, near him so that if necessary, the war god could compel the rain maker to exert his powers.
Etymology.
Tlaloc was also associated with the watery world of the dead and with the earth. His name is thought to be derived from the Nahuatl word "tlālli" "earth", and its meaning has been interpreted as "path beneath the earth," "long cave," or "he who is made of earth." J. Richard Andrews interprets it as "one that lies on the land," identifying Tlaloc as a cloud resting on the mountaintops. Other names of Tlaloc were Tlamacazqui ("Giver") and Xoxouhqui ("Green One"); and (among the contemporary Nahua of Veracruz), Chaneco.
Rites and rituals.
The Tlalocan-bound dead were not cremated as was standard custom, but instead were buried in the earth with seeds planted in their faces and blue paint covering their foreheads. Their bodies were dressed in paper and accompanied by a digging stick for planting put in their hands.
The second shrine on top of the main pyramid at Tenochtitlan was dedicated to Tlaloc. Both his shrine, and Huitzilopochtli′s next to it, faced west. Sacrifices and rites took place in these temples. The Aztecs believed Tlaloc resided in mountain caves, thus his shrine in Tenochtitlan’s pyramid was called "mountain abode." Many rich offerings were regularly placed before it, especially those linked to water such as jade, shells, and sand. Mount Tlaloc, the jewel in the crown of Tlaloc’s places of worship, was situated directly east of the pyramid. It was 44 miles away and a long road connected the two places of worship. On it was a shrine containing stone images of the mountain itself and other neighboring peaks. The shrine was called Tlalocan, in reference to the paradise. Also to be found inside its walls were four pitchers containing water. Each pitcher would bring a different fate if used on crops: the first would bring forth a good harvest, the second would rot it, the third would dry the harvest out, and the final one would freeze it. Sacrifices that took place here were thought to favor early rains.
The "Atlcahualo" was celebrated from the 12th of February until the 3rd of March. Dedicated to the Tlaloque, this veintena involved the sacrifice of many children on sacred mountaintops. The children were beautifully adorned, dressed in the style of Tlaloc and the Tlaloque. On litters strewn with flowers and feathers; surrounded by dancers, they were transported to a shrine and their hearts would be pulled out by priests. If, on the way to the shrine, these children cried, their tears were viewed as signs of imminent and abundant rains. Every Atlcahualo festival, seven children were sacrificed in and around Lake Texcoco in the Aztec capital. They were either slaves or the second-born children of nobles.
The festival of Tozoztontli (24 March – 12 April) similarly involved child sacrifice. During this festival, offerings were made in caves. The flayed skins of sacrificial victims that had been worn by priests for the last twenty days were taken off and placed in these dark, magical caverns.
The winter "veintena" of Atemoztli (9 December- 28 December) was also dedicated to the Tlaloque. This period preceded an important rainy season and so statues were made out of amaranth dough. Their teeth were pumpkin seeds and their eyes, beans. Once these statues were offered copal and fine scents, prayed to, and adorned, food was presented before them.
Afterwards, their doughy chests were opened, their "hearts" taken out and, finally, their bodies cut up and eaten. The ornaments with which they had been adorned were taken and burned in peoples’ patios. On the final day of the "veintena," people celebrated and held banquets.
Related gods.
Archaeological evidence indicates Tlaloc was worshiped in Mesoamerica before the Aztecs even settled there in the 13th century AD. He was a prominent god in Teotihuacan at least 800 years before the Aztecs. This has led to Meso-American goggle-eyed rain gods being referred to generically as "Tlaloc," although in some cases it is unknown what they were called in these cultures, and in other cases we know that he was called by a different name, e.g., the Mayan version was known as Chaac and the Zapotec deity as Cocijo.
Chalchiuhtlicue or "she of the jade skirt," was the deity connected with the worship of ground water. Her shrines were therefore by springs, streams, irrigation ditches, or aqueducts, the most important of these shrines being at Pantitlan, in the center of Lake Tetzcoco. Sometimes described as Tlaloc's sister, Chalchiuhtlicue was impersonated by ritual performers wearing the green skirt that identifies the deity. Like that of Tlaloc, this cult was linked to the earth, fertility and nature's regeneration.
Tlaloc was first married to the goddess of flowers, Xochiquetzal, which literally translates to "Flower Quetzal." Xochiquetzal personifies pleasure, flowers, and young female sexual power. In doing so, she is thought to oversee pregnancies and childbirths and act as a guardian figure for new mothers. Unlike many other female Aztec deities, Xochiquetzal maintains her youthful looks and is often depicted in opulent attire and gold adornments.
Tlaloc was the father of Tecciztecatl, possibly with Chalchiuhtlicue. Also, Tlaloc had an older sister named Huixtocihuatl.
Mount Tlaloc.
There is a sanctuary found atop Mount Tlaloc, dedicated to the god, Tlaloc; it is thought that the location of this sanctuary in relation to other temples surrounding it may have been a way for the Aztecs to mark the time of year and keep track of important ceremonial dates. Research has shown in fact that different orientations linked to Mount Tlaloc revealed a grouping of dates at the end of April and beginning of May associated with certain astronomical and meteorological events. Arcaheological, ethnohistoric, and ethnographic data indicate that these phenomena coincide with the sowing of maize in dry lands associated with agricultural sites.
Geographical Setting.
Mount Tlaloc is the highest peak of the part of the Sierra Nevada called Sierra del Rio Frio that separates the valleys of Mexico and Puebla. It rises over two diffierent ecological zones: alpine meadows and subalpine forests. The rainy season starts in May and lasts until October. The highest annual temperature occurs in April, the onset of the rainy season, and the lowest in December–January. Some 500 years ago weather conditions were slightly more severe, but the best time to climb the mountain was practically the same as today: October through December, and February until the beginning of May. The date of the feast of Huey Tozotli celebrated atop Mount Tlaloc coincided with a period of the highest annual temperature, shortly before dangerous thunderstorms might block access to the summit.
Archaeological Evidence.
The first detailed account of Mount Tlaloc by Jim Rickards in 1929 was followed by visits or descriptions by other scholars. In 1953 Wicke and Horcasitas carried out preliminary archaeological investigations at the site; their conclusions were repeated by Parsons in 1971. Archaeo-astronomical research began in 1984, some of which remains unpublished. In 1989 excavation was undertaken at the site by Solis and Townsend.

</doc>
<doc id="30745" url="http://en.wikipedia.org/wiki?curid=30745" title="Titius–Bode law">
Titius–Bode law

The Titius–Bode law (sometimes termed just Bode's law) is a hypothesis that the bodies in some orbital systems, including the Sun's, orbit at semi-major axes in a function of planetary sequence. The hypothesis correctly predicted the orbits of Ceres and Uranus, but failed as a predictor of Neptune's orbit. It is named for Johann Daniel Titius and Johann Elert Bode.
Formulation.
The law relates the semi-major axis formula_1 of each planet outward from the Sun in units such that the Earth's semi-major axis is equal to 10:
where formula_3 with the exception of the first step, each value is twice the previous value. 
There is another representation of the formula: formula_4
where formula_5.
The resulting values can be divided by 10 to convert them into astronomical units (AU), resulting in the expression
for formula_7
For the outer planets, each planet is predicted to be roughly twice as far from the Sun as the previous object.
History.
The first mention of a series approximating Bode's Law is found in David Gregory's "The Elements of Astronomy", published in 1715. In it, he says, "...supposing the distance of the Earth from the Sun to be divided into ten equal Parts, of these the distance of Mercury will be about four, of Venus seven, of Mars fifteen, of Jupiter fifty two, and that of Saturn ninety six." A similar sentence, likely paraphrased from Gregory, appears in a work published by Christian Wolff in 1724.
In 1764, Charles Bonnet said in his "Contemplation de la Nature" that, "We know seventeen planets that enter into the composition of our solar system [that is, major planets and their satellites]; but we are not sure that there are no more." To this, in his 1766 translation of Bonnet's work, Johann Daniel Titius added the following unattributed addition, removed to a footnote in later editions:
Take notice of the distances of the planets from one another, and recognize that almost all are separated from one another in a proportion which matches their bodily magnitudes. Divide the distance from the Sun to Saturn into 100 parts; then Mercury is separated by four such parts from the Sun, Venus by 4+3=7 such parts, the Earth by 4+6=10, Mars by 4+12=16. But notice that from Mars to Jupiter there comes a deviation from this so exact progression. From Mars there follows a space of 4+24=28 such parts, but so far no planet was sighted there. But should the Lord Architect have left that space empty? Not at all. Let us therefore assume that this space without doubt belongs to the still undiscovered satellites of Mars, let us also add that perhaps Jupiter still has around itself some smaller ones which have not been sighted yet by any telescope. Next to this for us still unexplored space there rises Jupiter's sphere of influence at 4+48=52 parts; and that of Saturn at 4+96=100 parts.
In 1772, Johann Elert Bode, aged only twenty-five, completed the second edition of his astronomical compendium "Anleitung zur Kenntniss des gestirnten Himmels" (“Manual for Knowing the Starry Sky”), into which he added the following footnote, initially unsourced, but credited to Titius in later versions:
This latter point seems in particular to follow from the astonishing relation which the known six planets observe in their distances from the Sun. Let the distance from the Sun to Saturn be taken as 100, then Mercury is separated by 4 such parts from the Sun. Venus is 4+3=7. The Earth 4+6=10. Mars 4+12=16. Now comes a gap in this so orderly progression. After Mars there follows a space of 4+24=28 parts, in which no planet has yet been seen. Can one believe that the Founder of the universe had left this space empty? Certainly not. From here we come to the distance of Jupiter by 4+48=52 parts, and finally to that of Saturn by 4+96=100 parts.
When originally published, the law was approximately satisfied by all the known planets — Mercury through Saturn — with a gap between the fourth and fifth planets. It was regarded as interesting, but of no great importance until the discovery of Uranus in 1781 which happens to fit neatly into the series. Based on this discovery, Bode urged a search for a fifth planet. Ceres, the largest object in the asteroid belt, was found at Bode's predicted position in 1801. Bode's law was then widely accepted until Neptune was discovered in 1846 and found not to satisfy Bode's law. Simultaneously, the large number of known asteroids in the belt resulted in Ceres no longer being considered a planet at that time. Bode's law was discussed as an example of fallacious reasoning by the astronomer and logician Charles Sanders Peirce in 1898.
The discovery of Pluto in 1930 confounded the issue still further. While nowhere near its position as predicted by Bode's law, it was roughly at the position the law had predicted for Neptune. However, the subsequent discovery of the Kuiper belt, and in particular of the object Eris, which is larger than Pluto yet does not fit Bode's law, have further discredited the formula.
Data.
Here are the distances of planets in the Solar System, calculated from the rule and compared with the real ones:
Theoretical explanations.
There is no solid theoretical explanation of the Titius–Bode law, but if there is one it is possibly a combination of orbital resonance and shortage of degrees of freedom: any stable planetary system has a high probability of satisfying a Titius–Bode-type relationship. Since it may simply be a mathematical coincidence rather than a "law of nature", it is sometimes referred to as a rule instead of "law". However, astrophysicist Alan Boss states that it is just a coincidence, and the planetary science journal "Icarus" no longer accepts papers attempting to provide improved versions of the law.
Orbital resonance from major orbiting bodies creates regions around the Sun that are free of long-term stable orbits. Results from simulations of planetary formation support the idea that a randomly chosen stable planetary system will likely satisfy a Titius–Bode law.
Dubrulle and Graner have shown that power-law distance rules can be a consequence of collapsing-cloud models of planetary systems possessing two symmetries: rotational invariance (the cloud and its contents are axially symmetric) and scale invariance (the cloud and its contents look the same on all scales), the latter being a feature of many phenomena considered to play a role in planetary formation, such as turbulence.
Lunar systems and other planetary systems.
There is a decidedly limited number of systems on which Bode's law can presently be tested. Two of the solar planets have a number of big moons that appear possibly to have been created by a process similar to that which created the planets themselves. The four big satellites of Jupiter and the biggest inner satellite, Amalthea, cling to a regular, but non-Bode, spacing with the four innermost locked into orbital periods that are each twice that of the next inner satellite. The big moons of Uranus have a regular, but non-Bode, spacing. However, according to Martin Harwit, "a slight new phrasing of this law permits us to include not only planetary orbits around the Sun, but also the orbits of moons around their parent planets." The new phrasing is known as Dermott's law.
Of the recent discoveries of extrasolar planetary systems, few have enough known planets to test whether similar rules apply to other planetary systems. An attempt with 55 Cancri suggested the equation a = 0.0142 "e" 0.9975 "n", and predicts for "n" = 5 an undiscovered planet or asteroid field at 2 AU. This is controversial. Furthermore the orbital period and semimajor axis of the innermost planet in the 55 Cancri system have been significantly revised (from 2.817 days to 0.737 days and from 0.038 AU to 0.016 AU respectively) since the publication of these studies.
Recent astronomical research suggests that planetary systems around some other stars may fit Titius–Bode-like laws. Bovaird and Lineweaver applied a generalized Titius-Bode relation to 68 exoplanet systems which contain four or more planets. They showed that 96% of these exoplanet systems adhere to a generalized Titius-Bode relation to a similar or greater extent than the Solar System does. The locations of potentially undetected exoplanets are predicted in each system.
Subsequent research managed to detect five planet candidates from predicted 97 planets from the 68 planetary systems. The study showed that the actual number of planets could be larger. The occurrence rate of Mars and Mercury sized planets are currently unknown so many planets could be missed due to their small size. Other reasons were accounted to planet not transiting the star or the predicted space being occupied by circumstellar disks. Despite this, the number of planets found with Titius–Bode law predictions were still lower than expected.

</doc>
<doc id="30746" url="http://en.wikipedia.org/wiki?curid=30746" title="Theory">
Theory

Theory is a contemplative and rational type of abstract or generalizing thinking, or the results of such thinking. Depending on the context, the results might for example include generalized explanations of how nature works. The word has its roots in ancient Greek, but in modern use it has taken on several different related meanings. A theory is not the same as a hypothesis. A theory provides an explanatory framework for some observation, and from the assumptions of the explanation follows a number of possible hypotheses that can be tested in order to provide support for, or challenge, the theory.
A theory can be "normative" (or prescriptive), meaning a postulation about what ought to be. It provides "goals, norms, and standards". A theory can be a body of knowledge, which may or may not be associated with particular explanatory models. To theorize is to develop this body of knowledge.
As already in Aristotle's definitions, theory is very often contrasted to "practice" (from Greek "", πρᾶξις) a Greek term for "doing", which is opposed to theory because pure theory involves no doing apart from itself. A classical example of the distinction between "theoretical" and "practical" uses the discipline of medicine: medical theory involves trying to understand the causes and nature of health and sickness, while the practical side of medicine is trying to make people healthy. These two things are related but can be independent, because it is possible to research health and sickness without curing specific patients, and it is possible to cure a patient without knowing how the cure worked.
In modern science, the term "theory" refers to scientific theories, a well-confirmed type of explanation of nature, made in a way consistent with scientific method, and fulfilling the criteria required by modern science. Such theories are described in such a way that any scientist in the field is in a position to understand and either provide empirical support ("verify") or empirically contradict ("falsify") it. Scientific theories are the most reliable, rigorous, and comprehensive form of scientific knowledge, in contrast to more common uses of the word "theory" that imply that something is unproven or speculative (which is better characterized by the word 'hypothesis'). Scientific theories are distinguished from hypotheses, which are individual empirically testable conjectures, and scientific laws, which are descriptive accounts of how nature will behave under certain conditions.
Ancient uses.
The English word theory was derived from a technical term in philosophy in Ancient Greek. As an everyday word, "theoria", θεωρία, meant "a looking at, viewing, beholding", but in more technical contexts it came to refer to contemplative or speculative understandings of natural things, such as those of natural philosophers, as opposed to more practical ways of knowing things, like that of skilled orators or artisans. The word has been in use in English since at least the late 16th century. Modern uses of the word "theory" are derived from the original definition, but have taken on new shades of meaning, still based on the idea that a theory is a thoughtful and rational explanation of the general nature of things.
Although it has more mundane meanings in Greek, the word θεωρία apparently developed special uses early in the recorded history of the Greek language. In the book "From Religion to Philosophy", Francis Cornford suggests that the Orphics used the word "theory" to mean 'passionate sympathetic contemplation'. Pythagoras changed the word to mean a passionate sympathetic contemplation of mathematical knowledge, because he considered this intellectual pursuit the way to reach the highest plane of existence. Pythagoras emphasized subduing emotions and bodily desires in order to enable the intellect to function at the higher plane of theory. Thus it was Pythagoras who gave the word "theory" the specific meaning which leads to the classical and modern concept of a distinction between theory as uninvolved, neutral thinking, and practice.
In Aristotle's terminology, as has already been mentioned above, theory is contrasted with "praxis" or practice, which remains the case today. For Aristotle, both practice and theory involve thinking, but the aims are different. Theoretical contemplation considers things which humans do not move or change, such as nature, so it has no human aim apart from itself and the knowledge it helps create. On the other hand, "praxis" involves thinking, but always with an aim to desired actions, whereby humans cause change or movement themselves for their own ends. Any human movement which involves no conscious choice and thinking could not be an example of "praxis" or doing.
Theories formally and scientifically.
Theories are analytical tools for understanding, explaining, and making predictions about a given subject matter. There are theories in many and varied fields of study, including the arts and sciences. A formal theory is syntactic in nature and is only meaningful when given a semantic component by applying it to some content (i.e. facts and relationships of the actual historical world as it is unfolding). Theories in various fields of study are expressed in natural language, but are always constructed in such a way that their general form is identical to a theory as it is expressed in the formal language of mathematical logic. Theories may be expressed mathematically, symbolically, or in common language, but are generally expected to follow principles of rational thought or logic.
Theory is constructed of a set of sentences which consist entirely of true statements about the subject matter under consideration. However, the truth of any one of these statements is always relative to the whole theory. Therefore the same statement may be true with respect to one theory, and not true with respect to another. This is, in ordinary language, where statements such as "He is a terrible person" cannot be judged to be true or false without reference to some interpretation of who "He" is and for that matter what a "terrible person" is under the theory.
Sometimes two theories have exactly the same explanatory power because they make the same predictions. A pair of such theories is called indistinguishable or observationally equivalent, and the choice between them reduces to convenience or philosophical preference.
The form of theories is studied formally in mathematical logic, especially in model theory. When theories are studied in mathematics, they are usually expressed in some formal language and their statements are closed under application of certain procedures called rules of inference. A special case of this, an axiomatic theory, consists of axioms (or axiom schemata) and rules of inference. A theorem is a statement that can be derived from those axioms by application of these rules of inference. Theories used in applications are abstractions of observed phenomena and the resulting theorems provide solutions to real-world problems. Obvious examples include arithmetic (abstracting concepts of number), geometry (concepts of space), and probability (concepts of randomness and likelihood).
Gödel's incompleteness theorem shows that no consistent, recursively enumerable theory (that is, one whose theorems form a recursively enumerable set) in which the concept of natural numbers can be expressed, can include all true statements about them. As a result, some domains of knowledge cannot be formalized, accurately and completely, as mathematical theories. (Here, formalizing accurately and completely means that all true propositions—and only true propositions—are derivable within the mathematical system.) This limitation, however, in no way precludes the construction of mathematical theories that formalize large bodies of scientific knowledge.
Underdetermination.
A theory is "underdetermined" (also called "indeterminacy of data to theory") if, given the available evidence cited to support the theory, there is a rival theory which is inconsistent with it that is at least as consistent with the evidence. Underdetermination is an epistemological issue about the relation of evidence to conclusions.
Intertheoretic reduction and elimination.
If there is a new theory which is better at explaining and predicting phenomena than an older theory (i.e. it has more explanatory power), we are justified in believing that the newer theory describes reality more correctly. This is called an "intertheoretic reduction" because the terms of the old theory can be reduced to the terms of the new one. For instance, our historical understanding about "sound", "light" and "heat" have today been reduced to "wave compressions and rarefactions", "electromagnetic waves", and "molecular kinetic energy", respectively. These terms which are identified with each other are called "intertheoretic identities." When an old theory and a new one are parallel in this way, we can conclude that we are describing the same reality, only more completely.
In cases where a new theory uses new terms which do not reduce to terms of an older one, but rather replace them entirely because they are actually a misrepresentation it is called an "intertheoretic elimination." For instance, the obsolete scientific theory that put forward an understanding of heat transfer in terms of the movement of caloric fluid was eliminated when a theory of heat as energy replaced it. Also, the theory that phlogiston is a substance released from burning and rusting material was eliminated with the new understanding of the reactivity of oxygen.
Theories vs. theorems.
Theories are distinct from theorems. Theorems are derived deductively from objections according to a formal system of rules, sometimes as an end in itself and sometimes as a first step in testing or applying a theory in a concrete situation; theorems are said to be true in the sense that the conclusions of a theorem are logical consequences of the objections. Theories are abstract and conceptual, and to this end they are always considered true. They are supported or challenged by observations in the world. They are 'rigorously tentative', meaning that they are proposed as true and expected to satisfy careful examination to account for the possibility of faulty inference or incorrect observation. Sometimes theories are incorrect, meaning that an explicit set of observations contradicts some fundamental objection or application of the theory, but more often theories are corrected to conform to new observations, by restricting the class of phenomena the theory applies to or changing the assertions made. An example of the former is the restriction of Classical mechanics to phenomena involving macroscopic lengthscales and particle speeds much lower than the speed of light.
"Sometimes a hypothesis never reaches the point of being considered a theory because the answer is not found to derive its assertions analytically or not applied empirically."
Philosophical theories.
Theories whose subject matter consists not in empirical data, but rather in ideas are in the realm of "philosophical theories" as contrasted with "scientific theories". At least some of the elementary theorems of a philosophical theory are statements whose truth cannot necessarily be scientifically tested through empirical observation.
Fields of study are sometimes named "theory" because their basis is some initial set of objections describing the field's approach to a subject matter. These assumptions are the elementary theorems of the particular theory, and can be thought of as the axioms of that field. Some commonly known examples include set theory and number theory; however literary theory, critical theory, and music theory are also of the same form.
Metatheory.
One form of philosophical theory is a "metatheory" or "meta-theory". A metatheory is a theory whose subject matter is some other theory. In other words it is a theory about a theory. Statements made in the metatheory about the theory are called metatheorems.
Political theories.
A political theory is an ethical theory about the law and government. Often the term "political theory" refers to a general view, or specific ethic, political belief or attitude, about politics.
Scientific theories.
In science, the term "theory" refers to "a well-substantiated explanation of some aspect of the natural world, based on a body of facts that have been repeatedly confirmed through observation and experiment." Theories must also meet further requirements, such as the ability to make falsifiable predictions with consistent accuracy across a broad area of scientific inquiry, and production of strong evidence in favor of the theory from multiple independent sources.
The strength of a scientific theory is related to the diversity of phenomena it can explain, which is measured by its ability to make falsifiable predictions with respect to those phenomena. Theories are improved (or replaced by better theories) as more evidence is gathered, so that accuracy in prediction improves over time; this increased accuracy corresponds to an increase in scientific knowledge. Scientists use theories as a foundation to gain further scientific knowledge, as well as to accomplish goals such as inventing technology or curing disease.
Definitions from scientific organizations.
The United States National Academy of Sciences defines scientific theories as follows:
The formal scientific definition of "theory" is quite different from the everyday meaning of the word. It refers to a comprehensive explanation of some aspect of nature that is supported by a vast body of evidence. Many scientific theories are so well established that no new evidence is likely to alter them substantially. For example, no new evidence will demonstrate that the Earth does not orbit around the sun (heliocentric theory), or that living things are not made of cells (cell theory), that matter is not composed of atoms, or that the surface of the Earth is not divided into solid plates that have moved over geological timescales (the theory of plate tectonics)...One of the most useful properties of scientific theories is that they can be used to make predictions about natural events or phenomena that have not yet been observed.
From the American Association for the Advancement of Science:
A scientific theory is a well-substantiated explanation of some aspect of the natural world, based on a body of facts that have been repeatedly confirmed through observation and experiment. Such fact-supported theories are not "guesses" but reliable accounts of the real world. The theory of biological evolution is more than "just a theory." It is as factual an explanation of the universe as the atomic theory of matter or the germ theory of disease. Our understanding of gravity is still a work in progress. But the phenomenon of gravity, like evolution, is an accepted fact.
Note that the term "theory" would not be appropriate for describing untested but intricate hypotheses or even scientific models.
Philosophical views.
The logical positivists thought of scientific theories as "deductive theories" - that a theory's content is based on some formal system of logic and on basic axioms. In a deductive theory, any sentence which is a logical consequence of one or more of the axioms is also a sentence of that theory. This is called the received view of theories.
In the semantic view of theories, which has largely replaced the received view, theories are viewed as scientific models. A model is a logical framework intended to represent reality (a "model of reality"), similar to the way that a map is a graphical model that represents the territory of a city or country. In this approach, theories are a specific category of models which fulfill the necessary criteria. (See Theories as models for further discussion.)
In physics.
In physics the term "theory" is generally used for a mathematical framework—derived from a small set of basic postulates (usually symmetries, like equality of locations in space or in time, or identity of electrons, etc.)—which is capable of producing experimental predictions for a given category of physical systems. One good example is classical electromagnetism, which encompasses results derived from gauge symmetry (sometimes called gauge invariance) in a form of a few equations called Maxwell's equations. The specific mathematical aspects of classical electromagnetic theory are termed "laws of electromagnetism", reflecting the level of consistent and reproducible evidence that supports them. Within electromagnetic theory generally, there are numerous hypotheses about how electromagnetism applies to specific situations. Many of these hypotheses are already considered to be adequately tested, with new ones always in the making and perhaps untested.
The term "theoretical".
Acceptance of a theory does not require that all of its major predictions be tested, if it is already supported by sufficiently strong evidence. For example, certain tests may be unfeasible or technically difficult. As a result, theories may make predictions that have not yet been confirmed or proven incorrect; in this case, the predicted results may be described informally with the term "theoretical." These predictions can be tested at a later time, and if they are incorrect, this may lead to revision or rejection of the theory.

</doc>
<doc id="30747" url="http://en.wikipedia.org/wiki?curid=30747" title="TRS-80">
TRS-80

The TRS-80 Micro Computer System (TRS-80; later known as the Model I to distinguish it from successors) is a desktop microcomputer launched in 1977 and sold by Tandy Corporation through their Radio Shack stores. The name is an abbreviation of "Tandy/Radio Shack, Z-80 microprocessor". It was one of the earliest mass-produced personal computers.
By 1979, the TRS-80 had the largest selection of software in the microcomputer market. Until 1982, the TRS-80 was the best-selling PC line, outselling the Apple II series by a factor of 5 according to one analysis.
In mid-1980, the broadly compatible TRS-80 Model III was released. The Model I was discontinued shortly after, primarily due to stricter FCC regulations on the massive radio-frequency interference it caused in surrounding electronics. In 1983, the Model III was in turn succeeded by the compatible Model 4.
As well as the original Model I and its compatible descendants, the TRS-80 name was later used as a generic brand on other technically unrelated computer lines sold by Tandy, such as the TRS-80 Model II, TRS-80 Color Computer and TRS-80 Pocket Computer.
History.
In the mid-1970s, Tandy Corporation's Radio Shack division was a successful American chain of more than 3,000 electronics stores. After buyer Don French purchased a MITS Altair kit computer, he began designing his own and showed it to vice president of manufacturing John Roach. Although the design did not impress Roach, the idea of selling a microcomputer did. When the two men visited National Semiconductor in California in mid-1976, Steve Leininger's expertise on the SC/MP microprocessor impressed them. National executives refused to provide Leininger's contact information when French and Roach wanted to hire him as a consultant, but they found Leininger working part-time at Byte Shop and he and French began working together in June 1976. The company envisioned a kit, but Leininger persuaded the others that because "too many people can't solder", a preassembled computer would be better.
Tandy had 11 million customers that might buy a microcomputer, but it would be much more expensive than the US$ median price of a Radio Shack product, and a great risk for the very conservative company. Many opposed the project; one executive told French, "Don't waste my time—we can't sell computers." As the popularity of CB radio—at one point more than 20% of Radio Shack's sales—declined, however, the company sought new products. In December 1976 French and Leininger received official approval for the project but were told to emphasize cost; for example, leaving out lowercase characters saved US$1.50 in components and reduced the retail price by US$. In February 1977 they showed their prototype, running a simple tax-accounting program, to Charles Tandy, head of Tandy Corporation. The program quickly crashed as the computer could not handle the US$ figure that Tandy typed in as his salary, and the two men added support for floating-point math to its Tiny BASIC to prevent a recurrence. After the demonstration Tandy revealed that he had already leaked the computer's existence to the press, so the project was approved.
MITS sold 1,000 Altairs in February 1975, and was selling 10,000 a year. Leininger and French suggested that Radio Shack could sell 50,000 computers, but others disagreed and suggested 1,000 to 3,000 per year at the target US$199 price. Roach persuaded Tandy to agree to build 3,500—the number of Radio Shack stores—so that each store could use a computer for inventory purposes if they did not sell.
Having spent less than US$ on development, Radio Shack announced the TRS-80 (Tandy Radio Shack) at a New York City press conference on August 3, 1977. It cost US$, or US$ with a 12" monitor and a Radio Shack tape recorder as datacassette storage; the most expensive product Radio Shack previously sold was a US$ stereo. The company hoped that the new computer would help Radio Shack sell higher-priced products, and improve its "schlocky" image among customers. Small businesses were the primary target market, followed by educators, then consumers and hobbyists; despite its hobbyist customer base, Radio Shack saw them as "not the mainstream of the business".
Although the press conference did not receive much media attention because of a terrorist bombing elsewhere in the city, the computer received much more publicity at the Personal Computer Faire in Boston two days later. A front-page Associated Press article discussed the novelty of a large consumer-electronics company selling a home computer that could "do a payroll for up to 15 people in a small business, teach children mathematics, store your favorite recipes or keep track of an investment portfolio. It can also play cards." Six sacks of mail arrived at Tandy headquarters asking about the computer, over 15,000 people called to purchase a TRS-80—paralyzing the company switchboard—and 250,000 joined the waiting list with a $100 deposit.
Despite the internal skepticism, Radio Shack aggressively entered the market. Company president Lewis Kornfeld stated when announcing the TRS-80, "This device is inevitably in the future of everyone in the civilized world—in some way—now and so far as ahead as one can think", and Tandy's 1977 annual report called the computer "probably the most important product we've ever built in a company factory". Unlike competitor Commodore—which had announced the PET several months earlier but had not yet shipped any—Tandy had its own factories and distribution network, and even small towns had Radio Shack stores. The company announced plans to by Christmas sell a range of peripherals and software for the TRS-80, began shipping computers by September, and opened its first computer-only store in October. Still forecasting 3,000 sales a year, Radio Shack sold over 10,000 TRS-80s Model Is in its first one and a half months of sales, and over 200,000 during the product's lifetime;:4 one entered the Smithsonian's National Museum of American History.
The first units, ordered unseen, were delivered in November 1977, and rolled out to the stores the third week of December. The line won popularity with hobbyists, home users, and small-businesses. Tandy Corporation's leading position in what "Byte" Magazine called the "1977 Trinity" (Apple, Commodore and Tandy) had much to do with Tandy's retailing the computer through more than 3,000 of its Radio Shack storefronts. Notable features of the original TRS-80 included its full-stroke QWERTY keyboard, small size, its floating-point BASIC programming language, an included monitor, and a starting price of US$600 (equivalent to US$<br>{Inflation} - Amount must not have "" prefix: 600.   in 2014). The pre-release price was US$500 and a US$50 deposit was required, with a money-back guarantee at time of delivery.
By 1980 "InfoWorld" described Radio Shack as "the dominant supplier of small computers". "Kilobaud Microcomputing" estimated that it was selling three times as many computers as Apple Computer, with both companies ahead of Commodore. By 1981 hundreds of small companies produced TRS-80 software and accessories, and Adam Osborne described Tandy as "the number-one microcomputer manufacturer" despite having "so few roots in microcomputing". Roach became Tandy's CEO that year, Leininger became director of strategic planning, and French founded a software company. Although selling computers did not change the company's "schlocky" image, the Radio Shack name embarrassed business customers, and Tandy executives disliked the "Trash-80" nickname for its products, by 1984 computers accounted for 35% of sales and the company had 500 Tandy Radio Shack Computer Centers.
Following the Model III launch in mid-1980, Tandy initially claimed that the Model I had not been dropped. However, it had been discontinued by the end of the year. Tandy cited one of the main reasons as being the prohibitive cost of redesigning it to meet stricter FCC regulations covering the significant levels of radio-frequency interference emitted by the original design. The Model I radiated so much interference that while playing games an AM radio placed next to the computer could be used to provide sounds.
Hardware.
The Model I combined the mainboard and keyboard into one unit, in what was to be a common case design trend throughout the 8-bit microcomputer era, although it had a separate power supply unit. It used a Zilog Z80 processor clocked at 1.77 MHz (later models were shipped with a Z80A). The basic model originally shipped with 4 KB of RAM, and later 16 KB.
Keyboard.
The implementation of the keyboard was unusual. Instead of transferring data through an I/O chip, the hardware mapped the keyboard to dedicated locations in the processor's memory. Performing a read from the keyboard area of the memory would return the state of a particular set of keys.
A version of the computer was produced which replaced the nameplate with a numeric keypad.
Many users complained about the TRS-80 keyboards, which used mechanical switches and suffered from "keyboard bounce", resulting in multiple letters being typed accidentally. The problem was so widespread that Wayne Green's editorial in the first issue of "80 Micro" mentioned it. A Keyboard De-Bounce tape was distributed, which altered the system's software to reduce the effect of bounce and to slow down polling of the keyboard. Eventually, this change was added to a later ROM revision. The keyboard hardware was also changed to be less vulnerable to bounce.
Video and audio.
The TRS-80 was accompanied by a modified RCA black-and-white television. The color of the screen text is light bluish (the standard "P4" phosphor used in black-and white televisions). Green and amber filters, or replacement tubes to make the display easier on the eyes, were common aftermarket items. Later models came with a green-on-black display.
Because of bandwidth problems in the interface card that replaced the TV's tuner, the display would lose horizontal sync if large areas of white were displayed; a simple hardware fix (involving less than half an hour's work) could be applied to correct that.
The video hardware can only display text at 64 or 32 characters wide by 16 lines of resolution. This is because the video memory system uses a single kilobyte of video memory. Seven bits of each byte are used to display ASCII characters, with the eighth bit used to differentiate between text and "semigraphics" characters.
Primitive graphics ("text semigraphics", rather than a true bitmap) can be displayed because the upper 64 characters of the 128-character set appear as a grid of 2×3 blocks resembling Teletext. BASIC routines can write directly to the virtual 128×48 grid.
The original TRS-80 Model I could not differentiate between upper and lower characters in display memory. With only seven 1-bit-wide memory chips, the 8th bit was faked by circuitry that forced uppercase characters. The display hardware did have lowercase letters, but without descenders. In order to display lower case, owners had to add an eighth memory chip. This modification became a popular third-party add-on, along with a character chip with descenders for the lowercase letters. Later models came with the hardware for lowercase character set to be displayed with descenders.
Many users complained about the poor quality of the video display; as Green wrote, "hells bells, [the monitor] "is" a cheap black and white television set with a bit of conversion for computer use". (The computer could be purchased without the Radio Shack monitor.) Any access to the screen memory caused "flicker" on the screen. The bus arbitration logic would block video display while access was given to the CPU, causing a short black line. This had little effect on normal BASIC programs, but fast programs made in assembly language could be affected. Many software authors were able to minimize this effect. Notwithstanding this primitive display hardware, many arcade-style games were available for the Tandy TRS-80.
The Model I has no sound hardware. Square wave tones can be produced by outputting data to the cassette port and plugging headphones or an amplifier into the Data Out line. Some games use this ability for sound effects. An adapter was available to use Atari joysticks.
Peripherals.
Cassette tape drive.
User data was originally stored on cassette tape. Radio Shack's model CTR-41 cassette recorder was included with the US$599 package.:3–4 The software-based cassette tape interface was very slow and erratic; Green described it as "crummy ... drives users up the wall", and the first issue of "80 Micro" had three articles on how to improve cassette performance. It was sensitive to audio volume changes, and the machine gave only the very crudest indication as to whether the correct volume was set, via a blinking character on screen when data was being loaded. To find the correct volume, one would sometimes have to attempt to load a program once, adjusting volume until the machine picked up the data, then reset the machine, rewind the tape and attempt the load again. Users quickly learned to save a file three or more times in hopes that one copy would prove to be readable. Automatic gain control or indicator circuits could be constructed to compensate for this (the owner's manual provided complete circuit diagrams for the whole machine, including the peripheral interfaces, with notes on operation).
An alternative tape interface could receive transmissions from the BBC's "Chip Shop" programme in the UK, which broadcast software for several different microcomputers over the radio. A special program (loaded using the conventional tape interface) was needed to access the custom interface. Tandy eventually replaced the CTR-41 unit with the CTR-80 which had built-in AGC circuitry (and no volume control). This helped the situation, but tape operation was still unreliable.
TRS-80s with Level I BASIC read and wrote tapes at 250 bits per second (31.25 bytes per second); Level II BASIC doubled this to 500 bits per second (62.5 bytes per second). Some programmers wrote machine language programs that would increase the speed to up to 1800 bits per second without loss in reliability.
For loading and storing data, no hardware controller existed. Instead, the processor created the sound itself by switching the output voltage between three states, creating very crude sine wave audio.
The first models of the Model I also had problems reading from the cassette drives. Tandy eventually offered a small board which was installed in a service center to correct earlier models. The ROMs in later models were modified to correct this.
Expansion interface.
The TRS-80 did not use the S-100 bus like other Z80-based computers. A proprietary Expansion Interface (E/I) provided several features: the ability to expand up to 48K of RAM, a floppy disk controller, a real-time clock, a second cassette port, an RS-232 port (as an option) and a Centronics parallel printer port.
Originally, one could not print from the Model I without purchasing an Expansion Interface. However, Tandy Corp. soon sold a printer-only Interface for the Model I for approx. DM300 in Germany.
The Expansion Interface was the most troublesome part of the TRS-80 system. It went through several revisions. A pre-production version is said to have looked completely different, and to have had a card cage. Its edge card connectors tended to oxidise due to the use of two different metals in the contacts, and required periodic cleaning with a pencil eraser. The expansion unit required a second power supply, identical to the base unit power supply; an interior recess held both power supplies.
"InfoWorld" compared the cable spaghetti connecting the TRS-80's various components to the snakes in "Raiders of the Lost Ark". Since the cable connecting the expansion interface carried the system bus, it was kept short (about two inches). This meant that the user had no choice but to place it directly behind the computer with the monitor on top of it. This caused problems if one owned a monitor whose case did not fit the mounting holes. Also, the loose friction fit of the edge connector on the already short interconnect cable created the precarious possibility of disconnecting the system bus from the CPU if either unit happened to be moved during operation.
Floppy disk drives.
Radio Shack did not offer a floppy disk drive for the TRS 80 until 1978. To use the Model I with a disk operating system,:14–15 one had to buy the Expansion Interface, which included a single density floppy disk interface (formatted capacity of 85k). This was based on a Western Digital 1771 single density floppy disk controller chip. Four floppy drives could be used with the Model I in a daisy-chain.
Although demand for Model I drives greatly exceeded supply at first, since the interface lacked a separate external data separator, it was very unreliable in practice. Much of the unreliability was due to bugs in Radio Shack's early version(s) of TRS-DOS. The 1771 could not report its status for a short interval (several instruction cycles) after it received a command. A common method of handling this was to issue a command to the 1771, perform several "NOP" instructions, then query the 1771 for command status. Early TRS-DOS neglected to use the required wait period, instead querying the chip immediately after issuing a command, and thus false status was often returned to the OS, causing various errors and crashes. If the 1771 was handled correctly by the OS, it was actually fairly reliable.
In 1981 Steve Ciarcia published in "BYTE" the design for a homemade, enhanced expansion interface with additional RAM and a disk controller for the TRS-80.
A data separator and a double density disk controller (based on the WD 1791 chip) were made by Percom (a Texas peripheral vendor), LNW, Tandy and others. The Percom Doubler added the ability to boot and use Double Density Floppies (they provided their own modified TRSDOS called DoubleDOS), and included the Data Separator. The LNDoubler added the ability to read and write from 5¼" diskette drives for over 1.2 Mb of storage. Near the end of the Model I's lifespan in 1982, double-density drives became available for it.
All TRS-80 disk formats were soft-sectored with index-sync, and except for some very early Shugart drives (recognizable by their spiral-cam head positioner), all TRS-80 floppy drives were 40-track double-density models. The combination of 40 tracks and double-density gave a maximum capacity of 180 kilobytes per single-sided floppy disk. The use of index-sync meant that a "flippy disk" required a second index hole and write-enable notch. One could purchase factory-made "flippies". Some software publishers formatted one side for Apple systems and the other for the TRS 80. The early drives sold by Radio Shack were 35-track models with a 160 kb capacity.
Hard drive.
Radio Shack introduced a 5 MB hard-drive unit for the TRS-80 Models I and III (and later Model 4) in 1983. The size of the unit was about the same as a modern desktop computer enclosure. The initial retail price (US$2495) is equivalent to US$<br>{Inflation} - Amount must not have "" prefix: 2495.   in 2014.
Printers.
One unusual peripheral offered was a "Quick Printer", an electrostatic rotary printer that scanned the video memory through the same bus connector used for the expansion interface, and printed an image of the screen onto aluminum-coated paper in about a second.:16 Unfortunately, it was incompatible with both the final, buffered version of the expansion interface, and with the "heartbeat" interrupt used for the real-time clock under Disk BASIC. This could be overcome by using special cabling, and by doing a "dummy" write to the cassette port while triggering the printer.
Two other printers were offered: one for 57 mm metal coated paper, selling for approximately DM600 in Germany, and one built by Centronics for normal paper, costing at first DM 3000, later sold at approximately DM1500 in some stores. It had only 7 pins, so letters with descenders such as lowercase "g" did not reach under the baseline, but were elevated within the normal line.
Software.
BASIC.
Three versions of the BASIC programming language were produced for the Model I. "Level I BASIC" fit in 4 KB of ROM, and "Level II BASIC" fit into 12 KB of ROM. Level I was single precision only and had a smaller set of commands. Level II introduced double precision floating point support and had a much wider set of commands. Level II was further enhanced when a disk system was added, allowing for the loading of "Disk BASIC".
Level I Basic was based on Li-Chen Wang's free Tiny BASIC, additional functions added by Radio Shack. It had an excellent manual written by David Lien, which presented lessons on programming with text and humorous graphics, making the subjects very easy to understand. Lien wrote that it was "written specifically for people who don't know anything about computers ... I want you to have fun with your computer! I don't want you to be afraid of it, because there is nothing to fear ..." Level I BASIC had only two string variables (codice_1 and codice_2), 26 numeric variables (codice_3 - codice_4) and one array, codice_5. Code for functions like SIN(), COS() and TAN() was not included in ROM but printed at the end of the book. The only error messages were: "codice_6" for syntax errors, "codice_7" for arithmetic errors such as division by zero, and "codice_8" for out of memory errors.
Level I BASIC was not tokenized—reserved words were stored literally. In order to maximize the code that could be crammed into 4K of memory users could enter abbreviations for reserved words. For example, writing "codice_9" instead of "codice_10" thus saving 3 bytes.
Level II BASIC was licensed from Microsoft. It was a cut-down version of the 16 KB Extended BASIC, since the Model I had 12 KB of ROM space. The accompanying manual was not nearly as colorful and suited for beginning programmers as the Level I BASIC manual. Original Level I BASIC-equipped machines could be retrofitted to Level II through a ROM replacement performed by Radio Shack for a fee (originally US$199). Users with Level I BASIC programs stored on cassette had to convert these to the non-tokenized Level II BASIC before use. A utility for this was provided with the Level II ROMS.
Disk BASIC added the ability to perform disk I/O, and in some cases (NewDos/80, MultiDOS, DosPlus, LDOS) added powerful sorting, searching, full screen editing, and other features. Level II BASIC reserved some of these keywords and issued a "codice_11", suggesting a behind-the-scenes change of direction intervened between the creation of the Level II ROMs and the introduction of Disk BASIC.
Microsoft also marketed a tape-cassette based enhanced BASIC called Level III BASIC. This added most of the functions in the full 16 KB version of BASIC.
Other applications.
Blackjack and backgammon came with the TRS-80 for free, and at its debut Radio Shack offered four payroll, personal finance, and educational programs, all on cassette.:3 While Radio Shack franchise stores sold third-party products, company-owned stores were at first prohibited from reselling products not sold by Radio Shack itself. Its own products' quality was often poor. A critical 1980 "80 Micro" review of a text adventure described it as "yet another example of Radio Shack's inability to deal with the consumer in a consumer's market". The magazine added, "Sadly, too, as with some other Radio Shack programs, the instructions seem to assume that the reader is either a child or an adult with the mentality of a slightly premature corned beef."
Green stated that year that although "there are more programs for the 80 than for all other systems combined" because of the computer's large market share, "Radio Shack can't advertise this because they are trying as hard as they can to keep this fact a secret from their customers. They don't want the TRS-80 buyers to know that there is anything more than their handful of mediocre programs available", many of which "are disastrous and, I'm sure, doing tremendous damage to the industry". By 1982 the company admitted—after no software appeared for the Model 16 after five months—that it should have, like Apple, encouraged third-party developers of products like the killer app VisiCalc. (A lengthy 1980 article in a Tandy publication introducing the TRS-80 version of VisiCalc did not mention that the spreadsheet had been available for the Apple II for a year.) A full suite of office applications nonetheless became available from the company and others, including the VisiCalc and Multiplan spreadsheets and the Lazy Writer, Electric Pencil, and Scripsit word processors.
Despite the TRS-80's limited graphics and sound capability, independent software companies such as Big Five produced unlicensed versions of arcade games like Namco's "Galaxian", Atari's "Asteroids", and Exidy's "Targ". Some companies ported games from other home computers of the era, such as the original "Zork" adventure game. There were also many games unique to the TRS-80, including shooters like "Cosmic Fighter" and "Defence Command" and strange experimental programs such as "Dancing Demon", a game in which the player composed a song for a devil and choreographed his dance steps to the music. "Microchess" for the Model I had three levels of play and could be run in the 4kb of memory that was standard with this model.
Utility software such as Stewart Software's Toolkit offered the first sorted directory, decoding or reset of passwords, and the ability to eliminate parts of TRS-DOS that were not needed in order to free up floppy disk space. They also produced the On-Line 80 BBS, a TRS-DOS based Bulletin Board System.
By 1982 perhaps more operating systems existed for the TRS-80 than for any other computer. TRS-DOS—Radio Shack's operating system for its TRS-80 computers—had significant limitations, opening the market for various alternative OSes, including NewDOS, a third-party rival sold by a company called Apparat Personal Computers, which went out of business in 1987. Others included DoubleDOS, DOSPlus, MicroDOS, NEWDOS/80, UltraDOS (later called Multidos), and VTOS. The last versions (6.x) of TRSDOS were actually renamed LS-DOS (aka LDOS).
CP/M became a standard OS for business use on Z80-based machines, and versions ran on all TRS-80s. Omikron Systems' Mappers board remapped the BASIC ROM to run unmodified CP/M programs on the Model I.
Reception.
Dan Fylstra, among the first owners, wrote in "BYTE" in April 1978 that as an "'appliance' computer ... the TRS-80 brings the personal computer a good deal closer to the average customer", suitable for home and light business use. He concluded that it "is not the only alternative for the aspiring personal computer user, but it is a strong contender." Jerry Pournelle wrote in 1980 that "the basic TRS-80 is a lot of computer for the money. It comes ready to run right out of the box, and it can be set up by three boys – ages 9, 11, and 13 ... The Tandy/Radio Shack documentation is excellent, and there are a lot of good programs available". He noted that while "just about every component of my TRS-80 has taken a trip to the local store to be fixed", "none of that cost me anything; it wasn't even inconvenient, especially with local Radio Shacks all over the place ... Given the price of the TRS-80, Tandy's quality control is better than you'd expect." Pournelle criticized the quality of Tandy's application and system software—including the "needlessly complex" TRSDOS—and high cost of its peripherals. He reported, however, that with the Omikron board, additional memory, and 8- and 5 1/4-inch disk drives, "for a total cost of under $5000, you have a 48 K-byte machine capable of running all the TRS-80 programs, CP/M software, and top-grade text editors like Word Master, Magic Wand, Electric Pencil, and the Proteus editor ... all without building a single kit".
Compatible successors.
Tandy would go on to replace the Model I with the broadly compatible Model III in 1980. (The TRS-80 Model II had been an entirely different and incompatible design). The Model III was in turn succeeded by the backward-compatible Model 4 in 1983.
Model III.
In July 1980 Tandy released the TRS-80 Model III. The improvements of the Model III over the Model I included built-in lower case, a better keyboard, elimination of the cable spaghetti, 1500-baud cassette interface, and a faster (2.03 MHz) Z-80 processor. Shortly after, Model I production was discontinued as it did not comply with new FCC regulations as of January 1, 1981 regarding electromagnetic interference.
The Model III could run about 80% of Model I software, but used an incompatible disk format. Customers and developers complained of bugs in its BASIC and the TRSDOS operating system. The computer also came with the option of integrated disk drives.
"InfoWorld" approved of the Model III's single-unit design, simplified cable management, and improvements such as lack of keyboard bounce and improved disk reliability. The reviewer, a former Model I owner, stated "I'm impressed" and that "had the Model III been available, it's probable that I wouldn't have sold it". He concluded, "If you're looking for a computer that's not too expensive but that performs well, you would be wise to test the Model III—you might end up buying it."
Model 4.
The successor to the Model III was the TRS-80 Model 4 (April 1983, with "4" written as an Arabic numeral), which included the capability to run CP/M. It had faster Z80A 4 MHz CPU and was completely compatible with Model III software. A diskless version cost $999, with one disk drive $1699, and two drives $1999; an upgrade for Model III owners cost $799 and provided a new motherboard and keyboard. Tandy sold 71,000 in 1984.
Running CP/M had previously only been possible via a hardware modification that remapped the BASIC ROMs away from memory address zero, such as the third-party add-on sold as the Omikron Mapper board, or by running a version of CP/M modified to run at a starting address other than zero. However, this also required modified applications, since the area of memory at zero contained the vectors for applications to access CP/M itself.
The Model 4 shipped with TRSDOS 6, an enhanced version of the popular LDOS (itself an enhancement to older versions of TRSDOS) by Logical Systems. When the Model 4 boots into TRSDOS 6 the video display switches into 80×24 mode and the entire 64KB address space is mapped as RAM. The Model 4 is also capable of running all Model III software when a Model III operating system disk is detected and loaded during bootup, with a 64×16 video mode and Model III ROMs mapped from address zero. Model 4 features, including the internal speaker, are unavailable in Model III mode.
The Model 4 also has the ability to display 640×240 or 512×192 high-resolution monochrome graphics with an optional board. A "luggable" version known as the Model 4P (1983) is a self-contained unit with a case design similar to that of a portable sewing machine.
Early versions of the Model 4 mainboard were designed to accept a Zilog Z800 16 bit CPU upgrade board to replace the Z80 8 bit CPU but this option was never released.
"BYTE" in October 1983 noted the lack of native software for the Model 4 but praised its backwards compatibility and TRSDOS 6's new features. The magazine concluded that the Model 4 "provides a lot of flexible computing power ... Radio Shack has a guaranteed winner".
Clones.
Many clones of the TRS-80 Model I came on the market: the Lobo Max-80 (Lobo also produced their own version of the Expansion Interface), the LNW-80 Models I/II and Team computers (LNW also produced an alternate version of the Expansion Interface), and the Dutch Aster CT-80, a computer that could run both TRS-80 and CP/M software, and also had all the improvements of the later Model III.
EACA in Hong Kong made a Model I clone that was marketed around the world under different names with modifications. In Australia and New Zealand it was the Dick Smith System 80, in North America it was PMC-80 and PMC-81, in Hungary the HT-1080Z, in South Africa the TRZ-80, and in Western Europe it was Video Genie. The expansion bus was different and EACA also made its own Expansion Interface to fit it. There were several versions, and it was later split into a 'home' and a 'business' version, Genie I and II, and System-80 Mark I and II, where the II would have a numeric keypad instead of the built-in cassette player. EACA's Colour Genie was also based on TRS-80 Model I but with improved graphics and other changes, reducing its compatibility.
In Brazil several manufacturers developed clones for models I/III/IV. Dismac series D8000/D8001/D8002 (all three Model I clones) were the first personal computers manufactured in industrial scale in South America. Digitus made the DGT-100 and DGT-1000, made the highly successful and series (both Model III clones), Sysdata Eletrônica Ltda. made the Sysdata Jr. Prologica also made the CP400 / CP 400II which were copies of the TRS-80 Color Computer, with the external case being almost a copy of the Timex Sinclair 2068.
In Germany, S.C.S. GmbH in Mörfelden-Walldorf offered the "Komtek-I" Model I clone. Noteworthy was its four relay switching outputs.
In the Soviet Union, some ideas from the TRS-80 were used in development of the home/school computer.

</doc>
<doc id="30749" url="http://en.wikipedia.org/wiki?curid=30749" title="Tanker">
Tanker

Tanker may refer to:

</doc>
<doc id="30755" url="http://en.wikipedia.org/wiki?curid=30755" title="The Balloon-Hoax">
The Balloon-Hoax

"The Balloon-Hoax" is the title used in collections and anthologies of a newspaper article written by Edgar Allan Poe, first published in 1844. Originally presented as a true story, it detailed European Monck Mason's trip across the Atlantic Ocean in only three days in a gas balloon. It was later revealed as a hoax and the story was retracted two days later.
Overview.
The story now known as "The Balloon-Hoax" was first printed in "The Sun" newspaper in New York. The article provided a detailed and highly plausible account of a lighter-than-air balloon trip by famous European balloonist Monck Mason across the Atlantic Ocean taking 75 hours, along with a diagram and specifications of the craft.
Poe may have been inspired, at least in part, by a prior journalistic hoax known as the "Great Moon Hoax", published in the same newspaper in 1835. One of the suspected writers of that hoax, Richard Adams Locke, was Poe's editor at the time "The Balloon-Hoax" was published. Poe had complained for a decade that the paper's Great Moon Hoax had plagiarized (by way of Locke) the basic idea from "The Unparalleled Adventure of One Hans Pfaall", one of Poe's less successful stories which also involved similar inhabitants on the moon. Poe felt "The Sun" had made tremendous profits from his story without giving him a cent. (Poe's anger at "The Sun" is chronicled in the 2008 book "The Sun and the Moon" by Matthew Goodman.)
Publication history.
The story was first published on April 13, 1844 in the "New York Sun". It ran with the headline:
A retraction concerning the article was printed in "The Sun" on April 15, 1844:
"BALLOON - The mails from the South last Saturday night not having brought a confirmation of the arrival of the Balloon from England, the particulars of which from our correspondent we detailed in our Extra, we are inclined to believe that the intelligence is erroneous. The description of the Balloon and the voyage was written with a minuteness and scientific ability calculated to obtain credit everywhere, and was read with great pleasure and satisfaction. We by no means think such a project impossible."
Critical reception and significance.
Poe himself describes the enthusiasm his story had aroused: he claims that the "Sun" building was "besieged" by people wanting copies of the newspaper. "I never witnessed more intense excitement to get possession of a newspaper," he wrote. The story's impact reflects on the period's infatuation with progress. Poe added realistic elements, discussing at length the balloon's design and propulsion system in believable detail. His use of real people, including William Harrison Ainsworth, also lent credence to the story. The character of Monck Mason was not a real person, though he was based heavily on Thomas Monck Mason; the story borrowed heavily from Mason's 1836 book "Account of the Late Aeronautical Expedition from London to Weilburg".
"The Balloon-Hoax" is like one of Poe's "tales of ratiocination" (such as "The Murders in the Rue Morgue") in reverse: rather than taking things apart to solve a problem, Poe builds up fiction to make it seem true. The story is also an early form of science fiction, specifically responding to the emerging technology of hot air balloons.
The story may have later been an inspiration for Jules Verne's "Around the World in Eighty Days". As Verne scholar William Butcher pointed out, Verne was an early admirer of Poe and his novel "Cinq semaines en ballon" ("Five Weeks in a Balloon") was published within a year of his nonfiction book "Edgar Poe et ses oeuvres" ("Edgar Allan Poe and his Works"). Verne even has a character mention Poe's story in "From the Earth to the Moon." It is not difficult to see Poe's works, published in France as "Histoires extraordinaires" (Extraordinary Stories), as one of the influences on Verne's "Voyages extraordinaires" (Extraordinary Journeys).
Real trans-oceanic lighter-than-air flights.
The first human-carrying lighter-than-air craft of any type to cross the Atlantic was the British dirigible R-34, a direct copy of the German L-33 which crashed in Britain during World War I, in 1919. The 3559.5 mile flight from Britain to New York City took 108 hours 12 minutes.
The first human-carrying unpowered balloon to actually cross the Atlantic Ocean was Double Eagle II from August 11 to 17, 1978. The Pacific was crossed in three days by unmanned Japanese "fire balloons" in 1944, exactly 100 years after Poe's story.

</doc>
<doc id="30756" url="http://en.wikipedia.org/wiki?curid=30756" title="Terence">
Terence

Publius Terentius Afer (; c. 195/185 – c. 159 BC), better known in English as Terence (), was a playwright of the Roman Republic, of North African descent. His comedies were performed for the first time around 170–160 BC. Terentius Lucanus, a Roman senator, brought Terence to Rome as a slave, educated him and later on, impressed by his abilities, freed him. Terence apparently died young, probably in Greece or on his way back to Rome. All of the six plays Terence wrote have survived.
One famous quotation by Terence reads: "Homo sum, humani nihil a me alienum puto", or "I am a human, and I think nothing human is alien to me." This appeared in his play "Heauton Timorumenos".
Biography.
Terence's date of birth is disputed; Aelius Donatus, in his incomplete "Commentum Terenti", considers the year 185 BC to be the year Terentius was born; Fenestella, on the other hand, states that he was born ten years earlier, in 195 BC.
He may have been born in or near Carthage or in Greek Italy to a woman taken to Carthage as a slave. Terence's cognomen "Afer" suggests he lived in the territory of the Libyan tribe called by the Romans Afri near Carthage prior to being brought to Rome as a slave. This inference is based on the fact that the term was used in two different ways during the republican era: during Terence's lifetime, it was used to refer to non-Carthaginian Libyco-Berbers, with the term "Punicus" reserved for the Carthaginians. Later, after the destruction of Carthage in 146 BC, it was used to refer to anyone from the land of the Afri (Tunisia and its surroundings). It is therefore most likely that Terence was of Libyan descent, considered ancestors to the modern-day Berber peoples.
In any case, he was sold to P. Terentius Lucanus, a Roman senator, who educated him and later on, impressed by Terence's abilities, freed him. Terence then took the "nomen" "Terentius," which is the origin of the present form.
He was a member of the so-called Scipionic Circle.
When he was 25, Terence left Rome and he never returned, after having exhibited the six comedies which are still in existence. According to some ancient writers, he died at sea.
Terence's plays.
Like Plautus, Terence adapted Greek plays from the late phases of Attic comedy. Terence wrote in a simple conversational Latin, and most students who persevere long enough to be able to read him in the vernacular find his style particularly pleasant and direct. Aelius Donatus, Jerome's teacher, is the earliest surviving commentator on Terence's work. Terence's popularity throughout the Middle Ages and the Renaissance is attested to by the numerous manuscripts containing part or all of his plays; the scholar Claudia Villa has estimated that 650 manuscripts containing Terence's work date from after AD 800. The mediaeval playwright Hroswitha of Gandersheim claims to have written her plays so that learned men had a Christian alternative to reading the pagan plays of Terence, while the reformer Martin Luther not only quoted Terence frequently to tap into his insights into all things human but also recommended his comedies for the instruction of children in school.
Terence's six plays are:
The first printed edition of Terence appeared in Strasbourg in 1470, while the first certain post-antique performance of one of Terence's plays, "Andria", took place in Florence in 1476. There is evidence, however, that Terence was performed much earlier. The short dialogue "Terentius et delusor" was probably written to be performed as an introduction to a Terentian performance in the 9th century (possibly earlier).
A phrase by his musical collaborator Flaccus for Terence's comedy "Hecyra" is all that remains of the entire body of ancient Roman music. This has recently been shown to be inauthentic.
Cultural legacy.
Due to his clear and entertaining language, Terence's works were heavily used by monasteries and convents during the Middle Ages and The Renaissance. Scribes often learned Latin through the meticulous copying of Terence's texts. Priests and nuns often learned to speak Latin through reenactment of Terence's plays, thereby learning both Latin and Gregorian chants. It should be noted that although Terence's plays often dealt with heretical material, the quality of his language promoted the copying and preserving of his text by the church. The preservation of Terence through the church enabled his work to directly influence much of Western drama.
Terence's plays were a standard part of the Latin curriculum of the neoclassical period. US President John Adams once wrote to his son, "Terence is remarkable, for good morals, good taste, and good Latin...His language has simplicity and an elegance that make him proper to be accurately studied as a model."
Two of the earliest English comedies, "Ralph Roister Doister" and "Gammer Gurton's Needle", are thought to parody Terence's plays.
Due to his cognomen Afer, Terence has long been identified with Africa and heralded as the first poet of the African diaspora by generations of writers, including Juan Latino, Phyllis Wheatley, Alexandre Dumas, Langston Hughes and Maya Angelou.
American playwright Thornton Wilder based his novel "The Woman of Andros" on Terence's "Andria".
Questions as to whether Terence received assistance in writing or was not the actual author have been debated over the ages, as described in the 1911 edition of the "Encyclopædia Britannica:"
[In a prologue to one of his plays, Terence] meets the charge of receiving assistance in the composition of his plays by claiming as a great honour the favour which he enjoyed with those who were the favorites of the Roman people. But the gossip, not discouraged by Terence, lived and throve; it crops up in Cicero and Quintilian, and the ascription of the plays to Scipio had the honour to be accepted by Montaigne and rejected by Diderot.

</doc>
<doc id="30757" url="http://en.wikipedia.org/wiki?curid=30757" title="The Pit and the Pendulum">
The Pit and the Pendulum

"The Pit and the Pendulum" is a short story written by Edgar Allan Poe and first published in 1842 in the literary annual "The Gift: A Christmas and New Year's Present for 1843". The story is about the torments endured by a prisoner of the Spanish Inquisition, though Poe skews historical facts. The narrator of the story describes his experience of being tortured. The story is especially effective at inspiring fear in the reader because of its heavy focus on the senses, such as sound, emphasizing its reality, unlike many of Poe's stories which are aided by the supernatural. The traditional elements established in popular horror tales at the time are followed, but critical reception has been mixed. The tale has been adapted to film several times.
Plot summary.
The story depicts the Spanish Inquisition. An unnamed narrator is brought to trial before sinister judges. Poe provides no explanation of why he is there or what he has been arrested for. Before him are seven tall white candles on a table, and, as they melt, his hopes of survival also diminish. He is condemned to death and finds himself in a pitch black compartment. At first the prisoner thinks that he is locked in a tomb, but then he discovers that he is in a cell. He decides to explore the cell by placing a hem from his robe against a wall so that he can count the paces around the room, but he faints before he can measure the whole perimeter.
When he reawakens he discovers food and water nearby. He tries to measure the cell again, and finds that the perimeter measures one hundred steps. While crossing the room he slips on the hem of his robe and discovers that if he had not tripped, he would have walked into a deep pit in the center of the cell, with water at the bottom.
After losing consciousness again the narrator discovers that the prison is slightly illuminated and that he is bound to a wooden board by ropes. He looks up to see a painted picture of Father Time on the ceiling. Hanging from the figure is a gigantic pendulum with a crescent razor measuring "one feet from horn to horn," and swinging slowly back and forth. The pendulum is inexorably sliding downwards and will eventually kill him. However, the condemned man is able to attract rats to his bonds with the meat left for him to eat and they start chewing through the ropes. As the pendulum reaches a point inches above his heart, the prisoner breaks free of the ropes and watches as the pendulum is drawn back to the ceiling.
He then sees that the walls have become red-hot and have begun moving inwards, driving him into the center of the room and towards the brink of the pit. As he gazes into the pit, he decides that no fate could be worse than falling into it: "Neither could I forget what I had read of these pits -- that the sudden extinction of life formed no part of their most horrible plan." 
As the narrator moves back from the pit, he sees that the red-hot walls are leaving him with no foothold. As he begins to fall into the pit, he hears human voices, a loud trumpeting, and a huge boom as loud as "a thousand thunders." The walls rush back and an arm catches him. The French Army has taken Toledo and the Inquisition is in the hands of its enemies.
Lack of historical authenticity.
Poe makes no attempt to describe accurately the operations of the Spanish Inquisition, and takes considerable dramatic license with the broader history premised in this story. The rescuers are led by Napoleon's General Lasalle (who was not, however, in command of the French occupation of Toledo) and this places the action during the Peninsular War (1808–14), centuries after the height of the Spanish Inquisition. The elaborate tortures of this story have no historic parallels in the activity of the Spanish Inquisition in any century, let alone the nineteenth when under Charles III and Charles IV only 4 persons were condemned. The Inquisition was, however, abolished during the period of French intervention (1808–13).
Poe places a Latin epigraph before the story, describing it as "a quatrain composed for the gates of a market to be erected upon the site of the Jacobin Club House at Paris". The epigraph was not Poe's invention; such an inscription had been reported, no later than 1803, as having been composed with the intention (possibly facetious) of having it placed on the site, and it had appeared, without attribution, as an item of trivia in the 1836 "Southern Literary Messenger", a periodical to which Poe contributed. It does not appear, however, that the market was ever built as intended. Charles Baudelaire, a noted French writer who translated Poe's works into French and who was largely inspired by him, said that the building on the site of the Old Jacobin Club had no gates and, therefore, no inscription.
Analysis.
"The Pit and the Pendulum" is a study of the effect terror has on the narrator, starting with the opening line, which suggests that he is already suffering from death anxiety ("I was sick — sick unto death with that long agony"). However, there is an implicit irony in the reference to the black-robed judges having lips "whiter than the sheet upon which I trace these words," which shows that he has survived and is writing the story after the events. Unlike much of Poe's work, the story has no supernatural elements. The "realism" of the story is enhanced through Poe's focus on reporting : the dungeon is airless and unlit, the narrator is subject to thirst and starvation, he is swarmed by rats, the closing walls are red-hot, and the razor-sharp pendulum threatens to slice into him. The narrator experiences the blade mostly through sound as it "hissed" while swinging. Poe emphasizes this element of sound with such words as "surcingle," "cessation," "crescent," and "scimitar", and various forms of literary consonance.
Inspiration.
Poe was following an established model of terror writing of his day, often seen in "Blackwood's Magazine" (a formula he mocks in "A Predicament"). Those stories, however, often focused on chance occurrences or personal vengeance as a source of terror. Poe may have been inspired to focus on the purposeful impersonal torture in part by Juan Antonio Llorente's "History of the Spanish Inquisition", first published in 1817. It has also been suggested that Poe's "pit" was inspired by a translation of the Koran (Poe had referenced the Koran also in "Al Aaraaf" and "Israfel") by George Sale. Poe was familiar with Sale, and even mentioned him by name in a note in his story "The Thousand-and-Second Tale of Scheherazade". Sale's translation was a part of commentary and, in one of those notes, refers to an allegedly common form of torture and execution by "throwing [people] into a glowing pit of fire, whence he had the opprobrious appellation of the Lord of the Pit." In the Koran itself, in Sura (Chapter) 85, "The Celestial Signs", a passage reads: "...cursed were the contrivers of the pit, of fire supplied with the fuel... and they afflicted them for no other reason, but because they believed in the mighty, the glorious God." Poe is also considered to have been influenced by William Mudford's "The Iron Shroud", a short story about an iron torture chamber which shrinks through mechanical action and eventually crushes the victim inside. Poe apparently got the idea for the shrinking chamber in the "Pit and the Pendulum" after Mudford's story was published in "Blackwood's magazine" in 1830.
Publication and response.
"The Pit and the Pendulum" was included in "The Gift: A Christmas and New Year's Present" for 1843, published by Carey & Hart. It was slightly revised for a republication in the May 17, 1845 issue of the "Broadway Journal".
William Butler Yeats was generally critical of Poe, calling him "vulgar." Of "The Pit and the Pendulum" in particular he said, "[it does] not seem to me to have permanent literary value of any kind... Analyse the Pit and the Pendulum and you find an appeal to the nerves by tawdry physical affrightments."

</doc>
<doc id="30758" url="http://en.wikipedia.org/wiki?curid=30758" title="Age of Enlightenment">
Age of Enlightenment

The Age of Enlightenment (or simply the Enlightenment, or Age of Reason) is an era from the 1650s to the 1780s in which cultural and intellectual forces in Western Europe emphasized reason, analysis, and individualism rather than traditional lines of authority. It was promoted by philosophes and local thinkers in urban coffee houses, salons, and Masonic lodges. It challenged the authority of institutions that were deeply rooted in society, especially the Catholic Church; there was much talk of ways to reform society with toleration, science and skepticism.
Philosophers including Francis Bacon (1562–1626), René Descartes (1596–1650), John Locke (1632–1704), Baruch Spinoza (1632–1677), Pierre Bayle (1647–1706), Voltaire (1694–1778), David Hume (1711–1776), Cesare Beccaria (1738–1794), Immanuel Kant (1724–1804), and Sir Isaac Newton (1642–1727) influenced society by publishing widely read works. Upon learning about enlightened views, some rulers met with intellectuals and tried to apply their reforms, such as allowing for toleration, or accepting multiple religions, in what became known as enlightened absolutism. Coinciding with the Age of Enlightenment was the Scientific revolution, spearheaded by Newton.
New ideas and beliefs spread around the continent and were fostered by an increase in literacy due to a departure from solely religious texts. Publications include "Encyclopédie" (1751–72) that was edited by Denis Diderot and (until 1759) Jean le Rond d'Alembert. Some 25,000 copies of the 35 volume encyclopedia were sold, half of them outside France. The "Dictionnaire philosophique" (Philosophical Dictionary, 1764) and "Letters on the English" (1733) written by Voltaire (1694–1778) were revolutionary texts that spread the ideals of the Enlightenment. Some of these ideals proved influential and decisive in the course of the French Revolution, which began in 1789. After the Revolution, the Enlightenment was followed by an opposing intellectual movement known as Romanticism.
Use of the term.
The term "Enlightenment" emerged in English in the later part of the 19th century, with particular reference to French philosophy, as the equivalent of the French term 'Lumières' (used first by Dubos in 1733 and already well established by 1751). From Immanuel Kant's 1784 essay "Beantwortung der Frage: Was ist Aufklärung?" ("") the German term became 'Aufklärung' ("aufklären" = to illuminate; "sich aufklären" = to clear up).
However, scholars have never agreed on a definition of the Enlightenment, or on its chronological or geographical extent. Terms like "les Lumières" (French), "illuminismo" (Italian), "ilustración" (Spanish) and "Aufklärung" (German) referred to partly overlapping movements. Not until the late nineteenth century did English scholars agree they were talking about "the Enlightenment."
Enlightenment historiography began in the period itself, from what "Enlightenment figures" said about their work. A dominant element was the intellectual angle they took. D'Alembert's "Preliminary Discourse of l'Encyclopédie" provides a history of the Enlightenment which comprises a chronological list of developments in the realm of knowledge – of which the "Encyclopédie" forms the pinnacle.
A more philosophical example of this was the 1783 essay contest (in itself an activity typical of the Enlightenment) announced by the Berlin newspaper "Berlinische Monatsschrift", which asked that very question: "What is Enlightenment?" Jewish philosopher Moses Mendelssohn was among those who responded, referring to Enlightenment as a process by which man was educated in the use of reason ("Jerusalem", 1783).
Immanuel Kant also wrote a response, referring to Enlightenment as "man's release from his self-incurred tutelage", tutelage being "man's inability to make use of his understanding without direction from another". "For Kant, Enlightenment was mankind's final coming of age, the emancipation of the human consciousness from an immature state of ignorance." According to historian Roy Porter, the thesis of the liberation of the human mind from the dogmatic state of ignorance that he argues was prevalent at the time is the epitome of what the age of enlightenment was trying to capture.
According to Bertrand Russell, however, the enlightenment was a phase in a progressive development, which began in antiquity, and that reason and challenges to the established order were constant ideals throughout that time. Russell argues that the enlightenment was ultimately born out of the Protestant reaction against the Catholic counter-reformation, when the philosophical views of the past two centuries crystallized into a coherent world view. He argues that many of the philosophical views, such as affinity for democracy against monarchy, originated among Protestants in the early 16th century to justify their desire to break away from the Pope and the Catholic Church. Though many of these philosophical ideals were picked up by Catholics, Russell argues, by the 18th century the Enlightenment was the principal manifestation of the schism that began with Martin Luther.
Chartier (1991) argues that the Enlightenment was only invented after the fact for a political goal. He claims the leaders of the French Revolution created an Enlightenment canon of basic text, by selecting certain authors and identifying them with the Enlightenment in order to legitimize their republican political agenda.
Jonathan Israel rejects the attempts of postmodern and Marxian historians to understand the revolutionary ideas of the period purely as by-products of social and economic transformations. He instead focuses on the history of ideas in the period from 1650 to the end of the 18th century, and claims that it was the ideas themselves that caused the change that eventually led to the revolutions of the latter half of the 18th century and the early 19th century. Israel argues that until the 1650s Western civilization "was based on a largely shared core of faith, tradition and authority".
Up until this date most intellectual debates revolved around "confessional" – that is, Catholic, Lutheran, Reformed (Calvinist), or Anglican issues, and the main aim of these debates was to establish which bloc of faith ought to have the "monopoly of truth and a God-given title to authority". After this date everything thus previously rooted in tradition was questioned and often replaced by new concepts in the light of philosophical reason. After the second half of the 17th century and during the 18th century a "general process of rationalization and secularization set in which rapidly overthrew theology's age-old hegemony in the world of study", and thus confessional disputes were reduced to a secondary status in favor of the "escalating contest between faith and incredulity".
Time span.
There is little consensus on the precise beginning of the age of Enlightenment; the beginning of the 18th century (1701) or the middle of the 17th century (1650) are often used as an approximate starting point. If taken back to the mid-17th century, the Enlightenment would trace its origins to Descartes' "Discourse on Method", published in 1637. In France, many cited the publication of Isaac Newton's "Principia Mathematica" in 1687. It is argued by several historians and philosophers that the beginning of the Enlightenment is when Descartes shifted the epistemological basis from external authority to internal certainty by his cogito ergo sum published in 1637.
As to its end, most scholars use the last years of the century – often choosing the French Revolution of 1789 or the beginning of the Napoleonic Wars (1804–15) as a convenient point in time with which to date the end of the Enlightenment.
Furthermore, the term "Enlightenment" is anachronistic and often applied across epochs. For example, in their work Dialectic of Enlightenment, Max Horkheimer and Theodor W. Adorno see developments of the 20th century as late consequences of the Enlightenment: humans are installed as "Master" of a world being freed from its magic; truth is understood as a system; rationality becomes an instrument and an ideology managed by apparatuses; civilisation turns into the barbarism of fascism; civilizing effects of the Enlightenment turn into their opposite; and exactly this – they claim – corresponds to the problematic structure of the Enlightenment's way of thinking. Jürgen Habermas, however, disagrees with his teachers' (Adorno and Horkheimer's) view of the Enlightenment as a process of decay. He talks about an "incomplete project of modernity" which, in a process of communicative actions, always asks for rational reasons.
Goals.
Although Enlightenment thinkers generally shared a similar set of values, their philosophical perspectives and methodological approaches to accomplishing their goals varied in significant and sometimes contradictory ways. As Outram notes, the Enlightenment comprised "many different paths, varying in time and geography, to the common goals of progress, of tolerance, and the removal of abuses in Church and state".
In his essay "What is Enlightenment?" (1784), Immanuel Kant described it simply as freedom to use one's own intelligence. More broadly, the Enlightenment period is marked by increasing empiricism, scientific rigor, and reductionism, along with increased questioning of religious orthodoxy.
Historian Peter Gay asserts that the Enlightenment broke through "the sacred circle," whose dogma had circumscribed thinking. The Sacred Circle is a term he uses to describe the interdependent relationship between the hereditary aristocracy, the leaders of the church, and the text of the Bible. This interrelationship manifests itself as kings invoking the doctrine "Divine Right of Kings" to rule. Thus, the church sanctioned the rule of the king and in return the king defended the church.
Zafirovski (2010) argues that the Enlightenment is the source of critical ideas, such as the centrality of freedom, democracy, and reason as primary values of society – as opposed to the divine right of kings or traditions as the ruling authority. This view argues that the establishment of a contractual basis of rights would lead to the market mechanism and capitalism, the scientific method, religious tolerance, and the organization of states into self-governing republics through democratic means. In this view, the tendency of the "philosophes" in particular to apply rationality to every problem is considered the essential change. Later critics of the Enlightenment, such as the Romantics of the 19th century, contended that its goals for rationality in human affairs were too ambitious ever to be achieved.
A variety of 19th-century movements, including liberalism and neo-classicism, traced their intellectual heritage back to the Enlightenment.
National variations.
The Enlightenment took hold in most European countries, often with a specific local emphasis. For example, in France it became associated with anti-government and anti-Church radicalism while in Germany it reached deep into the middle classes and where it expressed a spiritualistic and nationalistic tone without threatening governments or established churches.
Government responses varied widely. In France, the government was hostile, and the "philosophes" fought against its censorship, sometimes being imprisoned or hounded into exile. The British government for the most part ignored the Enlightenment's leaders in England and Scotland although it did give Isaac Newton a knighthood and a very lucrative government office.
Enlightened absolutism.
In several nations, powerful rulers – called "enlightened despots" by historians – welcomed leaders of the Enlightenment at court and asked them to help design laws and programs to reform the system, typically to build stronger national states. The most prominent of those rulers were Frederick the Great of Prussia, Catherine the Great, Empress of Russia from 1762 to 1796, Leopold II, who had ruled the Grand Duchy of Tuscany from 1765 to 1790, and Joseph II, Emperor of Austria from 1780 to 1790. Joseph was over-enthusiastic, announcing so many reforms that had so little support that revolts broke out and his regime became a comedy of errors and nearly all his programs were reversed. Senior ministers Pombal in Portugal and Struensee in Denmark governed according to Enlightenment ideals.
Britain.
Scotland.
By 1750 Scotland's major cities had created an intellectual infrastructure of mutually supporting institutions such as universities, reading societies, libraries, periodicals, museums and masonic lodges. The Scottish network was "predominantly liberal Calvinist, Newtonian, and 'design' oriented in character which played a major role in the further development of the transatlantic Enlightenment". In France, Voltaire said "we look to Scotland for all our ideas of civilization," and the Scots in turn paid close attention to French ideas. Historian Bruce Lenman says the Scots' "central achievement was a new capacity to recognize and interpret social patterns." The first major philosopher of the Scottish Enlightenment was Francis Hutcheson, who held the Chair of Philosophy at the University of Glasgow from 1729 to 1746. A moral philosopher who produced alternatives to the ideas of Thomas Hobbes, one of his major contributions to world thought was the utilitarian and consequentialist principle that virtue is that which provides, in his words, "the greatest happiness for the greatest numbers". Much of what is incorporated in the scientific method (the nature of knowledge, evidence, experience, and causation) and some modern attitudes towards the relationship between science and religion were developed by his protégés David Hume and Adam Smith. Hume became a major figure in the skeptical philosophical and empiricist traditions of philosophy. He and other Scottish Enlightenment thinkers developed a 'science of man', which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar, and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement, and Hume's philosophical concepts that directly influenced James Madison (and thus the U.S. Constitution) and as popularised by Dugald Stewart, would be the basis of classical liberalism. Adam Smith published "The Wealth of Nations", often considered the first work on modern economics. It had an immediate impact on British economic policy that continues into the 21st century. The focus of the Scottish Enlightenment ranged from intellectual and economic matters to the specifically scientific as in the work of William Cullen, physician and chemist; James Anderson, an agronomist; Joseph Black, physicist and chemist; and James Hutton, the first modern geologist.
Francis Hutcheson, Adam Smith, and David Hume paved the way for the modernization of Scotland and the entire Atlantic world. Hutcheson, the father of the Scottish Enlightenment, championed political liberty and the right of popular rebellion against tyranny. Smith, in his monumental "Wealth of Nations" (1776), advocated liberty in the sphere of commerce and the global economy. Hume developed philosophical concepts that directly influenced James Madison and thus the U.S. Constitution.
Scientific progress was influenced by, amongst others, the discovery of carbon dioxide (fixed air) by the chemist Joseph Black, the argument for deep time by the gentleman geologist James Hutton, and the invention of the steam engine by James Watt. In a similar vein, the University of Edinburgh's Medical School was arguably the leading scientific institution of Europe. Students from far and wide travelled to the university to study chemistry with William Cullen, James Black, and Thomas Charles Hope, natural history with John Hope, John Walker, and Robert Jameson, and anatomy with the Alexander Monro primus, secondus, and tertius.
The second stage of the Scottish Enlightenment, from the 1780s to the 1810s, consisted of a younger generation of scholars intent on popularizing the ideas of their predecessors. The end result was a reinterpretation and popularisation of the 'Scottish Enlightenment' as a set of ideals that were in turn significantly influential on liberal politics and the university systems of Britain, America and, later, Australia. The de facto leader of this movement was Dugald Stewart. Other names include Sir Walter Scott, Alexander Fraser Tytler, Sir James Hall, and John Playfair.
Dugald Stewart was a student of Adam Ferguson in Edinburgh. He then spent the years 1771 and 1772 under the instruction of Thomas Reid in Glasgow; it was Reid rather than Ferguson who was crucial to Stewart's philosophical development. From an early age, Dugald Stewart exhibited the kind of intelligence typical to a polymath. Though his main interest was philosophy, his talent for mathematics led to his job, at the age of 25, as Professor of Mathematics at Edinburgh. He held that position, initially with and then in succession to his father, Matthew Stewart. Having also substituted in the moral philosophy chair from 1778 to 1779, when Ferguson was in America working for the British government, Stewart finally took the place of his father in 1785. He held this second Chair for 25 years, and lectured so famously well that by the time of his retirement from teaching in 1810, he had developed a distinguished reputation in Europe and in North America. Stewart had a huge impact on the intellectual climate of his time, partly through his lectures, partly through his writings. He attracted students from England, Europe and America, as well as domestic students, in numbers that had never been seen before. Their impact was exceptional. Lord Cockburn, a student of Stewart’s and subsequently a Scottish judge of considerable distinction, records that ‘To me Stewart’s lectures were like the opening of the heavens. I felt that I had a soul. Dugald Stewart was one of the greatest didactic orators’. Stewart lectured at the University of Edinburgh during the 1790s and then took his views to the British public through his books and many essays in the progressive periodicals that circulated across the British Empire. These late Enlightenment publications, combined with his many books, went on to have a profound impact on 19th-century utilitarianism, psychology, metaphysics, political economy, and, crucially, classic liberalism.
England.
Thomas Hobbes wrote the 1651 book "Leviathan", which provided the foundation for social contract theory. Though he was a champion of absolutism for the sovereign, Hobbes also developed some of the fundamentals of European liberal thought: the right of the individual; the natural equality of all men; the artificial character of the political order (which led to the later distinction between civil society and the state); the view that all legitimate political power must be "representative" and based on the consent of the people; and a liberal interpretation of law which leaves people free to do whatever the law does not explicitly forbid.
John Locke was one of the most influential Enlightenment thinkers. He influenced other thinkers such as Rousseau and Voltaire, among others. "He is one of the dozen or so thinkers who are remembered for their influential contributions across a broad spectrum of philosophical subfields – in Locke's case, across epistemology, the philosophy of language, the philosophy of mind, metaphysics, rational theology, ethics, and political philosophy."
Closely associated with the 1st Earl of Shaftesbury, who led the parliamentary grouping that later became the Whig party, Locke is still known today for his liberalism in political theory. He was particularly known for developing the social contract theory, an idea in political philosophy typically associated with Locke and Rousseau. The theory stated that a government and its subjects enter into an unspoken contract when that government takes power. The contract states that in exchange for some societal freedoms to the government or establishment and its laws, the subjects receive and are free to demand protection. The government’s authority lies in the consent of the governed. Locke is well known for his assertion that individuals have a right to "Life, Liberty and Property", and his belief that the natural right to property is derived from labor. Tutored by Locke, Anthony Ashley-Cooper, 3rd Earl of Shaftesbury wrote in 1706: "There is a mighty Light which spreads its self over the world especially in those two free Nations of England and Holland; on whom the Affairs of Europe now turn".
Mary Wollstonecraft was one of England's earliest feminist philosophers. She argued for a society based on reason, and that women, as well as men, should be treated as rational beings. She is best known for her work "A Vindication of the Rights of Woman" (1791).
Thirteen American Colonies.
Several Americans, especially Benjamin Franklin and Thomas Jefferson, played a major role in bringing Enlightenment ideas to the new world and in influencing British and French thinkers.
The Americans closely followed English and Scottish political ideas, as well as some French thinkers such as Montesquieu. As deists, they were influenced by ideas of John Toland (1670–1722) and Matthew Tindal (1656–1733). During the Enlightenment there was a great emphasis upon liberty, democracy, republicanism and religious tolerance. Attempts to reconcile science and religion resulted in a widespread rejection of prophecy, miracle and revealed religion in preference for Deism – especially by Thomas Paine in "The Age of Reason" and by Thomas Jefferson in his short "Jefferson Bible" – from which all supernatural aspects were removed.
Benjamin Franklin was influential in England, Scotland, and the United States and France, for his political activism and for his advances in physics.
The cultural exchange during the Age of Enlightenment ran in both directions across the Atlantic. Historian Charles C. Mann points out that thinkers such as Paine, Locke, and Rousseau all take Native American cultural practices as examples of natural freedom.
Dutch Republic.
For the Dutch the Enlightenment initially sprouted during the Dutch Golden Age.
Developments during this period were to have a profound influence in the shaping of western civilization, as science, art, philosophy and economic development flourished in the Dutch Republic. Some key players in the Dutch Enlightenment were: René Descartes, originator of cogito ergo sum, Baruch Spinoza, a philosopher that wrote on pantheism and a one substance philosophy as a critique of Cartesian Dualism; Pierre Bayle, a French philosopher who advocated separation between science and religion; Eise Eisinga, an astronomer who built a planetarium; Lodewijk Meyer, a radical who claimed the Bible was obscure and doubtful; Adriaan Koerbagh, a scholar and critic of religion and conventional morality; and Burchard de Volder, a natural philosopher.
Greece.
The Greek Enlightenment was given impetus by wealthy Greek merchants in the major cities of the Ottoman Empire. The most important centers of Greek learning, schools and universities, were situated in Ioannina, Chios, Smyrna (İzmir) and Ayvalik. The transmission of Enlightenment ideas into Greek thought also influenced the development of a national consciousness. The publication of the journal "Hermes o Logios" encouraged the ideas of the Enlightenment. The journal's objective was to advance Greek science, philosophy and culture. Two of the main figures of the Greek Enlightenment, Rigas Feraios and Adamantios Korais, encouraged Greek nationalists to pursue contemporary political thought.
Italy.
Italy was changed by the Enlightenment and it influenced Italian philosophy. Enlightened thinkers often met to discuss in private salons and coffeehouses; notably in the cities of Milan, Turin and Venice. Cities with important universities such as Padua, Bologna, Naples and Rome, however, also remained great centres of scholarship and the intellect, especially Giambattista Vico (1668–1744) and Antonio Genovesi. Parts of Italian society also dramatically changed during the Enlightenment, with rulers such as Leopold II of Tuscany abolishing the death penalty in Tuscany. The Church's power was significantly reduced which led to a period of great thought and invention, with scientists such as Alessandro Volta and Luigi Galvani making new discoveries and greatly contributing to Western science. Cesare Beccaria, one of the greatest Italian Enlightenment writers, became famous for his masterpiece "Of Crimes and Punishments" (1764), which was later translated into 22 languages. Another prominent intellectual was Francesco Mario Pagano, who wrote important studies such as "Saggi Politici" (Political Essays, 1783), one of the major works of the Enlightenment in Naples, and "Considerazioni sul processo criminale" (Considerations on the criminal trial, 1787), which established him as an international authority on criminal law.
France.
In the mid-18th century, Paris became the center of an explosion of philosophic and scientific activity challenging traditional doctrines and dogmas. French historians usually place the period, called the "Siècle des Lumières" (Century of Enlightenments), between 1715 and 1789, from the beginning of the reign of Louis XV until the French Revolution. The philosophic movement was led by Voltaire and Jean-Jacques Rousseau, who argued for a society based upon reason rather than faith and Catholic doctrine, for a new civil order based on natural law, and for science based on experiments and observation. The political philosopher Montesquieu introduced the idea of a separation of powers in a government, a concept which was enthusiastically adopted by the authors of the United States Constitution. While the "Philosophes" of the French Enlightenment were not revolutionaries, and many were members of the nobility, their ideas played an important part in undermining the legitimacy of the Old Regime and shaping the French Revolution, 
Much of the scientific activity was based at the Louvre, where the French Academy of Sciences, founded in 1666, was located; it had separate sections for geometry, astronomy, mechanics, anatomy, chemistry and botany. Under Louis XVI new sections were added on physics, natural history and mineralogy. French scientists rivalled British scientists in mathematics and astronomy, and were ahead in chemistry and natural history. The biologist and natural historian Georges-Louis Leclerc, Comte de Buffon directed the Jardin des Plantes, and made it a leading center for botanic research. The mathematicians Joseph-Louis Lagrange, Jean-Charles de Borda, and Pierre-Simon Laplace; the botanist René Louiche Desfontaines, the chemists Claude Louis Berthollet, Antoine François, comte de Fourcroy and Antoine Lavoisier, all contributed to the new scientific revolution taking place in Paris. 
The new ideas and discoveries were publicized throughout Europe by book publishers in Paris. Between 1720 and 1780, the number of books about science and art published in Paris doubled, while the number of books about religion dropped to just one-tenth of the total. 
Denis Diderot and Jean le Rond d'Alembert published their "Encyclopedie" in seventeen volumes between 1751 and 1766. It provided intellectuals across Europe with a high quality survey of human knowledge. Scientists came to Paris from across Europe and from the United States to share ideas; Benjamin Franklin came in 1767 to meet with Voltaire and to talk about his experiments with electricity.
Some of the discoveries of Paris scientists, particularly in the field of chemistry, were quickly put to practical use; the experiments of Lavoisier were used to create the first modern chemical plants in Paris, and the production of hydrogen gas enabled the Montgolfier Brothers to launch the first manned flight in a hot-air balloon on 21 November 1783, from the Château de la Muette, near the Bois de Boulogne.
Poland.
The Age of Enlightenment reached Poland later than in Germany or Austria, as szlachta (nobility) culture (Sarmatism) together with the Polish-Lithuanian Commonwealth political system (Golden Freedoms) were in deep crisis. The period of Polish Enlightenment began in the 1730s–1740s, peaked in the reign of Poland's last king, Stanisław August Poniatowski (second half of the 18th century), went into decline with the Third Partition of Poland (1795), and ended in 1822, replaced by Romanticism in Poland. The model constitution of 1791 expressed Enlightenment ideals but was in effect for only one year as the nation was partitioned among its neighbors. More enduring were the cultural achievements, which created a nationalist spirit in Poland.
Prussia and the German States.
By the mid-18th century the German Enlightenment in music, philosophy, science and literature emerged as an intellectual force. Frederick the Great (1712–86), the king of Prussia 1740–1786, saw himself as a leader of the Enlightenment and patronized philosophers and scientists at his court in Berlin. He was an enthusiast for French classicism as he criticized German culture and was unaware of the remarkable advances it was undergoing. Voltaire, who had been imprisoned and maltreated by the French government, was eager to accept Frederick's invitation to live at his palace. Frederick explained, "My principal occupation is to combat ignorance and prejudice ... to enlighten minds, cultivate morality, and to make people as happy as it suits human nature, and as the means at my disposal permit." Other rulers were supportive, such as Karl Friedrich, Grand Duke of Baden, who ruled Baden for 73 years (1738–1811).
Christian Wolff (1679–1754) was the pioneer as a writer who expounded the Enlightenment to German readers; he legitimized German as a philosophic language. Johann Gottfried von Herder (1744–1803) broke new ground in philosophy and poetry, specifically in the Sturm und Drang movement of proto-Romanticism. Weimar Classicism ("Weimarer Klassik") was a cultural and literary movement based in Weimar that sought to establish a new humanism by synthesizing Romantic, classical and Enlightenment ideas. The movement, from 1772 until 1805, involved Herder as well as polymath Johann Wolfgang von Goethe (1749–1832) and Friedrich Schiller (1759–1805), a poet and historian. Herder argued that every folk had its own particular identity, which was expressed in its language and culture. This legitimized the promotion of German language and culture and helped shape the development of German nationalism. Schiller's plays expressed the restless spirit of his generation, depicting the hero's struggle against social pressures and the force of destiny.
German music, sponsored by the upper classes, came of age under composers such as Carl Philipp Emanuel Bach (1714–1788), Joseph Haydn (1732–1809), and Wolfgang Amadeus Mozart (1756–1791).
In remote Königsberg philosopher Immanuel Kant (1724–1804) tried to reconcile rationalism and religious belief, individual freedom and political authority. As well as map out a view of the public sphere through private and public reason. Kant's work contained basic tensions that would continue to shape German thought – and indeed all of European philosophy – well into the 20th century.
The German Enlightenment won the support of princes, aristocrats and the middle classes and permanently reshaped the culture.
Russia.
In Russia the Enlightenment of the mid-eighteenth century saw the government begin to actively encourage the proliferation of arts and sciences. This era produced the first Russian university, library, theatre, public museum, and independent press. Like other enlightened despots, Catherine the Great played a key role in fostering the arts, sciences, and education. She used her own interpretation of Enlightenment ideals, assisted by notable international experts such as Voltaire (by correspondence) and, in residence, world class scientists such as Leonhard Euler, Peter Simon Pallas, Fedor Ivanovich Iankovich de Mirievo (also spelled Teodor Janković-Mirijevski), and Anders Johan Lexell. The national Enlightenment differed from its Western European counterpart in that it promoted further Modernization of all aspects of Russian life and was concerned with attacking the institution of serfdom in Russia. Historians argue that the Russian enlightenment centered on the individual instead of societal enlightenment and encouraged the living of an enlightened life.
Spain.
Charles III, king of Spain from 1759 to 1788, tried to rescue his empire from decay through far-reaching reforms such as weakening the Church and its monasteries, promoting science and university research, facilitating trade and commerce, modernizing agriculture, and avoiding wars. He was unable to control budget deficits, and borrowed more and more. Spain relapsed after his death.
Historiography.
Debates.
Historian Keith Thomas says the Enlightenment has always been contested territory. He says that its supporters:
However, he adds, "its enemies accuse it of 'shallow' rationalism, naïve optimism, unrealistic universalism, and moral darkness."
Thomas points out that from the start there was a Counter-Enlightenment in which conservative and clerical defenders of traditional religion attacked materialism and skepticism as evil forces that encouraged immorality. By 1794, they pointed to the Terror during the French Revolution as confirmation of their predictions. As the Enlightenment was ending, new generations of Romantic philosophers argued that excessive dependence on reason was a mistake perpetuated by the Enlightenment, because it disregarded the powerful bonds of history, myth, faith and tradition that were necessary to hold society together.
Political thought.
Like the French Revolution, the Enlightenment has long been hailed as the foundation of modern Western political and intellectual culture. It has been frequently linked to the French Revolution of 1789. However, as Roger Chartier points out, it was perhaps the Revolution that "invented the Enlightenment by attempting to root its legitimacy in a corpus of texts and founding authors reconciled and united ... by their preparation of a rupture with the old world".
In other words, the revolutionaries elevated to heroic status those philosophers, such as Voltaire and Rousseau, who could be used to justify their radical break with the Ancien Régime. In any case, two 19th-century historians of the Enlightenment, Hippolyte Taine and Alexis de Tocqueville, did much to solidify this link of Enlightenment causing revolution and the intellectual perception of the Enlightenment itself.
An alternative view is that the "consent of the governed" philosophy as delineated by Locke in "Two Treatises of Government" (1689) represented a paradigm shift from the old governance paradigm under feudalism known as the "divine right of kings". In this view, the revolutions of the late 1700s and early 1800s were caused by the fact that this governance paradigm shift often could not be resolved peacefully, and therefore violent revolution was the result. Clearly a governance philosophy where the king was never wrong was in direct conflict with one whereby citizens by natural law had to consent to the acts and rulings of their government.
John Locke was able to root his governance philosophy in social contract theory, a predominant subject that permeated Enlightenment political thought. Formally, it was the English philosopher Thomas Hobbes who ushered in this new debate with his work "Leviathan" in 1651. Both John Locke and Jean-Jacques Rousseau developed their own social contract theories in "Two Treatises of Government" and "Discourse on Inequality", respectively. While quite different works, all three argue that a social contract is necessary for man to live in civil society.
For Hobbes, the state of nature is a state of impoverished anarchic violence in which human life is "solitary, poor, nasty, brutish, and short". To counter this, Hobbes argues that society enters into a social contract with itself to have an all-powerful, absolute leader, giving up a few personal liberties in exchange for security and lawfulness.
In 1689 John Locke published his Two Treatises of Government. In it, he defines his state of nature as a condition in which humans are rational and follow natural law; in which all men are born equal and with the right to life, liberty and property. However, when one citizen breaks the Law of Nature, both the transgressor and the victim enter into a state of war, from which it is virtually impossible to break free. Therefore, Locke argues that individuals enter into civil society to protect their natural rights via an “unbiased judge” or common authority, such as courts, to appeal to.
Contrastingly, Rousseau’s conception of both the state of nature and civil society, and how man moves from one to the other, relies on the supposition that civil man is corrupted. In his work "Discourse on Inequality", Rousseau argues natural man is a sentient being that has no want he cannot fulfil himself. Natural man is only taken out of the state of nature when “the first man who, having enclosed a piece of ground, to whom it occurred to say this is mine, and found people sufficiently simple to believe him, was the true founder of civil society". Once the inequality associated with private property is established, society is corrupted and thusly perpetuates inequality through the division of labor and, ultimately, power relations. With this in mind, Rousseau wrote "On the Social Contract" to spell out his contract theory. He argues that men join into civil society via the social contract to achieve unity while preserving individual freedom. This is embodied in the sovereignty of the general will, the moral and collective legislative body constituted by citizens.
Though much of Enlightenment political thought was dominated by social contract theorists, both David Hume and Adam Ferguson criticized this camp. In his essay, "Of the Original Contract", Hume argues that governments derived from consent are rarely seen, rather civil government is grounded in a ruler's habitual authority and force. It is precisely because of the ruler's authority over-and-against the subject, that the subject tacitly consents; Hume argues that the subjects would "never imagine that their consent made him sovereign", rather the authority did so. Similarly, Ferguson did not believe citizens built the state, rather polities grew out of social development. In his 1767 "An Essay on the History of Civil Society", Ferguson uses the four stages of progress, a theory that was very popular in Scotland at the time, to explain how humans advance from a hunting and gathering society to a commercial and civil society without "signing" a social contract.
Both Rousseau and Locke's social contract theories rest on the presupposition of natural rights. A natural right is not given to man by law or custom, rather it is something that all men have in pre-political societies, and is therefore universal and inalienable. The most famous natural right formulation comes from John Locke in his "Second Treatise", when he introduces the state of nature. As previously discussed, man is perfectly free in the state of nature, within the bounds of the law of nature and reason. For Locke the law of nature is grounded on mutual security, or the idea that one cannot infringe on another's natural rights, as every man is equal and has the same inalienable rights. These natural rights include perfect equality and freedom, and the right to preserve life and property.
Based on his formulation, John Locke argued against slavery on the basis that enslaving yourself goes against the law of nature; you cannot surrender your own rights, your freedom is absolute and no one can take it from you. Additionally, Locke argues that one person cannot enslave another because it is morally reprehensible. Locke does introduce a caveat in his indictment of slavery, he believes one can be made a slave during times of war and conflict because this is merely a continuation of the state of war. Therefore, one cannot sell oneself into slavery, but if one were to find oneself a lawful captive, ones enslavement would not go against ones natural rights.
Locke's theory of natural rights has influenced many political documents including the French National Constituent Assembly's Declaration of the Rights of Man and of the Citizen and the United States Declaration of Independence, to name a few.
In his "L’Ancien Régime" (1876), Hippolyte Taine traced the roots of the French Revolution back to French Classicism. However, this was not without the help of the Enlightenment view of the world, which wore down the "monarchical and religious dogma of the old regime". In other words, Taine was only interested in the Enlightenment insofar as it advanced scientific discourse and transmitted what he perceived to be the intellectual legacy of French classicism.
Alexis de Tocqueville painted a more elaborate picture of the Enlightenment in "L'Ancien Régime et la Révolution" (1850). For de Tocqueville, the Revolution was the inevitable result of the radical opposition created in the 18th century between the monarchy and the men of letters of the Enlightenment. These men of letters constituted a sort of "substitute aristocracy that was both all-powerful and without real power". This illusory power came from the rise of "public opinion", born when absolutist centralization removed the nobility and the bourgeoisie from the political sphere. The "literary politics" that resulted promoted a discourse of equality and was hence in fundamental opposition to the monarchical regime.
De Tocqueville "clearly designates ... the cultural effects of transformation in the forms of the exercise of power". Nevertheless, it took another century before cultural approach became central to the historiography, as typified by Robert Darnton, "The Business of Enlightenment: A Publishing History of the Encyclopédie, 1775–1800" (1979).
De Dijn argues that Peter Gay, in "The Enlightenment: An Interpretation" (1966), first formulated the interpretation that the Enlightenment brought political modernization to the West, in terms of introducing democratic values and institutions and the creation of modern, liberal democracies. While the thesis has many critics it has been widely accepted by Anglophone scholars and has been reinforced by the large-scale studies by Robert Darnton, Roy Porter and most recently by Jonathan Israel.
Religious debate.
Enlightenment era religious commentary was a response to the preceding century of religious conflict in Europe, especially the Thirty Years' War. Theologians of the Enlightenment wanted to reform their faith to its generally non-confrontational roots and to limit the capacity for religious controversy to spill over into politics and warfare while still maintaining a true faith in God.
For moderate Christians, this meant a return to simple Scripture. John Locke abandoned the corpus of theological commentary in favor of an "unprejudiced examination" of the Word of God alone. He determined the essence of Christianity to be a belief in Christ the redeemer and recommended avoiding more detailed debate. Thomas Jefferson in the "Jefferson Bible" went further; he dropped any passages dealing with miracles, visitations of angels, and the resurrection of Jesus after his death. He tried to extract the practical Christian moral code of the New Testament.
Enlightenment scholars sought to curtail the political power of organized religion and thereby prevent another age of intolerant religious war. Spinoza determined to remove politics from contemporary and historical theology (e.g. disregarding Judaic law). Moses Mendelssohn advised affording no political weight to any organized religion, but instead recommended that each person follow what s/he found most convincing. A good religion based in instinctive morals and a belief in God should not theoretically need force to maintain order in its believers, and both Mendelssohn and Spinoza judged religion on its moral fruits, not the logic of its theology.
A number of novel religious ideas developed with Enlightened faith, including Deism and talk of atheism. Deism, according to Thomas Paine, is the simple belief in God the Creator, with no reference to the Bible or any other miraculous source. Instead, the Deist relies solely on personal reason to guide his creed, which was eminently agreeable to many thinkers of the time.
Atheism was much discussed but there were few proponents. Wilson and Reill note that, "In fact, very few enlightened intellectuals, even when they were vocal critics of Christianity, were true atheists. Rather, they were critics of orthodox belief, wedded rather to skepticism, deism, vitalism, or perhaps pantheism."
Some followed Pierre Bayle and argued that atheists could indeed be moral men. Many others like Voltaire held that without belief in a God who punishes evil, the moral order of society was undermined. That is, since atheists gave themselves to no Supreme Authority and no law, and had no fear of eternal consequences, they were far more likely to disrupt society. Bayle (1647–1706) observed that in his day, "prudent persons will always maintain an appearance of [religion].". He believed that even atheists could hold concepts of honor and go beyond their own self-interest to create and interact in society. Locke considered the consequences for mankind if there were no God and no divine law. The result would be moral anarchy. Every individual “could have no law but his own will, no end but himself. He would be a god to himself, and the satisfaction of his own will the sole measure and end of all his actions”.
Intellectual history.
In the meantime, though, intellectual history remained the dominant historiographical trend. The German scholar Ernst Cassirer is typical, writing in his "The Philosophy of the Enlightenment" (1932) that the Enlightenment was "a part and a special phase of that whole intellectual development through which modern philosophic thought gained its characteristic self-confidence and self-consciousness". Borrowing from Kant, Cassirer states that Enlightenment is the process by which the spirit "achieves clarity and depth in its understanding of its own nature and destiny, and of its own fundamental character and mission". In short, the Enlightenment was a series of philosophical, scientific and otherwise intellectual developments that took place mostly in the 18th century – the birthplace of intellectual modernity.
Recent work.
Only in the 1970s did interpretation of the Enlightenment allow for a more heterogeneous and even extra-European vision. A. Owen Aldridge demonstrated how Enlightenment ideas spread to Spanish colonies and how they interacted with indigenous cultures, while Franco Venturi explored how the Enlightenment took place in normally unstudied areas – Italy, Greece, the Balkans, Poland, Hungary, and Russia.
Robert Darnton's cultural approach launched a new dimension of studies. He said, :
"Perhaps the Enlightenment was a more down-to-earth affair than the rarefied climate of opinion described by textbook writers, and we should question the overly highbrow, overly metaphysical view of intellectual life in the eighteenth century."
Darnton examines the underbelly of the French book industry in the 18th century, examining the world of book smuggling and the lives of those writers (the "Grub Street Hacks") who never met the success of their "philosophe" cousins. In short, rather than concerning himself with Enlightenment canon, Darnton studies "what Frenchmen wanted to read", and who wrote, published and distributed it.
Similarly, in "The Business of Enlightenment. A Publishing History of the Encyclopédie 1775–1800", Darnton states that there is no need to further study the encyclopædia itself, as "the book has been analyzed and anthologized dozen of times: to recapitulate all the studies of its intellectual content would be redundant". He instead, as the title of the book suggests, examines the social conditions that brought about the production of the "Encyclopédie". This is representative of the social interpretation as a whole – an examination of the social conditions that brought about Enlightenment ideas rather than a study of the ideas themselves.
The work of German philosopher Jürgen Habermas was central to this emerging social interpretation; his seminal work "The Structural Transformation of the Public Sphere" (published under the title "Strukturwandel der Öffentlichkeit" in 1962) was translated into English in 1989. The book outlines the creation of the "bourgeois public sphere" in 18th-century Europe. Essentially, this public sphere describes the new venues and modes of communication allowing for rational exchange that appeared in the 18th century. Habermas argued that the public sphere was bourgeois, egalitarian, rational, and independent from the state, making it the ideal venue for intellectuals to critically examine contemporary politics and society, away from the interference of established authority.
Habermas's work, though influential, has come under criticism on all fronts. While the public sphere is generally an integral component of social interpretations of the Enlightenment, numerous historians have brought into question whether the public sphere was bourgeois, oppositional to the state, independent from the state, or egalitarian.
These historiographical developments have done much to open up the study of Enlightenment to a multiplicity of interpretations. In "A Social History of Truth" (1994), for example, Steven Shapin makes the largely sociological argument that, in 17th-century England, the mode of sociability known as civility became the primary discourse of truth; for a statement to have the potential to be considered true, it had to be expressed according to the rules of civil society.
According to Jonathan Israel, this period saw the shaping of two distinct lines of enlightenment thought: Firstly the "radical enlightenment", largely inspired by the one-substance philosophy of Spinoza, which in its political form adhered to: "democracy; racial and sexual equality; individual liberty of lifestyle; full freedom of thought, expression, and the press; eradication of religious authority from the legislative process and education; and full separation of church and state".
Secondly the "moderate enlightenment", which in a number of different philosophical systems, like those in the writings of Descartes, John Locke, Isaac Newton or Christian Wolff, expressed some support for critical review and renewal of the old modes of thought, but in other parts sought reform and accommodation with the old systems of power and faith. These two lines of thought were again met by the conservative Counter-Enlightenment, encompassing those thinkers who held on to the traditional belief-based systems of thought.
Feminist interpretations have also appeared, with Dena Goodman being one notable example. In "The Republic of Letters: A Cultural History of the French Enlightenment" (1994), Goodman argues that many women in fact played an essential part in the French Enlightenment, due to the role they played as "salonnières" in Parisians salons. These salons "became the civil working spaces of the project of Enlightenment" and women, as salonnières, were "the legitimate governors of [the] potentially unruly discourse" that took place within. On the other hand, Carla Hesse, in "The Other Enlightenment: How French Women Became Modern" (2001), argues that "female participation in the public cultural life of the Old Regime was ... relatively marginal". It was instead the French Revolution, by destroying the old cultural and economic restraints of patronage and corporatism (guilds), that opened French society to female participation, particularly in the literary sphere.
Social and cultural interpretation.
In opposition to the intellectual historiographical approach of the Enlightenment, which examines the various currents or discourses of intellectual thought within the European context during the 17th and 18th centuries, the cultural (or social) approach examines the changes that occurred in European society and culture. Under this approach, the Enlightenment is less a body of thought than a process of changing sociabilities and cultural practices – both the "content" and the processes by which this content was spread are now important. Roger Chartier describes it as follows:
This movement [from the intellectual to the cultural/social] implies casting doubt on two ideas: first, that practices can be deduced from the discourses that authorize or justify them; second, that it is possible to translate into the terms of an explicit ideology the latent meaning of social mechanisms.
One of the primary elements of the cultural interpretation of the Enlightenment is the rise of the public sphere in Europe. Jürgen Habermas has influenced thinking on the public sphere more than any other, though his model is increasingly called into question. The essential problem that Habermas attempted to answer concerned the conditions necessary for "rational, critical, and genuinely open discussion of public issues". Or, more simply, the social conditions required for Enlightenment ideas to be spread and discussed. His response was the formation in the late 17th century and 18th century of the "bourgeois public sphere", a "realm of communication marked by new arenas of debate, more open and accessible forms of urban public space and sociability, and an explosion of print culture". More specifically, Habermas highlights three essential elements of the public sphere:
James Van Horn Melton provides a good summary of the values of this bourgeois public sphere: its members held reason to be supreme; everything was open to criticism (the public sphere is critical); and its participants opposed secrecy of all sorts. This helps explain what Habermas meant by the domain of "common concern". Habermas uses the term to describe those areas of political/social knowledge and discussion that were previously the exclusive territory of the state and religious authorities, now open to critical examination by the public sphere.
Habermas credits the creation of the bourgeois public sphere to two long-term historical trends: the rise of the modern nation state and the rise of capitalism. The modern nation state in its consolidation of public power created by counterpoint a private realm of society independent of the state – allowing for the public sphere. Capitalism also increased society's autonomy and self-awareness, and an increasing need for the exchange of information. As the nascent public sphere expanded, it embraced a large variety of institutions; the most commonly cited were coffee houses and cafés, salons and the literary public sphere, figuratively localized in the Republic of Letters.
Dorinda Outram further describes the rise of the public sphere. The context was the economic and social change commonly associated with the Industrial Revolution: "economic expansion, increasing urbanization, rising population and improving communications in comparison to the stagnation of the previous century"." Rising efficiency in production techniques and communication lowered the prices of consumer goods at the same time as it increased the amount and variety of goods available to consumers (including the literature essential to the public sphere). Meanwhile, the colonial experience (most European states had colonial Empires in the 18th century) began to expose European society to extremely heterogeneous cultures. Outram writes that the end result was the breaking down of "barriers between cultural systems, religious divides, gender differences and geographical areas". In short, the social context was set for the public sphere to come into existence.
A reductionist view of the Habermasian model has been used as a springboard to showcase historical investigations into the development of the public sphere. There are many examples of noble and lower class participation in areas such as the coffeehouses and the freemasonic lodges, demonstrating that the bourgeois-era public sphere was enriched by cross-class influences. A rough depiction of the public sphere as independent and critical of the state is contradicted by the diverse cases of government-sponsored public institutions and government participation in debate, along with the cases of private individuals using public venues to promote the status quo.
Exclusivity of the public sphere.
The word "public" implies the highest level of inclusivity – the public sphere by definition should be open to all. However, as the analysis of many "public" institutions of the Enlightenment will show, this sphere was only public to relative degrees. Indeed, as Roger Chartier emphasizes, Enlightenment thinkers frequently contrasted their conception of the "public" with that of the people: Chartier cites Condorcet, who contrasted "opinion" with populace; Marmontel with "the opinion of men of letters" versus "the opinion of the multitude"; and d'Alembert, who contrasted the "truly enlightened public" with "the blind and noisy multitude". In France the aristocracy played a central role in the public sphere when it moved from the King's palace at Versailles to Paris about 1720. Their rich spending stimulated the trade in luxuries and artistic creations, especially fine paintings.
As Mona Ozouf underlines, public opinion was defined in opposition to the opinion of the greater population. While the nature of public opinion during the Enlightenment is as difficult to define as it is today, it is nonetheless clear that the body that held it (i.e. the public sphere) was exclusive rather than inclusive. This observation will become more apparent during the descriptions of the institutions of the public sphere, most of which excluded both women and the lower classes.
Social and cultural implications in music.
Because of the focus on reason over superstition, the Enlightenment cultivated the arts. Emphasis on learning, art and music became more widespread, especially with the growing middle class. Areas of study such as literature, philosophy, science, and the fine arts increasingly explored subject matter that the general public in addition to the previously more segregated professionals and patrons could relate to.
As musicians depended more and more on public support, public concerts became increasingly popular and helped supplement performers' and composers' incomes. The concerts also helped them to reach a wider audience. Handel, for example, epitomized this with his highly public musical activities in London. He gained considerable fame there with performances of his operas and oratorios. The music of Haydn and Mozart, with their Viennese Classical styles, are usually regarded as being the most in line with the Enlightenment ideals.
Another important text that came about as a result of Enlightenment values was Charles Burney's "A General History of Music: From the Earliest Ages to the Present Period", originally published in 1776. This text was a historical survey and an attempt to rationalize elements in music systematically over time.
As the economy and the middle class expanded, there was an increasing number of amateur musicians. One manifestation of this involved women, who became more involved with music on a social level. Women were already engaged in professional roles as singers, and increased their presence in the amateur performers' scene, especially with keyboard music.
The desire to explore, record and systematize knowledge had a meaningful impact on music publications. Jean-Jacques Rousseau's "Dictionnaire de musique" (published 1767 in Geneva and 1768 in Paris) was a leading text in the late 18th century. This widely available dictionary gave short definitions of words like genius and taste, and was clearly influenced by the Enlightenment movement. Additionally, music publishers began to cater to amateur musicians, putting out music that they could understand and play. The majority of the works that were published were for keyboard, voice and keyboard, and chamber ensemble.
After these initial genres were popularized, from the mid-century on, amateur groups sang choral music, which then became a new trend for publishers to capitalize on. The increasing study of the fine arts, as well as access to amateur-friendly published works, led to more people becoming interested in reading and discussing music. Music magazines, reviews, and critical works which suited amateurs as well as connoisseurs began to surface.
Although the ideals of the Enlightenment were rejected in postmodernism, they held fast in modernism and have extended well beyond the 18th century even to the present. Recently, musicologists have shown renewed interest in the ideas and consequences of the Enlightenment. For example, Rose Rosengard Subotnik's "Deconstructive Variations" (subtitled "Music and Reason in Western Society") compares Mozart's "Die Zauberflöte" (1791) using the Enlightenment and Romantic perspectives, and concludes that the work is "an ideal musical representation of the Enlightenment".
Separation of church and state.
According to Jonathan Israel, this period saw the shaping of the "Radical Enlightenment", which promoted the concept of separating church and state. A concept that is often credited to the writings of English philosopher John Locke (1632–1704). According to his principle of the social contract, Locke argued that the government lacked authority in the realm of individual conscience, as this was something rational people could not cede to the government for it or others to control. For Locke, this created a natural right in the liberty of conscience, which he argued must therefore remain protected from any government authority.
These views on religious tolerance and the importance of individual conscience, along with his social contract, became particularly influential in the American colonies and the drafting of the United States Constitution. In which Thomas Jefferson called for a wall of separation between church and state at the federal level. He previously had supported successful efforts to disestablish the Church of England in Virginia, and authored the Virginia Statute for Religious Freedom. Thomas Jefferson's political ideals were greatly influenced by the writings of John Locke, Francis Bacon, and Isaac Newton whom he considered the three greatest men that ever lived.
Dissemination of ideas.
The "philosophes" spent a great deal of energy disseminating their ideas among educated men and women in cosmopolitan cities. They used many venues, some of them quite new.
The Republic of Letters.
The term "Republic of Letters" was coined by Pierre Bayle in 1664, in his journal "Nouvelles de la Republique des Lettres". Towards the end of the 18th century, the editor of "Histoire de la République des Lettres en France", a literary survey, described the Republic of Letters as being:
In the midst of all the governments that decide the fate of men; in the bosom of so many states, the majority of them despotic ... there exists a certain realm which holds sway only over the mind ... that we honour with the name Republic, because it preserves a measure of independence, and because it is almost its essence to be free. It is the realm of talent and of thought.
The ideal of the Republic of Letters was the sum of a number of Enlightenment ideals: an egalitarian realm governed by knowledge that could act across political boundaries and rival state power. It was a forum that supported "free public examination of questions regarding religion or legislation". Immanuel Kant considered written communication essential to his conception of the public sphere; once everyone was a part of the "reading public", then society could be said to be enlightened. The people who participated in the Republic of Letters, such as Diderot and Voltaire, are frequently known today as important Enlightenment figures. Indeed, the men who wrote Diderot's "Encyclopédie" arguably formed a microcosm of the larger "republic".
Dena Goodman has argued that women played a major role in French salons – "salonnières" to complement the male "philosophes". Discursively, she bases the Republic of Letters in polite conversation and letter writing; its principal social institution was the salon.
Robert Darnton's "The Literary Underground of the Old Regime" was the first major historical work to critique this ideal model. He argues that, by the mid-18th century, the established men of letters ("gens de lettres") had fused with the elites ("les grands") of French society. Consider the definition of "Goût" (taste) as written by Voltaire in the "Dictionnaire philosophique" (taken from Darnton): "Taste is like philosophy. It belongs to a very small number of privileged souls ... It is unknown in bourgeois families, where one is constantly occupied with the care of one's fortune". In the words of Darnton, Voltaire "thought that the Enlightenment should begin with the "grands"". The historian cites similar opinions from d'Alembert and Louis Sébastien Mercier.
Grub Street.
Darnton argues that the result of this "fusion of "gens de lettres" and "grands"" was the creation of an oppositional literary sphere, Grub Street, the domain of a "multitude of versifiers and would-be authors". These men, lured by the glory of the Republic of Letters, came to London to become authors, only to discover that their dreams of literary success were little more than chimeras. The literary market simply could not support large numbers of writers, who, in any case, were very poorly remunerated by the publishing-bookselling guilds. The writers of Grub Street, the Grub Street Hacks, were left feeling extremely bitter about the relative success of their literary cousins, the men of letters.
This bitterness and hatred found an outlet in the literature the Grub Street Hacks produced, typified by the "libelle". Written mostly in the form of pamphlets, the "libelles" "slandered the court, the Church, the aristocracy, the academies, the salons, everything elevated and respectable, including the monarchy itself". Darnton designates "Le Gazetier cuirassé" by Charles Théveneau de Morande as the prototype of the genre. Consider:
The devout wife of a certain Maréchal de France (who suffers from an imaginary lung disease), finding a husband of that species too delicate, considers it her religious duty to spare him and so condemns herself to the crude caresses of her butler, who would still be a lackey if he hadn't proven himself so robust.
or,
The public is warned that an epidemic disease is raging among the girls of the Opera, that it has begun to reach the ladies of the court, and that it has even been communicated to their lackeys. This disease elongates the face, destroys the complexion, reduces the weight, and causes horrible ravages where it becomes situated. There are ladies without teeth, others without eyebrows, and some are completely paralyzed.
It was Grub Street literature that was most read by the reading public during the Enlightenment. More importantly, Darnton argues, the Grub Street hacks inherited the "revolutionary spirit" once displayed by the "philosophes", and paved the way for the Revolution by desacralizing figures of political, moral and religious authority in France.
The book industry.
The increased consumption of reading materials of all sorts was one of the key features of the "social" Enlightenment. Developments in the Industrial Revolution allowed consumer goods to be produced in greater quantities at lower prices, encouraging the spread of books, pamphlets, newspapers and journals – "media of the transmission of ideas and attitudes". Commercial development likewise increased the demand for information, along with rising populations and increased urbanisation. However, demand for reading material extended outside of the realm of the commercial, and outside the realm of the upper and middle classes, as evidenced by the Bibliothèque Bleue. Literacy rates are difficult to gauge, but Robert Darnton writes that, in France at least, the rates doubled over the course of the 18th century.
Reading underwent serious changes in the 18th century. In particular, Rolf Engelsing has argued for the existence of a "Reading Revolution". Until 1750, reading was done "intensively: people tended to own a small number of books and read them repeatedly, often to small audience. After 1750, people began to read "extensively", finding as many books as they could, increasingly reading them alone. This is supported by increasing literacy rates, particularly among women.
Of course, the vast majority of the reading public could not afford to own a private library. And while most of the state-run "universal libraries" set up in the 17th and 18th centuries were open to the public, they were not the only sources of reading material.
On one end of the spectrum was the "Bibliothèque Bleue", a collection of cheaply produced books published in Troyes, France. Intended for a largely rural and semi-literate audience these books included almanacs, retellings of medieval romances and condensed versions of popular novels, among other things. While historians, such as Roger Chartier and Robert Darnton, have argued against the Enlightenment's penetration into the lower classes, the Bibliothèque Bleue, at the very least, represents a desire to participate in Enlightenment sociability, whether or not this was actually achieved.
Moving up the classes, a variety of institutions offered readers access to material without needing to buy anything. Libraries that lent out their material for a small price started to appear, and occasionally bookstores would offer a small lending library to their patrons. Coffee houses commonly offered books, journals and sometimes even popular novels to their customers. "The Tatler" and "The Spectator", two influential periodicals sold from 1709 to 1714, were closely associated with coffee house culture in London, being both read and produced in various establishments in the city. Indeed, this is an example of the triple or even quadruple function of the coffee house: reading material was often obtained, read, discussed and even produced on the premises.
As Darnton describes in "The Literary Underground of the Old Regime", it is extremely difficult to determine what people actually read during the Enlightenment. For example, examining the catalogs of private libraries not only gives an image skewed in favor of the classes wealthy enough to afford libraries, it also ignores censured works unlikely to be publicly acknowledged. For this reason, Darnton argues that a study of publishing would be much more fruitful for discerning reading habits.
All across continental Europe, but in France especially, booksellers and publishers had to negotiate censorship laws of varying strictness. The "Encyclopédie", for example, narrowly escaped seizure and had to be saved by Malesherbes, the man in charge of the French censure. Indeed, many publishing companies were conveniently located outside of France so as to avoid overzealous French censors. They would smuggle their merchandise – both pirated copies and censured works – across the border, where it would then be transported to clandestine booksellers or small-time peddlers.
Darnton provides a detailed record of one clandestine bookseller's (one de Mauvelain) business in the town of Troyes. At the time, the town's population was 22,000. It had one masonic lodge and an "important" library, even though the literacy rate seems to have been less than 50 percent. Mauvelain's records give us a good representation of what literate Frenchmen might have truly read, since the clandestine nature of his business provided a less restrictive product choice. The most popular category of books was political (319 copies ordered).
This included five copies of D'Holbach's "Système social", but around 300 libels and pamphlets. Readers were far more interested in sensationalist stories about criminals and political corruption than they were in political theory itself. The second most popular category, "general works" (those books "that did not have a dominant motif and that contained something to offend almost everyone in authority") likewise betrayed the high demand for generally low-brow subversive literature. These works, however, like the vast majority of work produced by Darnton's "grub street hacks", never became part of literary canon, and are largely forgotten today as a result.
Nevertheless, the Enlightenment was not the exclusive domain of illegal literature, as evidenced by the healthy, and mostly legal, publishing industry that existed throughout Europe. "Mostly legal" because even established publishers and book sellers occasionally ran afoul of the law. The Encyclopédie, for example, condemned not only by the King but also by Clement XII, nevertheless found its way into print with the help of the aforementioned Malesherbes and creative use of French censorship law.
But many works were sold without running into any legal trouble at all. Borrowing records from libraries in England, Germany and North America indicate that more than 70 percent of books borrowed were novels; that less than 1 percent of the books were of a religious nature supports a general trend of declining religiosity.
Natural history.
A genre that greatly rose in importance was that of scientific literature. Natural history in particular became increasingly popular among the upper classes. Works of natural history include René-Antoine Ferchault de Réaumur's "Histoire naturelle des insectes" and Jacques Gautier d'Agoty's "La Myologie complète, ou description de tous les muscles du corps humain" (1746). However, as François-Alexandre Aubert de La Chesnaye des Bois's "Dictionnaire de la Noblesse" (1770) indicates, natural history was very often a political affair. As E. C. Spary writes, the classifications used by naturalists "slipped between the natural world and the social ... to establish not only the expertise of the naturalists over the natural, but also the dominance of the natural over the social". From this basis, naturalists could then develop their own social ideals based on their scientific works.
The target audience of natural history was French polite society, evidenced more by the specific discourse of the genre than by the generally high prices of its works. Naturalists catered to polite society's desire for erudition – many texts had an explicit instructive purpose. But the idea of taste ("le goût") was the real social indicator: to truly be able to categorize nature, one had to have the proper taste, an ability of discretion shared by all members of polite society. In this way natural history spread many of the scientific developments of the time, but also provided a new source of legitimacy for the dominant class.
Outside ancien régime France, natural history was an important part of medicine and industry, encompassing the fields of botany, zoology, meteorology, hydrology and mineralogy. Students in Enlightenment universities and academies were taught these subjects to prepare them for careers as diverse as medicine and theology. As shown by M D Eddy, natural history in this context was a very middle class pursuit and operated as a fertile trading zone for the interdisciplinary exchange of diverse scientific ideas.
Scientific and literary journals.
The many scientific and literary journals (predominantly composed of book reviews) that were published during this time are also evidence of the intellectual side of the Enlightenment. In fact, Jonathan Israel argues that the learned journals, from the 1680s onwards, influenced European intellectual culture to a greater degree than any other "cultural innovation".
The first journal appeared in 1665– the Parisian "Journal des Sçavans" – but it was not until 1682 that periodicals began to be more widely produced. French and Latin were the dominant languages of publication, but there was also a steady demand for material in German and Dutch. There was generally low demand for English publications on the Continent, which was echoed by England's similar lack of desire for French works. Languages commanding less of an international market – such as Danish, Spanish and Portuguese – found journal success more difficult, and more often than not, a more international language was used instead. Although German did have an international quality to it, it was French that slowly took over Latin's status as the "lingua franca" of learned circles. This in turn gave precedence to the publishing industry in Holland, where the vast majority of these French language periodicals were produced.
Israel divides the journals' intellectual importance into four elements. First was their role in shifting the attention of the "cultivated public" away from "established authorities" to "what was new, innovative, or challenging." Secondly, they did much to promote the "'enlightened' ideals of toleration and intellectual objectivity." Thirdly, the journals were an implicit critique of existing notions of universal truth monopolized by monarchies, parliaments, and religious authorities. The journals suggested a new source of knowledge – through science and reason – that undermined these sources of authority. And finally, they advanced Christian enlightenment that upheld "the legitimacy of God-ordained authority"—the Bible—in which there had to be agreement between the biblical and natural theories.
Schools and universities.
Most work on the Enlightenment tends to emphasise what intellectuals wrote about what education should be and not about what education actually was during the seventeenth and eighteenth centuries. Leading educational theorists like England's John Locke and Switzerland's Jean Jacques Rousseau both emphasised the importance of shaping young minds early. By the late Enlightenment there was a rising demand for a more universal approach to education, particularly after the American and French Revolutions.
Enlightenment children were taught to memorise facts through oral and graphic methods that originated during the Renaissance. The predominant educational psychology from the 1750s onward, especially in northern European countries was associationism, the notion that the mind associates or dissociates ideas through repeated routines. In addition to being conducive to Enlightenment ideologies of liberty, self-determination and personal responsibility, it offered a practical theory of the mind that allowed teachers to transform longstanding forms of print and manuscript culture into effective graphic tools of learning for the lower and middle orders of society.
Many of the leading universities associated Enlightenment progressive principles were located in northern Europe, with the most renowned being the universities of Leiden, Göttingen, Halle, Montpellier, Uppsala and Edinburgh. These universities, especially Edinburgh, produced professors whose ideas had a significant impact on Britain's North American colonies and, later, the American Republic. Within the natural sciences Edinburgh's medical also led the way in chemistry, anatomy and pharmacology.
However, in general the universities and schools of France and most of Europe were bastions of traditionalism and were not hospitable to the Enlightenment. In France the major exception was the medical university at Montpellier.
Learned academies.
The history of Academies in France during the Enlightenment begins with the Academy of Science, founded in 1635 in Paris. It was closely tied to the French state, acting as an extension of a government seriously lacking in scientists. It helped promote and organize new disciplines, and it trained new scientists. It also contributed to the enhancement of scientists' social status, and considered them to be the "most useful of all citizens". Academies demonstrate the rising interest in science along with its increasing secularization, as evidenced by the small number of clerics who were members (13 percent).
In the first flush of scientific confidence, the thinkers of the Enlightenment tried to carry over into every human intellectual endeavour the search for first principles which, in Newton's physics, had been attended with such success. This search brought with it a sceptical attitude towards authority, rejecting everything that had no secure foundation in experience. In history, morals, metaphysics and literature the Enlightenment attitude briefly prevailed, giving rise to the phenomenal ambitions of the French encyclopaedists, and to their materialist, almost clockwork, vision of the universe. It produced the political theories which motivated the French and American revolutions, and the systematic explorations in chemistry and biology that were to find fruition in nineteenth-century evolutionism. It also brought about the technical achievements which precipitated modern industrialism, and while thus preparing the way for the miseries of revolution and factory labour, it infected the minds of the educated classes with a serenity of outlook, and a trust in human capacities, that weathered the assaults of Hume's scepticism, of Vice's anti-rationalism, of the growing introversion and doom-laden mysticism of the romantics. This was the Augustan age of English poetry, the age of Johnson and Goldsmith, of Voltaire, Diderot and Rousseau, of Lessing and Winckelmann. From the point of view of the historian it is perhaps the richest and most exciting of all intellectual eras, not because of the content, but because of the influence, of the ideas that were current in it."
”
"A Short History of Modern Philosophy"
The presence of the French academies in the public sphere cannot be attributed to their membership; although the majority of their members were bourgeois, the exclusive institution was only open to elite Parisian scholars. They did perceive themselves to be "interpreters of the sciences for the people". Indeed, it was with this in mind that academians took it upon themselves to disprove the popular pseudo-science of mesmerism.
However, the strongest case for the French Academies' being part of the public sphere comes from the concours académiques (roughly translated as 'academic contests') they sponsored throughout France. As Jeremy L. Caradonna argues in a recent article in the "Annales", "Prendre part au siècle des Lumières: Le concours académique et la culture intellectuelle au XVIIIe siècle", these academic contests were perhaps the most public of any institution during the Enlightenment.
"L'Académie française" revived a practice dating back to the Middle Ages when it revived public contests in the mid-17th century. The subject matter was generally religious and/or monarchical, and featured essays, poetry, and painting. By roughly 1725, however, this subject matter had radically expanded and diversified, including "royal propaganda, philosophical battles, and critical ruminations on the social and political institutions of the Old Regime." Controversial topics were not always avoided: Caradonna cites as examples the theories of Newton and Descartes, the slave trade, women's education, and justice in France.
More importantly, the contests were open to all, and the enforced anonymity of each submission guaranteed that neither gender nor social rank would determine the judging. Indeed, although the "vast majority" of participants belonged to the wealthier strata of society ("the liberal arts, the clergy, the judiciary, and the medical profession"), there were some cases of the popular classes submitting essays, and even winning.
Similarly, a significant number of women participated – and won – the competitions. Of a total of 2300 prize competitions offered in France, women won 49 – perhaps a small number by modern standards, but very significant in an age in which most women did not have any academic training. Indeed, the majority of the winning entries were for poetry competitions, a genre commonly stressed in women's education.
In England, the Royal Society of London also played a significant role in the public sphere and the spread of Enlightenment ideas. It was given a royal charter in 1662 by the King of England and was founded by a group of independent Scientists. In particular, the Society played a large role in spreading Robert Boyle's experimental philosophy around Europe, and acted as a clearinghouse for intellectual correspondence and exchange. As Steven Shapin and Simon Schaffer have argued, Robert Boyle was "a founder of the experimental world in which scientists now live and operate". Boyle's method based knowledge on experimentation, which had to be witnessed to provide proper empirical legitimacy. This is where the Royal Society came into play: witnessing had to be a "collective act", and the Royal Society's assembly rooms were ideal locations for relatively public demonstrations.
However, not just any witness was considered to be credible; "Oxford professors were accounted more reliable witnesses than Oxfordshire peasants." Two factors were taken into account: a witness's knowledge in the area; and a witness's "moral constitution". In other words, only civil society were considered for Boyle's public.
Coffeehouses.
Coffeehouses were especially important to the spread of knowledge during the Enlightenment because they created a unique environment in which people from many different walks of life gathered and shared ideas. Coffeehouse culture was frequently criticized by nobles who feared and abhorred the possibility of an environment in which class and its accompanying titles and privileges were disregarded. Such an environment was especially intimidating to monarchs who derived much of their power from the disparity between classes of people. If classes were to join together under the influence of Enlightenment thinking, they might recognize the all-encompassing oppression and abuses of their monarchs and, because of their size, might be able to carry out successful revolts. Monarchs also resented the idea of their subjects convening as one to discuss political matters—especially those concerning foreign affairs—for rulers thought political affairs to be their business only, a result of their supposed divine right to rule.
The first English coffeehouse opened in Oxford in 1650. Historian Brian Cowan argues that Oxford coffeehouses developed into "penny universities", offering a locus of learning that was less formal than structured institutions. These penny universities occupied a significant position in Oxford academic life, as they were frequented by those consequently referred to as the "virtuosi", who conducted their research on some of the resulting premises. According to Cowan, "the coffeehouse was a place for like-minded scholars to congregate, to read, as well as learn from and to debate with each other, but was emphatically not a university institution, and the discourse there was of a far different order than any university tutorial."
Although many coffeehouse patrons were scholars, a great deal were not. Coffeehouse culture attracted a diverse set of people including not only the educated wealthy but also more ignorant members of the bourgeoisie and even the lower class. While it may seem positive that patrons, being doctors, lawyers, merchants, etc. represented almost all classes, the coffeeshop environment sparked fear in those who sought to preserve class distinction. According to historian Lawrence E. Klein, one of the most popular critiques of the coffeehouse claimed that it "allowed promiscuous association among people from different rungs of the social ladder, from the artisan to the aristocrat" and was therefore compared to Noah's Ark, receiving all types of animals, clean or unclean.
This unique culture served as a catalyst for journalism when Joseph Addison and Richard Steele Steele recognized its potential as an audience. Together, Steele and Addison published "The Spectator", a daily publication which aimed, through fictional narrator Mr. Spectator, both to entertain and to provoke discussion regarding serious philosophical matters. Steele alone published "The Tatler", a British literary and society journal that discussed, in the first person, news and gossip overheard in popular coffeehouses.
Francesco Procopio dei Coltelli – François Procope – established the first café in Paris, the Café Procope, in 1686; by the 1720s there were around 400 cafés in the city. The Café Procope in particular became a center of Enlightenment, welcoming such celebrities as Voltaire and Rousseau. The Café Procope was where Diderot and D'Alembert decided to create the "Encyclopédie". Robert Darnton in particular has studied Parisian café conversation in great detail. He describes how the cafés were one of the various "nerve centers" for "bruits publics", public noise or rumour. These "bruits" were allegedly a much better source of information than were the actual newspapers available at the time.
Moreover, coffeehouses represent a turning point in history during which people discovered that they could have enjoyable social lives within their communities. Coffeeshops became homes away from home for many who sought, for the first time, to engage in discourse with their neighbors and discuss intriguing and thought-provoking matters, especially those regarding philosophy to politics. Coffeehouses were essential to the Enlightenment, for they were centers of free-thinking and self-discovery.
Debating societies.
The Debating Societies that rapidly came into existence in 1780 London present an almost perfect example of the public sphere during the Enlightenment. Donna T Andrew provides four separate origins:
In any event, popular debating societies began, in the late 1770s, to move into more "genteel", or respectable rooms, a change which helped establish a new standard of sociability: "order, decency, and liberality", in the words of the Religious Society of Old Portugal Street. Respectability was also encouraged by the higher admissions prices (ranging from 6d. to 3s.), which also contributed to the upkeep of the newer establishments. The backdrop to these developments was what Andrew calls "an explosion of interest in the theory and practice of public elocution". The debating societies were commercial enterprises that responded to this demand, sometimes very successfully. Indeed, some societies welcomed from 800 to 1200 spectators a night.
These societies discussed an extremely wide range of topics. One broad area was women: societies debated over "male and female qualities", courtship, marriage, and the role of women in the public sphere. Societies also discussed political issues, varying from recent events to "the nature and limits of political authority", and the nature of suffrage. Debates on religion rounded out the subject matter. It is important to note, however, that the critical subject matter of these debates did not necessarily translate into opposition to the government. In other words, the results of the debate quite frequently upheld the status quo.
From a historical standpoint, one of the most important features of the debating society was their openness to the public; women attended and even participated in almost every debating society, which were likewise open to all classes providing they could pay the entrance fee. Once inside, spectators were able to participate in a largely egalitarian form of sociability that helped spread "Enlightening ideas".
Masonic lodges.
Historians have long debated the extent to which the secret network of Freemasonry was a main factor in the Enlightenment. Historians agree that the famous leaders of the Enlightenment included Freemasons such as Diderot, Montesquieu, Voltaire, Pope, Horace Walpole, Sir Robert Walpole, Mozart, Goethe, Frederick the Great, Benjamin Franklin, and George Washington. In long-term historical perspective, historian Norman Davies has argued that Freemasonry was a powerful force on behalf of Liberalism in Europe, from about 1700 to the twentieth century. It expanded rapidly during the Age of Enlightenment, reaching practically every country in Europe. It was especially attractive to powerful aristocrats and politicians as well as intellectuals, artists and political activists.
During the Age of Enlightenment, American historian Margaret Jacob argues, Freemasons comprised an international network of like-minded men, often meeting in secret in ritualistic programs at their lodges. they promoted the ideals of the Enlightenment, and helped diffuse these values across Britain and France and other places. Freemasonry as a systematic creed with its own myths, values and set of rituals originated in Scotand around 1600 and spread first to England and then across the Continent in the eighteenth-century. They fostered new codes of conduct – including a communal understanding of liberty and equality inherited from guild sociability – "liberty, fraternity, and equality" Scottish soldiers and Jacobite Scots brought to the Continent ideals of fraternity which reflected not the local system of Scottish customs but the institutions and ideals originating in the English Revolution against royal absolutism. Freemasonry was particularly prevalent in France – by 1789, there were perhaps as many as 100,000 French Masons, making Freemasonry the most popular of all Enlightenment associations. The Freemasons displayed a passion for secrecy and created new degrees and ceremonies. Similar societies, partially imitating Freemasonry, emerged in France, Germany, Sweden and Russia. One example was the "Illuminati" founded in Bavaria in 1776, which was copied after the Freemasons but was never part of the movement. The Illuminati was an overtly political group, which most Masonic lodges decidedly were not.
Jacob further argues that Masonic lodges created a private model for public affairs. They "reconstituted the polity and established a constitutional form of self-government, complete with constitutions and laws, elections and representatives”. In other words, the micro-society set up within the lodges constituted a normative model for society as a whole. This was especially true on the Continent: when the first lodges began to appear in the 1730s, their embodiment of British values was often seen as threatening by state authorities. For example, the Parisian lodge that met in the mid 1720s was composed of English Jacobite exiles. Furthermore, freemasons all across Europe explicitly linked themselveto the Enlightenment as a whole. In French lodges, for example, the line “As the means to be enlightened I search for the enlightened” was a part of their initiation rites. British lodges assigned themselves the duty to “initiate the unenlightened”. This did not necessarily link lodges to the irreligious, but neither did this exclude them from the occasional heresy. In fact, many lodges praised the Grand Architect, the masonic terminology for the deistic divine being who created a scientifically ordered universe.
German historian Reinhart Koselleck claimed that "On the Continent there were two social structures that left a decisive imprint on the Age of Enlightenment: the Republic of Letters and the Masonic lodges.". Scottish professor Thomas Munck argues that "although the Masons did promote international and cross-social contacts which were essentially non-religious and broadly in agreement with enlightened values, they can hardly be described as a major radical or reformist network in their own right." Many of the Masons values seemed to greatly appeal to Enlightenment values and thinkers. Diderot discusses the link between Freemason ideals and the enlightenment in D'Alembert's Dream, exploring masonry as a way of spreading enlightenment beliefs. Historian Margaret Jacob stresses the importance of the Masons in indirectly inspiring enlightened political thought.
On the nagative side, Daniel Roche contests claims that Masonry promoted egalitarianism. He argues that “the real equality of the lodges was elitist”, only attracting men of similar social backgrounds. The presence of noble women in the French “lodges of adoption” that formed in the 1780s was largely due to the close ties shared between these lodges and aristocratic society.
Masons and the French and American revolutions.
The great enemy of Freemasonry was the Roman Catholic Church, so that in countries with a large Catholic element, such as France, Italy, Spain, and Mexico, much of the ferocity of the political battles involve the confrontation between what Davies calls the reactionary Church and enlightened Freemasonry.
In terms of their impact on revolutionary politics historian Robert Roswell Palmer concluded that even in France, Masons were politically "innocuous if not ridiculous" and did not act as a group. American historians, while noting that Benjamin Franklin and George Washington were indeed active Masons, have downplayed the importance of Freemasonry in causing the American Revolution because the Masonic order was non-political and included both Patriots and their enemy the Loyalists.

</doc>
<doc id="30761" url="http://en.wikipedia.org/wiki?curid=30761" title="The Hunt for Red October">
The Hunt for Red October

The Hunt for Red October was Tom Clancy's 1984 debut novel. The story follows a CIA analyst leading a covert group of US Naval officers to steal a cutting-edge Soviet nuclear submarine from 26 defecting Soviet officers, and the intertwined adventures of Soviet submarine captain Marko Aleksandrovich Ramius and Jack Ryan, former Marine turned CIA analyst.
The novel was originally published by the U.S. Naval Institute Press—one of the first fictional works it ever published, and still its most successful.
Plot.
Marko Alexandrovich Ramius, a Lithuanian submarine commander in the Soviet Navy and son of a prominent Soviet politician, intends to defect to the United States with his officers on board the experimental nuclear submarine "Red October", a "Typhoon"-class vessel equipped with a revolutionary stealth propulsion system that makes audio detection by sonar extremely difficult. The result is a strategic weapon platform that is capable of sneaking its way into American waters and launching nuclear missiles with little or no warning.
The strategic value of "Red October" was not lost upon Ramius, but other factors have spurred his decision to defect. His wife, Natalia, died at the hands of a doctor who was incompetent and intoxicated; however, the doctor escaped punishment due to his status as the son of a Politburo member. Natalia's untimely death, combined with Ramius' long-standing dissatisfaction with the callousness of Soviet rule and his fear of "Red October"'s destabilizing effect on world affairs, exhausts his tolerance for the failings of the Soviet system.
As the ship leaves the shipyard at Polyarny, Ramius kills Ivan Putin, his political officer, to ensure that Putin will not interfere with the defection. Before sailing, Ramius had sent a letter to Admiral Yuri Padorin, Natalia's uncle, brazenly stating his intention to defect. The Soviet Northern Fleet sails out to sink "Red October" under the pretext of a search and rescue mission. Meanwhile, Ryan, a high-level CIA analyst, flies from London to Langley, Virginia, to deliver MI6's photographs of "Red October" to the Deputy Director of Intelligence. Ryan consults a friend at the U.S. Naval Academy, ex-submariner Skip Tyler, and finds out that "Red October"'s new construction variations house its stealth drive.
"Red October" passes near USS "Dallas", a Los Angeles class submarine under the command of Cdr. Bart Mancuso, which is patrolling the entrance of a route used by Soviet submarines in the Reykjanes Ridge off Iceland. "Dallas" hears the sound of the stealth drive but does not identify it as a submarine. Putting information about Ramius letter together with the subsequent launch of the entire Northern Fleet, Ryan deduces Ramius' plans. The U.S. military reluctantly agrees, while planning for contingencies in case the Soviet Fleet has intentions other than those stated. As tensions rise between the U.S. and Soviet fleets, the crew of "Dallas" analyse sonar tapes of "Red October" and finally realize that it is the sound of a new propulsion system. Ryan must contact Ramius to prevent the loss of the submarine and her decisive technology. After it is revealed that Ramius has informed Moscow of his plan for him and his officers to defect, Ryan becomes responsible for shepherding Ramius and his vessel away from the pursuing Soviet fleet, and meets with an old Royal Navy acquaintance, Admiral White, commanding a task force from the aircraft carrier "Invincible".
In order to convince the Soviets that "Red October" has been destroyed, the U.S. Navy rescues her crew after Ramius fakes a reactor meltdown. Ramius and his officers heroically stay behind, claiming they are about to scuttle the submarine to prevent it getting into the hands of the Americans. A decommissioned U.S. ballistic missile submarine, the USS "Ethan Allen", is blown up underwater as a deception ploy. A depth gauge taken from the main instrument panel of "Red October" (with the appropriate serial number) is made to appear as if it was salvaged from the wreckage. Meanwhile, Ryan, Captain Mancuso and some of his crew, and Owen Williams (a Russian-speaking British officer from the "Invincible") board the "Red October" and meet Ramius face-to-face.
The deception efforts succeed in convincing Soviet observers that "Red October" has been lost. However, GRU intelligence officer Igor Loginov, masquerading as "Red October"'s cook, is aware of what Ramius is doing and attempts to ignite a missile rocket motor inside a launch tube so as to destroy "Red October". Loginov opens fire with his weapon, killing Captain Lieutenant Kamarov (the ship's navigator) and seriously wounding Ramius and Williams. Ryan attempts to persuade the fiercely patriotic Loginov to surrender rather than die in the explosion, but Loginov refuses. Ryan manages to kill Loginov in the submarine's missile compartment. Ramius orders the missile jettisoned in case Loginov had managed to arm it, an action which adds to the deception as the Soviets regard the missile as further proof of the destruction of "Red October".
Captain Viktor Tupolev, a former student of Ramius and commander of the Soviet "Alfa"-class attack submarine "V. K. Konovalov", has been trailing what he initially believes is an "Ohio"-class vessel. Based on acoustical signature information, Tupolev realizes that it is "Red October", and proceeds to pursue and engage it. The two U.S. submarines escorting "Red October" are unable to fire due to rules of engagement, and "Red October" is damaged by a torpedo from the Alfa. After a tense standoff, "Red October" rams "Konovalov" broadside and sinks it.
The Americans escort "Red October" safely into the eight-ten dry dock in Norfolk, Virginia, where Ramius and his crew are taken to a CIA safehouse to begin their Americanization. Ryan is commended by his superiors and flies back to his posting in London.
Influence on later Clancy books.
"The Hunt for Red October" was the start of a loosely connected series by Tom Clancy which shared a rough continuity. Many of the characters in the novel, particularly Jack Ryan, went on to be the central characters of many of Clancy's later novels. The ultimate fate of "Red October" is explained in the Clancy novel "The Cardinal of the Kremlin", where it is revealed that the vessel was reverse engineered and stripped of all technology. "Red October" was then sunk in a deep ocean trench off Puerto Rico to avoid discovery. Both Ryan and Ramius are on hand to see the submarine off for the last time, and Ramius sentimentally comments, "He was a good ship."
Adaptations.
Film.
The novel was made into a commercially-successful movie in 1990, starring:
There were several differences between the novel and the film, including "Red October" traveling up the Penobscot River in Maine to dry dock, and the prominence of the Royal Navy, including light aircraft carrier "Invincible". The order of many events also has been changed. In the film version, the "Caterpillar Drive" is described as a magnetohydrodynamic system, essentially, "a jet engine for the water".
Games.
The novel also served as the basis for several computer and video games, as well as some board games.
"The Hunt for Red October" wargame, published in 1988 by TSR, Inc. became one of the bestselling wargames of all time.
Reception.
"The Hunt for Red October" sold very well and launched Clancy's successful career as a novelist. President Ronald Reagan helped to fuel the success of "The Hunt for Red October" when he announced that he enjoyed the book at a televised press conference, calling it "unputdown-able" and a "perfect yarn."
Publication history.
The hardback edition of "The Hunt for Red October" is the first novel published by the Naval Institute Press. Clancy had not been able to place the novel with any traditional publishers, but had a good relationship with the Press from writing articles in their "Proceedings of the Naval Institute." To his surprise the Press accepted the manuscript and sent a small advance. After the book received unexpected praise from President Reagan, the book became a bestseller. Clancy's later books were published by Penguin Putnam.
The paperback edition was the first in a string of successful publications of technothrillers by Berkley Books.
In 1988 it was published in French as "Octobre Rouge", translated by Marianne Véron and with the collaboration of Jean Sabbagh.

</doc>
<doc id="30762" url="http://en.wikipedia.org/wiki?curid=30762" title="The Cardinal of the Kremlin">
The Cardinal of the Kremlin

The Cardinal of the Kremlin is a novel by Tom Clancy, featuring his character Jack Ryan. It is a sequel to "The Hunt for Red October", based on the development of the Strategic Defense Initiative and its Soviet equivalent, covering themes including intelligence gathering and counterintelligence, political intrigue, and guerrilla warfare in Afghanistan.
The SDI systems discussed in the book are based on real-world systems. In the book, satellite photos are shown of the Dushanbe Complex called "Bright Star" in the novel. These images are of an actual then-Soviet mountaintop site of then disputed function called Okno. The Soviet government claimed that the site was an imaging station for optically tracking space objects, while Western experts believed it was a site built to employ directed-energy weapons against space based targets. The site is referenced in the Federation of American Scientist's Space Policy Project Special Weapons Monitor section.
Plot.
CIA analyst Jack Ryan attends a diplomatic conference in Moscow as part of an American delegation to the Soviet Union. He learns that the CIA's most highly placed agent, codenamed "CARDINAL", is none other than Colonel Mikhail Semyonovich Filitov, the personal aide to the Soviet Minister of Defense and a national war hero. Filitov was recruited by GRU colonel and British agent Oleg Penkovsky, and offered his services to the CIA after the deaths of his wife and two sons; the latter two were killed during their service in the Red Army. As a result, Filitov has been passing political, technical, and military intelligence to the CIA for the past thirty years.
The U.S. discovers through "National Technical Means" that the Soviets are working on an ABM defense system codenamed "Bright Star", based at Dushanbe in Tajikistan. Emilio Ortiz, a CIA liaison, is sent to aid Mujaheddin rebels in the region. One rebel leader, known as "the Archer" due to his expertise in using surface-to-air missiles to bring down Soviet ground support aircraft, is questioned after unwittingly witnessing a test of the Soviets' ABM system. The Archer determines that the Soviet installation is a threat to him and his people, and tasks his group with attacking and pillaging the facility. In the end, the guerrillas destroy a large amount of Soviet equipment. However, the rebels suffer horrendous losses, including the death of the Archer.
Ryan travels to New Mexico to meet with the country's top SDI researcher, U.S. Army Major Alan Gregory, whom he brings to Washington, D.C., to brief the president. Gregory lives with another scientist, Candi Long, who is working on adaptive optics for use in the development of laser weaponry. A lesbian KGB agent, Bea Taussig—who has unluckily fallen in love with Long—describes Gregory and his work to her KGB handler, Tanya Bisyarina. The KGB launches a plan to kidnap and debrief Gregory.
Filitov is arrested after his work for the CIA is discovered. However, Ryan concocts a plan to both secure the return of Filitov and arrange the defection of the sitting KGB chairman, Nikolay Borissovich Gerasimov. Gerasimov is angling to take over as General Secretary in the wake of Filitov's arrest, something Ryan is determined to prevent because of his unyielding anti-American ideology. Ryan schemes to go public with the prior capture of the Soviet submarine "Red October", banking on the political instability of the Soviet Politburo. He plans for Filitov and Gerasimov to be exfiltrated on the American delegation's aircraft, while Gerasimov's family is extracted from Estonia by John Clark onto the submarine USS "Dallas". He reveals this in a private meeting with Gerasimov, forcing the KGB chairman's hand. 
On Gerasimov's orders, three KGB officers kidnap Gregory and hold him in a shabby desert safe house, planning to send him to Moscow for debriefing as counter-leverage should he refuse to defect and Ryan reveal the intelligence windfall, along with the nuclear missiles the U.S. received when the "Red October" crew defected. Their plans are foiled when the FBI sends in the Hostage Rescue Team to retrieve Gregory and return him to Long. Among those killed is Bisyarina. Ryan informs Gerasimov of the failed operation, forcing the enraged chairman to accept Ryan's defection offer. Taussig is arrested when she attempts to seduce Long after Gregory is reported kidnapped, though she'd originally only wanted to comfort her.
The flipped Gerasimov fetches Filitov from his confinement. The three make their way to Sheremetyevo Airport, awaiting the departure of the American delegation. Unfortunately, two KGB officers, Klementi Vladimirovich Vatutin, the KGB officer who had been interrogating Filitov and finally extracted a confession from him, and Sergey Nikolayevch Golovko, who would become an old, somewhat friendly acquaintance of Ryan's over the years, become aware of their planned departure. As Gerasimov and Filitov escape, Ryan allows himself to be captured by Golovko, banking on his diplomatic status to protect him from harm. Golovko then escorts Ryan to the private dacha of General Secretary Narmonov, where the two men discuss the CIA's interest in his political position and the CIA's interference in their internal security.
Ryan returns to the United States, where he and several others attend the funeral of Filitov, who had died of heart disease in the months following his CIA debriefing period. Filitov is buried at Camp David, within twenty miles of the Antietam battlefield. A Soviet military attaché attending the funeral questions why Filitov would be buried so close to American soldiers. Ryan, always working to keep the peace, explains to him, "One way or another, we all fight for what we believe in. Doesn't that give us some common ground?"
Film adaptation.
A film, based on the book, was planned. It was to involve Harrison Ford and William Shatner. It was never released and the idea was most likely scrapped.
Video game.
"The Cardinal of the Kremlin" is also the title of a 1990 video game based on the novel.

</doc>
<doc id="30763" url="http://en.wikipedia.org/wiki?curid=30763" title="Debt of Honor">
Debt of Honor

Debt of Honor (1994) is a thriller novel by Tom Clancy. It is a continuation of the series featuring his character Jack Ryan. In this installment, Ryan has become the National Security Advisor when the Japanese government (controlled by a group of corporate tycoons known as the "Zaibatsu") goes to war with the United States. One of the sub-plots in this novel (on occupying the Siberian "Northern Resource Area") would later form part of the main plot of Clancy's later novel "The Bear and the Dragon".
Plot summary.
In New York City, Japanese industrialist Raizo Yamata purchases a controlling interest in an American mutual fund group. He flies to Saipan — the site of his parents' suicide during the American invasion of the island at the close of World War II — to buy a large tract of land.
Meanwhile, in eastern Tennessee, a car accident involving two Japanese vehicles leads to the deaths of six people. Revelations about manufacturing and shipping errors that led to the accident stir long-standing resentment against Japan's protectionist trade policies. As trade negotiations between the United States and Japan grind to a halt, Congress passes a law enabling the U.S. to mirror the trade practices of the countries from which it imports goods. The bill is immediately used to replicate Japan's non-tariff barriers, cutting off the U.S. export markets upon which the Japanese economy depends.
Facing an economic crisis, Japan's ruling corporate cabal, led by Yamata, decides to take military action against the U.S. Along with covert support from China and India, they plot to curtail the American presence in the Pacific and re-establish the Greater East Asia Co-Prosperity Sphere. In the wake of these developments, Jack Ryan is recruited as National Security Advisor by President Roger Durling. Meanwhile, CIA officers John Clark and Domingo Chavez are sent to Japan to reactivate a former KGB spy network in order to gain intelligence.
Japan launches the first phase of its assault, sending Self-Defense Force units to occupy the Mariana Islands, specifically Saipan and Guam. The invasion, conducted with commercial airliners, is virtually bloodless. Meanwhile, during a joint military exercise, Japanese ships "accidentally" launch torpedoes at the U.S. Pacific Fleet, destroying two submarines and crippling two aircraft carriers, the "Enterprise" and the "John C. Stennis". This drastically reduces the U.S. capability to project power into the western Pacific.
An immediate retaliation is forestalled by the second phase of the Japanese offensive: an economic attack. Even as the military offensive begins, Japan engineers the collapse of the U.S. stock market by hiring a programmer who is a consultant for an exchange firm to insert a logic bomb into the system, which when triggered blocks the storage of all trade records made after noon on Friday. The Japanese also assassinate the chairman of the Federal Reserve. With a massive economic crisis and subsequent mass panic, the Japanese hope that America will be too distracted to quickly respond to Japan's military actions.
Japan immediately sues for peace, offering international talks and seemingly free elections in the Marianas to delay a U.S. response. Negotiators secretly reveal to the U.S. that Japan has obtained nuclear ballistic missile capability. The Japanese oligarchs, led by Yamata, believe that offers of negotiation and the nuclear deterrent, defended by a seemingly impregnable AWACS system, will cause the U.S. to concede Japan's advantage. With two of America's twelve carriers disabled, and the rest pinned down by a mix of maintenance and international crises elsewhere, Ryan has few resources with which to defend American interests.
Despite his typical focus on military issues, Ryan advises President Durling to deal with the economic crisis first. Ryan also realizes that Japan's deletion of trade records could be an advantage in responding to the economic threat. He engineers a "do-over", where all of the transactions that were deleted on the day of the mass deletion are ignored and all trade information is restored to its condition at noon of that day. Accompanied by a presidential address to the nation and behind-the-scenes bullying of investment banks, the plan is a success: America's stock market is restored with only minor disruption. Concurrently, a group of American investment banks start a massive economic unloading of Japanese investment products, effectively eliminating any gains made by the Zaibatsu.
Ryan eliminates Japan's AWACS system through a series of "accidents" and low-profile military attacks using widely dispersed U.S. assets, allowing B-2 bombers to destroy the silos.
In one staged accident, Clark and Chavez blind two incoming Japanese AWACS pilots with a high-intensity light and cause them to crash on landing. A fictitious technical warning of a problem with the automatic landing system was used to create the impression that the attack was an accident. They then managed to rescue Japan's moderate former prime minister from his house arrest so that he could be used in later peace talks.
The Air Force uses an attack by stealthy F-22 fighters to further damage Japan's air defenses.
An Army special operations team is airdropped into Japan to support covertly inserted Comanche helicopters. One helicopter is used to attack another AWACS plane with air-to-air missiles while several others use Hellfire missiles to kill members of Yamata's cabal.
Meanwhile, Admiral Robby Jackson liberates the Marianas with little bloodshed by using a combination of missiles and carrier air attacks to severely damage the Japanese aircraft stationed on the islands which forces the Japanese commander to surrender his troops. The damaged "John C. Stennis" been stealthily removed from Pearl Harbor while it was supposedly under repair for damage to the propellers. However, the damaged carrier had two workable shafts which gave it enough speed for air operations so it was pressed into emergency service for the attack.
Outmaneuvered and cornered by the United States military and economic response, Japan's aggressive prime minister resigns, ceding power to his rescued predecessor. Yamata is arrested, and the new Japanese government accepts America's generous offer of "status quo ante".
Throughout the book, President Durling faces another, less important political crisis: Vice-President Ed Kealty is forced to resign after being accused of drugging and raping a former member of his staff. With the crisis over, President Durling nominates Ryan as vice-president for his services during the crisis. However, an embittered Japan Air Lines pilot—driven mad by the deaths of his son and brother during the conflict—flies his Boeing 747 directly into the U.S. Capitol during a special joint session of Congress.
The president, as well as nearly the entire Congress, the Supreme Court, and many other members of the Federal Government are killed in the attack. Ryan, who had been confirmed as vice-president moments before, is exiting the Capitol Building through a tunnel and narrowly escapes the explosion. He first realizes that he is suddenly the new President of the United States when a Secret Service agent addresses him as "Mr President." He takes the oath of office and begins an uncertain term as President.
Legacy.
In the aftermath of the September 11 attacks, Tom Clancy commented on CNN about the very close similarity between the events in the novel and those attacks.

</doc>
<doc id="30765" url="http://en.wikipedia.org/wiki?curid=30765" title="Jack Ryan (character)">
Jack Ryan (character)

John Patrick "Jack" Ryan, Sr., KCVO, (Hon) is a fictional character by Tom Clancy who appears in many of his novels and their respective film adaptations. The character is born in Baltimore in 1950 and grows up there. He earns an NROTC commission in the Marines at Boston College. Medically retired following a helicopter crash, he works as an investment broker. He meets and marries Caroline "Cathy" Mueller, a medical student and later an ophthalmic surgeon, with whom he has four children. He returns to academia eventually accepting a position at the U.S. Naval Academy. Later he is recommended to the CIA, eventually spending a short period there writing a position paper as well as developing a counter-espionage mechanism. He returns to the Academy and while on a history research trip to London, he interrupts an assassination attempt on the Royal Family. After his return to the States, he eventually accepts a position with the CIA. He rises rapidly through the ranks in a variety of covert operations against the USSR, eventually becoming the Deputy Director of the Central Intelligence Agency. As DDI, he begins having political battles which eventually lead to him becoming President of the United States, serving two terms and dealing with international crises in the Pacific.
Biography.
Backstory.
Ryan had his background established in "Patriot Games" and "Red Rabbit". He was born in 1950, the son of Emmet William Ryan (1922–1974), a Baltimore Police Department homicide lieutenant, and World War II veteran. The elder Ryan had served with the U.S. Army's 101st Airborne Division at the Battle of the Bulge. His mother, Catherine Burke Ryan, (1923–1974) was a nurse. "Without Remorse" mentioned that he had a sister, who lived in Seattle.
After graduating from Loyola Blakefield prep school in Towson, Maryland, Ryan attended Boston College, graduating with a Bachelor of Arts degree in Economics (with a strong minor in history) and a commission as a Second Lieutenant in the U.S. Marine Corps (via NROTC). While waiting for the Corps to assign him, he passed the Certified Public Accountant exam.
After officer training at Marine Corps Base Quantico, he went on to serve as a platoon commander. However, his military career was cut short at the age of 23 when his platoon's helicopter, a CH-46 Sea Knight, crashed during a North Atlantic Treaty Organization (NATO) exercise over the Greek island of Crete. The crash badly injured Ryan's back. U.S. Navy surgeons, at the National Naval Medical Center in Bethesda, Maryland, inadequately repaired his back. This led to a lengthy recovery process (during which he nearly became addicted to pain medications) after which, complete with a permanent disability and wearing a back brace, he left the Marines. He passed his stockbroker's exam and took a position with Wall Street investment firm Merrill Lynch's Baltimore office.
His parents died in a plane crash at Chicago Midway International Airport, 19 months after his crash in Crete. He developed a fear of flying that persisted for years.
There are also other changes to Ryan's background in "". This version of the character joins the United States Marine Corps after the 9/11 attacks (likely graduating from its Officer Candidates School) and commissions as a Second Lieutenant. In his first tour as platoon commander in Afghanistan, Ryan's helicopter is shot down by an enemy rocket and crashes. Ryan is able to save the lives of his two marines from the wreckage while also sustaining serious injury to his spinal vertebrae. He makes a full recovery thanks to the help of his future wife, Cathy Muller, and attracts the attention of the CIA due to his unique ability to recognize unusual patterns. Ryan is recruited into the agency and subsequently completes his Ph.D. in economics at the London School of Economics. After three weeks of training at the Farm, he is assigned to work as a cover job as analyst and compliance officer for a major Wall Street firm, where he can watch for suspicious financial transactions that could indicate terrorist activity.
Civilian career.
Ryan's story starts in "Patriot Games" and continues in "Red Rabbit". While managing clients' portfolios, he began to invest his own money, banking on a tip he had received from an uncle about the workers' takeover of the Chicago and North Western Railway, making approximately $6 million off his $100,000 initial investment. He did so well that one of Merrill Lynch's senior vice presidents, Joe Muller, came to Baltimore to have dinner with him, with the objective of inviting him to the firm's New York City headquarters. Also present is Muller's daughter Caroline, nicknamed Cathy, then a senior medical student at the Johns Hopkins University School of Medicine. They immediately fall in love and get engaged. One night, while having dinner with his fiancée, Ryan throws out his back. Cathy takes him directly to Doctor Stanley Rabinowitz, professor of neurosurgery at Johns Hopkins, to be evaluated. Rabinowitz later operates on Ryan's back and cures his chronic pain in relatively short order (in a later novel the surgeon is credited as Sam Rosen, a doctor introduced in "Without Remorse".) Ryan subsequently persuades the government to terminate his disability checks. Cathy later becomes an ophthalmic surgeon at the Wilmer Eye Institute of Johns Hopkins University School of Medicine and a Professor of Surgery at Johns Hopkins.
After creating a net worth of $8 million, Ryan left the firm after four years and enrolled at Georgetown University for doctorate courses in history. He does a brief stint at the Center for Strategic and International Studies, then accepts a position at the U.S. Naval Academy as a civilian professor of history.
First CIA work.
Following a recommendation from Father Tim O'Riley, a Jesuit priest and Georgetown University professor, to a Central Intelligence Agency contact, Ryan is asked to work as a consultant for the Agency, although officially employed by MITRE Corporation. He agrees and spends several months at Langley, Virginia, where he writes a paper entitled "Agents and Agencies", in which he maintains that state-sponsored terrorism is an act of war. He also invents the canary trap, a method for exposing an information leak, which involves giving different versions of a sensitive document to each of a group of suspects and seeing which version is leaked. By ensuring that each copy of the document differs slightly in its wording, if any copy is leaked then it's possible to determine the informant's identity.
These accomplishments come to the attention of U.S. Navy Vice Admiral James Greer, the CIA's Deputy Director for Intelligence. The expertise of Ryan's report, plus the application, persuades Greer to offer him a permanent job in the CIA, but Ryan declines.
While Ryan is still teaching at the Naval Academy, he and his family (wife and daughter Sally) take a trip to London for research and vacationing. After spending the day sifting through Royal Navy archives doing research for a book on the British naval war in the Indian Ocean during World War II, Ryan walks to meet his family at a park. As he joins them, members of the Ulster Liberation Army (ULA), an ultra-violent Maoist offshoot of the Marxist Provisional Irish Republican Army, led by Kevin O'Donnell, attack a car containing the Prince of Wales and his family right in front of the Ryans. Ryan is wounded while intervening in the attack and foils their plan, killing one of the gunmen and capturing another. Ryan is knighted by Queen Elizabeth II as an honorary Knight Commander of the Royal Victorian Order, in the books some British characters call him "Sir John" but honorary knights are not permitted to use the style of "Sir".
Sean Miller, the man he captured, vows revenge on Ryan and his family (only in the movie, not the book), but since he is going to Albany Prison on the Isle of Wight, the threat seems unrealistic. Ryan returns to the U.S. and the Naval Academy. When O'Donnell and the ULA liberate Miller on his way to prison (killing both police officers and civilians in the process), the Ryans become the target of their revenge—particularly Miller's.
CIA career.
In "Patriot Games", Greer comes to Ryan and asks him to rejoin the CIA permanently as an analyst to help track down the terrorists. He declines initially, only to accept it after a failed ULA attack on the Ryans mildly wounds his pregnant wife, but severely injures his daughter. Later, while Ryan hosts the Prince and Princess of Wales at his home in Maryland, the ULA conducts another attack against him, which Ryan, the Prince, and Navy Commander Robert Jackson foil. Following the incident and arrests of the ULA members and Miller (whom Ryan nearly executes with his Browning Hi Power), Ryan is taken to the Naval Academy hospital, where he arrives just in time for the birth of Jack Ryan, Jr..
In "Red Rabbit", Ryan's first CIA assignment is to London as a member of a liaison group to the British Secret Intelligence Service. The first order of business focuses on a mission to assist the defection of a KGB communications-center officer who has discovered that KGB director Yuri Andropov had ordered Pope John Paul II's attempted assassination. Although Ryan and a small team of British agents helps the "Rabbit" and his family get to the West, they fail to prevent the attack on the Pope. Nevertheless, the Pope is only wounded and his would-be assassin captured, while the British agents execute his Bulgarian handler. "Rabbit's" defection proves to be a major coup for both the American and British intelligence communities. Ryan soon afterward suggests a non-military strategy to help hasten the USSR's collapse.
In "The Hunt for Red October", Captain First Rank Marko Ramius, the Soviet Navy's top submarine commander, takes command of the "Красный Октябрь" ("Krasny Oktyabr", or in English, "Red October"), the newest Typhoon class submarine, with which he plans to defect. Ryan recognizes this and works to welcome him to the U.S., eventually succeeding.
In "The Cardinal of the Kremlin", Ryan is reassigned to Langley. He becomes Greer's assistant with the official title of Special Assistant to the Deputy Director for Intelligence. Greer is grooming him for bigger and better positions, maybe even his own job when the veteran spy finally retires. Ryan is sent to Moscow as part of the American strategic nuclear weapons reduction negotiation team. There he meets Sergey Golovko, a rising star in the KGB hierarchy, and becomes entangled in a complex web related to both the race to develop "Star Wars" space-based defensive technology and engineer another defection, this time compromising the KGB director to save the CIA's highest informant in the USSR, Agent CARDINAL, better known as Colonel Misha Filitov. Although they initially meet as adversaries—at one time literally at gunpoint—Golovko respects him as a worthy adversary and in later books befriends him, whom he calls "Ivan Emmetovich," giving him a Russian-style patronymic based on his father's name, Emmet.
In "Clear and Present Danger", Ryan is promoted to acting DDI when Greer is hospitalized with cancer. Despite this, he isn't made aware of a highly covert and illegal CIA operation approved by corrupt National Security Advisor Admiral Cutter. This operation targets Colombian drug lords using military assets, in what is usually considered a law enforcement area. Ryan works with the Federal Bureau of Investigation to rescue a small group of American soldiers cut off in Colombia, forcing him to miss Greer's funeral. Around this time Ryan also runs afoul of Elizabeth Elliott, international affairs advisor to then presidential candidate Governor of Ohio J. Robert Fowler, and one of Cathy Ryan's former professors.
In "The Sum of All Fears", Ryan reaches his highest post at the CIA; Deputy Director of Central Intelligence. His career is jeopardized when Fowler becomes President and Elizabeth Elliott, Fowler's lover/manipulator, becomes National Security Advisor. They not only deny Ryan any credit for an innovative Middle East peace plan (basically turning Jerusalem into a Vatican-like city co-ruled by three Christian, Jewish, and Arab mayors), but also panic when Iranian and former East German terrorists detonate a nuclear bomb in Denver during the Super Bowl and nearly plunge the world into a Soviet-American nuclear war. Ryan defuses the nuclear crisis by commandeering the Washington-Moscow hot line and convincing the Soviet premier (through his friend Golovko) that the crisis is a setup. He then refuses to confirm Fowler's order to launch a nuclear missile at Qom (thus preventing the attack), where the Iranian Ayatollah lived. The crisis and Elliot scandal drives Fowler to resign (with Elliot arrested) and, on this note, Ryan retires from the CIA after he and his CIA friends fly to Riyadh and witness the execution of the terrorists, then being honored by the U.S.'s Middle Eastern allies. (The film version again departs from the printed version, by presenting a younger, unmarried Ryan, an intelligent mistress-free Fowler, a Greer-like Cabot, and the nuclear bomb is detonated in Baltimore, not Denver.)
First Ryan Administration.
In "Debt of Honor", Ryan returns to government service as the National Security Advisor, restoring honor to the job that Cutter and Elliot disgraced. It has been two and a half years since Fowler resigned and his Vice-President Roger Durling is now well into his own term. Jack and the administration must deal with a second war between the U.S. and Japan, as well as an attack on America's economic infrastructure. After a clean sweep of Japan's forces in the South Pacific, Vice President Ed Kealty is forced to resign after a sex scandal, President Durling taps him for the job. Ryan accepts the job on the condition that he'll only serve until the end of Durling's term. He sees this as a way of ending his public life. But only minutes after Congress confirms Ryan, a Japanese airline pilot deliberately crashes a 747 into the U.S. Capitol building during Congress' joint session, killing most of the people inside, decapitating the U.S. government and elevating Ryan to the Presidency.
The reluctant yet determined Ryan Administration emerges in "Executive Orders" as Ryan slowly rebuilds the government. He is faced with Kealty's political trickery, China's growing military antagonizing of Taiwan, and a deadly plague initiated by the newly formed United Islamic Republic, resulting in two major military conflicts far from American shores (but one will not take place until the next Ryan novel).
In "The Bear and the Dragon", it's established that Ryan has completed Durling's term as President and has campaigned for—and won—the next election. He retains most of his emergency Cabinet and has Robby Jackson as Vice President.
Ryan has to deal with the attempted assassination of Golovko, head of Russia's Foreign Intelligence Service (formerly the KGB). This turns out to be an attempt to sow confusion in the Russian government because of China's designs to annex Eastern Siberia, where geologists had recently discovered a large amount of oil and gold. These events lead to the inclusion of Russia into NATO and the assistance of U.S. forces in the Sino-Russian conflict. When the Chinese begin losing the war, U.S. forces target their strategic assets. A U.S. submarine sinks a Chinese ballistic missile submarine, causing China's Politburo to panic and increase the readiness of their 12 land-based ICBMs. U.S. forces don't have the ability to destroy the silos, as they could only use deep penetrating bombs, which had all been used to destroy Chinese bridges to disrupt the People's Liberation Army's (PLA) logistical support. This causes the U.S. and Russia to send a joint RAINBOW-Spetsnaz team to destroy the silos. They destroy 11 of the 12 ICBMs but one of them manages to launch. The warhead heads towards Washington, D.C.; and with Ryan taking a command initiative at an Aegis missile cruiser, the ICBM is intercepted by ABMs from the USS "Gettysburg". With the PLA's looming defeat in Siberia, which they were about to learn about via live UAV broadcasts from the CIA through the Internet, student demonstrators in Beijing raid the Politburo, causing a reformist Politburo member, Fang Gan, to take control and arrest the war's perpetrators, making peace negotiations with the U.S. and Russia, and beginning China's transition to democracy.
Ryan Doctrine.
At the end of "Executive Orders", Ryan, in the tradition of Presidents Monroe, Truman, Carter and Reagan, issues a foreign policy doctrine which largely defines his administration's international perspective. The Ryan Doctrine states that the U.S. will no longer tolerate attacks on "our territory, our possessions, or our citizens," and will hold whoever orders such attacks accountable.
This statement comes soon after the Ebola attack on the U.S. ordered by Mahmoud Haji Daryaei, the dictator of the new United Islamic Republic. Ryan announces the new doctrine on television, momentarily cutting away to show Daryaei and his UIR advisors being incinerated by laser guided bombs launched from two F-117s, on Ryan's orders. Therefore, the Ryan Doctrine supersedes the executive order put in place by President Ford, which forbids the assassination of foreign heads of state. Ryan, however, believes it's a more ethical alternative than total war, since it punishes the person responsible for the attack instead of the people he rules.
Within the books, the Ryan Doctrine is not officially invoked after Daryaei's death (although Ryan threatens to use it on the Chinese leadership in "The Bear and the Dragon", should anything happen to American citizens living in China as a consequence of the Siberian War).
The Campus.
Following this, Ryan apparently completes his term and refuses to run for a second elected term. Robby Jackson thus campaigns to become the first African American President, but is assassinated on a trip to the South, which enables Kealty to become the next President. (It is also possible from what Jack Ryan Jr. says in "Teeth of the Tiger" that Jack Sr. resigned, feeling he has done what he needed to as President, and encouraged Robby Jackson to run for the Presidency.) Before Ryan leaves office, he creates "The Campus," a covert counter-terrorism organization that fronts as Hendley Associates, a financial trading firm. He also writes one hundred presidential pardons for its members, with Attorney General Pat Martin's assistance.
Second Ryan Administration.
In his retirement, Ryan is living easy with a net worth of over $80 million. He is working on two versions of his memoirs, one for immediate release, and another detailing his CIA career, to be published posthumously.
However, in "Dead or Alive", he becomes increasingly frustrated with the direction in which President Kealty is taking the country, although he is initially publicly silent. Ultimately, he announces that he will come out of retirement to run for a second full term as President as a Republican candidate. Despite having originally not being involved in the Campus's activities due to his high-profile status, he gradually becomes more directly linked to the Campus's operations, aiding them from behind the scenes on occasion. It is here Ryan learns his elder son, Jack Jr., is a field operative of the Campus.
Ryan campaigns against Kealty in "Locked On", facing off against him in various televised debates. It quickly becomes apparent that Ryan will win the election, as the majority of Americans had never entirely accepted Kealty. Despite the efforts of Paul Laska; a high-profile Czech-American billionaire and a devout enemy of Ryan, and key members of the Kealty administration who labelled Ryan's longtime friend John Clark a fugitive in an effort to expose the Campus (as well as tying Ryan to it by association), Ryan narrowly wins the election, overcoming all of Kealty's efforts to harm him. The President-elect now prepares to undo the damage the Kealty administration has done.
Ryan initially finds his return to the presidency easy and without struggle following his re-election, but things quickly start to take a turn for the worse. Angered by a contraction in economic growth, the majority of the People's Republic of China Politburo Standing Committee members turn against their pro-capitalist President Wei Zhen Lin. Wei attempts to commit suicide when a coup is undertaken by other committee members. It is only when Chairman Su Ke Qiang orders PLA tanks to defend Wei, that he agrees to promote and support Su's expansionist policies, in exchange for Su's ongoing protection. The expansionist policies - which include the annexation of Taiwan and the expansion of China's territory into the South China Sea - are finally revealed to the world after several months. The Ryan administration is vehemently against the new policies, and President Ryan himself decides to take action by supporting Taiwan, along with India, Vietnam, Indonesia and the Philippines, which would also be affected by an expansion of China's territory.
A devastating series of cyber-attacks on American infrastructure occurs, enacted by the "Ghost Ship" - a Chinese state sponsored version of the Campus, using assets of the Chinese MSS and Divine Sword Special Forces. The attacks serve to compromise the nation's national security apparatus and weaken the United States' resolve. The Campus helps track the attacks to China, and local investigation pinpoints the exact building the Ghost Ship is currently quartered in. President Ryan orders the destruction of the building, decapitating China's cyberwarfare abilities.
Ryan makes contact with Wei and warns him that the cyber-attacks are considered an act of war on China's part. Wei repeatedly denies the claim, and reiterates he is supporting Su, though Ryan guesses correctly Su is controlling Wei since saving him from the attempted coup. Ryan appeals to Wei as a businessman to understand what he is doing will destroy China. After a lengthy, unusual pause, Wei responds that he must discuss Ryan's claims with Su, providing exact details of when and where Su will be travelling to address the Politburo in regards to the war effort. Ryan takes the information as a request from Wei to have the United States assassinate Su. A team from The Campus, with support from the Russian FSB, and working with a local rebel force in China, stage an attack on Su while he is traveling in a motorcade. Su is assassinated by a U.S. sniper, but the event is made to look like Su's own men turned on him. Ryan announces a blockade of China's oil supplies until the war effort is abandoned, calling upon Wei and the Politburo to accept defeat.
President Wei accepts that the expansionist movement has failed and the United States has won its second war with China, and decides to take his own life after realizing the Politburo will move against him without Su's protection. Wei botches the suicide by accidentally shooting himself in the cheek, but ends up choking to death on his own blood. Wei and Su's deaths mark the end of the war in the South China Sea, and Ryan emerges the clear victor in the conflict.
Ryan is featured prominently in "Command Authority"; Ryan and his administration contend with the Russian Federation, currently led by their new President; Valeri Volodin. Volodin is established as a dedicated communist opposed to the West, seeking to restore Russia as a strengthened Soviet Union. Volodin moves to establish ties with Iran and China, reunify the nation's state security services under the FSB, and most notably annex the Ukraine. Those opposed to his actions are replaced or assassinated by Russian government forces or elements of the "Seven Strong Men"; a Mafia group that is now the easily the most powerful and dangerous criminal underworld faction in Russia. Later when the FSB and SVR and merged under the FSB's banner, Volodin makes the announcement that FSB director Roman Romanovich Talanov, Volodin's enigmatic enforcer, is the nation's new intelligence chief.
Sergey Golovko, having retired from the SVR and effectively exiled from Russia for acting as a high-profile Kremlin dissident against Volodin and his policies, succumbs to poisoning from a radioactive agent while at a private lunch at the White House. Ryan's old friend dies the next day, but on his deathbed Golovko relays his concerns of Talanov's unknown background and mysterious connection to Volodin to Ryan. Ryan resolves to decipher Talanov's history and work out his links to Volodin, hopeful the answers behind his swift rise to power can be used as leverage against Volodin. As armed conflict becomes increasingly likely, Ryan focuses on the growing armed standoff in the Ukraine and absorption of the Crimea, with the rest of the Ukraine facing imminent Russian invasion. An investigation following Golovko's death implicates the SSM working with the FSB. It also possibly identifies Talanov as a mysterious ex-GRU assassin who operated for the KGB during the Cold War, code-named "Zenith". Ryan is personally alarmed by these discoveries - he became involved in the Zenith affair in his time with the CIA as a MI6 liaison officer, during an investigation into a string of deaths in Berlin, Germany. Ryan ultimately sensed an unknown Russian operator was at work behind the events in Berlin, but he was encouraged by MI6 Director General Sir Basil Charleston to let it go. The mystery of Zenith was left unsolved for 30 years, and remained the sole remaining mystery of Ryan's intelligence career.
Operational assets of the Campus, with Jack Ryan, Jr. leading the effort (much to his father's displeasure and trepidation for his safety), ultimately confirm Talanov was Zenith, and Volodin, a senior KGB officer at the time, still acts as his control officer. As young men, they were employed by members of the KGB and GRU leadership who knew the Soviet Union would eventually fall, but made a plan to survive and prosper in the chaotic aftermath so they could seize control of the nation and turn it back to communism stronger than ever. After siphoning billions from Soviet programs to achieve it, Volodin double-crossed his co-conspirators and had Talanov kill them all so it would be theirs alone. Others were killed to maintain the safety of their black funds, including the bankers killed by Talanov during the Zenith affair so as to prevent exposure to the rest of the KGB. Talanov is also the secret leader of the Seven Strong Men, having been sent undercover with the SSM - placed in a gulag, Talanov worked his way up to become a charter member and leader of the Seven Strong Men, and through them become FSB director for the SSM's benefit and control of the government, when in actuality the SSM was a tool for Volodin's policies.
These discoveries are made with the help of former MI5 officer Victor Oxley, aka "Bedrock" - an off-book MI5 asset who operated as an assassin during the Cold War in similar fashion to Talanov, aka Zenith. Oxley's final mission before his disappearance was to hunt down and kill Zenith, but instead found Ryan, Sr. about to be killed by a German Stasi team working with Zenith. Oxley interfered and saved Ryan's life, but was captured, driven away to Russia, brutally tortured by the KGB and then imprisoned in the same gulag as Talanov ultimately was placed in, accidentally hearing of Talanov being Zenith from other inmates. Oxley and the Campus team confront his traitorous control officer Hugh Castor, who confirms the entire story and protected Volodin and Talanov's secret in exchange for a cut of their black funds, but Castor gives up what he knows for protection by the American government, knowing Talanov will have realized Castor deceived him over the leverage he had. However, Talanov realizes this faster than Castor anticipated - he sends a Spetsnaz team to kill Castor and Oxley, the latter sacrificing himself for Jack Ryan, Jr.
As the Russian invasion force pushes into the Ukraine, the Campus team and Delta Force operators arrest Dmitri Nesterov, aka Gleb the Scar, an SSM capo who is Talanov's second-in-command and who was behind Golovko's poisoning. With Nesterov and the Campus's acquired information in hand, Ryan makes contact with Volodin and confronts him with implications he could be politically destroyed by what he has learned about Zenith and Talanov's ties to the SSM: claiming (falsely) to have suitable evidence gathered that will ruin his government and the invasion, and he must distance himself from Talanov as the Campus has exposed him as a government spy who has been using them all along. Volodin pulls back his troops, in exchange the United States keeps what evidence it has secret. Volodin also forces Talanov to resign from the FSB after his criminal dealings are made public and the SSM turns on him. Despite the promise of protection, Volodin allows Talanov to be killed - he is stabbed by a civilian member of his guard force on Nesterov's orders (having been encouraged by John Clark to have Talanov killed so he could succeed him). The stalemate of Russia and the United States is left ongoing.
Ryan, at this time, is in his mid-sixties and world-famous; and is looking forward to retirement back to the shores of Chesapeake Bay once and for all.
Ryan is mentioned by title only in "Support and Defend"; when a National Security Council staff member, Ethan Ross, is exposed by the FBI as a traitor responsible for leaking classified government information so as to weaken the administration's connections with friendly governments, he proceeds to flee as a fugitive to Venezuela, with an intelligence scrape with enough information to ruin the CIA. Ryan is said to have made Ross's capture or death the government's top priority, establishing him as America's Most Wanted. Ryan's nephew, FBI special agent and Campus operative Dominic Caruso, ultimately succeeds in killing Ross and securing the scrape for the CIA, despite attempts by the Russian FSB and Iranian Quds Force to acquire it.
Novels.
The first published book to feature Jack Ryan was "The Hunt for Red October".
Chronological order.
In the order in which they occur in the storyline (and when they occur):
Starting with the following novel, the series becomes distinctly different from real history as noted below.
Films.
Five films based on Clancy novels featuring Jack Ryan have been produced. The movie portraying the earliest incarnation of Ryan (fifth film chronologically) is titled "" which was released on January 17, 2014 with Chris Pine in which Ryan moves from his accident in the Marines into his CIA career involvement. Other Jack Ryan based films are
portrayed by Alec Baldwin in the 1990 film "The Hunt for Red October", Harrison Ford in "Patriot Games" (1992) and "Clear and Present Danger" (1994), and Ben Affleck in the 2002 film "The Sum of All Fears".
In the novels, "Patriot Games" occurs before "The Hunt for Red October", though the order was reversed in the film versions. Additionally, "The Sum of All Fears" is not part of Baldwin/Ford series, but rather an intended reboot of the franchise which departs significantly from the chronology of the novels. It takes place in 2002 whereas the novel takes place in 1991/1992. "Jack Ryan: Shadow Recruit" is a second reboot of the franchise and departs from all previous films.
Video games.
Many video games based on the series have been made, some based on the novels, some on the films, some on the spin-offs.
In addition there is the "Rainbow Six" video game universe, see Tom Clancy's Rainbow Six

</doc>
<doc id="30766" url="http://en.wikipedia.org/wiki?curid=30766" title="John Clark (Tom Clancy character)">
John Clark (Tom Clancy character)

John T. Clark (real name John Terrence Kelly) is a fictional character created by Tom Clancy who appears in many of Clancy's novels.
Personal life.
John Kelly was born in 1944 in Indianapolis to Irish American Catholic parents. His father, Timothy Kelly, was a fireman who perished from a heart attack during a fire while saving two children. John lost his mother to cancer when he was a young boy. He attended Brebeuf Jesuit Preparatory School in Indianapolis.
His first wife, Patricia, for whom his second daughter would eventually be named, was killed in a car accident when her car went under a tractor/trailer unit. She was pregnant at the time.
Six months after his wife died, John Kelly spent a brief period of time in a relationship with Pamela Madden. Pamela was a former prostitute who had been forced into working as a courier for a drug ring, and she worked with Kelly to bring her former captors to justice. Together, they scouted out the area in which Pamela used to work, intending to share the information with a police contact of John's. While there, Pam was spotted by her former captors and a chase ensued. Thinking that he had lost them, Kelly stopped to talk to Pamela. The traffickers, however, caught up to Kelly's vehicle, shot him, and captured Pamela. She was later tortured and murdered, and her body was dumped in a fountain.
While recovering from his injuries at Johns Hopkins Hospital, he met his future second wife, nurse Sandra "Sandy" O'Toole. They eventually had two daughters, Patricia Doris and Margaret Pamela. The girls' middle names were taken from two girls whom Kelly had temporarily rescued from the drug ring, who eventually murdered them. Patricia, a doctor, went on to marry Domingo "Ding" Chavez, who worked with Kelly (who at this point had adopted the identity of John Clark) in the CIA, during a black operation in Colombia, and later as an assault team leader. In "Rainbow Six," Patricia gave birth to a son, John Conor Chavez, making John a grandfather.
Professional life.
Clark originally joined the Navy during the Vietnam War (as John Terrence Kelly) and became a Navy SEAL who participated in several special operations, one of which was the rescue of a naval aviator shot down over North Vietnam. After his first tour of duty, Kelly left the service, but is later re-hired by the Central Intelligence Agency's (CIA) Special Activities Division (Special Operations Group) for another mission in Vietnam. At the same time at home, Kelly is carrying out his own war against a drug ring that killed his girlfriend, Pamela Madden. While he succeeds in taking it down, the Baltimore Police Department (including Emmet Ryan, Jack Ryan's father) eventually identifies him as the man who murdered the drug dealers. In response, Kelly fakes his own death (with the help of the CIA, which falsifies the identity of the fingerprints found at one of the murder scenes) and goes to work for the CIA full-time, under the pseudonym "John Clark". (See "Without Remorse") His middle name appears variously with one and two 'R's, and the name "John Terrence Clark" does appear in the novel "Clear and Present Danger".
Throughout his career, Clark has been through a number of real-life crisis zones. In addition to the Vietnam War, he has also been through the Iran hostage crisis and the Gulf War, plus a number of missions in the Soviet Union, and claims to have "had Abu Nidal's head in my gunsights", but never got the green light allowing him to kill the man ("Clear and Present Danger").
He first enters the Jack Ryan universe in "Without Remorse", which contains Officer Emmett Ryan with his son Jack. Although he does not appear in "Patriot Games", it is later revealed that he was the CIA's liaison with a French black ops unit involved in the campaign against the ULA. He appears briefly in "The Cardinal of the Kremlin", during which he extracts KGB Chairman Gerasimov's wife and daughter from Leningrad after the Chairman decides to defect to the United States. This marks Clark's first published appearance.
In "Clear and Present Danger," he commands a U.S. Army black-ops unit carrying out a secret war against the Cali Cartel in Colombia. When the government abandons the men for political reasons, Clark and Jack Ryan fly down to Colombia and rescue the survivors. This is the first time he interacts with Ryan.
In "The Sum of All Fears", he is Ryan's personal driver and bodyguard. Later in the novel, he is returned to the field for one operation, electronically bugging the aircraft of the Japanese Prime Minister in Mexico City. During the operation, the terrorist bombing in Denver occurs and his mission is changed to intercepting the Palestinian terrorists trying to escape through Mexico, which he does successfully. He interrogates them and secures their confessions, then hands them over the judicial system for eventual Islamic justice (execution by sword) in Riyadh.
In "Debt of Honor", he is again a field officer for the CIA's Directorate of Operations (DO). At the beginning of the novel, he and his partner Domingo Chavez capture an Aidid-like African warlord, Mohammed Abdul Corp, and bring him to justice. Soon thereafter, they are sent to Japan to assess the national mood of the country—Clark is under cover as a Russian reporter. When the situation turns into a war between Japan and America, they establish contacts with the opposition in the Japanese government and are also used to eliminate a pair of Japanese AWACS planes.
Clark spends the first half of the next book, "Executive Orders", serving as an instructor for CIA field officers in training. Early in the novel, Jack Ryan, the new President, issues a presidential pardon to John Terence Kelly for his several murders (Although the President can only pardon Federal offenses, Kelly's murders were federal crimes because they took place in D.C.). This clears his name and personal honor, but he will continue his career as John Clark. Towards the end of the book, he and Chavez are returned to the field and ordered to discover who is responsible for the Ebola attack on the United States, an action they quickly trace to the new United Islamic Republic (comprising Iran and Iraq). With the cooperation of the Russian SVR, they are infiltrated into Tehran, where they laser-designate the home of UIR dictator Mahmoud Haji Daryaei so that Air Force stealth aircraft can destroy the house.
The next year, Clark writes a memo to the CIA expressing his concerns over the rise of international terrorism since the demise of the Cold War, and recommends creating a NATO response team that could be rapidly deployed in terrorist situations. This special unit is created soon thereafter, with its base in Hereford, Britain. It is code-named Rainbow, and Clark is put in command of the unit with the simulated rank of Major General.
In the book "Rainbow Six", Rainbow is first put into operation. It responds successfully to three attacks by "Red" terrorists in Bern, Vienna, and Spain. It also succeeds in defending itself from an attack by the Provisional Irish Republican Army (PIRA) against its home base. This is eventually determined to have been ordered by a radical eco-terrorist group, which Rainbow tracks down and destroys in the last pages of the novel.
Clark's next appearance is in "The Bear and the Dragon", where he is still the head of Rainbow. In the novel, Rainbow is temporarily reassigned from its anti-terrorist duties to the Russian-Chinese war being fought in Siberia. In a joint Rainbow-Spetsnaz operation, he is involved in the destruction of China's only ICBM base. The operation is mostly successful: all but one of the missiles is destroyed, and the last one, while it is fired, is destroyed by the Navy before it can reach its intended target.
Neither Clark nor Rainbow appears in "The Teeth of the Tiger", but it is revealed that Rainbow is still operating. Prior to Jack Ryan resigning as President, Clark's Navy Cross was upgraded to the Medal of Honor. During the Medal of Honor ceremony Jack Ryan, Jr. was present in the Oval Office.
Clark returns in "Dead or Alive", in which he is part of a Rainbow team that successfully rescues all hostages taken by terrorists at the Swedish embassy in Libya. This proves to be his last act with the CIA, as he is pushed into retirement by Kealty political appointees. He then joins The Campus, an "off-the-books" intelligence agency that Jack Ryan had founded late in his Presidency. Clark is immediately involved with the organization's effort to find and neutralize "The Emir", an international terrorist leader modeled on Osama bin Laden, while also serving as mentor and trainer to Jack's son Jack Jr., a Campus analyst who wants to do field work.
In "Locked On", Clark continues his work with The Campus as Jack Ryan Sr. runs for election against President Kealty. The Campus's efforts focus on a new terrorist kingpin based in Pakistan, General Riaz Rehan, who works to orchestrate a coup in Pakistan. While The Campus works to interfere with Rehan, Clark finds himself the target of a government manhunt and private intelligence trackers, forcing him to go on the run. Instead of going into hiding, Clark works to clear his name in Eastern Europe, while the remaining Campus operators work to foil Rehan's designs on Pakistan. Clark is successfully in tracking the allegations back to a rogue operation between SVR officer Valentin Kovalenko and Czech-American billionaire Pavel "Paul" Laska; the latter of which, having discovered through the imprisonment of the Emir, the involvement of Clark, Chavez, Ryan Jr. and Caruso in his capture, and so worked with Kovalenko and his agents to pass the information about Clark's technically illegal activities to President Kealty and his supporters in the US government, resulting in a manhunt that would damage Ryan's image during the election. Clark is able to get this information to The Campus, but is captured shortly after. Kovalenko and his men torture Clark for information on his employers, but Clark is saved without giving any information up by Russian FSB internal security officers, led by its director Stanislav Biryukov - Clark's Russian counterpart. After working out a deal with Biryukov to expose and bring down Laska, Clark works with Rainbow to foil terrorists' attempts to launch a nuclear weapon at Moscow.
In "Threat Vector", it is established Clark has been completely exonerated and has returned to his life - a public apology by outgoing U.S. President Kealty, and the revelation the world's press were being manipulated by elements of Russian intelligence, results in the matter being dropped quickly. After an operation to eliminate a group of former Libyan military intelligence operatives, Clark, still recovering from his injuries suffered by Kovalenko and his men, combined with his increasing age, decides it is time to properly retire - and submits his resignation to the Campus. Later, however, Clark temporarily returns to the Campus after an attack by Chinese Special Forces, and with the Campus operators, travels to China (calling in his favor with the Russian FSB for the support and equipment needed for their mission) and works with local rebels to assassinate Chairman Su Ke Qiang - effectively ending the Second America-China War.
Outside the novels, John Clark's career continues further in the "Rainbow Six" video game series. In ', John retires and passes the leadership of Team Rainbow on to his son-in-law, Domingo "Ding" Chavez. In the next video game, ', although Ding Chavez appears in the game, as Rainbow commander, no mention is made of John Clark.
Analysis.
John Clark has been awarded the Navy Cross, Silver Star with an oak leaf cluster, Bronze Star with Valor devices with 3 oak leaf clusters, three Purple Hearts and four Intelligence Stars. He is also recipient of the Medal of Honor, awarded and presented to him by Jack Ryan (then President of the U.S.) for the rescue of a downed fighter pilot during his time in Vietnam (see "Without Remorse"). He is a simulated major general in the "Rainbow Six" book, though he only reached the rank of Chief Boatswain's Mate (Chief Petty Officer) during his Naval career.
Clark has a small tattoo of a red seal, sitting up on its hind flippers "grinning impudently," on his forearm. Though no other visual details are given, a comment made by Lieutenant Colonel Daniel "Bear" Malloy in "Rainbow Six" indicated that at least some of the Ryanverse Special Operations community had heard of the red seal tattoo and understood that it was associated with the Third Special Operations Group (SOG), with whom Clark served during the Vietnam War. Clark stated that everyone in his unit got the tattoo. In the real world, having such a tattoo would violate operations security (OPSEC) (however, similar tattoos are not particularly uncommon, so long as the tattoo is not specifically unit identifiable). Also, the Third Special Operations Group is not a real military unit (however, a similarly named group, the "Studies and Observation Group" MACV-SOG, which had initially been named the "Special Operations Group"; was active in Vietnam, in the types of operations and environments referenced in the series; and had Navy SEALs among its personnel) . The symbol of the red seal is actually the unit insignia for SEAL Team 1.
Parallels can be drawn between John Clark and Jack Ryan, who both exist within the same fictional universe. Clark is more capable of bending the rules and operating outside the law than Ryan is, so Clancy uses him in grittier roles. Clark also loathes the "desk work" that Ryan typically finds himself "at home" doing. Clancy himself has stated that John Clark is the "dark side" of Jack Ryan.
In books.
The character John Clark appears in the following books:
In films.
On film, John Clark has been portrayed by Willem Dafoe in "Clear and Present Danger" and Liev Schreiber in "The Sum of All Fears". As of now Paramount is trying to get "Without Remorse" off the ground - the screenplay has to be written yet, a director has to be picked and it still needs a budget. Currently there is not an actor attached to play John Clark, although reportedly Paramount is interested in pursuing Tom Hardy.
In the 1996 novel "Executive Orders", Clark sarcastically suggests to reporter Robert Holtzman "Get Val Kilmer to play me in the movies" to which Holtzman replies "Too pretty, Nick Cage has a better stare."
Various directors, screenwriters, and actors have been involved in attempts to film other novels in which John Clark appears, but none of these movies were produced.

</doc>
<doc id="30769" url="http://en.wikipedia.org/wiki?curid=30769" title="Thích Nhất Hạnh">
Thích Nhất Hạnh

Thích Nhất Hạnh (; ]; born as Nguyen Xuan Bao on October 11, 1926) is a Vietnamese Zen Buddhist monk, teacher, author, poet and peace activist. He lives in the Plum Village Monastery in the Dordogne region in the South of France, travelling internationally to give retreats and talks. He coined the term Engaged Buddhism in his book "Vietnam: Lotus in a Sea of Fire". A long-term exile, he was given permission to make his first return trip to Vietnam in 2005.
Nhất Hạnh has published more than 100 books, including more than 40 in English. Nhat Hanh is active in the peace movement, promoting non-violent solutions to conflict and he also refrains from animal product consumption as a means of non-violence towards non-human animals.
In November 2014, Nhất Hạnh experienced a severe brain hemorrhage and was brought back to a hospital. After months of rehabilitation, Nhất Hạnh was released from the stroke rehabilitation clinic at Bordeaux University Hospital where he had recovered enough to "enjoy going outside, sitting under a tree and listening to birdsong, drinking a cup of tea and enjoying the sound of the bell". With the guidance of visiting doctors and nurses, as of April 2015, Nhất Hạnh resides at his hermitage at Plum Village where attendants from the monastery continue to help him recover from hemiparesis with the goal of improving his swallowing and recovering his speech.
Biography.
Born as Nguyễn Xuân Bảo, Nhất Hạnh was born in the city of Thừa Thiên Huế in Central Vietnam in 1926. At the age of 16 he entered the monastery at Từ Hiếu Temple near Huế, Vietnam, where his primary teacher was Dhyana (meditation Zen) Master Thanh Quý Chân Thật.
 A graduate of Bao Quoc Buddhist Academy in Central Vietnam, Thich Nhat Hanh received training in Zen and the Mahayana school of Buddhism and was ordained as a monk in 1949.
In 1956, he was named editor-in-chief of "Vietnamese Buddhism", the periodical of the Unified Vietnam Buddhist Association (Giáo Hội Phật Giáo Việt Nam Thống Nhất). In the following years he founded Lá Bối Press, the Van Hanh Buddhist University in Saigon, and the School of Youth for Social Service (SYSS), a neutral corps of Buddhist peaceworkers who went into rural areas to establish schools, build healthcare clinics, and help rebuild villages.
Nhat Hanh is now recognized as a Dharmacharya and as the spiritual head of the Từ Hiếu Temple and associated monasteries. On May 1, 1966 at Từ Hiếu Temple, he received the "lamp transmission", making him a Dharmacharya or Dharma Teacher, from Master Chân Thật.
During the Vietnam War.
In 1960, Nhat Hanh went to the U.S. to study comparative religion at Princeton University, and was subsequently appointed lecturer in Buddhism at Columbia University. By then he had gained fluency in French, Chinese, Sanskrit, Pali, Japanese and English, in addition to his native Vietnamese. In 1963, he returned to Vietnam to aid his fellow monks in their non-violent peace efforts.
Nhat Hanh taught Buddhist psychology and "Prajnaparamita" literature at the Van Hanh Buddhist University, a private institution that focused on Buddhist studies, Vietnamese culture, and languages. At a meeting in April 1965 Van Hanh Union students issued a "Call for Peace" statement. It declared: "It is time for North and South Vietnam to find a way to stop the war and help all Vietnamese people live peacefully and with mutual respect." Nhat Hanh left for the U.S. shortly afterwards, leaving Sister Chan Khong in charge of the SYSS. Van Hanh University was taken over by one of the Chancellors who wished to sever ties with Thich Nhat Hanh and the SYSS, accusing Chan Khong of being a communist. From that point the SYSS struggled to raise funds and faced attacks on its members. The SYSS persisted in their relief efforts without taking sides in the conflict.
Nhat Hanh returned to the US in 1966 to lead a symposium in Vietnamese Buddhism at Cornell University and to continue his work for peace. He had written a letter to Martin Luther King, Jr. in 1965 entitled: "In Search of the Enemy of Man". It was during his 1966 stay in the U.S. that Thich Nhat Hanh met with Martin Luther King, Jr. and urged him to publicly denounce the Vietnam War. In 1967, Dr. King gave a famous speech at the Riverside Church in New York City, his first to publicly question the U.S. involvement in Vietnam. Later that year Dr. King nominated Thich Nhat Hanh for the 1967 Nobel Peace Prize. In his nomination Dr. King said, "I do not personally know of anyone more worthy of [this prize] than this gentle monk from Vietnam. His ideas for peace, if applied, would build a monument to ecumenism, to world brotherhood, to humanity". The fact that King had revealed the candidate he had chosen to nominate and had made a "strong request" to the prize committee, was in sharp violation of the Nobel traditions and protocol. The committee did not make an award that year.
In 1969, Nhat Hanh was the delegate for the Buddhist Peace Delegation at the Paris Peace talks. When the Paris Peace Accords were signed in 1973, Thich Nhat Hanh was denied permission to return to Vietnam and he went into exile in France. From 1976–1977 he led efforts to help rescue Vietnamese boat people in the Gulf of Siam, eventually stopping under pressure from the governments of Thailand and Singapore.
Establishing the Order of Interbeing.
Nhat Hanh created the Order of Inter-Being in 1966. He heads this monastic and lay group, teaching Five Mindfulness Trainings and Fourteen Precepts. In 1969, Nhat Hanh established the Unified Buddhist Church (Église Bouddhique Unifiée) in France (not a part of the Unified Buddhist Church of Vietnam). In 1975, he formed the Sweet Potatoes Meditation Center. The center grew and in 1982 he and his colleague Sister Chân Không founded Plum Village Buddhist Center (Làng Mai), a monastery and Practice Center in the Dordogne in the south of France. The Unified Buddhist Church is the legally recognized governing body for Plum Village (Làng Mai) in France, for Blue Cliff Monastery in Pine Bush, New York, the Community of Mindful Living, Parallax Press, Deer Park Monastery in California, Magnolia Village in Batesville, Mississippi, and the European Institute of Applied Buddhism in Waldbröl, Germany.
He established two monasteries in Vietnam, at the original Từ Hiếu Temple near Huế and at Prajna Temple in the central highlands. Thich Nhat Hanh and the Order of Interbeing have established monasteries and Dharma centers in the United States at Deer Park Monastery (Tu Viện Lộc Uyển) in Escondido, California, Maple Forest Monastery (Tu Viện Rừng Phong) and Green Mountain Dharma Center (Ðạo Tràng Thanh Sơn) in Vermont both of which closed in 2007 and moved to the Blue Cliff Monastery in Pine Bush, New York, and Magnolia Village Practice Center (Đạo Tràng Mộc Lan) in Mississippi. These monasteries are open to the public during much of the year and provide on-going retreats for lay people. The Order of Interbeing also holds retreats for specific groups of lay people, such as families, teenagers, veterans, the entertainment industry, members of Congress, law enforcement officers and people of color. He conducted a peace walk in Los Angeles in 2005, and again in 2007.
Notable students of Thich Nhat Hanh include: Skip Ewing founder of the Nashville Mindfulness Center, Natalie Goldberg author and teacher, Joan Halifax founder of the Upaya Institute, Stephanie Kaza environmentalist, Sister Chan Khong Dharma teacher, Noah Levine author, Albert Low Zen teacher and author, Joanna Macy environmentalist and author, John Croft co-creator of Dragon Dreaming, Caitriona Reed Dharma teacher and co-founder of Manzanita Village Retreat Center, Leila Seth author and Chief Justice of the Delhi High Court, and Pritam Singh real estate developer and editor of several of Nhat Hanh's books.
Return to Vietnam.
In 2005, following lengthy negotiations, Nhat Hanh was given permission from the Vietnamese government to return for a visit. He was also allowed to teach there, publish four of his books in Vietnamese, and travel the country with monastic and lay members of his Order, including a return to his root temple, Tu Hieu Temple in Huế. The trip was not without controversy. Thich Vien Dinh, writing on behalf of the Unified Buddhist Church of Vietnam (considered illegal by the Vietnamese government), called for Nhat Hanh to make a statement against the Vietnam government's poor record on religious freedom. Thich Vien Dinh feared that the trip would be used as propaganda by the Vietnamese government, suggesting to the world that religious freedom is improving there, while abuses continue.
Despite the controversy, Nhat Hanh again returned to Vietnam in 2007, while two senior officials of the banned Unified Buddhist Church of Vietnam (UBCV) remained under house arrest. The Unified Buddhist Church called Nhat Hanh's visit a betrayal, symbolizing Nhat Hanh's willingness to work with his co-religionists' oppressors. Vo Van Ai, a spokesman for the UBCV said "I believe Thich Nhat Hanh's trip is manipulated by the Hanoi government to hide its repression of the Unified Buddhist Church and create a false impression of religious freedom in Vietnam." The Plum Village Website states that the three goals of his 2007 trip back to Vietnam were to support new monastics in his Order; to organize and conduct "Great Chanting Ceremonies" intended to help heal remaining wounds from the Vietnam War; and to lead retreats for monastics and lay people. The chanting ceremonies were originally called "Grand Requiem for Praying Equally for All to Untie the Knots of Unjust Suffering", but Vietnamese officials objected, saying it was unacceptable for the government to "equally" pray for soldiers in the South Vietnamese army or U.S. soldiers. Nhat Hanh agreed to change the name to "Grand Requiem For Praying".
Other.
In 2014, for the first time in history major Anglican, Catholic, and Orthodox Christian leaders, as well as Jewish, Muslim, Hindu, and Buddhist leaders (including Chân Không, representing Nhất Hạnh), met to sign a shared commitment against modern-day slavery; the declaration they signed calls for the elimination of slavery and human trafficking by the year 2020.
Approach.
Nhat Hanh's approach has been to combine a variety of traditional Zen teachings with insights from other Mahayana Buddhist traditions, methods from Theravada Buddhism, and ideas from Western psychology—to offer a modern light on meditation practice. Hanh's presentation of the Prajñāpāramitā in terms of "interbeing" has doctrinal antecedents in the Huayan school of thought, which "is often said to provide a philosophical foundation" for Zen.
Nhat Hanh has also been a leader in the Engaged Buddhism movement (he coined the term), promoting the individual's active role in creating change. He cites the 13th-century Vietnamese King Trần Nhân Tông with the origination of the concept. Trần Nhân Tông abdicated his throne to become a monk, and founded the Vietnamese Buddhist school in the Bamboo Forest tradition.
Names applied to him.
The Vietnamese name "Thích" (釋) is from "Thích Ca" or "Thích Già" (釋迦), means "of the Shakya (Shakyamuni Buddha) clan." All Buddhist monks and nuns within the East Asian tradition of Mahayana and Zen adopt this name as their "family" name or surname implying that their first family is the Buddhist community. In many Buddhist traditions, there is a progression of names that a person can receive. The first, the lineage name, is given when a person takes refuge in the Three Jewels. Thich Nhat Hanh's lineage name is Trừng Quang. The next is a Dharma name, given when a person, lay or monastic, takes additional vows or when one is ordained as a monastic. Thich Nhat Hanh's Dharma name is Phung Xuan. Additionally, Dharma titles are sometimes given, and Thich Nhat Hanh's Dharma title is "Nhat Hanh".
Neither "Nhất" (一) nor "Hạnh" (行)—which approximate the roles of middle name or intercalary name and given name, respectively, when referring to him in English—was part of his name at birth. "Nhất" (一) means "one", implying "first-class", or "of best quality", in English; "Hạnh" (行) means "move", implying "right conduct" or "good nature." Thích Nhất Hạnh has translated his Dharma names as Nhất = One, and Hạnh = Action. Vietnamese names follow this naming convention, placing the family or surname first, then the middle or intercalary name which often refers to the person's position in the family or generation, followed by the given name.
Thich Nhat Hanh is often referred to as "Thay" (Vietnamese: "Thầy", "master; teacher") or Thay Nhat Hanh by his followers. On the Vietnamese version of the Plum Village website, he is also referred to as Thiền Sư Nhất Hạnh which can be translated as "Zen Master", or "Dhyana Master". Any Vietnamese monk or nun in the Mahayana tradition can be addressed as "Thầy" ("teacher"). Vietnamese Buddhist monks are addressed "Thầy tu" ("monk") and nuns are addressed "Sư Cô" ("Sister") or "Sư Bà" ("Elder Sister").
Awards and honors.
Nobel laureate Martin Luther King, Jr. nominated Nhat Hanh for the Nobel Peace Prize in 1967. However, the prize was not awarded to anybody that year. Nhat Hanh was awarded the Courage of Conscience award in 1991.
He has been featured in many films, including "The Power of Forgiveness" showcased at the Dawn Breakers International Film Festival.
Nhat Hanh, along with Alfred Hassler and Sister Chan Khong, became the subject of a graphic novel entitled "The Secret of the 5 Powers" in 2013.

</doc>
